{
    "id": "H-83",
    "original_text": "Estimating the Global PageRank of Web Communities Jason V. Davis Dept. of Computer Sciences University of Texas at Austin Austin, TX 78712 jdavis@cs.utexas.edu Inderjit S. Dhillon Dept. of Computer Sciences University of Texas at Austin Austin, TX 78712 inderjit@cs.utexas.edu ABSTRACT Localized search engines are small-scale systems that index a particular community on the web. They offer several benefits over their large-scale counterparts in that they are relatively inexpensive to build, and can provide more precise and complete search capability over their relevant domains. One disadvantage such systems have over large-scale search engines is the lack of global PageRank values. Such information is needed to assess the value of pages in the localized search domain within the context of the web as a whole. In this paper, we present well-motivated algorithms to estimate the global PageRank values of a local domain. The algorithms are all highly scalable in that, given a local domain of size n, they use O(n) resources that include computation time, bandwidth, and storage. We test our methods across a variety of localized domains, including site-specific domains and topic-specific domains. We demonstrate that by crawling as few as n or 2n additional pages, our methods can give excellent global PageRank estimates. Categories and Subject Descriptors H.3.3 [Information Storage and Retrieval]: Information Search and Retrieval; G.1.3 [Numerical Analysis]: Numerical Linear Algebra; G.3 [Probability and Statistics]: Markov Processes General Terms PageRank, Markov Chain, Stochastic Complementation 1. INTRODUCTION Localized search engines are small-scale search engines that index only a single community of the web. Such communities can be site-specific domains, such as pages within the cs.utexas.edu domain, or topic-related communitiesfor example, political websites. Compared to the web graph crawled and indexed by large-scale search engines, the size of such local communities is typically orders of magnitude smaller. Consequently, the computational resources needed to build such a search engine are also similarly lighter. By restricting themselves to smaller, more manageable sections of the web, localized search engines can also provide more precise and complete search capabilities over their respective domains. One drawback of localized indexes is the lack of global information needed to compute link-based rankings. The PageRank algorithm [3], has proven to be an effective such measure. In general, the PageRank of a given page is dependent on pages throughout the entire web graph. In the context of a localized search engine, if the PageRanks are computed using only the local subgraph, then we would expect the resulting PageRanks to reflect the perceived popularity within the local community and not of the web as a whole. For example, consider a localized search engine that indexes political pages with conservative views. A person wishing to research the opinions on global warming within the conservative political community may encounter numerous such opinions across various websites. If only local PageRank values are available, then the search results will reflect only strongly held beliefs within the community. However, if global PageRanks are also available, then the results can additionally reflect outsiders views of the conservative community (those documents that liberals most often access within the conservative community). Thus, for many localized search engines, incorporating global PageRanks can improve the quality of search results. However, the number of pages a local search engine indexes is typically orders of magnitude smaller than the number of pages indexed by their large-scale counterparts. Localized search engines do not have the bandwidth, storage capacity, or computational power to crawl, download, and compute the global PageRanks of the entire web. In this work, we present a method of approximating the global PageRanks of a local domain while only using resources of the same order as those needed to compute the PageRanks of the local subgraph. Our proposed method looks for a supergraph of our local subgraph such that the local PageRanks within this supergraph are close to the true global PageRanks. We construct this supergraph by iteratively crawling global pages on the current web frontier-i.e., global pages with inlinks from pages that have already been crawled. In order to provide 116 Research Track Paper a good approximation to the global PageRanks, care must be taken when choosing which pages to crawl next; in this paper, we present a well-motivated page selection algorithm that also performs well empirically. This algorithm is derived from a well-defined problem objective and has a running time linear in the number of local nodes. We experiment across several types of local subgraphs, including four topic related communities and several sitespecific domains. To evaluate performance, we measure the difference between the current global PageRank estimate and the global PageRank, as a function of the number of pages crawled. We compare our algorithm against several heuristics and also against a baseline algorithm that chooses pages at random, and we show that our method outperforms these other methods. Finally, we empirically demonstrate that, given a local domain of size n, we can provide good approximations to the global PageRank values by crawling at most n or 2n additional pages. The paper is organized as follows. Section 2 gives an overview of localized search engines and outlines their advantages over global search. Section 3 provides background on the PageRank algorithm. Section 4 formally defines our problem, and section 5 presents our page selection criteria and derives our algorithms. Section 6 provides experimental results, section 7 gives an overview of related work, and, finally, conclusions are given in section 8. 2. LOCALIZED SEARCH ENGINES Localized search engines index a single community of the web, typically either a site-specific community, or a topicspecific community. Localized search engines enjoy three major advantages over their large-scale counterparts: they are relatively inexpensive to build, they can offer more precise search capability over their local domain, and they can provide a more complete index. The resources needed to build a global search engine are enormous. A 2003 study by Lyman et al. [13] found that the surface web (publicly available static sites) consists of 8.9 billion pages, and that the average size of these pages is approximately 18.7 kilobytes. To download a crawl of this size, approximately 167 terabytes of space is needed. For a researcher who wishes to build a search engine with access to a couple of workstations or a small server, storage of this magnitude is simply not available. However, building a localized search engine over a web community of a hundred thousand pages would only require a few gigabytes of storage. The computational burden required to support search queries over a database this size is more manageable as well. We note that, for topic-specific search engines, the relevant community can be efficiently identified and downloaded by using a focused crawler [21, 4]. For site-specific domains, the local domain is readily available on their own web server. This obviates the need for crawling or spidering, and a complete and up-to-date index of the domain can thus be guaranteed. This is in contrast to their large-scale counterparts, which suffer from several shortcomings. First, crawling dynamically generated pages-pages in the hidden web-has been the subject of research [20] and is a non-trivial task for an external crawler. Second, site-specific domains can enable the robots exclusion policy. This prohibits external search engines crawlers from downloading content from the domain, and an external search engine must instead rely on outside links and anchor text to index these restricted pages. By restricting itself to only a specific domain of the internet, a localized search engine can provide more precise search results. Consider the canonical ambiguous search query, jaguar, which can refer to either the car manufacturer or the animal. A scientist trying to research the habitat and evolutionary history of a jaguar may have better success using a finely tuned zoology-specific search engine than querying Google with multiple keyword searches and wading through irrelevant results. A method to learn better ranking functions for retrieval was recently proposed by Radlinski and Joachims [19] and has been applied to various local domains, including Cornell Universitys website [8]. 3. PAGERANK OVERVIEW The PageRank algorithm defines the importance of web pages by analyzing the underlying hyperlink structure of a web graph. The algorithm works by building a Markov chain from the link structure of the web graph and computing its stationary distribution. One way to compute the stationary distribution of a Markov chain is to find the limiting distribution of a random walk over the chain. Thus, the PageRank algorithm uses what is sometimes referred to as the random surfer model. In each step of the random walk, the surfer either follows an outlink from the current page (i.e. the current node in the chain), or jumps to a random page on the web. We now precisely define the PageRank problem. Let U be an m × m adjacency matrix for a given web graph such that Uji = 1 if page i links to page j and Uji = 0 otherwise. We define the PageRank matrix PU to be: PU = αUD−1 U + (1 − α)veT , (1) where DU is the (unique) diagonal matrix such that UD−1 U is column stochastic, α is a given scalar such that 0 ≤ α ≤ 1, e is the vector of all ones, and v is a non-negative, L1normalized vector, sometimes called the random surfer vector. Note that the matrix D−1 U is well-defined only if each column of U has at least one non-zero entry-i.e., each page in the webgraph has at least one outlink. In the presence of such dangling nodes that have no outlinks, one commonly used solution, proposed by Brin et al. [3], is to replace each zero column of U by a non-negative, L1-normalized vector. The PageRank vector r is the dominant eigenvector of the PageRank matrix, r = PU r. We will assume, without loss of generality, that r has an L1-norm of one. Computationally, r can be computed using the power method. This method first chooses a random starting vector r(0) , and iteratively multiplies the current vector by the PageRank matrix PU ; see Algorithm 1. In general, each iteration of the power method can take O(m2 ) operations when PU is a dense matrix. However, in practice, the number of links in a web graph will be of the order of the number of pages. By exploiting the sparsity of the PageRank matrix, the work per iteration can be reduced to O(km), where k is the average number of links per web page. It has also been shown that the total number of iterations needed for convergence is proportional to α and does not depend on the size of the web graph [11, 7]. Finally, the total space needed is also O(km), mainly to store the matrix U. 117 Research Track Paper Algorithm 1: A linear time (per iteration) algorithm for computing PageRank. ComputePR(U) Input: U: Adjacency matrix. Output: r: PageRank vector. Choose (randomly) an initial non-negative vector r(0) such that r(0) 1 = 1. i ← 0 repeat i ← i + 1 ν ← αUD−1 U r(i−1) {α is the random surfing probability} r(i) ← ν + (1 − α)v {v is the random surfer vector.} until r(i) − r(i−1) < δ {δ is the convergence threshold.} r ← r(i) 4. PROBLEM DEFINITION Given a local domain L, let G be an N × N adjacency matrix for the entire connected component of the web that contains L, such that Gji = 1 if page i links to page j and Gji = 0 otherwise. Without loss of generality, we will partition G as: G = L Gout Lout Gwithin , (2) where L is the n × n local subgraph corresponding to links inside the local domain, Lout is the subgraph that corresponds to links from the local domain pointing out to the global domain, Gout is the subgraph containing links from the global domain into the local domain, and Gwithin contains links within the global domain. We assume that when building a localized search engine, only pages inside the local domain are crawled, and the links between these pages are represented by the subgraph L. The links in Lout are also known, as these point from crawled pages in the local domain to uncrawled pages in the global domain. As defined in equation (1), PG is the PageRank matrix formed from the global graph G, and we define the global PageRank vector of this graph to be g. Let the n-length vector p∗ be the L1-normalized vector corresponding to the global PageRank of the pages in the local domain L: p∗ = EL g ELg 1 , where EL = [ I | 0 ] is the restriction matrix that selects the components from g corresponding to nodes in L. Let p denote the PageRank vector constructed from the local domain subgraph L. In practice, the observed local PageRank p and the global PageRank p∗ will be quite different. One would expect that as the size of local matrix L approaches the size of global matrix G, the global PageRank and the observed local PageRank will become more similar. Thus, one approach to estimating the global PageRank is to crawl the entire global domain, compute its PageRank, and extract the PageRanks of the local domain. Typically, however, n N , i.e., the number of global pages is much larger than the number of local pages. Therefore, crawling all global pages will quickly exhaust all local resources (computational, storage, and bandwidth) available to create the local search engine. We instead seek a supergraph ˆF of our local subgraph L with size O(n). Our goal Algorithm 2: The FindGlobalPR algorithm. FindGlobalPR(L, Lout, T, k) Input: L: zero-one adjacency matrix for the local domain, Lout: zero-one outlink matrix from L to global subgraph as in (2), T: number of iterations, k: number of pages to crawl per iteration. Output: ˆp: an improved estimate of the global PageRank of L. F ← L Fout ← Lout f ← ComputePR(F ) for (i = 1 to T) {Determine which pages to crawl next} pages ← SelectNodes(F , Fout, f, k) Crawl pages, augment F and modify Fout {Update PageRanks for new local domain} f ← ComputePR(F ) end {Extract PageRanks of original local domain & normalize} ˆp ← ELf ELf 1 is to find such a supergraph ˆF with PageRank ˆf, so that ˆf when restricted to L is close to p∗ . Formally, we seek to minimize GlobalDiff( ˆf) = EL ˆf EL ˆf 1 − p∗ 1 . (3) We choose the L1 norm for measuring the error as it does not place excessive weight on outliers (as the L2 norm does, for example), and also because it is the most commonly used distance measure in the literature for comparing PageRank vectors, as well as for detecting convergence of the algorithm [3]. We propose a greedy framework, given in Algorithm 2, for constructing ˆF . Initially, F is set to the local subgraph L, and the PageRank f of this graph is computed. The algorithm then proceeds as follows. First, the SelectNodes algorithm (which we discuss in the next section) is called and it returns a set of k nodes to crawl next from the set of nodes in the current crawl frontier, Fout. These selected nodes are then crawled to expand the local subgraph, F , and the PageRanks of this expanded graph are then recomputed. These steps are repeated for each of T iterations. Finally, the PageRank vector ˆp, which is restricted to pages within the original local domain, is returned. Given our computation, bandwidth, and memory restrictions, we will assume that the algorithm will crawl at most O(n) pages. Since the PageRanks are computed in each iteration of the algorithm, which is an O(n) operation, we will also assume that the number of iterations T is a constant. Of course, the main challenge here is in selecting which set of k nodes to crawl next. In the next section, we formally define the problem and give efficient algorithms. 5. NODE SELECTION In this section, we present node selection algorithms that operate within the greedy framework presented in the previous section. We first give a well-defined criteria for the page selection problem and provide experimental evidence that this criteria can effectively identify pages that optimize our problem objective (3). We then present our main al118 Research Track Paper gorithmic contribution of the paper, a method with linear running time that is derived from this page selection criteria. Finally, we give an intuitive analysis of our algorithm in terms of leaks and flows. We show that if only the flow is considered, then the resulting method is very similar to a widely used page selection heuristic [6]. 5.1 Formulation For a given page j in the global domain, we define the expanded local graph Fj: Fj = F s uT j 0 , (4) where uj is the zero-one vector containing the outlinks from F into page j, and s contains the inlinks from page j into the local domain. Note that we do not allow self-links in this framework. In practice, self-links are often removed, as they only serve to inflate a given pages PageRank. Observe that the inlinks into F from node j are not known until after node j is crawled. Therefore, we estimate this inlink vector as the expectation over inlink counts among the set of already crawled pages, s = F T e F T e 1 . (5) In practice, for any given page, this estimate may not reflect the true inlinks from that page. Furthermore, this expectation is sampled from the set of links within the crawled domain, whereas a better estimate would also use links from the global domain. However, the latter distribution is not known to a localized search engine, and we contend that the above estimate will, on average, be a better estimate than the uniform distribution, for example. Let the PageRank of F be f. We express the PageRank f+ j of the expanded local graph Fj as f+ j = (1 − xj)fj xj , (6) where xj is the PageRank of the candidate global node j, and fj is the L1-normalized PageRank vector restricted to the pages in F . Since directly optimizing our problem goal requires knowing the global PageRank p∗ , we instead propose to crawl those nodes that will have the greatest influence on the PageRanks of pages in the original local domain L: influence(j) = k∈L |fj[k] − f[k]| (7) = EL (fj − f) 1. Experimentally, the influence score is a very good predictor of our problem objective (3). For each candidate global node j, figure 1(a) shows the objective function value Global Diff(fj) as a function of the influence of page j. The local domain used here is a crawl of conservative political pages (we will provide more details about this dataset in section 6); we observed similar results in other domains. The correlation is quite strong, implying that the influence criteria can effectively identify pages that improve the global PageRank estimate. As a baseline, figure 1(b) compares our objective with an alternative criteria, outlink count. The outlink count is defined as the number of outlinks from the local domain to page j. The correlation here is much weaker. .00001 .0001 .001 .01 0.26 0.262 0.264 0.266 Influence Objective 1 10 100 1000 0.266 0.264 0.262 0.26 Outlink Count Objective (a) (b) Figure 1: (a) The correlation between our influence page selection criteria (7) and the actual objective function (3) value is quite strong. (b) This is in contrast to other criteria, such as outlink count, which exhibit a much weaker correlation. 5.2 Computation As described, for each candidate global page j, the influence score (7) must be computed. If fj is computed exactly for each global page j, then the PageRank algorithm would need to be run for each of the O(n) such global pages j we consider, resulting in an O(n2 ) computational cost for the node selection method. Thus, computing the exact value of fj will lead to a quadratic algorithm, and we must instead turn to methods of approximating this vector. The algorithm we present works by performing one power method iteration used by the PageRank algorithm (Algorithm 1). The convergence rate for the PageRank algorithm has been shown to equal the random surfer probability α [7, 11]. Given a starting vector x(0) , if k PageRank iterations are performed, the current PageRank solution x(k) satisfies: x(k) − x∗ 1 = O(αk x(0) − x∗ 1), (8) where x∗ is the desired PageRank vector. Therefore, if only one iteration is performed, choosing a good starting vector is necessary to achieve an accurate approximation. We partition the PageRank matrix PFj , corresponding to the × subgraph Fj as: PFj = ˜F ˜s ˜uT j w , (9) where ˜F = αF (DF + diag(uj))−1 + (1 − α) e + 1 eT , ˜s = αs + (1 − α) e + 1 , ˜uj = α(DF + diag(uj))−1 uj + (1 − α) e + 1 , w = 1 − α + 1 , and diag(uj) is the diagonal matrix with the (i, i)th entry equal to one if the ith element of uj equals one, and is zero otherwise. We have assumed here that the random surfer vector is the uniform vector, and that L has no dangling links. These assumptions are not necessary and serve only to simplify discussion and analysis. A simple approach for estimating fj is the following. First, estimate the PageRank f+ j of Fj by computing one PageRank iteration over the matrix PFj , using the starting vector ν = f 0 . Then, estimate fj by removing the last 119 Research Track Paper component from our estimate of f+ j (i.e., the component corresponding to the added node j), and renormalizing. The problem with this approach is in the starting vector. Recall from (6) that xj is the PageRank of the added node j. The difference between the actual PageRank f+ j of PFj and the starting vector ν is ν − f+ j 1 = xj + f − (1 − xj)fj 1 ≥ xj + | f 1 − (1 − xj) fj 1| = xj + |xj| = 2xj. Thus, by (8), after one PageRank iteration, we expect our estimate of f+ j to still have an error of about 2αxj. In particular, for candidate nodes j with relatively high PageRank xj, this method will yield more inaccurate results. We will next present a method that eliminates this bias and runs in O(n) time. 5.2.1 Stochastic Complementation Since f+ j , as given in (6) is the PageRank of the matrix PFj , we have: fj(1 − xj) xj = ˜F ˜s ˜uT j w fj(1 − xj) xj = ˜F fj(1 − xj) + ˜sxj ˜uT j fj(1 − xj) + wxj . Solving the above system for fj can be shown to yield fj = ( ˜F + (1 − w)−1 ˜s˜uT j )fj. (10) The matrix S = ˜F +(1−w)−1 ˜s˜uT j is known as the stochastic complement of the column stochastic matrix PFj with respect to the sub matrix ˜F . The theory of stochastic complementation is well studied, and it can be shown the stochastic complement of an irreducible matrix (such as the PageRank matrix) is unique. Furthermore, the stochastic complement is also irreducible and therefore has a unique stationary distribution as well. For an extensive study, see [15]. It can be easily shown that the sub-dominant eigenvalue of S is at most +1 α, where is the size of F . For sufficiently large , this value will be very close to α. This is important, as other properties of the PageRank algorithm, notably the algorithms sensitivity, are dependent on this value [11]. In this method, we estimate the length vector fj by computing one PageRank iteration over the × stochastic complement S, starting at the vector f: fj ≈ Sf. (11) This is in contrast to the simple method outlined in the previous section, which first iterates over the ( + 1) × ( + 1) matrix PFj to estimate f+ j , and then removes the last component from the estimate and renormalizes to approximate fj. The problem with the latter method is in the choice of the ( + 1) length starting vector, ν. Consequently, the PageRank estimate given by the simple method differs from the true PageRank by at least 2αxj, where xj is the PageRank of page j. By using the stochastic complement, we can establish a tight lower bound of zero for this difference. To see this, consider the case in which a node k is added to F to form the augmented local subgraph Fk, and that the PageRank of this new graph is (1 − xk)f xk . Specifically, the addition of page k does not change the PageRanks of the pages in F , and thus fk = f. By construction of the stochastic complement, fk = Sfk, so the approximation given in equation (11) will yield the exact solution. Next, we present the computational details needed to efficiently compute the quantity fj −f 1 over all known global pages j. We begin by expanding the difference fj −f, where the vector fj is estimated as in (11), fj − f ≈ Sf − f = αF (DF + diag(uj))−1 f + (1 − α) e + 1 eT f +(1 − w)−1 (˜uT j f)˜s − f. (12) Note that the matrix (DF +diag(uj))−1 is diagonal. Letting o[k] be the outlink count for page k in F , we can express the kth diagonal element as: (DF + diag(uj))−1 [k, k] = 1 o[k]+1 if uj[k] = 1 1 o[k] if uj[k] = 0 Noting that (o[k] + 1)−1 = o[k]−1 − (o[k](o[k] + 1))−1 and rewriting this in matrix form yields (DF +diag(uj))−1 = D−1 F −D−1 F (DF +diag(uj))−1 diag(uj). (13) We use the same identity to express e + 1 = e − e ( + 1) . (14) Recall that, by definition, we have PF = αF D−1 F +(1−α)e . Substituting (13) and (14) in (12) yields fj − f ≈ (PF f − f) −αF D−1 F (DF + diag(uj))−1 diag(uj)f −(1 − α) e ( + 1) + (1 − w)−1 (˜uT j f)˜s = x + y + (˜uT j f)z, (15) noting that by definition, f = PF f, and defining the vectors x, y, and z to be x = −αF D−1 F (DF + diag(uj))−1 diag(uj)f (16) y = −(1 − α) e ( + 1) (17) z = (1 − w)−1 ˜s. (18) The first term x is a sparse vector, and takes non-zero values only for local pages k that are siblings of the global page j. We define (i, j) ∈ F if and only if F [j, i] = 1 (equivalently, page i links to page j) and express the value of the component x[k ] as: x[k ] = −α k:(k,k )∈F ,uj [k]=1 f[k] o[k](o[k] + 1) , (19) where o[k], as before, is the number of outlinks from page k in the local domain. Note that the last two terms, y and z are not dependent on the current global node j. Given the function hj(f) = y + (˜uT j f)z 1, the quantity fj − f 1 120 Research Track Paper can be expressed as fj − f 1 = k x[k] + y[k] + (˜uT j f)z[k] = k:x[k]=0 y[k] + (˜uT j f)z[k] + k:x[k]=0 x[k] + y[k] + (˜uT j f)z[k] = hj(f) − k:x[k]=0 y[k] + (˜uT j f)z[k] + k:x[k]=0 x[k] + y[k] + (˜uT j f)z[k] .(20) If we can compute the function hj in linear time, then we can compute each value of fj − f 1 using an additional amount of time that is proportional to the number of nonzero components in x. These optimizations are carried out in Algorithm 3. Note that (20) computes the difference between all components of f and fj, whereas our node selection criteria, given in (7), is restricted to the components corresponding to nodes in the original local domain L. Let us examine Algorithm 3 in more detail. First, the algorithm computes the outlink counts for each page in the local domain. The algorithm then computes the quantity ˜uT j f for each known global page j. This inner product can be written as (1 − α) 1 + 1 + α k:(k,j)∈Fout f[k] o[k] + 1 , where the second term sums over the set of local pages that link to page j. Since the total number of edges in Fout was assumed to have size O( ) (recall that is the number of pages in F ), the running time of this step is also O( ). The algorithm then computes the vectors y and z, as given in (17) and (18), respectively. The L1NormDiff method is called on the components of these vectors which correspond to the pages in L, and it estimates the value of EL(y + (˜uT j f)z) 1 for each page j. The estimation works as follows. First, the values of ˜uT j f are discretized uniformly into c values {a1, ..., ac}. The quantity EL(y + aiz) 1 is then computed for each discretized value of ai and stored in a table. To evaluate EL (y + az) 1 for some a ∈ [a1, ac], the closest discretized value ai is determined, and the corresponding entry in the table is used. The total running time for this method is linear in and the discretization parameter c (which we take to be a constant). We note that if exact values are desired, we have also developed an algorithm that runs in O( log ) time that is not described here. In the main loop, we compute the vector x, as defined in equation (16). The nested loops iterate over the set of pages in F that are siblings of page j. Typically, the size of this set is bounded by a constant. Finally, for each page j, the scores vector is updated over the set of non-zero components k of the vector x with k ∈ L. This set has size equal to the number of local siblings of page j, and is a subset of the total number of siblings of page j. Thus, each iteration of the main loop takes constant time, and the total running time of the main loop is O( ). Since we have assumed that the size of F will not grow larger than O(n), the total running time for the algorithm is O(n). Algorithm 3: Node Selection via Stochastic Complementation. SC-Select(F , Fout, f, k) Input: F : zero-one adjacency matrix of size corresponding to the current local subgraph, Fout: zero-one outlink matrix from F to global subgraph, f: PageRank of F , k: number of pages to return Output: pages: set of k pages to crawl next {Compute outlink sums for local subgraph} foreach (page j ∈ F ) o[j] ← k:(j,k)∈F F[j, k] end {Compute scalar ˜uT j f for each global node j } foreach (page j ∈ Fout) g[j] ← (1 − α) 1 +1 foreach (page k : (k, j) ∈ Fout) g[j] ← g[j] + α f[k] o[k]+1 end end {Compute vectors y and z as in (17) and (18) } y ← −(1 − α) e ( +1) z ← (1 − w)−1 ˜s {Approximate y + g[j] ∗ z 1 for all values g[j]} norm diffs ←L1NormDiffs(g, ELy, ELz) foreach (page j ∈ Fout) {Compute sparse vector x as in (19)} x ← 0 foreach (page k : (k, j) ∈ Fout) foreach (page k : (k, k ) ∈ F )) x[k ] ← x[k ] − f[k] o[k](o[k]+1) end end x ← αx scores[j] ← norm diffs[j] foreach (k : x[k] > 0 and page k ∈ L) scores[j] ← scores[j] − |y[k] + g[j] ∗ z[k]| +|x[k]+y[k]+g[j]∗z[k])| end end Return k pages with highest scores 5.2.2 PageRank Flows We now present an intuitive analysis of the stochastic complementation method by decomposing the change in PageRank in terms of leaks and flows. This analysis is motivated by the decomposition given in (15). PageRank flow is the increase in the local PageRanks originating from global page j. The flows are represented by the non-negative vector (˜uT j f)z (equations (15) and (18)). The scalar ˜uT j f can be thought of as the total amount of PageRank flow that page j has available to distribute. The vector z dictates how the flow is allocated to the local domain; the flow that local page k receives is proportional to (within a constant factor due to the random surfer vector) the expected number of its inlinks. The PageRank leaks represent the decrease in PageRank resulting from the addition of page j. The leakage can be quantified in terms of the non-positive vectors x and y (equations (16) and (17)). For vector x, we can see from equation (19) that the amount of PageRank leaked by a local page is proportional to the weighted sum of the Page121 Research Track Paper Ranks of its siblings. Thus, pages that have siblings with higher PageRanks (and low outlink counts) will experience more leakage. The leakage caused by y is an artifact of the random surfer vector. We will next show that if only the flow term, (˜uT j f)z, is considered, then the resulting method is very similar to a heuristic proposed by Cho et al. [6] that has been widely used for the Crawling Through URL Ordering problem. This heuristic is computationally cheaper, but as we will see later, not as effective as the Stochastic Complementation method. Our node selection strategy chooses global nodes that have the largest influence (equation (7)). If this influence is approximated using only flows, the optimal node j∗ is: j∗ = argmaxj EL ˜uT j fz 1 = argmaxj ˜uT j f EL z 1 = argmaxj ˜uT j f = argmaxj α(DF + diag(uj))−1 uj + (1 − α) e + 1 , f = argmaxjfT (DF + diag(uj))−1 uj. The resulting page selection score can be expressed as a sum of the PageRanks of each local page k that links to j, where each PageRank value is normalized by o[k]+1. Interestingly, the normalization that arises in our method differs from the heuristic given in [6], which normalizes by o[k]. The algorithm PF-Select, which is omitted due to lack of space, first computes the quantity fT (DF +diag(uj))−1 uj for each global page j, and then returns the pages with the k largest scores. To see that the running time for this algorithm is O(n), note that the computation involved in this method is a subset of that needed for the SC-Select method (Algorithm 3), which was shown to have a running time of O(n). 6. EXPERIMENTS In this section, we provide experimental evidence to verify the effectiveness of our algorithms. We first outline our experimental methodology and then provide results across a variety of local domains. 6.1 Methodology Given the limited resources available at an academic institution, crawling a section of the web that is of the same magnitude as that indexed by Google or Yahoo! is clearly infeasible. Thus, for a given local domain, we approximate the global graph by crawling a local neighborhood around the domain that is several orders of magnitude larger than the local subgraph. Even though such a graph is still orders of magnitude smaller than the true global graph, we contend that, even if there exist some highly influential pages that are very far away from our local domain, it is unrealistic for any local node selection algorithm to find them. Such pages also tend to be highly unrelated to pages within the local domain. When explaining our node selection strategies in section 5, we made the simplifying assumption that our local graph contained no dangling nodes. This assumption was only made to ease our analysis. Our implementation efficiently handles dangling links by replacing each zero column of our adjacency matrix with the uniform vector. We evaluate the algorithm using the two node selection strategies given in Section 5.2, and also against the following baseline methods: • Random: Nodes are chosen uniformly at random among the known global nodes. • OutlinkCount: Global nodes with the highest number of outlinks from the local domain are chosen. At each iteration of the FindGlobalPR algorithm, we evaluate performance by computing the difference between the current PageRank estimate of the local domain, ELf ELf 1 , and the global PageRank of the local domain ELg ELg 1 . All PageRank calculations were performed using the uniform random surfer vector. Across all experiments, we set the random surfer parameter α, to be .85, and used a convergence threshold of 10−6 . We evaluate the difference between the local and global PageRank vectors using three different metrics: the L1 and L∞ norms, and Kendalls tau. The L1 norm measures the sum of the absolute value of the differences between the two vectors, and the L∞ norm measures the absolute value of the largest difference. Kendalls tau metric is a popular rank correlation measure used to compare PageRanks [2, 11]. This metric can be computed by counting the number of pairs of pairs that agree in ranking, and subtracting from that the number of pairs of pairs that disagree in ranking. The final value is then normalized by the total number of n 2 such pairs, resulting in a [−1, 1] range, where a negative score signifies anti-correlation among rankings, and values near one correspond to strong rank correlation. 6.2 Results Our experiments are based on two large web crawls and were downloaded using the web crawler that is part of the Nutch open source search engine project [18]. All crawls were restricted to only http pages, and to limit the number of dynamically generated pages that we crawl, we ignored all pages with urls containing any of the characters ?, *, @, or =. The first crawl, which we will refer to as the edu dataset, was seeded by homepages of the top 100 graduate computer science departments in the USA, as rated by the US News and World Report [16], and also by the home pages of their respective institutions. A crawl of depth 5 was performed, restricted to pages within the .edu domain, resulting in a graph with approximately 4.7 million pages and 22.9 million links. The second crawl was seeded by the set of pages under the politics hierarchy in the dmoz open directory project[17]. We crawled all pages up to four links away, which yielded a graph with 4.4 million pages and 17.3 million links. Within the edu crawl, we identified the five site-specific domains corresponding to the websites of the top five graduate computer science departments, as ranked by the US News and World Report. This yielded local domains of various sizes, from 10,626 (UIUC) to 59,895 (Berkeley). For each of these site-specific domains with size n, we performed 50 iterations of the FindGlobalPR algorithm to crawl a total of 2n additional nodes. Figure 2(a) gives the (L1) difference from the PageRank estimate at each iteration to the global PageRank, for the Berkeley local domain. The performance of this dataset was representative of the typical performance across the five computer science sitespecific local domains. Initially, the L1 difference between the global and local PageRanks ranged from .0469 (Stanford) to .149 (MIT). For the first several iterations, the 122 Research Track Paper 0 5 10 15 20 25 30 35 40 45 50 0.015 0.02 0.025 0.03 0.035 0.04 0.045 0.05 0.055 Number of Iterations GlobalandLocalPageRankDifference(L1) Stochastic Complement PageRank Flow Outlink Count Random 0 10 20 30 40 50 0 0.05 0.1 0.15 0.2 0.25 0.3 0.35 Number of Iterations GlobalandLocalPageRankDifference(L1) Stochastic Complement PageRank Flow Outlink Count Random 0 5 10 15 20 25 0.16 0.18 0.2 0.22 0.24 0.26 0.28 0.3 0.32 0.34 Number of Iterations GlobalandLocalPageRankDifference(L1) Stochastic Complement PageRank Flow Outlink Count Random (a) www.cs.berkeley.edu (b) www.enterstageright.com (c) Politics Figure 2: L1 difference between the estimated and true global PageRanks for (a) Berkeleys computer science website, (b) the site-specific domain, www.enterstageright.com, and (c) the politics topic-specific domain. The stochastic complement method outperforms all other methods across various domains. three link-based methods all outperform the random selection heuristic. After these initial iterations, the random heuristic tended to be more competitive with (or even outperform, as in the Berkeley local domain) the outlink count and PageRank flow heuristics. In all tests, the stochastic complementation method either outperformed, or was competitive with, the other methods. Table 1 gives the average difference between the final estimated global PageRanks and the true global PageRanks for various distance measures. Algorithm L1 L∞ Kendall Stoch. Comp. .0384 .00154 .9257 PR Flow .0470 .00272 .8946 Outlink .0419 .00196 .9053 Random .0407 .00204 .9086 Table 1: Average final performance of various node selection strategies for the five site-specific computer science local domains. Note that Kendalls Tau measures similarity, while the other metrics are dissimilarity measures. Stochastic Complementation clearly outperforms the other methods in all metrics. Within the politics dataset, we also performed two sitespecific tests for the largest websites in the crawl: www.adamsmith.org, the website for the London based Adam Smith Institute, and www.enterstageright.com, an online conservative journal. As with the edu local domains, we ran our algorithm for 50 iterations, crawling a total of 2n nodes. Figure 2 (b) plots the results for the www.enterstageright.com domain. In contrast to the edu local domains, the Random and OutlinkCount methods were not competitive with either the SC-Select or the PF-Select methods. Among all datasets and all node selection methods, the stochastic complementation method was most impressive in this dataset, realizing a final estimate that differed only .0279 from the global PageRank, a ten-fold improvement over the initial local PageRank difference of .299. For the Adam Smith local domain, the initial difference between the local and global PageRanks was .148, and the final estimates given by the SC-Select, PF-Select, OutlinkCount, and Random methods were .0208, .0193, .0222, and .0356, respectively. Within the politics dataset, we constructed four topicspecific local domains. The first domain consisted of all pages in the dmoz politics category, and also all pages within each of these sites up to two links away. This yielded a local domain of 90,811 pages, and the results are given in figure 2 (c). Because of the larger size of the topic-specific domains, we ran our algorithm for only 25 iterations to crawl a total of n nodes. We also created topic-specific domains from three political sub-topics: liberalism, conservatism, and socialism. The pages in these domains were identified by their corresponding dmoz categories. For each sub-topic, we set the local domain to be all pages within three links from the corresponding dmoz category pages. Table 2 summarizes the performance of these three topic-specific domains, and also the larger political domain. To quantify a global page js effect on the global PageRank values of pages in the local domain, we define page js impact to be its PageRank value, g[j], normalized by the fraction of its outlinks pointing to the local domain: impact(j) = oL[j] o[j] · g[j], where, oL[j] is the number of outlinks from page j to pages in the local domain L, and o[j] is the total number of js outlinks. In terms of the random surfer model, the impact of page j is the probability that the random surfer (1) is currently at global page j in her random walk and (2) takes an outlink to a local page, given that she has already decided not to jump to a random page. For the politics local domain, we found that many of the pages with high impact were in fact political pages that should have been included in the dmoz politics topic, but were not. For example, the two most influential global pages were the political search engine www.askhenry.com, and the home page of the online political magazine, www.policyreview.com. Among non-political pages, the home page of the journal Education Next was most influential. The journal is freely available online and contains articles regarding various aspect of K-12 education in America. To provide some anecdotal evidence for the effectiveness of our page selection methods, we note that the SC-Select method chose 11 pages within the www.educationnext.org domain, the PF-Select method discovered 7 such pages, while the OutlinkCount and Random methods found only 6 pages each. For the conservative political local domain, the socialist website www.ornery.org had a very high impact score. This 123 Research Track Paper All Politics: Algorithm L1 L2 Kendall Stoch. Comp. .1253 .000700 .8671 PR Flow .1446 .000710 .8518 Outlink .1470 .00225 .8642 Random .2055 .00203 .8271 Conservativism: Algorithm L1 L2 Kendall Stoch. Comp. .0496 .000990 .9158 PR Flow .0554 .000939 .9028 Outlink .0602 .00527 .9144 Random .1197 .00102 .8843 Liberalism: Algorithm L1 L2 Kendall Stoch. Comp. .0622 .001360 .8848 PR Flow .0799 .001378 .8669 Outlink .0763 .001379 .8844 Random .1127 .001899 .8372 Socialism: Algorithm L1 L∞ Kendall Stoch. Comp. .04318 .00439 .9604 PR Flow .0450 .004251 .9559 Outlink .04282 .00344 .9591 Random .0631 .005123 .9350 Table 2: Final performance among node selection strategies for the four political topic-specific crawls. Note that Kendalls Tau measures similarity, while the other metrics are dissimilarity measures. was largely due to a link from the front page of this site to an article regarding global warming published by the National Center for Public Policy Research, a conservative research group in Washington, DC. Not surprisingly, the global PageRank of this article (which happens to be on the home page of the NCCPR, www.nationalresearch.com), was approximately .002, whereas the local PageRank of this page was only .00158. The SC-Select method yielded a global PageRank estimate of approximately .00182, the PFSelect method estimated a value of .00167, and the Random and OutlinkCount methods yielded values of .01522 and .00171, respectively. 7. RELATED WORK The node selection framework we have proposed is similar to the url ordering for crawling problem proposed by Cho et al. in [6]. Whereas our framework seeks to minimize the difference between the global and local PageRank, the objective used in [6] is to crawl the most highly (globally) ranked pages first. They propose several node selection algorithms, including the outlink count heuristic, as well as a variant of our PF-Select algorithm which they refer to as the PageRank ordering metric. They found this method to be most effective in optimizing their objective, as did a recent survey of these methods by Baeza-Yates et al. [1]. Boldi et al. also experiment within a similar crawling framework in [2], but quantify their results by comparing Kendalls rank correlation between the PageRanks of the current set of crawled pages and those of the entire global graph. They found that node selection strategies that crawled pages with the highest global PageRank first actually performed worse (with respect to Kendalls Tau correlation between the local and global PageRanks) than basic depth first or breadth first strategies. However, their experiments differ from our work in that our node selection algorithms do not use (or have access to) global PageRank values. Many algorithmic improvements for computing exact PageRank values have been proposed [9, 10, 14]. If such algorithms are used to compute the global PageRanks of our local domain, they would all require O(N) computation, storage, and bandwidth, where N is the size of the global domain. This is in contrast to our method, which approximates the global PageRank and scales linearly with the size of the local domain. Wang and Dewitt [22] propose a system where the set of web servers that comprise the global domain communicate with each other to compute their respective global PageRanks. For a given web server hosting n pages, the computational, bandwidth, and storage requirements are also linear in n. One drawback of this system is that the number of distinct web servers that comprise the global domain can be very large. For example, our edu dataset contains websites from over 3,200 different universities; coordinating such a system among a large number of sites can be very difficult. Gan, Chen, and Suel propose a method for estimating the PageRank of a single page [5] which uses only constant bandwidth, computation, and space. Their approach relies on the availability of a remote connectivity server that can supply the set of inlinks to a given page, an assumption not used in our framework. They experimentally show that a reasonable estimate of the nodes PageRank can be obtained by visiting at most a few hundred nodes. Using their algorithm for our problem would require that either the entire global domain first be downloaded or a connectivity server be used, both of which would lead to very large web graphs. 8. CONCLUSIONS AND FUTURE WORK The internet is growing exponentially, and in order to navigate such a large repository as the web, global search engines have established themselves as a necessity. Along with the ubiquity of these large-scale search engines comes an increase in search users expectations. By providing complete and isolated coverage of a particular web domain, localized search engines are an effective outlet to quickly locate content that could otherwise be difficult to find. In this work, we contend that the use of global PageRank in a localized search engine can improve performance. To estimate the global PageRank, we have proposed an iterative node selection framework where we select which pages from the global frontier to crawl next. Our primary contribution is our stochastic complementation page selection algorithm. This method crawls nodes that will most significantly impact the local domain and has running time linear in the number of nodes in the local domain. Experimentally, we validate these methods across a diverse set of local domains, including seven site-specific domains and four topic-specific domains. We conclude that by crawling an additional n or 2n pages, our methods find an estimate of the global PageRanks that is up to ten times better than just using the local PageRanks. Furthermore, we demonstrate that our algorithm consistently outperforms other existing heuristics. 124 Research Track Paper Often times, topic-specific domains are discovered using a focused web crawler which considers a pages content in conjunction with link anchor text to decide which pages to crawl next [4]. Although such crawlers have proven to be quite effective in discovering topic-related content, many irrelevant pages are also crawled in the process. Typically, these pages are deleted and not indexed by the localized search engine. These pages can of course provide valuable information regarding the global PageRank of the local domain. One way to integrate these pages into our framework is to start the FindGlobalPR algorithm with the current subgraph F equal to the set of pages that were crawled by the focused crawler. The global PageRank estimation framework, along with the node selection algorithms presented, all require O(n) computation per iteration and bandwidth proportional to the number of pages crawled, Tk. If the number of iterations T is relatively small compared to the number of pages crawled per iteration, k, then the bottleneck of the algorithm will be the crawling phase. However, as the number of iterations increases (relative to k), the bottleneck will reside in the node selection computation. In this case, our algorithms would benefit from constant factor optimizations. Recall that the FindGlobalPR algorithm (Algorithm 2) requires that the PageRanks of the current expanded local domain be recomputed in each iteration. Recent work by Langville and Meyer [12] gives an algorithm to quickly recompute PageRanks of a given webgraph if a small number of nodes are added. This algorithm was shown to give speedup of five to ten times on some datasets. We plan to investigate this and other such optimizations as future work. In this paper, we have objectively evaluated our methods by measuring how close our global PageRank estimates are to the actual global PageRanks. To determine the benefit of using global PageRanks in a localized search engine, we suggest a user study in which users are asked to rate the quality of search results for various search queries. For some queries, only the local PageRanks are used in ranking, and for the remaining queries, local PageRanks and the approximate global PageRanks, as computed by our algorithms, are used. The results of such a study can then be analyzed to determine the added benefit of using the global PageRanks computed by our methods, over just using the local PageRanks. Acknowledgements. This research was supported by NSF grant CCF-0431257, NSF Career Award ACI-0093404, and a grant from Sabre, Inc. 9. REFERENCES [1] R. Baeza-Yates, M. Marin, C. Castillo, and A. Rodriguez. Crawling a country: better strategies than breadth-first for web page ordering. World-Wide Web Conference, 2005. [2] P. Boldi, M. Santini, and S. Vigna. Do your worst to make the best: paradoxical effects in pagerank incremental computations. Workshop on Web Graphs, 3243:168-180, 2004. [3] S. Brin and L. Page. The anatomy of a large-scale hypertextual web search engine. Computer Networks and ISDN Systems, 33(1-7):107-117, 1998. [4] S. Chakrabarti, M. van den Berg, and B. Dom. Focused crawling: a new approach to topic-specific web resource discovery. World-Wide Web Conference, 1999. [5] Y. Chen, Q. Gan, and T. Suel. Local methods for estimating pagerank values. Conference on Information and Knowledge Management, 2004. [6] J. Cho, H. Garcia-Molina, and L. Page. Efficient crawling through url ordering. World-Wide Web Conference, 1998. [7] T. H. Haveliwala and S. D. Kamvar. The second eigenvalue of the Google matrix. Technical report, Stanford University, 2003. [8] T. Joachims, F. Radlinski, L. Granka, A. Cheng, C. Tillekeratne, and A. Patel. Learning retrieval functions from implicit feedback. http://www.cs.cornell.edu/People/tj/career. [9] S. D. Kamvar, T. H. Haveliwala, C. D. Manning, and G. H. Golub. Exploiting the block structure of the web for computing pagerank. World-Wide Web Conference, 2003. [10] S. D. Kamvar, T. H. Haveliwala, C. D. Manning, and G. H. Golub. Extrapolation methods for accelerating pagerank computation. World-Wide Web Conference, 2003. [11] A. N. Langville and C. D. Meyer. Deeper inside pagerank. Internet Mathematics, 2004. [12] A. N. Langville and C. D. Meyer. Updating the stationary vector of an irreducible markov chain with an eye on Googles pagerank. SIAM Journal on Matrix Analysis, 2005. [13] P. Lyman, H. R. Varian, K. Swearingen, P. Charles, N. Good, L. L. Jordan, and J. Pal. How much information 2003? School of Information Management and System, University of California at Berkely, 2003. [14] F. McSherry. A uniform approach to accelerated pagerank computation. World-Wide Web Conference, 2005. [15] C. D. Meyer. Stochastic complementation, uncoupling markov chains, and the theory of nearly reducible systems. SIAM Review, 31:240-272, 1989. [16] US News and World Report. http://www.usnews.com. [17] Dmoz open directory project. http://www.dmoz.org. [18] Nutch open source search engine. http://www.nutch.org. [19] F. Radlinski and T. Joachims. Query chains: learning to rank from implicit feedback. ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, 2005. [20] S. Raghavan and H. Garcia-Molina. Crawling the hidden web. In Proceedings of the Twenty-seventh International Conference on Very Large Databases, 2001. [21] T. Tin Tang, D. Hawking, N. Craswell, and K. Griffiths. Focused crawling for both topical relevance and quality of medical information. Conference on Information and Knowledge Management, 2005. [22] Y. Wang and D. J. DeWitt. Computing pagerank in a distributed internet search system. Proceedings of the 30th VLDB Conference, 2004. 125 Research Track Paper",
    "original_translation": "Estimando el PageRank Global de Comunidades Web Jason V. Davis Dept. Departamento de Ciencias de la Computación Universidad de Texas en Austin Austin, TX 78712 jdavis@cs.utexas.edu Inderjit S. Dhillon Departamento de Ciencias de la Computación Universidad de Texas en Austin Austin, TX 78712 inderjit@cs.utexas.edu RESUMEN Los motores de búsqueda localizados son sistemas a pequeña escala que indexan una comunidad particular en la web. Ofrecen varios beneficios en comparación con sus contrapartes a gran escala, ya que son relativamente económicos de construir y pueden proporcionar una capacidad de búsqueda más precisa y completa en sus dominios relevantes. Una desventaja que tienen estos sistemas en comparación con los motores de búsqueda a gran escala es la falta de valores globales de PageRank. Se necesita esa información para evaluar el valor de las páginas en el dominio de búsqueda localizada dentro del contexto de la web en su totalidad. En este artículo, presentamos algoritmos bien fundamentados para estimar los valores globales de PageRank de un dominio local. Los algoritmos son altamente escalables en el sentido de que, dado un dominio local de tamaño n, utilizan recursos de O(n) que incluyen tiempo de computación, ancho de banda y almacenamiento. Probamos nuestros métodos en una variedad de dominios localizados, incluyendo dominios específicos del sitio y dominios específicos del tema. Demostramos que al rastrear tan solo n o 2n páginas adicionales, nuestros métodos pueden proporcionar excelentes estimaciones globales de PageRank. Categorías y Descriptores de Asignaturas H.3.3 [Almacenamiento y Recuperación de Información]: Búsqueda y Recuperación de Información; G.1.3 [Análisis Numérico]: Álgebra Lineal Numérica; G.3 [Probabilidad y Estadística]: Procesos de Markov Términos Generales PageRank, Cadena de Markov, Complementación Estocástica. Los motores de búsqueda localizados son motores de búsqueda a pequeña escala que indexan solo una comunidad específica de la web. Tales comunidades pueden ser dominios específicos del sitio, como páginas dentro del dominio cs.utexas.edu, o comunidades relacionadas con un tema, por ejemplo, sitios web políticos. En comparación con el grafo web rastreado e indexado por los motores de búsqueda a gran escala, el tamaño de estas comunidades locales suele ser típicamente órdenes de magnitud más pequeño. Por consiguiente, los recursos computacionales necesarios para construir un motor de búsqueda de este tipo también son igualmente más ligeros. Al restringirse a secciones más pequeñas y manejables de la web, los motores de búsqueda localizados también pueden ofrecer capacidades de búsqueda más precisas y completas dentro de sus respectivos dominios. Una desventaja de los índices localizados es la falta de información global necesaria para calcular clasificaciones basadas en enlaces. El algoritmo PageRank [3] ha demostrado ser una medida efectiva de este tipo. En general, el PageRank de una página dada depende de las páginas en todo el grafo web. En el contexto de un motor de búsqueda localizado, si los PageRanks se calculan utilizando solo el subgrafo local, entonces esperaríamos que los PageRanks resultantes reflejen la popularidad percibida dentro de la comunidad local y no de la web en su totalidad. Por ejemplo, consideremos un motor de búsqueda localizado que indexa páginas políticas con puntos de vista conservadores. Una persona que desee investigar las opiniones sobre el calentamiento global dentro de la comunidad política conservadora puede encontrarse con numerosas opiniones de este tipo en varios sitios web. Si solo se dispone de valores de PageRank locales, entonces los resultados de búsqueda reflejarán solo creencias fuertemente arraigadas dentro de la comunidad. Sin embargo, si los PageRanks globales también están disponibles, entonces los resultados pueden reflejar adicionalmente las opiniones de los externos sobre la comunidad conservadora (es decir, aquellos documentos a los que los liberales acceden con mayor frecuencia dentro de la comunidad conservadora). Por lo tanto, para muchos motores de búsqueda localizados, la incorporación de PageRanks globales puede mejorar la calidad de los resultados de búsqueda. Sin embargo, el número de páginas que indexa un motor de búsqueda local suele ser órdenes de magnitud más pequeño que el número de páginas indexadas por sus contrapartes a gran escala. Los motores de búsqueda localizados no tienen el ancho de banda, la capacidad de almacenamiento o la potencia computacional para rastrear, descargar y calcular los PageRanks globales de toda la web. En este trabajo, presentamos un método para aproximar los PageRanks globales de un dominio local utilizando recursos del mismo orden que los necesarios para calcular los PageRanks del subgrafo local. Nuestro método propuesto busca un supergrafo de nuestro subgrafo local de manera que los PageRanks locales dentro de este supergrafo estén cerca de los verdaderos PageRanks globales. Construimos este supergrafo mediante el rastreo iterativo de páginas globales en la frontera web actual, es decir, páginas globales con enlaces entrantes de páginas que ya han sido rastreadas. Para proporcionar a 116 Research Track Paper una buena aproximación a los PageRanks globales, es necesario tener cuidado al elegir qué páginas rastrear a continuación; en este documento, presentamos un algoritmo de selección de páginas bien fundamentado que también tiene un buen rendimiento empírico. Este algoritmo se deriva de un objetivo de problema bien definido y tiene un tiempo de ejecución lineal en el número de nodos locales. Experimentamos en varios tipos de subgrafos locales, incluidas cuatro comunidades relacionadas con el tema y varios dominios específicos del sitio. Para evaluar el rendimiento, medimos la diferencia entre la estimación actual del PageRank global y el PageRank global, en función del número de páginas rastreadas. Comparamos nuestro algoritmo con varios heurísticos y también con un algoritmo base que elige páginas al azar, y demostramos que nuestro método supera a estos otros métodos. Finalmente, demostramos empíricamente que, dado un dominio local de tamaño n, podemos proporcionar buenas aproximaciones a los valores globales de PageRank rastreando como máximo n o 2n páginas adicionales. El documento está organizado de la siguiente manera. La sección 2 ofrece una visión general de los motores de búsqueda localizados y destaca sus ventajas sobre los motores de búsqueda globales. La sección 3 proporciona antecedentes sobre el algoritmo PageRank. La sección 4 define formalmente nuestro problema, y la sección 5 presenta nuestros criterios de selección de páginas y deriva nuestros algoritmos. La sección 6 presenta los resultados experimentales, la sección 7 ofrece una visión general del trabajo relacionado y, finalmente, las conclusiones se presentan en la sección 8. MOTORES DE BÚSQUEDA LOCALIZADOS Los motores de búsqueda localizados indexan una sola comunidad de la web, típicamente una comunidad específica del sitio o una comunidad específica del tema. Los motores de búsqueda localizados disfrutan de tres ventajas principales sobre sus contrapartes a gran escala: son relativamente económicos de construir, pueden ofrecer una capacidad de búsqueda más precisa dentro de su dominio local y pueden proporcionar un índice más completo. Los recursos necesarios para construir un motor de búsqueda global son enormes. Un estudio de 2003 realizado por Lyman et al. [13] encontró que la web superficial (sitios estáticos de acceso público) consta de 8.9 mil millones de páginas, y que el tamaño promedio de estas páginas es de aproximadamente 18.7 kilobytes. Para descargar un rastreo de este tamaño, se necesita aproximadamente 167 terabytes de espacio. Para un investigador que desee construir un motor de búsqueda con acceso a un par de estaciones de trabajo o un servidor pequeño, un almacenamiento de esta magnitud simplemente no está disponible. Sin embargo, construir un motor de búsqueda localizado sobre una comunidad web de cien mil páginas solo requeriría unos pocos gigabytes de almacenamiento. La carga computacional necesaria para soportar consultas de búsqueda sobre una base de datos de este tamaño es más manejable también. Observamos que, para los motores de búsqueda específicos de un tema, la comunidad relevante puede ser identificada y descargada de manera eficiente utilizando un rastreador enfocado [21, 4]. Para dominios específicos del sitio, el dominio local está fácilmente disponible en su propio servidor web. Esto evita la necesidad de rastreo o indexación, y por lo tanto se puede garantizar un índice completo y actualizado del dominio. Esto contrasta con sus contrapartes a gran escala, las cuales sufren de varias deficiencias. Primero, el rastreo de páginas generadas dinámicamente en la web oculta ha sido objeto de investigación [20] y es una tarea no trivial para un rastreador externo. En segundo lugar, los dominios específicos del sitio pueden habilitar la política de exclusión de robots. Esto prohíbe a los rastreadores de motores de búsqueda externos descargar contenido del dominio, y en su lugar un motor de búsqueda externo debe depender de enlaces externos y texto ancla para indexar estas páginas restringidas. Al restringirse a un dominio específico de internet, un motor de búsqueda localizado puede proporcionar resultados de búsqueda más precisos. Considera la consulta de búsqueda ambigua canónica, jaguar, que puede referirse tanto al fabricante de automóviles como al animal. Un científico que intenta investigar el hábitat y la historia evolutiva de un jaguar puede tener más éxito utilizando un motor de búsqueda específico de zoología bien ajustado que consultando Google con múltiples búsquedas de palabras clave y navegando a través de resultados irrelevantes. Recientemente se propuso un método para aprender funciones de clasificación mejores para la recuperación por Radlinski y Joachims [19] y se ha aplicado a varios dominios locales, incluido el sitio web de la Universidad de Cornell [8]. 3. PAGERANK RESUMEN El algoritmo PageRank define la importancia de las páginas web analizando la estructura de hipervínculos subyacente de un grafo web. El algoritmo funciona construyendo una cadena de Markov a partir de la estructura de enlaces del grafo web y calculando su distribución estacionaria. Una forma de calcular la distribución estacionaria de una cadena de Markov es encontrar la distribución límite de un paseo aleatorio sobre la cadena. Por lo tanto, el algoritmo PageRank utiliza lo que a veces se conoce como el modelo del surfista aleatorio. En cada paso de la caminata aleatoria, el surfista sigue un enlace de salida de la página actual (es decir, el nodo actual en la cadena), o salta a una página aleatoria en la web. Ahora definimos con precisión el problema de PageRank. Sea U una matriz de adyacencia m × m para un grafo web dado tal que Uji = 1 si la página i enlaza a la página j y Uji = 0 en caso contrario. Definimos la matriz de PageRank PU como: PU = αUD−1 U + (1 − α)veT , (1) donde DU es la matriz diagonal (única) tal que UD−1 U es estocástica por columnas, α es un escalar dado tal que 0 ≤ α ≤ 1, e es el vector de todos unos, y v es un vector no negativo, L1-normalizado, a veces llamado vector de navegante aleatorio. Ten en cuenta que la matriz D−1 U está bien definida solo si cada columna de U tiene al menos una entrada distinta de cero, es decir, cada página en el grafo web tiene al menos un enlace de salida. En presencia de nodos colgantes que no tienen enlaces de salida, una solución comúnmente utilizada, propuesta por Brin et al. [3], es reemplazar cada columna de ceros de U por un vector no negativo, normalizado en L1. El vector PageRank r es el eigenvector dominante de la matriz PageRank, r = PU r. Supondremos, sin pérdida de generalidad, que r tiene una norma L1 de uno. Computacionalmente, r se puede calcular utilizando el método de la potencia. Este método primero elige un vector inicial aleatorio r(0) y, de forma iterativa, multiplica el vector actual por la matriz de PageRank PU; ver Algoritmo 1. En general, cada iteración del método de la potencia puede requerir O(m2) operaciones cuando PU es una matriz densa. Sin embargo, en la práctica, el número de enlaces en un grafo web será del orden del número de páginas. Al explotar la dispersión de la matriz de PageRank, el trabajo por iteración se puede reducir a O(km), donde k es el número promedio de enlaces por página web. También se ha demostrado que el número total de iteraciones necesarias para la convergencia es proporcional a α y no depende del tamaño del grafo web [11, 7]. Finalmente, el espacio total necesario también es O(km), principalmente para almacenar la matriz U. 117 Research Track Paper Algorithm 1: Un algoritmo de tiempo lineal (por iteración) para calcular PageRank. CalcularPR(U) Entrada: U: Matriz de adyacencia. Salida: vector de PageRank. Elige (aleatoriamente) un vector inicial no negativo r(0) tal que r(0) 1 = 1. i ← 0 repetir i ← i + 1 ν ← αUD−1 U r(i−1) {α es la probabilidad de navegación aleatoria} r(i) ← ν + (1 − α)v {v es el vector del navegante aleatorio.} hasta que r(i) − r(i−1) < δ {δ es el umbral de convergencia.} r ← r(i) 4. Dada un dominio local L, sea G una matriz de adyacencia N × N para el componente conectado completo de la web que contiene L, tal que Gji = 1 si la página i enlaza a la página j y Gji = 0 en caso contrario. Sin pérdida de generalidad, vamos a dividir G de la siguiente manera: G = L Gout Lout Gwithin, donde L es el subgrafo local de n × n correspondiente a los enlaces dentro del dominio local, Lout es el subgrafo que corresponde a los enlaces desde el dominio local apuntando hacia el dominio global, Gout es el subgrafo que contiene los enlaces desde el dominio global hacia el dominio local, y Gwithin contiene los enlaces dentro del dominio global. Suponemos que al construir un motor de búsqueda localizado, solo se rastrean las páginas dentro del dominio local, y los enlaces entre estas páginas están representados por el subgrafo L. También se conocen los enlaces en Lout, ya que estos apuntan desde las páginas rastreadas en el dominio local a las páginas no rastreadas en el dominio global. Como se define en la ecuación (1), PG es la matriz de PageRank formada a partir del grafo global G, y definimos el vector de PageRank global de este grafo como g. Sea el vector de longitud n p∗ el vector L1-normalizado que corresponde al PageRank global de las páginas en el dominio local L: p∗ = EL g ELg 1 , donde EL = [ I | 0 ] es la matriz de restricción que selecciona los componentes de g correspondientes a los nodos en L. Sea p el vector de PageRank construido a partir del subgrafo del dominio local L. En la práctica, el PageRank local observado p y el PageRank global p∗ serán bastante diferentes. Se esperaría que a medida que el tamaño de la matriz local L se acerque al tamaño de la matriz global G, el PageRank global y el PageRank local observado se vuelvan más similares. Por lo tanto, un enfoque para estimar el PageRank global es rastrear todo el dominio global, calcular su PageRank y extraer los PageRanks del dominio local. Por lo general, sin embargo, n N, es decir, el número de páginas globales es mucho mayor que el número de páginas locales. Por lo tanto, rastrear todas las páginas globales agotará rápidamente todos los recursos locales (computacionales, de almacenamiento y de ancho de banda) disponibles para crear el motor de búsqueda local. En cambio, buscamos un supergrafo ˆF de nuestro subgrafo local L con tamaño O(n). Nuestro objetivo es el Algoritmo 2: El algoritmo FindGlobalPR. EncuentraGlobalPR(L, Lout, T, k) Entrada: L: matriz de adyacencia de ceros y unos para el dominio local, Lout: matriz de enlaces de ceros y unos desde L al subgrafo global como en (2), T: número de iteraciones, k: número de páginas a rastrear por iteración. Salida: ˆp: una estimación mejorada del PageRank global de L. F ← L Fout ← Lout f ← CalcularPR(F) para (i = 1 a T) {Determinar qué páginas rastrear a continuación} páginas ← SeleccionarNodos(F, Fout, f, k) Rastrear páginas, aumentar F y modificar Fout {Actualizar PageRanks para el nuevo dominio local} f ← CalcularPR(F) fin {Extraer PageRanks del dominio local original y normalizar} ˆp ← ELf ELf 1 es encontrar un supergrafo ˆF con PageRank ˆf, de modo que ˆf cuando se restringe a L esté cerca de p∗. Formalmente, buscamos minimizar GlobalDiff( ˆf) = EL ˆf EL ˆf 1 − p∗ 1 . (3) Elegimos la norma L1 para medir el error ya que no otorga un peso excesivo a los valores atípicos (como lo hace la norma L2, por ejemplo), y también porque es la medida de distancia más comúnmente utilizada en la literatura para comparar vectores de PageRank, así como para detectar la convergencia del algoritmo [3]. Proponemos un marco codicioso, presentado en el Algoritmo 2, para construir ˆF. Inicialmente, F se establece en el subgrafo local L, y se calcula el PageRank f de este grafo. El algoritmo luego procede de la siguiente manera. Primero, se llama al algoritmo SelectNodes (que discutimos en la siguiente sección) y devuelve un conjunto de k nodos para rastrear a continuación del conjunto de nodos en la frontera de rastreo actual, Fout. Estos nodos seleccionados son luego rastreados para expandir el subgrafo local, F, y los PageRanks de este grafo expandido son luego recalculados. Estos pasos se repiten para cada una de las T iteraciones. Finalmente, se devuelve el vector PageRank ˆp, el cual está restringido a las páginas dentro del dominio local original. Dadas nuestras restricciones de computación, ancho de banda y memoria, asumiremos que el algoritmo rastreará como máximo O(n) páginas. Dado que los PageRanks se calculan en cada iteración del algoritmo, lo cual es una operación O(n), también asumiremos que el número de iteraciones T es una constante. Por supuesto, el principal desafío aquí radica en seleccionar qué conjunto de k nodos rastrear a continuación. En la siguiente sección, definimos formalmente el problema y presentamos algoritmos eficientes. 5. SELECCIÓN DE NODO En esta sección, presentamos algoritmos de selección de nodo que operan dentro del marco codicioso presentado en la sección anterior. Primero damos un criterio bien definido para el problema de selección de páginas y proporcionamos evidencia experimental de que este criterio puede identificar de manera efectiva las páginas que optimizan nuestro objetivo del problema (3). A continuación, presentamos nuestra principal contribución algorítmica del artículo de investigación al118, un método con tiempo de ejecución lineal que se deriva de los criterios de selección de esta página. Finalmente, ofrecemos un análisis intuitivo de nuestro algoritmo en términos de fugas y flujos. Mostramos que si solo se considera el flujo, entonces el método resultante es muy similar a una heurística de selección de páginas ampliamente utilizada [6]. 5.1 Formulación Para una página dada j en el dominio global, definimos el grafo local expandido Fj: Fj = F s uT j 0, (4) donde uj es el vector de ceros y unos que contiene los enlaces de salida de F hacia la página j, y s contiene los enlaces de entrada de la página j en el dominio local. Ten en cuenta que no permitimos enlaces a uno mismo en este marco de trabajo. En la práctica, los enlaces internos suelen ser eliminados, ya que solo sirven para inflar el PageRank de una página determinada. Observa que los enlaces entrantes a F desde el nodo j no se conocen hasta después de que el nodo j sea rastreado. Por lo tanto, estimamos este vector de inlink como la expectativa sobre el recuento de inlinks entre el conjunto de páginas ya rastreadas, s = F T e F T e 1. En la práctica, para cualquier página dada, esta estimación puede no reflejar los verdaderos inlinks de esa página. Además, esta expectativa se extrae del conjunto de enlaces dentro del dominio rastreado, mientras que una estimación más precisa también utilizaría enlaces del dominio global. Sin embargo, la distribución mencionada no es conocida por un motor de búsqueda localizado, y sostenemos que la estimación anterior, en promedio, será una estimación mejor que la distribución uniforme, por ejemplo. Dejemos que el PageRank de F sea f. Expresamos el PageRank f+ j del grafo local expandido Fj como f+ j = (1 − xj)fj xj , donde xj es el PageRank del nodo global candidato j, y fj es el vector de PageRank L1-normalizado restringido a las páginas en F. Dado que optimizar directamente nuestro objetivo requiere conocer el PageRank global p∗, proponemos en su lugar rastrear aquellos nodos que tendrán la mayor influencia en los PageRanks de las páginas en el dominio local original L: influencia(j) = k∈L |fj[k] − f[k]| (7) = EL (fj − f) 1. Experimentalmente, el puntaje de influencia es un predictor muy bueno de nuestro objetivo del problema (3). Para cada nodo global candidato j, la figura 1(a) muestra el valor de la función objetivo Global Diff(fj) en función de la influencia de la página j. El dominio local utilizado aquí es un rastreo de páginas políticas conservadoras (proporcionaremos más detalles sobre este conjunto de datos en la sección 6); observamos resultados similares en otros dominios. La correlación es bastante fuerte, lo que implica que los criterios de influencia pueden identificar de manera efectiva las páginas que mejoran la estimación global del PageRank. Como referencia, la figura 1(b) compara nuestro objetivo con un criterio alternativo, el recuento de enlaces de salida. El recuento de enlaces de salida se define como el número de enlaces de salida desde el dominio local a la página j. La correlación aquí es mucho más débil. .00001 .0001 .001 .01 0.26 0.262 0.264 0.266 Influencia Objetivo 1 10 100 1000 0.266 0.264 0.262 0.26 Recuento de Enlaces Salientes Objetivo (a) (b) Figura 1: (a) La correlación entre nuestros criterios de selección de página de influencia (7) y el valor real de la función objetivo (3) es bastante fuerte. (b) Esto contrasta con otros criterios, como el recuento de enlaces salientes, que muestran una correlación mucho más débil. 5.2 Cálculo Como se describe, para cada página global candidata j, se debe calcular el puntaje de influencia (7). Si fj se calcula exactamente para cada página global j, entonces el algoritmo de PageRank tendría que ejecutarse para cada una de las O(n) páginas globales j que consideramos, lo que resultaría en un costo computacional de O(n2) para el método de selección de nodos. Por lo tanto, calcular el valor exacto de fj conducirá a un algoritmo cuadrático, y en su lugar debemos recurrir a métodos de aproximación de este vector. El algoritmo que presentamos funciona realizando una iteración del método de potencia utilizado por el algoritmo PageRank (Algoritmo 1). La tasa de convergencia para el algoritmo PageRank se ha demostrado que es igual a la probabilidad del surfista aleatorio α [7, 11]. Dado un vector inicial x(0), si se realizan k iteraciones de PageRank, la solución actual de PageRank x(k) satisface: x(k) − x∗ 1 = O(αk x(0) − x∗ 1), (8), donde x∗ es el vector de PageRank deseado. Por lo tanto, si solo se realiza una iteración, es necesario elegir un buen vector inicial para lograr una aproximación precisa. Particionamos la matriz de PageRank PFj, correspondiente al subgrafo Fj, como: PFj = ˜F ˜s ˜uT j w, (9) donde ˜F = αF (DF + diag(uj))−1 + (1 − α) e + 1 eT, ˜s = αs + (1 − α) e + 1, ˜uj = α(DF + diag(uj))−1 uj + (1 − α) e + 1, w = 1 − α + 1, y diag(uj) es la matriz diagonal con la entrada (i, i) igual a uno si el i-ésimo elemento de uj es uno, y cero en caso contrario. Hemos asumido aquí que el vector del surfista aleatorio es el vector uniforme, y que L no tiene enlaces colgantes. Estas suposiciones no son necesarias y solo sirven para simplificar la discusión y el análisis. Un enfoque sencillo para estimar fj es el siguiente. Primero, estima el PageRank f+ j de Fj calculando una iteración de PageRank sobre la matriz PFj, utilizando el vector inicial ν = f 0. Luego, estima fj eliminando el último componente de 119 Research Track Paper de nuestra estimación de f+ j (es decir, el componente correspondiente al nodo j añadido), y renormalizando. El problema con este enfoque está en el vector inicial. Recuerde que xj es el PageRank del nodo j añadido. La diferencia entre el PageRank actual f+ j de PFj y el vector inicial ν es ν − f+ j 1 = xj + f − (1 − xj)fj 1 ≥ xj + | f 1 − (1 − xj) fj 1| = xj + |xj| = 2xj. Por lo tanto, según (8), después de una iteración de PageRank, esperamos que nuestra estimación de f+ j todavía tenga un error de aproximadamente 2αxj. En particular, para los nodos candidatos j con un PageRank xj relativamente alto, este método producirá resultados más inexactos. A continuación, presentaremos un método que elimina este sesgo y se ejecuta en tiempo O(n). 5.2.1 Complementación Estocástica Dado que f+ j, como se muestra en (6), es el PageRank de la matriz PFj, tenemos: fj(1 − xj) xj = ˜F ˜s ˜uT j w fj(1 − xj) xj = ˜F fj(1 − xj) + ˜sxj ˜uT j fj(1 − xj) + wxj. Resolver el sistema anterior para fj puede demostrarse que produce fj = ( ˜F + (1 − w)−1 ˜s˜uT j )fj. (10) La matriz S = ˜F +(1−w)−1 ˜s˜uT j se conoce como el complemento estocástico de la matriz estocástica de columna PFj con respecto a la submatriz ˜F. La teoría de complementación estocástica está bien estudiada, y se puede demostrar que el complemento estocástico de una matriz irreducible (como la matriz de PageRank) es único. Además, el complemento estocástico también es irreducible y, por lo tanto, tiene una distribución estacionaria única. Para un estudio extenso, ver [15]. Se puede demostrar fácilmente que el autovalor subdominante de S es a lo sumo +1 α, donde α es el tamaño de F. Para valores suficientemente grandes, este valor estará muy cerca de α. Esto es importante, ya que otras propiedades del algoritmo PageRank, especialmente la sensibilidad del algoritmo, dependen de este valor [11]. En este método, estimamos el vector de longitud fj calculando una iteración de PageRank sobre el complemento estocástico × S, comenzando en el vector f: fj ≈ Sf. (11) Esto contrasta con el método simple descrito en la sección anterior, que primero itera sobre la matriz ( + 1) × ( + 1) PFj para estimar f+ j, y luego elimina el último componente de la estimación y renormaliza para aproximar fj. El problema con el último método radica en la elección del vector inicial de longitud ( + 1), ν. En consecuencia, la estimación de PageRank dada por el método simple difiere del verdadero PageRank en al menos 2αxj, donde xj es el PageRank de la página j. Al utilizar el complemento estocástico, podemos establecer un límite inferior estricto de cero para esta diferencia. Para ver esto, considera el caso en el que se agrega un nodo k a F para formar el subgrafo local aumentado Fk, y que el PageRank de este nuevo grafo es (1 − xk)f xk. Específicamente, la adición de la página k no cambia los PageRanks de las páginas en F, y por lo tanto fk = f. Por la construcción del complemento estocástico, fk = Sfk, por lo que la aproximación dada en la ecuación (11) producirá la solución exacta. A continuación, presentamos los detalles computacionales necesarios para calcular eficientemente la cantidad fj − f 1 sobre todas las páginas globales conocidas j. Comenzamos expandiendo la diferencia fj − f, donde el vector fj se estima como en (11), fj − f ≈ Sf − f = αF (DF + diag(uj))−1 f + (1 − α) e + 1 eT f +(1 − w)−1 (˜uT j f)˜s − f. (12) Tenga en cuenta que la matriz (DF + diag(uj))−1 es diagonal. Dejando que o[k] sea el recuento de enlaces de salida para la página k en F, podemos expresar el elemento diagonal k-ésimo como: (DF + diag(uj))−1 [k, k] = 1 o[k]+1 si uj[k] = 1 1 o[k] si uj[k] = 0 Notando que (o[k] + 1)−1 = o[k]−1 − (o[k](o[k] + 1))−1 y reescribiendo esto en forma matricial obtenemos (DF +diag(uj))−1 = D−1 F −D−1 F (DF +diag(uj))−1 diag(uj). (13) Usamos la misma identidad para expresar e + 1 = e − e ( + 1) . (14) Recordemos que, por definición, tenemos PF = αF D−1 F +(1−α)e. Sustituyendo (13) y (14) en (12) se obtiene que fj − f ≈ (PF f − f) −αF D−1 F (DF + diag(uj))−1 diag(uj)f −(1 − α) e ( + 1) + (1 − w)−1 (˜uT j f)˜s = x + y + (˜uT j f)z, (15), notando que por definición, f = PF f, y definiendo los vectores x, y, y z como x = −αF D−1 F (DF + diag(uj))−1 diag(uj)f (16) y = −(1 − α) e ( + 1) (17) z = (1 − w)−1 ˜s. (18) El primer término x es un vector disperso, y toma valores no nulos solo para las páginas locales k que son hermanas de la página global j. Definimos (i, j) ∈ F si y solo si F [j, i] = 1 (equivalentemente, la página i enlaza a la página j) y expresamos el valor del componente x[k] como: x[k] = −α k:(k,k)∈F, uj[k]=1 f[k] o[k](o[k] + 1), (19) donde o[k], como antes, es el número de enlaces salientes de la página k en el dominio local. Ten en cuenta que los dos últimos términos, y y z, no dependen del nodo global actual j. Dada la función hj(f) = y + (˜uT j f)z 1, la cantidad fj − f 1 120 Research Track Paper puede expresarse como fj − f 1 = k x[k] + y[k] + (˜uT j f)z[k] = k:x[k]=0 y[k] + (˜uT j f)z[k] + k:x[k]=0 x[k] + y[k] + (˜uT j f)z[k] = hj(f) − k:x[k]=0 y[k] + (˜uT j f)z[k] + k:x[k]=0 x[k] + y[k] + (˜uT j f)z[k]. (20) Si podemos calcular la función hj en tiempo lineal, entonces podemos calcular cada valor de fj − f 1 usando una cantidad adicional de tiempo proporcional al número de componentes no nulas en x. Estas optimizaciones se llevan a cabo en el Algoritmo 3. Nótese que la ecuación (20) calcula la diferencia entre todos los componentes de f y fj, mientras que nuestros criterios de selección de nodos, dados en la ecuación (7), se restringen a los componentes correspondientes a los nodos en el dominio local original L. Examinemos el Algoritmo 3 con más detalle. Primero, el algoritmo calcula el número de enlaces de salida para cada página en el dominio local. El algoritmo luego calcula la cantidad ˜uT j f para cada página global j conocida. Este producto interno se puede escribir como (1 − α) 1 + 1 + α k:(k,j)∈Fout f[k] o[k] + 1, donde el segundo término suma sobre el conjunto de páginas locales que enlazan a la página j. Dado que se asumió que el número total de aristas en Fout tenía un tamaño O( ) (recordemos que es el número de páginas en F), el tiempo de ejecución de este paso también es O( ). El algoritmo luego calcula los vectores y y z, como se indican en (17) y (18), respectivamente. El método L1NormDiff se llama en los componentes de estos vectores que corresponden a las páginas en L, y estima el valor de EL(y + (˜uT j f)z) 1 para cada página j. La estimación funciona de la siguiente manera. Primero, los valores de ˜uT j f se discretizan de forma uniforme en c valores {a1, ..., ac}. La cantidad EL(y + aiz) 1 se calcula entonces para cada valor discretizado de ai y se almacena en una tabla. Para evaluar EL (y + az) 1 para algún a ∈ [a1, ac], se determina el valor discretizado más cercano ai, y se utiliza la entrada correspondiente en la tabla. El tiempo total de ejecución de este método es lineal en y el parámetro de discretización c (que consideramos constante). Observamos que si se desean valores exactos, también hemos desarrollado un algoritmo que se ejecuta en tiempo O(log) que no se describe aquí. En el bucle principal, calculamos el vector x, tal como se define en la ecuación (16). Los bucles anidados iteran sobre el conjunto de páginas en F que son hermanas de la página j. Normalmente, el tamaño de este conjunto está limitado por una constante. Finalmente, para cada página j, el vector de puntuaciones se actualiza sobre el conjunto de componentes no nulos k del vector x con k ∈ L. Este conjunto tiene un tamaño igual al número de hermanos locales de la página j, y es un subconjunto del número total de hermanos de la página j. Por lo tanto, cada iteración del bucle principal toma tiempo constante, y el tiempo de ejecución total del bucle principal es O( ). Dado que hemos asumido que el tamaño de F no crecerá más allá de O(n), el tiempo de ejecución total del algoritmo es O(n). Algoritmo 3: Selección de nodos a través de la complementación estocástica. SC-Select(F , Fout, f, k) Entrada: F : matriz de adyacencia de ceros y unos del tamaño correspondiente al subgrafo local actual, Fout: matriz de enlaces de ceros y unos de F al subgrafo global, f: PageRank de F , k: número de páginas a devolver Salida: páginas: conjunto de k páginas para rastrear a continuación {Calcular sumas de enlaces de salida para el subgrafo local} para cada (página j ∈ F ) o[j] ← k:(j,k)∈F F[j, k] fin {Calcular escalar ˜uT j f para cada nodo global j } para cada (página j ∈ Fout) g[j] ← (1 − α) 1 +1 para cada (página k : (k, j) ∈ Fout) g[j] ← g[j] + α f[k] o[k]+1 fin fin {Calcular vectores y z como en (17) y (18) } y ← −(1 − α) e ( +1) z ← (1 − w)−1 ˜s {Aproximar y + g[j] ∗ z 1 para todos los valores g[j]} norm diffs ←L1NormDiffs(g, ELy, ELz) para cada (página j ∈ Fout) {Calcular vector disperso x como en (19)} x ← 0 para cada (página k : (k, j) ∈ Fout) para cada (página k : (k, k ) ∈ F )) x[k ] ← x[k ] − f[k] o[k](o[k]+1) fin fin x ← αx scores[j] ← norm diffs[j] para cada (k : x[k] > 0 y página k ∈ L) scores[j] ← scores[j] − |y[k] + g[j] ∗ z[k]| +|x[k]+y[k]+g[j]∗z[k])| fin fin Devolver k páginas con los puntajes más altos 5.2.2 Flujos de PageRank Ahora presentamos un análisis intuitivo del método de complementación estocástica descomponiendo el cambio en PageRank en términos de fugas y flujos. Este análisis está motivado por la descomposición dada en (15). El flujo de PageRank es el aumento en los PageRanks locales que se originan desde la página global j. Los flujos están representados por el vector no negativo (˜uT j f)z (ecuaciones (15) y (18)). El escalar ˜uT j f se puede pensar como la cantidad total de flujo de PageRank que la página j tiene disponible para distribuir. El vector z dicta cómo se asigna el flujo al dominio local; el flujo que recibe la página local k es proporcional (con un factor constante debido al vector de navegante aleatorio) al número esperado de sus enlaces entrantes. Las filtraciones de PageRank representan la disminución en el PageRank resultante de la adición de la página j. La fuga puede ser cuantificada en términos de los vectores no positivos x e y (ecuaciones (16) y (17)). Para el vector x, podemos ver a partir de la ecuación (19) que la cantidad de PageRank filtrado por una página local es proporcional a la suma ponderada de los Page121 Research Track Paper Ranks de sus páginas hermanas. Por lo tanto, las páginas que tienen hermanos con PageRanks más altos (y un bajo número de enlaces salientes) experimentarán más pérdida de valor. La fuga causada por y es un artefacto del vector del surfista aleatorio. A continuación demostraremos que si solo se considera el término de flujo, (˜uT j f)z, entonces el método resultante es muy similar a una heurística propuesta por Cho et al. [6] que ha sido ampliamente utilizada para el problema de Ordenación de URL en el Rastreo. Esta heurística es computacionalmente más económica, pero como veremos más adelante, no es tan efectiva como el método de Complementación Estocástica. Nuestra estrategia de selección de nodos elige nodos globales que tienen la mayor influencia (ecuación (7)). Si esta influencia se aproxima utilizando solo flujos, el nodo óptimo j∗ es: j∗ = argmaxj EL ˜uT j fz 1 = argmaxj ˜uT j f EL z 1 = argmaxj ˜uT j f = argmaxj α(DF + diag(uj))−1 uj + (1 − α) e + 1 , f = argmaxjfT (DF + diag(uj))−1 uj. La puntuación de selección de página resultante se puede expresar como la suma de los PageRanks de cada página local k que enlaza con j, donde cada valor de PageRank se normaliza por o[k]+1. Curiosamente, la normalización que surge en nuestro método difiere de la heurística dada en [6], la cual normaliza por o[k]. El algoritmo PF-Select, que se omite por falta de espacio, primero calcula la cantidad fT (DF +diag(uj))−1 uj para cada página global j, y luego devuelve las páginas con los k puntajes más altos. Para ver que el tiempo de ejecución de este algoritmo es O(n), observe que la computación involucrada en este método es un subconjunto de la necesaria para el método SC-Select (Algoritmo 3), el cual se demostró que tiene un tiempo de ejecución de O(n). 6. EXPERIMENTOS En esta sección, proporcionamos evidencia experimental para verificar la efectividad de nuestros algoritmos. Primero describimos nuestra metodología experimental y luego presentamos resultados en una variedad de dominios locales. 6.1 Metodología Dado los recursos limitados disponibles en una institución académica, rastrear una sección de la web que sea de la misma magnitud que la indexada por Google o Yahoo! claramente es inviable. Por lo tanto, para un dominio local dado, aproximamos el grafo global rastreando un vecindario local alrededor del dominio que es varias órdenes de magnitud más grande que el subgrafo local. A pesar de que dicho gráfico sigue siendo órdenes de magnitud más pequeño que el verdadero gráfico global, sostenemos que, incluso si existen algunas páginas altamente influyentes que están muy lejos de nuestro dominio local, es poco realista que cualquier algoritmo de selección de nodos locales las encuentre. Tales páginas suelen ser muy poco relacionadas con las páginas dentro del dominio local. Al explicar nuestras estrategias de selección de nodos en la sección 5, hicimos la suposición simplificadora de que nuestro grafo local no contenía nodos colgantes. Esta suposición se hizo solo para facilitar nuestro análisis. Nuestra implementación maneja de manera eficiente los enlaces colgantes al reemplazar cada columna de ceros de nuestra matriz de adyacencia con el vector uniforme. Evaluamos el algoritmo utilizando las dos estrategias de selección de nodos dadas en la Sección 5.2, y también comparándolo con los siguientes métodos de referencia: • Aleatorio: Los nodos se eligen de forma uniforme al azar entre los nodos globales conocidos. • Conteo de enlaces de salida: Se eligen los nodos globales con el mayor número de enlaces de salida desde el dominio local. En cada iteración del algoritmo FindGlobalPR, evaluamos el rendimiento calculando la diferencia entre la estimación actual de PageRank del dominio local, ELf ELf 1, y el PageRank global del dominio local, ELg ELg 1. Todas las calculaciones de PageRank se realizaron utilizando el vector de surfista aleatorio uniforme. En todos los experimentos, establecimos el parámetro del surfista aleatorio α en .85 y utilizamos un umbral de convergencia de 10−6. Evaluamos la diferencia entre los vectores de PageRank local y global utilizando tres métricas diferentes: las normas L1 y L∞, y el tau de Kendall. La norma L1 mide la suma del valor absoluto de las diferencias entre los dos vectores, y la norma L∞ mide el valor absoluto de la mayor diferencia. La métrica de tau de Kendall es una medida de correlación de rangos popular utilizada para comparar PageRanks [2, 11]. Esta métrica se puede calcular contando el número de pares de pares que coinciden en la clasificación, y restando de eso el número de pares de pares que no coinciden en la clasificación. El valor final se normaliza luego por el número total de n pares de este tipo, resultando en un rango de [−1, 1], donde una puntuación negativa indica una anticorrelación entre las clasificaciones, y valores cercanos a uno corresponden a una fuerte correlación de rangos. 6.2 Resultados Nuestros experimentos se basan en dos grandes rastreos web y se descargaron utilizando el rastreador web que forma parte del proyecto de motor de búsqueda de código abierto Nutch [18]. Todas las exploraciones se limitaron únicamente a páginas http, y para limitar el número de páginas generadas dinámicamente que exploramos, ignoramos todas las páginas con URLs que contengan alguno de los caracteres ?, *, @ o =. El primer rastreo, al que nos referiremos como el conjunto de datos edu, fue iniciado por las páginas de inicio de los 100 principales departamentos de posgrado en informática en los Estados Unidos, según la clasificación de US News and World Report [16], y también por las páginas de inicio de sus respectivas instituciones. Se realizó un rastreo de profundidad 5, restringido a páginas dentro del dominio .edu, lo que resultó en un grafo con aproximadamente 4.7 millones de páginas y 22.9 millones de enlaces. El segundo rastreo fue alimentado por el conjunto de páginas bajo la jerarquía de política en el proyecto de directorio abierto dmoz[17]. Rastreamos todas las páginas hasta cuatro enlaces de distancia, lo que resultó en un grafo con 4.4 millones de páginas y 17.3 millones de enlaces. Dentro del rastreo educativo, identificamos los cinco dominios específicos del sitio correspondientes a los sitios web de los cinco principales departamentos de posgrado en ciencias de la computación, según la clasificación de US News and World Report. Esto produjo dominios locales de varios tamaños, desde 10,626 (UIUC) hasta 59,895 (Berkeley). Para cada uno de estos dominios específicos del sitio con tamaño n, realizamos 50 iteraciones del algoritmo FindGlobalPR para rastrear un total de 2n nodos adicionales. La Figura 2(a) muestra la diferencia (L1) entre la estimación de PageRank en cada iteración y el PageRank global, para el dominio local de Berkeley. El rendimiento de este conjunto de datos fue representativo del rendimiento típico en los cinco dominios locales específicos de informática. Inicialmente, la diferencia de L1 entre los PageRanks globales y locales variaba desde .0469 (Stanford) hasta .149 (MIT). Para las primeras varias iteraciones, el Artículo de Investigación 122 0 5 10 15 20 25 30 35 40 45 50 0.015 0.02 0.025 0.03 0.035 0.04 0.045 0.05 0.055 Número de Iteraciones Diferencia de PageRank Global y Local (L1) Complemento Estocástico PageRank Flujo de Enlaces de Conteo Aleatorio 0 10 20 30 40 50 0 0.05 0.1 0.15 0.2 0.25 0.3 0.35 Número de Iteraciones Diferencia de PageRank Global y Local (L1) Complemento Estocástico PageRank Flujo de Enlaces de Conteo Aleatorio 0 5 10 15 20 25 0.16 0.18 0.2 0.22 0.24 0.26 0.28 0.3 0.32 0.34 Número de Iteraciones Diferencia de PageRank Global y Local (L1) Complemento Estocástico PageRank Flujo de Enlaces de Conteo Aleatorio (a) www.cs.berkeley.edu (b) www.enterstageright.com (c) Política Figura 2: Diferencia L1 entre los PageRanks globales estimados y verdaderos para (a) el sitio web de ciencias de la computación de Berkeley, (b) el dominio específico del sitio, www.enterstageright.com, y (c) el dominio específico del tema de política. El método de complemento estocástico supera a todos los demás métodos en diferentes dominios. Tres métodos basados en enlaces superan a la heurística de selección aleatoria. Después de estas iteraciones iniciales, la heurística aleatoria tendió a ser más competitiva con (o incluso superar, como en el dominio local de Berkeley) las heurísticas de conteo de enlaces de salida y flujo de PageRank. En todos los ensayos, el método de complementación estocástica superó a los otros métodos o compitió con ellos. La Tabla 1 muestra la diferencia promedio entre los PageRanks globales estimados finales y los PageRanks globales reales para varias medidas de distancia. Algoritmo L1 L∞ Kendall Estocástico. Tabla 1: Rendimiento final promedio de varias estrategias de selección de nodos para los cinco dominios locales de informática específicos del sitio. Ten en cuenta que el Tau de Kendall mide similitud, mientras que las otras métricas son medidas de disimilitud. La Complementación Estocástica claramente supera a los otros métodos en todas las métricas. Dentro del conjunto de datos de política, también realizamos dos pruebas específicas para los sitios web más grandes en el rastreo: www.adamsmith.org, el sitio web del Instituto Adam Smith con sede en Londres, y www.enterstageright.com, una revista en línea conservadora. Al igual que con los dominios locales de edu, ejecutamos nuestro algoritmo durante 50 iteraciones, rastreando un total de 2n nodos. La figura 2 (b) muestra los resultados para el dominio www.enterstageright.com. A diferencia de los dominios locales de edu, los métodos Random y OutlinkCount no fueron competitivos ni con los métodos SC-Select ni con los métodos PF-Select. Entre todos los conjuntos de datos y todos los métodos de selección de nodos, el método de complementación estocástica fue el más impresionante en este conjunto de datos, logrando una estimación final que difería solo .0279 del PageRank global, una mejora de diez veces sobre la diferencia inicial del PageRank local de .299. Para el dominio local de Adam Smith, la diferencia inicial entre los PageRanks locales y globales fue de .148, y las estimaciones finales proporcionadas por los métodos SC-Select, PF-Select, OutlinkCount y Random fueron de .0208, .0193, .0222 y .0356, respectivamente. Dentro del conjunto de datos de política, construimos cuatro dominios locales específicos de temas. El primer dominio consistía en todas las páginas de la categoría de política de dmoz, y también todas las páginas dentro de cada uno de estos sitios hasta dos enlaces de distancia. Esto produjo un dominio local de 90,811 páginas, y los resultados se muestran en la figura 2 (c). Debido al mayor tamaño de los dominios específicos del tema, ejecutamos nuestro algoritmo solo durante 25 iteraciones para rastrear un total de n nodos. También creamos dominios específicos de temas a partir de tres subtemas políticos: liberalismo, conservadurismo y socialismo. Las páginas en estos dominios fueron identificadas por sus categorías correspondientes de dmoz. Para cada subtema, establecemos el dominio local como todas las páginas dentro de tres enlaces de las páginas de categoría dmoz correspondientes. La Tabla 2 resume el rendimiento de estos tres dominios específicos del tema, así como también del dominio político más amplio. Para cuantificar el efecto global de una página js en los valores globales de PageRank de las páginas en el dominio local, definimos el impacto de la página js como su valor de PageRank, g[j], normalizado por la fracción de sus enlaces salientes que apuntan al dominio local: impacto(j) = oL[j] o[j] · g[j], donde oL[j] es el número de enlaces salientes de la página j a páginas en el dominio local L, y o[j] es el número total de enlaces salientes de js. En términos del modelo del surfista aleatorio, el impacto de la página j es la probabilidad de que el surfista aleatorio (1) se encuentre actualmente en la página global j en su caminata aleatoria y (2) tome un enlace de salida a una página local, dado que ya ha decidido no saltar a una página aleatoria. Para el dominio político local, encontramos que muchas de las páginas con alto impacto eran de hecho páginas políticas que deberían haber sido incluidas en el tema de política de dmoz, pero no lo estaban. Por ejemplo, las dos páginas globales más influyentes fueron el motor de búsqueda político www.askhenry.com y la página de inicio de la revista política en línea www.policyreview.com. Entre las páginas no políticas, la página de inicio de la revista Education Next fue la más influyente. El diario está disponible de forma gratuita en línea y contiene artículos sobre varios aspectos de la educación K-12 en América. Para proporcionar algunas pruebas anecdóticas de la efectividad de nuestros métodos de selección de páginas, observamos que el método SC-Select eligió 11 páginas dentro del dominio www.educationnext.org, el método PF-Select descubrió 7 páginas, mientras que los métodos OutlinkCount y Random encontraron solo 6 páginas cada uno. Para el ámbito político local conservador, el sitio web socialista www.ornery.org tuvo una puntuación de impacto muy alta. Este documento de investigación de la pista 123 titulado \"Toda la política: Algoritmo L1 L2 Kendall Stoch\". Comp. .1253 .000700 .8671 Flujo PR .1446 .000710 .8518 Enlace saliente .1470 .00225 .8642 Aleatorio .2055 .00203 .8271 Conservadurismo: Algoritmo L1 L2 Kendall Estoc. Comp. .0496 .000990 .9158 Flujo PR .0554 .000939 .9028 Enlace saliente .0602 .00527 .9144 Aleatorio .1197 .00102 .8843 Liberalismo: Algoritmo L1 L2 Kendall Estoc. Comp. .0622 .001360 .8848 Flujo PR .0799 .001378 .8669 Enlace saliente .0763 .001379 .8844 Aleatorio .1127 .001899 .8372 Socialismo: Algoritmo L1 L∞ Kendall Estoc. Tabla 2: Rendimiento final entre estrategias de selección de nodos para las cuatro exploraciones específicas de temas políticos. Ten en cuenta que el coeficiente de correlación de Kendall mide la similitud, mientras que las otras métricas son medidas de disimilitud. Como era de esperar, el PageRank global de este artículo (que resulta estar en la página de inicio de la NCCPR, www.nationalresearch.com) era aproximadamente de .002, mientras que el PageRank local de esta página era solo de .00158. El método SC-Select produjo una estimación global de PageRank de aproximadamente .00182, el método PFSelect estimó un valor de .00167, y los métodos Random y OutlinkCount produjeron valores de .01522 y .00171, respectivamente. TRABAJO RELACIONADO El marco de selección de nodos que hemos propuesto es similar al problema de ordenación de URL para el rastreo propuesto por Cho et al. en [6]. Mientras que nuestro marco busca minimizar la diferencia entre el PageRank global y local, el objetivo utilizado en [6] es rastrear primero las páginas más altamente clasificadas (globalmente). Proponen varios algoritmos de selección de nodos, incluyendo la heurística del recuento de enlaces de salida, así como una variante de nuestro algoritmo PF-Select al que se refieren como la métrica de ordenación de PageRank. Encontraron que este método era el más efectivo para optimizar su objetivo, al igual que lo demostró una encuesta reciente de estos métodos realizada por Baeza-Yates et al. [1]. Boldi et al. también experimentan dentro de un marco de rastreo similar en [2], pero cuantifican sus resultados al comparar la correlación de rangos de Kendall entre los PageRanks del conjunto actual de páginas rastreadas y los del grafo global completo. Encontraron que las estrategias de selección de nodos que rastreaban páginas con el PageRank global más alto primero en realidad tenían un peor rendimiento (con respecto a la correlación de Kendalls Tau entre los PageRanks locales y globales) que las estrategias básicas de búsqueda en profundidad o en amplitud. Sin embargo, sus experimentos difieren de nuestro trabajo en que nuestros algoritmos de selección de nodos no utilizan (ni tienen acceso a) valores globales de PageRank. Se han propuesto muchas mejoras algorítmicas para calcular los valores exactos de PageRank [9, 10, 14]. Si se utilizan tales algoritmos para calcular los PageRanks globales de nuestro dominio local, todos requerirían una computación, almacenamiento y ancho de banda de O(N), donde N es el tamaño del dominio global. Esto contrasta con nuestro método, que aproxima el PageRank global y escala linealmente con el tamaño del dominio local. Wang y Dewitt [22] proponen un sistema en el que el conjunto de servidores web que conforman el dominio global se comunican entre sí para calcular sus respectivos PageRanks globales. Para un servidor web dado que aloja n páginas, los requisitos computacionales, de ancho de banda y almacenamiento también son lineales en n. Una desventaja de este sistema es que el número de servidores web distintos que conforman el dominio global puede ser muy grande. Por ejemplo, nuestro conjunto de datos edu contiene sitios web de más de 3,200 universidades diferentes; coordinar un sistema así entre un gran número de sitios puede ser muy difícil. Gan, Chen y Suel proponen un método para estimar el PageRank de una sola página [5] que utiliza solo ancho de banda, computación y espacio constantes. Su enfoque se basa en la disponibilidad de un servidor de conectividad remota que puede suministrar el conjunto de enlaces entrantes a una página dada, una suposición que no se utiliza en nuestro marco de trabajo. Experimentalmente demuestran que se puede obtener una estimación razonable del PageRank de los nodos visitando como máximo unos pocos cientos de nodos. El uso de su algoritmo para nuestro problema requeriría que primero se descargue todo el dominio global o se utilice un servidor de conectividad, lo que resultaría en grafos web muy grandes. 8. CONCLUSIONES Y TRABAJOS FUTUROS Internet está creciendo de forma exponencial, y para poder navegar por un repositorio tan grande como la web, los motores de búsqueda globales se han establecido como una necesidad. Junto con la omnipresencia de estos motores de búsqueda a gran escala, surge un aumento en las expectativas de los usuarios de búsqueda. Al proporcionar una cobertura completa y aislada de un dominio web específico, los motores de búsqueda localizados son un medio efectivo para localizar rápidamente contenido que de otra manera podría ser difícil de encontrar. En este trabajo, sostenemos que el uso de PageRank global en un motor de búsqueda localizado puede mejorar el rendimiento. Para estimar el PageRank global, hemos propuesto un marco de selección de nodos iterativo en el que seleccionamos qué páginas de la frontera global rastrear a continuación. Nuestra principal contribución es nuestro algoritmo de selección de páginas de complementación estocástica. Este método recorre los nodos que tendrán un impacto significativo en el dominio local y tiene un tiempo de ejecución lineal en el número de nodos en el dominio local. Experimentalmente, validamos estos métodos en un conjunto diverso de dominios locales, que incluyen siete dominios específicos del sitio y cuatro dominios específicos del tema. Concluimos que al rastrear n o 2n páginas adicionales, nuestros métodos encuentran una estimación de los PageRanks globales que es hasta diez veces mejor que simplemente usar los PageRanks locales. Además, demostramos que nuestro algoritmo supera consistentemente a otras heurísticas existentes. En muchas ocasiones, los dominios específicos de un tema se descubren utilizando un rastreador web enfocado que considera el contenido de las páginas junto con el texto del ancla del enlace para decidir qué páginas rastrear a continuación [4]. Aunque estos rastreadores han demostrado ser bastante efectivos en descubrir contenido relacionado con el tema, también se rastrean muchas páginas irrelevantes en el proceso. Por lo general, estas páginas son eliminadas y no son indexadas por el motor de búsqueda localizado. Estas páginas pueden, por supuesto, proporcionar información valiosa sobre el PageRank global del dominio local. Una forma de integrar estas páginas en nuestro marco de trabajo es comenzar el algoritmo FindGlobalPR con el subgrafo actual F igual al conjunto de páginas que fueron rastreadas por el rastreador enfocado. El marco de estimación global de PageRank, junto con los algoritmos de selección de nodos presentados, requieren todos una computación de O(n) por iteración y un ancho de banda proporcional al número de páginas rastreadas, Tk. Si el número de iteraciones T es relativamente pequeño en comparación con el número de páginas rastreadas por iteración, k, entonces el cuello de botella del algoritmo será la fase de rastreo. Sin embargo, a medida que el número de iteraciones aumenta (en relación con k), el cuello de botella residirá en el cálculo de la selección de nodos. En este caso, nuestros algoritmos se beneficiarían de optimizaciones en el factor constante. Recuerde que el algoritmo FindGlobalPR (Algoritmo 2) requiere que los PageRanks del dominio local expandido actual se vuelvan a calcular en cada iteración. El trabajo reciente de Langville y Meyer [12] proporciona un algoritmo para recalcular rápidamente los PageRanks de un grafo web dado si se agregan un pequeño número de nodos. Este algoritmo demostró proporcionar una aceleración de cinco a diez veces en algunos conjuntos de datos. Planeamos investigar esto y otras optimizaciones similares como trabajo futuro. En este artículo, hemos evaluado objetivamente nuestros métodos midiendo qué tan cercanas son nuestras estimaciones globales de PageRank a los verdaderos PageRanks globales. Para determinar el beneficio de utilizar PageRanks globales en un motor de búsqueda localizado, sugerimos un estudio de usuarios en el que se les pida a los usuarios que califiquen la calidad de los resultados de búsqueda para varias consultas de búsqueda. Para algunas consultas, solo se utilizan los PageRanks locales en la clasificación, y para las consultas restantes, se utilizan los PageRanks locales y los PageRanks globales aproximados, según lo calculado por nuestros algoritmos. Los resultados de dicho estudio pueden ser analizados para determinar el beneficio adicional de utilizar los PageRanks globales calculados por nuestros métodos, en lugar de solo utilizar los PageRanks locales. Agradecimientos. Esta investigación fue apoyada por la subvención de la NSF CCF-0431257, el Premio de Carrera de la NSF ACI-0093404 y una subvención de Sabre, Inc. 9. REFERENCIAS [1] R. Baeza-Yates, M. Marín, C. Castillo y A. Rodríguez. Rastreando un país: estrategias mejores que el recorrido en anchura para ordenar páginas web. Conferencia de la World-Wide Web, 2005. [2] P. Boldi, M. Santini y S. Vigna. Haz lo peor para lograr lo mejor: efectos paradójicos en los cálculos incrementales de PageRank. Taller sobre Grafos Web, 3243:168-180, 2004. [3] S. Brin y L. Page. La anatomía de un motor de búsqueda web hipertextual a gran escala. Redes de Computadoras y Sistemas ISDN, 33(1-7):107-117, 1998. [4] S. Chakrabarti, M. van den Berg y B. Dom. Rastreo enfocado: un nuevo enfoque para el descubrimiento de recursos web específicos de un tema. Conferencia de la World-Wide Web, 1999. [5] Y. Chen, Q. Gan y T. Suel. Métodos locales para estimar los valores de pagerank. Conferencia sobre Gestión de Información y Conocimiento, 2004. [6] J. Cho, H. Garcia-Molina y L. Page. Rastreo eficiente a través de la ordenación de URL. Conferencia de la World-Wide Web, 1998. [7] T. H. Haveliwala y S. D. Kamvar. El segundo valor propio de la matriz de Google. Informe técnico, Universidad de Stanford, 2003. [8] T. Joachims, F. Radlinski, L. Granka, A. Cheng, C. Tillekeratne y A. Patel. Aprendizaje de funciones de recuperación a partir de retroalimentación implícita. http://www.cs.cornell.edu/People/tj/career. [9] S. D. Kamvar, T. H. Haveliwala, C. D. Manning y G. H. Golub. Explotando la estructura de bloques de la web para calcular el pagerank. Conferencia de la World-Wide Web, 2003. [10] S. D. Kamvar, T. H. Haveliwala, C. D. Manning y G. H. Golub. Métodos de extrapolación para acelerar el cálculo de PageRank. Conferencia de la World-Wide Web, 2003. [11] A. N. Langville y C. D. Meyer. Más profundo dentro de PageRank. Matemáticas en Internet, 2004. [12] A. N. Langville y C. D. Meyer. Actualizando el vector estacionario de una cadena de Markov irreducible con miras al PageRank de Google. Revista SIAM sobre Análisis de Matrices, 2005. [13] P. Lyman, H. R. Varian, K. Swearingen, P. Charles, N. Good, L. L. Jordan y J. Pal. ¿Cuánta información en 2003? Escuela de Gestión de la Información y Sistemas, Universidad de California en Berkeley, 2003. [14] F. McSherry. Un enfoque uniforme para el cálculo acelerado de PageRank. Conferencia de la World-Wide Web, 2005. [15] C. D. Meyer. Complementación estocástica, desacoplamiento de cadenas de Markov y la teoría de sistemas casi reducibles. SIAM Review, 31:240-272, 1989. [16] US News and World Report. http://www.usnews.com. [17] Proyecto de directorio abierto Dmoz. http://www.dmoz.org. [18] Motor de búsqueda de código abierto Nutch. http://www.nutch.org. [19] F. Radlinski y T. Joachims. Cadenas de consulta: aprendizaje para clasificar a partir de retroalimentación implícita. Conferencia Internacional ACM SIGKDD sobre Descubrimiento de Conocimiento y Minería de Datos, 2005. [20] S. Raghavan y H. Garcia-Molina. Explorando la web oculta. En Actas de la Vigésimo séptima Conferencia Internacional sobre Bases de Datos Muy Grandes, 2001. [21] T. Tin Tang, D. Hawking, N. Craswell y K. Griffiths. Rastreo enfocado para relevancia temática y calidad de la información médica. Conferencia sobre Gestión de Información y Conocimiento, 2005. [22] Y. Wang y D. J. DeWitt. Calculando el pagerank en un sistema distribuido de búsqueda en internet. Actas de la 30ª Conferencia VLDB, 2004. 125 Artículos de Investigación.",
    "original_sentences": [
        "Estimating the Global PageRank of Web Communities Jason V. Davis Dept.",
        "of Computer Sciences University of Texas at Austin Austin, TX 78712 jdavis@cs.utexas.edu Inderjit S. Dhillon Dept. of Computer Sciences University of Texas at Austin Austin, TX 78712 inderjit@cs.utexas.edu ABSTRACT Localized search engines are small-scale systems that index a particular community on the web.",
        "They offer several benefits over their large-scale counterparts in that they are relatively inexpensive to build, and can provide more precise and complete search capability over their relevant domains.",
        "One disadvantage such systems have over large-scale search engines is the lack of global PageRank values.",
        "Such information is needed to assess the value of pages in the localized search domain within the context of the web as a whole.",
        "In this paper, we present well-motivated algorithms to estimate the global PageRank values of a local domain.",
        "The algorithms are all highly scalable in that, given a local domain of size n, they use O(n) resources that include computation time, bandwidth, and storage.",
        "We test our methods across a variety of localized domains, including site-specific domains and topic-specific domains.",
        "We demonstrate that by crawling as few as n or 2n additional pages, our methods can give excellent global PageRank estimates.",
        "Categories and Subject Descriptors H.3.3 [Information Storage and Retrieval]: Information Search and Retrieval; G.1.3 [Numerical Analysis]: Numerical Linear Algebra; G.3 [Probability and Statistics]: Markov Processes General Terms PageRank, Markov Chain, Stochastic Complementation 1.",
        "INTRODUCTION Localized search engines are small-scale search engines that index only a single community of the web.",
        "Such communities can be site-specific domains, such as pages within the cs.utexas.edu domain, or topic-related communitiesfor example, political websites.",
        "Compared to the web graph crawled and indexed by large-scale search engines, the size of such local communities is typically orders of magnitude smaller.",
        "Consequently, the computational resources needed to build such a search engine are also similarly lighter.",
        "By restricting themselves to smaller, more manageable sections of the web, localized search engines can also provide more precise and complete search capabilities over their respective domains.",
        "One drawback of localized indexes is the lack of global information needed to compute link-based rankings.",
        "The PageRank algorithm [3], has proven to be an effective such measure.",
        "In general, the PageRank of a given page is dependent on pages throughout the entire web graph.",
        "In the context of a localized search engine, if the PageRanks are computed using only the local subgraph, then we would expect the resulting PageRanks to reflect the perceived popularity within the local community and not of the web as a whole.",
        "For example, consider a localized search engine that indexes political pages with conservative views.",
        "A person wishing to research the opinions on global warming within the conservative political community may encounter numerous such opinions across various websites.",
        "If only local PageRank values are available, then the search results will reflect only strongly held beliefs within the community.",
        "However, if global PageRanks are also available, then the results can additionally reflect outsiders views of the conservative community (those documents that liberals most often access within the conservative community).",
        "Thus, for many localized search engines, incorporating global PageRanks can improve the quality of search results.",
        "However, the number of pages a local search engine indexes is typically orders of magnitude smaller than the number of pages indexed by their large-scale counterparts.",
        "Localized search engines do not have the bandwidth, storage capacity, or computational power to crawl, download, and compute the global PageRanks of the entire web.",
        "In this work, we present a method of approximating the global PageRanks of a local domain while only using resources of the same order as those needed to compute the PageRanks of the local subgraph.",
        "Our proposed method looks for a supergraph of our local subgraph such that the local PageRanks within this supergraph are close to the true global PageRanks.",
        "We construct this supergraph by iteratively crawling global pages on the current web frontier-i.e., global pages with inlinks from pages that have already been crawled.",
        "In order to provide 116 Research Track Paper a good approximation to the global PageRanks, care must be taken when choosing which pages to crawl next; in this paper, we present a well-motivated page selection algorithm that also performs well empirically.",
        "This algorithm is derived from a well-defined problem objective and has a running time linear in the number of local nodes.",
        "We experiment across several types of local subgraphs, including four topic related communities and several sitespecific domains.",
        "To evaluate performance, we measure the difference between the current global PageRank estimate and the global PageRank, as a function of the number of pages crawled.",
        "We compare our algorithm against several heuristics and also against a baseline algorithm that chooses pages at random, and we show that our method outperforms these other methods.",
        "Finally, we empirically demonstrate that, given a local domain of size n, we can provide good approximations to the global PageRank values by crawling at most n or 2n additional pages.",
        "The paper is organized as follows.",
        "Section 2 gives an overview of localized search engines and outlines their advantages over global search.",
        "Section 3 provides background on the PageRank algorithm.",
        "Section 4 formally defines our problem, and section 5 presents our page selection criteria and derives our algorithms.",
        "Section 6 provides experimental results, section 7 gives an overview of related work, and, finally, conclusions are given in section 8. 2.",
        "LOCALIZED SEARCH ENGINES Localized search engines index a single community of the web, typically either a site-specific community, or a topicspecific community.",
        "Localized search engines enjoy three major advantages over their large-scale counterparts: they are relatively inexpensive to build, they can offer more precise search capability over their local domain, and they can provide a more complete index.",
        "The resources needed to build a global search engine are enormous.",
        "A 2003 study by Lyman et al. [13] found that the surface web (publicly available static sites) consists of 8.9 billion pages, and that the average size of these pages is approximately 18.7 kilobytes.",
        "To download a crawl of this size, approximately 167 terabytes of space is needed.",
        "For a researcher who wishes to build a search engine with access to a couple of workstations or a small server, storage of this magnitude is simply not available.",
        "However, building a localized search engine over a web community of a hundred thousand pages would only require a few gigabytes of storage.",
        "The computational burden required to support search queries over a database this size is more manageable as well.",
        "We note that, for topic-specific search engines, the relevant community can be efficiently identified and downloaded by using a focused crawler [21, 4].",
        "For site-specific domains, the local domain is readily available on their own web server.",
        "This obviates the need for crawling or spidering, and a complete and up-to-date index of the domain can thus be guaranteed.",
        "This is in contrast to their large-scale counterparts, which suffer from several shortcomings.",
        "First, crawling dynamically generated pages-pages in the hidden web-has been the subject of research [20] and is a non-trivial task for an external crawler.",
        "Second, site-specific domains can enable the robots exclusion policy.",
        "This prohibits external search engines crawlers from downloading content from the domain, and an external search engine must instead rely on outside links and anchor text to index these restricted pages.",
        "By restricting itself to only a specific domain of the internet, a localized search engine can provide more precise search results.",
        "Consider the canonical ambiguous search query, jaguar, which can refer to either the car manufacturer or the animal.",
        "A scientist trying to research the habitat and evolutionary history of a jaguar may have better success using a finely tuned zoology-specific search engine than querying Google with multiple keyword searches and wading through irrelevant results.",
        "A method to learn better ranking functions for retrieval was recently proposed by Radlinski and Joachims [19] and has been applied to various local domains, including Cornell Universitys website [8]. 3.",
        "PAGERANK OVERVIEW The PageRank algorithm defines the importance of web pages by analyzing the underlying hyperlink structure of a web graph.",
        "The algorithm works by building a Markov chain from the link structure of the web graph and computing its stationary distribution.",
        "One way to compute the stationary distribution of a Markov chain is to find the limiting distribution of a random walk over the chain.",
        "Thus, the PageRank algorithm uses what is sometimes referred to as the random surfer model.",
        "In each step of the random walk, the surfer either follows an outlink from the current page (i.e. the current node in the chain), or jumps to a random page on the web.",
        "We now precisely define the PageRank problem.",
        "Let U be an m × m adjacency matrix for a given web graph such that Uji = 1 if page i links to page j and Uji = 0 otherwise.",
        "We define the PageRank matrix PU to be: PU = αUD−1 U + (1 − α)veT , (1) where DU is the (unique) diagonal matrix such that UD−1 U is column stochastic, α is a given scalar such that 0 ≤ α ≤ 1, e is the vector of all ones, and v is a non-negative, L1normalized vector, sometimes called the random surfer vector.",
        "Note that the matrix D−1 U is well-defined only if each column of U has at least one non-zero entry-i.e., each page in the webgraph has at least one outlink.",
        "In the presence of such dangling nodes that have no outlinks, one commonly used solution, proposed by Brin et al. [3], is to replace each zero column of U by a non-negative, L1-normalized vector.",
        "The PageRank vector r is the dominant eigenvector of the PageRank matrix, r = PU r. We will assume, without loss of generality, that r has an L1-norm of one.",
        "Computationally, r can be computed using the power method.",
        "This method first chooses a random starting vector r(0) , and iteratively multiplies the current vector by the PageRank matrix PU ; see Algorithm 1.",
        "In general, each iteration of the power method can take O(m2 ) operations when PU is a dense matrix.",
        "However, in practice, the number of links in a web graph will be of the order of the number of pages.",
        "By exploiting the sparsity of the PageRank matrix, the work per iteration can be reduced to O(km), where k is the average number of links per web page.",
        "It has also been shown that the total number of iterations needed for convergence is proportional to α and does not depend on the size of the web graph [11, 7].",
        "Finally, the total space needed is also O(km), mainly to store the matrix U. 117 Research Track Paper Algorithm 1: A linear time (per iteration) algorithm for computing PageRank.",
        "ComputePR(U) Input: U: Adjacency matrix.",
        "Output: r: PageRank vector.",
        "Choose (randomly) an initial non-negative vector r(0) such that r(0) 1 = 1. i ← 0 repeat i ← i + 1 ν ← αUD−1 U r(i−1) {α is the random surfing probability} r(i) ← ν + (1 − α)v {v is the random surfer vector.} until r(i) − r(i−1) < δ {δ is the convergence threshold.} r ← r(i) 4.",
        "PROBLEM DEFINITION Given a local domain L, let G be an N × N adjacency matrix for the entire connected component of the web that contains L, such that Gji = 1 if page i links to page j and Gji = 0 otherwise.",
        "Without loss of generality, we will partition G as: G = L Gout Lout Gwithin , (2) where L is the n × n local subgraph corresponding to links inside the local domain, Lout is the subgraph that corresponds to links from the local domain pointing out to the global domain, Gout is the subgraph containing links from the global domain into the local domain, and Gwithin contains links within the global domain.",
        "We assume that when building a localized search engine, only pages inside the local domain are crawled, and the links between these pages are represented by the subgraph L. The links in Lout are also known, as these point from crawled pages in the local domain to uncrawled pages in the global domain.",
        "As defined in equation (1), PG is the PageRank matrix formed from the global graph G, and we define the global PageRank vector of this graph to be g. Let the n-length vector p∗ be the L1-normalized vector corresponding to the global PageRank of the pages in the local domain L: p∗ = EL g ELg 1 , where EL = [ I | 0 ] is the restriction matrix that selects the components from g corresponding to nodes in L. Let p denote the PageRank vector constructed from the local domain subgraph L. In practice, the observed local PageRank p and the global PageRank p∗ will be quite different.",
        "One would expect that as the size of local matrix L approaches the size of global matrix G, the global PageRank and the observed local PageRank will become more similar.",
        "Thus, one approach to estimating the global PageRank is to crawl the entire global domain, compute its PageRank, and extract the PageRanks of the local domain.",
        "Typically, however, n N , i.e., the number of global pages is much larger than the number of local pages.",
        "Therefore, crawling all global pages will quickly exhaust all local resources (computational, storage, and bandwidth) available to create the local search engine.",
        "We instead seek a supergraph ˆF of our local subgraph L with size O(n).",
        "Our goal Algorithm 2: The FindGlobalPR algorithm.",
        "FindGlobalPR(L, Lout, T, k) Input: L: zero-one adjacency matrix for the local domain, Lout: zero-one outlink matrix from L to global subgraph as in (2), T: number of iterations, k: number of pages to crawl per iteration.",
        "Output: ˆp: an improved estimate of the global PageRank of L. F ← L Fout ← Lout f ← ComputePR(F ) for (i = 1 to T) {Determine which pages to crawl next} pages ← SelectNodes(F , Fout, f, k) Crawl pages, augment F and modify Fout {Update PageRanks for new local domain} f ← ComputePR(F ) end {Extract PageRanks of original local domain & normalize} ˆp ← ELf ELf 1 is to find such a supergraph ˆF with PageRank ˆf, so that ˆf when restricted to L is close to p∗ .",
        "Formally, we seek to minimize GlobalDiff( ˆf) = EL ˆf EL ˆf 1 − p∗ 1 . (3) We choose the L1 norm for measuring the error as it does not place excessive weight on outliers (as the L2 norm does, for example), and also because it is the most commonly used distance measure in the literature for comparing PageRank vectors, as well as for detecting convergence of the algorithm [3].",
        "We propose a greedy framework, given in Algorithm 2, for constructing ˆF .",
        "Initially, F is set to the local subgraph L, and the PageRank f of this graph is computed.",
        "The algorithm then proceeds as follows.",
        "First, the SelectNodes algorithm (which we discuss in the next section) is called and it returns a set of k nodes to crawl next from the set of nodes in the current crawl frontier, Fout.",
        "These selected nodes are then crawled to expand the local subgraph, F , and the PageRanks of this expanded graph are then recomputed.",
        "These steps are repeated for each of T iterations.",
        "Finally, the PageRank vector ˆp, which is restricted to pages within the original local domain, is returned.",
        "Given our computation, bandwidth, and memory restrictions, we will assume that the algorithm will crawl at most O(n) pages.",
        "Since the PageRanks are computed in each iteration of the algorithm, which is an O(n) operation, we will also assume that the number of iterations T is a constant.",
        "Of course, the main challenge here is in selecting which set of k nodes to crawl next.",
        "In the next section, we formally define the problem and give efficient algorithms. 5.",
        "NODE SELECTION In this section, we present node selection algorithms that operate within the greedy framework presented in the previous section.",
        "We first give a well-defined criteria for the page selection problem and provide experimental evidence that this criteria can effectively identify pages that optimize our problem objective (3).",
        "We then present our main al118 Research Track Paper gorithmic contribution of the paper, a method with linear running time that is derived from this page selection criteria.",
        "Finally, we give an intuitive analysis of our algorithm in terms of leaks and flows.",
        "We show that if only the flow is considered, then the resulting method is very similar to a widely used page selection heuristic [6]. 5.1 Formulation For a given page j in the global domain, we define the expanded local graph Fj: Fj = F s uT j 0 , (4) where uj is the zero-one vector containing the outlinks from F into page j, and s contains the inlinks from page j into the local domain.",
        "Note that we do not allow self-links in this framework.",
        "In practice, self-links are often removed, as they only serve to inflate a given pages PageRank.",
        "Observe that the inlinks into F from node j are not known until after node j is crawled.",
        "Therefore, we estimate this inlink vector as the expectation over inlink counts among the set of already crawled pages, s = F T e F T e 1 . (5) In practice, for any given page, this estimate may not reflect the true inlinks from that page.",
        "Furthermore, this expectation is sampled from the set of links within the crawled domain, whereas a better estimate would also use links from the global domain.",
        "However, the latter distribution is not known to a localized search engine, and we contend that the above estimate will, on average, be a better estimate than the uniform distribution, for example.",
        "Let the PageRank of F be f. We express the PageRank f+ j of the expanded local graph Fj as f+ j = (1 − xj)fj xj , (6) where xj is the PageRank of the candidate global node j, and fj is the L1-normalized PageRank vector restricted to the pages in F .",
        "Since directly optimizing our problem goal requires knowing the global PageRank p∗ , we instead propose to crawl those nodes that will have the greatest influence on the PageRanks of pages in the original local domain L: influence(j) = k∈L |fj[k] − f[k]| (7) = EL (fj − f) 1.",
        "Experimentally, the influence score is a very good predictor of our problem objective (3).",
        "For each candidate global node j, figure 1(a) shows the objective function value Global Diff(fj) as a function of the influence of page j.",
        "The local domain used here is a crawl of conservative political pages (we will provide more details about this dataset in section 6); we observed similar results in other domains.",
        "The correlation is quite strong, implying that the influence criteria can effectively identify pages that improve the global PageRank estimate.",
        "As a baseline, figure 1(b) compares our objective with an alternative criteria, outlink count.",
        "The outlink count is defined as the number of outlinks from the local domain to page j.",
        "The correlation here is much weaker. .00001 .0001 .001 .01 0.26 0.262 0.264 0.266 Influence Objective 1 10 100 1000 0.266 0.264 0.262 0.26 Outlink Count Objective (a) (b) Figure 1: (a) The correlation between our influence page selection criteria (7) and the actual objective function (3) value is quite strong. (b) This is in contrast to other criteria, such as outlink count, which exhibit a much weaker correlation. 5.2 Computation As described, for each candidate global page j, the influence score (7) must be computed.",
        "If fj is computed exactly for each global page j, then the PageRank algorithm would need to be run for each of the O(n) such global pages j we consider, resulting in an O(n2 ) computational cost for the node selection method.",
        "Thus, computing the exact value of fj will lead to a quadratic algorithm, and we must instead turn to methods of approximating this vector.",
        "The algorithm we present works by performing one power method iteration used by the PageRank algorithm (Algorithm 1).",
        "The convergence rate for the PageRank algorithm has been shown to equal the random surfer probability α [7, 11].",
        "Given a starting vector x(0) , if k PageRank iterations are performed, the current PageRank solution x(k) satisfies: x(k) − x∗ 1 = O(αk x(0) − x∗ 1), (8) where x∗ is the desired PageRank vector.",
        "Therefore, if only one iteration is performed, choosing a good starting vector is necessary to achieve an accurate approximation.",
        "We partition the PageRank matrix PFj , corresponding to the × subgraph Fj as: PFj = ˜F ˜s ˜uT j w , (9) where ˜F = αF (DF + diag(uj))−1 + (1 − α) e + 1 eT , ˜s = αs + (1 − α) e + 1 , ˜uj = α(DF + diag(uj))−1 uj + (1 − α) e + 1 , w = 1 − α + 1 , and diag(uj) is the diagonal matrix with the (i, i)th entry equal to one if the ith element of uj equals one, and is zero otherwise.",
        "We have assumed here that the random surfer vector is the uniform vector, and that L has no dangling links.",
        "These assumptions are not necessary and serve only to simplify discussion and analysis.",
        "A simple approach for estimating fj is the following.",
        "First, estimate the PageRank f+ j of Fj by computing one PageRank iteration over the matrix PFj , using the starting vector ν = f 0 .",
        "Then, estimate fj by removing the last 119 Research Track Paper component from our estimate of f+ j (i.e., the component corresponding to the added node j), and renormalizing.",
        "The problem with this approach is in the starting vector.",
        "Recall from (6) that xj is the PageRank of the added node j.",
        "The difference between the actual PageRank f+ j of PFj and the starting vector ν is ν − f+ j 1 = xj + f − (1 − xj)fj 1 ≥ xj + | f 1 − (1 − xj) fj 1| = xj + |xj| = 2xj.",
        "Thus, by (8), after one PageRank iteration, we expect our estimate of f+ j to still have an error of about 2αxj.",
        "In particular, for candidate nodes j with relatively high PageRank xj, this method will yield more inaccurate results.",
        "We will next present a method that eliminates this bias and runs in O(n) time. 5.2.1 Stochastic Complementation Since f+ j , as given in (6) is the PageRank of the matrix PFj , we have: fj(1 − xj) xj = ˜F ˜s ˜uT j w fj(1 − xj) xj = ˜F fj(1 − xj) + ˜sxj ˜uT j fj(1 − xj) + wxj .",
        "Solving the above system for fj can be shown to yield fj = ( ˜F + (1 − w)−1 ˜s˜uT j )fj. (10) The matrix S = ˜F +(1−w)−1 ˜s˜uT j is known as the stochastic complement of the column stochastic matrix PFj with respect to the sub matrix ˜F .",
        "The theory of stochastic complementation is well studied, and it can be shown the stochastic complement of an irreducible matrix (such as the PageRank matrix) is unique.",
        "Furthermore, the stochastic complement is also irreducible and therefore has a unique stationary distribution as well.",
        "For an extensive study, see [15].",
        "It can be easily shown that the sub-dominant eigenvalue of S is at most +1 α, where is the size of F .",
        "For sufficiently large , this value will be very close to α.",
        "This is important, as other properties of the PageRank algorithm, notably the algorithms sensitivity, are dependent on this value [11].",
        "In this method, we estimate the length vector fj by computing one PageRank iteration over the × stochastic complement S, starting at the vector f: fj ≈ Sf. (11) This is in contrast to the simple method outlined in the previous section, which first iterates over the ( + 1) × ( + 1) matrix PFj to estimate f+ j , and then removes the last component from the estimate and renormalizes to approximate fj.",
        "The problem with the latter method is in the choice of the ( + 1) length starting vector, ν. Consequently, the PageRank estimate given by the simple method differs from the true PageRank by at least 2αxj, where xj is the PageRank of page j.",
        "By using the stochastic complement, we can establish a tight lower bound of zero for this difference.",
        "To see this, consider the case in which a node k is added to F to form the augmented local subgraph Fk, and that the PageRank of this new graph is (1 − xk)f xk .",
        "Specifically, the addition of page k does not change the PageRanks of the pages in F , and thus fk = f. By construction of the stochastic complement, fk = Sfk, so the approximation given in equation (11) will yield the exact solution.",
        "Next, we present the computational details needed to efficiently compute the quantity fj −f 1 over all known global pages j.",
        "We begin by expanding the difference fj −f, where the vector fj is estimated as in (11), fj − f ≈ Sf − f = αF (DF + diag(uj))−1 f + (1 − α) e + 1 eT f +(1 − w)−1 (˜uT j f)˜s − f. (12) Note that the matrix (DF +diag(uj))−1 is diagonal.",
        "Letting o[k] be the outlink count for page k in F , we can express the kth diagonal element as: (DF + diag(uj))−1 [k, k] = 1 o[k]+1 if uj[k] = 1 1 o[k] if uj[k] = 0 Noting that (o[k] + 1)−1 = o[k]−1 − (o[k](o[k] + 1))−1 and rewriting this in matrix form yields (DF +diag(uj))−1 = D−1 F −D−1 F (DF +diag(uj))−1 diag(uj). (13) We use the same identity to express e + 1 = e − e ( + 1) . (14) Recall that, by definition, we have PF = αF D−1 F +(1−α)e .",
        "Substituting (13) and (14) in (12) yields fj − f ≈ (PF f − f) −αF D−1 F (DF + diag(uj))−1 diag(uj)f −(1 − α) e ( + 1) + (1 − w)−1 (˜uT j f)˜s = x + y + (˜uT j f)z, (15) noting that by definition, f = PF f, and defining the vectors x, y, and z to be x = −αF D−1 F (DF + diag(uj))−1 diag(uj)f (16) y = −(1 − α) e ( + 1) (17) z = (1 − w)−1 ˜s. (18) The first term x is a sparse vector, and takes non-zero values only for local pages k that are siblings of the global page j.",
        "We define (i, j) ∈ F if and only if F [j, i] = 1 (equivalently, page i links to page j) and express the value of the component x[k ] as: x[k ] = −α k:(k,k )∈F ,uj [k]=1 f[k] o[k](o[k] + 1) , (19) where o[k], as before, is the number of outlinks from page k in the local domain.",
        "Note that the last two terms, y and z are not dependent on the current global node j.",
        "Given the function hj(f) = y + (˜uT j f)z 1, the quantity fj − f 1 120 Research Track Paper can be expressed as fj − f 1 = k x[k] + y[k] + (˜uT j f)z[k] = k:x[k]=0 y[k] + (˜uT j f)z[k] + k:x[k]=0 x[k] + y[k] + (˜uT j f)z[k] = hj(f) − k:x[k]=0 y[k] + (˜uT j f)z[k] + k:x[k]=0 x[k] + y[k] + (˜uT j f)z[k] . (20) If we can compute the function hj in linear time, then we can compute each value of fj − f 1 using an additional amount of time that is proportional to the number of nonzero components in x.",
        "These optimizations are carried out in Algorithm 3.",
        "Note that (20) computes the difference between all components of f and fj, whereas our node selection criteria, given in (7), is restricted to the components corresponding to nodes in the original local domain L. Let us examine Algorithm 3 in more detail.",
        "First, the algorithm computes the outlink counts for each page in the local domain.",
        "The algorithm then computes the quantity ˜uT j f for each known global page j.",
        "This inner product can be written as (1 − α) 1 + 1 + α k:(k,j)∈Fout f[k] o[k] + 1 , where the second term sums over the set of local pages that link to page j.",
        "Since the total number of edges in Fout was assumed to have size O( ) (recall that is the number of pages in F ), the running time of this step is also O( ).",
        "The algorithm then computes the vectors y and z, as given in (17) and (18), respectively.",
        "The L1NormDiff method is called on the components of these vectors which correspond to the pages in L, and it estimates the value of EL(y + (˜uT j f)z) 1 for each page j.",
        "The estimation works as follows.",
        "First, the values of ˜uT j f are discretized uniformly into c values {a1, ..., ac}.",
        "The quantity EL(y + aiz) 1 is then computed for each discretized value of ai and stored in a table.",
        "To evaluate EL (y + az) 1 for some a ∈ [a1, ac], the closest discretized value ai is determined, and the corresponding entry in the table is used.",
        "The total running time for this method is linear in and the discretization parameter c (which we take to be a constant).",
        "We note that if exact values are desired, we have also developed an algorithm that runs in O( log ) time that is not described here.",
        "In the main loop, we compute the vector x, as defined in equation (16).",
        "The nested loops iterate over the set of pages in F that are siblings of page j.",
        "Typically, the size of this set is bounded by a constant.",
        "Finally, for each page j, the scores vector is updated over the set of non-zero components k of the vector x with k ∈ L. This set has size equal to the number of local siblings of page j, and is a subset of the total number of siblings of page j.",
        "Thus, each iteration of the main loop takes constant time, and the total running time of the main loop is O( ).",
        "Since we have assumed that the size of F will not grow larger than O(n), the total running time for the algorithm is O(n).",
        "Algorithm 3: Node Selection via Stochastic Complementation.",
        "SC-Select(F , Fout, f, k) Input: F : zero-one adjacency matrix of size corresponding to the current local subgraph, Fout: zero-one outlink matrix from F to global subgraph, f: PageRank of F , k: number of pages to return Output: pages: set of k pages to crawl next {Compute outlink sums for local subgraph} foreach (page j ∈ F ) o[j] ← k:(j,k)∈F F[j, k] end {Compute scalar ˜uT j f for each global node j } foreach (page j ∈ Fout) g[j] ← (1 − α) 1 +1 foreach (page k : (k, j) ∈ Fout) g[j] ← g[j] + α f[k] o[k]+1 end end {Compute vectors y and z as in (17) and (18) } y ← −(1 − α) e ( +1) z ← (1 − w)−1 ˜s {Approximate y + g[j] ∗ z 1 for all values g[j]} norm diffs ←L1NormDiffs(g, ELy, ELz) foreach (page j ∈ Fout) {Compute sparse vector x as in (19)} x ← 0 foreach (page k : (k, j) ∈ Fout) foreach (page k : (k, k ) ∈ F )) x[k ] ← x[k ] − f[k] o[k](o[k]+1) end end x ← αx scores[j] ← norm diffs[j] foreach (k : x[k] > 0 and page k ∈ L) scores[j] ← scores[j] − |y[k] + g[j] ∗ z[k]| +|x[k]+y[k]+g[j]∗z[k])| end end Return k pages with highest scores 5.2.2 PageRank Flows We now present an intuitive analysis of the stochastic complementation method by decomposing the change in PageRank in terms of leaks and flows.",
        "This analysis is motivated by the decomposition given in (15).",
        "PageRank flow is the increase in the local PageRanks originating from global page j.",
        "The flows are represented by the non-negative vector (˜uT j f)z (equations (15) and (18)).",
        "The scalar ˜uT j f can be thought of as the total amount of PageRank flow that page j has available to distribute.",
        "The vector z dictates how the flow is allocated to the local domain; the flow that local page k receives is proportional to (within a constant factor due to the random surfer vector) the expected number of its inlinks.",
        "The PageRank leaks represent the decrease in PageRank resulting from the addition of page j.",
        "The leakage can be quantified in terms of the non-positive vectors x and y (equations (16) and (17)).",
        "For vector x, we can see from equation (19) that the amount of PageRank leaked by a local page is proportional to the weighted sum of the Page121 Research Track Paper Ranks of its siblings.",
        "Thus, pages that have siblings with higher PageRanks (and low outlink counts) will experience more leakage.",
        "The leakage caused by y is an artifact of the random surfer vector.",
        "We will next show that if only the flow term, (˜uT j f)z, is considered, then the resulting method is very similar to a heuristic proposed by Cho et al. [6] that has been widely used for the Crawling Through URL Ordering problem.",
        "This heuristic is computationally cheaper, but as we will see later, not as effective as the Stochastic Complementation method.",
        "Our node selection strategy chooses global nodes that have the largest influence (equation (7)).",
        "If this influence is approximated using only flows, the optimal node j∗ is: j∗ = argmaxj EL ˜uT j fz 1 = argmaxj ˜uT j f EL z 1 = argmaxj ˜uT j f = argmaxj α(DF + diag(uj))−1 uj + (1 − α) e + 1 , f = argmaxjfT (DF + diag(uj))−1 uj.",
        "The resulting page selection score can be expressed as a sum of the PageRanks of each local page k that links to j, where each PageRank value is normalized by o[k]+1.",
        "Interestingly, the normalization that arises in our method differs from the heuristic given in [6], which normalizes by o[k].",
        "The algorithm PF-Select, which is omitted due to lack of space, first computes the quantity fT (DF +diag(uj))−1 uj for each global page j, and then returns the pages with the k largest scores.",
        "To see that the running time for this algorithm is O(n), note that the computation involved in this method is a subset of that needed for the SC-Select method (Algorithm 3), which was shown to have a running time of O(n). 6.",
        "EXPERIMENTS In this section, we provide experimental evidence to verify the effectiveness of our algorithms.",
        "We first outline our experimental methodology and then provide results across a variety of local domains. 6.1 Methodology Given the limited resources available at an academic institution, crawling a section of the web that is of the same magnitude as that indexed by Google or Yahoo! is clearly infeasible.",
        "Thus, for a given local domain, we approximate the global graph by crawling a local neighborhood around the domain that is several orders of magnitude larger than the local subgraph.",
        "Even though such a graph is still orders of magnitude smaller than the true global graph, we contend that, even if there exist some highly influential pages that are very far away from our local domain, it is unrealistic for any local node selection algorithm to find them.",
        "Such pages also tend to be highly unrelated to pages within the local domain.",
        "When explaining our node selection strategies in section 5, we made the simplifying assumption that our local graph contained no dangling nodes.",
        "This assumption was only made to ease our analysis.",
        "Our implementation efficiently handles dangling links by replacing each zero column of our adjacency matrix with the uniform vector.",
        "We evaluate the algorithm using the two node selection strategies given in Section 5.2, and also against the following baseline methods: • Random: Nodes are chosen uniformly at random among the known global nodes. • OutlinkCount: Global nodes with the highest number of outlinks from the local domain are chosen.",
        "At each iteration of the FindGlobalPR algorithm, we evaluate performance by computing the difference between the current PageRank estimate of the local domain, ELf ELf 1 , and the global PageRank of the local domain ELg ELg 1 .",
        "All PageRank calculations were performed using the uniform random surfer vector.",
        "Across all experiments, we set the random surfer parameter α, to be .85, and used a convergence threshold of 10−6 .",
        "We evaluate the difference between the local and global PageRank vectors using three different metrics: the L1 and L∞ norms, and Kendalls tau.",
        "The L1 norm measures the sum of the absolute value of the differences between the two vectors, and the L∞ norm measures the absolute value of the largest difference.",
        "Kendalls tau metric is a popular rank correlation measure used to compare PageRanks [2, 11].",
        "This metric can be computed by counting the number of pairs of pairs that agree in ranking, and subtracting from that the number of pairs of pairs that disagree in ranking.",
        "The final value is then normalized by the total number of n 2 such pairs, resulting in a [−1, 1] range, where a negative score signifies anti-correlation among rankings, and values near one correspond to strong rank correlation. 6.2 Results Our experiments are based on two large web crawls and were downloaded using the web crawler that is part of the Nutch open source search engine project [18].",
        "All crawls were restricted to only http pages, and to limit the number of dynamically generated pages that we crawl, we ignored all pages with urls containing any of the characters ?, *, @, or =.",
        "The first crawl, which we will refer to as the edu dataset, was seeded by homepages of the top 100 graduate computer science departments in the USA, as rated by the US News and World Report [16], and also by the home pages of their respective institutions.",
        "A crawl of depth 5 was performed, restricted to pages within the .edu domain, resulting in a graph with approximately 4.7 million pages and 22.9 million links.",
        "The second crawl was seeded by the set of pages under the politics hierarchy in the dmoz open directory project[17].",
        "We crawled all pages up to four links away, which yielded a graph with 4.4 million pages and 17.3 million links.",
        "Within the edu crawl, we identified the five site-specific domains corresponding to the websites of the top five graduate computer science departments, as ranked by the US News and World Report.",
        "This yielded local domains of various sizes, from 10,626 (UIUC) to 59,895 (Berkeley).",
        "For each of these site-specific domains with size n, we performed 50 iterations of the FindGlobalPR algorithm to crawl a total of 2n additional nodes.",
        "Figure 2(a) gives the (L1) difference from the PageRank estimate at each iteration to the global PageRank, for the Berkeley local domain.",
        "The performance of this dataset was representative of the typical performance across the five computer science sitespecific local domains.",
        "Initially, the L1 difference between the global and local PageRanks ranged from .0469 (Stanford) to .149 (MIT).",
        "For the first several iterations, the 122 Research Track Paper 0 5 10 15 20 25 30 35 40 45 50 0.015 0.02 0.025 0.03 0.035 0.04 0.045 0.05 0.055 Number of Iterations GlobalandLocalPageRankDifference(L1) Stochastic Complement PageRank Flow Outlink Count Random 0 10 20 30 40 50 0 0.05 0.1 0.15 0.2 0.25 0.3 0.35 Number of Iterations GlobalandLocalPageRankDifference(L1) Stochastic Complement PageRank Flow Outlink Count Random 0 5 10 15 20 25 0.16 0.18 0.2 0.22 0.24 0.26 0.28 0.3 0.32 0.34 Number of Iterations GlobalandLocalPageRankDifference(L1) Stochastic Complement PageRank Flow Outlink Count Random (a) www.cs.berkeley.edu (b) www.enterstageright.com (c) Politics Figure 2: L1 difference between the estimated and true global PageRanks for (a) Berkeleys computer science website, (b) the site-specific domain, www.enterstageright.com, and (c) the politics topic-specific domain.",
        "The stochastic complement method outperforms all other methods across various domains. three link-based methods all outperform the random selection heuristic.",
        "After these initial iterations, the random heuristic tended to be more competitive with (or even outperform, as in the Berkeley local domain) the outlink count and PageRank flow heuristics.",
        "In all tests, the stochastic complementation method either outperformed, or was competitive with, the other methods.",
        "Table 1 gives the average difference between the final estimated global PageRanks and the true global PageRanks for various distance measures.",
        "Algorithm L1 L∞ Kendall Stoch.",
        "Comp. .0384 .00154 .9257 PR Flow .0470 .00272 .8946 Outlink .0419 .00196 .9053 Random .0407 .00204 .9086 Table 1: Average final performance of various node selection strategies for the five site-specific computer science local domains.",
        "Note that Kendalls Tau measures similarity, while the other metrics are dissimilarity measures.",
        "Stochastic Complementation clearly outperforms the other methods in all metrics.",
        "Within the politics dataset, we also performed two sitespecific tests for the largest websites in the crawl: www.adamsmith.org, the website for the London based Adam Smith Institute, and www.enterstageright.com, an online conservative journal.",
        "As with the edu local domains, we ran our algorithm for 50 iterations, crawling a total of 2n nodes.",
        "Figure 2 (b) plots the results for the www.enterstageright.com domain.",
        "In contrast to the edu local domains, the Random and OutlinkCount methods were not competitive with either the SC-Select or the PF-Select methods.",
        "Among all datasets and all node selection methods, the stochastic complementation method was most impressive in this dataset, realizing a final estimate that differed only .0279 from the global PageRank, a ten-fold improvement over the initial local PageRank difference of .299.",
        "For the Adam Smith local domain, the initial difference between the local and global PageRanks was .148, and the final estimates given by the SC-Select, PF-Select, OutlinkCount, and Random methods were .0208, .0193, .0222, and .0356, respectively.",
        "Within the politics dataset, we constructed four topicspecific local domains.",
        "The first domain consisted of all pages in the dmoz politics category, and also all pages within each of these sites up to two links away.",
        "This yielded a local domain of 90,811 pages, and the results are given in figure 2 (c).",
        "Because of the larger size of the topic-specific domains, we ran our algorithm for only 25 iterations to crawl a total of n nodes.",
        "We also created topic-specific domains from three political sub-topics: liberalism, conservatism, and socialism.",
        "The pages in these domains were identified by their corresponding dmoz categories.",
        "For each sub-topic, we set the local domain to be all pages within three links from the corresponding dmoz category pages.",
        "Table 2 summarizes the performance of these three topic-specific domains, and also the larger political domain.",
        "To quantify a global page js effect on the global PageRank values of pages in the local domain, we define page js impact to be its PageRank value, g[j], normalized by the fraction of its outlinks pointing to the local domain: impact(j) = oL[j] o[j] · g[j], where, oL[j] is the number of outlinks from page j to pages in the local domain L, and o[j] is the total number of js outlinks.",
        "In terms of the random surfer model, the impact of page j is the probability that the random surfer (1) is currently at global page j in her random walk and (2) takes an outlink to a local page, given that she has already decided not to jump to a random page.",
        "For the politics local domain, we found that many of the pages with high impact were in fact political pages that should have been included in the dmoz politics topic, but were not.",
        "For example, the two most influential global pages were the political search engine www.askhenry.com, and the home page of the online political magazine, www.policyreview.com.",
        "Among non-political pages, the home page of the journal Education Next was most influential.",
        "The journal is freely available online and contains articles regarding various aspect of K-12 education in America.",
        "To provide some anecdotal evidence for the effectiveness of our page selection methods, we note that the SC-Select method chose 11 pages within the www.educationnext.org domain, the PF-Select method discovered 7 such pages, while the OutlinkCount and Random methods found only 6 pages each.",
        "For the conservative political local domain, the socialist website www.ornery.org had a very high impact score.",
        "This 123 Research Track Paper All Politics: Algorithm L1 L2 Kendall Stoch.",
        "Comp. .1253 .000700 .8671 PR Flow .1446 .000710 .8518 Outlink .1470 .00225 .8642 Random .2055 .00203 .8271 Conservativism: Algorithm L1 L2 Kendall Stoch.",
        "Comp. .0496 .000990 .9158 PR Flow .0554 .000939 .9028 Outlink .0602 .00527 .9144 Random .1197 .00102 .8843 Liberalism: Algorithm L1 L2 Kendall Stoch.",
        "Comp. .0622 .001360 .8848 PR Flow .0799 .001378 .8669 Outlink .0763 .001379 .8844 Random .1127 .001899 .8372 Socialism: Algorithm L1 L∞ Kendall Stoch.",
        "Comp. .04318 .00439 .9604 PR Flow .0450 .004251 .9559 Outlink .04282 .00344 .9591 Random .0631 .005123 .9350 Table 2: Final performance among node selection strategies for the four political topic-specific crawls.",
        "Note that Kendalls Tau measures similarity, while the other metrics are dissimilarity measures. was largely due to a link from the front page of this site to an article regarding global warming published by the National Center for Public Policy Research, a conservative research group in Washington, DC.",
        "Not surprisingly, the global PageRank of this article (which happens to be on the home page of the NCCPR, www.nationalresearch.com), was approximately .002, whereas the local PageRank of this page was only .00158.",
        "The SC-Select method yielded a global PageRank estimate of approximately .00182, the PFSelect method estimated a value of .00167, and the Random and OutlinkCount methods yielded values of .01522 and .00171, respectively. 7.",
        "RELATED WORK The node selection framework we have proposed is similar to the url ordering for crawling problem proposed by Cho et al. in [6].",
        "Whereas our framework seeks to minimize the difference between the global and local PageRank, the objective used in [6] is to crawl the most highly (globally) ranked pages first.",
        "They propose several node selection algorithms, including the outlink count heuristic, as well as a variant of our PF-Select algorithm which they refer to as the PageRank ordering metric.",
        "They found this method to be most effective in optimizing their objective, as did a recent survey of these methods by Baeza-Yates et al. [1].",
        "Boldi et al. also experiment within a similar crawling framework in [2], but quantify their results by comparing Kendalls rank correlation between the PageRanks of the current set of crawled pages and those of the entire global graph.",
        "They found that node selection strategies that crawled pages with the highest global PageRank first actually performed worse (with respect to Kendalls Tau correlation between the local and global PageRanks) than basic depth first or breadth first strategies.",
        "However, their experiments differ from our work in that our node selection algorithms do not use (or have access to) global PageRank values.",
        "Many algorithmic improvements for computing exact PageRank values have been proposed [9, 10, 14].",
        "If such algorithms are used to compute the global PageRanks of our local domain, they would all require O(N) computation, storage, and bandwidth, where N is the size of the global domain.",
        "This is in contrast to our method, which approximates the global PageRank and scales linearly with the size of the local domain.",
        "Wang and Dewitt [22] propose a system where the set of web servers that comprise the global domain communicate with each other to compute their respective global PageRanks.",
        "For a given web server hosting n pages, the computational, bandwidth, and storage requirements are also linear in n. One drawback of this system is that the number of distinct web servers that comprise the global domain can be very large.",
        "For example, our edu dataset contains websites from over 3,200 different universities; coordinating such a system among a large number of sites can be very difficult.",
        "Gan, Chen, and Suel propose a method for estimating the PageRank of a single page [5] which uses only constant bandwidth, computation, and space.",
        "Their approach relies on the availability of a remote connectivity server that can supply the set of inlinks to a given page, an assumption not used in our framework.",
        "They experimentally show that a reasonable estimate of the nodes PageRank can be obtained by visiting at most a few hundred nodes.",
        "Using their algorithm for our problem would require that either the entire global domain first be downloaded or a connectivity server be used, both of which would lead to very large web graphs. 8.",
        "CONCLUSIONS AND FUTURE WORK The internet is growing exponentially, and in order to navigate such a large repository as the web, global search engines have established themselves as a necessity.",
        "Along with the ubiquity of these large-scale search engines comes an increase in search users expectations.",
        "By providing complete and isolated coverage of a particular web domain, localized search engines are an effective outlet to quickly locate content that could otherwise be difficult to find.",
        "In this work, we contend that the use of global PageRank in a localized search engine can improve performance.",
        "To estimate the global PageRank, we have proposed an iterative node selection framework where we select which pages from the global frontier to crawl next.",
        "Our primary contribution is our stochastic complementation page selection algorithm.",
        "This method crawls nodes that will most significantly impact the local domain and has running time linear in the number of nodes in the local domain.",
        "Experimentally, we validate these methods across a diverse set of local domains, including seven site-specific domains and four topic-specific domains.",
        "We conclude that by crawling an additional n or 2n pages, our methods find an estimate of the global PageRanks that is up to ten times better than just using the local PageRanks.",
        "Furthermore, we demonstrate that our algorithm consistently outperforms other existing heuristics. 124 Research Track Paper Often times, topic-specific domains are discovered using a focused web crawler which considers a pages content in conjunction with link anchor text to decide which pages to crawl next [4].",
        "Although such crawlers have proven to be quite effective in discovering topic-related content, many irrelevant pages are also crawled in the process.",
        "Typically, these pages are deleted and not indexed by the localized search engine.",
        "These pages can of course provide valuable information regarding the global PageRank of the local domain.",
        "One way to integrate these pages into our framework is to start the FindGlobalPR algorithm with the current subgraph F equal to the set of pages that were crawled by the focused crawler.",
        "The global PageRank estimation framework, along with the node selection algorithms presented, all require O(n) computation per iteration and bandwidth proportional to the number of pages crawled, Tk.",
        "If the number of iterations T is relatively small compared to the number of pages crawled per iteration, k, then the bottleneck of the algorithm will be the crawling phase.",
        "However, as the number of iterations increases (relative to k), the bottleneck will reside in the node selection computation.",
        "In this case, our algorithms would benefit from constant factor optimizations.",
        "Recall that the FindGlobalPR algorithm (Algorithm 2) requires that the PageRanks of the current expanded local domain be recomputed in each iteration.",
        "Recent work by Langville and Meyer [12] gives an algorithm to quickly recompute PageRanks of a given webgraph if a small number of nodes are added.",
        "This algorithm was shown to give speedup of five to ten times on some datasets.",
        "We plan to investigate this and other such optimizations as future work.",
        "In this paper, we have objectively evaluated our methods by measuring how close our global PageRank estimates are to the actual global PageRanks.",
        "To determine the benefit of using global PageRanks in a localized search engine, we suggest a user study in which users are asked to rate the quality of search results for various search queries.",
        "For some queries, only the local PageRanks are used in ranking, and for the remaining queries, local PageRanks and the approximate global PageRanks, as computed by our algorithms, are used.",
        "The results of such a study can then be analyzed to determine the added benefit of using the global PageRanks computed by our methods, over just using the local PageRanks.",
        "Acknowledgements.",
        "This research was supported by NSF grant CCF-0431257, NSF Career Award ACI-0093404, and a grant from Sabre, Inc. 9.",
        "REFERENCES [1] R. Baeza-Yates, M. Marin, C. Castillo, and A. Rodriguez.",
        "Crawling a country: better strategies than breadth-first for web page ordering.",
        "World-Wide Web Conference, 2005. [2] P. Boldi, M. Santini, and S. Vigna.",
        "Do your worst to make the best: paradoxical effects in pagerank incremental computations.",
        "Workshop on Web Graphs, 3243:168-180, 2004. [3] S. Brin and L. Page.",
        "The anatomy of a large-scale hypertextual web search engine.",
        "Computer Networks and ISDN Systems, 33(1-7):107-117, 1998. [4] S. Chakrabarti, M. van den Berg, and B. Dom.",
        "Focused crawling: a new approach to topic-specific web resource discovery.",
        "World-Wide Web Conference, 1999. [5] Y. Chen, Q. Gan, and T. Suel.",
        "Local methods for estimating pagerank values.",
        "Conference on Information and Knowledge Management, 2004. [6] J. Cho, H. Garcia-Molina, and L. Page.",
        "Efficient crawling through url ordering.",
        "World-Wide Web Conference, 1998. [7] T. H. Haveliwala and S. D. Kamvar.",
        "The second eigenvalue of the Google matrix.",
        "Technical report, Stanford University, 2003. [8] T. Joachims, F. Radlinski, L. Granka, A. Cheng, C. Tillekeratne, and A. Patel.",
        "Learning retrieval functions from implicit feedback. http://www.cs.cornell.edu/People/tj/career. [9] S. D. Kamvar, T. H. Haveliwala, C. D. Manning, and G. H. Golub.",
        "Exploiting the block structure of the web for computing pagerank.",
        "World-Wide Web Conference, 2003. [10] S. D. Kamvar, T. H. Haveliwala, C. D. Manning, and G. H. Golub.",
        "Extrapolation methods for accelerating pagerank computation.",
        "World-Wide Web Conference, 2003. [11] A. N. Langville and C. D. Meyer.",
        "Deeper inside pagerank.",
        "Internet Mathematics, 2004. [12] A. N. Langville and C. D. Meyer.",
        "Updating the stationary vector of an irreducible markov chain with an eye on Googles pagerank.",
        "SIAM Journal on Matrix Analysis, 2005. [13] P. Lyman, H. R. Varian, K. Swearingen, P. Charles, N. Good, L. L. Jordan, and J. Pal.",
        "How much information 2003?",
        "School of Information Management and System, University of California at Berkely, 2003. [14] F. McSherry.",
        "A uniform approach to accelerated pagerank computation.",
        "World-Wide Web Conference, 2005. [15] C. D. Meyer.",
        "Stochastic complementation, uncoupling markov chains, and the theory of nearly reducible systems.",
        "SIAM Review, 31:240-272, 1989. [16] US News and World Report. http://www.usnews.com. [17] Dmoz open directory project. http://www.dmoz.org. [18] Nutch open source search engine. http://www.nutch.org. [19] F. Radlinski and T. Joachims.",
        "Query chains: learning to rank from implicit feedback.",
        "ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, 2005. [20] S. Raghavan and H. Garcia-Molina.",
        "Crawling the hidden web.",
        "In Proceedings of the Twenty-seventh International Conference on Very Large Databases, 2001. [21] T. Tin Tang, D. Hawking, N. Craswell, and K. Griffiths.",
        "Focused crawling for both topical relevance and quality of medical information.",
        "Conference on Information and Knowledge Management, 2005. [22] Y. Wang and D. J. DeWitt.",
        "Computing pagerank in a distributed internet search system.",
        "Proceedings of the 30th VLDB Conference, 2004. 125 Research Track Paper"
    ],
    "translated_text_sentences": [
        "Estimando el PageRank Global de Comunidades Web Jason V. Davis Dept.",
        "Departamento de Ciencias de la Computación Universidad de Texas en Austin Austin, TX 78712 jdavis@cs.utexas.edu Inderjit S. Dhillon Departamento de Ciencias de la Computación Universidad de Texas en Austin Austin, TX 78712 inderjit@cs.utexas.edu RESUMEN Los motores de búsqueda localizados son sistemas a pequeña escala que indexan una comunidad particular en la web.",
        "Ofrecen varios beneficios en comparación con sus contrapartes a gran escala, ya que son relativamente económicos de construir y pueden proporcionar una capacidad de búsqueda más precisa y completa en sus dominios relevantes.",
        "Una desventaja que tienen estos sistemas en comparación con los motores de búsqueda a gran escala es la falta de valores globales de PageRank.",
        "Se necesita esa información para evaluar el valor de las páginas en el dominio de búsqueda localizada dentro del contexto de la web en su totalidad.",
        "En este artículo, presentamos algoritmos bien fundamentados para estimar los valores globales de PageRank de un dominio local.",
        "Los algoritmos son altamente escalables en el sentido de que, dado un dominio local de tamaño n, utilizan recursos de O(n) que incluyen tiempo de computación, ancho de banda y almacenamiento.",
        "Probamos nuestros métodos en una variedad de dominios localizados, incluyendo dominios específicos del sitio y dominios específicos del tema.",
        "Demostramos que al rastrear tan solo n o 2n páginas adicionales, nuestros métodos pueden proporcionar excelentes estimaciones globales de PageRank.",
        "Categorías y Descriptores de Asignaturas H.3.3 [Almacenamiento y Recuperación de Información]: Búsqueda y Recuperación de Información; G.1.3 [Análisis Numérico]: Álgebra Lineal Numérica; G.3 [Probabilidad y Estadística]: Procesos de Markov Términos Generales PageRank, Cadena de Markov, Complementación Estocástica.",
        "Los motores de búsqueda localizados son motores de búsqueda a pequeña escala que indexan solo una comunidad específica de la web.",
        "Tales comunidades pueden ser dominios específicos del sitio, como páginas dentro del dominio cs.utexas.edu, o comunidades relacionadas con un tema, por ejemplo, sitios web políticos.",
        "En comparación con el grafo web rastreado e indexado por los motores de búsqueda a gran escala, el tamaño de estas comunidades locales suele ser típicamente órdenes de magnitud más pequeño.",
        "Por consiguiente, los recursos computacionales necesarios para construir un motor de búsqueda de este tipo también son igualmente más ligeros.",
        "Al restringirse a secciones más pequeñas y manejables de la web, los motores de búsqueda localizados también pueden ofrecer capacidades de búsqueda más precisas y completas dentro de sus respectivos dominios.",
        "Una desventaja de los índices localizados es la falta de información global necesaria para calcular clasificaciones basadas en enlaces.",
        "El algoritmo PageRank [3] ha demostrado ser una medida efectiva de este tipo.",
        "En general, el PageRank de una página dada depende de las páginas en todo el grafo web.",
        "En el contexto de un motor de búsqueda localizado, si los PageRanks se calculan utilizando solo el subgrafo local, entonces esperaríamos que los PageRanks resultantes reflejen la popularidad percibida dentro de la comunidad local y no de la web en su totalidad.",
        "Por ejemplo, consideremos un motor de búsqueda localizado que indexa páginas políticas con puntos de vista conservadores.",
        "Una persona que desee investigar las opiniones sobre el calentamiento global dentro de la comunidad política conservadora puede encontrarse con numerosas opiniones de este tipo en varios sitios web.",
        "Si solo se dispone de valores de PageRank locales, entonces los resultados de búsqueda reflejarán solo creencias fuertemente arraigadas dentro de la comunidad.",
        "Sin embargo, si los PageRanks globales también están disponibles, entonces los resultados pueden reflejar adicionalmente las opiniones de los externos sobre la comunidad conservadora (es decir, aquellos documentos a los que los liberales acceden con mayor frecuencia dentro de la comunidad conservadora).",
        "Por lo tanto, para muchos motores de búsqueda localizados, la incorporación de PageRanks globales puede mejorar la calidad de los resultados de búsqueda.",
        "Sin embargo, el número de páginas que indexa un motor de búsqueda local suele ser órdenes de magnitud más pequeño que el número de páginas indexadas por sus contrapartes a gran escala.",
        "Los motores de búsqueda localizados no tienen el ancho de banda, la capacidad de almacenamiento o la potencia computacional para rastrear, descargar y calcular los PageRanks globales de toda la web.",
        "En este trabajo, presentamos un método para aproximar los PageRanks globales de un dominio local utilizando recursos del mismo orden que los necesarios para calcular los PageRanks del subgrafo local.",
        "Nuestro método propuesto busca un supergrafo de nuestro subgrafo local de manera que los PageRanks locales dentro de este supergrafo estén cerca de los verdaderos PageRanks globales.",
        "Construimos este supergrafo mediante el rastreo iterativo de páginas globales en la frontera web actual, es decir, páginas globales con enlaces entrantes de páginas que ya han sido rastreadas.",
        "Para proporcionar a 116 Research Track Paper una buena aproximación a los PageRanks globales, es necesario tener cuidado al elegir qué páginas rastrear a continuación; en este documento, presentamos un algoritmo de selección de páginas bien fundamentado que también tiene un buen rendimiento empírico.",
        "Este algoritmo se deriva de un objetivo de problema bien definido y tiene un tiempo de ejecución lineal en el número de nodos locales.",
        "Experimentamos en varios tipos de subgrafos locales, incluidas cuatro comunidades relacionadas con el tema y varios dominios específicos del sitio.",
        "Para evaluar el rendimiento, medimos la diferencia entre la estimación actual del PageRank global y el PageRank global, en función del número de páginas rastreadas.",
        "Comparamos nuestro algoritmo con varios heurísticos y también con un algoritmo base que elige páginas al azar, y demostramos que nuestro método supera a estos otros métodos.",
        "Finalmente, demostramos empíricamente que, dado un dominio local de tamaño n, podemos proporcionar buenas aproximaciones a los valores globales de PageRank rastreando como máximo n o 2n páginas adicionales.",
        "El documento está organizado de la siguiente manera.",
        "La sección 2 ofrece una visión general de los motores de búsqueda localizados y destaca sus ventajas sobre los motores de búsqueda globales.",
        "La sección 3 proporciona antecedentes sobre el algoritmo PageRank.",
        "La sección 4 define formalmente nuestro problema, y la sección 5 presenta nuestros criterios de selección de páginas y deriva nuestros algoritmos.",
        "La sección 6 presenta los resultados experimentales, la sección 7 ofrece una visión general del trabajo relacionado y, finalmente, las conclusiones se presentan en la sección 8.",
        "MOTORES DE BÚSQUEDA LOCALIZADOS Los motores de búsqueda localizados indexan una sola comunidad de la web, típicamente una comunidad específica del sitio o una comunidad específica del tema.",
        "Los motores de búsqueda localizados disfrutan de tres ventajas principales sobre sus contrapartes a gran escala: son relativamente económicos de construir, pueden ofrecer una capacidad de búsqueda más precisa dentro de su dominio local y pueden proporcionar un índice más completo.",
        "Los recursos necesarios para construir un motor de búsqueda global son enormes.",
        "Un estudio de 2003 realizado por Lyman et al. [13] encontró que la web superficial (sitios estáticos de acceso público) consta de 8.9 mil millones de páginas, y que el tamaño promedio de estas páginas es de aproximadamente 18.7 kilobytes.",
        "Para descargar un rastreo de este tamaño, se necesita aproximadamente 167 terabytes de espacio.",
        "Para un investigador que desee construir un motor de búsqueda con acceso a un par de estaciones de trabajo o un servidor pequeño, un almacenamiento de esta magnitud simplemente no está disponible.",
        "Sin embargo, construir un motor de búsqueda localizado sobre una comunidad web de cien mil páginas solo requeriría unos pocos gigabytes de almacenamiento.",
        "La carga computacional necesaria para soportar consultas de búsqueda sobre una base de datos de este tamaño es más manejable también.",
        "Observamos que, para los motores de búsqueda específicos de un tema, la comunidad relevante puede ser identificada y descargada de manera eficiente utilizando un rastreador enfocado [21, 4].",
        "Para dominios específicos del sitio, el dominio local está fácilmente disponible en su propio servidor web.",
        "Esto evita la necesidad de rastreo o indexación, y por lo tanto se puede garantizar un índice completo y actualizado del dominio.",
        "Esto contrasta con sus contrapartes a gran escala, las cuales sufren de varias deficiencias.",
        "Primero, el rastreo de páginas generadas dinámicamente en la web oculta ha sido objeto de investigación [20] y es una tarea no trivial para un rastreador externo.",
        "En segundo lugar, los dominios específicos del sitio pueden habilitar la política de exclusión de robots.",
        "Esto prohíbe a los rastreadores de motores de búsqueda externos descargar contenido del dominio, y en su lugar un motor de búsqueda externo debe depender de enlaces externos y texto ancla para indexar estas páginas restringidas.",
        "Al restringirse a un dominio específico de internet, un motor de búsqueda localizado puede proporcionar resultados de búsqueda más precisos.",
        "Considera la consulta de búsqueda ambigua canónica, jaguar, que puede referirse tanto al fabricante de automóviles como al animal.",
        "Un científico que intenta investigar el hábitat y la historia evolutiva de un jaguar puede tener más éxito utilizando un motor de búsqueda específico de zoología bien ajustado que consultando Google con múltiples búsquedas de palabras clave y navegando a través de resultados irrelevantes.",
        "Recientemente se propuso un método para aprender funciones de clasificación mejores para la recuperación por Radlinski y Joachims [19] y se ha aplicado a varios dominios locales, incluido el sitio web de la Universidad de Cornell [8]. 3.",
        "PAGERANK RESUMEN El algoritmo PageRank define la importancia de las páginas web analizando la estructura de hipervínculos subyacente de un grafo web.",
        "El algoritmo funciona construyendo una cadena de Markov a partir de la estructura de enlaces del grafo web y calculando su distribución estacionaria.",
        "Una forma de calcular la distribución estacionaria de una cadena de Markov es encontrar la distribución límite de un paseo aleatorio sobre la cadena.",
        "Por lo tanto, el algoritmo PageRank utiliza lo que a veces se conoce como el modelo del surfista aleatorio.",
        "En cada paso de la caminata aleatoria, el surfista sigue un enlace de salida de la página actual (es decir, el nodo actual en la cadena), o salta a una página aleatoria en la web.",
        "Ahora definimos con precisión el problema de PageRank.",
        "Sea U una matriz de adyacencia m × m para un grafo web dado tal que Uji = 1 si la página i enlaza a la página j y Uji = 0 en caso contrario.",
        "Definimos la matriz de PageRank PU como: PU = αUD−1 U + (1 − α)veT , (1) donde DU es la matriz diagonal (única) tal que UD−1 U es estocástica por columnas, α es un escalar dado tal que 0 ≤ α ≤ 1, e es el vector de todos unos, y v es un vector no negativo, L1-normalizado, a veces llamado vector de navegante aleatorio.",
        "Ten en cuenta que la matriz D−1 U está bien definida solo si cada columna de U tiene al menos una entrada distinta de cero, es decir, cada página en el grafo web tiene al menos un enlace de salida.",
        "En presencia de nodos colgantes que no tienen enlaces de salida, una solución comúnmente utilizada, propuesta por Brin et al. [3], es reemplazar cada columna de ceros de U por un vector no negativo, normalizado en L1.",
        "El vector PageRank r es el eigenvector dominante de la matriz PageRank, r = PU r. Supondremos, sin pérdida de generalidad, que r tiene una norma L1 de uno.",
        "Computacionalmente, r se puede calcular utilizando el método de la potencia.",
        "Este método primero elige un vector inicial aleatorio r(0) y, de forma iterativa, multiplica el vector actual por la matriz de PageRank PU; ver Algoritmo 1.",
        "En general, cada iteración del método de la potencia puede requerir O(m2) operaciones cuando PU es una matriz densa.",
        "Sin embargo, en la práctica, el número de enlaces en un grafo web será del orden del número de páginas.",
        "Al explotar la dispersión de la matriz de PageRank, el trabajo por iteración se puede reducir a O(km), donde k es el número promedio de enlaces por página web.",
        "También se ha demostrado que el número total de iteraciones necesarias para la convergencia es proporcional a α y no depende del tamaño del grafo web [11, 7].",
        "Finalmente, el espacio total necesario también es O(km), principalmente para almacenar la matriz U. 117 Research Track Paper Algorithm 1: Un algoritmo de tiempo lineal (por iteración) para calcular PageRank.",
        "CalcularPR(U) Entrada: U: Matriz de adyacencia.",
        "Salida: vector de PageRank.",
        "Elige (aleatoriamente) un vector inicial no negativo r(0) tal que r(0) 1 = 1. i ← 0 repetir i ← i + 1 ν ← αUD−1 U r(i−1) {α es la probabilidad de navegación aleatoria} r(i) ← ν + (1 − α)v {v es el vector del navegante aleatorio.} hasta que r(i) − r(i−1) < δ {δ es el umbral de convergencia.} r ← r(i) 4.",
        "Dada un dominio local L, sea G una matriz de adyacencia N × N para el componente conectado completo de la web que contiene L, tal que Gji = 1 si la página i enlaza a la página j y Gji = 0 en caso contrario.",
        "Sin pérdida de generalidad, vamos a dividir G de la siguiente manera: G = L Gout Lout Gwithin, donde L es el subgrafo local de n × n correspondiente a los enlaces dentro del dominio local, Lout es el subgrafo que corresponde a los enlaces desde el dominio local apuntando hacia el dominio global, Gout es el subgrafo que contiene los enlaces desde el dominio global hacia el dominio local, y Gwithin contiene los enlaces dentro del dominio global.",
        "Suponemos que al construir un motor de búsqueda localizado, solo se rastrean las páginas dentro del dominio local, y los enlaces entre estas páginas están representados por el subgrafo L. También se conocen los enlaces en Lout, ya que estos apuntan desde las páginas rastreadas en el dominio local a las páginas no rastreadas en el dominio global.",
        "Como se define en la ecuación (1), PG es la matriz de PageRank formada a partir del grafo global G, y definimos el vector de PageRank global de este grafo como g. Sea el vector de longitud n p∗ el vector L1-normalizado que corresponde al PageRank global de las páginas en el dominio local L: p∗ = EL g ELg 1 , donde EL = [ I | 0 ] es la matriz de restricción que selecciona los componentes de g correspondientes a los nodos en L. Sea p el vector de PageRank construido a partir del subgrafo del dominio local L. En la práctica, el PageRank local observado p y el PageRank global p∗ serán bastante diferentes.",
        "Se esperaría que a medida que el tamaño de la matriz local L se acerque al tamaño de la matriz global G, el PageRank global y el PageRank local observado se vuelvan más similares.",
        "Por lo tanto, un enfoque para estimar el PageRank global es rastrear todo el dominio global, calcular su PageRank y extraer los PageRanks del dominio local.",
        "Por lo general, sin embargo, n N, es decir, el número de páginas globales es mucho mayor que el número de páginas locales.",
        "Por lo tanto, rastrear todas las páginas globales agotará rápidamente todos los recursos locales (computacionales, de almacenamiento y de ancho de banda) disponibles para crear el motor de búsqueda local.",
        "En cambio, buscamos un supergrafo ˆF de nuestro subgrafo local L con tamaño O(n).",
        "Nuestro objetivo es el Algoritmo 2: El algoritmo FindGlobalPR.",
        "EncuentraGlobalPR(L, Lout, T, k) Entrada: L: matriz de adyacencia de ceros y unos para el dominio local, Lout: matriz de enlaces de ceros y unos desde L al subgrafo global como en (2), T: número de iteraciones, k: número de páginas a rastrear por iteración.",
        "Salida: ˆp: una estimación mejorada del PageRank global de L. F ← L Fout ← Lout f ← CalcularPR(F) para (i = 1 a T) {Determinar qué páginas rastrear a continuación} páginas ← SeleccionarNodos(F, Fout, f, k) Rastrear páginas, aumentar F y modificar Fout {Actualizar PageRanks para el nuevo dominio local} f ← CalcularPR(F) fin {Extraer PageRanks del dominio local original y normalizar} ˆp ← ELf ELf 1 es encontrar un supergrafo ˆF con PageRank ˆf, de modo que ˆf cuando se restringe a L esté cerca de p∗.",
        "Formalmente, buscamos minimizar GlobalDiff( ˆf) = EL ˆf EL ˆf 1 − p∗ 1 . (3) Elegimos la norma L1 para medir el error ya que no otorga un peso excesivo a los valores atípicos (como lo hace la norma L2, por ejemplo), y también porque es la medida de distancia más comúnmente utilizada en la literatura para comparar vectores de PageRank, así como para detectar la convergencia del algoritmo [3].",
        "Proponemos un marco codicioso, presentado en el Algoritmo 2, para construir ˆF.",
        "Inicialmente, F se establece en el subgrafo local L, y se calcula el PageRank f de este grafo.",
        "El algoritmo luego procede de la siguiente manera.",
        "Primero, se llama al algoritmo SelectNodes (que discutimos en la siguiente sección) y devuelve un conjunto de k nodos para rastrear a continuación del conjunto de nodos en la frontera de rastreo actual, Fout.",
        "Estos nodos seleccionados son luego rastreados para expandir el subgrafo local, F, y los PageRanks de este grafo expandido son luego recalculados.",
        "Estos pasos se repiten para cada una de las T iteraciones.",
        "Finalmente, se devuelve el vector PageRank ˆp, el cual está restringido a las páginas dentro del dominio local original.",
        "Dadas nuestras restricciones de computación, ancho de banda y memoria, asumiremos que el algoritmo rastreará como máximo O(n) páginas.",
        "Dado que los PageRanks se calculan en cada iteración del algoritmo, lo cual es una operación O(n), también asumiremos que el número de iteraciones T es una constante.",
        "Por supuesto, el principal desafío aquí radica en seleccionar qué conjunto de k nodos rastrear a continuación.",
        "En la siguiente sección, definimos formalmente el problema y presentamos algoritmos eficientes. 5.",
        "SELECCIÓN DE NODO En esta sección, presentamos algoritmos de selección de nodo que operan dentro del marco codicioso presentado en la sección anterior.",
        "Primero damos un criterio bien definido para el problema de selección de páginas y proporcionamos evidencia experimental de que este criterio puede identificar de manera efectiva las páginas que optimizan nuestro objetivo del problema (3).",
        "A continuación, presentamos nuestra principal contribución algorítmica del artículo de investigación al118, un método con tiempo de ejecución lineal que se deriva de los criterios de selección de esta página.",
        "Finalmente, ofrecemos un análisis intuitivo de nuestro algoritmo en términos de fugas y flujos.",
        "Mostramos que si solo se considera el flujo, entonces el método resultante es muy similar a una heurística de selección de páginas ampliamente utilizada [6]. 5.1 Formulación Para una página dada j en el dominio global, definimos el grafo local expandido Fj: Fj = F s uT j 0, (4) donde uj es el vector de ceros y unos que contiene los enlaces de salida de F hacia la página j, y s contiene los enlaces de entrada de la página j en el dominio local.",
        "Ten en cuenta que no permitimos enlaces a uno mismo en este marco de trabajo.",
        "En la práctica, los enlaces internos suelen ser eliminados, ya que solo sirven para inflar el PageRank de una página determinada.",
        "Observa que los enlaces entrantes a F desde el nodo j no se conocen hasta después de que el nodo j sea rastreado.",
        "Por lo tanto, estimamos este vector de inlink como la expectativa sobre el recuento de inlinks entre el conjunto de páginas ya rastreadas, s = F T e F T e 1. En la práctica, para cualquier página dada, esta estimación puede no reflejar los verdaderos inlinks de esa página.",
        "Además, esta expectativa se extrae del conjunto de enlaces dentro del dominio rastreado, mientras que una estimación más precisa también utilizaría enlaces del dominio global.",
        "Sin embargo, la distribución mencionada no es conocida por un motor de búsqueda localizado, y sostenemos que la estimación anterior, en promedio, será una estimación mejor que la distribución uniforme, por ejemplo.",
        "Dejemos que el PageRank de F sea f. Expresamos el PageRank f+ j del grafo local expandido Fj como f+ j = (1 − xj)fj xj , donde xj es el PageRank del nodo global candidato j, y fj es el vector de PageRank L1-normalizado restringido a las páginas en F.",
        "Dado que optimizar directamente nuestro objetivo requiere conocer el PageRank global p∗, proponemos en su lugar rastrear aquellos nodos que tendrán la mayor influencia en los PageRanks de las páginas en el dominio local original L: influencia(j) = k∈L |fj[k] − f[k]| (7) = EL (fj − f) 1.",
        "Experimentalmente, el puntaje de influencia es un predictor muy bueno de nuestro objetivo del problema (3).",
        "Para cada nodo global candidato j, la figura 1(a) muestra el valor de la función objetivo Global Diff(fj) en función de la influencia de la página j.",
        "El dominio local utilizado aquí es un rastreo de páginas políticas conservadoras (proporcionaremos más detalles sobre este conjunto de datos en la sección 6); observamos resultados similares en otros dominios.",
        "La correlación es bastante fuerte, lo que implica que los criterios de influencia pueden identificar de manera efectiva las páginas que mejoran la estimación global del PageRank.",
        "Como referencia, la figura 1(b) compara nuestro objetivo con un criterio alternativo, el recuento de enlaces de salida.",
        "El recuento de enlaces de salida se define como el número de enlaces de salida desde el dominio local a la página j.",
        "La correlación aquí es mucho más débil. .00001 .0001 .001 .01 0.26 0.262 0.264 0.266 Influencia Objetivo 1 10 100 1000 0.266 0.264 0.262 0.26 Recuento de Enlaces Salientes Objetivo (a) (b) Figura 1: (a) La correlación entre nuestros criterios de selección de página de influencia (7) y el valor real de la función objetivo (3) es bastante fuerte. (b) Esto contrasta con otros criterios, como el recuento de enlaces salientes, que muestran una correlación mucho más débil. 5.2 Cálculo Como se describe, para cada página global candidata j, se debe calcular el puntaje de influencia (7).",
        "Si fj se calcula exactamente para cada página global j, entonces el algoritmo de PageRank tendría que ejecutarse para cada una de las O(n) páginas globales j que consideramos, lo que resultaría en un costo computacional de O(n2) para el método de selección de nodos.",
        "Por lo tanto, calcular el valor exacto de fj conducirá a un algoritmo cuadrático, y en su lugar debemos recurrir a métodos de aproximación de este vector.",
        "El algoritmo que presentamos funciona realizando una iteración del método de potencia utilizado por el algoritmo PageRank (Algoritmo 1).",
        "La tasa de convergencia para el algoritmo PageRank se ha demostrado que es igual a la probabilidad del surfista aleatorio α [7, 11].",
        "Dado un vector inicial x(0), si se realizan k iteraciones de PageRank, la solución actual de PageRank x(k) satisface: x(k) − x∗ 1 = O(αk x(0) − x∗ 1), (8), donde x∗ es el vector de PageRank deseado.",
        "Por lo tanto, si solo se realiza una iteración, es necesario elegir un buen vector inicial para lograr una aproximación precisa.",
        "Particionamos la matriz de PageRank PFj, correspondiente al subgrafo Fj, como: PFj = ˜F ˜s ˜uT j w, (9) donde ˜F = αF (DF + diag(uj))−1 + (1 − α) e + 1 eT, ˜s = αs + (1 − α) e + 1, ˜uj = α(DF + diag(uj))−1 uj + (1 − α) e + 1, w = 1 − α + 1, y diag(uj) es la matriz diagonal con la entrada (i, i) igual a uno si el i-ésimo elemento de uj es uno, y cero en caso contrario.",
        "Hemos asumido aquí que el vector del surfista aleatorio es el vector uniforme, y que L no tiene enlaces colgantes.",
        "Estas suposiciones no son necesarias y solo sirven para simplificar la discusión y el análisis.",
        "Un enfoque sencillo para estimar fj es el siguiente.",
        "Primero, estima el PageRank f+ j de Fj calculando una iteración de PageRank sobre la matriz PFj, utilizando el vector inicial ν = f 0.",
        "Luego, estima fj eliminando el último componente de 119 Research Track Paper de nuestra estimación de f+ j (es decir, el componente correspondiente al nodo j añadido), y renormalizando.",
        "El problema con este enfoque está en el vector inicial.",
        "Recuerde que xj es el PageRank del nodo j añadido.",
        "La diferencia entre el PageRank actual f+ j de PFj y el vector inicial ν es ν − f+ j 1 = xj + f − (1 − xj)fj 1 ≥ xj + | f 1 − (1 − xj) fj 1| = xj + |xj| = 2xj.",
        "Por lo tanto, según (8), después de una iteración de PageRank, esperamos que nuestra estimación de f+ j todavía tenga un error de aproximadamente 2αxj.",
        "En particular, para los nodos candidatos j con un PageRank xj relativamente alto, este método producirá resultados más inexactos.",
        "A continuación, presentaremos un método que elimina este sesgo y se ejecuta en tiempo O(n). 5.2.1 Complementación Estocástica Dado que f+ j, como se muestra en (6), es el PageRank de la matriz PFj, tenemos: fj(1 − xj) xj = ˜F ˜s ˜uT j w fj(1 − xj) xj = ˜F fj(1 − xj) + ˜sxj ˜uT j fj(1 − xj) + wxj.",
        "Resolver el sistema anterior para fj puede demostrarse que produce fj = ( ˜F + (1 − w)−1 ˜s˜uT j )fj. (10) La matriz S = ˜F +(1−w)−1 ˜s˜uT j se conoce como el complemento estocástico de la matriz estocástica de columna PFj con respecto a la submatriz ˜F.",
        "La teoría de complementación estocástica está bien estudiada, y se puede demostrar que el complemento estocástico de una matriz irreducible (como la matriz de PageRank) es único.",
        "Además, el complemento estocástico también es irreducible y, por lo tanto, tiene una distribución estacionaria única.",
        "Para un estudio extenso, ver [15].",
        "Se puede demostrar fácilmente que el autovalor subdominante de S es a lo sumo +1 α, donde α es el tamaño de F.",
        "Para valores suficientemente grandes, este valor estará muy cerca de α.",
        "Esto es importante, ya que otras propiedades del algoritmo PageRank, especialmente la sensibilidad del algoritmo, dependen de este valor [11].",
        "En este método, estimamos el vector de longitud fj calculando una iteración de PageRank sobre el complemento estocástico × S, comenzando en el vector f: fj ≈ Sf. (11) Esto contrasta con el método simple descrito en la sección anterior, que primero itera sobre la matriz ( + 1) × ( + 1) PFj para estimar f+ j, y luego elimina el último componente de la estimación y renormaliza para aproximar fj.",
        "El problema con el último método radica en la elección del vector inicial de longitud ( + 1), ν. En consecuencia, la estimación de PageRank dada por el método simple difiere del verdadero PageRank en al menos 2αxj, donde xj es el PageRank de la página j.",
        "Al utilizar el complemento estocástico, podemos establecer un límite inferior estricto de cero para esta diferencia.",
        "Para ver esto, considera el caso en el que se agrega un nodo k a F para formar el subgrafo local aumentado Fk, y que el PageRank de este nuevo grafo es (1 − xk)f xk.",
        "Específicamente, la adición de la página k no cambia los PageRanks de las páginas en F, y por lo tanto fk = f. Por la construcción del complemento estocástico, fk = Sfk, por lo que la aproximación dada en la ecuación (11) producirá la solución exacta.",
        "A continuación, presentamos los detalles computacionales necesarios para calcular eficientemente la cantidad fj − f 1 sobre todas las páginas globales conocidas j.",
        "Comenzamos expandiendo la diferencia fj − f, donde el vector fj se estima como en (11), fj − f ≈ Sf − f = αF (DF + diag(uj))−1 f + (1 − α) e + 1 eT f +(1 − w)−1 (˜uT j f)˜s − f. (12) Tenga en cuenta que la matriz (DF + diag(uj))−1 es diagonal.",
        "Dejando que o[k] sea el recuento de enlaces de salida para la página k en F, podemos expresar el elemento diagonal k-ésimo como: (DF + diag(uj))−1 [k, k] = 1 o[k]+1 si uj[k] = 1 1 o[k] si uj[k] = 0 Notando que (o[k] + 1)−1 = o[k]−1 − (o[k](o[k] + 1))−1 y reescribiendo esto en forma matricial obtenemos (DF +diag(uj))−1 = D−1 F −D−1 F (DF +diag(uj))−1 diag(uj). (13) Usamos la misma identidad para expresar e + 1 = e − e ( + 1) . (14) Recordemos que, por definición, tenemos PF = αF D−1 F +(1−α)e.",
        "Sustituyendo (13) y (14) en (12) se obtiene que fj − f ≈ (PF f − f) −αF D−1 F (DF + diag(uj))−1 diag(uj)f −(1 − α) e ( + 1) + (1 − w)−1 (˜uT j f)˜s = x + y + (˜uT j f)z, (15), notando que por definición, f = PF f, y definiendo los vectores x, y, y z como x = −αF D−1 F (DF + diag(uj))−1 diag(uj)f (16) y = −(1 − α) e ( + 1) (17) z = (1 − w)−1 ˜s. (18) El primer término x es un vector disperso, y toma valores no nulos solo para las páginas locales k que son hermanas de la página global j.",
        "Definimos (i, j) ∈ F si y solo si F [j, i] = 1 (equivalentemente, la página i enlaza a la página j) y expresamos el valor del componente x[k] como: x[k] = −α k:(k,k)∈F, uj[k]=1 f[k] o[k](o[k] + 1), (19) donde o[k], como antes, es el número de enlaces salientes de la página k en el dominio local.",
        "Ten en cuenta que los dos últimos términos, y y z, no dependen del nodo global actual j.",
        "Dada la función hj(f) = y + (˜uT j f)z 1, la cantidad fj − f 1 120 Research Track Paper puede expresarse como fj − f 1 = k x[k] + y[k] + (˜uT j f)z[k] = k:x[k]=0 y[k] + (˜uT j f)z[k] + k:x[k]=0 x[k] + y[k] + (˜uT j f)z[k] = hj(f) − k:x[k]=0 y[k] + (˜uT j f)z[k] + k:x[k]=0 x[k] + y[k] + (˜uT j f)z[k]. (20) Si podemos calcular la función hj en tiempo lineal, entonces podemos calcular cada valor de fj − f 1 usando una cantidad adicional de tiempo proporcional al número de componentes no nulas en x.",
        "Estas optimizaciones se llevan a cabo en el Algoritmo 3.",
        "Nótese que la ecuación (20) calcula la diferencia entre todos los componentes de f y fj, mientras que nuestros criterios de selección de nodos, dados en la ecuación (7), se restringen a los componentes correspondientes a los nodos en el dominio local original L. Examinemos el Algoritmo 3 con más detalle.",
        "Primero, el algoritmo calcula el número de enlaces de salida para cada página en el dominio local.",
        "El algoritmo luego calcula la cantidad ˜uT j f para cada página global j conocida.",
        "Este producto interno se puede escribir como (1 − α) 1 + 1 + α k:(k,j)∈Fout f[k] o[k] + 1, donde el segundo término suma sobre el conjunto de páginas locales que enlazan a la página j.",
        "Dado que se asumió que el número total de aristas en Fout tenía un tamaño O( ) (recordemos que es el número de páginas en F), el tiempo de ejecución de este paso también es O( ).",
        "El algoritmo luego calcula los vectores y y z, como se indican en (17) y (18), respectivamente.",
        "El método L1NormDiff se llama en los componentes de estos vectores que corresponden a las páginas en L, y estima el valor de EL(y + (˜uT j f)z) 1 para cada página j.",
        "La estimación funciona de la siguiente manera.",
        "Primero, los valores de ˜uT j f se discretizan de forma uniforme en c valores {a1, ..., ac}.",
        "La cantidad EL(y + aiz) 1 se calcula entonces para cada valor discretizado de ai y se almacena en una tabla.",
        "Para evaluar EL (y + az) 1 para algún a ∈ [a1, ac], se determina el valor discretizado más cercano ai, y se utiliza la entrada correspondiente en la tabla.",
        "El tiempo total de ejecución de este método es lineal en y el parámetro de discretización c (que consideramos constante).",
        "Observamos que si se desean valores exactos, también hemos desarrollado un algoritmo que se ejecuta en tiempo O(log) que no se describe aquí.",
        "En el bucle principal, calculamos el vector x, tal como se define en la ecuación (16).",
        "Los bucles anidados iteran sobre el conjunto de páginas en F que son hermanas de la página j.",
        "Normalmente, el tamaño de este conjunto está limitado por una constante.",
        "Finalmente, para cada página j, el vector de puntuaciones se actualiza sobre el conjunto de componentes no nulos k del vector x con k ∈ L. Este conjunto tiene un tamaño igual al número de hermanos locales de la página j, y es un subconjunto del número total de hermanos de la página j.",
        "Por lo tanto, cada iteración del bucle principal toma tiempo constante, y el tiempo de ejecución total del bucle principal es O( ).",
        "Dado que hemos asumido que el tamaño de F no crecerá más allá de O(n), el tiempo de ejecución total del algoritmo es O(n).",
        "Algoritmo 3: Selección de nodos a través de la complementación estocástica.",
        "SC-Select(F , Fout, f, k) Entrada: F : matriz de adyacencia de ceros y unos del tamaño correspondiente al subgrafo local actual, Fout: matriz de enlaces de ceros y unos de F al subgrafo global, f: PageRank de F , k: número de páginas a devolver Salida: páginas: conjunto de k páginas para rastrear a continuación {Calcular sumas de enlaces de salida para el subgrafo local} para cada (página j ∈ F ) o[j] ← k:(j,k)∈F F[j, k] fin {Calcular escalar ˜uT j f para cada nodo global j } para cada (página j ∈ Fout) g[j] ← (1 − α) 1 +1 para cada (página k : (k, j) ∈ Fout) g[j] ← g[j] + α f[k] o[k]+1 fin fin {Calcular vectores y z como en (17) y (18) } y ← −(1 − α) e ( +1) z ← (1 − w)−1 ˜s {Aproximar y + g[j] ∗ z 1 para todos los valores g[j]} norm diffs ←L1NormDiffs(g, ELy, ELz) para cada (página j ∈ Fout) {Calcular vector disperso x como en (19)} x ← 0 para cada (página k : (k, j) ∈ Fout) para cada (página k : (k, k ) ∈ F )) x[k ] ← x[k ] − f[k] o[k](o[k]+1) fin fin x ← αx scores[j] ← norm diffs[j] para cada (k : x[k] > 0 y página k ∈ L) scores[j] ← scores[j] − |y[k] + g[j] ∗ z[k]| +|x[k]+y[k]+g[j]∗z[k])| fin fin Devolver k páginas con los puntajes más altos 5.2.2 Flujos de PageRank Ahora presentamos un análisis intuitivo del método de complementación estocástica descomponiendo el cambio en PageRank en términos de fugas y flujos.",
        "Este análisis está motivado por la descomposición dada en (15).",
        "El flujo de PageRank es el aumento en los PageRanks locales que se originan desde la página global j.",
        "Los flujos están representados por el vector no negativo (˜uT j f)z (ecuaciones (15) y (18)).",
        "El escalar ˜uT j f se puede pensar como la cantidad total de flujo de PageRank que la página j tiene disponible para distribuir.",
        "El vector z dicta cómo se asigna el flujo al dominio local; el flujo que recibe la página local k es proporcional (con un factor constante debido al vector de navegante aleatorio) al número esperado de sus enlaces entrantes.",
        "Las filtraciones de PageRank representan la disminución en el PageRank resultante de la adición de la página j.",
        "La fuga puede ser cuantificada en términos de los vectores no positivos x e y (ecuaciones (16) y (17)).",
        "Para el vector x, podemos ver a partir de la ecuación (19) que la cantidad de PageRank filtrado por una página local es proporcional a la suma ponderada de los Page121 Research Track Paper Ranks de sus páginas hermanas.",
        "Por lo tanto, las páginas que tienen hermanos con PageRanks más altos (y un bajo número de enlaces salientes) experimentarán más pérdida de valor.",
        "La fuga causada por y es un artefacto del vector del surfista aleatorio.",
        "A continuación demostraremos que si solo se considera el término de flujo, (˜uT j f)z, entonces el método resultante es muy similar a una heurística propuesta por Cho et al. [6] que ha sido ampliamente utilizada para el problema de Ordenación de URL en el Rastreo.",
        "Esta heurística es computacionalmente más económica, pero como veremos más adelante, no es tan efectiva como el método de Complementación Estocástica.",
        "Nuestra estrategia de selección de nodos elige nodos globales que tienen la mayor influencia (ecuación (7)).",
        "Si esta influencia se aproxima utilizando solo flujos, el nodo óptimo j∗ es: j∗ = argmaxj EL ˜uT j fz 1 = argmaxj ˜uT j f EL z 1 = argmaxj ˜uT j f = argmaxj α(DF + diag(uj))−1 uj + (1 − α) e + 1 , f = argmaxjfT (DF + diag(uj))−1 uj.",
        "La puntuación de selección de página resultante se puede expresar como la suma de los PageRanks de cada página local k que enlaza con j, donde cada valor de PageRank se normaliza por o[k]+1.",
        "Curiosamente, la normalización que surge en nuestro método difiere de la heurística dada en [6], la cual normaliza por o[k].",
        "El algoritmo PF-Select, que se omite por falta de espacio, primero calcula la cantidad fT (DF +diag(uj))−1 uj para cada página global j, y luego devuelve las páginas con los k puntajes más altos.",
        "Para ver que el tiempo de ejecución de este algoritmo es O(n), observe que la computación involucrada en este método es un subconjunto de la necesaria para el método SC-Select (Algoritmo 3), el cual se demostró que tiene un tiempo de ejecución de O(n). 6.",
        "EXPERIMENTOS En esta sección, proporcionamos evidencia experimental para verificar la efectividad de nuestros algoritmos.",
        "Primero describimos nuestra metodología experimental y luego presentamos resultados en una variedad de dominios locales. 6.1 Metodología Dado los recursos limitados disponibles en una institución académica, rastrear una sección de la web que sea de la misma magnitud que la indexada por Google o Yahoo! claramente es inviable.",
        "Por lo tanto, para un dominio local dado, aproximamos el grafo global rastreando un vecindario local alrededor del dominio que es varias órdenes de magnitud más grande que el subgrafo local.",
        "A pesar de que dicho gráfico sigue siendo órdenes de magnitud más pequeño que el verdadero gráfico global, sostenemos que, incluso si existen algunas páginas altamente influyentes que están muy lejos de nuestro dominio local, es poco realista que cualquier algoritmo de selección de nodos locales las encuentre.",
        "Tales páginas suelen ser muy poco relacionadas con las páginas dentro del dominio local.",
        "Al explicar nuestras estrategias de selección de nodos en la sección 5, hicimos la suposición simplificadora de que nuestro grafo local no contenía nodos colgantes.",
        "Esta suposición se hizo solo para facilitar nuestro análisis.",
        "Nuestra implementación maneja de manera eficiente los enlaces colgantes al reemplazar cada columna de ceros de nuestra matriz de adyacencia con el vector uniforme.",
        "Evaluamos el algoritmo utilizando las dos estrategias de selección de nodos dadas en la Sección 5.2, y también comparándolo con los siguientes métodos de referencia: • Aleatorio: Los nodos se eligen de forma uniforme al azar entre los nodos globales conocidos. • Conteo de enlaces de salida: Se eligen los nodos globales con el mayor número de enlaces de salida desde el dominio local.",
        "En cada iteración del algoritmo FindGlobalPR, evaluamos el rendimiento calculando la diferencia entre la estimación actual de PageRank del dominio local, ELf ELf 1, y el PageRank global del dominio local, ELg ELg 1.",
        "Todas las calculaciones de PageRank se realizaron utilizando el vector de surfista aleatorio uniforme.",
        "En todos los experimentos, establecimos el parámetro del surfista aleatorio α en .85 y utilizamos un umbral de convergencia de 10−6.",
        "Evaluamos la diferencia entre los vectores de PageRank local y global utilizando tres métricas diferentes: las normas L1 y L∞, y el tau de Kendall.",
        "La norma L1 mide la suma del valor absoluto de las diferencias entre los dos vectores, y la norma L∞ mide el valor absoluto de la mayor diferencia.",
        "La métrica de tau de Kendall es una medida de correlación de rangos popular utilizada para comparar PageRanks [2, 11].",
        "Esta métrica se puede calcular contando el número de pares de pares que coinciden en la clasificación, y restando de eso el número de pares de pares que no coinciden en la clasificación.",
        "El valor final se normaliza luego por el número total de n pares de este tipo, resultando en un rango de [−1, 1], donde una puntuación negativa indica una anticorrelación entre las clasificaciones, y valores cercanos a uno corresponden a una fuerte correlación de rangos. 6.2 Resultados Nuestros experimentos se basan en dos grandes rastreos web y se descargaron utilizando el rastreador web que forma parte del proyecto de motor de búsqueda de código abierto Nutch [18].",
        "Todas las exploraciones se limitaron únicamente a páginas http, y para limitar el número de páginas generadas dinámicamente que exploramos, ignoramos todas las páginas con URLs que contengan alguno de los caracteres ?, *, @ o =.",
        "El primer rastreo, al que nos referiremos como el conjunto de datos edu, fue iniciado por las páginas de inicio de los 100 principales departamentos de posgrado en informática en los Estados Unidos, según la clasificación de US News and World Report [16], y también por las páginas de inicio de sus respectivas instituciones.",
        "Se realizó un rastreo de profundidad 5, restringido a páginas dentro del dominio .edu, lo que resultó en un grafo con aproximadamente 4.7 millones de páginas y 22.9 millones de enlaces.",
        "El segundo rastreo fue alimentado por el conjunto de páginas bajo la jerarquía de política en el proyecto de directorio abierto dmoz[17].",
        "Rastreamos todas las páginas hasta cuatro enlaces de distancia, lo que resultó en un grafo con 4.4 millones de páginas y 17.3 millones de enlaces.",
        "Dentro del rastreo educativo, identificamos los cinco dominios específicos del sitio correspondientes a los sitios web de los cinco principales departamentos de posgrado en ciencias de la computación, según la clasificación de US News and World Report.",
        "Esto produjo dominios locales de varios tamaños, desde 10,626 (UIUC) hasta 59,895 (Berkeley).",
        "Para cada uno de estos dominios específicos del sitio con tamaño n, realizamos 50 iteraciones del algoritmo FindGlobalPR para rastrear un total de 2n nodos adicionales.",
        "La Figura 2(a) muestra la diferencia (L1) entre la estimación de PageRank en cada iteración y el PageRank global, para el dominio local de Berkeley.",
        "El rendimiento de este conjunto de datos fue representativo del rendimiento típico en los cinco dominios locales específicos de informática.",
        "Inicialmente, la diferencia de L1 entre los PageRanks globales y locales variaba desde .0469 (Stanford) hasta .149 (MIT).",
        "Para las primeras varias iteraciones, el Artículo de Investigación 122 0 5 10 15 20 25 30 35 40 45 50 0.015 0.02 0.025 0.03 0.035 0.04 0.045 0.05 0.055 Número de Iteraciones Diferencia de PageRank Global y Local (L1) Complemento Estocástico PageRank Flujo de Enlaces de Conteo Aleatorio 0 10 20 30 40 50 0 0.05 0.1 0.15 0.2 0.25 0.3 0.35 Número de Iteraciones Diferencia de PageRank Global y Local (L1) Complemento Estocástico PageRank Flujo de Enlaces de Conteo Aleatorio 0 5 10 15 20 25 0.16 0.18 0.2 0.22 0.24 0.26 0.28 0.3 0.32 0.34 Número de Iteraciones Diferencia de PageRank Global y Local (L1) Complemento Estocástico PageRank Flujo de Enlaces de Conteo Aleatorio (a) www.cs.berkeley.edu (b) www.enterstageright.com (c) Política Figura 2: Diferencia L1 entre los PageRanks globales estimados y verdaderos para (a) el sitio web de ciencias de la computación de Berkeley, (b) el dominio específico del sitio, www.enterstageright.com, y (c) el dominio específico del tema de política.",
        "El método de complemento estocástico supera a todos los demás métodos en diferentes dominios. Tres métodos basados en enlaces superan a la heurística de selección aleatoria.",
        "Después de estas iteraciones iniciales, la heurística aleatoria tendió a ser más competitiva con (o incluso superar, como en el dominio local de Berkeley) las heurísticas de conteo de enlaces de salida y flujo de PageRank.",
        "En todos los ensayos, el método de complementación estocástica superó a los otros métodos o compitió con ellos.",
        "La Tabla 1 muestra la diferencia promedio entre los PageRanks globales estimados finales y los PageRanks globales reales para varias medidas de distancia.",
        "Algoritmo L1 L∞ Kendall Estocástico.",
        "Tabla 1: Rendimiento final promedio de varias estrategias de selección de nodos para los cinco dominios locales de informática específicos del sitio.",
        "Ten en cuenta que el Tau de Kendall mide similitud, mientras que las otras métricas son medidas de disimilitud.",
        "La Complementación Estocástica claramente supera a los otros métodos en todas las métricas.",
        "Dentro del conjunto de datos de política, también realizamos dos pruebas específicas para los sitios web más grandes en el rastreo: www.adamsmith.org, el sitio web del Instituto Adam Smith con sede en Londres, y www.enterstageright.com, una revista en línea conservadora.",
        "Al igual que con los dominios locales de edu, ejecutamos nuestro algoritmo durante 50 iteraciones, rastreando un total de 2n nodos.",
        "La figura 2 (b) muestra los resultados para el dominio www.enterstageright.com.",
        "A diferencia de los dominios locales de edu, los métodos Random y OutlinkCount no fueron competitivos ni con los métodos SC-Select ni con los métodos PF-Select.",
        "Entre todos los conjuntos de datos y todos los métodos de selección de nodos, el método de complementación estocástica fue el más impresionante en este conjunto de datos, logrando una estimación final que difería solo .0279 del PageRank global, una mejora de diez veces sobre la diferencia inicial del PageRank local de .299.",
        "Para el dominio local de Adam Smith, la diferencia inicial entre los PageRanks locales y globales fue de .148, y las estimaciones finales proporcionadas por los métodos SC-Select, PF-Select, OutlinkCount y Random fueron de .0208, .0193, .0222 y .0356, respectivamente.",
        "Dentro del conjunto de datos de política, construimos cuatro dominios locales específicos de temas.",
        "El primer dominio consistía en todas las páginas de la categoría de política de dmoz, y también todas las páginas dentro de cada uno de estos sitios hasta dos enlaces de distancia.",
        "Esto produjo un dominio local de 90,811 páginas, y los resultados se muestran en la figura 2 (c).",
        "Debido al mayor tamaño de los dominios específicos del tema, ejecutamos nuestro algoritmo solo durante 25 iteraciones para rastrear un total de n nodos.",
        "También creamos dominios específicos de temas a partir de tres subtemas políticos: liberalismo, conservadurismo y socialismo.",
        "Las páginas en estos dominios fueron identificadas por sus categorías correspondientes de dmoz.",
        "Para cada subtema, establecemos el dominio local como todas las páginas dentro de tres enlaces de las páginas de categoría dmoz correspondientes.",
        "La Tabla 2 resume el rendimiento de estos tres dominios específicos del tema, así como también del dominio político más amplio.",
        "Para cuantificar el efecto global de una página js en los valores globales de PageRank de las páginas en el dominio local, definimos el impacto de la página js como su valor de PageRank, g[j], normalizado por la fracción de sus enlaces salientes que apuntan al dominio local: impacto(j) = oL[j] o[j] · g[j], donde oL[j] es el número de enlaces salientes de la página j a páginas en el dominio local L, y o[j] es el número total de enlaces salientes de js.",
        "En términos del modelo del surfista aleatorio, el impacto de la página j es la probabilidad de que el surfista aleatorio (1) se encuentre actualmente en la página global j en su caminata aleatoria y (2) tome un enlace de salida a una página local, dado que ya ha decidido no saltar a una página aleatoria.",
        "Para el dominio político local, encontramos que muchas de las páginas con alto impacto eran de hecho páginas políticas que deberían haber sido incluidas en el tema de política de dmoz, pero no lo estaban.",
        "Por ejemplo, las dos páginas globales más influyentes fueron el motor de búsqueda político www.askhenry.com y la página de inicio de la revista política en línea www.policyreview.com.",
        "Entre las páginas no políticas, la página de inicio de la revista Education Next fue la más influyente.",
        "El diario está disponible de forma gratuita en línea y contiene artículos sobre varios aspectos de la educación K-12 en América.",
        "Para proporcionar algunas pruebas anecdóticas de la efectividad de nuestros métodos de selección de páginas, observamos que el método SC-Select eligió 11 páginas dentro del dominio www.educationnext.org, el método PF-Select descubrió 7 páginas, mientras que los métodos OutlinkCount y Random encontraron solo 6 páginas cada uno.",
        "Para el ámbito político local conservador, el sitio web socialista www.ornery.org tuvo una puntuación de impacto muy alta.",
        "Este documento de investigación de la pista 123 titulado \"Toda la política: Algoritmo L1 L2 Kendall Stoch\".",
        "Comp. .1253 .000700 .8671 Flujo PR .1446 .000710 .8518 Enlace saliente .1470 .00225 .8642 Aleatorio .2055 .00203 .8271 Conservadurismo: Algoritmo L1 L2 Kendall Estoc.",
        "Comp. .0496 .000990 .9158 Flujo PR .0554 .000939 .9028 Enlace saliente .0602 .00527 .9144 Aleatorio .1197 .00102 .8843 Liberalismo: Algoritmo L1 L2 Kendall Estoc.",
        "Comp. .0622 .001360 .8848 Flujo PR .0799 .001378 .8669 Enlace saliente .0763 .001379 .8844 Aleatorio .1127 .001899 .8372 Socialismo: Algoritmo L1 L∞ Kendall Estoc.",
        "Tabla 2: Rendimiento final entre estrategias de selección de nodos para las cuatro exploraciones específicas de temas políticos.",
        "Ten en cuenta que el coeficiente de correlación de Kendall mide la similitud, mientras que las otras métricas son medidas de disimilitud.",
        "Como era de esperar, el PageRank global de este artículo (que resulta estar en la página de inicio de la NCCPR, www.nationalresearch.com) era aproximadamente de .002, mientras que el PageRank local de esta página era solo de .00158.",
        "El método SC-Select produjo una estimación global de PageRank de aproximadamente .00182, el método PFSelect estimó un valor de .00167, y los métodos Random y OutlinkCount produjeron valores de .01522 y .00171, respectivamente.",
        "TRABAJO RELACIONADO El marco de selección de nodos que hemos propuesto es similar al problema de ordenación de URL para el rastreo propuesto por Cho et al. en [6].",
        "Mientras que nuestro marco busca minimizar la diferencia entre el PageRank global y local, el objetivo utilizado en [6] es rastrear primero las páginas más altamente clasificadas (globalmente).",
        "Proponen varios algoritmos de selección de nodos, incluyendo la heurística del recuento de enlaces de salida, así como una variante de nuestro algoritmo PF-Select al que se refieren como la métrica de ordenación de PageRank.",
        "Encontraron que este método era el más efectivo para optimizar su objetivo, al igual que lo demostró una encuesta reciente de estos métodos realizada por Baeza-Yates et al. [1].",
        "Boldi et al. también experimentan dentro de un marco de rastreo similar en [2], pero cuantifican sus resultados al comparar la correlación de rangos de Kendall entre los PageRanks del conjunto actual de páginas rastreadas y los del grafo global completo.",
        "Encontraron que las estrategias de selección de nodos que rastreaban páginas con el PageRank global más alto primero en realidad tenían un peor rendimiento (con respecto a la correlación de Kendalls Tau entre los PageRanks locales y globales) que las estrategias básicas de búsqueda en profundidad o en amplitud.",
        "Sin embargo, sus experimentos difieren de nuestro trabajo en que nuestros algoritmos de selección de nodos no utilizan (ni tienen acceso a) valores globales de PageRank.",
        "Se han propuesto muchas mejoras algorítmicas para calcular los valores exactos de PageRank [9, 10, 14].",
        "Si se utilizan tales algoritmos para calcular los PageRanks globales de nuestro dominio local, todos requerirían una computación, almacenamiento y ancho de banda de O(N), donde N es el tamaño del dominio global.",
        "Esto contrasta con nuestro método, que aproxima el PageRank global y escala linealmente con el tamaño del dominio local.",
        "Wang y Dewitt [22] proponen un sistema en el que el conjunto de servidores web que conforman el dominio global se comunican entre sí para calcular sus respectivos PageRanks globales.",
        "Para un servidor web dado que aloja n páginas, los requisitos computacionales, de ancho de banda y almacenamiento también son lineales en n. Una desventaja de este sistema es que el número de servidores web distintos que conforman el dominio global puede ser muy grande.",
        "Por ejemplo, nuestro conjunto de datos edu contiene sitios web de más de 3,200 universidades diferentes; coordinar un sistema así entre un gran número de sitios puede ser muy difícil.",
        "Gan, Chen y Suel proponen un método para estimar el PageRank de una sola página [5] que utiliza solo ancho de banda, computación y espacio constantes.",
        "Su enfoque se basa en la disponibilidad de un servidor de conectividad remota que puede suministrar el conjunto de enlaces entrantes a una página dada, una suposición que no se utiliza en nuestro marco de trabajo.",
        "Experimentalmente demuestran que se puede obtener una estimación razonable del PageRank de los nodos visitando como máximo unos pocos cientos de nodos.",
        "El uso de su algoritmo para nuestro problema requeriría que primero se descargue todo el dominio global o se utilice un servidor de conectividad, lo que resultaría en grafos web muy grandes. 8.",
        "CONCLUSIONES Y TRABAJOS FUTUROS Internet está creciendo de forma exponencial, y para poder navegar por un repositorio tan grande como la web, los motores de búsqueda globales se han establecido como una necesidad.",
        "Junto con la omnipresencia de estos motores de búsqueda a gran escala, surge un aumento en las expectativas de los usuarios de búsqueda.",
        "Al proporcionar una cobertura completa y aislada de un dominio web específico, los motores de búsqueda localizados son un medio efectivo para localizar rápidamente contenido que de otra manera podría ser difícil de encontrar.",
        "En este trabajo, sostenemos que el uso de PageRank global en un motor de búsqueda localizado puede mejorar el rendimiento.",
        "Para estimar el PageRank global, hemos propuesto un marco de selección de nodos iterativo en el que seleccionamos qué páginas de la frontera global rastrear a continuación.",
        "Nuestra principal contribución es nuestro algoritmo de selección de páginas de complementación estocástica.",
        "Este método recorre los nodos que tendrán un impacto significativo en el dominio local y tiene un tiempo de ejecución lineal en el número de nodos en el dominio local.",
        "Experimentalmente, validamos estos métodos en un conjunto diverso de dominios locales, que incluyen siete dominios específicos del sitio y cuatro dominios específicos del tema.",
        "Concluimos que al rastrear n o 2n páginas adicionales, nuestros métodos encuentran una estimación de los PageRanks globales que es hasta diez veces mejor que simplemente usar los PageRanks locales.",
        "Además, demostramos que nuestro algoritmo supera consistentemente a otras heurísticas existentes. En muchas ocasiones, los dominios específicos de un tema se descubren utilizando un rastreador web enfocado que considera el contenido de las páginas junto con el texto del ancla del enlace para decidir qué páginas rastrear a continuación [4].",
        "Aunque estos rastreadores han demostrado ser bastante efectivos en descubrir contenido relacionado con el tema, también se rastrean muchas páginas irrelevantes en el proceso.",
        "Por lo general, estas páginas son eliminadas y no son indexadas por el motor de búsqueda localizado.",
        "Estas páginas pueden, por supuesto, proporcionar información valiosa sobre el PageRank global del dominio local.",
        "Una forma de integrar estas páginas en nuestro marco de trabajo es comenzar el algoritmo FindGlobalPR con el subgrafo actual F igual al conjunto de páginas que fueron rastreadas por el rastreador enfocado.",
        "El marco de estimación global de PageRank, junto con los algoritmos de selección de nodos presentados, requieren todos una computación de O(n) por iteración y un ancho de banda proporcional al número de páginas rastreadas, Tk.",
        "Si el número de iteraciones T es relativamente pequeño en comparación con el número de páginas rastreadas por iteración, k, entonces el cuello de botella del algoritmo será la fase de rastreo.",
        "Sin embargo, a medida que el número de iteraciones aumenta (en relación con k), el cuello de botella residirá en el cálculo de la selección de nodos.",
        "En este caso, nuestros algoritmos se beneficiarían de optimizaciones en el factor constante.",
        "Recuerde que el algoritmo FindGlobalPR (Algoritmo 2) requiere que los PageRanks del dominio local expandido actual se vuelvan a calcular en cada iteración.",
        "El trabajo reciente de Langville y Meyer [12] proporciona un algoritmo para recalcular rápidamente los PageRanks de un grafo web dado si se agregan un pequeño número de nodos.",
        "Este algoritmo demostró proporcionar una aceleración de cinco a diez veces en algunos conjuntos de datos.",
        "Planeamos investigar esto y otras optimizaciones similares como trabajo futuro.",
        "En este artículo, hemos evaluado objetivamente nuestros métodos midiendo qué tan cercanas son nuestras estimaciones globales de PageRank a los verdaderos PageRanks globales.",
        "Para determinar el beneficio de utilizar PageRanks globales en un motor de búsqueda localizado, sugerimos un estudio de usuarios en el que se les pida a los usuarios que califiquen la calidad de los resultados de búsqueda para varias consultas de búsqueda.",
        "Para algunas consultas, solo se utilizan los PageRanks locales en la clasificación, y para las consultas restantes, se utilizan los PageRanks locales y los PageRanks globales aproximados, según lo calculado por nuestros algoritmos.",
        "Los resultados de dicho estudio pueden ser analizados para determinar el beneficio adicional de utilizar los PageRanks globales calculados por nuestros métodos, en lugar de solo utilizar los PageRanks locales.",
        "Agradecimientos.",
        "Esta investigación fue apoyada por la subvención de la NSF CCF-0431257, el Premio de Carrera de la NSF ACI-0093404 y una subvención de Sabre, Inc. 9.",
        "REFERENCIAS [1] R. Baeza-Yates, M. Marín, C. Castillo y A. Rodríguez.",
        "Rastreando un país: estrategias mejores que el recorrido en anchura para ordenar páginas web.",
        "Conferencia de la World-Wide Web, 2005. [2] P. Boldi, M. Santini y S. Vigna.",
        "Haz lo peor para lograr lo mejor: efectos paradójicos en los cálculos incrementales de PageRank.",
        "Taller sobre Grafos Web, 3243:168-180, 2004. [3] S. Brin y L. Page.",
        "La anatomía de un motor de búsqueda web hipertextual a gran escala.",
        "Redes de Computadoras y Sistemas ISDN, 33(1-7):107-117, 1998. [4] S. Chakrabarti, M. van den Berg y B. Dom.",
        "Rastreo enfocado: un nuevo enfoque para el descubrimiento de recursos web específicos de un tema.",
        "Conferencia de la World-Wide Web, 1999. [5] Y. Chen, Q. Gan y T. Suel.",
        "Métodos locales para estimar los valores de pagerank.",
        "Conferencia sobre Gestión de Información y Conocimiento, 2004. [6] J. Cho, H. Garcia-Molina y L. Page.",
        "Rastreo eficiente a través de la ordenación de URL.",
        "Conferencia de la World-Wide Web, 1998. [7] T. H. Haveliwala y S. D. Kamvar.",
        "El segundo valor propio de la matriz de Google.",
        "Informe técnico, Universidad de Stanford, 2003. [8] T. Joachims, F. Radlinski, L. Granka, A. Cheng, C. Tillekeratne y A. Patel.",
        "Aprendizaje de funciones de recuperación a partir de retroalimentación implícita. http://www.cs.cornell.edu/People/tj/career. [9] S. D. Kamvar, T. H. Haveliwala, C. D. Manning y G. H. Golub.",
        "Explotando la estructura de bloques de la web para calcular el pagerank.",
        "Conferencia de la World-Wide Web, 2003. [10] S. D. Kamvar, T. H. Haveliwala, C. D. Manning y G. H. Golub.",
        "Métodos de extrapolación para acelerar el cálculo de PageRank.",
        "Conferencia de la World-Wide Web, 2003. [11] A. N. Langville y C. D. Meyer.",
        "Más profundo dentro de PageRank.",
        "Matemáticas en Internet, 2004. [12] A. N. Langville y C. D. Meyer.",
        "Actualizando el vector estacionario de una cadena de Markov irreducible con miras al PageRank de Google.",
        "Revista SIAM sobre Análisis de Matrices, 2005. [13] P. Lyman, H. R. Varian, K. Swearingen, P. Charles, N. Good, L. L. Jordan y J. Pal.",
        "¿Cuánta información en 2003?",
        "Escuela de Gestión de la Información y Sistemas, Universidad de California en Berkeley, 2003. [14] F. McSherry.",
        "Un enfoque uniforme para el cálculo acelerado de PageRank.",
        "Conferencia de la World-Wide Web, 2005. [15] C. D. Meyer.",
        "Complementación estocástica, desacoplamiento de cadenas de Markov y la teoría de sistemas casi reducibles.",
        "SIAM Review, 31:240-272, 1989. [16] US News and World Report. http://www.usnews.com. [17] Proyecto de directorio abierto Dmoz. http://www.dmoz.org. [18] Motor de búsqueda de código abierto Nutch. http://www.nutch.org. [19] F. Radlinski y T. Joachims.",
        "Cadenas de consulta: aprendizaje para clasificar a partir de retroalimentación implícita.",
        "Conferencia Internacional ACM SIGKDD sobre Descubrimiento de Conocimiento y Minería de Datos, 2005. [20] S. Raghavan y H. Garcia-Molina.",
        "Explorando la web oculta.",
        "En Actas de la Vigésimo séptima Conferencia Internacional sobre Bases de Datos Muy Grandes, 2001. [21] T. Tin Tang, D. Hawking, N. Craswell y K. Griffiths.",
        "Rastreo enfocado para relevancia temática y calidad de la información médica.",
        "Conferencia sobre Gestión de Información y Conocimiento, 2005. [22] Y. Wang y D. J. DeWitt.",
        "Calculando el pagerank en un sistema distribuido de búsqueda en internet.",
        "Actas de la 30ª Conferencia VLDB, 2004. 125 Artículos de Investigación."
    ],
    "error_count": 1,
    "keys": {
        "global pagerank": {
            "translated_key": "PageRank Global",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Estimating the <br>global pagerank</br> of Web Communities Jason V. Davis Dept.",
                "of Computer Sciences University of Texas at Austin Austin, TX 78712 jdavis@cs.utexas.edu Inderjit S. Dhillon Dept. of Computer Sciences University of Texas at Austin Austin, TX 78712 inderjit@cs.utexas.edu ABSTRACT Localized search engines are small-scale systems that index a particular community on the web.",
                "They offer several benefits over their large-scale counterparts in that they are relatively inexpensive to build, and can provide more precise and complete search capability over their relevant domains.",
                "One disadvantage such systems have over large-scale search engines is the lack of <br>global pagerank</br> values.",
                "Such information is needed to assess the value of pages in the localized search domain within the context of the web as a whole.",
                "In this paper, we present well-motivated algorithms to estimate the <br>global pagerank</br> values of a local domain.",
                "The algorithms are all highly scalable in that, given a local domain of size n, they use O(n) resources that include computation time, bandwidth, and storage.",
                "We test our methods across a variety of localized domains, including site-specific domains and topic-specific domains.",
                "We demonstrate that by crawling as few as n or 2n additional pages, our methods can give excellent <br>global pagerank</br> estimates.",
                "Categories and Subject Descriptors H.3.3 [Information Storage and Retrieval]: Information Search and Retrieval; G.1.3 [Numerical Analysis]: Numerical Linear Algebra; G.3 [Probability and Statistics]: Markov Processes General Terms PageRank, Markov Chain, Stochastic Complementation 1.",
                "INTRODUCTION Localized search engines are small-scale search engines that index only a single community of the web.",
                "Such communities can be site-specific domains, such as pages within the cs.utexas.edu domain, or topic-related communitiesfor example, political websites.",
                "Compared to the web graph crawled and indexed by large-scale search engines, the size of such local communities is typically orders of magnitude smaller.",
                "Consequently, the computational resources needed to build such a search engine are also similarly lighter.",
                "By restricting themselves to smaller, more manageable sections of the web, localized search engines can also provide more precise and complete search capabilities over their respective domains.",
                "One drawback of localized indexes is the lack of global information needed to compute link-based rankings.",
                "The PageRank algorithm [3], has proven to be an effective such measure.",
                "In general, the PageRank of a given page is dependent on pages throughout the entire web graph.",
                "In the context of a localized search engine, if the PageRanks are computed using only the local subgraph, then we would expect the resulting PageRanks to reflect the perceived popularity within the local community and not of the web as a whole.",
                "For example, consider a localized search engine that indexes political pages with conservative views.",
                "A person wishing to research the opinions on global warming within the conservative political community may encounter numerous such opinions across various websites.",
                "If only local PageRank values are available, then the search results will reflect only strongly held beliefs within the community.",
                "However, if global PageRanks are also available, then the results can additionally reflect outsiders views of the conservative community (those documents that liberals most often access within the conservative community).",
                "Thus, for many localized search engines, incorporating global PageRanks can improve the quality of search results.",
                "However, the number of pages a local search engine indexes is typically orders of magnitude smaller than the number of pages indexed by their large-scale counterparts.",
                "Localized search engines do not have the bandwidth, storage capacity, or computational power to crawl, download, and compute the global PageRanks of the entire web.",
                "In this work, we present a method of approximating the global PageRanks of a local domain while only using resources of the same order as those needed to compute the PageRanks of the local subgraph.",
                "Our proposed method looks for a supergraph of our local subgraph such that the local PageRanks within this supergraph are close to the true global PageRanks.",
                "We construct this supergraph by iteratively crawling global pages on the current web frontier-i.e., global pages with inlinks from pages that have already been crawled.",
                "In order to provide 116 Research Track Paper a good approximation to the global PageRanks, care must be taken when choosing which pages to crawl next; in this paper, we present a well-motivated page selection algorithm that also performs well empirically.",
                "This algorithm is derived from a well-defined problem objective and has a running time linear in the number of local nodes.",
                "We experiment across several types of local subgraphs, including four topic related communities and several sitespecific domains.",
                "To evaluate performance, we measure the difference between the current <br>global pagerank</br> estimate and the <br>global pagerank</br>, as a function of the number of pages crawled.",
                "We compare our algorithm against several heuristics and also against a baseline algorithm that chooses pages at random, and we show that our method outperforms these other methods.",
                "Finally, we empirically demonstrate that, given a local domain of size n, we can provide good approximations to the <br>global pagerank</br> values by crawling at most n or 2n additional pages.",
                "The paper is organized as follows.",
                "Section 2 gives an overview of localized search engines and outlines their advantages over global search.",
                "Section 3 provides background on the PageRank algorithm.",
                "Section 4 formally defines our problem, and section 5 presents our page selection criteria and derives our algorithms.",
                "Section 6 provides experimental results, section 7 gives an overview of related work, and, finally, conclusions are given in section 8. 2.",
                "LOCALIZED SEARCH ENGINES Localized search engines index a single community of the web, typically either a site-specific community, or a topicspecific community.",
                "Localized search engines enjoy three major advantages over their large-scale counterparts: they are relatively inexpensive to build, they can offer more precise search capability over their local domain, and they can provide a more complete index.",
                "The resources needed to build a global search engine are enormous.",
                "A 2003 study by Lyman et al. [13] found that the surface web (publicly available static sites) consists of 8.9 billion pages, and that the average size of these pages is approximately 18.7 kilobytes.",
                "To download a crawl of this size, approximately 167 terabytes of space is needed.",
                "For a researcher who wishes to build a search engine with access to a couple of workstations or a small server, storage of this magnitude is simply not available.",
                "However, building a localized search engine over a web community of a hundred thousand pages would only require a few gigabytes of storage.",
                "The computational burden required to support search queries over a database this size is more manageable as well.",
                "We note that, for topic-specific search engines, the relevant community can be efficiently identified and downloaded by using a focused crawler [21, 4].",
                "For site-specific domains, the local domain is readily available on their own web server.",
                "This obviates the need for crawling or spidering, and a complete and up-to-date index of the domain can thus be guaranteed.",
                "This is in contrast to their large-scale counterparts, which suffer from several shortcomings.",
                "First, crawling dynamically generated pages-pages in the hidden web-has been the subject of research [20] and is a non-trivial task for an external crawler.",
                "Second, site-specific domains can enable the robots exclusion policy.",
                "This prohibits external search engines crawlers from downloading content from the domain, and an external search engine must instead rely on outside links and anchor text to index these restricted pages.",
                "By restricting itself to only a specific domain of the internet, a localized search engine can provide more precise search results.",
                "Consider the canonical ambiguous search query, jaguar, which can refer to either the car manufacturer or the animal.",
                "A scientist trying to research the habitat and evolutionary history of a jaguar may have better success using a finely tuned zoology-specific search engine than querying Google with multiple keyword searches and wading through irrelevant results.",
                "A method to learn better ranking functions for retrieval was recently proposed by Radlinski and Joachims [19] and has been applied to various local domains, including Cornell Universitys website [8]. 3.",
                "PAGERANK OVERVIEW The PageRank algorithm defines the importance of web pages by analyzing the underlying hyperlink structure of a web graph.",
                "The algorithm works by building a Markov chain from the link structure of the web graph and computing its stationary distribution.",
                "One way to compute the stationary distribution of a Markov chain is to find the limiting distribution of a random walk over the chain.",
                "Thus, the PageRank algorithm uses what is sometimes referred to as the random surfer model.",
                "In each step of the random walk, the surfer either follows an outlink from the current page (i.e. the current node in the chain), or jumps to a random page on the web.",
                "We now precisely define the PageRank problem.",
                "Let U be an m × m adjacency matrix for a given web graph such that Uji = 1 if page i links to page j and Uji = 0 otherwise.",
                "We define the PageRank matrix PU to be: PU = αUD−1 U + (1 − α)veT , (1) where DU is the (unique) diagonal matrix such that UD−1 U is column stochastic, α is a given scalar such that 0 ≤ α ≤ 1, e is the vector of all ones, and v is a non-negative, L1normalized vector, sometimes called the random surfer vector.",
                "Note that the matrix D−1 U is well-defined only if each column of U has at least one non-zero entry-i.e., each page in the webgraph has at least one outlink.",
                "In the presence of such dangling nodes that have no outlinks, one commonly used solution, proposed by Brin et al. [3], is to replace each zero column of U by a non-negative, L1-normalized vector.",
                "The PageRank vector r is the dominant eigenvector of the PageRank matrix, r = PU r. We will assume, without loss of generality, that r has an L1-norm of one.",
                "Computationally, r can be computed using the power method.",
                "This method first chooses a random starting vector r(0) , and iteratively multiplies the current vector by the PageRank matrix PU ; see Algorithm 1.",
                "In general, each iteration of the power method can take O(m2 ) operations when PU is a dense matrix.",
                "However, in practice, the number of links in a web graph will be of the order of the number of pages.",
                "By exploiting the sparsity of the PageRank matrix, the work per iteration can be reduced to O(km), where k is the average number of links per web page.",
                "It has also been shown that the total number of iterations needed for convergence is proportional to α and does not depend on the size of the web graph [11, 7].",
                "Finally, the total space needed is also O(km), mainly to store the matrix U. 117 Research Track Paper Algorithm 1: A linear time (per iteration) algorithm for computing PageRank.",
                "ComputePR(U) Input: U: Adjacency matrix.",
                "Output: r: PageRank vector.",
                "Choose (randomly) an initial non-negative vector r(0) such that r(0) 1 = 1. i ← 0 repeat i ← i + 1 ν ← αUD−1 U r(i−1) {α is the random surfing probability} r(i) ← ν + (1 − α)v {v is the random surfer vector.} until r(i) − r(i−1) < δ {δ is the convergence threshold.} r ← r(i) 4.",
                "PROBLEM DEFINITION Given a local domain L, let G be an N × N adjacency matrix for the entire connected component of the web that contains L, such that Gji = 1 if page i links to page j and Gji = 0 otherwise.",
                "Without loss of generality, we will partition G as: G = L Gout Lout Gwithin , (2) where L is the n × n local subgraph corresponding to links inside the local domain, Lout is the subgraph that corresponds to links from the local domain pointing out to the global domain, Gout is the subgraph containing links from the global domain into the local domain, and Gwithin contains links within the global domain.",
                "We assume that when building a localized search engine, only pages inside the local domain are crawled, and the links between these pages are represented by the subgraph L. The links in Lout are also known, as these point from crawled pages in the local domain to uncrawled pages in the global domain.",
                "As defined in equation (1), PG is the PageRank matrix formed from the global graph G, and we define the <br>global pagerank</br> vector of this graph to be g. Let the n-length vector p∗ be the L1-normalized vector corresponding to the <br>global pagerank</br> of the pages in the local domain L: p∗ = EL g ELg 1 , where EL = [ I | 0 ] is the restriction matrix that selects the components from g corresponding to nodes in L. Let p denote the PageRank vector constructed from the local domain subgraph L. In practice, the observed local PageRank p and the global PageRank p∗ will be quite different.",
                "One would expect that as the size of local matrix L approaches the size of global matrix G, the <br>global pagerank</br> and the observed local PageRank will become more similar.",
                "Thus, one approach to estimating the <br>global pagerank</br> is to crawl the entire global domain, compute its PageRank, and extract the PageRanks of the local domain.",
                "Typically, however, n N , i.e., the number of global pages is much larger than the number of local pages.",
                "Therefore, crawling all global pages will quickly exhaust all local resources (computational, storage, and bandwidth) available to create the local search engine.",
                "We instead seek a supergraph ˆF of our local subgraph L with size O(n).",
                "Our goal Algorithm 2: The FindGlobalPR algorithm.",
                "FindGlobalPR(L, Lout, T, k) Input: L: zero-one adjacency matrix for the local domain, Lout: zero-one outlink matrix from L to global subgraph as in (2), T: number of iterations, k: number of pages to crawl per iteration.",
                "Output: ˆp: an improved estimate of the <br>global pagerank</br> of L. F ← L Fout ← Lout f ← ComputePR(F ) for (i = 1 to T) {Determine which pages to crawl next} pages ← SelectNodes(F , Fout, f, k) Crawl pages, augment F and modify Fout {Update PageRanks for new local domain} f ← ComputePR(F ) end {Extract PageRanks of original local domain & normalize} ˆp ← ELf ELf 1 is to find such a supergraph ˆF with PageRank ˆf, so that ˆf when restricted to L is close to p∗ .",
                "Formally, we seek to minimize GlobalDiff( ˆf) = EL ˆf EL ˆf 1 − p∗ 1 . (3) We choose the L1 norm for measuring the error as it does not place excessive weight on outliers (as the L2 norm does, for example), and also because it is the most commonly used distance measure in the literature for comparing PageRank vectors, as well as for detecting convergence of the algorithm [3].",
                "We propose a greedy framework, given in Algorithm 2, for constructing ˆF .",
                "Initially, F is set to the local subgraph L, and the PageRank f of this graph is computed.",
                "The algorithm then proceeds as follows.",
                "First, the SelectNodes algorithm (which we discuss in the next section) is called and it returns a set of k nodes to crawl next from the set of nodes in the current crawl frontier, Fout.",
                "These selected nodes are then crawled to expand the local subgraph, F , and the PageRanks of this expanded graph are then recomputed.",
                "These steps are repeated for each of T iterations.",
                "Finally, the PageRank vector ˆp, which is restricted to pages within the original local domain, is returned.",
                "Given our computation, bandwidth, and memory restrictions, we will assume that the algorithm will crawl at most O(n) pages.",
                "Since the PageRanks are computed in each iteration of the algorithm, which is an O(n) operation, we will also assume that the number of iterations T is a constant.",
                "Of course, the main challenge here is in selecting which set of k nodes to crawl next.",
                "In the next section, we formally define the problem and give efficient algorithms. 5.",
                "NODE SELECTION In this section, we present node selection algorithms that operate within the greedy framework presented in the previous section.",
                "We first give a well-defined criteria for the page selection problem and provide experimental evidence that this criteria can effectively identify pages that optimize our problem objective (3).",
                "We then present our main al118 Research Track Paper gorithmic contribution of the paper, a method with linear running time that is derived from this page selection criteria.",
                "Finally, we give an intuitive analysis of our algorithm in terms of leaks and flows.",
                "We show that if only the flow is considered, then the resulting method is very similar to a widely used page selection heuristic [6]. 5.1 Formulation For a given page j in the global domain, we define the expanded local graph Fj: Fj = F s uT j 0 , (4) where uj is the zero-one vector containing the outlinks from F into page j, and s contains the inlinks from page j into the local domain.",
                "Note that we do not allow self-links in this framework.",
                "In practice, self-links are often removed, as they only serve to inflate a given pages PageRank.",
                "Observe that the inlinks into F from node j are not known until after node j is crawled.",
                "Therefore, we estimate this inlink vector as the expectation over inlink counts among the set of already crawled pages, s = F T e F T e 1 . (5) In practice, for any given page, this estimate may not reflect the true inlinks from that page.",
                "Furthermore, this expectation is sampled from the set of links within the crawled domain, whereas a better estimate would also use links from the global domain.",
                "However, the latter distribution is not known to a localized search engine, and we contend that the above estimate will, on average, be a better estimate than the uniform distribution, for example.",
                "Let the PageRank of F be f. We express the PageRank f+ j of the expanded local graph Fj as f+ j = (1 − xj)fj xj , (6) where xj is the PageRank of the candidate global node j, and fj is the L1-normalized PageRank vector restricted to the pages in F .",
                "Since directly optimizing our problem goal requires knowing the <br>global pagerank</br> p∗ , we instead propose to crawl those nodes that will have the greatest influence on the PageRanks of pages in the original local domain L: influence(j) = k∈L |fj[k] − f[k]| (7) = EL (fj − f) 1.",
                "Experimentally, the influence score is a very good predictor of our problem objective (3).",
                "For each candidate global node j, figure 1(a) shows the objective function value Global Diff(fj) as a function of the influence of page j.",
                "The local domain used here is a crawl of conservative political pages (we will provide more details about this dataset in section 6); we observed similar results in other domains.",
                "The correlation is quite strong, implying that the influence criteria can effectively identify pages that improve the <br>global pagerank</br> estimate.",
                "As a baseline, figure 1(b) compares our objective with an alternative criteria, outlink count.",
                "The outlink count is defined as the number of outlinks from the local domain to page j.",
                "The correlation here is much weaker. .00001 .0001 .001 .01 0.26 0.262 0.264 0.266 Influence Objective 1 10 100 1000 0.266 0.264 0.262 0.26 Outlink Count Objective (a) (b) Figure 1: (a) The correlation between our influence page selection criteria (7) and the actual objective function (3) value is quite strong. (b) This is in contrast to other criteria, such as outlink count, which exhibit a much weaker correlation. 5.2 Computation As described, for each candidate global page j, the influence score (7) must be computed.",
                "If fj is computed exactly for each global page j, then the PageRank algorithm would need to be run for each of the O(n) such global pages j we consider, resulting in an O(n2 ) computational cost for the node selection method.",
                "Thus, computing the exact value of fj will lead to a quadratic algorithm, and we must instead turn to methods of approximating this vector.",
                "The algorithm we present works by performing one power method iteration used by the PageRank algorithm (Algorithm 1).",
                "The convergence rate for the PageRank algorithm has been shown to equal the random surfer probability α [7, 11].",
                "Given a starting vector x(0) , if k PageRank iterations are performed, the current PageRank solution x(k) satisfies: x(k) − x∗ 1 = O(αk x(0) − x∗ 1), (8) where x∗ is the desired PageRank vector.",
                "Therefore, if only one iteration is performed, choosing a good starting vector is necessary to achieve an accurate approximation.",
                "We partition the PageRank matrix PFj , corresponding to the × subgraph Fj as: PFj = ˜F ˜s ˜uT j w , (9) where ˜F = αF (DF + diag(uj))−1 + (1 − α) e + 1 eT , ˜s = αs + (1 − α) e + 1 , ˜uj = α(DF + diag(uj))−1 uj + (1 − α) e + 1 , w = 1 − α + 1 , and diag(uj) is the diagonal matrix with the (i, i)th entry equal to one if the ith element of uj equals one, and is zero otherwise.",
                "We have assumed here that the random surfer vector is the uniform vector, and that L has no dangling links.",
                "These assumptions are not necessary and serve only to simplify discussion and analysis.",
                "A simple approach for estimating fj is the following.",
                "First, estimate the PageRank f+ j of Fj by computing one PageRank iteration over the matrix PFj , using the starting vector ν = f 0 .",
                "Then, estimate fj by removing the last 119 Research Track Paper component from our estimate of f+ j (i.e., the component corresponding to the added node j), and renormalizing.",
                "The problem with this approach is in the starting vector.",
                "Recall from (6) that xj is the PageRank of the added node j.",
                "The difference between the actual PageRank f+ j of PFj and the starting vector ν is ν − f+ j 1 = xj + f − (1 − xj)fj 1 ≥ xj + | f 1 − (1 − xj) fj 1| = xj + |xj| = 2xj.",
                "Thus, by (8), after one PageRank iteration, we expect our estimate of f+ j to still have an error of about 2αxj.",
                "In particular, for candidate nodes j with relatively high PageRank xj, this method will yield more inaccurate results.",
                "We will next present a method that eliminates this bias and runs in O(n) time. 5.2.1 Stochastic Complementation Since f+ j , as given in (6) is the PageRank of the matrix PFj , we have: fj(1 − xj) xj = ˜F ˜s ˜uT j w fj(1 − xj) xj = ˜F fj(1 − xj) + ˜sxj ˜uT j fj(1 − xj) + wxj .",
                "Solving the above system for fj can be shown to yield fj = ( ˜F + (1 − w)−1 ˜s˜uT j )fj. (10) The matrix S = ˜F +(1−w)−1 ˜s˜uT j is known as the stochastic complement of the column stochastic matrix PFj with respect to the sub matrix ˜F .",
                "The theory of stochastic complementation is well studied, and it can be shown the stochastic complement of an irreducible matrix (such as the PageRank matrix) is unique.",
                "Furthermore, the stochastic complement is also irreducible and therefore has a unique stationary distribution as well.",
                "For an extensive study, see [15].",
                "It can be easily shown that the sub-dominant eigenvalue of S is at most +1 α, where is the size of F .",
                "For sufficiently large , this value will be very close to α.",
                "This is important, as other properties of the PageRank algorithm, notably the algorithms sensitivity, are dependent on this value [11].",
                "In this method, we estimate the length vector fj by computing one PageRank iteration over the × stochastic complement S, starting at the vector f: fj ≈ Sf. (11) This is in contrast to the simple method outlined in the previous section, which first iterates over the ( + 1) × ( + 1) matrix PFj to estimate f+ j , and then removes the last component from the estimate and renormalizes to approximate fj.",
                "The problem with the latter method is in the choice of the ( + 1) length starting vector, ν. Consequently, the PageRank estimate given by the simple method differs from the true PageRank by at least 2αxj, where xj is the PageRank of page j.",
                "By using the stochastic complement, we can establish a tight lower bound of zero for this difference.",
                "To see this, consider the case in which a node k is added to F to form the augmented local subgraph Fk, and that the PageRank of this new graph is (1 − xk)f xk .",
                "Specifically, the addition of page k does not change the PageRanks of the pages in F , and thus fk = f. By construction of the stochastic complement, fk = Sfk, so the approximation given in equation (11) will yield the exact solution.",
                "Next, we present the computational details needed to efficiently compute the quantity fj −f 1 over all known global pages j.",
                "We begin by expanding the difference fj −f, where the vector fj is estimated as in (11), fj − f ≈ Sf − f = αF (DF + diag(uj))−1 f + (1 − α) e + 1 eT f +(1 − w)−1 (˜uT j f)˜s − f. (12) Note that the matrix (DF +diag(uj))−1 is diagonal.",
                "Letting o[k] be the outlink count for page k in F , we can express the kth diagonal element as: (DF + diag(uj))−1 [k, k] = 1 o[k]+1 if uj[k] = 1 1 o[k] if uj[k] = 0 Noting that (o[k] + 1)−1 = o[k]−1 − (o[k](o[k] + 1))−1 and rewriting this in matrix form yields (DF +diag(uj))−1 = D−1 F −D−1 F (DF +diag(uj))−1 diag(uj). (13) We use the same identity to express e + 1 = e − e ( + 1) . (14) Recall that, by definition, we have PF = αF D−1 F +(1−α)e .",
                "Substituting (13) and (14) in (12) yields fj − f ≈ (PF f − f) −αF D−1 F (DF + diag(uj))−1 diag(uj)f −(1 − α) e ( + 1) + (1 − w)−1 (˜uT j f)˜s = x + y + (˜uT j f)z, (15) noting that by definition, f = PF f, and defining the vectors x, y, and z to be x = −αF D−1 F (DF + diag(uj))−1 diag(uj)f (16) y = −(1 − α) e ( + 1) (17) z = (1 − w)−1 ˜s. (18) The first term x is a sparse vector, and takes non-zero values only for local pages k that are siblings of the global page j.",
                "We define (i, j) ∈ F if and only if F [j, i] = 1 (equivalently, page i links to page j) and express the value of the component x[k ] as: x[k ] = −α k:(k,k )∈F ,uj [k]=1 f[k] o[k](o[k] + 1) , (19) where o[k], as before, is the number of outlinks from page k in the local domain.",
                "Note that the last two terms, y and z are not dependent on the current global node j.",
                "Given the function hj(f) = y + (˜uT j f)z 1, the quantity fj − f 1 120 Research Track Paper can be expressed as fj − f 1 = k x[k] + y[k] + (˜uT j f)z[k] = k:x[k]=0 y[k] + (˜uT j f)z[k] + k:x[k]=0 x[k] + y[k] + (˜uT j f)z[k] = hj(f) − k:x[k]=0 y[k] + (˜uT j f)z[k] + k:x[k]=0 x[k] + y[k] + (˜uT j f)z[k] . (20) If we can compute the function hj in linear time, then we can compute each value of fj − f 1 using an additional amount of time that is proportional to the number of nonzero components in x.",
                "These optimizations are carried out in Algorithm 3.",
                "Note that (20) computes the difference between all components of f and fj, whereas our node selection criteria, given in (7), is restricted to the components corresponding to nodes in the original local domain L. Let us examine Algorithm 3 in more detail.",
                "First, the algorithm computes the outlink counts for each page in the local domain.",
                "The algorithm then computes the quantity ˜uT j f for each known global page j.",
                "This inner product can be written as (1 − α) 1 + 1 + α k:(k,j)∈Fout f[k] o[k] + 1 , where the second term sums over the set of local pages that link to page j.",
                "Since the total number of edges in Fout was assumed to have size O( ) (recall that is the number of pages in F ), the running time of this step is also O( ).",
                "The algorithm then computes the vectors y and z, as given in (17) and (18), respectively.",
                "The L1NormDiff method is called on the components of these vectors which correspond to the pages in L, and it estimates the value of EL(y + (˜uT j f)z) 1 for each page j.",
                "The estimation works as follows.",
                "First, the values of ˜uT j f are discretized uniformly into c values {a1, ..., ac}.",
                "The quantity EL(y + aiz) 1 is then computed for each discretized value of ai and stored in a table.",
                "To evaluate EL (y + az) 1 for some a ∈ [a1, ac], the closest discretized value ai is determined, and the corresponding entry in the table is used.",
                "The total running time for this method is linear in and the discretization parameter c (which we take to be a constant).",
                "We note that if exact values are desired, we have also developed an algorithm that runs in O( log ) time that is not described here.",
                "In the main loop, we compute the vector x, as defined in equation (16).",
                "The nested loops iterate over the set of pages in F that are siblings of page j.",
                "Typically, the size of this set is bounded by a constant.",
                "Finally, for each page j, the scores vector is updated over the set of non-zero components k of the vector x with k ∈ L. This set has size equal to the number of local siblings of page j, and is a subset of the total number of siblings of page j.",
                "Thus, each iteration of the main loop takes constant time, and the total running time of the main loop is O( ).",
                "Since we have assumed that the size of F will not grow larger than O(n), the total running time for the algorithm is O(n).",
                "Algorithm 3: Node Selection via Stochastic Complementation.",
                "SC-Select(F , Fout, f, k) Input: F : zero-one adjacency matrix of size corresponding to the current local subgraph, Fout: zero-one outlink matrix from F to global subgraph, f: PageRank of F , k: number of pages to return Output: pages: set of k pages to crawl next {Compute outlink sums for local subgraph} foreach (page j ∈ F ) o[j] ← k:(j,k)∈F F[j, k] end {Compute scalar ˜uT j f for each global node j } foreach (page j ∈ Fout) g[j] ← (1 − α) 1 +1 foreach (page k : (k, j) ∈ Fout) g[j] ← g[j] + α f[k] o[k]+1 end end {Compute vectors y and z as in (17) and (18) } y ← −(1 − α) e ( +1) z ← (1 − w)−1 ˜s {Approximate y + g[j] ∗ z 1 for all values g[j]} norm diffs ←L1NormDiffs(g, ELy, ELz) foreach (page j ∈ Fout) {Compute sparse vector x as in (19)} x ← 0 foreach (page k : (k, j) ∈ Fout) foreach (page k : (k, k ) ∈ F )) x[k ] ← x[k ] − f[k] o[k](o[k]+1) end end x ← αx scores[j] ← norm diffs[j] foreach (k : x[k] > 0 and page k ∈ L) scores[j] ← scores[j] − |y[k] + g[j] ∗ z[k]| +|x[k]+y[k]+g[j]∗z[k])| end end Return k pages with highest scores 5.2.2 PageRank Flows We now present an intuitive analysis of the stochastic complementation method by decomposing the change in PageRank in terms of leaks and flows.",
                "This analysis is motivated by the decomposition given in (15).",
                "PageRank flow is the increase in the local PageRanks originating from global page j.",
                "The flows are represented by the non-negative vector (˜uT j f)z (equations (15) and (18)).",
                "The scalar ˜uT j f can be thought of as the total amount of PageRank flow that page j has available to distribute.",
                "The vector z dictates how the flow is allocated to the local domain; the flow that local page k receives is proportional to (within a constant factor due to the random surfer vector) the expected number of its inlinks.",
                "The PageRank leaks represent the decrease in PageRank resulting from the addition of page j.",
                "The leakage can be quantified in terms of the non-positive vectors x and y (equations (16) and (17)).",
                "For vector x, we can see from equation (19) that the amount of PageRank leaked by a local page is proportional to the weighted sum of the Page121 Research Track Paper Ranks of its siblings.",
                "Thus, pages that have siblings with higher PageRanks (and low outlink counts) will experience more leakage.",
                "The leakage caused by y is an artifact of the random surfer vector.",
                "We will next show that if only the flow term, (˜uT j f)z, is considered, then the resulting method is very similar to a heuristic proposed by Cho et al. [6] that has been widely used for the Crawling Through URL Ordering problem.",
                "This heuristic is computationally cheaper, but as we will see later, not as effective as the Stochastic Complementation method.",
                "Our node selection strategy chooses global nodes that have the largest influence (equation (7)).",
                "If this influence is approximated using only flows, the optimal node j∗ is: j∗ = argmaxj EL ˜uT j fz 1 = argmaxj ˜uT j f EL z 1 = argmaxj ˜uT j f = argmaxj α(DF + diag(uj))−1 uj + (1 − α) e + 1 , f = argmaxjfT (DF + diag(uj))−1 uj.",
                "The resulting page selection score can be expressed as a sum of the PageRanks of each local page k that links to j, where each PageRank value is normalized by o[k]+1.",
                "Interestingly, the normalization that arises in our method differs from the heuristic given in [6], which normalizes by o[k].",
                "The algorithm PF-Select, which is omitted due to lack of space, first computes the quantity fT (DF +diag(uj))−1 uj for each global page j, and then returns the pages with the k largest scores.",
                "To see that the running time for this algorithm is O(n), note that the computation involved in this method is a subset of that needed for the SC-Select method (Algorithm 3), which was shown to have a running time of O(n). 6.",
                "EXPERIMENTS In this section, we provide experimental evidence to verify the effectiveness of our algorithms.",
                "We first outline our experimental methodology and then provide results across a variety of local domains. 6.1 Methodology Given the limited resources available at an academic institution, crawling a section of the web that is of the same magnitude as that indexed by Google or Yahoo! is clearly infeasible.",
                "Thus, for a given local domain, we approximate the global graph by crawling a local neighborhood around the domain that is several orders of magnitude larger than the local subgraph.",
                "Even though such a graph is still orders of magnitude smaller than the true global graph, we contend that, even if there exist some highly influential pages that are very far away from our local domain, it is unrealistic for any local node selection algorithm to find them.",
                "Such pages also tend to be highly unrelated to pages within the local domain.",
                "When explaining our node selection strategies in section 5, we made the simplifying assumption that our local graph contained no dangling nodes.",
                "This assumption was only made to ease our analysis.",
                "Our implementation efficiently handles dangling links by replacing each zero column of our adjacency matrix with the uniform vector.",
                "We evaluate the algorithm using the two node selection strategies given in Section 5.2, and also against the following baseline methods: • Random: Nodes are chosen uniformly at random among the known global nodes. • OutlinkCount: Global nodes with the highest number of outlinks from the local domain are chosen.",
                "At each iteration of the FindGlobalPR algorithm, we evaluate performance by computing the difference between the current PageRank estimate of the local domain, ELf ELf 1 , and the <br>global pagerank</br> of the local domain ELg ELg 1 .",
                "All PageRank calculations were performed using the uniform random surfer vector.",
                "Across all experiments, we set the random surfer parameter α, to be .85, and used a convergence threshold of 10−6 .",
                "We evaluate the difference between the local and <br>global pagerank</br> vectors using three different metrics: the L1 and L∞ norms, and Kendalls tau.",
                "The L1 norm measures the sum of the absolute value of the differences between the two vectors, and the L∞ norm measures the absolute value of the largest difference.",
                "Kendalls tau metric is a popular rank correlation measure used to compare PageRanks [2, 11].",
                "This metric can be computed by counting the number of pairs of pairs that agree in ranking, and subtracting from that the number of pairs of pairs that disagree in ranking.",
                "The final value is then normalized by the total number of n 2 such pairs, resulting in a [−1, 1] range, where a negative score signifies anti-correlation among rankings, and values near one correspond to strong rank correlation. 6.2 Results Our experiments are based on two large web crawls and were downloaded using the web crawler that is part of the Nutch open source search engine project [18].",
                "All crawls were restricted to only http pages, and to limit the number of dynamically generated pages that we crawl, we ignored all pages with urls containing any of the characters ?, *, @, or =.",
                "The first crawl, which we will refer to as the edu dataset, was seeded by homepages of the top 100 graduate computer science departments in the USA, as rated by the US News and World Report [16], and also by the home pages of their respective institutions.",
                "A crawl of depth 5 was performed, restricted to pages within the .edu domain, resulting in a graph with approximately 4.7 million pages and 22.9 million links.",
                "The second crawl was seeded by the set of pages under the politics hierarchy in the dmoz open directory project[17].",
                "We crawled all pages up to four links away, which yielded a graph with 4.4 million pages and 17.3 million links.",
                "Within the edu crawl, we identified the five site-specific domains corresponding to the websites of the top five graduate computer science departments, as ranked by the US News and World Report.",
                "This yielded local domains of various sizes, from 10,626 (UIUC) to 59,895 (Berkeley).",
                "For each of these site-specific domains with size n, we performed 50 iterations of the FindGlobalPR algorithm to crawl a total of 2n additional nodes.",
                "Figure 2(a) gives the (L1) difference from the PageRank estimate at each iteration to the <br>global pagerank</br>, for the Berkeley local domain.",
                "The performance of this dataset was representative of the typical performance across the five computer science sitespecific local domains.",
                "Initially, the L1 difference between the global and local PageRanks ranged from .0469 (Stanford) to .149 (MIT).",
                "For the first several iterations, the 122 Research Track Paper 0 5 10 15 20 25 30 35 40 45 50 0.015 0.02 0.025 0.03 0.035 0.04 0.045 0.05 0.055 Number of Iterations GlobalandLocalPageRankDifference(L1) Stochastic Complement PageRank Flow Outlink Count Random 0 10 20 30 40 50 0 0.05 0.1 0.15 0.2 0.25 0.3 0.35 Number of Iterations GlobalandLocalPageRankDifference(L1) Stochastic Complement PageRank Flow Outlink Count Random 0 5 10 15 20 25 0.16 0.18 0.2 0.22 0.24 0.26 0.28 0.3 0.32 0.34 Number of Iterations GlobalandLocalPageRankDifference(L1) Stochastic Complement PageRank Flow Outlink Count Random (a) www.cs.berkeley.edu (b) www.enterstageright.com (c) Politics Figure 2: L1 difference between the estimated and true global PageRanks for (a) Berkeleys computer science website, (b) the site-specific domain, www.enterstageright.com, and (c) the politics topic-specific domain.",
                "The stochastic complement method outperforms all other methods across various domains. three link-based methods all outperform the random selection heuristic.",
                "After these initial iterations, the random heuristic tended to be more competitive with (or even outperform, as in the Berkeley local domain) the outlink count and PageRank flow heuristics.",
                "In all tests, the stochastic complementation method either outperformed, or was competitive with, the other methods.",
                "Table 1 gives the average difference between the final estimated global PageRanks and the true global PageRanks for various distance measures.",
                "Algorithm L1 L∞ Kendall Stoch.",
                "Comp. .0384 .00154 .9257 PR Flow .0470 .00272 .8946 Outlink .0419 .00196 .9053 Random .0407 .00204 .9086 Table 1: Average final performance of various node selection strategies for the five site-specific computer science local domains.",
                "Note that Kendalls Tau measures similarity, while the other metrics are dissimilarity measures.",
                "Stochastic Complementation clearly outperforms the other methods in all metrics.",
                "Within the politics dataset, we also performed two sitespecific tests for the largest websites in the crawl: www.adamsmith.org, the website for the London based Adam Smith Institute, and www.enterstageright.com, an online conservative journal.",
                "As with the edu local domains, we ran our algorithm for 50 iterations, crawling a total of 2n nodes.",
                "Figure 2 (b) plots the results for the www.enterstageright.com domain.",
                "In contrast to the edu local domains, the Random and OutlinkCount methods were not competitive with either the SC-Select or the PF-Select methods.",
                "Among all datasets and all node selection methods, the stochastic complementation method was most impressive in this dataset, realizing a final estimate that differed only .0279 from the <br>global pagerank</br>, a ten-fold improvement over the initial local PageRank difference of .299.",
                "For the Adam Smith local domain, the initial difference between the local and global PageRanks was .148, and the final estimates given by the SC-Select, PF-Select, OutlinkCount, and Random methods were .0208, .0193, .0222, and .0356, respectively.",
                "Within the politics dataset, we constructed four topicspecific local domains.",
                "The first domain consisted of all pages in the dmoz politics category, and also all pages within each of these sites up to two links away.",
                "This yielded a local domain of 90,811 pages, and the results are given in figure 2 (c).",
                "Because of the larger size of the topic-specific domains, we ran our algorithm for only 25 iterations to crawl a total of n nodes.",
                "We also created topic-specific domains from three political sub-topics: liberalism, conservatism, and socialism.",
                "The pages in these domains were identified by their corresponding dmoz categories.",
                "For each sub-topic, we set the local domain to be all pages within three links from the corresponding dmoz category pages.",
                "Table 2 summarizes the performance of these three topic-specific domains, and also the larger political domain.",
                "To quantify a global page js effect on the <br>global pagerank</br> values of pages in the local domain, we define page js impact to be its PageRank value, g[j], normalized by the fraction of its outlinks pointing to the local domain: impact(j) = oL[j] o[j] · g[j], where, oL[j] is the number of outlinks from page j to pages in the local domain L, and o[j] is the total number of js outlinks.",
                "In terms of the random surfer model, the impact of page j is the probability that the random surfer (1) is currently at global page j in her random walk and (2) takes an outlink to a local page, given that she has already decided not to jump to a random page.",
                "For the politics local domain, we found that many of the pages with high impact were in fact political pages that should have been included in the dmoz politics topic, but were not.",
                "For example, the two most influential global pages were the political search engine www.askhenry.com, and the home page of the online political magazine, www.policyreview.com.",
                "Among non-political pages, the home page of the journal Education Next was most influential.",
                "The journal is freely available online and contains articles regarding various aspect of K-12 education in America.",
                "To provide some anecdotal evidence for the effectiveness of our page selection methods, we note that the SC-Select method chose 11 pages within the www.educationnext.org domain, the PF-Select method discovered 7 such pages, while the OutlinkCount and Random methods found only 6 pages each.",
                "For the conservative political local domain, the socialist website www.ornery.org had a very high impact score.",
                "This 123 Research Track Paper All Politics: Algorithm L1 L2 Kendall Stoch.",
                "Comp. .1253 .000700 .8671 PR Flow .1446 .000710 .8518 Outlink .1470 .00225 .8642 Random .2055 .00203 .8271 Conservativism: Algorithm L1 L2 Kendall Stoch.",
                "Comp. .0496 .000990 .9158 PR Flow .0554 .000939 .9028 Outlink .0602 .00527 .9144 Random .1197 .00102 .8843 Liberalism: Algorithm L1 L2 Kendall Stoch.",
                "Comp. .0622 .001360 .8848 PR Flow .0799 .001378 .8669 Outlink .0763 .001379 .8844 Random .1127 .001899 .8372 Socialism: Algorithm L1 L∞ Kendall Stoch.",
                "Comp. .04318 .00439 .9604 PR Flow .0450 .004251 .9559 Outlink .04282 .00344 .9591 Random .0631 .005123 .9350 Table 2: Final performance among node selection strategies for the four political topic-specific crawls.",
                "Note that Kendalls Tau measures similarity, while the other metrics are dissimilarity measures. was largely due to a link from the front page of this site to an article regarding global warming published by the National Center for Public Policy Research, a conservative research group in Washington, DC.",
                "Not surprisingly, the <br>global pagerank</br> of this article (which happens to be on the home page of the NCCPR, www.nationalresearch.com), was approximately .002, whereas the local PageRank of this page was only .00158.",
                "The SC-Select method yielded a <br>global pagerank</br> estimate of approximately .00182, the PFSelect method estimated a value of .00167, and the Random and OutlinkCount methods yielded values of .01522 and .00171, respectively. 7.",
                "RELATED WORK The node selection framework we have proposed is similar to the url ordering for crawling problem proposed by Cho et al. in [6].",
                "Whereas our framework seeks to minimize the difference between the global and local PageRank, the objective used in [6] is to crawl the most highly (globally) ranked pages first.",
                "They propose several node selection algorithms, including the outlink count heuristic, as well as a variant of our PF-Select algorithm which they refer to as the PageRank ordering metric.",
                "They found this method to be most effective in optimizing their objective, as did a recent survey of these methods by Baeza-Yates et al. [1].",
                "Boldi et al. also experiment within a similar crawling framework in [2], but quantify their results by comparing Kendalls rank correlation between the PageRanks of the current set of crawled pages and those of the entire global graph.",
                "They found that node selection strategies that crawled pages with the highest <br>global pagerank</br> first actually performed worse (with respect to Kendalls Tau correlation between the local and global PageRanks) than basic depth first or breadth first strategies.",
                "However, their experiments differ from our work in that our node selection algorithms do not use (or have access to) <br>global pagerank</br> values.",
                "Many algorithmic improvements for computing exact PageRank values have been proposed [9, 10, 14].",
                "If such algorithms are used to compute the global PageRanks of our local domain, they would all require O(N) computation, storage, and bandwidth, where N is the size of the global domain.",
                "This is in contrast to our method, which approximates the <br>global pagerank</br> and scales linearly with the size of the local domain.",
                "Wang and Dewitt [22] propose a system where the set of web servers that comprise the global domain communicate with each other to compute their respective global PageRanks.",
                "For a given web server hosting n pages, the computational, bandwidth, and storage requirements are also linear in n. One drawback of this system is that the number of distinct web servers that comprise the global domain can be very large.",
                "For example, our edu dataset contains websites from over 3,200 different universities; coordinating such a system among a large number of sites can be very difficult.",
                "Gan, Chen, and Suel propose a method for estimating the PageRank of a single page [5] which uses only constant bandwidth, computation, and space.",
                "Their approach relies on the availability of a remote connectivity server that can supply the set of inlinks to a given page, an assumption not used in our framework.",
                "They experimentally show that a reasonable estimate of the nodes PageRank can be obtained by visiting at most a few hundred nodes.",
                "Using their algorithm for our problem would require that either the entire global domain first be downloaded or a connectivity server be used, both of which would lead to very large web graphs. 8.",
                "CONCLUSIONS AND FUTURE WORK The internet is growing exponentially, and in order to navigate such a large repository as the web, global search engines have established themselves as a necessity.",
                "Along with the ubiquity of these large-scale search engines comes an increase in search users expectations.",
                "By providing complete and isolated coverage of a particular web domain, localized search engines are an effective outlet to quickly locate content that could otherwise be difficult to find.",
                "In this work, we contend that the use of <br>global pagerank</br> in a localized search engine can improve performance.",
                "To estimate the <br>global pagerank</br>, we have proposed an iterative node selection framework where we select which pages from the global frontier to crawl next.",
                "Our primary contribution is our stochastic complementation page selection algorithm.",
                "This method crawls nodes that will most significantly impact the local domain and has running time linear in the number of nodes in the local domain.",
                "Experimentally, we validate these methods across a diverse set of local domains, including seven site-specific domains and four topic-specific domains.",
                "We conclude that by crawling an additional n or 2n pages, our methods find an estimate of the global PageRanks that is up to ten times better than just using the local PageRanks.",
                "Furthermore, we demonstrate that our algorithm consistently outperforms other existing heuristics. 124 Research Track Paper Often times, topic-specific domains are discovered using a focused web crawler which considers a pages content in conjunction with link anchor text to decide which pages to crawl next [4].",
                "Although such crawlers have proven to be quite effective in discovering topic-related content, many irrelevant pages are also crawled in the process.",
                "Typically, these pages are deleted and not indexed by the localized search engine.",
                "These pages can of course provide valuable information regarding the <br>global pagerank</br> of the local domain.",
                "One way to integrate these pages into our framework is to start the FindGlobalPR algorithm with the current subgraph F equal to the set of pages that were crawled by the focused crawler.",
                "The <br>global pagerank</br> estimation framework, along with the node selection algorithms presented, all require O(n) computation per iteration and bandwidth proportional to the number of pages crawled, Tk.",
                "If the number of iterations T is relatively small compared to the number of pages crawled per iteration, k, then the bottleneck of the algorithm will be the crawling phase.",
                "However, as the number of iterations increases (relative to k), the bottleneck will reside in the node selection computation.",
                "In this case, our algorithms would benefit from constant factor optimizations.",
                "Recall that the FindGlobalPR algorithm (Algorithm 2) requires that the PageRanks of the current expanded local domain be recomputed in each iteration.",
                "Recent work by Langville and Meyer [12] gives an algorithm to quickly recompute PageRanks of a given webgraph if a small number of nodes are added.",
                "This algorithm was shown to give speedup of five to ten times on some datasets.",
                "We plan to investigate this and other such optimizations as future work.",
                "In this paper, we have objectively evaluated our methods by measuring how close our <br>global pagerank</br> estimates are to the actual global PageRanks.",
                "To determine the benefit of using global PageRanks in a localized search engine, we suggest a user study in which users are asked to rate the quality of search results for various search queries.",
                "For some queries, only the local PageRanks are used in ranking, and for the remaining queries, local PageRanks and the approximate global PageRanks, as computed by our algorithms, are used.",
                "The results of such a study can then be analyzed to determine the added benefit of using the global PageRanks computed by our methods, over just using the local PageRanks.",
                "Acknowledgements.",
                "This research was supported by NSF grant CCF-0431257, NSF Career Award ACI-0093404, and a grant from Sabre, Inc. 9.",
                "REFERENCES [1] R. Baeza-Yates, M. Marin, C. Castillo, and A. Rodriguez.",
                "Crawling a country: better strategies than breadth-first for web page ordering.",
                "World-Wide Web Conference, 2005. [2] P. Boldi, M. Santini, and S. Vigna.",
                "Do your worst to make the best: paradoxical effects in pagerank incremental computations.",
                "Workshop on Web Graphs, 3243:168-180, 2004. [3] S. Brin and L. Page.",
                "The anatomy of a large-scale hypertextual web search engine.",
                "Computer Networks and ISDN Systems, 33(1-7):107-117, 1998. [4] S. Chakrabarti, M. van den Berg, and B. Dom.",
                "Focused crawling: a new approach to topic-specific web resource discovery.",
                "World-Wide Web Conference, 1999. [5] Y. Chen, Q. Gan, and T. Suel.",
                "Local methods for estimating pagerank values.",
                "Conference on Information and Knowledge Management, 2004. [6] J. Cho, H. Garcia-Molina, and L. Page.",
                "Efficient crawling through url ordering.",
                "World-Wide Web Conference, 1998. [7] T. H. Haveliwala and S. D. Kamvar.",
                "The second eigenvalue of the Google matrix.",
                "Technical report, Stanford University, 2003. [8] T. Joachims, F. Radlinski, L. Granka, A. Cheng, C. Tillekeratne, and A. Patel.",
                "Learning retrieval functions from implicit feedback. http://www.cs.cornell.edu/People/tj/career. [9] S. D. Kamvar, T. H. Haveliwala, C. D. Manning, and G. H. Golub.",
                "Exploiting the block structure of the web for computing pagerank.",
                "World-Wide Web Conference, 2003. [10] S. D. Kamvar, T. H. Haveliwala, C. D. Manning, and G. H. Golub.",
                "Extrapolation methods for accelerating pagerank computation.",
                "World-Wide Web Conference, 2003. [11] A. N. Langville and C. D. Meyer.",
                "Deeper inside pagerank.",
                "Internet Mathematics, 2004. [12] A. N. Langville and C. D. Meyer.",
                "Updating the stationary vector of an irreducible markov chain with an eye on Googles pagerank.",
                "SIAM Journal on Matrix Analysis, 2005. [13] P. Lyman, H. R. Varian, K. Swearingen, P. Charles, N. Good, L. L. Jordan, and J. Pal.",
                "How much information 2003?",
                "School of Information Management and System, University of California at Berkely, 2003. [14] F. McSherry.",
                "A uniform approach to accelerated pagerank computation.",
                "World-Wide Web Conference, 2005. [15] C. D. Meyer.",
                "Stochastic complementation, uncoupling markov chains, and the theory of nearly reducible systems.",
                "SIAM Review, 31:240-272, 1989. [16] US News and World Report. http://www.usnews.com. [17] Dmoz open directory project. http://www.dmoz.org. [18] Nutch open source search engine. http://www.nutch.org. [19] F. Radlinski and T. Joachims.",
                "Query chains: learning to rank from implicit feedback.",
                "ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, 2005. [20] S. Raghavan and H. Garcia-Molina.",
                "Crawling the hidden web.",
                "In Proceedings of the Twenty-seventh International Conference on Very Large Databases, 2001. [21] T. Tin Tang, D. Hawking, N. Craswell, and K. Griffiths.",
                "Focused crawling for both topical relevance and quality of medical information.",
                "Conference on Information and Knowledge Management, 2005. [22] Y. Wang and D. J. DeWitt.",
                "Computing pagerank in a distributed internet search system.",
                "Proceedings of the 30th VLDB Conference, 2004. 125 Research Track Paper"
            ],
            "original_annotated_samples": [
                "Estimating the <br>global pagerank</br> of Web Communities Jason V. Davis Dept.",
                "One disadvantage such systems have over large-scale search engines is the lack of <br>global pagerank</br> values.",
                "In this paper, we present well-motivated algorithms to estimate the <br>global pagerank</br> values of a local domain.",
                "We demonstrate that by crawling as few as n or 2n additional pages, our methods can give excellent <br>global pagerank</br> estimates.",
                "To evaluate performance, we measure the difference between the current <br>global pagerank</br> estimate and the <br>global pagerank</br>, as a function of the number of pages crawled."
            ],
            "translated_annotated_samples": [
                "Estimando el <br>PageRank Global</br> de Comunidades Web Jason V. Davis Dept.",
                "Una desventaja que tienen estos sistemas en comparación con los motores de búsqueda a gran escala es la falta de valores globales de PageRank.",
                "En este artículo, presentamos algoritmos bien fundamentados para estimar los valores globales de PageRank de un dominio local.",
                "Demostramos que al rastrear tan solo n o 2n páginas adicionales, nuestros métodos pueden proporcionar excelentes estimaciones globales de PageRank.",
                "Para evaluar el rendimiento, medimos la diferencia entre la estimación actual del <br>PageRank global</br> y el <br>PageRank global</br>, en función del número de páginas rastreadas."
            ],
            "translated_text": "Estimando el <br>PageRank Global</br> de Comunidades Web Jason V. Davis Dept. Departamento de Ciencias de la Computación Universidad de Texas en Austin Austin, TX 78712 jdavis@cs.utexas.edu Inderjit S. Dhillon Departamento de Ciencias de la Computación Universidad de Texas en Austin Austin, TX 78712 inderjit@cs.utexas.edu RESUMEN Los motores de búsqueda localizados son sistemas a pequeña escala que indexan una comunidad particular en la web. Ofrecen varios beneficios en comparación con sus contrapartes a gran escala, ya que son relativamente económicos de construir y pueden proporcionar una capacidad de búsqueda más precisa y completa en sus dominios relevantes. Una desventaja que tienen estos sistemas en comparación con los motores de búsqueda a gran escala es la falta de valores globales de PageRank. Se necesita esa información para evaluar el valor de las páginas en el dominio de búsqueda localizada dentro del contexto de la web en su totalidad. En este artículo, presentamos algoritmos bien fundamentados para estimar los valores globales de PageRank de un dominio local. Los algoritmos son altamente escalables en el sentido de que, dado un dominio local de tamaño n, utilizan recursos de O(n) que incluyen tiempo de computación, ancho de banda y almacenamiento. Probamos nuestros métodos en una variedad de dominios localizados, incluyendo dominios específicos del sitio y dominios específicos del tema. Demostramos que al rastrear tan solo n o 2n páginas adicionales, nuestros métodos pueden proporcionar excelentes estimaciones globales de PageRank. Categorías y Descriptores de Asignaturas H.3.3 [Almacenamiento y Recuperación de Información]: Búsqueda y Recuperación de Información; G.1.3 [Análisis Numérico]: Álgebra Lineal Numérica; G.3 [Probabilidad y Estadística]: Procesos de Markov Términos Generales PageRank, Cadena de Markov, Complementación Estocástica. Los motores de búsqueda localizados son motores de búsqueda a pequeña escala que indexan solo una comunidad específica de la web. Tales comunidades pueden ser dominios específicos del sitio, como páginas dentro del dominio cs.utexas.edu, o comunidades relacionadas con un tema, por ejemplo, sitios web políticos. En comparación con el grafo web rastreado e indexado por los motores de búsqueda a gran escala, el tamaño de estas comunidades locales suele ser típicamente órdenes de magnitud más pequeño. Por consiguiente, los recursos computacionales necesarios para construir un motor de búsqueda de este tipo también son igualmente más ligeros. Al restringirse a secciones más pequeñas y manejables de la web, los motores de búsqueda localizados también pueden ofrecer capacidades de búsqueda más precisas y completas dentro de sus respectivos dominios. Una desventaja de los índices localizados es la falta de información global necesaria para calcular clasificaciones basadas en enlaces. El algoritmo PageRank [3] ha demostrado ser una medida efectiva de este tipo. En general, el PageRank de una página dada depende de las páginas en todo el grafo web. En el contexto de un motor de búsqueda localizado, si los PageRanks se calculan utilizando solo el subgrafo local, entonces esperaríamos que los PageRanks resultantes reflejen la popularidad percibida dentro de la comunidad local y no de la web en su totalidad. Por ejemplo, consideremos un motor de búsqueda localizado que indexa páginas políticas con puntos de vista conservadores. Una persona que desee investigar las opiniones sobre el calentamiento global dentro de la comunidad política conservadora puede encontrarse con numerosas opiniones de este tipo en varios sitios web. Si solo se dispone de valores de PageRank locales, entonces los resultados de búsqueda reflejarán solo creencias fuertemente arraigadas dentro de la comunidad. Sin embargo, si los PageRanks globales también están disponibles, entonces los resultados pueden reflejar adicionalmente las opiniones de los externos sobre la comunidad conservadora (es decir, aquellos documentos a los que los liberales acceden con mayor frecuencia dentro de la comunidad conservadora). Por lo tanto, para muchos motores de búsqueda localizados, la incorporación de PageRanks globales puede mejorar la calidad de los resultados de búsqueda. Sin embargo, el número de páginas que indexa un motor de búsqueda local suele ser órdenes de magnitud más pequeño que el número de páginas indexadas por sus contrapartes a gran escala. Los motores de búsqueda localizados no tienen el ancho de banda, la capacidad de almacenamiento o la potencia computacional para rastrear, descargar y calcular los PageRanks globales de toda la web. En este trabajo, presentamos un método para aproximar los PageRanks globales de un dominio local utilizando recursos del mismo orden que los necesarios para calcular los PageRanks del subgrafo local. Nuestro método propuesto busca un supergrafo de nuestro subgrafo local de manera que los PageRanks locales dentro de este supergrafo estén cerca de los verdaderos PageRanks globales. Construimos este supergrafo mediante el rastreo iterativo de páginas globales en la frontera web actual, es decir, páginas globales con enlaces entrantes de páginas que ya han sido rastreadas. Para proporcionar a 116 Research Track Paper una buena aproximación a los PageRanks globales, es necesario tener cuidado al elegir qué páginas rastrear a continuación; en este documento, presentamos un algoritmo de selección de páginas bien fundamentado que también tiene un buen rendimiento empírico. Este algoritmo se deriva de un objetivo de problema bien definido y tiene un tiempo de ejecución lineal en el número de nodos locales. Experimentamos en varios tipos de subgrafos locales, incluidas cuatro comunidades relacionadas con el tema y varios dominios específicos del sitio. Para evaluar el rendimiento, medimos la diferencia entre la estimación actual del <br>PageRank global</br> y el <br>PageRank global</br>, en función del número de páginas rastreadas. ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "web community": {
            "translated_key": "comunidad web",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Estimating the Global PageRank of Web Communities Jason V. Davis Dept.",
                "of Computer Sciences University of Texas at Austin Austin, TX 78712 jdavis@cs.utexas.edu Inderjit S. Dhillon Dept. of Computer Sciences University of Texas at Austin Austin, TX 78712 inderjit@cs.utexas.edu ABSTRACT Localized search engines are small-scale systems that index a particular community on the web.",
                "They offer several benefits over their large-scale counterparts in that they are relatively inexpensive to build, and can provide more precise and complete search capability over their relevant domains.",
                "One disadvantage such systems have over large-scale search engines is the lack of global PageRank values.",
                "Such information is needed to assess the value of pages in the localized search domain within the context of the web as a whole.",
                "In this paper, we present well-motivated algorithms to estimate the global PageRank values of a local domain.",
                "The algorithms are all highly scalable in that, given a local domain of size n, they use O(n) resources that include computation time, bandwidth, and storage.",
                "We test our methods across a variety of localized domains, including site-specific domains and topic-specific domains.",
                "We demonstrate that by crawling as few as n or 2n additional pages, our methods can give excellent global PageRank estimates.",
                "Categories and Subject Descriptors H.3.3 [Information Storage and Retrieval]: Information Search and Retrieval; G.1.3 [Numerical Analysis]: Numerical Linear Algebra; G.3 [Probability and Statistics]: Markov Processes General Terms PageRank, Markov Chain, Stochastic Complementation 1.",
                "INTRODUCTION Localized search engines are small-scale search engines that index only a single community of the web.",
                "Such communities can be site-specific domains, such as pages within the cs.utexas.edu domain, or topic-related communitiesfor example, political websites.",
                "Compared to the web graph crawled and indexed by large-scale search engines, the size of such local communities is typically orders of magnitude smaller.",
                "Consequently, the computational resources needed to build such a search engine are also similarly lighter.",
                "By restricting themselves to smaller, more manageable sections of the web, localized search engines can also provide more precise and complete search capabilities over their respective domains.",
                "One drawback of localized indexes is the lack of global information needed to compute link-based rankings.",
                "The PageRank algorithm [3], has proven to be an effective such measure.",
                "In general, the PageRank of a given page is dependent on pages throughout the entire web graph.",
                "In the context of a localized search engine, if the PageRanks are computed using only the local subgraph, then we would expect the resulting PageRanks to reflect the perceived popularity within the local community and not of the web as a whole.",
                "For example, consider a localized search engine that indexes political pages with conservative views.",
                "A person wishing to research the opinions on global warming within the conservative political community may encounter numerous such opinions across various websites.",
                "If only local PageRank values are available, then the search results will reflect only strongly held beliefs within the community.",
                "However, if global PageRanks are also available, then the results can additionally reflect outsiders views of the conservative community (those documents that liberals most often access within the conservative community).",
                "Thus, for many localized search engines, incorporating global PageRanks can improve the quality of search results.",
                "However, the number of pages a local search engine indexes is typically orders of magnitude smaller than the number of pages indexed by their large-scale counterparts.",
                "Localized search engines do not have the bandwidth, storage capacity, or computational power to crawl, download, and compute the global PageRanks of the entire web.",
                "In this work, we present a method of approximating the global PageRanks of a local domain while only using resources of the same order as those needed to compute the PageRanks of the local subgraph.",
                "Our proposed method looks for a supergraph of our local subgraph such that the local PageRanks within this supergraph are close to the true global PageRanks.",
                "We construct this supergraph by iteratively crawling global pages on the current web frontier-i.e., global pages with inlinks from pages that have already been crawled.",
                "In order to provide 116 Research Track Paper a good approximation to the global PageRanks, care must be taken when choosing which pages to crawl next; in this paper, we present a well-motivated page selection algorithm that also performs well empirically.",
                "This algorithm is derived from a well-defined problem objective and has a running time linear in the number of local nodes.",
                "We experiment across several types of local subgraphs, including four topic related communities and several sitespecific domains.",
                "To evaluate performance, we measure the difference between the current global PageRank estimate and the global PageRank, as a function of the number of pages crawled.",
                "We compare our algorithm against several heuristics and also against a baseline algorithm that chooses pages at random, and we show that our method outperforms these other methods.",
                "Finally, we empirically demonstrate that, given a local domain of size n, we can provide good approximations to the global PageRank values by crawling at most n or 2n additional pages.",
                "The paper is organized as follows.",
                "Section 2 gives an overview of localized search engines and outlines their advantages over global search.",
                "Section 3 provides background on the PageRank algorithm.",
                "Section 4 formally defines our problem, and section 5 presents our page selection criteria and derives our algorithms.",
                "Section 6 provides experimental results, section 7 gives an overview of related work, and, finally, conclusions are given in section 8. 2.",
                "LOCALIZED SEARCH ENGINES Localized search engines index a single community of the web, typically either a site-specific community, or a topicspecific community.",
                "Localized search engines enjoy three major advantages over their large-scale counterparts: they are relatively inexpensive to build, they can offer more precise search capability over their local domain, and they can provide a more complete index.",
                "The resources needed to build a global search engine are enormous.",
                "A 2003 study by Lyman et al. [13] found that the surface web (publicly available static sites) consists of 8.9 billion pages, and that the average size of these pages is approximately 18.7 kilobytes.",
                "To download a crawl of this size, approximately 167 terabytes of space is needed.",
                "For a researcher who wishes to build a search engine with access to a couple of workstations or a small server, storage of this magnitude is simply not available.",
                "However, building a localized search engine over a <br>web community</br> of a hundred thousand pages would only require a few gigabytes of storage.",
                "The computational burden required to support search queries over a database this size is more manageable as well.",
                "We note that, for topic-specific search engines, the relevant community can be efficiently identified and downloaded by using a focused crawler [21, 4].",
                "For site-specific domains, the local domain is readily available on their own web server.",
                "This obviates the need for crawling or spidering, and a complete and up-to-date index of the domain can thus be guaranteed.",
                "This is in contrast to their large-scale counterparts, which suffer from several shortcomings.",
                "First, crawling dynamically generated pages-pages in the hidden web-has been the subject of research [20] and is a non-trivial task for an external crawler.",
                "Second, site-specific domains can enable the robots exclusion policy.",
                "This prohibits external search engines crawlers from downloading content from the domain, and an external search engine must instead rely on outside links and anchor text to index these restricted pages.",
                "By restricting itself to only a specific domain of the internet, a localized search engine can provide more precise search results.",
                "Consider the canonical ambiguous search query, jaguar, which can refer to either the car manufacturer or the animal.",
                "A scientist trying to research the habitat and evolutionary history of a jaguar may have better success using a finely tuned zoology-specific search engine than querying Google with multiple keyword searches and wading through irrelevant results.",
                "A method to learn better ranking functions for retrieval was recently proposed by Radlinski and Joachims [19] and has been applied to various local domains, including Cornell Universitys website [8]. 3.",
                "PAGERANK OVERVIEW The PageRank algorithm defines the importance of web pages by analyzing the underlying hyperlink structure of a web graph.",
                "The algorithm works by building a Markov chain from the link structure of the web graph and computing its stationary distribution.",
                "One way to compute the stationary distribution of a Markov chain is to find the limiting distribution of a random walk over the chain.",
                "Thus, the PageRank algorithm uses what is sometimes referred to as the random surfer model.",
                "In each step of the random walk, the surfer either follows an outlink from the current page (i.e. the current node in the chain), or jumps to a random page on the web.",
                "We now precisely define the PageRank problem.",
                "Let U be an m × m adjacency matrix for a given web graph such that Uji = 1 if page i links to page j and Uji = 0 otherwise.",
                "We define the PageRank matrix PU to be: PU = αUD−1 U + (1 − α)veT , (1) where DU is the (unique) diagonal matrix such that UD−1 U is column stochastic, α is a given scalar such that 0 ≤ α ≤ 1, e is the vector of all ones, and v is a non-negative, L1normalized vector, sometimes called the random surfer vector.",
                "Note that the matrix D−1 U is well-defined only if each column of U has at least one non-zero entry-i.e., each page in the webgraph has at least one outlink.",
                "In the presence of such dangling nodes that have no outlinks, one commonly used solution, proposed by Brin et al. [3], is to replace each zero column of U by a non-negative, L1-normalized vector.",
                "The PageRank vector r is the dominant eigenvector of the PageRank matrix, r = PU r. We will assume, without loss of generality, that r has an L1-norm of one.",
                "Computationally, r can be computed using the power method.",
                "This method first chooses a random starting vector r(0) , and iteratively multiplies the current vector by the PageRank matrix PU ; see Algorithm 1.",
                "In general, each iteration of the power method can take O(m2 ) operations when PU is a dense matrix.",
                "However, in practice, the number of links in a web graph will be of the order of the number of pages.",
                "By exploiting the sparsity of the PageRank matrix, the work per iteration can be reduced to O(km), where k is the average number of links per web page.",
                "It has also been shown that the total number of iterations needed for convergence is proportional to α and does not depend on the size of the web graph [11, 7].",
                "Finally, the total space needed is also O(km), mainly to store the matrix U. 117 Research Track Paper Algorithm 1: A linear time (per iteration) algorithm for computing PageRank.",
                "ComputePR(U) Input: U: Adjacency matrix.",
                "Output: r: PageRank vector.",
                "Choose (randomly) an initial non-negative vector r(0) such that r(0) 1 = 1. i ← 0 repeat i ← i + 1 ν ← αUD−1 U r(i−1) {α is the random surfing probability} r(i) ← ν + (1 − α)v {v is the random surfer vector.} until r(i) − r(i−1) < δ {δ is the convergence threshold.} r ← r(i) 4.",
                "PROBLEM DEFINITION Given a local domain L, let G be an N × N adjacency matrix for the entire connected component of the web that contains L, such that Gji = 1 if page i links to page j and Gji = 0 otherwise.",
                "Without loss of generality, we will partition G as: G = L Gout Lout Gwithin , (2) where L is the n × n local subgraph corresponding to links inside the local domain, Lout is the subgraph that corresponds to links from the local domain pointing out to the global domain, Gout is the subgraph containing links from the global domain into the local domain, and Gwithin contains links within the global domain.",
                "We assume that when building a localized search engine, only pages inside the local domain are crawled, and the links between these pages are represented by the subgraph L. The links in Lout are also known, as these point from crawled pages in the local domain to uncrawled pages in the global domain.",
                "As defined in equation (1), PG is the PageRank matrix formed from the global graph G, and we define the global PageRank vector of this graph to be g. Let the n-length vector p∗ be the L1-normalized vector corresponding to the global PageRank of the pages in the local domain L: p∗ = EL g ELg 1 , where EL = [ I | 0 ] is the restriction matrix that selects the components from g corresponding to nodes in L. Let p denote the PageRank vector constructed from the local domain subgraph L. In practice, the observed local PageRank p and the global PageRank p∗ will be quite different.",
                "One would expect that as the size of local matrix L approaches the size of global matrix G, the global PageRank and the observed local PageRank will become more similar.",
                "Thus, one approach to estimating the global PageRank is to crawl the entire global domain, compute its PageRank, and extract the PageRanks of the local domain.",
                "Typically, however, n N , i.e., the number of global pages is much larger than the number of local pages.",
                "Therefore, crawling all global pages will quickly exhaust all local resources (computational, storage, and bandwidth) available to create the local search engine.",
                "We instead seek a supergraph ˆF of our local subgraph L with size O(n).",
                "Our goal Algorithm 2: The FindGlobalPR algorithm.",
                "FindGlobalPR(L, Lout, T, k) Input: L: zero-one adjacency matrix for the local domain, Lout: zero-one outlink matrix from L to global subgraph as in (2), T: number of iterations, k: number of pages to crawl per iteration.",
                "Output: ˆp: an improved estimate of the global PageRank of L. F ← L Fout ← Lout f ← ComputePR(F ) for (i = 1 to T) {Determine which pages to crawl next} pages ← SelectNodes(F , Fout, f, k) Crawl pages, augment F and modify Fout {Update PageRanks for new local domain} f ← ComputePR(F ) end {Extract PageRanks of original local domain & normalize} ˆp ← ELf ELf 1 is to find such a supergraph ˆF with PageRank ˆf, so that ˆf when restricted to L is close to p∗ .",
                "Formally, we seek to minimize GlobalDiff( ˆf) = EL ˆf EL ˆf 1 − p∗ 1 . (3) We choose the L1 norm for measuring the error as it does not place excessive weight on outliers (as the L2 norm does, for example), and also because it is the most commonly used distance measure in the literature for comparing PageRank vectors, as well as for detecting convergence of the algorithm [3].",
                "We propose a greedy framework, given in Algorithm 2, for constructing ˆF .",
                "Initially, F is set to the local subgraph L, and the PageRank f of this graph is computed.",
                "The algorithm then proceeds as follows.",
                "First, the SelectNodes algorithm (which we discuss in the next section) is called and it returns a set of k nodes to crawl next from the set of nodes in the current crawl frontier, Fout.",
                "These selected nodes are then crawled to expand the local subgraph, F , and the PageRanks of this expanded graph are then recomputed.",
                "These steps are repeated for each of T iterations.",
                "Finally, the PageRank vector ˆp, which is restricted to pages within the original local domain, is returned.",
                "Given our computation, bandwidth, and memory restrictions, we will assume that the algorithm will crawl at most O(n) pages.",
                "Since the PageRanks are computed in each iteration of the algorithm, which is an O(n) operation, we will also assume that the number of iterations T is a constant.",
                "Of course, the main challenge here is in selecting which set of k nodes to crawl next.",
                "In the next section, we formally define the problem and give efficient algorithms. 5.",
                "NODE SELECTION In this section, we present node selection algorithms that operate within the greedy framework presented in the previous section.",
                "We first give a well-defined criteria for the page selection problem and provide experimental evidence that this criteria can effectively identify pages that optimize our problem objective (3).",
                "We then present our main al118 Research Track Paper gorithmic contribution of the paper, a method with linear running time that is derived from this page selection criteria.",
                "Finally, we give an intuitive analysis of our algorithm in terms of leaks and flows.",
                "We show that if only the flow is considered, then the resulting method is very similar to a widely used page selection heuristic [6]. 5.1 Formulation For a given page j in the global domain, we define the expanded local graph Fj: Fj = F s uT j 0 , (4) where uj is the zero-one vector containing the outlinks from F into page j, and s contains the inlinks from page j into the local domain.",
                "Note that we do not allow self-links in this framework.",
                "In practice, self-links are often removed, as they only serve to inflate a given pages PageRank.",
                "Observe that the inlinks into F from node j are not known until after node j is crawled.",
                "Therefore, we estimate this inlink vector as the expectation over inlink counts among the set of already crawled pages, s = F T e F T e 1 . (5) In practice, for any given page, this estimate may not reflect the true inlinks from that page.",
                "Furthermore, this expectation is sampled from the set of links within the crawled domain, whereas a better estimate would also use links from the global domain.",
                "However, the latter distribution is not known to a localized search engine, and we contend that the above estimate will, on average, be a better estimate than the uniform distribution, for example.",
                "Let the PageRank of F be f. We express the PageRank f+ j of the expanded local graph Fj as f+ j = (1 − xj)fj xj , (6) where xj is the PageRank of the candidate global node j, and fj is the L1-normalized PageRank vector restricted to the pages in F .",
                "Since directly optimizing our problem goal requires knowing the global PageRank p∗ , we instead propose to crawl those nodes that will have the greatest influence on the PageRanks of pages in the original local domain L: influence(j) = k∈L |fj[k] − f[k]| (7) = EL (fj − f) 1.",
                "Experimentally, the influence score is a very good predictor of our problem objective (3).",
                "For each candidate global node j, figure 1(a) shows the objective function value Global Diff(fj) as a function of the influence of page j.",
                "The local domain used here is a crawl of conservative political pages (we will provide more details about this dataset in section 6); we observed similar results in other domains.",
                "The correlation is quite strong, implying that the influence criteria can effectively identify pages that improve the global PageRank estimate.",
                "As a baseline, figure 1(b) compares our objective with an alternative criteria, outlink count.",
                "The outlink count is defined as the number of outlinks from the local domain to page j.",
                "The correlation here is much weaker. .00001 .0001 .001 .01 0.26 0.262 0.264 0.266 Influence Objective 1 10 100 1000 0.266 0.264 0.262 0.26 Outlink Count Objective (a) (b) Figure 1: (a) The correlation between our influence page selection criteria (7) and the actual objective function (3) value is quite strong. (b) This is in contrast to other criteria, such as outlink count, which exhibit a much weaker correlation. 5.2 Computation As described, for each candidate global page j, the influence score (7) must be computed.",
                "If fj is computed exactly for each global page j, then the PageRank algorithm would need to be run for each of the O(n) such global pages j we consider, resulting in an O(n2 ) computational cost for the node selection method.",
                "Thus, computing the exact value of fj will lead to a quadratic algorithm, and we must instead turn to methods of approximating this vector.",
                "The algorithm we present works by performing one power method iteration used by the PageRank algorithm (Algorithm 1).",
                "The convergence rate for the PageRank algorithm has been shown to equal the random surfer probability α [7, 11].",
                "Given a starting vector x(0) , if k PageRank iterations are performed, the current PageRank solution x(k) satisfies: x(k) − x∗ 1 = O(αk x(0) − x∗ 1), (8) where x∗ is the desired PageRank vector.",
                "Therefore, if only one iteration is performed, choosing a good starting vector is necessary to achieve an accurate approximation.",
                "We partition the PageRank matrix PFj , corresponding to the × subgraph Fj as: PFj = ˜F ˜s ˜uT j w , (9) where ˜F = αF (DF + diag(uj))−1 + (1 − α) e + 1 eT , ˜s = αs + (1 − α) e + 1 , ˜uj = α(DF + diag(uj))−1 uj + (1 − α) e + 1 , w = 1 − α + 1 , and diag(uj) is the diagonal matrix with the (i, i)th entry equal to one if the ith element of uj equals one, and is zero otherwise.",
                "We have assumed here that the random surfer vector is the uniform vector, and that L has no dangling links.",
                "These assumptions are not necessary and serve only to simplify discussion and analysis.",
                "A simple approach for estimating fj is the following.",
                "First, estimate the PageRank f+ j of Fj by computing one PageRank iteration over the matrix PFj , using the starting vector ν = f 0 .",
                "Then, estimate fj by removing the last 119 Research Track Paper component from our estimate of f+ j (i.e., the component corresponding to the added node j), and renormalizing.",
                "The problem with this approach is in the starting vector.",
                "Recall from (6) that xj is the PageRank of the added node j.",
                "The difference between the actual PageRank f+ j of PFj and the starting vector ν is ν − f+ j 1 = xj + f − (1 − xj)fj 1 ≥ xj + | f 1 − (1 − xj) fj 1| = xj + |xj| = 2xj.",
                "Thus, by (8), after one PageRank iteration, we expect our estimate of f+ j to still have an error of about 2αxj.",
                "In particular, for candidate nodes j with relatively high PageRank xj, this method will yield more inaccurate results.",
                "We will next present a method that eliminates this bias and runs in O(n) time. 5.2.1 Stochastic Complementation Since f+ j , as given in (6) is the PageRank of the matrix PFj , we have: fj(1 − xj) xj = ˜F ˜s ˜uT j w fj(1 − xj) xj = ˜F fj(1 − xj) + ˜sxj ˜uT j fj(1 − xj) + wxj .",
                "Solving the above system for fj can be shown to yield fj = ( ˜F + (1 − w)−1 ˜s˜uT j )fj. (10) The matrix S = ˜F +(1−w)−1 ˜s˜uT j is known as the stochastic complement of the column stochastic matrix PFj with respect to the sub matrix ˜F .",
                "The theory of stochastic complementation is well studied, and it can be shown the stochastic complement of an irreducible matrix (such as the PageRank matrix) is unique.",
                "Furthermore, the stochastic complement is also irreducible and therefore has a unique stationary distribution as well.",
                "For an extensive study, see [15].",
                "It can be easily shown that the sub-dominant eigenvalue of S is at most +1 α, where is the size of F .",
                "For sufficiently large , this value will be very close to α.",
                "This is important, as other properties of the PageRank algorithm, notably the algorithms sensitivity, are dependent on this value [11].",
                "In this method, we estimate the length vector fj by computing one PageRank iteration over the × stochastic complement S, starting at the vector f: fj ≈ Sf. (11) This is in contrast to the simple method outlined in the previous section, which first iterates over the ( + 1) × ( + 1) matrix PFj to estimate f+ j , and then removes the last component from the estimate and renormalizes to approximate fj.",
                "The problem with the latter method is in the choice of the ( + 1) length starting vector, ν. Consequently, the PageRank estimate given by the simple method differs from the true PageRank by at least 2αxj, where xj is the PageRank of page j.",
                "By using the stochastic complement, we can establish a tight lower bound of zero for this difference.",
                "To see this, consider the case in which a node k is added to F to form the augmented local subgraph Fk, and that the PageRank of this new graph is (1 − xk)f xk .",
                "Specifically, the addition of page k does not change the PageRanks of the pages in F , and thus fk = f. By construction of the stochastic complement, fk = Sfk, so the approximation given in equation (11) will yield the exact solution.",
                "Next, we present the computational details needed to efficiently compute the quantity fj −f 1 over all known global pages j.",
                "We begin by expanding the difference fj −f, where the vector fj is estimated as in (11), fj − f ≈ Sf − f = αF (DF + diag(uj))−1 f + (1 − α) e + 1 eT f +(1 − w)−1 (˜uT j f)˜s − f. (12) Note that the matrix (DF +diag(uj))−1 is diagonal.",
                "Letting o[k] be the outlink count for page k in F , we can express the kth diagonal element as: (DF + diag(uj))−1 [k, k] = 1 o[k]+1 if uj[k] = 1 1 o[k] if uj[k] = 0 Noting that (o[k] + 1)−1 = o[k]−1 − (o[k](o[k] + 1))−1 and rewriting this in matrix form yields (DF +diag(uj))−1 = D−1 F −D−1 F (DF +diag(uj))−1 diag(uj). (13) We use the same identity to express e + 1 = e − e ( + 1) . (14) Recall that, by definition, we have PF = αF D−1 F +(1−α)e .",
                "Substituting (13) and (14) in (12) yields fj − f ≈ (PF f − f) −αF D−1 F (DF + diag(uj))−1 diag(uj)f −(1 − α) e ( + 1) + (1 − w)−1 (˜uT j f)˜s = x + y + (˜uT j f)z, (15) noting that by definition, f = PF f, and defining the vectors x, y, and z to be x = −αF D−1 F (DF + diag(uj))−1 diag(uj)f (16) y = −(1 − α) e ( + 1) (17) z = (1 − w)−1 ˜s. (18) The first term x is a sparse vector, and takes non-zero values only for local pages k that are siblings of the global page j.",
                "We define (i, j) ∈ F if and only if F [j, i] = 1 (equivalently, page i links to page j) and express the value of the component x[k ] as: x[k ] = −α k:(k,k )∈F ,uj [k]=1 f[k] o[k](o[k] + 1) , (19) where o[k], as before, is the number of outlinks from page k in the local domain.",
                "Note that the last two terms, y and z are not dependent on the current global node j.",
                "Given the function hj(f) = y + (˜uT j f)z 1, the quantity fj − f 1 120 Research Track Paper can be expressed as fj − f 1 = k x[k] + y[k] + (˜uT j f)z[k] = k:x[k]=0 y[k] + (˜uT j f)z[k] + k:x[k]=0 x[k] + y[k] + (˜uT j f)z[k] = hj(f) − k:x[k]=0 y[k] + (˜uT j f)z[k] + k:x[k]=0 x[k] + y[k] + (˜uT j f)z[k] . (20) If we can compute the function hj in linear time, then we can compute each value of fj − f 1 using an additional amount of time that is proportional to the number of nonzero components in x.",
                "These optimizations are carried out in Algorithm 3.",
                "Note that (20) computes the difference between all components of f and fj, whereas our node selection criteria, given in (7), is restricted to the components corresponding to nodes in the original local domain L. Let us examine Algorithm 3 in more detail.",
                "First, the algorithm computes the outlink counts for each page in the local domain.",
                "The algorithm then computes the quantity ˜uT j f for each known global page j.",
                "This inner product can be written as (1 − α) 1 + 1 + α k:(k,j)∈Fout f[k] o[k] + 1 , where the second term sums over the set of local pages that link to page j.",
                "Since the total number of edges in Fout was assumed to have size O( ) (recall that is the number of pages in F ), the running time of this step is also O( ).",
                "The algorithm then computes the vectors y and z, as given in (17) and (18), respectively.",
                "The L1NormDiff method is called on the components of these vectors which correspond to the pages in L, and it estimates the value of EL(y + (˜uT j f)z) 1 for each page j.",
                "The estimation works as follows.",
                "First, the values of ˜uT j f are discretized uniformly into c values {a1, ..., ac}.",
                "The quantity EL(y + aiz) 1 is then computed for each discretized value of ai and stored in a table.",
                "To evaluate EL (y + az) 1 for some a ∈ [a1, ac], the closest discretized value ai is determined, and the corresponding entry in the table is used.",
                "The total running time for this method is linear in and the discretization parameter c (which we take to be a constant).",
                "We note that if exact values are desired, we have also developed an algorithm that runs in O( log ) time that is not described here.",
                "In the main loop, we compute the vector x, as defined in equation (16).",
                "The nested loops iterate over the set of pages in F that are siblings of page j.",
                "Typically, the size of this set is bounded by a constant.",
                "Finally, for each page j, the scores vector is updated over the set of non-zero components k of the vector x with k ∈ L. This set has size equal to the number of local siblings of page j, and is a subset of the total number of siblings of page j.",
                "Thus, each iteration of the main loop takes constant time, and the total running time of the main loop is O( ).",
                "Since we have assumed that the size of F will not grow larger than O(n), the total running time for the algorithm is O(n).",
                "Algorithm 3: Node Selection via Stochastic Complementation.",
                "SC-Select(F , Fout, f, k) Input: F : zero-one adjacency matrix of size corresponding to the current local subgraph, Fout: zero-one outlink matrix from F to global subgraph, f: PageRank of F , k: number of pages to return Output: pages: set of k pages to crawl next {Compute outlink sums for local subgraph} foreach (page j ∈ F ) o[j] ← k:(j,k)∈F F[j, k] end {Compute scalar ˜uT j f for each global node j } foreach (page j ∈ Fout) g[j] ← (1 − α) 1 +1 foreach (page k : (k, j) ∈ Fout) g[j] ← g[j] + α f[k] o[k]+1 end end {Compute vectors y and z as in (17) and (18) } y ← −(1 − α) e ( +1) z ← (1 − w)−1 ˜s {Approximate y + g[j] ∗ z 1 for all values g[j]} norm diffs ←L1NormDiffs(g, ELy, ELz) foreach (page j ∈ Fout) {Compute sparse vector x as in (19)} x ← 0 foreach (page k : (k, j) ∈ Fout) foreach (page k : (k, k ) ∈ F )) x[k ] ← x[k ] − f[k] o[k](o[k]+1) end end x ← αx scores[j] ← norm diffs[j] foreach (k : x[k] > 0 and page k ∈ L) scores[j] ← scores[j] − |y[k] + g[j] ∗ z[k]| +|x[k]+y[k]+g[j]∗z[k])| end end Return k pages with highest scores 5.2.2 PageRank Flows We now present an intuitive analysis of the stochastic complementation method by decomposing the change in PageRank in terms of leaks and flows.",
                "This analysis is motivated by the decomposition given in (15).",
                "PageRank flow is the increase in the local PageRanks originating from global page j.",
                "The flows are represented by the non-negative vector (˜uT j f)z (equations (15) and (18)).",
                "The scalar ˜uT j f can be thought of as the total amount of PageRank flow that page j has available to distribute.",
                "The vector z dictates how the flow is allocated to the local domain; the flow that local page k receives is proportional to (within a constant factor due to the random surfer vector) the expected number of its inlinks.",
                "The PageRank leaks represent the decrease in PageRank resulting from the addition of page j.",
                "The leakage can be quantified in terms of the non-positive vectors x and y (equations (16) and (17)).",
                "For vector x, we can see from equation (19) that the amount of PageRank leaked by a local page is proportional to the weighted sum of the Page121 Research Track Paper Ranks of its siblings.",
                "Thus, pages that have siblings with higher PageRanks (and low outlink counts) will experience more leakage.",
                "The leakage caused by y is an artifact of the random surfer vector.",
                "We will next show that if only the flow term, (˜uT j f)z, is considered, then the resulting method is very similar to a heuristic proposed by Cho et al. [6] that has been widely used for the Crawling Through URL Ordering problem.",
                "This heuristic is computationally cheaper, but as we will see later, not as effective as the Stochastic Complementation method.",
                "Our node selection strategy chooses global nodes that have the largest influence (equation (7)).",
                "If this influence is approximated using only flows, the optimal node j∗ is: j∗ = argmaxj EL ˜uT j fz 1 = argmaxj ˜uT j f EL z 1 = argmaxj ˜uT j f = argmaxj α(DF + diag(uj))−1 uj + (1 − α) e + 1 , f = argmaxjfT (DF + diag(uj))−1 uj.",
                "The resulting page selection score can be expressed as a sum of the PageRanks of each local page k that links to j, where each PageRank value is normalized by o[k]+1.",
                "Interestingly, the normalization that arises in our method differs from the heuristic given in [6], which normalizes by o[k].",
                "The algorithm PF-Select, which is omitted due to lack of space, first computes the quantity fT (DF +diag(uj))−1 uj for each global page j, and then returns the pages with the k largest scores.",
                "To see that the running time for this algorithm is O(n), note that the computation involved in this method is a subset of that needed for the SC-Select method (Algorithm 3), which was shown to have a running time of O(n). 6.",
                "EXPERIMENTS In this section, we provide experimental evidence to verify the effectiveness of our algorithms.",
                "We first outline our experimental methodology and then provide results across a variety of local domains. 6.1 Methodology Given the limited resources available at an academic institution, crawling a section of the web that is of the same magnitude as that indexed by Google or Yahoo! is clearly infeasible.",
                "Thus, for a given local domain, we approximate the global graph by crawling a local neighborhood around the domain that is several orders of magnitude larger than the local subgraph.",
                "Even though such a graph is still orders of magnitude smaller than the true global graph, we contend that, even if there exist some highly influential pages that are very far away from our local domain, it is unrealistic for any local node selection algorithm to find them.",
                "Such pages also tend to be highly unrelated to pages within the local domain.",
                "When explaining our node selection strategies in section 5, we made the simplifying assumption that our local graph contained no dangling nodes.",
                "This assumption was only made to ease our analysis.",
                "Our implementation efficiently handles dangling links by replacing each zero column of our adjacency matrix with the uniform vector.",
                "We evaluate the algorithm using the two node selection strategies given in Section 5.2, and also against the following baseline methods: • Random: Nodes are chosen uniformly at random among the known global nodes. • OutlinkCount: Global nodes with the highest number of outlinks from the local domain are chosen.",
                "At each iteration of the FindGlobalPR algorithm, we evaluate performance by computing the difference between the current PageRank estimate of the local domain, ELf ELf 1 , and the global PageRank of the local domain ELg ELg 1 .",
                "All PageRank calculations were performed using the uniform random surfer vector.",
                "Across all experiments, we set the random surfer parameter α, to be .85, and used a convergence threshold of 10−6 .",
                "We evaluate the difference between the local and global PageRank vectors using three different metrics: the L1 and L∞ norms, and Kendalls tau.",
                "The L1 norm measures the sum of the absolute value of the differences between the two vectors, and the L∞ norm measures the absolute value of the largest difference.",
                "Kendalls tau metric is a popular rank correlation measure used to compare PageRanks [2, 11].",
                "This metric can be computed by counting the number of pairs of pairs that agree in ranking, and subtracting from that the number of pairs of pairs that disagree in ranking.",
                "The final value is then normalized by the total number of n 2 such pairs, resulting in a [−1, 1] range, where a negative score signifies anti-correlation among rankings, and values near one correspond to strong rank correlation. 6.2 Results Our experiments are based on two large web crawls and were downloaded using the web crawler that is part of the Nutch open source search engine project [18].",
                "All crawls were restricted to only http pages, and to limit the number of dynamically generated pages that we crawl, we ignored all pages with urls containing any of the characters ?, *, @, or =.",
                "The first crawl, which we will refer to as the edu dataset, was seeded by homepages of the top 100 graduate computer science departments in the USA, as rated by the US News and World Report [16], and also by the home pages of their respective institutions.",
                "A crawl of depth 5 was performed, restricted to pages within the .edu domain, resulting in a graph with approximately 4.7 million pages and 22.9 million links.",
                "The second crawl was seeded by the set of pages under the politics hierarchy in the dmoz open directory project[17].",
                "We crawled all pages up to four links away, which yielded a graph with 4.4 million pages and 17.3 million links.",
                "Within the edu crawl, we identified the five site-specific domains corresponding to the websites of the top five graduate computer science departments, as ranked by the US News and World Report.",
                "This yielded local domains of various sizes, from 10,626 (UIUC) to 59,895 (Berkeley).",
                "For each of these site-specific domains with size n, we performed 50 iterations of the FindGlobalPR algorithm to crawl a total of 2n additional nodes.",
                "Figure 2(a) gives the (L1) difference from the PageRank estimate at each iteration to the global PageRank, for the Berkeley local domain.",
                "The performance of this dataset was representative of the typical performance across the five computer science sitespecific local domains.",
                "Initially, the L1 difference between the global and local PageRanks ranged from .0469 (Stanford) to .149 (MIT).",
                "For the first several iterations, the 122 Research Track Paper 0 5 10 15 20 25 30 35 40 45 50 0.015 0.02 0.025 0.03 0.035 0.04 0.045 0.05 0.055 Number of Iterations GlobalandLocalPageRankDifference(L1) Stochastic Complement PageRank Flow Outlink Count Random 0 10 20 30 40 50 0 0.05 0.1 0.15 0.2 0.25 0.3 0.35 Number of Iterations GlobalandLocalPageRankDifference(L1) Stochastic Complement PageRank Flow Outlink Count Random 0 5 10 15 20 25 0.16 0.18 0.2 0.22 0.24 0.26 0.28 0.3 0.32 0.34 Number of Iterations GlobalandLocalPageRankDifference(L1) Stochastic Complement PageRank Flow Outlink Count Random (a) www.cs.berkeley.edu (b) www.enterstageright.com (c) Politics Figure 2: L1 difference between the estimated and true global PageRanks for (a) Berkeleys computer science website, (b) the site-specific domain, www.enterstageright.com, and (c) the politics topic-specific domain.",
                "The stochastic complement method outperforms all other methods across various domains. three link-based methods all outperform the random selection heuristic.",
                "After these initial iterations, the random heuristic tended to be more competitive with (or even outperform, as in the Berkeley local domain) the outlink count and PageRank flow heuristics.",
                "In all tests, the stochastic complementation method either outperformed, or was competitive with, the other methods.",
                "Table 1 gives the average difference between the final estimated global PageRanks and the true global PageRanks for various distance measures.",
                "Algorithm L1 L∞ Kendall Stoch.",
                "Comp. .0384 .00154 .9257 PR Flow .0470 .00272 .8946 Outlink .0419 .00196 .9053 Random .0407 .00204 .9086 Table 1: Average final performance of various node selection strategies for the five site-specific computer science local domains.",
                "Note that Kendalls Tau measures similarity, while the other metrics are dissimilarity measures.",
                "Stochastic Complementation clearly outperforms the other methods in all metrics.",
                "Within the politics dataset, we also performed two sitespecific tests for the largest websites in the crawl: www.adamsmith.org, the website for the London based Adam Smith Institute, and www.enterstageright.com, an online conservative journal.",
                "As with the edu local domains, we ran our algorithm for 50 iterations, crawling a total of 2n nodes.",
                "Figure 2 (b) plots the results for the www.enterstageright.com domain.",
                "In contrast to the edu local domains, the Random and OutlinkCount methods were not competitive with either the SC-Select or the PF-Select methods.",
                "Among all datasets and all node selection methods, the stochastic complementation method was most impressive in this dataset, realizing a final estimate that differed only .0279 from the global PageRank, a ten-fold improvement over the initial local PageRank difference of .299.",
                "For the Adam Smith local domain, the initial difference between the local and global PageRanks was .148, and the final estimates given by the SC-Select, PF-Select, OutlinkCount, and Random methods were .0208, .0193, .0222, and .0356, respectively.",
                "Within the politics dataset, we constructed four topicspecific local domains.",
                "The first domain consisted of all pages in the dmoz politics category, and also all pages within each of these sites up to two links away.",
                "This yielded a local domain of 90,811 pages, and the results are given in figure 2 (c).",
                "Because of the larger size of the topic-specific domains, we ran our algorithm for only 25 iterations to crawl a total of n nodes.",
                "We also created topic-specific domains from three political sub-topics: liberalism, conservatism, and socialism.",
                "The pages in these domains were identified by their corresponding dmoz categories.",
                "For each sub-topic, we set the local domain to be all pages within three links from the corresponding dmoz category pages.",
                "Table 2 summarizes the performance of these three topic-specific domains, and also the larger political domain.",
                "To quantify a global page js effect on the global PageRank values of pages in the local domain, we define page js impact to be its PageRank value, g[j], normalized by the fraction of its outlinks pointing to the local domain: impact(j) = oL[j] o[j] · g[j], where, oL[j] is the number of outlinks from page j to pages in the local domain L, and o[j] is the total number of js outlinks.",
                "In terms of the random surfer model, the impact of page j is the probability that the random surfer (1) is currently at global page j in her random walk and (2) takes an outlink to a local page, given that she has already decided not to jump to a random page.",
                "For the politics local domain, we found that many of the pages with high impact were in fact political pages that should have been included in the dmoz politics topic, but were not.",
                "For example, the two most influential global pages were the political search engine www.askhenry.com, and the home page of the online political magazine, www.policyreview.com.",
                "Among non-political pages, the home page of the journal Education Next was most influential.",
                "The journal is freely available online and contains articles regarding various aspect of K-12 education in America.",
                "To provide some anecdotal evidence for the effectiveness of our page selection methods, we note that the SC-Select method chose 11 pages within the www.educationnext.org domain, the PF-Select method discovered 7 such pages, while the OutlinkCount and Random methods found only 6 pages each.",
                "For the conservative political local domain, the socialist website www.ornery.org had a very high impact score.",
                "This 123 Research Track Paper All Politics: Algorithm L1 L2 Kendall Stoch.",
                "Comp. .1253 .000700 .8671 PR Flow .1446 .000710 .8518 Outlink .1470 .00225 .8642 Random .2055 .00203 .8271 Conservativism: Algorithm L1 L2 Kendall Stoch.",
                "Comp. .0496 .000990 .9158 PR Flow .0554 .000939 .9028 Outlink .0602 .00527 .9144 Random .1197 .00102 .8843 Liberalism: Algorithm L1 L2 Kendall Stoch.",
                "Comp. .0622 .001360 .8848 PR Flow .0799 .001378 .8669 Outlink .0763 .001379 .8844 Random .1127 .001899 .8372 Socialism: Algorithm L1 L∞ Kendall Stoch.",
                "Comp. .04318 .00439 .9604 PR Flow .0450 .004251 .9559 Outlink .04282 .00344 .9591 Random .0631 .005123 .9350 Table 2: Final performance among node selection strategies for the four political topic-specific crawls.",
                "Note that Kendalls Tau measures similarity, while the other metrics are dissimilarity measures. was largely due to a link from the front page of this site to an article regarding global warming published by the National Center for Public Policy Research, a conservative research group in Washington, DC.",
                "Not surprisingly, the global PageRank of this article (which happens to be on the home page of the NCCPR, www.nationalresearch.com), was approximately .002, whereas the local PageRank of this page was only .00158.",
                "The SC-Select method yielded a global PageRank estimate of approximately .00182, the PFSelect method estimated a value of .00167, and the Random and OutlinkCount methods yielded values of .01522 and .00171, respectively. 7.",
                "RELATED WORK The node selection framework we have proposed is similar to the url ordering for crawling problem proposed by Cho et al. in [6].",
                "Whereas our framework seeks to minimize the difference between the global and local PageRank, the objective used in [6] is to crawl the most highly (globally) ranked pages first.",
                "They propose several node selection algorithms, including the outlink count heuristic, as well as a variant of our PF-Select algorithm which they refer to as the PageRank ordering metric.",
                "They found this method to be most effective in optimizing their objective, as did a recent survey of these methods by Baeza-Yates et al. [1].",
                "Boldi et al. also experiment within a similar crawling framework in [2], but quantify their results by comparing Kendalls rank correlation between the PageRanks of the current set of crawled pages and those of the entire global graph.",
                "They found that node selection strategies that crawled pages with the highest global PageRank first actually performed worse (with respect to Kendalls Tau correlation between the local and global PageRanks) than basic depth first or breadth first strategies.",
                "However, their experiments differ from our work in that our node selection algorithms do not use (or have access to) global PageRank values.",
                "Many algorithmic improvements for computing exact PageRank values have been proposed [9, 10, 14].",
                "If such algorithms are used to compute the global PageRanks of our local domain, they would all require O(N) computation, storage, and bandwidth, where N is the size of the global domain.",
                "This is in contrast to our method, which approximates the global PageRank and scales linearly with the size of the local domain.",
                "Wang and Dewitt [22] propose a system where the set of web servers that comprise the global domain communicate with each other to compute their respective global PageRanks.",
                "For a given web server hosting n pages, the computational, bandwidth, and storage requirements are also linear in n. One drawback of this system is that the number of distinct web servers that comprise the global domain can be very large.",
                "For example, our edu dataset contains websites from over 3,200 different universities; coordinating such a system among a large number of sites can be very difficult.",
                "Gan, Chen, and Suel propose a method for estimating the PageRank of a single page [5] which uses only constant bandwidth, computation, and space.",
                "Their approach relies on the availability of a remote connectivity server that can supply the set of inlinks to a given page, an assumption not used in our framework.",
                "They experimentally show that a reasonable estimate of the nodes PageRank can be obtained by visiting at most a few hundred nodes.",
                "Using their algorithm for our problem would require that either the entire global domain first be downloaded or a connectivity server be used, both of which would lead to very large web graphs. 8.",
                "CONCLUSIONS AND FUTURE WORK The internet is growing exponentially, and in order to navigate such a large repository as the web, global search engines have established themselves as a necessity.",
                "Along with the ubiquity of these large-scale search engines comes an increase in search users expectations.",
                "By providing complete and isolated coverage of a particular web domain, localized search engines are an effective outlet to quickly locate content that could otherwise be difficult to find.",
                "In this work, we contend that the use of global PageRank in a localized search engine can improve performance.",
                "To estimate the global PageRank, we have proposed an iterative node selection framework where we select which pages from the global frontier to crawl next.",
                "Our primary contribution is our stochastic complementation page selection algorithm.",
                "This method crawls nodes that will most significantly impact the local domain and has running time linear in the number of nodes in the local domain.",
                "Experimentally, we validate these methods across a diverse set of local domains, including seven site-specific domains and four topic-specific domains.",
                "We conclude that by crawling an additional n or 2n pages, our methods find an estimate of the global PageRanks that is up to ten times better than just using the local PageRanks.",
                "Furthermore, we demonstrate that our algorithm consistently outperforms other existing heuristics. 124 Research Track Paper Often times, topic-specific domains are discovered using a focused web crawler which considers a pages content in conjunction with link anchor text to decide which pages to crawl next [4].",
                "Although such crawlers have proven to be quite effective in discovering topic-related content, many irrelevant pages are also crawled in the process.",
                "Typically, these pages are deleted and not indexed by the localized search engine.",
                "These pages can of course provide valuable information regarding the global PageRank of the local domain.",
                "One way to integrate these pages into our framework is to start the FindGlobalPR algorithm with the current subgraph F equal to the set of pages that were crawled by the focused crawler.",
                "The global PageRank estimation framework, along with the node selection algorithms presented, all require O(n) computation per iteration and bandwidth proportional to the number of pages crawled, Tk.",
                "If the number of iterations T is relatively small compared to the number of pages crawled per iteration, k, then the bottleneck of the algorithm will be the crawling phase.",
                "However, as the number of iterations increases (relative to k), the bottleneck will reside in the node selection computation.",
                "In this case, our algorithms would benefit from constant factor optimizations.",
                "Recall that the FindGlobalPR algorithm (Algorithm 2) requires that the PageRanks of the current expanded local domain be recomputed in each iteration.",
                "Recent work by Langville and Meyer [12] gives an algorithm to quickly recompute PageRanks of a given webgraph if a small number of nodes are added.",
                "This algorithm was shown to give speedup of five to ten times on some datasets.",
                "We plan to investigate this and other such optimizations as future work.",
                "In this paper, we have objectively evaluated our methods by measuring how close our global PageRank estimates are to the actual global PageRanks.",
                "To determine the benefit of using global PageRanks in a localized search engine, we suggest a user study in which users are asked to rate the quality of search results for various search queries.",
                "For some queries, only the local PageRanks are used in ranking, and for the remaining queries, local PageRanks and the approximate global PageRanks, as computed by our algorithms, are used.",
                "The results of such a study can then be analyzed to determine the added benefit of using the global PageRanks computed by our methods, over just using the local PageRanks.",
                "Acknowledgements.",
                "This research was supported by NSF grant CCF-0431257, NSF Career Award ACI-0093404, and a grant from Sabre, Inc. 9.",
                "REFERENCES [1] R. Baeza-Yates, M. Marin, C. Castillo, and A. Rodriguez.",
                "Crawling a country: better strategies than breadth-first for web page ordering.",
                "World-Wide Web Conference, 2005. [2] P. Boldi, M. Santini, and S. Vigna.",
                "Do your worst to make the best: paradoxical effects in pagerank incremental computations.",
                "Workshop on Web Graphs, 3243:168-180, 2004. [3] S. Brin and L. Page.",
                "The anatomy of a large-scale hypertextual web search engine.",
                "Computer Networks and ISDN Systems, 33(1-7):107-117, 1998. [4] S. Chakrabarti, M. van den Berg, and B. Dom.",
                "Focused crawling: a new approach to topic-specific web resource discovery.",
                "World-Wide Web Conference, 1999. [5] Y. Chen, Q. Gan, and T. Suel.",
                "Local methods for estimating pagerank values.",
                "Conference on Information and Knowledge Management, 2004. [6] J. Cho, H. Garcia-Molina, and L. Page.",
                "Efficient crawling through url ordering.",
                "World-Wide Web Conference, 1998. [7] T. H. Haveliwala and S. D. Kamvar.",
                "The second eigenvalue of the Google matrix.",
                "Technical report, Stanford University, 2003. [8] T. Joachims, F. Radlinski, L. Granka, A. Cheng, C. Tillekeratne, and A. Patel.",
                "Learning retrieval functions from implicit feedback. http://www.cs.cornell.edu/People/tj/career. [9] S. D. Kamvar, T. H. Haveliwala, C. D. Manning, and G. H. Golub.",
                "Exploiting the block structure of the web for computing pagerank.",
                "World-Wide Web Conference, 2003. [10] S. D. Kamvar, T. H. Haveliwala, C. D. Manning, and G. H. Golub.",
                "Extrapolation methods for accelerating pagerank computation.",
                "World-Wide Web Conference, 2003. [11] A. N. Langville and C. D. Meyer.",
                "Deeper inside pagerank.",
                "Internet Mathematics, 2004. [12] A. N. Langville and C. D. Meyer.",
                "Updating the stationary vector of an irreducible markov chain with an eye on Googles pagerank.",
                "SIAM Journal on Matrix Analysis, 2005. [13] P. Lyman, H. R. Varian, K. Swearingen, P. Charles, N. Good, L. L. Jordan, and J. Pal.",
                "How much information 2003?",
                "School of Information Management and System, University of California at Berkely, 2003. [14] F. McSherry.",
                "A uniform approach to accelerated pagerank computation.",
                "World-Wide Web Conference, 2005. [15] C. D. Meyer.",
                "Stochastic complementation, uncoupling markov chains, and the theory of nearly reducible systems.",
                "SIAM Review, 31:240-272, 1989. [16] US News and World Report. http://www.usnews.com. [17] Dmoz open directory project. http://www.dmoz.org. [18] Nutch open source search engine. http://www.nutch.org. [19] F. Radlinski and T. Joachims.",
                "Query chains: learning to rank from implicit feedback.",
                "ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, 2005. [20] S. Raghavan and H. Garcia-Molina.",
                "Crawling the hidden web.",
                "In Proceedings of the Twenty-seventh International Conference on Very Large Databases, 2001. [21] T. Tin Tang, D. Hawking, N. Craswell, and K. Griffiths.",
                "Focused crawling for both topical relevance and quality of medical information.",
                "Conference on Information and Knowledge Management, 2005. [22] Y. Wang and D. J. DeWitt.",
                "Computing pagerank in a distributed internet search system.",
                "Proceedings of the 30th VLDB Conference, 2004. 125 Research Track Paper"
            ],
            "original_annotated_samples": [
                "However, building a localized search engine over a <br>web community</br> of a hundred thousand pages would only require a few gigabytes of storage."
            ],
            "translated_annotated_samples": [
                "Sin embargo, construir un motor de búsqueda localizado sobre una <br>comunidad web</br> de cien mil páginas solo requeriría unos pocos gigabytes de almacenamiento."
            ],
            "translated_text": "Estimando el PageRank Global de Comunidades Web Jason V. Davis Dept. Departamento de Ciencias de la Computación Universidad de Texas en Austin Austin, TX 78712 jdavis@cs.utexas.edu Inderjit S. Dhillon Departamento de Ciencias de la Computación Universidad de Texas en Austin Austin, TX 78712 inderjit@cs.utexas.edu RESUMEN Los motores de búsqueda localizados son sistemas a pequeña escala que indexan una comunidad particular en la web. Ofrecen varios beneficios en comparación con sus contrapartes a gran escala, ya que son relativamente económicos de construir y pueden proporcionar una capacidad de búsqueda más precisa y completa en sus dominios relevantes. Una desventaja que tienen estos sistemas en comparación con los motores de búsqueda a gran escala es la falta de valores globales de PageRank. Se necesita esa información para evaluar el valor de las páginas en el dominio de búsqueda localizada dentro del contexto de la web en su totalidad. En este artículo, presentamos algoritmos bien fundamentados para estimar los valores globales de PageRank de un dominio local. Los algoritmos son altamente escalables en el sentido de que, dado un dominio local de tamaño n, utilizan recursos de O(n) que incluyen tiempo de computación, ancho de banda y almacenamiento. Probamos nuestros métodos en una variedad de dominios localizados, incluyendo dominios específicos del sitio y dominios específicos del tema. Demostramos que al rastrear tan solo n o 2n páginas adicionales, nuestros métodos pueden proporcionar excelentes estimaciones globales de PageRank. Categorías y Descriptores de Asignaturas H.3.3 [Almacenamiento y Recuperación de Información]: Búsqueda y Recuperación de Información; G.1.3 [Análisis Numérico]: Álgebra Lineal Numérica; G.3 [Probabilidad y Estadística]: Procesos de Markov Términos Generales PageRank, Cadena de Markov, Complementación Estocástica. Los motores de búsqueda localizados son motores de búsqueda a pequeña escala que indexan solo una comunidad específica de la web. Tales comunidades pueden ser dominios específicos del sitio, como páginas dentro del dominio cs.utexas.edu, o comunidades relacionadas con un tema, por ejemplo, sitios web políticos. En comparación con el grafo web rastreado e indexado por los motores de búsqueda a gran escala, el tamaño de estas comunidades locales suele ser típicamente órdenes de magnitud más pequeño. Por consiguiente, los recursos computacionales necesarios para construir un motor de búsqueda de este tipo también son igualmente más ligeros. Al restringirse a secciones más pequeñas y manejables de la web, los motores de búsqueda localizados también pueden ofrecer capacidades de búsqueda más precisas y completas dentro de sus respectivos dominios. Una desventaja de los índices localizados es la falta de información global necesaria para calcular clasificaciones basadas en enlaces. El algoritmo PageRank [3] ha demostrado ser una medida efectiva de este tipo. En general, el PageRank de una página dada depende de las páginas en todo el grafo web. En el contexto de un motor de búsqueda localizado, si los PageRanks se calculan utilizando solo el subgrafo local, entonces esperaríamos que los PageRanks resultantes reflejen la popularidad percibida dentro de la comunidad local y no de la web en su totalidad. Por ejemplo, consideremos un motor de búsqueda localizado que indexa páginas políticas con puntos de vista conservadores. Una persona que desee investigar las opiniones sobre el calentamiento global dentro de la comunidad política conservadora puede encontrarse con numerosas opiniones de este tipo en varios sitios web. Si solo se dispone de valores de PageRank locales, entonces los resultados de búsqueda reflejarán solo creencias fuertemente arraigadas dentro de la comunidad. Sin embargo, si los PageRanks globales también están disponibles, entonces los resultados pueden reflejar adicionalmente las opiniones de los externos sobre la comunidad conservadora (es decir, aquellos documentos a los que los liberales acceden con mayor frecuencia dentro de la comunidad conservadora). Por lo tanto, para muchos motores de búsqueda localizados, la incorporación de PageRanks globales puede mejorar la calidad de los resultados de búsqueda. Sin embargo, el número de páginas que indexa un motor de búsqueda local suele ser órdenes de magnitud más pequeño que el número de páginas indexadas por sus contrapartes a gran escala. Los motores de búsqueda localizados no tienen el ancho de banda, la capacidad de almacenamiento o la potencia computacional para rastrear, descargar y calcular los PageRanks globales de toda la web. En este trabajo, presentamos un método para aproximar los PageRanks globales de un dominio local utilizando recursos del mismo orden que los necesarios para calcular los PageRanks del subgrafo local. Nuestro método propuesto busca un supergrafo de nuestro subgrafo local de manera que los PageRanks locales dentro de este supergrafo estén cerca de los verdaderos PageRanks globales. Construimos este supergrafo mediante el rastreo iterativo de páginas globales en la frontera web actual, es decir, páginas globales con enlaces entrantes de páginas que ya han sido rastreadas. Para proporcionar a 116 Research Track Paper una buena aproximación a los PageRanks globales, es necesario tener cuidado al elegir qué páginas rastrear a continuación; en este documento, presentamos un algoritmo de selección de páginas bien fundamentado que también tiene un buen rendimiento empírico. Este algoritmo se deriva de un objetivo de problema bien definido y tiene un tiempo de ejecución lineal en el número de nodos locales. Experimentamos en varios tipos de subgrafos locales, incluidas cuatro comunidades relacionadas con el tema y varios dominios específicos del sitio. Para evaluar el rendimiento, medimos la diferencia entre la estimación actual del PageRank global y el PageRank global, en función del número de páginas rastreadas. Comparamos nuestro algoritmo con varios heurísticos y también con un algoritmo base que elige páginas al azar, y demostramos que nuestro método supera a estos otros métodos. Finalmente, demostramos empíricamente que, dado un dominio local de tamaño n, podemos proporcionar buenas aproximaciones a los valores globales de PageRank rastreando como máximo n o 2n páginas adicionales. El documento está organizado de la siguiente manera. La sección 2 ofrece una visión general de los motores de búsqueda localizados y destaca sus ventajas sobre los motores de búsqueda globales. La sección 3 proporciona antecedentes sobre el algoritmo PageRank. La sección 4 define formalmente nuestro problema, y la sección 5 presenta nuestros criterios de selección de páginas y deriva nuestros algoritmos. La sección 6 presenta los resultados experimentales, la sección 7 ofrece una visión general del trabajo relacionado y, finalmente, las conclusiones se presentan en la sección 8. MOTORES DE BÚSQUEDA LOCALIZADOS Los motores de búsqueda localizados indexan una sola comunidad de la web, típicamente una comunidad específica del sitio o una comunidad específica del tema. Los motores de búsqueda localizados disfrutan de tres ventajas principales sobre sus contrapartes a gran escala: son relativamente económicos de construir, pueden ofrecer una capacidad de búsqueda más precisa dentro de su dominio local y pueden proporcionar un índice más completo. Los recursos necesarios para construir un motor de búsqueda global son enormes. Un estudio de 2003 realizado por Lyman et al. [13] encontró que la web superficial (sitios estáticos de acceso público) consta de 8.9 mil millones de páginas, y que el tamaño promedio de estas páginas es de aproximadamente 18.7 kilobytes. Para descargar un rastreo de este tamaño, se necesita aproximadamente 167 terabytes de espacio. Para un investigador que desee construir un motor de búsqueda con acceso a un par de estaciones de trabajo o un servidor pequeño, un almacenamiento de esta magnitud simplemente no está disponible. Sin embargo, construir un motor de búsqueda localizado sobre una <br>comunidad web</br> de cien mil páginas solo requeriría unos pocos gigabytes de almacenamiento. La carga computacional necesaria para soportar consultas de búsqueda sobre una base de datos de este tamaño es más manejable también. Observamos que, para los motores de búsqueda específicos de un tema, la comunidad relevante puede ser identificada y descargada de manera eficiente utilizando un rastreador enfocado [21, 4]. Para dominios específicos del sitio, el dominio local está fácilmente disponible en su propio servidor web. Esto evita la necesidad de rastreo o indexación, y por lo tanto se puede garantizar un índice completo y actualizado del dominio. Esto contrasta con sus contrapartes a gran escala, las cuales sufren de varias deficiencias. Primero, el rastreo de páginas generadas dinámicamente en la web oculta ha sido objeto de investigación [20] y es una tarea no trivial para un rastreador externo. En segundo lugar, los dominios específicos del sitio pueden habilitar la política de exclusión de robots. Esto prohíbe a los rastreadores de motores de búsqueda externos descargar contenido del dominio, y en su lugar un motor de búsqueda externo debe depender de enlaces externos y texto ancla para indexar estas páginas restringidas. Al restringirse a un dominio específico de internet, un motor de búsqueda localizado puede proporcionar resultados de búsqueda más precisos. Considera la consulta de búsqueda ambigua canónica, jaguar, que puede referirse tanto al fabricante de automóviles como al animal. Un científico que intenta investigar el hábitat y la historia evolutiva de un jaguar puede tener más éxito utilizando un motor de búsqueda específico de zoología bien ajustado que consultando Google con múltiples búsquedas de palabras clave y navegando a través de resultados irrelevantes. Recientemente se propuso un método para aprender funciones de clasificación mejores para la recuperación por Radlinski y Joachims [19] y se ha aplicado a varios dominios locales, incluido el sitio web de la Universidad de Cornell [8]. 3. PAGERANK RESUMEN El algoritmo PageRank define la importancia de las páginas web analizando la estructura de hipervínculos subyacente de un grafo web. El algoritmo funciona construyendo una cadena de Markov a partir de la estructura de enlaces del grafo web y calculando su distribución estacionaria. Una forma de calcular la distribución estacionaria de una cadena de Markov es encontrar la distribución límite de un paseo aleatorio sobre la cadena. Por lo tanto, el algoritmo PageRank utiliza lo que a veces se conoce como el modelo del surfista aleatorio. En cada paso de la caminata aleatoria, el surfista sigue un enlace de salida de la página actual (es decir, el nodo actual en la cadena), o salta a una página aleatoria en la web. Ahora definimos con precisión el problema de PageRank. Sea U una matriz de adyacencia m × m para un grafo web dado tal que Uji = 1 si la página i enlaza a la página j y Uji = 0 en caso contrario. Definimos la matriz de PageRank PU como: PU = αUD−1 U + (1 − α)veT , (1) donde DU es la matriz diagonal (única) tal que UD−1 U es estocástica por columnas, α es un escalar dado tal que 0 ≤ α ≤ 1, e es el vector de todos unos, y v es un vector no negativo, L1-normalizado, a veces llamado vector de navegante aleatorio. Ten en cuenta que la matriz D−1 U está bien definida solo si cada columna de U tiene al menos una entrada distinta de cero, es decir, cada página en el grafo web tiene al menos un enlace de salida. En presencia de nodos colgantes que no tienen enlaces de salida, una solución comúnmente utilizada, propuesta por Brin et al. [3], es reemplazar cada columna de ceros de U por un vector no negativo, normalizado en L1. El vector PageRank r es el eigenvector dominante de la matriz PageRank, r = PU r. Supondremos, sin pérdida de generalidad, que r tiene una norma L1 de uno. Computacionalmente, r se puede calcular utilizando el método de la potencia. Este método primero elige un vector inicial aleatorio r(0) y, de forma iterativa, multiplica el vector actual por la matriz de PageRank PU; ver Algoritmo 1. En general, cada iteración del método de la potencia puede requerir O(m2) operaciones cuando PU es una matriz densa. Sin embargo, en la práctica, el número de enlaces en un grafo web será del orden del número de páginas. Al explotar la dispersión de la matriz de PageRank, el trabajo por iteración se puede reducir a O(km), donde k es el número promedio de enlaces por página web. También se ha demostrado que el número total de iteraciones necesarias para la convergencia es proporcional a α y no depende del tamaño del grafo web [11, 7]. Finalmente, el espacio total necesario también es O(km), principalmente para almacenar la matriz U. 117 Research Track Paper Algorithm 1: Un algoritmo de tiempo lineal (por iteración) para calcular PageRank. CalcularPR(U) Entrada: U: Matriz de adyacencia. Salida: vector de PageRank. Elige (aleatoriamente) un vector inicial no negativo r(0) tal que r(0) 1 = 1. i ← 0 repetir i ← i + 1 ν ← αUD−1 U r(i−1) {α es la probabilidad de navegación aleatoria} r(i) ← ν + (1 − α)v {v es el vector del navegante aleatorio.} hasta que r(i) − r(i−1) < δ {δ es el umbral de convergencia.} r ← r(i) 4. Dada un dominio local L, sea G una matriz de adyacencia N × N para el componente conectado completo de la web que contiene L, tal que Gji = 1 si la página i enlaza a la página j y Gji = 0 en caso contrario. Sin pérdida de generalidad, vamos a dividir G de la siguiente manera: G = L Gout Lout Gwithin, donde L es el subgrafo local de n × n correspondiente a los enlaces dentro del dominio local, Lout es el subgrafo que corresponde a los enlaces desde el dominio local apuntando hacia el dominio global, Gout es el subgrafo que contiene los enlaces desde el dominio global hacia el dominio local, y Gwithin contiene los enlaces dentro del dominio global. Suponemos que al construir un motor de búsqueda localizado, solo se rastrean las páginas dentro del dominio local, y los enlaces entre estas páginas están representados por el subgrafo L. También se conocen los enlaces en Lout, ya que estos apuntan desde las páginas rastreadas en el dominio local a las páginas no rastreadas en el dominio global. Como se define en la ecuación (1), PG es la matriz de PageRank formada a partir del grafo global G, y definimos el vector de PageRank global de este grafo como g. Sea el vector de longitud n p∗ el vector L1-normalizado que corresponde al PageRank global de las páginas en el dominio local L: p∗ = EL g ELg 1 , donde EL = [ I | 0 ] es la matriz de restricción que selecciona los componentes de g correspondientes a los nodos en L. Sea p el vector de PageRank construido a partir del subgrafo del dominio local L. En la práctica, el PageRank local observado p y el PageRank global p∗ serán bastante diferentes. Se esperaría que a medida que el tamaño de la matriz local L se acerque al tamaño de la matriz global G, el PageRank global y el PageRank local observado se vuelvan más similares. Por lo tanto, un enfoque para estimar el PageRank global es rastrear todo el dominio global, calcular su PageRank y extraer los PageRanks del dominio local. Por lo general, sin embargo, n N, es decir, el número de páginas globales es mucho mayor que el número de páginas locales. Por lo tanto, rastrear todas las páginas globales agotará rápidamente todos los recursos locales (computacionales, de almacenamiento y de ancho de banda) disponibles para crear el motor de búsqueda local. En cambio, buscamos un supergrafo ˆF de nuestro subgrafo local L con tamaño O(n). Nuestro objetivo es el Algoritmo 2: El algoritmo FindGlobalPR. EncuentraGlobalPR(L, Lout, T, k) Entrada: L: matriz de adyacencia de ceros y unos para el dominio local, Lout: matriz de enlaces de ceros y unos desde L al subgrafo global como en (2), T: número de iteraciones, k: número de páginas a rastrear por iteración. Salida: ˆp: una estimación mejorada del PageRank global de L. F ← L Fout ← Lout f ← CalcularPR(F) para (i = 1 a T) {Determinar qué páginas rastrear a continuación} páginas ← SeleccionarNodos(F, Fout, f, k) Rastrear páginas, aumentar F y modificar Fout {Actualizar PageRanks para el nuevo dominio local} f ← CalcularPR(F) fin {Extraer PageRanks del dominio local original y normalizar} ˆp ← ELf ELf 1 es encontrar un supergrafo ˆF con PageRank ˆf, de modo que ˆf cuando se restringe a L esté cerca de p∗. Formalmente, buscamos minimizar GlobalDiff( ˆf) = EL ˆf EL ˆf 1 − p∗ 1 . (3) Elegimos la norma L1 para medir el error ya que no otorga un peso excesivo a los valores atípicos (como lo hace la norma L2, por ejemplo), y también porque es la medida de distancia más comúnmente utilizada en la literatura para comparar vectores de PageRank, así como para detectar la convergencia del algoritmo [3]. Proponemos un marco codicioso, presentado en el Algoritmo 2, para construir ˆF. Inicialmente, F se establece en el subgrafo local L, y se calcula el PageRank f de este grafo. El algoritmo luego procede de la siguiente manera. Primero, se llama al algoritmo SelectNodes (que discutimos en la siguiente sección) y devuelve un conjunto de k nodos para rastrear a continuación del conjunto de nodos en la frontera de rastreo actual, Fout. Estos nodos seleccionados son luego rastreados para expandir el subgrafo local, F, y los PageRanks de este grafo expandido son luego recalculados. Estos pasos se repiten para cada una de las T iteraciones. Finalmente, se devuelve el vector PageRank ˆp, el cual está restringido a las páginas dentro del dominio local original. Dadas nuestras restricciones de computación, ancho de banda y memoria, asumiremos que el algoritmo rastreará como máximo O(n) páginas. Dado que los PageRanks se calculan en cada iteración del algoritmo, lo cual es una operación O(n), también asumiremos que el número de iteraciones T es una constante. Por supuesto, el principal desafío aquí radica en seleccionar qué conjunto de k nodos rastrear a continuación. En la siguiente sección, definimos formalmente el problema y presentamos algoritmos eficientes. 5. SELECCIÓN DE NODO En esta sección, presentamos algoritmos de selección de nodo que operan dentro del marco codicioso presentado en la sección anterior. Primero damos un criterio bien definido para el problema de selección de páginas y proporcionamos evidencia experimental de que este criterio puede identificar de manera efectiva las páginas que optimizan nuestro objetivo del problema (3). A continuación, presentamos nuestra principal contribución algorítmica del artículo de investigación al118, un método con tiempo de ejecución lineal que se deriva de los criterios de selección de esta página. Finalmente, ofrecemos un análisis intuitivo de nuestro algoritmo en términos de fugas y flujos. Mostramos que si solo se considera el flujo, entonces el método resultante es muy similar a una heurística de selección de páginas ampliamente utilizada [6]. 5.1 Formulación Para una página dada j en el dominio global, definimos el grafo local expandido Fj: Fj = F s uT j 0, (4) donde uj es el vector de ceros y unos que contiene los enlaces de salida de F hacia la página j, y s contiene los enlaces de entrada de la página j en el dominio local. Ten en cuenta que no permitimos enlaces a uno mismo en este marco de trabajo. En la práctica, los enlaces internos suelen ser eliminados, ya que solo sirven para inflar el PageRank de una página determinada. Observa que los enlaces entrantes a F desde el nodo j no se conocen hasta después de que el nodo j sea rastreado. Por lo tanto, estimamos este vector de inlink como la expectativa sobre el recuento de inlinks entre el conjunto de páginas ya rastreadas, s = F T e F T e 1. En la práctica, para cualquier página dada, esta estimación puede no reflejar los verdaderos inlinks de esa página. Además, esta expectativa se extrae del conjunto de enlaces dentro del dominio rastreado, mientras que una estimación más precisa también utilizaría enlaces del dominio global. Sin embargo, la distribución mencionada no es conocida por un motor de búsqueda localizado, y sostenemos que la estimación anterior, en promedio, será una estimación mejor que la distribución uniforme, por ejemplo. Dejemos que el PageRank de F sea f. Expresamos el PageRank f+ j del grafo local expandido Fj como f+ j = (1 − xj)fj xj , donde xj es el PageRank del nodo global candidato j, y fj es el vector de PageRank L1-normalizado restringido a las páginas en F. Dado que optimizar directamente nuestro objetivo requiere conocer el PageRank global p∗, proponemos en su lugar rastrear aquellos nodos que tendrán la mayor influencia en los PageRanks de las páginas en el dominio local original L: influencia(j) = k∈L |fj[k] − f[k]| (7) = EL (fj − f) 1. Experimentalmente, el puntaje de influencia es un predictor muy bueno de nuestro objetivo del problema (3). Para cada nodo global candidato j, la figura 1(a) muestra el valor de la función objetivo Global Diff(fj) en función de la influencia de la página j. El dominio local utilizado aquí es un rastreo de páginas políticas conservadoras (proporcionaremos más detalles sobre este conjunto de datos en la sección 6); observamos resultados similares en otros dominios. La correlación es bastante fuerte, lo que implica que los criterios de influencia pueden identificar de manera efectiva las páginas que mejoran la estimación global del PageRank. Como referencia, la figura 1(b) compara nuestro objetivo con un criterio alternativo, el recuento de enlaces de salida. El recuento de enlaces de salida se define como el número de enlaces de salida desde el dominio local a la página j. La correlación aquí es mucho más débil. .00001 .0001 .001 .01 0.26 0.262 0.264 0.266 Influencia Objetivo 1 10 100 1000 0.266 0.264 0.262 0.26 Recuento de Enlaces Salientes Objetivo (a) (b) Figura 1: (a) La correlación entre nuestros criterios de selección de página de influencia (7) y el valor real de la función objetivo (3) es bastante fuerte. (b) Esto contrasta con otros criterios, como el recuento de enlaces salientes, que muestran una correlación mucho más débil. 5.2 Cálculo Como se describe, para cada página global candidata j, se debe calcular el puntaje de influencia (7). Si fj se calcula exactamente para cada página global j, entonces el algoritmo de PageRank tendría que ejecutarse para cada una de las O(n) páginas globales j que consideramos, lo que resultaría en un costo computacional de O(n2) para el método de selección de nodos. Por lo tanto, calcular el valor exacto de fj conducirá a un algoritmo cuadrático, y en su lugar debemos recurrir a métodos de aproximación de este vector. El algoritmo que presentamos funciona realizando una iteración del método de potencia utilizado por el algoritmo PageRank (Algoritmo 1). La tasa de convergencia para el algoritmo PageRank se ha demostrado que es igual a la probabilidad del surfista aleatorio α [7, 11]. Dado un vector inicial x(0), si se realizan k iteraciones de PageRank, la solución actual de PageRank x(k) satisface: x(k) − x∗ 1 = O(αk x(0) − x∗ 1), (8), donde x∗ es el vector de PageRank deseado. Por lo tanto, si solo se realiza una iteración, es necesario elegir un buen vector inicial para lograr una aproximación precisa. Particionamos la matriz de PageRank PFj, correspondiente al subgrafo Fj, como: PFj = ˜F ˜s ˜uT j w, (9) donde ˜F = αF (DF + diag(uj))−1 + (1 − α) e + 1 eT, ˜s = αs + (1 − α) e + 1, ˜uj = α(DF + diag(uj))−1 uj + (1 − α) e + 1, w = 1 − α + 1, y diag(uj) es la matriz diagonal con la entrada (i, i) igual a uno si el i-ésimo elemento de uj es uno, y cero en caso contrario. Hemos asumido aquí que el vector del surfista aleatorio es el vector uniforme, y que L no tiene enlaces colgantes. Estas suposiciones no son necesarias y solo sirven para simplificar la discusión y el análisis. Un enfoque sencillo para estimar fj es el siguiente. Primero, estima el PageRank f+ j de Fj calculando una iteración de PageRank sobre la matriz PFj, utilizando el vector inicial ν = f 0. Luego, estima fj eliminando el último componente de 119 Research Track Paper de nuestra estimación de f+ j (es decir, el componente correspondiente al nodo j añadido), y renormalizando. El problema con este enfoque está en el vector inicial. Recuerde que xj es el PageRank del nodo j añadido. La diferencia entre el PageRank actual f+ j de PFj y el vector inicial ν es ν − f+ j 1 = xj + f − (1 − xj)fj 1 ≥ xj + | f 1 − (1 − xj) fj 1| = xj + |xj| = 2xj. Por lo tanto, según (8), después de una iteración de PageRank, esperamos que nuestra estimación de f+ j todavía tenga un error de aproximadamente 2αxj. En particular, para los nodos candidatos j con un PageRank xj relativamente alto, este método producirá resultados más inexactos. A continuación, presentaremos un método que elimina este sesgo y se ejecuta en tiempo O(n). 5.2.1 Complementación Estocástica Dado que f+ j, como se muestra en (6), es el PageRank de la matriz PFj, tenemos: fj(1 − xj) xj = ˜F ˜s ˜uT j w fj(1 − xj) xj = ˜F fj(1 − xj) + ˜sxj ˜uT j fj(1 − xj) + wxj. Resolver el sistema anterior para fj puede demostrarse que produce fj = ( ˜F + (1 − w)−1 ˜s˜uT j )fj. (10) La matriz S = ˜F +(1−w)−1 ˜s˜uT j se conoce como el complemento estocástico de la matriz estocástica de columna PFj con respecto a la submatriz ˜F. La teoría de complementación estocástica está bien estudiada, y se puede demostrar que el complemento estocástico de una matriz irreducible (como la matriz de PageRank) es único. Además, el complemento estocástico también es irreducible y, por lo tanto, tiene una distribución estacionaria única. Para un estudio extenso, ver [15]. Se puede demostrar fácilmente que el autovalor subdominante de S es a lo sumo +1 α, donde α es el tamaño de F. Para valores suficientemente grandes, este valor estará muy cerca de α. Esto es importante, ya que otras propiedades del algoritmo PageRank, especialmente la sensibilidad del algoritmo, dependen de este valor [11]. En este método, estimamos el vector de longitud fj calculando una iteración de PageRank sobre el complemento estocástico × S, comenzando en el vector f: fj ≈ Sf. (11) Esto contrasta con el método simple descrito en la sección anterior, que primero itera sobre la matriz ( + 1) × ( + 1) PFj para estimar f+ j, y luego elimina el último componente de la estimación y renormaliza para aproximar fj. El problema con el último método radica en la elección del vector inicial de longitud ( + 1), ν. En consecuencia, la estimación de PageRank dada por el método simple difiere del verdadero PageRank en al menos 2αxj, donde xj es el PageRank de la página j. Al utilizar el complemento estocástico, podemos establecer un límite inferior estricto de cero para esta diferencia. Para ver esto, considera el caso en el que se agrega un nodo k a F para formar el subgrafo local aumentado Fk, y que el PageRank de este nuevo grafo es (1 − xk)f xk. Específicamente, la adición de la página k no cambia los PageRanks de las páginas en F, y por lo tanto fk = f. Por la construcción del complemento estocástico, fk = Sfk, por lo que la aproximación dada en la ecuación (11) producirá la solución exacta. A continuación, presentamos los detalles computacionales necesarios para calcular eficientemente la cantidad fj − f 1 sobre todas las páginas globales conocidas j. Comenzamos expandiendo la diferencia fj − f, donde el vector fj se estima como en (11), fj − f ≈ Sf − f = αF (DF + diag(uj))−1 f + (1 − α) e + 1 eT f +(1 − w)−1 (˜uT j f)˜s − f. (12) Tenga en cuenta que la matriz (DF + diag(uj))−1 es diagonal. Dejando que o[k] sea el recuento de enlaces de salida para la página k en F, podemos expresar el elemento diagonal k-ésimo como: (DF + diag(uj))−1 [k, k] = 1 o[k]+1 si uj[k] = 1 1 o[k] si uj[k] = 0 Notando que (o[k] + 1)−1 = o[k]−1 − (o[k](o[k] + 1))−1 y reescribiendo esto en forma matricial obtenemos (DF +diag(uj))−1 = D−1 F −D−1 F (DF +diag(uj))−1 diag(uj). (13) Usamos la misma identidad para expresar e + 1 = e − e ( + 1) . (14) Recordemos que, por definición, tenemos PF = αF D−1 F +(1−α)e. Sustituyendo (13) y (14) en (12) se obtiene que fj − f ≈ (PF f − f) −αF D−1 F (DF + diag(uj))−1 diag(uj)f −(1 − α) e ( + 1) + (1 − w)−1 (˜uT j f)˜s = x + y + (˜uT j f)z, (15), notando que por definición, f = PF f, y definiendo los vectores x, y, y z como x = −αF D−1 F (DF + diag(uj))−1 diag(uj)f (16) y = −(1 − α) e ( + 1) (17) z = (1 − w)−1 ˜s. (18) El primer término x es un vector disperso, y toma valores no nulos solo para las páginas locales k que son hermanas de la página global j. Definimos (i, j) ∈ F si y solo si F [j, i] = 1 (equivalentemente, la página i enlaza a la página j) y expresamos el valor del componente x[k] como: x[k] = −α k:(k,k)∈F, uj[k]=1 f[k] o[k](o[k] + 1), (19) donde o[k], como antes, es el número de enlaces salientes de la página k en el dominio local. Ten en cuenta que los dos últimos términos, y y z, no dependen del nodo global actual j. Dada la función hj(f) = y + (˜uT j f)z 1, la cantidad fj − f 1 120 Research Track Paper puede expresarse como fj − f 1 = k x[k] + y[k] + (˜uT j f)z[k] = k:x[k]=0 y[k] + (˜uT j f)z[k] + k:x[k]=0 x[k] + y[k] + (˜uT j f)z[k] = hj(f) − k:x[k]=0 y[k] + (˜uT j f)z[k] + k:x[k]=0 x[k] + y[k] + (˜uT j f)z[k]. (20) Si podemos calcular la función hj en tiempo lineal, entonces podemos calcular cada valor de fj − f 1 usando una cantidad adicional de tiempo proporcional al número de componentes no nulas en x. Estas optimizaciones se llevan a cabo en el Algoritmo 3. Nótese que la ecuación (20) calcula la diferencia entre todos los componentes de f y fj, mientras que nuestros criterios de selección de nodos, dados en la ecuación (7), se restringen a los componentes correspondientes a los nodos en el dominio local original L. Examinemos el Algoritmo 3 con más detalle. Primero, el algoritmo calcula el número de enlaces de salida para cada página en el dominio local. El algoritmo luego calcula la cantidad ˜uT j f para cada página global j conocida. Este producto interno se puede escribir como (1 − α) 1 + 1 + α k:(k,j)∈Fout f[k] o[k] + 1, donde el segundo término suma sobre el conjunto de páginas locales que enlazan a la página j. Dado que se asumió que el número total de aristas en Fout tenía un tamaño O( ) (recordemos que es el número de páginas en F), el tiempo de ejecución de este paso también es O( ). El algoritmo luego calcula los vectores y y z, como se indican en (17) y (18), respectivamente. El método L1NormDiff se llama en los componentes de estos vectores que corresponden a las páginas en L, y estima el valor de EL(y + (˜uT j f)z) 1 para cada página j. La estimación funciona de la siguiente manera. Primero, los valores de ˜uT j f se discretizan de forma uniforme en c valores {a1, ..., ac}. La cantidad EL(y + aiz) 1 se calcula entonces para cada valor discretizado de ai y se almacena en una tabla. Para evaluar EL (y + az) 1 para algún a ∈ [a1, ac], se determina el valor discretizado más cercano ai, y se utiliza la entrada correspondiente en la tabla. El tiempo total de ejecución de este método es lineal en y el parámetro de discretización c (que consideramos constante). Observamos que si se desean valores exactos, también hemos desarrollado un algoritmo que se ejecuta en tiempo O(log) que no se describe aquí. En el bucle principal, calculamos el vector x, tal como se define en la ecuación (16). Los bucles anidados iteran sobre el conjunto de páginas en F que son hermanas de la página j. Normalmente, el tamaño de este conjunto está limitado por una constante. Finalmente, para cada página j, el vector de puntuaciones se actualiza sobre el conjunto de componentes no nulos k del vector x con k ∈ L. Este conjunto tiene un tamaño igual al número de hermanos locales de la página j, y es un subconjunto del número total de hermanos de la página j. Por lo tanto, cada iteración del bucle principal toma tiempo constante, y el tiempo de ejecución total del bucle principal es O( ). Dado que hemos asumido que el tamaño de F no crecerá más allá de O(n), el tiempo de ejecución total del algoritmo es O(n). Algoritmo 3: Selección de nodos a través de la complementación estocástica. SC-Select(F , Fout, f, k) Entrada: F : matriz de adyacencia de ceros y unos del tamaño correspondiente al subgrafo local actual, Fout: matriz de enlaces de ceros y unos de F al subgrafo global, f: PageRank de F , k: número de páginas a devolver Salida: páginas: conjunto de k páginas para rastrear a continuación {Calcular sumas de enlaces de salida para el subgrafo local} para cada (página j ∈ F ) o[j] ← k:(j,k)∈F F[j, k] fin {Calcular escalar ˜uT j f para cada nodo global j } para cada (página j ∈ Fout) g[j] ← (1 − α) 1 +1 para cada (página k : (k, j) ∈ Fout) g[j] ← g[j] + α f[k] o[k]+1 fin fin {Calcular vectores y z como en (17) y (18) } y ← −(1 − α) e ( +1) z ← (1 − w)−1 ˜s {Aproximar y + g[j] ∗ z 1 para todos los valores g[j]} norm diffs ←L1NormDiffs(g, ELy, ELz) para cada (página j ∈ Fout) {Calcular vector disperso x como en (19)} x ← 0 para cada (página k : (k, j) ∈ Fout) para cada (página k : (k, k ) ∈ F )) x[k ] ← x[k ] − f[k] o[k](o[k]+1) fin fin x ← αx scores[j] ← norm diffs[j] para cada (k : x[k] > 0 y página k ∈ L) scores[j] ← scores[j] − |y[k] + g[j] ∗ z[k]| +|x[k]+y[k]+g[j]∗z[k])| fin fin Devolver k páginas con los puntajes más altos 5.2.2 Flujos de PageRank Ahora presentamos un análisis intuitivo del método de complementación estocástica descomponiendo el cambio en PageRank en términos de fugas y flujos. Este análisis está motivado por la descomposición dada en (15). El flujo de PageRank es el aumento en los PageRanks locales que se originan desde la página global j. Los flujos están representados por el vector no negativo (˜uT j f)z (ecuaciones (15) y (18)). El escalar ˜uT j f se puede pensar como la cantidad total de flujo de PageRank que la página j tiene disponible para distribuir. El vector z dicta cómo se asigna el flujo al dominio local; el flujo que recibe la página local k es proporcional (con un factor constante debido al vector de navegante aleatorio) al número esperado de sus enlaces entrantes. Las filtraciones de PageRank representan la disminución en el PageRank resultante de la adición de la página j. La fuga puede ser cuantificada en términos de los vectores no positivos x e y (ecuaciones (16) y (17)). Para el vector x, podemos ver a partir de la ecuación (19) que la cantidad de PageRank filtrado por una página local es proporcional a la suma ponderada de los Page121 Research Track Paper Ranks de sus páginas hermanas. Por lo tanto, las páginas que tienen hermanos con PageRanks más altos (y un bajo número de enlaces salientes) experimentarán más pérdida de valor. La fuga causada por y es un artefacto del vector del surfista aleatorio. A continuación demostraremos que si solo se considera el término de flujo, (˜uT j f)z, entonces el método resultante es muy similar a una heurística propuesta por Cho et al. [6] que ha sido ampliamente utilizada para el problema de Ordenación de URL en el Rastreo. Esta heurística es computacionalmente más económica, pero como veremos más adelante, no es tan efectiva como el método de Complementación Estocástica. Nuestra estrategia de selección de nodos elige nodos globales que tienen la mayor influencia (ecuación (7)). Si esta influencia se aproxima utilizando solo flujos, el nodo óptimo j∗ es: j∗ = argmaxj EL ˜uT j fz 1 = argmaxj ˜uT j f EL z 1 = argmaxj ˜uT j f = argmaxj α(DF + diag(uj))−1 uj + (1 − α) e + 1 , f = argmaxjfT (DF + diag(uj))−1 uj. La puntuación de selección de página resultante se puede expresar como la suma de los PageRanks de cada página local k que enlaza con j, donde cada valor de PageRank se normaliza por o[k]+1. Curiosamente, la normalización que surge en nuestro método difiere de la heurística dada en [6], la cual normaliza por o[k]. El algoritmo PF-Select, que se omite por falta de espacio, primero calcula la cantidad fT (DF +diag(uj))−1 uj para cada página global j, y luego devuelve las páginas con los k puntajes más altos. Para ver que el tiempo de ejecución de este algoritmo es O(n), observe que la computación involucrada en este método es un subconjunto de la necesaria para el método SC-Select (Algoritmo 3), el cual se demostró que tiene un tiempo de ejecución de O(n). 6. EXPERIMENTOS En esta sección, proporcionamos evidencia experimental para verificar la efectividad de nuestros algoritmos. Primero describimos nuestra metodología experimental y luego presentamos resultados en una variedad de dominios locales. 6.1 Metodología Dado los recursos limitados disponibles en una institución académica, rastrear una sección de la web que sea de la misma magnitud que la indexada por Google o Yahoo! claramente es inviable. Por lo tanto, para un dominio local dado, aproximamos el grafo global rastreando un vecindario local alrededor del dominio que es varias órdenes de magnitud más grande que el subgrafo local. A pesar de que dicho gráfico sigue siendo órdenes de magnitud más pequeño que el verdadero gráfico global, sostenemos que, incluso si existen algunas páginas altamente influyentes que están muy lejos de nuestro dominio local, es poco realista que cualquier algoritmo de selección de nodos locales las encuentre. Tales páginas suelen ser muy poco relacionadas con las páginas dentro del dominio local. Al explicar nuestras estrategias de selección de nodos en la sección 5, hicimos la suposición simplificadora de que nuestro grafo local no contenía nodos colgantes. Esta suposición se hizo solo para facilitar nuestro análisis. Nuestra implementación maneja de manera eficiente los enlaces colgantes al reemplazar cada columna de ceros de nuestra matriz de adyacencia con el vector uniforme. Evaluamos el algoritmo utilizando las dos estrategias de selección de nodos dadas en la Sección 5.2, y también comparándolo con los siguientes métodos de referencia: • Aleatorio: Los nodos se eligen de forma uniforme al azar entre los nodos globales conocidos. • Conteo de enlaces de salida: Se eligen los nodos globales con el mayor número de enlaces de salida desde el dominio local. En cada iteración del algoritmo FindGlobalPR, evaluamos el rendimiento calculando la diferencia entre la estimación actual de PageRank del dominio local, ELf ELf 1, y el PageRank global del dominio local, ELg ELg 1. Todas las calculaciones de PageRank se realizaron utilizando el vector de surfista aleatorio uniforme. En todos los experimentos, establecimos el parámetro del surfista aleatorio α en .85 y utilizamos un umbral de convergencia de 10−6. Evaluamos la diferencia entre los vectores de PageRank local y global utilizando tres métricas diferentes: las normas L1 y L∞, y el tau de Kendall. La norma L1 mide la suma del valor absoluto de las diferencias entre los dos vectores, y la norma L∞ mide el valor absoluto de la mayor diferencia. La métrica de tau de Kendall es una medida de correlación de rangos popular utilizada para comparar PageRanks [2, 11]. Esta métrica se puede calcular contando el número de pares de pares que coinciden en la clasificación, y restando de eso el número de pares de pares que no coinciden en la clasificación. El valor final se normaliza luego por el número total de n pares de este tipo, resultando en un rango de [−1, 1], donde una puntuación negativa indica una anticorrelación entre las clasificaciones, y valores cercanos a uno corresponden a una fuerte correlación de rangos. 6.2 Resultados Nuestros experimentos se basan en dos grandes rastreos web y se descargaron utilizando el rastreador web que forma parte del proyecto de motor de búsqueda de código abierto Nutch [18]. Todas las exploraciones se limitaron únicamente a páginas http, y para limitar el número de páginas generadas dinámicamente que exploramos, ignoramos todas las páginas con URLs que contengan alguno de los caracteres ?, *, @ o =. El primer rastreo, al que nos referiremos como el conjunto de datos edu, fue iniciado por las páginas de inicio de los 100 principales departamentos de posgrado en informática en los Estados Unidos, según la clasificación de US News and World Report [16], y también por las páginas de inicio de sus respectivas instituciones. Se realizó un rastreo de profundidad 5, restringido a páginas dentro del dominio .edu, lo que resultó en un grafo con aproximadamente 4.7 millones de páginas y 22.9 millones de enlaces. El segundo rastreo fue alimentado por el conjunto de páginas bajo la jerarquía de política en el proyecto de directorio abierto dmoz[17]. Rastreamos todas las páginas hasta cuatro enlaces de distancia, lo que resultó en un grafo con 4.4 millones de páginas y 17.3 millones de enlaces. Dentro del rastreo educativo, identificamos los cinco dominios específicos del sitio correspondientes a los sitios web de los cinco principales departamentos de posgrado en ciencias de la computación, según la clasificación de US News and World Report. Esto produjo dominios locales de varios tamaños, desde 10,626 (UIUC) hasta 59,895 (Berkeley). Para cada uno de estos dominios específicos del sitio con tamaño n, realizamos 50 iteraciones del algoritmo FindGlobalPR para rastrear un total de 2n nodos adicionales. La Figura 2(a) muestra la diferencia (L1) entre la estimación de PageRank en cada iteración y el PageRank global, para el dominio local de Berkeley. El rendimiento de este conjunto de datos fue representativo del rendimiento típico en los cinco dominios locales específicos de informática. Inicialmente, la diferencia de L1 entre los PageRanks globales y locales variaba desde .0469 (Stanford) hasta .149 (MIT). Para las primeras varias iteraciones, el Artículo de Investigación 122 0 5 10 15 20 25 30 35 40 45 50 0.015 0.02 0.025 0.03 0.035 0.04 0.045 0.05 0.055 Número de Iteraciones Diferencia de PageRank Global y Local (L1) Complemento Estocástico PageRank Flujo de Enlaces de Conteo Aleatorio 0 10 20 30 40 50 0 0.05 0.1 0.15 0.2 0.25 0.3 0.35 Número de Iteraciones Diferencia de PageRank Global y Local (L1) Complemento Estocástico PageRank Flujo de Enlaces de Conteo Aleatorio 0 5 10 15 20 25 0.16 0.18 0.2 0.22 0.24 0.26 0.28 0.3 0.32 0.34 Número de Iteraciones Diferencia de PageRank Global y Local (L1) Complemento Estocástico PageRank Flujo de Enlaces de Conteo Aleatorio (a) www.cs.berkeley.edu (b) www.enterstageright.com (c) Política Figura 2: Diferencia L1 entre los PageRanks globales estimados y verdaderos para (a) el sitio web de ciencias de la computación de Berkeley, (b) el dominio específico del sitio, www.enterstageright.com, y (c) el dominio específico del tema de política. El método de complemento estocástico supera a todos los demás métodos en diferentes dominios. Tres métodos basados en enlaces superan a la heurística de selección aleatoria. Después de estas iteraciones iniciales, la heurística aleatoria tendió a ser más competitiva con (o incluso superar, como en el dominio local de Berkeley) las heurísticas de conteo de enlaces de salida y flujo de PageRank. En todos los ensayos, el método de complementación estocástica superó a los otros métodos o compitió con ellos. La Tabla 1 muestra la diferencia promedio entre los PageRanks globales estimados finales y los PageRanks globales reales para varias medidas de distancia. Algoritmo L1 L∞ Kendall Estocástico. Tabla 1: Rendimiento final promedio de varias estrategias de selección de nodos para los cinco dominios locales de informática específicos del sitio. Ten en cuenta que el Tau de Kendall mide similitud, mientras que las otras métricas son medidas de disimilitud. La Complementación Estocástica claramente supera a los otros métodos en todas las métricas. Dentro del conjunto de datos de política, también realizamos dos pruebas específicas para los sitios web más grandes en el rastreo: www.adamsmith.org, el sitio web del Instituto Adam Smith con sede en Londres, y www.enterstageright.com, una revista en línea conservadora. Al igual que con los dominios locales de edu, ejecutamos nuestro algoritmo durante 50 iteraciones, rastreando un total de 2n nodos. La figura 2 (b) muestra los resultados para el dominio www.enterstageright.com. A diferencia de los dominios locales de edu, los métodos Random y OutlinkCount no fueron competitivos ni con los métodos SC-Select ni con los métodos PF-Select. Entre todos los conjuntos de datos y todos los métodos de selección de nodos, el método de complementación estocástica fue el más impresionante en este conjunto de datos, logrando una estimación final que difería solo .0279 del PageRank global, una mejora de diez veces sobre la diferencia inicial del PageRank local de .299. Para el dominio local de Adam Smith, la diferencia inicial entre los PageRanks locales y globales fue de .148, y las estimaciones finales proporcionadas por los métodos SC-Select, PF-Select, OutlinkCount y Random fueron de .0208, .0193, .0222 y .0356, respectivamente. Dentro del conjunto de datos de política, construimos cuatro dominios locales específicos de temas. El primer dominio consistía en todas las páginas de la categoría de política de dmoz, y también todas las páginas dentro de cada uno de estos sitios hasta dos enlaces de distancia. Esto produjo un dominio local de 90,811 páginas, y los resultados se muestran en la figura 2 (c). Debido al mayor tamaño de los dominios específicos del tema, ejecutamos nuestro algoritmo solo durante 25 iteraciones para rastrear un total de n nodos. También creamos dominios específicos de temas a partir de tres subtemas políticos: liberalismo, conservadurismo y socialismo. Las páginas en estos dominios fueron identificadas por sus categorías correspondientes de dmoz. Para cada subtema, establecemos el dominio local como todas las páginas dentro de tres enlaces de las páginas de categoría dmoz correspondientes. La Tabla 2 resume el rendimiento de estos tres dominios específicos del tema, así como también del dominio político más amplio. Para cuantificar el efecto global de una página js en los valores globales de PageRank de las páginas en el dominio local, definimos el impacto de la página js como su valor de PageRank, g[j], normalizado por la fracción de sus enlaces salientes que apuntan al dominio local: impacto(j) = oL[j] o[j] · g[j], donde oL[j] es el número de enlaces salientes de la página j a páginas en el dominio local L, y o[j] es el número total de enlaces salientes de js. En términos del modelo del surfista aleatorio, el impacto de la página j es la probabilidad de que el surfista aleatorio (1) se encuentre actualmente en la página global j en su caminata aleatoria y (2) tome un enlace de salida a una página local, dado que ya ha decidido no saltar a una página aleatoria. Para el dominio político local, encontramos que muchas de las páginas con alto impacto eran de hecho páginas políticas que deberían haber sido incluidas en el tema de política de dmoz, pero no lo estaban. Por ejemplo, las dos páginas globales más influyentes fueron el motor de búsqueda político www.askhenry.com y la página de inicio de la revista política en línea www.policyreview.com. Entre las páginas no políticas, la página de inicio de la revista Education Next fue la más influyente. El diario está disponible de forma gratuita en línea y contiene artículos sobre varios aspectos de la educación K-12 en América. Para proporcionar algunas pruebas anecdóticas de la efectividad de nuestros métodos de selección de páginas, observamos que el método SC-Select eligió 11 páginas dentro del dominio www.educationnext.org, el método PF-Select descubrió 7 páginas, mientras que los métodos OutlinkCount y Random encontraron solo 6 páginas cada uno. Para el ámbito político local conservador, el sitio web socialista www.ornery.org tuvo una puntuación de impacto muy alta. Este documento de investigación de la pista 123 titulado \"Toda la política: Algoritmo L1 L2 Kendall Stoch\". Comp. .1253 .000700 .8671 Flujo PR .1446 .000710 .8518 Enlace saliente .1470 .00225 .8642 Aleatorio .2055 .00203 .8271 Conservadurismo: Algoritmo L1 L2 Kendall Estoc. Comp. .0496 .000990 .9158 Flujo PR .0554 .000939 .9028 Enlace saliente .0602 .00527 .9144 Aleatorio .1197 .00102 .8843 Liberalismo: Algoritmo L1 L2 Kendall Estoc. Comp. .0622 .001360 .8848 Flujo PR .0799 .001378 .8669 Enlace saliente .0763 .001379 .8844 Aleatorio .1127 .001899 .8372 Socialismo: Algoritmo L1 L∞ Kendall Estoc. Tabla 2: Rendimiento final entre estrategias de selección de nodos para las cuatro exploraciones específicas de temas políticos. Ten en cuenta que el coeficiente de correlación de Kendall mide la similitud, mientras que las otras métricas son medidas de disimilitud. Como era de esperar, el PageRank global de este artículo (que resulta estar en la página de inicio de la NCCPR, www.nationalresearch.com) era aproximadamente de .002, mientras que el PageRank local de esta página era solo de .00158. El método SC-Select produjo una estimación global de PageRank de aproximadamente .00182, el método PFSelect estimó un valor de .00167, y los métodos Random y OutlinkCount produjeron valores de .01522 y .00171, respectivamente. TRABAJO RELACIONADO El marco de selección de nodos que hemos propuesto es similar al problema de ordenación de URL para el rastreo propuesto por Cho et al. en [6]. Mientras que nuestro marco busca minimizar la diferencia entre el PageRank global y local, el objetivo utilizado en [6] es rastrear primero las páginas más altamente clasificadas (globalmente). Proponen varios algoritmos de selección de nodos, incluyendo la heurística del recuento de enlaces de salida, así como una variante de nuestro algoritmo PF-Select al que se refieren como la métrica de ordenación de PageRank. Encontraron que este método era el más efectivo para optimizar su objetivo, al igual que lo demostró una encuesta reciente de estos métodos realizada por Baeza-Yates et al. [1]. Boldi et al. también experimentan dentro de un marco de rastreo similar en [2], pero cuantifican sus resultados al comparar la correlación de rangos de Kendall entre los PageRanks del conjunto actual de páginas rastreadas y los del grafo global completo. Encontraron que las estrategias de selección de nodos que rastreaban páginas con el PageRank global más alto primero en realidad tenían un peor rendimiento (con respecto a la correlación de Kendalls Tau entre los PageRanks locales y globales) que las estrategias básicas de búsqueda en profundidad o en amplitud. Sin embargo, sus experimentos difieren de nuestro trabajo en que nuestros algoritmos de selección de nodos no utilizan (ni tienen acceso a) valores globales de PageRank. Se han propuesto muchas mejoras algorítmicas para calcular los valores exactos de PageRank [9, 10, 14]. Si se utilizan tales algoritmos para calcular los PageRanks globales de nuestro dominio local, todos requerirían una computación, almacenamiento y ancho de banda de O(N), donde N es el tamaño del dominio global. Esto contrasta con nuestro método, que aproxima el PageRank global y escala linealmente con el tamaño del dominio local. Wang y Dewitt [22] proponen un sistema en el que el conjunto de servidores web que conforman el dominio global se comunican entre sí para calcular sus respectivos PageRanks globales. Para un servidor web dado que aloja n páginas, los requisitos computacionales, de ancho de banda y almacenamiento también son lineales en n. Una desventaja de este sistema es que el número de servidores web distintos que conforman el dominio global puede ser muy grande. Por ejemplo, nuestro conjunto de datos edu contiene sitios web de más de 3,200 universidades diferentes; coordinar un sistema así entre un gran número de sitios puede ser muy difícil. Gan, Chen y Suel proponen un método para estimar el PageRank de una sola página [5] que utiliza solo ancho de banda, computación y espacio constantes. Su enfoque se basa en la disponibilidad de un servidor de conectividad remota que puede suministrar el conjunto de enlaces entrantes a una página dada, una suposición que no se utiliza en nuestro marco de trabajo. Experimentalmente demuestran que se puede obtener una estimación razonable del PageRank de los nodos visitando como máximo unos pocos cientos de nodos. El uso de su algoritmo para nuestro problema requeriría que primero se descargue todo el dominio global o se utilice un servidor de conectividad, lo que resultaría en grafos web muy grandes. 8. CONCLUSIONES Y TRABAJOS FUTUROS Internet está creciendo de forma exponencial, y para poder navegar por un repositorio tan grande como la web, los motores de búsqueda globales se han establecido como una necesidad. Junto con la omnipresencia de estos motores de búsqueda a gran escala, surge un aumento en las expectativas de los usuarios de búsqueda. Al proporcionar una cobertura completa y aislada de un dominio web específico, los motores de búsqueda localizados son un medio efectivo para localizar rápidamente contenido que de otra manera podría ser difícil de encontrar. En este trabajo, sostenemos que el uso de PageRank global en un motor de búsqueda localizado puede mejorar el rendimiento. Para estimar el PageRank global, hemos propuesto un marco de selección de nodos iterativo en el que seleccionamos qué páginas de la frontera global rastrear a continuación. Nuestra principal contribución es nuestro algoritmo de selección de páginas de complementación estocástica. Este método recorre los nodos que tendrán un impacto significativo en el dominio local y tiene un tiempo de ejecución lineal en el número de nodos en el dominio local. Experimentalmente, validamos estos métodos en un conjunto diverso de dominios locales, que incluyen siete dominios específicos del sitio y cuatro dominios específicos del tema. Concluimos que al rastrear n o 2n páginas adicionales, nuestros métodos encuentran una estimación de los PageRanks globales que es hasta diez veces mejor que simplemente usar los PageRanks locales. Además, demostramos que nuestro algoritmo supera consistentemente a otras heurísticas existentes. En muchas ocasiones, los dominios específicos de un tema se descubren utilizando un rastreador web enfocado que considera el contenido de las páginas junto con el texto del ancla del enlace para decidir qué páginas rastrear a continuación [4]. Aunque estos rastreadores han demostrado ser bastante efectivos en descubrir contenido relacionado con el tema, también se rastrean muchas páginas irrelevantes en el proceso. Por lo general, estas páginas son eliminadas y no son indexadas por el motor de búsqueda localizado. Estas páginas pueden, por supuesto, proporcionar información valiosa sobre el PageRank global del dominio local. Una forma de integrar estas páginas en nuestro marco de trabajo es comenzar el algoritmo FindGlobalPR con el subgrafo actual F igual al conjunto de páginas que fueron rastreadas por el rastreador enfocado. El marco de estimación global de PageRank, junto con los algoritmos de selección de nodos presentados, requieren todos una computación de O(n) por iteración y un ancho de banda proporcional al número de páginas rastreadas, Tk. Si el número de iteraciones T es relativamente pequeño en comparación con el número de páginas rastreadas por iteración, k, entonces el cuello de botella del algoritmo será la fase de rastreo. Sin embargo, a medida que el número de iteraciones aumenta (en relación con k), el cuello de botella residirá en el cálculo de la selección de nodos. En este caso, nuestros algoritmos se beneficiarían de optimizaciones en el factor constante. Recuerde que el algoritmo FindGlobalPR (Algoritmo 2) requiere que los PageRanks del dominio local expandido actual se vuelvan a calcular en cada iteración. El trabajo reciente de Langville y Meyer [12] proporciona un algoritmo para recalcular rápidamente los PageRanks de un grafo web dado si se agregan un pequeño número de nodos. Este algoritmo demostró proporcionar una aceleración de cinco a diez veces en algunos conjuntos de datos. Planeamos investigar esto y otras optimizaciones similares como trabajo futuro. En este artículo, hemos evaluado objetivamente nuestros métodos midiendo qué tan cercanas son nuestras estimaciones globales de PageRank a los verdaderos PageRanks globales. Para determinar el beneficio de utilizar PageRanks globales en un motor de búsqueda localizado, sugerimos un estudio de usuarios en el que se les pida a los usuarios que califiquen la calidad de los resultados de búsqueda para varias consultas de búsqueda. Para algunas consultas, solo se utilizan los PageRanks locales en la clasificación, y para las consultas restantes, se utilizan los PageRanks locales y los PageRanks globales aproximados, según lo calculado por nuestros algoritmos. Los resultados de dicho estudio pueden ser analizados para determinar el beneficio adicional de utilizar los PageRanks globales calculados por nuestros métodos, en lugar de solo utilizar los PageRanks locales. Agradecimientos. Esta investigación fue apoyada por la subvención de la NSF CCF-0431257, el Premio de Carrera de la NSF ACI-0093404 y una subvención de Sabre, Inc. 9. REFERENCIAS [1] R. Baeza-Yates, M. Marín, C. Castillo y A. Rodríguez. Rastreando un país: estrategias mejores que el recorrido en anchura para ordenar páginas web. Conferencia de la World-Wide Web, 2005. [2] P. Boldi, M. Santini y S. Vigna. Haz lo peor para lograr lo mejor: efectos paradójicos en los cálculos incrementales de PageRank. Taller sobre Grafos Web, 3243:168-180, 2004. [3] S. Brin y L. Page. La anatomía de un motor de búsqueda web hipertextual a gran escala. Redes de Computadoras y Sistemas ISDN, 33(1-7):107-117, 1998. [4] S. Chakrabarti, M. van den Berg y B. Dom. Rastreo enfocado: un nuevo enfoque para el descubrimiento de recursos web específicos de un tema. Conferencia de la World-Wide Web, 1999. [5] Y. Chen, Q. Gan y T. Suel. Métodos locales para estimar los valores de pagerank. Conferencia sobre Gestión de Información y Conocimiento, 2004. [6] J. Cho, H. Garcia-Molina y L. Page. Rastreo eficiente a través de la ordenación de URL. Conferencia de la World-Wide Web, 1998. [7] T. H. Haveliwala y S. D. Kamvar. El segundo valor propio de la matriz de Google. Informe técnico, Universidad de Stanford, 2003. [8] T. Joachims, F. Radlinski, L. Granka, A. Cheng, C. Tillekeratne y A. Patel. Aprendizaje de funciones de recuperación a partir de retroalimentación implícita. http://www.cs.cornell.edu/People/tj/career. [9] S. D. Kamvar, T. H. Haveliwala, C. D. Manning y G. H. Golub. Explotando la estructura de bloques de la web para calcular el pagerank. Conferencia de la World-Wide Web, 2003. [10] S. D. Kamvar, T. H. Haveliwala, C. D. Manning y G. H. Golub. Métodos de extrapolación para acelerar el cálculo de PageRank. Conferencia de la World-Wide Web, 2003. [11] A. N. Langville y C. D. Meyer. Más profundo dentro de PageRank. Matemáticas en Internet, 2004. [12] A. N. Langville y C. D. Meyer. Actualizando el vector estacionario de una cadena de Markov irreducible con miras al PageRank de Google. Revista SIAM sobre Análisis de Matrices, 2005. [13] P. Lyman, H. R. Varian, K. Swearingen, P. Charles, N. Good, L. L. Jordan y J. Pal. ¿Cuánta información en 2003? Escuela de Gestión de la Información y Sistemas, Universidad de California en Berkeley, 2003. [14] F. McSherry. Un enfoque uniforme para el cálculo acelerado de PageRank. Conferencia de la World-Wide Web, 2005. [15] C. D. Meyer. Complementación estocástica, desacoplamiento de cadenas de Markov y la teoría de sistemas casi reducibles. SIAM Review, 31:240-272, 1989. [16] US News and World Report. http://www.usnews.com. [17] Proyecto de directorio abierto Dmoz. http://www.dmoz.org. [18] Motor de búsqueda de código abierto Nutch. http://www.nutch.org. [19] F. Radlinski y T. Joachims. Cadenas de consulta: aprendizaje para clasificar a partir de retroalimentación implícita. Conferencia Internacional ACM SIGKDD sobre Descubrimiento de Conocimiento y Minería de Datos, 2005. [20] S. Raghavan y H. Garcia-Molina. Explorando la web oculta. En Actas de la Vigésimo séptima Conferencia Internacional sobre Bases de Datos Muy Grandes, 2001. [21] T. Tin Tang, D. Hawking, N. Craswell y K. Griffiths. Rastreo enfocado para relevancia temática y calidad de la información médica. Conferencia sobre Gestión de Información y Conocimiento, 2005. [22] Y. Wang y D. J. DeWitt. Calculando el pagerank en un sistema distribuido de búsqueda en internet. Actas de la 30ª Conferencia VLDB, 2004. 125 Artículos de Investigación. ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "localized search engine": {
            "translated_key": "motor de búsqueda localizado",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Estimating the Global PageRank of Web Communities Jason V. Davis Dept.",
                "of Computer Sciences University of Texas at Austin Austin, TX 78712 jdavis@cs.utexas.edu Inderjit S. Dhillon Dept. of Computer Sciences University of Texas at Austin Austin, TX 78712 inderjit@cs.utexas.edu ABSTRACT Localized search engines are small-scale systems that index a particular community on the web.",
                "They offer several benefits over their large-scale counterparts in that they are relatively inexpensive to build, and can provide more precise and complete search capability over their relevant domains.",
                "One disadvantage such systems have over large-scale search engines is the lack of global PageRank values.",
                "Such information is needed to assess the value of pages in the localized search domain within the context of the web as a whole.",
                "In this paper, we present well-motivated algorithms to estimate the global PageRank values of a local domain.",
                "The algorithms are all highly scalable in that, given a local domain of size n, they use O(n) resources that include computation time, bandwidth, and storage.",
                "We test our methods across a variety of localized domains, including site-specific domains and topic-specific domains.",
                "We demonstrate that by crawling as few as n or 2n additional pages, our methods can give excellent global PageRank estimates.",
                "Categories and Subject Descriptors H.3.3 [Information Storage and Retrieval]: Information Search and Retrieval; G.1.3 [Numerical Analysis]: Numerical Linear Algebra; G.3 [Probability and Statistics]: Markov Processes General Terms PageRank, Markov Chain, Stochastic Complementation 1.",
                "INTRODUCTION Localized search engines are small-scale search engines that index only a single community of the web.",
                "Such communities can be site-specific domains, such as pages within the cs.utexas.edu domain, or topic-related communitiesfor example, political websites.",
                "Compared to the web graph crawled and indexed by large-scale search engines, the size of such local communities is typically orders of magnitude smaller.",
                "Consequently, the computational resources needed to build such a search engine are also similarly lighter.",
                "By restricting themselves to smaller, more manageable sections of the web, localized search engines can also provide more precise and complete search capabilities over their respective domains.",
                "One drawback of localized indexes is the lack of global information needed to compute link-based rankings.",
                "The PageRank algorithm [3], has proven to be an effective such measure.",
                "In general, the PageRank of a given page is dependent on pages throughout the entire web graph.",
                "In the context of a <br>localized search engine</br>, if the PageRanks are computed using only the local subgraph, then we would expect the resulting PageRanks to reflect the perceived popularity within the local community and not of the web as a whole.",
                "For example, consider a <br>localized search engine</br> that indexes political pages with conservative views.",
                "A person wishing to research the opinions on global warming within the conservative political community may encounter numerous such opinions across various websites.",
                "If only local PageRank values are available, then the search results will reflect only strongly held beliefs within the community.",
                "However, if global PageRanks are also available, then the results can additionally reflect outsiders views of the conservative community (those documents that liberals most often access within the conservative community).",
                "Thus, for many localized search engines, incorporating global PageRanks can improve the quality of search results.",
                "However, the number of pages a local search engine indexes is typically orders of magnitude smaller than the number of pages indexed by their large-scale counterparts.",
                "Localized search engines do not have the bandwidth, storage capacity, or computational power to crawl, download, and compute the global PageRanks of the entire web.",
                "In this work, we present a method of approximating the global PageRanks of a local domain while only using resources of the same order as those needed to compute the PageRanks of the local subgraph.",
                "Our proposed method looks for a supergraph of our local subgraph such that the local PageRanks within this supergraph are close to the true global PageRanks.",
                "We construct this supergraph by iteratively crawling global pages on the current web frontier-i.e., global pages with inlinks from pages that have already been crawled.",
                "In order to provide 116 Research Track Paper a good approximation to the global PageRanks, care must be taken when choosing which pages to crawl next; in this paper, we present a well-motivated page selection algorithm that also performs well empirically.",
                "This algorithm is derived from a well-defined problem objective and has a running time linear in the number of local nodes.",
                "We experiment across several types of local subgraphs, including four topic related communities and several sitespecific domains.",
                "To evaluate performance, we measure the difference between the current global PageRank estimate and the global PageRank, as a function of the number of pages crawled.",
                "We compare our algorithm against several heuristics and also against a baseline algorithm that chooses pages at random, and we show that our method outperforms these other methods.",
                "Finally, we empirically demonstrate that, given a local domain of size n, we can provide good approximations to the global PageRank values by crawling at most n or 2n additional pages.",
                "The paper is organized as follows.",
                "Section 2 gives an overview of localized search engines and outlines their advantages over global search.",
                "Section 3 provides background on the PageRank algorithm.",
                "Section 4 formally defines our problem, and section 5 presents our page selection criteria and derives our algorithms.",
                "Section 6 provides experimental results, section 7 gives an overview of related work, and, finally, conclusions are given in section 8. 2.",
                "LOCALIZED SEARCH ENGINES Localized search engines index a single community of the web, typically either a site-specific community, or a topicspecific community.",
                "Localized search engines enjoy three major advantages over their large-scale counterparts: they are relatively inexpensive to build, they can offer more precise search capability over their local domain, and they can provide a more complete index.",
                "The resources needed to build a global search engine are enormous.",
                "A 2003 study by Lyman et al. [13] found that the surface web (publicly available static sites) consists of 8.9 billion pages, and that the average size of these pages is approximately 18.7 kilobytes.",
                "To download a crawl of this size, approximately 167 terabytes of space is needed.",
                "For a researcher who wishes to build a search engine with access to a couple of workstations or a small server, storage of this magnitude is simply not available.",
                "However, building a <br>localized search engine</br> over a web community of a hundred thousand pages would only require a few gigabytes of storage.",
                "The computational burden required to support search queries over a database this size is more manageable as well.",
                "We note that, for topic-specific search engines, the relevant community can be efficiently identified and downloaded by using a focused crawler [21, 4].",
                "For site-specific domains, the local domain is readily available on their own web server.",
                "This obviates the need for crawling or spidering, and a complete and up-to-date index of the domain can thus be guaranteed.",
                "This is in contrast to their large-scale counterparts, which suffer from several shortcomings.",
                "First, crawling dynamically generated pages-pages in the hidden web-has been the subject of research [20] and is a non-trivial task for an external crawler.",
                "Second, site-specific domains can enable the robots exclusion policy.",
                "This prohibits external search engines crawlers from downloading content from the domain, and an external search engine must instead rely on outside links and anchor text to index these restricted pages.",
                "By restricting itself to only a specific domain of the internet, a <br>localized search engine</br> can provide more precise search results.",
                "Consider the canonical ambiguous search query, jaguar, which can refer to either the car manufacturer or the animal.",
                "A scientist trying to research the habitat and evolutionary history of a jaguar may have better success using a finely tuned zoology-specific search engine than querying Google with multiple keyword searches and wading through irrelevant results.",
                "A method to learn better ranking functions for retrieval was recently proposed by Radlinski and Joachims [19] and has been applied to various local domains, including Cornell Universitys website [8]. 3.",
                "PAGERANK OVERVIEW The PageRank algorithm defines the importance of web pages by analyzing the underlying hyperlink structure of a web graph.",
                "The algorithm works by building a Markov chain from the link structure of the web graph and computing its stationary distribution.",
                "One way to compute the stationary distribution of a Markov chain is to find the limiting distribution of a random walk over the chain.",
                "Thus, the PageRank algorithm uses what is sometimes referred to as the random surfer model.",
                "In each step of the random walk, the surfer either follows an outlink from the current page (i.e. the current node in the chain), or jumps to a random page on the web.",
                "We now precisely define the PageRank problem.",
                "Let U be an m × m adjacency matrix for a given web graph such that Uji = 1 if page i links to page j and Uji = 0 otherwise.",
                "We define the PageRank matrix PU to be: PU = αUD−1 U + (1 − α)veT , (1) where DU is the (unique) diagonal matrix such that UD−1 U is column stochastic, α is a given scalar such that 0 ≤ α ≤ 1, e is the vector of all ones, and v is a non-negative, L1normalized vector, sometimes called the random surfer vector.",
                "Note that the matrix D−1 U is well-defined only if each column of U has at least one non-zero entry-i.e., each page in the webgraph has at least one outlink.",
                "In the presence of such dangling nodes that have no outlinks, one commonly used solution, proposed by Brin et al. [3], is to replace each zero column of U by a non-negative, L1-normalized vector.",
                "The PageRank vector r is the dominant eigenvector of the PageRank matrix, r = PU r. We will assume, without loss of generality, that r has an L1-norm of one.",
                "Computationally, r can be computed using the power method.",
                "This method first chooses a random starting vector r(0) , and iteratively multiplies the current vector by the PageRank matrix PU ; see Algorithm 1.",
                "In general, each iteration of the power method can take O(m2 ) operations when PU is a dense matrix.",
                "However, in practice, the number of links in a web graph will be of the order of the number of pages.",
                "By exploiting the sparsity of the PageRank matrix, the work per iteration can be reduced to O(km), where k is the average number of links per web page.",
                "It has also been shown that the total number of iterations needed for convergence is proportional to α and does not depend on the size of the web graph [11, 7].",
                "Finally, the total space needed is also O(km), mainly to store the matrix U. 117 Research Track Paper Algorithm 1: A linear time (per iteration) algorithm for computing PageRank.",
                "ComputePR(U) Input: U: Adjacency matrix.",
                "Output: r: PageRank vector.",
                "Choose (randomly) an initial non-negative vector r(0) such that r(0) 1 = 1. i ← 0 repeat i ← i + 1 ν ← αUD−1 U r(i−1) {α is the random surfing probability} r(i) ← ν + (1 − α)v {v is the random surfer vector.} until r(i) − r(i−1) < δ {δ is the convergence threshold.} r ← r(i) 4.",
                "PROBLEM DEFINITION Given a local domain L, let G be an N × N adjacency matrix for the entire connected component of the web that contains L, such that Gji = 1 if page i links to page j and Gji = 0 otherwise.",
                "Without loss of generality, we will partition G as: G = L Gout Lout Gwithin , (2) where L is the n × n local subgraph corresponding to links inside the local domain, Lout is the subgraph that corresponds to links from the local domain pointing out to the global domain, Gout is the subgraph containing links from the global domain into the local domain, and Gwithin contains links within the global domain.",
                "We assume that when building a <br>localized search engine</br>, only pages inside the local domain are crawled, and the links between these pages are represented by the subgraph L. The links in Lout are also known, as these point from crawled pages in the local domain to uncrawled pages in the global domain.",
                "As defined in equation (1), PG is the PageRank matrix formed from the global graph G, and we define the global PageRank vector of this graph to be g. Let the n-length vector p∗ be the L1-normalized vector corresponding to the global PageRank of the pages in the local domain L: p∗ = EL g ELg 1 , where EL = [ I | 0 ] is the restriction matrix that selects the components from g corresponding to nodes in L. Let p denote the PageRank vector constructed from the local domain subgraph L. In practice, the observed local PageRank p and the global PageRank p∗ will be quite different.",
                "One would expect that as the size of local matrix L approaches the size of global matrix G, the global PageRank and the observed local PageRank will become more similar.",
                "Thus, one approach to estimating the global PageRank is to crawl the entire global domain, compute its PageRank, and extract the PageRanks of the local domain.",
                "Typically, however, n N , i.e., the number of global pages is much larger than the number of local pages.",
                "Therefore, crawling all global pages will quickly exhaust all local resources (computational, storage, and bandwidth) available to create the local search engine.",
                "We instead seek a supergraph ˆF of our local subgraph L with size O(n).",
                "Our goal Algorithm 2: The FindGlobalPR algorithm.",
                "FindGlobalPR(L, Lout, T, k) Input: L: zero-one adjacency matrix for the local domain, Lout: zero-one outlink matrix from L to global subgraph as in (2), T: number of iterations, k: number of pages to crawl per iteration.",
                "Output: ˆp: an improved estimate of the global PageRank of L. F ← L Fout ← Lout f ← ComputePR(F ) for (i = 1 to T) {Determine which pages to crawl next} pages ← SelectNodes(F , Fout, f, k) Crawl pages, augment F and modify Fout {Update PageRanks for new local domain} f ← ComputePR(F ) end {Extract PageRanks of original local domain & normalize} ˆp ← ELf ELf 1 is to find such a supergraph ˆF with PageRank ˆf, so that ˆf when restricted to L is close to p∗ .",
                "Formally, we seek to minimize GlobalDiff( ˆf) = EL ˆf EL ˆf 1 − p∗ 1 . (3) We choose the L1 norm for measuring the error as it does not place excessive weight on outliers (as the L2 norm does, for example), and also because it is the most commonly used distance measure in the literature for comparing PageRank vectors, as well as for detecting convergence of the algorithm [3].",
                "We propose a greedy framework, given in Algorithm 2, for constructing ˆF .",
                "Initially, F is set to the local subgraph L, and the PageRank f of this graph is computed.",
                "The algorithm then proceeds as follows.",
                "First, the SelectNodes algorithm (which we discuss in the next section) is called and it returns a set of k nodes to crawl next from the set of nodes in the current crawl frontier, Fout.",
                "These selected nodes are then crawled to expand the local subgraph, F , and the PageRanks of this expanded graph are then recomputed.",
                "These steps are repeated for each of T iterations.",
                "Finally, the PageRank vector ˆp, which is restricted to pages within the original local domain, is returned.",
                "Given our computation, bandwidth, and memory restrictions, we will assume that the algorithm will crawl at most O(n) pages.",
                "Since the PageRanks are computed in each iteration of the algorithm, which is an O(n) operation, we will also assume that the number of iterations T is a constant.",
                "Of course, the main challenge here is in selecting which set of k nodes to crawl next.",
                "In the next section, we formally define the problem and give efficient algorithms. 5.",
                "NODE SELECTION In this section, we present node selection algorithms that operate within the greedy framework presented in the previous section.",
                "We first give a well-defined criteria for the page selection problem and provide experimental evidence that this criteria can effectively identify pages that optimize our problem objective (3).",
                "We then present our main al118 Research Track Paper gorithmic contribution of the paper, a method with linear running time that is derived from this page selection criteria.",
                "Finally, we give an intuitive analysis of our algorithm in terms of leaks and flows.",
                "We show that if only the flow is considered, then the resulting method is very similar to a widely used page selection heuristic [6]. 5.1 Formulation For a given page j in the global domain, we define the expanded local graph Fj: Fj = F s uT j 0 , (4) where uj is the zero-one vector containing the outlinks from F into page j, and s contains the inlinks from page j into the local domain.",
                "Note that we do not allow self-links in this framework.",
                "In practice, self-links are often removed, as they only serve to inflate a given pages PageRank.",
                "Observe that the inlinks into F from node j are not known until after node j is crawled.",
                "Therefore, we estimate this inlink vector as the expectation over inlink counts among the set of already crawled pages, s = F T e F T e 1 . (5) In practice, for any given page, this estimate may not reflect the true inlinks from that page.",
                "Furthermore, this expectation is sampled from the set of links within the crawled domain, whereas a better estimate would also use links from the global domain.",
                "However, the latter distribution is not known to a <br>localized search engine</br>, and we contend that the above estimate will, on average, be a better estimate than the uniform distribution, for example.",
                "Let the PageRank of F be f. We express the PageRank f+ j of the expanded local graph Fj as f+ j = (1 − xj)fj xj , (6) where xj is the PageRank of the candidate global node j, and fj is the L1-normalized PageRank vector restricted to the pages in F .",
                "Since directly optimizing our problem goal requires knowing the global PageRank p∗ , we instead propose to crawl those nodes that will have the greatest influence on the PageRanks of pages in the original local domain L: influence(j) = k∈L |fj[k] − f[k]| (7) = EL (fj − f) 1.",
                "Experimentally, the influence score is a very good predictor of our problem objective (3).",
                "For each candidate global node j, figure 1(a) shows the objective function value Global Diff(fj) as a function of the influence of page j.",
                "The local domain used here is a crawl of conservative political pages (we will provide more details about this dataset in section 6); we observed similar results in other domains.",
                "The correlation is quite strong, implying that the influence criteria can effectively identify pages that improve the global PageRank estimate.",
                "As a baseline, figure 1(b) compares our objective with an alternative criteria, outlink count.",
                "The outlink count is defined as the number of outlinks from the local domain to page j.",
                "The correlation here is much weaker. .00001 .0001 .001 .01 0.26 0.262 0.264 0.266 Influence Objective 1 10 100 1000 0.266 0.264 0.262 0.26 Outlink Count Objective (a) (b) Figure 1: (a) The correlation between our influence page selection criteria (7) and the actual objective function (3) value is quite strong. (b) This is in contrast to other criteria, such as outlink count, which exhibit a much weaker correlation. 5.2 Computation As described, for each candidate global page j, the influence score (7) must be computed.",
                "If fj is computed exactly for each global page j, then the PageRank algorithm would need to be run for each of the O(n) such global pages j we consider, resulting in an O(n2 ) computational cost for the node selection method.",
                "Thus, computing the exact value of fj will lead to a quadratic algorithm, and we must instead turn to methods of approximating this vector.",
                "The algorithm we present works by performing one power method iteration used by the PageRank algorithm (Algorithm 1).",
                "The convergence rate for the PageRank algorithm has been shown to equal the random surfer probability α [7, 11].",
                "Given a starting vector x(0) , if k PageRank iterations are performed, the current PageRank solution x(k) satisfies: x(k) − x∗ 1 = O(αk x(0) − x∗ 1), (8) where x∗ is the desired PageRank vector.",
                "Therefore, if only one iteration is performed, choosing a good starting vector is necessary to achieve an accurate approximation.",
                "We partition the PageRank matrix PFj , corresponding to the × subgraph Fj as: PFj = ˜F ˜s ˜uT j w , (9) where ˜F = αF (DF + diag(uj))−1 + (1 − α) e + 1 eT , ˜s = αs + (1 − α) e + 1 , ˜uj = α(DF + diag(uj))−1 uj + (1 − α) e + 1 , w = 1 − α + 1 , and diag(uj) is the diagonal matrix with the (i, i)th entry equal to one if the ith element of uj equals one, and is zero otherwise.",
                "We have assumed here that the random surfer vector is the uniform vector, and that L has no dangling links.",
                "These assumptions are not necessary and serve only to simplify discussion and analysis.",
                "A simple approach for estimating fj is the following.",
                "First, estimate the PageRank f+ j of Fj by computing one PageRank iteration over the matrix PFj , using the starting vector ν = f 0 .",
                "Then, estimate fj by removing the last 119 Research Track Paper component from our estimate of f+ j (i.e., the component corresponding to the added node j), and renormalizing.",
                "The problem with this approach is in the starting vector.",
                "Recall from (6) that xj is the PageRank of the added node j.",
                "The difference between the actual PageRank f+ j of PFj and the starting vector ν is ν − f+ j 1 = xj + f − (1 − xj)fj 1 ≥ xj + | f 1 − (1 − xj) fj 1| = xj + |xj| = 2xj.",
                "Thus, by (8), after one PageRank iteration, we expect our estimate of f+ j to still have an error of about 2αxj.",
                "In particular, for candidate nodes j with relatively high PageRank xj, this method will yield more inaccurate results.",
                "We will next present a method that eliminates this bias and runs in O(n) time. 5.2.1 Stochastic Complementation Since f+ j , as given in (6) is the PageRank of the matrix PFj , we have: fj(1 − xj) xj = ˜F ˜s ˜uT j w fj(1 − xj) xj = ˜F fj(1 − xj) + ˜sxj ˜uT j fj(1 − xj) + wxj .",
                "Solving the above system for fj can be shown to yield fj = ( ˜F + (1 − w)−1 ˜s˜uT j )fj. (10) The matrix S = ˜F +(1−w)−1 ˜s˜uT j is known as the stochastic complement of the column stochastic matrix PFj with respect to the sub matrix ˜F .",
                "The theory of stochastic complementation is well studied, and it can be shown the stochastic complement of an irreducible matrix (such as the PageRank matrix) is unique.",
                "Furthermore, the stochastic complement is also irreducible and therefore has a unique stationary distribution as well.",
                "For an extensive study, see [15].",
                "It can be easily shown that the sub-dominant eigenvalue of S is at most +1 α, where is the size of F .",
                "For sufficiently large , this value will be very close to α.",
                "This is important, as other properties of the PageRank algorithm, notably the algorithms sensitivity, are dependent on this value [11].",
                "In this method, we estimate the length vector fj by computing one PageRank iteration over the × stochastic complement S, starting at the vector f: fj ≈ Sf. (11) This is in contrast to the simple method outlined in the previous section, which first iterates over the ( + 1) × ( + 1) matrix PFj to estimate f+ j , and then removes the last component from the estimate and renormalizes to approximate fj.",
                "The problem with the latter method is in the choice of the ( + 1) length starting vector, ν. Consequently, the PageRank estimate given by the simple method differs from the true PageRank by at least 2αxj, where xj is the PageRank of page j.",
                "By using the stochastic complement, we can establish a tight lower bound of zero for this difference.",
                "To see this, consider the case in which a node k is added to F to form the augmented local subgraph Fk, and that the PageRank of this new graph is (1 − xk)f xk .",
                "Specifically, the addition of page k does not change the PageRanks of the pages in F , and thus fk = f. By construction of the stochastic complement, fk = Sfk, so the approximation given in equation (11) will yield the exact solution.",
                "Next, we present the computational details needed to efficiently compute the quantity fj −f 1 over all known global pages j.",
                "We begin by expanding the difference fj −f, where the vector fj is estimated as in (11), fj − f ≈ Sf − f = αF (DF + diag(uj))−1 f + (1 − α) e + 1 eT f +(1 − w)−1 (˜uT j f)˜s − f. (12) Note that the matrix (DF +diag(uj))−1 is diagonal.",
                "Letting o[k] be the outlink count for page k in F , we can express the kth diagonal element as: (DF + diag(uj))−1 [k, k] = 1 o[k]+1 if uj[k] = 1 1 o[k] if uj[k] = 0 Noting that (o[k] + 1)−1 = o[k]−1 − (o[k](o[k] + 1))−1 and rewriting this in matrix form yields (DF +diag(uj))−1 = D−1 F −D−1 F (DF +diag(uj))−1 diag(uj). (13) We use the same identity to express e + 1 = e − e ( + 1) . (14) Recall that, by definition, we have PF = αF D−1 F +(1−α)e .",
                "Substituting (13) and (14) in (12) yields fj − f ≈ (PF f − f) −αF D−1 F (DF + diag(uj))−1 diag(uj)f −(1 − α) e ( + 1) + (1 − w)−1 (˜uT j f)˜s = x + y + (˜uT j f)z, (15) noting that by definition, f = PF f, and defining the vectors x, y, and z to be x = −αF D−1 F (DF + diag(uj))−1 diag(uj)f (16) y = −(1 − α) e ( + 1) (17) z = (1 − w)−1 ˜s. (18) The first term x is a sparse vector, and takes non-zero values only for local pages k that are siblings of the global page j.",
                "We define (i, j) ∈ F if and only if F [j, i] = 1 (equivalently, page i links to page j) and express the value of the component x[k ] as: x[k ] = −α k:(k,k )∈F ,uj [k]=1 f[k] o[k](o[k] + 1) , (19) where o[k], as before, is the number of outlinks from page k in the local domain.",
                "Note that the last two terms, y and z are not dependent on the current global node j.",
                "Given the function hj(f) = y + (˜uT j f)z 1, the quantity fj − f 1 120 Research Track Paper can be expressed as fj − f 1 = k x[k] + y[k] + (˜uT j f)z[k] = k:x[k]=0 y[k] + (˜uT j f)z[k] + k:x[k]=0 x[k] + y[k] + (˜uT j f)z[k] = hj(f) − k:x[k]=0 y[k] + (˜uT j f)z[k] + k:x[k]=0 x[k] + y[k] + (˜uT j f)z[k] . (20) If we can compute the function hj in linear time, then we can compute each value of fj − f 1 using an additional amount of time that is proportional to the number of nonzero components in x.",
                "These optimizations are carried out in Algorithm 3.",
                "Note that (20) computes the difference between all components of f and fj, whereas our node selection criteria, given in (7), is restricted to the components corresponding to nodes in the original local domain L. Let us examine Algorithm 3 in more detail.",
                "First, the algorithm computes the outlink counts for each page in the local domain.",
                "The algorithm then computes the quantity ˜uT j f for each known global page j.",
                "This inner product can be written as (1 − α) 1 + 1 + α k:(k,j)∈Fout f[k] o[k] + 1 , where the second term sums over the set of local pages that link to page j.",
                "Since the total number of edges in Fout was assumed to have size O( ) (recall that is the number of pages in F ), the running time of this step is also O( ).",
                "The algorithm then computes the vectors y and z, as given in (17) and (18), respectively.",
                "The L1NormDiff method is called on the components of these vectors which correspond to the pages in L, and it estimates the value of EL(y + (˜uT j f)z) 1 for each page j.",
                "The estimation works as follows.",
                "First, the values of ˜uT j f are discretized uniformly into c values {a1, ..., ac}.",
                "The quantity EL(y + aiz) 1 is then computed for each discretized value of ai and stored in a table.",
                "To evaluate EL (y + az) 1 for some a ∈ [a1, ac], the closest discretized value ai is determined, and the corresponding entry in the table is used.",
                "The total running time for this method is linear in and the discretization parameter c (which we take to be a constant).",
                "We note that if exact values are desired, we have also developed an algorithm that runs in O( log ) time that is not described here.",
                "In the main loop, we compute the vector x, as defined in equation (16).",
                "The nested loops iterate over the set of pages in F that are siblings of page j.",
                "Typically, the size of this set is bounded by a constant.",
                "Finally, for each page j, the scores vector is updated over the set of non-zero components k of the vector x with k ∈ L. This set has size equal to the number of local siblings of page j, and is a subset of the total number of siblings of page j.",
                "Thus, each iteration of the main loop takes constant time, and the total running time of the main loop is O( ).",
                "Since we have assumed that the size of F will not grow larger than O(n), the total running time for the algorithm is O(n).",
                "Algorithm 3: Node Selection via Stochastic Complementation.",
                "SC-Select(F , Fout, f, k) Input: F : zero-one adjacency matrix of size corresponding to the current local subgraph, Fout: zero-one outlink matrix from F to global subgraph, f: PageRank of F , k: number of pages to return Output: pages: set of k pages to crawl next {Compute outlink sums for local subgraph} foreach (page j ∈ F ) o[j] ← k:(j,k)∈F F[j, k] end {Compute scalar ˜uT j f for each global node j } foreach (page j ∈ Fout) g[j] ← (1 − α) 1 +1 foreach (page k : (k, j) ∈ Fout) g[j] ← g[j] + α f[k] o[k]+1 end end {Compute vectors y and z as in (17) and (18) } y ← −(1 − α) e ( +1) z ← (1 − w)−1 ˜s {Approximate y + g[j] ∗ z 1 for all values g[j]} norm diffs ←L1NormDiffs(g, ELy, ELz) foreach (page j ∈ Fout) {Compute sparse vector x as in (19)} x ← 0 foreach (page k : (k, j) ∈ Fout) foreach (page k : (k, k ) ∈ F )) x[k ] ← x[k ] − f[k] o[k](o[k]+1) end end x ← αx scores[j] ← norm diffs[j] foreach (k : x[k] > 0 and page k ∈ L) scores[j] ← scores[j] − |y[k] + g[j] ∗ z[k]| +|x[k]+y[k]+g[j]∗z[k])| end end Return k pages with highest scores 5.2.2 PageRank Flows We now present an intuitive analysis of the stochastic complementation method by decomposing the change in PageRank in terms of leaks and flows.",
                "This analysis is motivated by the decomposition given in (15).",
                "PageRank flow is the increase in the local PageRanks originating from global page j.",
                "The flows are represented by the non-negative vector (˜uT j f)z (equations (15) and (18)).",
                "The scalar ˜uT j f can be thought of as the total amount of PageRank flow that page j has available to distribute.",
                "The vector z dictates how the flow is allocated to the local domain; the flow that local page k receives is proportional to (within a constant factor due to the random surfer vector) the expected number of its inlinks.",
                "The PageRank leaks represent the decrease in PageRank resulting from the addition of page j.",
                "The leakage can be quantified in terms of the non-positive vectors x and y (equations (16) and (17)).",
                "For vector x, we can see from equation (19) that the amount of PageRank leaked by a local page is proportional to the weighted sum of the Page121 Research Track Paper Ranks of its siblings.",
                "Thus, pages that have siblings with higher PageRanks (and low outlink counts) will experience more leakage.",
                "The leakage caused by y is an artifact of the random surfer vector.",
                "We will next show that if only the flow term, (˜uT j f)z, is considered, then the resulting method is very similar to a heuristic proposed by Cho et al. [6] that has been widely used for the Crawling Through URL Ordering problem.",
                "This heuristic is computationally cheaper, but as we will see later, not as effective as the Stochastic Complementation method.",
                "Our node selection strategy chooses global nodes that have the largest influence (equation (7)).",
                "If this influence is approximated using only flows, the optimal node j∗ is: j∗ = argmaxj EL ˜uT j fz 1 = argmaxj ˜uT j f EL z 1 = argmaxj ˜uT j f = argmaxj α(DF + diag(uj))−1 uj + (1 − α) e + 1 , f = argmaxjfT (DF + diag(uj))−1 uj.",
                "The resulting page selection score can be expressed as a sum of the PageRanks of each local page k that links to j, where each PageRank value is normalized by o[k]+1.",
                "Interestingly, the normalization that arises in our method differs from the heuristic given in [6], which normalizes by o[k].",
                "The algorithm PF-Select, which is omitted due to lack of space, first computes the quantity fT (DF +diag(uj))−1 uj for each global page j, and then returns the pages with the k largest scores.",
                "To see that the running time for this algorithm is O(n), note that the computation involved in this method is a subset of that needed for the SC-Select method (Algorithm 3), which was shown to have a running time of O(n). 6.",
                "EXPERIMENTS In this section, we provide experimental evidence to verify the effectiveness of our algorithms.",
                "We first outline our experimental methodology and then provide results across a variety of local domains. 6.1 Methodology Given the limited resources available at an academic institution, crawling a section of the web that is of the same magnitude as that indexed by Google or Yahoo! is clearly infeasible.",
                "Thus, for a given local domain, we approximate the global graph by crawling a local neighborhood around the domain that is several orders of magnitude larger than the local subgraph.",
                "Even though such a graph is still orders of magnitude smaller than the true global graph, we contend that, even if there exist some highly influential pages that are very far away from our local domain, it is unrealistic for any local node selection algorithm to find them.",
                "Such pages also tend to be highly unrelated to pages within the local domain.",
                "When explaining our node selection strategies in section 5, we made the simplifying assumption that our local graph contained no dangling nodes.",
                "This assumption was only made to ease our analysis.",
                "Our implementation efficiently handles dangling links by replacing each zero column of our adjacency matrix with the uniform vector.",
                "We evaluate the algorithm using the two node selection strategies given in Section 5.2, and also against the following baseline methods: • Random: Nodes are chosen uniformly at random among the known global nodes. • OutlinkCount: Global nodes with the highest number of outlinks from the local domain are chosen.",
                "At each iteration of the FindGlobalPR algorithm, we evaluate performance by computing the difference between the current PageRank estimate of the local domain, ELf ELf 1 , and the global PageRank of the local domain ELg ELg 1 .",
                "All PageRank calculations were performed using the uniform random surfer vector.",
                "Across all experiments, we set the random surfer parameter α, to be .85, and used a convergence threshold of 10−6 .",
                "We evaluate the difference between the local and global PageRank vectors using three different metrics: the L1 and L∞ norms, and Kendalls tau.",
                "The L1 norm measures the sum of the absolute value of the differences between the two vectors, and the L∞ norm measures the absolute value of the largest difference.",
                "Kendalls tau metric is a popular rank correlation measure used to compare PageRanks [2, 11].",
                "This metric can be computed by counting the number of pairs of pairs that agree in ranking, and subtracting from that the number of pairs of pairs that disagree in ranking.",
                "The final value is then normalized by the total number of n 2 such pairs, resulting in a [−1, 1] range, where a negative score signifies anti-correlation among rankings, and values near one correspond to strong rank correlation. 6.2 Results Our experiments are based on two large web crawls and were downloaded using the web crawler that is part of the Nutch open source search engine project [18].",
                "All crawls were restricted to only http pages, and to limit the number of dynamically generated pages that we crawl, we ignored all pages with urls containing any of the characters ?, *, @, or =.",
                "The first crawl, which we will refer to as the edu dataset, was seeded by homepages of the top 100 graduate computer science departments in the USA, as rated by the US News and World Report [16], and also by the home pages of their respective institutions.",
                "A crawl of depth 5 was performed, restricted to pages within the .edu domain, resulting in a graph with approximately 4.7 million pages and 22.9 million links.",
                "The second crawl was seeded by the set of pages under the politics hierarchy in the dmoz open directory project[17].",
                "We crawled all pages up to four links away, which yielded a graph with 4.4 million pages and 17.3 million links.",
                "Within the edu crawl, we identified the five site-specific domains corresponding to the websites of the top five graduate computer science departments, as ranked by the US News and World Report.",
                "This yielded local domains of various sizes, from 10,626 (UIUC) to 59,895 (Berkeley).",
                "For each of these site-specific domains with size n, we performed 50 iterations of the FindGlobalPR algorithm to crawl a total of 2n additional nodes.",
                "Figure 2(a) gives the (L1) difference from the PageRank estimate at each iteration to the global PageRank, for the Berkeley local domain.",
                "The performance of this dataset was representative of the typical performance across the five computer science sitespecific local domains.",
                "Initially, the L1 difference between the global and local PageRanks ranged from .0469 (Stanford) to .149 (MIT).",
                "For the first several iterations, the 122 Research Track Paper 0 5 10 15 20 25 30 35 40 45 50 0.015 0.02 0.025 0.03 0.035 0.04 0.045 0.05 0.055 Number of Iterations GlobalandLocalPageRankDifference(L1) Stochastic Complement PageRank Flow Outlink Count Random 0 10 20 30 40 50 0 0.05 0.1 0.15 0.2 0.25 0.3 0.35 Number of Iterations GlobalandLocalPageRankDifference(L1) Stochastic Complement PageRank Flow Outlink Count Random 0 5 10 15 20 25 0.16 0.18 0.2 0.22 0.24 0.26 0.28 0.3 0.32 0.34 Number of Iterations GlobalandLocalPageRankDifference(L1) Stochastic Complement PageRank Flow Outlink Count Random (a) www.cs.berkeley.edu (b) www.enterstageright.com (c) Politics Figure 2: L1 difference between the estimated and true global PageRanks for (a) Berkeleys computer science website, (b) the site-specific domain, www.enterstageright.com, and (c) the politics topic-specific domain.",
                "The stochastic complement method outperforms all other methods across various domains. three link-based methods all outperform the random selection heuristic.",
                "After these initial iterations, the random heuristic tended to be more competitive with (or even outperform, as in the Berkeley local domain) the outlink count and PageRank flow heuristics.",
                "In all tests, the stochastic complementation method either outperformed, or was competitive with, the other methods.",
                "Table 1 gives the average difference between the final estimated global PageRanks and the true global PageRanks for various distance measures.",
                "Algorithm L1 L∞ Kendall Stoch.",
                "Comp. .0384 .00154 .9257 PR Flow .0470 .00272 .8946 Outlink .0419 .00196 .9053 Random .0407 .00204 .9086 Table 1: Average final performance of various node selection strategies for the five site-specific computer science local domains.",
                "Note that Kendalls Tau measures similarity, while the other metrics are dissimilarity measures.",
                "Stochastic Complementation clearly outperforms the other methods in all metrics.",
                "Within the politics dataset, we also performed two sitespecific tests for the largest websites in the crawl: www.adamsmith.org, the website for the London based Adam Smith Institute, and www.enterstageright.com, an online conservative journal.",
                "As with the edu local domains, we ran our algorithm for 50 iterations, crawling a total of 2n nodes.",
                "Figure 2 (b) plots the results for the www.enterstageright.com domain.",
                "In contrast to the edu local domains, the Random and OutlinkCount methods were not competitive with either the SC-Select or the PF-Select methods.",
                "Among all datasets and all node selection methods, the stochastic complementation method was most impressive in this dataset, realizing a final estimate that differed only .0279 from the global PageRank, a ten-fold improvement over the initial local PageRank difference of .299.",
                "For the Adam Smith local domain, the initial difference between the local and global PageRanks was .148, and the final estimates given by the SC-Select, PF-Select, OutlinkCount, and Random methods were .0208, .0193, .0222, and .0356, respectively.",
                "Within the politics dataset, we constructed four topicspecific local domains.",
                "The first domain consisted of all pages in the dmoz politics category, and also all pages within each of these sites up to two links away.",
                "This yielded a local domain of 90,811 pages, and the results are given in figure 2 (c).",
                "Because of the larger size of the topic-specific domains, we ran our algorithm for only 25 iterations to crawl a total of n nodes.",
                "We also created topic-specific domains from three political sub-topics: liberalism, conservatism, and socialism.",
                "The pages in these domains were identified by their corresponding dmoz categories.",
                "For each sub-topic, we set the local domain to be all pages within three links from the corresponding dmoz category pages.",
                "Table 2 summarizes the performance of these three topic-specific domains, and also the larger political domain.",
                "To quantify a global page js effect on the global PageRank values of pages in the local domain, we define page js impact to be its PageRank value, g[j], normalized by the fraction of its outlinks pointing to the local domain: impact(j) = oL[j] o[j] · g[j], where, oL[j] is the number of outlinks from page j to pages in the local domain L, and o[j] is the total number of js outlinks.",
                "In terms of the random surfer model, the impact of page j is the probability that the random surfer (1) is currently at global page j in her random walk and (2) takes an outlink to a local page, given that she has already decided not to jump to a random page.",
                "For the politics local domain, we found that many of the pages with high impact were in fact political pages that should have been included in the dmoz politics topic, but were not.",
                "For example, the two most influential global pages were the political search engine www.askhenry.com, and the home page of the online political magazine, www.policyreview.com.",
                "Among non-political pages, the home page of the journal Education Next was most influential.",
                "The journal is freely available online and contains articles regarding various aspect of K-12 education in America.",
                "To provide some anecdotal evidence for the effectiveness of our page selection methods, we note that the SC-Select method chose 11 pages within the www.educationnext.org domain, the PF-Select method discovered 7 such pages, while the OutlinkCount and Random methods found only 6 pages each.",
                "For the conservative political local domain, the socialist website www.ornery.org had a very high impact score.",
                "This 123 Research Track Paper All Politics: Algorithm L1 L2 Kendall Stoch.",
                "Comp. .1253 .000700 .8671 PR Flow .1446 .000710 .8518 Outlink .1470 .00225 .8642 Random .2055 .00203 .8271 Conservativism: Algorithm L1 L2 Kendall Stoch.",
                "Comp. .0496 .000990 .9158 PR Flow .0554 .000939 .9028 Outlink .0602 .00527 .9144 Random .1197 .00102 .8843 Liberalism: Algorithm L1 L2 Kendall Stoch.",
                "Comp. .0622 .001360 .8848 PR Flow .0799 .001378 .8669 Outlink .0763 .001379 .8844 Random .1127 .001899 .8372 Socialism: Algorithm L1 L∞ Kendall Stoch.",
                "Comp. .04318 .00439 .9604 PR Flow .0450 .004251 .9559 Outlink .04282 .00344 .9591 Random .0631 .005123 .9350 Table 2: Final performance among node selection strategies for the four political topic-specific crawls.",
                "Note that Kendalls Tau measures similarity, while the other metrics are dissimilarity measures. was largely due to a link from the front page of this site to an article regarding global warming published by the National Center for Public Policy Research, a conservative research group in Washington, DC.",
                "Not surprisingly, the global PageRank of this article (which happens to be on the home page of the NCCPR, www.nationalresearch.com), was approximately .002, whereas the local PageRank of this page was only .00158.",
                "The SC-Select method yielded a global PageRank estimate of approximately .00182, the PFSelect method estimated a value of .00167, and the Random and OutlinkCount methods yielded values of .01522 and .00171, respectively. 7.",
                "RELATED WORK The node selection framework we have proposed is similar to the url ordering for crawling problem proposed by Cho et al. in [6].",
                "Whereas our framework seeks to minimize the difference between the global and local PageRank, the objective used in [6] is to crawl the most highly (globally) ranked pages first.",
                "They propose several node selection algorithms, including the outlink count heuristic, as well as a variant of our PF-Select algorithm which they refer to as the PageRank ordering metric.",
                "They found this method to be most effective in optimizing their objective, as did a recent survey of these methods by Baeza-Yates et al. [1].",
                "Boldi et al. also experiment within a similar crawling framework in [2], but quantify their results by comparing Kendalls rank correlation between the PageRanks of the current set of crawled pages and those of the entire global graph.",
                "They found that node selection strategies that crawled pages with the highest global PageRank first actually performed worse (with respect to Kendalls Tau correlation between the local and global PageRanks) than basic depth first or breadth first strategies.",
                "However, their experiments differ from our work in that our node selection algorithms do not use (or have access to) global PageRank values.",
                "Many algorithmic improvements for computing exact PageRank values have been proposed [9, 10, 14].",
                "If such algorithms are used to compute the global PageRanks of our local domain, they would all require O(N) computation, storage, and bandwidth, where N is the size of the global domain.",
                "This is in contrast to our method, which approximates the global PageRank and scales linearly with the size of the local domain.",
                "Wang and Dewitt [22] propose a system where the set of web servers that comprise the global domain communicate with each other to compute their respective global PageRanks.",
                "For a given web server hosting n pages, the computational, bandwidth, and storage requirements are also linear in n. One drawback of this system is that the number of distinct web servers that comprise the global domain can be very large.",
                "For example, our edu dataset contains websites from over 3,200 different universities; coordinating such a system among a large number of sites can be very difficult.",
                "Gan, Chen, and Suel propose a method for estimating the PageRank of a single page [5] which uses only constant bandwidth, computation, and space.",
                "Their approach relies on the availability of a remote connectivity server that can supply the set of inlinks to a given page, an assumption not used in our framework.",
                "They experimentally show that a reasonable estimate of the nodes PageRank can be obtained by visiting at most a few hundred nodes.",
                "Using their algorithm for our problem would require that either the entire global domain first be downloaded or a connectivity server be used, both of which would lead to very large web graphs. 8.",
                "CONCLUSIONS AND FUTURE WORK The internet is growing exponentially, and in order to navigate such a large repository as the web, global search engines have established themselves as a necessity.",
                "Along with the ubiquity of these large-scale search engines comes an increase in search users expectations.",
                "By providing complete and isolated coverage of a particular web domain, localized search engines are an effective outlet to quickly locate content that could otherwise be difficult to find.",
                "In this work, we contend that the use of global PageRank in a <br>localized search engine</br> can improve performance.",
                "To estimate the global PageRank, we have proposed an iterative node selection framework where we select which pages from the global frontier to crawl next.",
                "Our primary contribution is our stochastic complementation page selection algorithm.",
                "This method crawls nodes that will most significantly impact the local domain and has running time linear in the number of nodes in the local domain.",
                "Experimentally, we validate these methods across a diverse set of local domains, including seven site-specific domains and four topic-specific domains.",
                "We conclude that by crawling an additional n or 2n pages, our methods find an estimate of the global PageRanks that is up to ten times better than just using the local PageRanks.",
                "Furthermore, we demonstrate that our algorithm consistently outperforms other existing heuristics. 124 Research Track Paper Often times, topic-specific domains are discovered using a focused web crawler which considers a pages content in conjunction with link anchor text to decide which pages to crawl next [4].",
                "Although such crawlers have proven to be quite effective in discovering topic-related content, many irrelevant pages are also crawled in the process.",
                "Typically, these pages are deleted and not indexed by the <br>localized search engine</br>.",
                "These pages can of course provide valuable information regarding the global PageRank of the local domain.",
                "One way to integrate these pages into our framework is to start the FindGlobalPR algorithm with the current subgraph F equal to the set of pages that were crawled by the focused crawler.",
                "The global PageRank estimation framework, along with the node selection algorithms presented, all require O(n) computation per iteration and bandwidth proportional to the number of pages crawled, Tk.",
                "If the number of iterations T is relatively small compared to the number of pages crawled per iteration, k, then the bottleneck of the algorithm will be the crawling phase.",
                "However, as the number of iterations increases (relative to k), the bottleneck will reside in the node selection computation.",
                "In this case, our algorithms would benefit from constant factor optimizations.",
                "Recall that the FindGlobalPR algorithm (Algorithm 2) requires that the PageRanks of the current expanded local domain be recomputed in each iteration.",
                "Recent work by Langville and Meyer [12] gives an algorithm to quickly recompute PageRanks of a given webgraph if a small number of nodes are added.",
                "This algorithm was shown to give speedup of five to ten times on some datasets.",
                "We plan to investigate this and other such optimizations as future work.",
                "In this paper, we have objectively evaluated our methods by measuring how close our global PageRank estimates are to the actual global PageRanks.",
                "To determine the benefit of using global PageRanks in a <br>localized search engine</br>, we suggest a user study in which users are asked to rate the quality of search results for various search queries.",
                "For some queries, only the local PageRanks are used in ranking, and for the remaining queries, local PageRanks and the approximate global PageRanks, as computed by our algorithms, are used.",
                "The results of such a study can then be analyzed to determine the added benefit of using the global PageRanks computed by our methods, over just using the local PageRanks.",
                "Acknowledgements.",
                "This research was supported by NSF grant CCF-0431257, NSF Career Award ACI-0093404, and a grant from Sabre, Inc. 9.",
                "REFERENCES [1] R. Baeza-Yates, M. Marin, C. Castillo, and A. Rodriguez.",
                "Crawling a country: better strategies than breadth-first for web page ordering.",
                "World-Wide Web Conference, 2005. [2] P. Boldi, M. Santini, and S. Vigna.",
                "Do your worst to make the best: paradoxical effects in pagerank incremental computations.",
                "Workshop on Web Graphs, 3243:168-180, 2004. [3] S. Brin and L. Page.",
                "The anatomy of a large-scale hypertextual web search engine.",
                "Computer Networks and ISDN Systems, 33(1-7):107-117, 1998. [4] S. Chakrabarti, M. van den Berg, and B. Dom.",
                "Focused crawling: a new approach to topic-specific web resource discovery.",
                "World-Wide Web Conference, 1999. [5] Y. Chen, Q. Gan, and T. Suel.",
                "Local methods for estimating pagerank values.",
                "Conference on Information and Knowledge Management, 2004. [6] J. Cho, H. Garcia-Molina, and L. Page.",
                "Efficient crawling through url ordering.",
                "World-Wide Web Conference, 1998. [7] T. H. Haveliwala and S. D. Kamvar.",
                "The second eigenvalue of the Google matrix.",
                "Technical report, Stanford University, 2003. [8] T. Joachims, F. Radlinski, L. Granka, A. Cheng, C. Tillekeratne, and A. Patel.",
                "Learning retrieval functions from implicit feedback. http://www.cs.cornell.edu/People/tj/career. [9] S. D. Kamvar, T. H. Haveliwala, C. D. Manning, and G. H. Golub.",
                "Exploiting the block structure of the web for computing pagerank.",
                "World-Wide Web Conference, 2003. [10] S. D. Kamvar, T. H. Haveliwala, C. D. Manning, and G. H. Golub.",
                "Extrapolation methods for accelerating pagerank computation.",
                "World-Wide Web Conference, 2003. [11] A. N. Langville and C. D. Meyer.",
                "Deeper inside pagerank.",
                "Internet Mathematics, 2004. [12] A. N. Langville and C. D. Meyer.",
                "Updating the stationary vector of an irreducible markov chain with an eye on Googles pagerank.",
                "SIAM Journal on Matrix Analysis, 2005. [13] P. Lyman, H. R. Varian, K. Swearingen, P. Charles, N. Good, L. L. Jordan, and J. Pal.",
                "How much information 2003?",
                "School of Information Management and System, University of California at Berkely, 2003. [14] F. McSherry.",
                "A uniform approach to accelerated pagerank computation.",
                "World-Wide Web Conference, 2005. [15] C. D. Meyer.",
                "Stochastic complementation, uncoupling markov chains, and the theory of nearly reducible systems.",
                "SIAM Review, 31:240-272, 1989. [16] US News and World Report. http://www.usnews.com. [17] Dmoz open directory project. http://www.dmoz.org. [18] Nutch open source search engine. http://www.nutch.org. [19] F. Radlinski and T. Joachims.",
                "Query chains: learning to rank from implicit feedback.",
                "ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, 2005. [20] S. Raghavan and H. Garcia-Molina.",
                "Crawling the hidden web.",
                "In Proceedings of the Twenty-seventh International Conference on Very Large Databases, 2001. [21] T. Tin Tang, D. Hawking, N. Craswell, and K. Griffiths.",
                "Focused crawling for both topical relevance and quality of medical information.",
                "Conference on Information and Knowledge Management, 2005. [22] Y. Wang and D. J. DeWitt.",
                "Computing pagerank in a distributed internet search system.",
                "Proceedings of the 30th VLDB Conference, 2004. 125 Research Track Paper"
            ],
            "original_annotated_samples": [
                "In the context of a <br>localized search engine</br>, if the PageRanks are computed using only the local subgraph, then we would expect the resulting PageRanks to reflect the perceived popularity within the local community and not of the web as a whole.",
                "For example, consider a <br>localized search engine</br> that indexes political pages with conservative views.",
                "However, building a <br>localized search engine</br> over a web community of a hundred thousand pages would only require a few gigabytes of storage.",
                "By restricting itself to only a specific domain of the internet, a <br>localized search engine</br> can provide more precise search results.",
                "We assume that when building a <br>localized search engine</br>, only pages inside the local domain are crawled, and the links between these pages are represented by the subgraph L. The links in Lout are also known, as these point from crawled pages in the local domain to uncrawled pages in the global domain."
            ],
            "translated_annotated_samples": [
                "En el contexto de un <br>motor de búsqueda localizado</br>, si los PageRanks se calculan utilizando solo el subgrafo local, entonces esperaríamos que los PageRanks resultantes reflejen la popularidad percibida dentro de la comunidad local y no de la web en su totalidad.",
                "Por ejemplo, consideremos un <br>motor de búsqueda localizado</br> que indexa páginas políticas con puntos de vista conservadores.",
                "Sin embargo, construir un <br>motor de búsqueda localizado</br> sobre una comunidad web de cien mil páginas solo requeriría unos pocos gigabytes de almacenamiento.",
                "Al restringirse a un dominio específico de internet, un <br>motor de búsqueda localizado</br> puede proporcionar resultados de búsqueda más precisos.",
                "Suponemos que al construir un <br>motor de búsqueda localizado</br>, solo se rastrean las páginas dentro del dominio local, y los enlaces entre estas páginas están representados por el subgrafo L. También se conocen los enlaces en Lout, ya que estos apuntan desde las páginas rastreadas en el dominio local a las páginas no rastreadas en el dominio global."
            ],
            "translated_text": "Estimando el PageRank Global de Comunidades Web Jason V. Davis Dept. Departamento de Ciencias de la Computación Universidad de Texas en Austin Austin, TX 78712 jdavis@cs.utexas.edu Inderjit S. Dhillon Departamento de Ciencias de la Computación Universidad de Texas en Austin Austin, TX 78712 inderjit@cs.utexas.edu RESUMEN Los motores de búsqueda localizados son sistemas a pequeña escala que indexan una comunidad particular en la web. Ofrecen varios beneficios en comparación con sus contrapartes a gran escala, ya que son relativamente económicos de construir y pueden proporcionar una capacidad de búsqueda más precisa y completa en sus dominios relevantes. Una desventaja que tienen estos sistemas en comparación con los motores de búsqueda a gran escala es la falta de valores globales de PageRank. Se necesita esa información para evaluar el valor de las páginas en el dominio de búsqueda localizada dentro del contexto de la web en su totalidad. En este artículo, presentamos algoritmos bien fundamentados para estimar los valores globales de PageRank de un dominio local. Los algoritmos son altamente escalables en el sentido de que, dado un dominio local de tamaño n, utilizan recursos de O(n) que incluyen tiempo de computación, ancho de banda y almacenamiento. Probamos nuestros métodos en una variedad de dominios localizados, incluyendo dominios específicos del sitio y dominios específicos del tema. Demostramos que al rastrear tan solo n o 2n páginas adicionales, nuestros métodos pueden proporcionar excelentes estimaciones globales de PageRank. Categorías y Descriptores de Asignaturas H.3.3 [Almacenamiento y Recuperación de Información]: Búsqueda y Recuperación de Información; G.1.3 [Análisis Numérico]: Álgebra Lineal Numérica; G.3 [Probabilidad y Estadística]: Procesos de Markov Términos Generales PageRank, Cadena de Markov, Complementación Estocástica. Los motores de búsqueda localizados son motores de búsqueda a pequeña escala que indexan solo una comunidad específica de la web. Tales comunidades pueden ser dominios específicos del sitio, como páginas dentro del dominio cs.utexas.edu, o comunidades relacionadas con un tema, por ejemplo, sitios web políticos. En comparación con el grafo web rastreado e indexado por los motores de búsqueda a gran escala, el tamaño de estas comunidades locales suele ser típicamente órdenes de magnitud más pequeño. Por consiguiente, los recursos computacionales necesarios para construir un motor de búsqueda de este tipo también son igualmente más ligeros. Al restringirse a secciones más pequeñas y manejables de la web, los motores de búsqueda localizados también pueden ofrecer capacidades de búsqueda más precisas y completas dentro de sus respectivos dominios. Una desventaja de los índices localizados es la falta de información global necesaria para calcular clasificaciones basadas en enlaces. El algoritmo PageRank [3] ha demostrado ser una medida efectiva de este tipo. En general, el PageRank de una página dada depende de las páginas en todo el grafo web. En el contexto de un <br>motor de búsqueda localizado</br>, si los PageRanks se calculan utilizando solo el subgrafo local, entonces esperaríamos que los PageRanks resultantes reflejen la popularidad percibida dentro de la comunidad local y no de la web en su totalidad. Por ejemplo, consideremos un <br>motor de búsqueda localizado</br> que indexa páginas políticas con puntos de vista conservadores. Una persona que desee investigar las opiniones sobre el calentamiento global dentro de la comunidad política conservadora puede encontrarse con numerosas opiniones de este tipo en varios sitios web. Si solo se dispone de valores de PageRank locales, entonces los resultados de búsqueda reflejarán solo creencias fuertemente arraigadas dentro de la comunidad. Sin embargo, si los PageRanks globales también están disponibles, entonces los resultados pueden reflejar adicionalmente las opiniones de los externos sobre la comunidad conservadora (es decir, aquellos documentos a los que los liberales acceden con mayor frecuencia dentro de la comunidad conservadora). Por lo tanto, para muchos motores de búsqueda localizados, la incorporación de PageRanks globales puede mejorar la calidad de los resultados de búsqueda. Sin embargo, el número de páginas que indexa un motor de búsqueda local suele ser órdenes de magnitud más pequeño que el número de páginas indexadas por sus contrapartes a gran escala. Los motores de búsqueda localizados no tienen el ancho de banda, la capacidad de almacenamiento o la potencia computacional para rastrear, descargar y calcular los PageRanks globales de toda la web. En este trabajo, presentamos un método para aproximar los PageRanks globales de un dominio local utilizando recursos del mismo orden que los necesarios para calcular los PageRanks del subgrafo local. Nuestro método propuesto busca un supergrafo de nuestro subgrafo local de manera que los PageRanks locales dentro de este supergrafo estén cerca de los verdaderos PageRanks globales. Construimos este supergrafo mediante el rastreo iterativo de páginas globales en la frontera web actual, es decir, páginas globales con enlaces entrantes de páginas que ya han sido rastreadas. Para proporcionar a 116 Research Track Paper una buena aproximación a los PageRanks globales, es necesario tener cuidado al elegir qué páginas rastrear a continuación; en este documento, presentamos un algoritmo de selección de páginas bien fundamentado que también tiene un buen rendimiento empírico. Este algoritmo se deriva de un objetivo de problema bien definido y tiene un tiempo de ejecución lineal en el número de nodos locales. Experimentamos en varios tipos de subgrafos locales, incluidas cuatro comunidades relacionadas con el tema y varios dominios específicos del sitio. Para evaluar el rendimiento, medimos la diferencia entre la estimación actual del PageRank global y el PageRank global, en función del número de páginas rastreadas. Comparamos nuestro algoritmo con varios heurísticos y también con un algoritmo base que elige páginas al azar, y demostramos que nuestro método supera a estos otros métodos. Finalmente, demostramos empíricamente que, dado un dominio local de tamaño n, podemos proporcionar buenas aproximaciones a los valores globales de PageRank rastreando como máximo n o 2n páginas adicionales. El documento está organizado de la siguiente manera. La sección 2 ofrece una visión general de los motores de búsqueda localizados y destaca sus ventajas sobre los motores de búsqueda globales. La sección 3 proporciona antecedentes sobre el algoritmo PageRank. La sección 4 define formalmente nuestro problema, y la sección 5 presenta nuestros criterios de selección de páginas y deriva nuestros algoritmos. La sección 6 presenta los resultados experimentales, la sección 7 ofrece una visión general del trabajo relacionado y, finalmente, las conclusiones se presentan en la sección 8. MOTORES DE BÚSQUEDA LOCALIZADOS Los motores de búsqueda localizados indexan una sola comunidad de la web, típicamente una comunidad específica del sitio o una comunidad específica del tema. Los motores de búsqueda localizados disfrutan de tres ventajas principales sobre sus contrapartes a gran escala: son relativamente económicos de construir, pueden ofrecer una capacidad de búsqueda más precisa dentro de su dominio local y pueden proporcionar un índice más completo. Los recursos necesarios para construir un motor de búsqueda global son enormes. Un estudio de 2003 realizado por Lyman et al. [13] encontró que la web superficial (sitios estáticos de acceso público) consta de 8.9 mil millones de páginas, y que el tamaño promedio de estas páginas es de aproximadamente 18.7 kilobytes. Para descargar un rastreo de este tamaño, se necesita aproximadamente 167 terabytes de espacio. Para un investigador que desee construir un motor de búsqueda con acceso a un par de estaciones de trabajo o un servidor pequeño, un almacenamiento de esta magnitud simplemente no está disponible. Sin embargo, construir un <br>motor de búsqueda localizado</br> sobre una comunidad web de cien mil páginas solo requeriría unos pocos gigabytes de almacenamiento. La carga computacional necesaria para soportar consultas de búsqueda sobre una base de datos de este tamaño es más manejable también. Observamos que, para los motores de búsqueda específicos de un tema, la comunidad relevante puede ser identificada y descargada de manera eficiente utilizando un rastreador enfocado [21, 4]. Para dominios específicos del sitio, el dominio local está fácilmente disponible en su propio servidor web. Esto evita la necesidad de rastreo o indexación, y por lo tanto se puede garantizar un índice completo y actualizado del dominio. Esto contrasta con sus contrapartes a gran escala, las cuales sufren de varias deficiencias. Primero, el rastreo de páginas generadas dinámicamente en la web oculta ha sido objeto de investigación [20] y es una tarea no trivial para un rastreador externo. En segundo lugar, los dominios específicos del sitio pueden habilitar la política de exclusión de robots. Esto prohíbe a los rastreadores de motores de búsqueda externos descargar contenido del dominio, y en su lugar un motor de búsqueda externo debe depender de enlaces externos y texto ancla para indexar estas páginas restringidas. Al restringirse a un dominio específico de internet, un <br>motor de búsqueda localizado</br> puede proporcionar resultados de búsqueda más precisos. Considera la consulta de búsqueda ambigua canónica, jaguar, que puede referirse tanto al fabricante de automóviles como al animal. Un científico que intenta investigar el hábitat y la historia evolutiva de un jaguar puede tener más éxito utilizando un motor de búsqueda específico de zoología bien ajustado que consultando Google con múltiples búsquedas de palabras clave y navegando a través de resultados irrelevantes. Recientemente se propuso un método para aprender funciones de clasificación mejores para la recuperación por Radlinski y Joachims [19] y se ha aplicado a varios dominios locales, incluido el sitio web de la Universidad de Cornell [8]. 3. PAGERANK RESUMEN El algoritmo PageRank define la importancia de las páginas web analizando la estructura de hipervínculos subyacente de un grafo web. El algoritmo funciona construyendo una cadena de Markov a partir de la estructura de enlaces del grafo web y calculando su distribución estacionaria. Una forma de calcular la distribución estacionaria de una cadena de Markov es encontrar la distribución límite de un paseo aleatorio sobre la cadena. Por lo tanto, el algoritmo PageRank utiliza lo que a veces se conoce como el modelo del surfista aleatorio. En cada paso de la caminata aleatoria, el surfista sigue un enlace de salida de la página actual (es decir, el nodo actual en la cadena), o salta a una página aleatoria en la web. Ahora definimos con precisión el problema de PageRank. Sea U una matriz de adyacencia m × m para un grafo web dado tal que Uji = 1 si la página i enlaza a la página j y Uji = 0 en caso contrario. Definimos la matriz de PageRank PU como: PU = αUD−1 U + (1 − α)veT , (1) donde DU es la matriz diagonal (única) tal que UD−1 U es estocástica por columnas, α es un escalar dado tal que 0 ≤ α ≤ 1, e es el vector de todos unos, y v es un vector no negativo, L1-normalizado, a veces llamado vector de navegante aleatorio. Ten en cuenta que la matriz D−1 U está bien definida solo si cada columna de U tiene al menos una entrada distinta de cero, es decir, cada página en el grafo web tiene al menos un enlace de salida. En presencia de nodos colgantes que no tienen enlaces de salida, una solución comúnmente utilizada, propuesta por Brin et al. [3], es reemplazar cada columna de ceros de U por un vector no negativo, normalizado en L1. El vector PageRank r es el eigenvector dominante de la matriz PageRank, r = PU r. Supondremos, sin pérdida de generalidad, que r tiene una norma L1 de uno. Computacionalmente, r se puede calcular utilizando el método de la potencia. Este método primero elige un vector inicial aleatorio r(0) y, de forma iterativa, multiplica el vector actual por la matriz de PageRank PU; ver Algoritmo 1. En general, cada iteración del método de la potencia puede requerir O(m2) operaciones cuando PU es una matriz densa. Sin embargo, en la práctica, el número de enlaces en un grafo web será del orden del número de páginas. Al explotar la dispersión de la matriz de PageRank, el trabajo por iteración se puede reducir a O(km), donde k es el número promedio de enlaces por página web. También se ha demostrado que el número total de iteraciones necesarias para la convergencia es proporcional a α y no depende del tamaño del grafo web [11, 7]. Finalmente, el espacio total necesario también es O(km), principalmente para almacenar la matriz U. 117 Research Track Paper Algorithm 1: Un algoritmo de tiempo lineal (por iteración) para calcular PageRank. CalcularPR(U) Entrada: U: Matriz de adyacencia. Salida: vector de PageRank. Elige (aleatoriamente) un vector inicial no negativo r(0) tal que r(0) 1 = 1. i ← 0 repetir i ← i + 1 ν ← αUD−1 U r(i−1) {α es la probabilidad de navegación aleatoria} r(i) ← ν + (1 − α)v {v es el vector del navegante aleatorio.} hasta que r(i) − r(i−1) < δ {δ es el umbral de convergencia.} r ← r(i) 4. Dada un dominio local L, sea G una matriz de adyacencia N × N para el componente conectado completo de la web que contiene L, tal que Gji = 1 si la página i enlaza a la página j y Gji = 0 en caso contrario. Sin pérdida de generalidad, vamos a dividir G de la siguiente manera: G = L Gout Lout Gwithin, donde L es el subgrafo local de n × n correspondiente a los enlaces dentro del dominio local, Lout es el subgrafo que corresponde a los enlaces desde el dominio local apuntando hacia el dominio global, Gout es el subgrafo que contiene los enlaces desde el dominio global hacia el dominio local, y Gwithin contiene los enlaces dentro del dominio global. Suponemos que al construir un <br>motor de búsqueda localizado</br>, solo se rastrean las páginas dentro del dominio local, y los enlaces entre estas páginas están representados por el subgrafo L. También se conocen los enlaces en Lout, ya que estos apuntan desde las páginas rastreadas en el dominio local a las páginas no rastreadas en el dominio global. ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "large-scale search engine": {
            "translated_key": "motores de búsqueda a gran escala",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Estimating the Global PageRank of Web Communities Jason V. Davis Dept.",
                "of Computer Sciences University of Texas at Austin Austin, TX 78712 jdavis@cs.utexas.edu Inderjit S. Dhillon Dept. of Computer Sciences University of Texas at Austin Austin, TX 78712 inderjit@cs.utexas.edu ABSTRACT Localized search engines are small-scale systems that index a particular community on the web.",
                "They offer several benefits over their large-scale counterparts in that they are relatively inexpensive to build, and can provide more precise and complete search capability over their relevant domains.",
                "One disadvantage such systems have over <br>large-scale search engine</br>s is the lack of global PageRank values.",
                "Such information is needed to assess the value of pages in the localized search domain within the context of the web as a whole.",
                "In this paper, we present well-motivated algorithms to estimate the global PageRank values of a local domain.",
                "The algorithms are all highly scalable in that, given a local domain of size n, they use O(n) resources that include computation time, bandwidth, and storage.",
                "We test our methods across a variety of localized domains, including site-specific domains and topic-specific domains.",
                "We demonstrate that by crawling as few as n or 2n additional pages, our methods can give excellent global PageRank estimates.",
                "Categories and Subject Descriptors H.3.3 [Information Storage and Retrieval]: Information Search and Retrieval; G.1.3 [Numerical Analysis]: Numerical Linear Algebra; G.3 [Probability and Statistics]: Markov Processes General Terms PageRank, Markov Chain, Stochastic Complementation 1.",
                "INTRODUCTION Localized search engines are small-scale search engines that index only a single community of the web.",
                "Such communities can be site-specific domains, such as pages within the cs.utexas.edu domain, or topic-related communitiesfor example, political websites.",
                "Compared to the web graph crawled and indexed by <br>large-scale search engine</br>s, the size of such local communities is typically orders of magnitude smaller.",
                "Consequently, the computational resources needed to build such a search engine are also similarly lighter.",
                "By restricting themselves to smaller, more manageable sections of the web, localized search engines can also provide more precise and complete search capabilities over their respective domains.",
                "One drawback of localized indexes is the lack of global information needed to compute link-based rankings.",
                "The PageRank algorithm [3], has proven to be an effective such measure.",
                "In general, the PageRank of a given page is dependent on pages throughout the entire web graph.",
                "In the context of a localized search engine, if the PageRanks are computed using only the local subgraph, then we would expect the resulting PageRanks to reflect the perceived popularity within the local community and not of the web as a whole.",
                "For example, consider a localized search engine that indexes political pages with conservative views.",
                "A person wishing to research the opinions on global warming within the conservative political community may encounter numerous such opinions across various websites.",
                "If only local PageRank values are available, then the search results will reflect only strongly held beliefs within the community.",
                "However, if global PageRanks are also available, then the results can additionally reflect outsiders views of the conservative community (those documents that liberals most often access within the conservative community).",
                "Thus, for many localized search engines, incorporating global PageRanks can improve the quality of search results.",
                "However, the number of pages a local search engine indexes is typically orders of magnitude smaller than the number of pages indexed by their large-scale counterparts.",
                "Localized search engines do not have the bandwidth, storage capacity, or computational power to crawl, download, and compute the global PageRanks of the entire web.",
                "In this work, we present a method of approximating the global PageRanks of a local domain while only using resources of the same order as those needed to compute the PageRanks of the local subgraph.",
                "Our proposed method looks for a supergraph of our local subgraph such that the local PageRanks within this supergraph are close to the true global PageRanks.",
                "We construct this supergraph by iteratively crawling global pages on the current web frontier-i.e., global pages with inlinks from pages that have already been crawled.",
                "In order to provide 116 Research Track Paper a good approximation to the global PageRanks, care must be taken when choosing which pages to crawl next; in this paper, we present a well-motivated page selection algorithm that also performs well empirically.",
                "This algorithm is derived from a well-defined problem objective and has a running time linear in the number of local nodes.",
                "We experiment across several types of local subgraphs, including four topic related communities and several sitespecific domains.",
                "To evaluate performance, we measure the difference between the current global PageRank estimate and the global PageRank, as a function of the number of pages crawled.",
                "We compare our algorithm against several heuristics and also against a baseline algorithm that chooses pages at random, and we show that our method outperforms these other methods.",
                "Finally, we empirically demonstrate that, given a local domain of size n, we can provide good approximations to the global PageRank values by crawling at most n or 2n additional pages.",
                "The paper is organized as follows.",
                "Section 2 gives an overview of localized search engines and outlines their advantages over global search.",
                "Section 3 provides background on the PageRank algorithm.",
                "Section 4 formally defines our problem, and section 5 presents our page selection criteria and derives our algorithms.",
                "Section 6 provides experimental results, section 7 gives an overview of related work, and, finally, conclusions are given in section 8. 2.",
                "LOCALIZED SEARCH ENGINES Localized search engines index a single community of the web, typically either a site-specific community, or a topicspecific community.",
                "Localized search engines enjoy three major advantages over their large-scale counterparts: they are relatively inexpensive to build, they can offer more precise search capability over their local domain, and they can provide a more complete index.",
                "The resources needed to build a global search engine are enormous.",
                "A 2003 study by Lyman et al. [13] found that the surface web (publicly available static sites) consists of 8.9 billion pages, and that the average size of these pages is approximately 18.7 kilobytes.",
                "To download a crawl of this size, approximately 167 terabytes of space is needed.",
                "For a researcher who wishes to build a search engine with access to a couple of workstations or a small server, storage of this magnitude is simply not available.",
                "However, building a localized search engine over a web community of a hundred thousand pages would only require a few gigabytes of storage.",
                "The computational burden required to support search queries over a database this size is more manageable as well.",
                "We note that, for topic-specific search engines, the relevant community can be efficiently identified and downloaded by using a focused crawler [21, 4].",
                "For site-specific domains, the local domain is readily available on their own web server.",
                "This obviates the need for crawling or spidering, and a complete and up-to-date index of the domain can thus be guaranteed.",
                "This is in contrast to their large-scale counterparts, which suffer from several shortcomings.",
                "First, crawling dynamically generated pages-pages in the hidden web-has been the subject of research [20] and is a non-trivial task for an external crawler.",
                "Second, site-specific domains can enable the robots exclusion policy.",
                "This prohibits external search engines crawlers from downloading content from the domain, and an external search engine must instead rely on outside links and anchor text to index these restricted pages.",
                "By restricting itself to only a specific domain of the internet, a localized search engine can provide more precise search results.",
                "Consider the canonical ambiguous search query, jaguar, which can refer to either the car manufacturer or the animal.",
                "A scientist trying to research the habitat and evolutionary history of a jaguar may have better success using a finely tuned zoology-specific search engine than querying Google with multiple keyword searches and wading through irrelevant results.",
                "A method to learn better ranking functions for retrieval was recently proposed by Radlinski and Joachims [19] and has been applied to various local domains, including Cornell Universitys website [8]. 3.",
                "PAGERANK OVERVIEW The PageRank algorithm defines the importance of web pages by analyzing the underlying hyperlink structure of a web graph.",
                "The algorithm works by building a Markov chain from the link structure of the web graph and computing its stationary distribution.",
                "One way to compute the stationary distribution of a Markov chain is to find the limiting distribution of a random walk over the chain.",
                "Thus, the PageRank algorithm uses what is sometimes referred to as the random surfer model.",
                "In each step of the random walk, the surfer either follows an outlink from the current page (i.e. the current node in the chain), or jumps to a random page on the web.",
                "We now precisely define the PageRank problem.",
                "Let U be an m × m adjacency matrix for a given web graph such that Uji = 1 if page i links to page j and Uji = 0 otherwise.",
                "We define the PageRank matrix PU to be: PU = αUD−1 U + (1 − α)veT , (1) where DU is the (unique) diagonal matrix such that UD−1 U is column stochastic, α is a given scalar such that 0 ≤ α ≤ 1, e is the vector of all ones, and v is a non-negative, L1normalized vector, sometimes called the random surfer vector.",
                "Note that the matrix D−1 U is well-defined only if each column of U has at least one non-zero entry-i.e., each page in the webgraph has at least one outlink.",
                "In the presence of such dangling nodes that have no outlinks, one commonly used solution, proposed by Brin et al. [3], is to replace each zero column of U by a non-negative, L1-normalized vector.",
                "The PageRank vector r is the dominant eigenvector of the PageRank matrix, r = PU r. We will assume, without loss of generality, that r has an L1-norm of one.",
                "Computationally, r can be computed using the power method.",
                "This method first chooses a random starting vector r(0) , and iteratively multiplies the current vector by the PageRank matrix PU ; see Algorithm 1.",
                "In general, each iteration of the power method can take O(m2 ) operations when PU is a dense matrix.",
                "However, in practice, the number of links in a web graph will be of the order of the number of pages.",
                "By exploiting the sparsity of the PageRank matrix, the work per iteration can be reduced to O(km), where k is the average number of links per web page.",
                "It has also been shown that the total number of iterations needed for convergence is proportional to α and does not depend on the size of the web graph [11, 7].",
                "Finally, the total space needed is also O(km), mainly to store the matrix U. 117 Research Track Paper Algorithm 1: A linear time (per iteration) algorithm for computing PageRank.",
                "ComputePR(U) Input: U: Adjacency matrix.",
                "Output: r: PageRank vector.",
                "Choose (randomly) an initial non-negative vector r(0) such that r(0) 1 = 1. i ← 0 repeat i ← i + 1 ν ← αUD−1 U r(i−1) {α is the random surfing probability} r(i) ← ν + (1 − α)v {v is the random surfer vector.} until r(i) − r(i−1) < δ {δ is the convergence threshold.} r ← r(i) 4.",
                "PROBLEM DEFINITION Given a local domain L, let G be an N × N adjacency matrix for the entire connected component of the web that contains L, such that Gji = 1 if page i links to page j and Gji = 0 otherwise.",
                "Without loss of generality, we will partition G as: G = L Gout Lout Gwithin , (2) where L is the n × n local subgraph corresponding to links inside the local domain, Lout is the subgraph that corresponds to links from the local domain pointing out to the global domain, Gout is the subgraph containing links from the global domain into the local domain, and Gwithin contains links within the global domain.",
                "We assume that when building a localized search engine, only pages inside the local domain are crawled, and the links between these pages are represented by the subgraph L. The links in Lout are also known, as these point from crawled pages in the local domain to uncrawled pages in the global domain.",
                "As defined in equation (1), PG is the PageRank matrix formed from the global graph G, and we define the global PageRank vector of this graph to be g. Let the n-length vector p∗ be the L1-normalized vector corresponding to the global PageRank of the pages in the local domain L: p∗ = EL g ELg 1 , where EL = [ I | 0 ] is the restriction matrix that selects the components from g corresponding to nodes in L. Let p denote the PageRank vector constructed from the local domain subgraph L. In practice, the observed local PageRank p and the global PageRank p∗ will be quite different.",
                "One would expect that as the size of local matrix L approaches the size of global matrix G, the global PageRank and the observed local PageRank will become more similar.",
                "Thus, one approach to estimating the global PageRank is to crawl the entire global domain, compute its PageRank, and extract the PageRanks of the local domain.",
                "Typically, however, n N , i.e., the number of global pages is much larger than the number of local pages.",
                "Therefore, crawling all global pages will quickly exhaust all local resources (computational, storage, and bandwidth) available to create the local search engine.",
                "We instead seek a supergraph ˆF of our local subgraph L with size O(n).",
                "Our goal Algorithm 2: The FindGlobalPR algorithm.",
                "FindGlobalPR(L, Lout, T, k) Input: L: zero-one adjacency matrix for the local domain, Lout: zero-one outlink matrix from L to global subgraph as in (2), T: number of iterations, k: number of pages to crawl per iteration.",
                "Output: ˆp: an improved estimate of the global PageRank of L. F ← L Fout ← Lout f ← ComputePR(F ) for (i = 1 to T) {Determine which pages to crawl next} pages ← SelectNodes(F , Fout, f, k) Crawl pages, augment F and modify Fout {Update PageRanks for new local domain} f ← ComputePR(F ) end {Extract PageRanks of original local domain & normalize} ˆp ← ELf ELf 1 is to find such a supergraph ˆF with PageRank ˆf, so that ˆf when restricted to L is close to p∗ .",
                "Formally, we seek to minimize GlobalDiff( ˆf) = EL ˆf EL ˆf 1 − p∗ 1 . (3) We choose the L1 norm for measuring the error as it does not place excessive weight on outliers (as the L2 norm does, for example), and also because it is the most commonly used distance measure in the literature for comparing PageRank vectors, as well as for detecting convergence of the algorithm [3].",
                "We propose a greedy framework, given in Algorithm 2, for constructing ˆF .",
                "Initially, F is set to the local subgraph L, and the PageRank f of this graph is computed.",
                "The algorithm then proceeds as follows.",
                "First, the SelectNodes algorithm (which we discuss in the next section) is called and it returns a set of k nodes to crawl next from the set of nodes in the current crawl frontier, Fout.",
                "These selected nodes are then crawled to expand the local subgraph, F , and the PageRanks of this expanded graph are then recomputed.",
                "These steps are repeated for each of T iterations.",
                "Finally, the PageRank vector ˆp, which is restricted to pages within the original local domain, is returned.",
                "Given our computation, bandwidth, and memory restrictions, we will assume that the algorithm will crawl at most O(n) pages.",
                "Since the PageRanks are computed in each iteration of the algorithm, which is an O(n) operation, we will also assume that the number of iterations T is a constant.",
                "Of course, the main challenge here is in selecting which set of k nodes to crawl next.",
                "In the next section, we formally define the problem and give efficient algorithms. 5.",
                "NODE SELECTION In this section, we present node selection algorithms that operate within the greedy framework presented in the previous section.",
                "We first give a well-defined criteria for the page selection problem and provide experimental evidence that this criteria can effectively identify pages that optimize our problem objective (3).",
                "We then present our main al118 Research Track Paper gorithmic contribution of the paper, a method with linear running time that is derived from this page selection criteria.",
                "Finally, we give an intuitive analysis of our algorithm in terms of leaks and flows.",
                "We show that if only the flow is considered, then the resulting method is very similar to a widely used page selection heuristic [6]. 5.1 Formulation For a given page j in the global domain, we define the expanded local graph Fj: Fj = F s uT j 0 , (4) where uj is the zero-one vector containing the outlinks from F into page j, and s contains the inlinks from page j into the local domain.",
                "Note that we do not allow self-links in this framework.",
                "In practice, self-links are often removed, as they only serve to inflate a given pages PageRank.",
                "Observe that the inlinks into F from node j are not known until after node j is crawled.",
                "Therefore, we estimate this inlink vector as the expectation over inlink counts among the set of already crawled pages, s = F T e F T e 1 . (5) In practice, for any given page, this estimate may not reflect the true inlinks from that page.",
                "Furthermore, this expectation is sampled from the set of links within the crawled domain, whereas a better estimate would also use links from the global domain.",
                "However, the latter distribution is not known to a localized search engine, and we contend that the above estimate will, on average, be a better estimate than the uniform distribution, for example.",
                "Let the PageRank of F be f. We express the PageRank f+ j of the expanded local graph Fj as f+ j = (1 − xj)fj xj , (6) where xj is the PageRank of the candidate global node j, and fj is the L1-normalized PageRank vector restricted to the pages in F .",
                "Since directly optimizing our problem goal requires knowing the global PageRank p∗ , we instead propose to crawl those nodes that will have the greatest influence on the PageRanks of pages in the original local domain L: influence(j) = k∈L |fj[k] − f[k]| (7) = EL (fj − f) 1.",
                "Experimentally, the influence score is a very good predictor of our problem objective (3).",
                "For each candidate global node j, figure 1(a) shows the objective function value Global Diff(fj) as a function of the influence of page j.",
                "The local domain used here is a crawl of conservative political pages (we will provide more details about this dataset in section 6); we observed similar results in other domains.",
                "The correlation is quite strong, implying that the influence criteria can effectively identify pages that improve the global PageRank estimate.",
                "As a baseline, figure 1(b) compares our objective with an alternative criteria, outlink count.",
                "The outlink count is defined as the number of outlinks from the local domain to page j.",
                "The correlation here is much weaker. .00001 .0001 .001 .01 0.26 0.262 0.264 0.266 Influence Objective 1 10 100 1000 0.266 0.264 0.262 0.26 Outlink Count Objective (a) (b) Figure 1: (a) The correlation between our influence page selection criteria (7) and the actual objective function (3) value is quite strong. (b) This is in contrast to other criteria, such as outlink count, which exhibit a much weaker correlation. 5.2 Computation As described, for each candidate global page j, the influence score (7) must be computed.",
                "If fj is computed exactly for each global page j, then the PageRank algorithm would need to be run for each of the O(n) such global pages j we consider, resulting in an O(n2 ) computational cost for the node selection method.",
                "Thus, computing the exact value of fj will lead to a quadratic algorithm, and we must instead turn to methods of approximating this vector.",
                "The algorithm we present works by performing one power method iteration used by the PageRank algorithm (Algorithm 1).",
                "The convergence rate for the PageRank algorithm has been shown to equal the random surfer probability α [7, 11].",
                "Given a starting vector x(0) , if k PageRank iterations are performed, the current PageRank solution x(k) satisfies: x(k) − x∗ 1 = O(αk x(0) − x∗ 1), (8) where x∗ is the desired PageRank vector.",
                "Therefore, if only one iteration is performed, choosing a good starting vector is necessary to achieve an accurate approximation.",
                "We partition the PageRank matrix PFj , corresponding to the × subgraph Fj as: PFj = ˜F ˜s ˜uT j w , (9) where ˜F = αF (DF + diag(uj))−1 + (1 − α) e + 1 eT , ˜s = αs + (1 − α) e + 1 , ˜uj = α(DF + diag(uj))−1 uj + (1 − α) e + 1 , w = 1 − α + 1 , and diag(uj) is the diagonal matrix with the (i, i)th entry equal to one if the ith element of uj equals one, and is zero otherwise.",
                "We have assumed here that the random surfer vector is the uniform vector, and that L has no dangling links.",
                "These assumptions are not necessary and serve only to simplify discussion and analysis.",
                "A simple approach for estimating fj is the following.",
                "First, estimate the PageRank f+ j of Fj by computing one PageRank iteration over the matrix PFj , using the starting vector ν = f 0 .",
                "Then, estimate fj by removing the last 119 Research Track Paper component from our estimate of f+ j (i.e., the component corresponding to the added node j), and renormalizing.",
                "The problem with this approach is in the starting vector.",
                "Recall from (6) that xj is the PageRank of the added node j.",
                "The difference between the actual PageRank f+ j of PFj and the starting vector ν is ν − f+ j 1 = xj + f − (1 − xj)fj 1 ≥ xj + | f 1 − (1 − xj) fj 1| = xj + |xj| = 2xj.",
                "Thus, by (8), after one PageRank iteration, we expect our estimate of f+ j to still have an error of about 2αxj.",
                "In particular, for candidate nodes j with relatively high PageRank xj, this method will yield more inaccurate results.",
                "We will next present a method that eliminates this bias and runs in O(n) time. 5.2.1 Stochastic Complementation Since f+ j , as given in (6) is the PageRank of the matrix PFj , we have: fj(1 − xj) xj = ˜F ˜s ˜uT j w fj(1 − xj) xj = ˜F fj(1 − xj) + ˜sxj ˜uT j fj(1 − xj) + wxj .",
                "Solving the above system for fj can be shown to yield fj = ( ˜F + (1 − w)−1 ˜s˜uT j )fj. (10) The matrix S = ˜F +(1−w)−1 ˜s˜uT j is known as the stochastic complement of the column stochastic matrix PFj with respect to the sub matrix ˜F .",
                "The theory of stochastic complementation is well studied, and it can be shown the stochastic complement of an irreducible matrix (such as the PageRank matrix) is unique.",
                "Furthermore, the stochastic complement is also irreducible and therefore has a unique stationary distribution as well.",
                "For an extensive study, see [15].",
                "It can be easily shown that the sub-dominant eigenvalue of S is at most +1 α, where is the size of F .",
                "For sufficiently large , this value will be very close to α.",
                "This is important, as other properties of the PageRank algorithm, notably the algorithms sensitivity, are dependent on this value [11].",
                "In this method, we estimate the length vector fj by computing one PageRank iteration over the × stochastic complement S, starting at the vector f: fj ≈ Sf. (11) This is in contrast to the simple method outlined in the previous section, which first iterates over the ( + 1) × ( + 1) matrix PFj to estimate f+ j , and then removes the last component from the estimate and renormalizes to approximate fj.",
                "The problem with the latter method is in the choice of the ( + 1) length starting vector, ν. Consequently, the PageRank estimate given by the simple method differs from the true PageRank by at least 2αxj, where xj is the PageRank of page j.",
                "By using the stochastic complement, we can establish a tight lower bound of zero for this difference.",
                "To see this, consider the case in which a node k is added to F to form the augmented local subgraph Fk, and that the PageRank of this new graph is (1 − xk)f xk .",
                "Specifically, the addition of page k does not change the PageRanks of the pages in F , and thus fk = f. By construction of the stochastic complement, fk = Sfk, so the approximation given in equation (11) will yield the exact solution.",
                "Next, we present the computational details needed to efficiently compute the quantity fj −f 1 over all known global pages j.",
                "We begin by expanding the difference fj −f, where the vector fj is estimated as in (11), fj − f ≈ Sf − f = αF (DF + diag(uj))−1 f + (1 − α) e + 1 eT f +(1 − w)−1 (˜uT j f)˜s − f. (12) Note that the matrix (DF +diag(uj))−1 is diagonal.",
                "Letting o[k] be the outlink count for page k in F , we can express the kth diagonal element as: (DF + diag(uj))−1 [k, k] = 1 o[k]+1 if uj[k] = 1 1 o[k] if uj[k] = 0 Noting that (o[k] + 1)−1 = o[k]−1 − (o[k](o[k] + 1))−1 and rewriting this in matrix form yields (DF +diag(uj))−1 = D−1 F −D−1 F (DF +diag(uj))−1 diag(uj). (13) We use the same identity to express e + 1 = e − e ( + 1) . (14) Recall that, by definition, we have PF = αF D−1 F +(1−α)e .",
                "Substituting (13) and (14) in (12) yields fj − f ≈ (PF f − f) −αF D−1 F (DF + diag(uj))−1 diag(uj)f −(1 − α) e ( + 1) + (1 − w)−1 (˜uT j f)˜s = x + y + (˜uT j f)z, (15) noting that by definition, f = PF f, and defining the vectors x, y, and z to be x = −αF D−1 F (DF + diag(uj))−1 diag(uj)f (16) y = −(1 − α) e ( + 1) (17) z = (1 − w)−1 ˜s. (18) The first term x is a sparse vector, and takes non-zero values only for local pages k that are siblings of the global page j.",
                "We define (i, j) ∈ F if and only if F [j, i] = 1 (equivalently, page i links to page j) and express the value of the component x[k ] as: x[k ] = −α k:(k,k )∈F ,uj [k]=1 f[k] o[k](o[k] + 1) , (19) where o[k], as before, is the number of outlinks from page k in the local domain.",
                "Note that the last two terms, y and z are not dependent on the current global node j.",
                "Given the function hj(f) = y + (˜uT j f)z 1, the quantity fj − f 1 120 Research Track Paper can be expressed as fj − f 1 = k x[k] + y[k] + (˜uT j f)z[k] = k:x[k]=0 y[k] + (˜uT j f)z[k] + k:x[k]=0 x[k] + y[k] + (˜uT j f)z[k] = hj(f) − k:x[k]=0 y[k] + (˜uT j f)z[k] + k:x[k]=0 x[k] + y[k] + (˜uT j f)z[k] . (20) If we can compute the function hj in linear time, then we can compute each value of fj − f 1 using an additional amount of time that is proportional to the number of nonzero components in x.",
                "These optimizations are carried out in Algorithm 3.",
                "Note that (20) computes the difference between all components of f and fj, whereas our node selection criteria, given in (7), is restricted to the components corresponding to nodes in the original local domain L. Let us examine Algorithm 3 in more detail.",
                "First, the algorithm computes the outlink counts for each page in the local domain.",
                "The algorithm then computes the quantity ˜uT j f for each known global page j.",
                "This inner product can be written as (1 − α) 1 + 1 + α k:(k,j)∈Fout f[k] o[k] + 1 , where the second term sums over the set of local pages that link to page j.",
                "Since the total number of edges in Fout was assumed to have size O( ) (recall that is the number of pages in F ), the running time of this step is also O( ).",
                "The algorithm then computes the vectors y and z, as given in (17) and (18), respectively.",
                "The L1NormDiff method is called on the components of these vectors which correspond to the pages in L, and it estimates the value of EL(y + (˜uT j f)z) 1 for each page j.",
                "The estimation works as follows.",
                "First, the values of ˜uT j f are discretized uniformly into c values {a1, ..., ac}.",
                "The quantity EL(y + aiz) 1 is then computed for each discretized value of ai and stored in a table.",
                "To evaluate EL (y + az) 1 for some a ∈ [a1, ac], the closest discretized value ai is determined, and the corresponding entry in the table is used.",
                "The total running time for this method is linear in and the discretization parameter c (which we take to be a constant).",
                "We note that if exact values are desired, we have also developed an algorithm that runs in O( log ) time that is not described here.",
                "In the main loop, we compute the vector x, as defined in equation (16).",
                "The nested loops iterate over the set of pages in F that are siblings of page j.",
                "Typically, the size of this set is bounded by a constant.",
                "Finally, for each page j, the scores vector is updated over the set of non-zero components k of the vector x with k ∈ L. This set has size equal to the number of local siblings of page j, and is a subset of the total number of siblings of page j.",
                "Thus, each iteration of the main loop takes constant time, and the total running time of the main loop is O( ).",
                "Since we have assumed that the size of F will not grow larger than O(n), the total running time for the algorithm is O(n).",
                "Algorithm 3: Node Selection via Stochastic Complementation.",
                "SC-Select(F , Fout, f, k) Input: F : zero-one adjacency matrix of size corresponding to the current local subgraph, Fout: zero-one outlink matrix from F to global subgraph, f: PageRank of F , k: number of pages to return Output: pages: set of k pages to crawl next {Compute outlink sums for local subgraph} foreach (page j ∈ F ) o[j] ← k:(j,k)∈F F[j, k] end {Compute scalar ˜uT j f for each global node j } foreach (page j ∈ Fout) g[j] ← (1 − α) 1 +1 foreach (page k : (k, j) ∈ Fout) g[j] ← g[j] + α f[k] o[k]+1 end end {Compute vectors y and z as in (17) and (18) } y ← −(1 − α) e ( +1) z ← (1 − w)−1 ˜s {Approximate y + g[j] ∗ z 1 for all values g[j]} norm diffs ←L1NormDiffs(g, ELy, ELz) foreach (page j ∈ Fout) {Compute sparse vector x as in (19)} x ← 0 foreach (page k : (k, j) ∈ Fout) foreach (page k : (k, k ) ∈ F )) x[k ] ← x[k ] − f[k] o[k](o[k]+1) end end x ← αx scores[j] ← norm diffs[j] foreach (k : x[k] > 0 and page k ∈ L) scores[j] ← scores[j] − |y[k] + g[j] ∗ z[k]| +|x[k]+y[k]+g[j]∗z[k])| end end Return k pages with highest scores 5.2.2 PageRank Flows We now present an intuitive analysis of the stochastic complementation method by decomposing the change in PageRank in terms of leaks and flows.",
                "This analysis is motivated by the decomposition given in (15).",
                "PageRank flow is the increase in the local PageRanks originating from global page j.",
                "The flows are represented by the non-negative vector (˜uT j f)z (equations (15) and (18)).",
                "The scalar ˜uT j f can be thought of as the total amount of PageRank flow that page j has available to distribute.",
                "The vector z dictates how the flow is allocated to the local domain; the flow that local page k receives is proportional to (within a constant factor due to the random surfer vector) the expected number of its inlinks.",
                "The PageRank leaks represent the decrease in PageRank resulting from the addition of page j.",
                "The leakage can be quantified in terms of the non-positive vectors x and y (equations (16) and (17)).",
                "For vector x, we can see from equation (19) that the amount of PageRank leaked by a local page is proportional to the weighted sum of the Page121 Research Track Paper Ranks of its siblings.",
                "Thus, pages that have siblings with higher PageRanks (and low outlink counts) will experience more leakage.",
                "The leakage caused by y is an artifact of the random surfer vector.",
                "We will next show that if only the flow term, (˜uT j f)z, is considered, then the resulting method is very similar to a heuristic proposed by Cho et al. [6] that has been widely used for the Crawling Through URL Ordering problem.",
                "This heuristic is computationally cheaper, but as we will see later, not as effective as the Stochastic Complementation method.",
                "Our node selection strategy chooses global nodes that have the largest influence (equation (7)).",
                "If this influence is approximated using only flows, the optimal node j∗ is: j∗ = argmaxj EL ˜uT j fz 1 = argmaxj ˜uT j f EL z 1 = argmaxj ˜uT j f = argmaxj α(DF + diag(uj))−1 uj + (1 − α) e + 1 , f = argmaxjfT (DF + diag(uj))−1 uj.",
                "The resulting page selection score can be expressed as a sum of the PageRanks of each local page k that links to j, where each PageRank value is normalized by o[k]+1.",
                "Interestingly, the normalization that arises in our method differs from the heuristic given in [6], which normalizes by o[k].",
                "The algorithm PF-Select, which is omitted due to lack of space, first computes the quantity fT (DF +diag(uj))−1 uj for each global page j, and then returns the pages with the k largest scores.",
                "To see that the running time for this algorithm is O(n), note that the computation involved in this method is a subset of that needed for the SC-Select method (Algorithm 3), which was shown to have a running time of O(n). 6.",
                "EXPERIMENTS In this section, we provide experimental evidence to verify the effectiveness of our algorithms.",
                "We first outline our experimental methodology and then provide results across a variety of local domains. 6.1 Methodology Given the limited resources available at an academic institution, crawling a section of the web that is of the same magnitude as that indexed by Google or Yahoo! is clearly infeasible.",
                "Thus, for a given local domain, we approximate the global graph by crawling a local neighborhood around the domain that is several orders of magnitude larger than the local subgraph.",
                "Even though such a graph is still orders of magnitude smaller than the true global graph, we contend that, even if there exist some highly influential pages that are very far away from our local domain, it is unrealistic for any local node selection algorithm to find them.",
                "Such pages also tend to be highly unrelated to pages within the local domain.",
                "When explaining our node selection strategies in section 5, we made the simplifying assumption that our local graph contained no dangling nodes.",
                "This assumption was only made to ease our analysis.",
                "Our implementation efficiently handles dangling links by replacing each zero column of our adjacency matrix with the uniform vector.",
                "We evaluate the algorithm using the two node selection strategies given in Section 5.2, and also against the following baseline methods: • Random: Nodes are chosen uniformly at random among the known global nodes. • OutlinkCount: Global nodes with the highest number of outlinks from the local domain are chosen.",
                "At each iteration of the FindGlobalPR algorithm, we evaluate performance by computing the difference between the current PageRank estimate of the local domain, ELf ELf 1 , and the global PageRank of the local domain ELg ELg 1 .",
                "All PageRank calculations were performed using the uniform random surfer vector.",
                "Across all experiments, we set the random surfer parameter α, to be .85, and used a convergence threshold of 10−6 .",
                "We evaluate the difference between the local and global PageRank vectors using three different metrics: the L1 and L∞ norms, and Kendalls tau.",
                "The L1 norm measures the sum of the absolute value of the differences between the two vectors, and the L∞ norm measures the absolute value of the largest difference.",
                "Kendalls tau metric is a popular rank correlation measure used to compare PageRanks [2, 11].",
                "This metric can be computed by counting the number of pairs of pairs that agree in ranking, and subtracting from that the number of pairs of pairs that disagree in ranking.",
                "The final value is then normalized by the total number of n 2 such pairs, resulting in a [−1, 1] range, where a negative score signifies anti-correlation among rankings, and values near one correspond to strong rank correlation. 6.2 Results Our experiments are based on two large web crawls and were downloaded using the web crawler that is part of the Nutch open source search engine project [18].",
                "All crawls were restricted to only http pages, and to limit the number of dynamically generated pages that we crawl, we ignored all pages with urls containing any of the characters ?, *, @, or =.",
                "The first crawl, which we will refer to as the edu dataset, was seeded by homepages of the top 100 graduate computer science departments in the USA, as rated by the US News and World Report [16], and also by the home pages of their respective institutions.",
                "A crawl of depth 5 was performed, restricted to pages within the .edu domain, resulting in a graph with approximately 4.7 million pages and 22.9 million links.",
                "The second crawl was seeded by the set of pages under the politics hierarchy in the dmoz open directory project[17].",
                "We crawled all pages up to four links away, which yielded a graph with 4.4 million pages and 17.3 million links.",
                "Within the edu crawl, we identified the five site-specific domains corresponding to the websites of the top five graduate computer science departments, as ranked by the US News and World Report.",
                "This yielded local domains of various sizes, from 10,626 (UIUC) to 59,895 (Berkeley).",
                "For each of these site-specific domains with size n, we performed 50 iterations of the FindGlobalPR algorithm to crawl a total of 2n additional nodes.",
                "Figure 2(a) gives the (L1) difference from the PageRank estimate at each iteration to the global PageRank, for the Berkeley local domain.",
                "The performance of this dataset was representative of the typical performance across the five computer science sitespecific local domains.",
                "Initially, the L1 difference between the global and local PageRanks ranged from .0469 (Stanford) to .149 (MIT).",
                "For the first several iterations, the 122 Research Track Paper 0 5 10 15 20 25 30 35 40 45 50 0.015 0.02 0.025 0.03 0.035 0.04 0.045 0.05 0.055 Number of Iterations GlobalandLocalPageRankDifference(L1) Stochastic Complement PageRank Flow Outlink Count Random 0 10 20 30 40 50 0 0.05 0.1 0.15 0.2 0.25 0.3 0.35 Number of Iterations GlobalandLocalPageRankDifference(L1) Stochastic Complement PageRank Flow Outlink Count Random 0 5 10 15 20 25 0.16 0.18 0.2 0.22 0.24 0.26 0.28 0.3 0.32 0.34 Number of Iterations GlobalandLocalPageRankDifference(L1) Stochastic Complement PageRank Flow Outlink Count Random (a) www.cs.berkeley.edu (b) www.enterstageright.com (c) Politics Figure 2: L1 difference between the estimated and true global PageRanks for (a) Berkeleys computer science website, (b) the site-specific domain, www.enterstageright.com, and (c) the politics topic-specific domain.",
                "The stochastic complement method outperforms all other methods across various domains. three link-based methods all outperform the random selection heuristic.",
                "After these initial iterations, the random heuristic tended to be more competitive with (or even outperform, as in the Berkeley local domain) the outlink count and PageRank flow heuristics.",
                "In all tests, the stochastic complementation method either outperformed, or was competitive with, the other methods.",
                "Table 1 gives the average difference between the final estimated global PageRanks and the true global PageRanks for various distance measures.",
                "Algorithm L1 L∞ Kendall Stoch.",
                "Comp. .0384 .00154 .9257 PR Flow .0470 .00272 .8946 Outlink .0419 .00196 .9053 Random .0407 .00204 .9086 Table 1: Average final performance of various node selection strategies for the five site-specific computer science local domains.",
                "Note that Kendalls Tau measures similarity, while the other metrics are dissimilarity measures.",
                "Stochastic Complementation clearly outperforms the other methods in all metrics.",
                "Within the politics dataset, we also performed two sitespecific tests for the largest websites in the crawl: www.adamsmith.org, the website for the London based Adam Smith Institute, and www.enterstageright.com, an online conservative journal.",
                "As with the edu local domains, we ran our algorithm for 50 iterations, crawling a total of 2n nodes.",
                "Figure 2 (b) plots the results for the www.enterstageright.com domain.",
                "In contrast to the edu local domains, the Random and OutlinkCount methods were not competitive with either the SC-Select or the PF-Select methods.",
                "Among all datasets and all node selection methods, the stochastic complementation method was most impressive in this dataset, realizing a final estimate that differed only .0279 from the global PageRank, a ten-fold improvement over the initial local PageRank difference of .299.",
                "For the Adam Smith local domain, the initial difference between the local and global PageRanks was .148, and the final estimates given by the SC-Select, PF-Select, OutlinkCount, and Random methods were .0208, .0193, .0222, and .0356, respectively.",
                "Within the politics dataset, we constructed four topicspecific local domains.",
                "The first domain consisted of all pages in the dmoz politics category, and also all pages within each of these sites up to two links away.",
                "This yielded a local domain of 90,811 pages, and the results are given in figure 2 (c).",
                "Because of the larger size of the topic-specific domains, we ran our algorithm for only 25 iterations to crawl a total of n nodes.",
                "We also created topic-specific domains from three political sub-topics: liberalism, conservatism, and socialism.",
                "The pages in these domains were identified by their corresponding dmoz categories.",
                "For each sub-topic, we set the local domain to be all pages within three links from the corresponding dmoz category pages.",
                "Table 2 summarizes the performance of these three topic-specific domains, and also the larger political domain.",
                "To quantify a global page js effect on the global PageRank values of pages in the local domain, we define page js impact to be its PageRank value, g[j], normalized by the fraction of its outlinks pointing to the local domain: impact(j) = oL[j] o[j] · g[j], where, oL[j] is the number of outlinks from page j to pages in the local domain L, and o[j] is the total number of js outlinks.",
                "In terms of the random surfer model, the impact of page j is the probability that the random surfer (1) is currently at global page j in her random walk and (2) takes an outlink to a local page, given that she has already decided not to jump to a random page.",
                "For the politics local domain, we found that many of the pages with high impact were in fact political pages that should have been included in the dmoz politics topic, but were not.",
                "For example, the two most influential global pages were the political search engine www.askhenry.com, and the home page of the online political magazine, www.policyreview.com.",
                "Among non-political pages, the home page of the journal Education Next was most influential.",
                "The journal is freely available online and contains articles regarding various aspect of K-12 education in America.",
                "To provide some anecdotal evidence for the effectiveness of our page selection methods, we note that the SC-Select method chose 11 pages within the www.educationnext.org domain, the PF-Select method discovered 7 such pages, while the OutlinkCount and Random methods found only 6 pages each.",
                "For the conservative political local domain, the socialist website www.ornery.org had a very high impact score.",
                "This 123 Research Track Paper All Politics: Algorithm L1 L2 Kendall Stoch.",
                "Comp. .1253 .000700 .8671 PR Flow .1446 .000710 .8518 Outlink .1470 .00225 .8642 Random .2055 .00203 .8271 Conservativism: Algorithm L1 L2 Kendall Stoch.",
                "Comp. .0496 .000990 .9158 PR Flow .0554 .000939 .9028 Outlink .0602 .00527 .9144 Random .1197 .00102 .8843 Liberalism: Algorithm L1 L2 Kendall Stoch.",
                "Comp. .0622 .001360 .8848 PR Flow .0799 .001378 .8669 Outlink .0763 .001379 .8844 Random .1127 .001899 .8372 Socialism: Algorithm L1 L∞ Kendall Stoch.",
                "Comp. .04318 .00439 .9604 PR Flow .0450 .004251 .9559 Outlink .04282 .00344 .9591 Random .0631 .005123 .9350 Table 2: Final performance among node selection strategies for the four political topic-specific crawls.",
                "Note that Kendalls Tau measures similarity, while the other metrics are dissimilarity measures. was largely due to a link from the front page of this site to an article regarding global warming published by the National Center for Public Policy Research, a conservative research group in Washington, DC.",
                "Not surprisingly, the global PageRank of this article (which happens to be on the home page of the NCCPR, www.nationalresearch.com), was approximately .002, whereas the local PageRank of this page was only .00158.",
                "The SC-Select method yielded a global PageRank estimate of approximately .00182, the PFSelect method estimated a value of .00167, and the Random and OutlinkCount methods yielded values of .01522 and .00171, respectively. 7.",
                "RELATED WORK The node selection framework we have proposed is similar to the url ordering for crawling problem proposed by Cho et al. in [6].",
                "Whereas our framework seeks to minimize the difference between the global and local PageRank, the objective used in [6] is to crawl the most highly (globally) ranked pages first.",
                "They propose several node selection algorithms, including the outlink count heuristic, as well as a variant of our PF-Select algorithm which they refer to as the PageRank ordering metric.",
                "They found this method to be most effective in optimizing their objective, as did a recent survey of these methods by Baeza-Yates et al. [1].",
                "Boldi et al. also experiment within a similar crawling framework in [2], but quantify their results by comparing Kendalls rank correlation between the PageRanks of the current set of crawled pages and those of the entire global graph.",
                "They found that node selection strategies that crawled pages with the highest global PageRank first actually performed worse (with respect to Kendalls Tau correlation between the local and global PageRanks) than basic depth first or breadth first strategies.",
                "However, their experiments differ from our work in that our node selection algorithms do not use (or have access to) global PageRank values.",
                "Many algorithmic improvements for computing exact PageRank values have been proposed [9, 10, 14].",
                "If such algorithms are used to compute the global PageRanks of our local domain, they would all require O(N) computation, storage, and bandwidth, where N is the size of the global domain.",
                "This is in contrast to our method, which approximates the global PageRank and scales linearly with the size of the local domain.",
                "Wang and Dewitt [22] propose a system where the set of web servers that comprise the global domain communicate with each other to compute their respective global PageRanks.",
                "For a given web server hosting n pages, the computational, bandwidth, and storage requirements are also linear in n. One drawback of this system is that the number of distinct web servers that comprise the global domain can be very large.",
                "For example, our edu dataset contains websites from over 3,200 different universities; coordinating such a system among a large number of sites can be very difficult.",
                "Gan, Chen, and Suel propose a method for estimating the PageRank of a single page [5] which uses only constant bandwidth, computation, and space.",
                "Their approach relies on the availability of a remote connectivity server that can supply the set of inlinks to a given page, an assumption not used in our framework.",
                "They experimentally show that a reasonable estimate of the nodes PageRank can be obtained by visiting at most a few hundred nodes.",
                "Using their algorithm for our problem would require that either the entire global domain first be downloaded or a connectivity server be used, both of which would lead to very large web graphs. 8.",
                "CONCLUSIONS AND FUTURE WORK The internet is growing exponentially, and in order to navigate such a large repository as the web, global search engines have established themselves as a necessity.",
                "Along with the ubiquity of these <br>large-scale search engine</br>s comes an increase in search users expectations.",
                "By providing complete and isolated coverage of a particular web domain, localized search engines are an effective outlet to quickly locate content that could otherwise be difficult to find.",
                "In this work, we contend that the use of global PageRank in a localized search engine can improve performance.",
                "To estimate the global PageRank, we have proposed an iterative node selection framework where we select which pages from the global frontier to crawl next.",
                "Our primary contribution is our stochastic complementation page selection algorithm.",
                "This method crawls nodes that will most significantly impact the local domain and has running time linear in the number of nodes in the local domain.",
                "Experimentally, we validate these methods across a diverse set of local domains, including seven site-specific domains and four topic-specific domains.",
                "We conclude that by crawling an additional n or 2n pages, our methods find an estimate of the global PageRanks that is up to ten times better than just using the local PageRanks.",
                "Furthermore, we demonstrate that our algorithm consistently outperforms other existing heuristics. 124 Research Track Paper Often times, topic-specific domains are discovered using a focused web crawler which considers a pages content in conjunction with link anchor text to decide which pages to crawl next [4].",
                "Although such crawlers have proven to be quite effective in discovering topic-related content, many irrelevant pages are also crawled in the process.",
                "Typically, these pages are deleted and not indexed by the localized search engine.",
                "These pages can of course provide valuable information regarding the global PageRank of the local domain.",
                "One way to integrate these pages into our framework is to start the FindGlobalPR algorithm with the current subgraph F equal to the set of pages that were crawled by the focused crawler.",
                "The global PageRank estimation framework, along with the node selection algorithms presented, all require O(n) computation per iteration and bandwidth proportional to the number of pages crawled, Tk.",
                "If the number of iterations T is relatively small compared to the number of pages crawled per iteration, k, then the bottleneck of the algorithm will be the crawling phase.",
                "However, as the number of iterations increases (relative to k), the bottleneck will reside in the node selection computation.",
                "In this case, our algorithms would benefit from constant factor optimizations.",
                "Recall that the FindGlobalPR algorithm (Algorithm 2) requires that the PageRanks of the current expanded local domain be recomputed in each iteration.",
                "Recent work by Langville and Meyer [12] gives an algorithm to quickly recompute PageRanks of a given webgraph if a small number of nodes are added.",
                "This algorithm was shown to give speedup of five to ten times on some datasets.",
                "We plan to investigate this and other such optimizations as future work.",
                "In this paper, we have objectively evaluated our methods by measuring how close our global PageRank estimates are to the actual global PageRanks.",
                "To determine the benefit of using global PageRanks in a localized search engine, we suggest a user study in which users are asked to rate the quality of search results for various search queries.",
                "For some queries, only the local PageRanks are used in ranking, and for the remaining queries, local PageRanks and the approximate global PageRanks, as computed by our algorithms, are used.",
                "The results of such a study can then be analyzed to determine the added benefit of using the global PageRanks computed by our methods, over just using the local PageRanks.",
                "Acknowledgements.",
                "This research was supported by NSF grant CCF-0431257, NSF Career Award ACI-0093404, and a grant from Sabre, Inc. 9.",
                "REFERENCES [1] R. Baeza-Yates, M. Marin, C. Castillo, and A. Rodriguez.",
                "Crawling a country: better strategies than breadth-first for web page ordering.",
                "World-Wide Web Conference, 2005. [2] P. Boldi, M. Santini, and S. Vigna.",
                "Do your worst to make the best: paradoxical effects in pagerank incremental computations.",
                "Workshop on Web Graphs, 3243:168-180, 2004. [3] S. Brin and L. Page.",
                "The anatomy of a large-scale hypertextual web search engine.",
                "Computer Networks and ISDN Systems, 33(1-7):107-117, 1998. [4] S. Chakrabarti, M. van den Berg, and B. Dom.",
                "Focused crawling: a new approach to topic-specific web resource discovery.",
                "World-Wide Web Conference, 1999. [5] Y. Chen, Q. Gan, and T. Suel.",
                "Local methods for estimating pagerank values.",
                "Conference on Information and Knowledge Management, 2004. [6] J. Cho, H. Garcia-Molina, and L. Page.",
                "Efficient crawling through url ordering.",
                "World-Wide Web Conference, 1998. [7] T. H. Haveliwala and S. D. Kamvar.",
                "The second eigenvalue of the Google matrix.",
                "Technical report, Stanford University, 2003. [8] T. Joachims, F. Radlinski, L. Granka, A. Cheng, C. Tillekeratne, and A. Patel.",
                "Learning retrieval functions from implicit feedback. http://www.cs.cornell.edu/People/tj/career. [9] S. D. Kamvar, T. H. Haveliwala, C. D. Manning, and G. H. Golub.",
                "Exploiting the block structure of the web for computing pagerank.",
                "World-Wide Web Conference, 2003. [10] S. D. Kamvar, T. H. Haveliwala, C. D. Manning, and G. H. Golub.",
                "Extrapolation methods for accelerating pagerank computation.",
                "World-Wide Web Conference, 2003. [11] A. N. Langville and C. D. Meyer.",
                "Deeper inside pagerank.",
                "Internet Mathematics, 2004. [12] A. N. Langville and C. D. Meyer.",
                "Updating the stationary vector of an irreducible markov chain with an eye on Googles pagerank.",
                "SIAM Journal on Matrix Analysis, 2005. [13] P. Lyman, H. R. Varian, K. Swearingen, P. Charles, N. Good, L. L. Jordan, and J. Pal.",
                "How much information 2003?",
                "School of Information Management and System, University of California at Berkely, 2003. [14] F. McSherry.",
                "A uniform approach to accelerated pagerank computation.",
                "World-Wide Web Conference, 2005. [15] C. D. Meyer.",
                "Stochastic complementation, uncoupling markov chains, and the theory of nearly reducible systems.",
                "SIAM Review, 31:240-272, 1989. [16] US News and World Report. http://www.usnews.com. [17] Dmoz open directory project. http://www.dmoz.org. [18] Nutch open source search engine. http://www.nutch.org. [19] F. Radlinski and T. Joachims.",
                "Query chains: learning to rank from implicit feedback.",
                "ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, 2005. [20] S. Raghavan and H. Garcia-Molina.",
                "Crawling the hidden web.",
                "In Proceedings of the Twenty-seventh International Conference on Very Large Databases, 2001. [21] T. Tin Tang, D. Hawking, N. Craswell, and K. Griffiths.",
                "Focused crawling for both topical relevance and quality of medical information.",
                "Conference on Information and Knowledge Management, 2005. [22] Y. Wang and D. J. DeWitt.",
                "Computing pagerank in a distributed internet search system.",
                "Proceedings of the 30th VLDB Conference, 2004. 125 Research Track Paper"
            ],
            "original_annotated_samples": [
                "One disadvantage such systems have over <br>large-scale search engine</br>s is the lack of global PageRank values.",
                "Compared to the web graph crawled and indexed by <br>large-scale search engine</br>s, the size of such local communities is typically orders of magnitude smaller.",
                "Along with the ubiquity of these <br>large-scale search engine</br>s comes an increase in search users expectations."
            ],
            "translated_annotated_samples": [
                "Una desventaja que tienen estos sistemas en comparación con los <br>motores de búsqueda a gran escala</br> es la falta de valores globales de PageRank.",
                "En comparación con el grafo web rastreado e indexado por los <br>motores de búsqueda a gran escala</br>, el tamaño de estas comunidades locales suele ser típicamente órdenes de magnitud más pequeño.",
                "Junto con la omnipresencia de estos <br>motores de búsqueda a gran escala</br>, surge un aumento en las expectativas de los usuarios de búsqueda."
            ],
            "translated_text": "Estimando el PageRank Global de Comunidades Web Jason V. Davis Dept. Departamento de Ciencias de la Computación Universidad de Texas en Austin Austin, TX 78712 jdavis@cs.utexas.edu Inderjit S. Dhillon Departamento de Ciencias de la Computación Universidad de Texas en Austin Austin, TX 78712 inderjit@cs.utexas.edu RESUMEN Los motores de búsqueda localizados son sistemas a pequeña escala que indexan una comunidad particular en la web. Ofrecen varios beneficios en comparación con sus contrapartes a gran escala, ya que son relativamente económicos de construir y pueden proporcionar una capacidad de búsqueda más precisa y completa en sus dominios relevantes. Una desventaja que tienen estos sistemas en comparación con los <br>motores de búsqueda a gran escala</br> es la falta de valores globales de PageRank. Se necesita esa información para evaluar el valor de las páginas en el dominio de búsqueda localizada dentro del contexto de la web en su totalidad. En este artículo, presentamos algoritmos bien fundamentados para estimar los valores globales de PageRank de un dominio local. Los algoritmos son altamente escalables en el sentido de que, dado un dominio local de tamaño n, utilizan recursos de O(n) que incluyen tiempo de computación, ancho de banda y almacenamiento. Probamos nuestros métodos en una variedad de dominios localizados, incluyendo dominios específicos del sitio y dominios específicos del tema. Demostramos que al rastrear tan solo n o 2n páginas adicionales, nuestros métodos pueden proporcionar excelentes estimaciones globales de PageRank. Categorías y Descriptores de Asignaturas H.3.3 [Almacenamiento y Recuperación de Información]: Búsqueda y Recuperación de Información; G.1.3 [Análisis Numérico]: Álgebra Lineal Numérica; G.3 [Probabilidad y Estadística]: Procesos de Markov Términos Generales PageRank, Cadena de Markov, Complementación Estocástica. Los motores de búsqueda localizados son motores de búsqueda a pequeña escala que indexan solo una comunidad específica de la web. Tales comunidades pueden ser dominios específicos del sitio, como páginas dentro del dominio cs.utexas.edu, o comunidades relacionadas con un tema, por ejemplo, sitios web políticos. En comparación con el grafo web rastreado e indexado por los <br>motores de búsqueda a gran escala</br>, el tamaño de estas comunidades locales suele ser típicamente órdenes de magnitud más pequeño. Por consiguiente, los recursos computacionales necesarios para construir un motor de búsqueda de este tipo también son igualmente más ligeros. Al restringirse a secciones más pequeñas y manejables de la web, los motores de búsqueda localizados también pueden ofrecer capacidades de búsqueda más precisas y completas dentro de sus respectivos dominios. Una desventaja de los índices localizados es la falta de información global necesaria para calcular clasificaciones basadas en enlaces. El algoritmo PageRank [3] ha demostrado ser una medida efectiva de este tipo. En general, el PageRank de una página dada depende de las páginas en todo el grafo web. En el contexto de un motor de búsqueda localizado, si los PageRanks se calculan utilizando solo el subgrafo local, entonces esperaríamos que los PageRanks resultantes reflejen la popularidad percibida dentro de la comunidad local y no de la web en su totalidad. Por ejemplo, consideremos un motor de búsqueda localizado que indexa páginas políticas con puntos de vista conservadores. Una persona que desee investigar las opiniones sobre el calentamiento global dentro de la comunidad política conservadora puede encontrarse con numerosas opiniones de este tipo en varios sitios web. Si solo se dispone de valores de PageRank locales, entonces los resultados de búsqueda reflejarán solo creencias fuertemente arraigadas dentro de la comunidad. Sin embargo, si los PageRanks globales también están disponibles, entonces los resultados pueden reflejar adicionalmente las opiniones de los externos sobre la comunidad conservadora (es decir, aquellos documentos a los que los liberales acceden con mayor frecuencia dentro de la comunidad conservadora). Por lo tanto, para muchos motores de búsqueda localizados, la incorporación de PageRanks globales puede mejorar la calidad de los resultados de búsqueda. Sin embargo, el número de páginas que indexa un motor de búsqueda local suele ser órdenes de magnitud más pequeño que el número de páginas indexadas por sus contrapartes a gran escala. Los motores de búsqueda localizados no tienen el ancho de banda, la capacidad de almacenamiento o la potencia computacional para rastrear, descargar y calcular los PageRanks globales de toda la web. En este trabajo, presentamos un método para aproximar los PageRanks globales de un dominio local utilizando recursos del mismo orden que los necesarios para calcular los PageRanks del subgrafo local. Nuestro método propuesto busca un supergrafo de nuestro subgrafo local de manera que los PageRanks locales dentro de este supergrafo estén cerca de los verdaderos PageRanks globales. Construimos este supergrafo mediante el rastreo iterativo de páginas globales en la frontera web actual, es decir, páginas globales con enlaces entrantes de páginas que ya han sido rastreadas. Para proporcionar a 116 Research Track Paper una buena aproximación a los PageRanks globales, es necesario tener cuidado al elegir qué páginas rastrear a continuación; en este documento, presentamos un algoritmo de selección de páginas bien fundamentado que también tiene un buen rendimiento empírico. Este algoritmo se deriva de un objetivo de problema bien definido y tiene un tiempo de ejecución lineal en el número de nodos locales. Experimentamos en varios tipos de subgrafos locales, incluidas cuatro comunidades relacionadas con el tema y varios dominios específicos del sitio. Para evaluar el rendimiento, medimos la diferencia entre la estimación actual del PageRank global y el PageRank global, en función del número de páginas rastreadas. Comparamos nuestro algoritmo con varios heurísticos y también con un algoritmo base que elige páginas al azar, y demostramos que nuestro método supera a estos otros métodos. Finalmente, demostramos empíricamente que, dado un dominio local de tamaño n, podemos proporcionar buenas aproximaciones a los valores globales de PageRank rastreando como máximo n o 2n páginas adicionales. El documento está organizado de la siguiente manera. La sección 2 ofrece una visión general de los motores de búsqueda localizados y destaca sus ventajas sobre los motores de búsqueda globales. La sección 3 proporciona antecedentes sobre el algoritmo PageRank. La sección 4 define formalmente nuestro problema, y la sección 5 presenta nuestros criterios de selección de páginas y deriva nuestros algoritmos. La sección 6 presenta los resultados experimentales, la sección 7 ofrece una visión general del trabajo relacionado y, finalmente, las conclusiones se presentan en la sección 8. MOTORES DE BÚSQUEDA LOCALIZADOS Los motores de búsqueda localizados indexan una sola comunidad de la web, típicamente una comunidad específica del sitio o una comunidad específica del tema. Los motores de búsqueda localizados disfrutan de tres ventajas principales sobre sus contrapartes a gran escala: son relativamente económicos de construir, pueden ofrecer una capacidad de búsqueda más precisa dentro de su dominio local y pueden proporcionar un índice más completo. Los recursos necesarios para construir un motor de búsqueda global son enormes. Un estudio de 2003 realizado por Lyman et al. [13] encontró que la web superficial (sitios estáticos de acceso público) consta de 8.9 mil millones de páginas, y que el tamaño promedio de estas páginas es de aproximadamente 18.7 kilobytes. Para descargar un rastreo de este tamaño, se necesita aproximadamente 167 terabytes de espacio. Para un investigador que desee construir un motor de búsqueda con acceso a un par de estaciones de trabajo o un servidor pequeño, un almacenamiento de esta magnitud simplemente no está disponible. Sin embargo, construir un motor de búsqueda localizado sobre una comunidad web de cien mil páginas solo requeriría unos pocos gigabytes de almacenamiento. La carga computacional necesaria para soportar consultas de búsqueda sobre una base de datos de este tamaño es más manejable también. Observamos que, para los motores de búsqueda específicos de un tema, la comunidad relevante puede ser identificada y descargada de manera eficiente utilizando un rastreador enfocado [21, 4]. Para dominios específicos del sitio, el dominio local está fácilmente disponible en su propio servidor web. Esto evita la necesidad de rastreo o indexación, y por lo tanto se puede garantizar un índice completo y actualizado del dominio. Esto contrasta con sus contrapartes a gran escala, las cuales sufren de varias deficiencias. Primero, el rastreo de páginas generadas dinámicamente en la web oculta ha sido objeto de investigación [20] y es una tarea no trivial para un rastreador externo. En segundo lugar, los dominios específicos del sitio pueden habilitar la política de exclusión de robots. Esto prohíbe a los rastreadores de motores de búsqueda externos descargar contenido del dominio, y en su lugar un motor de búsqueda externo debe depender de enlaces externos y texto ancla para indexar estas páginas restringidas. Al restringirse a un dominio específico de internet, un motor de búsqueda localizado puede proporcionar resultados de búsqueda más precisos. Considera la consulta de búsqueda ambigua canónica, jaguar, que puede referirse tanto al fabricante de automóviles como al animal. Un científico que intenta investigar el hábitat y la historia evolutiva de un jaguar puede tener más éxito utilizando un motor de búsqueda específico de zoología bien ajustado que consultando Google con múltiples búsquedas de palabras clave y navegando a través de resultados irrelevantes. Recientemente se propuso un método para aprender funciones de clasificación mejores para la recuperación por Radlinski y Joachims [19] y se ha aplicado a varios dominios locales, incluido el sitio web de la Universidad de Cornell [8]. 3. PAGERANK RESUMEN El algoritmo PageRank define la importancia de las páginas web analizando la estructura de hipervínculos subyacente de un grafo web. El algoritmo funciona construyendo una cadena de Markov a partir de la estructura de enlaces del grafo web y calculando su distribución estacionaria. Una forma de calcular la distribución estacionaria de una cadena de Markov es encontrar la distribución límite de un paseo aleatorio sobre la cadena. Por lo tanto, el algoritmo PageRank utiliza lo que a veces se conoce como el modelo del surfista aleatorio. En cada paso de la caminata aleatoria, el surfista sigue un enlace de salida de la página actual (es decir, el nodo actual en la cadena), o salta a una página aleatoria en la web. Ahora definimos con precisión el problema de PageRank. Sea U una matriz de adyacencia m × m para un grafo web dado tal que Uji = 1 si la página i enlaza a la página j y Uji = 0 en caso contrario. Definimos la matriz de PageRank PU como: PU = αUD−1 U + (1 − α)veT , (1) donde DU es la matriz diagonal (única) tal que UD−1 U es estocástica por columnas, α es un escalar dado tal que 0 ≤ α ≤ 1, e es el vector de todos unos, y v es un vector no negativo, L1-normalizado, a veces llamado vector de navegante aleatorio. Ten en cuenta que la matriz D−1 U está bien definida solo si cada columna de U tiene al menos una entrada distinta de cero, es decir, cada página en el grafo web tiene al menos un enlace de salida. En presencia de nodos colgantes que no tienen enlaces de salida, una solución comúnmente utilizada, propuesta por Brin et al. [3], es reemplazar cada columna de ceros de U por un vector no negativo, normalizado en L1. El vector PageRank r es el eigenvector dominante de la matriz PageRank, r = PU r. Supondremos, sin pérdida de generalidad, que r tiene una norma L1 de uno. Computacionalmente, r se puede calcular utilizando el método de la potencia. Este método primero elige un vector inicial aleatorio r(0) y, de forma iterativa, multiplica el vector actual por la matriz de PageRank PU; ver Algoritmo 1. En general, cada iteración del método de la potencia puede requerir O(m2) operaciones cuando PU es una matriz densa. Sin embargo, en la práctica, el número de enlaces en un grafo web será del orden del número de páginas. Al explotar la dispersión de la matriz de PageRank, el trabajo por iteración se puede reducir a O(km), donde k es el número promedio de enlaces por página web. También se ha demostrado que el número total de iteraciones necesarias para la convergencia es proporcional a α y no depende del tamaño del grafo web [11, 7]. Finalmente, el espacio total necesario también es O(km), principalmente para almacenar la matriz U. 117 Research Track Paper Algorithm 1: Un algoritmo de tiempo lineal (por iteración) para calcular PageRank. CalcularPR(U) Entrada: U: Matriz de adyacencia. Salida: vector de PageRank. Elige (aleatoriamente) un vector inicial no negativo r(0) tal que r(0) 1 = 1. i ← 0 repetir i ← i + 1 ν ← αUD−1 U r(i−1) {α es la probabilidad de navegación aleatoria} r(i) ← ν + (1 − α)v {v es el vector del navegante aleatorio.} hasta que r(i) − r(i−1) < δ {δ es el umbral de convergencia.} r ← r(i) 4. Dada un dominio local L, sea G una matriz de adyacencia N × N para el componente conectado completo de la web que contiene L, tal que Gji = 1 si la página i enlaza a la página j y Gji = 0 en caso contrario. Sin pérdida de generalidad, vamos a dividir G de la siguiente manera: G = L Gout Lout Gwithin, donde L es el subgrafo local de n × n correspondiente a los enlaces dentro del dominio local, Lout es el subgrafo que corresponde a los enlaces desde el dominio local apuntando hacia el dominio global, Gout es el subgrafo que contiene los enlaces desde el dominio global hacia el dominio local, y Gwithin contiene los enlaces dentro del dominio global. Suponemos que al construir un motor de búsqueda localizado, solo se rastrean las páginas dentro del dominio local, y los enlaces entre estas páginas están representados por el subgrafo L. También se conocen los enlaces en Lout, ya que estos apuntan desde las páginas rastreadas en el dominio local a las páginas no rastreadas en el dominio global. Como se define en la ecuación (1), PG es la matriz de PageRank formada a partir del grafo global G, y definimos el vector de PageRank global de este grafo como g. Sea el vector de longitud n p∗ el vector L1-normalizado que corresponde al PageRank global de las páginas en el dominio local L: p∗ = EL g ELg 1 , donde EL = [ I | 0 ] es la matriz de restricción que selecciona los componentes de g correspondientes a los nodos en L. Sea p el vector de PageRank construido a partir del subgrafo del dominio local L. En la práctica, el PageRank local observado p y el PageRank global p∗ serán bastante diferentes. Se esperaría que a medida que el tamaño de la matriz local L se acerque al tamaño de la matriz global G, el PageRank global y el PageRank local observado se vuelvan más similares. Por lo tanto, un enfoque para estimar el PageRank global es rastrear todo el dominio global, calcular su PageRank y extraer los PageRanks del dominio local. Por lo general, sin embargo, n N, es decir, el número de páginas globales es mucho mayor que el número de páginas locales. Por lo tanto, rastrear todas las páginas globales agotará rápidamente todos los recursos locales (computacionales, de almacenamiento y de ancho de banda) disponibles para crear el motor de búsqueda local. En cambio, buscamos un supergrafo ˆF de nuestro subgrafo local L con tamaño O(n). Nuestro objetivo es el Algoritmo 2: El algoritmo FindGlobalPR. EncuentraGlobalPR(L, Lout, T, k) Entrada: L: matriz de adyacencia de ceros y unos para el dominio local, Lout: matriz de enlaces de ceros y unos desde L al subgrafo global como en (2), T: número de iteraciones, k: número de páginas a rastrear por iteración. Salida: ˆp: una estimación mejorada del PageRank global de L. F ← L Fout ← Lout f ← CalcularPR(F) para (i = 1 a T) {Determinar qué páginas rastrear a continuación} páginas ← SeleccionarNodos(F, Fout, f, k) Rastrear páginas, aumentar F y modificar Fout {Actualizar PageRanks para el nuevo dominio local} f ← CalcularPR(F) fin {Extraer PageRanks del dominio local original y normalizar} ˆp ← ELf ELf 1 es encontrar un supergrafo ˆF con PageRank ˆf, de modo que ˆf cuando se restringe a L esté cerca de p∗. Formalmente, buscamos minimizar GlobalDiff( ˆf) = EL ˆf EL ˆf 1 − p∗ 1 . (3) Elegimos la norma L1 para medir el error ya que no otorga un peso excesivo a los valores atípicos (como lo hace la norma L2, por ejemplo), y también porque es la medida de distancia más comúnmente utilizada en la literatura para comparar vectores de PageRank, así como para detectar la convergencia del algoritmo [3]. Proponemos un marco codicioso, presentado en el Algoritmo 2, para construir ˆF. Inicialmente, F se establece en el subgrafo local L, y se calcula el PageRank f de este grafo. El algoritmo luego procede de la siguiente manera. Primero, se llama al algoritmo SelectNodes (que discutimos en la siguiente sección) y devuelve un conjunto de k nodos para rastrear a continuación del conjunto de nodos en la frontera de rastreo actual, Fout. Estos nodos seleccionados son luego rastreados para expandir el subgrafo local, F, y los PageRanks de este grafo expandido son luego recalculados. Estos pasos se repiten para cada una de las T iteraciones. Finalmente, se devuelve el vector PageRank ˆp, el cual está restringido a las páginas dentro del dominio local original. Dadas nuestras restricciones de computación, ancho de banda y memoria, asumiremos que el algoritmo rastreará como máximo O(n) páginas. Dado que los PageRanks se calculan en cada iteración del algoritmo, lo cual es una operación O(n), también asumiremos que el número de iteraciones T es una constante. Por supuesto, el principal desafío aquí radica en seleccionar qué conjunto de k nodos rastrear a continuación. En la siguiente sección, definimos formalmente el problema y presentamos algoritmos eficientes. 5. SELECCIÓN DE NODO En esta sección, presentamos algoritmos de selección de nodo que operan dentro del marco codicioso presentado en la sección anterior. Primero damos un criterio bien definido para el problema de selección de páginas y proporcionamos evidencia experimental de que este criterio puede identificar de manera efectiva las páginas que optimizan nuestro objetivo del problema (3). A continuación, presentamos nuestra principal contribución algorítmica del artículo de investigación al118, un método con tiempo de ejecución lineal que se deriva de los criterios de selección de esta página. Finalmente, ofrecemos un análisis intuitivo de nuestro algoritmo en términos de fugas y flujos. Mostramos que si solo se considera el flujo, entonces el método resultante es muy similar a una heurística de selección de páginas ampliamente utilizada [6]. 5.1 Formulación Para una página dada j en el dominio global, definimos el grafo local expandido Fj: Fj = F s uT j 0, (4) donde uj es el vector de ceros y unos que contiene los enlaces de salida de F hacia la página j, y s contiene los enlaces de entrada de la página j en el dominio local. Ten en cuenta que no permitimos enlaces a uno mismo en este marco de trabajo. En la práctica, los enlaces internos suelen ser eliminados, ya que solo sirven para inflar el PageRank de una página determinada. Observa que los enlaces entrantes a F desde el nodo j no se conocen hasta después de que el nodo j sea rastreado. Por lo tanto, estimamos este vector de inlink como la expectativa sobre el recuento de inlinks entre el conjunto de páginas ya rastreadas, s = F T e F T e 1. En la práctica, para cualquier página dada, esta estimación puede no reflejar los verdaderos inlinks de esa página. Además, esta expectativa se extrae del conjunto de enlaces dentro del dominio rastreado, mientras que una estimación más precisa también utilizaría enlaces del dominio global. Sin embargo, la distribución mencionada no es conocida por un motor de búsqueda localizado, y sostenemos que la estimación anterior, en promedio, será una estimación mejor que la distribución uniforme, por ejemplo. Dejemos que el PageRank de F sea f. Expresamos el PageRank f+ j del grafo local expandido Fj como f+ j = (1 − xj)fj xj , donde xj es el PageRank del nodo global candidato j, y fj es el vector de PageRank L1-normalizado restringido a las páginas en F. Dado que optimizar directamente nuestro objetivo requiere conocer el PageRank global p∗, proponemos en su lugar rastrear aquellos nodos que tendrán la mayor influencia en los PageRanks de las páginas en el dominio local original L: influencia(j) = k∈L |fj[k] − f[k]| (7) = EL (fj − f) 1. Experimentalmente, el puntaje de influencia es un predictor muy bueno de nuestro objetivo del problema (3). Para cada nodo global candidato j, la figura 1(a) muestra el valor de la función objetivo Global Diff(fj) en función de la influencia de la página j. El dominio local utilizado aquí es un rastreo de páginas políticas conservadoras (proporcionaremos más detalles sobre este conjunto de datos en la sección 6); observamos resultados similares en otros dominios. La correlación es bastante fuerte, lo que implica que los criterios de influencia pueden identificar de manera efectiva las páginas que mejoran la estimación global del PageRank. Como referencia, la figura 1(b) compara nuestro objetivo con un criterio alternativo, el recuento de enlaces de salida. El recuento de enlaces de salida se define como el número de enlaces de salida desde el dominio local a la página j. La correlación aquí es mucho más débil. .00001 .0001 .001 .01 0.26 0.262 0.264 0.266 Influencia Objetivo 1 10 100 1000 0.266 0.264 0.262 0.26 Recuento de Enlaces Salientes Objetivo (a) (b) Figura 1: (a) La correlación entre nuestros criterios de selección de página de influencia (7) y el valor real de la función objetivo (3) es bastante fuerte. (b) Esto contrasta con otros criterios, como el recuento de enlaces salientes, que muestran una correlación mucho más débil. 5.2 Cálculo Como se describe, para cada página global candidata j, se debe calcular el puntaje de influencia (7). Si fj se calcula exactamente para cada página global j, entonces el algoritmo de PageRank tendría que ejecutarse para cada una de las O(n) páginas globales j que consideramos, lo que resultaría en un costo computacional de O(n2) para el método de selección de nodos. Por lo tanto, calcular el valor exacto de fj conducirá a un algoritmo cuadrático, y en su lugar debemos recurrir a métodos de aproximación de este vector. El algoritmo que presentamos funciona realizando una iteración del método de potencia utilizado por el algoritmo PageRank (Algoritmo 1). La tasa de convergencia para el algoritmo PageRank se ha demostrado que es igual a la probabilidad del surfista aleatorio α [7, 11]. Dado un vector inicial x(0), si se realizan k iteraciones de PageRank, la solución actual de PageRank x(k) satisface: x(k) − x∗ 1 = O(αk x(0) − x∗ 1), (8), donde x∗ es el vector de PageRank deseado. Por lo tanto, si solo se realiza una iteración, es necesario elegir un buen vector inicial para lograr una aproximación precisa. Particionamos la matriz de PageRank PFj, correspondiente al subgrafo Fj, como: PFj = ˜F ˜s ˜uT j w, (9) donde ˜F = αF (DF + diag(uj))−1 + (1 − α) e + 1 eT, ˜s = αs + (1 − α) e + 1, ˜uj = α(DF + diag(uj))−1 uj + (1 − α) e + 1, w = 1 − α + 1, y diag(uj) es la matriz diagonal con la entrada (i, i) igual a uno si el i-ésimo elemento de uj es uno, y cero en caso contrario. Hemos asumido aquí que el vector del surfista aleatorio es el vector uniforme, y que L no tiene enlaces colgantes. Estas suposiciones no son necesarias y solo sirven para simplificar la discusión y el análisis. Un enfoque sencillo para estimar fj es el siguiente. Primero, estima el PageRank f+ j de Fj calculando una iteración de PageRank sobre la matriz PFj, utilizando el vector inicial ν = f 0. Luego, estima fj eliminando el último componente de 119 Research Track Paper de nuestra estimación de f+ j (es decir, el componente correspondiente al nodo j añadido), y renormalizando. El problema con este enfoque está en el vector inicial. Recuerde que xj es el PageRank del nodo j añadido. La diferencia entre el PageRank actual f+ j de PFj y el vector inicial ν es ν − f+ j 1 = xj + f − (1 − xj)fj 1 ≥ xj + | f 1 − (1 − xj) fj 1| = xj + |xj| = 2xj. Por lo tanto, según (8), después de una iteración de PageRank, esperamos que nuestra estimación de f+ j todavía tenga un error de aproximadamente 2αxj. En particular, para los nodos candidatos j con un PageRank xj relativamente alto, este método producirá resultados más inexactos. A continuación, presentaremos un método que elimina este sesgo y se ejecuta en tiempo O(n). 5.2.1 Complementación Estocástica Dado que f+ j, como se muestra en (6), es el PageRank de la matriz PFj, tenemos: fj(1 − xj) xj = ˜F ˜s ˜uT j w fj(1 − xj) xj = ˜F fj(1 − xj) + ˜sxj ˜uT j fj(1 − xj) + wxj. Resolver el sistema anterior para fj puede demostrarse que produce fj = ( ˜F + (1 − w)−1 ˜s˜uT j )fj. (10) La matriz S = ˜F +(1−w)−1 ˜s˜uT j se conoce como el complemento estocástico de la matriz estocástica de columna PFj con respecto a la submatriz ˜F. La teoría de complementación estocástica está bien estudiada, y se puede demostrar que el complemento estocástico de una matriz irreducible (como la matriz de PageRank) es único. Además, el complemento estocástico también es irreducible y, por lo tanto, tiene una distribución estacionaria única. Para un estudio extenso, ver [15]. Se puede demostrar fácilmente que el autovalor subdominante de S es a lo sumo +1 α, donde α es el tamaño de F. Para valores suficientemente grandes, este valor estará muy cerca de α. Esto es importante, ya que otras propiedades del algoritmo PageRank, especialmente la sensibilidad del algoritmo, dependen de este valor [11]. En este método, estimamos el vector de longitud fj calculando una iteración de PageRank sobre el complemento estocástico × S, comenzando en el vector f: fj ≈ Sf. (11) Esto contrasta con el método simple descrito en la sección anterior, que primero itera sobre la matriz ( + 1) × ( + 1) PFj para estimar f+ j, y luego elimina el último componente de la estimación y renormaliza para aproximar fj. El problema con el último método radica en la elección del vector inicial de longitud ( + 1), ν. En consecuencia, la estimación de PageRank dada por el método simple difiere del verdadero PageRank en al menos 2αxj, donde xj es el PageRank de la página j. Al utilizar el complemento estocástico, podemos establecer un límite inferior estricto de cero para esta diferencia. Para ver esto, considera el caso en el que se agrega un nodo k a F para formar el subgrafo local aumentado Fk, y que el PageRank de este nuevo grafo es (1 − xk)f xk. Específicamente, la adición de la página k no cambia los PageRanks de las páginas en F, y por lo tanto fk = f. Por la construcción del complemento estocástico, fk = Sfk, por lo que la aproximación dada en la ecuación (11) producirá la solución exacta. A continuación, presentamos los detalles computacionales necesarios para calcular eficientemente la cantidad fj − f 1 sobre todas las páginas globales conocidas j. Comenzamos expandiendo la diferencia fj − f, donde el vector fj se estima como en (11), fj − f ≈ Sf − f = αF (DF + diag(uj))−1 f + (1 − α) e + 1 eT f +(1 − w)−1 (˜uT j f)˜s − f. (12) Tenga en cuenta que la matriz (DF + diag(uj))−1 es diagonal. Dejando que o[k] sea el recuento de enlaces de salida para la página k en F, podemos expresar el elemento diagonal k-ésimo como: (DF + diag(uj))−1 [k, k] = 1 o[k]+1 si uj[k] = 1 1 o[k] si uj[k] = 0 Notando que (o[k] + 1)−1 = o[k]−1 − (o[k](o[k] + 1))−1 y reescribiendo esto en forma matricial obtenemos (DF +diag(uj))−1 = D−1 F −D−1 F (DF +diag(uj))−1 diag(uj). (13) Usamos la misma identidad para expresar e + 1 = e − e ( + 1) . (14) Recordemos que, por definición, tenemos PF = αF D−1 F +(1−α)e. Sustituyendo (13) y (14) en (12) se obtiene que fj − f ≈ (PF f − f) −αF D−1 F (DF + diag(uj))−1 diag(uj)f −(1 − α) e ( + 1) + (1 − w)−1 (˜uT j f)˜s = x + y + (˜uT j f)z, (15), notando que por definición, f = PF f, y definiendo los vectores x, y, y z como x = −αF D−1 F (DF + diag(uj))−1 diag(uj)f (16) y = −(1 − α) e ( + 1) (17) z = (1 − w)−1 ˜s. (18) El primer término x es un vector disperso, y toma valores no nulos solo para las páginas locales k que son hermanas de la página global j. Definimos (i, j) ∈ F si y solo si F [j, i] = 1 (equivalentemente, la página i enlaza a la página j) y expresamos el valor del componente x[k] como: x[k] = −α k:(k,k)∈F, uj[k]=1 f[k] o[k](o[k] + 1), (19) donde o[k], como antes, es el número de enlaces salientes de la página k en el dominio local. Ten en cuenta que los dos últimos términos, y y z, no dependen del nodo global actual j. Dada la función hj(f) = y + (˜uT j f)z 1, la cantidad fj − f 1 120 Research Track Paper puede expresarse como fj − f 1 = k x[k] + y[k] + (˜uT j f)z[k] = k:x[k]=0 y[k] + (˜uT j f)z[k] + k:x[k]=0 x[k] + y[k] + (˜uT j f)z[k] = hj(f) − k:x[k]=0 y[k] + (˜uT j f)z[k] + k:x[k]=0 x[k] + y[k] + (˜uT j f)z[k]. (20) Si podemos calcular la función hj en tiempo lineal, entonces podemos calcular cada valor de fj − f 1 usando una cantidad adicional de tiempo proporcional al número de componentes no nulas en x. Estas optimizaciones se llevan a cabo en el Algoritmo 3. Nótese que la ecuación (20) calcula la diferencia entre todos los componentes de f y fj, mientras que nuestros criterios de selección de nodos, dados en la ecuación (7), se restringen a los componentes correspondientes a los nodos en el dominio local original L. Examinemos el Algoritmo 3 con más detalle. Primero, el algoritmo calcula el número de enlaces de salida para cada página en el dominio local. El algoritmo luego calcula la cantidad ˜uT j f para cada página global j conocida. Este producto interno se puede escribir como (1 − α) 1 + 1 + α k:(k,j)∈Fout f[k] o[k] + 1, donde el segundo término suma sobre el conjunto de páginas locales que enlazan a la página j. Dado que se asumió que el número total de aristas en Fout tenía un tamaño O( ) (recordemos que es el número de páginas en F), el tiempo de ejecución de este paso también es O( ). El algoritmo luego calcula los vectores y y z, como se indican en (17) y (18), respectivamente. El método L1NormDiff se llama en los componentes de estos vectores que corresponden a las páginas en L, y estima el valor de EL(y + (˜uT j f)z) 1 para cada página j. La estimación funciona de la siguiente manera. Primero, los valores de ˜uT j f se discretizan de forma uniforme en c valores {a1, ..., ac}. La cantidad EL(y + aiz) 1 se calcula entonces para cada valor discretizado de ai y se almacena en una tabla. Para evaluar EL (y + az) 1 para algún a ∈ [a1, ac], se determina el valor discretizado más cercano ai, y se utiliza la entrada correspondiente en la tabla. El tiempo total de ejecución de este método es lineal en y el parámetro de discretización c (que consideramos constante). Observamos que si se desean valores exactos, también hemos desarrollado un algoritmo que se ejecuta en tiempo O(log) que no se describe aquí. En el bucle principal, calculamos el vector x, tal como se define en la ecuación (16). Los bucles anidados iteran sobre el conjunto de páginas en F que son hermanas de la página j. Normalmente, el tamaño de este conjunto está limitado por una constante. Finalmente, para cada página j, el vector de puntuaciones se actualiza sobre el conjunto de componentes no nulos k del vector x con k ∈ L. Este conjunto tiene un tamaño igual al número de hermanos locales de la página j, y es un subconjunto del número total de hermanos de la página j. Por lo tanto, cada iteración del bucle principal toma tiempo constante, y el tiempo de ejecución total del bucle principal es O( ). Dado que hemos asumido que el tamaño de F no crecerá más allá de O(n), el tiempo de ejecución total del algoritmo es O(n). Algoritmo 3: Selección de nodos a través de la complementación estocástica. SC-Select(F , Fout, f, k) Entrada: F : matriz de adyacencia de ceros y unos del tamaño correspondiente al subgrafo local actual, Fout: matriz de enlaces de ceros y unos de F al subgrafo global, f: PageRank de F , k: número de páginas a devolver Salida: páginas: conjunto de k páginas para rastrear a continuación {Calcular sumas de enlaces de salida para el subgrafo local} para cada (página j ∈ F ) o[j] ← k:(j,k)∈F F[j, k] fin {Calcular escalar ˜uT j f para cada nodo global j } para cada (página j ∈ Fout) g[j] ← (1 − α) 1 +1 para cada (página k : (k, j) ∈ Fout) g[j] ← g[j] + α f[k] o[k]+1 fin fin {Calcular vectores y z como en (17) y (18) } y ← −(1 − α) e ( +1) z ← (1 − w)−1 ˜s {Aproximar y + g[j] ∗ z 1 para todos los valores g[j]} norm diffs ←L1NormDiffs(g, ELy, ELz) para cada (página j ∈ Fout) {Calcular vector disperso x como en (19)} x ← 0 para cada (página k : (k, j) ∈ Fout) para cada (página k : (k, k ) ∈ F )) x[k ] ← x[k ] − f[k] o[k](o[k]+1) fin fin x ← αx scores[j] ← norm diffs[j] para cada (k : x[k] > 0 y página k ∈ L) scores[j] ← scores[j] − |y[k] + g[j] ∗ z[k]| +|x[k]+y[k]+g[j]∗z[k])| fin fin Devolver k páginas con los puntajes más altos 5.2.2 Flujos de PageRank Ahora presentamos un análisis intuitivo del método de complementación estocástica descomponiendo el cambio en PageRank en términos de fugas y flujos. Este análisis está motivado por la descomposición dada en (15). El flujo de PageRank es el aumento en los PageRanks locales que se originan desde la página global j. Los flujos están representados por el vector no negativo (˜uT j f)z (ecuaciones (15) y (18)). El escalar ˜uT j f se puede pensar como la cantidad total de flujo de PageRank que la página j tiene disponible para distribuir. El vector z dicta cómo se asigna el flujo al dominio local; el flujo que recibe la página local k es proporcional (con un factor constante debido al vector de navegante aleatorio) al número esperado de sus enlaces entrantes. Las filtraciones de PageRank representan la disminución en el PageRank resultante de la adición de la página j. La fuga puede ser cuantificada en términos de los vectores no positivos x e y (ecuaciones (16) y (17)). Para el vector x, podemos ver a partir de la ecuación (19) que la cantidad de PageRank filtrado por una página local es proporcional a la suma ponderada de los Page121 Research Track Paper Ranks de sus páginas hermanas. Por lo tanto, las páginas que tienen hermanos con PageRanks más altos (y un bajo número de enlaces salientes) experimentarán más pérdida de valor. La fuga causada por y es un artefacto del vector del surfista aleatorio. A continuación demostraremos que si solo se considera el término de flujo, (˜uT j f)z, entonces el método resultante es muy similar a una heurística propuesta por Cho et al. [6] que ha sido ampliamente utilizada para el problema de Ordenación de URL en el Rastreo. Esta heurística es computacionalmente más económica, pero como veremos más adelante, no es tan efectiva como el método de Complementación Estocástica. Nuestra estrategia de selección de nodos elige nodos globales que tienen la mayor influencia (ecuación (7)). Si esta influencia se aproxima utilizando solo flujos, el nodo óptimo j∗ es: j∗ = argmaxj EL ˜uT j fz 1 = argmaxj ˜uT j f EL z 1 = argmaxj ˜uT j f = argmaxj α(DF + diag(uj))−1 uj + (1 − α) e + 1 , f = argmaxjfT (DF + diag(uj))−1 uj. La puntuación de selección de página resultante se puede expresar como la suma de los PageRanks de cada página local k que enlaza con j, donde cada valor de PageRank se normaliza por o[k]+1. Curiosamente, la normalización que surge en nuestro método difiere de la heurística dada en [6], la cual normaliza por o[k]. El algoritmo PF-Select, que se omite por falta de espacio, primero calcula la cantidad fT (DF +diag(uj))−1 uj para cada página global j, y luego devuelve las páginas con los k puntajes más altos. Para ver que el tiempo de ejecución de este algoritmo es O(n), observe que la computación involucrada en este método es un subconjunto de la necesaria para el método SC-Select (Algoritmo 3), el cual se demostró que tiene un tiempo de ejecución de O(n). 6. EXPERIMENTOS En esta sección, proporcionamos evidencia experimental para verificar la efectividad de nuestros algoritmos. Primero describimos nuestra metodología experimental y luego presentamos resultados en una variedad de dominios locales. 6.1 Metodología Dado los recursos limitados disponibles en una institución académica, rastrear una sección de la web que sea de la misma magnitud que la indexada por Google o Yahoo! claramente es inviable. Por lo tanto, para un dominio local dado, aproximamos el grafo global rastreando un vecindario local alrededor del dominio que es varias órdenes de magnitud más grande que el subgrafo local. A pesar de que dicho gráfico sigue siendo órdenes de magnitud más pequeño que el verdadero gráfico global, sostenemos que, incluso si existen algunas páginas altamente influyentes que están muy lejos de nuestro dominio local, es poco realista que cualquier algoritmo de selección de nodos locales las encuentre. Tales páginas suelen ser muy poco relacionadas con las páginas dentro del dominio local. Al explicar nuestras estrategias de selección de nodos en la sección 5, hicimos la suposición simplificadora de que nuestro grafo local no contenía nodos colgantes. Esta suposición se hizo solo para facilitar nuestro análisis. Nuestra implementación maneja de manera eficiente los enlaces colgantes al reemplazar cada columna de ceros de nuestra matriz de adyacencia con el vector uniforme. Evaluamos el algoritmo utilizando las dos estrategias de selección de nodos dadas en la Sección 5.2, y también comparándolo con los siguientes métodos de referencia: • Aleatorio: Los nodos se eligen de forma uniforme al azar entre los nodos globales conocidos. • Conteo de enlaces de salida: Se eligen los nodos globales con el mayor número de enlaces de salida desde el dominio local. En cada iteración del algoritmo FindGlobalPR, evaluamos el rendimiento calculando la diferencia entre la estimación actual de PageRank del dominio local, ELf ELf 1, y el PageRank global del dominio local, ELg ELg 1. Todas las calculaciones de PageRank se realizaron utilizando el vector de surfista aleatorio uniforme. En todos los experimentos, establecimos el parámetro del surfista aleatorio α en .85 y utilizamos un umbral de convergencia de 10−6. Evaluamos la diferencia entre los vectores de PageRank local y global utilizando tres métricas diferentes: las normas L1 y L∞, y el tau de Kendall. La norma L1 mide la suma del valor absoluto de las diferencias entre los dos vectores, y la norma L∞ mide el valor absoluto de la mayor diferencia. La métrica de tau de Kendall es una medida de correlación de rangos popular utilizada para comparar PageRanks [2, 11]. Esta métrica se puede calcular contando el número de pares de pares que coinciden en la clasificación, y restando de eso el número de pares de pares que no coinciden en la clasificación. El valor final se normaliza luego por el número total de n pares de este tipo, resultando en un rango de [−1, 1], donde una puntuación negativa indica una anticorrelación entre las clasificaciones, y valores cercanos a uno corresponden a una fuerte correlación de rangos. 6.2 Resultados Nuestros experimentos se basan en dos grandes rastreos web y se descargaron utilizando el rastreador web que forma parte del proyecto de motor de búsqueda de código abierto Nutch [18]. Todas las exploraciones se limitaron únicamente a páginas http, y para limitar el número de páginas generadas dinámicamente que exploramos, ignoramos todas las páginas con URLs que contengan alguno de los caracteres ?, *, @ o =. El primer rastreo, al que nos referiremos como el conjunto de datos edu, fue iniciado por las páginas de inicio de los 100 principales departamentos de posgrado en informática en los Estados Unidos, según la clasificación de US News and World Report [16], y también por las páginas de inicio de sus respectivas instituciones. Se realizó un rastreo de profundidad 5, restringido a páginas dentro del dominio .edu, lo que resultó en un grafo con aproximadamente 4.7 millones de páginas y 22.9 millones de enlaces. El segundo rastreo fue alimentado por el conjunto de páginas bajo la jerarquía de política en el proyecto de directorio abierto dmoz[17]. Rastreamos todas las páginas hasta cuatro enlaces de distancia, lo que resultó en un grafo con 4.4 millones de páginas y 17.3 millones de enlaces. Dentro del rastreo educativo, identificamos los cinco dominios específicos del sitio correspondientes a los sitios web de los cinco principales departamentos de posgrado en ciencias de la computación, según la clasificación de US News and World Report. Esto produjo dominios locales de varios tamaños, desde 10,626 (UIUC) hasta 59,895 (Berkeley). Para cada uno de estos dominios específicos del sitio con tamaño n, realizamos 50 iteraciones del algoritmo FindGlobalPR para rastrear un total de 2n nodos adicionales. La Figura 2(a) muestra la diferencia (L1) entre la estimación de PageRank en cada iteración y el PageRank global, para el dominio local de Berkeley. El rendimiento de este conjunto de datos fue representativo del rendimiento típico en los cinco dominios locales específicos de informática. Inicialmente, la diferencia de L1 entre los PageRanks globales y locales variaba desde .0469 (Stanford) hasta .149 (MIT). Para las primeras varias iteraciones, el Artículo de Investigación 122 0 5 10 15 20 25 30 35 40 45 50 0.015 0.02 0.025 0.03 0.035 0.04 0.045 0.05 0.055 Número de Iteraciones Diferencia de PageRank Global y Local (L1) Complemento Estocástico PageRank Flujo de Enlaces de Conteo Aleatorio 0 10 20 30 40 50 0 0.05 0.1 0.15 0.2 0.25 0.3 0.35 Número de Iteraciones Diferencia de PageRank Global y Local (L1) Complemento Estocástico PageRank Flujo de Enlaces de Conteo Aleatorio 0 5 10 15 20 25 0.16 0.18 0.2 0.22 0.24 0.26 0.28 0.3 0.32 0.34 Número de Iteraciones Diferencia de PageRank Global y Local (L1) Complemento Estocástico PageRank Flujo de Enlaces de Conteo Aleatorio (a) www.cs.berkeley.edu (b) www.enterstageright.com (c) Política Figura 2: Diferencia L1 entre los PageRanks globales estimados y verdaderos para (a) el sitio web de ciencias de la computación de Berkeley, (b) el dominio específico del sitio, www.enterstageright.com, y (c) el dominio específico del tema de política. El método de complemento estocástico supera a todos los demás métodos en diferentes dominios. Tres métodos basados en enlaces superan a la heurística de selección aleatoria. Después de estas iteraciones iniciales, la heurística aleatoria tendió a ser más competitiva con (o incluso superar, como en el dominio local de Berkeley) las heurísticas de conteo de enlaces de salida y flujo de PageRank. En todos los ensayos, el método de complementación estocástica superó a los otros métodos o compitió con ellos. La Tabla 1 muestra la diferencia promedio entre los PageRanks globales estimados finales y los PageRanks globales reales para varias medidas de distancia. Algoritmo L1 L∞ Kendall Estocástico. Tabla 1: Rendimiento final promedio de varias estrategias de selección de nodos para los cinco dominios locales de informática específicos del sitio. Ten en cuenta que el Tau de Kendall mide similitud, mientras que las otras métricas son medidas de disimilitud. La Complementación Estocástica claramente supera a los otros métodos en todas las métricas. Dentro del conjunto de datos de política, también realizamos dos pruebas específicas para los sitios web más grandes en el rastreo: www.adamsmith.org, el sitio web del Instituto Adam Smith con sede en Londres, y www.enterstageright.com, una revista en línea conservadora. Al igual que con los dominios locales de edu, ejecutamos nuestro algoritmo durante 50 iteraciones, rastreando un total de 2n nodos. La figura 2 (b) muestra los resultados para el dominio www.enterstageright.com. A diferencia de los dominios locales de edu, los métodos Random y OutlinkCount no fueron competitivos ni con los métodos SC-Select ni con los métodos PF-Select. Entre todos los conjuntos de datos y todos los métodos de selección de nodos, el método de complementación estocástica fue el más impresionante en este conjunto de datos, logrando una estimación final que difería solo .0279 del PageRank global, una mejora de diez veces sobre la diferencia inicial del PageRank local de .299. Para el dominio local de Adam Smith, la diferencia inicial entre los PageRanks locales y globales fue de .148, y las estimaciones finales proporcionadas por los métodos SC-Select, PF-Select, OutlinkCount y Random fueron de .0208, .0193, .0222 y .0356, respectivamente. Dentro del conjunto de datos de política, construimos cuatro dominios locales específicos de temas. El primer dominio consistía en todas las páginas de la categoría de política de dmoz, y también todas las páginas dentro de cada uno de estos sitios hasta dos enlaces de distancia. Esto produjo un dominio local de 90,811 páginas, y los resultados se muestran en la figura 2 (c). Debido al mayor tamaño de los dominios específicos del tema, ejecutamos nuestro algoritmo solo durante 25 iteraciones para rastrear un total de n nodos. También creamos dominios específicos de temas a partir de tres subtemas políticos: liberalismo, conservadurismo y socialismo. Las páginas en estos dominios fueron identificadas por sus categorías correspondientes de dmoz. Para cada subtema, establecemos el dominio local como todas las páginas dentro de tres enlaces de las páginas de categoría dmoz correspondientes. La Tabla 2 resume el rendimiento de estos tres dominios específicos del tema, así como también del dominio político más amplio. Para cuantificar el efecto global de una página js en los valores globales de PageRank de las páginas en el dominio local, definimos el impacto de la página js como su valor de PageRank, g[j], normalizado por la fracción de sus enlaces salientes que apuntan al dominio local: impacto(j) = oL[j] o[j] · g[j], donde oL[j] es el número de enlaces salientes de la página j a páginas en el dominio local L, y o[j] es el número total de enlaces salientes de js. En términos del modelo del surfista aleatorio, el impacto de la página j es la probabilidad de que el surfista aleatorio (1) se encuentre actualmente en la página global j en su caminata aleatoria y (2) tome un enlace de salida a una página local, dado que ya ha decidido no saltar a una página aleatoria. Para el dominio político local, encontramos que muchas de las páginas con alto impacto eran de hecho páginas políticas que deberían haber sido incluidas en el tema de política de dmoz, pero no lo estaban. Por ejemplo, las dos páginas globales más influyentes fueron el motor de búsqueda político www.askhenry.com y la página de inicio de la revista política en línea www.policyreview.com. Entre las páginas no políticas, la página de inicio de la revista Education Next fue la más influyente. El diario está disponible de forma gratuita en línea y contiene artículos sobre varios aspectos de la educación K-12 en América. Para proporcionar algunas pruebas anecdóticas de la efectividad de nuestros métodos de selección de páginas, observamos que el método SC-Select eligió 11 páginas dentro del dominio www.educationnext.org, el método PF-Select descubrió 7 páginas, mientras que los métodos OutlinkCount y Random encontraron solo 6 páginas cada uno. Para el ámbito político local conservador, el sitio web socialista www.ornery.org tuvo una puntuación de impacto muy alta. Este documento de investigación de la pista 123 titulado \"Toda la política: Algoritmo L1 L2 Kendall Stoch\". Comp. .1253 .000700 .8671 Flujo PR .1446 .000710 .8518 Enlace saliente .1470 .00225 .8642 Aleatorio .2055 .00203 .8271 Conservadurismo: Algoritmo L1 L2 Kendall Estoc. Comp. .0496 .000990 .9158 Flujo PR .0554 .000939 .9028 Enlace saliente .0602 .00527 .9144 Aleatorio .1197 .00102 .8843 Liberalismo: Algoritmo L1 L2 Kendall Estoc. Comp. .0622 .001360 .8848 Flujo PR .0799 .001378 .8669 Enlace saliente .0763 .001379 .8844 Aleatorio .1127 .001899 .8372 Socialismo: Algoritmo L1 L∞ Kendall Estoc. Tabla 2: Rendimiento final entre estrategias de selección de nodos para las cuatro exploraciones específicas de temas políticos. Ten en cuenta que el coeficiente de correlación de Kendall mide la similitud, mientras que las otras métricas son medidas de disimilitud. Como era de esperar, el PageRank global de este artículo (que resulta estar en la página de inicio de la NCCPR, www.nationalresearch.com) era aproximadamente de .002, mientras que el PageRank local de esta página era solo de .00158. El método SC-Select produjo una estimación global de PageRank de aproximadamente .00182, el método PFSelect estimó un valor de .00167, y los métodos Random y OutlinkCount produjeron valores de .01522 y .00171, respectivamente. TRABAJO RELACIONADO El marco de selección de nodos que hemos propuesto es similar al problema de ordenación de URL para el rastreo propuesto por Cho et al. en [6]. Mientras que nuestro marco busca minimizar la diferencia entre el PageRank global y local, el objetivo utilizado en [6] es rastrear primero las páginas más altamente clasificadas (globalmente). Proponen varios algoritmos de selección de nodos, incluyendo la heurística del recuento de enlaces de salida, así como una variante de nuestro algoritmo PF-Select al que se refieren como la métrica de ordenación de PageRank. Encontraron que este método era el más efectivo para optimizar su objetivo, al igual que lo demostró una encuesta reciente de estos métodos realizada por Baeza-Yates et al. [1]. Boldi et al. también experimentan dentro de un marco de rastreo similar en [2], pero cuantifican sus resultados al comparar la correlación de rangos de Kendall entre los PageRanks del conjunto actual de páginas rastreadas y los del grafo global completo. Encontraron que las estrategias de selección de nodos que rastreaban páginas con el PageRank global más alto primero en realidad tenían un peor rendimiento (con respecto a la correlación de Kendalls Tau entre los PageRanks locales y globales) que las estrategias básicas de búsqueda en profundidad o en amplitud. Sin embargo, sus experimentos difieren de nuestro trabajo en que nuestros algoritmos de selección de nodos no utilizan (ni tienen acceso a) valores globales de PageRank. Se han propuesto muchas mejoras algorítmicas para calcular los valores exactos de PageRank [9, 10, 14]. Si se utilizan tales algoritmos para calcular los PageRanks globales de nuestro dominio local, todos requerirían una computación, almacenamiento y ancho de banda de O(N), donde N es el tamaño del dominio global. Esto contrasta con nuestro método, que aproxima el PageRank global y escala linealmente con el tamaño del dominio local. Wang y Dewitt [22] proponen un sistema en el que el conjunto de servidores web que conforman el dominio global se comunican entre sí para calcular sus respectivos PageRanks globales. Para un servidor web dado que aloja n páginas, los requisitos computacionales, de ancho de banda y almacenamiento también son lineales en n. Una desventaja de este sistema es que el número de servidores web distintos que conforman el dominio global puede ser muy grande. Por ejemplo, nuestro conjunto de datos edu contiene sitios web de más de 3,200 universidades diferentes; coordinar un sistema así entre un gran número de sitios puede ser muy difícil. Gan, Chen y Suel proponen un método para estimar el PageRank de una sola página [5] que utiliza solo ancho de banda, computación y espacio constantes. Su enfoque se basa en la disponibilidad de un servidor de conectividad remota que puede suministrar el conjunto de enlaces entrantes a una página dada, una suposición que no se utiliza en nuestro marco de trabajo. Experimentalmente demuestran que se puede obtener una estimación razonable del PageRank de los nodos visitando como máximo unos pocos cientos de nodos. El uso de su algoritmo para nuestro problema requeriría que primero se descargue todo el dominio global o se utilice un servidor de conectividad, lo que resultaría en grafos web muy grandes. 8. CONCLUSIONES Y TRABAJOS FUTUROS Internet está creciendo de forma exponencial, y para poder navegar por un repositorio tan grande como la web, los motores de búsqueda globales se han establecido como una necesidad. Junto con la omnipresencia de estos <br>motores de búsqueda a gran escala</br>, surge un aumento en las expectativas de los usuarios de búsqueda. Al proporcionar una cobertura completa y aislada de un dominio web específico, los motores de búsqueda localizados son un medio efectivo para localizar rápidamente contenido que de otra manera podría ser difícil de encontrar. En este trabajo, sostenemos que el uso de PageRank global en un motor de búsqueda localizado puede mejorar el rendimiento. Para estimar el PageRank global, hemos propuesto un marco de selección de nodos iterativo en el que seleccionamos qué páginas de la frontera global rastrear a continuación. Nuestra principal contribución es nuestro algoritmo de selección de páginas de complementación estocástica. Este método recorre los nodos que tendrán un impacto significativo en el dominio local y tiene un tiempo de ejecución lineal en el número de nodos en el dominio local. Experimentalmente, validamos estos métodos en un conjunto diverso de dominios locales, que incluyen siete dominios específicos del sitio y cuatro dominios específicos del tema. Concluimos que al rastrear n o 2n páginas adicionales, nuestros métodos encuentran una estimación de los PageRanks globales que es hasta diez veces mejor que simplemente usar los PageRanks locales. Además, demostramos que nuestro algoritmo supera consistentemente a otras heurísticas existentes. En muchas ocasiones, los dominios específicos de un tema se descubren utilizando un rastreador web enfocado que considera el contenido de las páginas junto con el texto del ancla del enlace para decidir qué páginas rastrear a continuación [4]. Aunque estos rastreadores han demostrado ser bastante efectivos en descubrir contenido relacionado con el tema, también se rastrean muchas páginas irrelevantes en el proceso. Por lo general, estas páginas son eliminadas y no son indexadas por el motor de búsqueda localizado. Estas páginas pueden, por supuesto, proporcionar información valiosa sobre el PageRank global del dominio local. Una forma de integrar estas páginas en nuestro marco de trabajo es comenzar el algoritmo FindGlobalPR con el subgrafo actual F igual al conjunto de páginas que fueron rastreadas por el rastreador enfocado. El marco de estimación global de PageRank, junto con los algoritmos de selección de nodos presentados, requieren todos una computación de O(n) por iteración y un ancho de banda proporcional al número de páginas rastreadas, Tk. Si el número de iteraciones T es relativamente pequeño en comparación con el número de páginas rastreadas por iteración, k, entonces el cuello de botella del algoritmo será la fase de rastreo. Sin embargo, a medida que el número de iteraciones aumenta (en relación con k), el cuello de botella residirá en el cálculo de la selección de nodos. En este caso, nuestros algoritmos se beneficiarían de optimizaciones en el factor constante. Recuerde que el algoritmo FindGlobalPR (Algoritmo 2) requiere que los PageRanks del dominio local expandido actual se vuelvan a calcular en cada iteración. El trabajo reciente de Langville y Meyer [12] proporciona un algoritmo para recalcular rápidamente los PageRanks de un grafo web dado si se agregan un pequeño número de nodos. Este algoritmo demostró proporcionar una aceleración de cinco a diez veces en algunos conjuntos de datos. Planeamos investigar esto y otras optimizaciones similares como trabajo futuro. En este artículo, hemos evaluado objetivamente nuestros métodos midiendo qué tan cercanas son nuestras estimaciones globales de PageRank a los verdaderos PageRanks globales. Para determinar el beneficio de utilizar PageRanks globales en un motor de búsqueda localizado, sugerimos un estudio de usuarios en el que se les pida a los usuarios que califiquen la calidad de los resultados de búsqueda para varias consultas de búsqueda. Para algunas consultas, solo se utilizan los PageRanks locales en la clasificación, y para las consultas restantes, se utilizan los PageRanks locales y los PageRanks globales aproximados, según lo calculado por nuestros algoritmos. Los resultados de dicho estudio pueden ser analizados para determinar el beneficio adicional de utilizar los PageRanks globales calculados por nuestros métodos, en lugar de solo utilizar los PageRanks locales. Agradecimientos. Esta investigación fue apoyada por la subvención de la NSF CCF-0431257, el Premio de Carrera de la NSF ACI-0093404 y una subvención de Sabre, Inc. 9. REFERENCIAS [1] R. Baeza-Yates, M. Marín, C. Castillo y A. Rodríguez. Rastreando un país: estrategias mejores que el recorrido en anchura para ordenar páginas web. Conferencia de la World-Wide Web, 2005. [2] P. Boldi, M. Santini y S. Vigna. Haz lo peor para lograr lo mejor: efectos paradójicos en los cálculos incrementales de PageRank. Taller sobre Grafos Web, 3243:168-180, 2004. [3] S. Brin y L. Page. La anatomía de un motor de búsqueda web hipertextual a gran escala. Redes de Computadoras y Sistemas ISDN, 33(1-7):107-117, 1998. [4] S. Chakrabarti, M. van den Berg y B. Dom. Rastreo enfocado: un nuevo enfoque para el descubrimiento de recursos web específicos de un tema. Conferencia de la World-Wide Web, 1999. [5] Y. Chen, Q. Gan y T. Suel. Métodos locales para estimar los valores de pagerank. Conferencia sobre Gestión de Información y Conocimiento, 2004. [6] J. Cho, H. Garcia-Molina y L. Page. Rastreo eficiente a través de la ordenación de URL. Conferencia de la World-Wide Web, 1998. [7] T. H. Haveliwala y S. D. Kamvar. El segundo valor propio de la matriz de Google. Informe técnico, Universidad de Stanford, 2003. [8] T. Joachims, F. Radlinski, L. Granka, A. Cheng, C. Tillekeratne y A. Patel. Aprendizaje de funciones de recuperación a partir de retroalimentación implícita. http://www.cs.cornell.edu/People/tj/career. [9] S. D. Kamvar, T. H. Haveliwala, C. D. Manning y G. H. Golub. Explotando la estructura de bloques de la web para calcular el pagerank. Conferencia de la World-Wide Web, 2003. [10] S. D. Kamvar, T. H. Haveliwala, C. D. Manning y G. H. Golub. Métodos de extrapolación para acelerar el cálculo de PageRank. Conferencia de la World-Wide Web, 2003. [11] A. N. Langville y C. D. Meyer. Más profundo dentro de PageRank. Matemáticas en Internet, 2004. [12] A. N. Langville y C. D. Meyer. Actualizando el vector estacionario de una cadena de Markov irreducible con miras al PageRank de Google. Revista SIAM sobre Análisis de Matrices, 2005. [13] P. Lyman, H. R. Varian, K. Swearingen, P. Charles, N. Good, L. L. Jordan y J. Pal. ¿Cuánta información en 2003? Escuela de Gestión de la Información y Sistemas, Universidad de California en Berkeley, 2003. [14] F. McSherry. Un enfoque uniforme para el cálculo acelerado de PageRank. Conferencia de la World-Wide Web, 2005. [15] C. D. Meyer. Complementación estocástica, desacoplamiento de cadenas de Markov y la teoría de sistemas casi reducibles. SIAM Review, 31:240-272, 1989. [16] US News and World Report. http://www.usnews.com. [17] Proyecto de directorio abierto Dmoz. http://www.dmoz.org. [18] Motor de búsqueda de código abierto Nutch. http://www.nutch.org. [19] F. Radlinski y T. Joachims. Cadenas de consulta: aprendizaje para clasificar a partir de retroalimentación implícita. Conferencia Internacional ACM SIGKDD sobre Descubrimiento de Conocimiento y Minería de Datos, 2005. [20] S. Raghavan y H. Garcia-Molina. Explorando la web oculta. En Actas de la Vigésimo séptima Conferencia Internacional sobre Bases de Datos Muy Grandes, 2001. [21] T. Tin Tang, D. Hawking, N. Craswell y K. Griffiths. Rastreo enfocado para relevancia temática y calidad de la información médica. Conferencia sobre Gestión de Información y Conocimiento, 2005. [22] Y. Wang y D. J. DeWitt. Calculando el pagerank en un sistema distribuido de búsqueda en internet. Actas de la 30ª Conferencia VLDB, 2004. 125 Artículos de Investigación. ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "link-based ranking": {
            "translated_key": "clasificaciones basadas en enlaces",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Estimating the Global PageRank of Web Communities Jason V. Davis Dept.",
                "of Computer Sciences University of Texas at Austin Austin, TX 78712 jdavis@cs.utexas.edu Inderjit S. Dhillon Dept. of Computer Sciences University of Texas at Austin Austin, TX 78712 inderjit@cs.utexas.edu ABSTRACT Localized search engines are small-scale systems that index a particular community on the web.",
                "They offer several benefits over their large-scale counterparts in that they are relatively inexpensive to build, and can provide more precise and complete search capability over their relevant domains.",
                "One disadvantage such systems have over large-scale search engines is the lack of global PageRank values.",
                "Such information is needed to assess the value of pages in the localized search domain within the context of the web as a whole.",
                "In this paper, we present well-motivated algorithms to estimate the global PageRank values of a local domain.",
                "The algorithms are all highly scalable in that, given a local domain of size n, they use O(n) resources that include computation time, bandwidth, and storage.",
                "We test our methods across a variety of localized domains, including site-specific domains and topic-specific domains.",
                "We demonstrate that by crawling as few as n or 2n additional pages, our methods can give excellent global PageRank estimates.",
                "Categories and Subject Descriptors H.3.3 [Information Storage and Retrieval]: Information Search and Retrieval; G.1.3 [Numerical Analysis]: Numerical Linear Algebra; G.3 [Probability and Statistics]: Markov Processes General Terms PageRank, Markov Chain, Stochastic Complementation 1.",
                "INTRODUCTION Localized search engines are small-scale search engines that index only a single community of the web.",
                "Such communities can be site-specific domains, such as pages within the cs.utexas.edu domain, or topic-related communitiesfor example, political websites.",
                "Compared to the web graph crawled and indexed by large-scale search engines, the size of such local communities is typically orders of magnitude smaller.",
                "Consequently, the computational resources needed to build such a search engine are also similarly lighter.",
                "By restricting themselves to smaller, more manageable sections of the web, localized search engines can also provide more precise and complete search capabilities over their respective domains.",
                "One drawback of localized indexes is the lack of global information needed to compute <br>link-based ranking</br>s.",
                "The PageRank algorithm [3], has proven to be an effective such measure.",
                "In general, the PageRank of a given page is dependent on pages throughout the entire web graph.",
                "In the context of a localized search engine, if the PageRanks are computed using only the local subgraph, then we would expect the resulting PageRanks to reflect the perceived popularity within the local community and not of the web as a whole.",
                "For example, consider a localized search engine that indexes political pages with conservative views.",
                "A person wishing to research the opinions on global warming within the conservative political community may encounter numerous such opinions across various websites.",
                "If only local PageRank values are available, then the search results will reflect only strongly held beliefs within the community.",
                "However, if global PageRanks are also available, then the results can additionally reflect outsiders views of the conservative community (those documents that liberals most often access within the conservative community).",
                "Thus, for many localized search engines, incorporating global PageRanks can improve the quality of search results.",
                "However, the number of pages a local search engine indexes is typically orders of magnitude smaller than the number of pages indexed by their large-scale counterparts.",
                "Localized search engines do not have the bandwidth, storage capacity, or computational power to crawl, download, and compute the global PageRanks of the entire web.",
                "In this work, we present a method of approximating the global PageRanks of a local domain while only using resources of the same order as those needed to compute the PageRanks of the local subgraph.",
                "Our proposed method looks for a supergraph of our local subgraph such that the local PageRanks within this supergraph are close to the true global PageRanks.",
                "We construct this supergraph by iteratively crawling global pages on the current web frontier-i.e., global pages with inlinks from pages that have already been crawled.",
                "In order to provide 116 Research Track Paper a good approximation to the global PageRanks, care must be taken when choosing which pages to crawl next; in this paper, we present a well-motivated page selection algorithm that also performs well empirically.",
                "This algorithm is derived from a well-defined problem objective and has a running time linear in the number of local nodes.",
                "We experiment across several types of local subgraphs, including four topic related communities and several sitespecific domains.",
                "To evaluate performance, we measure the difference between the current global PageRank estimate and the global PageRank, as a function of the number of pages crawled.",
                "We compare our algorithm against several heuristics and also against a baseline algorithm that chooses pages at random, and we show that our method outperforms these other methods.",
                "Finally, we empirically demonstrate that, given a local domain of size n, we can provide good approximations to the global PageRank values by crawling at most n or 2n additional pages.",
                "The paper is organized as follows.",
                "Section 2 gives an overview of localized search engines and outlines their advantages over global search.",
                "Section 3 provides background on the PageRank algorithm.",
                "Section 4 formally defines our problem, and section 5 presents our page selection criteria and derives our algorithms.",
                "Section 6 provides experimental results, section 7 gives an overview of related work, and, finally, conclusions are given in section 8. 2.",
                "LOCALIZED SEARCH ENGINES Localized search engines index a single community of the web, typically either a site-specific community, or a topicspecific community.",
                "Localized search engines enjoy three major advantages over their large-scale counterparts: they are relatively inexpensive to build, they can offer more precise search capability over their local domain, and they can provide a more complete index.",
                "The resources needed to build a global search engine are enormous.",
                "A 2003 study by Lyman et al. [13] found that the surface web (publicly available static sites) consists of 8.9 billion pages, and that the average size of these pages is approximately 18.7 kilobytes.",
                "To download a crawl of this size, approximately 167 terabytes of space is needed.",
                "For a researcher who wishes to build a search engine with access to a couple of workstations or a small server, storage of this magnitude is simply not available.",
                "However, building a localized search engine over a web community of a hundred thousand pages would only require a few gigabytes of storage.",
                "The computational burden required to support search queries over a database this size is more manageable as well.",
                "We note that, for topic-specific search engines, the relevant community can be efficiently identified and downloaded by using a focused crawler [21, 4].",
                "For site-specific domains, the local domain is readily available on their own web server.",
                "This obviates the need for crawling or spidering, and a complete and up-to-date index of the domain can thus be guaranteed.",
                "This is in contrast to their large-scale counterparts, which suffer from several shortcomings.",
                "First, crawling dynamically generated pages-pages in the hidden web-has been the subject of research [20] and is a non-trivial task for an external crawler.",
                "Second, site-specific domains can enable the robots exclusion policy.",
                "This prohibits external search engines crawlers from downloading content from the domain, and an external search engine must instead rely on outside links and anchor text to index these restricted pages.",
                "By restricting itself to only a specific domain of the internet, a localized search engine can provide more precise search results.",
                "Consider the canonical ambiguous search query, jaguar, which can refer to either the car manufacturer or the animal.",
                "A scientist trying to research the habitat and evolutionary history of a jaguar may have better success using a finely tuned zoology-specific search engine than querying Google with multiple keyword searches and wading through irrelevant results.",
                "A method to learn better ranking functions for retrieval was recently proposed by Radlinski and Joachims [19] and has been applied to various local domains, including Cornell Universitys website [8]. 3.",
                "PAGERANK OVERVIEW The PageRank algorithm defines the importance of web pages by analyzing the underlying hyperlink structure of a web graph.",
                "The algorithm works by building a Markov chain from the link structure of the web graph and computing its stationary distribution.",
                "One way to compute the stationary distribution of a Markov chain is to find the limiting distribution of a random walk over the chain.",
                "Thus, the PageRank algorithm uses what is sometimes referred to as the random surfer model.",
                "In each step of the random walk, the surfer either follows an outlink from the current page (i.e. the current node in the chain), or jumps to a random page on the web.",
                "We now precisely define the PageRank problem.",
                "Let U be an m × m adjacency matrix for a given web graph such that Uji = 1 if page i links to page j and Uji = 0 otherwise.",
                "We define the PageRank matrix PU to be: PU = αUD−1 U + (1 − α)veT , (1) where DU is the (unique) diagonal matrix such that UD−1 U is column stochastic, α is a given scalar such that 0 ≤ α ≤ 1, e is the vector of all ones, and v is a non-negative, L1normalized vector, sometimes called the random surfer vector.",
                "Note that the matrix D−1 U is well-defined only if each column of U has at least one non-zero entry-i.e., each page in the webgraph has at least one outlink.",
                "In the presence of such dangling nodes that have no outlinks, one commonly used solution, proposed by Brin et al. [3], is to replace each zero column of U by a non-negative, L1-normalized vector.",
                "The PageRank vector r is the dominant eigenvector of the PageRank matrix, r = PU r. We will assume, without loss of generality, that r has an L1-norm of one.",
                "Computationally, r can be computed using the power method.",
                "This method first chooses a random starting vector r(0) , and iteratively multiplies the current vector by the PageRank matrix PU ; see Algorithm 1.",
                "In general, each iteration of the power method can take O(m2 ) operations when PU is a dense matrix.",
                "However, in practice, the number of links in a web graph will be of the order of the number of pages.",
                "By exploiting the sparsity of the PageRank matrix, the work per iteration can be reduced to O(km), where k is the average number of links per web page.",
                "It has also been shown that the total number of iterations needed for convergence is proportional to α and does not depend on the size of the web graph [11, 7].",
                "Finally, the total space needed is also O(km), mainly to store the matrix U. 117 Research Track Paper Algorithm 1: A linear time (per iteration) algorithm for computing PageRank.",
                "ComputePR(U) Input: U: Adjacency matrix.",
                "Output: r: PageRank vector.",
                "Choose (randomly) an initial non-negative vector r(0) such that r(0) 1 = 1. i ← 0 repeat i ← i + 1 ν ← αUD−1 U r(i−1) {α is the random surfing probability} r(i) ← ν + (1 − α)v {v is the random surfer vector.} until r(i) − r(i−1) < δ {δ is the convergence threshold.} r ← r(i) 4.",
                "PROBLEM DEFINITION Given a local domain L, let G be an N × N adjacency matrix for the entire connected component of the web that contains L, such that Gji = 1 if page i links to page j and Gji = 0 otherwise.",
                "Without loss of generality, we will partition G as: G = L Gout Lout Gwithin , (2) where L is the n × n local subgraph corresponding to links inside the local domain, Lout is the subgraph that corresponds to links from the local domain pointing out to the global domain, Gout is the subgraph containing links from the global domain into the local domain, and Gwithin contains links within the global domain.",
                "We assume that when building a localized search engine, only pages inside the local domain are crawled, and the links between these pages are represented by the subgraph L. The links in Lout are also known, as these point from crawled pages in the local domain to uncrawled pages in the global domain.",
                "As defined in equation (1), PG is the PageRank matrix formed from the global graph G, and we define the global PageRank vector of this graph to be g. Let the n-length vector p∗ be the L1-normalized vector corresponding to the global PageRank of the pages in the local domain L: p∗ = EL g ELg 1 , where EL = [ I | 0 ] is the restriction matrix that selects the components from g corresponding to nodes in L. Let p denote the PageRank vector constructed from the local domain subgraph L. In practice, the observed local PageRank p and the global PageRank p∗ will be quite different.",
                "One would expect that as the size of local matrix L approaches the size of global matrix G, the global PageRank and the observed local PageRank will become more similar.",
                "Thus, one approach to estimating the global PageRank is to crawl the entire global domain, compute its PageRank, and extract the PageRanks of the local domain.",
                "Typically, however, n N , i.e., the number of global pages is much larger than the number of local pages.",
                "Therefore, crawling all global pages will quickly exhaust all local resources (computational, storage, and bandwidth) available to create the local search engine.",
                "We instead seek a supergraph ˆF of our local subgraph L with size O(n).",
                "Our goal Algorithm 2: The FindGlobalPR algorithm.",
                "FindGlobalPR(L, Lout, T, k) Input: L: zero-one adjacency matrix for the local domain, Lout: zero-one outlink matrix from L to global subgraph as in (2), T: number of iterations, k: number of pages to crawl per iteration.",
                "Output: ˆp: an improved estimate of the global PageRank of L. F ← L Fout ← Lout f ← ComputePR(F ) for (i = 1 to T) {Determine which pages to crawl next} pages ← SelectNodes(F , Fout, f, k) Crawl pages, augment F and modify Fout {Update PageRanks for new local domain} f ← ComputePR(F ) end {Extract PageRanks of original local domain & normalize} ˆp ← ELf ELf 1 is to find such a supergraph ˆF with PageRank ˆf, so that ˆf when restricted to L is close to p∗ .",
                "Formally, we seek to minimize GlobalDiff( ˆf) = EL ˆf EL ˆf 1 − p∗ 1 . (3) We choose the L1 norm for measuring the error as it does not place excessive weight on outliers (as the L2 norm does, for example), and also because it is the most commonly used distance measure in the literature for comparing PageRank vectors, as well as for detecting convergence of the algorithm [3].",
                "We propose a greedy framework, given in Algorithm 2, for constructing ˆF .",
                "Initially, F is set to the local subgraph L, and the PageRank f of this graph is computed.",
                "The algorithm then proceeds as follows.",
                "First, the SelectNodes algorithm (which we discuss in the next section) is called and it returns a set of k nodes to crawl next from the set of nodes in the current crawl frontier, Fout.",
                "These selected nodes are then crawled to expand the local subgraph, F , and the PageRanks of this expanded graph are then recomputed.",
                "These steps are repeated for each of T iterations.",
                "Finally, the PageRank vector ˆp, which is restricted to pages within the original local domain, is returned.",
                "Given our computation, bandwidth, and memory restrictions, we will assume that the algorithm will crawl at most O(n) pages.",
                "Since the PageRanks are computed in each iteration of the algorithm, which is an O(n) operation, we will also assume that the number of iterations T is a constant.",
                "Of course, the main challenge here is in selecting which set of k nodes to crawl next.",
                "In the next section, we formally define the problem and give efficient algorithms. 5.",
                "NODE SELECTION In this section, we present node selection algorithms that operate within the greedy framework presented in the previous section.",
                "We first give a well-defined criteria for the page selection problem and provide experimental evidence that this criteria can effectively identify pages that optimize our problem objective (3).",
                "We then present our main al118 Research Track Paper gorithmic contribution of the paper, a method with linear running time that is derived from this page selection criteria.",
                "Finally, we give an intuitive analysis of our algorithm in terms of leaks and flows.",
                "We show that if only the flow is considered, then the resulting method is very similar to a widely used page selection heuristic [6]. 5.1 Formulation For a given page j in the global domain, we define the expanded local graph Fj: Fj = F s uT j 0 , (4) where uj is the zero-one vector containing the outlinks from F into page j, and s contains the inlinks from page j into the local domain.",
                "Note that we do not allow self-links in this framework.",
                "In practice, self-links are often removed, as they only serve to inflate a given pages PageRank.",
                "Observe that the inlinks into F from node j are not known until after node j is crawled.",
                "Therefore, we estimate this inlink vector as the expectation over inlink counts among the set of already crawled pages, s = F T e F T e 1 . (5) In practice, for any given page, this estimate may not reflect the true inlinks from that page.",
                "Furthermore, this expectation is sampled from the set of links within the crawled domain, whereas a better estimate would also use links from the global domain.",
                "However, the latter distribution is not known to a localized search engine, and we contend that the above estimate will, on average, be a better estimate than the uniform distribution, for example.",
                "Let the PageRank of F be f. We express the PageRank f+ j of the expanded local graph Fj as f+ j = (1 − xj)fj xj , (6) where xj is the PageRank of the candidate global node j, and fj is the L1-normalized PageRank vector restricted to the pages in F .",
                "Since directly optimizing our problem goal requires knowing the global PageRank p∗ , we instead propose to crawl those nodes that will have the greatest influence on the PageRanks of pages in the original local domain L: influence(j) = k∈L |fj[k] − f[k]| (7) = EL (fj − f) 1.",
                "Experimentally, the influence score is a very good predictor of our problem objective (3).",
                "For each candidate global node j, figure 1(a) shows the objective function value Global Diff(fj) as a function of the influence of page j.",
                "The local domain used here is a crawl of conservative political pages (we will provide more details about this dataset in section 6); we observed similar results in other domains.",
                "The correlation is quite strong, implying that the influence criteria can effectively identify pages that improve the global PageRank estimate.",
                "As a baseline, figure 1(b) compares our objective with an alternative criteria, outlink count.",
                "The outlink count is defined as the number of outlinks from the local domain to page j.",
                "The correlation here is much weaker. .00001 .0001 .001 .01 0.26 0.262 0.264 0.266 Influence Objective 1 10 100 1000 0.266 0.264 0.262 0.26 Outlink Count Objective (a) (b) Figure 1: (a) The correlation between our influence page selection criteria (7) and the actual objective function (3) value is quite strong. (b) This is in contrast to other criteria, such as outlink count, which exhibit a much weaker correlation. 5.2 Computation As described, for each candidate global page j, the influence score (7) must be computed.",
                "If fj is computed exactly for each global page j, then the PageRank algorithm would need to be run for each of the O(n) such global pages j we consider, resulting in an O(n2 ) computational cost for the node selection method.",
                "Thus, computing the exact value of fj will lead to a quadratic algorithm, and we must instead turn to methods of approximating this vector.",
                "The algorithm we present works by performing one power method iteration used by the PageRank algorithm (Algorithm 1).",
                "The convergence rate for the PageRank algorithm has been shown to equal the random surfer probability α [7, 11].",
                "Given a starting vector x(0) , if k PageRank iterations are performed, the current PageRank solution x(k) satisfies: x(k) − x∗ 1 = O(αk x(0) − x∗ 1), (8) where x∗ is the desired PageRank vector.",
                "Therefore, if only one iteration is performed, choosing a good starting vector is necessary to achieve an accurate approximation.",
                "We partition the PageRank matrix PFj , corresponding to the × subgraph Fj as: PFj = ˜F ˜s ˜uT j w , (9) where ˜F = αF (DF + diag(uj))−1 + (1 − α) e + 1 eT , ˜s = αs + (1 − α) e + 1 , ˜uj = α(DF + diag(uj))−1 uj + (1 − α) e + 1 , w = 1 − α + 1 , and diag(uj) is the diagonal matrix with the (i, i)th entry equal to one if the ith element of uj equals one, and is zero otherwise.",
                "We have assumed here that the random surfer vector is the uniform vector, and that L has no dangling links.",
                "These assumptions are not necessary and serve only to simplify discussion and analysis.",
                "A simple approach for estimating fj is the following.",
                "First, estimate the PageRank f+ j of Fj by computing one PageRank iteration over the matrix PFj , using the starting vector ν = f 0 .",
                "Then, estimate fj by removing the last 119 Research Track Paper component from our estimate of f+ j (i.e., the component corresponding to the added node j), and renormalizing.",
                "The problem with this approach is in the starting vector.",
                "Recall from (6) that xj is the PageRank of the added node j.",
                "The difference between the actual PageRank f+ j of PFj and the starting vector ν is ν − f+ j 1 = xj + f − (1 − xj)fj 1 ≥ xj + | f 1 − (1 − xj) fj 1| = xj + |xj| = 2xj.",
                "Thus, by (8), after one PageRank iteration, we expect our estimate of f+ j to still have an error of about 2αxj.",
                "In particular, for candidate nodes j with relatively high PageRank xj, this method will yield more inaccurate results.",
                "We will next present a method that eliminates this bias and runs in O(n) time. 5.2.1 Stochastic Complementation Since f+ j , as given in (6) is the PageRank of the matrix PFj , we have: fj(1 − xj) xj = ˜F ˜s ˜uT j w fj(1 − xj) xj = ˜F fj(1 − xj) + ˜sxj ˜uT j fj(1 − xj) + wxj .",
                "Solving the above system for fj can be shown to yield fj = ( ˜F + (1 − w)−1 ˜s˜uT j )fj. (10) The matrix S = ˜F +(1−w)−1 ˜s˜uT j is known as the stochastic complement of the column stochastic matrix PFj with respect to the sub matrix ˜F .",
                "The theory of stochastic complementation is well studied, and it can be shown the stochastic complement of an irreducible matrix (such as the PageRank matrix) is unique.",
                "Furthermore, the stochastic complement is also irreducible and therefore has a unique stationary distribution as well.",
                "For an extensive study, see [15].",
                "It can be easily shown that the sub-dominant eigenvalue of S is at most +1 α, where is the size of F .",
                "For sufficiently large , this value will be very close to α.",
                "This is important, as other properties of the PageRank algorithm, notably the algorithms sensitivity, are dependent on this value [11].",
                "In this method, we estimate the length vector fj by computing one PageRank iteration over the × stochastic complement S, starting at the vector f: fj ≈ Sf. (11) This is in contrast to the simple method outlined in the previous section, which first iterates over the ( + 1) × ( + 1) matrix PFj to estimate f+ j , and then removes the last component from the estimate and renormalizes to approximate fj.",
                "The problem with the latter method is in the choice of the ( + 1) length starting vector, ν. Consequently, the PageRank estimate given by the simple method differs from the true PageRank by at least 2αxj, where xj is the PageRank of page j.",
                "By using the stochastic complement, we can establish a tight lower bound of zero for this difference.",
                "To see this, consider the case in which a node k is added to F to form the augmented local subgraph Fk, and that the PageRank of this new graph is (1 − xk)f xk .",
                "Specifically, the addition of page k does not change the PageRanks of the pages in F , and thus fk = f. By construction of the stochastic complement, fk = Sfk, so the approximation given in equation (11) will yield the exact solution.",
                "Next, we present the computational details needed to efficiently compute the quantity fj −f 1 over all known global pages j.",
                "We begin by expanding the difference fj −f, where the vector fj is estimated as in (11), fj − f ≈ Sf − f = αF (DF + diag(uj))−1 f + (1 − α) e + 1 eT f +(1 − w)−1 (˜uT j f)˜s − f. (12) Note that the matrix (DF +diag(uj))−1 is diagonal.",
                "Letting o[k] be the outlink count for page k in F , we can express the kth diagonal element as: (DF + diag(uj))−1 [k, k] = 1 o[k]+1 if uj[k] = 1 1 o[k] if uj[k] = 0 Noting that (o[k] + 1)−1 = o[k]−1 − (o[k](o[k] + 1))−1 and rewriting this in matrix form yields (DF +diag(uj))−1 = D−1 F −D−1 F (DF +diag(uj))−1 diag(uj). (13) We use the same identity to express e + 1 = e − e ( + 1) . (14) Recall that, by definition, we have PF = αF D−1 F +(1−α)e .",
                "Substituting (13) and (14) in (12) yields fj − f ≈ (PF f − f) −αF D−1 F (DF + diag(uj))−1 diag(uj)f −(1 − α) e ( + 1) + (1 − w)−1 (˜uT j f)˜s = x + y + (˜uT j f)z, (15) noting that by definition, f = PF f, and defining the vectors x, y, and z to be x = −αF D−1 F (DF + diag(uj))−1 diag(uj)f (16) y = −(1 − α) e ( + 1) (17) z = (1 − w)−1 ˜s. (18) The first term x is a sparse vector, and takes non-zero values only for local pages k that are siblings of the global page j.",
                "We define (i, j) ∈ F if and only if F [j, i] = 1 (equivalently, page i links to page j) and express the value of the component x[k ] as: x[k ] = −α k:(k,k )∈F ,uj [k]=1 f[k] o[k](o[k] + 1) , (19) where o[k], as before, is the number of outlinks from page k in the local domain.",
                "Note that the last two terms, y and z are not dependent on the current global node j.",
                "Given the function hj(f) = y + (˜uT j f)z 1, the quantity fj − f 1 120 Research Track Paper can be expressed as fj − f 1 = k x[k] + y[k] + (˜uT j f)z[k] = k:x[k]=0 y[k] + (˜uT j f)z[k] + k:x[k]=0 x[k] + y[k] + (˜uT j f)z[k] = hj(f) − k:x[k]=0 y[k] + (˜uT j f)z[k] + k:x[k]=0 x[k] + y[k] + (˜uT j f)z[k] . (20) If we can compute the function hj in linear time, then we can compute each value of fj − f 1 using an additional amount of time that is proportional to the number of nonzero components in x.",
                "These optimizations are carried out in Algorithm 3.",
                "Note that (20) computes the difference between all components of f and fj, whereas our node selection criteria, given in (7), is restricted to the components corresponding to nodes in the original local domain L. Let us examine Algorithm 3 in more detail.",
                "First, the algorithm computes the outlink counts for each page in the local domain.",
                "The algorithm then computes the quantity ˜uT j f for each known global page j.",
                "This inner product can be written as (1 − α) 1 + 1 + α k:(k,j)∈Fout f[k] o[k] + 1 , where the second term sums over the set of local pages that link to page j.",
                "Since the total number of edges in Fout was assumed to have size O( ) (recall that is the number of pages in F ), the running time of this step is also O( ).",
                "The algorithm then computes the vectors y and z, as given in (17) and (18), respectively.",
                "The L1NormDiff method is called on the components of these vectors which correspond to the pages in L, and it estimates the value of EL(y + (˜uT j f)z) 1 for each page j.",
                "The estimation works as follows.",
                "First, the values of ˜uT j f are discretized uniformly into c values {a1, ..., ac}.",
                "The quantity EL(y + aiz) 1 is then computed for each discretized value of ai and stored in a table.",
                "To evaluate EL (y + az) 1 for some a ∈ [a1, ac], the closest discretized value ai is determined, and the corresponding entry in the table is used.",
                "The total running time for this method is linear in and the discretization parameter c (which we take to be a constant).",
                "We note that if exact values are desired, we have also developed an algorithm that runs in O( log ) time that is not described here.",
                "In the main loop, we compute the vector x, as defined in equation (16).",
                "The nested loops iterate over the set of pages in F that are siblings of page j.",
                "Typically, the size of this set is bounded by a constant.",
                "Finally, for each page j, the scores vector is updated over the set of non-zero components k of the vector x with k ∈ L. This set has size equal to the number of local siblings of page j, and is a subset of the total number of siblings of page j.",
                "Thus, each iteration of the main loop takes constant time, and the total running time of the main loop is O( ).",
                "Since we have assumed that the size of F will not grow larger than O(n), the total running time for the algorithm is O(n).",
                "Algorithm 3: Node Selection via Stochastic Complementation.",
                "SC-Select(F , Fout, f, k) Input: F : zero-one adjacency matrix of size corresponding to the current local subgraph, Fout: zero-one outlink matrix from F to global subgraph, f: PageRank of F , k: number of pages to return Output: pages: set of k pages to crawl next {Compute outlink sums for local subgraph} foreach (page j ∈ F ) o[j] ← k:(j,k)∈F F[j, k] end {Compute scalar ˜uT j f for each global node j } foreach (page j ∈ Fout) g[j] ← (1 − α) 1 +1 foreach (page k : (k, j) ∈ Fout) g[j] ← g[j] + α f[k] o[k]+1 end end {Compute vectors y and z as in (17) and (18) } y ← −(1 − α) e ( +1) z ← (1 − w)−1 ˜s {Approximate y + g[j] ∗ z 1 for all values g[j]} norm diffs ←L1NormDiffs(g, ELy, ELz) foreach (page j ∈ Fout) {Compute sparse vector x as in (19)} x ← 0 foreach (page k : (k, j) ∈ Fout) foreach (page k : (k, k ) ∈ F )) x[k ] ← x[k ] − f[k] o[k](o[k]+1) end end x ← αx scores[j] ← norm diffs[j] foreach (k : x[k] > 0 and page k ∈ L) scores[j] ← scores[j] − |y[k] + g[j] ∗ z[k]| +|x[k]+y[k]+g[j]∗z[k])| end end Return k pages with highest scores 5.2.2 PageRank Flows We now present an intuitive analysis of the stochastic complementation method by decomposing the change in PageRank in terms of leaks and flows.",
                "This analysis is motivated by the decomposition given in (15).",
                "PageRank flow is the increase in the local PageRanks originating from global page j.",
                "The flows are represented by the non-negative vector (˜uT j f)z (equations (15) and (18)).",
                "The scalar ˜uT j f can be thought of as the total amount of PageRank flow that page j has available to distribute.",
                "The vector z dictates how the flow is allocated to the local domain; the flow that local page k receives is proportional to (within a constant factor due to the random surfer vector) the expected number of its inlinks.",
                "The PageRank leaks represent the decrease in PageRank resulting from the addition of page j.",
                "The leakage can be quantified in terms of the non-positive vectors x and y (equations (16) and (17)).",
                "For vector x, we can see from equation (19) that the amount of PageRank leaked by a local page is proportional to the weighted sum of the Page121 Research Track Paper Ranks of its siblings.",
                "Thus, pages that have siblings with higher PageRanks (and low outlink counts) will experience more leakage.",
                "The leakage caused by y is an artifact of the random surfer vector.",
                "We will next show that if only the flow term, (˜uT j f)z, is considered, then the resulting method is very similar to a heuristic proposed by Cho et al. [6] that has been widely used for the Crawling Through URL Ordering problem.",
                "This heuristic is computationally cheaper, but as we will see later, not as effective as the Stochastic Complementation method.",
                "Our node selection strategy chooses global nodes that have the largest influence (equation (7)).",
                "If this influence is approximated using only flows, the optimal node j∗ is: j∗ = argmaxj EL ˜uT j fz 1 = argmaxj ˜uT j f EL z 1 = argmaxj ˜uT j f = argmaxj α(DF + diag(uj))−1 uj + (1 − α) e + 1 , f = argmaxjfT (DF + diag(uj))−1 uj.",
                "The resulting page selection score can be expressed as a sum of the PageRanks of each local page k that links to j, where each PageRank value is normalized by o[k]+1.",
                "Interestingly, the normalization that arises in our method differs from the heuristic given in [6], which normalizes by o[k].",
                "The algorithm PF-Select, which is omitted due to lack of space, first computes the quantity fT (DF +diag(uj))−1 uj for each global page j, and then returns the pages with the k largest scores.",
                "To see that the running time for this algorithm is O(n), note that the computation involved in this method is a subset of that needed for the SC-Select method (Algorithm 3), which was shown to have a running time of O(n). 6.",
                "EXPERIMENTS In this section, we provide experimental evidence to verify the effectiveness of our algorithms.",
                "We first outline our experimental methodology and then provide results across a variety of local domains. 6.1 Methodology Given the limited resources available at an academic institution, crawling a section of the web that is of the same magnitude as that indexed by Google or Yahoo! is clearly infeasible.",
                "Thus, for a given local domain, we approximate the global graph by crawling a local neighborhood around the domain that is several orders of magnitude larger than the local subgraph.",
                "Even though such a graph is still orders of magnitude smaller than the true global graph, we contend that, even if there exist some highly influential pages that are very far away from our local domain, it is unrealistic for any local node selection algorithm to find them.",
                "Such pages also tend to be highly unrelated to pages within the local domain.",
                "When explaining our node selection strategies in section 5, we made the simplifying assumption that our local graph contained no dangling nodes.",
                "This assumption was only made to ease our analysis.",
                "Our implementation efficiently handles dangling links by replacing each zero column of our adjacency matrix with the uniform vector.",
                "We evaluate the algorithm using the two node selection strategies given in Section 5.2, and also against the following baseline methods: • Random: Nodes are chosen uniformly at random among the known global nodes. • OutlinkCount: Global nodes with the highest number of outlinks from the local domain are chosen.",
                "At each iteration of the FindGlobalPR algorithm, we evaluate performance by computing the difference between the current PageRank estimate of the local domain, ELf ELf 1 , and the global PageRank of the local domain ELg ELg 1 .",
                "All PageRank calculations were performed using the uniform random surfer vector.",
                "Across all experiments, we set the random surfer parameter α, to be .85, and used a convergence threshold of 10−6 .",
                "We evaluate the difference between the local and global PageRank vectors using three different metrics: the L1 and L∞ norms, and Kendalls tau.",
                "The L1 norm measures the sum of the absolute value of the differences between the two vectors, and the L∞ norm measures the absolute value of the largest difference.",
                "Kendalls tau metric is a popular rank correlation measure used to compare PageRanks [2, 11].",
                "This metric can be computed by counting the number of pairs of pairs that agree in ranking, and subtracting from that the number of pairs of pairs that disagree in ranking.",
                "The final value is then normalized by the total number of n 2 such pairs, resulting in a [−1, 1] range, where a negative score signifies anti-correlation among rankings, and values near one correspond to strong rank correlation. 6.2 Results Our experiments are based on two large web crawls and were downloaded using the web crawler that is part of the Nutch open source search engine project [18].",
                "All crawls were restricted to only http pages, and to limit the number of dynamically generated pages that we crawl, we ignored all pages with urls containing any of the characters ?, *, @, or =.",
                "The first crawl, which we will refer to as the edu dataset, was seeded by homepages of the top 100 graduate computer science departments in the USA, as rated by the US News and World Report [16], and also by the home pages of their respective institutions.",
                "A crawl of depth 5 was performed, restricted to pages within the .edu domain, resulting in a graph with approximately 4.7 million pages and 22.9 million links.",
                "The second crawl was seeded by the set of pages under the politics hierarchy in the dmoz open directory project[17].",
                "We crawled all pages up to four links away, which yielded a graph with 4.4 million pages and 17.3 million links.",
                "Within the edu crawl, we identified the five site-specific domains corresponding to the websites of the top five graduate computer science departments, as ranked by the US News and World Report.",
                "This yielded local domains of various sizes, from 10,626 (UIUC) to 59,895 (Berkeley).",
                "For each of these site-specific domains with size n, we performed 50 iterations of the FindGlobalPR algorithm to crawl a total of 2n additional nodes.",
                "Figure 2(a) gives the (L1) difference from the PageRank estimate at each iteration to the global PageRank, for the Berkeley local domain.",
                "The performance of this dataset was representative of the typical performance across the five computer science sitespecific local domains.",
                "Initially, the L1 difference between the global and local PageRanks ranged from .0469 (Stanford) to .149 (MIT).",
                "For the first several iterations, the 122 Research Track Paper 0 5 10 15 20 25 30 35 40 45 50 0.015 0.02 0.025 0.03 0.035 0.04 0.045 0.05 0.055 Number of Iterations GlobalandLocalPageRankDifference(L1) Stochastic Complement PageRank Flow Outlink Count Random 0 10 20 30 40 50 0 0.05 0.1 0.15 0.2 0.25 0.3 0.35 Number of Iterations GlobalandLocalPageRankDifference(L1) Stochastic Complement PageRank Flow Outlink Count Random 0 5 10 15 20 25 0.16 0.18 0.2 0.22 0.24 0.26 0.28 0.3 0.32 0.34 Number of Iterations GlobalandLocalPageRankDifference(L1) Stochastic Complement PageRank Flow Outlink Count Random (a) www.cs.berkeley.edu (b) www.enterstageright.com (c) Politics Figure 2: L1 difference between the estimated and true global PageRanks for (a) Berkeleys computer science website, (b) the site-specific domain, www.enterstageright.com, and (c) the politics topic-specific domain.",
                "The stochastic complement method outperforms all other methods across various domains. three link-based methods all outperform the random selection heuristic.",
                "After these initial iterations, the random heuristic tended to be more competitive with (or even outperform, as in the Berkeley local domain) the outlink count and PageRank flow heuristics.",
                "In all tests, the stochastic complementation method either outperformed, or was competitive with, the other methods.",
                "Table 1 gives the average difference between the final estimated global PageRanks and the true global PageRanks for various distance measures.",
                "Algorithm L1 L∞ Kendall Stoch.",
                "Comp. .0384 .00154 .9257 PR Flow .0470 .00272 .8946 Outlink .0419 .00196 .9053 Random .0407 .00204 .9086 Table 1: Average final performance of various node selection strategies for the five site-specific computer science local domains.",
                "Note that Kendalls Tau measures similarity, while the other metrics are dissimilarity measures.",
                "Stochastic Complementation clearly outperforms the other methods in all metrics.",
                "Within the politics dataset, we also performed two sitespecific tests for the largest websites in the crawl: www.adamsmith.org, the website for the London based Adam Smith Institute, and www.enterstageright.com, an online conservative journal.",
                "As with the edu local domains, we ran our algorithm for 50 iterations, crawling a total of 2n nodes.",
                "Figure 2 (b) plots the results for the www.enterstageright.com domain.",
                "In contrast to the edu local domains, the Random and OutlinkCount methods were not competitive with either the SC-Select or the PF-Select methods.",
                "Among all datasets and all node selection methods, the stochastic complementation method was most impressive in this dataset, realizing a final estimate that differed only .0279 from the global PageRank, a ten-fold improvement over the initial local PageRank difference of .299.",
                "For the Adam Smith local domain, the initial difference between the local and global PageRanks was .148, and the final estimates given by the SC-Select, PF-Select, OutlinkCount, and Random methods were .0208, .0193, .0222, and .0356, respectively.",
                "Within the politics dataset, we constructed four topicspecific local domains.",
                "The first domain consisted of all pages in the dmoz politics category, and also all pages within each of these sites up to two links away.",
                "This yielded a local domain of 90,811 pages, and the results are given in figure 2 (c).",
                "Because of the larger size of the topic-specific domains, we ran our algorithm for only 25 iterations to crawl a total of n nodes.",
                "We also created topic-specific domains from three political sub-topics: liberalism, conservatism, and socialism.",
                "The pages in these domains were identified by their corresponding dmoz categories.",
                "For each sub-topic, we set the local domain to be all pages within three links from the corresponding dmoz category pages.",
                "Table 2 summarizes the performance of these three topic-specific domains, and also the larger political domain.",
                "To quantify a global page js effect on the global PageRank values of pages in the local domain, we define page js impact to be its PageRank value, g[j], normalized by the fraction of its outlinks pointing to the local domain: impact(j) = oL[j] o[j] · g[j], where, oL[j] is the number of outlinks from page j to pages in the local domain L, and o[j] is the total number of js outlinks.",
                "In terms of the random surfer model, the impact of page j is the probability that the random surfer (1) is currently at global page j in her random walk and (2) takes an outlink to a local page, given that she has already decided not to jump to a random page.",
                "For the politics local domain, we found that many of the pages with high impact were in fact political pages that should have been included in the dmoz politics topic, but were not.",
                "For example, the two most influential global pages were the political search engine www.askhenry.com, and the home page of the online political magazine, www.policyreview.com.",
                "Among non-political pages, the home page of the journal Education Next was most influential.",
                "The journal is freely available online and contains articles regarding various aspect of K-12 education in America.",
                "To provide some anecdotal evidence for the effectiveness of our page selection methods, we note that the SC-Select method chose 11 pages within the www.educationnext.org domain, the PF-Select method discovered 7 such pages, while the OutlinkCount and Random methods found only 6 pages each.",
                "For the conservative political local domain, the socialist website www.ornery.org had a very high impact score.",
                "This 123 Research Track Paper All Politics: Algorithm L1 L2 Kendall Stoch.",
                "Comp. .1253 .000700 .8671 PR Flow .1446 .000710 .8518 Outlink .1470 .00225 .8642 Random .2055 .00203 .8271 Conservativism: Algorithm L1 L2 Kendall Stoch.",
                "Comp. .0496 .000990 .9158 PR Flow .0554 .000939 .9028 Outlink .0602 .00527 .9144 Random .1197 .00102 .8843 Liberalism: Algorithm L1 L2 Kendall Stoch.",
                "Comp. .0622 .001360 .8848 PR Flow .0799 .001378 .8669 Outlink .0763 .001379 .8844 Random .1127 .001899 .8372 Socialism: Algorithm L1 L∞ Kendall Stoch.",
                "Comp. .04318 .00439 .9604 PR Flow .0450 .004251 .9559 Outlink .04282 .00344 .9591 Random .0631 .005123 .9350 Table 2: Final performance among node selection strategies for the four political topic-specific crawls.",
                "Note that Kendalls Tau measures similarity, while the other metrics are dissimilarity measures. was largely due to a link from the front page of this site to an article regarding global warming published by the National Center for Public Policy Research, a conservative research group in Washington, DC.",
                "Not surprisingly, the global PageRank of this article (which happens to be on the home page of the NCCPR, www.nationalresearch.com), was approximately .002, whereas the local PageRank of this page was only .00158.",
                "The SC-Select method yielded a global PageRank estimate of approximately .00182, the PFSelect method estimated a value of .00167, and the Random and OutlinkCount methods yielded values of .01522 and .00171, respectively. 7.",
                "RELATED WORK The node selection framework we have proposed is similar to the url ordering for crawling problem proposed by Cho et al. in [6].",
                "Whereas our framework seeks to minimize the difference between the global and local PageRank, the objective used in [6] is to crawl the most highly (globally) ranked pages first.",
                "They propose several node selection algorithms, including the outlink count heuristic, as well as a variant of our PF-Select algorithm which they refer to as the PageRank ordering metric.",
                "They found this method to be most effective in optimizing their objective, as did a recent survey of these methods by Baeza-Yates et al. [1].",
                "Boldi et al. also experiment within a similar crawling framework in [2], but quantify their results by comparing Kendalls rank correlation between the PageRanks of the current set of crawled pages and those of the entire global graph.",
                "They found that node selection strategies that crawled pages with the highest global PageRank first actually performed worse (with respect to Kendalls Tau correlation between the local and global PageRanks) than basic depth first or breadth first strategies.",
                "However, their experiments differ from our work in that our node selection algorithms do not use (or have access to) global PageRank values.",
                "Many algorithmic improvements for computing exact PageRank values have been proposed [9, 10, 14].",
                "If such algorithms are used to compute the global PageRanks of our local domain, they would all require O(N) computation, storage, and bandwidth, where N is the size of the global domain.",
                "This is in contrast to our method, which approximates the global PageRank and scales linearly with the size of the local domain.",
                "Wang and Dewitt [22] propose a system where the set of web servers that comprise the global domain communicate with each other to compute their respective global PageRanks.",
                "For a given web server hosting n pages, the computational, bandwidth, and storage requirements are also linear in n. One drawback of this system is that the number of distinct web servers that comprise the global domain can be very large.",
                "For example, our edu dataset contains websites from over 3,200 different universities; coordinating such a system among a large number of sites can be very difficult.",
                "Gan, Chen, and Suel propose a method for estimating the PageRank of a single page [5] which uses only constant bandwidth, computation, and space.",
                "Their approach relies on the availability of a remote connectivity server that can supply the set of inlinks to a given page, an assumption not used in our framework.",
                "They experimentally show that a reasonable estimate of the nodes PageRank can be obtained by visiting at most a few hundred nodes.",
                "Using their algorithm for our problem would require that either the entire global domain first be downloaded or a connectivity server be used, both of which would lead to very large web graphs. 8.",
                "CONCLUSIONS AND FUTURE WORK The internet is growing exponentially, and in order to navigate such a large repository as the web, global search engines have established themselves as a necessity.",
                "Along with the ubiquity of these large-scale search engines comes an increase in search users expectations.",
                "By providing complete and isolated coverage of a particular web domain, localized search engines are an effective outlet to quickly locate content that could otherwise be difficult to find.",
                "In this work, we contend that the use of global PageRank in a localized search engine can improve performance.",
                "To estimate the global PageRank, we have proposed an iterative node selection framework where we select which pages from the global frontier to crawl next.",
                "Our primary contribution is our stochastic complementation page selection algorithm.",
                "This method crawls nodes that will most significantly impact the local domain and has running time linear in the number of nodes in the local domain.",
                "Experimentally, we validate these methods across a diverse set of local domains, including seven site-specific domains and four topic-specific domains.",
                "We conclude that by crawling an additional n or 2n pages, our methods find an estimate of the global PageRanks that is up to ten times better than just using the local PageRanks.",
                "Furthermore, we demonstrate that our algorithm consistently outperforms other existing heuristics. 124 Research Track Paper Often times, topic-specific domains are discovered using a focused web crawler which considers a pages content in conjunction with link anchor text to decide which pages to crawl next [4].",
                "Although such crawlers have proven to be quite effective in discovering topic-related content, many irrelevant pages are also crawled in the process.",
                "Typically, these pages are deleted and not indexed by the localized search engine.",
                "These pages can of course provide valuable information regarding the global PageRank of the local domain.",
                "One way to integrate these pages into our framework is to start the FindGlobalPR algorithm with the current subgraph F equal to the set of pages that were crawled by the focused crawler.",
                "The global PageRank estimation framework, along with the node selection algorithms presented, all require O(n) computation per iteration and bandwidth proportional to the number of pages crawled, Tk.",
                "If the number of iterations T is relatively small compared to the number of pages crawled per iteration, k, then the bottleneck of the algorithm will be the crawling phase.",
                "However, as the number of iterations increases (relative to k), the bottleneck will reside in the node selection computation.",
                "In this case, our algorithms would benefit from constant factor optimizations.",
                "Recall that the FindGlobalPR algorithm (Algorithm 2) requires that the PageRanks of the current expanded local domain be recomputed in each iteration.",
                "Recent work by Langville and Meyer [12] gives an algorithm to quickly recompute PageRanks of a given webgraph if a small number of nodes are added.",
                "This algorithm was shown to give speedup of five to ten times on some datasets.",
                "We plan to investigate this and other such optimizations as future work.",
                "In this paper, we have objectively evaluated our methods by measuring how close our global PageRank estimates are to the actual global PageRanks.",
                "To determine the benefit of using global PageRanks in a localized search engine, we suggest a user study in which users are asked to rate the quality of search results for various search queries.",
                "For some queries, only the local PageRanks are used in ranking, and for the remaining queries, local PageRanks and the approximate global PageRanks, as computed by our algorithms, are used.",
                "The results of such a study can then be analyzed to determine the added benefit of using the global PageRanks computed by our methods, over just using the local PageRanks.",
                "Acknowledgements.",
                "This research was supported by NSF grant CCF-0431257, NSF Career Award ACI-0093404, and a grant from Sabre, Inc. 9.",
                "REFERENCES [1] R. Baeza-Yates, M. Marin, C. Castillo, and A. Rodriguez.",
                "Crawling a country: better strategies than breadth-first for web page ordering.",
                "World-Wide Web Conference, 2005. [2] P. Boldi, M. Santini, and S. Vigna.",
                "Do your worst to make the best: paradoxical effects in pagerank incremental computations.",
                "Workshop on Web Graphs, 3243:168-180, 2004. [3] S. Brin and L. Page.",
                "The anatomy of a large-scale hypertextual web search engine.",
                "Computer Networks and ISDN Systems, 33(1-7):107-117, 1998. [4] S. Chakrabarti, M. van den Berg, and B. Dom.",
                "Focused crawling: a new approach to topic-specific web resource discovery.",
                "World-Wide Web Conference, 1999. [5] Y. Chen, Q. Gan, and T. Suel.",
                "Local methods for estimating pagerank values.",
                "Conference on Information and Knowledge Management, 2004. [6] J. Cho, H. Garcia-Molina, and L. Page.",
                "Efficient crawling through url ordering.",
                "World-Wide Web Conference, 1998. [7] T. H. Haveliwala and S. D. Kamvar.",
                "The second eigenvalue of the Google matrix.",
                "Technical report, Stanford University, 2003. [8] T. Joachims, F. Radlinski, L. Granka, A. Cheng, C. Tillekeratne, and A. Patel.",
                "Learning retrieval functions from implicit feedback. http://www.cs.cornell.edu/People/tj/career. [9] S. D. Kamvar, T. H. Haveliwala, C. D. Manning, and G. H. Golub.",
                "Exploiting the block structure of the web for computing pagerank.",
                "World-Wide Web Conference, 2003. [10] S. D. Kamvar, T. H. Haveliwala, C. D. Manning, and G. H. Golub.",
                "Extrapolation methods for accelerating pagerank computation.",
                "World-Wide Web Conference, 2003. [11] A. N. Langville and C. D. Meyer.",
                "Deeper inside pagerank.",
                "Internet Mathematics, 2004. [12] A. N. Langville and C. D. Meyer.",
                "Updating the stationary vector of an irreducible markov chain with an eye on Googles pagerank.",
                "SIAM Journal on Matrix Analysis, 2005. [13] P. Lyman, H. R. Varian, K. Swearingen, P. Charles, N. Good, L. L. Jordan, and J. Pal.",
                "How much information 2003?",
                "School of Information Management and System, University of California at Berkely, 2003. [14] F. McSherry.",
                "A uniform approach to accelerated pagerank computation.",
                "World-Wide Web Conference, 2005. [15] C. D. Meyer.",
                "Stochastic complementation, uncoupling markov chains, and the theory of nearly reducible systems.",
                "SIAM Review, 31:240-272, 1989. [16] US News and World Report. http://www.usnews.com. [17] Dmoz open directory project. http://www.dmoz.org. [18] Nutch open source search engine. http://www.nutch.org. [19] F. Radlinski and T. Joachims.",
                "Query chains: learning to rank from implicit feedback.",
                "ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, 2005. [20] S. Raghavan and H. Garcia-Molina.",
                "Crawling the hidden web.",
                "In Proceedings of the Twenty-seventh International Conference on Very Large Databases, 2001. [21] T. Tin Tang, D. Hawking, N. Craswell, and K. Griffiths.",
                "Focused crawling for both topical relevance and quality of medical information.",
                "Conference on Information and Knowledge Management, 2005. [22] Y. Wang and D. J. DeWitt.",
                "Computing pagerank in a distributed internet search system.",
                "Proceedings of the 30th VLDB Conference, 2004. 125 Research Track Paper"
            ],
            "original_annotated_samples": [
                "One drawback of localized indexes is the lack of global information needed to compute <br>link-based ranking</br>s."
            ],
            "translated_annotated_samples": [
                "Una desventaja de los índices localizados es la falta de información global necesaria para calcular <br>clasificaciones basadas en enlaces</br>."
            ],
            "translated_text": "Estimando el PageRank Global de Comunidades Web Jason V. Davis Dept. Departamento de Ciencias de la Computación Universidad de Texas en Austin Austin, TX 78712 jdavis@cs.utexas.edu Inderjit S. Dhillon Departamento de Ciencias de la Computación Universidad de Texas en Austin Austin, TX 78712 inderjit@cs.utexas.edu RESUMEN Los motores de búsqueda localizados son sistemas a pequeña escala que indexan una comunidad particular en la web. Ofrecen varios beneficios en comparación con sus contrapartes a gran escala, ya que son relativamente económicos de construir y pueden proporcionar una capacidad de búsqueda más precisa y completa en sus dominios relevantes. Una desventaja que tienen estos sistemas en comparación con los motores de búsqueda a gran escala es la falta de valores globales de PageRank. Se necesita esa información para evaluar el valor de las páginas en el dominio de búsqueda localizada dentro del contexto de la web en su totalidad. En este artículo, presentamos algoritmos bien fundamentados para estimar los valores globales de PageRank de un dominio local. Los algoritmos son altamente escalables en el sentido de que, dado un dominio local de tamaño n, utilizan recursos de O(n) que incluyen tiempo de computación, ancho de banda y almacenamiento. Probamos nuestros métodos en una variedad de dominios localizados, incluyendo dominios específicos del sitio y dominios específicos del tema. Demostramos que al rastrear tan solo n o 2n páginas adicionales, nuestros métodos pueden proporcionar excelentes estimaciones globales de PageRank. Categorías y Descriptores de Asignaturas H.3.3 [Almacenamiento y Recuperación de Información]: Búsqueda y Recuperación de Información; G.1.3 [Análisis Numérico]: Álgebra Lineal Numérica; G.3 [Probabilidad y Estadística]: Procesos de Markov Términos Generales PageRank, Cadena de Markov, Complementación Estocástica. Los motores de búsqueda localizados son motores de búsqueda a pequeña escala que indexan solo una comunidad específica de la web. Tales comunidades pueden ser dominios específicos del sitio, como páginas dentro del dominio cs.utexas.edu, o comunidades relacionadas con un tema, por ejemplo, sitios web políticos. En comparación con el grafo web rastreado e indexado por los motores de búsqueda a gran escala, el tamaño de estas comunidades locales suele ser típicamente órdenes de magnitud más pequeño. Por consiguiente, los recursos computacionales necesarios para construir un motor de búsqueda de este tipo también son igualmente más ligeros. Al restringirse a secciones más pequeñas y manejables de la web, los motores de búsqueda localizados también pueden ofrecer capacidades de búsqueda más precisas y completas dentro de sus respectivos dominios. Una desventaja de los índices localizados es la falta de información global necesaria para calcular <br>clasificaciones basadas en enlaces</br>. El algoritmo PageRank [3] ha demostrado ser una medida efectiva de este tipo. En general, el PageRank de una página dada depende de las páginas en todo el grafo web. En el contexto de un motor de búsqueda localizado, si los PageRanks se calculan utilizando solo el subgrafo local, entonces esperaríamos que los PageRanks resultantes reflejen la popularidad percibida dentro de la comunidad local y no de la web en su totalidad. Por ejemplo, consideremos un motor de búsqueda localizado que indexa páginas políticas con puntos de vista conservadores. Una persona que desee investigar las opiniones sobre el calentamiento global dentro de la comunidad política conservadora puede encontrarse con numerosas opiniones de este tipo en varios sitios web. Si solo se dispone de valores de PageRank locales, entonces los resultados de búsqueda reflejarán solo creencias fuertemente arraigadas dentro de la comunidad. Sin embargo, si los PageRanks globales también están disponibles, entonces los resultados pueden reflejar adicionalmente las opiniones de los externos sobre la comunidad conservadora (es decir, aquellos documentos a los que los liberales acceden con mayor frecuencia dentro de la comunidad conservadora). Por lo tanto, para muchos motores de búsqueda localizados, la incorporación de PageRanks globales puede mejorar la calidad de los resultados de búsqueda. Sin embargo, el número de páginas que indexa un motor de búsqueda local suele ser órdenes de magnitud más pequeño que el número de páginas indexadas por sus contrapartes a gran escala. Los motores de búsqueda localizados no tienen el ancho de banda, la capacidad de almacenamiento o la potencia computacional para rastrear, descargar y calcular los PageRanks globales de toda la web. En este trabajo, presentamos un método para aproximar los PageRanks globales de un dominio local utilizando recursos del mismo orden que los necesarios para calcular los PageRanks del subgrafo local. Nuestro método propuesto busca un supergrafo de nuestro subgrafo local de manera que los PageRanks locales dentro de este supergrafo estén cerca de los verdaderos PageRanks globales. Construimos este supergrafo mediante el rastreo iterativo de páginas globales en la frontera web actual, es decir, páginas globales con enlaces entrantes de páginas que ya han sido rastreadas. Para proporcionar a 116 Research Track Paper una buena aproximación a los PageRanks globales, es necesario tener cuidado al elegir qué páginas rastrear a continuación; en este documento, presentamos un algoritmo de selección de páginas bien fundamentado que también tiene un buen rendimiento empírico. Este algoritmo se deriva de un objetivo de problema bien definido y tiene un tiempo de ejecución lineal en el número de nodos locales. Experimentamos en varios tipos de subgrafos locales, incluidas cuatro comunidades relacionadas con el tema y varios dominios específicos del sitio. Para evaluar el rendimiento, medimos la diferencia entre la estimación actual del PageRank global y el PageRank global, en función del número de páginas rastreadas. Comparamos nuestro algoritmo con varios heurísticos y también con un algoritmo base que elige páginas al azar, y demostramos que nuestro método supera a estos otros métodos. Finalmente, demostramos empíricamente que, dado un dominio local de tamaño n, podemos proporcionar buenas aproximaciones a los valores globales de PageRank rastreando como máximo n o 2n páginas adicionales. El documento está organizado de la siguiente manera. La sección 2 ofrece una visión general de los motores de búsqueda localizados y destaca sus ventajas sobre los motores de búsqueda globales. La sección 3 proporciona antecedentes sobre el algoritmo PageRank. La sección 4 define formalmente nuestro problema, y la sección 5 presenta nuestros criterios de selección de páginas y deriva nuestros algoritmos. La sección 6 presenta los resultados experimentales, la sección 7 ofrece una visión general del trabajo relacionado y, finalmente, las conclusiones se presentan en la sección 8. MOTORES DE BÚSQUEDA LOCALIZADOS Los motores de búsqueda localizados indexan una sola comunidad de la web, típicamente una comunidad específica del sitio o una comunidad específica del tema. Los motores de búsqueda localizados disfrutan de tres ventajas principales sobre sus contrapartes a gran escala: son relativamente económicos de construir, pueden ofrecer una capacidad de búsqueda más precisa dentro de su dominio local y pueden proporcionar un índice más completo. Los recursos necesarios para construir un motor de búsqueda global son enormes. Un estudio de 2003 realizado por Lyman et al. [13] encontró que la web superficial (sitios estáticos de acceso público) consta de 8.9 mil millones de páginas, y que el tamaño promedio de estas páginas es de aproximadamente 18.7 kilobytes. Para descargar un rastreo de este tamaño, se necesita aproximadamente 167 terabytes de espacio. Para un investigador que desee construir un motor de búsqueda con acceso a un par de estaciones de trabajo o un servidor pequeño, un almacenamiento de esta magnitud simplemente no está disponible. Sin embargo, construir un motor de búsqueda localizado sobre una comunidad web de cien mil páginas solo requeriría unos pocos gigabytes de almacenamiento. La carga computacional necesaria para soportar consultas de búsqueda sobre una base de datos de este tamaño es más manejable también. Observamos que, para los motores de búsqueda específicos de un tema, la comunidad relevante puede ser identificada y descargada de manera eficiente utilizando un rastreador enfocado [21, 4]. Para dominios específicos del sitio, el dominio local está fácilmente disponible en su propio servidor web. Esto evita la necesidad de rastreo o indexación, y por lo tanto se puede garantizar un índice completo y actualizado del dominio. Esto contrasta con sus contrapartes a gran escala, las cuales sufren de varias deficiencias. Primero, el rastreo de páginas generadas dinámicamente en la web oculta ha sido objeto de investigación [20] y es una tarea no trivial para un rastreador externo. En segundo lugar, los dominios específicos del sitio pueden habilitar la política de exclusión de robots. Esto prohíbe a los rastreadores de motores de búsqueda externos descargar contenido del dominio, y en su lugar un motor de búsqueda externo debe depender de enlaces externos y texto ancla para indexar estas páginas restringidas. Al restringirse a un dominio específico de internet, un motor de búsqueda localizado puede proporcionar resultados de búsqueda más precisos. Considera la consulta de búsqueda ambigua canónica, jaguar, que puede referirse tanto al fabricante de automóviles como al animal. Un científico que intenta investigar el hábitat y la historia evolutiva de un jaguar puede tener más éxito utilizando un motor de búsqueda específico de zoología bien ajustado que consultando Google con múltiples búsquedas de palabras clave y navegando a través de resultados irrelevantes. Recientemente se propuso un método para aprender funciones de clasificación mejores para la recuperación por Radlinski y Joachims [19] y se ha aplicado a varios dominios locales, incluido el sitio web de la Universidad de Cornell [8]. 3. PAGERANK RESUMEN El algoritmo PageRank define la importancia de las páginas web analizando la estructura de hipervínculos subyacente de un grafo web. El algoritmo funciona construyendo una cadena de Markov a partir de la estructura de enlaces del grafo web y calculando su distribución estacionaria. Una forma de calcular la distribución estacionaria de una cadena de Markov es encontrar la distribución límite de un paseo aleatorio sobre la cadena. Por lo tanto, el algoritmo PageRank utiliza lo que a veces se conoce como el modelo del surfista aleatorio. En cada paso de la caminata aleatoria, el surfista sigue un enlace de salida de la página actual (es decir, el nodo actual en la cadena), o salta a una página aleatoria en la web. Ahora definimos con precisión el problema de PageRank. Sea U una matriz de adyacencia m × m para un grafo web dado tal que Uji = 1 si la página i enlaza a la página j y Uji = 0 en caso contrario. Definimos la matriz de PageRank PU como: PU = αUD−1 U + (1 − α)veT , (1) donde DU es la matriz diagonal (única) tal que UD−1 U es estocástica por columnas, α es un escalar dado tal que 0 ≤ α ≤ 1, e es el vector de todos unos, y v es un vector no negativo, L1-normalizado, a veces llamado vector de navegante aleatorio. Ten en cuenta que la matriz D−1 U está bien definida solo si cada columna de U tiene al menos una entrada distinta de cero, es decir, cada página en el grafo web tiene al menos un enlace de salida. En presencia de nodos colgantes que no tienen enlaces de salida, una solución comúnmente utilizada, propuesta por Brin et al. [3], es reemplazar cada columna de ceros de U por un vector no negativo, normalizado en L1. El vector PageRank r es el eigenvector dominante de la matriz PageRank, r = PU r. Supondremos, sin pérdida de generalidad, que r tiene una norma L1 de uno. Computacionalmente, r se puede calcular utilizando el método de la potencia. Este método primero elige un vector inicial aleatorio r(0) y, de forma iterativa, multiplica el vector actual por la matriz de PageRank PU; ver Algoritmo 1. En general, cada iteración del método de la potencia puede requerir O(m2) operaciones cuando PU es una matriz densa. Sin embargo, en la práctica, el número de enlaces en un grafo web será del orden del número de páginas. Al explotar la dispersión de la matriz de PageRank, el trabajo por iteración se puede reducir a O(km), donde k es el número promedio de enlaces por página web. También se ha demostrado que el número total de iteraciones necesarias para la convergencia es proporcional a α y no depende del tamaño del grafo web [11, 7]. Finalmente, el espacio total necesario también es O(km), principalmente para almacenar la matriz U. 117 Research Track Paper Algorithm 1: Un algoritmo de tiempo lineal (por iteración) para calcular PageRank. CalcularPR(U) Entrada: U: Matriz de adyacencia. Salida: vector de PageRank. Elige (aleatoriamente) un vector inicial no negativo r(0) tal que r(0) 1 = 1. i ← 0 repetir i ← i + 1 ν ← αUD−1 U r(i−1) {α es la probabilidad de navegación aleatoria} r(i) ← ν + (1 − α)v {v es el vector del navegante aleatorio.} hasta que r(i) − r(i−1) < δ {δ es el umbral de convergencia.} r ← r(i) 4. Dada un dominio local L, sea G una matriz de adyacencia N × N para el componente conectado completo de la web que contiene L, tal que Gji = 1 si la página i enlaza a la página j y Gji = 0 en caso contrario. Sin pérdida de generalidad, vamos a dividir G de la siguiente manera: G = L Gout Lout Gwithin, donde L es el subgrafo local de n × n correspondiente a los enlaces dentro del dominio local, Lout es el subgrafo que corresponde a los enlaces desde el dominio local apuntando hacia el dominio global, Gout es el subgrafo que contiene los enlaces desde el dominio global hacia el dominio local, y Gwithin contiene los enlaces dentro del dominio global. Suponemos que al construir un motor de búsqueda localizado, solo se rastrean las páginas dentro del dominio local, y los enlaces entre estas páginas están representados por el subgrafo L. También se conocen los enlaces en Lout, ya que estos apuntan desde las páginas rastreadas en el dominio local a las páginas no rastreadas en el dominio global. Como se define en la ecuación (1), PG es la matriz de PageRank formada a partir del grafo global G, y definimos el vector de PageRank global de este grafo como g. Sea el vector de longitud n p∗ el vector L1-normalizado que corresponde al PageRank global de las páginas en el dominio local L: p∗ = EL g ELg 1 , donde EL = [ I | 0 ] es la matriz de restricción que selecciona los componentes de g correspondientes a los nodos en L. Sea p el vector de PageRank construido a partir del subgrafo del dominio local L. En la práctica, el PageRank local observado p y el PageRank global p∗ serán bastante diferentes. Se esperaría que a medida que el tamaño de la matriz local L se acerque al tamaño de la matriz global G, el PageRank global y el PageRank local observado se vuelvan más similares. Por lo tanto, un enfoque para estimar el PageRank global es rastrear todo el dominio global, calcular su PageRank y extraer los PageRanks del dominio local. Por lo general, sin embargo, n N, es decir, el número de páginas globales es mucho mayor que el número de páginas locales. Por lo tanto, rastrear todas las páginas globales agotará rápidamente todos los recursos locales (computacionales, de almacenamiento y de ancho de banda) disponibles para crear el motor de búsqueda local. En cambio, buscamos un supergrafo ˆF de nuestro subgrafo local L con tamaño O(n). Nuestro objetivo es el Algoritmo 2: El algoritmo FindGlobalPR. EncuentraGlobalPR(L, Lout, T, k) Entrada: L: matriz de adyacencia de ceros y unos para el dominio local, Lout: matriz de enlaces de ceros y unos desde L al subgrafo global como en (2), T: número de iteraciones, k: número de páginas a rastrear por iteración. Salida: ˆp: una estimación mejorada del PageRank global de L. F ← L Fout ← Lout f ← CalcularPR(F) para (i = 1 a T) {Determinar qué páginas rastrear a continuación} páginas ← SeleccionarNodos(F, Fout, f, k) Rastrear páginas, aumentar F y modificar Fout {Actualizar PageRanks para el nuevo dominio local} f ← CalcularPR(F) fin {Extraer PageRanks del dominio local original y normalizar} ˆp ← ELf ELf 1 es encontrar un supergrafo ˆF con PageRank ˆf, de modo que ˆf cuando se restringe a L esté cerca de p∗. Formalmente, buscamos minimizar GlobalDiff( ˆf) = EL ˆf EL ˆf 1 − p∗ 1 . (3) Elegimos la norma L1 para medir el error ya que no otorga un peso excesivo a los valores atípicos (como lo hace la norma L2, por ejemplo), y también porque es la medida de distancia más comúnmente utilizada en la literatura para comparar vectores de PageRank, así como para detectar la convergencia del algoritmo [3]. Proponemos un marco codicioso, presentado en el Algoritmo 2, para construir ˆF. Inicialmente, F se establece en el subgrafo local L, y se calcula el PageRank f de este grafo. El algoritmo luego procede de la siguiente manera. Primero, se llama al algoritmo SelectNodes (que discutimos en la siguiente sección) y devuelve un conjunto de k nodos para rastrear a continuación del conjunto de nodos en la frontera de rastreo actual, Fout. Estos nodos seleccionados son luego rastreados para expandir el subgrafo local, F, y los PageRanks de este grafo expandido son luego recalculados. Estos pasos se repiten para cada una de las T iteraciones. Finalmente, se devuelve el vector PageRank ˆp, el cual está restringido a las páginas dentro del dominio local original. Dadas nuestras restricciones de computación, ancho de banda y memoria, asumiremos que el algoritmo rastreará como máximo O(n) páginas. Dado que los PageRanks se calculan en cada iteración del algoritmo, lo cual es una operación O(n), también asumiremos que el número de iteraciones T es una constante. Por supuesto, el principal desafío aquí radica en seleccionar qué conjunto de k nodos rastrear a continuación. En la siguiente sección, definimos formalmente el problema y presentamos algoritmos eficientes. 5. SELECCIÓN DE NODO En esta sección, presentamos algoritmos de selección de nodo que operan dentro del marco codicioso presentado en la sección anterior. Primero damos un criterio bien definido para el problema de selección de páginas y proporcionamos evidencia experimental de que este criterio puede identificar de manera efectiva las páginas que optimizan nuestro objetivo del problema (3). A continuación, presentamos nuestra principal contribución algorítmica del artículo de investigación al118, un método con tiempo de ejecución lineal que se deriva de los criterios de selección de esta página. Finalmente, ofrecemos un análisis intuitivo de nuestro algoritmo en términos de fugas y flujos. Mostramos que si solo se considera el flujo, entonces el método resultante es muy similar a una heurística de selección de páginas ampliamente utilizada [6]. 5.1 Formulación Para una página dada j en el dominio global, definimos el grafo local expandido Fj: Fj = F s uT j 0, (4) donde uj es el vector de ceros y unos que contiene los enlaces de salida de F hacia la página j, y s contiene los enlaces de entrada de la página j en el dominio local. Ten en cuenta que no permitimos enlaces a uno mismo en este marco de trabajo. En la práctica, los enlaces internos suelen ser eliminados, ya que solo sirven para inflar el PageRank de una página determinada. Observa que los enlaces entrantes a F desde el nodo j no se conocen hasta después de que el nodo j sea rastreado. Por lo tanto, estimamos este vector de inlink como la expectativa sobre el recuento de inlinks entre el conjunto de páginas ya rastreadas, s = F T e F T e 1. En la práctica, para cualquier página dada, esta estimación puede no reflejar los verdaderos inlinks de esa página. Además, esta expectativa se extrae del conjunto de enlaces dentro del dominio rastreado, mientras que una estimación más precisa también utilizaría enlaces del dominio global. Sin embargo, la distribución mencionada no es conocida por un motor de búsqueda localizado, y sostenemos que la estimación anterior, en promedio, será una estimación mejor que la distribución uniforme, por ejemplo. Dejemos que el PageRank de F sea f. Expresamos el PageRank f+ j del grafo local expandido Fj como f+ j = (1 − xj)fj xj , donde xj es el PageRank del nodo global candidato j, y fj es el vector de PageRank L1-normalizado restringido a las páginas en F. Dado que optimizar directamente nuestro objetivo requiere conocer el PageRank global p∗, proponemos en su lugar rastrear aquellos nodos que tendrán la mayor influencia en los PageRanks de las páginas en el dominio local original L: influencia(j) = k∈L |fj[k] − f[k]| (7) = EL (fj − f) 1. Experimentalmente, el puntaje de influencia es un predictor muy bueno de nuestro objetivo del problema (3). Para cada nodo global candidato j, la figura 1(a) muestra el valor de la función objetivo Global Diff(fj) en función de la influencia de la página j. El dominio local utilizado aquí es un rastreo de páginas políticas conservadoras (proporcionaremos más detalles sobre este conjunto de datos en la sección 6); observamos resultados similares en otros dominios. La correlación es bastante fuerte, lo que implica que los criterios de influencia pueden identificar de manera efectiva las páginas que mejoran la estimación global del PageRank. Como referencia, la figura 1(b) compara nuestro objetivo con un criterio alternativo, el recuento de enlaces de salida. El recuento de enlaces de salida se define como el número de enlaces de salida desde el dominio local a la página j. La correlación aquí es mucho más débil. .00001 .0001 .001 .01 0.26 0.262 0.264 0.266 Influencia Objetivo 1 10 100 1000 0.266 0.264 0.262 0.26 Recuento de Enlaces Salientes Objetivo (a) (b) Figura 1: (a) La correlación entre nuestros criterios de selección de página de influencia (7) y el valor real de la función objetivo (3) es bastante fuerte. (b) Esto contrasta con otros criterios, como el recuento de enlaces salientes, que muestran una correlación mucho más débil. 5.2 Cálculo Como se describe, para cada página global candidata j, se debe calcular el puntaje de influencia (7). Si fj se calcula exactamente para cada página global j, entonces el algoritmo de PageRank tendría que ejecutarse para cada una de las O(n) páginas globales j que consideramos, lo que resultaría en un costo computacional de O(n2) para el método de selección de nodos. Por lo tanto, calcular el valor exacto de fj conducirá a un algoritmo cuadrático, y en su lugar debemos recurrir a métodos de aproximación de este vector. El algoritmo que presentamos funciona realizando una iteración del método de potencia utilizado por el algoritmo PageRank (Algoritmo 1). La tasa de convergencia para el algoritmo PageRank se ha demostrado que es igual a la probabilidad del surfista aleatorio α [7, 11]. Dado un vector inicial x(0), si se realizan k iteraciones de PageRank, la solución actual de PageRank x(k) satisface: x(k) − x∗ 1 = O(αk x(0) − x∗ 1), (8), donde x∗ es el vector de PageRank deseado. Por lo tanto, si solo se realiza una iteración, es necesario elegir un buen vector inicial para lograr una aproximación precisa. Particionamos la matriz de PageRank PFj, correspondiente al subgrafo Fj, como: PFj = ˜F ˜s ˜uT j w, (9) donde ˜F = αF (DF + diag(uj))−1 + (1 − α) e + 1 eT, ˜s = αs + (1 − α) e + 1, ˜uj = α(DF + diag(uj))−1 uj + (1 − α) e + 1, w = 1 − α + 1, y diag(uj) es la matriz diagonal con la entrada (i, i) igual a uno si el i-ésimo elemento de uj es uno, y cero en caso contrario. Hemos asumido aquí que el vector del surfista aleatorio es el vector uniforme, y que L no tiene enlaces colgantes. Estas suposiciones no son necesarias y solo sirven para simplificar la discusión y el análisis. Un enfoque sencillo para estimar fj es el siguiente. Primero, estima el PageRank f+ j de Fj calculando una iteración de PageRank sobre la matriz PFj, utilizando el vector inicial ν = f 0. Luego, estima fj eliminando el último componente de 119 Research Track Paper de nuestra estimación de f+ j (es decir, el componente correspondiente al nodo j añadido), y renormalizando. El problema con este enfoque está en el vector inicial. Recuerde que xj es el PageRank del nodo j añadido. La diferencia entre el PageRank actual f+ j de PFj y el vector inicial ν es ν − f+ j 1 = xj + f − (1 − xj)fj 1 ≥ xj + | f 1 − (1 − xj) fj 1| = xj + |xj| = 2xj. Por lo tanto, según (8), después de una iteración de PageRank, esperamos que nuestra estimación de f+ j todavía tenga un error de aproximadamente 2αxj. En particular, para los nodos candidatos j con un PageRank xj relativamente alto, este método producirá resultados más inexactos. A continuación, presentaremos un método que elimina este sesgo y se ejecuta en tiempo O(n). 5.2.1 Complementación Estocástica Dado que f+ j, como se muestra en (6), es el PageRank de la matriz PFj, tenemos: fj(1 − xj) xj = ˜F ˜s ˜uT j w fj(1 − xj) xj = ˜F fj(1 − xj) + ˜sxj ˜uT j fj(1 − xj) + wxj. Resolver el sistema anterior para fj puede demostrarse que produce fj = ( ˜F + (1 − w)−1 ˜s˜uT j )fj. (10) La matriz S = ˜F +(1−w)−1 ˜s˜uT j se conoce como el complemento estocástico de la matriz estocástica de columna PFj con respecto a la submatriz ˜F. La teoría de complementación estocástica está bien estudiada, y se puede demostrar que el complemento estocástico de una matriz irreducible (como la matriz de PageRank) es único. Además, el complemento estocástico también es irreducible y, por lo tanto, tiene una distribución estacionaria única. Para un estudio extenso, ver [15]. Se puede demostrar fácilmente que el autovalor subdominante de S es a lo sumo +1 α, donde α es el tamaño de F. Para valores suficientemente grandes, este valor estará muy cerca de α. Esto es importante, ya que otras propiedades del algoritmo PageRank, especialmente la sensibilidad del algoritmo, dependen de este valor [11]. En este método, estimamos el vector de longitud fj calculando una iteración de PageRank sobre el complemento estocástico × S, comenzando en el vector f: fj ≈ Sf. (11) Esto contrasta con el método simple descrito en la sección anterior, que primero itera sobre la matriz ( + 1) × ( + 1) PFj para estimar f+ j, y luego elimina el último componente de la estimación y renormaliza para aproximar fj. El problema con el último método radica en la elección del vector inicial de longitud ( + 1), ν. En consecuencia, la estimación de PageRank dada por el método simple difiere del verdadero PageRank en al menos 2αxj, donde xj es el PageRank de la página j. Al utilizar el complemento estocástico, podemos establecer un límite inferior estricto de cero para esta diferencia. Para ver esto, considera el caso en el que se agrega un nodo k a F para formar el subgrafo local aumentado Fk, y que el PageRank de este nuevo grafo es (1 − xk)f xk. Específicamente, la adición de la página k no cambia los PageRanks de las páginas en F, y por lo tanto fk = f. Por la construcción del complemento estocástico, fk = Sfk, por lo que la aproximación dada en la ecuación (11) producirá la solución exacta. A continuación, presentamos los detalles computacionales necesarios para calcular eficientemente la cantidad fj − f 1 sobre todas las páginas globales conocidas j. Comenzamos expandiendo la diferencia fj − f, donde el vector fj se estima como en (11), fj − f ≈ Sf − f = αF (DF + diag(uj))−1 f + (1 − α) e + 1 eT f +(1 − w)−1 (˜uT j f)˜s − f. (12) Tenga en cuenta que la matriz (DF + diag(uj))−1 es diagonal. Dejando que o[k] sea el recuento de enlaces de salida para la página k en F, podemos expresar el elemento diagonal k-ésimo como: (DF + diag(uj))−1 [k, k] = 1 o[k]+1 si uj[k] = 1 1 o[k] si uj[k] = 0 Notando que (o[k] + 1)−1 = o[k]−1 − (o[k](o[k] + 1))−1 y reescribiendo esto en forma matricial obtenemos (DF +diag(uj))−1 = D−1 F −D−1 F (DF +diag(uj))−1 diag(uj). (13) Usamos la misma identidad para expresar e + 1 = e − e ( + 1) . (14) Recordemos que, por definición, tenemos PF = αF D−1 F +(1−α)e. Sustituyendo (13) y (14) en (12) se obtiene que fj − f ≈ (PF f − f) −αF D−1 F (DF + diag(uj))−1 diag(uj)f −(1 − α) e ( + 1) + (1 − w)−1 (˜uT j f)˜s = x + y + (˜uT j f)z, (15), notando que por definición, f = PF f, y definiendo los vectores x, y, y z como x = −αF D−1 F (DF + diag(uj))−1 diag(uj)f (16) y = −(1 − α) e ( + 1) (17) z = (1 − w)−1 ˜s. (18) El primer término x es un vector disperso, y toma valores no nulos solo para las páginas locales k que son hermanas de la página global j. Definimos (i, j) ∈ F si y solo si F [j, i] = 1 (equivalentemente, la página i enlaza a la página j) y expresamos el valor del componente x[k] como: x[k] = −α k:(k,k)∈F, uj[k]=1 f[k] o[k](o[k] + 1), (19) donde o[k], como antes, es el número de enlaces salientes de la página k en el dominio local. Ten en cuenta que los dos últimos términos, y y z, no dependen del nodo global actual j. Dada la función hj(f) = y + (˜uT j f)z 1, la cantidad fj − f 1 120 Research Track Paper puede expresarse como fj − f 1 = k x[k] + y[k] + (˜uT j f)z[k] = k:x[k]=0 y[k] + (˜uT j f)z[k] + k:x[k]=0 x[k] + y[k] + (˜uT j f)z[k] = hj(f) − k:x[k]=0 y[k] + (˜uT j f)z[k] + k:x[k]=0 x[k] + y[k] + (˜uT j f)z[k]. (20) Si podemos calcular la función hj en tiempo lineal, entonces podemos calcular cada valor de fj − f 1 usando una cantidad adicional de tiempo proporcional al número de componentes no nulas en x. Estas optimizaciones se llevan a cabo en el Algoritmo 3. Nótese que la ecuación (20) calcula la diferencia entre todos los componentes de f y fj, mientras que nuestros criterios de selección de nodos, dados en la ecuación (7), se restringen a los componentes correspondientes a los nodos en el dominio local original L. Examinemos el Algoritmo 3 con más detalle. Primero, el algoritmo calcula el número de enlaces de salida para cada página en el dominio local. El algoritmo luego calcula la cantidad ˜uT j f para cada página global j conocida. Este producto interno se puede escribir como (1 − α) 1 + 1 + α k:(k,j)∈Fout f[k] o[k] + 1, donde el segundo término suma sobre el conjunto de páginas locales que enlazan a la página j. Dado que se asumió que el número total de aristas en Fout tenía un tamaño O( ) (recordemos que es el número de páginas en F), el tiempo de ejecución de este paso también es O( ). El algoritmo luego calcula los vectores y y z, como se indican en (17) y (18), respectivamente. El método L1NormDiff se llama en los componentes de estos vectores que corresponden a las páginas en L, y estima el valor de EL(y + (˜uT j f)z) 1 para cada página j. La estimación funciona de la siguiente manera. Primero, los valores de ˜uT j f se discretizan de forma uniforme en c valores {a1, ..., ac}. La cantidad EL(y + aiz) 1 se calcula entonces para cada valor discretizado de ai y se almacena en una tabla. Para evaluar EL (y + az) 1 para algún a ∈ [a1, ac], se determina el valor discretizado más cercano ai, y se utiliza la entrada correspondiente en la tabla. El tiempo total de ejecución de este método es lineal en y el parámetro de discretización c (que consideramos constante). Observamos que si se desean valores exactos, también hemos desarrollado un algoritmo que se ejecuta en tiempo O(log) que no se describe aquí. En el bucle principal, calculamos el vector x, tal como se define en la ecuación (16). Los bucles anidados iteran sobre el conjunto de páginas en F que son hermanas de la página j. Normalmente, el tamaño de este conjunto está limitado por una constante. Finalmente, para cada página j, el vector de puntuaciones se actualiza sobre el conjunto de componentes no nulos k del vector x con k ∈ L. Este conjunto tiene un tamaño igual al número de hermanos locales de la página j, y es un subconjunto del número total de hermanos de la página j. Por lo tanto, cada iteración del bucle principal toma tiempo constante, y el tiempo de ejecución total del bucle principal es O( ). Dado que hemos asumido que el tamaño de F no crecerá más allá de O(n), el tiempo de ejecución total del algoritmo es O(n). Algoritmo 3: Selección de nodos a través de la complementación estocástica. SC-Select(F , Fout, f, k) Entrada: F : matriz de adyacencia de ceros y unos del tamaño correspondiente al subgrafo local actual, Fout: matriz de enlaces de ceros y unos de F al subgrafo global, f: PageRank de F , k: número de páginas a devolver Salida: páginas: conjunto de k páginas para rastrear a continuación {Calcular sumas de enlaces de salida para el subgrafo local} para cada (página j ∈ F ) o[j] ← k:(j,k)∈F F[j, k] fin {Calcular escalar ˜uT j f para cada nodo global j } para cada (página j ∈ Fout) g[j] ← (1 − α) 1 +1 para cada (página k : (k, j) ∈ Fout) g[j] ← g[j] + α f[k] o[k]+1 fin fin {Calcular vectores y z como en (17) y (18) } y ← −(1 − α) e ( +1) z ← (1 − w)−1 ˜s {Aproximar y + g[j] ∗ z 1 para todos los valores g[j]} norm diffs ←L1NormDiffs(g, ELy, ELz) para cada (página j ∈ Fout) {Calcular vector disperso x como en (19)} x ← 0 para cada (página k : (k, j) ∈ Fout) para cada (página k : (k, k ) ∈ F )) x[k ] ← x[k ] − f[k] o[k](o[k]+1) fin fin x ← αx scores[j] ← norm diffs[j] para cada (k : x[k] > 0 y página k ∈ L) scores[j] ← scores[j] − |y[k] + g[j] ∗ z[k]| +|x[k]+y[k]+g[j]∗z[k])| fin fin Devolver k páginas con los puntajes más altos 5.2.2 Flujos de PageRank Ahora presentamos un análisis intuitivo del método de complementación estocástica descomponiendo el cambio en PageRank en términos de fugas y flujos. Este análisis está motivado por la descomposición dada en (15). El flujo de PageRank es el aumento en los PageRanks locales que se originan desde la página global j. Los flujos están representados por el vector no negativo (˜uT j f)z (ecuaciones (15) y (18)). El escalar ˜uT j f se puede pensar como la cantidad total de flujo de PageRank que la página j tiene disponible para distribuir. El vector z dicta cómo se asigna el flujo al dominio local; el flujo que recibe la página local k es proporcional (con un factor constante debido al vector de navegante aleatorio) al número esperado de sus enlaces entrantes. Las filtraciones de PageRank representan la disminución en el PageRank resultante de la adición de la página j. La fuga puede ser cuantificada en términos de los vectores no positivos x e y (ecuaciones (16) y (17)). Para el vector x, podemos ver a partir de la ecuación (19) que la cantidad de PageRank filtrado por una página local es proporcional a la suma ponderada de los Page121 Research Track Paper Ranks de sus páginas hermanas. Por lo tanto, las páginas que tienen hermanos con PageRanks más altos (y un bajo número de enlaces salientes) experimentarán más pérdida de valor. La fuga causada por y es un artefacto del vector del surfista aleatorio. A continuación demostraremos que si solo se considera el término de flujo, (˜uT j f)z, entonces el método resultante es muy similar a una heurística propuesta por Cho et al. [6] que ha sido ampliamente utilizada para el problema de Ordenación de URL en el Rastreo. Esta heurística es computacionalmente más económica, pero como veremos más adelante, no es tan efectiva como el método de Complementación Estocástica. Nuestra estrategia de selección de nodos elige nodos globales que tienen la mayor influencia (ecuación (7)). Si esta influencia se aproxima utilizando solo flujos, el nodo óptimo j∗ es: j∗ = argmaxj EL ˜uT j fz 1 = argmaxj ˜uT j f EL z 1 = argmaxj ˜uT j f = argmaxj α(DF + diag(uj))−1 uj + (1 − α) e + 1 , f = argmaxjfT (DF + diag(uj))−1 uj. La puntuación de selección de página resultante se puede expresar como la suma de los PageRanks de cada página local k que enlaza con j, donde cada valor de PageRank se normaliza por o[k]+1. Curiosamente, la normalización que surge en nuestro método difiere de la heurística dada en [6], la cual normaliza por o[k]. El algoritmo PF-Select, que se omite por falta de espacio, primero calcula la cantidad fT (DF +diag(uj))−1 uj para cada página global j, y luego devuelve las páginas con los k puntajes más altos. Para ver que el tiempo de ejecución de este algoritmo es O(n), observe que la computación involucrada en este método es un subconjunto de la necesaria para el método SC-Select (Algoritmo 3), el cual se demostró que tiene un tiempo de ejecución de O(n). 6. EXPERIMENTOS En esta sección, proporcionamos evidencia experimental para verificar la efectividad de nuestros algoritmos. Primero describimos nuestra metodología experimental y luego presentamos resultados en una variedad de dominios locales. 6.1 Metodología Dado los recursos limitados disponibles en una institución académica, rastrear una sección de la web que sea de la misma magnitud que la indexada por Google o Yahoo! claramente es inviable. Por lo tanto, para un dominio local dado, aproximamos el grafo global rastreando un vecindario local alrededor del dominio que es varias órdenes de magnitud más grande que el subgrafo local. A pesar de que dicho gráfico sigue siendo órdenes de magnitud más pequeño que el verdadero gráfico global, sostenemos que, incluso si existen algunas páginas altamente influyentes que están muy lejos de nuestro dominio local, es poco realista que cualquier algoritmo de selección de nodos locales las encuentre. Tales páginas suelen ser muy poco relacionadas con las páginas dentro del dominio local. Al explicar nuestras estrategias de selección de nodos en la sección 5, hicimos la suposición simplificadora de que nuestro grafo local no contenía nodos colgantes. Esta suposición se hizo solo para facilitar nuestro análisis. Nuestra implementación maneja de manera eficiente los enlaces colgantes al reemplazar cada columna de ceros de nuestra matriz de adyacencia con el vector uniforme. Evaluamos el algoritmo utilizando las dos estrategias de selección de nodos dadas en la Sección 5.2, y también comparándolo con los siguientes métodos de referencia: • Aleatorio: Los nodos se eligen de forma uniforme al azar entre los nodos globales conocidos. • Conteo de enlaces de salida: Se eligen los nodos globales con el mayor número de enlaces de salida desde el dominio local. En cada iteración del algoritmo FindGlobalPR, evaluamos el rendimiento calculando la diferencia entre la estimación actual de PageRank del dominio local, ELf ELf 1, y el PageRank global del dominio local, ELg ELg 1. Todas las calculaciones de PageRank se realizaron utilizando el vector de surfista aleatorio uniforme. En todos los experimentos, establecimos el parámetro del surfista aleatorio α en .85 y utilizamos un umbral de convergencia de 10−6. Evaluamos la diferencia entre los vectores de PageRank local y global utilizando tres métricas diferentes: las normas L1 y L∞, y el tau de Kendall. La norma L1 mide la suma del valor absoluto de las diferencias entre los dos vectores, y la norma L∞ mide el valor absoluto de la mayor diferencia. La métrica de tau de Kendall es una medida de correlación de rangos popular utilizada para comparar PageRanks [2, 11]. Esta métrica se puede calcular contando el número de pares de pares que coinciden en la clasificación, y restando de eso el número de pares de pares que no coinciden en la clasificación. El valor final se normaliza luego por el número total de n pares de este tipo, resultando en un rango de [−1, 1], donde una puntuación negativa indica una anticorrelación entre las clasificaciones, y valores cercanos a uno corresponden a una fuerte correlación de rangos. 6.2 Resultados Nuestros experimentos se basan en dos grandes rastreos web y se descargaron utilizando el rastreador web que forma parte del proyecto de motor de búsqueda de código abierto Nutch [18]. Todas las exploraciones se limitaron únicamente a páginas http, y para limitar el número de páginas generadas dinámicamente que exploramos, ignoramos todas las páginas con URLs que contengan alguno de los caracteres ?, *, @ o =. El primer rastreo, al que nos referiremos como el conjunto de datos edu, fue iniciado por las páginas de inicio de los 100 principales departamentos de posgrado en informática en los Estados Unidos, según la clasificación de US News and World Report [16], y también por las páginas de inicio de sus respectivas instituciones. Se realizó un rastreo de profundidad 5, restringido a páginas dentro del dominio .edu, lo que resultó en un grafo con aproximadamente 4.7 millones de páginas y 22.9 millones de enlaces. El segundo rastreo fue alimentado por el conjunto de páginas bajo la jerarquía de política en el proyecto de directorio abierto dmoz[17]. Rastreamos todas las páginas hasta cuatro enlaces de distancia, lo que resultó en un grafo con 4.4 millones de páginas y 17.3 millones de enlaces. Dentro del rastreo educativo, identificamos los cinco dominios específicos del sitio correspondientes a los sitios web de los cinco principales departamentos de posgrado en ciencias de la computación, según la clasificación de US News and World Report. Esto produjo dominios locales de varios tamaños, desde 10,626 (UIUC) hasta 59,895 (Berkeley). Para cada uno de estos dominios específicos del sitio con tamaño n, realizamos 50 iteraciones del algoritmo FindGlobalPR para rastrear un total de 2n nodos adicionales. La Figura 2(a) muestra la diferencia (L1) entre la estimación de PageRank en cada iteración y el PageRank global, para el dominio local de Berkeley. El rendimiento de este conjunto de datos fue representativo del rendimiento típico en los cinco dominios locales específicos de informática. Inicialmente, la diferencia de L1 entre los PageRanks globales y locales variaba desde .0469 (Stanford) hasta .149 (MIT). Para las primeras varias iteraciones, el Artículo de Investigación 122 0 5 10 15 20 25 30 35 40 45 50 0.015 0.02 0.025 0.03 0.035 0.04 0.045 0.05 0.055 Número de Iteraciones Diferencia de PageRank Global y Local (L1) Complemento Estocástico PageRank Flujo de Enlaces de Conteo Aleatorio 0 10 20 30 40 50 0 0.05 0.1 0.15 0.2 0.25 0.3 0.35 Número de Iteraciones Diferencia de PageRank Global y Local (L1) Complemento Estocástico PageRank Flujo de Enlaces de Conteo Aleatorio 0 5 10 15 20 25 0.16 0.18 0.2 0.22 0.24 0.26 0.28 0.3 0.32 0.34 Número de Iteraciones Diferencia de PageRank Global y Local (L1) Complemento Estocástico PageRank Flujo de Enlaces de Conteo Aleatorio (a) www.cs.berkeley.edu (b) www.enterstageright.com (c) Política Figura 2: Diferencia L1 entre los PageRanks globales estimados y verdaderos para (a) el sitio web de ciencias de la computación de Berkeley, (b) el dominio específico del sitio, www.enterstageright.com, y (c) el dominio específico del tema de política. El método de complemento estocástico supera a todos los demás métodos en diferentes dominios. Tres métodos basados en enlaces superan a la heurística de selección aleatoria. Después de estas iteraciones iniciales, la heurística aleatoria tendió a ser más competitiva con (o incluso superar, como en el dominio local de Berkeley) las heurísticas de conteo de enlaces de salida y flujo de PageRank. En todos los ensayos, el método de complementación estocástica superó a los otros métodos o compitió con ellos. La Tabla 1 muestra la diferencia promedio entre los PageRanks globales estimados finales y los PageRanks globales reales para varias medidas de distancia. Algoritmo L1 L∞ Kendall Estocástico. Tabla 1: Rendimiento final promedio de varias estrategias de selección de nodos para los cinco dominios locales de informática específicos del sitio. Ten en cuenta que el Tau de Kendall mide similitud, mientras que las otras métricas son medidas de disimilitud. La Complementación Estocástica claramente supera a los otros métodos en todas las métricas. Dentro del conjunto de datos de política, también realizamos dos pruebas específicas para los sitios web más grandes en el rastreo: www.adamsmith.org, el sitio web del Instituto Adam Smith con sede en Londres, y www.enterstageright.com, una revista en línea conservadora. Al igual que con los dominios locales de edu, ejecutamos nuestro algoritmo durante 50 iteraciones, rastreando un total de 2n nodos. La figura 2 (b) muestra los resultados para el dominio www.enterstageright.com. A diferencia de los dominios locales de edu, los métodos Random y OutlinkCount no fueron competitivos ni con los métodos SC-Select ni con los métodos PF-Select. Entre todos los conjuntos de datos y todos los métodos de selección de nodos, el método de complementación estocástica fue el más impresionante en este conjunto de datos, logrando una estimación final que difería solo .0279 del PageRank global, una mejora de diez veces sobre la diferencia inicial del PageRank local de .299. Para el dominio local de Adam Smith, la diferencia inicial entre los PageRanks locales y globales fue de .148, y las estimaciones finales proporcionadas por los métodos SC-Select, PF-Select, OutlinkCount y Random fueron de .0208, .0193, .0222 y .0356, respectivamente. Dentro del conjunto de datos de política, construimos cuatro dominios locales específicos de temas. El primer dominio consistía en todas las páginas de la categoría de política de dmoz, y también todas las páginas dentro de cada uno de estos sitios hasta dos enlaces de distancia. Esto produjo un dominio local de 90,811 páginas, y los resultados se muestran en la figura 2 (c). Debido al mayor tamaño de los dominios específicos del tema, ejecutamos nuestro algoritmo solo durante 25 iteraciones para rastrear un total de n nodos. También creamos dominios específicos de temas a partir de tres subtemas políticos: liberalismo, conservadurismo y socialismo. Las páginas en estos dominios fueron identificadas por sus categorías correspondientes de dmoz. Para cada subtema, establecemos el dominio local como todas las páginas dentro de tres enlaces de las páginas de categoría dmoz correspondientes. La Tabla 2 resume el rendimiento de estos tres dominios específicos del tema, así como también del dominio político más amplio. Para cuantificar el efecto global de una página js en los valores globales de PageRank de las páginas en el dominio local, definimos el impacto de la página js como su valor de PageRank, g[j], normalizado por la fracción de sus enlaces salientes que apuntan al dominio local: impacto(j) = oL[j] o[j] · g[j], donde oL[j] es el número de enlaces salientes de la página j a páginas en el dominio local L, y o[j] es el número total de enlaces salientes de js. En términos del modelo del surfista aleatorio, el impacto de la página j es la probabilidad de que el surfista aleatorio (1) se encuentre actualmente en la página global j en su caminata aleatoria y (2) tome un enlace de salida a una página local, dado que ya ha decidido no saltar a una página aleatoria. Para el dominio político local, encontramos que muchas de las páginas con alto impacto eran de hecho páginas políticas que deberían haber sido incluidas en el tema de política de dmoz, pero no lo estaban. Por ejemplo, las dos páginas globales más influyentes fueron el motor de búsqueda político www.askhenry.com y la página de inicio de la revista política en línea www.policyreview.com. Entre las páginas no políticas, la página de inicio de la revista Education Next fue la más influyente. El diario está disponible de forma gratuita en línea y contiene artículos sobre varios aspectos de la educación K-12 en América. Para proporcionar algunas pruebas anecdóticas de la efectividad de nuestros métodos de selección de páginas, observamos que el método SC-Select eligió 11 páginas dentro del dominio www.educationnext.org, el método PF-Select descubrió 7 páginas, mientras que los métodos OutlinkCount y Random encontraron solo 6 páginas cada uno. Para el ámbito político local conservador, el sitio web socialista www.ornery.org tuvo una puntuación de impacto muy alta. Este documento de investigación de la pista 123 titulado \"Toda la política: Algoritmo L1 L2 Kendall Stoch\". Comp. .1253 .000700 .8671 Flujo PR .1446 .000710 .8518 Enlace saliente .1470 .00225 .8642 Aleatorio .2055 .00203 .8271 Conservadurismo: Algoritmo L1 L2 Kendall Estoc. Comp. .0496 .000990 .9158 Flujo PR .0554 .000939 .9028 Enlace saliente .0602 .00527 .9144 Aleatorio .1197 .00102 .8843 Liberalismo: Algoritmo L1 L2 Kendall Estoc. Comp. .0622 .001360 .8848 Flujo PR .0799 .001378 .8669 Enlace saliente .0763 .001379 .8844 Aleatorio .1127 .001899 .8372 Socialismo: Algoritmo L1 L∞ Kendall Estoc. Tabla 2: Rendimiento final entre estrategias de selección de nodos para las cuatro exploraciones específicas de temas políticos. Ten en cuenta que el coeficiente de correlación de Kendall mide la similitud, mientras que las otras métricas son medidas de disimilitud. Como era de esperar, el PageRank global de este artículo (que resulta estar en la página de inicio de la NCCPR, www.nationalresearch.com) era aproximadamente de .002, mientras que el PageRank local de esta página era solo de .00158. El método SC-Select produjo una estimación global de PageRank de aproximadamente .00182, el método PFSelect estimó un valor de .00167, y los métodos Random y OutlinkCount produjeron valores de .01522 y .00171, respectivamente. TRABAJO RELACIONADO El marco de selección de nodos que hemos propuesto es similar al problema de ordenación de URL para el rastreo propuesto por Cho et al. en [6]. Mientras que nuestro marco busca minimizar la diferencia entre el PageRank global y local, el objetivo utilizado en [6] es rastrear primero las páginas más altamente clasificadas (globalmente). Proponen varios algoritmos de selección de nodos, incluyendo la heurística del recuento de enlaces de salida, así como una variante de nuestro algoritmo PF-Select al que se refieren como la métrica de ordenación de PageRank. Encontraron que este método era el más efectivo para optimizar su objetivo, al igual que lo demostró una encuesta reciente de estos métodos realizada por Baeza-Yates et al. [1]. Boldi et al. también experimentan dentro de un marco de rastreo similar en [2], pero cuantifican sus resultados al comparar la correlación de rangos de Kendall entre los PageRanks del conjunto actual de páginas rastreadas y los del grafo global completo. Encontraron que las estrategias de selección de nodos que rastreaban páginas con el PageRank global más alto primero en realidad tenían un peor rendimiento (con respecto a la correlación de Kendalls Tau entre los PageRanks locales y globales) que las estrategias básicas de búsqueda en profundidad o en amplitud. Sin embargo, sus experimentos difieren de nuestro trabajo en que nuestros algoritmos de selección de nodos no utilizan (ni tienen acceso a) valores globales de PageRank. Se han propuesto muchas mejoras algorítmicas para calcular los valores exactos de PageRank [9, 10, 14]. Si se utilizan tales algoritmos para calcular los PageRanks globales de nuestro dominio local, todos requerirían una computación, almacenamiento y ancho de banda de O(N), donde N es el tamaño del dominio global. Esto contrasta con nuestro método, que aproxima el PageRank global y escala linealmente con el tamaño del dominio local. Wang y Dewitt [22] proponen un sistema en el que el conjunto de servidores web que conforman el dominio global se comunican entre sí para calcular sus respectivos PageRanks globales. Para un servidor web dado que aloja n páginas, los requisitos computacionales, de ancho de banda y almacenamiento también son lineales en n. Una desventaja de este sistema es que el número de servidores web distintos que conforman el dominio global puede ser muy grande. Por ejemplo, nuestro conjunto de datos edu contiene sitios web de más de 3,200 universidades diferentes; coordinar un sistema así entre un gran número de sitios puede ser muy difícil. Gan, Chen y Suel proponen un método para estimar el PageRank de una sola página [5] que utiliza solo ancho de banda, computación y espacio constantes. Su enfoque se basa en la disponibilidad de un servidor de conectividad remota que puede suministrar el conjunto de enlaces entrantes a una página dada, una suposición que no se utiliza en nuestro marco de trabajo. Experimentalmente demuestran que se puede obtener una estimación razonable del PageRank de los nodos visitando como máximo unos pocos cientos de nodos. El uso de su algoritmo para nuestro problema requeriría que primero se descargue todo el dominio global o se utilice un servidor de conectividad, lo que resultaría en grafos web muy grandes. 8. CONCLUSIONES Y TRABAJOS FUTUROS Internet está creciendo de forma exponencial, y para poder navegar por un repositorio tan grande como la web, los motores de búsqueda globales se han establecido como una necesidad. Junto con la omnipresencia de estos motores de búsqueda a gran escala, surge un aumento en las expectativas de los usuarios de búsqueda. Al proporcionar una cobertura completa y aislada de un dominio web específico, los motores de búsqueda localizados son un medio efectivo para localizar rápidamente contenido que de otra manera podría ser difícil de encontrar. En este trabajo, sostenemos que el uso de PageRank global en un motor de búsqueda localizado puede mejorar el rendimiento. Para estimar el PageRank global, hemos propuesto un marco de selección de nodos iterativo en el que seleccionamos qué páginas de la frontera global rastrear a continuación. Nuestra principal contribución es nuestro algoritmo de selección de páginas de complementación estocástica. Este método recorre los nodos que tendrán un impacto significativo en el dominio local y tiene un tiempo de ejecución lineal en el número de nodos en el dominio local. Experimentalmente, validamos estos métodos en un conjunto diverso de dominios locales, que incluyen siete dominios específicos del sitio y cuatro dominios específicos del tema. Concluimos que al rastrear n o 2n páginas adicionales, nuestros métodos encuentran una estimación de los PageRanks globales que es hasta diez veces mejor que simplemente usar los PageRanks locales. Además, demostramos que nuestro algoritmo supera consistentemente a otras heurísticas existentes. En muchas ocasiones, los dominios específicos de un tema se descubren utilizando un rastreador web enfocado que considera el contenido de las páginas junto con el texto del ancla del enlace para decidir qué páginas rastrear a continuación [4]. Aunque estos rastreadores han demostrado ser bastante efectivos en descubrir contenido relacionado con el tema, también se rastrean muchas páginas irrelevantes en el proceso. Por lo general, estas páginas son eliminadas y no son indexadas por el motor de búsqueda localizado. Estas páginas pueden, por supuesto, proporcionar información valiosa sobre el PageRank global del dominio local. Una forma de integrar estas páginas en nuestro marco de trabajo es comenzar el algoritmo FindGlobalPR con el subgrafo actual F igual al conjunto de páginas que fueron rastreadas por el rastreador enfocado. El marco de estimación global de PageRank, junto con los algoritmos de selección de nodos presentados, requieren todos una computación de O(n) por iteración y un ancho de banda proporcional al número de páginas rastreadas, Tk. Si el número de iteraciones T es relativamente pequeño en comparación con el número de páginas rastreadas por iteración, k, entonces el cuello de botella del algoritmo será la fase de rastreo. Sin embargo, a medida que el número de iteraciones aumenta (en relación con k), el cuello de botella residirá en el cálculo de la selección de nodos. En este caso, nuestros algoritmos se beneficiarían de optimizaciones en el factor constante. Recuerde que el algoritmo FindGlobalPR (Algoritmo 2) requiere que los PageRanks del dominio local expandido actual se vuelvan a calcular en cada iteración. El trabajo reciente de Langville y Meyer [12] proporciona un algoritmo para recalcular rápidamente los PageRanks de un grafo web dado si se agregan un pequeño número de nodos. Este algoritmo demostró proporcionar una aceleración de cinco a diez veces en algunos conjuntos de datos. Planeamos investigar esto y otras optimizaciones similares como trabajo futuro. En este artículo, hemos evaluado objetivamente nuestros métodos midiendo qué tan cercanas son nuestras estimaciones globales de PageRank a los verdaderos PageRanks globales. Para determinar el beneficio de utilizar PageRanks globales en un motor de búsqueda localizado, sugerimos un estudio de usuarios en el que se les pida a los usuarios que califiquen la calidad de los resultados de búsqueda para varias consultas de búsqueda. Para algunas consultas, solo se utilizan los PageRanks locales en la clasificación, y para las consultas restantes, se utilizan los PageRanks locales y los PageRanks globales aproximados, según lo calculado por nuestros algoritmos. Los resultados de dicho estudio pueden ser analizados para determinar el beneficio adicional de utilizar los PageRanks globales calculados por nuestros métodos, en lugar de solo utilizar los PageRanks locales. Agradecimientos. Esta investigación fue apoyada por la subvención de la NSF CCF-0431257, el Premio de Carrera de la NSF ACI-0093404 y una subvención de Sabre, Inc. 9. REFERENCIAS [1] R. Baeza-Yates, M. Marín, C. Castillo y A. Rodríguez. Rastreando un país: estrategias mejores que el recorrido en anchura para ordenar páginas web. Conferencia de la World-Wide Web, 2005. [2] P. Boldi, M. Santini y S. Vigna. Haz lo peor para lograr lo mejor: efectos paradójicos en los cálculos incrementales de PageRank. Taller sobre Grafos Web, 3243:168-180, 2004. [3] S. Brin y L. Page. La anatomía de un motor de búsqueda web hipertextual a gran escala. Redes de Computadoras y Sistemas ISDN, 33(1-7):107-117, 1998. [4] S. Chakrabarti, M. van den Berg y B. Dom. Rastreo enfocado: un nuevo enfoque para el descubrimiento de recursos web específicos de un tema. Conferencia de la World-Wide Web, 1999. [5] Y. Chen, Q. Gan y T. Suel. Métodos locales para estimar los valores de pagerank. Conferencia sobre Gestión de Información y Conocimiento, 2004. [6] J. Cho, H. Garcia-Molina y L. Page. Rastreo eficiente a través de la ordenación de URL. Conferencia de la World-Wide Web, 1998. [7] T. H. Haveliwala y S. D. Kamvar. El segundo valor propio de la matriz de Google. Informe técnico, Universidad de Stanford, 2003. [8] T. Joachims, F. Radlinski, L. Granka, A. Cheng, C. Tillekeratne y A. Patel. Aprendizaje de funciones de recuperación a partir de retroalimentación implícita. http://www.cs.cornell.edu/People/tj/career. [9] S. D. Kamvar, T. H. Haveliwala, C. D. Manning y G. H. Golub. Explotando la estructura de bloques de la web para calcular el pagerank. Conferencia de la World-Wide Web, 2003. [10] S. D. Kamvar, T. H. Haveliwala, C. D. Manning y G. H. Golub. Métodos de extrapolación para acelerar el cálculo de PageRank. Conferencia de la World-Wide Web, 2003. [11] A. N. Langville y C. D. Meyer. Más profundo dentro de PageRank. Matemáticas en Internet, 2004. [12] A. N. Langville y C. D. Meyer. Actualizando el vector estacionario de una cadena de Markov irreducible con miras al PageRank de Google. Revista SIAM sobre Análisis de Matrices, 2005. [13] P. Lyman, H. R. Varian, K. Swearingen, P. Charles, N. Good, L. L. Jordan y J. Pal. ¿Cuánta información en 2003? Escuela de Gestión de la Información y Sistemas, Universidad de California en Berkeley, 2003. [14] F. McSherry. Un enfoque uniforme para el cálculo acelerado de PageRank. Conferencia de la World-Wide Web, 2005. [15] C. D. Meyer. Complementación estocástica, desacoplamiento de cadenas de Markov y la teoría de sistemas casi reducibles. SIAM Review, 31:240-272, 1989. [16] US News and World Report. http://www.usnews.com. [17] Proyecto de directorio abierto Dmoz. http://www.dmoz.org. [18] Motor de búsqueda de código abierto Nutch. http://www.nutch.org. [19] F. Radlinski y T. Joachims. Cadenas de consulta: aprendizaje para clasificar a partir de retroalimentación implícita. Conferencia Internacional ACM SIGKDD sobre Descubrimiento de Conocimiento y Minería de Datos, 2005. [20] S. Raghavan y H. Garcia-Molina. Explorando la web oculta. En Actas de la Vigésimo séptima Conferencia Internacional sobre Bases de Datos Muy Grandes, 2001. [21] T. Tin Tang, D. Hawking, N. Craswell y K. Griffiths. Rastreo enfocado para relevancia temática y calidad de la información médica. Conferencia sobre Gestión de Información y Conocimiento, 2005. [22] Y. Wang y D. J. DeWitt. Calculando el pagerank en un sistema distribuido de búsqueda en internet. Actas de la 30ª Conferencia VLDB, 2004. 125 Artículos de Investigación. ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "subgraph": {
            "translated_key": "subgrafo",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Estimating the Global PageRank of Web Communities Jason V. Davis Dept.",
                "of Computer Sciences University of Texas at Austin Austin, TX 78712 jdavis@cs.utexas.edu Inderjit S. Dhillon Dept. of Computer Sciences University of Texas at Austin Austin, TX 78712 inderjit@cs.utexas.edu ABSTRACT Localized search engines are small-scale systems that index a particular community on the web.",
                "They offer several benefits over their large-scale counterparts in that they are relatively inexpensive to build, and can provide more precise and complete search capability over their relevant domains.",
                "One disadvantage such systems have over large-scale search engines is the lack of global PageRank values.",
                "Such information is needed to assess the value of pages in the localized search domain within the context of the web as a whole.",
                "In this paper, we present well-motivated algorithms to estimate the global PageRank values of a local domain.",
                "The algorithms are all highly scalable in that, given a local domain of size n, they use O(n) resources that include computation time, bandwidth, and storage.",
                "We test our methods across a variety of localized domains, including site-specific domains and topic-specific domains.",
                "We demonstrate that by crawling as few as n or 2n additional pages, our methods can give excellent global PageRank estimates.",
                "Categories and Subject Descriptors H.3.3 [Information Storage and Retrieval]: Information Search and Retrieval; G.1.3 [Numerical Analysis]: Numerical Linear Algebra; G.3 [Probability and Statistics]: Markov Processes General Terms PageRank, Markov Chain, Stochastic Complementation 1.",
                "INTRODUCTION Localized search engines are small-scale search engines that index only a single community of the web.",
                "Such communities can be site-specific domains, such as pages within the cs.utexas.edu domain, or topic-related communitiesfor example, political websites.",
                "Compared to the web graph crawled and indexed by large-scale search engines, the size of such local communities is typically orders of magnitude smaller.",
                "Consequently, the computational resources needed to build such a search engine are also similarly lighter.",
                "By restricting themselves to smaller, more manageable sections of the web, localized search engines can also provide more precise and complete search capabilities over their respective domains.",
                "One drawback of localized indexes is the lack of global information needed to compute link-based rankings.",
                "The PageRank algorithm [3], has proven to be an effective such measure.",
                "In general, the PageRank of a given page is dependent on pages throughout the entire web graph.",
                "In the context of a localized search engine, if the PageRanks are computed using only the local <br>subgraph</br>, then we would expect the resulting PageRanks to reflect the perceived popularity within the local community and not of the web as a whole.",
                "For example, consider a localized search engine that indexes political pages with conservative views.",
                "A person wishing to research the opinions on global warming within the conservative political community may encounter numerous such opinions across various websites.",
                "If only local PageRank values are available, then the search results will reflect only strongly held beliefs within the community.",
                "However, if global PageRanks are also available, then the results can additionally reflect outsiders views of the conservative community (those documents that liberals most often access within the conservative community).",
                "Thus, for many localized search engines, incorporating global PageRanks can improve the quality of search results.",
                "However, the number of pages a local search engine indexes is typically orders of magnitude smaller than the number of pages indexed by their large-scale counterparts.",
                "Localized search engines do not have the bandwidth, storage capacity, or computational power to crawl, download, and compute the global PageRanks of the entire web.",
                "In this work, we present a method of approximating the global PageRanks of a local domain while only using resources of the same order as those needed to compute the PageRanks of the local <br>subgraph</br>.",
                "Our proposed method looks for a supergraph of our local <br>subgraph</br> such that the local PageRanks within this supergraph are close to the true global PageRanks.",
                "We construct this supergraph by iteratively crawling global pages on the current web frontier-i.e., global pages with inlinks from pages that have already been crawled.",
                "In order to provide 116 Research Track Paper a good approximation to the global PageRanks, care must be taken when choosing which pages to crawl next; in this paper, we present a well-motivated page selection algorithm that also performs well empirically.",
                "This algorithm is derived from a well-defined problem objective and has a running time linear in the number of local nodes.",
                "We experiment across several types of local subgraphs, including four topic related communities and several sitespecific domains.",
                "To evaluate performance, we measure the difference between the current global PageRank estimate and the global PageRank, as a function of the number of pages crawled.",
                "We compare our algorithm against several heuristics and also against a baseline algorithm that chooses pages at random, and we show that our method outperforms these other methods.",
                "Finally, we empirically demonstrate that, given a local domain of size n, we can provide good approximations to the global PageRank values by crawling at most n or 2n additional pages.",
                "The paper is organized as follows.",
                "Section 2 gives an overview of localized search engines and outlines their advantages over global search.",
                "Section 3 provides background on the PageRank algorithm.",
                "Section 4 formally defines our problem, and section 5 presents our page selection criteria and derives our algorithms.",
                "Section 6 provides experimental results, section 7 gives an overview of related work, and, finally, conclusions are given in section 8. 2.",
                "LOCALIZED SEARCH ENGINES Localized search engines index a single community of the web, typically either a site-specific community, or a topicspecific community.",
                "Localized search engines enjoy three major advantages over their large-scale counterparts: they are relatively inexpensive to build, they can offer more precise search capability over their local domain, and they can provide a more complete index.",
                "The resources needed to build a global search engine are enormous.",
                "A 2003 study by Lyman et al. [13] found that the surface web (publicly available static sites) consists of 8.9 billion pages, and that the average size of these pages is approximately 18.7 kilobytes.",
                "To download a crawl of this size, approximately 167 terabytes of space is needed.",
                "For a researcher who wishes to build a search engine with access to a couple of workstations or a small server, storage of this magnitude is simply not available.",
                "However, building a localized search engine over a web community of a hundred thousand pages would only require a few gigabytes of storage.",
                "The computational burden required to support search queries over a database this size is more manageable as well.",
                "We note that, for topic-specific search engines, the relevant community can be efficiently identified and downloaded by using a focused crawler [21, 4].",
                "For site-specific domains, the local domain is readily available on their own web server.",
                "This obviates the need for crawling or spidering, and a complete and up-to-date index of the domain can thus be guaranteed.",
                "This is in contrast to their large-scale counterparts, which suffer from several shortcomings.",
                "First, crawling dynamically generated pages-pages in the hidden web-has been the subject of research [20] and is a non-trivial task for an external crawler.",
                "Second, site-specific domains can enable the robots exclusion policy.",
                "This prohibits external search engines crawlers from downloading content from the domain, and an external search engine must instead rely on outside links and anchor text to index these restricted pages.",
                "By restricting itself to only a specific domain of the internet, a localized search engine can provide more precise search results.",
                "Consider the canonical ambiguous search query, jaguar, which can refer to either the car manufacturer or the animal.",
                "A scientist trying to research the habitat and evolutionary history of a jaguar may have better success using a finely tuned zoology-specific search engine than querying Google with multiple keyword searches and wading through irrelevant results.",
                "A method to learn better ranking functions for retrieval was recently proposed by Radlinski and Joachims [19] and has been applied to various local domains, including Cornell Universitys website [8]. 3.",
                "PAGERANK OVERVIEW The PageRank algorithm defines the importance of web pages by analyzing the underlying hyperlink structure of a web graph.",
                "The algorithm works by building a Markov chain from the link structure of the web graph and computing its stationary distribution.",
                "One way to compute the stationary distribution of a Markov chain is to find the limiting distribution of a random walk over the chain.",
                "Thus, the PageRank algorithm uses what is sometimes referred to as the random surfer model.",
                "In each step of the random walk, the surfer either follows an outlink from the current page (i.e. the current node in the chain), or jumps to a random page on the web.",
                "We now precisely define the PageRank problem.",
                "Let U be an m × m adjacency matrix for a given web graph such that Uji = 1 if page i links to page j and Uji = 0 otherwise.",
                "We define the PageRank matrix PU to be: PU = αUD−1 U + (1 − α)veT , (1) where DU is the (unique) diagonal matrix such that UD−1 U is column stochastic, α is a given scalar such that 0 ≤ α ≤ 1, e is the vector of all ones, and v is a non-negative, L1normalized vector, sometimes called the random surfer vector.",
                "Note that the matrix D−1 U is well-defined only if each column of U has at least one non-zero entry-i.e., each page in the webgraph has at least one outlink.",
                "In the presence of such dangling nodes that have no outlinks, one commonly used solution, proposed by Brin et al. [3], is to replace each zero column of U by a non-negative, L1-normalized vector.",
                "The PageRank vector r is the dominant eigenvector of the PageRank matrix, r = PU r. We will assume, without loss of generality, that r has an L1-norm of one.",
                "Computationally, r can be computed using the power method.",
                "This method first chooses a random starting vector r(0) , and iteratively multiplies the current vector by the PageRank matrix PU ; see Algorithm 1.",
                "In general, each iteration of the power method can take O(m2 ) operations when PU is a dense matrix.",
                "However, in practice, the number of links in a web graph will be of the order of the number of pages.",
                "By exploiting the sparsity of the PageRank matrix, the work per iteration can be reduced to O(km), where k is the average number of links per web page.",
                "It has also been shown that the total number of iterations needed for convergence is proportional to α and does not depend on the size of the web graph [11, 7].",
                "Finally, the total space needed is also O(km), mainly to store the matrix U. 117 Research Track Paper Algorithm 1: A linear time (per iteration) algorithm for computing PageRank.",
                "ComputePR(U) Input: U: Adjacency matrix.",
                "Output: r: PageRank vector.",
                "Choose (randomly) an initial non-negative vector r(0) such that r(0) 1 = 1. i ← 0 repeat i ← i + 1 ν ← αUD−1 U r(i−1) {α is the random surfing probability} r(i) ← ν + (1 − α)v {v is the random surfer vector.} until r(i) − r(i−1) < δ {δ is the convergence threshold.} r ← r(i) 4.",
                "PROBLEM DEFINITION Given a local domain L, let G be an N × N adjacency matrix for the entire connected component of the web that contains L, such that Gji = 1 if page i links to page j and Gji = 0 otherwise.",
                "Without loss of generality, we will partition G as: G = L Gout Lout Gwithin , (2) where L is the n × n local <br>subgraph</br> corresponding to links inside the local domain, Lout is the <br>subgraph</br> that corresponds to links from the local domain pointing out to the global domain, Gout is the subgraph containing links from the global domain into the local domain, and Gwithin contains links within the global domain.",
                "We assume that when building a localized search engine, only pages inside the local domain are crawled, and the links between these pages are represented by the <br>subgraph</br> L. The links in Lout are also known, as these point from crawled pages in the local domain to uncrawled pages in the global domain.",
                "As defined in equation (1), PG is the PageRank matrix formed from the global graph G, and we define the global PageRank vector of this graph to be g. Let the n-length vector p∗ be the L1-normalized vector corresponding to the global PageRank of the pages in the local domain L: p∗ = EL g ELg 1 , where EL = [ I | 0 ] is the restriction matrix that selects the components from g corresponding to nodes in L. Let p denote the PageRank vector constructed from the local domain <br>subgraph</br> L. In practice, the observed local PageRank p and the global PageRank p∗ will be quite different.",
                "One would expect that as the size of local matrix L approaches the size of global matrix G, the global PageRank and the observed local PageRank will become more similar.",
                "Thus, one approach to estimating the global PageRank is to crawl the entire global domain, compute its PageRank, and extract the PageRanks of the local domain.",
                "Typically, however, n N , i.e., the number of global pages is much larger than the number of local pages.",
                "Therefore, crawling all global pages will quickly exhaust all local resources (computational, storage, and bandwidth) available to create the local search engine.",
                "We instead seek a supergraph ˆF of our local <br>subgraph</br> L with size O(n).",
                "Our goal Algorithm 2: The FindGlobalPR algorithm.",
                "FindGlobalPR(L, Lout, T, k) Input: L: zero-one adjacency matrix for the local domain, Lout: zero-one outlink matrix from L to global <br>subgraph</br> as in (2), T: number of iterations, k: number of pages to crawl per iteration.",
                "Output: ˆp: an improved estimate of the global PageRank of L. F ← L Fout ← Lout f ← ComputePR(F ) for (i = 1 to T) {Determine which pages to crawl next} pages ← SelectNodes(F , Fout, f, k) Crawl pages, augment F and modify Fout {Update PageRanks for new local domain} f ← ComputePR(F ) end {Extract PageRanks of original local domain & normalize} ˆp ← ELf ELf 1 is to find such a supergraph ˆF with PageRank ˆf, so that ˆf when restricted to L is close to p∗ .",
                "Formally, we seek to minimize GlobalDiff( ˆf) = EL ˆf EL ˆf 1 − p∗ 1 . (3) We choose the L1 norm for measuring the error as it does not place excessive weight on outliers (as the L2 norm does, for example), and also because it is the most commonly used distance measure in the literature for comparing PageRank vectors, as well as for detecting convergence of the algorithm [3].",
                "We propose a greedy framework, given in Algorithm 2, for constructing ˆF .",
                "Initially, F is set to the local <br>subgraph</br> L, and the PageRank f of this graph is computed.",
                "The algorithm then proceeds as follows.",
                "First, the SelectNodes algorithm (which we discuss in the next section) is called and it returns a set of k nodes to crawl next from the set of nodes in the current crawl frontier, Fout.",
                "These selected nodes are then crawled to expand the local <br>subgraph</br>, F , and the PageRanks of this expanded graph are then recomputed.",
                "These steps are repeated for each of T iterations.",
                "Finally, the PageRank vector ˆp, which is restricted to pages within the original local domain, is returned.",
                "Given our computation, bandwidth, and memory restrictions, we will assume that the algorithm will crawl at most O(n) pages.",
                "Since the PageRanks are computed in each iteration of the algorithm, which is an O(n) operation, we will also assume that the number of iterations T is a constant.",
                "Of course, the main challenge here is in selecting which set of k nodes to crawl next.",
                "In the next section, we formally define the problem and give efficient algorithms. 5.",
                "NODE SELECTION In this section, we present node selection algorithms that operate within the greedy framework presented in the previous section.",
                "We first give a well-defined criteria for the page selection problem and provide experimental evidence that this criteria can effectively identify pages that optimize our problem objective (3).",
                "We then present our main al118 Research Track Paper gorithmic contribution of the paper, a method with linear running time that is derived from this page selection criteria.",
                "Finally, we give an intuitive analysis of our algorithm in terms of leaks and flows.",
                "We show that if only the flow is considered, then the resulting method is very similar to a widely used page selection heuristic [6]. 5.1 Formulation For a given page j in the global domain, we define the expanded local graph Fj: Fj = F s uT j 0 , (4) where uj is the zero-one vector containing the outlinks from F into page j, and s contains the inlinks from page j into the local domain.",
                "Note that we do not allow self-links in this framework.",
                "In practice, self-links are often removed, as they only serve to inflate a given pages PageRank.",
                "Observe that the inlinks into F from node j are not known until after node j is crawled.",
                "Therefore, we estimate this inlink vector as the expectation over inlink counts among the set of already crawled pages, s = F T e F T e 1 . (5) In practice, for any given page, this estimate may not reflect the true inlinks from that page.",
                "Furthermore, this expectation is sampled from the set of links within the crawled domain, whereas a better estimate would also use links from the global domain.",
                "However, the latter distribution is not known to a localized search engine, and we contend that the above estimate will, on average, be a better estimate than the uniform distribution, for example.",
                "Let the PageRank of F be f. We express the PageRank f+ j of the expanded local graph Fj as f+ j = (1 − xj)fj xj , (6) where xj is the PageRank of the candidate global node j, and fj is the L1-normalized PageRank vector restricted to the pages in F .",
                "Since directly optimizing our problem goal requires knowing the global PageRank p∗ , we instead propose to crawl those nodes that will have the greatest influence on the PageRanks of pages in the original local domain L: influence(j) = k∈L |fj[k] − f[k]| (7) = EL (fj − f) 1.",
                "Experimentally, the influence score is a very good predictor of our problem objective (3).",
                "For each candidate global node j, figure 1(a) shows the objective function value Global Diff(fj) as a function of the influence of page j.",
                "The local domain used here is a crawl of conservative political pages (we will provide more details about this dataset in section 6); we observed similar results in other domains.",
                "The correlation is quite strong, implying that the influence criteria can effectively identify pages that improve the global PageRank estimate.",
                "As a baseline, figure 1(b) compares our objective with an alternative criteria, outlink count.",
                "The outlink count is defined as the number of outlinks from the local domain to page j.",
                "The correlation here is much weaker. .00001 .0001 .001 .01 0.26 0.262 0.264 0.266 Influence Objective 1 10 100 1000 0.266 0.264 0.262 0.26 Outlink Count Objective (a) (b) Figure 1: (a) The correlation between our influence page selection criteria (7) and the actual objective function (3) value is quite strong. (b) This is in contrast to other criteria, such as outlink count, which exhibit a much weaker correlation. 5.2 Computation As described, for each candidate global page j, the influence score (7) must be computed.",
                "If fj is computed exactly for each global page j, then the PageRank algorithm would need to be run for each of the O(n) such global pages j we consider, resulting in an O(n2 ) computational cost for the node selection method.",
                "Thus, computing the exact value of fj will lead to a quadratic algorithm, and we must instead turn to methods of approximating this vector.",
                "The algorithm we present works by performing one power method iteration used by the PageRank algorithm (Algorithm 1).",
                "The convergence rate for the PageRank algorithm has been shown to equal the random surfer probability α [7, 11].",
                "Given a starting vector x(0) , if k PageRank iterations are performed, the current PageRank solution x(k) satisfies: x(k) − x∗ 1 = O(αk x(0) − x∗ 1), (8) where x∗ is the desired PageRank vector.",
                "Therefore, if only one iteration is performed, choosing a good starting vector is necessary to achieve an accurate approximation.",
                "We partition the PageRank matrix PFj , corresponding to the × <br>subgraph</br> Fj as: PFj = ˜F ˜s ˜uT j w , (9) where ˜F = αF (DF + diag(uj))−1 + (1 − α) e + 1 eT , ˜s = αs + (1 − α) e + 1 , ˜uj = α(DF + diag(uj))−1 uj + (1 − α) e + 1 , w = 1 − α + 1 , and diag(uj) is the diagonal matrix with the (i, i)th entry equal to one if the ith element of uj equals one, and is zero otherwise.",
                "We have assumed here that the random surfer vector is the uniform vector, and that L has no dangling links.",
                "These assumptions are not necessary and serve only to simplify discussion and analysis.",
                "A simple approach for estimating fj is the following.",
                "First, estimate the PageRank f+ j of Fj by computing one PageRank iteration over the matrix PFj , using the starting vector ν = f 0 .",
                "Then, estimate fj by removing the last 119 Research Track Paper component from our estimate of f+ j (i.e., the component corresponding to the added node j), and renormalizing.",
                "The problem with this approach is in the starting vector.",
                "Recall from (6) that xj is the PageRank of the added node j.",
                "The difference between the actual PageRank f+ j of PFj and the starting vector ν is ν − f+ j 1 = xj + f − (1 − xj)fj 1 ≥ xj + | f 1 − (1 − xj) fj 1| = xj + |xj| = 2xj.",
                "Thus, by (8), after one PageRank iteration, we expect our estimate of f+ j to still have an error of about 2αxj.",
                "In particular, for candidate nodes j with relatively high PageRank xj, this method will yield more inaccurate results.",
                "We will next present a method that eliminates this bias and runs in O(n) time. 5.2.1 Stochastic Complementation Since f+ j , as given in (6) is the PageRank of the matrix PFj , we have: fj(1 − xj) xj = ˜F ˜s ˜uT j w fj(1 − xj) xj = ˜F fj(1 − xj) + ˜sxj ˜uT j fj(1 − xj) + wxj .",
                "Solving the above system for fj can be shown to yield fj = ( ˜F + (1 − w)−1 ˜s˜uT j )fj. (10) The matrix S = ˜F +(1−w)−1 ˜s˜uT j is known as the stochastic complement of the column stochastic matrix PFj with respect to the sub matrix ˜F .",
                "The theory of stochastic complementation is well studied, and it can be shown the stochastic complement of an irreducible matrix (such as the PageRank matrix) is unique.",
                "Furthermore, the stochastic complement is also irreducible and therefore has a unique stationary distribution as well.",
                "For an extensive study, see [15].",
                "It can be easily shown that the sub-dominant eigenvalue of S is at most +1 α, where is the size of F .",
                "For sufficiently large , this value will be very close to α.",
                "This is important, as other properties of the PageRank algorithm, notably the algorithms sensitivity, are dependent on this value [11].",
                "In this method, we estimate the length vector fj by computing one PageRank iteration over the × stochastic complement S, starting at the vector f: fj ≈ Sf. (11) This is in contrast to the simple method outlined in the previous section, which first iterates over the ( + 1) × ( + 1) matrix PFj to estimate f+ j , and then removes the last component from the estimate and renormalizes to approximate fj.",
                "The problem with the latter method is in the choice of the ( + 1) length starting vector, ν. Consequently, the PageRank estimate given by the simple method differs from the true PageRank by at least 2αxj, where xj is the PageRank of page j.",
                "By using the stochastic complement, we can establish a tight lower bound of zero for this difference.",
                "To see this, consider the case in which a node k is added to F to form the augmented local <br>subgraph</br> Fk, and that the PageRank of this new graph is (1 − xk)f xk .",
                "Specifically, the addition of page k does not change the PageRanks of the pages in F , and thus fk = f. By construction of the stochastic complement, fk = Sfk, so the approximation given in equation (11) will yield the exact solution.",
                "Next, we present the computational details needed to efficiently compute the quantity fj −f 1 over all known global pages j.",
                "We begin by expanding the difference fj −f, where the vector fj is estimated as in (11), fj − f ≈ Sf − f = αF (DF + diag(uj))−1 f + (1 − α) e + 1 eT f +(1 − w)−1 (˜uT j f)˜s − f. (12) Note that the matrix (DF +diag(uj))−1 is diagonal.",
                "Letting o[k] be the outlink count for page k in F , we can express the kth diagonal element as: (DF + diag(uj))−1 [k, k] = 1 o[k]+1 if uj[k] = 1 1 o[k] if uj[k] = 0 Noting that (o[k] + 1)−1 = o[k]−1 − (o[k](o[k] + 1))−1 and rewriting this in matrix form yields (DF +diag(uj))−1 = D−1 F −D−1 F (DF +diag(uj))−1 diag(uj). (13) We use the same identity to express e + 1 = e − e ( + 1) . (14) Recall that, by definition, we have PF = αF D−1 F +(1−α)e .",
                "Substituting (13) and (14) in (12) yields fj − f ≈ (PF f − f) −αF D−1 F (DF + diag(uj))−1 diag(uj)f −(1 − α) e ( + 1) + (1 − w)−1 (˜uT j f)˜s = x + y + (˜uT j f)z, (15) noting that by definition, f = PF f, and defining the vectors x, y, and z to be x = −αF D−1 F (DF + diag(uj))−1 diag(uj)f (16) y = −(1 − α) e ( + 1) (17) z = (1 − w)−1 ˜s. (18) The first term x is a sparse vector, and takes non-zero values only for local pages k that are siblings of the global page j.",
                "We define (i, j) ∈ F if and only if F [j, i] = 1 (equivalently, page i links to page j) and express the value of the component x[k ] as: x[k ] = −α k:(k,k )∈F ,uj [k]=1 f[k] o[k](o[k] + 1) , (19) where o[k], as before, is the number of outlinks from page k in the local domain.",
                "Note that the last two terms, y and z are not dependent on the current global node j.",
                "Given the function hj(f) = y + (˜uT j f)z 1, the quantity fj − f 1 120 Research Track Paper can be expressed as fj − f 1 = k x[k] + y[k] + (˜uT j f)z[k] = k:x[k]=0 y[k] + (˜uT j f)z[k] + k:x[k]=0 x[k] + y[k] + (˜uT j f)z[k] = hj(f) − k:x[k]=0 y[k] + (˜uT j f)z[k] + k:x[k]=0 x[k] + y[k] + (˜uT j f)z[k] . (20) If we can compute the function hj in linear time, then we can compute each value of fj − f 1 using an additional amount of time that is proportional to the number of nonzero components in x.",
                "These optimizations are carried out in Algorithm 3.",
                "Note that (20) computes the difference between all components of f and fj, whereas our node selection criteria, given in (7), is restricted to the components corresponding to nodes in the original local domain L. Let us examine Algorithm 3 in more detail.",
                "First, the algorithm computes the outlink counts for each page in the local domain.",
                "The algorithm then computes the quantity ˜uT j f for each known global page j.",
                "This inner product can be written as (1 − α) 1 + 1 + α k:(k,j)∈Fout f[k] o[k] + 1 , where the second term sums over the set of local pages that link to page j.",
                "Since the total number of edges in Fout was assumed to have size O( ) (recall that is the number of pages in F ), the running time of this step is also O( ).",
                "The algorithm then computes the vectors y and z, as given in (17) and (18), respectively.",
                "The L1NormDiff method is called on the components of these vectors which correspond to the pages in L, and it estimates the value of EL(y + (˜uT j f)z) 1 for each page j.",
                "The estimation works as follows.",
                "First, the values of ˜uT j f are discretized uniformly into c values {a1, ..., ac}.",
                "The quantity EL(y + aiz) 1 is then computed for each discretized value of ai and stored in a table.",
                "To evaluate EL (y + az) 1 for some a ∈ [a1, ac], the closest discretized value ai is determined, and the corresponding entry in the table is used.",
                "The total running time for this method is linear in and the discretization parameter c (which we take to be a constant).",
                "We note that if exact values are desired, we have also developed an algorithm that runs in O( log ) time that is not described here.",
                "In the main loop, we compute the vector x, as defined in equation (16).",
                "The nested loops iterate over the set of pages in F that are siblings of page j.",
                "Typically, the size of this set is bounded by a constant.",
                "Finally, for each page j, the scores vector is updated over the set of non-zero components k of the vector x with k ∈ L. This set has size equal to the number of local siblings of page j, and is a subset of the total number of siblings of page j.",
                "Thus, each iteration of the main loop takes constant time, and the total running time of the main loop is O( ).",
                "Since we have assumed that the size of F will not grow larger than O(n), the total running time for the algorithm is O(n).",
                "Algorithm 3: Node Selection via Stochastic Complementation.",
                "SC-Select(F , Fout, f, k) Input: F : zero-one adjacency matrix of size corresponding to the current local <br>subgraph</br>, Fout: zero-one outlink matrix from F to global <br>subgraph</br>, f: PageRank of F , k: number of pages to return Output: pages: set of k pages to crawl next {Compute outlink sums for local subgraph} foreach (page j ∈ F ) o[j] ← k:(j,k)∈F F[j, k] end {Compute scalar ˜uT j f for each global node j } foreach (page j ∈ Fout) g[j] ← (1 − α) 1 +1 foreach (page k : (k, j) ∈ Fout) g[j] ← g[j] + α f[k] o[k]+1 end end {Compute vectors y and z as in (17) and (18) } y ← −(1 − α) e ( +1) z ← (1 − w)−1 ˜s {Approximate y + g[j] ∗ z 1 for all values g[j]} norm diffs ←L1NormDiffs(g, ELy, ELz) foreach (page j ∈ Fout) {Compute sparse vector x as in (19)} x ← 0 foreach (page k : (k, j) ∈ Fout) foreach (page k : (k, k ) ∈ F )) x[k ] ← x[k ] − f[k] o[k](o[k]+1) end end x ← αx scores[j] ← norm diffs[j] foreach (k : x[k] > 0 and page k ∈ L) scores[j] ← scores[j] − |y[k] + g[j] ∗ z[k]| +|x[k]+y[k]+g[j]∗z[k])| end end Return k pages with highest scores 5.2.2 PageRank Flows We now present an intuitive analysis of the stochastic complementation method by decomposing the change in PageRank in terms of leaks and flows.",
                "This analysis is motivated by the decomposition given in (15).",
                "PageRank flow is the increase in the local PageRanks originating from global page j.",
                "The flows are represented by the non-negative vector (˜uT j f)z (equations (15) and (18)).",
                "The scalar ˜uT j f can be thought of as the total amount of PageRank flow that page j has available to distribute.",
                "The vector z dictates how the flow is allocated to the local domain; the flow that local page k receives is proportional to (within a constant factor due to the random surfer vector) the expected number of its inlinks.",
                "The PageRank leaks represent the decrease in PageRank resulting from the addition of page j.",
                "The leakage can be quantified in terms of the non-positive vectors x and y (equations (16) and (17)).",
                "For vector x, we can see from equation (19) that the amount of PageRank leaked by a local page is proportional to the weighted sum of the Page121 Research Track Paper Ranks of its siblings.",
                "Thus, pages that have siblings with higher PageRanks (and low outlink counts) will experience more leakage.",
                "The leakage caused by y is an artifact of the random surfer vector.",
                "We will next show that if only the flow term, (˜uT j f)z, is considered, then the resulting method is very similar to a heuristic proposed by Cho et al. [6] that has been widely used for the Crawling Through URL Ordering problem.",
                "This heuristic is computationally cheaper, but as we will see later, not as effective as the Stochastic Complementation method.",
                "Our node selection strategy chooses global nodes that have the largest influence (equation (7)).",
                "If this influence is approximated using only flows, the optimal node j∗ is: j∗ = argmaxj EL ˜uT j fz 1 = argmaxj ˜uT j f EL z 1 = argmaxj ˜uT j f = argmaxj α(DF + diag(uj))−1 uj + (1 − α) e + 1 , f = argmaxjfT (DF + diag(uj))−1 uj.",
                "The resulting page selection score can be expressed as a sum of the PageRanks of each local page k that links to j, where each PageRank value is normalized by o[k]+1.",
                "Interestingly, the normalization that arises in our method differs from the heuristic given in [6], which normalizes by o[k].",
                "The algorithm PF-Select, which is omitted due to lack of space, first computes the quantity fT (DF +diag(uj))−1 uj for each global page j, and then returns the pages with the k largest scores.",
                "To see that the running time for this algorithm is O(n), note that the computation involved in this method is a subset of that needed for the SC-Select method (Algorithm 3), which was shown to have a running time of O(n). 6.",
                "EXPERIMENTS In this section, we provide experimental evidence to verify the effectiveness of our algorithms.",
                "We first outline our experimental methodology and then provide results across a variety of local domains. 6.1 Methodology Given the limited resources available at an academic institution, crawling a section of the web that is of the same magnitude as that indexed by Google or Yahoo! is clearly infeasible.",
                "Thus, for a given local domain, we approximate the global graph by crawling a local neighborhood around the domain that is several orders of magnitude larger than the local <br>subgraph</br>.",
                "Even though such a graph is still orders of magnitude smaller than the true global graph, we contend that, even if there exist some highly influential pages that are very far away from our local domain, it is unrealistic for any local node selection algorithm to find them.",
                "Such pages also tend to be highly unrelated to pages within the local domain.",
                "When explaining our node selection strategies in section 5, we made the simplifying assumption that our local graph contained no dangling nodes.",
                "This assumption was only made to ease our analysis.",
                "Our implementation efficiently handles dangling links by replacing each zero column of our adjacency matrix with the uniform vector.",
                "We evaluate the algorithm using the two node selection strategies given in Section 5.2, and also against the following baseline methods: • Random: Nodes are chosen uniformly at random among the known global nodes. • OutlinkCount: Global nodes with the highest number of outlinks from the local domain are chosen.",
                "At each iteration of the FindGlobalPR algorithm, we evaluate performance by computing the difference between the current PageRank estimate of the local domain, ELf ELf 1 , and the global PageRank of the local domain ELg ELg 1 .",
                "All PageRank calculations were performed using the uniform random surfer vector.",
                "Across all experiments, we set the random surfer parameter α, to be .85, and used a convergence threshold of 10−6 .",
                "We evaluate the difference between the local and global PageRank vectors using three different metrics: the L1 and L∞ norms, and Kendalls tau.",
                "The L1 norm measures the sum of the absolute value of the differences between the two vectors, and the L∞ norm measures the absolute value of the largest difference.",
                "Kendalls tau metric is a popular rank correlation measure used to compare PageRanks [2, 11].",
                "This metric can be computed by counting the number of pairs of pairs that agree in ranking, and subtracting from that the number of pairs of pairs that disagree in ranking.",
                "The final value is then normalized by the total number of n 2 such pairs, resulting in a [−1, 1] range, where a negative score signifies anti-correlation among rankings, and values near one correspond to strong rank correlation. 6.2 Results Our experiments are based on two large web crawls and were downloaded using the web crawler that is part of the Nutch open source search engine project [18].",
                "All crawls were restricted to only http pages, and to limit the number of dynamically generated pages that we crawl, we ignored all pages with urls containing any of the characters ?, *, @, or =.",
                "The first crawl, which we will refer to as the edu dataset, was seeded by homepages of the top 100 graduate computer science departments in the USA, as rated by the US News and World Report [16], and also by the home pages of their respective institutions.",
                "A crawl of depth 5 was performed, restricted to pages within the .edu domain, resulting in a graph with approximately 4.7 million pages and 22.9 million links.",
                "The second crawl was seeded by the set of pages under the politics hierarchy in the dmoz open directory project[17].",
                "We crawled all pages up to four links away, which yielded a graph with 4.4 million pages and 17.3 million links.",
                "Within the edu crawl, we identified the five site-specific domains corresponding to the websites of the top five graduate computer science departments, as ranked by the US News and World Report.",
                "This yielded local domains of various sizes, from 10,626 (UIUC) to 59,895 (Berkeley).",
                "For each of these site-specific domains with size n, we performed 50 iterations of the FindGlobalPR algorithm to crawl a total of 2n additional nodes.",
                "Figure 2(a) gives the (L1) difference from the PageRank estimate at each iteration to the global PageRank, for the Berkeley local domain.",
                "The performance of this dataset was representative of the typical performance across the five computer science sitespecific local domains.",
                "Initially, the L1 difference between the global and local PageRanks ranged from .0469 (Stanford) to .149 (MIT).",
                "For the first several iterations, the 122 Research Track Paper 0 5 10 15 20 25 30 35 40 45 50 0.015 0.02 0.025 0.03 0.035 0.04 0.045 0.05 0.055 Number of Iterations GlobalandLocalPageRankDifference(L1) Stochastic Complement PageRank Flow Outlink Count Random 0 10 20 30 40 50 0 0.05 0.1 0.15 0.2 0.25 0.3 0.35 Number of Iterations GlobalandLocalPageRankDifference(L1) Stochastic Complement PageRank Flow Outlink Count Random 0 5 10 15 20 25 0.16 0.18 0.2 0.22 0.24 0.26 0.28 0.3 0.32 0.34 Number of Iterations GlobalandLocalPageRankDifference(L1) Stochastic Complement PageRank Flow Outlink Count Random (a) www.cs.berkeley.edu (b) www.enterstageright.com (c) Politics Figure 2: L1 difference between the estimated and true global PageRanks for (a) Berkeleys computer science website, (b) the site-specific domain, www.enterstageright.com, and (c) the politics topic-specific domain.",
                "The stochastic complement method outperforms all other methods across various domains. three link-based methods all outperform the random selection heuristic.",
                "After these initial iterations, the random heuristic tended to be more competitive with (or even outperform, as in the Berkeley local domain) the outlink count and PageRank flow heuristics.",
                "In all tests, the stochastic complementation method either outperformed, or was competitive with, the other methods.",
                "Table 1 gives the average difference between the final estimated global PageRanks and the true global PageRanks for various distance measures.",
                "Algorithm L1 L∞ Kendall Stoch.",
                "Comp. .0384 .00154 .9257 PR Flow .0470 .00272 .8946 Outlink .0419 .00196 .9053 Random .0407 .00204 .9086 Table 1: Average final performance of various node selection strategies for the five site-specific computer science local domains.",
                "Note that Kendalls Tau measures similarity, while the other metrics are dissimilarity measures.",
                "Stochastic Complementation clearly outperforms the other methods in all metrics.",
                "Within the politics dataset, we also performed two sitespecific tests for the largest websites in the crawl: www.adamsmith.org, the website for the London based Adam Smith Institute, and www.enterstageright.com, an online conservative journal.",
                "As with the edu local domains, we ran our algorithm for 50 iterations, crawling a total of 2n nodes.",
                "Figure 2 (b) plots the results for the www.enterstageright.com domain.",
                "In contrast to the edu local domains, the Random and OutlinkCount methods were not competitive with either the SC-Select or the PF-Select methods.",
                "Among all datasets and all node selection methods, the stochastic complementation method was most impressive in this dataset, realizing a final estimate that differed only .0279 from the global PageRank, a ten-fold improvement over the initial local PageRank difference of .299.",
                "For the Adam Smith local domain, the initial difference between the local and global PageRanks was .148, and the final estimates given by the SC-Select, PF-Select, OutlinkCount, and Random methods were .0208, .0193, .0222, and .0356, respectively.",
                "Within the politics dataset, we constructed four topicspecific local domains.",
                "The first domain consisted of all pages in the dmoz politics category, and also all pages within each of these sites up to two links away.",
                "This yielded a local domain of 90,811 pages, and the results are given in figure 2 (c).",
                "Because of the larger size of the topic-specific domains, we ran our algorithm for only 25 iterations to crawl a total of n nodes.",
                "We also created topic-specific domains from three political sub-topics: liberalism, conservatism, and socialism.",
                "The pages in these domains were identified by their corresponding dmoz categories.",
                "For each sub-topic, we set the local domain to be all pages within three links from the corresponding dmoz category pages.",
                "Table 2 summarizes the performance of these three topic-specific domains, and also the larger political domain.",
                "To quantify a global page js effect on the global PageRank values of pages in the local domain, we define page js impact to be its PageRank value, g[j], normalized by the fraction of its outlinks pointing to the local domain: impact(j) = oL[j] o[j] · g[j], where, oL[j] is the number of outlinks from page j to pages in the local domain L, and o[j] is the total number of js outlinks.",
                "In terms of the random surfer model, the impact of page j is the probability that the random surfer (1) is currently at global page j in her random walk and (2) takes an outlink to a local page, given that she has already decided not to jump to a random page.",
                "For the politics local domain, we found that many of the pages with high impact were in fact political pages that should have been included in the dmoz politics topic, but were not.",
                "For example, the two most influential global pages were the political search engine www.askhenry.com, and the home page of the online political magazine, www.policyreview.com.",
                "Among non-political pages, the home page of the journal Education Next was most influential.",
                "The journal is freely available online and contains articles regarding various aspect of K-12 education in America.",
                "To provide some anecdotal evidence for the effectiveness of our page selection methods, we note that the SC-Select method chose 11 pages within the www.educationnext.org domain, the PF-Select method discovered 7 such pages, while the OutlinkCount and Random methods found only 6 pages each.",
                "For the conservative political local domain, the socialist website www.ornery.org had a very high impact score.",
                "This 123 Research Track Paper All Politics: Algorithm L1 L2 Kendall Stoch.",
                "Comp. .1253 .000700 .8671 PR Flow .1446 .000710 .8518 Outlink .1470 .00225 .8642 Random .2055 .00203 .8271 Conservativism: Algorithm L1 L2 Kendall Stoch.",
                "Comp. .0496 .000990 .9158 PR Flow .0554 .000939 .9028 Outlink .0602 .00527 .9144 Random .1197 .00102 .8843 Liberalism: Algorithm L1 L2 Kendall Stoch.",
                "Comp. .0622 .001360 .8848 PR Flow .0799 .001378 .8669 Outlink .0763 .001379 .8844 Random .1127 .001899 .8372 Socialism: Algorithm L1 L∞ Kendall Stoch.",
                "Comp. .04318 .00439 .9604 PR Flow .0450 .004251 .9559 Outlink .04282 .00344 .9591 Random .0631 .005123 .9350 Table 2: Final performance among node selection strategies for the four political topic-specific crawls.",
                "Note that Kendalls Tau measures similarity, while the other metrics are dissimilarity measures. was largely due to a link from the front page of this site to an article regarding global warming published by the National Center for Public Policy Research, a conservative research group in Washington, DC.",
                "Not surprisingly, the global PageRank of this article (which happens to be on the home page of the NCCPR, www.nationalresearch.com), was approximately .002, whereas the local PageRank of this page was only .00158.",
                "The SC-Select method yielded a global PageRank estimate of approximately .00182, the PFSelect method estimated a value of .00167, and the Random and OutlinkCount methods yielded values of .01522 and .00171, respectively. 7.",
                "RELATED WORK The node selection framework we have proposed is similar to the url ordering for crawling problem proposed by Cho et al. in [6].",
                "Whereas our framework seeks to minimize the difference between the global and local PageRank, the objective used in [6] is to crawl the most highly (globally) ranked pages first.",
                "They propose several node selection algorithms, including the outlink count heuristic, as well as a variant of our PF-Select algorithm which they refer to as the PageRank ordering metric.",
                "They found this method to be most effective in optimizing their objective, as did a recent survey of these methods by Baeza-Yates et al. [1].",
                "Boldi et al. also experiment within a similar crawling framework in [2], but quantify their results by comparing Kendalls rank correlation between the PageRanks of the current set of crawled pages and those of the entire global graph.",
                "They found that node selection strategies that crawled pages with the highest global PageRank first actually performed worse (with respect to Kendalls Tau correlation between the local and global PageRanks) than basic depth first or breadth first strategies.",
                "However, their experiments differ from our work in that our node selection algorithms do not use (or have access to) global PageRank values.",
                "Many algorithmic improvements for computing exact PageRank values have been proposed [9, 10, 14].",
                "If such algorithms are used to compute the global PageRanks of our local domain, they would all require O(N) computation, storage, and bandwidth, where N is the size of the global domain.",
                "This is in contrast to our method, which approximates the global PageRank and scales linearly with the size of the local domain.",
                "Wang and Dewitt [22] propose a system where the set of web servers that comprise the global domain communicate with each other to compute their respective global PageRanks.",
                "For a given web server hosting n pages, the computational, bandwidth, and storage requirements are also linear in n. One drawback of this system is that the number of distinct web servers that comprise the global domain can be very large.",
                "For example, our edu dataset contains websites from over 3,200 different universities; coordinating such a system among a large number of sites can be very difficult.",
                "Gan, Chen, and Suel propose a method for estimating the PageRank of a single page [5] which uses only constant bandwidth, computation, and space.",
                "Their approach relies on the availability of a remote connectivity server that can supply the set of inlinks to a given page, an assumption not used in our framework.",
                "They experimentally show that a reasonable estimate of the nodes PageRank can be obtained by visiting at most a few hundred nodes.",
                "Using their algorithm for our problem would require that either the entire global domain first be downloaded or a connectivity server be used, both of which would lead to very large web graphs. 8.",
                "CONCLUSIONS AND FUTURE WORK The internet is growing exponentially, and in order to navigate such a large repository as the web, global search engines have established themselves as a necessity.",
                "Along with the ubiquity of these large-scale search engines comes an increase in search users expectations.",
                "By providing complete and isolated coverage of a particular web domain, localized search engines are an effective outlet to quickly locate content that could otherwise be difficult to find.",
                "In this work, we contend that the use of global PageRank in a localized search engine can improve performance.",
                "To estimate the global PageRank, we have proposed an iterative node selection framework where we select which pages from the global frontier to crawl next.",
                "Our primary contribution is our stochastic complementation page selection algorithm.",
                "This method crawls nodes that will most significantly impact the local domain and has running time linear in the number of nodes in the local domain.",
                "Experimentally, we validate these methods across a diverse set of local domains, including seven site-specific domains and four topic-specific domains.",
                "We conclude that by crawling an additional n or 2n pages, our methods find an estimate of the global PageRanks that is up to ten times better than just using the local PageRanks.",
                "Furthermore, we demonstrate that our algorithm consistently outperforms other existing heuristics. 124 Research Track Paper Often times, topic-specific domains are discovered using a focused web crawler which considers a pages content in conjunction with link anchor text to decide which pages to crawl next [4].",
                "Although such crawlers have proven to be quite effective in discovering topic-related content, many irrelevant pages are also crawled in the process.",
                "Typically, these pages are deleted and not indexed by the localized search engine.",
                "These pages can of course provide valuable information regarding the global PageRank of the local domain.",
                "One way to integrate these pages into our framework is to start the FindGlobalPR algorithm with the current <br>subgraph</br> F equal to the set of pages that were crawled by the focused crawler.",
                "The global PageRank estimation framework, along with the node selection algorithms presented, all require O(n) computation per iteration and bandwidth proportional to the number of pages crawled, Tk.",
                "If the number of iterations T is relatively small compared to the number of pages crawled per iteration, k, then the bottleneck of the algorithm will be the crawling phase.",
                "However, as the number of iterations increases (relative to k), the bottleneck will reside in the node selection computation.",
                "In this case, our algorithms would benefit from constant factor optimizations.",
                "Recall that the FindGlobalPR algorithm (Algorithm 2) requires that the PageRanks of the current expanded local domain be recomputed in each iteration.",
                "Recent work by Langville and Meyer [12] gives an algorithm to quickly recompute PageRanks of a given webgraph if a small number of nodes are added.",
                "This algorithm was shown to give speedup of five to ten times on some datasets.",
                "We plan to investigate this and other such optimizations as future work.",
                "In this paper, we have objectively evaluated our methods by measuring how close our global PageRank estimates are to the actual global PageRanks.",
                "To determine the benefit of using global PageRanks in a localized search engine, we suggest a user study in which users are asked to rate the quality of search results for various search queries.",
                "For some queries, only the local PageRanks are used in ranking, and for the remaining queries, local PageRanks and the approximate global PageRanks, as computed by our algorithms, are used.",
                "The results of such a study can then be analyzed to determine the added benefit of using the global PageRanks computed by our methods, over just using the local PageRanks.",
                "Acknowledgements.",
                "This research was supported by NSF grant CCF-0431257, NSF Career Award ACI-0093404, and a grant from Sabre, Inc. 9.",
                "REFERENCES [1] R. Baeza-Yates, M. Marin, C. Castillo, and A. Rodriguez.",
                "Crawling a country: better strategies than breadth-first for web page ordering.",
                "World-Wide Web Conference, 2005. [2] P. Boldi, M. Santini, and S. Vigna.",
                "Do your worst to make the best: paradoxical effects in pagerank incremental computations.",
                "Workshop on Web Graphs, 3243:168-180, 2004. [3] S. Brin and L. Page.",
                "The anatomy of a large-scale hypertextual web search engine.",
                "Computer Networks and ISDN Systems, 33(1-7):107-117, 1998. [4] S. Chakrabarti, M. van den Berg, and B. Dom.",
                "Focused crawling: a new approach to topic-specific web resource discovery.",
                "World-Wide Web Conference, 1999. [5] Y. Chen, Q. Gan, and T. Suel.",
                "Local methods for estimating pagerank values.",
                "Conference on Information and Knowledge Management, 2004. [6] J. Cho, H. Garcia-Molina, and L. Page.",
                "Efficient crawling through url ordering.",
                "World-Wide Web Conference, 1998. [7] T. H. Haveliwala and S. D. Kamvar.",
                "The second eigenvalue of the Google matrix.",
                "Technical report, Stanford University, 2003. [8] T. Joachims, F. Radlinski, L. Granka, A. Cheng, C. Tillekeratne, and A. Patel.",
                "Learning retrieval functions from implicit feedback. http://www.cs.cornell.edu/People/tj/career. [9] S. D. Kamvar, T. H. Haveliwala, C. D. Manning, and G. H. Golub.",
                "Exploiting the block structure of the web for computing pagerank.",
                "World-Wide Web Conference, 2003. [10] S. D. Kamvar, T. H. Haveliwala, C. D. Manning, and G. H. Golub.",
                "Extrapolation methods for accelerating pagerank computation.",
                "World-Wide Web Conference, 2003. [11] A. N. Langville and C. D. Meyer.",
                "Deeper inside pagerank.",
                "Internet Mathematics, 2004. [12] A. N. Langville and C. D. Meyer.",
                "Updating the stationary vector of an irreducible markov chain with an eye on Googles pagerank.",
                "SIAM Journal on Matrix Analysis, 2005. [13] P. Lyman, H. R. Varian, K. Swearingen, P. Charles, N. Good, L. L. Jordan, and J. Pal.",
                "How much information 2003?",
                "School of Information Management and System, University of California at Berkely, 2003. [14] F. McSherry.",
                "A uniform approach to accelerated pagerank computation.",
                "World-Wide Web Conference, 2005. [15] C. D. Meyer.",
                "Stochastic complementation, uncoupling markov chains, and the theory of nearly reducible systems.",
                "SIAM Review, 31:240-272, 1989. [16] US News and World Report. http://www.usnews.com. [17] Dmoz open directory project. http://www.dmoz.org. [18] Nutch open source search engine. http://www.nutch.org. [19] F. Radlinski and T. Joachims.",
                "Query chains: learning to rank from implicit feedback.",
                "ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, 2005. [20] S. Raghavan and H. Garcia-Molina.",
                "Crawling the hidden web.",
                "In Proceedings of the Twenty-seventh International Conference on Very Large Databases, 2001. [21] T. Tin Tang, D. Hawking, N. Craswell, and K. Griffiths.",
                "Focused crawling for both topical relevance and quality of medical information.",
                "Conference on Information and Knowledge Management, 2005. [22] Y. Wang and D. J. DeWitt.",
                "Computing pagerank in a distributed internet search system.",
                "Proceedings of the 30th VLDB Conference, 2004. 125 Research Track Paper"
            ],
            "original_annotated_samples": [
                "In the context of a localized search engine, if the PageRanks are computed using only the local <br>subgraph</br>, then we would expect the resulting PageRanks to reflect the perceived popularity within the local community and not of the web as a whole.",
                "In this work, we present a method of approximating the global PageRanks of a local domain while only using resources of the same order as those needed to compute the PageRanks of the local <br>subgraph</br>.",
                "Our proposed method looks for a supergraph of our local <br>subgraph</br> such that the local PageRanks within this supergraph are close to the true global PageRanks.",
                "Without loss of generality, we will partition G as: G = L Gout Lout Gwithin , (2) where L is the n × n local <br>subgraph</br> corresponding to links inside the local domain, Lout is the <br>subgraph</br> that corresponds to links from the local domain pointing out to the global domain, Gout is the subgraph containing links from the global domain into the local domain, and Gwithin contains links within the global domain.",
                "We assume that when building a localized search engine, only pages inside the local domain are crawled, and the links between these pages are represented by the <br>subgraph</br> L. The links in Lout are also known, as these point from crawled pages in the local domain to uncrawled pages in the global domain."
            ],
            "translated_annotated_samples": [
                "En el contexto de un motor de búsqueda localizado, si los PageRanks se calculan utilizando solo el <br>subgrafo</br> local, entonces esperaríamos que los PageRanks resultantes reflejen la popularidad percibida dentro de la comunidad local y no de la web en su totalidad.",
                "En este trabajo, presentamos un método para aproximar los PageRanks globales de un dominio local utilizando recursos del mismo orden que los necesarios para calcular los PageRanks del <br>subgrafo</br> local.",
                "Nuestro método propuesto busca un supergrafo de nuestro <br>subgrafo</br> local de manera que los PageRanks locales dentro de este supergrafo estén cerca de los verdaderos PageRanks globales.",
                "Sin pérdida de generalidad, vamos a dividir G de la siguiente manera: G = L Gout Lout Gwithin, donde L es el <br>subgrafo</br> local de n × n correspondiente a los enlaces dentro del dominio local, Lout es el <br>subgrafo</br> que corresponde a los enlaces desde el dominio local apuntando hacia el dominio global, Gout es el subgrafo que contiene los enlaces desde el dominio global hacia el dominio local, y Gwithin contiene los enlaces dentro del dominio global.",
                "Suponemos que al construir un motor de búsqueda localizado, solo se rastrean las páginas dentro del dominio local, y los enlaces entre estas páginas están representados por el <br>subgrafo</br> L. También se conocen los enlaces en Lout, ya que estos apuntan desde las páginas rastreadas en el dominio local a las páginas no rastreadas en el dominio global."
            ],
            "translated_text": "Estimando el PageRank Global de Comunidades Web Jason V. Davis Dept. Departamento de Ciencias de la Computación Universidad de Texas en Austin Austin, TX 78712 jdavis@cs.utexas.edu Inderjit S. Dhillon Departamento de Ciencias de la Computación Universidad de Texas en Austin Austin, TX 78712 inderjit@cs.utexas.edu RESUMEN Los motores de búsqueda localizados son sistemas a pequeña escala que indexan una comunidad particular en la web. Ofrecen varios beneficios en comparación con sus contrapartes a gran escala, ya que son relativamente económicos de construir y pueden proporcionar una capacidad de búsqueda más precisa y completa en sus dominios relevantes. Una desventaja que tienen estos sistemas en comparación con los motores de búsqueda a gran escala es la falta de valores globales de PageRank. Se necesita esa información para evaluar el valor de las páginas en el dominio de búsqueda localizada dentro del contexto de la web en su totalidad. En este artículo, presentamos algoritmos bien fundamentados para estimar los valores globales de PageRank de un dominio local. Los algoritmos son altamente escalables en el sentido de que, dado un dominio local de tamaño n, utilizan recursos de O(n) que incluyen tiempo de computación, ancho de banda y almacenamiento. Probamos nuestros métodos en una variedad de dominios localizados, incluyendo dominios específicos del sitio y dominios específicos del tema. Demostramos que al rastrear tan solo n o 2n páginas adicionales, nuestros métodos pueden proporcionar excelentes estimaciones globales de PageRank. Categorías y Descriptores de Asignaturas H.3.3 [Almacenamiento y Recuperación de Información]: Búsqueda y Recuperación de Información; G.1.3 [Análisis Numérico]: Álgebra Lineal Numérica; G.3 [Probabilidad y Estadística]: Procesos de Markov Términos Generales PageRank, Cadena de Markov, Complementación Estocástica. Los motores de búsqueda localizados son motores de búsqueda a pequeña escala que indexan solo una comunidad específica de la web. Tales comunidades pueden ser dominios específicos del sitio, como páginas dentro del dominio cs.utexas.edu, o comunidades relacionadas con un tema, por ejemplo, sitios web políticos. En comparación con el grafo web rastreado e indexado por los motores de búsqueda a gran escala, el tamaño de estas comunidades locales suele ser típicamente órdenes de magnitud más pequeño. Por consiguiente, los recursos computacionales necesarios para construir un motor de búsqueda de este tipo también son igualmente más ligeros. Al restringirse a secciones más pequeñas y manejables de la web, los motores de búsqueda localizados también pueden ofrecer capacidades de búsqueda más precisas y completas dentro de sus respectivos dominios. Una desventaja de los índices localizados es la falta de información global necesaria para calcular clasificaciones basadas en enlaces. El algoritmo PageRank [3] ha demostrado ser una medida efectiva de este tipo. En general, el PageRank de una página dada depende de las páginas en todo el grafo web. En el contexto de un motor de búsqueda localizado, si los PageRanks se calculan utilizando solo el <br>subgrafo</br> local, entonces esperaríamos que los PageRanks resultantes reflejen la popularidad percibida dentro de la comunidad local y no de la web en su totalidad. Por ejemplo, consideremos un motor de búsqueda localizado que indexa páginas políticas con puntos de vista conservadores. Una persona que desee investigar las opiniones sobre el calentamiento global dentro de la comunidad política conservadora puede encontrarse con numerosas opiniones de este tipo en varios sitios web. Si solo se dispone de valores de PageRank locales, entonces los resultados de búsqueda reflejarán solo creencias fuertemente arraigadas dentro de la comunidad. Sin embargo, si los PageRanks globales también están disponibles, entonces los resultados pueden reflejar adicionalmente las opiniones de los externos sobre la comunidad conservadora (es decir, aquellos documentos a los que los liberales acceden con mayor frecuencia dentro de la comunidad conservadora). Por lo tanto, para muchos motores de búsqueda localizados, la incorporación de PageRanks globales puede mejorar la calidad de los resultados de búsqueda. Sin embargo, el número de páginas que indexa un motor de búsqueda local suele ser órdenes de magnitud más pequeño que el número de páginas indexadas por sus contrapartes a gran escala. Los motores de búsqueda localizados no tienen el ancho de banda, la capacidad de almacenamiento o la potencia computacional para rastrear, descargar y calcular los PageRanks globales de toda la web. En este trabajo, presentamos un método para aproximar los PageRanks globales de un dominio local utilizando recursos del mismo orden que los necesarios para calcular los PageRanks del <br>subgrafo</br> local. Nuestro método propuesto busca un supergrafo de nuestro <br>subgrafo</br> local de manera que los PageRanks locales dentro de este supergrafo estén cerca de los verdaderos PageRanks globales. Construimos este supergrafo mediante el rastreo iterativo de páginas globales en la frontera web actual, es decir, páginas globales con enlaces entrantes de páginas que ya han sido rastreadas. Para proporcionar a 116 Research Track Paper una buena aproximación a los PageRanks globales, es necesario tener cuidado al elegir qué páginas rastrear a continuación; en este documento, presentamos un algoritmo de selección de páginas bien fundamentado que también tiene un buen rendimiento empírico. Este algoritmo se deriva de un objetivo de problema bien definido y tiene un tiempo de ejecución lineal en el número de nodos locales. Experimentamos en varios tipos de subgrafos locales, incluidas cuatro comunidades relacionadas con el tema y varios dominios específicos del sitio. Para evaluar el rendimiento, medimos la diferencia entre la estimación actual del PageRank global y el PageRank global, en función del número de páginas rastreadas. Comparamos nuestro algoritmo con varios heurísticos y también con un algoritmo base que elige páginas al azar, y demostramos que nuestro método supera a estos otros métodos. Finalmente, demostramos empíricamente que, dado un dominio local de tamaño n, podemos proporcionar buenas aproximaciones a los valores globales de PageRank rastreando como máximo n o 2n páginas adicionales. El documento está organizado de la siguiente manera. La sección 2 ofrece una visión general de los motores de búsqueda localizados y destaca sus ventajas sobre los motores de búsqueda globales. La sección 3 proporciona antecedentes sobre el algoritmo PageRank. La sección 4 define formalmente nuestro problema, y la sección 5 presenta nuestros criterios de selección de páginas y deriva nuestros algoritmos. La sección 6 presenta los resultados experimentales, la sección 7 ofrece una visión general del trabajo relacionado y, finalmente, las conclusiones se presentan en la sección 8. MOTORES DE BÚSQUEDA LOCALIZADOS Los motores de búsqueda localizados indexan una sola comunidad de la web, típicamente una comunidad específica del sitio o una comunidad específica del tema. Los motores de búsqueda localizados disfrutan de tres ventajas principales sobre sus contrapartes a gran escala: son relativamente económicos de construir, pueden ofrecer una capacidad de búsqueda más precisa dentro de su dominio local y pueden proporcionar un índice más completo. Los recursos necesarios para construir un motor de búsqueda global son enormes. Un estudio de 2003 realizado por Lyman et al. [13] encontró que la web superficial (sitios estáticos de acceso público) consta de 8.9 mil millones de páginas, y que el tamaño promedio de estas páginas es de aproximadamente 18.7 kilobytes. Para descargar un rastreo de este tamaño, se necesita aproximadamente 167 terabytes de espacio. Para un investigador que desee construir un motor de búsqueda con acceso a un par de estaciones de trabajo o un servidor pequeño, un almacenamiento de esta magnitud simplemente no está disponible. Sin embargo, construir un motor de búsqueda localizado sobre una comunidad web de cien mil páginas solo requeriría unos pocos gigabytes de almacenamiento. La carga computacional necesaria para soportar consultas de búsqueda sobre una base de datos de este tamaño es más manejable también. Observamos que, para los motores de búsqueda específicos de un tema, la comunidad relevante puede ser identificada y descargada de manera eficiente utilizando un rastreador enfocado [21, 4]. Para dominios específicos del sitio, el dominio local está fácilmente disponible en su propio servidor web. Esto evita la necesidad de rastreo o indexación, y por lo tanto se puede garantizar un índice completo y actualizado del dominio. Esto contrasta con sus contrapartes a gran escala, las cuales sufren de varias deficiencias. Primero, el rastreo de páginas generadas dinámicamente en la web oculta ha sido objeto de investigación [20] y es una tarea no trivial para un rastreador externo. En segundo lugar, los dominios específicos del sitio pueden habilitar la política de exclusión de robots. Esto prohíbe a los rastreadores de motores de búsqueda externos descargar contenido del dominio, y en su lugar un motor de búsqueda externo debe depender de enlaces externos y texto ancla para indexar estas páginas restringidas. Al restringirse a un dominio específico de internet, un motor de búsqueda localizado puede proporcionar resultados de búsqueda más precisos. Considera la consulta de búsqueda ambigua canónica, jaguar, que puede referirse tanto al fabricante de automóviles como al animal. Un científico que intenta investigar el hábitat y la historia evolutiva de un jaguar puede tener más éxito utilizando un motor de búsqueda específico de zoología bien ajustado que consultando Google con múltiples búsquedas de palabras clave y navegando a través de resultados irrelevantes. Recientemente se propuso un método para aprender funciones de clasificación mejores para la recuperación por Radlinski y Joachims [19] y se ha aplicado a varios dominios locales, incluido el sitio web de la Universidad de Cornell [8]. 3. PAGERANK RESUMEN El algoritmo PageRank define la importancia de las páginas web analizando la estructura de hipervínculos subyacente de un grafo web. El algoritmo funciona construyendo una cadena de Markov a partir de la estructura de enlaces del grafo web y calculando su distribución estacionaria. Una forma de calcular la distribución estacionaria de una cadena de Markov es encontrar la distribución límite de un paseo aleatorio sobre la cadena. Por lo tanto, el algoritmo PageRank utiliza lo que a veces se conoce como el modelo del surfista aleatorio. En cada paso de la caminata aleatoria, el surfista sigue un enlace de salida de la página actual (es decir, el nodo actual en la cadena), o salta a una página aleatoria en la web. Ahora definimos con precisión el problema de PageRank. Sea U una matriz de adyacencia m × m para un grafo web dado tal que Uji = 1 si la página i enlaza a la página j y Uji = 0 en caso contrario. Definimos la matriz de PageRank PU como: PU = αUD−1 U + (1 − α)veT , (1) donde DU es la matriz diagonal (única) tal que UD−1 U es estocástica por columnas, α es un escalar dado tal que 0 ≤ α ≤ 1, e es el vector de todos unos, y v es un vector no negativo, L1-normalizado, a veces llamado vector de navegante aleatorio. Ten en cuenta que la matriz D−1 U está bien definida solo si cada columna de U tiene al menos una entrada distinta de cero, es decir, cada página en el grafo web tiene al menos un enlace de salida. En presencia de nodos colgantes que no tienen enlaces de salida, una solución comúnmente utilizada, propuesta por Brin et al. [3], es reemplazar cada columna de ceros de U por un vector no negativo, normalizado en L1. El vector PageRank r es el eigenvector dominante de la matriz PageRank, r = PU r. Supondremos, sin pérdida de generalidad, que r tiene una norma L1 de uno. Computacionalmente, r se puede calcular utilizando el método de la potencia. Este método primero elige un vector inicial aleatorio r(0) y, de forma iterativa, multiplica el vector actual por la matriz de PageRank PU; ver Algoritmo 1. En general, cada iteración del método de la potencia puede requerir O(m2) operaciones cuando PU es una matriz densa. Sin embargo, en la práctica, el número de enlaces en un grafo web será del orden del número de páginas. Al explotar la dispersión de la matriz de PageRank, el trabajo por iteración se puede reducir a O(km), donde k es el número promedio de enlaces por página web. También se ha demostrado que el número total de iteraciones necesarias para la convergencia es proporcional a α y no depende del tamaño del grafo web [11, 7]. Finalmente, el espacio total necesario también es O(km), principalmente para almacenar la matriz U. 117 Research Track Paper Algorithm 1: Un algoritmo de tiempo lineal (por iteración) para calcular PageRank. CalcularPR(U) Entrada: U: Matriz de adyacencia. Salida: vector de PageRank. Elige (aleatoriamente) un vector inicial no negativo r(0) tal que r(0) 1 = 1. i ← 0 repetir i ← i + 1 ν ← αUD−1 U r(i−1) {α es la probabilidad de navegación aleatoria} r(i) ← ν + (1 − α)v {v es el vector del navegante aleatorio.} hasta que r(i) − r(i−1) < δ {δ es el umbral de convergencia.} r ← r(i) 4. Dada un dominio local L, sea G una matriz de adyacencia N × N para el componente conectado completo de la web que contiene L, tal que Gji = 1 si la página i enlaza a la página j y Gji = 0 en caso contrario. Sin pérdida de generalidad, vamos a dividir G de la siguiente manera: G = L Gout Lout Gwithin, donde L es el <br>subgrafo</br> local de n × n correspondiente a los enlaces dentro del dominio local, Lout es el <br>subgrafo</br> que corresponde a los enlaces desde el dominio local apuntando hacia el dominio global, Gout es el subgrafo que contiene los enlaces desde el dominio global hacia el dominio local, y Gwithin contiene los enlaces dentro del dominio global. Suponemos que al construir un motor de búsqueda localizado, solo se rastrean las páginas dentro del dominio local, y los enlaces entre estas páginas están representados por el <br>subgrafo</br> L. También se conocen los enlaces en Lout, ya que estos apuntan desde las páginas rastreadas en el dominio local a las páginas no rastreadas en el dominio global. ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "global graph": {
            "translated_key": "grafo global",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Estimating the Global PageRank of Web Communities Jason V. Davis Dept.",
                "of Computer Sciences University of Texas at Austin Austin, TX 78712 jdavis@cs.utexas.edu Inderjit S. Dhillon Dept. of Computer Sciences University of Texas at Austin Austin, TX 78712 inderjit@cs.utexas.edu ABSTRACT Localized search engines are small-scale systems that index a particular community on the web.",
                "They offer several benefits over their large-scale counterparts in that they are relatively inexpensive to build, and can provide more precise and complete search capability over their relevant domains.",
                "One disadvantage such systems have over large-scale search engines is the lack of global PageRank values.",
                "Such information is needed to assess the value of pages in the localized search domain within the context of the web as a whole.",
                "In this paper, we present well-motivated algorithms to estimate the global PageRank values of a local domain.",
                "The algorithms are all highly scalable in that, given a local domain of size n, they use O(n) resources that include computation time, bandwidth, and storage.",
                "We test our methods across a variety of localized domains, including site-specific domains and topic-specific domains.",
                "We demonstrate that by crawling as few as n or 2n additional pages, our methods can give excellent global PageRank estimates.",
                "Categories and Subject Descriptors H.3.3 [Information Storage and Retrieval]: Information Search and Retrieval; G.1.3 [Numerical Analysis]: Numerical Linear Algebra; G.3 [Probability and Statistics]: Markov Processes General Terms PageRank, Markov Chain, Stochastic Complementation 1.",
                "INTRODUCTION Localized search engines are small-scale search engines that index only a single community of the web.",
                "Such communities can be site-specific domains, such as pages within the cs.utexas.edu domain, or topic-related communitiesfor example, political websites.",
                "Compared to the web graph crawled and indexed by large-scale search engines, the size of such local communities is typically orders of magnitude smaller.",
                "Consequently, the computational resources needed to build such a search engine are also similarly lighter.",
                "By restricting themselves to smaller, more manageable sections of the web, localized search engines can also provide more precise and complete search capabilities over their respective domains.",
                "One drawback of localized indexes is the lack of global information needed to compute link-based rankings.",
                "The PageRank algorithm [3], has proven to be an effective such measure.",
                "In general, the PageRank of a given page is dependent on pages throughout the entire web graph.",
                "In the context of a localized search engine, if the PageRanks are computed using only the local subgraph, then we would expect the resulting PageRanks to reflect the perceived popularity within the local community and not of the web as a whole.",
                "For example, consider a localized search engine that indexes political pages with conservative views.",
                "A person wishing to research the opinions on global warming within the conservative political community may encounter numerous such opinions across various websites.",
                "If only local PageRank values are available, then the search results will reflect only strongly held beliefs within the community.",
                "However, if global PageRanks are also available, then the results can additionally reflect outsiders views of the conservative community (those documents that liberals most often access within the conservative community).",
                "Thus, for many localized search engines, incorporating global PageRanks can improve the quality of search results.",
                "However, the number of pages a local search engine indexes is typically orders of magnitude smaller than the number of pages indexed by their large-scale counterparts.",
                "Localized search engines do not have the bandwidth, storage capacity, or computational power to crawl, download, and compute the global PageRanks of the entire web.",
                "In this work, we present a method of approximating the global PageRanks of a local domain while only using resources of the same order as those needed to compute the PageRanks of the local subgraph.",
                "Our proposed method looks for a supergraph of our local subgraph such that the local PageRanks within this supergraph are close to the true global PageRanks.",
                "We construct this supergraph by iteratively crawling global pages on the current web frontier-i.e., global pages with inlinks from pages that have already been crawled.",
                "In order to provide 116 Research Track Paper a good approximation to the global PageRanks, care must be taken when choosing which pages to crawl next; in this paper, we present a well-motivated page selection algorithm that also performs well empirically.",
                "This algorithm is derived from a well-defined problem objective and has a running time linear in the number of local nodes.",
                "We experiment across several types of local subgraphs, including four topic related communities and several sitespecific domains.",
                "To evaluate performance, we measure the difference between the current global PageRank estimate and the global PageRank, as a function of the number of pages crawled.",
                "We compare our algorithm against several heuristics and also against a baseline algorithm that chooses pages at random, and we show that our method outperforms these other methods.",
                "Finally, we empirically demonstrate that, given a local domain of size n, we can provide good approximations to the global PageRank values by crawling at most n or 2n additional pages.",
                "The paper is organized as follows.",
                "Section 2 gives an overview of localized search engines and outlines their advantages over global search.",
                "Section 3 provides background on the PageRank algorithm.",
                "Section 4 formally defines our problem, and section 5 presents our page selection criteria and derives our algorithms.",
                "Section 6 provides experimental results, section 7 gives an overview of related work, and, finally, conclusions are given in section 8. 2.",
                "LOCALIZED SEARCH ENGINES Localized search engines index a single community of the web, typically either a site-specific community, or a topicspecific community.",
                "Localized search engines enjoy three major advantages over their large-scale counterparts: they are relatively inexpensive to build, they can offer more precise search capability over their local domain, and they can provide a more complete index.",
                "The resources needed to build a global search engine are enormous.",
                "A 2003 study by Lyman et al. [13] found that the surface web (publicly available static sites) consists of 8.9 billion pages, and that the average size of these pages is approximately 18.7 kilobytes.",
                "To download a crawl of this size, approximately 167 terabytes of space is needed.",
                "For a researcher who wishes to build a search engine with access to a couple of workstations or a small server, storage of this magnitude is simply not available.",
                "However, building a localized search engine over a web community of a hundred thousand pages would only require a few gigabytes of storage.",
                "The computational burden required to support search queries over a database this size is more manageable as well.",
                "We note that, for topic-specific search engines, the relevant community can be efficiently identified and downloaded by using a focused crawler [21, 4].",
                "For site-specific domains, the local domain is readily available on their own web server.",
                "This obviates the need for crawling or spidering, and a complete and up-to-date index of the domain can thus be guaranteed.",
                "This is in contrast to their large-scale counterparts, which suffer from several shortcomings.",
                "First, crawling dynamically generated pages-pages in the hidden web-has been the subject of research [20] and is a non-trivial task for an external crawler.",
                "Second, site-specific domains can enable the robots exclusion policy.",
                "This prohibits external search engines crawlers from downloading content from the domain, and an external search engine must instead rely on outside links and anchor text to index these restricted pages.",
                "By restricting itself to only a specific domain of the internet, a localized search engine can provide more precise search results.",
                "Consider the canonical ambiguous search query, jaguar, which can refer to either the car manufacturer or the animal.",
                "A scientist trying to research the habitat and evolutionary history of a jaguar may have better success using a finely tuned zoology-specific search engine than querying Google with multiple keyword searches and wading through irrelevant results.",
                "A method to learn better ranking functions for retrieval was recently proposed by Radlinski and Joachims [19] and has been applied to various local domains, including Cornell Universitys website [8]. 3.",
                "PAGERANK OVERVIEW The PageRank algorithm defines the importance of web pages by analyzing the underlying hyperlink structure of a web graph.",
                "The algorithm works by building a Markov chain from the link structure of the web graph and computing its stationary distribution.",
                "One way to compute the stationary distribution of a Markov chain is to find the limiting distribution of a random walk over the chain.",
                "Thus, the PageRank algorithm uses what is sometimes referred to as the random surfer model.",
                "In each step of the random walk, the surfer either follows an outlink from the current page (i.e. the current node in the chain), or jumps to a random page on the web.",
                "We now precisely define the PageRank problem.",
                "Let U be an m × m adjacency matrix for a given web graph such that Uji = 1 if page i links to page j and Uji = 0 otherwise.",
                "We define the PageRank matrix PU to be: PU = αUD−1 U + (1 − α)veT , (1) where DU is the (unique) diagonal matrix such that UD−1 U is column stochastic, α is a given scalar such that 0 ≤ α ≤ 1, e is the vector of all ones, and v is a non-negative, L1normalized vector, sometimes called the random surfer vector.",
                "Note that the matrix D−1 U is well-defined only if each column of U has at least one non-zero entry-i.e., each page in the webgraph has at least one outlink.",
                "In the presence of such dangling nodes that have no outlinks, one commonly used solution, proposed by Brin et al. [3], is to replace each zero column of U by a non-negative, L1-normalized vector.",
                "The PageRank vector r is the dominant eigenvector of the PageRank matrix, r = PU r. We will assume, without loss of generality, that r has an L1-norm of one.",
                "Computationally, r can be computed using the power method.",
                "This method first chooses a random starting vector r(0) , and iteratively multiplies the current vector by the PageRank matrix PU ; see Algorithm 1.",
                "In general, each iteration of the power method can take O(m2 ) operations when PU is a dense matrix.",
                "However, in practice, the number of links in a web graph will be of the order of the number of pages.",
                "By exploiting the sparsity of the PageRank matrix, the work per iteration can be reduced to O(km), where k is the average number of links per web page.",
                "It has also been shown that the total number of iterations needed for convergence is proportional to α and does not depend on the size of the web graph [11, 7].",
                "Finally, the total space needed is also O(km), mainly to store the matrix U. 117 Research Track Paper Algorithm 1: A linear time (per iteration) algorithm for computing PageRank.",
                "ComputePR(U) Input: U: Adjacency matrix.",
                "Output: r: PageRank vector.",
                "Choose (randomly) an initial non-negative vector r(0) such that r(0) 1 = 1. i ← 0 repeat i ← i + 1 ν ← αUD−1 U r(i−1) {α is the random surfing probability} r(i) ← ν + (1 − α)v {v is the random surfer vector.} until r(i) − r(i−1) < δ {δ is the convergence threshold.} r ← r(i) 4.",
                "PROBLEM DEFINITION Given a local domain L, let G be an N × N adjacency matrix for the entire connected component of the web that contains L, such that Gji = 1 if page i links to page j and Gji = 0 otherwise.",
                "Without loss of generality, we will partition G as: G = L Gout Lout Gwithin , (2) where L is the n × n local subgraph corresponding to links inside the local domain, Lout is the subgraph that corresponds to links from the local domain pointing out to the global domain, Gout is the subgraph containing links from the global domain into the local domain, and Gwithin contains links within the global domain.",
                "We assume that when building a localized search engine, only pages inside the local domain are crawled, and the links between these pages are represented by the subgraph L. The links in Lout are also known, as these point from crawled pages in the local domain to uncrawled pages in the global domain.",
                "As defined in equation (1), PG is the PageRank matrix formed from the <br>global graph</br> G, and we define the global PageRank vector of this graph to be g. Let the n-length vector p∗ be the L1-normalized vector corresponding to the global PageRank of the pages in the local domain L: p∗ = EL g ELg 1 , where EL = [ I | 0 ] is the restriction matrix that selects the components from g corresponding to nodes in L. Let p denote the PageRank vector constructed from the local domain subgraph L. In practice, the observed local PageRank p and the global PageRank p∗ will be quite different.",
                "One would expect that as the size of local matrix L approaches the size of global matrix G, the global PageRank and the observed local PageRank will become more similar.",
                "Thus, one approach to estimating the global PageRank is to crawl the entire global domain, compute its PageRank, and extract the PageRanks of the local domain.",
                "Typically, however, n N , i.e., the number of global pages is much larger than the number of local pages.",
                "Therefore, crawling all global pages will quickly exhaust all local resources (computational, storage, and bandwidth) available to create the local search engine.",
                "We instead seek a supergraph ˆF of our local subgraph L with size O(n).",
                "Our goal Algorithm 2: The FindGlobalPR algorithm.",
                "FindGlobalPR(L, Lout, T, k) Input: L: zero-one adjacency matrix for the local domain, Lout: zero-one outlink matrix from L to global subgraph as in (2), T: number of iterations, k: number of pages to crawl per iteration.",
                "Output: ˆp: an improved estimate of the global PageRank of L. F ← L Fout ← Lout f ← ComputePR(F ) for (i = 1 to T) {Determine which pages to crawl next} pages ← SelectNodes(F , Fout, f, k) Crawl pages, augment F and modify Fout {Update PageRanks for new local domain} f ← ComputePR(F ) end {Extract PageRanks of original local domain & normalize} ˆp ← ELf ELf 1 is to find such a supergraph ˆF with PageRank ˆf, so that ˆf when restricted to L is close to p∗ .",
                "Formally, we seek to minimize GlobalDiff( ˆf) = EL ˆf EL ˆf 1 − p∗ 1 . (3) We choose the L1 norm for measuring the error as it does not place excessive weight on outliers (as the L2 norm does, for example), and also because it is the most commonly used distance measure in the literature for comparing PageRank vectors, as well as for detecting convergence of the algorithm [3].",
                "We propose a greedy framework, given in Algorithm 2, for constructing ˆF .",
                "Initially, F is set to the local subgraph L, and the PageRank f of this graph is computed.",
                "The algorithm then proceeds as follows.",
                "First, the SelectNodes algorithm (which we discuss in the next section) is called and it returns a set of k nodes to crawl next from the set of nodes in the current crawl frontier, Fout.",
                "These selected nodes are then crawled to expand the local subgraph, F , and the PageRanks of this expanded graph are then recomputed.",
                "These steps are repeated for each of T iterations.",
                "Finally, the PageRank vector ˆp, which is restricted to pages within the original local domain, is returned.",
                "Given our computation, bandwidth, and memory restrictions, we will assume that the algorithm will crawl at most O(n) pages.",
                "Since the PageRanks are computed in each iteration of the algorithm, which is an O(n) operation, we will also assume that the number of iterations T is a constant.",
                "Of course, the main challenge here is in selecting which set of k nodes to crawl next.",
                "In the next section, we formally define the problem and give efficient algorithms. 5.",
                "NODE SELECTION In this section, we present node selection algorithms that operate within the greedy framework presented in the previous section.",
                "We first give a well-defined criteria for the page selection problem and provide experimental evidence that this criteria can effectively identify pages that optimize our problem objective (3).",
                "We then present our main al118 Research Track Paper gorithmic contribution of the paper, a method with linear running time that is derived from this page selection criteria.",
                "Finally, we give an intuitive analysis of our algorithm in terms of leaks and flows.",
                "We show that if only the flow is considered, then the resulting method is very similar to a widely used page selection heuristic [6]. 5.1 Formulation For a given page j in the global domain, we define the expanded local graph Fj: Fj = F s uT j 0 , (4) where uj is the zero-one vector containing the outlinks from F into page j, and s contains the inlinks from page j into the local domain.",
                "Note that we do not allow self-links in this framework.",
                "In practice, self-links are often removed, as they only serve to inflate a given pages PageRank.",
                "Observe that the inlinks into F from node j are not known until after node j is crawled.",
                "Therefore, we estimate this inlink vector as the expectation over inlink counts among the set of already crawled pages, s = F T e F T e 1 . (5) In practice, for any given page, this estimate may not reflect the true inlinks from that page.",
                "Furthermore, this expectation is sampled from the set of links within the crawled domain, whereas a better estimate would also use links from the global domain.",
                "However, the latter distribution is not known to a localized search engine, and we contend that the above estimate will, on average, be a better estimate than the uniform distribution, for example.",
                "Let the PageRank of F be f. We express the PageRank f+ j of the expanded local graph Fj as f+ j = (1 − xj)fj xj , (6) where xj is the PageRank of the candidate global node j, and fj is the L1-normalized PageRank vector restricted to the pages in F .",
                "Since directly optimizing our problem goal requires knowing the global PageRank p∗ , we instead propose to crawl those nodes that will have the greatest influence on the PageRanks of pages in the original local domain L: influence(j) = k∈L |fj[k] − f[k]| (7) = EL (fj − f) 1.",
                "Experimentally, the influence score is a very good predictor of our problem objective (3).",
                "For each candidate global node j, figure 1(a) shows the objective function value Global Diff(fj) as a function of the influence of page j.",
                "The local domain used here is a crawl of conservative political pages (we will provide more details about this dataset in section 6); we observed similar results in other domains.",
                "The correlation is quite strong, implying that the influence criteria can effectively identify pages that improve the global PageRank estimate.",
                "As a baseline, figure 1(b) compares our objective with an alternative criteria, outlink count.",
                "The outlink count is defined as the number of outlinks from the local domain to page j.",
                "The correlation here is much weaker. .00001 .0001 .001 .01 0.26 0.262 0.264 0.266 Influence Objective 1 10 100 1000 0.266 0.264 0.262 0.26 Outlink Count Objective (a) (b) Figure 1: (a) The correlation between our influence page selection criteria (7) and the actual objective function (3) value is quite strong. (b) This is in contrast to other criteria, such as outlink count, which exhibit a much weaker correlation. 5.2 Computation As described, for each candidate global page j, the influence score (7) must be computed.",
                "If fj is computed exactly for each global page j, then the PageRank algorithm would need to be run for each of the O(n) such global pages j we consider, resulting in an O(n2 ) computational cost for the node selection method.",
                "Thus, computing the exact value of fj will lead to a quadratic algorithm, and we must instead turn to methods of approximating this vector.",
                "The algorithm we present works by performing one power method iteration used by the PageRank algorithm (Algorithm 1).",
                "The convergence rate for the PageRank algorithm has been shown to equal the random surfer probability α [7, 11].",
                "Given a starting vector x(0) , if k PageRank iterations are performed, the current PageRank solution x(k) satisfies: x(k) − x∗ 1 = O(αk x(0) − x∗ 1), (8) where x∗ is the desired PageRank vector.",
                "Therefore, if only one iteration is performed, choosing a good starting vector is necessary to achieve an accurate approximation.",
                "We partition the PageRank matrix PFj , corresponding to the × subgraph Fj as: PFj = ˜F ˜s ˜uT j w , (9) where ˜F = αF (DF + diag(uj))−1 + (1 − α) e + 1 eT , ˜s = αs + (1 − α) e + 1 , ˜uj = α(DF + diag(uj))−1 uj + (1 − α) e + 1 , w = 1 − α + 1 , and diag(uj) is the diagonal matrix with the (i, i)th entry equal to one if the ith element of uj equals one, and is zero otherwise.",
                "We have assumed here that the random surfer vector is the uniform vector, and that L has no dangling links.",
                "These assumptions are not necessary and serve only to simplify discussion and analysis.",
                "A simple approach for estimating fj is the following.",
                "First, estimate the PageRank f+ j of Fj by computing one PageRank iteration over the matrix PFj , using the starting vector ν = f 0 .",
                "Then, estimate fj by removing the last 119 Research Track Paper component from our estimate of f+ j (i.e., the component corresponding to the added node j), and renormalizing.",
                "The problem with this approach is in the starting vector.",
                "Recall from (6) that xj is the PageRank of the added node j.",
                "The difference between the actual PageRank f+ j of PFj and the starting vector ν is ν − f+ j 1 = xj + f − (1 − xj)fj 1 ≥ xj + | f 1 − (1 − xj) fj 1| = xj + |xj| = 2xj.",
                "Thus, by (8), after one PageRank iteration, we expect our estimate of f+ j to still have an error of about 2αxj.",
                "In particular, for candidate nodes j with relatively high PageRank xj, this method will yield more inaccurate results.",
                "We will next present a method that eliminates this bias and runs in O(n) time. 5.2.1 Stochastic Complementation Since f+ j , as given in (6) is the PageRank of the matrix PFj , we have: fj(1 − xj) xj = ˜F ˜s ˜uT j w fj(1 − xj) xj = ˜F fj(1 − xj) + ˜sxj ˜uT j fj(1 − xj) + wxj .",
                "Solving the above system for fj can be shown to yield fj = ( ˜F + (1 − w)−1 ˜s˜uT j )fj. (10) The matrix S = ˜F +(1−w)−1 ˜s˜uT j is known as the stochastic complement of the column stochastic matrix PFj with respect to the sub matrix ˜F .",
                "The theory of stochastic complementation is well studied, and it can be shown the stochastic complement of an irreducible matrix (such as the PageRank matrix) is unique.",
                "Furthermore, the stochastic complement is also irreducible and therefore has a unique stationary distribution as well.",
                "For an extensive study, see [15].",
                "It can be easily shown that the sub-dominant eigenvalue of S is at most +1 α, where is the size of F .",
                "For sufficiently large , this value will be very close to α.",
                "This is important, as other properties of the PageRank algorithm, notably the algorithms sensitivity, are dependent on this value [11].",
                "In this method, we estimate the length vector fj by computing one PageRank iteration over the × stochastic complement S, starting at the vector f: fj ≈ Sf. (11) This is in contrast to the simple method outlined in the previous section, which first iterates over the ( + 1) × ( + 1) matrix PFj to estimate f+ j , and then removes the last component from the estimate and renormalizes to approximate fj.",
                "The problem with the latter method is in the choice of the ( + 1) length starting vector, ν. Consequently, the PageRank estimate given by the simple method differs from the true PageRank by at least 2αxj, where xj is the PageRank of page j.",
                "By using the stochastic complement, we can establish a tight lower bound of zero for this difference.",
                "To see this, consider the case in which a node k is added to F to form the augmented local subgraph Fk, and that the PageRank of this new graph is (1 − xk)f xk .",
                "Specifically, the addition of page k does not change the PageRanks of the pages in F , and thus fk = f. By construction of the stochastic complement, fk = Sfk, so the approximation given in equation (11) will yield the exact solution.",
                "Next, we present the computational details needed to efficiently compute the quantity fj −f 1 over all known global pages j.",
                "We begin by expanding the difference fj −f, where the vector fj is estimated as in (11), fj − f ≈ Sf − f = αF (DF + diag(uj))−1 f + (1 − α) e + 1 eT f +(1 − w)−1 (˜uT j f)˜s − f. (12) Note that the matrix (DF +diag(uj))−1 is diagonal.",
                "Letting o[k] be the outlink count for page k in F , we can express the kth diagonal element as: (DF + diag(uj))−1 [k, k] = 1 o[k]+1 if uj[k] = 1 1 o[k] if uj[k] = 0 Noting that (o[k] + 1)−1 = o[k]−1 − (o[k](o[k] + 1))−1 and rewriting this in matrix form yields (DF +diag(uj))−1 = D−1 F −D−1 F (DF +diag(uj))−1 diag(uj). (13) We use the same identity to express e + 1 = e − e ( + 1) . (14) Recall that, by definition, we have PF = αF D−1 F +(1−α)e .",
                "Substituting (13) and (14) in (12) yields fj − f ≈ (PF f − f) −αF D−1 F (DF + diag(uj))−1 diag(uj)f −(1 − α) e ( + 1) + (1 − w)−1 (˜uT j f)˜s = x + y + (˜uT j f)z, (15) noting that by definition, f = PF f, and defining the vectors x, y, and z to be x = −αF D−1 F (DF + diag(uj))−1 diag(uj)f (16) y = −(1 − α) e ( + 1) (17) z = (1 − w)−1 ˜s. (18) The first term x is a sparse vector, and takes non-zero values only for local pages k that are siblings of the global page j.",
                "We define (i, j) ∈ F if and only if F [j, i] = 1 (equivalently, page i links to page j) and express the value of the component x[k ] as: x[k ] = −α k:(k,k )∈F ,uj [k]=1 f[k] o[k](o[k] + 1) , (19) where o[k], as before, is the number of outlinks from page k in the local domain.",
                "Note that the last two terms, y and z are not dependent on the current global node j.",
                "Given the function hj(f) = y + (˜uT j f)z 1, the quantity fj − f 1 120 Research Track Paper can be expressed as fj − f 1 = k x[k] + y[k] + (˜uT j f)z[k] = k:x[k]=0 y[k] + (˜uT j f)z[k] + k:x[k]=0 x[k] + y[k] + (˜uT j f)z[k] = hj(f) − k:x[k]=0 y[k] + (˜uT j f)z[k] + k:x[k]=0 x[k] + y[k] + (˜uT j f)z[k] . (20) If we can compute the function hj in linear time, then we can compute each value of fj − f 1 using an additional amount of time that is proportional to the number of nonzero components in x.",
                "These optimizations are carried out in Algorithm 3.",
                "Note that (20) computes the difference between all components of f and fj, whereas our node selection criteria, given in (7), is restricted to the components corresponding to nodes in the original local domain L. Let us examine Algorithm 3 in more detail.",
                "First, the algorithm computes the outlink counts for each page in the local domain.",
                "The algorithm then computes the quantity ˜uT j f for each known global page j.",
                "This inner product can be written as (1 − α) 1 + 1 + α k:(k,j)∈Fout f[k] o[k] + 1 , where the second term sums over the set of local pages that link to page j.",
                "Since the total number of edges in Fout was assumed to have size O( ) (recall that is the number of pages in F ), the running time of this step is also O( ).",
                "The algorithm then computes the vectors y and z, as given in (17) and (18), respectively.",
                "The L1NormDiff method is called on the components of these vectors which correspond to the pages in L, and it estimates the value of EL(y + (˜uT j f)z) 1 for each page j.",
                "The estimation works as follows.",
                "First, the values of ˜uT j f are discretized uniformly into c values {a1, ..., ac}.",
                "The quantity EL(y + aiz) 1 is then computed for each discretized value of ai and stored in a table.",
                "To evaluate EL (y + az) 1 for some a ∈ [a1, ac], the closest discretized value ai is determined, and the corresponding entry in the table is used.",
                "The total running time for this method is linear in and the discretization parameter c (which we take to be a constant).",
                "We note that if exact values are desired, we have also developed an algorithm that runs in O( log ) time that is not described here.",
                "In the main loop, we compute the vector x, as defined in equation (16).",
                "The nested loops iterate over the set of pages in F that are siblings of page j.",
                "Typically, the size of this set is bounded by a constant.",
                "Finally, for each page j, the scores vector is updated over the set of non-zero components k of the vector x with k ∈ L. This set has size equal to the number of local siblings of page j, and is a subset of the total number of siblings of page j.",
                "Thus, each iteration of the main loop takes constant time, and the total running time of the main loop is O( ).",
                "Since we have assumed that the size of F will not grow larger than O(n), the total running time for the algorithm is O(n).",
                "Algorithm 3: Node Selection via Stochastic Complementation.",
                "SC-Select(F , Fout, f, k) Input: F : zero-one adjacency matrix of size corresponding to the current local subgraph, Fout: zero-one outlink matrix from F to global subgraph, f: PageRank of F , k: number of pages to return Output: pages: set of k pages to crawl next {Compute outlink sums for local subgraph} foreach (page j ∈ F ) o[j] ← k:(j,k)∈F F[j, k] end {Compute scalar ˜uT j f for each global node j } foreach (page j ∈ Fout) g[j] ← (1 − α) 1 +1 foreach (page k : (k, j) ∈ Fout) g[j] ← g[j] + α f[k] o[k]+1 end end {Compute vectors y and z as in (17) and (18) } y ← −(1 − α) e ( +1) z ← (1 − w)−1 ˜s {Approximate y + g[j] ∗ z 1 for all values g[j]} norm diffs ←L1NormDiffs(g, ELy, ELz) foreach (page j ∈ Fout) {Compute sparse vector x as in (19)} x ← 0 foreach (page k : (k, j) ∈ Fout) foreach (page k : (k, k ) ∈ F )) x[k ] ← x[k ] − f[k] o[k](o[k]+1) end end x ← αx scores[j] ← norm diffs[j] foreach (k : x[k] > 0 and page k ∈ L) scores[j] ← scores[j] − |y[k] + g[j] ∗ z[k]| +|x[k]+y[k]+g[j]∗z[k])| end end Return k pages with highest scores 5.2.2 PageRank Flows We now present an intuitive analysis of the stochastic complementation method by decomposing the change in PageRank in terms of leaks and flows.",
                "This analysis is motivated by the decomposition given in (15).",
                "PageRank flow is the increase in the local PageRanks originating from global page j.",
                "The flows are represented by the non-negative vector (˜uT j f)z (equations (15) and (18)).",
                "The scalar ˜uT j f can be thought of as the total amount of PageRank flow that page j has available to distribute.",
                "The vector z dictates how the flow is allocated to the local domain; the flow that local page k receives is proportional to (within a constant factor due to the random surfer vector) the expected number of its inlinks.",
                "The PageRank leaks represent the decrease in PageRank resulting from the addition of page j.",
                "The leakage can be quantified in terms of the non-positive vectors x and y (equations (16) and (17)).",
                "For vector x, we can see from equation (19) that the amount of PageRank leaked by a local page is proportional to the weighted sum of the Page121 Research Track Paper Ranks of its siblings.",
                "Thus, pages that have siblings with higher PageRanks (and low outlink counts) will experience more leakage.",
                "The leakage caused by y is an artifact of the random surfer vector.",
                "We will next show that if only the flow term, (˜uT j f)z, is considered, then the resulting method is very similar to a heuristic proposed by Cho et al. [6] that has been widely used for the Crawling Through URL Ordering problem.",
                "This heuristic is computationally cheaper, but as we will see later, not as effective as the Stochastic Complementation method.",
                "Our node selection strategy chooses global nodes that have the largest influence (equation (7)).",
                "If this influence is approximated using only flows, the optimal node j∗ is: j∗ = argmaxj EL ˜uT j fz 1 = argmaxj ˜uT j f EL z 1 = argmaxj ˜uT j f = argmaxj α(DF + diag(uj))−1 uj + (1 − α) e + 1 , f = argmaxjfT (DF + diag(uj))−1 uj.",
                "The resulting page selection score can be expressed as a sum of the PageRanks of each local page k that links to j, where each PageRank value is normalized by o[k]+1.",
                "Interestingly, the normalization that arises in our method differs from the heuristic given in [6], which normalizes by o[k].",
                "The algorithm PF-Select, which is omitted due to lack of space, first computes the quantity fT (DF +diag(uj))−1 uj for each global page j, and then returns the pages with the k largest scores.",
                "To see that the running time for this algorithm is O(n), note that the computation involved in this method is a subset of that needed for the SC-Select method (Algorithm 3), which was shown to have a running time of O(n). 6.",
                "EXPERIMENTS In this section, we provide experimental evidence to verify the effectiveness of our algorithms.",
                "We first outline our experimental methodology and then provide results across a variety of local domains. 6.1 Methodology Given the limited resources available at an academic institution, crawling a section of the web that is of the same magnitude as that indexed by Google or Yahoo! is clearly infeasible.",
                "Thus, for a given local domain, we approximate the <br>global graph</br> by crawling a local neighborhood around the domain that is several orders of magnitude larger than the local subgraph.",
                "Even though such a graph is still orders of magnitude smaller than the true <br>global graph</br>, we contend that, even if there exist some highly influential pages that are very far away from our local domain, it is unrealistic for any local node selection algorithm to find them.",
                "Such pages also tend to be highly unrelated to pages within the local domain.",
                "When explaining our node selection strategies in section 5, we made the simplifying assumption that our local graph contained no dangling nodes.",
                "This assumption was only made to ease our analysis.",
                "Our implementation efficiently handles dangling links by replacing each zero column of our adjacency matrix with the uniform vector.",
                "We evaluate the algorithm using the two node selection strategies given in Section 5.2, and also against the following baseline methods: • Random: Nodes are chosen uniformly at random among the known global nodes. • OutlinkCount: Global nodes with the highest number of outlinks from the local domain are chosen.",
                "At each iteration of the FindGlobalPR algorithm, we evaluate performance by computing the difference between the current PageRank estimate of the local domain, ELf ELf 1 , and the global PageRank of the local domain ELg ELg 1 .",
                "All PageRank calculations were performed using the uniform random surfer vector.",
                "Across all experiments, we set the random surfer parameter α, to be .85, and used a convergence threshold of 10−6 .",
                "We evaluate the difference between the local and global PageRank vectors using three different metrics: the L1 and L∞ norms, and Kendalls tau.",
                "The L1 norm measures the sum of the absolute value of the differences between the two vectors, and the L∞ norm measures the absolute value of the largest difference.",
                "Kendalls tau metric is a popular rank correlation measure used to compare PageRanks [2, 11].",
                "This metric can be computed by counting the number of pairs of pairs that agree in ranking, and subtracting from that the number of pairs of pairs that disagree in ranking.",
                "The final value is then normalized by the total number of n 2 such pairs, resulting in a [−1, 1] range, where a negative score signifies anti-correlation among rankings, and values near one correspond to strong rank correlation. 6.2 Results Our experiments are based on two large web crawls and were downloaded using the web crawler that is part of the Nutch open source search engine project [18].",
                "All crawls were restricted to only http pages, and to limit the number of dynamically generated pages that we crawl, we ignored all pages with urls containing any of the characters ?, *, @, or =.",
                "The first crawl, which we will refer to as the edu dataset, was seeded by homepages of the top 100 graduate computer science departments in the USA, as rated by the US News and World Report [16], and also by the home pages of their respective institutions.",
                "A crawl of depth 5 was performed, restricted to pages within the .edu domain, resulting in a graph with approximately 4.7 million pages and 22.9 million links.",
                "The second crawl was seeded by the set of pages under the politics hierarchy in the dmoz open directory project[17].",
                "We crawled all pages up to four links away, which yielded a graph with 4.4 million pages and 17.3 million links.",
                "Within the edu crawl, we identified the five site-specific domains corresponding to the websites of the top five graduate computer science departments, as ranked by the US News and World Report.",
                "This yielded local domains of various sizes, from 10,626 (UIUC) to 59,895 (Berkeley).",
                "For each of these site-specific domains with size n, we performed 50 iterations of the FindGlobalPR algorithm to crawl a total of 2n additional nodes.",
                "Figure 2(a) gives the (L1) difference from the PageRank estimate at each iteration to the global PageRank, for the Berkeley local domain.",
                "The performance of this dataset was representative of the typical performance across the five computer science sitespecific local domains.",
                "Initially, the L1 difference between the global and local PageRanks ranged from .0469 (Stanford) to .149 (MIT).",
                "For the first several iterations, the 122 Research Track Paper 0 5 10 15 20 25 30 35 40 45 50 0.015 0.02 0.025 0.03 0.035 0.04 0.045 0.05 0.055 Number of Iterations GlobalandLocalPageRankDifference(L1) Stochastic Complement PageRank Flow Outlink Count Random 0 10 20 30 40 50 0 0.05 0.1 0.15 0.2 0.25 0.3 0.35 Number of Iterations GlobalandLocalPageRankDifference(L1) Stochastic Complement PageRank Flow Outlink Count Random 0 5 10 15 20 25 0.16 0.18 0.2 0.22 0.24 0.26 0.28 0.3 0.32 0.34 Number of Iterations GlobalandLocalPageRankDifference(L1) Stochastic Complement PageRank Flow Outlink Count Random (a) www.cs.berkeley.edu (b) www.enterstageright.com (c) Politics Figure 2: L1 difference between the estimated and true global PageRanks for (a) Berkeleys computer science website, (b) the site-specific domain, www.enterstageright.com, and (c) the politics topic-specific domain.",
                "The stochastic complement method outperforms all other methods across various domains. three link-based methods all outperform the random selection heuristic.",
                "After these initial iterations, the random heuristic tended to be more competitive with (or even outperform, as in the Berkeley local domain) the outlink count and PageRank flow heuristics.",
                "In all tests, the stochastic complementation method either outperformed, or was competitive with, the other methods.",
                "Table 1 gives the average difference between the final estimated global PageRanks and the true global PageRanks for various distance measures.",
                "Algorithm L1 L∞ Kendall Stoch.",
                "Comp. .0384 .00154 .9257 PR Flow .0470 .00272 .8946 Outlink .0419 .00196 .9053 Random .0407 .00204 .9086 Table 1: Average final performance of various node selection strategies for the five site-specific computer science local domains.",
                "Note that Kendalls Tau measures similarity, while the other metrics are dissimilarity measures.",
                "Stochastic Complementation clearly outperforms the other methods in all metrics.",
                "Within the politics dataset, we also performed two sitespecific tests for the largest websites in the crawl: www.adamsmith.org, the website for the London based Adam Smith Institute, and www.enterstageright.com, an online conservative journal.",
                "As with the edu local domains, we ran our algorithm for 50 iterations, crawling a total of 2n nodes.",
                "Figure 2 (b) plots the results for the www.enterstageright.com domain.",
                "In contrast to the edu local domains, the Random and OutlinkCount methods were not competitive with either the SC-Select or the PF-Select methods.",
                "Among all datasets and all node selection methods, the stochastic complementation method was most impressive in this dataset, realizing a final estimate that differed only .0279 from the global PageRank, a ten-fold improvement over the initial local PageRank difference of .299.",
                "For the Adam Smith local domain, the initial difference between the local and global PageRanks was .148, and the final estimates given by the SC-Select, PF-Select, OutlinkCount, and Random methods were .0208, .0193, .0222, and .0356, respectively.",
                "Within the politics dataset, we constructed four topicspecific local domains.",
                "The first domain consisted of all pages in the dmoz politics category, and also all pages within each of these sites up to two links away.",
                "This yielded a local domain of 90,811 pages, and the results are given in figure 2 (c).",
                "Because of the larger size of the topic-specific domains, we ran our algorithm for only 25 iterations to crawl a total of n nodes.",
                "We also created topic-specific domains from three political sub-topics: liberalism, conservatism, and socialism.",
                "The pages in these domains were identified by their corresponding dmoz categories.",
                "For each sub-topic, we set the local domain to be all pages within three links from the corresponding dmoz category pages.",
                "Table 2 summarizes the performance of these three topic-specific domains, and also the larger political domain.",
                "To quantify a global page js effect on the global PageRank values of pages in the local domain, we define page js impact to be its PageRank value, g[j], normalized by the fraction of its outlinks pointing to the local domain: impact(j) = oL[j] o[j] · g[j], where, oL[j] is the number of outlinks from page j to pages in the local domain L, and o[j] is the total number of js outlinks.",
                "In terms of the random surfer model, the impact of page j is the probability that the random surfer (1) is currently at global page j in her random walk and (2) takes an outlink to a local page, given that she has already decided not to jump to a random page.",
                "For the politics local domain, we found that many of the pages with high impact were in fact political pages that should have been included in the dmoz politics topic, but were not.",
                "For example, the two most influential global pages were the political search engine www.askhenry.com, and the home page of the online political magazine, www.policyreview.com.",
                "Among non-political pages, the home page of the journal Education Next was most influential.",
                "The journal is freely available online and contains articles regarding various aspect of K-12 education in America.",
                "To provide some anecdotal evidence for the effectiveness of our page selection methods, we note that the SC-Select method chose 11 pages within the www.educationnext.org domain, the PF-Select method discovered 7 such pages, while the OutlinkCount and Random methods found only 6 pages each.",
                "For the conservative political local domain, the socialist website www.ornery.org had a very high impact score.",
                "This 123 Research Track Paper All Politics: Algorithm L1 L2 Kendall Stoch.",
                "Comp. .1253 .000700 .8671 PR Flow .1446 .000710 .8518 Outlink .1470 .00225 .8642 Random .2055 .00203 .8271 Conservativism: Algorithm L1 L2 Kendall Stoch.",
                "Comp. .0496 .000990 .9158 PR Flow .0554 .000939 .9028 Outlink .0602 .00527 .9144 Random .1197 .00102 .8843 Liberalism: Algorithm L1 L2 Kendall Stoch.",
                "Comp. .0622 .001360 .8848 PR Flow .0799 .001378 .8669 Outlink .0763 .001379 .8844 Random .1127 .001899 .8372 Socialism: Algorithm L1 L∞ Kendall Stoch.",
                "Comp. .04318 .00439 .9604 PR Flow .0450 .004251 .9559 Outlink .04282 .00344 .9591 Random .0631 .005123 .9350 Table 2: Final performance among node selection strategies for the four political topic-specific crawls.",
                "Note that Kendalls Tau measures similarity, while the other metrics are dissimilarity measures. was largely due to a link from the front page of this site to an article regarding global warming published by the National Center for Public Policy Research, a conservative research group in Washington, DC.",
                "Not surprisingly, the global PageRank of this article (which happens to be on the home page of the NCCPR, www.nationalresearch.com), was approximately .002, whereas the local PageRank of this page was only .00158.",
                "The SC-Select method yielded a global PageRank estimate of approximately .00182, the PFSelect method estimated a value of .00167, and the Random and OutlinkCount methods yielded values of .01522 and .00171, respectively. 7.",
                "RELATED WORK The node selection framework we have proposed is similar to the url ordering for crawling problem proposed by Cho et al. in [6].",
                "Whereas our framework seeks to minimize the difference between the global and local PageRank, the objective used in [6] is to crawl the most highly (globally) ranked pages first.",
                "They propose several node selection algorithms, including the outlink count heuristic, as well as a variant of our PF-Select algorithm which they refer to as the PageRank ordering metric.",
                "They found this method to be most effective in optimizing their objective, as did a recent survey of these methods by Baeza-Yates et al. [1].",
                "Boldi et al. also experiment within a similar crawling framework in [2], but quantify their results by comparing Kendalls rank correlation between the PageRanks of the current set of crawled pages and those of the entire <br>global graph</br>.",
                "They found that node selection strategies that crawled pages with the highest global PageRank first actually performed worse (with respect to Kendalls Tau correlation between the local and global PageRanks) than basic depth first or breadth first strategies.",
                "However, their experiments differ from our work in that our node selection algorithms do not use (or have access to) global PageRank values.",
                "Many algorithmic improvements for computing exact PageRank values have been proposed [9, 10, 14].",
                "If such algorithms are used to compute the global PageRanks of our local domain, they would all require O(N) computation, storage, and bandwidth, where N is the size of the global domain.",
                "This is in contrast to our method, which approximates the global PageRank and scales linearly with the size of the local domain.",
                "Wang and Dewitt [22] propose a system where the set of web servers that comprise the global domain communicate with each other to compute their respective global PageRanks.",
                "For a given web server hosting n pages, the computational, bandwidth, and storage requirements are also linear in n. One drawback of this system is that the number of distinct web servers that comprise the global domain can be very large.",
                "For example, our edu dataset contains websites from over 3,200 different universities; coordinating such a system among a large number of sites can be very difficult.",
                "Gan, Chen, and Suel propose a method for estimating the PageRank of a single page [5] which uses only constant bandwidth, computation, and space.",
                "Their approach relies on the availability of a remote connectivity server that can supply the set of inlinks to a given page, an assumption not used in our framework.",
                "They experimentally show that a reasonable estimate of the nodes PageRank can be obtained by visiting at most a few hundred nodes.",
                "Using their algorithm for our problem would require that either the entire global domain first be downloaded or a connectivity server be used, both of which would lead to very large web graphs. 8.",
                "CONCLUSIONS AND FUTURE WORK The internet is growing exponentially, and in order to navigate such a large repository as the web, global search engines have established themselves as a necessity.",
                "Along with the ubiquity of these large-scale search engines comes an increase in search users expectations.",
                "By providing complete and isolated coverage of a particular web domain, localized search engines are an effective outlet to quickly locate content that could otherwise be difficult to find.",
                "In this work, we contend that the use of global PageRank in a localized search engine can improve performance.",
                "To estimate the global PageRank, we have proposed an iterative node selection framework where we select which pages from the global frontier to crawl next.",
                "Our primary contribution is our stochastic complementation page selection algorithm.",
                "This method crawls nodes that will most significantly impact the local domain and has running time linear in the number of nodes in the local domain.",
                "Experimentally, we validate these methods across a diverse set of local domains, including seven site-specific domains and four topic-specific domains.",
                "We conclude that by crawling an additional n or 2n pages, our methods find an estimate of the global PageRanks that is up to ten times better than just using the local PageRanks.",
                "Furthermore, we demonstrate that our algorithm consistently outperforms other existing heuristics. 124 Research Track Paper Often times, topic-specific domains are discovered using a focused web crawler which considers a pages content in conjunction with link anchor text to decide which pages to crawl next [4].",
                "Although such crawlers have proven to be quite effective in discovering topic-related content, many irrelevant pages are also crawled in the process.",
                "Typically, these pages are deleted and not indexed by the localized search engine.",
                "These pages can of course provide valuable information regarding the global PageRank of the local domain.",
                "One way to integrate these pages into our framework is to start the FindGlobalPR algorithm with the current subgraph F equal to the set of pages that were crawled by the focused crawler.",
                "The global PageRank estimation framework, along with the node selection algorithms presented, all require O(n) computation per iteration and bandwidth proportional to the number of pages crawled, Tk.",
                "If the number of iterations T is relatively small compared to the number of pages crawled per iteration, k, then the bottleneck of the algorithm will be the crawling phase.",
                "However, as the number of iterations increases (relative to k), the bottleneck will reside in the node selection computation.",
                "In this case, our algorithms would benefit from constant factor optimizations.",
                "Recall that the FindGlobalPR algorithm (Algorithm 2) requires that the PageRanks of the current expanded local domain be recomputed in each iteration.",
                "Recent work by Langville and Meyer [12] gives an algorithm to quickly recompute PageRanks of a given webgraph if a small number of nodes are added.",
                "This algorithm was shown to give speedup of five to ten times on some datasets.",
                "We plan to investigate this and other such optimizations as future work.",
                "In this paper, we have objectively evaluated our methods by measuring how close our global PageRank estimates are to the actual global PageRanks.",
                "To determine the benefit of using global PageRanks in a localized search engine, we suggest a user study in which users are asked to rate the quality of search results for various search queries.",
                "For some queries, only the local PageRanks are used in ranking, and for the remaining queries, local PageRanks and the approximate global PageRanks, as computed by our algorithms, are used.",
                "The results of such a study can then be analyzed to determine the added benefit of using the global PageRanks computed by our methods, over just using the local PageRanks.",
                "Acknowledgements.",
                "This research was supported by NSF grant CCF-0431257, NSF Career Award ACI-0093404, and a grant from Sabre, Inc. 9.",
                "REFERENCES [1] R. Baeza-Yates, M. Marin, C. Castillo, and A. Rodriguez.",
                "Crawling a country: better strategies than breadth-first for web page ordering.",
                "World-Wide Web Conference, 2005. [2] P. Boldi, M. Santini, and S. Vigna.",
                "Do your worst to make the best: paradoxical effects in pagerank incremental computations.",
                "Workshop on Web Graphs, 3243:168-180, 2004. [3] S. Brin and L. Page.",
                "The anatomy of a large-scale hypertextual web search engine.",
                "Computer Networks and ISDN Systems, 33(1-7):107-117, 1998. [4] S. Chakrabarti, M. van den Berg, and B. Dom.",
                "Focused crawling: a new approach to topic-specific web resource discovery.",
                "World-Wide Web Conference, 1999. [5] Y. Chen, Q. Gan, and T. Suel.",
                "Local methods for estimating pagerank values.",
                "Conference on Information and Knowledge Management, 2004. [6] J. Cho, H. Garcia-Molina, and L. Page.",
                "Efficient crawling through url ordering.",
                "World-Wide Web Conference, 1998. [7] T. H. Haveliwala and S. D. Kamvar.",
                "The second eigenvalue of the Google matrix.",
                "Technical report, Stanford University, 2003. [8] T. Joachims, F. Radlinski, L. Granka, A. Cheng, C. Tillekeratne, and A. Patel.",
                "Learning retrieval functions from implicit feedback. http://www.cs.cornell.edu/People/tj/career. [9] S. D. Kamvar, T. H. Haveliwala, C. D. Manning, and G. H. Golub.",
                "Exploiting the block structure of the web for computing pagerank.",
                "World-Wide Web Conference, 2003. [10] S. D. Kamvar, T. H. Haveliwala, C. D. Manning, and G. H. Golub.",
                "Extrapolation methods for accelerating pagerank computation.",
                "World-Wide Web Conference, 2003. [11] A. N. Langville and C. D. Meyer.",
                "Deeper inside pagerank.",
                "Internet Mathematics, 2004. [12] A. N. Langville and C. D. Meyer.",
                "Updating the stationary vector of an irreducible markov chain with an eye on Googles pagerank.",
                "SIAM Journal on Matrix Analysis, 2005. [13] P. Lyman, H. R. Varian, K. Swearingen, P. Charles, N. Good, L. L. Jordan, and J. Pal.",
                "How much information 2003?",
                "School of Information Management and System, University of California at Berkely, 2003. [14] F. McSherry.",
                "A uniform approach to accelerated pagerank computation.",
                "World-Wide Web Conference, 2005. [15] C. D. Meyer.",
                "Stochastic complementation, uncoupling markov chains, and the theory of nearly reducible systems.",
                "SIAM Review, 31:240-272, 1989. [16] US News and World Report. http://www.usnews.com. [17] Dmoz open directory project. http://www.dmoz.org. [18] Nutch open source search engine. http://www.nutch.org. [19] F. Radlinski and T. Joachims.",
                "Query chains: learning to rank from implicit feedback.",
                "ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, 2005. [20] S. Raghavan and H. Garcia-Molina.",
                "Crawling the hidden web.",
                "In Proceedings of the Twenty-seventh International Conference on Very Large Databases, 2001. [21] T. Tin Tang, D. Hawking, N. Craswell, and K. Griffiths.",
                "Focused crawling for both topical relevance and quality of medical information.",
                "Conference on Information and Knowledge Management, 2005. [22] Y. Wang and D. J. DeWitt.",
                "Computing pagerank in a distributed internet search system.",
                "Proceedings of the 30th VLDB Conference, 2004. 125 Research Track Paper"
            ],
            "original_annotated_samples": [
                "As defined in equation (1), PG is the PageRank matrix formed from the <br>global graph</br> G, and we define the global PageRank vector of this graph to be g. Let the n-length vector p∗ be the L1-normalized vector corresponding to the global PageRank of the pages in the local domain L: p∗ = EL g ELg 1 , where EL = [ I | 0 ] is the restriction matrix that selects the components from g corresponding to nodes in L. Let p denote the PageRank vector constructed from the local domain subgraph L. In practice, the observed local PageRank p and the global PageRank p∗ will be quite different.",
                "Thus, for a given local domain, we approximate the <br>global graph</br> by crawling a local neighborhood around the domain that is several orders of magnitude larger than the local subgraph.",
                "Even though such a graph is still orders of magnitude smaller than the true <br>global graph</br>, we contend that, even if there exist some highly influential pages that are very far away from our local domain, it is unrealistic for any local node selection algorithm to find them.",
                "Boldi et al. also experiment within a similar crawling framework in [2], but quantify their results by comparing Kendalls rank correlation between the PageRanks of the current set of crawled pages and those of the entire <br>global graph</br>."
            ],
            "translated_annotated_samples": [
                "Como se define en la ecuación (1), PG es la matriz de PageRank formada a partir del <br>grafo global</br> G, y definimos el vector de PageRank global de este grafo como g. Sea el vector de longitud n p∗ el vector L1-normalizado que corresponde al PageRank global de las páginas en el dominio local L: p∗ = EL g ELg 1 , donde EL = [ I | 0 ] es la matriz de restricción que selecciona los componentes de g correspondientes a los nodos en L. Sea p el vector de PageRank construido a partir del subgrafo del dominio local L. En la práctica, el PageRank local observado p y el PageRank global p∗ serán bastante diferentes.",
                "Por lo tanto, para un dominio local dado, aproximamos el <br>grafo global</br> rastreando un vecindario local alrededor del dominio que es varias órdenes de magnitud más grande que el subgrafo local.",
                "A pesar de que dicho gráfico sigue siendo órdenes de magnitud más pequeño que el verdadero <br>gráfico global</br>, sostenemos que, incluso si existen algunas páginas altamente influyentes que están muy lejos de nuestro dominio local, es poco realista que cualquier algoritmo de selección de nodos locales las encuentre.",
                "Boldi et al. también experimentan dentro de un marco de rastreo similar en [2], pero cuantifican sus resultados al comparar la correlación de rangos de Kendall entre los PageRanks del conjunto actual de páginas rastreadas y los del <br>grafo global</br> completo."
            ],
            "translated_text": "Estimando el PageRank Global de Comunidades Web Jason V. Davis Dept. Departamento de Ciencias de la Computación Universidad de Texas en Austin Austin, TX 78712 jdavis@cs.utexas.edu Inderjit S. Dhillon Departamento de Ciencias de la Computación Universidad de Texas en Austin Austin, TX 78712 inderjit@cs.utexas.edu RESUMEN Los motores de búsqueda localizados son sistemas a pequeña escala que indexan una comunidad particular en la web. Ofrecen varios beneficios en comparación con sus contrapartes a gran escala, ya que son relativamente económicos de construir y pueden proporcionar una capacidad de búsqueda más precisa y completa en sus dominios relevantes. Una desventaja que tienen estos sistemas en comparación con los motores de búsqueda a gran escala es la falta de valores globales de PageRank. Se necesita esa información para evaluar el valor de las páginas en el dominio de búsqueda localizada dentro del contexto de la web en su totalidad. En este artículo, presentamos algoritmos bien fundamentados para estimar los valores globales de PageRank de un dominio local. Los algoritmos son altamente escalables en el sentido de que, dado un dominio local de tamaño n, utilizan recursos de O(n) que incluyen tiempo de computación, ancho de banda y almacenamiento. Probamos nuestros métodos en una variedad de dominios localizados, incluyendo dominios específicos del sitio y dominios específicos del tema. Demostramos que al rastrear tan solo n o 2n páginas adicionales, nuestros métodos pueden proporcionar excelentes estimaciones globales de PageRank. Categorías y Descriptores de Asignaturas H.3.3 [Almacenamiento y Recuperación de Información]: Búsqueda y Recuperación de Información; G.1.3 [Análisis Numérico]: Álgebra Lineal Numérica; G.3 [Probabilidad y Estadística]: Procesos de Markov Términos Generales PageRank, Cadena de Markov, Complementación Estocástica. Los motores de búsqueda localizados son motores de búsqueda a pequeña escala que indexan solo una comunidad específica de la web. Tales comunidades pueden ser dominios específicos del sitio, como páginas dentro del dominio cs.utexas.edu, o comunidades relacionadas con un tema, por ejemplo, sitios web políticos. En comparación con el grafo web rastreado e indexado por los motores de búsqueda a gran escala, el tamaño de estas comunidades locales suele ser típicamente órdenes de magnitud más pequeño. Por consiguiente, los recursos computacionales necesarios para construir un motor de búsqueda de este tipo también son igualmente más ligeros. Al restringirse a secciones más pequeñas y manejables de la web, los motores de búsqueda localizados también pueden ofrecer capacidades de búsqueda más precisas y completas dentro de sus respectivos dominios. Una desventaja de los índices localizados es la falta de información global necesaria para calcular clasificaciones basadas en enlaces. El algoritmo PageRank [3] ha demostrado ser una medida efectiva de este tipo. En general, el PageRank de una página dada depende de las páginas en todo el grafo web. En el contexto de un motor de búsqueda localizado, si los PageRanks se calculan utilizando solo el subgrafo local, entonces esperaríamos que los PageRanks resultantes reflejen la popularidad percibida dentro de la comunidad local y no de la web en su totalidad. Por ejemplo, consideremos un motor de búsqueda localizado que indexa páginas políticas con puntos de vista conservadores. Una persona que desee investigar las opiniones sobre el calentamiento global dentro de la comunidad política conservadora puede encontrarse con numerosas opiniones de este tipo en varios sitios web. Si solo se dispone de valores de PageRank locales, entonces los resultados de búsqueda reflejarán solo creencias fuertemente arraigadas dentro de la comunidad. Sin embargo, si los PageRanks globales también están disponibles, entonces los resultados pueden reflejar adicionalmente las opiniones de los externos sobre la comunidad conservadora (es decir, aquellos documentos a los que los liberales acceden con mayor frecuencia dentro de la comunidad conservadora). Por lo tanto, para muchos motores de búsqueda localizados, la incorporación de PageRanks globales puede mejorar la calidad de los resultados de búsqueda. Sin embargo, el número de páginas que indexa un motor de búsqueda local suele ser órdenes de magnitud más pequeño que el número de páginas indexadas por sus contrapartes a gran escala. Los motores de búsqueda localizados no tienen el ancho de banda, la capacidad de almacenamiento o la potencia computacional para rastrear, descargar y calcular los PageRanks globales de toda la web. En este trabajo, presentamos un método para aproximar los PageRanks globales de un dominio local utilizando recursos del mismo orden que los necesarios para calcular los PageRanks del subgrafo local. Nuestro método propuesto busca un supergrafo de nuestro subgrafo local de manera que los PageRanks locales dentro de este supergrafo estén cerca de los verdaderos PageRanks globales. Construimos este supergrafo mediante el rastreo iterativo de páginas globales en la frontera web actual, es decir, páginas globales con enlaces entrantes de páginas que ya han sido rastreadas. Para proporcionar a 116 Research Track Paper una buena aproximación a los PageRanks globales, es necesario tener cuidado al elegir qué páginas rastrear a continuación; en este documento, presentamos un algoritmo de selección de páginas bien fundamentado que también tiene un buen rendimiento empírico. Este algoritmo se deriva de un objetivo de problema bien definido y tiene un tiempo de ejecución lineal en el número de nodos locales. Experimentamos en varios tipos de subgrafos locales, incluidas cuatro comunidades relacionadas con el tema y varios dominios específicos del sitio. Para evaluar el rendimiento, medimos la diferencia entre la estimación actual del PageRank global y el PageRank global, en función del número de páginas rastreadas. Comparamos nuestro algoritmo con varios heurísticos y también con un algoritmo base que elige páginas al azar, y demostramos que nuestro método supera a estos otros métodos. Finalmente, demostramos empíricamente que, dado un dominio local de tamaño n, podemos proporcionar buenas aproximaciones a los valores globales de PageRank rastreando como máximo n o 2n páginas adicionales. El documento está organizado de la siguiente manera. La sección 2 ofrece una visión general de los motores de búsqueda localizados y destaca sus ventajas sobre los motores de búsqueda globales. La sección 3 proporciona antecedentes sobre el algoritmo PageRank. La sección 4 define formalmente nuestro problema, y la sección 5 presenta nuestros criterios de selección de páginas y deriva nuestros algoritmos. La sección 6 presenta los resultados experimentales, la sección 7 ofrece una visión general del trabajo relacionado y, finalmente, las conclusiones se presentan en la sección 8. MOTORES DE BÚSQUEDA LOCALIZADOS Los motores de búsqueda localizados indexan una sola comunidad de la web, típicamente una comunidad específica del sitio o una comunidad específica del tema. Los motores de búsqueda localizados disfrutan de tres ventajas principales sobre sus contrapartes a gran escala: son relativamente económicos de construir, pueden ofrecer una capacidad de búsqueda más precisa dentro de su dominio local y pueden proporcionar un índice más completo. Los recursos necesarios para construir un motor de búsqueda global son enormes. Un estudio de 2003 realizado por Lyman et al. [13] encontró que la web superficial (sitios estáticos de acceso público) consta de 8.9 mil millones de páginas, y que el tamaño promedio de estas páginas es de aproximadamente 18.7 kilobytes. Para descargar un rastreo de este tamaño, se necesita aproximadamente 167 terabytes de espacio. Para un investigador que desee construir un motor de búsqueda con acceso a un par de estaciones de trabajo o un servidor pequeño, un almacenamiento de esta magnitud simplemente no está disponible. Sin embargo, construir un motor de búsqueda localizado sobre una comunidad web de cien mil páginas solo requeriría unos pocos gigabytes de almacenamiento. La carga computacional necesaria para soportar consultas de búsqueda sobre una base de datos de este tamaño es más manejable también. Observamos que, para los motores de búsqueda específicos de un tema, la comunidad relevante puede ser identificada y descargada de manera eficiente utilizando un rastreador enfocado [21, 4]. Para dominios específicos del sitio, el dominio local está fácilmente disponible en su propio servidor web. Esto evita la necesidad de rastreo o indexación, y por lo tanto se puede garantizar un índice completo y actualizado del dominio. Esto contrasta con sus contrapartes a gran escala, las cuales sufren de varias deficiencias. Primero, el rastreo de páginas generadas dinámicamente en la web oculta ha sido objeto de investigación [20] y es una tarea no trivial para un rastreador externo. En segundo lugar, los dominios específicos del sitio pueden habilitar la política de exclusión de robots. Esto prohíbe a los rastreadores de motores de búsqueda externos descargar contenido del dominio, y en su lugar un motor de búsqueda externo debe depender de enlaces externos y texto ancla para indexar estas páginas restringidas. Al restringirse a un dominio específico de internet, un motor de búsqueda localizado puede proporcionar resultados de búsqueda más precisos. Considera la consulta de búsqueda ambigua canónica, jaguar, que puede referirse tanto al fabricante de automóviles como al animal. Un científico que intenta investigar el hábitat y la historia evolutiva de un jaguar puede tener más éxito utilizando un motor de búsqueda específico de zoología bien ajustado que consultando Google con múltiples búsquedas de palabras clave y navegando a través de resultados irrelevantes. Recientemente se propuso un método para aprender funciones de clasificación mejores para la recuperación por Radlinski y Joachims [19] y se ha aplicado a varios dominios locales, incluido el sitio web de la Universidad de Cornell [8]. 3. PAGERANK RESUMEN El algoritmo PageRank define la importancia de las páginas web analizando la estructura de hipervínculos subyacente de un grafo web. El algoritmo funciona construyendo una cadena de Markov a partir de la estructura de enlaces del grafo web y calculando su distribución estacionaria. Una forma de calcular la distribución estacionaria de una cadena de Markov es encontrar la distribución límite de un paseo aleatorio sobre la cadena. Por lo tanto, el algoritmo PageRank utiliza lo que a veces se conoce como el modelo del surfista aleatorio. En cada paso de la caminata aleatoria, el surfista sigue un enlace de salida de la página actual (es decir, el nodo actual en la cadena), o salta a una página aleatoria en la web. Ahora definimos con precisión el problema de PageRank. Sea U una matriz de adyacencia m × m para un grafo web dado tal que Uji = 1 si la página i enlaza a la página j y Uji = 0 en caso contrario. Definimos la matriz de PageRank PU como: PU = αUD−1 U + (1 − α)veT , (1) donde DU es la matriz diagonal (única) tal que UD−1 U es estocástica por columnas, α es un escalar dado tal que 0 ≤ α ≤ 1, e es el vector de todos unos, y v es un vector no negativo, L1-normalizado, a veces llamado vector de navegante aleatorio. Ten en cuenta que la matriz D−1 U está bien definida solo si cada columna de U tiene al menos una entrada distinta de cero, es decir, cada página en el grafo web tiene al menos un enlace de salida. En presencia de nodos colgantes que no tienen enlaces de salida, una solución comúnmente utilizada, propuesta por Brin et al. [3], es reemplazar cada columna de ceros de U por un vector no negativo, normalizado en L1. El vector PageRank r es el eigenvector dominante de la matriz PageRank, r = PU r. Supondremos, sin pérdida de generalidad, que r tiene una norma L1 de uno. Computacionalmente, r se puede calcular utilizando el método de la potencia. Este método primero elige un vector inicial aleatorio r(0) y, de forma iterativa, multiplica el vector actual por la matriz de PageRank PU; ver Algoritmo 1. En general, cada iteración del método de la potencia puede requerir O(m2) operaciones cuando PU es una matriz densa. Sin embargo, en la práctica, el número de enlaces en un grafo web será del orden del número de páginas. Al explotar la dispersión de la matriz de PageRank, el trabajo por iteración se puede reducir a O(km), donde k es el número promedio de enlaces por página web. También se ha demostrado que el número total de iteraciones necesarias para la convergencia es proporcional a α y no depende del tamaño del grafo web [11, 7]. Finalmente, el espacio total necesario también es O(km), principalmente para almacenar la matriz U. 117 Research Track Paper Algorithm 1: Un algoritmo de tiempo lineal (por iteración) para calcular PageRank. CalcularPR(U) Entrada: U: Matriz de adyacencia. Salida: vector de PageRank. Elige (aleatoriamente) un vector inicial no negativo r(0) tal que r(0) 1 = 1. i ← 0 repetir i ← i + 1 ν ← αUD−1 U r(i−1) {α es la probabilidad de navegación aleatoria} r(i) ← ν + (1 − α)v {v es el vector del navegante aleatorio.} hasta que r(i) − r(i−1) < δ {δ es el umbral de convergencia.} r ← r(i) 4. Dada un dominio local L, sea G una matriz de adyacencia N × N para el componente conectado completo de la web que contiene L, tal que Gji = 1 si la página i enlaza a la página j y Gji = 0 en caso contrario. Sin pérdida de generalidad, vamos a dividir G de la siguiente manera: G = L Gout Lout Gwithin, donde L es el subgrafo local de n × n correspondiente a los enlaces dentro del dominio local, Lout es el subgrafo que corresponde a los enlaces desde el dominio local apuntando hacia el dominio global, Gout es el subgrafo que contiene los enlaces desde el dominio global hacia el dominio local, y Gwithin contiene los enlaces dentro del dominio global. Suponemos que al construir un motor de búsqueda localizado, solo se rastrean las páginas dentro del dominio local, y los enlaces entre estas páginas están representados por el subgrafo L. También se conocen los enlaces en Lout, ya que estos apuntan desde las páginas rastreadas en el dominio local a las páginas no rastreadas en el dominio global. Como se define en la ecuación (1), PG es la matriz de PageRank formada a partir del <br>grafo global</br> G, y definimos el vector de PageRank global de este grafo como g. Sea el vector de longitud n p∗ el vector L1-normalizado que corresponde al PageRank global de las páginas en el dominio local L: p∗ = EL g ELg 1 , donde EL = [ I | 0 ] es la matriz de restricción que selecciona los componentes de g correspondientes a los nodos en L. Sea p el vector de PageRank construido a partir del subgrafo del dominio local L. En la práctica, el PageRank local observado p y el PageRank global p∗ serán bastante diferentes. Se esperaría que a medida que el tamaño de la matriz local L se acerque al tamaño de la matriz global G, el PageRank global y el PageRank local observado se vuelvan más similares. Por lo tanto, un enfoque para estimar el PageRank global es rastrear todo el dominio global, calcular su PageRank y extraer los PageRanks del dominio local. Por lo general, sin embargo, n N, es decir, el número de páginas globales es mucho mayor que el número de páginas locales. Por lo tanto, rastrear todas las páginas globales agotará rápidamente todos los recursos locales (computacionales, de almacenamiento y de ancho de banda) disponibles para crear el motor de búsqueda local. En cambio, buscamos un supergrafo ˆF de nuestro subgrafo local L con tamaño O(n). Nuestro objetivo es el Algoritmo 2: El algoritmo FindGlobalPR. EncuentraGlobalPR(L, Lout, T, k) Entrada: L: matriz de adyacencia de ceros y unos para el dominio local, Lout: matriz de enlaces de ceros y unos desde L al subgrafo global como en (2), T: número de iteraciones, k: número de páginas a rastrear por iteración. Salida: ˆp: una estimación mejorada del PageRank global de L. F ← L Fout ← Lout f ← CalcularPR(F) para (i = 1 a T) {Determinar qué páginas rastrear a continuación} páginas ← SeleccionarNodos(F, Fout, f, k) Rastrear páginas, aumentar F y modificar Fout {Actualizar PageRanks para el nuevo dominio local} f ← CalcularPR(F) fin {Extraer PageRanks del dominio local original y normalizar} ˆp ← ELf ELf 1 es encontrar un supergrafo ˆF con PageRank ˆf, de modo que ˆf cuando se restringe a L esté cerca de p∗. Formalmente, buscamos minimizar GlobalDiff( ˆf) = EL ˆf EL ˆf 1 − p∗ 1 . (3) Elegimos la norma L1 para medir el error ya que no otorga un peso excesivo a los valores atípicos (como lo hace la norma L2, por ejemplo), y también porque es la medida de distancia más comúnmente utilizada en la literatura para comparar vectores de PageRank, así como para detectar la convergencia del algoritmo [3]. Proponemos un marco codicioso, presentado en el Algoritmo 2, para construir ˆF. Inicialmente, F se establece en el subgrafo local L, y se calcula el PageRank f de este grafo. El algoritmo luego procede de la siguiente manera. Primero, se llama al algoritmo SelectNodes (que discutimos en la siguiente sección) y devuelve un conjunto de k nodos para rastrear a continuación del conjunto de nodos en la frontera de rastreo actual, Fout. Estos nodos seleccionados son luego rastreados para expandir el subgrafo local, F, y los PageRanks de este grafo expandido son luego recalculados. Estos pasos se repiten para cada una de las T iteraciones. Finalmente, se devuelve el vector PageRank ˆp, el cual está restringido a las páginas dentro del dominio local original. Dadas nuestras restricciones de computación, ancho de banda y memoria, asumiremos que el algoritmo rastreará como máximo O(n) páginas. Dado que los PageRanks se calculan en cada iteración del algoritmo, lo cual es una operación O(n), también asumiremos que el número de iteraciones T es una constante. Por supuesto, el principal desafío aquí radica en seleccionar qué conjunto de k nodos rastrear a continuación. En la siguiente sección, definimos formalmente el problema y presentamos algoritmos eficientes. 5. SELECCIÓN DE NODO En esta sección, presentamos algoritmos de selección de nodo que operan dentro del marco codicioso presentado en la sección anterior. Primero damos un criterio bien definido para el problema de selección de páginas y proporcionamos evidencia experimental de que este criterio puede identificar de manera efectiva las páginas que optimizan nuestro objetivo del problema (3). A continuación, presentamos nuestra principal contribución algorítmica del artículo de investigación al118, un método con tiempo de ejecución lineal que se deriva de los criterios de selección de esta página. Finalmente, ofrecemos un análisis intuitivo de nuestro algoritmo en términos de fugas y flujos. Mostramos que si solo se considera el flujo, entonces el método resultante es muy similar a una heurística de selección de páginas ampliamente utilizada [6]. 5.1 Formulación Para una página dada j en el dominio global, definimos el grafo local expandido Fj: Fj = F s uT j 0, (4) donde uj es el vector de ceros y unos que contiene los enlaces de salida de F hacia la página j, y s contiene los enlaces de entrada de la página j en el dominio local. Ten en cuenta que no permitimos enlaces a uno mismo en este marco de trabajo. En la práctica, los enlaces internos suelen ser eliminados, ya que solo sirven para inflar el PageRank de una página determinada. Observa que los enlaces entrantes a F desde el nodo j no se conocen hasta después de que el nodo j sea rastreado. Por lo tanto, estimamos este vector de inlink como la expectativa sobre el recuento de inlinks entre el conjunto de páginas ya rastreadas, s = F T e F T e 1. En la práctica, para cualquier página dada, esta estimación puede no reflejar los verdaderos inlinks de esa página. Además, esta expectativa se extrae del conjunto de enlaces dentro del dominio rastreado, mientras que una estimación más precisa también utilizaría enlaces del dominio global. Sin embargo, la distribución mencionada no es conocida por un motor de búsqueda localizado, y sostenemos que la estimación anterior, en promedio, será una estimación mejor que la distribución uniforme, por ejemplo. Dejemos que el PageRank de F sea f. Expresamos el PageRank f+ j del grafo local expandido Fj como f+ j = (1 − xj)fj xj , donde xj es el PageRank del nodo global candidato j, y fj es el vector de PageRank L1-normalizado restringido a las páginas en F. Dado que optimizar directamente nuestro objetivo requiere conocer el PageRank global p∗, proponemos en su lugar rastrear aquellos nodos que tendrán la mayor influencia en los PageRanks de las páginas en el dominio local original L: influencia(j) = k∈L |fj[k] − f[k]| (7) = EL (fj − f) 1. Experimentalmente, el puntaje de influencia es un predictor muy bueno de nuestro objetivo del problema (3). Para cada nodo global candidato j, la figura 1(a) muestra el valor de la función objetivo Global Diff(fj) en función de la influencia de la página j. El dominio local utilizado aquí es un rastreo de páginas políticas conservadoras (proporcionaremos más detalles sobre este conjunto de datos en la sección 6); observamos resultados similares en otros dominios. La correlación es bastante fuerte, lo que implica que los criterios de influencia pueden identificar de manera efectiva las páginas que mejoran la estimación global del PageRank. Como referencia, la figura 1(b) compara nuestro objetivo con un criterio alternativo, el recuento de enlaces de salida. El recuento de enlaces de salida se define como el número de enlaces de salida desde el dominio local a la página j. La correlación aquí es mucho más débil. .00001 .0001 .001 .01 0.26 0.262 0.264 0.266 Influencia Objetivo 1 10 100 1000 0.266 0.264 0.262 0.26 Recuento de Enlaces Salientes Objetivo (a) (b) Figura 1: (a) La correlación entre nuestros criterios de selección de página de influencia (7) y el valor real de la función objetivo (3) es bastante fuerte. (b) Esto contrasta con otros criterios, como el recuento de enlaces salientes, que muestran una correlación mucho más débil. 5.2 Cálculo Como se describe, para cada página global candidata j, se debe calcular el puntaje de influencia (7). Si fj se calcula exactamente para cada página global j, entonces el algoritmo de PageRank tendría que ejecutarse para cada una de las O(n) páginas globales j que consideramos, lo que resultaría en un costo computacional de O(n2) para el método de selección de nodos. Por lo tanto, calcular el valor exacto de fj conducirá a un algoritmo cuadrático, y en su lugar debemos recurrir a métodos de aproximación de este vector. El algoritmo que presentamos funciona realizando una iteración del método de potencia utilizado por el algoritmo PageRank (Algoritmo 1). La tasa de convergencia para el algoritmo PageRank se ha demostrado que es igual a la probabilidad del surfista aleatorio α [7, 11]. Dado un vector inicial x(0), si se realizan k iteraciones de PageRank, la solución actual de PageRank x(k) satisface: x(k) − x∗ 1 = O(αk x(0) − x∗ 1), (8), donde x∗ es el vector de PageRank deseado. Por lo tanto, si solo se realiza una iteración, es necesario elegir un buen vector inicial para lograr una aproximación precisa. Particionamos la matriz de PageRank PFj, correspondiente al subgrafo Fj, como: PFj = ˜F ˜s ˜uT j w, (9) donde ˜F = αF (DF + diag(uj))−1 + (1 − α) e + 1 eT, ˜s = αs + (1 − α) e + 1, ˜uj = α(DF + diag(uj))−1 uj + (1 − α) e + 1, w = 1 − α + 1, y diag(uj) es la matriz diagonal con la entrada (i, i) igual a uno si el i-ésimo elemento de uj es uno, y cero en caso contrario. Hemos asumido aquí que el vector del surfista aleatorio es el vector uniforme, y que L no tiene enlaces colgantes. Estas suposiciones no son necesarias y solo sirven para simplificar la discusión y el análisis. Un enfoque sencillo para estimar fj es el siguiente. Primero, estima el PageRank f+ j de Fj calculando una iteración de PageRank sobre la matriz PFj, utilizando el vector inicial ν = f 0. Luego, estima fj eliminando el último componente de 119 Research Track Paper de nuestra estimación de f+ j (es decir, el componente correspondiente al nodo j añadido), y renormalizando. El problema con este enfoque está en el vector inicial. Recuerde que xj es el PageRank del nodo j añadido. La diferencia entre el PageRank actual f+ j de PFj y el vector inicial ν es ν − f+ j 1 = xj + f − (1 − xj)fj 1 ≥ xj + | f 1 − (1 − xj) fj 1| = xj + |xj| = 2xj. Por lo tanto, según (8), después de una iteración de PageRank, esperamos que nuestra estimación de f+ j todavía tenga un error de aproximadamente 2αxj. En particular, para los nodos candidatos j con un PageRank xj relativamente alto, este método producirá resultados más inexactos. A continuación, presentaremos un método que elimina este sesgo y se ejecuta en tiempo O(n). 5.2.1 Complementación Estocástica Dado que f+ j, como se muestra en (6), es el PageRank de la matriz PFj, tenemos: fj(1 − xj) xj = ˜F ˜s ˜uT j w fj(1 − xj) xj = ˜F fj(1 − xj) + ˜sxj ˜uT j fj(1 − xj) + wxj. Resolver el sistema anterior para fj puede demostrarse que produce fj = ( ˜F + (1 − w)−1 ˜s˜uT j )fj. (10) La matriz S = ˜F +(1−w)−1 ˜s˜uT j se conoce como el complemento estocástico de la matriz estocástica de columna PFj con respecto a la submatriz ˜F. La teoría de complementación estocástica está bien estudiada, y se puede demostrar que el complemento estocástico de una matriz irreducible (como la matriz de PageRank) es único. Además, el complemento estocástico también es irreducible y, por lo tanto, tiene una distribución estacionaria única. Para un estudio extenso, ver [15]. Se puede demostrar fácilmente que el autovalor subdominante de S es a lo sumo +1 α, donde α es el tamaño de F. Para valores suficientemente grandes, este valor estará muy cerca de α. Esto es importante, ya que otras propiedades del algoritmo PageRank, especialmente la sensibilidad del algoritmo, dependen de este valor [11]. En este método, estimamos el vector de longitud fj calculando una iteración de PageRank sobre el complemento estocástico × S, comenzando en el vector f: fj ≈ Sf. (11) Esto contrasta con el método simple descrito en la sección anterior, que primero itera sobre la matriz ( + 1) × ( + 1) PFj para estimar f+ j, y luego elimina el último componente de la estimación y renormaliza para aproximar fj. El problema con el último método radica en la elección del vector inicial de longitud ( + 1), ν. En consecuencia, la estimación de PageRank dada por el método simple difiere del verdadero PageRank en al menos 2αxj, donde xj es el PageRank de la página j. Al utilizar el complemento estocástico, podemos establecer un límite inferior estricto de cero para esta diferencia. Para ver esto, considera el caso en el que se agrega un nodo k a F para formar el subgrafo local aumentado Fk, y que el PageRank de este nuevo grafo es (1 − xk)f xk. Específicamente, la adición de la página k no cambia los PageRanks de las páginas en F, y por lo tanto fk = f. Por la construcción del complemento estocástico, fk = Sfk, por lo que la aproximación dada en la ecuación (11) producirá la solución exacta. A continuación, presentamos los detalles computacionales necesarios para calcular eficientemente la cantidad fj − f 1 sobre todas las páginas globales conocidas j. Comenzamos expandiendo la diferencia fj − f, donde el vector fj se estima como en (11), fj − f ≈ Sf − f = αF (DF + diag(uj))−1 f + (1 − α) e + 1 eT f +(1 − w)−1 (˜uT j f)˜s − f. (12) Tenga en cuenta que la matriz (DF + diag(uj))−1 es diagonal. Dejando que o[k] sea el recuento de enlaces de salida para la página k en F, podemos expresar el elemento diagonal k-ésimo como: (DF + diag(uj))−1 [k, k] = 1 o[k]+1 si uj[k] = 1 1 o[k] si uj[k] = 0 Notando que (o[k] + 1)−1 = o[k]−1 − (o[k](o[k] + 1))−1 y reescribiendo esto en forma matricial obtenemos (DF +diag(uj))−1 = D−1 F −D−1 F (DF +diag(uj))−1 diag(uj). (13) Usamos la misma identidad para expresar e + 1 = e − e ( + 1) . (14) Recordemos que, por definición, tenemos PF = αF D−1 F +(1−α)e. Sustituyendo (13) y (14) en (12) se obtiene que fj − f ≈ (PF f − f) −αF D−1 F (DF + diag(uj))−1 diag(uj)f −(1 − α) e ( + 1) + (1 − w)−1 (˜uT j f)˜s = x + y + (˜uT j f)z, (15), notando que por definición, f = PF f, y definiendo los vectores x, y, y z como x = −αF D−1 F (DF + diag(uj))−1 diag(uj)f (16) y = −(1 − α) e ( + 1) (17) z = (1 − w)−1 ˜s. (18) El primer término x es un vector disperso, y toma valores no nulos solo para las páginas locales k que son hermanas de la página global j. Definimos (i, j) ∈ F si y solo si F [j, i] = 1 (equivalentemente, la página i enlaza a la página j) y expresamos el valor del componente x[k] como: x[k] = −α k:(k,k)∈F, uj[k]=1 f[k] o[k](o[k] + 1), (19) donde o[k], como antes, es el número de enlaces salientes de la página k en el dominio local. Ten en cuenta que los dos últimos términos, y y z, no dependen del nodo global actual j. Dada la función hj(f) = y + (˜uT j f)z 1, la cantidad fj − f 1 120 Research Track Paper puede expresarse como fj − f 1 = k x[k] + y[k] + (˜uT j f)z[k] = k:x[k]=0 y[k] + (˜uT j f)z[k] + k:x[k]=0 x[k] + y[k] + (˜uT j f)z[k] = hj(f) − k:x[k]=0 y[k] + (˜uT j f)z[k] + k:x[k]=0 x[k] + y[k] + (˜uT j f)z[k]. (20) Si podemos calcular la función hj en tiempo lineal, entonces podemos calcular cada valor de fj − f 1 usando una cantidad adicional de tiempo proporcional al número de componentes no nulas en x. Estas optimizaciones se llevan a cabo en el Algoritmo 3. Nótese que la ecuación (20) calcula la diferencia entre todos los componentes de f y fj, mientras que nuestros criterios de selección de nodos, dados en la ecuación (7), se restringen a los componentes correspondientes a los nodos en el dominio local original L. Examinemos el Algoritmo 3 con más detalle. Primero, el algoritmo calcula el número de enlaces de salida para cada página en el dominio local. El algoritmo luego calcula la cantidad ˜uT j f para cada página global j conocida. Este producto interno se puede escribir como (1 − α) 1 + 1 + α k:(k,j)∈Fout f[k] o[k] + 1, donde el segundo término suma sobre el conjunto de páginas locales que enlazan a la página j. Dado que se asumió que el número total de aristas en Fout tenía un tamaño O( ) (recordemos que es el número de páginas en F), el tiempo de ejecución de este paso también es O( ). El algoritmo luego calcula los vectores y y z, como se indican en (17) y (18), respectivamente. El método L1NormDiff se llama en los componentes de estos vectores que corresponden a las páginas en L, y estima el valor de EL(y + (˜uT j f)z) 1 para cada página j. La estimación funciona de la siguiente manera. Primero, los valores de ˜uT j f se discretizan de forma uniforme en c valores {a1, ..., ac}. La cantidad EL(y + aiz) 1 se calcula entonces para cada valor discretizado de ai y se almacena en una tabla. Para evaluar EL (y + az) 1 para algún a ∈ [a1, ac], se determina el valor discretizado más cercano ai, y se utiliza la entrada correspondiente en la tabla. El tiempo total de ejecución de este método es lineal en y el parámetro de discretización c (que consideramos constante). Observamos que si se desean valores exactos, también hemos desarrollado un algoritmo que se ejecuta en tiempo O(log) que no se describe aquí. En el bucle principal, calculamos el vector x, tal como se define en la ecuación (16). Los bucles anidados iteran sobre el conjunto de páginas en F que son hermanas de la página j. Normalmente, el tamaño de este conjunto está limitado por una constante. Finalmente, para cada página j, el vector de puntuaciones se actualiza sobre el conjunto de componentes no nulos k del vector x con k ∈ L. Este conjunto tiene un tamaño igual al número de hermanos locales de la página j, y es un subconjunto del número total de hermanos de la página j. Por lo tanto, cada iteración del bucle principal toma tiempo constante, y el tiempo de ejecución total del bucle principal es O( ). Dado que hemos asumido que el tamaño de F no crecerá más allá de O(n), el tiempo de ejecución total del algoritmo es O(n). Algoritmo 3: Selección de nodos a través de la complementación estocástica. SC-Select(F , Fout, f, k) Entrada: F : matriz de adyacencia de ceros y unos del tamaño correspondiente al subgrafo local actual, Fout: matriz de enlaces de ceros y unos de F al subgrafo global, f: PageRank de F , k: número de páginas a devolver Salida: páginas: conjunto de k páginas para rastrear a continuación {Calcular sumas de enlaces de salida para el subgrafo local} para cada (página j ∈ F ) o[j] ← k:(j,k)∈F F[j, k] fin {Calcular escalar ˜uT j f para cada nodo global j } para cada (página j ∈ Fout) g[j] ← (1 − α) 1 +1 para cada (página k : (k, j) ∈ Fout) g[j] ← g[j] + α f[k] o[k]+1 fin fin {Calcular vectores y z como en (17) y (18) } y ← −(1 − α) e ( +1) z ← (1 − w)−1 ˜s {Aproximar y + g[j] ∗ z 1 para todos los valores g[j]} norm diffs ←L1NormDiffs(g, ELy, ELz) para cada (página j ∈ Fout) {Calcular vector disperso x como en (19)} x ← 0 para cada (página k : (k, j) ∈ Fout) para cada (página k : (k, k ) ∈ F )) x[k ] ← x[k ] − f[k] o[k](o[k]+1) fin fin x ← αx scores[j] ← norm diffs[j] para cada (k : x[k] > 0 y página k ∈ L) scores[j] ← scores[j] − |y[k] + g[j] ∗ z[k]| +|x[k]+y[k]+g[j]∗z[k])| fin fin Devolver k páginas con los puntajes más altos 5.2.2 Flujos de PageRank Ahora presentamos un análisis intuitivo del método de complementación estocástica descomponiendo el cambio en PageRank en términos de fugas y flujos. Este análisis está motivado por la descomposición dada en (15). El flujo de PageRank es el aumento en los PageRanks locales que se originan desde la página global j. Los flujos están representados por el vector no negativo (˜uT j f)z (ecuaciones (15) y (18)). El escalar ˜uT j f se puede pensar como la cantidad total de flujo de PageRank que la página j tiene disponible para distribuir. El vector z dicta cómo se asigna el flujo al dominio local; el flujo que recibe la página local k es proporcional (con un factor constante debido al vector de navegante aleatorio) al número esperado de sus enlaces entrantes. Las filtraciones de PageRank representan la disminución en el PageRank resultante de la adición de la página j. La fuga puede ser cuantificada en términos de los vectores no positivos x e y (ecuaciones (16) y (17)). Para el vector x, podemos ver a partir de la ecuación (19) que la cantidad de PageRank filtrado por una página local es proporcional a la suma ponderada de los Page121 Research Track Paper Ranks de sus páginas hermanas. Por lo tanto, las páginas que tienen hermanos con PageRanks más altos (y un bajo número de enlaces salientes) experimentarán más pérdida de valor. La fuga causada por y es un artefacto del vector del surfista aleatorio. A continuación demostraremos que si solo se considera el término de flujo, (˜uT j f)z, entonces el método resultante es muy similar a una heurística propuesta por Cho et al. [6] que ha sido ampliamente utilizada para el problema de Ordenación de URL en el Rastreo. Esta heurística es computacionalmente más económica, pero como veremos más adelante, no es tan efectiva como el método de Complementación Estocástica. Nuestra estrategia de selección de nodos elige nodos globales que tienen la mayor influencia (ecuación (7)). Si esta influencia se aproxima utilizando solo flujos, el nodo óptimo j∗ es: j∗ = argmaxj EL ˜uT j fz 1 = argmaxj ˜uT j f EL z 1 = argmaxj ˜uT j f = argmaxj α(DF + diag(uj))−1 uj + (1 − α) e + 1 , f = argmaxjfT (DF + diag(uj))−1 uj. La puntuación de selección de página resultante se puede expresar como la suma de los PageRanks de cada página local k que enlaza con j, donde cada valor de PageRank se normaliza por o[k]+1. Curiosamente, la normalización que surge en nuestro método difiere de la heurística dada en [6], la cual normaliza por o[k]. El algoritmo PF-Select, que se omite por falta de espacio, primero calcula la cantidad fT (DF +diag(uj))−1 uj para cada página global j, y luego devuelve las páginas con los k puntajes más altos. Para ver que el tiempo de ejecución de este algoritmo es O(n), observe que la computación involucrada en este método es un subconjunto de la necesaria para el método SC-Select (Algoritmo 3), el cual se demostró que tiene un tiempo de ejecución de O(n). 6. EXPERIMENTOS En esta sección, proporcionamos evidencia experimental para verificar la efectividad de nuestros algoritmos. Primero describimos nuestra metodología experimental y luego presentamos resultados en una variedad de dominios locales. 6.1 Metodología Dado los recursos limitados disponibles en una institución académica, rastrear una sección de la web que sea de la misma magnitud que la indexada por Google o Yahoo! claramente es inviable. Por lo tanto, para un dominio local dado, aproximamos el <br>grafo global</br> rastreando un vecindario local alrededor del dominio que es varias órdenes de magnitud más grande que el subgrafo local. A pesar de que dicho gráfico sigue siendo órdenes de magnitud más pequeño que el verdadero <br>gráfico global</br>, sostenemos que, incluso si existen algunas páginas altamente influyentes que están muy lejos de nuestro dominio local, es poco realista que cualquier algoritmo de selección de nodos locales las encuentre. Tales páginas suelen ser muy poco relacionadas con las páginas dentro del dominio local. Al explicar nuestras estrategias de selección de nodos en la sección 5, hicimos la suposición simplificadora de que nuestro grafo local no contenía nodos colgantes. Esta suposición se hizo solo para facilitar nuestro análisis. Nuestra implementación maneja de manera eficiente los enlaces colgantes al reemplazar cada columna de ceros de nuestra matriz de adyacencia con el vector uniforme. Evaluamos el algoritmo utilizando las dos estrategias de selección de nodos dadas en la Sección 5.2, y también comparándolo con los siguientes métodos de referencia: • Aleatorio: Los nodos se eligen de forma uniforme al azar entre los nodos globales conocidos. • Conteo de enlaces de salida: Se eligen los nodos globales con el mayor número de enlaces de salida desde el dominio local. En cada iteración del algoritmo FindGlobalPR, evaluamos el rendimiento calculando la diferencia entre la estimación actual de PageRank del dominio local, ELf ELf 1, y el PageRank global del dominio local, ELg ELg 1. Todas las calculaciones de PageRank se realizaron utilizando el vector de surfista aleatorio uniforme. En todos los experimentos, establecimos el parámetro del surfista aleatorio α en .85 y utilizamos un umbral de convergencia de 10−6. Evaluamos la diferencia entre los vectores de PageRank local y global utilizando tres métricas diferentes: las normas L1 y L∞, y el tau de Kendall. La norma L1 mide la suma del valor absoluto de las diferencias entre los dos vectores, y la norma L∞ mide el valor absoluto de la mayor diferencia. La métrica de tau de Kendall es una medida de correlación de rangos popular utilizada para comparar PageRanks [2, 11]. Esta métrica se puede calcular contando el número de pares de pares que coinciden en la clasificación, y restando de eso el número de pares de pares que no coinciden en la clasificación. El valor final se normaliza luego por el número total de n pares de este tipo, resultando en un rango de [−1, 1], donde una puntuación negativa indica una anticorrelación entre las clasificaciones, y valores cercanos a uno corresponden a una fuerte correlación de rangos. 6.2 Resultados Nuestros experimentos se basan en dos grandes rastreos web y se descargaron utilizando el rastreador web que forma parte del proyecto de motor de búsqueda de código abierto Nutch [18]. Todas las exploraciones se limitaron únicamente a páginas http, y para limitar el número de páginas generadas dinámicamente que exploramos, ignoramos todas las páginas con URLs que contengan alguno de los caracteres ?, *, @ o =. El primer rastreo, al que nos referiremos como el conjunto de datos edu, fue iniciado por las páginas de inicio de los 100 principales departamentos de posgrado en informática en los Estados Unidos, según la clasificación de US News and World Report [16], y también por las páginas de inicio de sus respectivas instituciones. Se realizó un rastreo de profundidad 5, restringido a páginas dentro del dominio .edu, lo que resultó en un grafo con aproximadamente 4.7 millones de páginas y 22.9 millones de enlaces. El segundo rastreo fue alimentado por el conjunto de páginas bajo la jerarquía de política en el proyecto de directorio abierto dmoz[17]. Rastreamos todas las páginas hasta cuatro enlaces de distancia, lo que resultó en un grafo con 4.4 millones de páginas y 17.3 millones de enlaces. Dentro del rastreo educativo, identificamos los cinco dominios específicos del sitio correspondientes a los sitios web de los cinco principales departamentos de posgrado en ciencias de la computación, según la clasificación de US News and World Report. Esto produjo dominios locales de varios tamaños, desde 10,626 (UIUC) hasta 59,895 (Berkeley). Para cada uno de estos dominios específicos del sitio con tamaño n, realizamos 50 iteraciones del algoritmo FindGlobalPR para rastrear un total de 2n nodos adicionales. La Figura 2(a) muestra la diferencia (L1) entre la estimación de PageRank en cada iteración y el PageRank global, para el dominio local de Berkeley. El rendimiento de este conjunto de datos fue representativo del rendimiento típico en los cinco dominios locales específicos de informática. Inicialmente, la diferencia de L1 entre los PageRanks globales y locales variaba desde .0469 (Stanford) hasta .149 (MIT). Para las primeras varias iteraciones, el Artículo de Investigación 122 0 5 10 15 20 25 30 35 40 45 50 0.015 0.02 0.025 0.03 0.035 0.04 0.045 0.05 0.055 Número de Iteraciones Diferencia de PageRank Global y Local (L1) Complemento Estocástico PageRank Flujo de Enlaces de Conteo Aleatorio 0 10 20 30 40 50 0 0.05 0.1 0.15 0.2 0.25 0.3 0.35 Número de Iteraciones Diferencia de PageRank Global y Local (L1) Complemento Estocástico PageRank Flujo de Enlaces de Conteo Aleatorio 0 5 10 15 20 25 0.16 0.18 0.2 0.22 0.24 0.26 0.28 0.3 0.32 0.34 Número de Iteraciones Diferencia de PageRank Global y Local (L1) Complemento Estocástico PageRank Flujo de Enlaces de Conteo Aleatorio (a) www.cs.berkeley.edu (b) www.enterstageright.com (c) Política Figura 2: Diferencia L1 entre los PageRanks globales estimados y verdaderos para (a) el sitio web de ciencias de la computación de Berkeley, (b) el dominio específico del sitio, www.enterstageright.com, y (c) el dominio específico del tema de política. El método de complemento estocástico supera a todos los demás métodos en diferentes dominios. Tres métodos basados en enlaces superan a la heurística de selección aleatoria. Después de estas iteraciones iniciales, la heurística aleatoria tendió a ser más competitiva con (o incluso superar, como en el dominio local de Berkeley) las heurísticas de conteo de enlaces de salida y flujo de PageRank. En todos los ensayos, el método de complementación estocástica superó a los otros métodos o compitió con ellos. La Tabla 1 muestra la diferencia promedio entre los PageRanks globales estimados finales y los PageRanks globales reales para varias medidas de distancia. Algoritmo L1 L∞ Kendall Estocástico. Tabla 1: Rendimiento final promedio de varias estrategias de selección de nodos para los cinco dominios locales de informática específicos del sitio. Ten en cuenta que el Tau de Kendall mide similitud, mientras que las otras métricas son medidas de disimilitud. La Complementación Estocástica claramente supera a los otros métodos en todas las métricas. Dentro del conjunto de datos de política, también realizamos dos pruebas específicas para los sitios web más grandes en el rastreo: www.adamsmith.org, el sitio web del Instituto Adam Smith con sede en Londres, y www.enterstageright.com, una revista en línea conservadora. Al igual que con los dominios locales de edu, ejecutamos nuestro algoritmo durante 50 iteraciones, rastreando un total de 2n nodos. La figura 2 (b) muestra los resultados para el dominio www.enterstageright.com. A diferencia de los dominios locales de edu, los métodos Random y OutlinkCount no fueron competitivos ni con los métodos SC-Select ni con los métodos PF-Select. Entre todos los conjuntos de datos y todos los métodos de selección de nodos, el método de complementación estocástica fue el más impresionante en este conjunto de datos, logrando una estimación final que difería solo .0279 del PageRank global, una mejora de diez veces sobre la diferencia inicial del PageRank local de .299. Para el dominio local de Adam Smith, la diferencia inicial entre los PageRanks locales y globales fue de .148, y las estimaciones finales proporcionadas por los métodos SC-Select, PF-Select, OutlinkCount y Random fueron de .0208, .0193, .0222 y .0356, respectivamente. Dentro del conjunto de datos de política, construimos cuatro dominios locales específicos de temas. El primer dominio consistía en todas las páginas de la categoría de política de dmoz, y también todas las páginas dentro de cada uno de estos sitios hasta dos enlaces de distancia. Esto produjo un dominio local de 90,811 páginas, y los resultados se muestran en la figura 2 (c). Debido al mayor tamaño de los dominios específicos del tema, ejecutamos nuestro algoritmo solo durante 25 iteraciones para rastrear un total de n nodos. También creamos dominios específicos de temas a partir de tres subtemas políticos: liberalismo, conservadurismo y socialismo. Las páginas en estos dominios fueron identificadas por sus categorías correspondientes de dmoz. Para cada subtema, establecemos el dominio local como todas las páginas dentro de tres enlaces de las páginas de categoría dmoz correspondientes. La Tabla 2 resume el rendimiento de estos tres dominios específicos del tema, así como también del dominio político más amplio. Para cuantificar el efecto global de una página js en los valores globales de PageRank de las páginas en el dominio local, definimos el impacto de la página js como su valor de PageRank, g[j], normalizado por la fracción de sus enlaces salientes que apuntan al dominio local: impacto(j) = oL[j] o[j] · g[j], donde oL[j] es el número de enlaces salientes de la página j a páginas en el dominio local L, y o[j] es el número total de enlaces salientes de js. En términos del modelo del surfista aleatorio, el impacto de la página j es la probabilidad de que el surfista aleatorio (1) se encuentre actualmente en la página global j en su caminata aleatoria y (2) tome un enlace de salida a una página local, dado que ya ha decidido no saltar a una página aleatoria. Para el dominio político local, encontramos que muchas de las páginas con alto impacto eran de hecho páginas políticas que deberían haber sido incluidas en el tema de política de dmoz, pero no lo estaban. Por ejemplo, las dos páginas globales más influyentes fueron el motor de búsqueda político www.askhenry.com y la página de inicio de la revista política en línea www.policyreview.com. Entre las páginas no políticas, la página de inicio de la revista Education Next fue la más influyente. El diario está disponible de forma gratuita en línea y contiene artículos sobre varios aspectos de la educación K-12 en América. Para proporcionar algunas pruebas anecdóticas de la efectividad de nuestros métodos de selección de páginas, observamos que el método SC-Select eligió 11 páginas dentro del dominio www.educationnext.org, el método PF-Select descubrió 7 páginas, mientras que los métodos OutlinkCount y Random encontraron solo 6 páginas cada uno. Para el ámbito político local conservador, el sitio web socialista www.ornery.org tuvo una puntuación de impacto muy alta. Este documento de investigación de la pista 123 titulado \"Toda la política: Algoritmo L1 L2 Kendall Stoch\". Comp. .1253 .000700 .8671 Flujo PR .1446 .000710 .8518 Enlace saliente .1470 .00225 .8642 Aleatorio .2055 .00203 .8271 Conservadurismo: Algoritmo L1 L2 Kendall Estoc. Comp. .0496 .000990 .9158 Flujo PR .0554 .000939 .9028 Enlace saliente .0602 .00527 .9144 Aleatorio .1197 .00102 .8843 Liberalismo: Algoritmo L1 L2 Kendall Estoc. Comp. .0622 .001360 .8848 Flujo PR .0799 .001378 .8669 Enlace saliente .0763 .001379 .8844 Aleatorio .1127 .001899 .8372 Socialismo: Algoritmo L1 L∞ Kendall Estoc. Tabla 2: Rendimiento final entre estrategias de selección de nodos para las cuatro exploraciones específicas de temas políticos. Ten en cuenta que el coeficiente de correlación de Kendall mide la similitud, mientras que las otras métricas son medidas de disimilitud. Como era de esperar, el PageRank global de este artículo (que resulta estar en la página de inicio de la NCCPR, www.nationalresearch.com) era aproximadamente de .002, mientras que el PageRank local de esta página era solo de .00158. El método SC-Select produjo una estimación global de PageRank de aproximadamente .00182, el método PFSelect estimó un valor de .00167, y los métodos Random y OutlinkCount produjeron valores de .01522 y .00171, respectivamente. TRABAJO RELACIONADO El marco de selección de nodos que hemos propuesto es similar al problema de ordenación de URL para el rastreo propuesto por Cho et al. en [6]. Mientras que nuestro marco busca minimizar la diferencia entre el PageRank global y local, el objetivo utilizado en [6] es rastrear primero las páginas más altamente clasificadas (globalmente). Proponen varios algoritmos de selección de nodos, incluyendo la heurística del recuento de enlaces de salida, así como una variante de nuestro algoritmo PF-Select al que se refieren como la métrica de ordenación de PageRank. Encontraron que este método era el más efectivo para optimizar su objetivo, al igual que lo demostró una encuesta reciente de estos métodos realizada por Baeza-Yates et al. [1]. Boldi et al. también experimentan dentro de un marco de rastreo similar en [2], pero cuantifican sus resultados al comparar la correlación de rangos de Kendall entre los PageRanks del conjunto actual de páginas rastreadas y los del <br>grafo global</br> completo. Encontraron que las estrategias de selección de nodos que rastreaban páginas con el PageRank global más alto primero en realidad tenían un peor rendimiento (con respecto a la correlación de Kendalls Tau entre los PageRanks locales y globales) que las estrategias básicas de búsqueda en profundidad o en amplitud. Sin embargo, sus experimentos difieren de nuestro trabajo en que nuestros algoritmos de selección de nodos no utilizan (ni tienen acceso a) valores globales de PageRank. Se han propuesto muchas mejoras algorítmicas para calcular los valores exactos de PageRank [9, 10, 14]. Si se utilizan tales algoritmos para calcular los PageRanks globales de nuestro dominio local, todos requerirían una computación, almacenamiento y ancho de banda de O(N), donde N es el tamaño del dominio global. Esto contrasta con nuestro método, que aproxima el PageRank global y escala linealmente con el tamaño del dominio local. Wang y Dewitt [22] proponen un sistema en el que el conjunto de servidores web que conforman el dominio global se comunican entre sí para calcular sus respectivos PageRanks globales. Para un servidor web dado que aloja n páginas, los requisitos computacionales, de ancho de banda y almacenamiento también son lineales en n. Una desventaja de este sistema es que el número de servidores web distintos que conforman el dominio global puede ser muy grande. Por ejemplo, nuestro conjunto de datos edu contiene sitios web de más de 3,200 universidades diferentes; coordinar un sistema así entre un gran número de sitios puede ser muy difícil. Gan, Chen y Suel proponen un método para estimar el PageRank de una sola página [5] que utiliza solo ancho de banda, computación y espacio constantes. Su enfoque se basa en la disponibilidad de un servidor de conectividad remota que puede suministrar el conjunto de enlaces entrantes a una página dada, una suposición que no se utiliza en nuestro marco de trabajo. Experimentalmente demuestran que se puede obtener una estimación razonable del PageRank de los nodos visitando como máximo unos pocos cientos de nodos. El uso de su algoritmo para nuestro problema requeriría que primero se descargue todo el dominio global o se utilice un servidor de conectividad, lo que resultaría en grafos web muy grandes. 8. CONCLUSIONES Y TRABAJOS FUTUROS Internet está creciendo de forma exponencial, y para poder navegar por un repositorio tan grande como la web, los motores de búsqueda globales se han establecido como una necesidad. Junto con la omnipresencia de estos motores de búsqueda a gran escala, surge un aumento en las expectativas de los usuarios de búsqueda. Al proporcionar una cobertura completa y aislada de un dominio web específico, los motores de búsqueda localizados son un medio efectivo para localizar rápidamente contenido que de otra manera podría ser difícil de encontrar. En este trabajo, sostenemos que el uso de PageRank global en un motor de búsqueda localizado puede mejorar el rendimiento. Para estimar el PageRank global, hemos propuesto un marco de selección de nodos iterativo en el que seleccionamos qué páginas de la frontera global rastrear a continuación. Nuestra principal contribución es nuestro algoritmo de selección de páginas de complementación estocástica. Este método recorre los nodos que tendrán un impacto significativo en el dominio local y tiene un tiempo de ejecución lineal en el número de nodos en el dominio local. Experimentalmente, validamos estos métodos en un conjunto diverso de dominios locales, que incluyen siete dominios específicos del sitio y cuatro dominios específicos del tema. Concluimos que al rastrear n o 2n páginas adicionales, nuestros métodos encuentran una estimación de los PageRanks globales que es hasta diez veces mejor que simplemente usar los PageRanks locales. Además, demostramos que nuestro algoritmo supera consistentemente a otras heurísticas existentes. En muchas ocasiones, los dominios específicos de un tema se descubren utilizando un rastreador web enfocado que considera el contenido de las páginas junto con el texto del ancla del enlace para decidir qué páginas rastrear a continuación [4]. Aunque estos rastreadores han demostrado ser bastante efectivos en descubrir contenido relacionado con el tema, también se rastrean muchas páginas irrelevantes en el proceso. Por lo general, estas páginas son eliminadas y no son indexadas por el motor de búsqueda localizado. Estas páginas pueden, por supuesto, proporcionar información valiosa sobre el PageRank global del dominio local. Una forma de integrar estas páginas en nuestro marco de trabajo es comenzar el algoritmo FindGlobalPR con el subgrafo actual F igual al conjunto de páginas que fueron rastreadas por el rastreador enfocado. El marco de estimación global de PageRank, junto con los algoritmos de selección de nodos presentados, requieren todos una computación de O(n) por iteración y un ancho de banda proporcional al número de páginas rastreadas, Tk. Si el número de iteraciones T es relativamente pequeño en comparación con el número de páginas rastreadas por iteración, k, entonces el cuello de botella del algoritmo será la fase de rastreo. Sin embargo, a medida que el número de iteraciones aumenta (en relación con k), el cuello de botella residirá en el cálculo de la selección de nodos. En este caso, nuestros algoritmos se beneficiarían de optimizaciones en el factor constante. Recuerde que el algoritmo FindGlobalPR (Algoritmo 2) requiere que los PageRanks del dominio local expandido actual se vuelvan a calcular en cada iteración. El trabajo reciente de Langville y Meyer [12] proporciona un algoritmo para recalcular rápidamente los PageRanks de un grafo web dado si se agregan un pequeño número de nodos. Este algoritmo demostró proporcionar una aceleración de cinco a diez veces en algunos conjuntos de datos. Planeamos investigar esto y otras optimizaciones similares como trabajo futuro. En este artículo, hemos evaluado objetivamente nuestros métodos midiendo qué tan cercanas son nuestras estimaciones globales de PageRank a los verdaderos PageRanks globales. Para determinar el beneficio de utilizar PageRanks globales en un motor de búsqueda localizado, sugerimos un estudio de usuarios en el que se les pida a los usuarios que califiquen la calidad de los resultados de búsqueda para varias consultas de búsqueda. Para algunas consultas, solo se utilizan los PageRanks locales en la clasificación, y para las consultas restantes, se utilizan los PageRanks locales y los PageRanks globales aproximados, según lo calculado por nuestros algoritmos. Los resultados de dicho estudio pueden ser analizados para determinar el beneficio adicional de utilizar los PageRanks globales calculados por nuestros métodos, en lugar de solo utilizar los PageRanks locales. Agradecimientos. Esta investigación fue apoyada por la subvención de la NSF CCF-0431257, el Premio de Carrera de la NSF ACI-0093404 y una subvención de Sabre, Inc. 9. REFERENCIAS [1] R. Baeza-Yates, M. Marín, C. Castillo y A. Rodríguez. Rastreando un país: estrategias mejores que el recorrido en anchura para ordenar páginas web. Conferencia de la World-Wide Web, 2005. [2] P. Boldi, M. Santini y S. Vigna. Haz lo peor para lograr lo mejor: efectos paradójicos en los cálculos incrementales de PageRank. Taller sobre Grafos Web, 3243:168-180, 2004. [3] S. Brin y L. Page. La anatomía de un motor de búsqueda web hipertextual a gran escala. Redes de Computadoras y Sistemas ISDN, 33(1-7):107-117, 1998. [4] S. Chakrabarti, M. van den Berg y B. Dom. Rastreo enfocado: un nuevo enfoque para el descubrimiento de recursos web específicos de un tema. Conferencia de la World-Wide Web, 1999. [5] Y. Chen, Q. Gan y T. Suel. Métodos locales para estimar los valores de pagerank. Conferencia sobre Gestión de Información y Conocimiento, 2004. [6] J. Cho, H. Garcia-Molina y L. Page. Rastreo eficiente a través de la ordenación de URL. Conferencia de la World-Wide Web, 1998. [7] T. H. Haveliwala y S. D. Kamvar. El segundo valor propio de la matriz de Google. Informe técnico, Universidad de Stanford, 2003. [8] T. Joachims, F. Radlinski, L. Granka, A. Cheng, C. Tillekeratne y A. Patel. Aprendizaje de funciones de recuperación a partir de retroalimentación implícita. http://www.cs.cornell.edu/People/tj/career. [9] S. D. Kamvar, T. H. Haveliwala, C. D. Manning y G. H. Golub. Explotando la estructura de bloques de la web para calcular el pagerank. Conferencia de la World-Wide Web, 2003. [10] S. D. Kamvar, T. H. Haveliwala, C. D. Manning y G. H. Golub. Métodos de extrapolación para acelerar el cálculo de PageRank. Conferencia de la World-Wide Web, 2003. [11] A. N. Langville y C. D. Meyer. Más profundo dentro de PageRank. Matemáticas en Internet, 2004. [12] A. N. Langville y C. D. Meyer. Actualizando el vector estacionario de una cadena de Markov irreducible con miras al PageRank de Google. Revista SIAM sobre Análisis de Matrices, 2005. [13] P. Lyman, H. R. Varian, K. Swearingen, P. Charles, N. Good, L. L. Jordan y J. Pal. ¿Cuánta información en 2003? Escuela de Gestión de la Información y Sistemas, Universidad de California en Berkeley, 2003. [14] F. McSherry. Un enfoque uniforme para el cálculo acelerado de PageRank. Conferencia de la World-Wide Web, 2005. [15] C. D. Meyer. Complementación estocástica, desacoplamiento de cadenas de Markov y la teoría de sistemas casi reducibles. SIAM Review, 31:240-272, 1989. [16] US News and World Report. http://www.usnews.com. [17] Proyecto de directorio abierto Dmoz. http://www.dmoz.org. [18] Motor de búsqueda de código abierto Nutch. http://www.nutch.org. [19] F. Radlinski y T. Joachims. Cadenas de consulta: aprendizaje para clasificar a partir de retroalimentación implícita. Conferencia Internacional ACM SIGKDD sobre Descubrimiento de Conocimiento y Minería de Datos, 2005. [20] S. Raghavan y H. Garcia-Molina. Explorando la web oculta. En Actas de la Vigésimo séptima Conferencia Internacional sobre Bases de Datos Muy Grandes, 2001. [21] T. Tin Tang, D. Hawking, N. Craswell y K. Griffiths. Rastreo enfocado para relevancia temática y calidad de la información médica. Conferencia sobre Gestión de Información y Conocimiento, 2005. [22] Y. Wang y D. J. DeWitt. Calculando el pagerank en un sistema distribuido de búsqueda en internet. Actas de la 30ª Conferencia VLDB, 2004. 125 Artículos de Investigación. ",
            "candidates": [],
            "error": [
                [
                    "grafo global",
                    "grafo global",
                    "gráfico global",
                    "grafo global"
                ]
            ]
        },
        "crawling problem": {
            "translated_key": "problema de ordenación de URL para el rastreo",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Estimating the Global PageRank of Web Communities Jason V. Davis Dept.",
                "of Computer Sciences University of Texas at Austin Austin, TX 78712 jdavis@cs.utexas.edu Inderjit S. Dhillon Dept. of Computer Sciences University of Texas at Austin Austin, TX 78712 inderjit@cs.utexas.edu ABSTRACT Localized search engines are small-scale systems that index a particular community on the web.",
                "They offer several benefits over their large-scale counterparts in that they are relatively inexpensive to build, and can provide more precise and complete search capability over their relevant domains.",
                "One disadvantage such systems have over large-scale search engines is the lack of global PageRank values.",
                "Such information is needed to assess the value of pages in the localized search domain within the context of the web as a whole.",
                "In this paper, we present well-motivated algorithms to estimate the global PageRank values of a local domain.",
                "The algorithms are all highly scalable in that, given a local domain of size n, they use O(n) resources that include computation time, bandwidth, and storage.",
                "We test our methods across a variety of localized domains, including site-specific domains and topic-specific domains.",
                "We demonstrate that by crawling as few as n or 2n additional pages, our methods can give excellent global PageRank estimates.",
                "Categories and Subject Descriptors H.3.3 [Information Storage and Retrieval]: Information Search and Retrieval; G.1.3 [Numerical Analysis]: Numerical Linear Algebra; G.3 [Probability and Statistics]: Markov Processes General Terms PageRank, Markov Chain, Stochastic Complementation 1.",
                "INTRODUCTION Localized search engines are small-scale search engines that index only a single community of the web.",
                "Such communities can be site-specific domains, such as pages within the cs.utexas.edu domain, or topic-related communitiesfor example, political websites.",
                "Compared to the web graph crawled and indexed by large-scale search engines, the size of such local communities is typically orders of magnitude smaller.",
                "Consequently, the computational resources needed to build such a search engine are also similarly lighter.",
                "By restricting themselves to smaller, more manageable sections of the web, localized search engines can also provide more precise and complete search capabilities over their respective domains.",
                "One drawback of localized indexes is the lack of global information needed to compute link-based rankings.",
                "The PageRank algorithm [3], has proven to be an effective such measure.",
                "In general, the PageRank of a given page is dependent on pages throughout the entire web graph.",
                "In the context of a localized search engine, if the PageRanks are computed using only the local subgraph, then we would expect the resulting PageRanks to reflect the perceived popularity within the local community and not of the web as a whole.",
                "For example, consider a localized search engine that indexes political pages with conservative views.",
                "A person wishing to research the opinions on global warming within the conservative political community may encounter numerous such opinions across various websites.",
                "If only local PageRank values are available, then the search results will reflect only strongly held beliefs within the community.",
                "However, if global PageRanks are also available, then the results can additionally reflect outsiders views of the conservative community (those documents that liberals most often access within the conservative community).",
                "Thus, for many localized search engines, incorporating global PageRanks can improve the quality of search results.",
                "However, the number of pages a local search engine indexes is typically orders of magnitude smaller than the number of pages indexed by their large-scale counterparts.",
                "Localized search engines do not have the bandwidth, storage capacity, or computational power to crawl, download, and compute the global PageRanks of the entire web.",
                "In this work, we present a method of approximating the global PageRanks of a local domain while only using resources of the same order as those needed to compute the PageRanks of the local subgraph.",
                "Our proposed method looks for a supergraph of our local subgraph such that the local PageRanks within this supergraph are close to the true global PageRanks.",
                "We construct this supergraph by iteratively crawling global pages on the current web frontier-i.e., global pages with inlinks from pages that have already been crawled.",
                "In order to provide 116 Research Track Paper a good approximation to the global PageRanks, care must be taken when choosing which pages to crawl next; in this paper, we present a well-motivated page selection algorithm that also performs well empirically.",
                "This algorithm is derived from a well-defined problem objective and has a running time linear in the number of local nodes.",
                "We experiment across several types of local subgraphs, including four topic related communities and several sitespecific domains.",
                "To evaluate performance, we measure the difference between the current global PageRank estimate and the global PageRank, as a function of the number of pages crawled.",
                "We compare our algorithm against several heuristics and also against a baseline algorithm that chooses pages at random, and we show that our method outperforms these other methods.",
                "Finally, we empirically demonstrate that, given a local domain of size n, we can provide good approximations to the global PageRank values by crawling at most n or 2n additional pages.",
                "The paper is organized as follows.",
                "Section 2 gives an overview of localized search engines and outlines their advantages over global search.",
                "Section 3 provides background on the PageRank algorithm.",
                "Section 4 formally defines our problem, and section 5 presents our page selection criteria and derives our algorithms.",
                "Section 6 provides experimental results, section 7 gives an overview of related work, and, finally, conclusions are given in section 8. 2.",
                "LOCALIZED SEARCH ENGINES Localized search engines index a single community of the web, typically either a site-specific community, or a topicspecific community.",
                "Localized search engines enjoy three major advantages over their large-scale counterparts: they are relatively inexpensive to build, they can offer more precise search capability over their local domain, and they can provide a more complete index.",
                "The resources needed to build a global search engine are enormous.",
                "A 2003 study by Lyman et al. [13] found that the surface web (publicly available static sites) consists of 8.9 billion pages, and that the average size of these pages is approximately 18.7 kilobytes.",
                "To download a crawl of this size, approximately 167 terabytes of space is needed.",
                "For a researcher who wishes to build a search engine with access to a couple of workstations or a small server, storage of this magnitude is simply not available.",
                "However, building a localized search engine over a web community of a hundred thousand pages would only require a few gigabytes of storage.",
                "The computational burden required to support search queries over a database this size is more manageable as well.",
                "We note that, for topic-specific search engines, the relevant community can be efficiently identified and downloaded by using a focused crawler [21, 4].",
                "For site-specific domains, the local domain is readily available on their own web server.",
                "This obviates the need for crawling or spidering, and a complete and up-to-date index of the domain can thus be guaranteed.",
                "This is in contrast to their large-scale counterparts, which suffer from several shortcomings.",
                "First, crawling dynamically generated pages-pages in the hidden web-has been the subject of research [20] and is a non-trivial task for an external crawler.",
                "Second, site-specific domains can enable the robots exclusion policy.",
                "This prohibits external search engines crawlers from downloading content from the domain, and an external search engine must instead rely on outside links and anchor text to index these restricted pages.",
                "By restricting itself to only a specific domain of the internet, a localized search engine can provide more precise search results.",
                "Consider the canonical ambiguous search query, jaguar, which can refer to either the car manufacturer or the animal.",
                "A scientist trying to research the habitat and evolutionary history of a jaguar may have better success using a finely tuned zoology-specific search engine than querying Google with multiple keyword searches and wading through irrelevant results.",
                "A method to learn better ranking functions for retrieval was recently proposed by Radlinski and Joachims [19] and has been applied to various local domains, including Cornell Universitys website [8]. 3.",
                "PAGERANK OVERVIEW The PageRank algorithm defines the importance of web pages by analyzing the underlying hyperlink structure of a web graph.",
                "The algorithm works by building a Markov chain from the link structure of the web graph and computing its stationary distribution.",
                "One way to compute the stationary distribution of a Markov chain is to find the limiting distribution of a random walk over the chain.",
                "Thus, the PageRank algorithm uses what is sometimes referred to as the random surfer model.",
                "In each step of the random walk, the surfer either follows an outlink from the current page (i.e. the current node in the chain), or jumps to a random page on the web.",
                "We now precisely define the PageRank problem.",
                "Let U be an m × m adjacency matrix for a given web graph such that Uji = 1 if page i links to page j and Uji = 0 otherwise.",
                "We define the PageRank matrix PU to be: PU = αUD−1 U + (1 − α)veT , (1) where DU is the (unique) diagonal matrix such that UD−1 U is column stochastic, α is a given scalar such that 0 ≤ α ≤ 1, e is the vector of all ones, and v is a non-negative, L1normalized vector, sometimes called the random surfer vector.",
                "Note that the matrix D−1 U is well-defined only if each column of U has at least one non-zero entry-i.e., each page in the webgraph has at least one outlink.",
                "In the presence of such dangling nodes that have no outlinks, one commonly used solution, proposed by Brin et al. [3], is to replace each zero column of U by a non-negative, L1-normalized vector.",
                "The PageRank vector r is the dominant eigenvector of the PageRank matrix, r = PU r. We will assume, without loss of generality, that r has an L1-norm of one.",
                "Computationally, r can be computed using the power method.",
                "This method first chooses a random starting vector r(0) , and iteratively multiplies the current vector by the PageRank matrix PU ; see Algorithm 1.",
                "In general, each iteration of the power method can take O(m2 ) operations when PU is a dense matrix.",
                "However, in practice, the number of links in a web graph will be of the order of the number of pages.",
                "By exploiting the sparsity of the PageRank matrix, the work per iteration can be reduced to O(km), where k is the average number of links per web page.",
                "It has also been shown that the total number of iterations needed for convergence is proportional to α and does not depend on the size of the web graph [11, 7].",
                "Finally, the total space needed is also O(km), mainly to store the matrix U. 117 Research Track Paper Algorithm 1: A linear time (per iteration) algorithm for computing PageRank.",
                "ComputePR(U) Input: U: Adjacency matrix.",
                "Output: r: PageRank vector.",
                "Choose (randomly) an initial non-negative vector r(0) such that r(0) 1 = 1. i ← 0 repeat i ← i + 1 ν ← αUD−1 U r(i−1) {α is the random surfing probability} r(i) ← ν + (1 − α)v {v is the random surfer vector.} until r(i) − r(i−1) < δ {δ is the convergence threshold.} r ← r(i) 4.",
                "PROBLEM DEFINITION Given a local domain L, let G be an N × N adjacency matrix for the entire connected component of the web that contains L, such that Gji = 1 if page i links to page j and Gji = 0 otherwise.",
                "Without loss of generality, we will partition G as: G = L Gout Lout Gwithin , (2) where L is the n × n local subgraph corresponding to links inside the local domain, Lout is the subgraph that corresponds to links from the local domain pointing out to the global domain, Gout is the subgraph containing links from the global domain into the local domain, and Gwithin contains links within the global domain.",
                "We assume that when building a localized search engine, only pages inside the local domain are crawled, and the links between these pages are represented by the subgraph L. The links in Lout are also known, as these point from crawled pages in the local domain to uncrawled pages in the global domain.",
                "As defined in equation (1), PG is the PageRank matrix formed from the global graph G, and we define the global PageRank vector of this graph to be g. Let the n-length vector p∗ be the L1-normalized vector corresponding to the global PageRank of the pages in the local domain L: p∗ = EL g ELg 1 , where EL = [ I | 0 ] is the restriction matrix that selects the components from g corresponding to nodes in L. Let p denote the PageRank vector constructed from the local domain subgraph L. In practice, the observed local PageRank p and the global PageRank p∗ will be quite different.",
                "One would expect that as the size of local matrix L approaches the size of global matrix G, the global PageRank and the observed local PageRank will become more similar.",
                "Thus, one approach to estimating the global PageRank is to crawl the entire global domain, compute its PageRank, and extract the PageRanks of the local domain.",
                "Typically, however, n N , i.e., the number of global pages is much larger than the number of local pages.",
                "Therefore, crawling all global pages will quickly exhaust all local resources (computational, storage, and bandwidth) available to create the local search engine.",
                "We instead seek a supergraph ˆF of our local subgraph L with size O(n).",
                "Our goal Algorithm 2: The FindGlobalPR algorithm.",
                "FindGlobalPR(L, Lout, T, k) Input: L: zero-one adjacency matrix for the local domain, Lout: zero-one outlink matrix from L to global subgraph as in (2), T: number of iterations, k: number of pages to crawl per iteration.",
                "Output: ˆp: an improved estimate of the global PageRank of L. F ← L Fout ← Lout f ← ComputePR(F ) for (i = 1 to T) {Determine which pages to crawl next} pages ← SelectNodes(F , Fout, f, k) Crawl pages, augment F and modify Fout {Update PageRanks for new local domain} f ← ComputePR(F ) end {Extract PageRanks of original local domain & normalize} ˆp ← ELf ELf 1 is to find such a supergraph ˆF with PageRank ˆf, so that ˆf when restricted to L is close to p∗ .",
                "Formally, we seek to minimize GlobalDiff( ˆf) = EL ˆf EL ˆf 1 − p∗ 1 . (3) We choose the L1 norm for measuring the error as it does not place excessive weight on outliers (as the L2 norm does, for example), and also because it is the most commonly used distance measure in the literature for comparing PageRank vectors, as well as for detecting convergence of the algorithm [3].",
                "We propose a greedy framework, given in Algorithm 2, for constructing ˆF .",
                "Initially, F is set to the local subgraph L, and the PageRank f of this graph is computed.",
                "The algorithm then proceeds as follows.",
                "First, the SelectNodes algorithm (which we discuss in the next section) is called and it returns a set of k nodes to crawl next from the set of nodes in the current crawl frontier, Fout.",
                "These selected nodes are then crawled to expand the local subgraph, F , and the PageRanks of this expanded graph are then recomputed.",
                "These steps are repeated for each of T iterations.",
                "Finally, the PageRank vector ˆp, which is restricted to pages within the original local domain, is returned.",
                "Given our computation, bandwidth, and memory restrictions, we will assume that the algorithm will crawl at most O(n) pages.",
                "Since the PageRanks are computed in each iteration of the algorithm, which is an O(n) operation, we will also assume that the number of iterations T is a constant.",
                "Of course, the main challenge here is in selecting which set of k nodes to crawl next.",
                "In the next section, we formally define the problem and give efficient algorithms. 5.",
                "NODE SELECTION In this section, we present node selection algorithms that operate within the greedy framework presented in the previous section.",
                "We first give a well-defined criteria for the page selection problem and provide experimental evidence that this criteria can effectively identify pages that optimize our problem objective (3).",
                "We then present our main al118 Research Track Paper gorithmic contribution of the paper, a method with linear running time that is derived from this page selection criteria.",
                "Finally, we give an intuitive analysis of our algorithm in terms of leaks and flows.",
                "We show that if only the flow is considered, then the resulting method is very similar to a widely used page selection heuristic [6]. 5.1 Formulation For a given page j in the global domain, we define the expanded local graph Fj: Fj = F s uT j 0 , (4) where uj is the zero-one vector containing the outlinks from F into page j, and s contains the inlinks from page j into the local domain.",
                "Note that we do not allow self-links in this framework.",
                "In practice, self-links are often removed, as they only serve to inflate a given pages PageRank.",
                "Observe that the inlinks into F from node j are not known until after node j is crawled.",
                "Therefore, we estimate this inlink vector as the expectation over inlink counts among the set of already crawled pages, s = F T e F T e 1 . (5) In practice, for any given page, this estimate may not reflect the true inlinks from that page.",
                "Furthermore, this expectation is sampled from the set of links within the crawled domain, whereas a better estimate would also use links from the global domain.",
                "However, the latter distribution is not known to a localized search engine, and we contend that the above estimate will, on average, be a better estimate than the uniform distribution, for example.",
                "Let the PageRank of F be f. We express the PageRank f+ j of the expanded local graph Fj as f+ j = (1 − xj)fj xj , (6) where xj is the PageRank of the candidate global node j, and fj is the L1-normalized PageRank vector restricted to the pages in F .",
                "Since directly optimizing our problem goal requires knowing the global PageRank p∗ , we instead propose to crawl those nodes that will have the greatest influence on the PageRanks of pages in the original local domain L: influence(j) = k∈L |fj[k] − f[k]| (7) = EL (fj − f) 1.",
                "Experimentally, the influence score is a very good predictor of our problem objective (3).",
                "For each candidate global node j, figure 1(a) shows the objective function value Global Diff(fj) as a function of the influence of page j.",
                "The local domain used here is a crawl of conservative political pages (we will provide more details about this dataset in section 6); we observed similar results in other domains.",
                "The correlation is quite strong, implying that the influence criteria can effectively identify pages that improve the global PageRank estimate.",
                "As a baseline, figure 1(b) compares our objective with an alternative criteria, outlink count.",
                "The outlink count is defined as the number of outlinks from the local domain to page j.",
                "The correlation here is much weaker. .00001 .0001 .001 .01 0.26 0.262 0.264 0.266 Influence Objective 1 10 100 1000 0.266 0.264 0.262 0.26 Outlink Count Objective (a) (b) Figure 1: (a) The correlation between our influence page selection criteria (7) and the actual objective function (3) value is quite strong. (b) This is in contrast to other criteria, such as outlink count, which exhibit a much weaker correlation. 5.2 Computation As described, for each candidate global page j, the influence score (7) must be computed.",
                "If fj is computed exactly for each global page j, then the PageRank algorithm would need to be run for each of the O(n) such global pages j we consider, resulting in an O(n2 ) computational cost for the node selection method.",
                "Thus, computing the exact value of fj will lead to a quadratic algorithm, and we must instead turn to methods of approximating this vector.",
                "The algorithm we present works by performing one power method iteration used by the PageRank algorithm (Algorithm 1).",
                "The convergence rate for the PageRank algorithm has been shown to equal the random surfer probability α [7, 11].",
                "Given a starting vector x(0) , if k PageRank iterations are performed, the current PageRank solution x(k) satisfies: x(k) − x∗ 1 = O(αk x(0) − x∗ 1), (8) where x∗ is the desired PageRank vector.",
                "Therefore, if only one iteration is performed, choosing a good starting vector is necessary to achieve an accurate approximation.",
                "We partition the PageRank matrix PFj , corresponding to the × subgraph Fj as: PFj = ˜F ˜s ˜uT j w , (9) where ˜F = αF (DF + diag(uj))−1 + (1 − α) e + 1 eT , ˜s = αs + (1 − α) e + 1 , ˜uj = α(DF + diag(uj))−1 uj + (1 − α) e + 1 , w = 1 − α + 1 , and diag(uj) is the diagonal matrix with the (i, i)th entry equal to one if the ith element of uj equals one, and is zero otherwise.",
                "We have assumed here that the random surfer vector is the uniform vector, and that L has no dangling links.",
                "These assumptions are not necessary and serve only to simplify discussion and analysis.",
                "A simple approach for estimating fj is the following.",
                "First, estimate the PageRank f+ j of Fj by computing one PageRank iteration over the matrix PFj , using the starting vector ν = f 0 .",
                "Then, estimate fj by removing the last 119 Research Track Paper component from our estimate of f+ j (i.e., the component corresponding to the added node j), and renormalizing.",
                "The problem with this approach is in the starting vector.",
                "Recall from (6) that xj is the PageRank of the added node j.",
                "The difference between the actual PageRank f+ j of PFj and the starting vector ν is ν − f+ j 1 = xj + f − (1 − xj)fj 1 ≥ xj + | f 1 − (1 − xj) fj 1| = xj + |xj| = 2xj.",
                "Thus, by (8), after one PageRank iteration, we expect our estimate of f+ j to still have an error of about 2αxj.",
                "In particular, for candidate nodes j with relatively high PageRank xj, this method will yield more inaccurate results.",
                "We will next present a method that eliminates this bias and runs in O(n) time. 5.2.1 Stochastic Complementation Since f+ j , as given in (6) is the PageRank of the matrix PFj , we have: fj(1 − xj) xj = ˜F ˜s ˜uT j w fj(1 − xj) xj = ˜F fj(1 − xj) + ˜sxj ˜uT j fj(1 − xj) + wxj .",
                "Solving the above system for fj can be shown to yield fj = ( ˜F + (1 − w)−1 ˜s˜uT j )fj. (10) The matrix S = ˜F +(1−w)−1 ˜s˜uT j is known as the stochastic complement of the column stochastic matrix PFj with respect to the sub matrix ˜F .",
                "The theory of stochastic complementation is well studied, and it can be shown the stochastic complement of an irreducible matrix (such as the PageRank matrix) is unique.",
                "Furthermore, the stochastic complement is also irreducible and therefore has a unique stationary distribution as well.",
                "For an extensive study, see [15].",
                "It can be easily shown that the sub-dominant eigenvalue of S is at most +1 α, where is the size of F .",
                "For sufficiently large , this value will be very close to α.",
                "This is important, as other properties of the PageRank algorithm, notably the algorithms sensitivity, are dependent on this value [11].",
                "In this method, we estimate the length vector fj by computing one PageRank iteration over the × stochastic complement S, starting at the vector f: fj ≈ Sf. (11) This is in contrast to the simple method outlined in the previous section, which first iterates over the ( + 1) × ( + 1) matrix PFj to estimate f+ j , and then removes the last component from the estimate and renormalizes to approximate fj.",
                "The problem with the latter method is in the choice of the ( + 1) length starting vector, ν. Consequently, the PageRank estimate given by the simple method differs from the true PageRank by at least 2αxj, where xj is the PageRank of page j.",
                "By using the stochastic complement, we can establish a tight lower bound of zero for this difference.",
                "To see this, consider the case in which a node k is added to F to form the augmented local subgraph Fk, and that the PageRank of this new graph is (1 − xk)f xk .",
                "Specifically, the addition of page k does not change the PageRanks of the pages in F , and thus fk = f. By construction of the stochastic complement, fk = Sfk, so the approximation given in equation (11) will yield the exact solution.",
                "Next, we present the computational details needed to efficiently compute the quantity fj −f 1 over all known global pages j.",
                "We begin by expanding the difference fj −f, where the vector fj is estimated as in (11), fj − f ≈ Sf − f = αF (DF + diag(uj))−1 f + (1 − α) e + 1 eT f +(1 − w)−1 (˜uT j f)˜s − f. (12) Note that the matrix (DF +diag(uj))−1 is diagonal.",
                "Letting o[k] be the outlink count for page k in F , we can express the kth diagonal element as: (DF + diag(uj))−1 [k, k] = 1 o[k]+1 if uj[k] = 1 1 o[k] if uj[k] = 0 Noting that (o[k] + 1)−1 = o[k]−1 − (o[k](o[k] + 1))−1 and rewriting this in matrix form yields (DF +diag(uj))−1 = D−1 F −D−1 F (DF +diag(uj))−1 diag(uj). (13) We use the same identity to express e + 1 = e − e ( + 1) . (14) Recall that, by definition, we have PF = αF D−1 F +(1−α)e .",
                "Substituting (13) and (14) in (12) yields fj − f ≈ (PF f − f) −αF D−1 F (DF + diag(uj))−1 diag(uj)f −(1 − α) e ( + 1) + (1 − w)−1 (˜uT j f)˜s = x + y + (˜uT j f)z, (15) noting that by definition, f = PF f, and defining the vectors x, y, and z to be x = −αF D−1 F (DF + diag(uj))−1 diag(uj)f (16) y = −(1 − α) e ( + 1) (17) z = (1 − w)−1 ˜s. (18) The first term x is a sparse vector, and takes non-zero values only for local pages k that are siblings of the global page j.",
                "We define (i, j) ∈ F if and only if F [j, i] = 1 (equivalently, page i links to page j) and express the value of the component x[k ] as: x[k ] = −α k:(k,k )∈F ,uj [k]=1 f[k] o[k](o[k] + 1) , (19) where o[k], as before, is the number of outlinks from page k in the local domain.",
                "Note that the last two terms, y and z are not dependent on the current global node j.",
                "Given the function hj(f) = y + (˜uT j f)z 1, the quantity fj − f 1 120 Research Track Paper can be expressed as fj − f 1 = k x[k] + y[k] + (˜uT j f)z[k] = k:x[k]=0 y[k] + (˜uT j f)z[k] + k:x[k]=0 x[k] + y[k] + (˜uT j f)z[k] = hj(f) − k:x[k]=0 y[k] + (˜uT j f)z[k] + k:x[k]=0 x[k] + y[k] + (˜uT j f)z[k] . (20) If we can compute the function hj in linear time, then we can compute each value of fj − f 1 using an additional amount of time that is proportional to the number of nonzero components in x.",
                "These optimizations are carried out in Algorithm 3.",
                "Note that (20) computes the difference between all components of f and fj, whereas our node selection criteria, given in (7), is restricted to the components corresponding to nodes in the original local domain L. Let us examine Algorithm 3 in more detail.",
                "First, the algorithm computes the outlink counts for each page in the local domain.",
                "The algorithm then computes the quantity ˜uT j f for each known global page j.",
                "This inner product can be written as (1 − α) 1 + 1 + α k:(k,j)∈Fout f[k] o[k] + 1 , where the second term sums over the set of local pages that link to page j.",
                "Since the total number of edges in Fout was assumed to have size O( ) (recall that is the number of pages in F ), the running time of this step is also O( ).",
                "The algorithm then computes the vectors y and z, as given in (17) and (18), respectively.",
                "The L1NormDiff method is called on the components of these vectors which correspond to the pages in L, and it estimates the value of EL(y + (˜uT j f)z) 1 for each page j.",
                "The estimation works as follows.",
                "First, the values of ˜uT j f are discretized uniformly into c values {a1, ..., ac}.",
                "The quantity EL(y + aiz) 1 is then computed for each discretized value of ai and stored in a table.",
                "To evaluate EL (y + az) 1 for some a ∈ [a1, ac], the closest discretized value ai is determined, and the corresponding entry in the table is used.",
                "The total running time for this method is linear in and the discretization parameter c (which we take to be a constant).",
                "We note that if exact values are desired, we have also developed an algorithm that runs in O( log ) time that is not described here.",
                "In the main loop, we compute the vector x, as defined in equation (16).",
                "The nested loops iterate over the set of pages in F that are siblings of page j.",
                "Typically, the size of this set is bounded by a constant.",
                "Finally, for each page j, the scores vector is updated over the set of non-zero components k of the vector x with k ∈ L. This set has size equal to the number of local siblings of page j, and is a subset of the total number of siblings of page j.",
                "Thus, each iteration of the main loop takes constant time, and the total running time of the main loop is O( ).",
                "Since we have assumed that the size of F will not grow larger than O(n), the total running time for the algorithm is O(n).",
                "Algorithm 3: Node Selection via Stochastic Complementation.",
                "SC-Select(F , Fout, f, k) Input: F : zero-one adjacency matrix of size corresponding to the current local subgraph, Fout: zero-one outlink matrix from F to global subgraph, f: PageRank of F , k: number of pages to return Output: pages: set of k pages to crawl next {Compute outlink sums for local subgraph} foreach (page j ∈ F ) o[j] ← k:(j,k)∈F F[j, k] end {Compute scalar ˜uT j f for each global node j } foreach (page j ∈ Fout) g[j] ← (1 − α) 1 +1 foreach (page k : (k, j) ∈ Fout) g[j] ← g[j] + α f[k] o[k]+1 end end {Compute vectors y and z as in (17) and (18) } y ← −(1 − α) e ( +1) z ← (1 − w)−1 ˜s {Approximate y + g[j] ∗ z 1 for all values g[j]} norm diffs ←L1NormDiffs(g, ELy, ELz) foreach (page j ∈ Fout) {Compute sparse vector x as in (19)} x ← 0 foreach (page k : (k, j) ∈ Fout) foreach (page k : (k, k ) ∈ F )) x[k ] ← x[k ] − f[k] o[k](o[k]+1) end end x ← αx scores[j] ← norm diffs[j] foreach (k : x[k] > 0 and page k ∈ L) scores[j] ← scores[j] − |y[k] + g[j] ∗ z[k]| +|x[k]+y[k]+g[j]∗z[k])| end end Return k pages with highest scores 5.2.2 PageRank Flows We now present an intuitive analysis of the stochastic complementation method by decomposing the change in PageRank in terms of leaks and flows.",
                "This analysis is motivated by the decomposition given in (15).",
                "PageRank flow is the increase in the local PageRanks originating from global page j.",
                "The flows are represented by the non-negative vector (˜uT j f)z (equations (15) and (18)).",
                "The scalar ˜uT j f can be thought of as the total amount of PageRank flow that page j has available to distribute.",
                "The vector z dictates how the flow is allocated to the local domain; the flow that local page k receives is proportional to (within a constant factor due to the random surfer vector) the expected number of its inlinks.",
                "The PageRank leaks represent the decrease in PageRank resulting from the addition of page j.",
                "The leakage can be quantified in terms of the non-positive vectors x and y (equations (16) and (17)).",
                "For vector x, we can see from equation (19) that the amount of PageRank leaked by a local page is proportional to the weighted sum of the Page121 Research Track Paper Ranks of its siblings.",
                "Thus, pages that have siblings with higher PageRanks (and low outlink counts) will experience more leakage.",
                "The leakage caused by y is an artifact of the random surfer vector.",
                "We will next show that if only the flow term, (˜uT j f)z, is considered, then the resulting method is very similar to a heuristic proposed by Cho et al. [6] that has been widely used for the Crawling Through URL Ordering problem.",
                "This heuristic is computationally cheaper, but as we will see later, not as effective as the Stochastic Complementation method.",
                "Our node selection strategy chooses global nodes that have the largest influence (equation (7)).",
                "If this influence is approximated using only flows, the optimal node j∗ is: j∗ = argmaxj EL ˜uT j fz 1 = argmaxj ˜uT j f EL z 1 = argmaxj ˜uT j f = argmaxj α(DF + diag(uj))−1 uj + (1 − α) e + 1 , f = argmaxjfT (DF + diag(uj))−1 uj.",
                "The resulting page selection score can be expressed as a sum of the PageRanks of each local page k that links to j, where each PageRank value is normalized by o[k]+1.",
                "Interestingly, the normalization that arises in our method differs from the heuristic given in [6], which normalizes by o[k].",
                "The algorithm PF-Select, which is omitted due to lack of space, first computes the quantity fT (DF +diag(uj))−1 uj for each global page j, and then returns the pages with the k largest scores.",
                "To see that the running time for this algorithm is O(n), note that the computation involved in this method is a subset of that needed for the SC-Select method (Algorithm 3), which was shown to have a running time of O(n). 6.",
                "EXPERIMENTS In this section, we provide experimental evidence to verify the effectiveness of our algorithms.",
                "We first outline our experimental methodology and then provide results across a variety of local domains. 6.1 Methodology Given the limited resources available at an academic institution, crawling a section of the web that is of the same magnitude as that indexed by Google or Yahoo! is clearly infeasible.",
                "Thus, for a given local domain, we approximate the global graph by crawling a local neighborhood around the domain that is several orders of magnitude larger than the local subgraph.",
                "Even though such a graph is still orders of magnitude smaller than the true global graph, we contend that, even if there exist some highly influential pages that are very far away from our local domain, it is unrealistic for any local node selection algorithm to find them.",
                "Such pages also tend to be highly unrelated to pages within the local domain.",
                "When explaining our node selection strategies in section 5, we made the simplifying assumption that our local graph contained no dangling nodes.",
                "This assumption was only made to ease our analysis.",
                "Our implementation efficiently handles dangling links by replacing each zero column of our adjacency matrix with the uniform vector.",
                "We evaluate the algorithm using the two node selection strategies given in Section 5.2, and also against the following baseline methods: • Random: Nodes are chosen uniformly at random among the known global nodes. • OutlinkCount: Global nodes with the highest number of outlinks from the local domain are chosen.",
                "At each iteration of the FindGlobalPR algorithm, we evaluate performance by computing the difference between the current PageRank estimate of the local domain, ELf ELf 1 , and the global PageRank of the local domain ELg ELg 1 .",
                "All PageRank calculations were performed using the uniform random surfer vector.",
                "Across all experiments, we set the random surfer parameter α, to be .85, and used a convergence threshold of 10−6 .",
                "We evaluate the difference between the local and global PageRank vectors using three different metrics: the L1 and L∞ norms, and Kendalls tau.",
                "The L1 norm measures the sum of the absolute value of the differences between the two vectors, and the L∞ norm measures the absolute value of the largest difference.",
                "Kendalls tau metric is a popular rank correlation measure used to compare PageRanks [2, 11].",
                "This metric can be computed by counting the number of pairs of pairs that agree in ranking, and subtracting from that the number of pairs of pairs that disagree in ranking.",
                "The final value is then normalized by the total number of n 2 such pairs, resulting in a [−1, 1] range, where a negative score signifies anti-correlation among rankings, and values near one correspond to strong rank correlation. 6.2 Results Our experiments are based on two large web crawls and were downloaded using the web crawler that is part of the Nutch open source search engine project [18].",
                "All crawls were restricted to only http pages, and to limit the number of dynamically generated pages that we crawl, we ignored all pages with urls containing any of the characters ?, *, @, or =.",
                "The first crawl, which we will refer to as the edu dataset, was seeded by homepages of the top 100 graduate computer science departments in the USA, as rated by the US News and World Report [16], and also by the home pages of their respective institutions.",
                "A crawl of depth 5 was performed, restricted to pages within the .edu domain, resulting in a graph with approximately 4.7 million pages and 22.9 million links.",
                "The second crawl was seeded by the set of pages under the politics hierarchy in the dmoz open directory project[17].",
                "We crawled all pages up to four links away, which yielded a graph with 4.4 million pages and 17.3 million links.",
                "Within the edu crawl, we identified the five site-specific domains corresponding to the websites of the top five graduate computer science departments, as ranked by the US News and World Report.",
                "This yielded local domains of various sizes, from 10,626 (UIUC) to 59,895 (Berkeley).",
                "For each of these site-specific domains with size n, we performed 50 iterations of the FindGlobalPR algorithm to crawl a total of 2n additional nodes.",
                "Figure 2(a) gives the (L1) difference from the PageRank estimate at each iteration to the global PageRank, for the Berkeley local domain.",
                "The performance of this dataset was representative of the typical performance across the five computer science sitespecific local domains.",
                "Initially, the L1 difference between the global and local PageRanks ranged from .0469 (Stanford) to .149 (MIT).",
                "For the first several iterations, the 122 Research Track Paper 0 5 10 15 20 25 30 35 40 45 50 0.015 0.02 0.025 0.03 0.035 0.04 0.045 0.05 0.055 Number of Iterations GlobalandLocalPageRankDifference(L1) Stochastic Complement PageRank Flow Outlink Count Random 0 10 20 30 40 50 0 0.05 0.1 0.15 0.2 0.25 0.3 0.35 Number of Iterations GlobalandLocalPageRankDifference(L1) Stochastic Complement PageRank Flow Outlink Count Random 0 5 10 15 20 25 0.16 0.18 0.2 0.22 0.24 0.26 0.28 0.3 0.32 0.34 Number of Iterations GlobalandLocalPageRankDifference(L1) Stochastic Complement PageRank Flow Outlink Count Random (a) www.cs.berkeley.edu (b) www.enterstageright.com (c) Politics Figure 2: L1 difference between the estimated and true global PageRanks for (a) Berkeleys computer science website, (b) the site-specific domain, www.enterstageright.com, and (c) the politics topic-specific domain.",
                "The stochastic complement method outperforms all other methods across various domains. three link-based methods all outperform the random selection heuristic.",
                "After these initial iterations, the random heuristic tended to be more competitive with (or even outperform, as in the Berkeley local domain) the outlink count and PageRank flow heuristics.",
                "In all tests, the stochastic complementation method either outperformed, or was competitive with, the other methods.",
                "Table 1 gives the average difference between the final estimated global PageRanks and the true global PageRanks for various distance measures.",
                "Algorithm L1 L∞ Kendall Stoch.",
                "Comp. .0384 .00154 .9257 PR Flow .0470 .00272 .8946 Outlink .0419 .00196 .9053 Random .0407 .00204 .9086 Table 1: Average final performance of various node selection strategies for the five site-specific computer science local domains.",
                "Note that Kendalls Tau measures similarity, while the other metrics are dissimilarity measures.",
                "Stochastic Complementation clearly outperforms the other methods in all metrics.",
                "Within the politics dataset, we also performed two sitespecific tests for the largest websites in the crawl: www.adamsmith.org, the website for the London based Adam Smith Institute, and www.enterstageright.com, an online conservative journal.",
                "As with the edu local domains, we ran our algorithm for 50 iterations, crawling a total of 2n nodes.",
                "Figure 2 (b) plots the results for the www.enterstageright.com domain.",
                "In contrast to the edu local domains, the Random and OutlinkCount methods were not competitive with either the SC-Select or the PF-Select methods.",
                "Among all datasets and all node selection methods, the stochastic complementation method was most impressive in this dataset, realizing a final estimate that differed only .0279 from the global PageRank, a ten-fold improvement over the initial local PageRank difference of .299.",
                "For the Adam Smith local domain, the initial difference between the local and global PageRanks was .148, and the final estimates given by the SC-Select, PF-Select, OutlinkCount, and Random methods were .0208, .0193, .0222, and .0356, respectively.",
                "Within the politics dataset, we constructed four topicspecific local domains.",
                "The first domain consisted of all pages in the dmoz politics category, and also all pages within each of these sites up to two links away.",
                "This yielded a local domain of 90,811 pages, and the results are given in figure 2 (c).",
                "Because of the larger size of the topic-specific domains, we ran our algorithm for only 25 iterations to crawl a total of n nodes.",
                "We also created topic-specific domains from three political sub-topics: liberalism, conservatism, and socialism.",
                "The pages in these domains were identified by their corresponding dmoz categories.",
                "For each sub-topic, we set the local domain to be all pages within three links from the corresponding dmoz category pages.",
                "Table 2 summarizes the performance of these three topic-specific domains, and also the larger political domain.",
                "To quantify a global page js effect on the global PageRank values of pages in the local domain, we define page js impact to be its PageRank value, g[j], normalized by the fraction of its outlinks pointing to the local domain: impact(j) = oL[j] o[j] · g[j], where, oL[j] is the number of outlinks from page j to pages in the local domain L, and o[j] is the total number of js outlinks.",
                "In terms of the random surfer model, the impact of page j is the probability that the random surfer (1) is currently at global page j in her random walk and (2) takes an outlink to a local page, given that she has already decided not to jump to a random page.",
                "For the politics local domain, we found that many of the pages with high impact were in fact political pages that should have been included in the dmoz politics topic, but were not.",
                "For example, the two most influential global pages were the political search engine www.askhenry.com, and the home page of the online political magazine, www.policyreview.com.",
                "Among non-political pages, the home page of the journal Education Next was most influential.",
                "The journal is freely available online and contains articles regarding various aspect of K-12 education in America.",
                "To provide some anecdotal evidence for the effectiveness of our page selection methods, we note that the SC-Select method chose 11 pages within the www.educationnext.org domain, the PF-Select method discovered 7 such pages, while the OutlinkCount and Random methods found only 6 pages each.",
                "For the conservative political local domain, the socialist website www.ornery.org had a very high impact score.",
                "This 123 Research Track Paper All Politics: Algorithm L1 L2 Kendall Stoch.",
                "Comp. .1253 .000700 .8671 PR Flow .1446 .000710 .8518 Outlink .1470 .00225 .8642 Random .2055 .00203 .8271 Conservativism: Algorithm L1 L2 Kendall Stoch.",
                "Comp. .0496 .000990 .9158 PR Flow .0554 .000939 .9028 Outlink .0602 .00527 .9144 Random .1197 .00102 .8843 Liberalism: Algorithm L1 L2 Kendall Stoch.",
                "Comp. .0622 .001360 .8848 PR Flow .0799 .001378 .8669 Outlink .0763 .001379 .8844 Random .1127 .001899 .8372 Socialism: Algorithm L1 L∞ Kendall Stoch.",
                "Comp. .04318 .00439 .9604 PR Flow .0450 .004251 .9559 Outlink .04282 .00344 .9591 Random .0631 .005123 .9350 Table 2: Final performance among node selection strategies for the four political topic-specific crawls.",
                "Note that Kendalls Tau measures similarity, while the other metrics are dissimilarity measures. was largely due to a link from the front page of this site to an article regarding global warming published by the National Center for Public Policy Research, a conservative research group in Washington, DC.",
                "Not surprisingly, the global PageRank of this article (which happens to be on the home page of the NCCPR, www.nationalresearch.com), was approximately .002, whereas the local PageRank of this page was only .00158.",
                "The SC-Select method yielded a global PageRank estimate of approximately .00182, the PFSelect method estimated a value of .00167, and the Random and OutlinkCount methods yielded values of .01522 and .00171, respectively. 7.",
                "RELATED WORK The node selection framework we have proposed is similar to the url ordering for <br>crawling problem</br> proposed by Cho et al. in [6].",
                "Whereas our framework seeks to minimize the difference between the global and local PageRank, the objective used in [6] is to crawl the most highly (globally) ranked pages first.",
                "They propose several node selection algorithms, including the outlink count heuristic, as well as a variant of our PF-Select algorithm which they refer to as the PageRank ordering metric.",
                "They found this method to be most effective in optimizing their objective, as did a recent survey of these methods by Baeza-Yates et al. [1].",
                "Boldi et al. also experiment within a similar crawling framework in [2], but quantify their results by comparing Kendalls rank correlation between the PageRanks of the current set of crawled pages and those of the entire global graph.",
                "They found that node selection strategies that crawled pages with the highest global PageRank first actually performed worse (with respect to Kendalls Tau correlation between the local and global PageRanks) than basic depth first or breadth first strategies.",
                "However, their experiments differ from our work in that our node selection algorithms do not use (or have access to) global PageRank values.",
                "Many algorithmic improvements for computing exact PageRank values have been proposed [9, 10, 14].",
                "If such algorithms are used to compute the global PageRanks of our local domain, they would all require O(N) computation, storage, and bandwidth, where N is the size of the global domain.",
                "This is in contrast to our method, which approximates the global PageRank and scales linearly with the size of the local domain.",
                "Wang and Dewitt [22] propose a system where the set of web servers that comprise the global domain communicate with each other to compute their respective global PageRanks.",
                "For a given web server hosting n pages, the computational, bandwidth, and storage requirements are also linear in n. One drawback of this system is that the number of distinct web servers that comprise the global domain can be very large.",
                "For example, our edu dataset contains websites from over 3,200 different universities; coordinating such a system among a large number of sites can be very difficult.",
                "Gan, Chen, and Suel propose a method for estimating the PageRank of a single page [5] which uses only constant bandwidth, computation, and space.",
                "Their approach relies on the availability of a remote connectivity server that can supply the set of inlinks to a given page, an assumption not used in our framework.",
                "They experimentally show that a reasonable estimate of the nodes PageRank can be obtained by visiting at most a few hundred nodes.",
                "Using their algorithm for our problem would require that either the entire global domain first be downloaded or a connectivity server be used, both of which would lead to very large web graphs. 8.",
                "CONCLUSIONS AND FUTURE WORK The internet is growing exponentially, and in order to navigate such a large repository as the web, global search engines have established themselves as a necessity.",
                "Along with the ubiquity of these large-scale search engines comes an increase in search users expectations.",
                "By providing complete and isolated coverage of a particular web domain, localized search engines are an effective outlet to quickly locate content that could otherwise be difficult to find.",
                "In this work, we contend that the use of global PageRank in a localized search engine can improve performance.",
                "To estimate the global PageRank, we have proposed an iterative node selection framework where we select which pages from the global frontier to crawl next.",
                "Our primary contribution is our stochastic complementation page selection algorithm.",
                "This method crawls nodes that will most significantly impact the local domain and has running time linear in the number of nodes in the local domain.",
                "Experimentally, we validate these methods across a diverse set of local domains, including seven site-specific domains and four topic-specific domains.",
                "We conclude that by crawling an additional n or 2n pages, our methods find an estimate of the global PageRanks that is up to ten times better than just using the local PageRanks.",
                "Furthermore, we demonstrate that our algorithm consistently outperforms other existing heuristics. 124 Research Track Paper Often times, topic-specific domains are discovered using a focused web crawler which considers a pages content in conjunction with link anchor text to decide which pages to crawl next [4].",
                "Although such crawlers have proven to be quite effective in discovering topic-related content, many irrelevant pages are also crawled in the process.",
                "Typically, these pages are deleted and not indexed by the localized search engine.",
                "These pages can of course provide valuable information regarding the global PageRank of the local domain.",
                "One way to integrate these pages into our framework is to start the FindGlobalPR algorithm with the current subgraph F equal to the set of pages that were crawled by the focused crawler.",
                "The global PageRank estimation framework, along with the node selection algorithms presented, all require O(n) computation per iteration and bandwidth proportional to the number of pages crawled, Tk.",
                "If the number of iterations T is relatively small compared to the number of pages crawled per iteration, k, then the bottleneck of the algorithm will be the crawling phase.",
                "However, as the number of iterations increases (relative to k), the bottleneck will reside in the node selection computation.",
                "In this case, our algorithms would benefit from constant factor optimizations.",
                "Recall that the FindGlobalPR algorithm (Algorithm 2) requires that the PageRanks of the current expanded local domain be recomputed in each iteration.",
                "Recent work by Langville and Meyer [12] gives an algorithm to quickly recompute PageRanks of a given webgraph if a small number of nodes are added.",
                "This algorithm was shown to give speedup of five to ten times on some datasets.",
                "We plan to investigate this and other such optimizations as future work.",
                "In this paper, we have objectively evaluated our methods by measuring how close our global PageRank estimates are to the actual global PageRanks.",
                "To determine the benefit of using global PageRanks in a localized search engine, we suggest a user study in which users are asked to rate the quality of search results for various search queries.",
                "For some queries, only the local PageRanks are used in ranking, and for the remaining queries, local PageRanks and the approximate global PageRanks, as computed by our algorithms, are used.",
                "The results of such a study can then be analyzed to determine the added benefit of using the global PageRanks computed by our methods, over just using the local PageRanks.",
                "Acknowledgements.",
                "This research was supported by NSF grant CCF-0431257, NSF Career Award ACI-0093404, and a grant from Sabre, Inc. 9.",
                "REFERENCES [1] R. Baeza-Yates, M. Marin, C. Castillo, and A. Rodriguez.",
                "Crawling a country: better strategies than breadth-first for web page ordering.",
                "World-Wide Web Conference, 2005. [2] P. Boldi, M. Santini, and S. Vigna.",
                "Do your worst to make the best: paradoxical effects in pagerank incremental computations.",
                "Workshop on Web Graphs, 3243:168-180, 2004. [3] S. Brin and L. Page.",
                "The anatomy of a large-scale hypertextual web search engine.",
                "Computer Networks and ISDN Systems, 33(1-7):107-117, 1998. [4] S. Chakrabarti, M. van den Berg, and B. Dom.",
                "Focused crawling: a new approach to topic-specific web resource discovery.",
                "World-Wide Web Conference, 1999. [5] Y. Chen, Q. Gan, and T. Suel.",
                "Local methods for estimating pagerank values.",
                "Conference on Information and Knowledge Management, 2004. [6] J. Cho, H. Garcia-Molina, and L. Page.",
                "Efficient crawling through url ordering.",
                "World-Wide Web Conference, 1998. [7] T. H. Haveliwala and S. D. Kamvar.",
                "The second eigenvalue of the Google matrix.",
                "Technical report, Stanford University, 2003. [8] T. Joachims, F. Radlinski, L. Granka, A. Cheng, C. Tillekeratne, and A. Patel.",
                "Learning retrieval functions from implicit feedback. http://www.cs.cornell.edu/People/tj/career. [9] S. D. Kamvar, T. H. Haveliwala, C. D. Manning, and G. H. Golub.",
                "Exploiting the block structure of the web for computing pagerank.",
                "World-Wide Web Conference, 2003. [10] S. D. Kamvar, T. H. Haveliwala, C. D. Manning, and G. H. Golub.",
                "Extrapolation methods for accelerating pagerank computation.",
                "World-Wide Web Conference, 2003. [11] A. N. Langville and C. D. Meyer.",
                "Deeper inside pagerank.",
                "Internet Mathematics, 2004. [12] A. N. Langville and C. D. Meyer.",
                "Updating the stationary vector of an irreducible markov chain with an eye on Googles pagerank.",
                "SIAM Journal on Matrix Analysis, 2005. [13] P. Lyman, H. R. Varian, K. Swearingen, P. Charles, N. Good, L. L. Jordan, and J. Pal.",
                "How much information 2003?",
                "School of Information Management and System, University of California at Berkely, 2003. [14] F. McSherry.",
                "A uniform approach to accelerated pagerank computation.",
                "World-Wide Web Conference, 2005. [15] C. D. Meyer.",
                "Stochastic complementation, uncoupling markov chains, and the theory of nearly reducible systems.",
                "SIAM Review, 31:240-272, 1989. [16] US News and World Report. http://www.usnews.com. [17] Dmoz open directory project. http://www.dmoz.org. [18] Nutch open source search engine. http://www.nutch.org. [19] F. Radlinski and T. Joachims.",
                "Query chains: learning to rank from implicit feedback.",
                "ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, 2005. [20] S. Raghavan and H. Garcia-Molina.",
                "Crawling the hidden web.",
                "In Proceedings of the Twenty-seventh International Conference on Very Large Databases, 2001. [21] T. Tin Tang, D. Hawking, N. Craswell, and K. Griffiths.",
                "Focused crawling for both topical relevance and quality of medical information.",
                "Conference on Information and Knowledge Management, 2005. [22] Y. Wang and D. J. DeWitt.",
                "Computing pagerank in a distributed internet search system.",
                "Proceedings of the 30th VLDB Conference, 2004. 125 Research Track Paper"
            ],
            "original_annotated_samples": [
                "RELATED WORK The node selection framework we have proposed is similar to the url ordering for <br>crawling problem</br> proposed by Cho et al. in [6]."
            ],
            "translated_annotated_samples": [
                "TRABAJO RELACIONADO El marco de selección de nodos que hemos propuesto es similar al <br>problema de ordenación de URL para el rastreo</br> propuesto por Cho et al. en [6]."
            ],
            "translated_text": "Estimando el PageRank Global de Comunidades Web Jason V. Davis Dept. Departamento de Ciencias de la Computación Universidad de Texas en Austin Austin, TX 78712 jdavis@cs.utexas.edu Inderjit S. Dhillon Departamento de Ciencias de la Computación Universidad de Texas en Austin Austin, TX 78712 inderjit@cs.utexas.edu RESUMEN Los motores de búsqueda localizados son sistemas a pequeña escala que indexan una comunidad particular en la web. Ofrecen varios beneficios en comparación con sus contrapartes a gran escala, ya que son relativamente económicos de construir y pueden proporcionar una capacidad de búsqueda más precisa y completa en sus dominios relevantes. Una desventaja que tienen estos sistemas en comparación con los motores de búsqueda a gran escala es la falta de valores globales de PageRank. Se necesita esa información para evaluar el valor de las páginas en el dominio de búsqueda localizada dentro del contexto de la web en su totalidad. En este artículo, presentamos algoritmos bien fundamentados para estimar los valores globales de PageRank de un dominio local. Los algoritmos son altamente escalables en el sentido de que, dado un dominio local de tamaño n, utilizan recursos de O(n) que incluyen tiempo de computación, ancho de banda y almacenamiento. Probamos nuestros métodos en una variedad de dominios localizados, incluyendo dominios específicos del sitio y dominios específicos del tema. Demostramos que al rastrear tan solo n o 2n páginas adicionales, nuestros métodos pueden proporcionar excelentes estimaciones globales de PageRank. Categorías y Descriptores de Asignaturas H.3.3 [Almacenamiento y Recuperación de Información]: Búsqueda y Recuperación de Información; G.1.3 [Análisis Numérico]: Álgebra Lineal Numérica; G.3 [Probabilidad y Estadística]: Procesos de Markov Términos Generales PageRank, Cadena de Markov, Complementación Estocástica. Los motores de búsqueda localizados son motores de búsqueda a pequeña escala que indexan solo una comunidad específica de la web. Tales comunidades pueden ser dominios específicos del sitio, como páginas dentro del dominio cs.utexas.edu, o comunidades relacionadas con un tema, por ejemplo, sitios web políticos. En comparación con el grafo web rastreado e indexado por los motores de búsqueda a gran escala, el tamaño de estas comunidades locales suele ser típicamente órdenes de magnitud más pequeño. Por consiguiente, los recursos computacionales necesarios para construir un motor de búsqueda de este tipo también son igualmente más ligeros. Al restringirse a secciones más pequeñas y manejables de la web, los motores de búsqueda localizados también pueden ofrecer capacidades de búsqueda más precisas y completas dentro de sus respectivos dominios. Una desventaja de los índices localizados es la falta de información global necesaria para calcular clasificaciones basadas en enlaces. El algoritmo PageRank [3] ha demostrado ser una medida efectiva de este tipo. En general, el PageRank de una página dada depende de las páginas en todo el grafo web. En el contexto de un motor de búsqueda localizado, si los PageRanks se calculan utilizando solo el subgrafo local, entonces esperaríamos que los PageRanks resultantes reflejen la popularidad percibida dentro de la comunidad local y no de la web en su totalidad. Por ejemplo, consideremos un motor de búsqueda localizado que indexa páginas políticas con puntos de vista conservadores. Una persona que desee investigar las opiniones sobre el calentamiento global dentro de la comunidad política conservadora puede encontrarse con numerosas opiniones de este tipo en varios sitios web. Si solo se dispone de valores de PageRank locales, entonces los resultados de búsqueda reflejarán solo creencias fuertemente arraigadas dentro de la comunidad. Sin embargo, si los PageRanks globales también están disponibles, entonces los resultados pueden reflejar adicionalmente las opiniones de los externos sobre la comunidad conservadora (es decir, aquellos documentos a los que los liberales acceden con mayor frecuencia dentro de la comunidad conservadora). Por lo tanto, para muchos motores de búsqueda localizados, la incorporación de PageRanks globales puede mejorar la calidad de los resultados de búsqueda. Sin embargo, el número de páginas que indexa un motor de búsqueda local suele ser órdenes de magnitud más pequeño que el número de páginas indexadas por sus contrapartes a gran escala. Los motores de búsqueda localizados no tienen el ancho de banda, la capacidad de almacenamiento o la potencia computacional para rastrear, descargar y calcular los PageRanks globales de toda la web. En este trabajo, presentamos un método para aproximar los PageRanks globales de un dominio local utilizando recursos del mismo orden que los necesarios para calcular los PageRanks del subgrafo local. Nuestro método propuesto busca un supergrafo de nuestro subgrafo local de manera que los PageRanks locales dentro de este supergrafo estén cerca de los verdaderos PageRanks globales. Construimos este supergrafo mediante el rastreo iterativo de páginas globales en la frontera web actual, es decir, páginas globales con enlaces entrantes de páginas que ya han sido rastreadas. Para proporcionar a 116 Research Track Paper una buena aproximación a los PageRanks globales, es necesario tener cuidado al elegir qué páginas rastrear a continuación; en este documento, presentamos un algoritmo de selección de páginas bien fundamentado que también tiene un buen rendimiento empírico. Este algoritmo se deriva de un objetivo de problema bien definido y tiene un tiempo de ejecución lineal en el número de nodos locales. Experimentamos en varios tipos de subgrafos locales, incluidas cuatro comunidades relacionadas con el tema y varios dominios específicos del sitio. Para evaluar el rendimiento, medimos la diferencia entre la estimación actual del PageRank global y el PageRank global, en función del número de páginas rastreadas. Comparamos nuestro algoritmo con varios heurísticos y también con un algoritmo base que elige páginas al azar, y demostramos que nuestro método supera a estos otros métodos. Finalmente, demostramos empíricamente que, dado un dominio local de tamaño n, podemos proporcionar buenas aproximaciones a los valores globales de PageRank rastreando como máximo n o 2n páginas adicionales. El documento está organizado de la siguiente manera. La sección 2 ofrece una visión general de los motores de búsqueda localizados y destaca sus ventajas sobre los motores de búsqueda globales. La sección 3 proporciona antecedentes sobre el algoritmo PageRank. La sección 4 define formalmente nuestro problema, y la sección 5 presenta nuestros criterios de selección de páginas y deriva nuestros algoritmos. La sección 6 presenta los resultados experimentales, la sección 7 ofrece una visión general del trabajo relacionado y, finalmente, las conclusiones se presentan en la sección 8. MOTORES DE BÚSQUEDA LOCALIZADOS Los motores de búsqueda localizados indexan una sola comunidad de la web, típicamente una comunidad específica del sitio o una comunidad específica del tema. Los motores de búsqueda localizados disfrutan de tres ventajas principales sobre sus contrapartes a gran escala: son relativamente económicos de construir, pueden ofrecer una capacidad de búsqueda más precisa dentro de su dominio local y pueden proporcionar un índice más completo. Los recursos necesarios para construir un motor de búsqueda global son enormes. Un estudio de 2003 realizado por Lyman et al. [13] encontró que la web superficial (sitios estáticos de acceso público) consta de 8.9 mil millones de páginas, y que el tamaño promedio de estas páginas es de aproximadamente 18.7 kilobytes. Para descargar un rastreo de este tamaño, se necesita aproximadamente 167 terabytes de espacio. Para un investigador que desee construir un motor de búsqueda con acceso a un par de estaciones de trabajo o un servidor pequeño, un almacenamiento de esta magnitud simplemente no está disponible. Sin embargo, construir un motor de búsqueda localizado sobre una comunidad web de cien mil páginas solo requeriría unos pocos gigabytes de almacenamiento. La carga computacional necesaria para soportar consultas de búsqueda sobre una base de datos de este tamaño es más manejable también. Observamos que, para los motores de búsqueda específicos de un tema, la comunidad relevante puede ser identificada y descargada de manera eficiente utilizando un rastreador enfocado [21, 4]. Para dominios específicos del sitio, el dominio local está fácilmente disponible en su propio servidor web. Esto evita la necesidad de rastreo o indexación, y por lo tanto se puede garantizar un índice completo y actualizado del dominio. Esto contrasta con sus contrapartes a gran escala, las cuales sufren de varias deficiencias. Primero, el rastreo de páginas generadas dinámicamente en la web oculta ha sido objeto de investigación [20] y es una tarea no trivial para un rastreador externo. En segundo lugar, los dominios específicos del sitio pueden habilitar la política de exclusión de robots. Esto prohíbe a los rastreadores de motores de búsqueda externos descargar contenido del dominio, y en su lugar un motor de búsqueda externo debe depender de enlaces externos y texto ancla para indexar estas páginas restringidas. Al restringirse a un dominio específico de internet, un motor de búsqueda localizado puede proporcionar resultados de búsqueda más precisos. Considera la consulta de búsqueda ambigua canónica, jaguar, que puede referirse tanto al fabricante de automóviles como al animal. Un científico que intenta investigar el hábitat y la historia evolutiva de un jaguar puede tener más éxito utilizando un motor de búsqueda específico de zoología bien ajustado que consultando Google con múltiples búsquedas de palabras clave y navegando a través de resultados irrelevantes. Recientemente se propuso un método para aprender funciones de clasificación mejores para la recuperación por Radlinski y Joachims [19] y se ha aplicado a varios dominios locales, incluido el sitio web de la Universidad de Cornell [8]. 3. PAGERANK RESUMEN El algoritmo PageRank define la importancia de las páginas web analizando la estructura de hipervínculos subyacente de un grafo web. El algoritmo funciona construyendo una cadena de Markov a partir de la estructura de enlaces del grafo web y calculando su distribución estacionaria. Una forma de calcular la distribución estacionaria de una cadena de Markov es encontrar la distribución límite de un paseo aleatorio sobre la cadena. Por lo tanto, el algoritmo PageRank utiliza lo que a veces se conoce como el modelo del surfista aleatorio. En cada paso de la caminata aleatoria, el surfista sigue un enlace de salida de la página actual (es decir, el nodo actual en la cadena), o salta a una página aleatoria en la web. Ahora definimos con precisión el problema de PageRank. Sea U una matriz de adyacencia m × m para un grafo web dado tal que Uji = 1 si la página i enlaza a la página j y Uji = 0 en caso contrario. Definimos la matriz de PageRank PU como: PU = αUD−1 U + (1 − α)veT , (1) donde DU es la matriz diagonal (única) tal que UD−1 U es estocástica por columnas, α es un escalar dado tal que 0 ≤ α ≤ 1, e es el vector de todos unos, y v es un vector no negativo, L1-normalizado, a veces llamado vector de navegante aleatorio. Ten en cuenta que la matriz D−1 U está bien definida solo si cada columna de U tiene al menos una entrada distinta de cero, es decir, cada página en el grafo web tiene al menos un enlace de salida. En presencia de nodos colgantes que no tienen enlaces de salida, una solución comúnmente utilizada, propuesta por Brin et al. [3], es reemplazar cada columna de ceros de U por un vector no negativo, normalizado en L1. El vector PageRank r es el eigenvector dominante de la matriz PageRank, r = PU r. Supondremos, sin pérdida de generalidad, que r tiene una norma L1 de uno. Computacionalmente, r se puede calcular utilizando el método de la potencia. Este método primero elige un vector inicial aleatorio r(0) y, de forma iterativa, multiplica el vector actual por la matriz de PageRank PU; ver Algoritmo 1. En general, cada iteración del método de la potencia puede requerir O(m2) operaciones cuando PU es una matriz densa. Sin embargo, en la práctica, el número de enlaces en un grafo web será del orden del número de páginas. Al explotar la dispersión de la matriz de PageRank, el trabajo por iteración se puede reducir a O(km), donde k es el número promedio de enlaces por página web. También se ha demostrado que el número total de iteraciones necesarias para la convergencia es proporcional a α y no depende del tamaño del grafo web [11, 7]. Finalmente, el espacio total necesario también es O(km), principalmente para almacenar la matriz U. 117 Research Track Paper Algorithm 1: Un algoritmo de tiempo lineal (por iteración) para calcular PageRank. CalcularPR(U) Entrada: U: Matriz de adyacencia. Salida: vector de PageRank. Elige (aleatoriamente) un vector inicial no negativo r(0) tal que r(0) 1 = 1. i ← 0 repetir i ← i + 1 ν ← αUD−1 U r(i−1) {α es la probabilidad de navegación aleatoria} r(i) ← ν + (1 − α)v {v es el vector del navegante aleatorio.} hasta que r(i) − r(i−1) < δ {δ es el umbral de convergencia.} r ← r(i) 4. Dada un dominio local L, sea G una matriz de adyacencia N × N para el componente conectado completo de la web que contiene L, tal que Gji = 1 si la página i enlaza a la página j y Gji = 0 en caso contrario. Sin pérdida de generalidad, vamos a dividir G de la siguiente manera: G = L Gout Lout Gwithin, donde L es el subgrafo local de n × n correspondiente a los enlaces dentro del dominio local, Lout es el subgrafo que corresponde a los enlaces desde el dominio local apuntando hacia el dominio global, Gout es el subgrafo que contiene los enlaces desde el dominio global hacia el dominio local, y Gwithin contiene los enlaces dentro del dominio global. Suponemos que al construir un motor de búsqueda localizado, solo se rastrean las páginas dentro del dominio local, y los enlaces entre estas páginas están representados por el subgrafo L. También se conocen los enlaces en Lout, ya que estos apuntan desde las páginas rastreadas en el dominio local a las páginas no rastreadas en el dominio global. Como se define en la ecuación (1), PG es la matriz de PageRank formada a partir del grafo global G, y definimos el vector de PageRank global de este grafo como g. Sea el vector de longitud n p∗ el vector L1-normalizado que corresponde al PageRank global de las páginas en el dominio local L: p∗ = EL g ELg 1 , donde EL = [ I | 0 ] es la matriz de restricción que selecciona los componentes de g correspondientes a los nodos en L. Sea p el vector de PageRank construido a partir del subgrafo del dominio local L. En la práctica, el PageRank local observado p y el PageRank global p∗ serán bastante diferentes. Se esperaría que a medida que el tamaño de la matriz local L se acerque al tamaño de la matriz global G, el PageRank global y el PageRank local observado se vuelvan más similares. Por lo tanto, un enfoque para estimar el PageRank global es rastrear todo el dominio global, calcular su PageRank y extraer los PageRanks del dominio local. Por lo general, sin embargo, n N, es decir, el número de páginas globales es mucho mayor que el número de páginas locales. Por lo tanto, rastrear todas las páginas globales agotará rápidamente todos los recursos locales (computacionales, de almacenamiento y de ancho de banda) disponibles para crear el motor de búsqueda local. En cambio, buscamos un supergrafo ˆF de nuestro subgrafo local L con tamaño O(n). Nuestro objetivo es el Algoritmo 2: El algoritmo FindGlobalPR. EncuentraGlobalPR(L, Lout, T, k) Entrada: L: matriz de adyacencia de ceros y unos para el dominio local, Lout: matriz de enlaces de ceros y unos desde L al subgrafo global como en (2), T: número de iteraciones, k: número de páginas a rastrear por iteración. Salida: ˆp: una estimación mejorada del PageRank global de L. F ← L Fout ← Lout f ← CalcularPR(F) para (i = 1 a T) {Determinar qué páginas rastrear a continuación} páginas ← SeleccionarNodos(F, Fout, f, k) Rastrear páginas, aumentar F y modificar Fout {Actualizar PageRanks para el nuevo dominio local} f ← CalcularPR(F) fin {Extraer PageRanks del dominio local original y normalizar} ˆp ← ELf ELf 1 es encontrar un supergrafo ˆF con PageRank ˆf, de modo que ˆf cuando se restringe a L esté cerca de p∗. Formalmente, buscamos minimizar GlobalDiff( ˆf) = EL ˆf EL ˆf 1 − p∗ 1 . (3) Elegimos la norma L1 para medir el error ya que no otorga un peso excesivo a los valores atípicos (como lo hace la norma L2, por ejemplo), y también porque es la medida de distancia más comúnmente utilizada en la literatura para comparar vectores de PageRank, así como para detectar la convergencia del algoritmo [3]. Proponemos un marco codicioso, presentado en el Algoritmo 2, para construir ˆF. Inicialmente, F se establece en el subgrafo local L, y se calcula el PageRank f de este grafo. El algoritmo luego procede de la siguiente manera. Primero, se llama al algoritmo SelectNodes (que discutimos en la siguiente sección) y devuelve un conjunto de k nodos para rastrear a continuación del conjunto de nodos en la frontera de rastreo actual, Fout. Estos nodos seleccionados son luego rastreados para expandir el subgrafo local, F, y los PageRanks de este grafo expandido son luego recalculados. Estos pasos se repiten para cada una de las T iteraciones. Finalmente, se devuelve el vector PageRank ˆp, el cual está restringido a las páginas dentro del dominio local original. Dadas nuestras restricciones de computación, ancho de banda y memoria, asumiremos que el algoritmo rastreará como máximo O(n) páginas. Dado que los PageRanks se calculan en cada iteración del algoritmo, lo cual es una operación O(n), también asumiremos que el número de iteraciones T es una constante. Por supuesto, el principal desafío aquí radica en seleccionar qué conjunto de k nodos rastrear a continuación. En la siguiente sección, definimos formalmente el problema y presentamos algoritmos eficientes. 5. SELECCIÓN DE NODO En esta sección, presentamos algoritmos de selección de nodo que operan dentro del marco codicioso presentado en la sección anterior. Primero damos un criterio bien definido para el problema de selección de páginas y proporcionamos evidencia experimental de que este criterio puede identificar de manera efectiva las páginas que optimizan nuestro objetivo del problema (3). A continuación, presentamos nuestra principal contribución algorítmica del artículo de investigación al118, un método con tiempo de ejecución lineal que se deriva de los criterios de selección de esta página. Finalmente, ofrecemos un análisis intuitivo de nuestro algoritmo en términos de fugas y flujos. Mostramos que si solo se considera el flujo, entonces el método resultante es muy similar a una heurística de selección de páginas ampliamente utilizada [6]. 5.1 Formulación Para una página dada j en el dominio global, definimos el grafo local expandido Fj: Fj = F s uT j 0, (4) donde uj es el vector de ceros y unos que contiene los enlaces de salida de F hacia la página j, y s contiene los enlaces de entrada de la página j en el dominio local. Ten en cuenta que no permitimos enlaces a uno mismo en este marco de trabajo. En la práctica, los enlaces internos suelen ser eliminados, ya que solo sirven para inflar el PageRank de una página determinada. Observa que los enlaces entrantes a F desde el nodo j no se conocen hasta después de que el nodo j sea rastreado. Por lo tanto, estimamos este vector de inlink como la expectativa sobre el recuento de inlinks entre el conjunto de páginas ya rastreadas, s = F T e F T e 1. En la práctica, para cualquier página dada, esta estimación puede no reflejar los verdaderos inlinks de esa página. Además, esta expectativa se extrae del conjunto de enlaces dentro del dominio rastreado, mientras que una estimación más precisa también utilizaría enlaces del dominio global. Sin embargo, la distribución mencionada no es conocida por un motor de búsqueda localizado, y sostenemos que la estimación anterior, en promedio, será una estimación mejor que la distribución uniforme, por ejemplo. Dejemos que el PageRank de F sea f. Expresamos el PageRank f+ j del grafo local expandido Fj como f+ j = (1 − xj)fj xj , donde xj es el PageRank del nodo global candidato j, y fj es el vector de PageRank L1-normalizado restringido a las páginas en F. Dado que optimizar directamente nuestro objetivo requiere conocer el PageRank global p∗, proponemos en su lugar rastrear aquellos nodos que tendrán la mayor influencia en los PageRanks de las páginas en el dominio local original L: influencia(j) = k∈L |fj[k] − f[k]| (7) = EL (fj − f) 1. Experimentalmente, el puntaje de influencia es un predictor muy bueno de nuestro objetivo del problema (3). Para cada nodo global candidato j, la figura 1(a) muestra el valor de la función objetivo Global Diff(fj) en función de la influencia de la página j. El dominio local utilizado aquí es un rastreo de páginas políticas conservadoras (proporcionaremos más detalles sobre este conjunto de datos en la sección 6); observamos resultados similares en otros dominios. La correlación es bastante fuerte, lo que implica que los criterios de influencia pueden identificar de manera efectiva las páginas que mejoran la estimación global del PageRank. Como referencia, la figura 1(b) compara nuestro objetivo con un criterio alternativo, el recuento de enlaces de salida. El recuento de enlaces de salida se define como el número de enlaces de salida desde el dominio local a la página j. La correlación aquí es mucho más débil. .00001 .0001 .001 .01 0.26 0.262 0.264 0.266 Influencia Objetivo 1 10 100 1000 0.266 0.264 0.262 0.26 Recuento de Enlaces Salientes Objetivo (a) (b) Figura 1: (a) La correlación entre nuestros criterios de selección de página de influencia (7) y el valor real de la función objetivo (3) es bastante fuerte. (b) Esto contrasta con otros criterios, como el recuento de enlaces salientes, que muestran una correlación mucho más débil. 5.2 Cálculo Como se describe, para cada página global candidata j, se debe calcular el puntaje de influencia (7). Si fj se calcula exactamente para cada página global j, entonces el algoritmo de PageRank tendría que ejecutarse para cada una de las O(n) páginas globales j que consideramos, lo que resultaría en un costo computacional de O(n2) para el método de selección de nodos. Por lo tanto, calcular el valor exacto de fj conducirá a un algoritmo cuadrático, y en su lugar debemos recurrir a métodos de aproximación de este vector. El algoritmo que presentamos funciona realizando una iteración del método de potencia utilizado por el algoritmo PageRank (Algoritmo 1). La tasa de convergencia para el algoritmo PageRank se ha demostrado que es igual a la probabilidad del surfista aleatorio α [7, 11]. Dado un vector inicial x(0), si se realizan k iteraciones de PageRank, la solución actual de PageRank x(k) satisface: x(k) − x∗ 1 = O(αk x(0) − x∗ 1), (8), donde x∗ es el vector de PageRank deseado. Por lo tanto, si solo se realiza una iteración, es necesario elegir un buen vector inicial para lograr una aproximación precisa. Particionamos la matriz de PageRank PFj, correspondiente al subgrafo Fj, como: PFj = ˜F ˜s ˜uT j w, (9) donde ˜F = αF (DF + diag(uj))−1 + (1 − α) e + 1 eT, ˜s = αs + (1 − α) e + 1, ˜uj = α(DF + diag(uj))−1 uj + (1 − α) e + 1, w = 1 − α + 1, y diag(uj) es la matriz diagonal con la entrada (i, i) igual a uno si el i-ésimo elemento de uj es uno, y cero en caso contrario. Hemos asumido aquí que el vector del surfista aleatorio es el vector uniforme, y que L no tiene enlaces colgantes. Estas suposiciones no son necesarias y solo sirven para simplificar la discusión y el análisis. Un enfoque sencillo para estimar fj es el siguiente. Primero, estima el PageRank f+ j de Fj calculando una iteración de PageRank sobre la matriz PFj, utilizando el vector inicial ν = f 0. Luego, estima fj eliminando el último componente de 119 Research Track Paper de nuestra estimación de f+ j (es decir, el componente correspondiente al nodo j añadido), y renormalizando. El problema con este enfoque está en el vector inicial. Recuerde que xj es el PageRank del nodo j añadido. La diferencia entre el PageRank actual f+ j de PFj y el vector inicial ν es ν − f+ j 1 = xj + f − (1 − xj)fj 1 ≥ xj + | f 1 − (1 − xj) fj 1| = xj + |xj| = 2xj. Por lo tanto, según (8), después de una iteración de PageRank, esperamos que nuestra estimación de f+ j todavía tenga un error de aproximadamente 2αxj. En particular, para los nodos candidatos j con un PageRank xj relativamente alto, este método producirá resultados más inexactos. A continuación, presentaremos un método que elimina este sesgo y se ejecuta en tiempo O(n). 5.2.1 Complementación Estocástica Dado que f+ j, como se muestra en (6), es el PageRank de la matriz PFj, tenemos: fj(1 − xj) xj = ˜F ˜s ˜uT j w fj(1 − xj) xj = ˜F fj(1 − xj) + ˜sxj ˜uT j fj(1 − xj) + wxj. Resolver el sistema anterior para fj puede demostrarse que produce fj = ( ˜F + (1 − w)−1 ˜s˜uT j )fj. (10) La matriz S = ˜F +(1−w)−1 ˜s˜uT j se conoce como el complemento estocástico de la matriz estocástica de columna PFj con respecto a la submatriz ˜F. La teoría de complementación estocástica está bien estudiada, y se puede demostrar que el complemento estocástico de una matriz irreducible (como la matriz de PageRank) es único. Además, el complemento estocástico también es irreducible y, por lo tanto, tiene una distribución estacionaria única. Para un estudio extenso, ver [15]. Se puede demostrar fácilmente que el autovalor subdominante de S es a lo sumo +1 α, donde α es el tamaño de F. Para valores suficientemente grandes, este valor estará muy cerca de α. Esto es importante, ya que otras propiedades del algoritmo PageRank, especialmente la sensibilidad del algoritmo, dependen de este valor [11]. En este método, estimamos el vector de longitud fj calculando una iteración de PageRank sobre el complemento estocástico × S, comenzando en el vector f: fj ≈ Sf. (11) Esto contrasta con el método simple descrito en la sección anterior, que primero itera sobre la matriz ( + 1) × ( + 1) PFj para estimar f+ j, y luego elimina el último componente de la estimación y renormaliza para aproximar fj. El problema con el último método radica en la elección del vector inicial de longitud ( + 1), ν. En consecuencia, la estimación de PageRank dada por el método simple difiere del verdadero PageRank en al menos 2αxj, donde xj es el PageRank de la página j. Al utilizar el complemento estocástico, podemos establecer un límite inferior estricto de cero para esta diferencia. Para ver esto, considera el caso en el que se agrega un nodo k a F para formar el subgrafo local aumentado Fk, y que el PageRank de este nuevo grafo es (1 − xk)f xk. Específicamente, la adición de la página k no cambia los PageRanks de las páginas en F, y por lo tanto fk = f. Por la construcción del complemento estocástico, fk = Sfk, por lo que la aproximación dada en la ecuación (11) producirá la solución exacta. A continuación, presentamos los detalles computacionales necesarios para calcular eficientemente la cantidad fj − f 1 sobre todas las páginas globales conocidas j. Comenzamos expandiendo la diferencia fj − f, donde el vector fj se estima como en (11), fj − f ≈ Sf − f = αF (DF + diag(uj))−1 f + (1 − α) e + 1 eT f +(1 − w)−1 (˜uT j f)˜s − f. (12) Tenga en cuenta que la matriz (DF + diag(uj))−1 es diagonal. Dejando que o[k] sea el recuento de enlaces de salida para la página k en F, podemos expresar el elemento diagonal k-ésimo como: (DF + diag(uj))−1 [k, k] = 1 o[k]+1 si uj[k] = 1 1 o[k] si uj[k] = 0 Notando que (o[k] + 1)−1 = o[k]−1 − (o[k](o[k] + 1))−1 y reescribiendo esto en forma matricial obtenemos (DF +diag(uj))−1 = D−1 F −D−1 F (DF +diag(uj))−1 diag(uj). (13) Usamos la misma identidad para expresar e + 1 = e − e ( + 1) . (14) Recordemos que, por definición, tenemos PF = αF D−1 F +(1−α)e. Sustituyendo (13) y (14) en (12) se obtiene que fj − f ≈ (PF f − f) −αF D−1 F (DF + diag(uj))−1 diag(uj)f −(1 − α) e ( + 1) + (1 − w)−1 (˜uT j f)˜s = x + y + (˜uT j f)z, (15), notando que por definición, f = PF f, y definiendo los vectores x, y, y z como x = −αF D−1 F (DF + diag(uj))−1 diag(uj)f (16) y = −(1 − α) e ( + 1) (17) z = (1 − w)−1 ˜s. (18) El primer término x es un vector disperso, y toma valores no nulos solo para las páginas locales k que son hermanas de la página global j. Definimos (i, j) ∈ F si y solo si F [j, i] = 1 (equivalentemente, la página i enlaza a la página j) y expresamos el valor del componente x[k] como: x[k] = −α k:(k,k)∈F, uj[k]=1 f[k] o[k](o[k] + 1), (19) donde o[k], como antes, es el número de enlaces salientes de la página k en el dominio local. Ten en cuenta que los dos últimos términos, y y z, no dependen del nodo global actual j. Dada la función hj(f) = y + (˜uT j f)z 1, la cantidad fj − f 1 120 Research Track Paper puede expresarse como fj − f 1 = k x[k] + y[k] + (˜uT j f)z[k] = k:x[k]=0 y[k] + (˜uT j f)z[k] + k:x[k]=0 x[k] + y[k] + (˜uT j f)z[k] = hj(f) − k:x[k]=0 y[k] + (˜uT j f)z[k] + k:x[k]=0 x[k] + y[k] + (˜uT j f)z[k]. (20) Si podemos calcular la función hj en tiempo lineal, entonces podemos calcular cada valor de fj − f 1 usando una cantidad adicional de tiempo proporcional al número de componentes no nulas en x. Estas optimizaciones se llevan a cabo en el Algoritmo 3. Nótese que la ecuación (20) calcula la diferencia entre todos los componentes de f y fj, mientras que nuestros criterios de selección de nodos, dados en la ecuación (7), se restringen a los componentes correspondientes a los nodos en el dominio local original L. Examinemos el Algoritmo 3 con más detalle. Primero, el algoritmo calcula el número de enlaces de salida para cada página en el dominio local. El algoritmo luego calcula la cantidad ˜uT j f para cada página global j conocida. Este producto interno se puede escribir como (1 − α) 1 + 1 + α k:(k,j)∈Fout f[k] o[k] + 1, donde el segundo término suma sobre el conjunto de páginas locales que enlazan a la página j. Dado que se asumió que el número total de aristas en Fout tenía un tamaño O( ) (recordemos que es el número de páginas en F), el tiempo de ejecución de este paso también es O( ). El algoritmo luego calcula los vectores y y z, como se indican en (17) y (18), respectivamente. El método L1NormDiff se llama en los componentes de estos vectores que corresponden a las páginas en L, y estima el valor de EL(y + (˜uT j f)z) 1 para cada página j. La estimación funciona de la siguiente manera. Primero, los valores de ˜uT j f se discretizan de forma uniforme en c valores {a1, ..., ac}. La cantidad EL(y + aiz) 1 se calcula entonces para cada valor discretizado de ai y se almacena en una tabla. Para evaluar EL (y + az) 1 para algún a ∈ [a1, ac], se determina el valor discretizado más cercano ai, y se utiliza la entrada correspondiente en la tabla. El tiempo total de ejecución de este método es lineal en y el parámetro de discretización c (que consideramos constante). Observamos que si se desean valores exactos, también hemos desarrollado un algoritmo que se ejecuta en tiempo O(log) que no se describe aquí. En el bucle principal, calculamos el vector x, tal como se define en la ecuación (16). Los bucles anidados iteran sobre el conjunto de páginas en F que son hermanas de la página j. Normalmente, el tamaño de este conjunto está limitado por una constante. Finalmente, para cada página j, el vector de puntuaciones se actualiza sobre el conjunto de componentes no nulos k del vector x con k ∈ L. Este conjunto tiene un tamaño igual al número de hermanos locales de la página j, y es un subconjunto del número total de hermanos de la página j. Por lo tanto, cada iteración del bucle principal toma tiempo constante, y el tiempo de ejecución total del bucle principal es O( ). Dado que hemos asumido que el tamaño de F no crecerá más allá de O(n), el tiempo de ejecución total del algoritmo es O(n). Algoritmo 3: Selección de nodos a través de la complementación estocástica. SC-Select(F , Fout, f, k) Entrada: F : matriz de adyacencia de ceros y unos del tamaño correspondiente al subgrafo local actual, Fout: matriz de enlaces de ceros y unos de F al subgrafo global, f: PageRank de F , k: número de páginas a devolver Salida: páginas: conjunto de k páginas para rastrear a continuación {Calcular sumas de enlaces de salida para el subgrafo local} para cada (página j ∈ F ) o[j] ← k:(j,k)∈F F[j, k] fin {Calcular escalar ˜uT j f para cada nodo global j } para cada (página j ∈ Fout) g[j] ← (1 − α) 1 +1 para cada (página k : (k, j) ∈ Fout) g[j] ← g[j] + α f[k] o[k]+1 fin fin {Calcular vectores y z como en (17) y (18) } y ← −(1 − α) e ( +1) z ← (1 − w)−1 ˜s {Aproximar y + g[j] ∗ z 1 para todos los valores g[j]} norm diffs ←L1NormDiffs(g, ELy, ELz) para cada (página j ∈ Fout) {Calcular vector disperso x como en (19)} x ← 0 para cada (página k : (k, j) ∈ Fout) para cada (página k : (k, k ) ∈ F )) x[k ] ← x[k ] − f[k] o[k](o[k]+1) fin fin x ← αx scores[j] ← norm diffs[j] para cada (k : x[k] > 0 y página k ∈ L) scores[j] ← scores[j] − |y[k] + g[j] ∗ z[k]| +|x[k]+y[k]+g[j]∗z[k])| fin fin Devolver k páginas con los puntajes más altos 5.2.2 Flujos de PageRank Ahora presentamos un análisis intuitivo del método de complementación estocástica descomponiendo el cambio en PageRank en términos de fugas y flujos. Este análisis está motivado por la descomposición dada en (15). El flujo de PageRank es el aumento en los PageRanks locales que se originan desde la página global j. Los flujos están representados por el vector no negativo (˜uT j f)z (ecuaciones (15) y (18)). El escalar ˜uT j f se puede pensar como la cantidad total de flujo de PageRank que la página j tiene disponible para distribuir. El vector z dicta cómo se asigna el flujo al dominio local; el flujo que recibe la página local k es proporcional (con un factor constante debido al vector de navegante aleatorio) al número esperado de sus enlaces entrantes. Las filtraciones de PageRank representan la disminución en el PageRank resultante de la adición de la página j. La fuga puede ser cuantificada en términos de los vectores no positivos x e y (ecuaciones (16) y (17)). Para el vector x, podemos ver a partir de la ecuación (19) que la cantidad de PageRank filtrado por una página local es proporcional a la suma ponderada de los Page121 Research Track Paper Ranks de sus páginas hermanas. Por lo tanto, las páginas que tienen hermanos con PageRanks más altos (y un bajo número de enlaces salientes) experimentarán más pérdida de valor. La fuga causada por y es un artefacto del vector del surfista aleatorio. A continuación demostraremos que si solo se considera el término de flujo, (˜uT j f)z, entonces el método resultante es muy similar a una heurística propuesta por Cho et al. [6] que ha sido ampliamente utilizada para el problema de Ordenación de URL en el Rastreo. Esta heurística es computacionalmente más económica, pero como veremos más adelante, no es tan efectiva como el método de Complementación Estocástica. Nuestra estrategia de selección de nodos elige nodos globales que tienen la mayor influencia (ecuación (7)). Si esta influencia se aproxima utilizando solo flujos, el nodo óptimo j∗ es: j∗ = argmaxj EL ˜uT j fz 1 = argmaxj ˜uT j f EL z 1 = argmaxj ˜uT j f = argmaxj α(DF + diag(uj))−1 uj + (1 − α) e + 1 , f = argmaxjfT (DF + diag(uj))−1 uj. La puntuación de selección de página resultante se puede expresar como la suma de los PageRanks de cada página local k que enlaza con j, donde cada valor de PageRank se normaliza por o[k]+1. Curiosamente, la normalización que surge en nuestro método difiere de la heurística dada en [6], la cual normaliza por o[k]. El algoritmo PF-Select, que se omite por falta de espacio, primero calcula la cantidad fT (DF +diag(uj))−1 uj para cada página global j, y luego devuelve las páginas con los k puntajes más altos. Para ver que el tiempo de ejecución de este algoritmo es O(n), observe que la computación involucrada en este método es un subconjunto de la necesaria para el método SC-Select (Algoritmo 3), el cual se demostró que tiene un tiempo de ejecución de O(n). 6. EXPERIMENTOS En esta sección, proporcionamos evidencia experimental para verificar la efectividad de nuestros algoritmos. Primero describimos nuestra metodología experimental y luego presentamos resultados en una variedad de dominios locales. 6.1 Metodología Dado los recursos limitados disponibles en una institución académica, rastrear una sección de la web que sea de la misma magnitud que la indexada por Google o Yahoo! claramente es inviable. Por lo tanto, para un dominio local dado, aproximamos el grafo global rastreando un vecindario local alrededor del dominio que es varias órdenes de magnitud más grande que el subgrafo local. A pesar de que dicho gráfico sigue siendo órdenes de magnitud más pequeño que el verdadero gráfico global, sostenemos que, incluso si existen algunas páginas altamente influyentes que están muy lejos de nuestro dominio local, es poco realista que cualquier algoritmo de selección de nodos locales las encuentre. Tales páginas suelen ser muy poco relacionadas con las páginas dentro del dominio local. Al explicar nuestras estrategias de selección de nodos en la sección 5, hicimos la suposición simplificadora de que nuestro grafo local no contenía nodos colgantes. Esta suposición se hizo solo para facilitar nuestro análisis. Nuestra implementación maneja de manera eficiente los enlaces colgantes al reemplazar cada columna de ceros de nuestra matriz de adyacencia con el vector uniforme. Evaluamos el algoritmo utilizando las dos estrategias de selección de nodos dadas en la Sección 5.2, y también comparándolo con los siguientes métodos de referencia: • Aleatorio: Los nodos se eligen de forma uniforme al azar entre los nodos globales conocidos. • Conteo de enlaces de salida: Se eligen los nodos globales con el mayor número de enlaces de salida desde el dominio local. En cada iteración del algoritmo FindGlobalPR, evaluamos el rendimiento calculando la diferencia entre la estimación actual de PageRank del dominio local, ELf ELf 1, y el PageRank global del dominio local, ELg ELg 1. Todas las calculaciones de PageRank se realizaron utilizando el vector de surfista aleatorio uniforme. En todos los experimentos, establecimos el parámetro del surfista aleatorio α en .85 y utilizamos un umbral de convergencia de 10−6. Evaluamos la diferencia entre los vectores de PageRank local y global utilizando tres métricas diferentes: las normas L1 y L∞, y el tau de Kendall. La norma L1 mide la suma del valor absoluto de las diferencias entre los dos vectores, y la norma L∞ mide el valor absoluto de la mayor diferencia. La métrica de tau de Kendall es una medida de correlación de rangos popular utilizada para comparar PageRanks [2, 11]. Esta métrica se puede calcular contando el número de pares de pares que coinciden en la clasificación, y restando de eso el número de pares de pares que no coinciden en la clasificación. El valor final se normaliza luego por el número total de n pares de este tipo, resultando en un rango de [−1, 1], donde una puntuación negativa indica una anticorrelación entre las clasificaciones, y valores cercanos a uno corresponden a una fuerte correlación de rangos. 6.2 Resultados Nuestros experimentos se basan en dos grandes rastreos web y se descargaron utilizando el rastreador web que forma parte del proyecto de motor de búsqueda de código abierto Nutch [18]. Todas las exploraciones se limitaron únicamente a páginas http, y para limitar el número de páginas generadas dinámicamente que exploramos, ignoramos todas las páginas con URLs que contengan alguno de los caracteres ?, *, @ o =. El primer rastreo, al que nos referiremos como el conjunto de datos edu, fue iniciado por las páginas de inicio de los 100 principales departamentos de posgrado en informática en los Estados Unidos, según la clasificación de US News and World Report [16], y también por las páginas de inicio de sus respectivas instituciones. Se realizó un rastreo de profundidad 5, restringido a páginas dentro del dominio .edu, lo que resultó en un grafo con aproximadamente 4.7 millones de páginas y 22.9 millones de enlaces. El segundo rastreo fue alimentado por el conjunto de páginas bajo la jerarquía de política en el proyecto de directorio abierto dmoz[17]. Rastreamos todas las páginas hasta cuatro enlaces de distancia, lo que resultó en un grafo con 4.4 millones de páginas y 17.3 millones de enlaces. Dentro del rastreo educativo, identificamos los cinco dominios específicos del sitio correspondientes a los sitios web de los cinco principales departamentos de posgrado en ciencias de la computación, según la clasificación de US News and World Report. Esto produjo dominios locales de varios tamaños, desde 10,626 (UIUC) hasta 59,895 (Berkeley). Para cada uno de estos dominios específicos del sitio con tamaño n, realizamos 50 iteraciones del algoritmo FindGlobalPR para rastrear un total de 2n nodos adicionales. La Figura 2(a) muestra la diferencia (L1) entre la estimación de PageRank en cada iteración y el PageRank global, para el dominio local de Berkeley. El rendimiento de este conjunto de datos fue representativo del rendimiento típico en los cinco dominios locales específicos de informática. Inicialmente, la diferencia de L1 entre los PageRanks globales y locales variaba desde .0469 (Stanford) hasta .149 (MIT). Para las primeras varias iteraciones, el Artículo de Investigación 122 0 5 10 15 20 25 30 35 40 45 50 0.015 0.02 0.025 0.03 0.035 0.04 0.045 0.05 0.055 Número de Iteraciones Diferencia de PageRank Global y Local (L1) Complemento Estocástico PageRank Flujo de Enlaces de Conteo Aleatorio 0 10 20 30 40 50 0 0.05 0.1 0.15 0.2 0.25 0.3 0.35 Número de Iteraciones Diferencia de PageRank Global y Local (L1) Complemento Estocástico PageRank Flujo de Enlaces de Conteo Aleatorio 0 5 10 15 20 25 0.16 0.18 0.2 0.22 0.24 0.26 0.28 0.3 0.32 0.34 Número de Iteraciones Diferencia de PageRank Global y Local (L1) Complemento Estocástico PageRank Flujo de Enlaces de Conteo Aleatorio (a) www.cs.berkeley.edu (b) www.enterstageright.com (c) Política Figura 2: Diferencia L1 entre los PageRanks globales estimados y verdaderos para (a) el sitio web de ciencias de la computación de Berkeley, (b) el dominio específico del sitio, www.enterstageright.com, y (c) el dominio específico del tema de política. El método de complemento estocástico supera a todos los demás métodos en diferentes dominios. Tres métodos basados en enlaces superan a la heurística de selección aleatoria. Después de estas iteraciones iniciales, la heurística aleatoria tendió a ser más competitiva con (o incluso superar, como en el dominio local de Berkeley) las heurísticas de conteo de enlaces de salida y flujo de PageRank. En todos los ensayos, el método de complementación estocástica superó a los otros métodos o compitió con ellos. La Tabla 1 muestra la diferencia promedio entre los PageRanks globales estimados finales y los PageRanks globales reales para varias medidas de distancia. Algoritmo L1 L∞ Kendall Estocástico. Tabla 1: Rendimiento final promedio de varias estrategias de selección de nodos para los cinco dominios locales de informática específicos del sitio. Ten en cuenta que el Tau de Kendall mide similitud, mientras que las otras métricas son medidas de disimilitud. La Complementación Estocástica claramente supera a los otros métodos en todas las métricas. Dentro del conjunto de datos de política, también realizamos dos pruebas específicas para los sitios web más grandes en el rastreo: www.adamsmith.org, el sitio web del Instituto Adam Smith con sede en Londres, y www.enterstageright.com, una revista en línea conservadora. Al igual que con los dominios locales de edu, ejecutamos nuestro algoritmo durante 50 iteraciones, rastreando un total de 2n nodos. La figura 2 (b) muestra los resultados para el dominio www.enterstageright.com. A diferencia de los dominios locales de edu, los métodos Random y OutlinkCount no fueron competitivos ni con los métodos SC-Select ni con los métodos PF-Select. Entre todos los conjuntos de datos y todos los métodos de selección de nodos, el método de complementación estocástica fue el más impresionante en este conjunto de datos, logrando una estimación final que difería solo .0279 del PageRank global, una mejora de diez veces sobre la diferencia inicial del PageRank local de .299. Para el dominio local de Adam Smith, la diferencia inicial entre los PageRanks locales y globales fue de .148, y las estimaciones finales proporcionadas por los métodos SC-Select, PF-Select, OutlinkCount y Random fueron de .0208, .0193, .0222 y .0356, respectivamente. Dentro del conjunto de datos de política, construimos cuatro dominios locales específicos de temas. El primer dominio consistía en todas las páginas de la categoría de política de dmoz, y también todas las páginas dentro de cada uno de estos sitios hasta dos enlaces de distancia. Esto produjo un dominio local de 90,811 páginas, y los resultados se muestran en la figura 2 (c). Debido al mayor tamaño de los dominios específicos del tema, ejecutamos nuestro algoritmo solo durante 25 iteraciones para rastrear un total de n nodos. También creamos dominios específicos de temas a partir de tres subtemas políticos: liberalismo, conservadurismo y socialismo. Las páginas en estos dominios fueron identificadas por sus categorías correspondientes de dmoz. Para cada subtema, establecemos el dominio local como todas las páginas dentro de tres enlaces de las páginas de categoría dmoz correspondientes. La Tabla 2 resume el rendimiento de estos tres dominios específicos del tema, así como también del dominio político más amplio. Para cuantificar el efecto global de una página js en los valores globales de PageRank de las páginas en el dominio local, definimos el impacto de la página js como su valor de PageRank, g[j], normalizado por la fracción de sus enlaces salientes que apuntan al dominio local: impacto(j) = oL[j] o[j] · g[j], donde oL[j] es el número de enlaces salientes de la página j a páginas en el dominio local L, y o[j] es el número total de enlaces salientes de js. En términos del modelo del surfista aleatorio, el impacto de la página j es la probabilidad de que el surfista aleatorio (1) se encuentre actualmente en la página global j en su caminata aleatoria y (2) tome un enlace de salida a una página local, dado que ya ha decidido no saltar a una página aleatoria. Para el dominio político local, encontramos que muchas de las páginas con alto impacto eran de hecho páginas políticas que deberían haber sido incluidas en el tema de política de dmoz, pero no lo estaban. Por ejemplo, las dos páginas globales más influyentes fueron el motor de búsqueda político www.askhenry.com y la página de inicio de la revista política en línea www.policyreview.com. Entre las páginas no políticas, la página de inicio de la revista Education Next fue la más influyente. El diario está disponible de forma gratuita en línea y contiene artículos sobre varios aspectos de la educación K-12 en América. Para proporcionar algunas pruebas anecdóticas de la efectividad de nuestros métodos de selección de páginas, observamos que el método SC-Select eligió 11 páginas dentro del dominio www.educationnext.org, el método PF-Select descubrió 7 páginas, mientras que los métodos OutlinkCount y Random encontraron solo 6 páginas cada uno. Para el ámbito político local conservador, el sitio web socialista www.ornery.org tuvo una puntuación de impacto muy alta. Este documento de investigación de la pista 123 titulado \"Toda la política: Algoritmo L1 L2 Kendall Stoch\". Comp. .1253 .000700 .8671 Flujo PR .1446 .000710 .8518 Enlace saliente .1470 .00225 .8642 Aleatorio .2055 .00203 .8271 Conservadurismo: Algoritmo L1 L2 Kendall Estoc. Comp. .0496 .000990 .9158 Flujo PR .0554 .000939 .9028 Enlace saliente .0602 .00527 .9144 Aleatorio .1197 .00102 .8843 Liberalismo: Algoritmo L1 L2 Kendall Estoc. Comp. .0622 .001360 .8848 Flujo PR .0799 .001378 .8669 Enlace saliente .0763 .001379 .8844 Aleatorio .1127 .001899 .8372 Socialismo: Algoritmo L1 L∞ Kendall Estoc. Tabla 2: Rendimiento final entre estrategias de selección de nodos para las cuatro exploraciones específicas de temas políticos. Ten en cuenta que el coeficiente de correlación de Kendall mide la similitud, mientras que las otras métricas son medidas de disimilitud. Como era de esperar, el PageRank global de este artículo (que resulta estar en la página de inicio de la NCCPR, www.nationalresearch.com) era aproximadamente de .002, mientras que el PageRank local de esta página era solo de .00158. El método SC-Select produjo una estimación global de PageRank de aproximadamente .00182, el método PFSelect estimó un valor de .00167, y los métodos Random y OutlinkCount produjeron valores de .01522 y .00171, respectivamente. TRABAJO RELACIONADO El marco de selección de nodos que hemos propuesto es similar al <br>problema de ordenación de URL para el rastreo</br> propuesto por Cho et al. en [6]. Mientras que nuestro marco busca minimizar la diferencia entre el PageRank global y local, el objetivo utilizado en [6] es rastrear primero las páginas más altamente clasificadas (globalmente). Proponen varios algoritmos de selección de nodos, incluyendo la heurística del recuento de enlaces de salida, así como una variante de nuestro algoritmo PF-Select al que se refieren como la métrica de ordenación de PageRank. Encontraron que este método era el más efectivo para optimizar su objetivo, al igual que lo demostró una encuesta reciente de estos métodos realizada por Baeza-Yates et al. [1]. Boldi et al. también experimentan dentro de un marco de rastreo similar en [2], pero cuantifican sus resultados al comparar la correlación de rangos de Kendall entre los PageRanks del conjunto actual de páginas rastreadas y los del grafo global completo. Encontraron que las estrategias de selección de nodos que rastreaban páginas con el PageRank global más alto primero en realidad tenían un peor rendimiento (con respecto a la correlación de Kendalls Tau entre los PageRanks locales y globales) que las estrategias básicas de búsqueda en profundidad o en amplitud. Sin embargo, sus experimentos difieren de nuestro trabajo en que nuestros algoritmos de selección de nodos no utilizan (ni tienen acceso a) valores globales de PageRank. Se han propuesto muchas mejoras algorítmicas para calcular los valores exactos de PageRank [9, 10, 14]. Si se utilizan tales algoritmos para calcular los PageRanks globales de nuestro dominio local, todos requerirían una computación, almacenamiento y ancho de banda de O(N), donde N es el tamaño del dominio global. Esto contrasta con nuestro método, que aproxima el PageRank global y escala linealmente con el tamaño del dominio local. Wang y Dewitt [22] proponen un sistema en el que el conjunto de servidores web que conforman el dominio global se comunican entre sí para calcular sus respectivos PageRanks globales. Para un servidor web dado que aloja n páginas, los requisitos computacionales, de ancho de banda y almacenamiento también son lineales en n. Una desventaja de este sistema es que el número de servidores web distintos que conforman el dominio global puede ser muy grande. Por ejemplo, nuestro conjunto de datos edu contiene sitios web de más de 3,200 universidades diferentes; coordinar un sistema así entre un gran número de sitios puede ser muy difícil. Gan, Chen y Suel proponen un método para estimar el PageRank de una sola página [5] que utiliza solo ancho de banda, computación y espacio constantes. Su enfoque se basa en la disponibilidad de un servidor de conectividad remota que puede suministrar el conjunto de enlaces entrantes a una página dada, una suposición que no se utiliza en nuestro marco de trabajo. Experimentalmente demuestran que se puede obtener una estimación razonable del PageRank de los nodos visitando como máximo unos pocos cientos de nodos. El uso de su algoritmo para nuestro problema requeriría que primero se descargue todo el dominio global o se utilice un servidor de conectividad, lo que resultaría en grafos web muy grandes. 8. CONCLUSIONES Y TRABAJOS FUTUROS Internet está creciendo de forma exponencial, y para poder navegar por un repositorio tan grande como la web, los motores de búsqueda globales se han establecido como una necesidad. Junto con la omnipresencia de estos motores de búsqueda a gran escala, surge un aumento en las expectativas de los usuarios de búsqueda. Al proporcionar una cobertura completa y aislada de un dominio web específico, los motores de búsqueda localizados son un medio efectivo para localizar rápidamente contenido que de otra manera podría ser difícil de encontrar. En este trabajo, sostenemos que el uso de PageRank global en un motor de búsqueda localizado puede mejorar el rendimiento. Para estimar el PageRank global, hemos propuesto un marco de selección de nodos iterativo en el que seleccionamos qué páginas de la frontera global rastrear a continuación. Nuestra principal contribución es nuestro algoritmo de selección de páginas de complementación estocástica. Este método recorre los nodos que tendrán un impacto significativo en el dominio local y tiene un tiempo de ejecución lineal en el número de nodos en el dominio local. Experimentalmente, validamos estos métodos en un conjunto diverso de dominios locales, que incluyen siete dominios específicos del sitio y cuatro dominios específicos del tema. Concluimos que al rastrear n o 2n páginas adicionales, nuestros métodos encuentran una estimación de los PageRanks globales que es hasta diez veces mejor que simplemente usar los PageRanks locales. Además, demostramos que nuestro algoritmo supera consistentemente a otras heurísticas existentes. En muchas ocasiones, los dominios específicos de un tema se descubren utilizando un rastreador web enfocado que considera el contenido de las páginas junto con el texto del ancla del enlace para decidir qué páginas rastrear a continuación [4]. Aunque estos rastreadores han demostrado ser bastante efectivos en descubrir contenido relacionado con el tema, también se rastrean muchas páginas irrelevantes en el proceso. Por lo general, estas páginas son eliminadas y no son indexadas por el motor de búsqueda localizado. Estas páginas pueden, por supuesto, proporcionar información valiosa sobre el PageRank global del dominio local. Una forma de integrar estas páginas en nuestro marco de trabajo es comenzar el algoritmo FindGlobalPR con el subgrafo actual F igual al conjunto de páginas que fueron rastreadas por el rastreador enfocado. El marco de estimación global de PageRank, junto con los algoritmos de selección de nodos presentados, requieren todos una computación de O(n) por iteración y un ancho de banda proporcional al número de páginas rastreadas, Tk. Si el número de iteraciones T es relativamente pequeño en comparación con el número de páginas rastreadas por iteración, k, entonces el cuello de botella del algoritmo será la fase de rastreo. Sin embargo, a medida que el número de iteraciones aumenta (en relación con k), el cuello de botella residirá en el cálculo de la selección de nodos. En este caso, nuestros algoritmos se beneficiarían de optimizaciones en el factor constante. Recuerde que el algoritmo FindGlobalPR (Algoritmo 2) requiere que los PageRanks del dominio local expandido actual se vuelvan a calcular en cada iteración. El trabajo reciente de Langville y Meyer [12] proporciona un algoritmo para recalcular rápidamente los PageRanks de un grafo web dado si se agregan un pequeño número de nodos. Este algoritmo demostró proporcionar una aceleración de cinco a diez veces en algunos conjuntos de datos. Planeamos investigar esto y otras optimizaciones similares como trabajo futuro. En este artículo, hemos evaluado objetivamente nuestros métodos midiendo qué tan cercanas son nuestras estimaciones globales de PageRank a los verdaderos PageRanks globales. Para determinar el beneficio de utilizar PageRanks globales en un motor de búsqueda localizado, sugerimos un estudio de usuarios en el que se les pida a los usuarios que califiquen la calidad de los resultados de búsqueda para varias consultas de búsqueda. Para algunas consultas, solo se utilizan los PageRanks locales en la clasificación, y para las consultas restantes, se utilizan los PageRanks locales y los PageRanks globales aproximados, según lo calculado por nuestros algoritmos. Los resultados de dicho estudio pueden ser analizados para determinar el beneficio adicional de utilizar los PageRanks globales calculados por nuestros métodos, en lugar de solo utilizar los PageRanks locales. Agradecimientos. Esta investigación fue apoyada por la subvención de la NSF CCF-0431257, el Premio de Carrera de la NSF ACI-0093404 y una subvención de Sabre, Inc. 9. REFERENCIAS [1] R. Baeza-Yates, M. Marín, C. Castillo y A. Rodríguez. Rastreando un país: estrategias mejores que el recorrido en anchura para ordenar páginas web. Conferencia de la World-Wide Web, 2005. [2] P. Boldi, M. Santini y S. Vigna. Haz lo peor para lograr lo mejor: efectos paradójicos en los cálculos incrementales de PageRank. Taller sobre Grafos Web, 3243:168-180, 2004. [3] S. Brin y L. Page. La anatomía de un motor de búsqueda web hipertextual a gran escala. Redes de Computadoras y Sistemas ISDN, 33(1-7):107-117, 1998. [4] S. Chakrabarti, M. van den Berg y B. Dom. Rastreo enfocado: un nuevo enfoque para el descubrimiento de recursos web específicos de un tema. Conferencia de la World-Wide Web, 1999. [5] Y. Chen, Q. Gan y T. Suel. Métodos locales para estimar los valores de pagerank. Conferencia sobre Gestión de Información y Conocimiento, 2004. [6] J. Cho, H. Garcia-Molina y L. Page. Rastreo eficiente a través de la ordenación de URL. Conferencia de la World-Wide Web, 1998. [7] T. H. Haveliwala y S. D. Kamvar. El segundo valor propio de la matriz de Google. Informe técnico, Universidad de Stanford, 2003. [8] T. Joachims, F. Radlinski, L. Granka, A. Cheng, C. Tillekeratne y A. Patel. Aprendizaje de funciones de recuperación a partir de retroalimentación implícita. http://www.cs.cornell.edu/People/tj/career. [9] S. D. Kamvar, T. H. Haveliwala, C. D. Manning y G. H. Golub. Explotando la estructura de bloques de la web para calcular el pagerank. Conferencia de la World-Wide Web, 2003. [10] S. D. Kamvar, T. H. Haveliwala, C. D. Manning y G. H. Golub. Métodos de extrapolación para acelerar el cálculo de PageRank. Conferencia de la World-Wide Web, 2003. [11] A. N. Langville y C. D. Meyer. Más profundo dentro de PageRank. Matemáticas en Internet, 2004. [12] A. N. Langville y C. D. Meyer. Actualizando el vector estacionario de una cadena de Markov irreducible con miras al PageRank de Google. Revista SIAM sobre Análisis de Matrices, 2005. [13] P. Lyman, H. R. Varian, K. Swearingen, P. Charles, N. Good, L. L. Jordan y J. Pal. ¿Cuánta información en 2003? Escuela de Gestión de la Información y Sistemas, Universidad de California en Berkeley, 2003. [14] F. McSherry. Un enfoque uniforme para el cálculo acelerado de PageRank. Conferencia de la World-Wide Web, 2005. [15] C. D. Meyer. Complementación estocástica, desacoplamiento de cadenas de Markov y la teoría de sistemas casi reducibles. SIAM Review, 31:240-272, 1989. [16] US News and World Report. http://www.usnews.com. [17] Proyecto de directorio abierto Dmoz. http://www.dmoz.org. [18] Motor de búsqueda de código abierto Nutch. http://www.nutch.org. [19] F. Radlinski y T. Joachims. Cadenas de consulta: aprendizaje para clasificar a partir de retroalimentación implícita. Conferencia Internacional ACM SIGKDD sobre Descubrimiento de Conocimiento y Minería de Datos, 2005. [20] S. Raghavan y H. Garcia-Molina. Explorando la web oculta. En Actas de la Vigésimo séptima Conferencia Internacional sobre Bases de Datos Muy Grandes, 2001. [21] T. Tin Tang, D. Hawking, N. Craswell y K. Griffiths. Rastreo enfocado para relevancia temática y calidad de la información médica. Conferencia sobre Gestión de Información y Conocimiento, 2005. [22] Y. Wang y D. J. DeWitt. Calculando el pagerank en un sistema distribuido de búsqueda en internet. Actas de la 30ª Conferencia VLDB, 2004. 125 Artículos de Investigación. ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "topic-specific domain": {
            "translated_key": "dominio específico del tema",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Estimating the Global PageRank of Web Communities Jason V. Davis Dept.",
                "of Computer Sciences University of Texas at Austin Austin, TX 78712 jdavis@cs.utexas.edu Inderjit S. Dhillon Dept. of Computer Sciences University of Texas at Austin Austin, TX 78712 inderjit@cs.utexas.edu ABSTRACT Localized search engines are small-scale systems that index a particular community on the web.",
                "They offer several benefits over their large-scale counterparts in that they are relatively inexpensive to build, and can provide more precise and complete search capability over their relevant domains.",
                "One disadvantage such systems have over large-scale search engines is the lack of global PageRank values.",
                "Such information is needed to assess the value of pages in the localized search domain within the context of the web as a whole.",
                "In this paper, we present well-motivated algorithms to estimate the global PageRank values of a local domain.",
                "The algorithms are all highly scalable in that, given a local domain of size n, they use O(n) resources that include computation time, bandwidth, and storage.",
                "We test our methods across a variety of localized domains, including site-specific domains and topic-specific domains.",
                "We demonstrate that by crawling as few as n or 2n additional pages, our methods can give excellent global PageRank estimates.",
                "Categories and Subject Descriptors H.3.3 [Information Storage and Retrieval]: Information Search and Retrieval; G.1.3 [Numerical Analysis]: Numerical Linear Algebra; G.3 [Probability and Statistics]: Markov Processes General Terms PageRank, Markov Chain, Stochastic Complementation 1.",
                "INTRODUCTION Localized search engines are small-scale search engines that index only a single community of the web.",
                "Such communities can be site-specific domains, such as pages within the cs.utexas.edu domain, or topic-related communitiesfor example, political websites.",
                "Compared to the web graph crawled and indexed by large-scale search engines, the size of such local communities is typically orders of magnitude smaller.",
                "Consequently, the computational resources needed to build such a search engine are also similarly lighter.",
                "By restricting themselves to smaller, more manageable sections of the web, localized search engines can also provide more precise and complete search capabilities over their respective domains.",
                "One drawback of localized indexes is the lack of global information needed to compute link-based rankings.",
                "The PageRank algorithm [3], has proven to be an effective such measure.",
                "In general, the PageRank of a given page is dependent on pages throughout the entire web graph.",
                "In the context of a localized search engine, if the PageRanks are computed using only the local subgraph, then we would expect the resulting PageRanks to reflect the perceived popularity within the local community and not of the web as a whole.",
                "For example, consider a localized search engine that indexes political pages with conservative views.",
                "A person wishing to research the opinions on global warming within the conservative political community may encounter numerous such opinions across various websites.",
                "If only local PageRank values are available, then the search results will reflect only strongly held beliefs within the community.",
                "However, if global PageRanks are also available, then the results can additionally reflect outsiders views of the conservative community (those documents that liberals most often access within the conservative community).",
                "Thus, for many localized search engines, incorporating global PageRanks can improve the quality of search results.",
                "However, the number of pages a local search engine indexes is typically orders of magnitude smaller than the number of pages indexed by their large-scale counterparts.",
                "Localized search engines do not have the bandwidth, storage capacity, or computational power to crawl, download, and compute the global PageRanks of the entire web.",
                "In this work, we present a method of approximating the global PageRanks of a local domain while only using resources of the same order as those needed to compute the PageRanks of the local subgraph.",
                "Our proposed method looks for a supergraph of our local subgraph such that the local PageRanks within this supergraph are close to the true global PageRanks.",
                "We construct this supergraph by iteratively crawling global pages on the current web frontier-i.e., global pages with inlinks from pages that have already been crawled.",
                "In order to provide 116 Research Track Paper a good approximation to the global PageRanks, care must be taken when choosing which pages to crawl next; in this paper, we present a well-motivated page selection algorithm that also performs well empirically.",
                "This algorithm is derived from a well-defined problem objective and has a running time linear in the number of local nodes.",
                "We experiment across several types of local subgraphs, including four topic related communities and several sitespecific domains.",
                "To evaluate performance, we measure the difference between the current global PageRank estimate and the global PageRank, as a function of the number of pages crawled.",
                "We compare our algorithm against several heuristics and also against a baseline algorithm that chooses pages at random, and we show that our method outperforms these other methods.",
                "Finally, we empirically demonstrate that, given a local domain of size n, we can provide good approximations to the global PageRank values by crawling at most n or 2n additional pages.",
                "The paper is organized as follows.",
                "Section 2 gives an overview of localized search engines and outlines their advantages over global search.",
                "Section 3 provides background on the PageRank algorithm.",
                "Section 4 formally defines our problem, and section 5 presents our page selection criteria and derives our algorithms.",
                "Section 6 provides experimental results, section 7 gives an overview of related work, and, finally, conclusions are given in section 8. 2.",
                "LOCALIZED SEARCH ENGINES Localized search engines index a single community of the web, typically either a site-specific community, or a topicspecific community.",
                "Localized search engines enjoy three major advantages over their large-scale counterparts: they are relatively inexpensive to build, they can offer more precise search capability over their local domain, and they can provide a more complete index.",
                "The resources needed to build a global search engine are enormous.",
                "A 2003 study by Lyman et al. [13] found that the surface web (publicly available static sites) consists of 8.9 billion pages, and that the average size of these pages is approximately 18.7 kilobytes.",
                "To download a crawl of this size, approximately 167 terabytes of space is needed.",
                "For a researcher who wishes to build a search engine with access to a couple of workstations or a small server, storage of this magnitude is simply not available.",
                "However, building a localized search engine over a web community of a hundred thousand pages would only require a few gigabytes of storage.",
                "The computational burden required to support search queries over a database this size is more manageable as well.",
                "We note that, for topic-specific search engines, the relevant community can be efficiently identified and downloaded by using a focused crawler [21, 4].",
                "For site-specific domains, the local domain is readily available on their own web server.",
                "This obviates the need for crawling or spidering, and a complete and up-to-date index of the domain can thus be guaranteed.",
                "This is in contrast to their large-scale counterparts, which suffer from several shortcomings.",
                "First, crawling dynamically generated pages-pages in the hidden web-has been the subject of research [20] and is a non-trivial task for an external crawler.",
                "Second, site-specific domains can enable the robots exclusion policy.",
                "This prohibits external search engines crawlers from downloading content from the domain, and an external search engine must instead rely on outside links and anchor text to index these restricted pages.",
                "By restricting itself to only a specific domain of the internet, a localized search engine can provide more precise search results.",
                "Consider the canonical ambiguous search query, jaguar, which can refer to either the car manufacturer or the animal.",
                "A scientist trying to research the habitat and evolutionary history of a jaguar may have better success using a finely tuned zoology-specific search engine than querying Google with multiple keyword searches and wading through irrelevant results.",
                "A method to learn better ranking functions for retrieval was recently proposed by Radlinski and Joachims [19] and has been applied to various local domains, including Cornell Universitys website [8]. 3.",
                "PAGERANK OVERVIEW The PageRank algorithm defines the importance of web pages by analyzing the underlying hyperlink structure of a web graph.",
                "The algorithm works by building a Markov chain from the link structure of the web graph and computing its stationary distribution.",
                "One way to compute the stationary distribution of a Markov chain is to find the limiting distribution of a random walk over the chain.",
                "Thus, the PageRank algorithm uses what is sometimes referred to as the random surfer model.",
                "In each step of the random walk, the surfer either follows an outlink from the current page (i.e. the current node in the chain), or jumps to a random page on the web.",
                "We now precisely define the PageRank problem.",
                "Let U be an m × m adjacency matrix for a given web graph such that Uji = 1 if page i links to page j and Uji = 0 otherwise.",
                "We define the PageRank matrix PU to be: PU = αUD−1 U + (1 − α)veT , (1) where DU is the (unique) diagonal matrix such that UD−1 U is column stochastic, α is a given scalar such that 0 ≤ α ≤ 1, e is the vector of all ones, and v is a non-negative, L1normalized vector, sometimes called the random surfer vector.",
                "Note that the matrix D−1 U is well-defined only if each column of U has at least one non-zero entry-i.e., each page in the webgraph has at least one outlink.",
                "In the presence of such dangling nodes that have no outlinks, one commonly used solution, proposed by Brin et al. [3], is to replace each zero column of U by a non-negative, L1-normalized vector.",
                "The PageRank vector r is the dominant eigenvector of the PageRank matrix, r = PU r. We will assume, without loss of generality, that r has an L1-norm of one.",
                "Computationally, r can be computed using the power method.",
                "This method first chooses a random starting vector r(0) , and iteratively multiplies the current vector by the PageRank matrix PU ; see Algorithm 1.",
                "In general, each iteration of the power method can take O(m2 ) operations when PU is a dense matrix.",
                "However, in practice, the number of links in a web graph will be of the order of the number of pages.",
                "By exploiting the sparsity of the PageRank matrix, the work per iteration can be reduced to O(km), where k is the average number of links per web page.",
                "It has also been shown that the total number of iterations needed for convergence is proportional to α and does not depend on the size of the web graph [11, 7].",
                "Finally, the total space needed is also O(km), mainly to store the matrix U. 117 Research Track Paper Algorithm 1: A linear time (per iteration) algorithm for computing PageRank.",
                "ComputePR(U) Input: U: Adjacency matrix.",
                "Output: r: PageRank vector.",
                "Choose (randomly) an initial non-negative vector r(0) such that r(0) 1 = 1. i ← 0 repeat i ← i + 1 ν ← αUD−1 U r(i−1) {α is the random surfing probability} r(i) ← ν + (1 − α)v {v is the random surfer vector.} until r(i) − r(i−1) < δ {δ is the convergence threshold.} r ← r(i) 4.",
                "PROBLEM DEFINITION Given a local domain L, let G be an N × N adjacency matrix for the entire connected component of the web that contains L, such that Gji = 1 if page i links to page j and Gji = 0 otherwise.",
                "Without loss of generality, we will partition G as: G = L Gout Lout Gwithin , (2) where L is the n × n local subgraph corresponding to links inside the local domain, Lout is the subgraph that corresponds to links from the local domain pointing out to the global domain, Gout is the subgraph containing links from the global domain into the local domain, and Gwithin contains links within the global domain.",
                "We assume that when building a localized search engine, only pages inside the local domain are crawled, and the links between these pages are represented by the subgraph L. The links in Lout are also known, as these point from crawled pages in the local domain to uncrawled pages in the global domain.",
                "As defined in equation (1), PG is the PageRank matrix formed from the global graph G, and we define the global PageRank vector of this graph to be g. Let the n-length vector p∗ be the L1-normalized vector corresponding to the global PageRank of the pages in the local domain L: p∗ = EL g ELg 1 , where EL = [ I | 0 ] is the restriction matrix that selects the components from g corresponding to nodes in L. Let p denote the PageRank vector constructed from the local domain subgraph L. In practice, the observed local PageRank p and the global PageRank p∗ will be quite different.",
                "One would expect that as the size of local matrix L approaches the size of global matrix G, the global PageRank and the observed local PageRank will become more similar.",
                "Thus, one approach to estimating the global PageRank is to crawl the entire global domain, compute its PageRank, and extract the PageRanks of the local domain.",
                "Typically, however, n N , i.e., the number of global pages is much larger than the number of local pages.",
                "Therefore, crawling all global pages will quickly exhaust all local resources (computational, storage, and bandwidth) available to create the local search engine.",
                "We instead seek a supergraph ˆF of our local subgraph L with size O(n).",
                "Our goal Algorithm 2: The FindGlobalPR algorithm.",
                "FindGlobalPR(L, Lout, T, k) Input: L: zero-one adjacency matrix for the local domain, Lout: zero-one outlink matrix from L to global subgraph as in (2), T: number of iterations, k: number of pages to crawl per iteration.",
                "Output: ˆp: an improved estimate of the global PageRank of L. F ← L Fout ← Lout f ← ComputePR(F ) for (i = 1 to T) {Determine which pages to crawl next} pages ← SelectNodes(F , Fout, f, k) Crawl pages, augment F and modify Fout {Update PageRanks for new local domain} f ← ComputePR(F ) end {Extract PageRanks of original local domain & normalize} ˆp ← ELf ELf 1 is to find such a supergraph ˆF with PageRank ˆf, so that ˆf when restricted to L is close to p∗ .",
                "Formally, we seek to minimize GlobalDiff( ˆf) = EL ˆf EL ˆf 1 − p∗ 1 . (3) We choose the L1 norm for measuring the error as it does not place excessive weight on outliers (as the L2 norm does, for example), and also because it is the most commonly used distance measure in the literature for comparing PageRank vectors, as well as for detecting convergence of the algorithm [3].",
                "We propose a greedy framework, given in Algorithm 2, for constructing ˆF .",
                "Initially, F is set to the local subgraph L, and the PageRank f of this graph is computed.",
                "The algorithm then proceeds as follows.",
                "First, the SelectNodes algorithm (which we discuss in the next section) is called and it returns a set of k nodes to crawl next from the set of nodes in the current crawl frontier, Fout.",
                "These selected nodes are then crawled to expand the local subgraph, F , and the PageRanks of this expanded graph are then recomputed.",
                "These steps are repeated for each of T iterations.",
                "Finally, the PageRank vector ˆp, which is restricted to pages within the original local domain, is returned.",
                "Given our computation, bandwidth, and memory restrictions, we will assume that the algorithm will crawl at most O(n) pages.",
                "Since the PageRanks are computed in each iteration of the algorithm, which is an O(n) operation, we will also assume that the number of iterations T is a constant.",
                "Of course, the main challenge here is in selecting which set of k nodes to crawl next.",
                "In the next section, we formally define the problem and give efficient algorithms. 5.",
                "NODE SELECTION In this section, we present node selection algorithms that operate within the greedy framework presented in the previous section.",
                "We first give a well-defined criteria for the page selection problem and provide experimental evidence that this criteria can effectively identify pages that optimize our problem objective (3).",
                "We then present our main al118 Research Track Paper gorithmic contribution of the paper, a method with linear running time that is derived from this page selection criteria.",
                "Finally, we give an intuitive analysis of our algorithm in terms of leaks and flows.",
                "We show that if only the flow is considered, then the resulting method is very similar to a widely used page selection heuristic [6]. 5.1 Formulation For a given page j in the global domain, we define the expanded local graph Fj: Fj = F s uT j 0 , (4) where uj is the zero-one vector containing the outlinks from F into page j, and s contains the inlinks from page j into the local domain.",
                "Note that we do not allow self-links in this framework.",
                "In practice, self-links are often removed, as they only serve to inflate a given pages PageRank.",
                "Observe that the inlinks into F from node j are not known until after node j is crawled.",
                "Therefore, we estimate this inlink vector as the expectation over inlink counts among the set of already crawled pages, s = F T e F T e 1 . (5) In practice, for any given page, this estimate may not reflect the true inlinks from that page.",
                "Furthermore, this expectation is sampled from the set of links within the crawled domain, whereas a better estimate would also use links from the global domain.",
                "However, the latter distribution is not known to a localized search engine, and we contend that the above estimate will, on average, be a better estimate than the uniform distribution, for example.",
                "Let the PageRank of F be f. We express the PageRank f+ j of the expanded local graph Fj as f+ j = (1 − xj)fj xj , (6) where xj is the PageRank of the candidate global node j, and fj is the L1-normalized PageRank vector restricted to the pages in F .",
                "Since directly optimizing our problem goal requires knowing the global PageRank p∗ , we instead propose to crawl those nodes that will have the greatest influence on the PageRanks of pages in the original local domain L: influence(j) = k∈L |fj[k] − f[k]| (7) = EL (fj − f) 1.",
                "Experimentally, the influence score is a very good predictor of our problem objective (3).",
                "For each candidate global node j, figure 1(a) shows the objective function value Global Diff(fj) as a function of the influence of page j.",
                "The local domain used here is a crawl of conservative political pages (we will provide more details about this dataset in section 6); we observed similar results in other domains.",
                "The correlation is quite strong, implying that the influence criteria can effectively identify pages that improve the global PageRank estimate.",
                "As a baseline, figure 1(b) compares our objective with an alternative criteria, outlink count.",
                "The outlink count is defined as the number of outlinks from the local domain to page j.",
                "The correlation here is much weaker. .00001 .0001 .001 .01 0.26 0.262 0.264 0.266 Influence Objective 1 10 100 1000 0.266 0.264 0.262 0.26 Outlink Count Objective (a) (b) Figure 1: (a) The correlation between our influence page selection criteria (7) and the actual objective function (3) value is quite strong. (b) This is in contrast to other criteria, such as outlink count, which exhibit a much weaker correlation. 5.2 Computation As described, for each candidate global page j, the influence score (7) must be computed.",
                "If fj is computed exactly for each global page j, then the PageRank algorithm would need to be run for each of the O(n) such global pages j we consider, resulting in an O(n2 ) computational cost for the node selection method.",
                "Thus, computing the exact value of fj will lead to a quadratic algorithm, and we must instead turn to methods of approximating this vector.",
                "The algorithm we present works by performing one power method iteration used by the PageRank algorithm (Algorithm 1).",
                "The convergence rate for the PageRank algorithm has been shown to equal the random surfer probability α [7, 11].",
                "Given a starting vector x(0) , if k PageRank iterations are performed, the current PageRank solution x(k) satisfies: x(k) − x∗ 1 = O(αk x(0) − x∗ 1), (8) where x∗ is the desired PageRank vector.",
                "Therefore, if only one iteration is performed, choosing a good starting vector is necessary to achieve an accurate approximation.",
                "We partition the PageRank matrix PFj , corresponding to the × subgraph Fj as: PFj = ˜F ˜s ˜uT j w , (9) where ˜F = αF (DF + diag(uj))−1 + (1 − α) e + 1 eT , ˜s = αs + (1 − α) e + 1 , ˜uj = α(DF + diag(uj))−1 uj + (1 − α) e + 1 , w = 1 − α + 1 , and diag(uj) is the diagonal matrix with the (i, i)th entry equal to one if the ith element of uj equals one, and is zero otherwise.",
                "We have assumed here that the random surfer vector is the uniform vector, and that L has no dangling links.",
                "These assumptions are not necessary and serve only to simplify discussion and analysis.",
                "A simple approach for estimating fj is the following.",
                "First, estimate the PageRank f+ j of Fj by computing one PageRank iteration over the matrix PFj , using the starting vector ν = f 0 .",
                "Then, estimate fj by removing the last 119 Research Track Paper component from our estimate of f+ j (i.e., the component corresponding to the added node j), and renormalizing.",
                "The problem with this approach is in the starting vector.",
                "Recall from (6) that xj is the PageRank of the added node j.",
                "The difference between the actual PageRank f+ j of PFj and the starting vector ν is ν − f+ j 1 = xj + f − (1 − xj)fj 1 ≥ xj + | f 1 − (1 − xj) fj 1| = xj + |xj| = 2xj.",
                "Thus, by (8), after one PageRank iteration, we expect our estimate of f+ j to still have an error of about 2αxj.",
                "In particular, for candidate nodes j with relatively high PageRank xj, this method will yield more inaccurate results.",
                "We will next present a method that eliminates this bias and runs in O(n) time. 5.2.1 Stochastic Complementation Since f+ j , as given in (6) is the PageRank of the matrix PFj , we have: fj(1 − xj) xj = ˜F ˜s ˜uT j w fj(1 − xj) xj = ˜F fj(1 − xj) + ˜sxj ˜uT j fj(1 − xj) + wxj .",
                "Solving the above system for fj can be shown to yield fj = ( ˜F + (1 − w)−1 ˜s˜uT j )fj. (10) The matrix S = ˜F +(1−w)−1 ˜s˜uT j is known as the stochastic complement of the column stochastic matrix PFj with respect to the sub matrix ˜F .",
                "The theory of stochastic complementation is well studied, and it can be shown the stochastic complement of an irreducible matrix (such as the PageRank matrix) is unique.",
                "Furthermore, the stochastic complement is also irreducible and therefore has a unique stationary distribution as well.",
                "For an extensive study, see [15].",
                "It can be easily shown that the sub-dominant eigenvalue of S is at most +1 α, where is the size of F .",
                "For sufficiently large , this value will be very close to α.",
                "This is important, as other properties of the PageRank algorithm, notably the algorithms sensitivity, are dependent on this value [11].",
                "In this method, we estimate the length vector fj by computing one PageRank iteration over the × stochastic complement S, starting at the vector f: fj ≈ Sf. (11) This is in contrast to the simple method outlined in the previous section, which first iterates over the ( + 1) × ( + 1) matrix PFj to estimate f+ j , and then removes the last component from the estimate and renormalizes to approximate fj.",
                "The problem with the latter method is in the choice of the ( + 1) length starting vector, ν. Consequently, the PageRank estimate given by the simple method differs from the true PageRank by at least 2αxj, where xj is the PageRank of page j.",
                "By using the stochastic complement, we can establish a tight lower bound of zero for this difference.",
                "To see this, consider the case in which a node k is added to F to form the augmented local subgraph Fk, and that the PageRank of this new graph is (1 − xk)f xk .",
                "Specifically, the addition of page k does not change the PageRanks of the pages in F , and thus fk = f. By construction of the stochastic complement, fk = Sfk, so the approximation given in equation (11) will yield the exact solution.",
                "Next, we present the computational details needed to efficiently compute the quantity fj −f 1 over all known global pages j.",
                "We begin by expanding the difference fj −f, where the vector fj is estimated as in (11), fj − f ≈ Sf − f = αF (DF + diag(uj))−1 f + (1 − α) e + 1 eT f +(1 − w)−1 (˜uT j f)˜s − f. (12) Note that the matrix (DF +diag(uj))−1 is diagonal.",
                "Letting o[k] be the outlink count for page k in F , we can express the kth diagonal element as: (DF + diag(uj))−1 [k, k] = 1 o[k]+1 if uj[k] = 1 1 o[k] if uj[k] = 0 Noting that (o[k] + 1)−1 = o[k]−1 − (o[k](o[k] + 1))−1 and rewriting this in matrix form yields (DF +diag(uj))−1 = D−1 F −D−1 F (DF +diag(uj))−1 diag(uj). (13) We use the same identity to express e + 1 = e − e ( + 1) . (14) Recall that, by definition, we have PF = αF D−1 F +(1−α)e .",
                "Substituting (13) and (14) in (12) yields fj − f ≈ (PF f − f) −αF D−1 F (DF + diag(uj))−1 diag(uj)f −(1 − α) e ( + 1) + (1 − w)−1 (˜uT j f)˜s = x + y + (˜uT j f)z, (15) noting that by definition, f = PF f, and defining the vectors x, y, and z to be x = −αF D−1 F (DF + diag(uj))−1 diag(uj)f (16) y = −(1 − α) e ( + 1) (17) z = (1 − w)−1 ˜s. (18) The first term x is a sparse vector, and takes non-zero values only for local pages k that are siblings of the global page j.",
                "We define (i, j) ∈ F if and only if F [j, i] = 1 (equivalently, page i links to page j) and express the value of the component x[k ] as: x[k ] = −α k:(k,k )∈F ,uj [k]=1 f[k] o[k](o[k] + 1) , (19) where o[k], as before, is the number of outlinks from page k in the local domain.",
                "Note that the last two terms, y and z are not dependent on the current global node j.",
                "Given the function hj(f) = y + (˜uT j f)z 1, the quantity fj − f 1 120 Research Track Paper can be expressed as fj − f 1 = k x[k] + y[k] + (˜uT j f)z[k] = k:x[k]=0 y[k] + (˜uT j f)z[k] + k:x[k]=0 x[k] + y[k] + (˜uT j f)z[k] = hj(f) − k:x[k]=0 y[k] + (˜uT j f)z[k] + k:x[k]=0 x[k] + y[k] + (˜uT j f)z[k] . (20) If we can compute the function hj in linear time, then we can compute each value of fj − f 1 using an additional amount of time that is proportional to the number of nonzero components in x.",
                "These optimizations are carried out in Algorithm 3.",
                "Note that (20) computes the difference between all components of f and fj, whereas our node selection criteria, given in (7), is restricted to the components corresponding to nodes in the original local domain L. Let us examine Algorithm 3 in more detail.",
                "First, the algorithm computes the outlink counts for each page in the local domain.",
                "The algorithm then computes the quantity ˜uT j f for each known global page j.",
                "This inner product can be written as (1 − α) 1 + 1 + α k:(k,j)∈Fout f[k] o[k] + 1 , where the second term sums over the set of local pages that link to page j.",
                "Since the total number of edges in Fout was assumed to have size O( ) (recall that is the number of pages in F ), the running time of this step is also O( ).",
                "The algorithm then computes the vectors y and z, as given in (17) and (18), respectively.",
                "The L1NormDiff method is called on the components of these vectors which correspond to the pages in L, and it estimates the value of EL(y + (˜uT j f)z) 1 for each page j.",
                "The estimation works as follows.",
                "First, the values of ˜uT j f are discretized uniformly into c values {a1, ..., ac}.",
                "The quantity EL(y + aiz) 1 is then computed for each discretized value of ai and stored in a table.",
                "To evaluate EL (y + az) 1 for some a ∈ [a1, ac], the closest discretized value ai is determined, and the corresponding entry in the table is used.",
                "The total running time for this method is linear in and the discretization parameter c (which we take to be a constant).",
                "We note that if exact values are desired, we have also developed an algorithm that runs in O( log ) time that is not described here.",
                "In the main loop, we compute the vector x, as defined in equation (16).",
                "The nested loops iterate over the set of pages in F that are siblings of page j.",
                "Typically, the size of this set is bounded by a constant.",
                "Finally, for each page j, the scores vector is updated over the set of non-zero components k of the vector x with k ∈ L. This set has size equal to the number of local siblings of page j, and is a subset of the total number of siblings of page j.",
                "Thus, each iteration of the main loop takes constant time, and the total running time of the main loop is O( ).",
                "Since we have assumed that the size of F will not grow larger than O(n), the total running time for the algorithm is O(n).",
                "Algorithm 3: Node Selection via Stochastic Complementation.",
                "SC-Select(F , Fout, f, k) Input: F : zero-one adjacency matrix of size corresponding to the current local subgraph, Fout: zero-one outlink matrix from F to global subgraph, f: PageRank of F , k: number of pages to return Output: pages: set of k pages to crawl next {Compute outlink sums for local subgraph} foreach (page j ∈ F ) o[j] ← k:(j,k)∈F F[j, k] end {Compute scalar ˜uT j f for each global node j } foreach (page j ∈ Fout) g[j] ← (1 − α) 1 +1 foreach (page k : (k, j) ∈ Fout) g[j] ← g[j] + α f[k] o[k]+1 end end {Compute vectors y and z as in (17) and (18) } y ← −(1 − α) e ( +1) z ← (1 − w)−1 ˜s {Approximate y + g[j] ∗ z 1 for all values g[j]} norm diffs ←L1NormDiffs(g, ELy, ELz) foreach (page j ∈ Fout) {Compute sparse vector x as in (19)} x ← 0 foreach (page k : (k, j) ∈ Fout) foreach (page k : (k, k ) ∈ F )) x[k ] ← x[k ] − f[k] o[k](o[k]+1) end end x ← αx scores[j] ← norm diffs[j] foreach (k : x[k] > 0 and page k ∈ L) scores[j] ← scores[j] − |y[k] + g[j] ∗ z[k]| +|x[k]+y[k]+g[j]∗z[k])| end end Return k pages with highest scores 5.2.2 PageRank Flows We now present an intuitive analysis of the stochastic complementation method by decomposing the change in PageRank in terms of leaks and flows.",
                "This analysis is motivated by the decomposition given in (15).",
                "PageRank flow is the increase in the local PageRanks originating from global page j.",
                "The flows are represented by the non-negative vector (˜uT j f)z (equations (15) and (18)).",
                "The scalar ˜uT j f can be thought of as the total amount of PageRank flow that page j has available to distribute.",
                "The vector z dictates how the flow is allocated to the local domain; the flow that local page k receives is proportional to (within a constant factor due to the random surfer vector) the expected number of its inlinks.",
                "The PageRank leaks represent the decrease in PageRank resulting from the addition of page j.",
                "The leakage can be quantified in terms of the non-positive vectors x and y (equations (16) and (17)).",
                "For vector x, we can see from equation (19) that the amount of PageRank leaked by a local page is proportional to the weighted sum of the Page121 Research Track Paper Ranks of its siblings.",
                "Thus, pages that have siblings with higher PageRanks (and low outlink counts) will experience more leakage.",
                "The leakage caused by y is an artifact of the random surfer vector.",
                "We will next show that if only the flow term, (˜uT j f)z, is considered, then the resulting method is very similar to a heuristic proposed by Cho et al. [6] that has been widely used for the Crawling Through URL Ordering problem.",
                "This heuristic is computationally cheaper, but as we will see later, not as effective as the Stochastic Complementation method.",
                "Our node selection strategy chooses global nodes that have the largest influence (equation (7)).",
                "If this influence is approximated using only flows, the optimal node j∗ is: j∗ = argmaxj EL ˜uT j fz 1 = argmaxj ˜uT j f EL z 1 = argmaxj ˜uT j f = argmaxj α(DF + diag(uj))−1 uj + (1 − α) e + 1 , f = argmaxjfT (DF + diag(uj))−1 uj.",
                "The resulting page selection score can be expressed as a sum of the PageRanks of each local page k that links to j, where each PageRank value is normalized by o[k]+1.",
                "Interestingly, the normalization that arises in our method differs from the heuristic given in [6], which normalizes by o[k].",
                "The algorithm PF-Select, which is omitted due to lack of space, first computes the quantity fT (DF +diag(uj))−1 uj for each global page j, and then returns the pages with the k largest scores.",
                "To see that the running time for this algorithm is O(n), note that the computation involved in this method is a subset of that needed for the SC-Select method (Algorithm 3), which was shown to have a running time of O(n). 6.",
                "EXPERIMENTS In this section, we provide experimental evidence to verify the effectiveness of our algorithms.",
                "We first outline our experimental methodology and then provide results across a variety of local domains. 6.1 Methodology Given the limited resources available at an academic institution, crawling a section of the web that is of the same magnitude as that indexed by Google or Yahoo! is clearly infeasible.",
                "Thus, for a given local domain, we approximate the global graph by crawling a local neighborhood around the domain that is several orders of magnitude larger than the local subgraph.",
                "Even though such a graph is still orders of magnitude smaller than the true global graph, we contend that, even if there exist some highly influential pages that are very far away from our local domain, it is unrealistic for any local node selection algorithm to find them.",
                "Such pages also tend to be highly unrelated to pages within the local domain.",
                "When explaining our node selection strategies in section 5, we made the simplifying assumption that our local graph contained no dangling nodes.",
                "This assumption was only made to ease our analysis.",
                "Our implementation efficiently handles dangling links by replacing each zero column of our adjacency matrix with the uniform vector.",
                "We evaluate the algorithm using the two node selection strategies given in Section 5.2, and also against the following baseline methods: • Random: Nodes are chosen uniformly at random among the known global nodes. • OutlinkCount: Global nodes with the highest number of outlinks from the local domain are chosen.",
                "At each iteration of the FindGlobalPR algorithm, we evaluate performance by computing the difference between the current PageRank estimate of the local domain, ELf ELf 1 , and the global PageRank of the local domain ELg ELg 1 .",
                "All PageRank calculations were performed using the uniform random surfer vector.",
                "Across all experiments, we set the random surfer parameter α, to be .85, and used a convergence threshold of 10−6 .",
                "We evaluate the difference between the local and global PageRank vectors using three different metrics: the L1 and L∞ norms, and Kendalls tau.",
                "The L1 norm measures the sum of the absolute value of the differences between the two vectors, and the L∞ norm measures the absolute value of the largest difference.",
                "Kendalls tau metric is a popular rank correlation measure used to compare PageRanks [2, 11].",
                "This metric can be computed by counting the number of pairs of pairs that agree in ranking, and subtracting from that the number of pairs of pairs that disagree in ranking.",
                "The final value is then normalized by the total number of n 2 such pairs, resulting in a [−1, 1] range, where a negative score signifies anti-correlation among rankings, and values near one correspond to strong rank correlation. 6.2 Results Our experiments are based on two large web crawls and were downloaded using the web crawler that is part of the Nutch open source search engine project [18].",
                "All crawls were restricted to only http pages, and to limit the number of dynamically generated pages that we crawl, we ignored all pages with urls containing any of the characters ?, *, @, or =.",
                "The first crawl, which we will refer to as the edu dataset, was seeded by homepages of the top 100 graduate computer science departments in the USA, as rated by the US News and World Report [16], and also by the home pages of their respective institutions.",
                "A crawl of depth 5 was performed, restricted to pages within the .edu domain, resulting in a graph with approximately 4.7 million pages and 22.9 million links.",
                "The second crawl was seeded by the set of pages under the politics hierarchy in the dmoz open directory project[17].",
                "We crawled all pages up to four links away, which yielded a graph with 4.4 million pages and 17.3 million links.",
                "Within the edu crawl, we identified the five site-specific domains corresponding to the websites of the top five graduate computer science departments, as ranked by the US News and World Report.",
                "This yielded local domains of various sizes, from 10,626 (UIUC) to 59,895 (Berkeley).",
                "For each of these site-specific domains with size n, we performed 50 iterations of the FindGlobalPR algorithm to crawl a total of 2n additional nodes.",
                "Figure 2(a) gives the (L1) difference from the PageRank estimate at each iteration to the global PageRank, for the Berkeley local domain.",
                "The performance of this dataset was representative of the typical performance across the five computer science sitespecific local domains.",
                "Initially, the L1 difference between the global and local PageRanks ranged from .0469 (Stanford) to .149 (MIT).",
                "For the first several iterations, the 122 Research Track Paper 0 5 10 15 20 25 30 35 40 45 50 0.015 0.02 0.025 0.03 0.035 0.04 0.045 0.05 0.055 Number of Iterations GlobalandLocalPageRankDifference(L1) Stochastic Complement PageRank Flow Outlink Count Random 0 10 20 30 40 50 0 0.05 0.1 0.15 0.2 0.25 0.3 0.35 Number of Iterations GlobalandLocalPageRankDifference(L1) Stochastic Complement PageRank Flow Outlink Count Random 0 5 10 15 20 25 0.16 0.18 0.2 0.22 0.24 0.26 0.28 0.3 0.32 0.34 Number of Iterations GlobalandLocalPageRankDifference(L1) Stochastic Complement PageRank Flow Outlink Count Random (a) www.cs.berkeley.edu (b) www.enterstageright.com (c) Politics Figure 2: L1 difference between the estimated and true global PageRanks for (a) Berkeleys computer science website, (b) the site-specific domain, www.enterstageright.com, and (c) the politics <br>topic-specific domain</br>.",
                "The stochastic complement method outperforms all other methods across various domains. three link-based methods all outperform the random selection heuristic.",
                "After these initial iterations, the random heuristic tended to be more competitive with (or even outperform, as in the Berkeley local domain) the outlink count and PageRank flow heuristics.",
                "In all tests, the stochastic complementation method either outperformed, or was competitive with, the other methods.",
                "Table 1 gives the average difference between the final estimated global PageRanks and the true global PageRanks for various distance measures.",
                "Algorithm L1 L∞ Kendall Stoch.",
                "Comp. .0384 .00154 .9257 PR Flow .0470 .00272 .8946 Outlink .0419 .00196 .9053 Random .0407 .00204 .9086 Table 1: Average final performance of various node selection strategies for the five site-specific computer science local domains.",
                "Note that Kendalls Tau measures similarity, while the other metrics are dissimilarity measures.",
                "Stochastic Complementation clearly outperforms the other methods in all metrics.",
                "Within the politics dataset, we also performed two sitespecific tests for the largest websites in the crawl: www.adamsmith.org, the website for the London based Adam Smith Institute, and www.enterstageright.com, an online conservative journal.",
                "As with the edu local domains, we ran our algorithm for 50 iterations, crawling a total of 2n nodes.",
                "Figure 2 (b) plots the results for the www.enterstageright.com domain.",
                "In contrast to the edu local domains, the Random and OutlinkCount methods were not competitive with either the SC-Select or the PF-Select methods.",
                "Among all datasets and all node selection methods, the stochastic complementation method was most impressive in this dataset, realizing a final estimate that differed only .0279 from the global PageRank, a ten-fold improvement over the initial local PageRank difference of .299.",
                "For the Adam Smith local domain, the initial difference between the local and global PageRanks was .148, and the final estimates given by the SC-Select, PF-Select, OutlinkCount, and Random methods were .0208, .0193, .0222, and .0356, respectively.",
                "Within the politics dataset, we constructed four topicspecific local domains.",
                "The first domain consisted of all pages in the dmoz politics category, and also all pages within each of these sites up to two links away.",
                "This yielded a local domain of 90,811 pages, and the results are given in figure 2 (c).",
                "Because of the larger size of the topic-specific domains, we ran our algorithm for only 25 iterations to crawl a total of n nodes.",
                "We also created topic-specific domains from three political sub-topics: liberalism, conservatism, and socialism.",
                "The pages in these domains were identified by their corresponding dmoz categories.",
                "For each sub-topic, we set the local domain to be all pages within three links from the corresponding dmoz category pages.",
                "Table 2 summarizes the performance of these three topic-specific domains, and also the larger political domain.",
                "To quantify a global page js effect on the global PageRank values of pages in the local domain, we define page js impact to be its PageRank value, g[j], normalized by the fraction of its outlinks pointing to the local domain: impact(j) = oL[j] o[j] · g[j], where, oL[j] is the number of outlinks from page j to pages in the local domain L, and o[j] is the total number of js outlinks.",
                "In terms of the random surfer model, the impact of page j is the probability that the random surfer (1) is currently at global page j in her random walk and (2) takes an outlink to a local page, given that she has already decided not to jump to a random page.",
                "For the politics local domain, we found that many of the pages with high impact were in fact political pages that should have been included in the dmoz politics topic, but were not.",
                "For example, the two most influential global pages were the political search engine www.askhenry.com, and the home page of the online political magazine, www.policyreview.com.",
                "Among non-political pages, the home page of the journal Education Next was most influential.",
                "The journal is freely available online and contains articles regarding various aspect of K-12 education in America.",
                "To provide some anecdotal evidence for the effectiveness of our page selection methods, we note that the SC-Select method chose 11 pages within the www.educationnext.org domain, the PF-Select method discovered 7 such pages, while the OutlinkCount and Random methods found only 6 pages each.",
                "For the conservative political local domain, the socialist website www.ornery.org had a very high impact score.",
                "This 123 Research Track Paper All Politics: Algorithm L1 L2 Kendall Stoch.",
                "Comp. .1253 .000700 .8671 PR Flow .1446 .000710 .8518 Outlink .1470 .00225 .8642 Random .2055 .00203 .8271 Conservativism: Algorithm L1 L2 Kendall Stoch.",
                "Comp. .0496 .000990 .9158 PR Flow .0554 .000939 .9028 Outlink .0602 .00527 .9144 Random .1197 .00102 .8843 Liberalism: Algorithm L1 L2 Kendall Stoch.",
                "Comp. .0622 .001360 .8848 PR Flow .0799 .001378 .8669 Outlink .0763 .001379 .8844 Random .1127 .001899 .8372 Socialism: Algorithm L1 L∞ Kendall Stoch.",
                "Comp. .04318 .00439 .9604 PR Flow .0450 .004251 .9559 Outlink .04282 .00344 .9591 Random .0631 .005123 .9350 Table 2: Final performance among node selection strategies for the four political topic-specific crawls.",
                "Note that Kendalls Tau measures similarity, while the other metrics are dissimilarity measures. was largely due to a link from the front page of this site to an article regarding global warming published by the National Center for Public Policy Research, a conservative research group in Washington, DC.",
                "Not surprisingly, the global PageRank of this article (which happens to be on the home page of the NCCPR, www.nationalresearch.com), was approximately .002, whereas the local PageRank of this page was only .00158.",
                "The SC-Select method yielded a global PageRank estimate of approximately .00182, the PFSelect method estimated a value of .00167, and the Random and OutlinkCount methods yielded values of .01522 and .00171, respectively. 7.",
                "RELATED WORK The node selection framework we have proposed is similar to the url ordering for crawling problem proposed by Cho et al. in [6].",
                "Whereas our framework seeks to minimize the difference between the global and local PageRank, the objective used in [6] is to crawl the most highly (globally) ranked pages first.",
                "They propose several node selection algorithms, including the outlink count heuristic, as well as a variant of our PF-Select algorithm which they refer to as the PageRank ordering metric.",
                "They found this method to be most effective in optimizing their objective, as did a recent survey of these methods by Baeza-Yates et al. [1].",
                "Boldi et al. also experiment within a similar crawling framework in [2], but quantify their results by comparing Kendalls rank correlation between the PageRanks of the current set of crawled pages and those of the entire global graph.",
                "They found that node selection strategies that crawled pages with the highest global PageRank first actually performed worse (with respect to Kendalls Tau correlation between the local and global PageRanks) than basic depth first or breadth first strategies.",
                "However, their experiments differ from our work in that our node selection algorithms do not use (or have access to) global PageRank values.",
                "Many algorithmic improvements for computing exact PageRank values have been proposed [9, 10, 14].",
                "If such algorithms are used to compute the global PageRanks of our local domain, they would all require O(N) computation, storage, and bandwidth, where N is the size of the global domain.",
                "This is in contrast to our method, which approximates the global PageRank and scales linearly with the size of the local domain.",
                "Wang and Dewitt [22] propose a system where the set of web servers that comprise the global domain communicate with each other to compute their respective global PageRanks.",
                "For a given web server hosting n pages, the computational, bandwidth, and storage requirements are also linear in n. One drawback of this system is that the number of distinct web servers that comprise the global domain can be very large.",
                "For example, our edu dataset contains websites from over 3,200 different universities; coordinating such a system among a large number of sites can be very difficult.",
                "Gan, Chen, and Suel propose a method for estimating the PageRank of a single page [5] which uses only constant bandwidth, computation, and space.",
                "Their approach relies on the availability of a remote connectivity server that can supply the set of inlinks to a given page, an assumption not used in our framework.",
                "They experimentally show that a reasonable estimate of the nodes PageRank can be obtained by visiting at most a few hundred nodes.",
                "Using their algorithm for our problem would require that either the entire global domain first be downloaded or a connectivity server be used, both of which would lead to very large web graphs. 8.",
                "CONCLUSIONS AND FUTURE WORK The internet is growing exponentially, and in order to navigate such a large repository as the web, global search engines have established themselves as a necessity.",
                "Along with the ubiquity of these large-scale search engines comes an increase in search users expectations.",
                "By providing complete and isolated coverage of a particular web domain, localized search engines are an effective outlet to quickly locate content that could otherwise be difficult to find.",
                "In this work, we contend that the use of global PageRank in a localized search engine can improve performance.",
                "To estimate the global PageRank, we have proposed an iterative node selection framework where we select which pages from the global frontier to crawl next.",
                "Our primary contribution is our stochastic complementation page selection algorithm.",
                "This method crawls nodes that will most significantly impact the local domain and has running time linear in the number of nodes in the local domain.",
                "Experimentally, we validate these methods across a diverse set of local domains, including seven site-specific domains and four topic-specific domains.",
                "We conclude that by crawling an additional n or 2n pages, our methods find an estimate of the global PageRanks that is up to ten times better than just using the local PageRanks.",
                "Furthermore, we demonstrate that our algorithm consistently outperforms other existing heuristics. 124 Research Track Paper Often times, topic-specific domains are discovered using a focused web crawler which considers a pages content in conjunction with link anchor text to decide which pages to crawl next [4].",
                "Although such crawlers have proven to be quite effective in discovering topic-related content, many irrelevant pages are also crawled in the process.",
                "Typically, these pages are deleted and not indexed by the localized search engine.",
                "These pages can of course provide valuable information regarding the global PageRank of the local domain.",
                "One way to integrate these pages into our framework is to start the FindGlobalPR algorithm with the current subgraph F equal to the set of pages that were crawled by the focused crawler.",
                "The global PageRank estimation framework, along with the node selection algorithms presented, all require O(n) computation per iteration and bandwidth proportional to the number of pages crawled, Tk.",
                "If the number of iterations T is relatively small compared to the number of pages crawled per iteration, k, then the bottleneck of the algorithm will be the crawling phase.",
                "However, as the number of iterations increases (relative to k), the bottleneck will reside in the node selection computation.",
                "In this case, our algorithms would benefit from constant factor optimizations.",
                "Recall that the FindGlobalPR algorithm (Algorithm 2) requires that the PageRanks of the current expanded local domain be recomputed in each iteration.",
                "Recent work by Langville and Meyer [12] gives an algorithm to quickly recompute PageRanks of a given webgraph if a small number of nodes are added.",
                "This algorithm was shown to give speedup of five to ten times on some datasets.",
                "We plan to investigate this and other such optimizations as future work.",
                "In this paper, we have objectively evaluated our methods by measuring how close our global PageRank estimates are to the actual global PageRanks.",
                "To determine the benefit of using global PageRanks in a localized search engine, we suggest a user study in which users are asked to rate the quality of search results for various search queries.",
                "For some queries, only the local PageRanks are used in ranking, and for the remaining queries, local PageRanks and the approximate global PageRanks, as computed by our algorithms, are used.",
                "The results of such a study can then be analyzed to determine the added benefit of using the global PageRanks computed by our methods, over just using the local PageRanks.",
                "Acknowledgements.",
                "This research was supported by NSF grant CCF-0431257, NSF Career Award ACI-0093404, and a grant from Sabre, Inc. 9.",
                "REFERENCES [1] R. Baeza-Yates, M. Marin, C. Castillo, and A. Rodriguez.",
                "Crawling a country: better strategies than breadth-first for web page ordering.",
                "World-Wide Web Conference, 2005. [2] P. Boldi, M. Santini, and S. Vigna.",
                "Do your worst to make the best: paradoxical effects in pagerank incremental computations.",
                "Workshop on Web Graphs, 3243:168-180, 2004. [3] S. Brin and L. Page.",
                "The anatomy of a large-scale hypertextual web search engine.",
                "Computer Networks and ISDN Systems, 33(1-7):107-117, 1998. [4] S. Chakrabarti, M. van den Berg, and B. Dom.",
                "Focused crawling: a new approach to topic-specific web resource discovery.",
                "World-Wide Web Conference, 1999. [5] Y. Chen, Q. Gan, and T. Suel.",
                "Local methods for estimating pagerank values.",
                "Conference on Information and Knowledge Management, 2004. [6] J. Cho, H. Garcia-Molina, and L. Page.",
                "Efficient crawling through url ordering.",
                "World-Wide Web Conference, 1998. [7] T. H. Haveliwala and S. D. Kamvar.",
                "The second eigenvalue of the Google matrix.",
                "Technical report, Stanford University, 2003. [8] T. Joachims, F. Radlinski, L. Granka, A. Cheng, C. Tillekeratne, and A. Patel.",
                "Learning retrieval functions from implicit feedback. http://www.cs.cornell.edu/People/tj/career. [9] S. D. Kamvar, T. H. Haveliwala, C. D. Manning, and G. H. Golub.",
                "Exploiting the block structure of the web for computing pagerank.",
                "World-Wide Web Conference, 2003. [10] S. D. Kamvar, T. H. Haveliwala, C. D. Manning, and G. H. Golub.",
                "Extrapolation methods for accelerating pagerank computation.",
                "World-Wide Web Conference, 2003. [11] A. N. Langville and C. D. Meyer.",
                "Deeper inside pagerank.",
                "Internet Mathematics, 2004. [12] A. N. Langville and C. D. Meyer.",
                "Updating the stationary vector of an irreducible markov chain with an eye on Googles pagerank.",
                "SIAM Journal on Matrix Analysis, 2005. [13] P. Lyman, H. R. Varian, K. Swearingen, P. Charles, N. Good, L. L. Jordan, and J. Pal.",
                "How much information 2003?",
                "School of Information Management and System, University of California at Berkely, 2003. [14] F. McSherry.",
                "A uniform approach to accelerated pagerank computation.",
                "World-Wide Web Conference, 2005. [15] C. D. Meyer.",
                "Stochastic complementation, uncoupling markov chains, and the theory of nearly reducible systems.",
                "SIAM Review, 31:240-272, 1989. [16] US News and World Report. http://www.usnews.com. [17] Dmoz open directory project. http://www.dmoz.org. [18] Nutch open source search engine. http://www.nutch.org. [19] F. Radlinski and T. Joachims.",
                "Query chains: learning to rank from implicit feedback.",
                "ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, 2005. [20] S. Raghavan and H. Garcia-Molina.",
                "Crawling the hidden web.",
                "In Proceedings of the Twenty-seventh International Conference on Very Large Databases, 2001. [21] T. Tin Tang, D. Hawking, N. Craswell, and K. Griffiths.",
                "Focused crawling for both topical relevance and quality of medical information.",
                "Conference on Information and Knowledge Management, 2005. [22] Y. Wang and D. J. DeWitt.",
                "Computing pagerank in a distributed internet search system.",
                "Proceedings of the 30th VLDB Conference, 2004. 125 Research Track Paper"
            ],
            "original_annotated_samples": [
                "For the first several iterations, the 122 Research Track Paper 0 5 10 15 20 25 30 35 40 45 50 0.015 0.02 0.025 0.03 0.035 0.04 0.045 0.05 0.055 Number of Iterations GlobalandLocalPageRankDifference(L1) Stochastic Complement PageRank Flow Outlink Count Random 0 10 20 30 40 50 0 0.05 0.1 0.15 0.2 0.25 0.3 0.35 Number of Iterations GlobalandLocalPageRankDifference(L1) Stochastic Complement PageRank Flow Outlink Count Random 0 5 10 15 20 25 0.16 0.18 0.2 0.22 0.24 0.26 0.28 0.3 0.32 0.34 Number of Iterations GlobalandLocalPageRankDifference(L1) Stochastic Complement PageRank Flow Outlink Count Random (a) www.cs.berkeley.edu (b) www.enterstageright.com (c) Politics Figure 2: L1 difference between the estimated and true global PageRanks for (a) Berkeleys computer science website, (b) the site-specific domain, www.enterstageright.com, and (c) the politics <br>topic-specific domain</br>."
            ],
            "translated_annotated_samples": [
                "Para las primeras varias iteraciones, el Artículo de Investigación 122 0 5 10 15 20 25 30 35 40 45 50 0.015 0.02 0.025 0.03 0.035 0.04 0.045 0.05 0.055 Número de Iteraciones Diferencia de PageRank Global y Local (L1) Complemento Estocástico PageRank Flujo de Enlaces de Conteo Aleatorio 0 10 20 30 40 50 0 0.05 0.1 0.15 0.2 0.25 0.3 0.35 Número de Iteraciones Diferencia de PageRank Global y Local (L1) Complemento Estocástico PageRank Flujo de Enlaces de Conteo Aleatorio 0 5 10 15 20 25 0.16 0.18 0.2 0.22 0.24 0.26 0.28 0.3 0.32 0.34 Número de Iteraciones Diferencia de PageRank Global y Local (L1) Complemento Estocástico PageRank Flujo de Enlaces de Conteo Aleatorio (a) www.cs.berkeley.edu (b) www.enterstageright.com (c) Política Figura 2: Diferencia L1 entre los PageRanks globales estimados y verdaderos para (a) el sitio web de ciencias de la computación de Berkeley, (b) el dominio específico del sitio, www.enterstageright.com, y (c) el <br>dominio específico del tema</br> de política."
            ],
            "translated_text": "Estimando el PageRank Global de Comunidades Web Jason V. Davis Dept. Departamento de Ciencias de la Computación Universidad de Texas en Austin Austin, TX 78712 jdavis@cs.utexas.edu Inderjit S. Dhillon Departamento de Ciencias de la Computación Universidad de Texas en Austin Austin, TX 78712 inderjit@cs.utexas.edu RESUMEN Los motores de búsqueda localizados son sistemas a pequeña escala que indexan una comunidad particular en la web. Ofrecen varios beneficios en comparación con sus contrapartes a gran escala, ya que son relativamente económicos de construir y pueden proporcionar una capacidad de búsqueda más precisa y completa en sus dominios relevantes. Una desventaja que tienen estos sistemas en comparación con los motores de búsqueda a gran escala es la falta de valores globales de PageRank. Se necesita esa información para evaluar el valor de las páginas en el dominio de búsqueda localizada dentro del contexto de la web en su totalidad. En este artículo, presentamos algoritmos bien fundamentados para estimar los valores globales de PageRank de un dominio local. Los algoritmos son altamente escalables en el sentido de que, dado un dominio local de tamaño n, utilizan recursos de O(n) que incluyen tiempo de computación, ancho de banda y almacenamiento. Probamos nuestros métodos en una variedad de dominios localizados, incluyendo dominios específicos del sitio y dominios específicos del tema. Demostramos que al rastrear tan solo n o 2n páginas adicionales, nuestros métodos pueden proporcionar excelentes estimaciones globales de PageRank. Categorías y Descriptores de Asignaturas H.3.3 [Almacenamiento y Recuperación de Información]: Búsqueda y Recuperación de Información; G.1.3 [Análisis Numérico]: Álgebra Lineal Numérica; G.3 [Probabilidad y Estadística]: Procesos de Markov Términos Generales PageRank, Cadena de Markov, Complementación Estocástica. Los motores de búsqueda localizados son motores de búsqueda a pequeña escala que indexan solo una comunidad específica de la web. Tales comunidades pueden ser dominios específicos del sitio, como páginas dentro del dominio cs.utexas.edu, o comunidades relacionadas con un tema, por ejemplo, sitios web políticos. En comparación con el grafo web rastreado e indexado por los motores de búsqueda a gran escala, el tamaño de estas comunidades locales suele ser típicamente órdenes de magnitud más pequeño. Por consiguiente, los recursos computacionales necesarios para construir un motor de búsqueda de este tipo también son igualmente más ligeros. Al restringirse a secciones más pequeñas y manejables de la web, los motores de búsqueda localizados también pueden ofrecer capacidades de búsqueda más precisas y completas dentro de sus respectivos dominios. Una desventaja de los índices localizados es la falta de información global necesaria para calcular clasificaciones basadas en enlaces. El algoritmo PageRank [3] ha demostrado ser una medida efectiva de este tipo. En general, el PageRank de una página dada depende de las páginas en todo el grafo web. En el contexto de un motor de búsqueda localizado, si los PageRanks se calculan utilizando solo el subgrafo local, entonces esperaríamos que los PageRanks resultantes reflejen la popularidad percibida dentro de la comunidad local y no de la web en su totalidad. Por ejemplo, consideremos un motor de búsqueda localizado que indexa páginas políticas con puntos de vista conservadores. Una persona que desee investigar las opiniones sobre el calentamiento global dentro de la comunidad política conservadora puede encontrarse con numerosas opiniones de este tipo en varios sitios web. Si solo se dispone de valores de PageRank locales, entonces los resultados de búsqueda reflejarán solo creencias fuertemente arraigadas dentro de la comunidad. Sin embargo, si los PageRanks globales también están disponibles, entonces los resultados pueden reflejar adicionalmente las opiniones de los externos sobre la comunidad conservadora (es decir, aquellos documentos a los que los liberales acceden con mayor frecuencia dentro de la comunidad conservadora). Por lo tanto, para muchos motores de búsqueda localizados, la incorporación de PageRanks globales puede mejorar la calidad de los resultados de búsqueda. Sin embargo, el número de páginas que indexa un motor de búsqueda local suele ser órdenes de magnitud más pequeño que el número de páginas indexadas por sus contrapartes a gran escala. Los motores de búsqueda localizados no tienen el ancho de banda, la capacidad de almacenamiento o la potencia computacional para rastrear, descargar y calcular los PageRanks globales de toda la web. En este trabajo, presentamos un método para aproximar los PageRanks globales de un dominio local utilizando recursos del mismo orden que los necesarios para calcular los PageRanks del subgrafo local. Nuestro método propuesto busca un supergrafo de nuestro subgrafo local de manera que los PageRanks locales dentro de este supergrafo estén cerca de los verdaderos PageRanks globales. Construimos este supergrafo mediante el rastreo iterativo de páginas globales en la frontera web actual, es decir, páginas globales con enlaces entrantes de páginas que ya han sido rastreadas. Para proporcionar a 116 Research Track Paper una buena aproximación a los PageRanks globales, es necesario tener cuidado al elegir qué páginas rastrear a continuación; en este documento, presentamos un algoritmo de selección de páginas bien fundamentado que también tiene un buen rendimiento empírico. Este algoritmo se deriva de un objetivo de problema bien definido y tiene un tiempo de ejecución lineal en el número de nodos locales. Experimentamos en varios tipos de subgrafos locales, incluidas cuatro comunidades relacionadas con el tema y varios dominios específicos del sitio. Para evaluar el rendimiento, medimos la diferencia entre la estimación actual del PageRank global y el PageRank global, en función del número de páginas rastreadas. Comparamos nuestro algoritmo con varios heurísticos y también con un algoritmo base que elige páginas al azar, y demostramos que nuestro método supera a estos otros métodos. Finalmente, demostramos empíricamente que, dado un dominio local de tamaño n, podemos proporcionar buenas aproximaciones a los valores globales de PageRank rastreando como máximo n o 2n páginas adicionales. El documento está organizado de la siguiente manera. La sección 2 ofrece una visión general de los motores de búsqueda localizados y destaca sus ventajas sobre los motores de búsqueda globales. La sección 3 proporciona antecedentes sobre el algoritmo PageRank. La sección 4 define formalmente nuestro problema, y la sección 5 presenta nuestros criterios de selección de páginas y deriva nuestros algoritmos. La sección 6 presenta los resultados experimentales, la sección 7 ofrece una visión general del trabajo relacionado y, finalmente, las conclusiones se presentan en la sección 8. MOTORES DE BÚSQUEDA LOCALIZADOS Los motores de búsqueda localizados indexan una sola comunidad de la web, típicamente una comunidad específica del sitio o una comunidad específica del tema. Los motores de búsqueda localizados disfrutan de tres ventajas principales sobre sus contrapartes a gran escala: son relativamente económicos de construir, pueden ofrecer una capacidad de búsqueda más precisa dentro de su dominio local y pueden proporcionar un índice más completo. Los recursos necesarios para construir un motor de búsqueda global son enormes. Un estudio de 2003 realizado por Lyman et al. [13] encontró que la web superficial (sitios estáticos de acceso público) consta de 8.9 mil millones de páginas, y que el tamaño promedio de estas páginas es de aproximadamente 18.7 kilobytes. Para descargar un rastreo de este tamaño, se necesita aproximadamente 167 terabytes de espacio. Para un investigador que desee construir un motor de búsqueda con acceso a un par de estaciones de trabajo o un servidor pequeño, un almacenamiento de esta magnitud simplemente no está disponible. Sin embargo, construir un motor de búsqueda localizado sobre una comunidad web de cien mil páginas solo requeriría unos pocos gigabytes de almacenamiento. La carga computacional necesaria para soportar consultas de búsqueda sobre una base de datos de este tamaño es más manejable también. Observamos que, para los motores de búsqueda específicos de un tema, la comunidad relevante puede ser identificada y descargada de manera eficiente utilizando un rastreador enfocado [21, 4]. Para dominios específicos del sitio, el dominio local está fácilmente disponible en su propio servidor web. Esto evita la necesidad de rastreo o indexación, y por lo tanto se puede garantizar un índice completo y actualizado del dominio. Esto contrasta con sus contrapartes a gran escala, las cuales sufren de varias deficiencias. Primero, el rastreo de páginas generadas dinámicamente en la web oculta ha sido objeto de investigación [20] y es una tarea no trivial para un rastreador externo. En segundo lugar, los dominios específicos del sitio pueden habilitar la política de exclusión de robots. Esto prohíbe a los rastreadores de motores de búsqueda externos descargar contenido del dominio, y en su lugar un motor de búsqueda externo debe depender de enlaces externos y texto ancla para indexar estas páginas restringidas. Al restringirse a un dominio específico de internet, un motor de búsqueda localizado puede proporcionar resultados de búsqueda más precisos. Considera la consulta de búsqueda ambigua canónica, jaguar, que puede referirse tanto al fabricante de automóviles como al animal. Un científico que intenta investigar el hábitat y la historia evolutiva de un jaguar puede tener más éxito utilizando un motor de búsqueda específico de zoología bien ajustado que consultando Google con múltiples búsquedas de palabras clave y navegando a través de resultados irrelevantes. Recientemente se propuso un método para aprender funciones de clasificación mejores para la recuperación por Radlinski y Joachims [19] y se ha aplicado a varios dominios locales, incluido el sitio web de la Universidad de Cornell [8]. 3. PAGERANK RESUMEN El algoritmo PageRank define la importancia de las páginas web analizando la estructura de hipervínculos subyacente de un grafo web. El algoritmo funciona construyendo una cadena de Markov a partir de la estructura de enlaces del grafo web y calculando su distribución estacionaria. Una forma de calcular la distribución estacionaria de una cadena de Markov es encontrar la distribución límite de un paseo aleatorio sobre la cadena. Por lo tanto, el algoritmo PageRank utiliza lo que a veces se conoce como el modelo del surfista aleatorio. En cada paso de la caminata aleatoria, el surfista sigue un enlace de salida de la página actual (es decir, el nodo actual en la cadena), o salta a una página aleatoria en la web. Ahora definimos con precisión el problema de PageRank. Sea U una matriz de adyacencia m × m para un grafo web dado tal que Uji = 1 si la página i enlaza a la página j y Uji = 0 en caso contrario. Definimos la matriz de PageRank PU como: PU = αUD−1 U + (1 − α)veT , (1) donde DU es la matriz diagonal (única) tal que UD−1 U es estocástica por columnas, α es un escalar dado tal que 0 ≤ α ≤ 1, e es el vector de todos unos, y v es un vector no negativo, L1-normalizado, a veces llamado vector de navegante aleatorio. Ten en cuenta que la matriz D−1 U está bien definida solo si cada columna de U tiene al menos una entrada distinta de cero, es decir, cada página en el grafo web tiene al menos un enlace de salida. En presencia de nodos colgantes que no tienen enlaces de salida, una solución comúnmente utilizada, propuesta por Brin et al. [3], es reemplazar cada columna de ceros de U por un vector no negativo, normalizado en L1. El vector PageRank r es el eigenvector dominante de la matriz PageRank, r = PU r. Supondremos, sin pérdida de generalidad, que r tiene una norma L1 de uno. Computacionalmente, r se puede calcular utilizando el método de la potencia. Este método primero elige un vector inicial aleatorio r(0) y, de forma iterativa, multiplica el vector actual por la matriz de PageRank PU; ver Algoritmo 1. En general, cada iteración del método de la potencia puede requerir O(m2) operaciones cuando PU es una matriz densa. Sin embargo, en la práctica, el número de enlaces en un grafo web será del orden del número de páginas. Al explotar la dispersión de la matriz de PageRank, el trabajo por iteración se puede reducir a O(km), donde k es el número promedio de enlaces por página web. También se ha demostrado que el número total de iteraciones necesarias para la convergencia es proporcional a α y no depende del tamaño del grafo web [11, 7]. Finalmente, el espacio total necesario también es O(km), principalmente para almacenar la matriz U. 117 Research Track Paper Algorithm 1: Un algoritmo de tiempo lineal (por iteración) para calcular PageRank. CalcularPR(U) Entrada: U: Matriz de adyacencia. Salida: vector de PageRank. Elige (aleatoriamente) un vector inicial no negativo r(0) tal que r(0) 1 = 1. i ← 0 repetir i ← i + 1 ν ← αUD−1 U r(i−1) {α es la probabilidad de navegación aleatoria} r(i) ← ν + (1 − α)v {v es el vector del navegante aleatorio.} hasta que r(i) − r(i−1) < δ {δ es el umbral de convergencia.} r ← r(i) 4. Dada un dominio local L, sea G una matriz de adyacencia N × N para el componente conectado completo de la web que contiene L, tal que Gji = 1 si la página i enlaza a la página j y Gji = 0 en caso contrario. Sin pérdida de generalidad, vamos a dividir G de la siguiente manera: G = L Gout Lout Gwithin, donde L es el subgrafo local de n × n correspondiente a los enlaces dentro del dominio local, Lout es el subgrafo que corresponde a los enlaces desde el dominio local apuntando hacia el dominio global, Gout es el subgrafo que contiene los enlaces desde el dominio global hacia el dominio local, y Gwithin contiene los enlaces dentro del dominio global. Suponemos que al construir un motor de búsqueda localizado, solo se rastrean las páginas dentro del dominio local, y los enlaces entre estas páginas están representados por el subgrafo L. También se conocen los enlaces en Lout, ya que estos apuntan desde las páginas rastreadas en el dominio local a las páginas no rastreadas en el dominio global. Como se define en la ecuación (1), PG es la matriz de PageRank formada a partir del grafo global G, y definimos el vector de PageRank global de este grafo como g. Sea el vector de longitud n p∗ el vector L1-normalizado que corresponde al PageRank global de las páginas en el dominio local L: p∗ = EL g ELg 1 , donde EL = [ I | 0 ] es la matriz de restricción que selecciona los componentes de g correspondientes a los nodos en L. Sea p el vector de PageRank construido a partir del subgrafo del dominio local L. En la práctica, el PageRank local observado p y el PageRank global p∗ serán bastante diferentes. Se esperaría que a medida que el tamaño de la matriz local L se acerque al tamaño de la matriz global G, el PageRank global y el PageRank local observado se vuelvan más similares. Por lo tanto, un enfoque para estimar el PageRank global es rastrear todo el dominio global, calcular su PageRank y extraer los PageRanks del dominio local. Por lo general, sin embargo, n N, es decir, el número de páginas globales es mucho mayor que el número de páginas locales. Por lo tanto, rastrear todas las páginas globales agotará rápidamente todos los recursos locales (computacionales, de almacenamiento y de ancho de banda) disponibles para crear el motor de búsqueda local. En cambio, buscamos un supergrafo ˆF de nuestro subgrafo local L con tamaño O(n). Nuestro objetivo es el Algoritmo 2: El algoritmo FindGlobalPR. EncuentraGlobalPR(L, Lout, T, k) Entrada: L: matriz de adyacencia de ceros y unos para el dominio local, Lout: matriz de enlaces de ceros y unos desde L al subgrafo global como en (2), T: número de iteraciones, k: número de páginas a rastrear por iteración. Salida: ˆp: una estimación mejorada del PageRank global de L. F ← L Fout ← Lout f ← CalcularPR(F) para (i = 1 a T) {Determinar qué páginas rastrear a continuación} páginas ← SeleccionarNodos(F, Fout, f, k) Rastrear páginas, aumentar F y modificar Fout {Actualizar PageRanks para el nuevo dominio local} f ← CalcularPR(F) fin {Extraer PageRanks del dominio local original y normalizar} ˆp ← ELf ELf 1 es encontrar un supergrafo ˆF con PageRank ˆf, de modo que ˆf cuando se restringe a L esté cerca de p∗. Formalmente, buscamos minimizar GlobalDiff( ˆf) = EL ˆf EL ˆf 1 − p∗ 1 . (3) Elegimos la norma L1 para medir el error ya que no otorga un peso excesivo a los valores atípicos (como lo hace la norma L2, por ejemplo), y también porque es la medida de distancia más comúnmente utilizada en la literatura para comparar vectores de PageRank, así como para detectar la convergencia del algoritmo [3]. Proponemos un marco codicioso, presentado en el Algoritmo 2, para construir ˆF. Inicialmente, F se establece en el subgrafo local L, y se calcula el PageRank f de este grafo. El algoritmo luego procede de la siguiente manera. Primero, se llama al algoritmo SelectNodes (que discutimos en la siguiente sección) y devuelve un conjunto de k nodos para rastrear a continuación del conjunto de nodos en la frontera de rastreo actual, Fout. Estos nodos seleccionados son luego rastreados para expandir el subgrafo local, F, y los PageRanks de este grafo expandido son luego recalculados. Estos pasos se repiten para cada una de las T iteraciones. Finalmente, se devuelve el vector PageRank ˆp, el cual está restringido a las páginas dentro del dominio local original. Dadas nuestras restricciones de computación, ancho de banda y memoria, asumiremos que el algoritmo rastreará como máximo O(n) páginas. Dado que los PageRanks se calculan en cada iteración del algoritmo, lo cual es una operación O(n), también asumiremos que el número de iteraciones T es una constante. Por supuesto, el principal desafío aquí radica en seleccionar qué conjunto de k nodos rastrear a continuación. En la siguiente sección, definimos formalmente el problema y presentamos algoritmos eficientes. 5. SELECCIÓN DE NODO En esta sección, presentamos algoritmos de selección de nodo que operan dentro del marco codicioso presentado en la sección anterior. Primero damos un criterio bien definido para el problema de selección de páginas y proporcionamos evidencia experimental de que este criterio puede identificar de manera efectiva las páginas que optimizan nuestro objetivo del problema (3). A continuación, presentamos nuestra principal contribución algorítmica del artículo de investigación al118, un método con tiempo de ejecución lineal que se deriva de los criterios de selección de esta página. Finalmente, ofrecemos un análisis intuitivo de nuestro algoritmo en términos de fugas y flujos. Mostramos que si solo se considera el flujo, entonces el método resultante es muy similar a una heurística de selección de páginas ampliamente utilizada [6]. 5.1 Formulación Para una página dada j en el dominio global, definimos el grafo local expandido Fj: Fj = F s uT j 0, (4) donde uj es el vector de ceros y unos que contiene los enlaces de salida de F hacia la página j, y s contiene los enlaces de entrada de la página j en el dominio local. Ten en cuenta que no permitimos enlaces a uno mismo en este marco de trabajo. En la práctica, los enlaces internos suelen ser eliminados, ya que solo sirven para inflar el PageRank de una página determinada. Observa que los enlaces entrantes a F desde el nodo j no se conocen hasta después de que el nodo j sea rastreado. Por lo tanto, estimamos este vector de inlink como la expectativa sobre el recuento de inlinks entre el conjunto de páginas ya rastreadas, s = F T e F T e 1. En la práctica, para cualquier página dada, esta estimación puede no reflejar los verdaderos inlinks de esa página. Además, esta expectativa se extrae del conjunto de enlaces dentro del dominio rastreado, mientras que una estimación más precisa también utilizaría enlaces del dominio global. Sin embargo, la distribución mencionada no es conocida por un motor de búsqueda localizado, y sostenemos que la estimación anterior, en promedio, será una estimación mejor que la distribución uniforme, por ejemplo. Dejemos que el PageRank de F sea f. Expresamos el PageRank f+ j del grafo local expandido Fj como f+ j = (1 − xj)fj xj , donde xj es el PageRank del nodo global candidato j, y fj es el vector de PageRank L1-normalizado restringido a las páginas en F. Dado que optimizar directamente nuestro objetivo requiere conocer el PageRank global p∗, proponemos en su lugar rastrear aquellos nodos que tendrán la mayor influencia en los PageRanks de las páginas en el dominio local original L: influencia(j) = k∈L |fj[k] − f[k]| (7) = EL (fj − f) 1. Experimentalmente, el puntaje de influencia es un predictor muy bueno de nuestro objetivo del problema (3). Para cada nodo global candidato j, la figura 1(a) muestra el valor de la función objetivo Global Diff(fj) en función de la influencia de la página j. El dominio local utilizado aquí es un rastreo de páginas políticas conservadoras (proporcionaremos más detalles sobre este conjunto de datos en la sección 6); observamos resultados similares en otros dominios. La correlación es bastante fuerte, lo que implica que los criterios de influencia pueden identificar de manera efectiva las páginas que mejoran la estimación global del PageRank. Como referencia, la figura 1(b) compara nuestro objetivo con un criterio alternativo, el recuento de enlaces de salida. El recuento de enlaces de salida se define como el número de enlaces de salida desde el dominio local a la página j. La correlación aquí es mucho más débil. .00001 .0001 .001 .01 0.26 0.262 0.264 0.266 Influencia Objetivo 1 10 100 1000 0.266 0.264 0.262 0.26 Recuento de Enlaces Salientes Objetivo (a) (b) Figura 1: (a) La correlación entre nuestros criterios de selección de página de influencia (7) y el valor real de la función objetivo (3) es bastante fuerte. (b) Esto contrasta con otros criterios, como el recuento de enlaces salientes, que muestran una correlación mucho más débil. 5.2 Cálculo Como se describe, para cada página global candidata j, se debe calcular el puntaje de influencia (7). Si fj se calcula exactamente para cada página global j, entonces el algoritmo de PageRank tendría que ejecutarse para cada una de las O(n) páginas globales j que consideramos, lo que resultaría en un costo computacional de O(n2) para el método de selección de nodos. Por lo tanto, calcular el valor exacto de fj conducirá a un algoritmo cuadrático, y en su lugar debemos recurrir a métodos de aproximación de este vector. El algoritmo que presentamos funciona realizando una iteración del método de potencia utilizado por el algoritmo PageRank (Algoritmo 1). La tasa de convergencia para el algoritmo PageRank se ha demostrado que es igual a la probabilidad del surfista aleatorio α [7, 11]. Dado un vector inicial x(0), si se realizan k iteraciones de PageRank, la solución actual de PageRank x(k) satisface: x(k) − x∗ 1 = O(αk x(0) − x∗ 1), (8), donde x∗ es el vector de PageRank deseado. Por lo tanto, si solo se realiza una iteración, es necesario elegir un buen vector inicial para lograr una aproximación precisa. Particionamos la matriz de PageRank PFj, correspondiente al subgrafo Fj, como: PFj = ˜F ˜s ˜uT j w, (9) donde ˜F = αF (DF + diag(uj))−1 + (1 − α) e + 1 eT, ˜s = αs + (1 − α) e + 1, ˜uj = α(DF + diag(uj))−1 uj + (1 − α) e + 1, w = 1 − α + 1, y diag(uj) es la matriz diagonal con la entrada (i, i) igual a uno si el i-ésimo elemento de uj es uno, y cero en caso contrario. Hemos asumido aquí que el vector del surfista aleatorio es el vector uniforme, y que L no tiene enlaces colgantes. Estas suposiciones no son necesarias y solo sirven para simplificar la discusión y el análisis. Un enfoque sencillo para estimar fj es el siguiente. Primero, estima el PageRank f+ j de Fj calculando una iteración de PageRank sobre la matriz PFj, utilizando el vector inicial ν = f 0. Luego, estima fj eliminando el último componente de 119 Research Track Paper de nuestra estimación de f+ j (es decir, el componente correspondiente al nodo j añadido), y renormalizando. El problema con este enfoque está en el vector inicial. Recuerde que xj es el PageRank del nodo j añadido. La diferencia entre el PageRank actual f+ j de PFj y el vector inicial ν es ν − f+ j 1 = xj + f − (1 − xj)fj 1 ≥ xj + | f 1 − (1 − xj) fj 1| = xj + |xj| = 2xj. Por lo tanto, según (8), después de una iteración de PageRank, esperamos que nuestra estimación de f+ j todavía tenga un error de aproximadamente 2αxj. En particular, para los nodos candidatos j con un PageRank xj relativamente alto, este método producirá resultados más inexactos. A continuación, presentaremos un método que elimina este sesgo y se ejecuta en tiempo O(n). 5.2.1 Complementación Estocástica Dado que f+ j, como se muestra en (6), es el PageRank de la matriz PFj, tenemos: fj(1 − xj) xj = ˜F ˜s ˜uT j w fj(1 − xj) xj = ˜F fj(1 − xj) + ˜sxj ˜uT j fj(1 − xj) + wxj. Resolver el sistema anterior para fj puede demostrarse que produce fj = ( ˜F + (1 − w)−1 ˜s˜uT j )fj. (10) La matriz S = ˜F +(1−w)−1 ˜s˜uT j se conoce como el complemento estocástico de la matriz estocástica de columna PFj con respecto a la submatriz ˜F. La teoría de complementación estocástica está bien estudiada, y se puede demostrar que el complemento estocástico de una matriz irreducible (como la matriz de PageRank) es único. Además, el complemento estocástico también es irreducible y, por lo tanto, tiene una distribución estacionaria única. Para un estudio extenso, ver [15]. Se puede demostrar fácilmente que el autovalor subdominante de S es a lo sumo +1 α, donde α es el tamaño de F. Para valores suficientemente grandes, este valor estará muy cerca de α. Esto es importante, ya que otras propiedades del algoritmo PageRank, especialmente la sensibilidad del algoritmo, dependen de este valor [11]. En este método, estimamos el vector de longitud fj calculando una iteración de PageRank sobre el complemento estocástico × S, comenzando en el vector f: fj ≈ Sf. (11) Esto contrasta con el método simple descrito en la sección anterior, que primero itera sobre la matriz ( + 1) × ( + 1) PFj para estimar f+ j, y luego elimina el último componente de la estimación y renormaliza para aproximar fj. El problema con el último método radica en la elección del vector inicial de longitud ( + 1), ν. En consecuencia, la estimación de PageRank dada por el método simple difiere del verdadero PageRank en al menos 2αxj, donde xj es el PageRank de la página j. Al utilizar el complemento estocástico, podemos establecer un límite inferior estricto de cero para esta diferencia. Para ver esto, considera el caso en el que se agrega un nodo k a F para formar el subgrafo local aumentado Fk, y que el PageRank de este nuevo grafo es (1 − xk)f xk. Específicamente, la adición de la página k no cambia los PageRanks de las páginas en F, y por lo tanto fk = f. Por la construcción del complemento estocástico, fk = Sfk, por lo que la aproximación dada en la ecuación (11) producirá la solución exacta. A continuación, presentamos los detalles computacionales necesarios para calcular eficientemente la cantidad fj − f 1 sobre todas las páginas globales conocidas j. Comenzamos expandiendo la diferencia fj − f, donde el vector fj se estima como en (11), fj − f ≈ Sf − f = αF (DF + diag(uj))−1 f + (1 − α) e + 1 eT f +(1 − w)−1 (˜uT j f)˜s − f. (12) Tenga en cuenta que la matriz (DF + diag(uj))−1 es diagonal. Dejando que o[k] sea el recuento de enlaces de salida para la página k en F, podemos expresar el elemento diagonal k-ésimo como: (DF + diag(uj))−1 [k, k] = 1 o[k]+1 si uj[k] = 1 1 o[k] si uj[k] = 0 Notando que (o[k] + 1)−1 = o[k]−1 − (o[k](o[k] + 1))−1 y reescribiendo esto en forma matricial obtenemos (DF +diag(uj))−1 = D−1 F −D−1 F (DF +diag(uj))−1 diag(uj). (13) Usamos la misma identidad para expresar e + 1 = e − e ( + 1) . (14) Recordemos que, por definición, tenemos PF = αF D−1 F +(1−α)e. Sustituyendo (13) y (14) en (12) se obtiene que fj − f ≈ (PF f − f) −αF D−1 F (DF + diag(uj))−1 diag(uj)f −(1 − α) e ( + 1) + (1 − w)−1 (˜uT j f)˜s = x + y + (˜uT j f)z, (15), notando que por definición, f = PF f, y definiendo los vectores x, y, y z como x = −αF D−1 F (DF + diag(uj))−1 diag(uj)f (16) y = −(1 − α) e ( + 1) (17) z = (1 − w)−1 ˜s. (18) El primer término x es un vector disperso, y toma valores no nulos solo para las páginas locales k que son hermanas de la página global j. Definimos (i, j) ∈ F si y solo si F [j, i] = 1 (equivalentemente, la página i enlaza a la página j) y expresamos el valor del componente x[k] como: x[k] = −α k:(k,k)∈F, uj[k]=1 f[k] o[k](o[k] + 1), (19) donde o[k], como antes, es el número de enlaces salientes de la página k en el dominio local. Ten en cuenta que los dos últimos términos, y y z, no dependen del nodo global actual j. Dada la función hj(f) = y + (˜uT j f)z 1, la cantidad fj − f 1 120 Research Track Paper puede expresarse como fj − f 1 = k x[k] + y[k] + (˜uT j f)z[k] = k:x[k]=0 y[k] + (˜uT j f)z[k] + k:x[k]=0 x[k] + y[k] + (˜uT j f)z[k] = hj(f) − k:x[k]=0 y[k] + (˜uT j f)z[k] + k:x[k]=0 x[k] + y[k] + (˜uT j f)z[k]. (20) Si podemos calcular la función hj en tiempo lineal, entonces podemos calcular cada valor de fj − f 1 usando una cantidad adicional de tiempo proporcional al número de componentes no nulas en x. Estas optimizaciones se llevan a cabo en el Algoritmo 3. Nótese que la ecuación (20) calcula la diferencia entre todos los componentes de f y fj, mientras que nuestros criterios de selección de nodos, dados en la ecuación (7), se restringen a los componentes correspondientes a los nodos en el dominio local original L. Examinemos el Algoritmo 3 con más detalle. Primero, el algoritmo calcula el número de enlaces de salida para cada página en el dominio local. El algoritmo luego calcula la cantidad ˜uT j f para cada página global j conocida. Este producto interno se puede escribir como (1 − α) 1 + 1 + α k:(k,j)∈Fout f[k] o[k] + 1, donde el segundo término suma sobre el conjunto de páginas locales que enlazan a la página j. Dado que se asumió que el número total de aristas en Fout tenía un tamaño O( ) (recordemos que es el número de páginas en F), el tiempo de ejecución de este paso también es O( ). El algoritmo luego calcula los vectores y y z, como se indican en (17) y (18), respectivamente. El método L1NormDiff se llama en los componentes de estos vectores que corresponden a las páginas en L, y estima el valor de EL(y + (˜uT j f)z) 1 para cada página j. La estimación funciona de la siguiente manera. Primero, los valores de ˜uT j f se discretizan de forma uniforme en c valores {a1, ..., ac}. La cantidad EL(y + aiz) 1 se calcula entonces para cada valor discretizado de ai y se almacena en una tabla. Para evaluar EL (y + az) 1 para algún a ∈ [a1, ac], se determina el valor discretizado más cercano ai, y se utiliza la entrada correspondiente en la tabla. El tiempo total de ejecución de este método es lineal en y el parámetro de discretización c (que consideramos constante). Observamos que si se desean valores exactos, también hemos desarrollado un algoritmo que se ejecuta en tiempo O(log) que no se describe aquí. En el bucle principal, calculamos el vector x, tal como se define en la ecuación (16). Los bucles anidados iteran sobre el conjunto de páginas en F que son hermanas de la página j. Normalmente, el tamaño de este conjunto está limitado por una constante. Finalmente, para cada página j, el vector de puntuaciones se actualiza sobre el conjunto de componentes no nulos k del vector x con k ∈ L. Este conjunto tiene un tamaño igual al número de hermanos locales de la página j, y es un subconjunto del número total de hermanos de la página j. Por lo tanto, cada iteración del bucle principal toma tiempo constante, y el tiempo de ejecución total del bucle principal es O( ). Dado que hemos asumido que el tamaño de F no crecerá más allá de O(n), el tiempo de ejecución total del algoritmo es O(n). Algoritmo 3: Selección de nodos a través de la complementación estocástica. SC-Select(F , Fout, f, k) Entrada: F : matriz de adyacencia de ceros y unos del tamaño correspondiente al subgrafo local actual, Fout: matriz de enlaces de ceros y unos de F al subgrafo global, f: PageRank de F , k: número de páginas a devolver Salida: páginas: conjunto de k páginas para rastrear a continuación {Calcular sumas de enlaces de salida para el subgrafo local} para cada (página j ∈ F ) o[j] ← k:(j,k)∈F F[j, k] fin {Calcular escalar ˜uT j f para cada nodo global j } para cada (página j ∈ Fout) g[j] ← (1 − α) 1 +1 para cada (página k : (k, j) ∈ Fout) g[j] ← g[j] + α f[k] o[k]+1 fin fin {Calcular vectores y z como en (17) y (18) } y ← −(1 − α) e ( +1) z ← (1 − w)−1 ˜s {Aproximar y + g[j] ∗ z 1 para todos los valores g[j]} norm diffs ←L1NormDiffs(g, ELy, ELz) para cada (página j ∈ Fout) {Calcular vector disperso x como en (19)} x ← 0 para cada (página k : (k, j) ∈ Fout) para cada (página k : (k, k ) ∈ F )) x[k ] ← x[k ] − f[k] o[k](o[k]+1) fin fin x ← αx scores[j] ← norm diffs[j] para cada (k : x[k] > 0 y página k ∈ L) scores[j] ← scores[j] − |y[k] + g[j] ∗ z[k]| +|x[k]+y[k]+g[j]∗z[k])| fin fin Devolver k páginas con los puntajes más altos 5.2.2 Flujos de PageRank Ahora presentamos un análisis intuitivo del método de complementación estocástica descomponiendo el cambio en PageRank en términos de fugas y flujos. Este análisis está motivado por la descomposición dada en (15). El flujo de PageRank es el aumento en los PageRanks locales que se originan desde la página global j. Los flujos están representados por el vector no negativo (˜uT j f)z (ecuaciones (15) y (18)). El escalar ˜uT j f se puede pensar como la cantidad total de flujo de PageRank que la página j tiene disponible para distribuir. El vector z dicta cómo se asigna el flujo al dominio local; el flujo que recibe la página local k es proporcional (con un factor constante debido al vector de navegante aleatorio) al número esperado de sus enlaces entrantes. Las filtraciones de PageRank representan la disminución en el PageRank resultante de la adición de la página j. La fuga puede ser cuantificada en términos de los vectores no positivos x e y (ecuaciones (16) y (17)). Para el vector x, podemos ver a partir de la ecuación (19) que la cantidad de PageRank filtrado por una página local es proporcional a la suma ponderada de los Page121 Research Track Paper Ranks de sus páginas hermanas. Por lo tanto, las páginas que tienen hermanos con PageRanks más altos (y un bajo número de enlaces salientes) experimentarán más pérdida de valor. La fuga causada por y es un artefacto del vector del surfista aleatorio. A continuación demostraremos que si solo se considera el término de flujo, (˜uT j f)z, entonces el método resultante es muy similar a una heurística propuesta por Cho et al. [6] que ha sido ampliamente utilizada para el problema de Ordenación de URL en el Rastreo. Esta heurística es computacionalmente más económica, pero como veremos más adelante, no es tan efectiva como el método de Complementación Estocástica. Nuestra estrategia de selección de nodos elige nodos globales que tienen la mayor influencia (ecuación (7)). Si esta influencia se aproxima utilizando solo flujos, el nodo óptimo j∗ es: j∗ = argmaxj EL ˜uT j fz 1 = argmaxj ˜uT j f EL z 1 = argmaxj ˜uT j f = argmaxj α(DF + diag(uj))−1 uj + (1 − α) e + 1 , f = argmaxjfT (DF + diag(uj))−1 uj. La puntuación de selección de página resultante se puede expresar como la suma de los PageRanks de cada página local k que enlaza con j, donde cada valor de PageRank se normaliza por o[k]+1. Curiosamente, la normalización que surge en nuestro método difiere de la heurística dada en [6], la cual normaliza por o[k]. El algoritmo PF-Select, que se omite por falta de espacio, primero calcula la cantidad fT (DF +diag(uj))−1 uj para cada página global j, y luego devuelve las páginas con los k puntajes más altos. Para ver que el tiempo de ejecución de este algoritmo es O(n), observe que la computación involucrada en este método es un subconjunto de la necesaria para el método SC-Select (Algoritmo 3), el cual se demostró que tiene un tiempo de ejecución de O(n). 6. EXPERIMENTOS En esta sección, proporcionamos evidencia experimental para verificar la efectividad de nuestros algoritmos. Primero describimos nuestra metodología experimental y luego presentamos resultados en una variedad de dominios locales. 6.1 Metodología Dado los recursos limitados disponibles en una institución académica, rastrear una sección de la web que sea de la misma magnitud que la indexada por Google o Yahoo! claramente es inviable. Por lo tanto, para un dominio local dado, aproximamos el grafo global rastreando un vecindario local alrededor del dominio que es varias órdenes de magnitud más grande que el subgrafo local. A pesar de que dicho gráfico sigue siendo órdenes de magnitud más pequeño que el verdadero gráfico global, sostenemos que, incluso si existen algunas páginas altamente influyentes que están muy lejos de nuestro dominio local, es poco realista que cualquier algoritmo de selección de nodos locales las encuentre. Tales páginas suelen ser muy poco relacionadas con las páginas dentro del dominio local. Al explicar nuestras estrategias de selección de nodos en la sección 5, hicimos la suposición simplificadora de que nuestro grafo local no contenía nodos colgantes. Esta suposición se hizo solo para facilitar nuestro análisis. Nuestra implementación maneja de manera eficiente los enlaces colgantes al reemplazar cada columna de ceros de nuestra matriz de adyacencia con el vector uniforme. Evaluamos el algoritmo utilizando las dos estrategias de selección de nodos dadas en la Sección 5.2, y también comparándolo con los siguientes métodos de referencia: • Aleatorio: Los nodos se eligen de forma uniforme al azar entre los nodos globales conocidos. • Conteo de enlaces de salida: Se eligen los nodos globales con el mayor número de enlaces de salida desde el dominio local. En cada iteración del algoritmo FindGlobalPR, evaluamos el rendimiento calculando la diferencia entre la estimación actual de PageRank del dominio local, ELf ELf 1, y el PageRank global del dominio local, ELg ELg 1. Todas las calculaciones de PageRank se realizaron utilizando el vector de surfista aleatorio uniforme. En todos los experimentos, establecimos el parámetro del surfista aleatorio α en .85 y utilizamos un umbral de convergencia de 10−6. Evaluamos la diferencia entre los vectores de PageRank local y global utilizando tres métricas diferentes: las normas L1 y L∞, y el tau de Kendall. La norma L1 mide la suma del valor absoluto de las diferencias entre los dos vectores, y la norma L∞ mide el valor absoluto de la mayor diferencia. La métrica de tau de Kendall es una medida de correlación de rangos popular utilizada para comparar PageRanks [2, 11]. Esta métrica se puede calcular contando el número de pares de pares que coinciden en la clasificación, y restando de eso el número de pares de pares que no coinciden en la clasificación. El valor final se normaliza luego por el número total de n pares de este tipo, resultando en un rango de [−1, 1], donde una puntuación negativa indica una anticorrelación entre las clasificaciones, y valores cercanos a uno corresponden a una fuerte correlación de rangos. 6.2 Resultados Nuestros experimentos se basan en dos grandes rastreos web y se descargaron utilizando el rastreador web que forma parte del proyecto de motor de búsqueda de código abierto Nutch [18]. Todas las exploraciones se limitaron únicamente a páginas http, y para limitar el número de páginas generadas dinámicamente que exploramos, ignoramos todas las páginas con URLs que contengan alguno de los caracteres ?, *, @ o =. El primer rastreo, al que nos referiremos como el conjunto de datos edu, fue iniciado por las páginas de inicio de los 100 principales departamentos de posgrado en informática en los Estados Unidos, según la clasificación de US News and World Report [16], y también por las páginas de inicio de sus respectivas instituciones. Se realizó un rastreo de profundidad 5, restringido a páginas dentro del dominio .edu, lo que resultó en un grafo con aproximadamente 4.7 millones de páginas y 22.9 millones de enlaces. El segundo rastreo fue alimentado por el conjunto de páginas bajo la jerarquía de política en el proyecto de directorio abierto dmoz[17]. Rastreamos todas las páginas hasta cuatro enlaces de distancia, lo que resultó en un grafo con 4.4 millones de páginas y 17.3 millones de enlaces. Dentro del rastreo educativo, identificamos los cinco dominios específicos del sitio correspondientes a los sitios web de los cinco principales departamentos de posgrado en ciencias de la computación, según la clasificación de US News and World Report. Esto produjo dominios locales de varios tamaños, desde 10,626 (UIUC) hasta 59,895 (Berkeley). Para cada uno de estos dominios específicos del sitio con tamaño n, realizamos 50 iteraciones del algoritmo FindGlobalPR para rastrear un total de 2n nodos adicionales. La Figura 2(a) muestra la diferencia (L1) entre la estimación de PageRank en cada iteración y el PageRank global, para el dominio local de Berkeley. El rendimiento de este conjunto de datos fue representativo del rendimiento típico en los cinco dominios locales específicos de informática. Inicialmente, la diferencia de L1 entre los PageRanks globales y locales variaba desde .0469 (Stanford) hasta .149 (MIT). Para las primeras varias iteraciones, el Artículo de Investigación 122 0 5 10 15 20 25 30 35 40 45 50 0.015 0.02 0.025 0.03 0.035 0.04 0.045 0.05 0.055 Número de Iteraciones Diferencia de PageRank Global y Local (L1) Complemento Estocástico PageRank Flujo de Enlaces de Conteo Aleatorio 0 10 20 30 40 50 0 0.05 0.1 0.15 0.2 0.25 0.3 0.35 Número de Iteraciones Diferencia de PageRank Global y Local (L1) Complemento Estocástico PageRank Flujo de Enlaces de Conteo Aleatorio 0 5 10 15 20 25 0.16 0.18 0.2 0.22 0.24 0.26 0.28 0.3 0.32 0.34 Número de Iteraciones Diferencia de PageRank Global y Local (L1) Complemento Estocástico PageRank Flujo de Enlaces de Conteo Aleatorio (a) www.cs.berkeley.edu (b) www.enterstageright.com (c) Política Figura 2: Diferencia L1 entre los PageRanks globales estimados y verdaderos para (a) el sitio web de ciencias de la computación de Berkeley, (b) el dominio específico del sitio, www.enterstageright.com, y (c) el <br>dominio específico del tema</br> de política. El método de complemento estocástico supera a todos los demás métodos en diferentes dominios. Tres métodos basados en enlaces superan a la heurística de selección aleatoria. Después de estas iteraciones iniciales, la heurística aleatoria tendió a ser más competitiva con (o incluso superar, como en el dominio local de Berkeley) las heurísticas de conteo de enlaces de salida y flujo de PageRank. En todos los ensayos, el método de complementación estocástica superó a los otros métodos o compitió con ellos. La Tabla 1 muestra la diferencia promedio entre los PageRanks globales estimados finales y los PageRanks globales reales para varias medidas de distancia. Algoritmo L1 L∞ Kendall Estocástico. Tabla 1: Rendimiento final promedio de varias estrategias de selección de nodos para los cinco dominios locales de informática específicos del sitio. Ten en cuenta que el Tau de Kendall mide similitud, mientras que las otras métricas son medidas de disimilitud. La Complementación Estocástica claramente supera a los otros métodos en todas las métricas. Dentro del conjunto de datos de política, también realizamos dos pruebas específicas para los sitios web más grandes en el rastreo: www.adamsmith.org, el sitio web del Instituto Adam Smith con sede en Londres, y www.enterstageright.com, una revista en línea conservadora. Al igual que con los dominios locales de edu, ejecutamos nuestro algoritmo durante 50 iteraciones, rastreando un total de 2n nodos. La figura 2 (b) muestra los resultados para el dominio www.enterstageright.com. A diferencia de los dominios locales de edu, los métodos Random y OutlinkCount no fueron competitivos ni con los métodos SC-Select ni con los métodos PF-Select. Entre todos los conjuntos de datos y todos los métodos de selección de nodos, el método de complementación estocástica fue el más impresionante en este conjunto de datos, logrando una estimación final que difería solo .0279 del PageRank global, una mejora de diez veces sobre la diferencia inicial del PageRank local de .299. Para el dominio local de Adam Smith, la diferencia inicial entre los PageRanks locales y globales fue de .148, y las estimaciones finales proporcionadas por los métodos SC-Select, PF-Select, OutlinkCount y Random fueron de .0208, .0193, .0222 y .0356, respectivamente. Dentro del conjunto de datos de política, construimos cuatro dominios locales específicos de temas. El primer dominio consistía en todas las páginas de la categoría de política de dmoz, y también todas las páginas dentro de cada uno de estos sitios hasta dos enlaces de distancia. Esto produjo un dominio local de 90,811 páginas, y los resultados se muestran en la figura 2 (c). Debido al mayor tamaño de los dominios específicos del tema, ejecutamos nuestro algoritmo solo durante 25 iteraciones para rastrear un total de n nodos. También creamos dominios específicos de temas a partir de tres subtemas políticos: liberalismo, conservadurismo y socialismo. Las páginas en estos dominios fueron identificadas por sus categorías correspondientes de dmoz. Para cada subtema, establecemos el dominio local como todas las páginas dentro de tres enlaces de las páginas de categoría dmoz correspondientes. La Tabla 2 resume el rendimiento de estos tres dominios específicos del tema, así como también del dominio político más amplio. Para cuantificar el efecto global de una página js en los valores globales de PageRank de las páginas en el dominio local, definimos el impacto de la página js como su valor de PageRank, g[j], normalizado por la fracción de sus enlaces salientes que apuntan al dominio local: impacto(j) = oL[j] o[j] · g[j], donde oL[j] es el número de enlaces salientes de la página j a páginas en el dominio local L, y o[j] es el número total de enlaces salientes de js. En términos del modelo del surfista aleatorio, el impacto de la página j es la probabilidad de que el surfista aleatorio (1) se encuentre actualmente en la página global j en su caminata aleatoria y (2) tome un enlace de salida a una página local, dado que ya ha decidido no saltar a una página aleatoria. Para el dominio político local, encontramos que muchas de las páginas con alto impacto eran de hecho páginas políticas que deberían haber sido incluidas en el tema de política de dmoz, pero no lo estaban. Por ejemplo, las dos páginas globales más influyentes fueron el motor de búsqueda político www.askhenry.com y la página de inicio de la revista política en línea www.policyreview.com. Entre las páginas no políticas, la página de inicio de la revista Education Next fue la más influyente. El diario está disponible de forma gratuita en línea y contiene artículos sobre varios aspectos de la educación K-12 en América. Para proporcionar algunas pruebas anecdóticas de la efectividad de nuestros métodos de selección de páginas, observamos que el método SC-Select eligió 11 páginas dentro del dominio www.educationnext.org, el método PF-Select descubrió 7 páginas, mientras que los métodos OutlinkCount y Random encontraron solo 6 páginas cada uno. Para el ámbito político local conservador, el sitio web socialista www.ornery.org tuvo una puntuación de impacto muy alta. Este documento de investigación de la pista 123 titulado \"Toda la política: Algoritmo L1 L2 Kendall Stoch\". Comp. .1253 .000700 .8671 Flujo PR .1446 .000710 .8518 Enlace saliente .1470 .00225 .8642 Aleatorio .2055 .00203 .8271 Conservadurismo: Algoritmo L1 L2 Kendall Estoc. Comp. .0496 .000990 .9158 Flujo PR .0554 .000939 .9028 Enlace saliente .0602 .00527 .9144 Aleatorio .1197 .00102 .8843 Liberalismo: Algoritmo L1 L2 Kendall Estoc. Comp. .0622 .001360 .8848 Flujo PR .0799 .001378 .8669 Enlace saliente .0763 .001379 .8844 Aleatorio .1127 .001899 .8372 Socialismo: Algoritmo L1 L∞ Kendall Estoc. Tabla 2: Rendimiento final entre estrategias de selección de nodos para las cuatro exploraciones específicas de temas políticos. Ten en cuenta que el coeficiente de correlación de Kendall mide la similitud, mientras que las otras métricas son medidas de disimilitud. Como era de esperar, el PageRank global de este artículo (que resulta estar en la página de inicio de la NCCPR, www.nationalresearch.com) era aproximadamente de .002, mientras que el PageRank local de esta página era solo de .00158. El método SC-Select produjo una estimación global de PageRank de aproximadamente .00182, el método PFSelect estimó un valor de .00167, y los métodos Random y OutlinkCount produjeron valores de .01522 y .00171, respectivamente. TRABAJO RELACIONADO El marco de selección de nodos que hemos propuesto es similar al problema de ordenación de URL para el rastreo propuesto por Cho et al. en [6]. Mientras que nuestro marco busca minimizar la diferencia entre el PageRank global y local, el objetivo utilizado en [6] es rastrear primero las páginas más altamente clasificadas (globalmente). Proponen varios algoritmos de selección de nodos, incluyendo la heurística del recuento de enlaces de salida, así como una variante de nuestro algoritmo PF-Select al que se refieren como la métrica de ordenación de PageRank. Encontraron que este método era el más efectivo para optimizar su objetivo, al igual que lo demostró una encuesta reciente de estos métodos realizada por Baeza-Yates et al. [1]. Boldi et al. también experimentan dentro de un marco de rastreo similar en [2], pero cuantifican sus resultados al comparar la correlación de rangos de Kendall entre los PageRanks del conjunto actual de páginas rastreadas y los del grafo global completo. Encontraron que las estrategias de selección de nodos que rastreaban páginas con el PageRank global más alto primero en realidad tenían un peor rendimiento (con respecto a la correlación de Kendalls Tau entre los PageRanks locales y globales) que las estrategias básicas de búsqueda en profundidad o en amplitud. Sin embargo, sus experimentos difieren de nuestro trabajo en que nuestros algoritmos de selección de nodos no utilizan (ni tienen acceso a) valores globales de PageRank. Se han propuesto muchas mejoras algorítmicas para calcular los valores exactos de PageRank [9, 10, 14]. Si se utilizan tales algoritmos para calcular los PageRanks globales de nuestro dominio local, todos requerirían una computación, almacenamiento y ancho de banda de O(N), donde N es el tamaño del dominio global. Esto contrasta con nuestro método, que aproxima el PageRank global y escala linealmente con el tamaño del dominio local. Wang y Dewitt [22] proponen un sistema en el que el conjunto de servidores web que conforman el dominio global se comunican entre sí para calcular sus respectivos PageRanks globales. Para un servidor web dado que aloja n páginas, los requisitos computacionales, de ancho de banda y almacenamiento también son lineales en n. Una desventaja de este sistema es que el número de servidores web distintos que conforman el dominio global puede ser muy grande. Por ejemplo, nuestro conjunto de datos edu contiene sitios web de más de 3,200 universidades diferentes; coordinar un sistema así entre un gran número de sitios puede ser muy difícil. Gan, Chen y Suel proponen un método para estimar el PageRank de una sola página [5] que utiliza solo ancho de banda, computación y espacio constantes. Su enfoque se basa en la disponibilidad de un servidor de conectividad remota que puede suministrar el conjunto de enlaces entrantes a una página dada, una suposición que no se utiliza en nuestro marco de trabajo. Experimentalmente demuestran que se puede obtener una estimación razonable del PageRank de los nodos visitando como máximo unos pocos cientos de nodos. El uso de su algoritmo para nuestro problema requeriría que primero se descargue todo el dominio global o se utilice un servidor de conectividad, lo que resultaría en grafos web muy grandes. 8. CONCLUSIONES Y TRABAJOS FUTUROS Internet está creciendo de forma exponencial, y para poder navegar por un repositorio tan grande como la web, los motores de búsqueda globales se han establecido como una necesidad. Junto con la omnipresencia de estos motores de búsqueda a gran escala, surge un aumento en las expectativas de los usuarios de búsqueda. Al proporcionar una cobertura completa y aislada de un dominio web específico, los motores de búsqueda localizados son un medio efectivo para localizar rápidamente contenido que de otra manera podría ser difícil de encontrar. En este trabajo, sostenemos que el uso de PageRank global en un motor de búsqueda localizado puede mejorar el rendimiento. Para estimar el PageRank global, hemos propuesto un marco de selección de nodos iterativo en el que seleccionamos qué páginas de la frontera global rastrear a continuación. Nuestra principal contribución es nuestro algoritmo de selección de páginas de complementación estocástica. Este método recorre los nodos que tendrán un impacto significativo en el dominio local y tiene un tiempo de ejecución lineal en el número de nodos en el dominio local. Experimentalmente, validamos estos métodos en un conjunto diverso de dominios locales, que incluyen siete dominios específicos del sitio y cuatro dominios específicos del tema. Concluimos que al rastrear n o 2n páginas adicionales, nuestros métodos encuentran una estimación de los PageRanks globales que es hasta diez veces mejor que simplemente usar los PageRanks locales. Además, demostramos que nuestro algoritmo supera consistentemente a otras heurísticas existentes. En muchas ocasiones, los dominios específicos de un tema se descubren utilizando un rastreador web enfocado que considera el contenido de las páginas junto con el texto del ancla del enlace para decidir qué páginas rastrear a continuación [4]. Aunque estos rastreadores han demostrado ser bastante efectivos en descubrir contenido relacionado con el tema, también se rastrean muchas páginas irrelevantes en el proceso. Por lo general, estas páginas son eliminadas y no son indexadas por el motor de búsqueda localizado. Estas páginas pueden, por supuesto, proporcionar información valiosa sobre el PageRank global del dominio local. Una forma de integrar estas páginas en nuestro marco de trabajo es comenzar el algoritmo FindGlobalPR con el subgrafo actual F igual al conjunto de páginas que fueron rastreadas por el rastreador enfocado. El marco de estimación global de PageRank, junto con los algoritmos de selección de nodos presentados, requieren todos una computación de O(n) por iteración y un ancho de banda proporcional al número de páginas rastreadas, Tk. Si el número de iteraciones T es relativamente pequeño en comparación con el número de páginas rastreadas por iteración, k, entonces el cuello de botella del algoritmo será la fase de rastreo. Sin embargo, a medida que el número de iteraciones aumenta (en relación con k), el cuello de botella residirá en el cálculo de la selección de nodos. En este caso, nuestros algoritmos se beneficiarían de optimizaciones en el factor constante. Recuerde que el algoritmo FindGlobalPR (Algoritmo 2) requiere que los PageRanks del dominio local expandido actual se vuelvan a calcular en cada iteración. El trabajo reciente de Langville y Meyer [12] proporciona un algoritmo para recalcular rápidamente los PageRanks de un grafo web dado si se agregan un pequeño número de nodos. Este algoritmo demostró proporcionar una aceleración de cinco a diez veces en algunos conjuntos de datos. Planeamos investigar esto y otras optimizaciones similares como trabajo futuro. En este artículo, hemos evaluado objetivamente nuestros métodos midiendo qué tan cercanas son nuestras estimaciones globales de PageRank a los verdaderos PageRanks globales. Para determinar el beneficio de utilizar PageRanks globales en un motor de búsqueda localizado, sugerimos un estudio de usuarios en el que se les pida a los usuarios que califiquen la calidad de los resultados de búsqueda para varias consultas de búsqueda. Para algunas consultas, solo se utilizan los PageRanks locales en la clasificación, y para las consultas restantes, se utilizan los PageRanks locales y los PageRanks globales aproximados, según lo calculado por nuestros algoritmos. Los resultados de dicho estudio pueden ser analizados para determinar el beneficio adicional de utilizar los PageRanks globales calculados por nuestros métodos, en lugar de solo utilizar los PageRanks locales. Agradecimientos. Esta investigación fue apoyada por la subvención de la NSF CCF-0431257, el Premio de Carrera de la NSF ACI-0093404 y una subvención de Sabre, Inc. 9. REFERENCIAS [1] R. Baeza-Yates, M. Marín, C. Castillo y A. Rodríguez. Rastreando un país: estrategias mejores que el recorrido en anchura para ordenar páginas web. Conferencia de la World-Wide Web, 2005. [2] P. Boldi, M. Santini y S. Vigna. Haz lo peor para lograr lo mejor: efectos paradójicos en los cálculos incrementales de PageRank. Taller sobre Grafos Web, 3243:168-180, 2004. [3] S. Brin y L. Page. La anatomía de un motor de búsqueda web hipertextual a gran escala. Redes de Computadoras y Sistemas ISDN, 33(1-7):107-117, 1998. [4] S. Chakrabarti, M. van den Berg y B. Dom. Rastreo enfocado: un nuevo enfoque para el descubrimiento de recursos web específicos de un tema. Conferencia de la World-Wide Web, 1999. [5] Y. Chen, Q. Gan y T. Suel. Métodos locales para estimar los valores de pagerank. Conferencia sobre Gestión de Información y Conocimiento, 2004. [6] J. Cho, H. Garcia-Molina y L. Page. Rastreo eficiente a través de la ordenación de URL. Conferencia de la World-Wide Web, 1998. [7] T. H. Haveliwala y S. D. Kamvar. El segundo valor propio de la matriz de Google. Informe técnico, Universidad de Stanford, 2003. [8] T. Joachims, F. Radlinski, L. Granka, A. Cheng, C. Tillekeratne y A. Patel. Aprendizaje de funciones de recuperación a partir de retroalimentación implícita. http://www.cs.cornell.edu/People/tj/career. [9] S. D. Kamvar, T. H. Haveliwala, C. D. Manning y G. H. Golub. Explotando la estructura de bloques de la web para calcular el pagerank. Conferencia de la World-Wide Web, 2003. [10] S. D. Kamvar, T. H. Haveliwala, C. D. Manning y G. H. Golub. Métodos de extrapolación para acelerar el cálculo de PageRank. Conferencia de la World-Wide Web, 2003. [11] A. N. Langville y C. D. Meyer. Más profundo dentro de PageRank. Matemáticas en Internet, 2004. [12] A. N. Langville y C. D. Meyer. Actualizando el vector estacionario de una cadena de Markov irreducible con miras al PageRank de Google. Revista SIAM sobre Análisis de Matrices, 2005. [13] P. Lyman, H. R. Varian, K. Swearingen, P. Charles, N. Good, L. L. Jordan y J. Pal. ¿Cuánta información en 2003? Escuela de Gestión de la Información y Sistemas, Universidad de California en Berkeley, 2003. [14] F. McSherry. Un enfoque uniforme para el cálculo acelerado de PageRank. Conferencia de la World-Wide Web, 2005. [15] C. D. Meyer. Complementación estocástica, desacoplamiento de cadenas de Markov y la teoría de sistemas casi reducibles. SIAM Review, 31:240-272, 1989. [16] US News and World Report. http://www.usnews.com. [17] Proyecto de directorio abierto Dmoz. http://www.dmoz.org. [18] Motor de búsqueda de código abierto Nutch. http://www.nutch.org. [19] F. Radlinski y T. Joachims. Cadenas de consulta: aprendizaje para clasificar a partir de retroalimentación implícita. Conferencia Internacional ACM SIGKDD sobre Descubrimiento de Conocimiento y Minería de Datos, 2005. [20] S. Raghavan y H. Garcia-Molina. Explorando la web oculta. En Actas de la Vigésimo séptima Conferencia Internacional sobre Bases de Datos Muy Grandes, 2001. [21] T. Tin Tang, D. Hawking, N. Craswell y K. Griffiths. Rastreo enfocado para relevancia temática y calidad de la información médica. Conferencia sobre Gestión de Información y Conocimiento, 2005. [22] Y. Wang y D. J. DeWitt. Calculando el pagerank en un sistema distribuido de búsqueda en internet. Actas de la 30ª Conferencia VLDB, 2004. 125 Artículos de Investigación. ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "local domain": {
            "translated_key": "dominio local",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Estimating the Global PageRank of Web Communities Jason V. Davis Dept.",
                "of Computer Sciences University of Texas at Austin Austin, TX 78712 jdavis@cs.utexas.edu Inderjit S. Dhillon Dept. of Computer Sciences University of Texas at Austin Austin, TX 78712 inderjit@cs.utexas.edu ABSTRACT Localized search engines are small-scale systems that index a particular community on the web.",
                "They offer several benefits over their large-scale counterparts in that they are relatively inexpensive to build, and can provide more precise and complete search capability over their relevant domains.",
                "One disadvantage such systems have over large-scale search engines is the lack of global PageRank values.",
                "Such information is needed to assess the value of pages in the localized search domain within the context of the web as a whole.",
                "In this paper, we present well-motivated algorithms to estimate the global PageRank values of a <br>local domain</br>.",
                "The algorithms are all highly scalable in that, given a <br>local domain</br> of size n, they use O(n) resources that include computation time, bandwidth, and storage.",
                "We test our methods across a variety of localized domains, including site-specific domains and topic-specific domains.",
                "We demonstrate that by crawling as few as n or 2n additional pages, our methods can give excellent global PageRank estimates.",
                "Categories and Subject Descriptors H.3.3 [Information Storage and Retrieval]: Information Search and Retrieval; G.1.3 [Numerical Analysis]: Numerical Linear Algebra; G.3 [Probability and Statistics]: Markov Processes General Terms PageRank, Markov Chain, Stochastic Complementation 1.",
                "INTRODUCTION Localized search engines are small-scale search engines that index only a single community of the web.",
                "Such communities can be site-specific domains, such as pages within the cs.utexas.edu domain, or topic-related communitiesfor example, political websites.",
                "Compared to the web graph crawled and indexed by large-scale search engines, the size of such local communities is typically orders of magnitude smaller.",
                "Consequently, the computational resources needed to build such a search engine are also similarly lighter.",
                "By restricting themselves to smaller, more manageable sections of the web, localized search engines can also provide more precise and complete search capabilities over their respective domains.",
                "One drawback of localized indexes is the lack of global information needed to compute link-based rankings.",
                "The PageRank algorithm [3], has proven to be an effective such measure.",
                "In general, the PageRank of a given page is dependent on pages throughout the entire web graph.",
                "In the context of a localized search engine, if the PageRanks are computed using only the local subgraph, then we would expect the resulting PageRanks to reflect the perceived popularity within the local community and not of the web as a whole.",
                "For example, consider a localized search engine that indexes political pages with conservative views.",
                "A person wishing to research the opinions on global warming within the conservative political community may encounter numerous such opinions across various websites.",
                "If only local PageRank values are available, then the search results will reflect only strongly held beliefs within the community.",
                "However, if global PageRanks are also available, then the results can additionally reflect outsiders views of the conservative community (those documents that liberals most often access within the conservative community).",
                "Thus, for many localized search engines, incorporating global PageRanks can improve the quality of search results.",
                "However, the number of pages a local search engine indexes is typically orders of magnitude smaller than the number of pages indexed by their large-scale counterparts.",
                "Localized search engines do not have the bandwidth, storage capacity, or computational power to crawl, download, and compute the global PageRanks of the entire web.",
                "In this work, we present a method of approximating the global PageRanks of a <br>local domain</br> while only using resources of the same order as those needed to compute the PageRanks of the local subgraph.",
                "Our proposed method looks for a supergraph of our local subgraph such that the local PageRanks within this supergraph are close to the true global PageRanks.",
                "We construct this supergraph by iteratively crawling global pages on the current web frontier-i.e., global pages with inlinks from pages that have already been crawled.",
                "In order to provide 116 Research Track Paper a good approximation to the global PageRanks, care must be taken when choosing which pages to crawl next; in this paper, we present a well-motivated page selection algorithm that also performs well empirically.",
                "This algorithm is derived from a well-defined problem objective and has a running time linear in the number of local nodes.",
                "We experiment across several types of local subgraphs, including four topic related communities and several sitespecific domains.",
                "To evaluate performance, we measure the difference between the current global PageRank estimate and the global PageRank, as a function of the number of pages crawled.",
                "We compare our algorithm against several heuristics and also against a baseline algorithm that chooses pages at random, and we show that our method outperforms these other methods.",
                "Finally, we empirically demonstrate that, given a <br>local domain</br> of size n, we can provide good approximations to the global PageRank values by crawling at most n or 2n additional pages.",
                "The paper is organized as follows.",
                "Section 2 gives an overview of localized search engines and outlines their advantages over global search.",
                "Section 3 provides background on the PageRank algorithm.",
                "Section 4 formally defines our problem, and section 5 presents our page selection criteria and derives our algorithms.",
                "Section 6 provides experimental results, section 7 gives an overview of related work, and, finally, conclusions are given in section 8. 2.",
                "LOCALIZED SEARCH ENGINES Localized search engines index a single community of the web, typically either a site-specific community, or a topicspecific community.",
                "Localized search engines enjoy three major advantages over their large-scale counterparts: they are relatively inexpensive to build, they can offer more precise search capability over their <br>local domain</br>, and they can provide a more complete index.",
                "The resources needed to build a global search engine are enormous.",
                "A 2003 study by Lyman et al. [13] found that the surface web (publicly available static sites) consists of 8.9 billion pages, and that the average size of these pages is approximately 18.7 kilobytes.",
                "To download a crawl of this size, approximately 167 terabytes of space is needed.",
                "For a researcher who wishes to build a search engine with access to a couple of workstations or a small server, storage of this magnitude is simply not available.",
                "However, building a localized search engine over a web community of a hundred thousand pages would only require a few gigabytes of storage.",
                "The computational burden required to support search queries over a database this size is more manageable as well.",
                "We note that, for topic-specific search engines, the relevant community can be efficiently identified and downloaded by using a focused crawler [21, 4].",
                "For site-specific domains, the <br>local domain</br> is readily available on their own web server.",
                "This obviates the need for crawling or spidering, and a complete and up-to-date index of the domain can thus be guaranteed.",
                "This is in contrast to their large-scale counterparts, which suffer from several shortcomings.",
                "First, crawling dynamically generated pages-pages in the hidden web-has been the subject of research [20] and is a non-trivial task for an external crawler.",
                "Second, site-specific domains can enable the robots exclusion policy.",
                "This prohibits external search engines crawlers from downloading content from the domain, and an external search engine must instead rely on outside links and anchor text to index these restricted pages.",
                "By restricting itself to only a specific domain of the internet, a localized search engine can provide more precise search results.",
                "Consider the canonical ambiguous search query, jaguar, which can refer to either the car manufacturer or the animal.",
                "A scientist trying to research the habitat and evolutionary history of a jaguar may have better success using a finely tuned zoology-specific search engine than querying Google with multiple keyword searches and wading through irrelevant results.",
                "A method to learn better ranking functions for retrieval was recently proposed by Radlinski and Joachims [19] and has been applied to various local domains, including Cornell Universitys website [8]. 3.",
                "PAGERANK OVERVIEW The PageRank algorithm defines the importance of web pages by analyzing the underlying hyperlink structure of a web graph.",
                "The algorithm works by building a Markov chain from the link structure of the web graph and computing its stationary distribution.",
                "One way to compute the stationary distribution of a Markov chain is to find the limiting distribution of a random walk over the chain.",
                "Thus, the PageRank algorithm uses what is sometimes referred to as the random surfer model.",
                "In each step of the random walk, the surfer either follows an outlink from the current page (i.e. the current node in the chain), or jumps to a random page on the web.",
                "We now precisely define the PageRank problem.",
                "Let U be an m × m adjacency matrix for a given web graph such that Uji = 1 if page i links to page j and Uji = 0 otherwise.",
                "We define the PageRank matrix PU to be: PU = αUD−1 U + (1 − α)veT , (1) where DU is the (unique) diagonal matrix such that UD−1 U is column stochastic, α is a given scalar such that 0 ≤ α ≤ 1, e is the vector of all ones, and v is a non-negative, L1normalized vector, sometimes called the random surfer vector.",
                "Note that the matrix D−1 U is well-defined only if each column of U has at least one non-zero entry-i.e., each page in the webgraph has at least one outlink.",
                "In the presence of such dangling nodes that have no outlinks, one commonly used solution, proposed by Brin et al. [3], is to replace each zero column of U by a non-negative, L1-normalized vector.",
                "The PageRank vector r is the dominant eigenvector of the PageRank matrix, r = PU r. We will assume, without loss of generality, that r has an L1-norm of one.",
                "Computationally, r can be computed using the power method.",
                "This method first chooses a random starting vector r(0) , and iteratively multiplies the current vector by the PageRank matrix PU ; see Algorithm 1.",
                "In general, each iteration of the power method can take O(m2 ) operations when PU is a dense matrix.",
                "However, in practice, the number of links in a web graph will be of the order of the number of pages.",
                "By exploiting the sparsity of the PageRank matrix, the work per iteration can be reduced to O(km), where k is the average number of links per web page.",
                "It has also been shown that the total number of iterations needed for convergence is proportional to α and does not depend on the size of the web graph [11, 7].",
                "Finally, the total space needed is also O(km), mainly to store the matrix U. 117 Research Track Paper Algorithm 1: A linear time (per iteration) algorithm for computing PageRank.",
                "ComputePR(U) Input: U: Adjacency matrix.",
                "Output: r: PageRank vector.",
                "Choose (randomly) an initial non-negative vector r(0) such that r(0) 1 = 1. i ← 0 repeat i ← i + 1 ν ← αUD−1 U r(i−1) {α is the random surfing probability} r(i) ← ν + (1 − α)v {v is the random surfer vector.} until r(i) − r(i−1) < δ {δ is the convergence threshold.} r ← r(i) 4.",
                "PROBLEM DEFINITION Given a <br>local domain</br> L, let G be an N × N adjacency matrix for the entire connected component of the web that contains L, such that Gji = 1 if page i links to page j and Gji = 0 otherwise.",
                "Without loss of generality, we will partition G as: G = L Gout Lout Gwithin , (2) where L is the n × n local subgraph corresponding to links inside the <br>local domain</br>, Lout is the subgraph that corresponds to links from the <br>local domain</br> pointing out to the global domain, Gout is the subgraph containing links from the global domain into the local domain, and Gwithin contains links within the global domain.",
                "We assume that when building a localized search engine, only pages inside the <br>local domain</br> are crawled, and the links between these pages are represented by the subgraph L. The links in Lout are also known, as these point from crawled pages in the <br>local domain</br> to uncrawled pages in the global domain.",
                "As defined in equation (1), PG is the PageRank matrix formed from the global graph G, and we define the global PageRank vector of this graph to be g. Let the n-length vector p∗ be the L1-normalized vector corresponding to the global PageRank of the pages in the <br>local domain</br> L: p∗ = EL g ELg 1 , where EL = [ I | 0 ] is the restriction matrix that selects the components from g corresponding to nodes in L. Let p denote the PageRank vector constructed from the <br>local domain</br> subgraph L. In practice, the observed local PageRank p and the global PageRank p∗ will be quite different.",
                "One would expect that as the size of local matrix L approaches the size of global matrix G, the global PageRank and the observed local PageRank will become more similar.",
                "Thus, one approach to estimating the global PageRank is to crawl the entire global domain, compute its PageRank, and extract the PageRanks of the <br>local domain</br>.",
                "Typically, however, n N , i.e., the number of global pages is much larger than the number of local pages.",
                "Therefore, crawling all global pages will quickly exhaust all local resources (computational, storage, and bandwidth) available to create the local search engine.",
                "We instead seek a supergraph ˆF of our local subgraph L with size O(n).",
                "Our goal Algorithm 2: The FindGlobalPR algorithm.",
                "FindGlobalPR(L, Lout, T, k) Input: L: zero-one adjacency matrix for the <br>local domain</br>, Lout: zero-one outlink matrix from L to global subgraph as in (2), T: number of iterations, k: number of pages to crawl per iteration.",
                "Output: ˆp: an improved estimate of the global PageRank of L. F ← L Fout ← Lout f ← ComputePR(F ) for (i = 1 to T) {Determine which pages to crawl next} pages ← SelectNodes(F , Fout, f, k) Crawl pages, augment F and modify Fout {Update PageRanks for new <br>local domain</br>} f ← ComputePR(F ) end {Extract PageRanks of original <br>local domain</br> & normalize} ˆp ← ELf ELf 1 is to find such a supergraph ˆF with PageRank ˆf, so that ˆf when restricted to L is close to p∗ .",
                "Formally, we seek to minimize GlobalDiff( ˆf) = EL ˆf EL ˆf 1 − p∗ 1 . (3) We choose the L1 norm for measuring the error as it does not place excessive weight on outliers (as the L2 norm does, for example), and also because it is the most commonly used distance measure in the literature for comparing PageRank vectors, as well as for detecting convergence of the algorithm [3].",
                "We propose a greedy framework, given in Algorithm 2, for constructing ˆF .",
                "Initially, F is set to the local subgraph L, and the PageRank f of this graph is computed.",
                "The algorithm then proceeds as follows.",
                "First, the SelectNodes algorithm (which we discuss in the next section) is called and it returns a set of k nodes to crawl next from the set of nodes in the current crawl frontier, Fout.",
                "These selected nodes are then crawled to expand the local subgraph, F , and the PageRanks of this expanded graph are then recomputed.",
                "These steps are repeated for each of T iterations.",
                "Finally, the PageRank vector ˆp, which is restricted to pages within the original <br>local domain</br>, is returned.",
                "Given our computation, bandwidth, and memory restrictions, we will assume that the algorithm will crawl at most O(n) pages.",
                "Since the PageRanks are computed in each iteration of the algorithm, which is an O(n) operation, we will also assume that the number of iterations T is a constant.",
                "Of course, the main challenge here is in selecting which set of k nodes to crawl next.",
                "In the next section, we formally define the problem and give efficient algorithms. 5.",
                "NODE SELECTION In this section, we present node selection algorithms that operate within the greedy framework presented in the previous section.",
                "We first give a well-defined criteria for the page selection problem and provide experimental evidence that this criteria can effectively identify pages that optimize our problem objective (3).",
                "We then present our main al118 Research Track Paper gorithmic contribution of the paper, a method with linear running time that is derived from this page selection criteria.",
                "Finally, we give an intuitive analysis of our algorithm in terms of leaks and flows.",
                "We show that if only the flow is considered, then the resulting method is very similar to a widely used page selection heuristic [6]. 5.1 Formulation For a given page j in the global domain, we define the expanded local graph Fj: Fj = F s uT j 0 , (4) where uj is the zero-one vector containing the outlinks from F into page j, and s contains the inlinks from page j into the <br>local domain</br>.",
                "Note that we do not allow self-links in this framework.",
                "In practice, self-links are often removed, as they only serve to inflate a given pages PageRank.",
                "Observe that the inlinks into F from node j are not known until after node j is crawled.",
                "Therefore, we estimate this inlink vector as the expectation over inlink counts among the set of already crawled pages, s = F T e F T e 1 . (5) In practice, for any given page, this estimate may not reflect the true inlinks from that page.",
                "Furthermore, this expectation is sampled from the set of links within the crawled domain, whereas a better estimate would also use links from the global domain.",
                "However, the latter distribution is not known to a localized search engine, and we contend that the above estimate will, on average, be a better estimate than the uniform distribution, for example.",
                "Let the PageRank of F be f. We express the PageRank f+ j of the expanded local graph Fj as f+ j = (1 − xj)fj xj , (6) where xj is the PageRank of the candidate global node j, and fj is the L1-normalized PageRank vector restricted to the pages in F .",
                "Since directly optimizing our problem goal requires knowing the global PageRank p∗ , we instead propose to crawl those nodes that will have the greatest influence on the PageRanks of pages in the original <br>local domain</br> L: influence(j) = k∈L |fj[k] − f[k]| (7) = EL (fj − f) 1.",
                "Experimentally, the influence score is a very good predictor of our problem objective (3).",
                "For each candidate global node j, figure 1(a) shows the objective function value Global Diff(fj) as a function of the influence of page j.",
                "The <br>local domain</br> used here is a crawl of conservative political pages (we will provide more details about this dataset in section 6); we observed similar results in other domains.",
                "The correlation is quite strong, implying that the influence criteria can effectively identify pages that improve the global PageRank estimate.",
                "As a baseline, figure 1(b) compares our objective with an alternative criteria, outlink count.",
                "The outlink count is defined as the number of outlinks from the <br>local domain</br> to page j.",
                "The correlation here is much weaker. .00001 .0001 .001 .01 0.26 0.262 0.264 0.266 Influence Objective 1 10 100 1000 0.266 0.264 0.262 0.26 Outlink Count Objective (a) (b) Figure 1: (a) The correlation between our influence page selection criteria (7) and the actual objective function (3) value is quite strong. (b) This is in contrast to other criteria, such as outlink count, which exhibit a much weaker correlation. 5.2 Computation As described, for each candidate global page j, the influence score (7) must be computed.",
                "If fj is computed exactly for each global page j, then the PageRank algorithm would need to be run for each of the O(n) such global pages j we consider, resulting in an O(n2 ) computational cost for the node selection method.",
                "Thus, computing the exact value of fj will lead to a quadratic algorithm, and we must instead turn to methods of approximating this vector.",
                "The algorithm we present works by performing one power method iteration used by the PageRank algorithm (Algorithm 1).",
                "The convergence rate for the PageRank algorithm has been shown to equal the random surfer probability α [7, 11].",
                "Given a starting vector x(0) , if k PageRank iterations are performed, the current PageRank solution x(k) satisfies: x(k) − x∗ 1 = O(αk x(0) − x∗ 1), (8) where x∗ is the desired PageRank vector.",
                "Therefore, if only one iteration is performed, choosing a good starting vector is necessary to achieve an accurate approximation.",
                "We partition the PageRank matrix PFj , corresponding to the × subgraph Fj as: PFj = ˜F ˜s ˜uT j w , (9) where ˜F = αF (DF + diag(uj))−1 + (1 − α) e + 1 eT , ˜s = αs + (1 − α) e + 1 , ˜uj = α(DF + diag(uj))−1 uj + (1 − α) e + 1 , w = 1 − α + 1 , and diag(uj) is the diagonal matrix with the (i, i)th entry equal to one if the ith element of uj equals one, and is zero otherwise.",
                "We have assumed here that the random surfer vector is the uniform vector, and that L has no dangling links.",
                "These assumptions are not necessary and serve only to simplify discussion and analysis.",
                "A simple approach for estimating fj is the following.",
                "First, estimate the PageRank f+ j of Fj by computing one PageRank iteration over the matrix PFj , using the starting vector ν = f 0 .",
                "Then, estimate fj by removing the last 119 Research Track Paper component from our estimate of f+ j (i.e., the component corresponding to the added node j), and renormalizing.",
                "The problem with this approach is in the starting vector.",
                "Recall from (6) that xj is the PageRank of the added node j.",
                "The difference between the actual PageRank f+ j of PFj and the starting vector ν is ν − f+ j 1 = xj + f − (1 − xj)fj 1 ≥ xj + | f 1 − (1 − xj) fj 1| = xj + |xj| = 2xj.",
                "Thus, by (8), after one PageRank iteration, we expect our estimate of f+ j to still have an error of about 2αxj.",
                "In particular, for candidate nodes j with relatively high PageRank xj, this method will yield more inaccurate results.",
                "We will next present a method that eliminates this bias and runs in O(n) time. 5.2.1 Stochastic Complementation Since f+ j , as given in (6) is the PageRank of the matrix PFj , we have: fj(1 − xj) xj = ˜F ˜s ˜uT j w fj(1 − xj) xj = ˜F fj(1 − xj) + ˜sxj ˜uT j fj(1 − xj) + wxj .",
                "Solving the above system for fj can be shown to yield fj = ( ˜F + (1 − w)−1 ˜s˜uT j )fj. (10) The matrix S = ˜F +(1−w)−1 ˜s˜uT j is known as the stochastic complement of the column stochastic matrix PFj with respect to the sub matrix ˜F .",
                "The theory of stochastic complementation is well studied, and it can be shown the stochastic complement of an irreducible matrix (such as the PageRank matrix) is unique.",
                "Furthermore, the stochastic complement is also irreducible and therefore has a unique stationary distribution as well.",
                "For an extensive study, see [15].",
                "It can be easily shown that the sub-dominant eigenvalue of S is at most +1 α, where is the size of F .",
                "For sufficiently large , this value will be very close to α.",
                "This is important, as other properties of the PageRank algorithm, notably the algorithms sensitivity, are dependent on this value [11].",
                "In this method, we estimate the length vector fj by computing one PageRank iteration over the × stochastic complement S, starting at the vector f: fj ≈ Sf. (11) This is in contrast to the simple method outlined in the previous section, which first iterates over the ( + 1) × ( + 1) matrix PFj to estimate f+ j , and then removes the last component from the estimate and renormalizes to approximate fj.",
                "The problem with the latter method is in the choice of the ( + 1) length starting vector, ν. Consequently, the PageRank estimate given by the simple method differs from the true PageRank by at least 2αxj, where xj is the PageRank of page j.",
                "By using the stochastic complement, we can establish a tight lower bound of zero for this difference.",
                "To see this, consider the case in which a node k is added to F to form the augmented local subgraph Fk, and that the PageRank of this new graph is (1 − xk)f xk .",
                "Specifically, the addition of page k does not change the PageRanks of the pages in F , and thus fk = f. By construction of the stochastic complement, fk = Sfk, so the approximation given in equation (11) will yield the exact solution.",
                "Next, we present the computational details needed to efficiently compute the quantity fj −f 1 over all known global pages j.",
                "We begin by expanding the difference fj −f, where the vector fj is estimated as in (11), fj − f ≈ Sf − f = αF (DF + diag(uj))−1 f + (1 − α) e + 1 eT f +(1 − w)−1 (˜uT j f)˜s − f. (12) Note that the matrix (DF +diag(uj))−1 is diagonal.",
                "Letting o[k] be the outlink count for page k in F , we can express the kth diagonal element as: (DF + diag(uj))−1 [k, k] = 1 o[k]+1 if uj[k] = 1 1 o[k] if uj[k] = 0 Noting that (o[k] + 1)−1 = o[k]−1 − (o[k](o[k] + 1))−1 and rewriting this in matrix form yields (DF +diag(uj))−1 = D−1 F −D−1 F (DF +diag(uj))−1 diag(uj). (13) We use the same identity to express e + 1 = e − e ( + 1) . (14) Recall that, by definition, we have PF = αF D−1 F +(1−α)e .",
                "Substituting (13) and (14) in (12) yields fj − f ≈ (PF f − f) −αF D−1 F (DF + diag(uj))−1 diag(uj)f −(1 − α) e ( + 1) + (1 − w)−1 (˜uT j f)˜s = x + y + (˜uT j f)z, (15) noting that by definition, f = PF f, and defining the vectors x, y, and z to be x = −αF D−1 F (DF + diag(uj))−1 diag(uj)f (16) y = −(1 − α) e ( + 1) (17) z = (1 − w)−1 ˜s. (18) The first term x is a sparse vector, and takes non-zero values only for local pages k that are siblings of the global page j.",
                "We define (i, j) ∈ F if and only if F [j, i] = 1 (equivalently, page i links to page j) and express the value of the component x[k ] as: x[k ] = −α k:(k,k )∈F ,uj [k]=1 f[k] o[k](o[k] + 1) , (19) where o[k], as before, is the number of outlinks from page k in the <br>local domain</br>.",
                "Note that the last two terms, y and z are not dependent on the current global node j.",
                "Given the function hj(f) = y + (˜uT j f)z 1, the quantity fj − f 1 120 Research Track Paper can be expressed as fj − f 1 = k x[k] + y[k] + (˜uT j f)z[k] = k:x[k]=0 y[k] + (˜uT j f)z[k] + k:x[k]=0 x[k] + y[k] + (˜uT j f)z[k] = hj(f) − k:x[k]=0 y[k] + (˜uT j f)z[k] + k:x[k]=0 x[k] + y[k] + (˜uT j f)z[k] . (20) If we can compute the function hj in linear time, then we can compute each value of fj − f 1 using an additional amount of time that is proportional to the number of nonzero components in x.",
                "These optimizations are carried out in Algorithm 3.",
                "Note that (20) computes the difference between all components of f and fj, whereas our node selection criteria, given in (7), is restricted to the components corresponding to nodes in the original <br>local domain</br> L. Let us examine Algorithm 3 in more detail.",
                "First, the algorithm computes the outlink counts for each page in the <br>local domain</br>.",
                "The algorithm then computes the quantity ˜uT j f for each known global page j.",
                "This inner product can be written as (1 − α) 1 + 1 + α k:(k,j)∈Fout f[k] o[k] + 1 , where the second term sums over the set of local pages that link to page j.",
                "Since the total number of edges in Fout was assumed to have size O( ) (recall that is the number of pages in F ), the running time of this step is also O( ).",
                "The algorithm then computes the vectors y and z, as given in (17) and (18), respectively.",
                "The L1NormDiff method is called on the components of these vectors which correspond to the pages in L, and it estimates the value of EL(y + (˜uT j f)z) 1 for each page j.",
                "The estimation works as follows.",
                "First, the values of ˜uT j f are discretized uniformly into c values {a1, ..., ac}.",
                "The quantity EL(y + aiz) 1 is then computed for each discretized value of ai and stored in a table.",
                "To evaluate EL (y + az) 1 for some a ∈ [a1, ac], the closest discretized value ai is determined, and the corresponding entry in the table is used.",
                "The total running time for this method is linear in and the discretization parameter c (which we take to be a constant).",
                "We note that if exact values are desired, we have also developed an algorithm that runs in O( log ) time that is not described here.",
                "In the main loop, we compute the vector x, as defined in equation (16).",
                "The nested loops iterate over the set of pages in F that are siblings of page j.",
                "Typically, the size of this set is bounded by a constant.",
                "Finally, for each page j, the scores vector is updated over the set of non-zero components k of the vector x with k ∈ L. This set has size equal to the number of local siblings of page j, and is a subset of the total number of siblings of page j.",
                "Thus, each iteration of the main loop takes constant time, and the total running time of the main loop is O( ).",
                "Since we have assumed that the size of F will not grow larger than O(n), the total running time for the algorithm is O(n).",
                "Algorithm 3: Node Selection via Stochastic Complementation.",
                "SC-Select(F , Fout, f, k) Input: F : zero-one adjacency matrix of size corresponding to the current local subgraph, Fout: zero-one outlink matrix from F to global subgraph, f: PageRank of F , k: number of pages to return Output: pages: set of k pages to crawl next {Compute outlink sums for local subgraph} foreach (page j ∈ F ) o[j] ← k:(j,k)∈F F[j, k] end {Compute scalar ˜uT j f for each global node j } foreach (page j ∈ Fout) g[j] ← (1 − α) 1 +1 foreach (page k : (k, j) ∈ Fout) g[j] ← g[j] + α f[k] o[k]+1 end end {Compute vectors y and z as in (17) and (18) } y ← −(1 − α) e ( +1) z ← (1 − w)−1 ˜s {Approximate y + g[j] ∗ z 1 for all values g[j]} norm diffs ←L1NormDiffs(g, ELy, ELz) foreach (page j ∈ Fout) {Compute sparse vector x as in (19)} x ← 0 foreach (page k : (k, j) ∈ Fout) foreach (page k : (k, k ) ∈ F )) x[k ] ← x[k ] − f[k] o[k](o[k]+1) end end x ← αx scores[j] ← norm diffs[j] foreach (k : x[k] > 0 and page k ∈ L) scores[j] ← scores[j] − |y[k] + g[j] ∗ z[k]| +|x[k]+y[k]+g[j]∗z[k])| end end Return k pages with highest scores 5.2.2 PageRank Flows We now present an intuitive analysis of the stochastic complementation method by decomposing the change in PageRank in terms of leaks and flows.",
                "This analysis is motivated by the decomposition given in (15).",
                "PageRank flow is the increase in the local PageRanks originating from global page j.",
                "The flows are represented by the non-negative vector (˜uT j f)z (equations (15) and (18)).",
                "The scalar ˜uT j f can be thought of as the total amount of PageRank flow that page j has available to distribute.",
                "The vector z dictates how the flow is allocated to the <br>local domain</br>; the flow that local page k receives is proportional to (within a constant factor due to the random surfer vector) the expected number of its inlinks.",
                "The PageRank leaks represent the decrease in PageRank resulting from the addition of page j.",
                "The leakage can be quantified in terms of the non-positive vectors x and y (equations (16) and (17)).",
                "For vector x, we can see from equation (19) that the amount of PageRank leaked by a local page is proportional to the weighted sum of the Page121 Research Track Paper Ranks of its siblings.",
                "Thus, pages that have siblings with higher PageRanks (and low outlink counts) will experience more leakage.",
                "The leakage caused by y is an artifact of the random surfer vector.",
                "We will next show that if only the flow term, (˜uT j f)z, is considered, then the resulting method is very similar to a heuristic proposed by Cho et al. [6] that has been widely used for the Crawling Through URL Ordering problem.",
                "This heuristic is computationally cheaper, but as we will see later, not as effective as the Stochastic Complementation method.",
                "Our node selection strategy chooses global nodes that have the largest influence (equation (7)).",
                "If this influence is approximated using only flows, the optimal node j∗ is: j∗ = argmaxj EL ˜uT j fz 1 = argmaxj ˜uT j f EL z 1 = argmaxj ˜uT j f = argmaxj α(DF + diag(uj))−1 uj + (1 − α) e + 1 , f = argmaxjfT (DF + diag(uj))−1 uj.",
                "The resulting page selection score can be expressed as a sum of the PageRanks of each local page k that links to j, where each PageRank value is normalized by o[k]+1.",
                "Interestingly, the normalization that arises in our method differs from the heuristic given in [6], which normalizes by o[k].",
                "The algorithm PF-Select, which is omitted due to lack of space, first computes the quantity fT (DF +diag(uj))−1 uj for each global page j, and then returns the pages with the k largest scores.",
                "To see that the running time for this algorithm is O(n), note that the computation involved in this method is a subset of that needed for the SC-Select method (Algorithm 3), which was shown to have a running time of O(n). 6.",
                "EXPERIMENTS In this section, we provide experimental evidence to verify the effectiveness of our algorithms.",
                "We first outline our experimental methodology and then provide results across a variety of local domains. 6.1 Methodology Given the limited resources available at an academic institution, crawling a section of the web that is of the same magnitude as that indexed by Google or Yahoo! is clearly infeasible.",
                "Thus, for a given <br>local domain</br>, we approximate the global graph by crawling a local neighborhood around the domain that is several orders of magnitude larger than the local subgraph.",
                "Even though such a graph is still orders of magnitude smaller than the true global graph, we contend that, even if there exist some highly influential pages that are very far away from our <br>local domain</br>, it is unrealistic for any local node selection algorithm to find them.",
                "Such pages also tend to be highly unrelated to pages within the <br>local domain</br>.",
                "When explaining our node selection strategies in section 5, we made the simplifying assumption that our local graph contained no dangling nodes.",
                "This assumption was only made to ease our analysis.",
                "Our implementation efficiently handles dangling links by replacing each zero column of our adjacency matrix with the uniform vector.",
                "We evaluate the algorithm using the two node selection strategies given in Section 5.2, and also against the following baseline methods: • Random: Nodes are chosen uniformly at random among the known global nodes. • OutlinkCount: Global nodes with the highest number of outlinks from the <br>local domain</br> are chosen.",
                "At each iteration of the FindGlobalPR algorithm, we evaluate performance by computing the difference between the current PageRank estimate of the <br>local domain</br>, ELf ELf 1 , and the global PageRank of the <br>local domain</br> ELg ELg 1 .",
                "All PageRank calculations were performed using the uniform random surfer vector.",
                "Across all experiments, we set the random surfer parameter α, to be .85, and used a convergence threshold of 10−6 .",
                "We evaluate the difference between the local and global PageRank vectors using three different metrics: the L1 and L∞ norms, and Kendalls tau.",
                "The L1 norm measures the sum of the absolute value of the differences between the two vectors, and the L∞ norm measures the absolute value of the largest difference.",
                "Kendalls tau metric is a popular rank correlation measure used to compare PageRanks [2, 11].",
                "This metric can be computed by counting the number of pairs of pairs that agree in ranking, and subtracting from that the number of pairs of pairs that disagree in ranking.",
                "The final value is then normalized by the total number of n 2 such pairs, resulting in a [−1, 1] range, where a negative score signifies anti-correlation among rankings, and values near one correspond to strong rank correlation. 6.2 Results Our experiments are based on two large web crawls and were downloaded using the web crawler that is part of the Nutch open source search engine project [18].",
                "All crawls were restricted to only http pages, and to limit the number of dynamically generated pages that we crawl, we ignored all pages with urls containing any of the characters ?, *, @, or =.",
                "The first crawl, which we will refer to as the edu dataset, was seeded by homepages of the top 100 graduate computer science departments in the USA, as rated by the US News and World Report [16], and also by the home pages of their respective institutions.",
                "A crawl of depth 5 was performed, restricted to pages within the .edu domain, resulting in a graph with approximately 4.7 million pages and 22.9 million links.",
                "The second crawl was seeded by the set of pages under the politics hierarchy in the dmoz open directory project[17].",
                "We crawled all pages up to four links away, which yielded a graph with 4.4 million pages and 17.3 million links.",
                "Within the edu crawl, we identified the five site-specific domains corresponding to the websites of the top five graduate computer science departments, as ranked by the US News and World Report.",
                "This yielded local domains of various sizes, from 10,626 (UIUC) to 59,895 (Berkeley).",
                "For each of these site-specific domains with size n, we performed 50 iterations of the FindGlobalPR algorithm to crawl a total of 2n additional nodes.",
                "Figure 2(a) gives the (L1) difference from the PageRank estimate at each iteration to the global PageRank, for the Berkeley <br>local domain</br>.",
                "The performance of this dataset was representative of the typical performance across the five computer science sitespecific local domains.",
                "Initially, the L1 difference between the global and local PageRanks ranged from .0469 (Stanford) to .149 (MIT).",
                "For the first several iterations, the 122 Research Track Paper 0 5 10 15 20 25 30 35 40 45 50 0.015 0.02 0.025 0.03 0.035 0.04 0.045 0.05 0.055 Number of Iterations GlobalandLocalPageRankDifference(L1) Stochastic Complement PageRank Flow Outlink Count Random 0 10 20 30 40 50 0 0.05 0.1 0.15 0.2 0.25 0.3 0.35 Number of Iterations GlobalandLocalPageRankDifference(L1) Stochastic Complement PageRank Flow Outlink Count Random 0 5 10 15 20 25 0.16 0.18 0.2 0.22 0.24 0.26 0.28 0.3 0.32 0.34 Number of Iterations GlobalandLocalPageRankDifference(L1) Stochastic Complement PageRank Flow Outlink Count Random (a) www.cs.berkeley.edu (b) www.enterstageright.com (c) Politics Figure 2: L1 difference between the estimated and true global PageRanks for (a) Berkeleys computer science website, (b) the site-specific domain, www.enterstageright.com, and (c) the politics topic-specific domain.",
                "The stochastic complement method outperforms all other methods across various domains. three link-based methods all outperform the random selection heuristic.",
                "After these initial iterations, the random heuristic tended to be more competitive with (or even outperform, as in the Berkeley <br>local domain</br>) the outlink count and PageRank flow heuristics.",
                "In all tests, the stochastic complementation method either outperformed, or was competitive with, the other methods.",
                "Table 1 gives the average difference between the final estimated global PageRanks and the true global PageRanks for various distance measures.",
                "Algorithm L1 L∞ Kendall Stoch.",
                "Comp. .0384 .00154 .9257 PR Flow .0470 .00272 .8946 Outlink .0419 .00196 .9053 Random .0407 .00204 .9086 Table 1: Average final performance of various node selection strategies for the five site-specific computer science local domains.",
                "Note that Kendalls Tau measures similarity, while the other metrics are dissimilarity measures.",
                "Stochastic Complementation clearly outperforms the other methods in all metrics.",
                "Within the politics dataset, we also performed two sitespecific tests for the largest websites in the crawl: www.adamsmith.org, the website for the London based Adam Smith Institute, and www.enterstageright.com, an online conservative journal.",
                "As with the edu local domains, we ran our algorithm for 50 iterations, crawling a total of 2n nodes.",
                "Figure 2 (b) plots the results for the www.enterstageright.com domain.",
                "In contrast to the edu local domains, the Random and OutlinkCount methods were not competitive with either the SC-Select or the PF-Select methods.",
                "Among all datasets and all node selection methods, the stochastic complementation method was most impressive in this dataset, realizing a final estimate that differed only .0279 from the global PageRank, a ten-fold improvement over the initial local PageRank difference of .299.",
                "For the Adam Smith <br>local domain</br>, the initial difference between the local and global PageRanks was .148, and the final estimates given by the SC-Select, PF-Select, OutlinkCount, and Random methods were .0208, .0193, .0222, and .0356, respectively.",
                "Within the politics dataset, we constructed four topicspecific local domains.",
                "The first domain consisted of all pages in the dmoz politics category, and also all pages within each of these sites up to two links away.",
                "This yielded a <br>local domain</br> of 90,811 pages, and the results are given in figure 2 (c).",
                "Because of the larger size of the topic-specific domains, we ran our algorithm for only 25 iterations to crawl a total of n nodes.",
                "We also created topic-specific domains from three political sub-topics: liberalism, conservatism, and socialism.",
                "The pages in these domains were identified by their corresponding dmoz categories.",
                "For each sub-topic, we set the <br>local domain</br> to be all pages within three links from the corresponding dmoz category pages.",
                "Table 2 summarizes the performance of these three topic-specific domains, and also the larger political domain.",
                "To quantify a global page js effect on the global PageRank values of pages in the <br>local domain</br>, we define page js impact to be its PageRank value, g[j], normalized by the fraction of its outlinks pointing to the <br>local domain</br>: impact(j) = oL[j] o[j] · g[j], where, oL[j] is the number of outlinks from page j to pages in the local domain L, and o[j] is the total number of js outlinks.",
                "In terms of the random surfer model, the impact of page j is the probability that the random surfer (1) is currently at global page j in her random walk and (2) takes an outlink to a local page, given that she has already decided not to jump to a random page.",
                "For the politics <br>local domain</br>, we found that many of the pages with high impact were in fact political pages that should have been included in the dmoz politics topic, but were not.",
                "For example, the two most influential global pages were the political search engine www.askhenry.com, and the home page of the online political magazine, www.policyreview.com.",
                "Among non-political pages, the home page of the journal Education Next was most influential.",
                "The journal is freely available online and contains articles regarding various aspect of K-12 education in America.",
                "To provide some anecdotal evidence for the effectiveness of our page selection methods, we note that the SC-Select method chose 11 pages within the www.educationnext.org domain, the PF-Select method discovered 7 such pages, while the OutlinkCount and Random methods found only 6 pages each.",
                "For the conservative political <br>local domain</br>, the socialist website www.ornery.org had a very high impact score.",
                "This 123 Research Track Paper All Politics: Algorithm L1 L2 Kendall Stoch.",
                "Comp. .1253 .000700 .8671 PR Flow .1446 .000710 .8518 Outlink .1470 .00225 .8642 Random .2055 .00203 .8271 Conservativism: Algorithm L1 L2 Kendall Stoch.",
                "Comp. .0496 .000990 .9158 PR Flow .0554 .000939 .9028 Outlink .0602 .00527 .9144 Random .1197 .00102 .8843 Liberalism: Algorithm L1 L2 Kendall Stoch.",
                "Comp. .0622 .001360 .8848 PR Flow .0799 .001378 .8669 Outlink .0763 .001379 .8844 Random .1127 .001899 .8372 Socialism: Algorithm L1 L∞ Kendall Stoch.",
                "Comp. .04318 .00439 .9604 PR Flow .0450 .004251 .9559 Outlink .04282 .00344 .9591 Random .0631 .005123 .9350 Table 2: Final performance among node selection strategies for the four political topic-specific crawls.",
                "Note that Kendalls Tau measures similarity, while the other metrics are dissimilarity measures. was largely due to a link from the front page of this site to an article regarding global warming published by the National Center for Public Policy Research, a conservative research group in Washington, DC.",
                "Not surprisingly, the global PageRank of this article (which happens to be on the home page of the NCCPR, www.nationalresearch.com), was approximately .002, whereas the local PageRank of this page was only .00158.",
                "The SC-Select method yielded a global PageRank estimate of approximately .00182, the PFSelect method estimated a value of .00167, and the Random and OutlinkCount methods yielded values of .01522 and .00171, respectively. 7.",
                "RELATED WORK The node selection framework we have proposed is similar to the url ordering for crawling problem proposed by Cho et al. in [6].",
                "Whereas our framework seeks to minimize the difference between the global and local PageRank, the objective used in [6] is to crawl the most highly (globally) ranked pages first.",
                "They propose several node selection algorithms, including the outlink count heuristic, as well as a variant of our PF-Select algorithm which they refer to as the PageRank ordering metric.",
                "They found this method to be most effective in optimizing their objective, as did a recent survey of these methods by Baeza-Yates et al. [1].",
                "Boldi et al. also experiment within a similar crawling framework in [2], but quantify their results by comparing Kendalls rank correlation between the PageRanks of the current set of crawled pages and those of the entire global graph.",
                "They found that node selection strategies that crawled pages with the highest global PageRank first actually performed worse (with respect to Kendalls Tau correlation between the local and global PageRanks) than basic depth first or breadth first strategies.",
                "However, their experiments differ from our work in that our node selection algorithms do not use (or have access to) global PageRank values.",
                "Many algorithmic improvements for computing exact PageRank values have been proposed [9, 10, 14].",
                "If such algorithms are used to compute the global PageRanks of our <br>local domain</br>, they would all require O(N) computation, storage, and bandwidth, where N is the size of the global domain.",
                "This is in contrast to our method, which approximates the global PageRank and scales linearly with the size of the <br>local domain</br>.",
                "Wang and Dewitt [22] propose a system where the set of web servers that comprise the global domain communicate with each other to compute their respective global PageRanks.",
                "For a given web server hosting n pages, the computational, bandwidth, and storage requirements are also linear in n. One drawback of this system is that the number of distinct web servers that comprise the global domain can be very large.",
                "For example, our edu dataset contains websites from over 3,200 different universities; coordinating such a system among a large number of sites can be very difficult.",
                "Gan, Chen, and Suel propose a method for estimating the PageRank of a single page [5] which uses only constant bandwidth, computation, and space.",
                "Their approach relies on the availability of a remote connectivity server that can supply the set of inlinks to a given page, an assumption not used in our framework.",
                "They experimentally show that a reasonable estimate of the nodes PageRank can be obtained by visiting at most a few hundred nodes.",
                "Using their algorithm for our problem would require that either the entire global domain first be downloaded or a connectivity server be used, both of which would lead to very large web graphs. 8.",
                "CONCLUSIONS AND FUTURE WORK The internet is growing exponentially, and in order to navigate such a large repository as the web, global search engines have established themselves as a necessity.",
                "Along with the ubiquity of these large-scale search engines comes an increase in search users expectations.",
                "By providing complete and isolated coverage of a particular web domain, localized search engines are an effective outlet to quickly locate content that could otherwise be difficult to find.",
                "In this work, we contend that the use of global PageRank in a localized search engine can improve performance.",
                "To estimate the global PageRank, we have proposed an iterative node selection framework where we select which pages from the global frontier to crawl next.",
                "Our primary contribution is our stochastic complementation page selection algorithm.",
                "This method crawls nodes that will most significantly impact the <br>local domain</br> and has running time linear in the number of nodes in the <br>local domain</br>.",
                "Experimentally, we validate these methods across a diverse set of local domains, including seven site-specific domains and four topic-specific domains.",
                "We conclude that by crawling an additional n or 2n pages, our methods find an estimate of the global PageRanks that is up to ten times better than just using the local PageRanks.",
                "Furthermore, we demonstrate that our algorithm consistently outperforms other existing heuristics. 124 Research Track Paper Often times, topic-specific domains are discovered using a focused web crawler which considers a pages content in conjunction with link anchor text to decide which pages to crawl next [4].",
                "Although such crawlers have proven to be quite effective in discovering topic-related content, many irrelevant pages are also crawled in the process.",
                "Typically, these pages are deleted and not indexed by the localized search engine.",
                "These pages can of course provide valuable information regarding the global PageRank of the <br>local domain</br>.",
                "One way to integrate these pages into our framework is to start the FindGlobalPR algorithm with the current subgraph F equal to the set of pages that were crawled by the focused crawler.",
                "The global PageRank estimation framework, along with the node selection algorithms presented, all require O(n) computation per iteration and bandwidth proportional to the number of pages crawled, Tk.",
                "If the number of iterations T is relatively small compared to the number of pages crawled per iteration, k, then the bottleneck of the algorithm will be the crawling phase.",
                "However, as the number of iterations increases (relative to k), the bottleneck will reside in the node selection computation.",
                "In this case, our algorithms would benefit from constant factor optimizations.",
                "Recall that the FindGlobalPR algorithm (Algorithm 2) requires that the PageRanks of the current expanded <br>local domain</br> be recomputed in each iteration.",
                "Recent work by Langville and Meyer [12] gives an algorithm to quickly recompute PageRanks of a given webgraph if a small number of nodes are added.",
                "This algorithm was shown to give speedup of five to ten times on some datasets.",
                "We plan to investigate this and other such optimizations as future work.",
                "In this paper, we have objectively evaluated our methods by measuring how close our global PageRank estimates are to the actual global PageRanks.",
                "To determine the benefit of using global PageRanks in a localized search engine, we suggest a user study in which users are asked to rate the quality of search results for various search queries.",
                "For some queries, only the local PageRanks are used in ranking, and for the remaining queries, local PageRanks and the approximate global PageRanks, as computed by our algorithms, are used.",
                "The results of such a study can then be analyzed to determine the added benefit of using the global PageRanks computed by our methods, over just using the local PageRanks.",
                "Acknowledgements.",
                "This research was supported by NSF grant CCF-0431257, NSF Career Award ACI-0093404, and a grant from Sabre, Inc. 9.",
                "REFERENCES [1] R. Baeza-Yates, M. Marin, C. Castillo, and A. Rodriguez.",
                "Crawling a country: better strategies than breadth-first for web page ordering.",
                "World-Wide Web Conference, 2005. [2] P. Boldi, M. Santini, and S. Vigna.",
                "Do your worst to make the best: paradoxical effects in pagerank incremental computations.",
                "Workshop on Web Graphs, 3243:168-180, 2004. [3] S. Brin and L. Page.",
                "The anatomy of a large-scale hypertextual web search engine.",
                "Computer Networks and ISDN Systems, 33(1-7):107-117, 1998. [4] S. Chakrabarti, M. van den Berg, and B. Dom.",
                "Focused crawling: a new approach to topic-specific web resource discovery.",
                "World-Wide Web Conference, 1999. [5] Y. Chen, Q. Gan, and T. Suel.",
                "Local methods for estimating pagerank values.",
                "Conference on Information and Knowledge Management, 2004. [6] J. Cho, H. Garcia-Molina, and L. Page.",
                "Efficient crawling through url ordering.",
                "World-Wide Web Conference, 1998. [7] T. H. Haveliwala and S. D. Kamvar.",
                "The second eigenvalue of the Google matrix.",
                "Technical report, Stanford University, 2003. [8] T. Joachims, F. Radlinski, L. Granka, A. Cheng, C. Tillekeratne, and A. Patel.",
                "Learning retrieval functions from implicit feedback. http://www.cs.cornell.edu/People/tj/career. [9] S. D. Kamvar, T. H. Haveliwala, C. D. Manning, and G. H. Golub.",
                "Exploiting the block structure of the web for computing pagerank.",
                "World-Wide Web Conference, 2003. [10] S. D. Kamvar, T. H. Haveliwala, C. D. Manning, and G. H. Golub.",
                "Extrapolation methods for accelerating pagerank computation.",
                "World-Wide Web Conference, 2003. [11] A. N. Langville and C. D. Meyer.",
                "Deeper inside pagerank.",
                "Internet Mathematics, 2004. [12] A. N. Langville and C. D. Meyer.",
                "Updating the stationary vector of an irreducible markov chain with an eye on Googles pagerank.",
                "SIAM Journal on Matrix Analysis, 2005. [13] P. Lyman, H. R. Varian, K. Swearingen, P. Charles, N. Good, L. L. Jordan, and J. Pal.",
                "How much information 2003?",
                "School of Information Management and System, University of California at Berkely, 2003. [14] F. McSherry.",
                "A uniform approach to accelerated pagerank computation.",
                "World-Wide Web Conference, 2005. [15] C. D. Meyer.",
                "Stochastic complementation, uncoupling markov chains, and the theory of nearly reducible systems.",
                "SIAM Review, 31:240-272, 1989. [16] US News and World Report. http://www.usnews.com. [17] Dmoz open directory project. http://www.dmoz.org. [18] Nutch open source search engine. http://www.nutch.org. [19] F. Radlinski and T. Joachims.",
                "Query chains: learning to rank from implicit feedback.",
                "ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, 2005. [20] S. Raghavan and H. Garcia-Molina.",
                "Crawling the hidden web.",
                "In Proceedings of the Twenty-seventh International Conference on Very Large Databases, 2001. [21] T. Tin Tang, D. Hawking, N. Craswell, and K. Griffiths.",
                "Focused crawling for both topical relevance and quality of medical information.",
                "Conference on Information and Knowledge Management, 2005. [22] Y. Wang and D. J. DeWitt.",
                "Computing pagerank in a distributed internet search system.",
                "Proceedings of the 30th VLDB Conference, 2004. 125 Research Track Paper"
            ],
            "original_annotated_samples": [
                "In this paper, we present well-motivated algorithms to estimate the global PageRank values of a <br>local domain</br>.",
                "The algorithms are all highly scalable in that, given a <br>local domain</br> of size n, they use O(n) resources that include computation time, bandwidth, and storage.",
                "In this work, we present a method of approximating the global PageRanks of a <br>local domain</br> while only using resources of the same order as those needed to compute the PageRanks of the local subgraph.",
                "Finally, we empirically demonstrate that, given a <br>local domain</br> of size n, we can provide good approximations to the global PageRank values by crawling at most n or 2n additional pages.",
                "Localized search engines enjoy three major advantages over their large-scale counterparts: they are relatively inexpensive to build, they can offer more precise search capability over their <br>local domain</br>, and they can provide a more complete index."
            ],
            "translated_annotated_samples": [
                "En este artículo, presentamos algoritmos bien fundamentados para estimar los valores globales de PageRank de un <br>dominio local</br>.",
                "Los algoritmos son altamente escalables en el sentido de que, dado un <br>dominio local</br> de tamaño n, utilizan recursos de O(n) que incluyen tiempo de computación, ancho de banda y almacenamiento.",
                "En este trabajo, presentamos un método para aproximar los PageRanks globales de un <br>dominio local</br> utilizando recursos del mismo orden que los necesarios para calcular los PageRanks del subgrafo local.",
                "Finalmente, demostramos empíricamente que, dado un <br>dominio local</br> de tamaño n, podemos proporcionar buenas aproximaciones a los valores globales de PageRank rastreando como máximo n o 2n páginas adicionales.",
                "Los motores de búsqueda localizados disfrutan de tres ventajas principales sobre sus contrapartes a gran escala: son relativamente económicos de construir, pueden ofrecer una capacidad de búsqueda más precisa dentro de su <br>dominio local</br> y pueden proporcionar un índice más completo."
            ],
            "translated_text": "Estimando el PageRank Global de Comunidades Web Jason V. Davis Dept. Departamento de Ciencias de la Computación Universidad de Texas en Austin Austin, TX 78712 jdavis@cs.utexas.edu Inderjit S. Dhillon Departamento de Ciencias de la Computación Universidad de Texas en Austin Austin, TX 78712 inderjit@cs.utexas.edu RESUMEN Los motores de búsqueda localizados son sistemas a pequeña escala que indexan una comunidad particular en la web. Ofrecen varios beneficios en comparación con sus contrapartes a gran escala, ya que son relativamente económicos de construir y pueden proporcionar una capacidad de búsqueda más precisa y completa en sus dominios relevantes. Una desventaja que tienen estos sistemas en comparación con los motores de búsqueda a gran escala es la falta de valores globales de PageRank. Se necesita esa información para evaluar el valor de las páginas en el dominio de búsqueda localizada dentro del contexto de la web en su totalidad. En este artículo, presentamos algoritmos bien fundamentados para estimar los valores globales de PageRank de un <br>dominio local</br>. Los algoritmos son altamente escalables en el sentido de que, dado un <br>dominio local</br> de tamaño n, utilizan recursos de O(n) que incluyen tiempo de computación, ancho de banda y almacenamiento. Probamos nuestros métodos en una variedad de dominios localizados, incluyendo dominios específicos del sitio y dominios específicos del tema. Demostramos que al rastrear tan solo n o 2n páginas adicionales, nuestros métodos pueden proporcionar excelentes estimaciones globales de PageRank. Categorías y Descriptores de Asignaturas H.3.3 [Almacenamiento y Recuperación de Información]: Búsqueda y Recuperación de Información; G.1.3 [Análisis Numérico]: Álgebra Lineal Numérica; G.3 [Probabilidad y Estadística]: Procesos de Markov Términos Generales PageRank, Cadena de Markov, Complementación Estocástica. Los motores de búsqueda localizados son motores de búsqueda a pequeña escala que indexan solo una comunidad específica de la web. Tales comunidades pueden ser dominios específicos del sitio, como páginas dentro del dominio cs.utexas.edu, o comunidades relacionadas con un tema, por ejemplo, sitios web políticos. En comparación con el grafo web rastreado e indexado por los motores de búsqueda a gran escala, el tamaño de estas comunidades locales suele ser típicamente órdenes de magnitud más pequeño. Por consiguiente, los recursos computacionales necesarios para construir un motor de búsqueda de este tipo también son igualmente más ligeros. Al restringirse a secciones más pequeñas y manejables de la web, los motores de búsqueda localizados también pueden ofrecer capacidades de búsqueda más precisas y completas dentro de sus respectivos dominios. Una desventaja de los índices localizados es la falta de información global necesaria para calcular clasificaciones basadas en enlaces. El algoritmo PageRank [3] ha demostrado ser una medida efectiva de este tipo. En general, el PageRank de una página dada depende de las páginas en todo el grafo web. En el contexto de un motor de búsqueda localizado, si los PageRanks se calculan utilizando solo el subgrafo local, entonces esperaríamos que los PageRanks resultantes reflejen la popularidad percibida dentro de la comunidad local y no de la web en su totalidad. Por ejemplo, consideremos un motor de búsqueda localizado que indexa páginas políticas con puntos de vista conservadores. Una persona que desee investigar las opiniones sobre el calentamiento global dentro de la comunidad política conservadora puede encontrarse con numerosas opiniones de este tipo en varios sitios web. Si solo se dispone de valores de PageRank locales, entonces los resultados de búsqueda reflejarán solo creencias fuertemente arraigadas dentro de la comunidad. Sin embargo, si los PageRanks globales también están disponibles, entonces los resultados pueden reflejar adicionalmente las opiniones de los externos sobre la comunidad conservadora (es decir, aquellos documentos a los que los liberales acceden con mayor frecuencia dentro de la comunidad conservadora). Por lo tanto, para muchos motores de búsqueda localizados, la incorporación de PageRanks globales puede mejorar la calidad de los resultados de búsqueda. Sin embargo, el número de páginas que indexa un motor de búsqueda local suele ser órdenes de magnitud más pequeño que el número de páginas indexadas por sus contrapartes a gran escala. Los motores de búsqueda localizados no tienen el ancho de banda, la capacidad de almacenamiento o la potencia computacional para rastrear, descargar y calcular los PageRanks globales de toda la web. En este trabajo, presentamos un método para aproximar los PageRanks globales de un <br>dominio local</br> utilizando recursos del mismo orden que los necesarios para calcular los PageRanks del subgrafo local. Nuestro método propuesto busca un supergrafo de nuestro subgrafo local de manera que los PageRanks locales dentro de este supergrafo estén cerca de los verdaderos PageRanks globales. Construimos este supergrafo mediante el rastreo iterativo de páginas globales en la frontera web actual, es decir, páginas globales con enlaces entrantes de páginas que ya han sido rastreadas. Para proporcionar a 116 Research Track Paper una buena aproximación a los PageRanks globales, es necesario tener cuidado al elegir qué páginas rastrear a continuación; en este documento, presentamos un algoritmo de selección de páginas bien fundamentado que también tiene un buen rendimiento empírico. Este algoritmo se deriva de un objetivo de problema bien definido y tiene un tiempo de ejecución lineal en el número de nodos locales. Experimentamos en varios tipos de subgrafos locales, incluidas cuatro comunidades relacionadas con el tema y varios dominios específicos del sitio. Para evaluar el rendimiento, medimos la diferencia entre la estimación actual del PageRank global y el PageRank global, en función del número de páginas rastreadas. Comparamos nuestro algoritmo con varios heurísticos y también con un algoritmo base que elige páginas al azar, y demostramos que nuestro método supera a estos otros métodos. Finalmente, demostramos empíricamente que, dado un <br>dominio local</br> de tamaño n, podemos proporcionar buenas aproximaciones a los valores globales de PageRank rastreando como máximo n o 2n páginas adicionales. El documento está organizado de la siguiente manera. La sección 2 ofrece una visión general de los motores de búsqueda localizados y destaca sus ventajas sobre los motores de búsqueda globales. La sección 3 proporciona antecedentes sobre el algoritmo PageRank. La sección 4 define formalmente nuestro problema, y la sección 5 presenta nuestros criterios de selección de páginas y deriva nuestros algoritmos. La sección 6 presenta los resultados experimentales, la sección 7 ofrece una visión general del trabajo relacionado y, finalmente, las conclusiones se presentan en la sección 8. MOTORES DE BÚSQUEDA LOCALIZADOS Los motores de búsqueda localizados indexan una sola comunidad de la web, típicamente una comunidad específica del sitio o una comunidad específica del tema. Los motores de búsqueda localizados disfrutan de tres ventajas principales sobre sus contrapartes a gran escala: son relativamente económicos de construir, pueden ofrecer una capacidad de búsqueda más precisa dentro de su <br>dominio local</br> y pueden proporcionar un índice más completo. ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "algorithm": {
            "translated_key": "algoritmo",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Estimating the Global PageRank of Web Communities Jason V. Davis Dept.",
                "of Computer Sciences University of Texas at Austin Austin, TX 78712 jdavis@cs.utexas.edu Inderjit S. Dhillon Dept. of Computer Sciences University of Texas at Austin Austin, TX 78712 inderjit@cs.utexas.edu ABSTRACT Localized search engines are small-scale systems that index a particular community on the web.",
                "They offer several benefits over their large-scale counterparts in that they are relatively inexpensive to build, and can provide more precise and complete search capability over their relevant domains.",
                "One disadvantage such systems have over large-scale search engines is the lack of global PageRank values.",
                "Such information is needed to assess the value of pages in the localized search domain within the context of the web as a whole.",
                "In this paper, we present well-motivated algorithms to estimate the global PageRank values of a local domain.",
                "The algorithms are all highly scalable in that, given a local domain of size n, they use O(n) resources that include computation time, bandwidth, and storage.",
                "We test our methods across a variety of localized domains, including site-specific domains and topic-specific domains.",
                "We demonstrate that by crawling as few as n or 2n additional pages, our methods can give excellent global PageRank estimates.",
                "Categories and Subject Descriptors H.3.3 [Information Storage and Retrieval]: Information Search and Retrieval; G.1.3 [Numerical Analysis]: Numerical Linear Algebra; G.3 [Probability and Statistics]: Markov Processes General Terms PageRank, Markov Chain, Stochastic Complementation 1.",
                "INTRODUCTION Localized search engines are small-scale search engines that index only a single community of the web.",
                "Such communities can be site-specific domains, such as pages within the cs.utexas.edu domain, or topic-related communitiesfor example, political websites.",
                "Compared to the web graph crawled and indexed by large-scale search engines, the size of such local communities is typically orders of magnitude smaller.",
                "Consequently, the computational resources needed to build such a search engine are also similarly lighter.",
                "By restricting themselves to smaller, more manageable sections of the web, localized search engines can also provide more precise and complete search capabilities over their respective domains.",
                "One drawback of localized indexes is the lack of global information needed to compute link-based rankings.",
                "The PageRank <br>algorithm</br> [3], has proven to be an effective such measure.",
                "In general, the PageRank of a given page is dependent on pages throughout the entire web graph.",
                "In the context of a localized search engine, if the PageRanks are computed using only the local subgraph, then we would expect the resulting PageRanks to reflect the perceived popularity within the local community and not of the web as a whole.",
                "For example, consider a localized search engine that indexes political pages with conservative views.",
                "A person wishing to research the opinions on global warming within the conservative political community may encounter numerous such opinions across various websites.",
                "If only local PageRank values are available, then the search results will reflect only strongly held beliefs within the community.",
                "However, if global PageRanks are also available, then the results can additionally reflect outsiders views of the conservative community (those documents that liberals most often access within the conservative community).",
                "Thus, for many localized search engines, incorporating global PageRanks can improve the quality of search results.",
                "However, the number of pages a local search engine indexes is typically orders of magnitude smaller than the number of pages indexed by their large-scale counterparts.",
                "Localized search engines do not have the bandwidth, storage capacity, or computational power to crawl, download, and compute the global PageRanks of the entire web.",
                "In this work, we present a method of approximating the global PageRanks of a local domain while only using resources of the same order as those needed to compute the PageRanks of the local subgraph.",
                "Our proposed method looks for a supergraph of our local subgraph such that the local PageRanks within this supergraph are close to the true global PageRanks.",
                "We construct this supergraph by iteratively crawling global pages on the current web frontier-i.e., global pages with inlinks from pages that have already been crawled.",
                "In order to provide 116 Research Track Paper a good approximation to the global PageRanks, care must be taken when choosing which pages to crawl next; in this paper, we present a well-motivated page selection <br>algorithm</br> that also performs well empirically.",
                "This <br>algorithm</br> is derived from a well-defined problem objective and has a running time linear in the number of local nodes.",
                "We experiment across several types of local subgraphs, including four topic related communities and several sitespecific domains.",
                "To evaluate performance, we measure the difference between the current global PageRank estimate and the global PageRank, as a function of the number of pages crawled.",
                "We compare our <br>algorithm</br> against several heuristics and also against a baseline <br>algorithm</br> that chooses pages at random, and we show that our method outperforms these other methods.",
                "Finally, we empirically demonstrate that, given a local domain of size n, we can provide good approximations to the global PageRank values by crawling at most n or 2n additional pages.",
                "The paper is organized as follows.",
                "Section 2 gives an overview of localized search engines and outlines their advantages over global search.",
                "Section 3 provides background on the PageRank <br>algorithm</br>.",
                "Section 4 formally defines our problem, and section 5 presents our page selection criteria and derives our algorithms.",
                "Section 6 provides experimental results, section 7 gives an overview of related work, and, finally, conclusions are given in section 8. 2.",
                "LOCALIZED SEARCH ENGINES Localized search engines index a single community of the web, typically either a site-specific community, or a topicspecific community.",
                "Localized search engines enjoy three major advantages over their large-scale counterparts: they are relatively inexpensive to build, they can offer more precise search capability over their local domain, and they can provide a more complete index.",
                "The resources needed to build a global search engine are enormous.",
                "A 2003 study by Lyman et al. [13] found that the surface web (publicly available static sites) consists of 8.9 billion pages, and that the average size of these pages is approximately 18.7 kilobytes.",
                "To download a crawl of this size, approximately 167 terabytes of space is needed.",
                "For a researcher who wishes to build a search engine with access to a couple of workstations or a small server, storage of this magnitude is simply not available.",
                "However, building a localized search engine over a web community of a hundred thousand pages would only require a few gigabytes of storage.",
                "The computational burden required to support search queries over a database this size is more manageable as well.",
                "We note that, for topic-specific search engines, the relevant community can be efficiently identified and downloaded by using a focused crawler [21, 4].",
                "For site-specific domains, the local domain is readily available on their own web server.",
                "This obviates the need for crawling or spidering, and a complete and up-to-date index of the domain can thus be guaranteed.",
                "This is in contrast to their large-scale counterparts, which suffer from several shortcomings.",
                "First, crawling dynamically generated pages-pages in the hidden web-has been the subject of research [20] and is a non-trivial task for an external crawler.",
                "Second, site-specific domains can enable the robots exclusion policy.",
                "This prohibits external search engines crawlers from downloading content from the domain, and an external search engine must instead rely on outside links and anchor text to index these restricted pages.",
                "By restricting itself to only a specific domain of the internet, a localized search engine can provide more precise search results.",
                "Consider the canonical ambiguous search query, jaguar, which can refer to either the car manufacturer or the animal.",
                "A scientist trying to research the habitat and evolutionary history of a jaguar may have better success using a finely tuned zoology-specific search engine than querying Google with multiple keyword searches and wading through irrelevant results.",
                "A method to learn better ranking functions for retrieval was recently proposed by Radlinski and Joachims [19] and has been applied to various local domains, including Cornell Universitys website [8]. 3.",
                "PAGERANK OVERVIEW The PageRank <br>algorithm</br> defines the importance of web pages by analyzing the underlying hyperlink structure of a web graph.",
                "The <br>algorithm</br> works by building a Markov chain from the link structure of the web graph and computing its stationary distribution.",
                "One way to compute the stationary distribution of a Markov chain is to find the limiting distribution of a random walk over the chain.",
                "Thus, the PageRank <br>algorithm</br> uses what is sometimes referred to as the random surfer model.",
                "In each step of the random walk, the surfer either follows an outlink from the current page (i.e. the current node in the chain), or jumps to a random page on the web.",
                "We now precisely define the PageRank problem.",
                "Let U be an m × m adjacency matrix for a given web graph such that Uji = 1 if page i links to page j and Uji = 0 otherwise.",
                "We define the PageRank matrix PU to be: PU = αUD−1 U + (1 − α)veT , (1) where DU is the (unique) diagonal matrix such that UD−1 U is column stochastic, α is a given scalar such that 0 ≤ α ≤ 1, e is the vector of all ones, and v is a non-negative, L1normalized vector, sometimes called the random surfer vector.",
                "Note that the matrix D−1 U is well-defined only if each column of U has at least one non-zero entry-i.e., each page in the webgraph has at least one outlink.",
                "In the presence of such dangling nodes that have no outlinks, one commonly used solution, proposed by Brin et al. [3], is to replace each zero column of U by a non-negative, L1-normalized vector.",
                "The PageRank vector r is the dominant eigenvector of the PageRank matrix, r = PU r. We will assume, without loss of generality, that r has an L1-norm of one.",
                "Computationally, r can be computed using the power method.",
                "This method first chooses a random starting vector r(0) , and iteratively multiplies the current vector by the PageRank matrix PU ; see <br>algorithm</br> 1.",
                "In general, each iteration of the power method can take O(m2 ) operations when PU is a dense matrix.",
                "However, in practice, the number of links in a web graph will be of the order of the number of pages.",
                "By exploiting the sparsity of the PageRank matrix, the work per iteration can be reduced to O(km), where k is the average number of links per web page.",
                "It has also been shown that the total number of iterations needed for convergence is proportional to α and does not depend on the size of the web graph [11, 7].",
                "Finally, the total space needed is also O(km), mainly to store the matrix U. 117 Research Track Paper <br>algorithm</br> 1: A linear time (per iteration) <br>algorithm</br> for computing PageRank.",
                "ComputePR(U) Input: U: Adjacency matrix.",
                "Output: r: PageRank vector.",
                "Choose (randomly) an initial non-negative vector r(0) such that r(0) 1 = 1. i ← 0 repeat i ← i + 1 ν ← αUD−1 U r(i−1) {α is the random surfing probability} r(i) ← ν + (1 − α)v {v is the random surfer vector.} until r(i) − r(i−1) < δ {δ is the convergence threshold.} r ← r(i) 4.",
                "PROBLEM DEFINITION Given a local domain L, let G be an N × N adjacency matrix for the entire connected component of the web that contains L, such that Gji = 1 if page i links to page j and Gji = 0 otherwise.",
                "Without loss of generality, we will partition G as: G = L Gout Lout Gwithin , (2) where L is the n × n local subgraph corresponding to links inside the local domain, Lout is the subgraph that corresponds to links from the local domain pointing out to the global domain, Gout is the subgraph containing links from the global domain into the local domain, and Gwithin contains links within the global domain.",
                "We assume that when building a localized search engine, only pages inside the local domain are crawled, and the links between these pages are represented by the subgraph L. The links in Lout are also known, as these point from crawled pages in the local domain to uncrawled pages in the global domain.",
                "As defined in equation (1), PG is the PageRank matrix formed from the global graph G, and we define the global PageRank vector of this graph to be g. Let the n-length vector p∗ be the L1-normalized vector corresponding to the global PageRank of the pages in the local domain L: p∗ = EL g ELg 1 , where EL = [ I | 0 ] is the restriction matrix that selects the components from g corresponding to nodes in L. Let p denote the PageRank vector constructed from the local domain subgraph L. In practice, the observed local PageRank p and the global PageRank p∗ will be quite different.",
                "One would expect that as the size of local matrix L approaches the size of global matrix G, the global PageRank and the observed local PageRank will become more similar.",
                "Thus, one approach to estimating the global PageRank is to crawl the entire global domain, compute its PageRank, and extract the PageRanks of the local domain.",
                "Typically, however, n N , i.e., the number of global pages is much larger than the number of local pages.",
                "Therefore, crawling all global pages will quickly exhaust all local resources (computational, storage, and bandwidth) available to create the local search engine.",
                "We instead seek a supergraph ˆF of our local subgraph L with size O(n).",
                "Our goal <br>algorithm</br> 2: The FindGlobalPR <br>algorithm</br>.",
                "FindGlobalPR(L, Lout, T, k) Input: L: zero-one adjacency matrix for the local domain, Lout: zero-one outlink matrix from L to global subgraph as in (2), T: number of iterations, k: number of pages to crawl per iteration.",
                "Output: ˆp: an improved estimate of the global PageRank of L. F ← L Fout ← Lout f ← ComputePR(F ) for (i = 1 to T) {Determine which pages to crawl next} pages ← SelectNodes(F , Fout, f, k) Crawl pages, augment F and modify Fout {Update PageRanks for new local domain} f ← ComputePR(F ) end {Extract PageRanks of original local domain & normalize} ˆp ← ELf ELf 1 is to find such a supergraph ˆF with PageRank ˆf, so that ˆf when restricted to L is close to p∗ .",
                "Formally, we seek to minimize GlobalDiff( ˆf) = EL ˆf EL ˆf 1 − p∗ 1 . (3) We choose the L1 norm for measuring the error as it does not place excessive weight on outliers (as the L2 norm does, for example), and also because it is the most commonly used distance measure in the literature for comparing PageRank vectors, as well as for detecting convergence of the <br>algorithm</br> [3].",
                "We propose a greedy framework, given in <br>algorithm</br> 2, for constructing ˆF .",
                "Initially, F is set to the local subgraph L, and the PageRank f of this graph is computed.",
                "The <br>algorithm</br> then proceeds as follows.",
                "First, the SelectNodes <br>algorithm</br> (which we discuss in the next section) is called and it returns a set of k nodes to crawl next from the set of nodes in the current crawl frontier, Fout.",
                "These selected nodes are then crawled to expand the local subgraph, F , and the PageRanks of this expanded graph are then recomputed.",
                "These steps are repeated for each of T iterations.",
                "Finally, the PageRank vector ˆp, which is restricted to pages within the original local domain, is returned.",
                "Given our computation, bandwidth, and memory restrictions, we will assume that the <br>algorithm</br> will crawl at most O(n) pages.",
                "Since the PageRanks are computed in each iteration of the <br>algorithm</br>, which is an O(n) operation, we will also assume that the number of iterations T is a constant.",
                "Of course, the main challenge here is in selecting which set of k nodes to crawl next.",
                "In the next section, we formally define the problem and give efficient algorithms. 5.",
                "NODE SELECTION In this section, we present node selection algorithms that operate within the greedy framework presented in the previous section.",
                "We first give a well-defined criteria for the page selection problem and provide experimental evidence that this criteria can effectively identify pages that optimize our problem objective (3).",
                "We then present our main al118 Research Track Paper gorithmic contribution of the paper, a method with linear running time that is derived from this page selection criteria.",
                "Finally, we give an intuitive analysis of our <br>algorithm</br> in terms of leaks and flows.",
                "We show that if only the flow is considered, then the resulting method is very similar to a widely used page selection heuristic [6]. 5.1 Formulation For a given page j in the global domain, we define the expanded local graph Fj: Fj = F s uT j 0 , (4) where uj is the zero-one vector containing the outlinks from F into page j, and s contains the inlinks from page j into the local domain.",
                "Note that we do not allow self-links in this framework.",
                "In practice, self-links are often removed, as they only serve to inflate a given pages PageRank.",
                "Observe that the inlinks into F from node j are not known until after node j is crawled.",
                "Therefore, we estimate this inlink vector as the expectation over inlink counts among the set of already crawled pages, s = F T e F T e 1 . (5) In practice, for any given page, this estimate may not reflect the true inlinks from that page.",
                "Furthermore, this expectation is sampled from the set of links within the crawled domain, whereas a better estimate would also use links from the global domain.",
                "However, the latter distribution is not known to a localized search engine, and we contend that the above estimate will, on average, be a better estimate than the uniform distribution, for example.",
                "Let the PageRank of F be f. We express the PageRank f+ j of the expanded local graph Fj as f+ j = (1 − xj)fj xj , (6) where xj is the PageRank of the candidate global node j, and fj is the L1-normalized PageRank vector restricted to the pages in F .",
                "Since directly optimizing our problem goal requires knowing the global PageRank p∗ , we instead propose to crawl those nodes that will have the greatest influence on the PageRanks of pages in the original local domain L: influence(j) = k∈L |fj[k] − f[k]| (7) = EL (fj − f) 1.",
                "Experimentally, the influence score is a very good predictor of our problem objective (3).",
                "For each candidate global node j, figure 1(a) shows the objective function value Global Diff(fj) as a function of the influence of page j.",
                "The local domain used here is a crawl of conservative political pages (we will provide more details about this dataset in section 6); we observed similar results in other domains.",
                "The correlation is quite strong, implying that the influence criteria can effectively identify pages that improve the global PageRank estimate.",
                "As a baseline, figure 1(b) compares our objective with an alternative criteria, outlink count.",
                "The outlink count is defined as the number of outlinks from the local domain to page j.",
                "The correlation here is much weaker. .00001 .0001 .001 .01 0.26 0.262 0.264 0.266 Influence Objective 1 10 100 1000 0.266 0.264 0.262 0.26 Outlink Count Objective (a) (b) Figure 1: (a) The correlation between our influence page selection criteria (7) and the actual objective function (3) value is quite strong. (b) This is in contrast to other criteria, such as outlink count, which exhibit a much weaker correlation. 5.2 Computation As described, for each candidate global page j, the influence score (7) must be computed.",
                "If fj is computed exactly for each global page j, then the PageRank <br>algorithm</br> would need to be run for each of the O(n) such global pages j we consider, resulting in an O(n2 ) computational cost for the node selection method.",
                "Thus, computing the exact value of fj will lead to a quadratic <br>algorithm</br>, and we must instead turn to methods of approximating this vector.",
                "The <br>algorithm</br> we present works by performing one power method iteration used by the PageRank <br>algorithm</br> (Algorithm 1).",
                "The convergence rate for the PageRank <br>algorithm</br> has been shown to equal the random surfer probability α [7, 11].",
                "Given a starting vector x(0) , if k PageRank iterations are performed, the current PageRank solution x(k) satisfies: x(k) − x∗ 1 = O(αk x(0) − x∗ 1), (8) where x∗ is the desired PageRank vector.",
                "Therefore, if only one iteration is performed, choosing a good starting vector is necessary to achieve an accurate approximation.",
                "We partition the PageRank matrix PFj , corresponding to the × subgraph Fj as: PFj = ˜F ˜s ˜uT j w , (9) where ˜F = αF (DF + diag(uj))−1 + (1 − α) e + 1 eT , ˜s = αs + (1 − α) e + 1 , ˜uj = α(DF + diag(uj))−1 uj + (1 − α) e + 1 , w = 1 − α + 1 , and diag(uj) is the diagonal matrix with the (i, i)th entry equal to one if the ith element of uj equals one, and is zero otherwise.",
                "We have assumed here that the random surfer vector is the uniform vector, and that L has no dangling links.",
                "These assumptions are not necessary and serve only to simplify discussion and analysis.",
                "A simple approach for estimating fj is the following.",
                "First, estimate the PageRank f+ j of Fj by computing one PageRank iteration over the matrix PFj , using the starting vector ν = f 0 .",
                "Then, estimate fj by removing the last 119 Research Track Paper component from our estimate of f+ j (i.e., the component corresponding to the added node j), and renormalizing.",
                "The problem with this approach is in the starting vector.",
                "Recall from (6) that xj is the PageRank of the added node j.",
                "The difference between the actual PageRank f+ j of PFj and the starting vector ν is ν − f+ j 1 = xj + f − (1 − xj)fj 1 ≥ xj + | f 1 − (1 − xj) fj 1| = xj + |xj| = 2xj.",
                "Thus, by (8), after one PageRank iteration, we expect our estimate of f+ j to still have an error of about 2αxj.",
                "In particular, for candidate nodes j with relatively high PageRank xj, this method will yield more inaccurate results.",
                "We will next present a method that eliminates this bias and runs in O(n) time. 5.2.1 Stochastic Complementation Since f+ j , as given in (6) is the PageRank of the matrix PFj , we have: fj(1 − xj) xj = ˜F ˜s ˜uT j w fj(1 − xj) xj = ˜F fj(1 − xj) + ˜sxj ˜uT j fj(1 − xj) + wxj .",
                "Solving the above system for fj can be shown to yield fj = ( ˜F + (1 − w)−1 ˜s˜uT j )fj. (10) The matrix S = ˜F +(1−w)−1 ˜s˜uT j is known as the stochastic complement of the column stochastic matrix PFj with respect to the sub matrix ˜F .",
                "The theory of stochastic complementation is well studied, and it can be shown the stochastic complement of an irreducible matrix (such as the PageRank matrix) is unique.",
                "Furthermore, the stochastic complement is also irreducible and therefore has a unique stationary distribution as well.",
                "For an extensive study, see [15].",
                "It can be easily shown that the sub-dominant eigenvalue of S is at most +1 α, where is the size of F .",
                "For sufficiently large , this value will be very close to α.",
                "This is important, as other properties of the PageRank <br>algorithm</br>, notably the algorithms sensitivity, are dependent on this value [11].",
                "In this method, we estimate the length vector fj by computing one PageRank iteration over the × stochastic complement S, starting at the vector f: fj ≈ Sf. (11) This is in contrast to the simple method outlined in the previous section, which first iterates over the ( + 1) × ( + 1) matrix PFj to estimate f+ j , and then removes the last component from the estimate and renormalizes to approximate fj.",
                "The problem with the latter method is in the choice of the ( + 1) length starting vector, ν. Consequently, the PageRank estimate given by the simple method differs from the true PageRank by at least 2αxj, where xj is the PageRank of page j.",
                "By using the stochastic complement, we can establish a tight lower bound of zero for this difference.",
                "To see this, consider the case in which a node k is added to F to form the augmented local subgraph Fk, and that the PageRank of this new graph is (1 − xk)f xk .",
                "Specifically, the addition of page k does not change the PageRanks of the pages in F , and thus fk = f. By construction of the stochastic complement, fk = Sfk, so the approximation given in equation (11) will yield the exact solution.",
                "Next, we present the computational details needed to efficiently compute the quantity fj −f 1 over all known global pages j.",
                "We begin by expanding the difference fj −f, where the vector fj is estimated as in (11), fj − f ≈ Sf − f = αF (DF + diag(uj))−1 f + (1 − α) e + 1 eT f +(1 − w)−1 (˜uT j f)˜s − f. (12) Note that the matrix (DF +diag(uj))−1 is diagonal.",
                "Letting o[k] be the outlink count for page k in F , we can express the kth diagonal element as: (DF + diag(uj))−1 [k, k] = 1 o[k]+1 if uj[k] = 1 1 o[k] if uj[k] = 0 Noting that (o[k] + 1)−1 = o[k]−1 − (o[k](o[k] + 1))−1 and rewriting this in matrix form yields (DF +diag(uj))−1 = D−1 F −D−1 F (DF +diag(uj))−1 diag(uj). (13) We use the same identity to express e + 1 = e − e ( + 1) . (14) Recall that, by definition, we have PF = αF D−1 F +(1−α)e .",
                "Substituting (13) and (14) in (12) yields fj − f ≈ (PF f − f) −αF D−1 F (DF + diag(uj))−1 diag(uj)f −(1 − α) e ( + 1) + (1 − w)−1 (˜uT j f)˜s = x + y + (˜uT j f)z, (15) noting that by definition, f = PF f, and defining the vectors x, y, and z to be x = −αF D−1 F (DF + diag(uj))−1 diag(uj)f (16) y = −(1 − α) e ( + 1) (17) z = (1 − w)−1 ˜s. (18) The first term x is a sparse vector, and takes non-zero values only for local pages k that are siblings of the global page j.",
                "We define (i, j) ∈ F if and only if F [j, i] = 1 (equivalently, page i links to page j) and express the value of the component x[k ] as: x[k ] = −α k:(k,k )∈F ,uj [k]=1 f[k] o[k](o[k] + 1) , (19) where o[k], as before, is the number of outlinks from page k in the local domain.",
                "Note that the last two terms, y and z are not dependent on the current global node j.",
                "Given the function hj(f) = y + (˜uT j f)z 1, the quantity fj − f 1 120 Research Track Paper can be expressed as fj − f 1 = k x[k] + y[k] + (˜uT j f)z[k] = k:x[k]=0 y[k] + (˜uT j f)z[k] + k:x[k]=0 x[k] + y[k] + (˜uT j f)z[k] = hj(f) − k:x[k]=0 y[k] + (˜uT j f)z[k] + k:x[k]=0 x[k] + y[k] + (˜uT j f)z[k] . (20) If we can compute the function hj in linear time, then we can compute each value of fj − f 1 using an additional amount of time that is proportional to the number of nonzero components in x.",
                "These optimizations are carried out in <br>algorithm</br> 3.",
                "Note that (20) computes the difference between all components of f and fj, whereas our node selection criteria, given in (7), is restricted to the components corresponding to nodes in the original local domain L. Let us examine <br>algorithm</br> 3 in more detail.",
                "First, the <br>algorithm</br> computes the outlink counts for each page in the local domain.",
                "The <br>algorithm</br> then computes the quantity ˜uT j f for each known global page j.",
                "This inner product can be written as (1 − α) 1 + 1 + α k:(k,j)∈Fout f[k] o[k] + 1 , where the second term sums over the set of local pages that link to page j.",
                "Since the total number of edges in Fout was assumed to have size O( ) (recall that is the number of pages in F ), the running time of this step is also O( ).",
                "The <br>algorithm</br> then computes the vectors y and z, as given in (17) and (18), respectively.",
                "The L1NormDiff method is called on the components of these vectors which correspond to the pages in L, and it estimates the value of EL(y + (˜uT j f)z) 1 for each page j.",
                "The estimation works as follows.",
                "First, the values of ˜uT j f are discretized uniformly into c values {a1, ..., ac}.",
                "The quantity EL(y + aiz) 1 is then computed for each discretized value of ai and stored in a table.",
                "To evaluate EL (y + az) 1 for some a ∈ [a1, ac], the closest discretized value ai is determined, and the corresponding entry in the table is used.",
                "The total running time for this method is linear in and the discretization parameter c (which we take to be a constant).",
                "We note that if exact values are desired, we have also developed an <br>algorithm</br> that runs in O( log ) time that is not described here.",
                "In the main loop, we compute the vector x, as defined in equation (16).",
                "The nested loops iterate over the set of pages in F that are siblings of page j.",
                "Typically, the size of this set is bounded by a constant.",
                "Finally, for each page j, the scores vector is updated over the set of non-zero components k of the vector x with k ∈ L. This set has size equal to the number of local siblings of page j, and is a subset of the total number of siblings of page j.",
                "Thus, each iteration of the main loop takes constant time, and the total running time of the main loop is O( ).",
                "Since we have assumed that the size of F will not grow larger than O(n), the total running time for the <br>algorithm</br> is O(n).",
                "<br>algorithm</br> 3: Node Selection via Stochastic Complementation.",
                "SC-Select(F , Fout, f, k) Input: F : zero-one adjacency matrix of size corresponding to the current local subgraph, Fout: zero-one outlink matrix from F to global subgraph, f: PageRank of F , k: number of pages to return Output: pages: set of k pages to crawl next {Compute outlink sums for local subgraph} foreach (page j ∈ F ) o[j] ← k:(j,k)∈F F[j, k] end {Compute scalar ˜uT j f for each global node j } foreach (page j ∈ Fout) g[j] ← (1 − α) 1 +1 foreach (page k : (k, j) ∈ Fout) g[j] ← g[j] + α f[k] o[k]+1 end end {Compute vectors y and z as in (17) and (18) } y ← −(1 − α) e ( +1) z ← (1 − w)−1 ˜s {Approximate y + g[j] ∗ z 1 for all values g[j]} norm diffs ←L1NormDiffs(g, ELy, ELz) foreach (page j ∈ Fout) {Compute sparse vector x as in (19)} x ← 0 foreach (page k : (k, j) ∈ Fout) foreach (page k : (k, k ) ∈ F )) x[k ] ← x[k ] − f[k] o[k](o[k]+1) end end x ← αx scores[j] ← norm diffs[j] foreach (k : x[k] > 0 and page k ∈ L) scores[j] ← scores[j] − |y[k] + g[j] ∗ z[k]| +|x[k]+y[k]+g[j]∗z[k])| end end Return k pages with highest scores 5.2.2 PageRank Flows We now present an intuitive analysis of the stochastic complementation method by decomposing the change in PageRank in terms of leaks and flows.",
                "This analysis is motivated by the decomposition given in (15).",
                "PageRank flow is the increase in the local PageRanks originating from global page j.",
                "The flows are represented by the non-negative vector (˜uT j f)z (equations (15) and (18)).",
                "The scalar ˜uT j f can be thought of as the total amount of PageRank flow that page j has available to distribute.",
                "The vector z dictates how the flow is allocated to the local domain; the flow that local page k receives is proportional to (within a constant factor due to the random surfer vector) the expected number of its inlinks.",
                "The PageRank leaks represent the decrease in PageRank resulting from the addition of page j.",
                "The leakage can be quantified in terms of the non-positive vectors x and y (equations (16) and (17)).",
                "For vector x, we can see from equation (19) that the amount of PageRank leaked by a local page is proportional to the weighted sum of the Page121 Research Track Paper Ranks of its siblings.",
                "Thus, pages that have siblings with higher PageRanks (and low outlink counts) will experience more leakage.",
                "The leakage caused by y is an artifact of the random surfer vector.",
                "We will next show that if only the flow term, (˜uT j f)z, is considered, then the resulting method is very similar to a heuristic proposed by Cho et al. [6] that has been widely used for the Crawling Through URL Ordering problem.",
                "This heuristic is computationally cheaper, but as we will see later, not as effective as the Stochastic Complementation method.",
                "Our node selection strategy chooses global nodes that have the largest influence (equation (7)).",
                "If this influence is approximated using only flows, the optimal node j∗ is: j∗ = argmaxj EL ˜uT j fz 1 = argmaxj ˜uT j f EL z 1 = argmaxj ˜uT j f = argmaxj α(DF + diag(uj))−1 uj + (1 − α) e + 1 , f = argmaxjfT (DF + diag(uj))−1 uj.",
                "The resulting page selection score can be expressed as a sum of the PageRanks of each local page k that links to j, where each PageRank value is normalized by o[k]+1.",
                "Interestingly, the normalization that arises in our method differs from the heuristic given in [6], which normalizes by o[k].",
                "The <br>algorithm</br> PF-Select, which is omitted due to lack of space, first computes the quantity fT (DF +diag(uj))−1 uj for each global page j, and then returns the pages with the k largest scores.",
                "To see that the running time for this <br>algorithm</br> is O(n), note that the computation involved in this method is a subset of that needed for the SC-Select method (<br>algorithm</br> 3), which was shown to have a running time of O(n). 6.",
                "EXPERIMENTS In this section, we provide experimental evidence to verify the effectiveness of our algorithms.",
                "We first outline our experimental methodology and then provide results across a variety of local domains. 6.1 Methodology Given the limited resources available at an academic institution, crawling a section of the web that is of the same magnitude as that indexed by Google or Yahoo! is clearly infeasible.",
                "Thus, for a given local domain, we approximate the global graph by crawling a local neighborhood around the domain that is several orders of magnitude larger than the local subgraph.",
                "Even though such a graph is still orders of magnitude smaller than the true global graph, we contend that, even if there exist some highly influential pages that are very far away from our local domain, it is unrealistic for any local node selection <br>algorithm</br> to find them.",
                "Such pages also tend to be highly unrelated to pages within the local domain.",
                "When explaining our node selection strategies in section 5, we made the simplifying assumption that our local graph contained no dangling nodes.",
                "This assumption was only made to ease our analysis.",
                "Our implementation efficiently handles dangling links by replacing each zero column of our adjacency matrix with the uniform vector.",
                "We evaluate the <br>algorithm</br> using the two node selection strategies given in Section 5.2, and also against the following baseline methods: • Random: Nodes are chosen uniformly at random among the known global nodes. • OutlinkCount: Global nodes with the highest number of outlinks from the local domain are chosen.",
                "At each iteration of the FindGlobalPR <br>algorithm</br>, we evaluate performance by computing the difference between the current PageRank estimate of the local domain, ELf ELf 1 , and the global PageRank of the local domain ELg ELg 1 .",
                "All PageRank calculations were performed using the uniform random surfer vector.",
                "Across all experiments, we set the random surfer parameter α, to be .85, and used a convergence threshold of 10−6 .",
                "We evaluate the difference between the local and global PageRank vectors using three different metrics: the L1 and L∞ norms, and Kendalls tau.",
                "The L1 norm measures the sum of the absolute value of the differences between the two vectors, and the L∞ norm measures the absolute value of the largest difference.",
                "Kendalls tau metric is a popular rank correlation measure used to compare PageRanks [2, 11].",
                "This metric can be computed by counting the number of pairs of pairs that agree in ranking, and subtracting from that the number of pairs of pairs that disagree in ranking.",
                "The final value is then normalized by the total number of n 2 such pairs, resulting in a [−1, 1] range, where a negative score signifies anti-correlation among rankings, and values near one correspond to strong rank correlation. 6.2 Results Our experiments are based on two large web crawls and were downloaded using the web crawler that is part of the Nutch open source search engine project [18].",
                "All crawls were restricted to only http pages, and to limit the number of dynamically generated pages that we crawl, we ignored all pages with urls containing any of the characters ?, *, @, or =.",
                "The first crawl, which we will refer to as the edu dataset, was seeded by homepages of the top 100 graduate computer science departments in the USA, as rated by the US News and World Report [16], and also by the home pages of their respective institutions.",
                "A crawl of depth 5 was performed, restricted to pages within the .edu domain, resulting in a graph with approximately 4.7 million pages and 22.9 million links.",
                "The second crawl was seeded by the set of pages under the politics hierarchy in the dmoz open directory project[17].",
                "We crawled all pages up to four links away, which yielded a graph with 4.4 million pages and 17.3 million links.",
                "Within the edu crawl, we identified the five site-specific domains corresponding to the websites of the top five graduate computer science departments, as ranked by the US News and World Report.",
                "This yielded local domains of various sizes, from 10,626 (UIUC) to 59,895 (Berkeley).",
                "For each of these site-specific domains with size n, we performed 50 iterations of the FindGlobalPR <br>algorithm</br> to crawl a total of 2n additional nodes.",
                "Figure 2(a) gives the (L1) difference from the PageRank estimate at each iteration to the global PageRank, for the Berkeley local domain.",
                "The performance of this dataset was representative of the typical performance across the five computer science sitespecific local domains.",
                "Initially, the L1 difference between the global and local PageRanks ranged from .0469 (Stanford) to .149 (MIT).",
                "For the first several iterations, the 122 Research Track Paper 0 5 10 15 20 25 30 35 40 45 50 0.015 0.02 0.025 0.03 0.035 0.04 0.045 0.05 0.055 Number of Iterations GlobalandLocalPageRankDifference(L1) Stochastic Complement PageRank Flow Outlink Count Random 0 10 20 30 40 50 0 0.05 0.1 0.15 0.2 0.25 0.3 0.35 Number of Iterations GlobalandLocalPageRankDifference(L1) Stochastic Complement PageRank Flow Outlink Count Random 0 5 10 15 20 25 0.16 0.18 0.2 0.22 0.24 0.26 0.28 0.3 0.32 0.34 Number of Iterations GlobalandLocalPageRankDifference(L1) Stochastic Complement PageRank Flow Outlink Count Random (a) www.cs.berkeley.edu (b) www.enterstageright.com (c) Politics Figure 2: L1 difference between the estimated and true global PageRanks for (a) Berkeleys computer science website, (b) the site-specific domain, www.enterstageright.com, and (c) the politics topic-specific domain.",
                "The stochastic complement method outperforms all other methods across various domains. three link-based methods all outperform the random selection heuristic.",
                "After these initial iterations, the random heuristic tended to be more competitive with (or even outperform, as in the Berkeley local domain) the outlink count and PageRank flow heuristics.",
                "In all tests, the stochastic complementation method either outperformed, or was competitive with, the other methods.",
                "Table 1 gives the average difference between the final estimated global PageRanks and the true global PageRanks for various distance measures.",
                "<br>algorithm</br> L1 L∞ Kendall Stoch.",
                "Comp. .0384 .00154 .9257 PR Flow .0470 .00272 .8946 Outlink .0419 .00196 .9053 Random .0407 .00204 .9086 Table 1: Average final performance of various node selection strategies for the five site-specific computer science local domains.",
                "Note that Kendalls Tau measures similarity, while the other metrics are dissimilarity measures.",
                "Stochastic Complementation clearly outperforms the other methods in all metrics.",
                "Within the politics dataset, we also performed two sitespecific tests for the largest websites in the crawl: www.adamsmith.org, the website for the London based Adam Smith Institute, and www.enterstageright.com, an online conservative journal.",
                "As with the edu local domains, we ran our <br>algorithm</br> for 50 iterations, crawling a total of 2n nodes.",
                "Figure 2 (b) plots the results for the www.enterstageright.com domain.",
                "In contrast to the edu local domains, the Random and OutlinkCount methods were not competitive with either the SC-Select or the PF-Select methods.",
                "Among all datasets and all node selection methods, the stochastic complementation method was most impressive in this dataset, realizing a final estimate that differed only .0279 from the global PageRank, a ten-fold improvement over the initial local PageRank difference of .299.",
                "For the Adam Smith local domain, the initial difference between the local and global PageRanks was .148, and the final estimates given by the SC-Select, PF-Select, OutlinkCount, and Random methods were .0208, .0193, .0222, and .0356, respectively.",
                "Within the politics dataset, we constructed four topicspecific local domains.",
                "The first domain consisted of all pages in the dmoz politics category, and also all pages within each of these sites up to two links away.",
                "This yielded a local domain of 90,811 pages, and the results are given in figure 2 (c).",
                "Because of the larger size of the topic-specific domains, we ran our <br>algorithm</br> for only 25 iterations to crawl a total of n nodes.",
                "We also created topic-specific domains from three political sub-topics: liberalism, conservatism, and socialism.",
                "The pages in these domains were identified by their corresponding dmoz categories.",
                "For each sub-topic, we set the local domain to be all pages within three links from the corresponding dmoz category pages.",
                "Table 2 summarizes the performance of these three topic-specific domains, and also the larger political domain.",
                "To quantify a global page js effect on the global PageRank values of pages in the local domain, we define page js impact to be its PageRank value, g[j], normalized by the fraction of its outlinks pointing to the local domain: impact(j) = oL[j] o[j] · g[j], where, oL[j] is the number of outlinks from page j to pages in the local domain L, and o[j] is the total number of js outlinks.",
                "In terms of the random surfer model, the impact of page j is the probability that the random surfer (1) is currently at global page j in her random walk and (2) takes an outlink to a local page, given that she has already decided not to jump to a random page.",
                "For the politics local domain, we found that many of the pages with high impact were in fact political pages that should have been included in the dmoz politics topic, but were not.",
                "For example, the two most influential global pages were the political search engine www.askhenry.com, and the home page of the online political magazine, www.policyreview.com.",
                "Among non-political pages, the home page of the journal Education Next was most influential.",
                "The journal is freely available online and contains articles regarding various aspect of K-12 education in America.",
                "To provide some anecdotal evidence for the effectiveness of our page selection methods, we note that the SC-Select method chose 11 pages within the www.educationnext.org domain, the PF-Select method discovered 7 such pages, while the OutlinkCount and Random methods found only 6 pages each.",
                "For the conservative political local domain, the socialist website www.ornery.org had a very high impact score.",
                "This 123 Research Track Paper All Politics: <br>algorithm</br> L1 L2 Kendall Stoch.",
                "Comp. .1253 .000700 .8671 PR Flow .1446 .000710 .8518 Outlink .1470 .00225 .8642 Random .2055 .00203 .8271 Conservativism: <br>algorithm</br> L1 L2 Kendall Stoch.",
                "Comp. .0496 .000990 .9158 PR Flow .0554 .000939 .9028 Outlink .0602 .00527 .9144 Random .1197 .00102 .8843 Liberalism: <br>algorithm</br> L1 L2 Kendall Stoch.",
                "Comp. .0622 .001360 .8848 PR Flow .0799 .001378 .8669 Outlink .0763 .001379 .8844 Random .1127 .001899 .8372 Socialism: <br>algorithm</br> L1 L∞ Kendall Stoch.",
                "Comp. .04318 .00439 .9604 PR Flow .0450 .004251 .9559 Outlink .04282 .00344 .9591 Random .0631 .005123 .9350 Table 2: Final performance among node selection strategies for the four political topic-specific crawls.",
                "Note that Kendalls Tau measures similarity, while the other metrics are dissimilarity measures. was largely due to a link from the front page of this site to an article regarding global warming published by the National Center for Public Policy Research, a conservative research group in Washington, DC.",
                "Not surprisingly, the global PageRank of this article (which happens to be on the home page of the NCCPR, www.nationalresearch.com), was approximately .002, whereas the local PageRank of this page was only .00158.",
                "The SC-Select method yielded a global PageRank estimate of approximately .00182, the PFSelect method estimated a value of .00167, and the Random and OutlinkCount methods yielded values of .01522 and .00171, respectively. 7.",
                "RELATED WORK The node selection framework we have proposed is similar to the url ordering for crawling problem proposed by Cho et al. in [6].",
                "Whereas our framework seeks to minimize the difference between the global and local PageRank, the objective used in [6] is to crawl the most highly (globally) ranked pages first.",
                "They propose several node selection algorithms, including the outlink count heuristic, as well as a variant of our PF-Select <br>algorithm</br> which they refer to as the PageRank ordering metric.",
                "They found this method to be most effective in optimizing their objective, as did a recent survey of these methods by Baeza-Yates et al. [1].",
                "Boldi et al. also experiment within a similar crawling framework in [2], but quantify their results by comparing Kendalls rank correlation between the PageRanks of the current set of crawled pages and those of the entire global graph.",
                "They found that node selection strategies that crawled pages with the highest global PageRank first actually performed worse (with respect to Kendalls Tau correlation between the local and global PageRanks) than basic depth first or breadth first strategies.",
                "However, their experiments differ from our work in that our node selection algorithms do not use (or have access to) global PageRank values.",
                "Many algorithmic improvements for computing exact PageRank values have been proposed [9, 10, 14].",
                "If such algorithms are used to compute the global PageRanks of our local domain, they would all require O(N) computation, storage, and bandwidth, where N is the size of the global domain.",
                "This is in contrast to our method, which approximates the global PageRank and scales linearly with the size of the local domain.",
                "Wang and Dewitt [22] propose a system where the set of web servers that comprise the global domain communicate with each other to compute their respective global PageRanks.",
                "For a given web server hosting n pages, the computational, bandwidth, and storage requirements are also linear in n. One drawback of this system is that the number of distinct web servers that comprise the global domain can be very large.",
                "For example, our edu dataset contains websites from over 3,200 different universities; coordinating such a system among a large number of sites can be very difficult.",
                "Gan, Chen, and Suel propose a method for estimating the PageRank of a single page [5] which uses only constant bandwidth, computation, and space.",
                "Their approach relies on the availability of a remote connectivity server that can supply the set of inlinks to a given page, an assumption not used in our framework.",
                "They experimentally show that a reasonable estimate of the nodes PageRank can be obtained by visiting at most a few hundred nodes.",
                "Using their <br>algorithm</br> for our problem would require that either the entire global domain first be downloaded or a connectivity server be used, both of which would lead to very large web graphs. 8.",
                "CONCLUSIONS AND FUTURE WORK The internet is growing exponentially, and in order to navigate such a large repository as the web, global search engines have established themselves as a necessity.",
                "Along with the ubiquity of these large-scale search engines comes an increase in search users expectations.",
                "By providing complete and isolated coverage of a particular web domain, localized search engines are an effective outlet to quickly locate content that could otherwise be difficult to find.",
                "In this work, we contend that the use of global PageRank in a localized search engine can improve performance.",
                "To estimate the global PageRank, we have proposed an iterative node selection framework where we select which pages from the global frontier to crawl next.",
                "Our primary contribution is our stochastic complementation page selection <br>algorithm</br>.",
                "This method crawls nodes that will most significantly impact the local domain and has running time linear in the number of nodes in the local domain.",
                "Experimentally, we validate these methods across a diverse set of local domains, including seven site-specific domains and four topic-specific domains.",
                "We conclude that by crawling an additional n or 2n pages, our methods find an estimate of the global PageRanks that is up to ten times better than just using the local PageRanks.",
                "Furthermore, we demonstrate that our <br>algorithm</br> consistently outperforms other existing heuristics. 124 Research Track Paper Often times, topic-specific domains are discovered using a focused web crawler which considers a pages content in conjunction with link anchor text to decide which pages to crawl next [4].",
                "Although such crawlers have proven to be quite effective in discovering topic-related content, many irrelevant pages are also crawled in the process.",
                "Typically, these pages are deleted and not indexed by the localized search engine.",
                "These pages can of course provide valuable information regarding the global PageRank of the local domain.",
                "One way to integrate these pages into our framework is to start the FindGlobalPR <br>algorithm</br> with the current subgraph F equal to the set of pages that were crawled by the focused crawler.",
                "The global PageRank estimation framework, along with the node selection algorithms presented, all require O(n) computation per iteration and bandwidth proportional to the number of pages crawled, Tk.",
                "If the number of iterations T is relatively small compared to the number of pages crawled per iteration, k, then the bottleneck of the <br>algorithm</br> will be the crawling phase.",
                "However, as the number of iterations increases (relative to k), the bottleneck will reside in the node selection computation.",
                "In this case, our algorithms would benefit from constant factor optimizations.",
                "Recall that the FindGlobalPR <br>algorithm</br> (<br>algorithm</br> 2) requires that the PageRanks of the current expanded local domain be recomputed in each iteration.",
                "Recent work by Langville and Meyer [12] gives an <br>algorithm</br> to quickly recompute PageRanks of a given webgraph if a small number of nodes are added.",
                "This <br>algorithm</br> was shown to give speedup of five to ten times on some datasets.",
                "We plan to investigate this and other such optimizations as future work.",
                "In this paper, we have objectively evaluated our methods by measuring how close our global PageRank estimates are to the actual global PageRanks.",
                "To determine the benefit of using global PageRanks in a localized search engine, we suggest a user study in which users are asked to rate the quality of search results for various search queries.",
                "For some queries, only the local PageRanks are used in ranking, and for the remaining queries, local PageRanks and the approximate global PageRanks, as computed by our algorithms, are used.",
                "The results of such a study can then be analyzed to determine the added benefit of using the global PageRanks computed by our methods, over just using the local PageRanks.",
                "Acknowledgements.",
                "This research was supported by NSF grant CCF-0431257, NSF Career Award ACI-0093404, and a grant from Sabre, Inc. 9.",
                "REFERENCES [1] R. Baeza-Yates, M. Marin, C. Castillo, and A. Rodriguez.",
                "Crawling a country: better strategies than breadth-first for web page ordering.",
                "World-Wide Web Conference, 2005. [2] P. Boldi, M. Santini, and S. Vigna.",
                "Do your worst to make the best: paradoxical effects in pagerank incremental computations.",
                "Workshop on Web Graphs, 3243:168-180, 2004. [3] S. Brin and L. Page.",
                "The anatomy of a large-scale hypertextual web search engine.",
                "Computer Networks and ISDN Systems, 33(1-7):107-117, 1998. [4] S. Chakrabarti, M. van den Berg, and B. Dom.",
                "Focused crawling: a new approach to topic-specific web resource discovery.",
                "World-Wide Web Conference, 1999. [5] Y. Chen, Q. Gan, and T. Suel.",
                "Local methods for estimating pagerank values.",
                "Conference on Information and Knowledge Management, 2004. [6] J. Cho, H. Garcia-Molina, and L. Page.",
                "Efficient crawling through url ordering.",
                "World-Wide Web Conference, 1998. [7] T. H. Haveliwala and S. D. Kamvar.",
                "The second eigenvalue of the Google matrix.",
                "Technical report, Stanford University, 2003. [8] T. Joachims, F. Radlinski, L. Granka, A. Cheng, C. Tillekeratne, and A. Patel.",
                "Learning retrieval functions from implicit feedback. http://www.cs.cornell.edu/People/tj/career. [9] S. D. Kamvar, T. H. Haveliwala, C. D. Manning, and G. H. Golub.",
                "Exploiting the block structure of the web for computing pagerank.",
                "World-Wide Web Conference, 2003. [10] S. D. Kamvar, T. H. Haveliwala, C. D. Manning, and G. H. Golub.",
                "Extrapolation methods for accelerating pagerank computation.",
                "World-Wide Web Conference, 2003. [11] A. N. Langville and C. D. Meyer.",
                "Deeper inside pagerank.",
                "Internet Mathematics, 2004. [12] A. N. Langville and C. D. Meyer.",
                "Updating the stationary vector of an irreducible markov chain with an eye on Googles pagerank.",
                "SIAM Journal on Matrix Analysis, 2005. [13] P. Lyman, H. R. Varian, K. Swearingen, P. Charles, N. Good, L. L. Jordan, and J. Pal.",
                "How much information 2003?",
                "School of Information Management and System, University of California at Berkely, 2003. [14] F. McSherry.",
                "A uniform approach to accelerated pagerank computation.",
                "World-Wide Web Conference, 2005. [15] C. D. Meyer.",
                "Stochastic complementation, uncoupling markov chains, and the theory of nearly reducible systems.",
                "SIAM Review, 31:240-272, 1989. [16] US News and World Report. http://www.usnews.com. [17] Dmoz open directory project. http://www.dmoz.org. [18] Nutch open source search engine. http://www.nutch.org. [19] F. Radlinski and T. Joachims.",
                "Query chains: learning to rank from implicit feedback.",
                "ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, 2005. [20] S. Raghavan and H. Garcia-Molina.",
                "Crawling the hidden web.",
                "In Proceedings of the Twenty-seventh International Conference on Very Large Databases, 2001. [21] T. Tin Tang, D. Hawking, N. Craswell, and K. Griffiths.",
                "Focused crawling for both topical relevance and quality of medical information.",
                "Conference on Information and Knowledge Management, 2005. [22] Y. Wang and D. J. DeWitt.",
                "Computing pagerank in a distributed internet search system.",
                "Proceedings of the 30th VLDB Conference, 2004. 125 Research Track Paper"
            ],
            "original_annotated_samples": [
                "The PageRank <br>algorithm</br> [3], has proven to be an effective such measure.",
                "In order to provide 116 Research Track Paper a good approximation to the global PageRanks, care must be taken when choosing which pages to crawl next; in this paper, we present a well-motivated page selection <br>algorithm</br> that also performs well empirically.",
                "This <br>algorithm</br> is derived from a well-defined problem objective and has a running time linear in the number of local nodes.",
                "We compare our <br>algorithm</br> against several heuristics and also against a baseline <br>algorithm</br> that chooses pages at random, and we show that our method outperforms these other methods.",
                "Section 3 provides background on the PageRank <br>algorithm</br>."
            ],
            "translated_annotated_samples": [
                "El <br>algoritmo</br> PageRank [3] ha demostrado ser una medida efectiva de este tipo.",
                "Para proporcionar a 116 Research Track Paper una buena aproximación a los PageRanks globales, es necesario tener cuidado al elegir qué páginas rastrear a continuación; en este documento, presentamos un <br>algoritmo de selección de páginas</br> bien fundamentado que también tiene un buen rendimiento empírico.",
                "Este <br>algoritmo</br> se deriva de un objetivo de problema bien definido y tiene un tiempo de ejecución lineal en el número de nodos locales.",
                "Comparamos nuestro <br>algoritmo</br> con varios heurísticos y también con un <br>algoritmo</br> base que elige páginas al azar, y demostramos que nuestro método supera a estos otros métodos.",
                "La sección 3 proporciona antecedentes sobre el <br>algoritmo</br> PageRank."
            ],
            "translated_text": "Estimando el PageRank Global de Comunidades Web Jason V. Davis Dept. Departamento de Ciencias de la Computación Universidad de Texas en Austin Austin, TX 78712 jdavis@cs.utexas.edu Inderjit S. Dhillon Departamento de Ciencias de la Computación Universidad de Texas en Austin Austin, TX 78712 inderjit@cs.utexas.edu RESUMEN Los motores de búsqueda localizados son sistemas a pequeña escala que indexan una comunidad particular en la web. Ofrecen varios beneficios en comparación con sus contrapartes a gran escala, ya que son relativamente económicos de construir y pueden proporcionar una capacidad de búsqueda más precisa y completa en sus dominios relevantes. Una desventaja que tienen estos sistemas en comparación con los motores de búsqueda a gran escala es la falta de valores globales de PageRank. Se necesita esa información para evaluar el valor de las páginas en el dominio de búsqueda localizada dentro del contexto de la web en su totalidad. En este artículo, presentamos algoritmos bien fundamentados para estimar los valores globales de PageRank de un dominio local. Los algoritmos son altamente escalables en el sentido de que, dado un dominio local de tamaño n, utilizan recursos de O(n) que incluyen tiempo de computación, ancho de banda y almacenamiento. Probamos nuestros métodos en una variedad de dominios localizados, incluyendo dominios específicos del sitio y dominios específicos del tema. Demostramos que al rastrear tan solo n o 2n páginas adicionales, nuestros métodos pueden proporcionar excelentes estimaciones globales de PageRank. Categorías y Descriptores de Asignaturas H.3.3 [Almacenamiento y Recuperación de Información]: Búsqueda y Recuperación de Información; G.1.3 [Análisis Numérico]: Álgebra Lineal Numérica; G.3 [Probabilidad y Estadística]: Procesos de Markov Términos Generales PageRank, Cadena de Markov, Complementación Estocástica. Los motores de búsqueda localizados son motores de búsqueda a pequeña escala que indexan solo una comunidad específica de la web. Tales comunidades pueden ser dominios específicos del sitio, como páginas dentro del dominio cs.utexas.edu, o comunidades relacionadas con un tema, por ejemplo, sitios web políticos. En comparación con el grafo web rastreado e indexado por los motores de búsqueda a gran escala, el tamaño de estas comunidades locales suele ser típicamente órdenes de magnitud más pequeño. Por consiguiente, los recursos computacionales necesarios para construir un motor de búsqueda de este tipo también son igualmente más ligeros. Al restringirse a secciones más pequeñas y manejables de la web, los motores de búsqueda localizados también pueden ofrecer capacidades de búsqueda más precisas y completas dentro de sus respectivos dominios. Una desventaja de los índices localizados es la falta de información global necesaria para calcular clasificaciones basadas en enlaces. El <br>algoritmo</br> PageRank [3] ha demostrado ser una medida efectiva de este tipo. En general, el PageRank de una página dada depende de las páginas en todo el grafo web. En el contexto de un motor de búsqueda localizado, si los PageRanks se calculan utilizando solo el subgrafo local, entonces esperaríamos que los PageRanks resultantes reflejen la popularidad percibida dentro de la comunidad local y no de la web en su totalidad. Por ejemplo, consideremos un motor de búsqueda localizado que indexa páginas políticas con puntos de vista conservadores. Una persona que desee investigar las opiniones sobre el calentamiento global dentro de la comunidad política conservadora puede encontrarse con numerosas opiniones de este tipo en varios sitios web. Si solo se dispone de valores de PageRank locales, entonces los resultados de búsqueda reflejarán solo creencias fuertemente arraigadas dentro de la comunidad. Sin embargo, si los PageRanks globales también están disponibles, entonces los resultados pueden reflejar adicionalmente las opiniones de los externos sobre la comunidad conservadora (es decir, aquellos documentos a los que los liberales acceden con mayor frecuencia dentro de la comunidad conservadora). Por lo tanto, para muchos motores de búsqueda localizados, la incorporación de PageRanks globales puede mejorar la calidad de los resultados de búsqueda. Sin embargo, el número de páginas que indexa un motor de búsqueda local suele ser órdenes de magnitud más pequeño que el número de páginas indexadas por sus contrapartes a gran escala. Los motores de búsqueda localizados no tienen el ancho de banda, la capacidad de almacenamiento o la potencia computacional para rastrear, descargar y calcular los PageRanks globales de toda la web. En este trabajo, presentamos un método para aproximar los PageRanks globales de un dominio local utilizando recursos del mismo orden que los necesarios para calcular los PageRanks del subgrafo local. Nuestro método propuesto busca un supergrafo de nuestro subgrafo local de manera que los PageRanks locales dentro de este supergrafo estén cerca de los verdaderos PageRanks globales. Construimos este supergrafo mediante el rastreo iterativo de páginas globales en la frontera web actual, es decir, páginas globales con enlaces entrantes de páginas que ya han sido rastreadas. Para proporcionar a 116 Research Track Paper una buena aproximación a los PageRanks globales, es necesario tener cuidado al elegir qué páginas rastrear a continuación; en este documento, presentamos un <br>algoritmo de selección de páginas</br> bien fundamentado que también tiene un buen rendimiento empírico. Este <br>algoritmo</br> se deriva de un objetivo de problema bien definido y tiene un tiempo de ejecución lineal en el número de nodos locales. Experimentamos en varios tipos de subgrafos locales, incluidas cuatro comunidades relacionadas con el tema y varios dominios específicos del sitio. Para evaluar el rendimiento, medimos la diferencia entre la estimación actual del PageRank global y el PageRank global, en función del número de páginas rastreadas. Comparamos nuestro <br>algoritmo</br> con varios heurísticos y también con un <br>algoritmo</br> base que elige páginas al azar, y demostramos que nuestro método supera a estos otros métodos. Finalmente, demostramos empíricamente que, dado un dominio local de tamaño n, podemos proporcionar buenas aproximaciones a los valores globales de PageRank rastreando como máximo n o 2n páginas adicionales. El documento está organizado de la siguiente manera. La sección 2 ofrece una visión general de los motores de búsqueda localizados y destaca sus ventajas sobre los motores de búsqueda globales. La sección 3 proporciona antecedentes sobre el <br>algoritmo</br> PageRank. ",
            "candidates": [],
            "error": [
                [
                    "algoritmo",
                    "algoritmo de selección de páginas",
                    "algoritmo",
                    "algoritmo",
                    "algoritmo",
                    "algoritmo"
                ]
            ]
        },
        "experimentation": {
            "translated_key": "experimentación",
            "is_in_text": false,
            "original_annotated_sentences": [
                "Estimating the Global PageRank of Web Communities Jason V. Davis Dept.",
                "of Computer Sciences University of Texas at Austin Austin, TX 78712 jdavis@cs.utexas.edu Inderjit S. Dhillon Dept. of Computer Sciences University of Texas at Austin Austin, TX 78712 inderjit@cs.utexas.edu ABSTRACT Localized search engines are small-scale systems that index a particular community on the web.",
                "They offer several benefits over their large-scale counterparts in that they are relatively inexpensive to build, and can provide more precise and complete search capability over their relevant domains.",
                "One disadvantage such systems have over large-scale search engines is the lack of global PageRank values.",
                "Such information is needed to assess the value of pages in the localized search domain within the context of the web as a whole.",
                "In this paper, we present well-motivated algorithms to estimate the global PageRank values of a local domain.",
                "The algorithms are all highly scalable in that, given a local domain of size n, they use O(n) resources that include computation time, bandwidth, and storage.",
                "We test our methods across a variety of localized domains, including site-specific domains and topic-specific domains.",
                "We demonstrate that by crawling as few as n or 2n additional pages, our methods can give excellent global PageRank estimates.",
                "Categories and Subject Descriptors H.3.3 [Information Storage and Retrieval]: Information Search and Retrieval; G.1.3 [Numerical Analysis]: Numerical Linear Algebra; G.3 [Probability and Statistics]: Markov Processes General Terms PageRank, Markov Chain, Stochastic Complementation 1.",
                "INTRODUCTION Localized search engines are small-scale search engines that index only a single community of the web.",
                "Such communities can be site-specific domains, such as pages within the cs.utexas.edu domain, or topic-related communitiesfor example, political websites.",
                "Compared to the web graph crawled and indexed by large-scale search engines, the size of such local communities is typically orders of magnitude smaller.",
                "Consequently, the computational resources needed to build such a search engine are also similarly lighter.",
                "By restricting themselves to smaller, more manageable sections of the web, localized search engines can also provide more precise and complete search capabilities over their respective domains.",
                "One drawback of localized indexes is the lack of global information needed to compute link-based rankings.",
                "The PageRank algorithm [3], has proven to be an effective such measure.",
                "In general, the PageRank of a given page is dependent on pages throughout the entire web graph.",
                "In the context of a localized search engine, if the PageRanks are computed using only the local subgraph, then we would expect the resulting PageRanks to reflect the perceived popularity within the local community and not of the web as a whole.",
                "For example, consider a localized search engine that indexes political pages with conservative views.",
                "A person wishing to research the opinions on global warming within the conservative political community may encounter numerous such opinions across various websites.",
                "If only local PageRank values are available, then the search results will reflect only strongly held beliefs within the community.",
                "However, if global PageRanks are also available, then the results can additionally reflect outsiders views of the conservative community (those documents that liberals most often access within the conservative community).",
                "Thus, for many localized search engines, incorporating global PageRanks can improve the quality of search results.",
                "However, the number of pages a local search engine indexes is typically orders of magnitude smaller than the number of pages indexed by their large-scale counterparts.",
                "Localized search engines do not have the bandwidth, storage capacity, or computational power to crawl, download, and compute the global PageRanks of the entire web.",
                "In this work, we present a method of approximating the global PageRanks of a local domain while only using resources of the same order as those needed to compute the PageRanks of the local subgraph.",
                "Our proposed method looks for a supergraph of our local subgraph such that the local PageRanks within this supergraph are close to the true global PageRanks.",
                "We construct this supergraph by iteratively crawling global pages on the current web frontier-i.e., global pages with inlinks from pages that have already been crawled.",
                "In order to provide 116 Research Track Paper a good approximation to the global PageRanks, care must be taken when choosing which pages to crawl next; in this paper, we present a well-motivated page selection algorithm that also performs well empirically.",
                "This algorithm is derived from a well-defined problem objective and has a running time linear in the number of local nodes.",
                "We experiment across several types of local subgraphs, including four topic related communities and several sitespecific domains.",
                "To evaluate performance, we measure the difference between the current global PageRank estimate and the global PageRank, as a function of the number of pages crawled.",
                "We compare our algorithm against several heuristics and also against a baseline algorithm that chooses pages at random, and we show that our method outperforms these other methods.",
                "Finally, we empirically demonstrate that, given a local domain of size n, we can provide good approximations to the global PageRank values by crawling at most n or 2n additional pages.",
                "The paper is organized as follows.",
                "Section 2 gives an overview of localized search engines and outlines their advantages over global search.",
                "Section 3 provides background on the PageRank algorithm.",
                "Section 4 formally defines our problem, and section 5 presents our page selection criteria and derives our algorithms.",
                "Section 6 provides experimental results, section 7 gives an overview of related work, and, finally, conclusions are given in section 8. 2.",
                "LOCALIZED SEARCH ENGINES Localized search engines index a single community of the web, typically either a site-specific community, or a topicspecific community.",
                "Localized search engines enjoy three major advantages over their large-scale counterparts: they are relatively inexpensive to build, they can offer more precise search capability over their local domain, and they can provide a more complete index.",
                "The resources needed to build a global search engine are enormous.",
                "A 2003 study by Lyman et al. [13] found that the surface web (publicly available static sites) consists of 8.9 billion pages, and that the average size of these pages is approximately 18.7 kilobytes.",
                "To download a crawl of this size, approximately 167 terabytes of space is needed.",
                "For a researcher who wishes to build a search engine with access to a couple of workstations or a small server, storage of this magnitude is simply not available.",
                "However, building a localized search engine over a web community of a hundred thousand pages would only require a few gigabytes of storage.",
                "The computational burden required to support search queries over a database this size is more manageable as well.",
                "We note that, for topic-specific search engines, the relevant community can be efficiently identified and downloaded by using a focused crawler [21, 4].",
                "For site-specific domains, the local domain is readily available on their own web server.",
                "This obviates the need for crawling or spidering, and a complete and up-to-date index of the domain can thus be guaranteed.",
                "This is in contrast to their large-scale counterparts, which suffer from several shortcomings.",
                "First, crawling dynamically generated pages-pages in the hidden web-has been the subject of research [20] and is a non-trivial task for an external crawler.",
                "Second, site-specific domains can enable the robots exclusion policy.",
                "This prohibits external search engines crawlers from downloading content from the domain, and an external search engine must instead rely on outside links and anchor text to index these restricted pages.",
                "By restricting itself to only a specific domain of the internet, a localized search engine can provide more precise search results.",
                "Consider the canonical ambiguous search query, jaguar, which can refer to either the car manufacturer or the animal.",
                "A scientist trying to research the habitat and evolutionary history of a jaguar may have better success using a finely tuned zoology-specific search engine than querying Google with multiple keyword searches and wading through irrelevant results.",
                "A method to learn better ranking functions for retrieval was recently proposed by Radlinski and Joachims [19] and has been applied to various local domains, including Cornell Universitys website [8]. 3.",
                "PAGERANK OVERVIEW The PageRank algorithm defines the importance of web pages by analyzing the underlying hyperlink structure of a web graph.",
                "The algorithm works by building a Markov chain from the link structure of the web graph and computing its stationary distribution.",
                "One way to compute the stationary distribution of a Markov chain is to find the limiting distribution of a random walk over the chain.",
                "Thus, the PageRank algorithm uses what is sometimes referred to as the random surfer model.",
                "In each step of the random walk, the surfer either follows an outlink from the current page (i.e. the current node in the chain), or jumps to a random page on the web.",
                "We now precisely define the PageRank problem.",
                "Let U be an m × m adjacency matrix for a given web graph such that Uji = 1 if page i links to page j and Uji = 0 otherwise.",
                "We define the PageRank matrix PU to be: PU = αUD−1 U + (1 − α)veT , (1) where DU is the (unique) diagonal matrix such that UD−1 U is column stochastic, α is a given scalar such that 0 ≤ α ≤ 1, e is the vector of all ones, and v is a non-negative, L1normalized vector, sometimes called the random surfer vector.",
                "Note that the matrix D−1 U is well-defined only if each column of U has at least one non-zero entry-i.e., each page in the webgraph has at least one outlink.",
                "In the presence of such dangling nodes that have no outlinks, one commonly used solution, proposed by Brin et al. [3], is to replace each zero column of U by a non-negative, L1-normalized vector.",
                "The PageRank vector r is the dominant eigenvector of the PageRank matrix, r = PU r. We will assume, without loss of generality, that r has an L1-norm of one.",
                "Computationally, r can be computed using the power method.",
                "This method first chooses a random starting vector r(0) , and iteratively multiplies the current vector by the PageRank matrix PU ; see Algorithm 1.",
                "In general, each iteration of the power method can take O(m2 ) operations when PU is a dense matrix.",
                "However, in practice, the number of links in a web graph will be of the order of the number of pages.",
                "By exploiting the sparsity of the PageRank matrix, the work per iteration can be reduced to O(km), where k is the average number of links per web page.",
                "It has also been shown that the total number of iterations needed for convergence is proportional to α and does not depend on the size of the web graph [11, 7].",
                "Finally, the total space needed is also O(km), mainly to store the matrix U. 117 Research Track Paper Algorithm 1: A linear time (per iteration) algorithm for computing PageRank.",
                "ComputePR(U) Input: U: Adjacency matrix.",
                "Output: r: PageRank vector.",
                "Choose (randomly) an initial non-negative vector r(0) such that r(0) 1 = 1. i ← 0 repeat i ← i + 1 ν ← αUD−1 U r(i−1) {α is the random surfing probability} r(i) ← ν + (1 − α)v {v is the random surfer vector.} until r(i) − r(i−1) < δ {δ is the convergence threshold.} r ← r(i) 4.",
                "PROBLEM DEFINITION Given a local domain L, let G be an N × N adjacency matrix for the entire connected component of the web that contains L, such that Gji = 1 if page i links to page j and Gji = 0 otherwise.",
                "Without loss of generality, we will partition G as: G = L Gout Lout Gwithin , (2) where L is the n × n local subgraph corresponding to links inside the local domain, Lout is the subgraph that corresponds to links from the local domain pointing out to the global domain, Gout is the subgraph containing links from the global domain into the local domain, and Gwithin contains links within the global domain.",
                "We assume that when building a localized search engine, only pages inside the local domain are crawled, and the links between these pages are represented by the subgraph L. The links in Lout are also known, as these point from crawled pages in the local domain to uncrawled pages in the global domain.",
                "As defined in equation (1), PG is the PageRank matrix formed from the global graph G, and we define the global PageRank vector of this graph to be g. Let the n-length vector p∗ be the L1-normalized vector corresponding to the global PageRank of the pages in the local domain L: p∗ = EL g ELg 1 , where EL = [ I | 0 ] is the restriction matrix that selects the components from g corresponding to nodes in L. Let p denote the PageRank vector constructed from the local domain subgraph L. In practice, the observed local PageRank p and the global PageRank p∗ will be quite different.",
                "One would expect that as the size of local matrix L approaches the size of global matrix G, the global PageRank and the observed local PageRank will become more similar.",
                "Thus, one approach to estimating the global PageRank is to crawl the entire global domain, compute its PageRank, and extract the PageRanks of the local domain.",
                "Typically, however, n N , i.e., the number of global pages is much larger than the number of local pages.",
                "Therefore, crawling all global pages will quickly exhaust all local resources (computational, storage, and bandwidth) available to create the local search engine.",
                "We instead seek a supergraph ˆF of our local subgraph L with size O(n).",
                "Our goal Algorithm 2: The FindGlobalPR algorithm.",
                "FindGlobalPR(L, Lout, T, k) Input: L: zero-one adjacency matrix for the local domain, Lout: zero-one outlink matrix from L to global subgraph as in (2), T: number of iterations, k: number of pages to crawl per iteration.",
                "Output: ˆp: an improved estimate of the global PageRank of L. F ← L Fout ← Lout f ← ComputePR(F ) for (i = 1 to T) {Determine which pages to crawl next} pages ← SelectNodes(F , Fout, f, k) Crawl pages, augment F and modify Fout {Update PageRanks for new local domain} f ← ComputePR(F ) end {Extract PageRanks of original local domain & normalize} ˆp ← ELf ELf 1 is to find such a supergraph ˆF with PageRank ˆf, so that ˆf when restricted to L is close to p∗ .",
                "Formally, we seek to minimize GlobalDiff( ˆf) = EL ˆf EL ˆf 1 − p∗ 1 . (3) We choose the L1 norm for measuring the error as it does not place excessive weight on outliers (as the L2 norm does, for example), and also because it is the most commonly used distance measure in the literature for comparing PageRank vectors, as well as for detecting convergence of the algorithm [3].",
                "We propose a greedy framework, given in Algorithm 2, for constructing ˆF .",
                "Initially, F is set to the local subgraph L, and the PageRank f of this graph is computed.",
                "The algorithm then proceeds as follows.",
                "First, the SelectNodes algorithm (which we discuss in the next section) is called and it returns a set of k nodes to crawl next from the set of nodes in the current crawl frontier, Fout.",
                "These selected nodes are then crawled to expand the local subgraph, F , and the PageRanks of this expanded graph are then recomputed.",
                "These steps are repeated for each of T iterations.",
                "Finally, the PageRank vector ˆp, which is restricted to pages within the original local domain, is returned.",
                "Given our computation, bandwidth, and memory restrictions, we will assume that the algorithm will crawl at most O(n) pages.",
                "Since the PageRanks are computed in each iteration of the algorithm, which is an O(n) operation, we will also assume that the number of iterations T is a constant.",
                "Of course, the main challenge here is in selecting which set of k nodes to crawl next.",
                "In the next section, we formally define the problem and give efficient algorithms. 5.",
                "NODE SELECTION In this section, we present node selection algorithms that operate within the greedy framework presented in the previous section.",
                "We first give a well-defined criteria for the page selection problem and provide experimental evidence that this criteria can effectively identify pages that optimize our problem objective (3).",
                "We then present our main al118 Research Track Paper gorithmic contribution of the paper, a method with linear running time that is derived from this page selection criteria.",
                "Finally, we give an intuitive analysis of our algorithm in terms of leaks and flows.",
                "We show that if only the flow is considered, then the resulting method is very similar to a widely used page selection heuristic [6]. 5.1 Formulation For a given page j in the global domain, we define the expanded local graph Fj: Fj = F s uT j 0 , (4) where uj is the zero-one vector containing the outlinks from F into page j, and s contains the inlinks from page j into the local domain.",
                "Note that we do not allow self-links in this framework.",
                "In practice, self-links are often removed, as they only serve to inflate a given pages PageRank.",
                "Observe that the inlinks into F from node j are not known until after node j is crawled.",
                "Therefore, we estimate this inlink vector as the expectation over inlink counts among the set of already crawled pages, s = F T e F T e 1 . (5) In practice, for any given page, this estimate may not reflect the true inlinks from that page.",
                "Furthermore, this expectation is sampled from the set of links within the crawled domain, whereas a better estimate would also use links from the global domain.",
                "However, the latter distribution is not known to a localized search engine, and we contend that the above estimate will, on average, be a better estimate than the uniform distribution, for example.",
                "Let the PageRank of F be f. We express the PageRank f+ j of the expanded local graph Fj as f+ j = (1 − xj)fj xj , (6) where xj is the PageRank of the candidate global node j, and fj is the L1-normalized PageRank vector restricted to the pages in F .",
                "Since directly optimizing our problem goal requires knowing the global PageRank p∗ , we instead propose to crawl those nodes that will have the greatest influence on the PageRanks of pages in the original local domain L: influence(j) = k∈L |fj[k] − f[k]| (7) = EL (fj − f) 1.",
                "Experimentally, the influence score is a very good predictor of our problem objective (3).",
                "For each candidate global node j, figure 1(a) shows the objective function value Global Diff(fj) as a function of the influence of page j.",
                "The local domain used here is a crawl of conservative political pages (we will provide more details about this dataset in section 6); we observed similar results in other domains.",
                "The correlation is quite strong, implying that the influence criteria can effectively identify pages that improve the global PageRank estimate.",
                "As a baseline, figure 1(b) compares our objective with an alternative criteria, outlink count.",
                "The outlink count is defined as the number of outlinks from the local domain to page j.",
                "The correlation here is much weaker. .00001 .0001 .001 .01 0.26 0.262 0.264 0.266 Influence Objective 1 10 100 1000 0.266 0.264 0.262 0.26 Outlink Count Objective (a) (b) Figure 1: (a) The correlation between our influence page selection criteria (7) and the actual objective function (3) value is quite strong. (b) This is in contrast to other criteria, such as outlink count, which exhibit a much weaker correlation. 5.2 Computation As described, for each candidate global page j, the influence score (7) must be computed.",
                "If fj is computed exactly for each global page j, then the PageRank algorithm would need to be run for each of the O(n) such global pages j we consider, resulting in an O(n2 ) computational cost for the node selection method.",
                "Thus, computing the exact value of fj will lead to a quadratic algorithm, and we must instead turn to methods of approximating this vector.",
                "The algorithm we present works by performing one power method iteration used by the PageRank algorithm (Algorithm 1).",
                "The convergence rate for the PageRank algorithm has been shown to equal the random surfer probability α [7, 11].",
                "Given a starting vector x(0) , if k PageRank iterations are performed, the current PageRank solution x(k) satisfies: x(k) − x∗ 1 = O(αk x(0) − x∗ 1), (8) where x∗ is the desired PageRank vector.",
                "Therefore, if only one iteration is performed, choosing a good starting vector is necessary to achieve an accurate approximation.",
                "We partition the PageRank matrix PFj , corresponding to the × subgraph Fj as: PFj = ˜F ˜s ˜uT j w , (9) where ˜F = αF (DF + diag(uj))−1 + (1 − α) e + 1 eT , ˜s = αs + (1 − α) e + 1 , ˜uj = α(DF + diag(uj))−1 uj + (1 − α) e + 1 , w = 1 − α + 1 , and diag(uj) is the diagonal matrix with the (i, i)th entry equal to one if the ith element of uj equals one, and is zero otherwise.",
                "We have assumed here that the random surfer vector is the uniform vector, and that L has no dangling links.",
                "These assumptions are not necessary and serve only to simplify discussion and analysis.",
                "A simple approach for estimating fj is the following.",
                "First, estimate the PageRank f+ j of Fj by computing one PageRank iteration over the matrix PFj , using the starting vector ν = f 0 .",
                "Then, estimate fj by removing the last 119 Research Track Paper component from our estimate of f+ j (i.e., the component corresponding to the added node j), and renormalizing.",
                "The problem with this approach is in the starting vector.",
                "Recall from (6) that xj is the PageRank of the added node j.",
                "The difference between the actual PageRank f+ j of PFj and the starting vector ν is ν − f+ j 1 = xj + f − (1 − xj)fj 1 ≥ xj + | f 1 − (1 − xj) fj 1| = xj + |xj| = 2xj.",
                "Thus, by (8), after one PageRank iteration, we expect our estimate of f+ j to still have an error of about 2αxj.",
                "In particular, for candidate nodes j with relatively high PageRank xj, this method will yield more inaccurate results.",
                "We will next present a method that eliminates this bias and runs in O(n) time. 5.2.1 Stochastic Complementation Since f+ j , as given in (6) is the PageRank of the matrix PFj , we have: fj(1 − xj) xj = ˜F ˜s ˜uT j w fj(1 − xj) xj = ˜F fj(1 − xj) + ˜sxj ˜uT j fj(1 − xj) + wxj .",
                "Solving the above system for fj can be shown to yield fj = ( ˜F + (1 − w)−1 ˜s˜uT j )fj. (10) The matrix S = ˜F +(1−w)−1 ˜s˜uT j is known as the stochastic complement of the column stochastic matrix PFj with respect to the sub matrix ˜F .",
                "The theory of stochastic complementation is well studied, and it can be shown the stochastic complement of an irreducible matrix (such as the PageRank matrix) is unique.",
                "Furthermore, the stochastic complement is also irreducible and therefore has a unique stationary distribution as well.",
                "For an extensive study, see [15].",
                "It can be easily shown that the sub-dominant eigenvalue of S is at most +1 α, where is the size of F .",
                "For sufficiently large , this value will be very close to α.",
                "This is important, as other properties of the PageRank algorithm, notably the algorithms sensitivity, are dependent on this value [11].",
                "In this method, we estimate the length vector fj by computing one PageRank iteration over the × stochastic complement S, starting at the vector f: fj ≈ Sf. (11) This is in contrast to the simple method outlined in the previous section, which first iterates over the ( + 1) × ( + 1) matrix PFj to estimate f+ j , and then removes the last component from the estimate and renormalizes to approximate fj.",
                "The problem with the latter method is in the choice of the ( + 1) length starting vector, ν. Consequently, the PageRank estimate given by the simple method differs from the true PageRank by at least 2αxj, where xj is the PageRank of page j.",
                "By using the stochastic complement, we can establish a tight lower bound of zero for this difference.",
                "To see this, consider the case in which a node k is added to F to form the augmented local subgraph Fk, and that the PageRank of this new graph is (1 − xk)f xk .",
                "Specifically, the addition of page k does not change the PageRanks of the pages in F , and thus fk = f. By construction of the stochastic complement, fk = Sfk, so the approximation given in equation (11) will yield the exact solution.",
                "Next, we present the computational details needed to efficiently compute the quantity fj −f 1 over all known global pages j.",
                "We begin by expanding the difference fj −f, where the vector fj is estimated as in (11), fj − f ≈ Sf − f = αF (DF + diag(uj))−1 f + (1 − α) e + 1 eT f +(1 − w)−1 (˜uT j f)˜s − f. (12) Note that the matrix (DF +diag(uj))−1 is diagonal.",
                "Letting o[k] be the outlink count for page k in F , we can express the kth diagonal element as: (DF + diag(uj))−1 [k, k] = 1 o[k]+1 if uj[k] = 1 1 o[k] if uj[k] = 0 Noting that (o[k] + 1)−1 = o[k]−1 − (o[k](o[k] + 1))−1 and rewriting this in matrix form yields (DF +diag(uj))−1 = D−1 F −D−1 F (DF +diag(uj))−1 diag(uj). (13) We use the same identity to express e + 1 = e − e ( + 1) . (14) Recall that, by definition, we have PF = αF D−1 F +(1−α)e .",
                "Substituting (13) and (14) in (12) yields fj − f ≈ (PF f − f) −αF D−1 F (DF + diag(uj))−1 diag(uj)f −(1 − α) e ( + 1) + (1 − w)−1 (˜uT j f)˜s = x + y + (˜uT j f)z, (15) noting that by definition, f = PF f, and defining the vectors x, y, and z to be x = −αF D−1 F (DF + diag(uj))−1 diag(uj)f (16) y = −(1 − α) e ( + 1) (17) z = (1 − w)−1 ˜s. (18) The first term x is a sparse vector, and takes non-zero values only for local pages k that are siblings of the global page j.",
                "We define (i, j) ∈ F if and only if F [j, i] = 1 (equivalently, page i links to page j) and express the value of the component x[k ] as: x[k ] = −α k:(k,k )∈F ,uj [k]=1 f[k] o[k](o[k] + 1) , (19) where o[k], as before, is the number of outlinks from page k in the local domain.",
                "Note that the last two terms, y and z are not dependent on the current global node j.",
                "Given the function hj(f) = y + (˜uT j f)z 1, the quantity fj − f 1 120 Research Track Paper can be expressed as fj − f 1 = k x[k] + y[k] + (˜uT j f)z[k] = k:x[k]=0 y[k] + (˜uT j f)z[k] + k:x[k]=0 x[k] + y[k] + (˜uT j f)z[k] = hj(f) − k:x[k]=0 y[k] + (˜uT j f)z[k] + k:x[k]=0 x[k] + y[k] + (˜uT j f)z[k] . (20) If we can compute the function hj in linear time, then we can compute each value of fj − f 1 using an additional amount of time that is proportional to the number of nonzero components in x.",
                "These optimizations are carried out in Algorithm 3.",
                "Note that (20) computes the difference between all components of f and fj, whereas our node selection criteria, given in (7), is restricted to the components corresponding to nodes in the original local domain L. Let us examine Algorithm 3 in more detail.",
                "First, the algorithm computes the outlink counts for each page in the local domain.",
                "The algorithm then computes the quantity ˜uT j f for each known global page j.",
                "This inner product can be written as (1 − α) 1 + 1 + α k:(k,j)∈Fout f[k] o[k] + 1 , where the second term sums over the set of local pages that link to page j.",
                "Since the total number of edges in Fout was assumed to have size O( ) (recall that is the number of pages in F ), the running time of this step is also O( ).",
                "The algorithm then computes the vectors y and z, as given in (17) and (18), respectively.",
                "The L1NormDiff method is called on the components of these vectors which correspond to the pages in L, and it estimates the value of EL(y + (˜uT j f)z) 1 for each page j.",
                "The estimation works as follows.",
                "First, the values of ˜uT j f are discretized uniformly into c values {a1, ..., ac}.",
                "The quantity EL(y + aiz) 1 is then computed for each discretized value of ai and stored in a table.",
                "To evaluate EL (y + az) 1 for some a ∈ [a1, ac], the closest discretized value ai is determined, and the corresponding entry in the table is used.",
                "The total running time for this method is linear in and the discretization parameter c (which we take to be a constant).",
                "We note that if exact values are desired, we have also developed an algorithm that runs in O( log ) time that is not described here.",
                "In the main loop, we compute the vector x, as defined in equation (16).",
                "The nested loops iterate over the set of pages in F that are siblings of page j.",
                "Typically, the size of this set is bounded by a constant.",
                "Finally, for each page j, the scores vector is updated over the set of non-zero components k of the vector x with k ∈ L. This set has size equal to the number of local siblings of page j, and is a subset of the total number of siblings of page j.",
                "Thus, each iteration of the main loop takes constant time, and the total running time of the main loop is O( ).",
                "Since we have assumed that the size of F will not grow larger than O(n), the total running time for the algorithm is O(n).",
                "Algorithm 3: Node Selection via Stochastic Complementation.",
                "SC-Select(F , Fout, f, k) Input: F : zero-one adjacency matrix of size corresponding to the current local subgraph, Fout: zero-one outlink matrix from F to global subgraph, f: PageRank of F , k: number of pages to return Output: pages: set of k pages to crawl next {Compute outlink sums for local subgraph} foreach (page j ∈ F ) o[j] ← k:(j,k)∈F F[j, k] end {Compute scalar ˜uT j f for each global node j } foreach (page j ∈ Fout) g[j] ← (1 − α) 1 +1 foreach (page k : (k, j) ∈ Fout) g[j] ← g[j] + α f[k] o[k]+1 end end {Compute vectors y and z as in (17) and (18) } y ← −(1 − α) e ( +1) z ← (1 − w)−1 ˜s {Approximate y + g[j] ∗ z 1 for all values g[j]} norm diffs ←L1NormDiffs(g, ELy, ELz) foreach (page j ∈ Fout) {Compute sparse vector x as in (19)} x ← 0 foreach (page k : (k, j) ∈ Fout) foreach (page k : (k, k ) ∈ F )) x[k ] ← x[k ] − f[k] o[k](o[k]+1) end end x ← αx scores[j] ← norm diffs[j] foreach (k : x[k] > 0 and page k ∈ L) scores[j] ← scores[j] − |y[k] + g[j] ∗ z[k]| +|x[k]+y[k]+g[j]∗z[k])| end end Return k pages with highest scores 5.2.2 PageRank Flows We now present an intuitive analysis of the stochastic complementation method by decomposing the change in PageRank in terms of leaks and flows.",
                "This analysis is motivated by the decomposition given in (15).",
                "PageRank flow is the increase in the local PageRanks originating from global page j.",
                "The flows are represented by the non-negative vector (˜uT j f)z (equations (15) and (18)).",
                "The scalar ˜uT j f can be thought of as the total amount of PageRank flow that page j has available to distribute.",
                "The vector z dictates how the flow is allocated to the local domain; the flow that local page k receives is proportional to (within a constant factor due to the random surfer vector) the expected number of its inlinks.",
                "The PageRank leaks represent the decrease in PageRank resulting from the addition of page j.",
                "The leakage can be quantified in terms of the non-positive vectors x and y (equations (16) and (17)).",
                "For vector x, we can see from equation (19) that the amount of PageRank leaked by a local page is proportional to the weighted sum of the Page121 Research Track Paper Ranks of its siblings.",
                "Thus, pages that have siblings with higher PageRanks (and low outlink counts) will experience more leakage.",
                "The leakage caused by y is an artifact of the random surfer vector.",
                "We will next show that if only the flow term, (˜uT j f)z, is considered, then the resulting method is very similar to a heuristic proposed by Cho et al. [6] that has been widely used for the Crawling Through URL Ordering problem.",
                "This heuristic is computationally cheaper, but as we will see later, not as effective as the Stochastic Complementation method.",
                "Our node selection strategy chooses global nodes that have the largest influence (equation (7)).",
                "If this influence is approximated using only flows, the optimal node j∗ is: j∗ = argmaxj EL ˜uT j fz 1 = argmaxj ˜uT j f EL z 1 = argmaxj ˜uT j f = argmaxj α(DF + diag(uj))−1 uj + (1 − α) e + 1 , f = argmaxjfT (DF + diag(uj))−1 uj.",
                "The resulting page selection score can be expressed as a sum of the PageRanks of each local page k that links to j, where each PageRank value is normalized by o[k]+1.",
                "Interestingly, the normalization that arises in our method differs from the heuristic given in [6], which normalizes by o[k].",
                "The algorithm PF-Select, which is omitted due to lack of space, first computes the quantity fT (DF +diag(uj))−1 uj for each global page j, and then returns the pages with the k largest scores.",
                "To see that the running time for this algorithm is O(n), note that the computation involved in this method is a subset of that needed for the SC-Select method (Algorithm 3), which was shown to have a running time of O(n). 6.",
                "EXPERIMENTS In this section, we provide experimental evidence to verify the effectiveness of our algorithms.",
                "We first outline our experimental methodology and then provide results across a variety of local domains. 6.1 Methodology Given the limited resources available at an academic institution, crawling a section of the web that is of the same magnitude as that indexed by Google or Yahoo! is clearly infeasible.",
                "Thus, for a given local domain, we approximate the global graph by crawling a local neighborhood around the domain that is several orders of magnitude larger than the local subgraph.",
                "Even though such a graph is still orders of magnitude smaller than the true global graph, we contend that, even if there exist some highly influential pages that are very far away from our local domain, it is unrealistic for any local node selection algorithm to find them.",
                "Such pages also tend to be highly unrelated to pages within the local domain.",
                "When explaining our node selection strategies in section 5, we made the simplifying assumption that our local graph contained no dangling nodes.",
                "This assumption was only made to ease our analysis.",
                "Our implementation efficiently handles dangling links by replacing each zero column of our adjacency matrix with the uniform vector.",
                "We evaluate the algorithm using the two node selection strategies given in Section 5.2, and also against the following baseline methods: • Random: Nodes are chosen uniformly at random among the known global nodes. • OutlinkCount: Global nodes with the highest number of outlinks from the local domain are chosen.",
                "At each iteration of the FindGlobalPR algorithm, we evaluate performance by computing the difference between the current PageRank estimate of the local domain, ELf ELf 1 , and the global PageRank of the local domain ELg ELg 1 .",
                "All PageRank calculations were performed using the uniform random surfer vector.",
                "Across all experiments, we set the random surfer parameter α, to be .85, and used a convergence threshold of 10−6 .",
                "We evaluate the difference between the local and global PageRank vectors using three different metrics: the L1 and L∞ norms, and Kendalls tau.",
                "The L1 norm measures the sum of the absolute value of the differences between the two vectors, and the L∞ norm measures the absolute value of the largest difference.",
                "Kendalls tau metric is a popular rank correlation measure used to compare PageRanks [2, 11].",
                "This metric can be computed by counting the number of pairs of pairs that agree in ranking, and subtracting from that the number of pairs of pairs that disagree in ranking.",
                "The final value is then normalized by the total number of n 2 such pairs, resulting in a [−1, 1] range, where a negative score signifies anti-correlation among rankings, and values near one correspond to strong rank correlation. 6.2 Results Our experiments are based on two large web crawls and were downloaded using the web crawler that is part of the Nutch open source search engine project [18].",
                "All crawls were restricted to only http pages, and to limit the number of dynamically generated pages that we crawl, we ignored all pages with urls containing any of the characters ?, *, @, or =.",
                "The first crawl, which we will refer to as the edu dataset, was seeded by homepages of the top 100 graduate computer science departments in the USA, as rated by the US News and World Report [16], and also by the home pages of their respective institutions.",
                "A crawl of depth 5 was performed, restricted to pages within the .edu domain, resulting in a graph with approximately 4.7 million pages and 22.9 million links.",
                "The second crawl was seeded by the set of pages under the politics hierarchy in the dmoz open directory project[17].",
                "We crawled all pages up to four links away, which yielded a graph with 4.4 million pages and 17.3 million links.",
                "Within the edu crawl, we identified the five site-specific domains corresponding to the websites of the top five graduate computer science departments, as ranked by the US News and World Report.",
                "This yielded local domains of various sizes, from 10,626 (UIUC) to 59,895 (Berkeley).",
                "For each of these site-specific domains with size n, we performed 50 iterations of the FindGlobalPR algorithm to crawl a total of 2n additional nodes.",
                "Figure 2(a) gives the (L1) difference from the PageRank estimate at each iteration to the global PageRank, for the Berkeley local domain.",
                "The performance of this dataset was representative of the typical performance across the five computer science sitespecific local domains.",
                "Initially, the L1 difference between the global and local PageRanks ranged from .0469 (Stanford) to .149 (MIT).",
                "For the first several iterations, the 122 Research Track Paper 0 5 10 15 20 25 30 35 40 45 50 0.015 0.02 0.025 0.03 0.035 0.04 0.045 0.05 0.055 Number of Iterations GlobalandLocalPageRankDifference(L1) Stochastic Complement PageRank Flow Outlink Count Random 0 10 20 30 40 50 0 0.05 0.1 0.15 0.2 0.25 0.3 0.35 Number of Iterations GlobalandLocalPageRankDifference(L1) Stochastic Complement PageRank Flow Outlink Count Random 0 5 10 15 20 25 0.16 0.18 0.2 0.22 0.24 0.26 0.28 0.3 0.32 0.34 Number of Iterations GlobalandLocalPageRankDifference(L1) Stochastic Complement PageRank Flow Outlink Count Random (a) www.cs.berkeley.edu (b) www.enterstageright.com (c) Politics Figure 2: L1 difference between the estimated and true global PageRanks for (a) Berkeleys computer science website, (b) the site-specific domain, www.enterstageright.com, and (c) the politics topic-specific domain.",
                "The stochastic complement method outperforms all other methods across various domains. three link-based methods all outperform the random selection heuristic.",
                "After these initial iterations, the random heuristic tended to be more competitive with (or even outperform, as in the Berkeley local domain) the outlink count and PageRank flow heuristics.",
                "In all tests, the stochastic complementation method either outperformed, or was competitive with, the other methods.",
                "Table 1 gives the average difference between the final estimated global PageRanks and the true global PageRanks for various distance measures.",
                "Algorithm L1 L∞ Kendall Stoch.",
                "Comp. .0384 .00154 .9257 PR Flow .0470 .00272 .8946 Outlink .0419 .00196 .9053 Random .0407 .00204 .9086 Table 1: Average final performance of various node selection strategies for the five site-specific computer science local domains.",
                "Note that Kendalls Tau measures similarity, while the other metrics are dissimilarity measures.",
                "Stochastic Complementation clearly outperforms the other methods in all metrics.",
                "Within the politics dataset, we also performed two sitespecific tests for the largest websites in the crawl: www.adamsmith.org, the website for the London based Adam Smith Institute, and www.enterstageright.com, an online conservative journal.",
                "As with the edu local domains, we ran our algorithm for 50 iterations, crawling a total of 2n nodes.",
                "Figure 2 (b) plots the results for the www.enterstageright.com domain.",
                "In contrast to the edu local domains, the Random and OutlinkCount methods were not competitive with either the SC-Select or the PF-Select methods.",
                "Among all datasets and all node selection methods, the stochastic complementation method was most impressive in this dataset, realizing a final estimate that differed only .0279 from the global PageRank, a ten-fold improvement over the initial local PageRank difference of .299.",
                "For the Adam Smith local domain, the initial difference between the local and global PageRanks was .148, and the final estimates given by the SC-Select, PF-Select, OutlinkCount, and Random methods were .0208, .0193, .0222, and .0356, respectively.",
                "Within the politics dataset, we constructed four topicspecific local domains.",
                "The first domain consisted of all pages in the dmoz politics category, and also all pages within each of these sites up to two links away.",
                "This yielded a local domain of 90,811 pages, and the results are given in figure 2 (c).",
                "Because of the larger size of the topic-specific domains, we ran our algorithm for only 25 iterations to crawl a total of n nodes.",
                "We also created topic-specific domains from three political sub-topics: liberalism, conservatism, and socialism.",
                "The pages in these domains were identified by their corresponding dmoz categories.",
                "For each sub-topic, we set the local domain to be all pages within three links from the corresponding dmoz category pages.",
                "Table 2 summarizes the performance of these three topic-specific domains, and also the larger political domain.",
                "To quantify a global page js effect on the global PageRank values of pages in the local domain, we define page js impact to be its PageRank value, g[j], normalized by the fraction of its outlinks pointing to the local domain: impact(j) = oL[j] o[j] · g[j], where, oL[j] is the number of outlinks from page j to pages in the local domain L, and o[j] is the total number of js outlinks.",
                "In terms of the random surfer model, the impact of page j is the probability that the random surfer (1) is currently at global page j in her random walk and (2) takes an outlink to a local page, given that she has already decided not to jump to a random page.",
                "For the politics local domain, we found that many of the pages with high impact were in fact political pages that should have been included in the dmoz politics topic, but were not.",
                "For example, the two most influential global pages were the political search engine www.askhenry.com, and the home page of the online political magazine, www.policyreview.com.",
                "Among non-political pages, the home page of the journal Education Next was most influential.",
                "The journal is freely available online and contains articles regarding various aspect of K-12 education in America.",
                "To provide some anecdotal evidence for the effectiveness of our page selection methods, we note that the SC-Select method chose 11 pages within the www.educationnext.org domain, the PF-Select method discovered 7 such pages, while the OutlinkCount and Random methods found only 6 pages each.",
                "For the conservative political local domain, the socialist website www.ornery.org had a very high impact score.",
                "This 123 Research Track Paper All Politics: Algorithm L1 L2 Kendall Stoch.",
                "Comp. .1253 .000700 .8671 PR Flow .1446 .000710 .8518 Outlink .1470 .00225 .8642 Random .2055 .00203 .8271 Conservativism: Algorithm L1 L2 Kendall Stoch.",
                "Comp. .0496 .000990 .9158 PR Flow .0554 .000939 .9028 Outlink .0602 .00527 .9144 Random .1197 .00102 .8843 Liberalism: Algorithm L1 L2 Kendall Stoch.",
                "Comp. .0622 .001360 .8848 PR Flow .0799 .001378 .8669 Outlink .0763 .001379 .8844 Random .1127 .001899 .8372 Socialism: Algorithm L1 L∞ Kendall Stoch.",
                "Comp. .04318 .00439 .9604 PR Flow .0450 .004251 .9559 Outlink .04282 .00344 .9591 Random .0631 .005123 .9350 Table 2: Final performance among node selection strategies for the four political topic-specific crawls.",
                "Note that Kendalls Tau measures similarity, while the other metrics are dissimilarity measures. was largely due to a link from the front page of this site to an article regarding global warming published by the National Center for Public Policy Research, a conservative research group in Washington, DC.",
                "Not surprisingly, the global PageRank of this article (which happens to be on the home page of the NCCPR, www.nationalresearch.com), was approximately .002, whereas the local PageRank of this page was only .00158.",
                "The SC-Select method yielded a global PageRank estimate of approximately .00182, the PFSelect method estimated a value of .00167, and the Random and OutlinkCount methods yielded values of .01522 and .00171, respectively. 7.",
                "RELATED WORK The node selection framework we have proposed is similar to the url ordering for crawling problem proposed by Cho et al. in [6].",
                "Whereas our framework seeks to minimize the difference between the global and local PageRank, the objective used in [6] is to crawl the most highly (globally) ranked pages first.",
                "They propose several node selection algorithms, including the outlink count heuristic, as well as a variant of our PF-Select algorithm which they refer to as the PageRank ordering metric.",
                "They found this method to be most effective in optimizing their objective, as did a recent survey of these methods by Baeza-Yates et al. [1].",
                "Boldi et al. also experiment within a similar crawling framework in [2], but quantify their results by comparing Kendalls rank correlation between the PageRanks of the current set of crawled pages and those of the entire global graph.",
                "They found that node selection strategies that crawled pages with the highest global PageRank first actually performed worse (with respect to Kendalls Tau correlation between the local and global PageRanks) than basic depth first or breadth first strategies.",
                "However, their experiments differ from our work in that our node selection algorithms do not use (or have access to) global PageRank values.",
                "Many algorithmic improvements for computing exact PageRank values have been proposed [9, 10, 14].",
                "If such algorithms are used to compute the global PageRanks of our local domain, they would all require O(N) computation, storage, and bandwidth, where N is the size of the global domain.",
                "This is in contrast to our method, which approximates the global PageRank and scales linearly with the size of the local domain.",
                "Wang and Dewitt [22] propose a system where the set of web servers that comprise the global domain communicate with each other to compute their respective global PageRanks.",
                "For a given web server hosting n pages, the computational, bandwidth, and storage requirements are also linear in n. One drawback of this system is that the number of distinct web servers that comprise the global domain can be very large.",
                "For example, our edu dataset contains websites from over 3,200 different universities; coordinating such a system among a large number of sites can be very difficult.",
                "Gan, Chen, and Suel propose a method for estimating the PageRank of a single page [5] which uses only constant bandwidth, computation, and space.",
                "Their approach relies on the availability of a remote connectivity server that can supply the set of inlinks to a given page, an assumption not used in our framework.",
                "They experimentally show that a reasonable estimate of the nodes PageRank can be obtained by visiting at most a few hundred nodes.",
                "Using their algorithm for our problem would require that either the entire global domain first be downloaded or a connectivity server be used, both of which would lead to very large web graphs. 8.",
                "CONCLUSIONS AND FUTURE WORK The internet is growing exponentially, and in order to navigate such a large repository as the web, global search engines have established themselves as a necessity.",
                "Along with the ubiquity of these large-scale search engines comes an increase in search users expectations.",
                "By providing complete and isolated coverage of a particular web domain, localized search engines are an effective outlet to quickly locate content that could otherwise be difficult to find.",
                "In this work, we contend that the use of global PageRank in a localized search engine can improve performance.",
                "To estimate the global PageRank, we have proposed an iterative node selection framework where we select which pages from the global frontier to crawl next.",
                "Our primary contribution is our stochastic complementation page selection algorithm.",
                "This method crawls nodes that will most significantly impact the local domain and has running time linear in the number of nodes in the local domain.",
                "Experimentally, we validate these methods across a diverse set of local domains, including seven site-specific domains and four topic-specific domains.",
                "We conclude that by crawling an additional n or 2n pages, our methods find an estimate of the global PageRanks that is up to ten times better than just using the local PageRanks.",
                "Furthermore, we demonstrate that our algorithm consistently outperforms other existing heuristics. 124 Research Track Paper Often times, topic-specific domains are discovered using a focused web crawler which considers a pages content in conjunction with link anchor text to decide which pages to crawl next [4].",
                "Although such crawlers have proven to be quite effective in discovering topic-related content, many irrelevant pages are also crawled in the process.",
                "Typically, these pages are deleted and not indexed by the localized search engine.",
                "These pages can of course provide valuable information regarding the global PageRank of the local domain.",
                "One way to integrate these pages into our framework is to start the FindGlobalPR algorithm with the current subgraph F equal to the set of pages that were crawled by the focused crawler.",
                "The global PageRank estimation framework, along with the node selection algorithms presented, all require O(n) computation per iteration and bandwidth proportional to the number of pages crawled, Tk.",
                "If the number of iterations T is relatively small compared to the number of pages crawled per iteration, k, then the bottleneck of the algorithm will be the crawling phase.",
                "However, as the number of iterations increases (relative to k), the bottleneck will reside in the node selection computation.",
                "In this case, our algorithms would benefit from constant factor optimizations.",
                "Recall that the FindGlobalPR algorithm (Algorithm 2) requires that the PageRanks of the current expanded local domain be recomputed in each iteration.",
                "Recent work by Langville and Meyer [12] gives an algorithm to quickly recompute PageRanks of a given webgraph if a small number of nodes are added.",
                "This algorithm was shown to give speedup of five to ten times on some datasets.",
                "We plan to investigate this and other such optimizations as future work.",
                "In this paper, we have objectively evaluated our methods by measuring how close our global PageRank estimates are to the actual global PageRanks.",
                "To determine the benefit of using global PageRanks in a localized search engine, we suggest a user study in which users are asked to rate the quality of search results for various search queries.",
                "For some queries, only the local PageRanks are used in ranking, and for the remaining queries, local PageRanks and the approximate global PageRanks, as computed by our algorithms, are used.",
                "The results of such a study can then be analyzed to determine the added benefit of using the global PageRanks computed by our methods, over just using the local PageRanks.",
                "Acknowledgements.",
                "This research was supported by NSF grant CCF-0431257, NSF Career Award ACI-0093404, and a grant from Sabre, Inc. 9.",
                "REFERENCES [1] R. Baeza-Yates, M. Marin, C. Castillo, and A. Rodriguez.",
                "Crawling a country: better strategies than breadth-first for web page ordering.",
                "World-Wide Web Conference, 2005. [2] P. Boldi, M. Santini, and S. Vigna.",
                "Do your worst to make the best: paradoxical effects in pagerank incremental computations.",
                "Workshop on Web Graphs, 3243:168-180, 2004. [3] S. Brin and L. Page.",
                "The anatomy of a large-scale hypertextual web search engine.",
                "Computer Networks and ISDN Systems, 33(1-7):107-117, 1998. [4] S. Chakrabarti, M. van den Berg, and B. Dom.",
                "Focused crawling: a new approach to topic-specific web resource discovery.",
                "World-Wide Web Conference, 1999. [5] Y. Chen, Q. Gan, and T. Suel.",
                "Local methods for estimating pagerank values.",
                "Conference on Information and Knowledge Management, 2004. [6] J. Cho, H. Garcia-Molina, and L. Page.",
                "Efficient crawling through url ordering.",
                "World-Wide Web Conference, 1998. [7] T. H. Haveliwala and S. D. Kamvar.",
                "The second eigenvalue of the Google matrix.",
                "Technical report, Stanford University, 2003. [8] T. Joachims, F. Radlinski, L. Granka, A. Cheng, C. Tillekeratne, and A. Patel.",
                "Learning retrieval functions from implicit feedback. http://www.cs.cornell.edu/People/tj/career. [9] S. D. Kamvar, T. H. Haveliwala, C. D. Manning, and G. H. Golub.",
                "Exploiting the block structure of the web for computing pagerank.",
                "World-Wide Web Conference, 2003. [10] S. D. Kamvar, T. H. Haveliwala, C. D. Manning, and G. H. Golub.",
                "Extrapolation methods for accelerating pagerank computation.",
                "World-Wide Web Conference, 2003. [11] A. N. Langville and C. D. Meyer.",
                "Deeper inside pagerank.",
                "Internet Mathematics, 2004. [12] A. N. Langville and C. D. Meyer.",
                "Updating the stationary vector of an irreducible markov chain with an eye on Googles pagerank.",
                "SIAM Journal on Matrix Analysis, 2005. [13] P. Lyman, H. R. Varian, K. Swearingen, P. Charles, N. Good, L. L. Jordan, and J. Pal.",
                "How much information 2003?",
                "School of Information Management and System, University of California at Berkely, 2003. [14] F. McSherry.",
                "A uniform approach to accelerated pagerank computation.",
                "World-Wide Web Conference, 2005. [15] C. D. Meyer.",
                "Stochastic complementation, uncoupling markov chains, and the theory of nearly reducible systems.",
                "SIAM Review, 31:240-272, 1989. [16] US News and World Report. http://www.usnews.com. [17] Dmoz open directory project. http://www.dmoz.org. [18] Nutch open source search engine. http://www.nutch.org. [19] F. Radlinski and T. Joachims.",
                "Query chains: learning to rank from implicit feedback.",
                "ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, 2005. [20] S. Raghavan and H. Garcia-Molina.",
                "Crawling the hidden web.",
                "In Proceedings of the Twenty-seventh International Conference on Very Large Databases, 2001. [21] T. Tin Tang, D. Hawking, N. Craswell, and K. Griffiths.",
                "Focused crawling for both topical relevance and quality of medical information.",
                "Conference on Information and Knowledge Management, 2005. [22] Y. Wang and D. J. DeWitt.",
                "Computing pagerank in a distributed internet search system.",
                "Proceedings of the 30th VLDB Conference, 2004. 125 Research Track Paper"
            ],
            "original_annotated_samples": [],
            "translated_annotated_samples": [],
            "translated_text": "",
            "candidates": [],
            "error": [
                []
            ]
        }
    }
}