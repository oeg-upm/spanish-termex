{
    "id": "H-53",
    "original_text": "Context Sensitive Stemming for Web Search Fuchun Peng Nawaaz Ahmed Xin Li Yumao Lu Yahoo! Inc. 701 First Avenue Sunnyvale, California 94089 {fuchun, nawaaz, xinli, yumaol}@yahoo-inc.com ABSTRACT Traditionally, stemming has been applied to Information Retrieval tasks by transforming words in documents to the their root form before indexing, and applying a similar transformation to query terms. Although it increases recall, this naive strategy does not work well for Web Search since it lowers precision and requires a significant amount of additional computation. In this paper, we propose a context sensitive stemming method that addresses these two issues. Two unique properties make our approach feasible for Web Search. First, based on statistical language modeling, we perform context sensitive analysis on the query side. We accurately predict which of its morphological variants is useful to expand a query term with before submitting the query to the search engine. This dramatically reduces the number of bad expansions, which in turn reduces the cost of additional computation and improves the precision at the same time. Second, our approach performs a context sensitive document matching for those expanded variants. This conservative strategy serves as a safeguard against spurious stemming, and it turns out to be very important for improving precision. Using word pluralization handling as an example of our stemming approach, our experiments on a major Web search engine show that stemming only 29% of the query traffic, we can improve relevance as measured by average Discounted Cumulative Gain (DCG5) by 6.1% on these queries and 1.8% over all query traffic. Categories and Subject Descriptors H.3.3 [Information Systems]: Information Storage and Retrieval-Query formulation General Terms Algorithms, Experimentation 1. INTRODUCTION Web search has now become a major tool in our daily lives for information seeking. One of the important issues in Web search is that user queries are often not best formulated to get optimal results. For example, running shoe is a query that occurs frequently in query logs. However, the query running shoes is much more likely to give better search results than the original query because documents matching the intent of this query usually contain the words running shoes. Correctly formulating a query requires the user to accurately predict which word form is used in the documents that best satisfy his or her information needs. This is difficult even for experienced users, and especially difficult for non-native speakers. One traditional solution is to use stemming [16, 18], the process of transforming inflected or derived words to their root form so that a search term will match and retrieve documents containing all forms of the term. Thus, the word run will match running, ran, runs, and shoe will match shoes and shoeing. Stemming can be done either on the terms in a document during indexing (and applying the same transformation to the query terms during query processing) or by expanding the query with the variants during query processing. Stemming during indexing allows very little flexibility during query processing, while stemming by query expansion allows handling each query differently, and hence is preferred. Although traditional stemming increases recall by matching word variants [13], it can reduce precision by retrieving too many documents that have been incorrectly matched. When examining the results of applying stemming to a large number of queries, one usually finds that nearly equal numbers of queries are helped and hurt by the technique [6]. In addition, it reduces system performance because the search engine has to match all the word variants. As we will show in the experiments, this is true even if we simplify stemming to pluralization handling, which is the process of converting a word from its plural to singular form, or vice versa. Thus, one needs to be very cautious when using stemming in Web search engines. One problem of traditional stemming is its blind transformation of all query terms, that is, it always performs the same transformation for the same query word without considering the context of the word. For example, the word book has four forms book, books, booking, booked, and store has four forms store, stores, storing, stored. For the query book store, expanding both words to all of their variants significantly increases computation cost and hurts precision, since not all of the variants are useful for this query. Transforming book store to match book stores is fine, but matching book storing or booking store is not. A weighting method that gives variant words smaller weights alleviates the problems to a certain extent if the weights accurately reflect the importance of the variant in this particular query. However uniform weighting is not going to work and a query dependent weighting is still a challenging unsolved problem [20]. A second problem of traditional stemming is its blind matching of all occurrences in documents. For the query book store, a transformation that allows the variant stores to be matched will cause every occurrence of stores in the document to be treated equivalent to the query term store. Thus, a document containing the fragment reading a book in coffee stores will be matched, causing many wrong documents to be selected. Although we hope the ranking function can correctly handle these, with many more candidates to rank, the risk of making mistakes increases. To alleviate these two problems, we propose a context sensitive stemming approach for Web search. Our solution consists of two context sensitive analysis, one on the query side and the other on the document side. On the query side, we propose a statistical language modeling based approach to predict which word variants are better forms than the original word for search purpose and expanding the query with only those forms. On the document side, we propose a conservative context sensitive matching for the transformed word variants, only matching document occurrences in the context of other terms in the query. Our model is simple yet effective and efficient, making it feasible to be used in real commercial Web search engines. We use pluralization handling as a running example for our stemming approach. The motivation for using pluralization handling as an example is to show that even such simple stemming, if handled correctly, can give significant benefits to search relevance. As far as we know, no previous research has systematically investigated the usage of pluralization in Web search. As we have to point out, the method we propose is not limited to pluralization handling, it is a general stemming technique, and can also be applied to general query expansion. Experiments on general stemming yield additional significant improvements over pluralization handling for long queries, although details will not be reported in this paper. In the rest of the paper, we first present the related work and distinguish our method from previous work in Section 2. We describe the details of the context sensitive stemming approach in Section 3. We then perform extensive experiments on a major Web search engine to support our claims in Section 4, followed by discussions in Section 5. Finally, we conclude the paper in Section 6. 2. RELATED WORK Stemming is a long studied technology. Many stemmers have been developed, such as the Lovins stemmer [16] and the Porter stemmer [18]. The Porter stemmer is widely used due to its simplicity and effectiveness in many applications. However, the Porter stemming makes many mistakes because its simple rules cannot fully describe English morphology. Corpus analysis is used to improve Porter stemmer [26] by creating equivalence classes for words that are morphologically similar and occur in similar context as measured by expected mutual information [23]. We use a similar corpus based approach for stemming by computing the similarity between two words based on their distributional context features which can be more than just adjacent words [15], and then only keep the morphologically similar words as candidates. Using stemming in information retrieval is also a well known technique [8, 10]. However, the effectiveness of stemming for English query systems was previously reported to be rather limited. Lennon et al. [17] compared the Lovins and Porter algorithms and found little improvement in retrieval performance. Later, Harman [9] compares three general stemming techniques in text retrieval experiments including pluralization handing (called S stemmer in the paper). They also proposed selective stemming based on query length and term importance, but no positive results were reported. On the other hand, Krovetz [14] performed comparisons over small numbers of documents (from 400 to 12k) and showed dramatic precision improvement (up to 45%). However, due to the limited number of tested queries (less than 100) and the small size of the collection, the results are hard to generalize to Web search. These mixed results, mostly failures, led early IR researchers to deem stemming irrelevant in general for English [4], although recent research has shown stemming has greater benefits for retrieval in other languages [2]. We suspect the previous failures were mainly due to the two problems we mentioned in the introduction. Blind stemming, or a simple query length based selective stemming as used in [9] is not enough. Stemming has to be decided on case by case basis, not only at the query level but also at the document level. As we will show, if handled correctly, significant improvement can be achieved. A more general problem related to stemming is query reformulation [3, 12] and query expansion which expands words not only with word variants [7, 22, 24, 25]. To decide which expanded words to use, people often use pseudorelevance feedback techniquesthat send the original query to a search engine and retrieve the top documents, extract relevant words from these top documents as additional query words, and resubmit the expanded query again [21]. This normally requires sending a query multiple times to search engine and it is not cost effective for processing the huge amount of queries involved in Web search. In addition, query expansion, including query reformulation [3, 12], has a high risk of changing the user intent (called query drift). Since the expanded words may have different meanings, adding them to the query could potentially change the intent of the original query. Thus query expansion based on pseudorelevance and query reformulation can provide suggestions to users for interactive refinement but can hardly be directly used for Web search. On the other hand, stemming is much more conservative since most of the time, stemming preserves the original search intent. While most work on query expansion focuses on recall enhancement, our work focuses on increasing both recall and precision. The increase on recall is obvious. With quality stemming, good documents which were not selected before stemming will be pushed up and those low quality documents will be degraded. On selective query expansion, Cronen-Townsend et al. [6] proposed a method for selective query expansion based on comparing the Kullback-Leibler divergence of the results from the unexpanded query and the results from the expanded query. This is similar to the relevance feedback in the sense that it requires multiple passes retrieval. If a word can be expanded into several words, it requires running this process multiple times to decide which expanded word is useful. It is expensive to deploy this in production Web search engines. Our method predicts the quality of expansion based on oﬄine information without sending the query to a search engine. In summary, we propose a novel approach to attack an old, yet still important and challenging problem for Web search - stemming. Our approach is unique in that it performs predictive stemming on a per query basis without relevance feedback from the Web, using the context of the variants in documents to preserve precision. Its simple, yet very efficient and effective, making real time stemming feasible for Web search. Our results will affirm researchers that stemming is indeed very important to large scale information retrieval. 3. CONTEXT SENSITIVE STEMMING 3.1 Overview Our system has four components as illustrated in Figure 1: candidate generation, query segmentation and head word detection, context sensitive query stemming and context sensitive document matching. Candidate generation (component 1) is performed oﬄine and generated candidates are stored in a dictionary. For an input query, we first segment query into concepts and detect the head word for each concept (component 2). We then use statistical language modeling to decide whether a particular variant is useful (component 3), and finally for the expanded variants, we perform context sensitive document matching (component 4). Below we discuss each of the components in more detail. Component 4: context sensitive document matching Input Query: and head word detection Component 2: segment Component 1: candidate generation comparisons −> comparison Component 3: selective word expansion decision: comparisons −> comparison example: hotel price comparisons output: hotel comparisons hotel −> hotels Figure 1: System Components 3.2 Expansion candidate generation One of the ways to generate candidates is using the Porter stemmer [18]. The Porter stemmer simply uses morphological rules to convert a word to its base form. It has no knowledge of the semantic meaning of the words and sometimes makes serious mistakes, such as executive to execution, news to new, and paste to past. A more conservative way is based on using corpus analysis to improve the Porter stemmer results [26]. The corpus analysis we do is based on word distributional similarity [15]. The rationale of using distributional word similarity is that true variants tend to be used in similar contexts. In the distributional word similarity calculation, each word is represented with a vector of features derived from the context of the word. We use the bigrams to the left and right of the word as its context features, by mining a huge Web corpus. The similarity between two words is the cosine similarity between the two corresponding feature vectors. The top 20 similar words to develop is shown in the following table. rank candidate score rank candidate score 0 develop 1 10 berts 0.119 1 developing 0.339 11 wads 0.116 2 developed 0.176 12 developer 0.107 3 incubator 0.160 13 promoting 0.100 4 develops 0.150 14 developmental 0.091 5 development 0.148 15 reengineering 0.090 6 tutoring 0.138 16 build 0.083 7 analyzing 0.128 17 construct 0.081 8 developement 0.128 18 educational 0.081 9 automation 0.126 19 institute 0.077 Table 1: Top 20 most similar candidates to word develop. Column score is the similarity score. To determine the stemming candidates, we apply a few Porter stemmer [18] morphological rules to the similarity list. After applying these rules, for the word develop, the stemming candidates are developing, developed, develops, development, developement, developer, developmental. For the pluralization handling purpose, only the candidate develops is retained. One thing we note from observing the distributionally similar words is that they are closely related semantically. These words might serve as candidates for general query expansion, a topic we will investigate in the future. 3.3 Segmentation and headword identification For long queries, it is quite important to detect the concepts in the query and the most important words for those concepts. We first break a query into segments, each segment representing a concept which normally is a noun phrase. For each of the noun phrases, we then detect the most important word which we call the head word. Segmentation is also used in document sensitive matching (section 3.5) to enforce proximity. To break a query into segments, we have to define a criteria to measure the strength of the relation between words. One effective method is to use mutual information as an indicator on whether or not to split two words [19]. We use a log of 25M queries and collect the bigram and unigram frequencies from it. For every incoming query, we compute the mutual information of two adjacent words; if it passes a predefined threshold, we do not split the query between those two words and move on to next word. We continue this process until the mutual information between two words is below the threshold, then create a concept boundary here. Table 2 shows some examples of query segmentation. The ideal way of finding the head word of a concept is to do syntactic parsing to determine the dependency structure of the query. Query parsing is more difficult than sentence [running shoe] [best] [new york] [medical schools] [pictures] [of] [white house] [cookies] [in] [san francisco] [hotel] [price comparison] Table 2: Query segmentation: a segment is bracketed. parsing since many queries are not grammatical and are very short. Applying a parser trained on sentences from documents to queries will have poor performance. In our solution, we just use simple heuristics rules, and it works very well in practice for English. For an English noun phrase, the head word is typically the last nonstop word, unless the phrase is of a particular pattern, like XYZ of/in/at/from UVW. In such cases, the head word is typically the last nonstop word of XYZ. 3.4 Context sensitive word expansion After detecting which words are the most important words to expand, we have to decide whether the expansions will be useful. Our statistics show that about half of the queries can be transformed by pluralization via naive stemming. Among this half, about 25% of the queries improve relevance when transformed, the majority (about 50%) do not change their top 5 results, and the remaining 25% perform worse. Thus, it is extremely important to identify which queries should not be stemmed for the purpose of maximizing relevance improvement and minimizing stemming cost. In addition, for a query with multiple words that can be transformed, or a word with multiple variants, not all of the expansions are useful. Taking query hotel price comparison as an example, we decide that hotel and price comparison are two concepts. Head words hotel and comparison can be expanded to hotels and comparisons. Are both transformations useful? To test whether an expansion is useful, we have to know whether the expanded query is likely to get more relevant documents from the Web, which can be quantified by the probability of the query occurring as a string on the Web. The more likely a query to occur on the Web, the more relevant documents this query is able to return. Now the whole problem becomes how to calculate the probability of query to occur on the Web. Calculating the probability of string occurring in a corpus is a well known language modeling problem. The goal of language modeling is to predict the probability of naturally occurring word sequences, s = w1w2...wN ; or more simply, to put high probability on word sequences that actually occur (and low probability on word sequences that never occur). The simplest and most successful approach to language modeling is still based on the n-gram model. By the chain rule of probability one can write the probability of any word sequence as Pr(w1w2...wN ) = NY i=1 Pr(wi|w1...wi−1) (1) An n-gram model approximates this probability by assuming that the only words relevant to predicting Pr(wi|w1...wi−1) are the previous n − 1 words; i.e. Pr(wi|w1...wi−1) = Pr(wi|wi−n+1...wi−1) A straightforward maximum likelihood estimate of n-gram probabilities from a corpus is given by the observed frequency of each of the patterns Pr(wi|wi−n+1...wi−1) = #(wi−n+1...wi) #(wi−n+1...wi−1) (2) where #(.) denotes the number of occurrences of a specified gram in the training corpus. Although one could attempt to use simple n-gram models to capture long range dependencies in language, attempting to do so directly immediately creates sparse data problems: Using grams of length up to n entails estimating the probability of Wn events, where W is the size of the word vocabulary. This quickly overwhelms modern computational and data resources for even modest choices of n (beyond 3 to 6). Also, because of the heavy tailed nature of language (i.e. Zipfs law) one is likely to encounter novel n-grams that were never witnessed during training in any test corpus, and therefore some mechanism for assigning non-zero probability to novel n-grams is a central and unavoidable issue in statistical language modeling. One standard approach to smoothing probability estimates to cope with sparse data problems (and to cope with potentially missing n-grams) is to use some sort of back-off estimator. Pr(wi|wi−n+1...wi−1) = 8 >>< >>: ˆPr(wi|wi−n+1...wi−1), if #(wi−n+1...wi) > 0 β(wi−n+1...wi−1) × Pr(wi|wi−n+2...wi−1), otherwise (3) where ˆPr(wi|wi−n+1...wi−1) = discount #(wi−n+1...wi) #(wi−n+1...wi−1) (4) is the discounted probability and β(wi−n+1...wi−1) is a normalization constant β(wi−n+1...wi−1) = 1 − X x∈(wi−n+1...wi−1x) ˆPr(x|wi−n+1...wi−1) 1 − X x∈(wi−n+1...wi−1x) ˆPr(x|wi−n+2...wi−1) (5) The discounted probability (4) can be computed with different smoothing techniques, including absolute smoothing, Good-Turing smoothing, linear smoothing, and Witten-Bell smoothing [5]. We used absolute smoothing in our experiments. Since the likelihood of a string, Pr(w1w2...wN ), is a very small number and hard to interpret, we use entropy as defined below to score the string. Entropy = − 1 N log2 Pr(w1w2...wN ) (6) Now getting back to the example of the query hotel price comparisons, there are four variants of this query, and the entropy of these four candidates are shown in Table 3. We can see that all alternatives are less likely than the input query. It is therefore not useful to make an expansion for this query. On the other hand, if the input query is hotel price comparisons which is the second alternative in the table, then there is a better alternative than the input query, and it should therefore be expanded. To tolerate the variations in probability estimation, we relax the selection criterion to those query alternatives if their scores are within a certain distance (10% in our experiments) to the best score. Query variations Entropy hotel price comparison 6.177 hotel price comparisons 6.597 hotels price comparison 6.937 hotels price comparisons 7.360 Table 3: Variations of query hotel price comparison ranked by entropy score, with the original query in bold face. 3.5 Context sensitive document matching Even after we know which word variants are likely to be useful, we have to be conservative in document matching for the expanded variants. For the query hotel price comparisons, we decided that word comparisons is expanded to include comparison. However, not every occurrence of comparison in the document is of interest. A page which is about comparing customer service can contain all of the words hotel price comparisons comparison. This page is not a good page for the query. If we accept matches of every occurrence of comparison, it will hurt retrieval precision and this is one of the main reasons why most stemming approaches do not work well for information retrieval. To address this problem, we have a proximity constraint that considers the context around the expanded variant in the document. A variant match is considered valid only if the variant occurs in the same context as the original word does. The context is the left or the right non-stop segments 1 of the original word. Taking the same query as an example, the context of comparisons is price. The expanded word comparison is only valid if it is in the same context of comparisons, which is after the word price. Thus, we should only match those occurrences of comparison in the document if they occur after the word price. Considering the fact that queries and documents may not represent the intent in exactly the same way, we relax this proximity constraint to allow variant occurrences within a window of some fixed size. If the expanded word comparison occurs within the context of price within a window, it is considered valid. The smaller the window size is, the more restrictive the matching. We use a window size of 4, which typically captures contexts that include the containing and adjacent noun phrases. 4. EXPERIMENTAL EVALUATION 4.1 Evaluation metrics We will measure both relevance improvement and the stemming cost required to achieve the relevance. 1 a context segment can not be a single stop word. 4.1.1 Relevance measurement We use a variant of the average Discounted Cumulative Gain (DCG), a recently popularized scheme to measure search engine relevance [1, 11]. Given a query and a ranked list of K documents (K is set to 5 in our experiments), the DCG(K) score for this query is calculated as follows: DCG(K) = KX k=1 gk log2(1 + k) . (7) where gk is the weight for the document at rank k. Higher degree of relevance corresponds to a higher weight. A page is graded into one of the five scales: Perfect, Excellent, Good, Fair, Bad, with corresponding weights. We use dcg to represent the average DCG(5) over a set of test queries. 4.1.2 Stemming cost Another metric is to measure the additional cost incurred by stemming. Given the same level of relevance improvement, we prefer a stemming method that has less additional cost. We measure this by the percentage of queries that are actually stemmed, over all the queries that could possibly be stemmed. 4.2 Data preparation We randomly sample 870 queries from a three month query log, with 290 from each month. Among all these 870 queries, we remove all misspelled queries since misspelled queries are not of interest to stemming. We also remove all one word queries since stemming one word queries without context has a high risk of changing query intent, especially for short words. In the end, we have 529 correctly spelled queries with at least 2 words. 4.3 Naive stemming for Web search Before explaining the experiments and results in detail, wed like to describe the traditional way of using stemming for Web search, referred as the naive model. This is to treat every word variant equivalent for all possible words in the query. The query book store will be transformed into (book OR books)(store OR stores) when limiting stemming to pluralization handling only, where OR is an operator that denotes the equivalence of the left and right arguments. 4.4 Experimental setup The baseline model is the model without stemming. We first run the naive model to see how well it performs over the baseline. Then we improve the naive stemming model by document sensitive matching, referred as document sensitive matching model. This model makes the same stemming as the naive model on the query side, but performs conservative matching on the document side using the strategy described in section 3.5. The naive model and document sensitive matching model stem the most queries. Out of the 529 queries, there are 408 queries that they stem, corresponding to 46.7% query traffic (out of a total of 870). We then further improve the document sensitive matching model from the query side with selective word stemming based on statistical language modeling (section 3.4), referred as selective stemming model. Based on language modeling prediction, this model stems only a subset of the 408 queries stemmed by the document sensitive matching model. We experiment with unigram language model and bigram language model. Since we only care how much we can improve the naive model, we will only use these 408 queries (all the queries that are affected by the naive stemming model) in the experiments. To get a sense of how these models perform, we also have an oracle model that gives the upper-bound performance a stemmer can achieve on this data. The oracle model only expands a word if the stemming will give better results. To analyze the pluralization handling influence on different query categories, we divide queries into short queries and long queries. Among the 408 queries stemmed by the naive model, there are 272 short queries with 2 or 3 words, and 136 long queries with at least 4 words. 4.5 Results We summarize the overall results in Table 4, and present the results on short queries and long queries separately in Table 5. Each row in Table 4 is a stemming strategy described in section 4.4. The first column is the name of the strategy. The second column is the number of queries affected by this strategy; this column measures the stemming cost, and the numbers should be low for the same level of dcg. The third column is the average dcg score over all tested queries in this category (including the ones that were not stemmed by the strategy). The fourth column is the relative improvement over the baseline, and the last column is the p-value of Wilcoxon significance test. There are several observations about the results. We can see the naively stemming only obtains a statistically insignificant improvement of 1.5%. Looking at Table 5, it gives an improvement of 2.7% on short queries. However, it also hurts long queries by -2.4%. Overall, the improvement is canceled out. The reason that it improves short queries is that most short queries only have one word that can be stemmed. Thus, blindly pluralizing short queries is relatively safe. However for long queries, most queries can have multiple words that can be pluralized. Expanding all of them without selection will significantly hurt precision. Document context sensitive stemming gives a significant lift to the performance, from 2.7% to 4.2% for short queries and from -2.4% to -1.6% for long queries, with an overall lift from 1.5% to 2.8%. The improvement comes from the conservative context sensitive document matching. An expanded word is valid only if it occurs within the context of original query in the document. This reduces many spurious matches. However, we still notice that for long queries, context sensitive stemming is not able to improve performance because it still selects too many documents and gives the ranking function a hard problem. While the chosen window size of 4 works the best amongst all the choices, it still allows spurious matches. It is possible that the window size needs to be chosen on a per query basis to ensure tighter proximity constraints for different types of noun phrases. Selective word pluralization further helps resolving the problem faced by document context sensitive stemming. It does not stem every word that places all the burden on the ranking algorithm, but tries to eliminate unnecessary stemming in the first place. By predicting which word variants are going to be useful, we can dramatically reduce the number of stemmed words, thus improving both the recall and the precision. With the unigram language model, we can reduce the stemming cost by 26.7% (from 408/408 to 300/408) and lift the overall dcg improvement from 2.8% to 3.4%. In particular, it gives significant improvements on long queries. The dcg gain is turned from negative to positive, from −1.6% to 1.1%. This confirms our hypothesis that reducing unnecessary word expansion leads to precision improvement. For short queries too, we observe both dcg improvement and stemming cost reduction with the unigram language model. The advantages of predictive word expansion with a language model is further boosted with a better bigram language model. The overall dcg gain is lifted from 3.4% to 3.9%, and stemming cost is dramatically reduced from 408/408 to 250/408, corresponding to only 29% of query traffic (250 out of 870) and an overall 1.8% dcg improvement overall all query traffic. For short queries, bigram language model improves the dcg gain from 4.4% to 4.7%, and reduces stemming cost from 272/272 to 150/272. For long queries, bigram language model improves dcg gain from 1.1% to 2.5%, and reduces stemming cost from 136/136 to 100/136. We observe that the bigram language model gives a larger lift for long queries. This is because the uncertainty in long queries is larger and a more powerful language model is needed. We hypothesize that a trigram language model would give a further lift for long queries and leave this for future investigation. Considering the tight upper-bound 2 on the improvement to be gained from pluralization handling (via the oracle model), the current performance on short queries is very satisfying. For short queries, the dcg gain upper-bound is 6.3% for perfect pluralization handling, our current gain is 4.7% with a bigram language model. For long queries, the dcg gain upper-bound is 4.6% for perfect pluralization handling, our current gain is 2.5% with a bigram language model. We may gain additional benefit with a more powerful language model for long queries. However, the difficulties of long queries come from many other aspects including the proximity and the segmentation problem. These problems have to be addressed separately. Looking at the the upper-bound of overhead reduction for oracle stemming, 75% (308/408) of the naive stemmings are wasteful. We currently capture about half of them. Further reduction of the overhead requires sacrificing the dcg gain. Now we can compare the stemming strategies from a different aspect. Instead of looking at the influence over all queries as we described above, Table 6 summarizes the dcg improvements over the affected queries only. We can see that the number of affected queries decreases as the stemming strategy becomes more accurate (dcg improvement). For the bigram language model, over the 250/408 stemmed queries, the dcg improvement is 6.1%. An interesting observation is the average dcg decreases with a better model, which indicates a better stemming strategy stems more difficult queries (low dcg queries). 5. DISCUSSIONS 5.1 Language models from query vs. from Web As we mentioned in Section 1, we are trying to predict the probability of a string occurring on the Web. The language model should describe the occurrence of the string on the Web. However, the query log is also a good resource. 2 Note that this upperbound is for pluralization handling only, not for general stemming. General stemming gives a 8% upperbound, which is quite substantial in terms of our metrics. Affected Queries dcg dcg Improvement p-value baseline 0/408 7.102 N/A N/A naive model 408/408 7.206 1.5% 0.22 document context sensitive model 408/408 7.302 2.8% 0.014 selective model: unigram LM 300/408 7.321 3.4% 0.001 selective model: bigram LM 250/408 7.381 3.9% 0.001 oracle model 100/408 7.519 5.9% 0.001 Table 4: Results comparison of different stemming strategies over all queries affected by naive stemming Short Query Results Affected Queries dcg Improvement p-value baseline 0/272 N/A N/A naive model 272/272 2.7% 0.48 document context sensitive model 272/272 4.2% 0.002 selective model: unigram LM 185/272 4.4% 0.001 selective model: bigram LM 150/272 4.7% 0.001 oracle model 71/272 6.3% 0.001 Long Query Results Affected Queries dcg Improvement p-value baseline 0/136 N/A N/A naive model 136/136 -2.4% 0.25 document context sensitive model 136/136 -1.6% 0.27 selective model: unigram LM 115/136 1.1% 0.001 selective model: bigram LM 100/136 2.5% 0.001 oracle model 29/136 4.6% 0.001 Table 5: Results comparison of different stemming strategies overall short queries and long queries Users reformulate a query using many different variants to get good results. To test the hypothesis that we can learn reliable transformation probabilities from the query log, we trained a language model from the same query top 25M queries as used to learn segmentation, and use that for prediction. We observed a slight performance decrease compared to the model trained on Web frequencies. In particular, the performance for unigram LM was not affected, but the dcg gain for bigram LM changed from 4.7% to 4.5% for short queries. Thus, the query log can serve as a good approximation of the Web frequencies. 5.2 How linguistics helps Some linguistic knowledge is useful in stemming. For the pluralization handling case, pluralization and de-pluralization is not symmetric. A plural word used in a query indicates a special intent. For example, the query new york hotels is looking for a list of hotels in new york, not the specific new york hotel which might be a hotel located in California. A simple equivalence of hotel to hotels might boost a particular page about new york hotel to top rank. To capture this intent, we have to make sure the document is a general page about hotels in new york. We do this by requiring that the plural word hotels appears in the document. On the other hand, converting a singular word to plural is safer since a general purpose page normally contains specific information. We observed a slight overall dcg decrease, although not statistically significant, for document context sensitive stemming if we do not consider this asymmetric property. 5.3 Error analysis One type of mistakes we noticed, though rare but seriously hurting relevance, is the search intent change after stemming. Generally speaking, pluralization or depluralization keeps the original intent. However, the intent could change in a few cases. For one example of such a query, job at apple, we pluralize job to jobs. This stemming makes the original query ambiguous. The query job OR jobs at apple has two intents. One is the employment opportunities at apple, and another is a person working at Apple, Steve Jobs, who is the CEO and co-founder of the company. Thus, the results after query stemming returns Steve Jobs as one of the results in top 5. One solution is performing results set based analysis to check if the intent is changed. This is similar to relevance feedback and requires second phase ranking. A second type of mistakes is the entity/concept recognition problem, These include two kinds. One is that the stemmed word variant now matches part of an entity or concept. For example, query cookies in san francisco is pluralized to cookies OR cookie in san francisco. The results will match cookie jar in san francisco. Although cookie still means the same thing as cookies, cookie jar is a different concept. Another kind is the unstemmed word matches an entity or concept because of the stemming of the other words. For example, quote ICE is pluralized to quote OR quotes ICE. The original intent for this query is searching for stock quote for ticker ICE. However, we noticed that among the top results, one of the results is Food quotes: Ice cream. This is matched because of Affected Queries old dcg new dcg dcg Improvement naive model 408/408 7.102 7.206 1.5% document context sensitive model 408/408 7.102 7.302 2.8% selective model: unigram LM 300/408 5.904 6.187 4.8% selective model: bigram LM 250/408 5.551 5.891 6.1% Table 6: Results comparison over the stemmed queries only: column old/new dcg is the dcg score over the affected queries before/after applying stemming the pluralized word quotes. The unchanged word ICE matches part of the noun phrase ice cream here. To solve this kind of problem, we have to analyze the documents and recognize cookie jar and ice cream as concepts instead of two independent words. A third type of mistakes occurs in long queries. For the query bar code reader software, two words are pluralized. code to codes and reader to readers. In fact, bar code reader in the original query is a strong concept and the internal words should not be changed. This is the segmentation and entity and noun phrase detection problem in queries, which we actively are attacking. For long queries, we should correctly identify the concepts in the query, and boost the proximity for the words within a concept. 6. CONCLUSIONS AND FUTURE WORK We have presented a simple yet elegant way of stemming for Web search. It improves naive stemming in two aspects: selective word expansion on the query side and conservative word occurrence matching on the document side. Using pluralization handling as an example, experiments on a major Web search engine data show it significantly improves the Web relevance and reduces the stemming cost. It also significantly improves Web click through rate (details not reported in the paper). For the future work, we are investigating the problems we identified in the error analysis section. These include: entity and noun phrase matching mistakes, and improved segmentation. 7. REFERENCES [1] E. Agichtein, E. Brill, and S. T. Dumais. Improving Web Search Ranking by Incorporating User Behavior Information. In SIGIR, 2006. [2] E. Airio. Word Normalization and Decompounding in Mono- and Bilingual IR. Information Retrieval, 9:249-271, 2006. [3] P. Anick. Using Terminological Feedback for Web Search Refinement: a Log-based Study. In SIGIR, 2003. [4] R. Baeza-Yates and B. Ribeiro-Neto. Modern Information Retrieval. ACM Press/Addison Wesley, 1999. [5] S. Chen and J. Goodman. An Empirical Study of Smoothing Techniques for Language Modeling. Technical Report TR-10-98, Harvard University, 1998. [6] S. Cronen-Townsend, Y. Zhou, and B. Croft. A Framework for Selective Query Expansion. In CIKM, 2004. [7] H. Fang and C. Zhai. Semantic Term Matching in Axiomatic Approaches to Information Retrieval. In SIGIR, 2006. [8] W. B. Frakes. Term Conflation for Information Retrieval. In C. J. Rijsbergen, editor, Research and Development in Information Retrieval, pages 383-389. Cambridge University Press, 1984. [9] D. Harman. How Effective is Suffixing? JASIS, 42(1):7-15, 1991. [10] D. Hull. Stemming Algorithms - A Case Study for Detailed Evaluation. JASIS, 47(1):70-84, 1996. [11] K. Jarvelin and J. Kekalainen. Cumulated Gain-Based Evaluation Evaluation of IR Techniques. ACM TOIS, 20:422-446, 2002. [12] R. Jones, B. Rey, O. Madani, and W. Greiner. Generating Query Substitutions. In WWW, 2006. [13] W. Kraaij and R. Pohlmann. Viewing Stemming as Recall Enhancement. In SIGIR, 1996. [14] R. Krovetz. Viewing Morphology as an Inference Process. In SIGIR, 1993. [15] D. Lin. Automatic Retrieval and Clustering of Similar Words. In COLING-ACL, 1998. [16] J. B. Lovins. Development of a Stemming Algorithm. Mechanical Translation and Computational Linguistics, II:22-31, 1968. [17] M. Lennon and D. Peirce and B. Tarry and P. Willett. An Evaluation of Some Conflation Algorithms for Information Retrieval. Journal of Information Science, 3:177-188, 1981. [18] M. Porter. An Algorithm for Suffix Stripping. Program, 14(3):130-137, 1980. [19] K. M. Risvik, T. Mikolajewski, and P. Boros. Query Segmentation for Web Search. In WWW, 2003. [20] S. E. Robertson. On Term Selection for Query Expansion. Journal of Documentation, 46(4):359-364, 1990. [21] G. Salton and C. Buckley. Improving Retrieval Performance by Relevance Feedback. JASIS, 41(4):288 - 297, 1999. [22] R. Sun, C.-H. Ong, and T.-S. Chua. Mining Dependency Relations for Query Expansion in Passage Retrieval. In SIGIR, 2006. [23] C. Van Rijsbergen. Information Retrieval. Butterworths, second version, 1979. [24] B. V´elez, R. Weiss, M. A. Sheldon, and D. K. Gifford. Fast and Effective Query Refinement. In SIGIR, 1997. [25] J. Xu and B. Croft. Query Expansion using Local and Global Document Analysis. In SIGIR, 1996. [26] J. Xu and B. Croft. Corpus-based Stemming using Cooccurrence of Word Variants. ACM TOIS, 16 (1):61-81, 1998.",
    "original_translation": "Stemming sensible al contexto para la búsqueda web Fuchun Peng Nawaaz Ahmed Xin Li Yumao Lu Yahoo! Tradicionalmente, el truncamiento se ha aplicado a tareas de Recuperación de Información transformando las palabras en documentos a su forma raíz antes de indexarlas, y aplicando una transformación similar a los términos de consulta. Aunque aumenta la recuperación, esta estrategia ingenua no funciona bien para la Búsqueda en la Web, ya que disminuye la precisión y requiere una cantidad significativa de cálculos adicionales. En este artículo, proponemos un método de derivación sensible al contexto que aborda estos dos problemas. Dos propiedades únicas hacen que nuestro enfoque sea factible para la Búsqueda en la Web. Primero, basados en modelado estadístico del lenguaje, realizamos un análisis sensible al contexto en el lado de la consulta. Predecimos con precisión cuál de sus variantes morfológicas es útil para expandir un término de consulta antes de enviar la consulta al motor de búsqueda. Esto reduce drásticamente la cantidad de expansiones incorrectas, lo que a su vez disminuye el costo de la computación adicional y mejora la precisión al mismo tiempo. Segundo, nuestro enfoque realiza una coincidencia de documentos sensible al contexto para esas variantes ampliadas. Esta estrategia conservadora sirve como salvaguarda contra el truncamiento espurio, y resulta ser muy importante para mejorar la precisión. Usando el manejo de la pluralización de palabras como un ejemplo de nuestro enfoque de derivación, nuestros experimentos en un importante motor de búsqueda web muestran que al derivar solo el 29% del tráfico de consultas, podemos mejorar la relevancia medida por la Ganancia Acumulativa Descontada promedio (DCG5) en un 6.1% en estas consultas y en un 1.8% sobre todo el tráfico de consultas. Categorías y Descriptores de Asignaturas H.3.3 [Sistemas de Información]: Almacenamiento y Recuperación de Información-Formulación de Consultas Términos Generales Algoritmos, Experimentación 1. INTRODUCCIÓN La búsqueda en la web se ha convertido en una herramienta importante en nuestra vida diaria para buscar información. Uno de los problemas importantes en la búsqueda web es que las consultas de los usuarios a menudo no están formuladas de la mejor manera para obtener resultados óptimos. Por ejemplo, \"zapatilla para correr\" es una consulta que ocurre con frecuencia en los registros de consulta. Sin embargo, es mucho más probable que la búsqueda \"zapatillas para correr\" proporcione mejores resultados de búsqueda que la consulta original, ya que los documentos que coinciden con la intención de esta consulta suelen contener las palabras \"zapatillas para correr\". Formular correctamente una consulta requiere que el usuario prediga con precisión qué forma de palabra se utiliza en los documentos que mejor satisfacen sus necesidades de información. Esto es difícil incluso para usuarios experimentados, y especialmente difícil para hablantes no nativos. Una solución tradicional es utilizar el stemming [16, 18], el proceso de transformar palabras flexionadas o derivadas a su forma raíz para que un término de búsqueda coincida y recupere documentos que contengan todas las formas del término. Por lo tanto, la palabra \"run\" coincidirá con \"running\", \"ran\", \"runs\", y \"shoe\" coincidirá con \"shoes\" y \"shoeing\". El truncamiento se puede realizar tanto en los términos de un documento durante la indexación (y aplicando la misma transformación a los términos de la consulta durante el procesamiento de la consulta) o expandiendo la consulta con las variantes durante el procesamiento de la consulta. El truncamiento durante la indexación permite muy poca flexibilidad durante el procesamiento de consultas, mientras que el truncamiento mediante la expansión de consultas permite manejar cada consulta de manera diferente, y por lo tanto es preferible. Aunque el truncamiento tradicional aumenta la recuperación al emparejar variantes de palabras [13], puede reducir la precisión al recuperar demasiados documentos que han sido emparejados incorrectamente. Al examinar los resultados de aplicar el truncamiento a un gran número de consultas, generalmente se encuentra que casi igual cantidad de consultas se benefician y se ven perjudicadas por la técnica [6]. Además, reduce el rendimiento del sistema porque el motor de búsqueda tiene que hacer coincidir todas las variantes de palabras. Como mostraremos en los experimentos, esto es cierto incluso si simplificamos el proceso de derivación a la manipulación de pluralización, que es el proceso de convertir una palabra de su forma plural a singular, o viceversa. Por lo tanto, es necesario ser muy cauteloso al utilizar el stemming en los motores de búsqueda web. Un problema del truncamiento tradicional es su transformación ciega de todos los términos de consulta, es decir, siempre realiza la misma transformación para la misma palabra de consulta sin considerar el contexto de la palabra. Por ejemplo, la palabra \"book\" tiene cuatro formas: book, books, booking, booked, y la palabra \"store\" tiene cuatro formas: store, stores, storing, stored. Para la consulta de la librería, expandir ambas palabras a todas sus variantes aumenta significativamente el costo de computación y perjudica la precisión, ya que no todas las variantes son útiles para esta consulta. Transformar librería para que coincida con librerías está bien, pero hacer coincidir almacenamiento de libros o tienda de reservas no lo está. Un método de ponderación que otorga pesos más pequeños a las palabras variantes alivia los problemas hasta cierto punto si los pesos reflejan con precisión la importancia de la variante en esta consulta particular. Sin embargo, el peso uniforme no va a funcionar y un peso dependiente de la consulta sigue siendo un problema desafiante sin resolver [20]. Un segundo problema del truncamiento tradicional es su emparejamiento ciego de todas las ocurrencias en los documentos. Para la consulta de la librería, una transformación que permita que las tiendas variantes se emparejen hará que cada aparición de tiendas en el documento se trate de manera equivalente al término de consulta tienda. Por lo tanto, se emparejará un documento que contenga el fragmento de leer un libro en las cafeterías, lo que provocará que se seleccionen muchos documentos incorrectos. Aunque esperamos que la función de clasificación pueda manejar correctamente estos, con muchos más candidatos para clasificar, el riesgo de cometer errores aumenta. Para aliviar estos dos problemas, proponemos un enfoque de reducción de palabras raíz sensible al contexto para la búsqueda en la web. Nuestra solución consiste en dos análisis contextuales sensibles, uno en el lado de la consulta y otro en el lado del documento. En el lado de la consulta, proponemos un enfoque basado en modelado del lenguaje estadístico para predecir qué variantes de palabras son mejores formas que la palabra original con fines de búsqueda y expandir la consulta solo con esas formas. En el lado del documento, proponemos un emparejamiento conservador sensible al contexto para las variantes de palabras transformadas, solo emparejando las ocurrencias en el documento en el contexto de otros términos en la consulta. Nuestro modelo es simple pero efectivo y eficiente, lo que lo hace factible de ser utilizado en motores de búsqueda web comerciales reales. Utilizamos el manejo de pluralización como un ejemplo continuo para nuestro enfoque de derivación. La motivación para usar el manejo de pluralización como ejemplo es mostrar que incluso un truncamiento tan simple, si se maneja correctamente, puede brindar beneficios significativos a la relevancia de la búsqueda. Hasta donde sabemos, ninguna investigación previa ha investigado sistemáticamente el uso de la pluralización en la búsqueda en la web. Como debemos señalar, el método que proponemos no se limita al manejo de la pluralización, es una técnica de derivación general y también se puede aplicar a la expansión de consultas en general. Los experimentos sobre el truncamiento general producen mejoras significativas adicionales sobre el manejo de la pluralización para consultas largas, aunque los detalles no se informarán en este artículo. En el resto del documento, primero presentamos el trabajo relacionado y distinguimos nuestro método de trabajos anteriores en la Sección 2. Describimos los detalles del enfoque de derivación sensible al contexto en la Sección 3. Luego realizamos experimentos extensos en un importante motor de búsqueda web para respaldar nuestras afirmaciones en la Sección 4, seguidos de discusiones en la Sección 5. Finalmente, concluimos el artículo en la Sección 6.2. TRABAJO RELACIONADO El stemming es una tecnología estudiada desde hace mucho tiempo. Se han desarrollado muchos stemmers, como el stemmer Lovins [16] y el stemmer Porter [18]. El stemmer de Porter es ampliamente utilizado debido a su simplicidad y efectividad en muchas aplicaciones. Sin embargo, el algoritmo de Porter comete muchos errores porque sus reglas simples no pueden describir completamente la morfología del inglés. El análisis de corpus se utiliza para mejorar el stemmer de Porter [26] mediante la creación de clases de equivalencia para palabras que son morfológicamente similares y que ocurren en un contexto similar, medido por la información mutua esperada [23]. Utilizamos un enfoque de corpus similar para el stemming al calcular la similitud entre dos palabras basada en sus características de contexto distribucional, que pueden ser más que solo palabras adyacentes [15], y luego solo mantenemos las palabras morfológicamente similares como candidatas. El uso de la derivación en la recuperación de información también es una técnica bien conocida [8, 10]. Sin embargo, se informó previamente que la efectividad del truncamiento para los sistemas de consulta en inglés era bastante limitada. Lennon et al. [17] compararon los algoritmos de Lovins y Porter y encontraron poco mejoramiento en el rendimiento de recuperación. Más tarde, Harman [9] compara tres técnicas generales de derivación en experimentos de recuperación de texto, incluido el manejo de pluralización (llamado S stemmer en el artículo). También propusieron el truncamiento selectivo basado en la longitud de la consulta y la importancia del término, pero no se informaron resultados positivos. Por otro lado, Krovetz [14] realizó comparaciones sobre un pequeño número de documentos (de 400 a 12k) y mostró una mejora dramática en la precisión (de hasta un 45%). Sin embargo, debido al número limitado de consultas probadas (menos de 100) y al tamaño reducido de la colección, los resultados son difíciles de generalizar para la búsqueda en la web. Estos resultados mixtos, en su mayoría fracasos, llevaron a los primeros investigadores de IR a considerar que el truncamiento era irrelevante en general para el inglés [4], aunque investigaciones recientes han demostrado que el truncamiento tiene mayores beneficios para la recuperación en otros idiomas [2]. Sospechamos que los fracasos anteriores se debieron principalmente a los dos problemas que mencionamos en la introducción. El stemming ciego, o un stemming selectivo basado en la longitud de la consulta como se utiliza en [9], no es suficiente. El truncamiento debe decidirse caso por caso, no solo a nivel de consulta sino también a nivel de documento. Como demostraremos, si se maneja correctamente, se puede lograr una mejora significativa. Un problema más general relacionado con el stemming es la reformulación de consultas [3, 12] y la expansión de consultas que amplía las palabras no solo con variantes de palabras [7, 22, 24, 25]. Para decidir qué palabras expandidas usar, las personas a menudo utilizan técnicas de retroalimentación de seudorelevancia que envían la consulta original a un motor de búsqueda y recuperan los documentos principales, extraen palabras relevantes de estos documentos principales como palabras de consulta adicionales y vuelven a enviar la consulta expandida nuevamente [21]. Esto normalmente requiere enviar una consulta varias veces al motor de búsqueda y no es rentable para procesar la gran cantidad de consultas involucradas en la búsqueda web. Además, la expansión de consultas, incluida la reformulación de consultas [3, 12], tiene un alto riesgo de cambiar la intención del usuario (llamado desviación de consulta). Dado que las palabras expandidas pueden tener diferentes significados, agregarlas a la consulta podría potencialmente cambiar la intención de la consulta original. Por lo tanto, la expansión de consultas basada en pseudorelevancia y la reformulación de consultas pueden proporcionar sugerencias a los usuarios para su refinamiento interactivo, pero difícilmente pueden ser utilizadas directamente para la búsqueda en la web. Por otro lado, el truncamiento es mucho más conservador ya que la mayoría de las veces, conserva la intención de búsqueda original. Si bien la mayoría de los trabajos sobre la expansión de consultas se centran en mejorar la recuperación, nuestro trabajo se enfoca en aumentar tanto la recuperación como la precisión. El aumento en el recuerdo es evidente. Con el stemming de calidad, los buenos documentos que no fueron seleccionados antes del stemming serán promovidos y aquellos documentos de baja calidad serán degradados. En la expansión selectiva de consultas, Cronen-Townsend et al. [6] propusieron un método para la expansión selectiva de consultas basado en comparar la divergencia de Kullback-Leibler de los resultados de la consulta no expandida y los resultados de la consulta expandida. Esto es similar a la retroalimentación de relevancia en el sentido de que requiere múltiples pasadas de recuperación. Si una palabra puede expandirse en varias palabras, se requiere ejecutar este proceso varias veces para decidir cuál palabra expandida es útil. Es costoso implementar esto en motores de búsqueda web en producción. Nuestro método predice la calidad de la expansión basándose en información sin conexión sin enviar la consulta a un motor de búsqueda. En resumen, proponemos un enfoque novedoso para abordar un problema antiguo, pero aún importante y desafiante para la búsqueda en la web: el stemming. Nuestro enfoque es único en el sentido de que realiza el truncamiento predictivo de forma individualizada para cada consulta sin retroalimentación de relevancia de la Web, utilizando el contexto de las variantes en los documentos para preservar la precisión. Es simple, pero muy eficiente y efectivo, lo que hace factible el truncamiento en tiempo real para la búsqueda en la web. Nuestros resultados confirmarán a los investigadores que el truncamiento es realmente muy importante para la recuperación de información a gran escala. STEMMING CONTEXTUAL SENSIBLE 3.1 Resumen Nuestro sistema tiene cuatro componentes como se ilustra en la Figura 1: generación de candidatos, segmentación de consultas y detección de palabras clave, derivación de consultas sensible al contexto y coincidencia de documentos sensible al contexto. La generación de candidatos (componente 1) se realiza fuera de línea y los candidatos generados se almacenan en un diccionario. Para una consulta de entrada, primero segmentamos la consulta en conceptos y detectamos la palabra principal de cada concepto (componente 2). Luego utilizamos modelado de lenguaje estadístico para decidir si una variante particular es útil (componente 3), y finalmente, para las variantes expandidas, realizamos un emparejamiento de documentos sensible al contexto (componente 4). A continuación discutimos cada uno de los componentes con más detalle. Componente 4: coincidencia de documentos sensibles al contexto Consulta de entrada: y detección de palabras clave Componente 2: segmento Componente 1: generación de candidatos comparaciones −> comparación Componente 3: decisión de expansión selectiva de palabras: comparaciones −> comparación ejemplo: comparaciones de precios de hoteles salida: comparaciones de hoteles hotel −> hoteles Figura 1: Componentes del sistema 3.2 Generación de candidatos de expansión Una de las formas de generar candidatos es utilizando el stemmer de Porter [18]. El stemmer de Porter simplemente utiliza reglas morfológicas para convertir una palabra a su forma base. No tiene conocimiento del significado semántico de las palabras y a veces comete errores graves, como cambiar \"executive\" por \"execution\", \"news\" por \"new\" y \"paste\" por \"past\". Una forma más conservadora se basa en utilizar análisis de corpus para mejorar los resultados del stemmer de Porter [26]. El análisis de corpus que realizamos se basa en la similitud distribucional de palabras [15]. La razón de utilizar la similitud distribucional de palabras es que las variantes verdaderas tienden a ser utilizadas en contextos similares. En el cálculo de similitud de palabras distribucionales, cada palabra se representa con un vector de características derivadas del contexto de la palabra. Utilizamos los bigramas a la izquierda y a la derecha de la palabra como sus características de contexto, mediante la extracción de un gran corpus web. La similitud entre dos palabras es la similitud coseno entre los dos vectores de características correspondientes. Las 20 palabras similares a \"desarrollar\" se muestran en la siguiente tabla. rango candidato puntaje rango candidato puntaje 0 desarrollar 1 10 berts 0.119 1 desarrollando 0.339 11 wads 0.116 2 desarrollado 0.176 12 desarrollador 0.107 3 incubadora 0.160 13 promoviendo 0.100 4 desarrolla 0.150 14 desarrollo 0.091 5 desarrollo 0.148 15 reingeniería 0.090 6 tutoría 0.138 16 construir 0.083 7 analizando 0.128 17 construir 0.081 8 desarrollo 0.128 18 educativo 0.081 9 automatización 0.126 19 instituto 0.077 Tabla 1: Los 20 candidatos más similares a la palabra \"desarrollar\". La puntuación de la columna es la puntuación de similitud. Para determinar los candidatos de derivación, aplicamos algunas reglas morfológicas del stemmer de Porter [18] a la lista de similitud. Después de aplicar estas reglas, para la palabra desarrollar, los candidatos de derivación son desarrollando, desarrollado, desarrolla, desarrollo, desarrollo, desarrollador, y desarrollo. Para el propósito de manejo de pluralización, solo se conserva el candidato desarrolla. Una cosa que observamos al observar las palabras distribucionalmente similares es que están estrechamente relacionadas semánticamente. Estas palabras podrían servir como candidatas para la expansión general de consultas, un tema que investigaremos en el futuro. 3.3 Segmentación e identificación de palabras clave Para consultas largas, es bastante importante detectar los conceptos en la consulta y las palabras más importantes para esos conceptos. Primero dividimos una consulta en segmentos, cada segmento representando un concepto que normalmente es una frase nominal. Para cada una de las frases nominales, luego detectamos la palabra más importante a la que llamamos la palabra principal. La segmentación también se utiliza en la coincidencia sensible a documentos (sección 3.5) para hacer cumplir la proximidad. Para dividir una consulta en segmentos, tenemos que definir un criterio para medir la fuerza de la relación entre las palabras. Un método efectivo es utilizar la información mutua como indicador para decidir si dividir o no dos palabras [19]. Utilizamos un registro de 25 millones de consultas y recopilamos las frecuencias de bigramas y unigramas a partir de él. Para cada consulta entrante, calculamos la información mutua de dos palabras adyacentes; si supera un umbral predefinido, no dividimos la consulta entre esas dos palabras y pasamos a la siguiente palabra. Continuamos este proceso hasta que la información mutua entre dos palabras esté por debajo del umbral, luego creamos un límite conceptual aquí. La Tabla 2 muestra algunos ejemplos de segmentación de consultas. La forma ideal de encontrar la palabra principal de un concepto es realizar un análisis sintáctico para determinar la estructura de dependencia de la consulta. El análisis de consultas es más difícil que el análisis de oraciones, ya que muchas consultas no son gramaticales y son muy cortas. Aplicar un analizador entrenado en oraciones de documentos a consultas tendrá un rendimiento deficiente. En nuestra solución, solo utilizamos reglas heurísticas simples, y funciona muy bien en la práctica para el inglés. Para una frase nominal en inglés, la palabra principal suele ser la última palabra no detenida, a menos que la frase siga un patrón particular, como XYZ de/en/a/desde UVW. En tales casos, la palabra principal suele ser la última palabra no detenida de XYZ. 3.4 Expansión de palabras sensibles al contexto Después de detectar cuáles son las palabras más importantes para expandir, debemos decidir si las expansiones serán útiles. Nuestras estadísticas muestran que aproximadamente la mitad de las consultas pueden ser transformadas mediante la pluralización a través de un truncamiento ingenuo. Entre esta mitad, aproximadamente el 25% de las consultas mejoran la relevancia cuando se transforman, la mayoría (alrededor del 50%) no cambian sus 5 resultados principales, y el 25% restante tiene un rendimiento peor. Por lo tanto, es extremadamente importante identificar qué consultas no deben ser truncadas con el fin de maximizar la mejora de relevancia y minimizar el costo de truncamiento. Además, para una consulta con múltiples palabras que pueden ser transformadas, o una palabra con múltiples variantes, no todas las expansiones son útiles. Tomando la comparación de precios de hoteles como ejemplo, decidimos que hotel y comparación de precios son dos conceptos. Las palabras clave hotel y comparación se pueden expandir a hoteles y comparaciones. ¿Son útiles ambas transformaciones? Para probar si una expansión es útil, tenemos que saber si es probable que la consulta expandida obtenga más documentos relevantes de la web, lo cual puede cuantificarse mediante la probabilidad de que la consulta ocurra como una cadena en la web. Cuanto más probable sea que ocurra una consulta en la web, más documentos relevantes puede devolver esta consulta. Ahora todo el problema se convierte en cómo calcular la probabilidad de que ocurra la consulta en la Web. Calcular la probabilidad de que una cadena ocurra en un corpus es un problema bien conocido de modelado del lenguaje. El objetivo del modelado del lenguaje es predecir la probabilidad de secuencias de palabras que ocurren naturalmente, s = w1w2...wN; o más simplemente, asignar una alta probabilidad a las secuencias de palabras que realmente ocurren (y una baja probabilidad a las secuencias de palabras que nunca ocurren). El enfoque más simple y exitoso para el modelado del lenguaje sigue estando basado en el modelo n-gramo. Por la regla de la cadena de probabilidad, se puede escribir la probabilidad de cualquier secuencia de palabras como Pr(w1w2...wN) = ΠY i=1 Pr(wi|w1...wi−1) (1). Un modelo n-grama aproxima esta probabilidad asumiendo que las únicas palabras relevantes para predecir Pr(wi|w1...wi−1) son las n − 1 palabras anteriores; es decir, La probabilidad de una palabra wi dado w1...wi−1 es igual a la probabilidad de wi dado wi−n+1...wi−1. Una estimación directa de máxima verosimilitud de las probabilidades de n-gramas a partir de un corpus se obtiene a partir de la frecuencia observada de cada uno de los patrones Pr(wi|wi−n+1...wi−1) = #(wi−n+1...wi) #(wi−n+1...wi−1) donde #(.) denota el número de ocurrencias de un n-grama específico en el corpus de entrenamiento. Aunque se podría intentar usar modelos de n-gramos simples para capturar dependencias a largo plazo en el lenguaje, intentar hacerlo directamente crea inmediatamente problemas de datos dispersos: Utilizar n-gramos de longitud hasta n implica estimar la probabilidad de eventos de longitud Wn, donde W es el tamaño del vocabulario de palabras. Esto rápidamente abruma los recursos computacionales y de datos modernos incluso para opciones modestas de n (más allá de 3 a 6). Además, debido a la naturaleza de cola pesada del lenguaje (es decir, La ley de Zipf) es probable que uno se encuentre con n-gramas novedosos que nunca fueron observados durante el entrenamiento en ningún corpus de prueba, por lo tanto, algún mecanismo para asignar una probabilidad distinta de cero a los n-gramas novedosos es un problema central e inevitable en la modelización estadística del lenguaje. Un enfoque estándar para suavizar las estimaciones de probabilidad para hacer frente a problemas de datos escasos (y para hacer frente a posibles n-gramas faltantes) es utilizar algún tipo de estimador de retroceso. Pr(wi|wi−n+1...wi−1) = 8 >>< >>: ˆPr(wi|wi−n+1...wi−1), si #(wi−n+1...wi) > 0 β(wi−n+1...wi−1) × Pr(wi|wi−n+2...wi−1), de lo contrario (3) donde ˆPr(wi|wi−n+1...wi−1) = descuento #(wi−n+1...wi) #(wi−n+1...wi−1) (4) es la probabilidad descontada y β(wi−n+1...wi−1) es una constante de normalización β(wi−n+1...wi−1) = 1 − X x∈(wi−n+1...wi−1x) ˆPr(x|wi−n+1...wi−1) 1 − X x∈(wi−n+1...wi−1x) ˆPr(x|wi−n+2...wi−1) (5) La probabilidad descontada (4) se puede calcular con diferentes técnicas de suavizado, incluido el suavizado absoluto, el suavizado de Good-Turing, el suavizado lineal y el suavizado de Witten-Bell [5]. Utilizamos suavizado absoluto en nuestros experimentos. Dado que la probabilidad de una cadena, Pr(w1w2...wN), es un número muy pequeño y difícil de interpretar, utilizamos la entropía, tal como se define a continuación, para puntuar la cadena. Entropía = − 1 N log2 Pr(w1w2...wN ) (6) Ahora volviendo al ejemplo de la comparación de precios de hoteles, hay cuatro variantes de esta consulta, y la entropía de estos cuatro candidatos se muestra en la Tabla 3. Podemos ver que todas las alternativas son menos probables que la consulta de entrada. Por lo tanto, no es útil hacer una expansión para esta consulta. Por otro lado, si la consulta de entrada son comparaciones de precios de hoteles, que es la segunda alternativa en la tabla, entonces hay una mejor alternativa que la consulta de entrada, y por lo tanto debería ser ampliada. Para tolerar las variaciones en la estimación de probabilidad, relajamos el criterio de selección para esas alternativas de consulta si sus puntuaciones están dentro de una cierta distancia (10% en nuestros experimentos) de la mejor puntuación. Variaciones de la consulta Comparación de precios de hoteles 6.177 comparaciones de precios de hoteles 6.597 comparación de precios de hoteles 6.937 comparaciones de precios de hoteles 7.360 Tabla 3: Variaciones de la consulta comparación de precios de hoteles clasificadas por puntaje de entropía, con la consulta original en negrita. 3.5 Coincidencia de documentos sensibles al contexto Aun después de saber qué variantes de palabras son probablemente útiles, debemos ser conservadores en la coincidencia de documentos para las variantes ampliadas. Para la consulta de comparaciones de precios de hoteles, decidimos que la palabra \"comparaciones\" se amplía para incluir \"comparación\". Sin embargo, no todos los casos de comparación en el documento son de interés. Una página que trata sobre comparar el servicio al cliente puede contener todas las palabras comparaciones de precios de hoteles comparación. Esta página no es una buena página para la consulta. Si aceptamos coincidencias de cada ocurrencia de comparación, afectará la precisión de recuperación y esta es una de las principales razones por las que la mayoría de los enfoques de derivación no funcionan bien para la recuperación de información. Para abordar este problema, tenemos una restricción de proximidad que considera el contexto alrededor de la variante expandida en el documento. Una coincidencia de variante se considera válida solo si la variante ocurre en el mismo contexto que la palabra original lo hace. El contexto son los segmentos continuos de la izquierda o de la derecha de la palabra original. Tomando la misma consulta como ejemplo, el contexto de las comparaciones es el precio. La comparación de palabras ampliada solo es válida si está en el mismo contexto de comparaciones, que es después de la palabra precio. Por lo tanto, solo debemos emparejar aquellas ocurrencias de comparación en el documento si ocurren después de la palabra precio. Considerando el hecho de que las consultas y los documentos pueden no representar la intención de la misma manera exacta, relajamos esta restricción de proximidad para permitir ocurrencias variantes dentro de una ventana de un tamaño fijo. Si la comparación de palabras expandidas ocurre dentro del contexto de precio dentro de una ventana, se considera válida. Cuanto más pequeño sea el tamaño de la ventana, más restrictiva será la coincidencia. Utilizamos un tamaño de ventana de 4, que normalmente captura contextos que incluyen las frases nominales que contienen y las adyacentes. 4. EVALUACIÓN EXPERIMENTAL 4.1 Métricas de evaluación Mediremos tanto la mejora de relevancia como el costo de derivación necesario para lograr la relevancia. 1 un segmento de contexto no puede ser una sola palabra de parada. 4.1.1 Medición de relevancia Utilizamos una variante de la Ganancia Acumulada Descontada Promedio (DCG), un esquema recientemente popularizado para medir la relevancia de los motores de búsqueda [1, 11]. Dada una consulta y una lista clasificada de K documentos (K se establece en 5 en nuestros experimentos), el puntaje DCG(K) para esta consulta se calcula de la siguiente manera: DCG(K) = Σ k=1 a K gk log2(1 + k) . (7) donde gk es el peso para el documento en la posición k. Un mayor grado de relevancia corresponde a un peso mayor. Una página se califica en una de las cinco escalas: Perfecto, Excelente, Bueno, Regular, Malo, con pesos correspondientes. Utilizamos DCG para representar el DCG promedio(5) sobre un conjunto de consultas de prueba. 4.1.2 Costo de derivación Otro métrica es medir el costo adicional incurrido por la derivación. Dado el mismo nivel de mejora en la relevancia, preferimos un método de truncamiento que tenga un menor costo adicional. Medimos esto por el porcentaje de consultas que realmente se reducen, sobre todas las consultas que podrían ser reducidas. 4.2 Preparación de datos Muestreamos aleatoriamente 870 consultas de un registro de consultas de tres meses, con 290 de cada mes. Entre todas estas 870 consultas, eliminamos todas las consultas con errores ortográficos ya que las consultas con errores ortográficos no son de interés para el stemming. También eliminamos todas las consultas de una sola palabra, ya que reducir las consultas de una sola palabra sin contexto tiene un alto riesgo de cambiar la intención de la consulta, especialmente para palabras cortas. Al final, tenemos 529 consultas correctamente escritas con al menos 2 palabras. 4.3 Stemming ingenuo para la búsqueda en la Web Antes de explicar en detalle los experimentos y resultados, nos gustaría describir la forma tradicional de usar el stemming para la búsqueda en la Web, conocida como el modelo ingenuo. Esto es para tratar cada variante de palabra equivalente para todas las posibles palabras en la consulta. La consulta de la librería se transformará en (libro O libros)(tienda O tiendas) al limitar el truncamiento al manejo de pluralización solamente, donde O es un operador que denota la equivalencia de los argumentos izquierdo y derecho. 4.4 Configuración experimental El modelo base es el modelo sin truncamiento. Primero ejecutamos el modelo ingenuo para ver qué tan bien se desempeña en comparación con el punto de referencia. Luego mejoramos el modelo de derivación ingenua mediante la coincidencia sensible al documento, denominado modelo de coincidencia sensible al documento. Este modelo realiza el mismo stemming que el modelo ingenuo en el lado de la consulta, pero realiza un emparejamiento conservador en el lado del documento utilizando la estrategia descrita en la sección 3.5. El modelo ingenuo y el modelo de coincidencia sensible al documento son los que mejor responden a la mayoría de las consultas. De las 529 consultas, hay 408 consultas que se originan, lo que corresponde al 46.7% del tráfico de consultas (de un total de 870). Luego mejoramos aún más el modelo de coincidencia sensible de documentos desde el lado de la consulta con un proceso de derivación de palabras selectivo basado en modelado estadístico del lenguaje (sección 3.4), denominado modelo de derivación selectiva. Basado en la predicción del modelado del lenguaje, este modelo deriva solo un subconjunto de las 408 consultas derivadas por el modelo de coincidencia sensible al documento. Experimentamos con un modelo de lenguaje unigrama y un modelo de lenguaje bigrama. Dado que solo nos importa cuánto podemos mejorar el modelo ingenuo, solo utilizaremos estas 408 consultas (todas las consultas que se ven afectadas por el modelo de derivación ingenuo) en los experimentos. Para tener una idea de cómo se desempeñan estos modelos, también tenemos un modelo oráculo que proporciona el rendimiento máximo que un stemmer puede lograr en estos datos. El modelo del oráculo solo expande una palabra si el truncamiento dará mejores resultados. Para analizar la influencia del manejo de la pluralización en diferentes categorías de consultas, dividimos las consultas en consultas cortas y consultas largas. Entre las 408 consultas generadas por el modelo ingenuo, hay 272 consultas cortas con 2 o 3 palabras, y 136 consultas largas con al menos 4 palabras. Resumimos los resultados generales en la Tabla 4, y presentamos los resultados de las consultas cortas y largas por separado en la Tabla 5. Cada fila en la Tabla 4 es una estrategia de derivación descrita en la sección 4.4. La primera columna es el nombre de la estrategia. La segunda columna es el número de consultas afectadas por esta estrategia; esta columna mide el costo de derivación, y los números deberían ser bajos para el mismo nivel de dcg. La tercera columna es la puntuación DCG promedio sobre todas las consultas probadas en esta categoría (incluyendo aquellas que no fueron truncadas por la estrategia). La cuarta columna es la mejora relativa sobre la línea base, y la última columna es el valor p de la prueba de significancia de Wilcoxon. Hay varias observaciones sobre los resultados. Podemos ver que el truncado ingenuo solo logra una mejora estadísticamente insignificante del 1.5%. Mirando la Tabla 5, se observa una mejora del 2.7% en las consultas cortas. Sin embargo, también perjudica las consultas largas en un -2.4%. En general, la mejora se cancela. La razón por la que mejora las consultas cortas es que la mayoría de las consultas cortas solo tienen una palabra que se puede reducir a su raíz. Por lo tanto, pluralizar ciegamente consultas cortas es relativamente seguro. Sin embargo, para consultas largas, la mayoría de las consultas pueden tener varias palabras que pueden ser pluralizadas. Expandir todos ellos sin selección perjudicará significativamente la precisión. La aplicación de un stemming sensible al contexto del documento proporciona un aumento significativo en el rendimiento, desde un 2.7% hasta un 4.2% para consultas cortas y desde un -2.4% hasta un -1.6% para consultas largas, con un aumento general del 1.5% al 2.8%. La mejora proviene de la coincidencia de documentos sensible al contexto conservador. Una palabra expandida es válida solo si ocurre dentro del contexto de la consulta original en el documento. Esto reduce muchas coincidencias falsas. Sin embargo, aún observamos que para consultas largas, el truncamiento sensible al contexto no logra mejorar el rendimiento porque sigue seleccionando demasiados documentos y le presenta a la función de clasificación un problema difícil. Si bien el tamaño de ventana elegido de 4 es el que mejor funciona entre todas las opciones, aún permite coincidencias espurias. Es posible que el tamaño de la ventana deba elegirse según la consulta para garantizar restricciones de proximidad más estrictas para diferentes tipos de frases nominales. La pluralización selectiva de palabras ayuda aún más a resolver el problema enfrentado por el truncamiento sensible al contexto del documento. No se aplica el truncamiento a cada palabra que coloca toda la carga en el algoritmo de clasificación, sino que intenta eliminar el truncamiento innecesario en primer lugar. Al predecir qué variantes de palabras van a ser útiles, podemos reducir drásticamente el número de palabras derivadas, mejorando así tanto la recuperación como la precisión. Con el modelo de lenguaje unigrama, podemos reducir el costo de derivación en un 26.7% (de 408/408 a 300/408) y aumentar la mejora general de DCG del 2.8% al 3.4%. En particular, proporciona mejoras significativas en consultas largas. La ganancia de DCG se cambia de negativa a positiva, de -1.6% a 1.1%. Esto confirma nuestra hipótesis de que reducir la expansión innecesaria de palabras conduce a una mejora en la precisión. Para consultas cortas también observamos tanto la mejora de dcg como la reducción del costo de derivación con el modelo de lenguaje unigrama. Las ventajas de la expansión predictiva de palabras con un modelo de lenguaje se potencian aún más con un mejor modelo de lenguaje de bigrama. La ganancia total de DCG aumenta de 3.4% a 3.9%, y el costo de derivación se reduce drásticamente de 408/408 a 250/408, correspondiente a solo el 29% del tráfico de consultas (250 de 870) y una mejora total de DCG del 1.8% en todo el tráfico de consultas. Para consultas cortas, el modelo de lenguaje de bigrama mejora la ganancia de DCG del 4.4% al 4.7%, y reduce el costo de derivación de 272/272 a 150/272. Para consultas largas, el modelo de lenguaje de bigrama mejora la ganancia de DCG del 1.1% al 2.5%, y reduce el costo de derivación de 136/136 a 100/136. Observamos que el modelo de lenguaje de bigrama proporciona un mayor aumento para consultas largas. Esto se debe a que la incertidumbre en las consultas largas es mayor y se necesita un modelo de lenguaje más potente. Hacemos la hipótesis de que un modelo de lenguaje de trigramas proporcionaría un impulso adicional para consultas largas y dejamos esto para investigaciones futuras. Considerando el límite superior estricto de 2 en la mejora que se puede obtener del manejo de la pluralización (a través del modelo oráculo), el rendimiento actual en consultas cortas es muy satisfactorio. Para consultas breves, la ganancia máxima de DCG es del 6.3% para el manejo perfecto de la pluralización, nuestra ganancia actual es del 4.7% con un modelo de lenguaje de bigrama. Para consultas largas, la ganancia máxima de DCG es del 4.6% para el manejo perfecto de la pluralización, nuestra ganancia actual es del 2.5% con un modelo de lenguaje de bigrama. Podríamos obtener beneficios adicionales con un modelo de lenguaje más potente para consultas largas. Sin embargo, las dificultades de las consultas largas provienen de muchos otros aspectos, incluyendo la proximidad y el problema de la segmentación. Estos problemas deben ser abordados por separado. Al observar el límite superior de reducción de gastos generales para el truncamiento de Oracle, el 75% (308/408) de los truncamientos ingenuos son inútiles. Actualmente capturamos alrededor de la mitad de ellos. La reducción adicional de los gastos generales requiere sacrificar la ganancia de la DCG. Ahora podemos comparar las estrategias de derivación desde un aspecto diferente. En lugar de analizar la influencia sobre todas las consultas como describimos anteriormente, la Tabla 6 resume las mejoras de DCG solo sobre las consultas afectadas. Podemos ver que el número de consultas afectadas disminuye a medida que la estrategia de derivación se vuelve más precisa (mejora en el dcg). Para el modelo de lenguaje de bigrama, sobre las 250/408 consultas truncadas, la mejora en DCG es del 6.1%. Una observación interesante es que el dcg promedio disminuye con un modelo mejor, lo que indica que una estrategia de derivación mejorada deriva consultas más difíciles (consultas con bajo dcg). 5. Como mencionamos en la Sección 1, estamos tratando de predecir la probabilidad de que una cadena ocurra en la Web. El modelo de lenguaje debe describir la ocurrencia de la cadena en la web. Sin embargo, el registro de consultas también es un buen recurso. Tenga en cuenta que este límite superior es solo para el manejo de pluralización, no para el truncamiento general. El stemming general proporciona un límite superior del 8%, lo cual es bastante sustancial en términos de nuestras métricas. Las consultas afectadas dcg dcg Mejora p-valor línea de base 0/408 7.102 N/A N/A modelo ingenuo 408/408 7.206 1.5% 0.22 modelo sensible al contexto del documento 408/408 7.302 2.8% 0.014 modelo selectivo: unigram LM 300/408 7.321 3.4% 0.001 modelo selectivo: bigram LM 250/408 7.381 3.9% 0.001 modelo oráculo 100/408 7.519 5.9% 0.001 Tabla 4: Comparación de resultados de diferentes estrategias de derivación en todas las consultas afectadas por la derivación ingenua Resultados de Consultas Cortas Consultas Afectadas dcg Mejora p-valor línea de base 0/272 N/A N/A modelo ingenuo 272/272 2.7% 0.48 modelo sensible al contexto del documento 272/272 4.2% 0.002 modelo selectivo: unigram LM 185/272 4.4% 0.001 modelo selectivo: bigram LM 150/272 4.7% 0.001 modelo oráculo 71/272 6.3% 0.001 Resultados de Consultas Largas Consultas Afectadas dcg Mejora p-valor línea de base 0/136 N/A N/A modelo ingenuo 136/136 -2.4% 0.25 modelo sensible al contexto del documento 136/136 -1.6% 0.27 modelo selectivo: unigram LM 115/136 1.1% 0.001 modelo selectivo: bigram LM 100/136 2.5% 0.001 modelo oráculo 29/136 4.6% 0.001 Tabla 5: Comparación de resultados de diferentes estrategias de derivación en consultas cortas y largas en general Los usuarios reformulan una consulta utilizando muchas variantes diferentes para obtener buenos resultados. Para probar la hipótesis de que podemos aprender probabilidades de transformación confiables a partir del registro de consultas, entrenamos un modelo de lenguaje con las mismas 25 millones de consultas principales utilizadas para aprender la segmentación, y lo utilizamos para la predicción. Observamos una ligera disminución en el rendimiento en comparación con el modelo entrenado en frecuencias web. En particular, el rendimiento para el modelo de lenguaje unigrama no se vio afectado, pero la ganancia de dcg para el modelo de lenguaje bigrama cambió de 4.7% a 4.5% para consultas cortas. Por lo tanto, el registro de consultas puede servir como una buena aproximación de las frecuencias web. 5.2 Cómo la lingüística ayuda. Algunos conocimientos lingüísticos son útiles en el stemming. Para el manejo de la pluralización, la pluralización y la despluralización no son simétricas. Una palabra en plural utilizada en una consulta indica una intención especial. Por ejemplo, la consulta hoteles en Nueva York está buscando una lista de hoteles en Nueva York, no el hotel específico de Nueva York que podría estar ubicado en California. Una simple equivalencia de hotel a hoteles podría impulsar una página en particular sobre hoteles en Nueva York al primer puesto. Para capturar esta intención, tenemos que asegurarnos de que el documento sea una página general sobre hoteles en Nueva York. Esto lo hacemos exigiendo que la palabra en plural hoteles aparezca en el documento. Por otro lado, convertir una palabra singular a plural es más seguro ya que una página de propósito general normalmente contiene información específica. Observamos una ligera disminución general en el dcg, aunque no estadísticamente significativa, para el stemming sensible al contexto del documento si no consideramos esta propiedad asimétrica. Análisis de errores. Un tipo de errores que notamos, aunque raros pero que afectan seriamente la relevancia, es el cambio de intención de búsqueda después del stemming. En general, la pluralización o despluralización mantiene la intención original. Sin embargo, la intención podría cambiar en algunos casos. Por ejemplo, para una consulta de este tipo, trabajo en Apple, pluralizamos trabajo a trabajos. Este truncamiento hace que la consulta original sea ambigua. El trabajo de consulta O trabajos en Apple tiene dos intenciones. Una de las oportunidades laborales en Apple, y otra es una persona que trabaja en Apple, Steve Jobs, quien es el CEO y cofundador de la empresa. Por lo tanto, los resultados después de la reducción de consultas devuelven a Steve Jobs como uno de los resultados en el top 5. Una solución es realizar un análisis basado en el conjunto de resultados para verificar si la intención ha cambiado. Esto es similar a la retroalimentación de relevancia y requiere una clasificación en la segunda fase. Un segundo tipo de errores es el problema de reconocimiento de entidades/conceptos. Estos incluyen dos tipos. Una de ellas es que la variante de la palabra derivada ahora coincide con parte de una entidad o concepto. Por ejemplo, la consulta \"cookies en San Francisco\" se pluraliza como \"cookies\" O \"cookie en San Francisco\". Los resultados coincidirán con el tarro de galletas en San Francisco. Aunque \"cookie\" todavía significa lo mismo que \"galletas\", el concepto de \"cookie jar\" es diferente. Otro tipo es la palabra no derivada que coincide con una entidad o concepto debido al truncamiento de las otras palabras. Por ejemplo, la cita ICE se pluraliza como cita OR citas ICE. La intención original de esta consulta es buscar la cotización de acciones para el símbolo ICE. Sin embargo, notamos que entre los resultados principales, uno de los resultados es Citas sobre comida: Helado. Esto se empareja debido a las consultas afectadas dcg antiguas nuevas dcg dcg Mejora del modelo ingenuo 408/408 7.102 7.206 1.5% modelo sensible al contexto del documento 408/408 7.102 7.302 2.8% modelo selectivo: unigram LM 300/408 5.904 6.187 4.8% modelo selectivo: bigram LM 250/408 5.551 5.891 6.1% Tabla 6: Comparación de resultados solo sobre las consultas derivadas: la columna dcg antigua/nueva es la puntuación dcg sobre las consultas afectadas antes/después de aplicar la pluralización de la palabra entre comillas. La palabra inalterada ICE coincide con parte de la frase nominal helado aquí. Para resolver este tipo de problema, tenemos que analizar los documentos y reconocer \"cookie jar\" y \"ice cream\" como conceptos en lugar de dos palabras independientes. Un tercer tipo de errores ocurre en consultas largas. Para la consulta de software lector de códigos de barras, se pluralizan dos palabras. Códigos y lector. De hecho, el lector de códigos de barras en la consulta original es un concepto sólido y las palabras internas no deben ser cambiadas. Este es el problema de segmentación y detección de entidades y frases nominales en consultas, el cual estamos abordando activamente. Para consultas largas, debemos identificar correctamente los conceptos en la consulta y aumentar la proximidad de las palabras dentro de un concepto. 6. CONCLUSIONES Y TRABAJOS FUTUROS Hemos presentado una forma simple pero elegante de derivar palabras para la búsqueda en la web. Mejora el stemming ingenuo en dos aspectos: la expansión selectiva de palabras en el lado de la consulta y la coincidencia conservadora de ocurrencias de palabras en el lado del documento. Usando el manejo de pluralización como ejemplo, experimentos con datos de un motor de búsqueda web importante muestran que mejora significativamente la relevancia web y reduce el costo de derivación. También mejora significativamente la tasa de clics en la web (detalles no reportados en el artículo). Para el trabajo futuro, estamos investigando los problemas que identificamos en la sección de análisis de errores. Estos incluyen: errores de concordancia entre entidades y frases nominales, y una segmentación mejorada. 7. REFERENCIAS [1] E. Agichtein, E. Brill y S. T. Dumais. Mejorando la clasificación de búsqueda web al incorporar información sobre el comportamiento del usuario. En SIGIR, 2006. [2] E. Airio. Normalización de palabras y descomposición en IR monolingüe y bilingüe. Recuperación de información, 9:249-271, 2006. [3] P. Anick. Utilizando retroalimentación terminológica para el refinamiento de la búsqueda web: un estudio basado en registros. En SIGIR, 2003. [4] R. Baeza-Yates y B. Ribeiro-Neto. Recuperación de información moderna. ACM Press/Addison Wesley, 1999. [5] S. Chen y J. Goodman. Un estudio empírico de técnicas de suavizado para modelado del lenguaje. Informe técnico TR-10-98, Universidad de Harvard, 1998. [6] S. Cronen-Townsend, Y. Zhou y B. Croft. Un marco para la expansión selectiva de consultas. En CIKM, 2004. [7] H. Fang y C. Zhai. Coincidencia de términos semánticos en enfoques axiomáticos para la recuperación de información. En SIGIR, 2006. [8] W. B. Frakes. Confluencia de términos para la recuperación de información. En C. J. Rijsbergen, editor, Investigación y Desarrollo en Recuperación de Información, páginas 383-389. Cambridge University Press, 1984. [9] D. Harman.\nCambridge University Press, 1984. [9] D. Harman. ¿Qué tan efectivo es el sufijado? JASIS, 42(1):7-15, 1991. [10] D. Hull.\nJASIS, 42(1):7-15, 1991. [10] D. Hull. Algoritmos de derivación: un estudio de caso para una evaluación detallada. JASIS, 47(1):70-84, 1996. [11] K. Jarvelin y J. Kekalainen. Evaluación basada en la ganancia acumulada de técnicas de RI. ACM TOIS, 20:422-446, 2002. [12] R. Jones, B. Rey, O. Madani y W. Greiner. Generando Sustituciones de Consultas. En WWW, 2006. [13] W. Kraaij y R. Pohlmann. Viendo el Stemming como Mejora de la Recuperación. En SIGIR, 1996. [14] R. Krovetz. Viendo la morfología como un proceso de inferencia. En SIGIR, 1993. [15] D. Lin. Recuperación automática y agrupamiento de palabras similares. En COLING-ACL, 1998. [16] J. B. Lovins. Desarrollo de un algoritmo de derivación. Traducción Mecánica y Lingüística Computacional, II:22-31, 1968. [17] M. Lennon, D. Peirce, B. Tarry y P. Willett. Una evaluación de algunos algoritmos de confluencia para la recuperación de información. Revista de Ciencia de la Información, 3:177-188, 1981. [18] M. Porter. Un algoritmo para el recorte de sufijos. Programa, 14(3):130-137, 1980. [19] K. M. Risvik, T. Mikolajewski y P. Boros. Segmentación de consultas para búsqueda web. En WWW, 2003. [20] S. E. Robertson. Selección de términos para la expansión de consultas. Revista de Documentación, 46(4):359-364, 1990. [21] G. Salton y C. Buckley. Mejorando el rendimiento de recuperación mediante retroalimentación de relevancia. JASIS, 41(4):288 - 297, 1999. [22] R. Sun, C.-H. Ong, y T.-S. Chua. Extracción de relaciones de dependencia para la expansión de consultas en la recuperación de pasajes. En SIGIR, 2006. [23] C. Van Rijsbergen. Recuperación de información. Butterworths, segunda versión, 1979. [24] B. Vélez, R. Weiss, M. A. Sheldon y D. K. Gifford. Refinamiento de consultas rápido y efectivo. En SIGIR, 1997. [25] J. Xu y B. Croft. Expansión de consultas utilizando análisis local y global de documentos. En SIGIR, 1996. [26] J. Xu y B. Croft. Extracción de raíces basada en corpus utilizando la coocurrencia de variantes de palabras. ACM TOIS, 16 (1):61-81, 1998.",
    "original_sentences": [
        "Context Sensitive Stemming for Web Search Fuchun Peng Nawaaz Ahmed Xin Li Yumao Lu Yahoo!",
        "Inc. 701 First Avenue Sunnyvale, California 94089 {fuchun, nawaaz, xinli, yumaol}@yahoo-inc.com ABSTRACT Traditionally, stemming has been applied to Information Retrieval tasks by transforming words in documents to the their root form before indexing, and applying a similar transformation to query terms.",
        "Although it increases recall, this naive strategy does not work well for Web Search since it lowers precision and requires a significant amount of additional computation.",
        "In this paper, we propose a context sensitive stemming method that addresses these two issues.",
        "Two unique properties make our approach feasible for Web Search.",
        "First, based on statistical language modeling, we perform context sensitive analysis on the query side.",
        "We accurately predict which of its morphological variants is useful to expand a query term with before submitting the query to the search engine.",
        "This dramatically reduces the number of bad expansions, which in turn reduces the cost of additional computation and improves the precision at the same time.",
        "Second, our approach performs a context sensitive document matching for those expanded variants.",
        "This conservative strategy serves as a safeguard against spurious stemming, and it turns out to be very important for improving precision.",
        "Using word pluralization handling as an example of our stemming approach, our experiments on a major Web search engine show that stemming only 29% of the query traffic, we can improve relevance as measured by average Discounted Cumulative Gain (DCG5) by 6.1% on these queries and 1.8% over all query traffic.",
        "Categories and Subject Descriptors H.3.3 [Information Systems]: Information Storage and Retrieval-Query formulation General Terms Algorithms, Experimentation 1.",
        "INTRODUCTION Web search has now become a major tool in our daily lives for information seeking.",
        "One of the important issues in Web search is that user queries are often not best formulated to get optimal results.",
        "For example, running shoe is a query that occurs frequently in query logs.",
        "However, the query running shoes is much more likely to give better search results than the original query because documents matching the intent of this query usually contain the words running shoes.",
        "Correctly formulating a query requires the user to accurately predict which word form is used in the documents that best satisfy his or her information needs.",
        "This is difficult even for experienced users, and especially difficult for non-native speakers.",
        "One traditional solution is to use stemming [16, 18], the process of transforming inflected or derived words to their root form so that a search term will match and retrieve documents containing all forms of the term.",
        "Thus, the word run will match running, ran, runs, and shoe will match shoes and shoeing.",
        "Stemming can be done either on the terms in a document during indexing (and applying the same transformation to the query terms during query processing) or by expanding the query with the variants during query processing.",
        "Stemming during indexing allows very little flexibility during query processing, while stemming by query expansion allows handling each query differently, and hence is preferred.",
        "Although traditional stemming increases recall by matching word variants [13], it can reduce precision by retrieving too many documents that have been incorrectly matched.",
        "When examining the results of applying stemming to a large number of queries, one usually finds that nearly equal numbers of queries are helped and hurt by the technique [6].",
        "In addition, it reduces system performance because the search engine has to match all the word variants.",
        "As we will show in the experiments, this is true even if we simplify stemming to pluralization handling, which is the process of converting a word from its plural to singular form, or vice versa.",
        "Thus, one needs to be very cautious when using stemming in Web search engines.",
        "One problem of traditional stemming is its blind transformation of all query terms, that is, it always performs the same transformation for the same query word without considering the context of the word.",
        "For example, the word book has four forms book, books, booking, booked, and store has four forms store, stores, storing, stored.",
        "For the query book store, expanding both words to all of their variants significantly increases computation cost and hurts precision, since not all of the variants are useful for this query.",
        "Transforming book store to match book stores is fine, but matching book storing or booking store is not.",
        "A weighting method that gives variant words smaller weights alleviates the problems to a certain extent if the weights accurately reflect the importance of the variant in this particular query.",
        "However uniform weighting is not going to work and a query dependent weighting is still a challenging unsolved problem [20].",
        "A second problem of traditional stemming is its blind matching of all occurrences in documents.",
        "For the query book store, a transformation that allows the variant stores to be matched will cause every occurrence of stores in the document to be treated equivalent to the query term store.",
        "Thus, a document containing the fragment reading a book in coffee stores will be matched, causing many wrong documents to be selected.",
        "Although we hope the ranking function can correctly handle these, with many more candidates to rank, the risk of making mistakes increases.",
        "To alleviate these two problems, we propose a context sensitive stemming approach for Web search.",
        "Our solution consists of two context sensitive analysis, one on the query side and the other on the document side.",
        "On the query side, we propose a statistical language modeling based approach to predict which word variants are better forms than the original word for search purpose and expanding the query with only those forms.",
        "On the document side, we propose a conservative context sensitive matching for the transformed word variants, only matching document occurrences in the context of other terms in the query.",
        "Our model is simple yet effective and efficient, making it feasible to be used in real commercial Web search engines.",
        "We use pluralization handling as a running example for our stemming approach.",
        "The motivation for using pluralization handling as an example is to show that even such simple stemming, if handled correctly, can give significant benefits to search relevance.",
        "As far as we know, no previous research has systematically investigated the usage of pluralization in Web search.",
        "As we have to point out, the method we propose is not limited to pluralization handling, it is a general stemming technique, and can also be applied to general query expansion.",
        "Experiments on general stemming yield additional significant improvements over pluralization handling for long queries, although details will not be reported in this paper.",
        "In the rest of the paper, we first present the related work and distinguish our method from previous work in Section 2.",
        "We describe the details of the context sensitive stemming approach in Section 3.",
        "We then perform extensive experiments on a major Web search engine to support our claims in Section 4, followed by discussions in Section 5.",
        "Finally, we conclude the paper in Section 6. 2.",
        "RELATED WORK Stemming is a long studied technology.",
        "Many stemmers have been developed, such as the Lovins stemmer [16] and the Porter stemmer [18].",
        "The Porter stemmer is widely used due to its simplicity and effectiveness in many applications.",
        "However, the Porter stemming makes many mistakes because its simple rules cannot fully describe English morphology.",
        "Corpus analysis is used to improve Porter stemmer [26] by creating equivalence classes for words that are morphologically similar and occur in similar context as measured by expected mutual information [23].",
        "We use a similar corpus based approach for stemming by computing the similarity between two words based on their distributional context features which can be more than just adjacent words [15], and then only keep the morphologically similar words as candidates.",
        "Using stemming in information retrieval is also a well known technique [8, 10].",
        "However, the effectiveness of stemming for English query systems was previously reported to be rather limited.",
        "Lennon et al. [17] compared the Lovins and Porter algorithms and found little improvement in retrieval performance.",
        "Later, Harman [9] compares three general stemming techniques in text retrieval experiments including pluralization handing (called S stemmer in the paper).",
        "They also proposed selective stemming based on query length and term importance, but no positive results were reported.",
        "On the other hand, Krovetz [14] performed comparisons over small numbers of documents (from 400 to 12k) and showed dramatic precision improvement (up to 45%).",
        "However, due to the limited number of tested queries (less than 100) and the small size of the collection, the results are hard to generalize to Web search.",
        "These mixed results, mostly failures, led early IR researchers to deem stemming irrelevant in general for English [4], although recent research has shown stemming has greater benefits for retrieval in other languages [2].",
        "We suspect the previous failures were mainly due to the two problems we mentioned in the introduction.",
        "Blind stemming, or a simple query length based selective stemming as used in [9] is not enough.",
        "Stemming has to be decided on case by case basis, not only at the query level but also at the document level.",
        "As we will show, if handled correctly, significant improvement can be achieved.",
        "A more general problem related to stemming is query reformulation [3, 12] and query expansion which expands words not only with word variants [7, 22, 24, 25].",
        "To decide which expanded words to use, people often use pseudorelevance feedback techniquesthat send the original query to a search engine and retrieve the top documents, extract relevant words from these top documents as additional query words, and resubmit the expanded query again [21].",
        "This normally requires sending a query multiple times to search engine and it is not cost effective for processing the huge amount of queries involved in Web search.",
        "In addition, query expansion, including query reformulation [3, 12], has a high risk of changing the user intent (called query drift).",
        "Since the expanded words may have different meanings, adding them to the query could potentially change the intent of the original query.",
        "Thus query expansion based on pseudorelevance and query reformulation can provide suggestions to users for interactive refinement but can hardly be directly used for Web search.",
        "On the other hand, stemming is much more conservative since most of the time, stemming preserves the original search intent.",
        "While most work on query expansion focuses on recall enhancement, our work focuses on increasing both recall and precision.",
        "The increase on recall is obvious.",
        "With quality stemming, good documents which were not selected before stemming will be pushed up and those low quality documents will be degraded.",
        "On selective query expansion, Cronen-Townsend et al. [6] proposed a method for selective query expansion based on comparing the Kullback-Leibler divergence of the results from the unexpanded query and the results from the expanded query.",
        "This is similar to the relevance feedback in the sense that it requires multiple passes retrieval.",
        "If a word can be expanded into several words, it requires running this process multiple times to decide which expanded word is useful.",
        "It is expensive to deploy this in production Web search engines.",
        "Our method predicts the quality of expansion based on oﬄine information without sending the query to a search engine.",
        "In summary, we propose a novel approach to attack an old, yet still important and challenging problem for Web search - stemming.",
        "Our approach is unique in that it performs predictive stemming on a per query basis without relevance feedback from the Web, using the context of the variants in documents to preserve precision.",
        "Its simple, yet very efficient and effective, making real time stemming feasible for Web search.",
        "Our results will affirm researchers that stemming is indeed very important to large scale information retrieval. 3.",
        "CONTEXT SENSITIVE STEMMING 3.1 Overview Our system has four components as illustrated in Figure 1: candidate generation, query segmentation and head word detection, context sensitive query stemming and context sensitive document matching.",
        "Candidate generation (component 1) is performed oﬄine and generated candidates are stored in a dictionary.",
        "For an input query, we first segment query into concepts and detect the head word for each concept (component 2).",
        "We then use statistical language modeling to decide whether a particular variant is useful (component 3), and finally for the expanded variants, we perform context sensitive document matching (component 4).",
        "Below we discuss each of the components in more detail.",
        "Component 4: context sensitive document matching Input Query: and head word detection Component 2: segment Component 1: candidate generation comparisons −> comparison Component 3: selective word expansion decision: comparisons −> comparison example: hotel price comparisons output: hotel comparisons hotel −> hotels Figure 1: System Components 3.2 Expansion candidate generation One of the ways to generate candidates is using the Porter stemmer [18].",
        "The Porter stemmer simply uses morphological rules to convert a word to its base form.",
        "It has no knowledge of the semantic meaning of the words and sometimes makes serious mistakes, such as executive to execution, news to new, and paste to past.",
        "A more conservative way is based on using corpus analysis to improve the Porter stemmer results [26].",
        "The corpus analysis we do is based on word distributional similarity [15].",
        "The rationale of using distributional word similarity is that true variants tend to be used in similar contexts.",
        "In the distributional word similarity calculation, each word is represented with a vector of features derived from the context of the word.",
        "We use the bigrams to the left and right of the word as its context features, by mining a huge Web corpus.",
        "The similarity between two words is the cosine similarity between the two corresponding feature vectors.",
        "The top 20 similar words to develop is shown in the following table. rank candidate score rank candidate score 0 develop 1 10 berts 0.119 1 developing 0.339 11 wads 0.116 2 developed 0.176 12 developer 0.107 3 incubator 0.160 13 promoting 0.100 4 develops 0.150 14 developmental 0.091 5 development 0.148 15 reengineering 0.090 6 tutoring 0.138 16 build 0.083 7 analyzing 0.128 17 construct 0.081 8 developement 0.128 18 educational 0.081 9 automation 0.126 19 institute 0.077 Table 1: Top 20 most similar candidates to word develop.",
        "Column score is the similarity score.",
        "To determine the stemming candidates, we apply a few Porter stemmer [18] morphological rules to the similarity list.",
        "After applying these rules, for the word develop, the stemming candidates are developing, developed, develops, development, developement, developer, developmental.",
        "For the pluralization handling purpose, only the candidate develops is retained.",
        "One thing we note from observing the distributionally similar words is that they are closely related semantically.",
        "These words might serve as candidates for general query expansion, a topic we will investigate in the future. 3.3 Segmentation and headword identification For long queries, it is quite important to detect the concepts in the query and the most important words for those concepts.",
        "We first break a query into segments, each segment representing a concept which normally is a noun phrase.",
        "For each of the noun phrases, we then detect the most important word which we call the head word.",
        "Segmentation is also used in document sensitive matching (section 3.5) to enforce proximity.",
        "To break a query into segments, we have to define a criteria to measure the strength of the relation between words.",
        "One effective method is to use mutual information as an indicator on whether or not to split two words [19].",
        "We use a log of 25M queries and collect the bigram and unigram frequencies from it.",
        "For every incoming query, we compute the mutual information of two adjacent words; if it passes a predefined threshold, we do not split the query between those two words and move on to next word.",
        "We continue this process until the mutual information between two words is below the threshold, then create a concept boundary here.",
        "Table 2 shows some examples of query segmentation.",
        "The ideal way of finding the head word of a concept is to do syntactic parsing to determine the dependency structure of the query.",
        "Query parsing is more difficult than sentence [running shoe] [best] [new york] [medical schools] [pictures] [of] [white house] [cookies] [in] [san francisco] [hotel] [price comparison] Table 2: Query segmentation: a segment is bracketed. parsing since many queries are not grammatical and are very short.",
        "Applying a parser trained on sentences from documents to queries will have poor performance.",
        "In our solution, we just use simple heuristics rules, and it works very well in practice for English.",
        "For an English noun phrase, the head word is typically the last nonstop word, unless the phrase is of a particular pattern, like XYZ of/in/at/from UVW.",
        "In such cases, the head word is typically the last nonstop word of XYZ. 3.4 Context sensitive word expansion After detecting which words are the most important words to expand, we have to decide whether the expansions will be useful.",
        "Our statistics show that about half of the queries can be transformed by pluralization via naive stemming.",
        "Among this half, about 25% of the queries improve relevance when transformed, the majority (about 50%) do not change their top 5 results, and the remaining 25% perform worse.",
        "Thus, it is extremely important to identify which queries should not be stemmed for the purpose of maximizing relevance improvement and minimizing stemming cost.",
        "In addition, for a query with multiple words that can be transformed, or a word with multiple variants, not all of the expansions are useful.",
        "Taking query hotel price comparison as an example, we decide that hotel and price comparison are two concepts.",
        "Head words hotel and comparison can be expanded to hotels and comparisons.",
        "Are both transformations useful?",
        "To test whether an expansion is useful, we have to know whether the expanded query is likely to get more relevant documents from the Web, which can be quantified by the probability of the query occurring as a string on the Web.",
        "The more likely a query to occur on the Web, the more relevant documents this query is able to return.",
        "Now the whole problem becomes how to calculate the probability of query to occur on the Web.",
        "Calculating the probability of string occurring in a corpus is a well known language modeling problem.",
        "The goal of language modeling is to predict the probability of naturally occurring word sequences, s = w1w2...wN ; or more simply, to put high probability on word sequences that actually occur (and low probability on word sequences that never occur).",
        "The simplest and most successful approach to language modeling is still based on the n-gram model.",
        "By the chain rule of probability one can write the probability of any word sequence as Pr(w1w2...wN ) = NY i=1 Pr(wi|w1...wi−1) (1) An n-gram model approximates this probability by assuming that the only words relevant to predicting Pr(wi|w1...wi−1) are the previous n − 1 words; i.e.",
        "Pr(wi|w1...wi−1) = Pr(wi|wi−n+1...wi−1) A straightforward maximum likelihood estimate of n-gram probabilities from a corpus is given by the observed frequency of each of the patterns Pr(wi|wi−n+1...wi−1) = #(wi−n+1...wi) #(wi−n+1...wi−1) (2) where #(.) denotes the number of occurrences of a specified gram in the training corpus.",
        "Although one could attempt to use simple n-gram models to capture long range dependencies in language, attempting to do so directly immediately creates sparse data problems: Using grams of length up to n entails estimating the probability of Wn events, where W is the size of the word vocabulary.",
        "This quickly overwhelms modern computational and data resources for even modest choices of n (beyond 3 to 6).",
        "Also, because of the heavy tailed nature of language (i.e.",
        "Zipfs law) one is likely to encounter novel n-grams that were never witnessed during training in any test corpus, and therefore some mechanism for assigning non-zero probability to novel n-grams is a central and unavoidable issue in statistical language modeling.",
        "One standard approach to smoothing probability estimates to cope with sparse data problems (and to cope with potentially missing n-grams) is to use some sort of back-off estimator.",
        "Pr(wi|wi−n+1...wi−1) = 8 >>< >>: ˆPr(wi|wi−n+1...wi−1), if #(wi−n+1...wi) > 0 β(wi−n+1...wi−1) × Pr(wi|wi−n+2...wi−1), otherwise (3) where ˆPr(wi|wi−n+1...wi−1) = discount #(wi−n+1...wi) #(wi−n+1...wi−1) (4) is the discounted probability and β(wi−n+1...wi−1) is a normalization constant β(wi−n+1...wi−1) = 1 − X x∈(wi−n+1...wi−1x) ˆPr(x|wi−n+1...wi−1) 1 − X x∈(wi−n+1...wi−1x) ˆPr(x|wi−n+2...wi−1) (5) The discounted probability (4) can be computed with different smoothing techniques, including absolute smoothing, Good-Turing smoothing, linear smoothing, and Witten-Bell smoothing [5].",
        "We used absolute smoothing in our experiments.",
        "Since the likelihood of a string, Pr(w1w2...wN ), is a very small number and hard to interpret, we use entropy as defined below to score the string.",
        "Entropy = − 1 N log2 Pr(w1w2...wN ) (6) Now getting back to the example of the query hotel price comparisons, there are four variants of this query, and the entropy of these four candidates are shown in Table 3.",
        "We can see that all alternatives are less likely than the input query.",
        "It is therefore not useful to make an expansion for this query.",
        "On the other hand, if the input query is hotel price comparisons which is the second alternative in the table, then there is a better alternative than the input query, and it should therefore be expanded.",
        "To tolerate the variations in probability estimation, we relax the selection criterion to those query alternatives if their scores are within a certain distance (10% in our experiments) to the best score.",
        "Query variations Entropy hotel price comparison 6.177 hotel price comparisons 6.597 hotels price comparison 6.937 hotels price comparisons 7.360 Table 3: Variations of query hotel price comparison ranked by entropy score, with the original query in bold face. 3.5 Context sensitive document matching Even after we know which word variants are likely to be useful, we have to be conservative in document matching for the expanded variants.",
        "For the query hotel price comparisons, we decided that word comparisons is expanded to include comparison.",
        "However, not every occurrence of comparison in the document is of interest.",
        "A page which is about comparing customer service can contain all of the words hotel price comparisons comparison.",
        "This page is not a good page for the query.",
        "If we accept matches of every occurrence of comparison, it will hurt retrieval precision and this is one of the main reasons why most stemming approaches do not work well for information retrieval.",
        "To address this problem, we have a proximity constraint that considers the context around the expanded variant in the document.",
        "A variant match is considered valid only if the variant occurs in the same context as the original word does.",
        "The context is the left or the right non-stop segments 1 of the original word.",
        "Taking the same query as an example, the context of comparisons is price.",
        "The expanded word comparison is only valid if it is in the same context of comparisons, which is after the word price.",
        "Thus, we should only match those occurrences of comparison in the document if they occur after the word price.",
        "Considering the fact that queries and documents may not represent the intent in exactly the same way, we relax this proximity constraint to allow variant occurrences within a window of some fixed size.",
        "If the expanded word comparison occurs within the context of price within a window, it is considered valid.",
        "The smaller the window size is, the more restrictive the matching.",
        "We use a window size of 4, which typically captures contexts that include the containing and adjacent noun phrases. 4.",
        "EXPERIMENTAL EVALUATION 4.1 Evaluation metrics We will measure both relevance improvement and the stemming cost required to achieve the relevance. 1 a context segment can not be a single stop word. 4.1.1 Relevance measurement We use a variant of the average Discounted Cumulative Gain (DCG), a recently popularized scheme to measure search engine relevance [1, 11].",
        "Given a query and a ranked list of K documents (K is set to 5 in our experiments), the DCG(K) score for this query is calculated as follows: DCG(K) = KX k=1 gk log2(1 + k) . (7) where gk is the weight for the document at rank k. Higher degree of relevance corresponds to a higher weight.",
        "A page is graded into one of the five scales: Perfect, Excellent, Good, Fair, Bad, with corresponding weights.",
        "We use dcg to represent the average DCG(5) over a set of test queries. 4.1.2 Stemming cost Another metric is to measure the additional cost incurred by stemming.",
        "Given the same level of relevance improvement, we prefer a stemming method that has less additional cost.",
        "We measure this by the percentage of queries that are actually stemmed, over all the queries that could possibly be stemmed. 4.2 Data preparation We randomly sample 870 queries from a three month query log, with 290 from each month.",
        "Among all these 870 queries, we remove all misspelled queries since misspelled queries are not of interest to stemming.",
        "We also remove all one word queries since stemming one word queries without context has a high risk of changing query intent, especially for short words.",
        "In the end, we have 529 correctly spelled queries with at least 2 words. 4.3 Naive stemming for Web search Before explaining the experiments and results in detail, wed like to describe the traditional way of using stemming for Web search, referred as the naive model.",
        "This is to treat every word variant equivalent for all possible words in the query.",
        "The query book store will be transformed into (book OR books)(store OR stores) when limiting stemming to pluralization handling only, where OR is an operator that denotes the equivalence of the left and right arguments. 4.4 Experimental setup The baseline model is the model without stemming.",
        "We first run the naive model to see how well it performs over the baseline.",
        "Then we improve the naive stemming model by document sensitive matching, referred as document sensitive matching model.",
        "This model makes the same stemming as the naive model on the query side, but performs conservative matching on the document side using the strategy described in section 3.5.",
        "The naive model and document sensitive matching model stem the most queries.",
        "Out of the 529 queries, there are 408 queries that they stem, corresponding to 46.7% query traffic (out of a total of 870).",
        "We then further improve the document sensitive matching model from the query side with selective word stemming based on statistical language modeling (section 3.4), referred as selective stemming model.",
        "Based on language modeling prediction, this model stems only a subset of the 408 queries stemmed by the document sensitive matching model.",
        "We experiment with unigram language model and bigram language model.",
        "Since we only care how much we can improve the naive model, we will only use these 408 queries (all the queries that are affected by the naive stemming model) in the experiments.",
        "To get a sense of how these models perform, we also have an oracle model that gives the upper-bound performance a stemmer can achieve on this data.",
        "The oracle model only expands a word if the stemming will give better results.",
        "To analyze the pluralization handling influence on different query categories, we divide queries into short queries and long queries.",
        "Among the 408 queries stemmed by the naive model, there are 272 short queries with 2 or 3 words, and 136 long queries with at least 4 words. 4.5 Results We summarize the overall results in Table 4, and present the results on short queries and long queries separately in Table 5.",
        "Each row in Table 4 is a stemming strategy described in section 4.4.",
        "The first column is the name of the strategy.",
        "The second column is the number of queries affected by this strategy; this column measures the stemming cost, and the numbers should be low for the same level of dcg.",
        "The third column is the average dcg score over all tested queries in this category (including the ones that were not stemmed by the strategy).",
        "The fourth column is the relative improvement over the baseline, and the last column is the p-value of Wilcoxon significance test.",
        "There are several observations about the results.",
        "We can see the naively stemming only obtains a statistically insignificant improvement of 1.5%.",
        "Looking at Table 5, it gives an improvement of 2.7% on short queries.",
        "However, it also hurts long queries by -2.4%.",
        "Overall, the improvement is canceled out.",
        "The reason that it improves short queries is that most short queries only have one word that can be stemmed.",
        "Thus, blindly pluralizing short queries is relatively safe.",
        "However for long queries, most queries can have multiple words that can be pluralized.",
        "Expanding all of them without selection will significantly hurt precision.",
        "Document context sensitive stemming gives a significant lift to the performance, from 2.7% to 4.2% for short queries and from -2.4% to -1.6% for long queries, with an overall lift from 1.5% to 2.8%.",
        "The improvement comes from the conservative context sensitive document matching.",
        "An expanded word is valid only if it occurs within the context of original query in the document.",
        "This reduces many spurious matches.",
        "However, we still notice that for long queries, context sensitive stemming is not able to improve performance because it still selects too many documents and gives the ranking function a hard problem.",
        "While the chosen window size of 4 works the best amongst all the choices, it still allows spurious matches.",
        "It is possible that the window size needs to be chosen on a per query basis to ensure tighter proximity constraints for different types of noun phrases.",
        "Selective word pluralization further helps resolving the problem faced by document context sensitive stemming.",
        "It does not stem every word that places all the burden on the ranking algorithm, but tries to eliminate unnecessary stemming in the first place.",
        "By predicting which word variants are going to be useful, we can dramatically reduce the number of stemmed words, thus improving both the recall and the precision.",
        "With the unigram language model, we can reduce the stemming cost by 26.7% (from 408/408 to 300/408) and lift the overall dcg improvement from 2.8% to 3.4%.",
        "In particular, it gives significant improvements on long queries.",
        "The dcg gain is turned from negative to positive, from −1.6% to 1.1%.",
        "This confirms our hypothesis that reducing unnecessary word expansion leads to precision improvement.",
        "For short queries too, we observe both dcg improvement and stemming cost reduction with the unigram language model.",
        "The advantages of predictive word expansion with a language model is further boosted with a better bigram language model.",
        "The overall dcg gain is lifted from 3.4% to 3.9%, and stemming cost is dramatically reduced from 408/408 to 250/408, corresponding to only 29% of query traffic (250 out of 870) and an overall 1.8% dcg improvement overall all query traffic.",
        "For short queries, bigram language model improves the dcg gain from 4.4% to 4.7%, and reduces stemming cost from 272/272 to 150/272.",
        "For long queries, bigram language model improves dcg gain from 1.1% to 2.5%, and reduces stemming cost from 136/136 to 100/136.",
        "We observe that the bigram language model gives a larger lift for long queries.",
        "This is because the uncertainty in long queries is larger and a more powerful language model is needed.",
        "We hypothesize that a trigram language model would give a further lift for long queries and leave this for future investigation.",
        "Considering the tight upper-bound 2 on the improvement to be gained from pluralization handling (via the oracle model), the current performance on short queries is very satisfying.",
        "For short queries, the dcg gain upper-bound is 6.3% for perfect pluralization handling, our current gain is 4.7% with a bigram language model.",
        "For long queries, the dcg gain upper-bound is 4.6% for perfect pluralization handling, our current gain is 2.5% with a bigram language model.",
        "We may gain additional benefit with a more powerful language model for long queries.",
        "However, the difficulties of long queries come from many other aspects including the proximity and the segmentation problem.",
        "These problems have to be addressed separately.",
        "Looking at the the upper-bound of overhead reduction for oracle stemming, 75% (308/408) of the naive stemmings are wasteful.",
        "We currently capture about half of them.",
        "Further reduction of the overhead requires sacrificing the dcg gain.",
        "Now we can compare the stemming strategies from a different aspect.",
        "Instead of looking at the influence over all queries as we described above, Table 6 summarizes the dcg improvements over the affected queries only.",
        "We can see that the number of affected queries decreases as the stemming strategy becomes more accurate (dcg improvement).",
        "For the bigram language model, over the 250/408 stemmed queries, the dcg improvement is 6.1%.",
        "An interesting observation is the average dcg decreases with a better model, which indicates a better stemming strategy stems more difficult queries (low dcg queries). 5.",
        "DISCUSSIONS 5.1 Language models from query vs. from Web As we mentioned in Section 1, we are trying to predict the probability of a string occurring on the Web.",
        "The language model should describe the occurrence of the string on the Web.",
        "However, the query log is also a good resource. 2 Note that this upperbound is for pluralization handling only, not for general stemming.",
        "General stemming gives a 8% upperbound, which is quite substantial in terms of our metrics.",
        "Affected Queries dcg dcg Improvement p-value baseline 0/408 7.102 N/A N/A naive model 408/408 7.206 1.5% 0.22 document context sensitive model 408/408 7.302 2.8% 0.014 selective model: unigram LM 300/408 7.321 3.4% 0.001 selective model: bigram LM 250/408 7.381 3.9% 0.001 oracle model 100/408 7.519 5.9% 0.001 Table 4: Results comparison of different stemming strategies over all queries affected by naive stemming Short Query Results Affected Queries dcg Improvement p-value baseline 0/272 N/A N/A naive model 272/272 2.7% 0.48 document context sensitive model 272/272 4.2% 0.002 selective model: unigram LM 185/272 4.4% 0.001 selective model: bigram LM 150/272 4.7% 0.001 oracle model 71/272 6.3% 0.001 Long Query Results Affected Queries dcg Improvement p-value baseline 0/136 N/A N/A naive model 136/136 -2.4% 0.25 document context sensitive model 136/136 -1.6% 0.27 selective model: unigram LM 115/136 1.1% 0.001 selective model: bigram LM 100/136 2.5% 0.001 oracle model 29/136 4.6% 0.001 Table 5: Results comparison of different stemming strategies overall short queries and long queries Users reformulate a query using many different variants to get good results.",
        "To test the hypothesis that we can learn reliable transformation probabilities from the query log, we trained a language model from the same query top 25M queries as used to learn segmentation, and use that for prediction.",
        "We observed a slight performance decrease compared to the model trained on Web frequencies.",
        "In particular, the performance for unigram LM was not affected, but the dcg gain for bigram LM changed from 4.7% to 4.5% for short queries.",
        "Thus, the query log can serve as a good approximation of the Web frequencies. 5.2 How linguistics helps Some linguistic knowledge is useful in stemming.",
        "For the pluralization handling case, pluralization and de-pluralization is not symmetric.",
        "A plural word used in a query indicates a special intent.",
        "For example, the query new york hotels is looking for a list of hotels in new york, not the specific new york hotel which might be a hotel located in California.",
        "A simple equivalence of hotel to hotels might boost a particular page about new york hotel to top rank.",
        "To capture this intent, we have to make sure the document is a general page about hotels in new york.",
        "We do this by requiring that the plural word hotels appears in the document.",
        "On the other hand, converting a singular word to plural is safer since a general purpose page normally contains specific information.",
        "We observed a slight overall dcg decrease, although not statistically significant, for document context sensitive stemming if we do not consider this asymmetric property. 5.3 Error analysis One type of mistakes we noticed, though rare but seriously hurting relevance, is the search intent change after stemming.",
        "Generally speaking, pluralization or depluralization keeps the original intent.",
        "However, the intent could change in a few cases.",
        "For one example of such a query, job at apple, we pluralize job to jobs.",
        "This stemming makes the original query ambiguous.",
        "The query job OR jobs at apple has two intents.",
        "One is the employment opportunities at apple, and another is a person working at Apple, Steve Jobs, who is the CEO and co-founder of the company.",
        "Thus, the results after query stemming returns Steve Jobs as one of the results in top 5.",
        "One solution is performing results set based analysis to check if the intent is changed.",
        "This is similar to relevance feedback and requires second phase ranking.",
        "A second type of mistakes is the entity/concept recognition problem, These include two kinds.",
        "One is that the stemmed word variant now matches part of an entity or concept.",
        "For example, query cookies in san francisco is pluralized to cookies OR cookie in san francisco.",
        "The results will match cookie jar in san francisco.",
        "Although cookie still means the same thing as cookies, cookie jar is a different concept.",
        "Another kind is the unstemmed word matches an entity or concept because of the stemming of the other words.",
        "For example, quote ICE is pluralized to quote OR quotes ICE.",
        "The original intent for this query is searching for stock quote for ticker ICE.",
        "However, we noticed that among the top results, one of the results is Food quotes: Ice cream.",
        "This is matched because of Affected Queries old dcg new dcg dcg Improvement naive model 408/408 7.102 7.206 1.5% document context sensitive model 408/408 7.102 7.302 2.8% selective model: unigram LM 300/408 5.904 6.187 4.8% selective model: bigram LM 250/408 5.551 5.891 6.1% Table 6: Results comparison over the stemmed queries only: column old/new dcg is the dcg score over the affected queries before/after applying stemming the pluralized word quotes.",
        "The unchanged word ICE matches part of the noun phrase ice cream here.",
        "To solve this kind of problem, we have to analyze the documents and recognize cookie jar and ice cream as concepts instead of two independent words.",
        "A third type of mistakes occurs in long queries.",
        "For the query bar code reader software, two words are pluralized. code to codes and reader to readers.",
        "In fact, bar code reader in the original query is a strong concept and the internal words should not be changed.",
        "This is the segmentation and entity and noun phrase detection problem in queries, which we actively are attacking.",
        "For long queries, we should correctly identify the concepts in the query, and boost the proximity for the words within a concept. 6.",
        "CONCLUSIONS AND FUTURE WORK We have presented a simple yet elegant way of stemming for Web search.",
        "It improves naive stemming in two aspects: selective word expansion on the query side and conservative word occurrence matching on the document side.",
        "Using pluralization handling as an example, experiments on a major Web search engine data show it significantly improves the Web relevance and reduces the stemming cost.",
        "It also significantly improves Web click through rate (details not reported in the paper).",
        "For the future work, we are investigating the problems we identified in the error analysis section.",
        "These include: entity and noun phrase matching mistakes, and improved segmentation. 7.",
        "REFERENCES [1] E. Agichtein, E. Brill, and S. T. Dumais.",
        "Improving Web Search Ranking by Incorporating User Behavior Information.",
        "In SIGIR, 2006. [2] E. Airio.",
        "Word Normalization and Decompounding in Mono- and Bilingual IR.",
        "Information Retrieval, 9:249-271, 2006. [3] P. Anick.",
        "Using Terminological Feedback for Web Search Refinement: a Log-based Study.",
        "In SIGIR, 2003. [4] R. Baeza-Yates and B. Ribeiro-Neto.",
        "Modern Information Retrieval.",
        "ACM Press/Addison Wesley, 1999. [5] S. Chen and J. Goodman.",
        "An Empirical Study of Smoothing Techniques for Language Modeling.",
        "Technical Report TR-10-98, Harvard University, 1998. [6] S. Cronen-Townsend, Y. Zhou, and B. Croft.",
        "A Framework for Selective Query Expansion.",
        "In CIKM, 2004. [7] H. Fang and C. Zhai.",
        "Semantic Term Matching in Axiomatic Approaches to Information Retrieval.",
        "In SIGIR, 2006. [8] W. B. Frakes.",
        "Term Conflation for Information Retrieval.",
        "In C. J. Rijsbergen, editor, Research and Development in Information Retrieval, pages 383-389.",
        "Cambridge University Press, 1984. [9] D. Harman.",
        "How Effective is Suffixing?",
        "JASIS, 42(1):7-15, 1991. [10] D. Hull.",
        "Stemming Algorithms - A Case Study for Detailed Evaluation.",
        "JASIS, 47(1):70-84, 1996. [11] K. Jarvelin and J. Kekalainen.",
        "Cumulated Gain-Based Evaluation Evaluation of IR Techniques.",
        "ACM TOIS, 20:422-446, 2002. [12] R. Jones, B. Rey, O. Madani, and W. Greiner.",
        "Generating Query Substitutions.",
        "In WWW, 2006. [13] W. Kraaij and R. Pohlmann.",
        "Viewing Stemming as Recall Enhancement.",
        "In SIGIR, 1996. [14] R. Krovetz.",
        "Viewing Morphology as an Inference Process.",
        "In SIGIR, 1993. [15] D. Lin.",
        "Automatic Retrieval and Clustering of Similar Words.",
        "In COLING-ACL, 1998. [16] J.",
        "B. Lovins.",
        "Development of a Stemming Algorithm.",
        "Mechanical Translation and Computational Linguistics, II:22-31, 1968. [17] M. Lennon and D. Peirce and B. Tarry and P. Willett.",
        "An Evaluation of Some Conflation Algorithms for Information Retrieval.",
        "Journal of Information Science, 3:177-188, 1981. [18] M. Porter.",
        "An Algorithm for Suffix Stripping.",
        "Program, 14(3):130-137, 1980. [19] K. M. Risvik, T. Mikolajewski, and P. Boros.",
        "Query Segmentation for Web Search.",
        "In WWW, 2003. [20] S. E. Robertson.",
        "On Term Selection for Query Expansion.",
        "Journal of Documentation, 46(4):359-364, 1990. [21] G. Salton and C. Buckley.",
        "Improving Retrieval Performance by Relevance Feedback.",
        "JASIS, 41(4):288 - 297, 1999. [22] R. Sun, C.-H. Ong, and T.-S. Chua.",
        "Mining Dependency Relations for Query Expansion in Passage Retrieval.",
        "In SIGIR, 2006. [23] C. Van Rijsbergen.",
        "Information Retrieval.",
        "Butterworths, second version, 1979. [24] B. V´elez, R. Weiss, M. A. Sheldon, and D. K. Gifford.",
        "Fast and Effective Query Refinement.",
        "In SIGIR, 1997. [25] J. Xu and B. Croft.",
        "Query Expansion using Local and Global Document Analysis.",
        "In SIGIR, 1996. [26] J. Xu and B. Croft.",
        "Corpus-based Stemming using Cooccurrence of Word Variants.",
        "ACM TOIS, 16 (1):61-81, 1998."
    ],
    "translated_text_sentences": [
        "Stemming sensible al contexto para la búsqueda web Fuchun Peng Nawaaz Ahmed Xin Li Yumao Lu Yahoo!",
        "Tradicionalmente, el truncamiento se ha aplicado a tareas de Recuperación de Información transformando las palabras en documentos a su forma raíz antes de indexarlas, y aplicando una transformación similar a los términos de consulta.",
        "Aunque aumenta la recuperación, esta estrategia ingenua no funciona bien para la Búsqueda en la Web, ya que disminuye la precisión y requiere una cantidad significativa de cálculos adicionales.",
        "En este artículo, proponemos un método de derivación sensible al contexto que aborda estos dos problemas.",
        "Dos propiedades únicas hacen que nuestro enfoque sea factible para la Búsqueda en la Web.",
        "Primero, basados en modelado estadístico del lenguaje, realizamos un análisis sensible al contexto en el lado de la consulta.",
        "Predecimos con precisión cuál de sus variantes morfológicas es útil para expandir un término de consulta antes de enviar la consulta al motor de búsqueda.",
        "Esto reduce drásticamente la cantidad de expansiones incorrectas, lo que a su vez disminuye el costo de la computación adicional y mejora la precisión al mismo tiempo.",
        "Segundo, nuestro enfoque realiza una coincidencia de documentos sensible al contexto para esas variantes ampliadas.",
        "Esta estrategia conservadora sirve como salvaguarda contra el truncamiento espurio, y resulta ser muy importante para mejorar la precisión.",
        "Usando el manejo de la pluralización de palabras como un ejemplo de nuestro enfoque de derivación, nuestros experimentos en un importante motor de búsqueda web muestran que al derivar solo el 29% del tráfico de consultas, podemos mejorar la relevancia medida por la Ganancia Acumulativa Descontada promedio (DCG5) en un 6.1% en estas consultas y en un 1.8% sobre todo el tráfico de consultas.",
        "Categorías y Descriptores de Asignaturas H.3.3 [Sistemas de Información]: Almacenamiento y Recuperación de Información-Formulación de Consultas Términos Generales Algoritmos, Experimentación 1.",
        "INTRODUCCIÓN La búsqueda en la web se ha convertido en una herramienta importante en nuestra vida diaria para buscar información.",
        "Uno de los problemas importantes en la búsqueda web es que las consultas de los usuarios a menudo no están formuladas de la mejor manera para obtener resultados óptimos.",
        "Por ejemplo, \"zapatilla para correr\" es una consulta que ocurre con frecuencia en los registros de consulta.",
        "Sin embargo, es mucho más probable que la búsqueda \"zapatillas para correr\" proporcione mejores resultados de búsqueda que la consulta original, ya que los documentos que coinciden con la intención de esta consulta suelen contener las palabras \"zapatillas para correr\".",
        "Formular correctamente una consulta requiere que el usuario prediga con precisión qué forma de palabra se utiliza en los documentos que mejor satisfacen sus necesidades de información.",
        "Esto es difícil incluso para usuarios experimentados, y especialmente difícil para hablantes no nativos.",
        "Una solución tradicional es utilizar el stemming [16, 18], el proceso de transformar palabras flexionadas o derivadas a su forma raíz para que un término de búsqueda coincida y recupere documentos que contengan todas las formas del término.",
        "Por lo tanto, la palabra \"run\" coincidirá con \"running\", \"ran\", \"runs\", y \"shoe\" coincidirá con \"shoes\" y \"shoeing\".",
        "El truncamiento se puede realizar tanto en los términos de un documento durante la indexación (y aplicando la misma transformación a los términos de la consulta durante el procesamiento de la consulta) o expandiendo la consulta con las variantes durante el procesamiento de la consulta.",
        "El truncamiento durante la indexación permite muy poca flexibilidad durante el procesamiento de consultas, mientras que el truncamiento mediante la expansión de consultas permite manejar cada consulta de manera diferente, y por lo tanto es preferible.",
        "Aunque el truncamiento tradicional aumenta la recuperación al emparejar variantes de palabras [13], puede reducir la precisión al recuperar demasiados documentos que han sido emparejados incorrectamente.",
        "Al examinar los resultados de aplicar el truncamiento a un gran número de consultas, generalmente se encuentra que casi igual cantidad de consultas se benefician y se ven perjudicadas por la técnica [6].",
        "Además, reduce el rendimiento del sistema porque el motor de búsqueda tiene que hacer coincidir todas las variantes de palabras.",
        "Como mostraremos en los experimentos, esto es cierto incluso si simplificamos el proceso de derivación a la manipulación de pluralización, que es el proceso de convertir una palabra de su forma plural a singular, o viceversa.",
        "Por lo tanto, es necesario ser muy cauteloso al utilizar el stemming en los motores de búsqueda web.",
        "Un problema del truncamiento tradicional es su transformación ciega de todos los términos de consulta, es decir, siempre realiza la misma transformación para la misma palabra de consulta sin considerar el contexto de la palabra.",
        "Por ejemplo, la palabra \"book\" tiene cuatro formas: book, books, booking, booked, y la palabra \"store\" tiene cuatro formas: store, stores, storing, stored.",
        "Para la consulta de la librería, expandir ambas palabras a todas sus variantes aumenta significativamente el costo de computación y perjudica la precisión, ya que no todas las variantes son útiles para esta consulta.",
        "Transformar librería para que coincida con librerías está bien, pero hacer coincidir almacenamiento de libros o tienda de reservas no lo está.",
        "Un método de ponderación que otorga pesos más pequeños a las palabras variantes alivia los problemas hasta cierto punto si los pesos reflejan con precisión la importancia de la variante en esta consulta particular.",
        "Sin embargo, el peso uniforme no va a funcionar y un peso dependiente de la consulta sigue siendo un problema desafiante sin resolver [20].",
        "Un segundo problema del truncamiento tradicional es su emparejamiento ciego de todas las ocurrencias en los documentos.",
        "Para la consulta de la librería, una transformación que permita que las tiendas variantes se emparejen hará que cada aparición de tiendas en el documento se trate de manera equivalente al término de consulta tienda.",
        "Por lo tanto, se emparejará un documento que contenga el fragmento de leer un libro en las cafeterías, lo que provocará que se seleccionen muchos documentos incorrectos.",
        "Aunque esperamos que la función de clasificación pueda manejar correctamente estos, con muchos más candidatos para clasificar, el riesgo de cometer errores aumenta.",
        "Para aliviar estos dos problemas, proponemos un enfoque de reducción de palabras raíz sensible al contexto para la búsqueda en la web.",
        "Nuestra solución consiste en dos análisis contextuales sensibles, uno en el lado de la consulta y otro en el lado del documento.",
        "En el lado de la consulta, proponemos un enfoque basado en modelado del lenguaje estadístico para predecir qué variantes de palabras son mejores formas que la palabra original con fines de búsqueda y expandir la consulta solo con esas formas.",
        "En el lado del documento, proponemos un emparejamiento conservador sensible al contexto para las variantes de palabras transformadas, solo emparejando las ocurrencias en el documento en el contexto de otros términos en la consulta.",
        "Nuestro modelo es simple pero efectivo y eficiente, lo que lo hace factible de ser utilizado en motores de búsqueda web comerciales reales.",
        "Utilizamos el manejo de pluralización como un ejemplo continuo para nuestro enfoque de derivación.",
        "La motivación para usar el manejo de pluralización como ejemplo es mostrar que incluso un truncamiento tan simple, si se maneja correctamente, puede brindar beneficios significativos a la relevancia de la búsqueda.",
        "Hasta donde sabemos, ninguna investigación previa ha investigado sistemáticamente el uso de la pluralización en la búsqueda en la web.",
        "Como debemos señalar, el método que proponemos no se limita al manejo de la pluralización, es una técnica de derivación general y también se puede aplicar a la expansión de consultas en general.",
        "Los experimentos sobre el truncamiento general producen mejoras significativas adicionales sobre el manejo de la pluralización para consultas largas, aunque los detalles no se informarán en este artículo.",
        "En el resto del documento, primero presentamos el trabajo relacionado y distinguimos nuestro método de trabajos anteriores en la Sección 2.",
        "Describimos los detalles del enfoque de derivación sensible al contexto en la Sección 3.",
        "Luego realizamos experimentos extensos en un importante motor de búsqueda web para respaldar nuestras afirmaciones en la Sección 4, seguidos de discusiones en la Sección 5.",
        "Finalmente, concluimos el artículo en la Sección 6.2.",
        "TRABAJO RELACIONADO El stemming es una tecnología estudiada desde hace mucho tiempo.",
        "Se han desarrollado muchos stemmers, como el stemmer Lovins [16] y el stemmer Porter [18].",
        "El stemmer de Porter es ampliamente utilizado debido a su simplicidad y efectividad en muchas aplicaciones.",
        "Sin embargo, el algoritmo de Porter comete muchos errores porque sus reglas simples no pueden describir completamente la morfología del inglés.",
        "El análisis de corpus se utiliza para mejorar el stemmer de Porter [26] mediante la creación de clases de equivalencia para palabras que son morfológicamente similares y que ocurren en un contexto similar, medido por la información mutua esperada [23].",
        "Utilizamos un enfoque de corpus similar para el stemming al calcular la similitud entre dos palabras basada en sus características de contexto distribucional, que pueden ser más que solo palabras adyacentes [15], y luego solo mantenemos las palabras morfológicamente similares como candidatas.",
        "El uso de la derivación en la recuperación de información también es una técnica bien conocida [8, 10].",
        "Sin embargo, se informó previamente que la efectividad del truncamiento para los sistemas de consulta en inglés era bastante limitada.",
        "Lennon et al. [17] compararon los algoritmos de Lovins y Porter y encontraron poco mejoramiento en el rendimiento de recuperación.",
        "Más tarde, Harman [9] compara tres técnicas generales de derivación en experimentos de recuperación de texto, incluido el manejo de pluralización (llamado S stemmer en el artículo).",
        "También propusieron el truncamiento selectivo basado en la longitud de la consulta y la importancia del término, pero no se informaron resultados positivos.",
        "Por otro lado, Krovetz [14] realizó comparaciones sobre un pequeño número de documentos (de 400 a 12k) y mostró una mejora dramática en la precisión (de hasta un 45%).",
        "Sin embargo, debido al número limitado de consultas probadas (menos de 100) y al tamaño reducido de la colección, los resultados son difíciles de generalizar para la búsqueda en la web.",
        "Estos resultados mixtos, en su mayoría fracasos, llevaron a los primeros investigadores de IR a considerar que el truncamiento era irrelevante en general para el inglés [4], aunque investigaciones recientes han demostrado que el truncamiento tiene mayores beneficios para la recuperación en otros idiomas [2].",
        "Sospechamos que los fracasos anteriores se debieron principalmente a los dos problemas que mencionamos en la introducción.",
        "El stemming ciego, o un stemming selectivo basado en la longitud de la consulta como se utiliza en [9], no es suficiente.",
        "El truncamiento debe decidirse caso por caso, no solo a nivel de consulta sino también a nivel de documento.",
        "Como demostraremos, si se maneja correctamente, se puede lograr una mejora significativa.",
        "Un problema más general relacionado con el stemming es la reformulación de consultas [3, 12] y la expansión de consultas que amplía las palabras no solo con variantes de palabras [7, 22, 24, 25].",
        "Para decidir qué palabras expandidas usar, las personas a menudo utilizan técnicas de retroalimentación de seudorelevancia que envían la consulta original a un motor de búsqueda y recuperan los documentos principales, extraen palabras relevantes de estos documentos principales como palabras de consulta adicionales y vuelven a enviar la consulta expandida nuevamente [21].",
        "Esto normalmente requiere enviar una consulta varias veces al motor de búsqueda y no es rentable para procesar la gran cantidad de consultas involucradas en la búsqueda web.",
        "Además, la expansión de consultas, incluida la reformulación de consultas [3, 12], tiene un alto riesgo de cambiar la intención del usuario (llamado desviación de consulta).",
        "Dado que las palabras expandidas pueden tener diferentes significados, agregarlas a la consulta podría potencialmente cambiar la intención de la consulta original.",
        "Por lo tanto, la expansión de consultas basada en pseudorelevancia y la reformulación de consultas pueden proporcionar sugerencias a los usuarios para su refinamiento interactivo, pero difícilmente pueden ser utilizadas directamente para la búsqueda en la web.",
        "Por otro lado, el truncamiento es mucho más conservador ya que la mayoría de las veces, conserva la intención de búsqueda original.",
        "Si bien la mayoría de los trabajos sobre la expansión de consultas se centran en mejorar la recuperación, nuestro trabajo se enfoca en aumentar tanto la recuperación como la precisión.",
        "El aumento en el recuerdo es evidente.",
        "Con el stemming de calidad, los buenos documentos que no fueron seleccionados antes del stemming serán promovidos y aquellos documentos de baja calidad serán degradados.",
        "En la expansión selectiva de consultas, Cronen-Townsend et al. [6] propusieron un método para la expansión selectiva de consultas basado en comparar la divergencia de Kullback-Leibler de los resultados de la consulta no expandida y los resultados de la consulta expandida.",
        "Esto es similar a la retroalimentación de relevancia en el sentido de que requiere múltiples pasadas de recuperación.",
        "Si una palabra puede expandirse en varias palabras, se requiere ejecutar este proceso varias veces para decidir cuál palabra expandida es útil.",
        "Es costoso implementar esto en motores de búsqueda web en producción.",
        "Nuestro método predice la calidad de la expansión basándose en información sin conexión sin enviar la consulta a un motor de búsqueda.",
        "En resumen, proponemos un enfoque novedoso para abordar un problema antiguo, pero aún importante y desafiante para la búsqueda en la web: el stemming.",
        "Nuestro enfoque es único en el sentido de que realiza el truncamiento predictivo de forma individualizada para cada consulta sin retroalimentación de relevancia de la Web, utilizando el contexto de las variantes en los documentos para preservar la precisión.",
        "Es simple, pero muy eficiente y efectivo, lo que hace factible el truncamiento en tiempo real para la búsqueda en la web.",
        "Nuestros resultados confirmarán a los investigadores que el truncamiento es realmente muy importante para la recuperación de información a gran escala.",
        "STEMMING CONTEXTUAL SENSIBLE 3.1 Resumen Nuestro sistema tiene cuatro componentes como se ilustra en la Figura 1: generación de candidatos, segmentación de consultas y detección de palabras clave, derivación de consultas sensible al contexto y coincidencia de documentos sensible al contexto.",
        "La generación de candidatos (componente 1) se realiza fuera de línea y los candidatos generados se almacenan en un diccionario.",
        "Para una consulta de entrada, primero segmentamos la consulta en conceptos y detectamos la palabra principal de cada concepto (componente 2).",
        "Luego utilizamos modelado de lenguaje estadístico para decidir si una variante particular es útil (componente 3), y finalmente, para las variantes expandidas, realizamos un emparejamiento de documentos sensible al contexto (componente 4).",
        "A continuación discutimos cada uno de los componentes con más detalle.",
        "Componente 4: coincidencia de documentos sensibles al contexto Consulta de entrada: y detección de palabras clave Componente 2: segmento Componente 1: generación de candidatos comparaciones −> comparación Componente 3: decisión de expansión selectiva de palabras: comparaciones −> comparación ejemplo: comparaciones de precios de hoteles salida: comparaciones de hoteles hotel −> hoteles Figura 1: Componentes del sistema 3.2 Generación de candidatos de expansión Una de las formas de generar candidatos es utilizando el stemmer de Porter [18].",
        "El stemmer de Porter simplemente utiliza reglas morfológicas para convertir una palabra a su forma base.",
        "No tiene conocimiento del significado semántico de las palabras y a veces comete errores graves, como cambiar \"executive\" por \"execution\", \"news\" por \"new\" y \"paste\" por \"past\".",
        "Una forma más conservadora se basa en utilizar análisis de corpus para mejorar los resultados del stemmer de Porter [26].",
        "El análisis de corpus que realizamos se basa en la similitud distribucional de palabras [15].",
        "La razón de utilizar la similitud distribucional de palabras es que las variantes verdaderas tienden a ser utilizadas en contextos similares.",
        "En el cálculo de similitud de palabras distribucionales, cada palabra se representa con un vector de características derivadas del contexto de la palabra.",
        "Utilizamos los bigramas a la izquierda y a la derecha de la palabra como sus características de contexto, mediante la extracción de un gran corpus web.",
        "La similitud entre dos palabras es la similitud coseno entre los dos vectores de características correspondientes.",
        "Las 20 palabras similares a \"desarrollar\" se muestran en la siguiente tabla. rango candidato puntaje rango candidato puntaje 0 desarrollar 1 10 berts 0.119 1 desarrollando 0.339 11 wads 0.116 2 desarrollado 0.176 12 desarrollador 0.107 3 incubadora 0.160 13 promoviendo 0.100 4 desarrolla 0.150 14 desarrollo 0.091 5 desarrollo 0.148 15 reingeniería 0.090 6 tutoría 0.138 16 construir 0.083 7 analizando 0.128 17 construir 0.081 8 desarrollo 0.128 18 educativo 0.081 9 automatización 0.126 19 instituto 0.077 Tabla 1: Los 20 candidatos más similares a la palabra \"desarrollar\".",
        "La puntuación de la columna es la puntuación de similitud.",
        "Para determinar los candidatos de derivación, aplicamos algunas reglas morfológicas del stemmer de Porter [18] a la lista de similitud.",
        "Después de aplicar estas reglas, para la palabra desarrollar, los candidatos de derivación son desarrollando, desarrollado, desarrolla, desarrollo, desarrollo, desarrollador, y desarrollo.",
        "Para el propósito de manejo de pluralización, solo se conserva el candidato desarrolla.",
        "Una cosa que observamos al observar las palabras distribucionalmente similares es que están estrechamente relacionadas semánticamente.",
        "Estas palabras podrían servir como candidatas para la expansión general de consultas, un tema que investigaremos en el futuro. 3.3 Segmentación e identificación de palabras clave Para consultas largas, es bastante importante detectar los conceptos en la consulta y las palabras más importantes para esos conceptos.",
        "Primero dividimos una consulta en segmentos, cada segmento representando un concepto que normalmente es una frase nominal.",
        "Para cada una de las frases nominales, luego detectamos la palabra más importante a la que llamamos la palabra principal.",
        "La segmentación también se utiliza en la coincidencia sensible a documentos (sección 3.5) para hacer cumplir la proximidad.",
        "Para dividir una consulta en segmentos, tenemos que definir un criterio para medir la fuerza de la relación entre las palabras.",
        "Un método efectivo es utilizar la información mutua como indicador para decidir si dividir o no dos palabras [19].",
        "Utilizamos un registro de 25 millones de consultas y recopilamos las frecuencias de bigramas y unigramas a partir de él.",
        "Para cada consulta entrante, calculamos la información mutua de dos palabras adyacentes; si supera un umbral predefinido, no dividimos la consulta entre esas dos palabras y pasamos a la siguiente palabra.",
        "Continuamos este proceso hasta que la información mutua entre dos palabras esté por debajo del umbral, luego creamos un límite conceptual aquí.",
        "La Tabla 2 muestra algunos ejemplos de segmentación de consultas.",
        "La forma ideal de encontrar la palabra principal de un concepto es realizar un análisis sintáctico para determinar la estructura de dependencia de la consulta.",
        "El análisis de consultas es más difícil que el análisis de oraciones, ya que muchas consultas no son gramaticales y son muy cortas.",
        "Aplicar un analizador entrenado en oraciones de documentos a consultas tendrá un rendimiento deficiente.",
        "En nuestra solución, solo utilizamos reglas heurísticas simples, y funciona muy bien en la práctica para el inglés.",
        "Para una frase nominal en inglés, la palabra principal suele ser la última palabra no detenida, a menos que la frase siga un patrón particular, como XYZ de/en/a/desde UVW.",
        "En tales casos, la palabra principal suele ser la última palabra no detenida de XYZ. 3.4 Expansión de palabras sensibles al contexto Después de detectar cuáles son las palabras más importantes para expandir, debemos decidir si las expansiones serán útiles.",
        "Nuestras estadísticas muestran que aproximadamente la mitad de las consultas pueden ser transformadas mediante la pluralización a través de un truncamiento ingenuo.",
        "Entre esta mitad, aproximadamente el 25% de las consultas mejoran la relevancia cuando se transforman, la mayoría (alrededor del 50%) no cambian sus 5 resultados principales, y el 25% restante tiene un rendimiento peor.",
        "Por lo tanto, es extremadamente importante identificar qué consultas no deben ser truncadas con el fin de maximizar la mejora de relevancia y minimizar el costo de truncamiento.",
        "Además, para una consulta con múltiples palabras que pueden ser transformadas, o una palabra con múltiples variantes, no todas las expansiones son útiles.",
        "Tomando la comparación de precios de hoteles como ejemplo, decidimos que hotel y comparación de precios son dos conceptos.",
        "Las palabras clave hotel y comparación se pueden expandir a hoteles y comparaciones.",
        "¿Son útiles ambas transformaciones?",
        "Para probar si una expansión es útil, tenemos que saber si es probable que la consulta expandida obtenga más documentos relevantes de la web, lo cual puede cuantificarse mediante la probabilidad de que la consulta ocurra como una cadena en la web.",
        "Cuanto más probable sea que ocurra una consulta en la web, más documentos relevantes puede devolver esta consulta.",
        "Ahora todo el problema se convierte en cómo calcular la probabilidad de que ocurra la consulta en la Web.",
        "Calcular la probabilidad de que una cadena ocurra en un corpus es un problema bien conocido de modelado del lenguaje.",
        "El objetivo del modelado del lenguaje es predecir la probabilidad de secuencias de palabras que ocurren naturalmente, s = w1w2...wN; o más simplemente, asignar una alta probabilidad a las secuencias de palabras que realmente ocurren (y una baja probabilidad a las secuencias de palabras que nunca ocurren).",
        "El enfoque más simple y exitoso para el modelado del lenguaje sigue estando basado en el modelo n-gramo.",
        "Por la regla de la cadena de probabilidad, se puede escribir la probabilidad de cualquier secuencia de palabras como Pr(w1w2...wN) = ΠY i=1 Pr(wi|w1...wi−1) (1). Un modelo n-grama aproxima esta probabilidad asumiendo que las únicas palabras relevantes para predecir Pr(wi|w1...wi−1) son las n − 1 palabras anteriores; es decir,",
        "La probabilidad de una palabra wi dado w1...wi−1 es igual a la probabilidad de wi dado wi−n+1...wi−1. Una estimación directa de máxima verosimilitud de las probabilidades de n-gramas a partir de un corpus se obtiene a partir de la frecuencia observada de cada uno de los patrones Pr(wi|wi−n+1...wi−1) = #(wi−n+1...wi) #(wi−n+1...wi−1) donde #(.) denota el número de ocurrencias de un n-grama específico en el corpus de entrenamiento.",
        "Aunque se podría intentar usar modelos de n-gramos simples para capturar dependencias a largo plazo en el lenguaje, intentar hacerlo directamente crea inmediatamente problemas de datos dispersos: Utilizar n-gramos de longitud hasta n implica estimar la probabilidad de eventos de longitud Wn, donde W es el tamaño del vocabulario de palabras.",
        "Esto rápidamente abruma los recursos computacionales y de datos modernos incluso para opciones modestas de n (más allá de 3 a 6).",
        "Además, debido a la naturaleza de cola pesada del lenguaje (es decir,",
        "La ley de Zipf) es probable que uno se encuentre con n-gramas novedosos que nunca fueron observados durante el entrenamiento en ningún corpus de prueba, por lo tanto, algún mecanismo para asignar una probabilidad distinta de cero a los n-gramas novedosos es un problema central e inevitable en la modelización estadística del lenguaje.",
        "Un enfoque estándar para suavizar las estimaciones de probabilidad para hacer frente a problemas de datos escasos (y para hacer frente a posibles n-gramas faltantes) es utilizar algún tipo de estimador de retroceso.",
        "Pr(wi|wi−n+1...wi−1) = 8 >>< >>: ˆPr(wi|wi−n+1...wi−1), si #(wi−n+1...wi) > 0 β(wi−n+1...wi−1) × Pr(wi|wi−n+2...wi−1), de lo contrario (3) donde ˆPr(wi|wi−n+1...wi−1) = descuento #(wi−n+1...wi) #(wi−n+1...wi−1) (4) es la probabilidad descontada y β(wi−n+1...wi−1) es una constante de normalización β(wi−n+1...wi−1) = 1 − X x∈(wi−n+1...wi−1x) ˆPr(x|wi−n+1...wi−1) 1 − X x∈(wi−n+1...wi−1x) ˆPr(x|wi−n+2...wi−1) (5) La probabilidad descontada (4) se puede calcular con diferentes técnicas de suavizado, incluido el suavizado absoluto, el suavizado de Good-Turing, el suavizado lineal y el suavizado de Witten-Bell [5].",
        "Utilizamos suavizado absoluto en nuestros experimentos.",
        "Dado que la probabilidad de una cadena, Pr(w1w2...wN), es un número muy pequeño y difícil de interpretar, utilizamos la entropía, tal como se define a continuación, para puntuar la cadena.",
        "Entropía = − 1 N log2 Pr(w1w2...wN ) (6) Ahora volviendo al ejemplo de la comparación de precios de hoteles, hay cuatro variantes de esta consulta, y la entropía de estos cuatro candidatos se muestra en la Tabla 3.",
        "Podemos ver que todas las alternativas son menos probables que la consulta de entrada.",
        "Por lo tanto, no es útil hacer una expansión para esta consulta.",
        "Por otro lado, si la consulta de entrada son comparaciones de precios de hoteles, que es la segunda alternativa en la tabla, entonces hay una mejor alternativa que la consulta de entrada, y por lo tanto debería ser ampliada.",
        "Para tolerar las variaciones en la estimación de probabilidad, relajamos el criterio de selección para esas alternativas de consulta si sus puntuaciones están dentro de una cierta distancia (10% en nuestros experimentos) de la mejor puntuación.",
        "Variaciones de la consulta Comparación de precios de hoteles 6.177 comparaciones de precios de hoteles 6.597 comparación de precios de hoteles 6.937 comparaciones de precios de hoteles 7.360 Tabla 3: Variaciones de la consulta comparación de precios de hoteles clasificadas por puntaje de entropía, con la consulta original en negrita. 3.5 Coincidencia de documentos sensibles al contexto Aun después de saber qué variantes de palabras son probablemente útiles, debemos ser conservadores en la coincidencia de documentos para las variantes ampliadas.",
        "Para la consulta de comparaciones de precios de hoteles, decidimos que la palabra \"comparaciones\" se amplía para incluir \"comparación\".",
        "Sin embargo, no todos los casos de comparación en el documento son de interés.",
        "Una página que trata sobre comparar el servicio al cliente puede contener todas las palabras comparaciones de precios de hoteles comparación.",
        "Esta página no es una buena página para la consulta.",
        "Si aceptamos coincidencias de cada ocurrencia de comparación, afectará la precisión de recuperación y esta es una de las principales razones por las que la mayoría de los enfoques de derivación no funcionan bien para la recuperación de información.",
        "Para abordar este problema, tenemos una restricción de proximidad que considera el contexto alrededor de la variante expandida en el documento.",
        "Una coincidencia de variante se considera válida solo si la variante ocurre en el mismo contexto que la palabra original lo hace.",
        "El contexto son los segmentos continuos de la izquierda o de la derecha de la palabra original.",
        "Tomando la misma consulta como ejemplo, el contexto de las comparaciones es el precio.",
        "La comparación de palabras ampliada solo es válida si está en el mismo contexto de comparaciones, que es después de la palabra precio.",
        "Por lo tanto, solo debemos emparejar aquellas ocurrencias de comparación en el documento si ocurren después de la palabra precio.",
        "Considerando el hecho de que las consultas y los documentos pueden no representar la intención de la misma manera exacta, relajamos esta restricción de proximidad para permitir ocurrencias variantes dentro de una ventana de un tamaño fijo.",
        "Si la comparación de palabras expandidas ocurre dentro del contexto de precio dentro de una ventana, se considera válida.",
        "Cuanto más pequeño sea el tamaño de la ventana, más restrictiva será la coincidencia.",
        "Utilizamos un tamaño de ventana de 4, que normalmente captura contextos que incluyen las frases nominales que contienen y las adyacentes. 4.",
        "EVALUACIÓN EXPERIMENTAL 4.1 Métricas de evaluación Mediremos tanto la mejora de relevancia como el costo de derivación necesario para lograr la relevancia. 1 un segmento de contexto no puede ser una sola palabra de parada. 4.1.1 Medición de relevancia Utilizamos una variante de la Ganancia Acumulada Descontada Promedio (DCG), un esquema recientemente popularizado para medir la relevancia de los motores de búsqueda [1, 11].",
        "Dada una consulta y una lista clasificada de K documentos (K se establece en 5 en nuestros experimentos), el puntaje DCG(K) para esta consulta se calcula de la siguiente manera: DCG(K) = Σ k=1 a K gk log2(1 + k) . (7) donde gk es el peso para el documento en la posición k. Un mayor grado de relevancia corresponde a un peso mayor.",
        "Una página se califica en una de las cinco escalas: Perfecto, Excelente, Bueno, Regular, Malo, con pesos correspondientes.",
        "Utilizamos DCG para representar el DCG promedio(5) sobre un conjunto de consultas de prueba. 4.1.2 Costo de derivación Otro métrica es medir el costo adicional incurrido por la derivación.",
        "Dado el mismo nivel de mejora en la relevancia, preferimos un método de truncamiento que tenga un menor costo adicional.",
        "Medimos esto por el porcentaje de consultas que realmente se reducen, sobre todas las consultas que podrían ser reducidas. 4.2 Preparación de datos Muestreamos aleatoriamente 870 consultas de un registro de consultas de tres meses, con 290 de cada mes.",
        "Entre todas estas 870 consultas, eliminamos todas las consultas con errores ortográficos ya que las consultas con errores ortográficos no son de interés para el stemming.",
        "También eliminamos todas las consultas de una sola palabra, ya que reducir las consultas de una sola palabra sin contexto tiene un alto riesgo de cambiar la intención de la consulta, especialmente para palabras cortas.",
        "Al final, tenemos 529 consultas correctamente escritas con al menos 2 palabras. 4.3 Stemming ingenuo para la búsqueda en la Web Antes de explicar en detalle los experimentos y resultados, nos gustaría describir la forma tradicional de usar el stemming para la búsqueda en la Web, conocida como el modelo ingenuo.",
        "Esto es para tratar cada variante de palabra equivalente para todas las posibles palabras en la consulta.",
        "La consulta de la librería se transformará en (libro O libros)(tienda O tiendas) al limitar el truncamiento al manejo de pluralización solamente, donde O es un operador que denota la equivalencia de los argumentos izquierdo y derecho. 4.4 Configuración experimental El modelo base es el modelo sin truncamiento.",
        "Primero ejecutamos el modelo ingenuo para ver qué tan bien se desempeña en comparación con el punto de referencia.",
        "Luego mejoramos el modelo de derivación ingenua mediante la coincidencia sensible al documento, denominado modelo de coincidencia sensible al documento.",
        "Este modelo realiza el mismo stemming que el modelo ingenuo en el lado de la consulta, pero realiza un emparejamiento conservador en el lado del documento utilizando la estrategia descrita en la sección 3.5.",
        "El modelo ingenuo y el modelo de coincidencia sensible al documento son los que mejor responden a la mayoría de las consultas.",
        "De las 529 consultas, hay 408 consultas que se originan, lo que corresponde al 46.7% del tráfico de consultas (de un total de 870).",
        "Luego mejoramos aún más el modelo de coincidencia sensible de documentos desde el lado de la consulta con un proceso de derivación de palabras selectivo basado en modelado estadístico del lenguaje (sección 3.4), denominado modelo de derivación selectiva.",
        "Basado en la predicción del modelado del lenguaje, este modelo deriva solo un subconjunto de las 408 consultas derivadas por el modelo de coincidencia sensible al documento.",
        "Experimentamos con un modelo de lenguaje unigrama y un modelo de lenguaje bigrama.",
        "Dado que solo nos importa cuánto podemos mejorar el modelo ingenuo, solo utilizaremos estas 408 consultas (todas las consultas que se ven afectadas por el modelo de derivación ingenuo) en los experimentos.",
        "Para tener una idea de cómo se desempeñan estos modelos, también tenemos un modelo oráculo que proporciona el rendimiento máximo que un stemmer puede lograr en estos datos.",
        "El modelo del oráculo solo expande una palabra si el truncamiento dará mejores resultados.",
        "Para analizar la influencia del manejo de la pluralización en diferentes categorías de consultas, dividimos las consultas en consultas cortas y consultas largas.",
        "Entre las 408 consultas generadas por el modelo ingenuo, hay 272 consultas cortas con 2 o 3 palabras, y 136 consultas largas con al menos 4 palabras. Resumimos los resultados generales en la Tabla 4, y presentamos los resultados de las consultas cortas y largas por separado en la Tabla 5.",
        "Cada fila en la Tabla 4 es una estrategia de derivación descrita en la sección 4.4.",
        "La primera columna es el nombre de la estrategia.",
        "La segunda columna es el número de consultas afectadas por esta estrategia; esta columna mide el costo de derivación, y los números deberían ser bajos para el mismo nivel de dcg.",
        "La tercera columna es la puntuación DCG promedio sobre todas las consultas probadas en esta categoría (incluyendo aquellas que no fueron truncadas por la estrategia).",
        "La cuarta columna es la mejora relativa sobre la línea base, y la última columna es el valor p de la prueba de significancia de Wilcoxon.",
        "Hay varias observaciones sobre los resultados.",
        "Podemos ver que el truncado ingenuo solo logra una mejora estadísticamente insignificante del 1.5%.",
        "Mirando la Tabla 5, se observa una mejora del 2.7% en las consultas cortas.",
        "Sin embargo, también perjudica las consultas largas en un -2.4%.",
        "En general, la mejora se cancela.",
        "La razón por la que mejora las consultas cortas es que la mayoría de las consultas cortas solo tienen una palabra que se puede reducir a su raíz.",
        "Por lo tanto, pluralizar ciegamente consultas cortas es relativamente seguro.",
        "Sin embargo, para consultas largas, la mayoría de las consultas pueden tener varias palabras que pueden ser pluralizadas.",
        "Expandir todos ellos sin selección perjudicará significativamente la precisión.",
        "La aplicación de un stemming sensible al contexto del documento proporciona un aumento significativo en el rendimiento, desde un 2.7% hasta un 4.2% para consultas cortas y desde un -2.4% hasta un -1.6% para consultas largas, con un aumento general del 1.5% al 2.8%.",
        "La mejora proviene de la coincidencia de documentos sensible al contexto conservador.",
        "Una palabra expandida es válida solo si ocurre dentro del contexto de la consulta original en el documento.",
        "Esto reduce muchas coincidencias falsas.",
        "Sin embargo, aún observamos que para consultas largas, el truncamiento sensible al contexto no logra mejorar el rendimiento porque sigue seleccionando demasiados documentos y le presenta a la función de clasificación un problema difícil.",
        "Si bien el tamaño de ventana elegido de 4 es el que mejor funciona entre todas las opciones, aún permite coincidencias espurias.",
        "Es posible que el tamaño de la ventana deba elegirse según la consulta para garantizar restricciones de proximidad más estrictas para diferentes tipos de frases nominales.",
        "La pluralización selectiva de palabras ayuda aún más a resolver el problema enfrentado por el truncamiento sensible al contexto del documento.",
        "No se aplica el truncamiento a cada palabra que coloca toda la carga en el algoritmo de clasificación, sino que intenta eliminar el truncamiento innecesario en primer lugar.",
        "Al predecir qué variantes de palabras van a ser útiles, podemos reducir drásticamente el número de palabras derivadas, mejorando así tanto la recuperación como la precisión.",
        "Con el modelo de lenguaje unigrama, podemos reducir el costo de derivación en un 26.7% (de 408/408 a 300/408) y aumentar la mejora general de DCG del 2.8% al 3.4%.",
        "En particular, proporciona mejoras significativas en consultas largas.",
        "La ganancia de DCG se cambia de negativa a positiva, de -1.6% a 1.1%.",
        "Esto confirma nuestra hipótesis de que reducir la expansión innecesaria de palabras conduce a una mejora en la precisión.",
        "Para consultas cortas también observamos tanto la mejora de dcg como la reducción del costo de derivación con el modelo de lenguaje unigrama.",
        "Las ventajas de la expansión predictiva de palabras con un modelo de lenguaje se potencian aún más con un mejor modelo de lenguaje de bigrama.",
        "La ganancia total de DCG aumenta de 3.4% a 3.9%, y el costo de derivación se reduce drásticamente de 408/408 a 250/408, correspondiente a solo el 29% del tráfico de consultas (250 de 870) y una mejora total de DCG del 1.8% en todo el tráfico de consultas.",
        "Para consultas cortas, el modelo de lenguaje de bigrama mejora la ganancia de DCG del 4.4% al 4.7%, y reduce el costo de derivación de 272/272 a 150/272.",
        "Para consultas largas, el modelo de lenguaje de bigrama mejora la ganancia de DCG del 1.1% al 2.5%, y reduce el costo de derivación de 136/136 a 100/136.",
        "Observamos que el modelo de lenguaje de bigrama proporciona un mayor aumento para consultas largas.",
        "Esto se debe a que la incertidumbre en las consultas largas es mayor y se necesita un modelo de lenguaje más potente.",
        "Hacemos la hipótesis de que un modelo de lenguaje de trigramas proporcionaría un impulso adicional para consultas largas y dejamos esto para investigaciones futuras.",
        "Considerando el límite superior estricto de 2 en la mejora que se puede obtener del manejo de la pluralización (a través del modelo oráculo), el rendimiento actual en consultas cortas es muy satisfactorio.",
        "Para consultas breves, la ganancia máxima de DCG es del 6.3% para el manejo perfecto de la pluralización, nuestra ganancia actual es del 4.7% con un modelo de lenguaje de bigrama.",
        "Para consultas largas, la ganancia máxima de DCG es del 4.6% para el manejo perfecto de la pluralización, nuestra ganancia actual es del 2.5% con un modelo de lenguaje de bigrama.",
        "Podríamos obtener beneficios adicionales con un modelo de lenguaje más potente para consultas largas.",
        "Sin embargo, las dificultades de las consultas largas provienen de muchos otros aspectos, incluyendo la proximidad y el problema de la segmentación.",
        "Estos problemas deben ser abordados por separado.",
        "Al observar el límite superior de reducción de gastos generales para el truncamiento de Oracle, el 75% (308/408) de los truncamientos ingenuos son inútiles.",
        "Actualmente capturamos alrededor de la mitad de ellos.",
        "La reducción adicional de los gastos generales requiere sacrificar la ganancia de la DCG.",
        "Ahora podemos comparar las estrategias de derivación desde un aspecto diferente.",
        "En lugar de analizar la influencia sobre todas las consultas como describimos anteriormente, la Tabla 6 resume las mejoras de DCG solo sobre las consultas afectadas.",
        "Podemos ver que el número de consultas afectadas disminuye a medida que la estrategia de derivación se vuelve más precisa (mejora en el dcg).",
        "Para el modelo de lenguaje de bigrama, sobre las 250/408 consultas truncadas, la mejora en DCG es del 6.1%.",
        "Una observación interesante es que el dcg promedio disminuye con un modelo mejor, lo que indica que una estrategia de derivación mejorada deriva consultas más difíciles (consultas con bajo dcg). 5.",
        "Como mencionamos en la Sección 1, estamos tratando de predecir la probabilidad de que una cadena ocurra en la Web.",
        "El modelo de lenguaje debe describir la ocurrencia de la cadena en la web.",
        "Sin embargo, el registro de consultas también es un buen recurso. Tenga en cuenta que este límite superior es solo para el manejo de pluralización, no para el truncamiento general.",
        "El stemming general proporciona un límite superior del 8%, lo cual es bastante sustancial en términos de nuestras métricas.",
        "Las consultas afectadas dcg dcg Mejora p-valor línea de base 0/408 7.102 N/A N/A modelo ingenuo 408/408 7.206 1.5% 0.22 modelo sensible al contexto del documento 408/408 7.302 2.8% 0.014 modelo selectivo: unigram LM 300/408 7.321 3.4% 0.001 modelo selectivo: bigram LM 250/408 7.381 3.9% 0.001 modelo oráculo 100/408 7.519 5.9% 0.001 Tabla 4: Comparación de resultados de diferentes estrategias de derivación en todas las consultas afectadas por la derivación ingenua Resultados de Consultas Cortas Consultas Afectadas dcg Mejora p-valor línea de base 0/272 N/A N/A modelo ingenuo 272/272 2.7% 0.48 modelo sensible al contexto del documento 272/272 4.2% 0.002 modelo selectivo: unigram LM 185/272 4.4% 0.001 modelo selectivo: bigram LM 150/272 4.7% 0.001 modelo oráculo 71/272 6.3% 0.001 Resultados de Consultas Largas Consultas Afectadas dcg Mejora p-valor línea de base 0/136 N/A N/A modelo ingenuo 136/136 -2.4% 0.25 modelo sensible al contexto del documento 136/136 -1.6% 0.27 modelo selectivo: unigram LM 115/136 1.1% 0.001 modelo selectivo: bigram LM 100/136 2.5% 0.001 modelo oráculo 29/136 4.6% 0.001 Tabla 5: Comparación de resultados de diferentes estrategias de derivación en consultas cortas y largas en general Los usuarios reformulan una consulta utilizando muchas variantes diferentes para obtener buenos resultados.",
        "Para probar la hipótesis de que podemos aprender probabilidades de transformación confiables a partir del registro de consultas, entrenamos un modelo de lenguaje con las mismas 25 millones de consultas principales utilizadas para aprender la segmentación, y lo utilizamos para la predicción.",
        "Observamos una ligera disminución en el rendimiento en comparación con el modelo entrenado en frecuencias web.",
        "En particular, el rendimiento para el modelo de lenguaje unigrama no se vio afectado, pero la ganancia de dcg para el modelo de lenguaje bigrama cambió de 4.7% a 4.5% para consultas cortas.",
        "Por lo tanto, el registro de consultas puede servir como una buena aproximación de las frecuencias web. 5.2 Cómo la lingüística ayuda. Algunos conocimientos lingüísticos son útiles en el stemming.",
        "Para el manejo de la pluralización, la pluralización y la despluralización no son simétricas.",
        "Una palabra en plural utilizada en una consulta indica una intención especial.",
        "Por ejemplo, la consulta hoteles en Nueva York está buscando una lista de hoteles en Nueva York, no el hotel específico de Nueva York que podría estar ubicado en California.",
        "Una simple equivalencia de hotel a hoteles podría impulsar una página en particular sobre hoteles en Nueva York al primer puesto.",
        "Para capturar esta intención, tenemos que asegurarnos de que el documento sea una página general sobre hoteles en Nueva York.",
        "Esto lo hacemos exigiendo que la palabra en plural hoteles aparezca en el documento.",
        "Por otro lado, convertir una palabra singular a plural es más seguro ya que una página de propósito general normalmente contiene información específica.",
        "Observamos una ligera disminución general en el dcg, aunque no estadísticamente significativa, para el stemming sensible al contexto del documento si no consideramos esta propiedad asimétrica. Análisis de errores. Un tipo de errores que notamos, aunque raros pero que afectan seriamente la relevancia, es el cambio de intención de búsqueda después del stemming.",
        "En general, la pluralización o despluralización mantiene la intención original.",
        "Sin embargo, la intención podría cambiar en algunos casos.",
        "Por ejemplo, para una consulta de este tipo, trabajo en Apple, pluralizamos trabajo a trabajos.",
        "Este truncamiento hace que la consulta original sea ambigua.",
        "El trabajo de consulta O trabajos en Apple tiene dos intenciones.",
        "Una de las oportunidades laborales en Apple, y otra es una persona que trabaja en Apple, Steve Jobs, quien es el CEO y cofundador de la empresa.",
        "Por lo tanto, los resultados después de la reducción de consultas devuelven a Steve Jobs como uno de los resultados en el top 5.",
        "Una solución es realizar un análisis basado en el conjunto de resultados para verificar si la intención ha cambiado.",
        "Esto es similar a la retroalimentación de relevancia y requiere una clasificación en la segunda fase.",
        "Un segundo tipo de errores es el problema de reconocimiento de entidades/conceptos. Estos incluyen dos tipos.",
        "Una de ellas es que la variante de la palabra derivada ahora coincide con parte de una entidad o concepto.",
        "Por ejemplo, la consulta \"cookies en San Francisco\" se pluraliza como \"cookies\" O \"cookie en San Francisco\".",
        "Los resultados coincidirán con el tarro de galletas en San Francisco.",
        "Aunque \"cookie\" todavía significa lo mismo que \"galletas\", el concepto de \"cookie jar\" es diferente.",
        "Otro tipo es la palabra no derivada que coincide con una entidad o concepto debido al truncamiento de las otras palabras.",
        "Por ejemplo, la cita ICE se pluraliza como cita OR citas ICE.",
        "La intención original de esta consulta es buscar la cotización de acciones para el símbolo ICE.",
        "Sin embargo, notamos que entre los resultados principales, uno de los resultados es Citas sobre comida: Helado.",
        "Esto se empareja debido a las consultas afectadas dcg antiguas nuevas dcg dcg Mejora del modelo ingenuo 408/408 7.102 7.206 1.5% modelo sensible al contexto del documento 408/408 7.102 7.302 2.8% modelo selectivo: unigram LM 300/408 5.904 6.187 4.8% modelo selectivo: bigram LM 250/408 5.551 5.891 6.1% Tabla 6: Comparación de resultados solo sobre las consultas derivadas: la columna dcg antigua/nueva es la puntuación dcg sobre las consultas afectadas antes/después de aplicar la pluralización de la palabra entre comillas.",
        "La palabra inalterada ICE coincide con parte de la frase nominal helado aquí.",
        "Para resolver este tipo de problema, tenemos que analizar los documentos y reconocer \"cookie jar\" y \"ice cream\" como conceptos en lugar de dos palabras independientes.",
        "Un tercer tipo de errores ocurre en consultas largas.",
        "Para la consulta de software lector de códigos de barras, se pluralizan dos palabras. Códigos y lector.",
        "De hecho, el lector de códigos de barras en la consulta original es un concepto sólido y las palabras internas no deben ser cambiadas.",
        "Este es el problema de segmentación y detección de entidades y frases nominales en consultas, el cual estamos abordando activamente.",
        "Para consultas largas, debemos identificar correctamente los conceptos en la consulta y aumentar la proximidad de las palabras dentro de un concepto. 6.",
        "CONCLUSIONES Y TRABAJOS FUTUROS Hemos presentado una forma simple pero elegante de derivar palabras para la búsqueda en la web.",
        "Mejora el stemming ingenuo en dos aspectos: la expansión selectiva de palabras en el lado de la consulta y la coincidencia conservadora de ocurrencias de palabras en el lado del documento.",
        "Usando el manejo de pluralización como ejemplo, experimentos con datos de un motor de búsqueda web importante muestran que mejora significativamente la relevancia web y reduce el costo de derivación.",
        "También mejora significativamente la tasa de clics en la web (detalles no reportados en el artículo).",
        "Para el trabajo futuro, estamos investigando los problemas que identificamos en la sección de análisis de errores.",
        "Estos incluyen: errores de concordancia entre entidades y frases nominales, y una segmentación mejorada. 7.",
        "REFERENCIAS [1] E. Agichtein, E. Brill y S. T. Dumais.",
        "Mejorando la clasificación de búsqueda web al incorporar información sobre el comportamiento del usuario.",
        "En SIGIR, 2006. [2] E. Airio.",
        "Normalización de palabras y descomposición en IR monolingüe y bilingüe.",
        "Recuperación de información, 9:249-271, 2006. [3] P. Anick.",
        "Utilizando retroalimentación terminológica para el refinamiento de la búsqueda web: un estudio basado en registros.",
        "En SIGIR, 2003. [4] R. Baeza-Yates y B. Ribeiro-Neto.",
        "Recuperación de información moderna.",
        "ACM Press/Addison Wesley, 1999. [5] S. Chen y J. Goodman.",
        "Un estudio empírico de técnicas de suavizado para modelado del lenguaje.",
        "Informe técnico TR-10-98, Universidad de Harvard, 1998. [6] S. Cronen-Townsend, Y. Zhou y B. Croft.",
        "Un marco para la expansión selectiva de consultas.",
        "En CIKM, 2004. [7] H. Fang y C. Zhai.",
        "Coincidencia de términos semánticos en enfoques axiomáticos para la recuperación de información.",
        "En SIGIR, 2006. [8] W. B. Frakes.",
        "Confluencia de términos para la recuperación de información.",
        "En C. J. Rijsbergen, editor, Investigación y Desarrollo en Recuperación de Información, páginas 383-389.",
        "Cambridge University Press, 1984. [9] D. Harman.\nCambridge University Press, 1984. [9] D. Harman.",
        "¿Qué tan efectivo es el sufijado?",
        "JASIS, 42(1):7-15, 1991. [10] D. Hull.\nJASIS, 42(1):7-15, 1991. [10] D. Hull.",
        "Algoritmos de derivación: un estudio de caso para una evaluación detallada.",
        "JASIS, 47(1):70-84, 1996. [11] K. Jarvelin y J. Kekalainen.",
        "Evaluación basada en la ganancia acumulada de técnicas de RI.",
        "ACM TOIS, 20:422-446, 2002. [12] R. Jones, B. Rey, O. Madani y W. Greiner.",
        "Generando Sustituciones de Consultas.",
        "En WWW, 2006. [13] W. Kraaij y R. Pohlmann.",
        "Viendo el Stemming como Mejora de la Recuperación.",
        "En SIGIR, 1996. [14] R. Krovetz.",
        "Viendo la morfología como un proceso de inferencia.",
        "En SIGIR, 1993. [15] D. Lin.",
        "Recuperación automática y agrupamiento de palabras similares.",
        "En COLING-ACL, 1998. [16] J.",
        "B. Lovins.",
        "Desarrollo de un algoritmo de derivación.",
        "Traducción Mecánica y Lingüística Computacional, II:22-31, 1968. [17] M. Lennon, D. Peirce, B. Tarry y P. Willett.",
        "Una evaluación de algunos algoritmos de confluencia para la recuperación de información.",
        "Revista de Ciencia de la Información, 3:177-188, 1981. [18] M. Porter.",
        "Un algoritmo para el recorte de sufijos.",
        "Programa, 14(3):130-137, 1980. [19] K. M. Risvik, T. Mikolajewski y P. Boros.",
        "Segmentación de consultas para búsqueda web.",
        "En WWW, 2003. [20] S. E. Robertson.",
        "Selección de términos para la expansión de consultas.",
        "Revista de Documentación, 46(4):359-364, 1990. [21] G. Salton y C. Buckley.",
        "Mejorando el rendimiento de recuperación mediante retroalimentación de relevancia.",
        "JASIS, 41(4):288 - 297, 1999. [22] R. Sun, C.-H. Ong, y T.-S. Chua.",
        "Extracción de relaciones de dependencia para la expansión de consultas en la recuperación de pasajes.",
        "En SIGIR, 2006. [23] C. Van Rijsbergen.",
        "Recuperación de información.",
        "Butterworths, segunda versión, 1979. [24] B. Vélez, R. Weiss, M. A. Sheldon y D. K. Gifford.",
        "Refinamiento de consultas rápido y efectivo.",
        "En SIGIR, 1997. [25] J. Xu y B. Croft.",
        "Expansión de consultas utilizando análisis local y global de documentos.",
        "En SIGIR, 1996. [26] J. Xu y B. Croft.",
        "Extracción de raíces basada en corpus utilizando la coocurrencia de variantes de palabras.",
        "ACM TOIS, 16 (1):61-81, 1998."
    ],
    "error_count": 1,
    "keys": {
        "web search": {
            "translated_key": "búsqueda web",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Context Sensitive Stemming for <br>web search</br> Fuchun Peng Nawaaz Ahmed Xin Li Yumao Lu Yahoo!",
                "Inc. 701 First Avenue Sunnyvale, California 94089 {fuchun, nawaaz, xinli, yumaol}@yahoo-inc.com ABSTRACT Traditionally, stemming has been applied to Information Retrieval tasks by transforming words in documents to the their root form before indexing, and applying a similar transformation to query terms.",
                "Although it increases recall, this naive strategy does not work well for <br>web search</br> since it lowers precision and requires a significant amount of additional computation.",
                "In this paper, we propose a context sensitive stemming method that addresses these two issues.",
                "Two unique properties make our approach feasible for <br>web search</br>.",
                "First, based on statistical language modeling, we perform context sensitive analysis on the query side.",
                "We accurately predict which of its morphological variants is useful to expand a query term with before submitting the query to the search engine.",
                "This dramatically reduces the number of bad expansions, which in turn reduces the cost of additional computation and improves the precision at the same time.",
                "Second, our approach performs a context sensitive document matching for those expanded variants.",
                "This conservative strategy serves as a safeguard against spurious stemming, and it turns out to be very important for improving precision.",
                "Using word pluralization handling as an example of our stemming approach, our experiments on a major <br>web search</br> engine show that stemming only 29% of the query traffic, we can improve relevance as measured by average Discounted Cumulative Gain (DCG5) by 6.1% on these queries and 1.8% over all query traffic.",
                "Categories and Subject Descriptors H.3.3 [Information Systems]: Information Storage and Retrieval-Query formulation General Terms Algorithms, Experimentation 1.",
                "INTRODUCTION <br>web search</br> has now become a major tool in our daily lives for information seeking.",
                "One of the important issues in <br>web search</br> is that user queries are often not best formulated to get optimal results.",
                "For example, running shoe is a query that occurs frequently in query logs.",
                "However, the query running shoes is much more likely to give better search results than the original query because documents matching the intent of this query usually contain the words running shoes.",
                "Correctly formulating a query requires the user to accurately predict which word form is used in the documents that best satisfy his or her information needs.",
                "This is difficult even for experienced users, and especially difficult for non-native speakers.",
                "One traditional solution is to use stemming [16, 18], the process of transforming inflected or derived words to their root form so that a search term will match and retrieve documents containing all forms of the term.",
                "Thus, the word run will match running, ran, runs, and shoe will match shoes and shoeing.",
                "Stemming can be done either on the terms in a document during indexing (and applying the same transformation to the query terms during query processing) or by expanding the query with the variants during query processing.",
                "Stemming during indexing allows very little flexibility during query processing, while stemming by query expansion allows handling each query differently, and hence is preferred.",
                "Although traditional stemming increases recall by matching word variants [13], it can reduce precision by retrieving too many documents that have been incorrectly matched.",
                "When examining the results of applying stemming to a large number of queries, one usually finds that nearly equal numbers of queries are helped and hurt by the technique [6].",
                "In addition, it reduces system performance because the search engine has to match all the word variants.",
                "As we will show in the experiments, this is true even if we simplify stemming to pluralization handling, which is the process of converting a word from its plural to singular form, or vice versa.",
                "Thus, one needs to be very cautious when using stemming in <br>web search</br> engines.",
                "One problem of traditional stemming is its blind transformation of all query terms, that is, it always performs the same transformation for the same query word without considering the context of the word.",
                "For example, the word book has four forms book, books, booking, booked, and store has four forms store, stores, storing, stored.",
                "For the query book store, expanding both words to all of their variants significantly increases computation cost and hurts precision, since not all of the variants are useful for this query.",
                "Transforming book store to match book stores is fine, but matching book storing or booking store is not.",
                "A weighting method that gives variant words smaller weights alleviates the problems to a certain extent if the weights accurately reflect the importance of the variant in this particular query.",
                "However uniform weighting is not going to work and a query dependent weighting is still a challenging unsolved problem [20].",
                "A second problem of traditional stemming is its blind matching of all occurrences in documents.",
                "For the query book store, a transformation that allows the variant stores to be matched will cause every occurrence of stores in the document to be treated equivalent to the query term store.",
                "Thus, a document containing the fragment reading a book in coffee stores will be matched, causing many wrong documents to be selected.",
                "Although we hope the ranking function can correctly handle these, with many more candidates to rank, the risk of making mistakes increases.",
                "To alleviate these two problems, we propose a context sensitive stemming approach for <br>web search</br>.",
                "Our solution consists of two context sensitive analysis, one on the query side and the other on the document side.",
                "On the query side, we propose a statistical language modeling based approach to predict which word variants are better forms than the original word for search purpose and expanding the query with only those forms.",
                "On the document side, we propose a conservative context sensitive matching for the transformed word variants, only matching document occurrences in the context of other terms in the query.",
                "Our model is simple yet effective and efficient, making it feasible to be used in real commercial <br>web search</br> engines.",
                "We use pluralization handling as a running example for our stemming approach.",
                "The motivation for using pluralization handling as an example is to show that even such simple stemming, if handled correctly, can give significant benefits to search relevance.",
                "As far as we know, no previous research has systematically investigated the usage of pluralization in <br>web search</br>.",
                "As we have to point out, the method we propose is not limited to pluralization handling, it is a general stemming technique, and can also be applied to general query expansion.",
                "Experiments on general stemming yield additional significant improvements over pluralization handling for long queries, although details will not be reported in this paper.",
                "In the rest of the paper, we first present the related work and distinguish our method from previous work in Section 2.",
                "We describe the details of the context sensitive stemming approach in Section 3.",
                "We then perform extensive experiments on a major <br>web search</br> engine to support our claims in Section 4, followed by discussions in Section 5.",
                "Finally, we conclude the paper in Section 6. 2.",
                "RELATED WORK Stemming is a long studied technology.",
                "Many stemmers have been developed, such as the Lovins stemmer [16] and the Porter stemmer [18].",
                "The Porter stemmer is widely used due to its simplicity and effectiveness in many applications.",
                "However, the Porter stemming makes many mistakes because its simple rules cannot fully describe English morphology.",
                "Corpus analysis is used to improve Porter stemmer [26] by creating equivalence classes for words that are morphologically similar and occur in similar context as measured by expected mutual information [23].",
                "We use a similar corpus based approach for stemming by computing the similarity between two words based on their distributional context features which can be more than just adjacent words [15], and then only keep the morphologically similar words as candidates.",
                "Using stemming in information retrieval is also a well known technique [8, 10].",
                "However, the effectiveness of stemming for English query systems was previously reported to be rather limited.",
                "Lennon et al. [17] compared the Lovins and Porter algorithms and found little improvement in retrieval performance.",
                "Later, Harman [9] compares three general stemming techniques in text retrieval experiments including pluralization handing (called S stemmer in the paper).",
                "They also proposed selective stemming based on query length and term importance, but no positive results were reported.",
                "On the other hand, Krovetz [14] performed comparisons over small numbers of documents (from 400 to 12k) and showed dramatic precision improvement (up to 45%).",
                "However, due to the limited number of tested queries (less than 100) and the small size of the collection, the results are hard to generalize to <br>web search</br>.",
                "These mixed results, mostly failures, led early IR researchers to deem stemming irrelevant in general for English [4], although recent research has shown stemming has greater benefits for retrieval in other languages [2].",
                "We suspect the previous failures were mainly due to the two problems we mentioned in the introduction.",
                "Blind stemming, or a simple query length based selective stemming as used in [9] is not enough.",
                "Stemming has to be decided on case by case basis, not only at the query level but also at the document level.",
                "As we will show, if handled correctly, significant improvement can be achieved.",
                "A more general problem related to stemming is query reformulation [3, 12] and query expansion which expands words not only with word variants [7, 22, 24, 25].",
                "To decide which expanded words to use, people often use pseudorelevance feedback techniquesthat send the original query to a search engine and retrieve the top documents, extract relevant words from these top documents as additional query words, and resubmit the expanded query again [21].",
                "This normally requires sending a query multiple times to search engine and it is not cost effective for processing the huge amount of queries involved in <br>web search</br>.",
                "In addition, query expansion, including query reformulation [3, 12], has a high risk of changing the user intent (called query drift).",
                "Since the expanded words may have different meanings, adding them to the query could potentially change the intent of the original query.",
                "Thus query expansion based on pseudorelevance and query reformulation can provide suggestions to users for interactive refinement but can hardly be directly used for <br>web search</br>.",
                "On the other hand, stemming is much more conservative since most of the time, stemming preserves the original search intent.",
                "While most work on query expansion focuses on recall enhancement, our work focuses on increasing both recall and precision.",
                "The increase on recall is obvious.",
                "With quality stemming, good documents which were not selected before stemming will be pushed up and those low quality documents will be degraded.",
                "On selective query expansion, Cronen-Townsend et al. [6] proposed a method for selective query expansion based on comparing the Kullback-Leibler divergence of the results from the unexpanded query and the results from the expanded query.",
                "This is similar to the relevance feedback in the sense that it requires multiple passes retrieval.",
                "If a word can be expanded into several words, it requires running this process multiple times to decide which expanded word is useful.",
                "It is expensive to deploy this in production <br>web search</br> engines.",
                "Our method predicts the quality of expansion based on oﬄine information without sending the query to a search engine.",
                "In summary, we propose a novel approach to attack an old, yet still important and challenging problem for <br>web search</br> - stemming.",
                "Our approach is unique in that it performs predictive stemming on a per query basis without relevance feedback from the Web, using the context of the variants in documents to preserve precision.",
                "Its simple, yet very efficient and effective, making real time stemming feasible for <br>web search</br>.",
                "Our results will affirm researchers that stemming is indeed very important to large scale information retrieval. 3.",
                "CONTEXT SENSITIVE STEMMING 3.1 Overview Our system has four components as illustrated in Figure 1: candidate generation, query segmentation and head word detection, context sensitive query stemming and context sensitive document matching.",
                "Candidate generation (component 1) is performed oﬄine and generated candidates are stored in a dictionary.",
                "For an input query, we first segment query into concepts and detect the head word for each concept (component 2).",
                "We then use statistical language modeling to decide whether a particular variant is useful (component 3), and finally for the expanded variants, we perform context sensitive document matching (component 4).",
                "Below we discuss each of the components in more detail.",
                "Component 4: context sensitive document matching Input Query: and head word detection Component 2: segment Component 1: candidate generation comparisons −> comparison Component 3: selective word expansion decision: comparisons −> comparison example: hotel price comparisons output: hotel comparisons hotel −> hotels Figure 1: System Components 3.2 Expansion candidate generation One of the ways to generate candidates is using the Porter stemmer [18].",
                "The Porter stemmer simply uses morphological rules to convert a word to its base form.",
                "It has no knowledge of the semantic meaning of the words and sometimes makes serious mistakes, such as executive to execution, news to new, and paste to past.",
                "A more conservative way is based on using corpus analysis to improve the Porter stemmer results [26].",
                "The corpus analysis we do is based on word distributional similarity [15].",
                "The rationale of using distributional word similarity is that true variants tend to be used in similar contexts.",
                "In the distributional word similarity calculation, each word is represented with a vector of features derived from the context of the word.",
                "We use the bigrams to the left and right of the word as its context features, by mining a huge Web corpus.",
                "The similarity between two words is the cosine similarity between the two corresponding feature vectors.",
                "The top 20 similar words to develop is shown in the following table. rank candidate score rank candidate score 0 develop 1 10 berts 0.119 1 developing 0.339 11 wads 0.116 2 developed 0.176 12 developer 0.107 3 incubator 0.160 13 promoting 0.100 4 develops 0.150 14 developmental 0.091 5 development 0.148 15 reengineering 0.090 6 tutoring 0.138 16 build 0.083 7 analyzing 0.128 17 construct 0.081 8 developement 0.128 18 educational 0.081 9 automation 0.126 19 institute 0.077 Table 1: Top 20 most similar candidates to word develop.",
                "Column score is the similarity score.",
                "To determine the stemming candidates, we apply a few Porter stemmer [18] morphological rules to the similarity list.",
                "After applying these rules, for the word develop, the stemming candidates are developing, developed, develops, development, developement, developer, developmental.",
                "For the pluralization handling purpose, only the candidate develops is retained.",
                "One thing we note from observing the distributionally similar words is that they are closely related semantically.",
                "These words might serve as candidates for general query expansion, a topic we will investigate in the future. 3.3 Segmentation and headword identification For long queries, it is quite important to detect the concepts in the query and the most important words for those concepts.",
                "We first break a query into segments, each segment representing a concept which normally is a noun phrase.",
                "For each of the noun phrases, we then detect the most important word which we call the head word.",
                "Segmentation is also used in document sensitive matching (section 3.5) to enforce proximity.",
                "To break a query into segments, we have to define a criteria to measure the strength of the relation between words.",
                "One effective method is to use mutual information as an indicator on whether or not to split two words [19].",
                "We use a log of 25M queries and collect the bigram and unigram frequencies from it.",
                "For every incoming query, we compute the mutual information of two adjacent words; if it passes a predefined threshold, we do not split the query between those two words and move on to next word.",
                "We continue this process until the mutual information between two words is below the threshold, then create a concept boundary here.",
                "Table 2 shows some examples of query segmentation.",
                "The ideal way of finding the head word of a concept is to do syntactic parsing to determine the dependency structure of the query.",
                "Query parsing is more difficult than sentence [running shoe] [best] [new york] [medical schools] [pictures] [of] [white house] [cookies] [in] [san francisco] [hotel] [price comparison] Table 2: Query segmentation: a segment is bracketed. parsing since many queries are not grammatical and are very short.",
                "Applying a parser trained on sentences from documents to queries will have poor performance.",
                "In our solution, we just use simple heuristics rules, and it works very well in practice for English.",
                "For an English noun phrase, the head word is typically the last nonstop word, unless the phrase is of a particular pattern, like XYZ of/in/at/from UVW.",
                "In such cases, the head word is typically the last nonstop word of XYZ. 3.4 Context sensitive word expansion After detecting which words are the most important words to expand, we have to decide whether the expansions will be useful.",
                "Our statistics show that about half of the queries can be transformed by pluralization via naive stemming.",
                "Among this half, about 25% of the queries improve relevance when transformed, the majority (about 50%) do not change their top 5 results, and the remaining 25% perform worse.",
                "Thus, it is extremely important to identify which queries should not be stemmed for the purpose of maximizing relevance improvement and minimizing stemming cost.",
                "In addition, for a query with multiple words that can be transformed, or a word with multiple variants, not all of the expansions are useful.",
                "Taking query hotel price comparison as an example, we decide that hotel and price comparison are two concepts.",
                "Head words hotel and comparison can be expanded to hotels and comparisons.",
                "Are both transformations useful?",
                "To test whether an expansion is useful, we have to know whether the expanded query is likely to get more relevant documents from the Web, which can be quantified by the probability of the query occurring as a string on the Web.",
                "The more likely a query to occur on the Web, the more relevant documents this query is able to return.",
                "Now the whole problem becomes how to calculate the probability of query to occur on the Web.",
                "Calculating the probability of string occurring in a corpus is a well known language modeling problem.",
                "The goal of language modeling is to predict the probability of naturally occurring word sequences, s = w1w2...wN ; or more simply, to put high probability on word sequences that actually occur (and low probability on word sequences that never occur).",
                "The simplest and most successful approach to language modeling is still based on the n-gram model.",
                "By the chain rule of probability one can write the probability of any word sequence as Pr(w1w2...wN ) = NY i=1 Pr(wi|w1...wi−1) (1) An n-gram model approximates this probability by assuming that the only words relevant to predicting Pr(wi|w1...wi−1) are the previous n − 1 words; i.e.",
                "Pr(wi|w1...wi−1) = Pr(wi|wi−n+1...wi−1) A straightforward maximum likelihood estimate of n-gram probabilities from a corpus is given by the observed frequency of each of the patterns Pr(wi|wi−n+1...wi−1) = #(wi−n+1...wi) #(wi−n+1...wi−1) (2) where #(.) denotes the number of occurrences of a specified gram in the training corpus.",
                "Although one could attempt to use simple n-gram models to capture long range dependencies in language, attempting to do so directly immediately creates sparse data problems: Using grams of length up to n entails estimating the probability of Wn events, where W is the size of the word vocabulary.",
                "This quickly overwhelms modern computational and data resources for even modest choices of n (beyond 3 to 6).",
                "Also, because of the heavy tailed nature of language (i.e.",
                "Zipfs law) one is likely to encounter novel n-grams that were never witnessed during training in any test corpus, and therefore some mechanism for assigning non-zero probability to novel n-grams is a central and unavoidable issue in statistical language modeling.",
                "One standard approach to smoothing probability estimates to cope with sparse data problems (and to cope with potentially missing n-grams) is to use some sort of back-off estimator.",
                "Pr(wi|wi−n+1...wi−1) = 8 >>< >>: ˆPr(wi|wi−n+1...wi−1), if #(wi−n+1...wi) > 0 β(wi−n+1...wi−1) × Pr(wi|wi−n+2...wi−1), otherwise (3) where ˆPr(wi|wi−n+1...wi−1) = discount #(wi−n+1...wi) #(wi−n+1...wi−1) (4) is the discounted probability and β(wi−n+1...wi−1) is a normalization constant β(wi−n+1...wi−1) = 1 − X x∈(wi−n+1...wi−1x) ˆPr(x|wi−n+1...wi−1) 1 − X x∈(wi−n+1...wi−1x) ˆPr(x|wi−n+2...wi−1) (5) The discounted probability (4) can be computed with different smoothing techniques, including absolute smoothing, Good-Turing smoothing, linear smoothing, and Witten-Bell smoothing [5].",
                "We used absolute smoothing in our experiments.",
                "Since the likelihood of a string, Pr(w1w2...wN ), is a very small number and hard to interpret, we use entropy as defined below to score the string.",
                "Entropy = − 1 N log2 Pr(w1w2...wN ) (6) Now getting back to the example of the query hotel price comparisons, there are four variants of this query, and the entropy of these four candidates are shown in Table 3.",
                "We can see that all alternatives are less likely than the input query.",
                "It is therefore not useful to make an expansion for this query.",
                "On the other hand, if the input query is hotel price comparisons which is the second alternative in the table, then there is a better alternative than the input query, and it should therefore be expanded.",
                "To tolerate the variations in probability estimation, we relax the selection criterion to those query alternatives if their scores are within a certain distance (10% in our experiments) to the best score.",
                "Query variations Entropy hotel price comparison 6.177 hotel price comparisons 6.597 hotels price comparison 6.937 hotels price comparisons 7.360 Table 3: Variations of query hotel price comparison ranked by entropy score, with the original query in bold face. 3.5 Context sensitive document matching Even after we know which word variants are likely to be useful, we have to be conservative in document matching for the expanded variants.",
                "For the query hotel price comparisons, we decided that word comparisons is expanded to include comparison.",
                "However, not every occurrence of comparison in the document is of interest.",
                "A page which is about comparing customer service can contain all of the words hotel price comparisons comparison.",
                "This page is not a good page for the query.",
                "If we accept matches of every occurrence of comparison, it will hurt retrieval precision and this is one of the main reasons why most stemming approaches do not work well for information retrieval.",
                "To address this problem, we have a proximity constraint that considers the context around the expanded variant in the document.",
                "A variant match is considered valid only if the variant occurs in the same context as the original word does.",
                "The context is the left or the right non-stop segments 1 of the original word.",
                "Taking the same query as an example, the context of comparisons is price.",
                "The expanded word comparison is only valid if it is in the same context of comparisons, which is after the word price.",
                "Thus, we should only match those occurrences of comparison in the document if they occur after the word price.",
                "Considering the fact that queries and documents may not represent the intent in exactly the same way, we relax this proximity constraint to allow variant occurrences within a window of some fixed size.",
                "If the expanded word comparison occurs within the context of price within a window, it is considered valid.",
                "The smaller the window size is, the more restrictive the matching.",
                "We use a window size of 4, which typically captures contexts that include the containing and adjacent noun phrases. 4.",
                "EXPERIMENTAL EVALUATION 4.1 Evaluation metrics We will measure both relevance improvement and the stemming cost required to achieve the relevance. 1 a context segment can not be a single stop word. 4.1.1 Relevance measurement We use a variant of the average Discounted Cumulative Gain (DCG), a recently popularized scheme to measure search engine relevance [1, 11].",
                "Given a query and a ranked list of K documents (K is set to 5 in our experiments), the DCG(K) score for this query is calculated as follows: DCG(K) = KX k=1 gk log2(1 + k) . (7) where gk is the weight for the document at rank k. Higher degree of relevance corresponds to a higher weight.",
                "A page is graded into one of the five scales: Perfect, Excellent, Good, Fair, Bad, with corresponding weights.",
                "We use dcg to represent the average DCG(5) over a set of test queries. 4.1.2 Stemming cost Another metric is to measure the additional cost incurred by stemming.",
                "Given the same level of relevance improvement, we prefer a stemming method that has less additional cost.",
                "We measure this by the percentage of queries that are actually stemmed, over all the queries that could possibly be stemmed. 4.2 Data preparation We randomly sample 870 queries from a three month query log, with 290 from each month.",
                "Among all these 870 queries, we remove all misspelled queries since misspelled queries are not of interest to stemming.",
                "We also remove all one word queries since stemming one word queries without context has a high risk of changing query intent, especially for short words.",
                "In the end, we have 529 correctly spelled queries with at least 2 words. 4.3 Naive stemming for <br>web search</br> Before explaining the experiments and results in detail, wed like to describe the traditional way of using stemming for <br>web search</br>, referred as the naive model.",
                "This is to treat every word variant equivalent for all possible words in the query.",
                "The query book store will be transformed into (book OR books)(store OR stores) when limiting stemming to pluralization handling only, where OR is an operator that denotes the equivalence of the left and right arguments. 4.4 Experimental setup The baseline model is the model without stemming.",
                "We first run the naive model to see how well it performs over the baseline.",
                "Then we improve the naive stemming model by document sensitive matching, referred as document sensitive matching model.",
                "This model makes the same stemming as the naive model on the query side, but performs conservative matching on the document side using the strategy described in section 3.5.",
                "The naive model and document sensitive matching model stem the most queries.",
                "Out of the 529 queries, there are 408 queries that they stem, corresponding to 46.7% query traffic (out of a total of 870).",
                "We then further improve the document sensitive matching model from the query side with selective word stemming based on statistical language modeling (section 3.4), referred as selective stemming model.",
                "Based on language modeling prediction, this model stems only a subset of the 408 queries stemmed by the document sensitive matching model.",
                "We experiment with unigram language model and bigram language model.",
                "Since we only care how much we can improve the naive model, we will only use these 408 queries (all the queries that are affected by the naive stemming model) in the experiments.",
                "To get a sense of how these models perform, we also have an oracle model that gives the upper-bound performance a stemmer can achieve on this data.",
                "The oracle model only expands a word if the stemming will give better results.",
                "To analyze the pluralization handling influence on different query categories, we divide queries into short queries and long queries.",
                "Among the 408 queries stemmed by the naive model, there are 272 short queries with 2 or 3 words, and 136 long queries with at least 4 words. 4.5 Results We summarize the overall results in Table 4, and present the results on short queries and long queries separately in Table 5.",
                "Each row in Table 4 is a stemming strategy described in section 4.4.",
                "The first column is the name of the strategy.",
                "The second column is the number of queries affected by this strategy; this column measures the stemming cost, and the numbers should be low for the same level of dcg.",
                "The third column is the average dcg score over all tested queries in this category (including the ones that were not stemmed by the strategy).",
                "The fourth column is the relative improvement over the baseline, and the last column is the p-value of Wilcoxon significance test.",
                "There are several observations about the results.",
                "We can see the naively stemming only obtains a statistically insignificant improvement of 1.5%.",
                "Looking at Table 5, it gives an improvement of 2.7% on short queries.",
                "However, it also hurts long queries by -2.4%.",
                "Overall, the improvement is canceled out.",
                "The reason that it improves short queries is that most short queries only have one word that can be stemmed.",
                "Thus, blindly pluralizing short queries is relatively safe.",
                "However for long queries, most queries can have multiple words that can be pluralized.",
                "Expanding all of them without selection will significantly hurt precision.",
                "Document context sensitive stemming gives a significant lift to the performance, from 2.7% to 4.2% for short queries and from -2.4% to -1.6% for long queries, with an overall lift from 1.5% to 2.8%.",
                "The improvement comes from the conservative context sensitive document matching.",
                "An expanded word is valid only if it occurs within the context of original query in the document.",
                "This reduces many spurious matches.",
                "However, we still notice that for long queries, context sensitive stemming is not able to improve performance because it still selects too many documents and gives the ranking function a hard problem.",
                "While the chosen window size of 4 works the best amongst all the choices, it still allows spurious matches.",
                "It is possible that the window size needs to be chosen on a per query basis to ensure tighter proximity constraints for different types of noun phrases.",
                "Selective word pluralization further helps resolving the problem faced by document context sensitive stemming.",
                "It does not stem every word that places all the burden on the ranking algorithm, but tries to eliminate unnecessary stemming in the first place.",
                "By predicting which word variants are going to be useful, we can dramatically reduce the number of stemmed words, thus improving both the recall and the precision.",
                "With the unigram language model, we can reduce the stemming cost by 26.7% (from 408/408 to 300/408) and lift the overall dcg improvement from 2.8% to 3.4%.",
                "In particular, it gives significant improvements on long queries.",
                "The dcg gain is turned from negative to positive, from −1.6% to 1.1%.",
                "This confirms our hypothesis that reducing unnecessary word expansion leads to precision improvement.",
                "For short queries too, we observe both dcg improvement and stemming cost reduction with the unigram language model.",
                "The advantages of predictive word expansion with a language model is further boosted with a better bigram language model.",
                "The overall dcg gain is lifted from 3.4% to 3.9%, and stemming cost is dramatically reduced from 408/408 to 250/408, corresponding to only 29% of query traffic (250 out of 870) and an overall 1.8% dcg improvement overall all query traffic.",
                "For short queries, bigram language model improves the dcg gain from 4.4% to 4.7%, and reduces stemming cost from 272/272 to 150/272.",
                "For long queries, bigram language model improves dcg gain from 1.1% to 2.5%, and reduces stemming cost from 136/136 to 100/136.",
                "We observe that the bigram language model gives a larger lift for long queries.",
                "This is because the uncertainty in long queries is larger and a more powerful language model is needed.",
                "We hypothesize that a trigram language model would give a further lift for long queries and leave this for future investigation.",
                "Considering the tight upper-bound 2 on the improvement to be gained from pluralization handling (via the oracle model), the current performance on short queries is very satisfying.",
                "For short queries, the dcg gain upper-bound is 6.3% for perfect pluralization handling, our current gain is 4.7% with a bigram language model.",
                "For long queries, the dcg gain upper-bound is 4.6% for perfect pluralization handling, our current gain is 2.5% with a bigram language model.",
                "We may gain additional benefit with a more powerful language model for long queries.",
                "However, the difficulties of long queries come from many other aspects including the proximity and the segmentation problem.",
                "These problems have to be addressed separately.",
                "Looking at the the upper-bound of overhead reduction for oracle stemming, 75% (308/408) of the naive stemmings are wasteful.",
                "We currently capture about half of them.",
                "Further reduction of the overhead requires sacrificing the dcg gain.",
                "Now we can compare the stemming strategies from a different aspect.",
                "Instead of looking at the influence over all queries as we described above, Table 6 summarizes the dcg improvements over the affected queries only.",
                "We can see that the number of affected queries decreases as the stemming strategy becomes more accurate (dcg improvement).",
                "For the bigram language model, over the 250/408 stemmed queries, the dcg improvement is 6.1%.",
                "An interesting observation is the average dcg decreases with a better model, which indicates a better stemming strategy stems more difficult queries (low dcg queries). 5.",
                "DISCUSSIONS 5.1 Language models from query vs. from Web As we mentioned in Section 1, we are trying to predict the probability of a string occurring on the Web.",
                "The language model should describe the occurrence of the string on the Web.",
                "However, the query log is also a good resource. 2 Note that this upperbound is for pluralization handling only, not for general stemming.",
                "General stemming gives a 8% upperbound, which is quite substantial in terms of our metrics.",
                "Affected Queries dcg dcg Improvement p-value baseline 0/408 7.102 N/A N/A naive model 408/408 7.206 1.5% 0.22 document context sensitive model 408/408 7.302 2.8% 0.014 selective model: unigram LM 300/408 7.321 3.4% 0.001 selective model: bigram LM 250/408 7.381 3.9% 0.001 oracle model 100/408 7.519 5.9% 0.001 Table 4: Results comparison of different stemming strategies over all queries affected by naive stemming Short Query Results Affected Queries dcg Improvement p-value baseline 0/272 N/A N/A naive model 272/272 2.7% 0.48 document context sensitive model 272/272 4.2% 0.002 selective model: unigram LM 185/272 4.4% 0.001 selective model: bigram LM 150/272 4.7% 0.001 oracle model 71/272 6.3% 0.001 Long Query Results Affected Queries dcg Improvement p-value baseline 0/136 N/A N/A naive model 136/136 -2.4% 0.25 document context sensitive model 136/136 -1.6% 0.27 selective model: unigram LM 115/136 1.1% 0.001 selective model: bigram LM 100/136 2.5% 0.001 oracle model 29/136 4.6% 0.001 Table 5: Results comparison of different stemming strategies overall short queries and long queries Users reformulate a query using many different variants to get good results.",
                "To test the hypothesis that we can learn reliable transformation probabilities from the query log, we trained a language model from the same query top 25M queries as used to learn segmentation, and use that for prediction.",
                "We observed a slight performance decrease compared to the model trained on Web frequencies.",
                "In particular, the performance for unigram LM was not affected, but the dcg gain for bigram LM changed from 4.7% to 4.5% for short queries.",
                "Thus, the query log can serve as a good approximation of the Web frequencies. 5.2 How linguistics helps Some linguistic knowledge is useful in stemming.",
                "For the pluralization handling case, pluralization and de-pluralization is not symmetric.",
                "A plural word used in a query indicates a special intent.",
                "For example, the query new york hotels is looking for a list of hotels in new york, not the specific new york hotel which might be a hotel located in California.",
                "A simple equivalence of hotel to hotels might boost a particular page about new york hotel to top rank.",
                "To capture this intent, we have to make sure the document is a general page about hotels in new york.",
                "We do this by requiring that the plural word hotels appears in the document.",
                "On the other hand, converting a singular word to plural is safer since a general purpose page normally contains specific information.",
                "We observed a slight overall dcg decrease, although not statistically significant, for document context sensitive stemming if we do not consider this asymmetric property. 5.3 Error analysis One type of mistakes we noticed, though rare but seriously hurting relevance, is the search intent change after stemming.",
                "Generally speaking, pluralization or depluralization keeps the original intent.",
                "However, the intent could change in a few cases.",
                "For one example of such a query, job at apple, we pluralize job to jobs.",
                "This stemming makes the original query ambiguous.",
                "The query job OR jobs at apple has two intents.",
                "One is the employment opportunities at apple, and another is a person working at Apple, Steve Jobs, who is the CEO and co-founder of the company.",
                "Thus, the results after query stemming returns Steve Jobs as one of the results in top 5.",
                "One solution is performing results set based analysis to check if the intent is changed.",
                "This is similar to relevance feedback and requires second phase ranking.",
                "A second type of mistakes is the entity/concept recognition problem, These include two kinds.",
                "One is that the stemmed word variant now matches part of an entity or concept.",
                "For example, query cookies in san francisco is pluralized to cookies OR cookie in san francisco.",
                "The results will match cookie jar in san francisco.",
                "Although cookie still means the same thing as cookies, cookie jar is a different concept.",
                "Another kind is the unstemmed word matches an entity or concept because of the stemming of the other words.",
                "For example, quote ICE is pluralized to quote OR quotes ICE.",
                "The original intent for this query is searching for stock quote for ticker ICE.",
                "However, we noticed that among the top results, one of the results is Food quotes: Ice cream.",
                "This is matched because of Affected Queries old dcg new dcg dcg Improvement naive model 408/408 7.102 7.206 1.5% document context sensitive model 408/408 7.102 7.302 2.8% selective model: unigram LM 300/408 5.904 6.187 4.8% selective model: bigram LM 250/408 5.551 5.891 6.1% Table 6: Results comparison over the stemmed queries only: column old/new dcg is the dcg score over the affected queries before/after applying stemming the pluralized word quotes.",
                "The unchanged word ICE matches part of the noun phrase ice cream here.",
                "To solve this kind of problem, we have to analyze the documents and recognize cookie jar and ice cream as concepts instead of two independent words.",
                "A third type of mistakes occurs in long queries.",
                "For the query bar code reader software, two words are pluralized. code to codes and reader to readers.",
                "In fact, bar code reader in the original query is a strong concept and the internal words should not be changed.",
                "This is the segmentation and entity and noun phrase detection problem in queries, which we actively are attacking.",
                "For long queries, we should correctly identify the concepts in the query, and boost the proximity for the words within a concept. 6.",
                "CONCLUSIONS AND FUTURE WORK We have presented a simple yet elegant way of stemming for <br>web search</br>.",
                "It improves naive stemming in two aspects: selective word expansion on the query side and conservative word occurrence matching on the document side.",
                "Using pluralization handling as an example, experiments on a major <br>web search</br> engine data show it significantly improves the Web relevance and reduces the stemming cost.",
                "It also significantly improves Web click through rate (details not reported in the paper).",
                "For the future work, we are investigating the problems we identified in the error analysis section.",
                "These include: entity and noun phrase matching mistakes, and improved segmentation. 7.",
                "REFERENCES [1] E. Agichtein, E. Brill, and S. T. Dumais.",
                "Improving <br>web search</br> Ranking by Incorporating User Behavior Information.",
                "In SIGIR, 2006. [2] E. Airio.",
                "Word Normalization and Decompounding in Mono- and Bilingual IR.",
                "Information Retrieval, 9:249-271, 2006. [3] P. Anick.",
                "Using Terminological Feedback for <br>web search</br> Refinement: a Log-based Study.",
                "In SIGIR, 2003. [4] R. Baeza-Yates and B. Ribeiro-Neto.",
                "Modern Information Retrieval.",
                "ACM Press/Addison Wesley, 1999. [5] S. Chen and J. Goodman.",
                "An Empirical Study of Smoothing Techniques for Language Modeling.",
                "Technical Report TR-10-98, Harvard University, 1998. [6] S. Cronen-Townsend, Y. Zhou, and B. Croft.",
                "A Framework for Selective Query Expansion.",
                "In CIKM, 2004. [7] H. Fang and C. Zhai.",
                "Semantic Term Matching in Axiomatic Approaches to Information Retrieval.",
                "In SIGIR, 2006. [8] W. B. Frakes.",
                "Term Conflation for Information Retrieval.",
                "In C. J. Rijsbergen, editor, Research and Development in Information Retrieval, pages 383-389.",
                "Cambridge University Press, 1984. [9] D. Harman.",
                "How Effective is Suffixing?",
                "JASIS, 42(1):7-15, 1991. [10] D. Hull.",
                "Stemming Algorithms - A Case Study for Detailed Evaluation.",
                "JASIS, 47(1):70-84, 1996. [11] K. Jarvelin and J. Kekalainen.",
                "Cumulated Gain-Based Evaluation Evaluation of IR Techniques.",
                "ACM TOIS, 20:422-446, 2002. [12] R. Jones, B. Rey, O. Madani, and W. Greiner.",
                "Generating Query Substitutions.",
                "In WWW, 2006. [13] W. Kraaij and R. Pohlmann.",
                "Viewing Stemming as Recall Enhancement.",
                "In SIGIR, 1996. [14] R. Krovetz.",
                "Viewing Morphology as an Inference Process.",
                "In SIGIR, 1993. [15] D. Lin.",
                "Automatic Retrieval and Clustering of Similar Words.",
                "In COLING-ACL, 1998. [16] J.",
                "B. Lovins.",
                "Development of a Stemming Algorithm.",
                "Mechanical Translation and Computational Linguistics, II:22-31, 1968. [17] M. Lennon and D. Peirce and B. Tarry and P. Willett.",
                "An Evaluation of Some Conflation Algorithms for Information Retrieval.",
                "Journal of Information Science, 3:177-188, 1981. [18] M. Porter.",
                "An Algorithm for Suffix Stripping.",
                "Program, 14(3):130-137, 1980. [19] K. M. Risvik, T. Mikolajewski, and P. Boros.",
                "Query Segmentation for <br>web search</br>.",
                "In WWW, 2003. [20] S. E. Robertson.",
                "On Term Selection for Query Expansion.",
                "Journal of Documentation, 46(4):359-364, 1990. [21] G. Salton and C. Buckley.",
                "Improving Retrieval Performance by Relevance Feedback.",
                "JASIS, 41(4):288 - 297, 1999. [22] R. Sun, C.-H. Ong, and T.-S. Chua.",
                "Mining Dependency Relations for Query Expansion in Passage Retrieval.",
                "In SIGIR, 2006. [23] C. Van Rijsbergen.",
                "Information Retrieval.",
                "Butterworths, second version, 1979. [24] B. V´elez, R. Weiss, M. A. Sheldon, and D. K. Gifford.",
                "Fast and Effective Query Refinement.",
                "In SIGIR, 1997. [25] J. Xu and B. Croft.",
                "Query Expansion using Local and Global Document Analysis.",
                "In SIGIR, 1996. [26] J. Xu and B. Croft.",
                "Corpus-based Stemming using Cooccurrence of Word Variants.",
                "ACM TOIS, 16 (1):61-81, 1998."
            ],
            "original_annotated_samples": [
                "Context Sensitive Stemming for <br>web search</br> Fuchun Peng Nawaaz Ahmed Xin Li Yumao Lu Yahoo!",
                "Although it increases recall, this naive strategy does not work well for <br>web search</br> since it lowers precision and requires a significant amount of additional computation.",
                "Two unique properties make our approach feasible for <br>web search</br>.",
                "Using word pluralization handling as an example of our stemming approach, our experiments on a major <br>web search</br> engine show that stemming only 29% of the query traffic, we can improve relevance as measured by average Discounted Cumulative Gain (DCG5) by 6.1% on these queries and 1.8% over all query traffic.",
                "INTRODUCTION <br>web search</br> has now become a major tool in our daily lives for information seeking."
            ],
            "translated_annotated_samples": [
                "Stemming sensible al contexto para la <br>búsqueda web</br> Fuchun Peng Nawaaz Ahmed Xin Li Yumao Lu Yahoo!",
                "Aunque aumenta la recuperación, esta estrategia ingenua no funciona bien para la <br>Búsqueda en la Web</br>, ya que disminuye la precisión y requiere una cantidad significativa de cálculos adicionales.",
                "Dos propiedades únicas hacen que nuestro enfoque sea factible para la <br>Búsqueda en la Web</br>.",
                "Usando el manejo de la pluralización de palabras como un ejemplo de nuestro enfoque de derivación, nuestros experimentos en un importante motor de <br>búsqueda web</br> muestran que al derivar solo el 29% del tráfico de consultas, podemos mejorar la relevancia medida por la Ganancia Acumulativa Descontada promedio (DCG5) en un 6.1% en estas consultas y en un 1.8% sobre todo el tráfico de consultas.",
                "INTRODUCCIÓN La <br>búsqueda en la web</br> se ha convertido en una herramienta importante en nuestra vida diaria para buscar información."
            ],
            "translated_text": "Stemming sensible al contexto para la <br>búsqueda web</br> Fuchun Peng Nawaaz Ahmed Xin Li Yumao Lu Yahoo! Tradicionalmente, el truncamiento se ha aplicado a tareas de Recuperación de Información transformando las palabras en documentos a su forma raíz antes de indexarlas, y aplicando una transformación similar a los términos de consulta. Aunque aumenta la recuperación, esta estrategia ingenua no funciona bien para la <br>Búsqueda en la Web</br>, ya que disminuye la precisión y requiere una cantidad significativa de cálculos adicionales. En este artículo, proponemos un método de derivación sensible al contexto que aborda estos dos problemas. Dos propiedades únicas hacen que nuestro enfoque sea factible para la <br>Búsqueda en la Web</br>. Primero, basados en modelado estadístico del lenguaje, realizamos un análisis sensible al contexto en el lado de la consulta. Predecimos con precisión cuál de sus variantes morfológicas es útil para expandir un término de consulta antes de enviar la consulta al motor de búsqueda. Esto reduce drásticamente la cantidad de expansiones incorrectas, lo que a su vez disminuye el costo de la computación adicional y mejora la precisión al mismo tiempo. Segundo, nuestro enfoque realiza una coincidencia de documentos sensible al contexto para esas variantes ampliadas. Esta estrategia conservadora sirve como salvaguarda contra el truncamiento espurio, y resulta ser muy importante para mejorar la precisión. Usando el manejo de la pluralización de palabras como un ejemplo de nuestro enfoque de derivación, nuestros experimentos en un importante motor de <br>búsqueda web</br> muestran que al derivar solo el 29% del tráfico de consultas, podemos mejorar la relevancia medida por la Ganancia Acumulativa Descontada promedio (DCG5) en un 6.1% en estas consultas y en un 1.8% sobre todo el tráfico de consultas. Categorías y Descriptores de Asignaturas H.3.3 [Sistemas de Información]: Almacenamiento y Recuperación de Información-Formulación de Consultas Términos Generales Algoritmos, Experimentación 1. INTRODUCCIÓN La <br>búsqueda en la web</br> se ha convertido en una herramienta importante en nuestra vida diaria para buscar información. ",
            "candidates": [],
            "error": [
                [
                    "búsqueda web",
                    "Búsqueda en la Web",
                    "Búsqueda en la Web",
                    "búsqueda web",
                    "búsqueda en la web"
                ]
            ]
        },
        "stemming": {
            "translated_key": "truncamiento",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Context Sensitive <br>stemming</br> for Web Search Fuchun Peng Nawaaz Ahmed Xin Li Yumao Lu Yahoo!",
                "Inc. 701 First Avenue Sunnyvale, California 94089 {fuchun, nawaaz, xinli, yumaol}@yahoo-inc.com ABSTRACT Traditionally, <br>stemming</br> has been applied to Information Retrieval tasks by transforming words in documents to the their root form before indexing, and applying a similar transformation to query terms.",
                "Although it increases recall, this naive strategy does not work well for Web Search since it lowers precision and requires a significant amount of additional computation.",
                "In this paper, we propose a context sensitive <br>stemming</br> method that addresses these two issues.",
                "Two unique properties make our approach feasible for Web Search.",
                "First, based on statistical language modeling, we perform context sensitive analysis on the query side.",
                "We accurately predict which of its morphological variants is useful to expand a query term with before submitting the query to the search engine.",
                "This dramatically reduces the number of bad expansions, which in turn reduces the cost of additional computation and improves the precision at the same time.",
                "Second, our approach performs a context sensitive document matching for those expanded variants.",
                "This conservative strategy serves as a safeguard against spurious <br>stemming</br>, and it turns out to be very important for improving precision.",
                "Using word pluralization handling as an example of our <br>stemming</br> approach, our experiments on a major Web search engine show that <br>stemming</br> only 29% of the query traffic, we can improve relevance as measured by average Discounted Cumulative Gain (DCG5) by 6.1% on these queries and 1.8% over all query traffic.",
                "Categories and Subject Descriptors H.3.3 [Information Systems]: Information Storage and Retrieval-Query formulation General Terms Algorithms, Experimentation 1.",
                "INTRODUCTION Web search has now become a major tool in our daily lives for information seeking.",
                "One of the important issues in Web search is that user queries are often not best formulated to get optimal results.",
                "For example, running shoe is a query that occurs frequently in query logs.",
                "However, the query running shoes is much more likely to give better search results than the original query because documents matching the intent of this query usually contain the words running shoes.",
                "Correctly formulating a query requires the user to accurately predict which word form is used in the documents that best satisfy his or her information needs.",
                "This is difficult even for experienced users, and especially difficult for non-native speakers.",
                "One traditional solution is to use <br>stemming</br> [16, 18], the process of transforming inflected or derived words to their root form so that a search term will match and retrieve documents containing all forms of the term.",
                "Thus, the word run will match running, ran, runs, and shoe will match shoes and shoeing.",
                "<br>stemming</br> can be done either on the terms in a document during indexing (and applying the same transformation to the query terms during query processing) or by expanding the query with the variants during query processing.",
                "<br>stemming</br> during indexing allows very little flexibility during query processing, while <br>stemming</br> by query expansion allows handling each query differently, and hence is preferred.",
                "Although traditional <br>stemming</br> increases recall by matching word variants [13], it can reduce precision by retrieving too many documents that have been incorrectly matched.",
                "When examining the results of applying <br>stemming</br> to a large number of queries, one usually finds that nearly equal numbers of queries are helped and hurt by the technique [6].",
                "In addition, it reduces system performance because the search engine has to match all the word variants.",
                "As we will show in the experiments, this is true even if we simplify <br>stemming</br> to pluralization handling, which is the process of converting a word from its plural to singular form, or vice versa.",
                "Thus, one needs to be very cautious when using <br>stemming</br> in Web search engines.",
                "One problem of traditional <br>stemming</br> is its blind transformation of all query terms, that is, it always performs the same transformation for the same query word without considering the context of the word.",
                "For example, the word book has four forms book, books, booking, booked, and store has four forms store, stores, storing, stored.",
                "For the query book store, expanding both words to all of their variants significantly increases computation cost and hurts precision, since not all of the variants are useful for this query.",
                "Transforming book store to match book stores is fine, but matching book storing or booking store is not.",
                "A weighting method that gives variant words smaller weights alleviates the problems to a certain extent if the weights accurately reflect the importance of the variant in this particular query.",
                "However uniform weighting is not going to work and a query dependent weighting is still a challenging unsolved problem [20].",
                "A second problem of traditional <br>stemming</br> is its blind matching of all occurrences in documents.",
                "For the query book store, a transformation that allows the variant stores to be matched will cause every occurrence of stores in the document to be treated equivalent to the query term store.",
                "Thus, a document containing the fragment reading a book in coffee stores will be matched, causing many wrong documents to be selected.",
                "Although we hope the ranking function can correctly handle these, with many more candidates to rank, the risk of making mistakes increases.",
                "To alleviate these two problems, we propose a context sensitive <br>stemming</br> approach for Web search.",
                "Our solution consists of two context sensitive analysis, one on the query side and the other on the document side.",
                "On the query side, we propose a statistical language modeling based approach to predict which word variants are better forms than the original word for search purpose and expanding the query with only those forms.",
                "On the document side, we propose a conservative context sensitive matching for the transformed word variants, only matching document occurrences in the context of other terms in the query.",
                "Our model is simple yet effective and efficient, making it feasible to be used in real commercial Web search engines.",
                "We use pluralization handling as a running example for our <br>stemming</br> approach.",
                "The motivation for using pluralization handling as an example is to show that even such simple <br>stemming</br>, if handled correctly, can give significant benefits to search relevance.",
                "As far as we know, no previous research has systematically investigated the usage of pluralization in Web search.",
                "As we have to point out, the method we propose is not limited to pluralization handling, it is a general <br>stemming</br> technique, and can also be applied to general query expansion.",
                "Experiments on general <br>stemming</br> yield additional significant improvements over pluralization handling for long queries, although details will not be reported in this paper.",
                "In the rest of the paper, we first present the related work and distinguish our method from previous work in Section 2.",
                "We describe the details of the context sensitive <br>stemming</br> approach in Section 3.",
                "We then perform extensive experiments on a major Web search engine to support our claims in Section 4, followed by discussions in Section 5.",
                "Finally, we conclude the paper in Section 6. 2.",
                "RELATED WORK <br>stemming</br> is a long studied technology.",
                "Many stemmers have been developed, such as the Lovins stemmer [16] and the Porter stemmer [18].",
                "The Porter stemmer is widely used due to its simplicity and effectiveness in many applications.",
                "However, the Porter <br>stemming</br> makes many mistakes because its simple rules cannot fully describe English morphology.",
                "Corpus analysis is used to improve Porter stemmer [26] by creating equivalence classes for words that are morphologically similar and occur in similar context as measured by expected mutual information [23].",
                "We use a similar corpus based approach for <br>stemming</br> by computing the similarity between two words based on their distributional context features which can be more than just adjacent words [15], and then only keep the morphologically similar words as candidates.",
                "Using <br>stemming</br> in information retrieval is also a well known technique [8, 10].",
                "However, the effectiveness of <br>stemming</br> for English query systems was previously reported to be rather limited.",
                "Lennon et al. [17] compared the Lovins and Porter algorithms and found little improvement in retrieval performance.",
                "Later, Harman [9] compares three general <br>stemming</br> techniques in text retrieval experiments including pluralization handing (called S stemmer in the paper).",
                "They also proposed selective <br>stemming</br> based on query length and term importance, but no positive results were reported.",
                "On the other hand, Krovetz [14] performed comparisons over small numbers of documents (from 400 to 12k) and showed dramatic precision improvement (up to 45%).",
                "However, due to the limited number of tested queries (less than 100) and the small size of the collection, the results are hard to generalize to Web search.",
                "These mixed results, mostly failures, led early IR researchers to deem <br>stemming</br> irrelevant in general for English [4], although recent research has shown <br>stemming</br> has greater benefits for retrieval in other languages [2].",
                "We suspect the previous failures were mainly due to the two problems we mentioned in the introduction.",
                "Blind <br>stemming</br>, or a simple query length based selective <br>stemming</br> as used in [9] is not enough.",
                "<br>stemming</br> has to be decided on case by case basis, not only at the query level but also at the document level.",
                "As we will show, if handled correctly, significant improvement can be achieved.",
                "A more general problem related to <br>stemming</br> is query reformulation [3, 12] and query expansion which expands words not only with word variants [7, 22, 24, 25].",
                "To decide which expanded words to use, people often use pseudorelevance feedback techniquesthat send the original query to a search engine and retrieve the top documents, extract relevant words from these top documents as additional query words, and resubmit the expanded query again [21].",
                "This normally requires sending a query multiple times to search engine and it is not cost effective for processing the huge amount of queries involved in Web search.",
                "In addition, query expansion, including query reformulation [3, 12], has a high risk of changing the user intent (called query drift).",
                "Since the expanded words may have different meanings, adding them to the query could potentially change the intent of the original query.",
                "Thus query expansion based on pseudorelevance and query reformulation can provide suggestions to users for interactive refinement but can hardly be directly used for Web search.",
                "On the other hand, <br>stemming</br> is much more conservative since most of the time, <br>stemming</br> preserves the original search intent.",
                "While most work on query expansion focuses on recall enhancement, our work focuses on increasing both recall and precision.",
                "The increase on recall is obvious.",
                "With quality <br>stemming</br>, good documents which were not selected before <br>stemming</br> will be pushed up and those low quality documents will be degraded.",
                "On selective query expansion, Cronen-Townsend et al. [6] proposed a method for selective query expansion based on comparing the Kullback-Leibler divergence of the results from the unexpanded query and the results from the expanded query.",
                "This is similar to the relevance feedback in the sense that it requires multiple passes retrieval.",
                "If a word can be expanded into several words, it requires running this process multiple times to decide which expanded word is useful.",
                "It is expensive to deploy this in production Web search engines.",
                "Our method predicts the quality of expansion based on oﬄine information without sending the query to a search engine.",
                "In summary, we propose a novel approach to attack an old, yet still important and challenging problem for Web search - <br>stemming</br>.",
                "Our approach is unique in that it performs predictive <br>stemming</br> on a per query basis without relevance feedback from the Web, using the context of the variants in documents to preserve precision.",
                "Its simple, yet very efficient and effective, making real time <br>stemming</br> feasible for Web search.",
                "Our results will affirm researchers that <br>stemming</br> is indeed very important to large scale information retrieval. 3.",
                "CONTEXT SENSITIVE <br>stemming</br> 3.1 Overview Our system has four components as illustrated in Figure 1: candidate generation, query segmentation and head word detection, context sensitive query <br>stemming</br> and context sensitive document matching.",
                "Candidate generation (component 1) is performed oﬄine and generated candidates are stored in a dictionary.",
                "For an input query, we first segment query into concepts and detect the head word for each concept (component 2).",
                "We then use statistical language modeling to decide whether a particular variant is useful (component 3), and finally for the expanded variants, we perform context sensitive document matching (component 4).",
                "Below we discuss each of the components in more detail.",
                "Component 4: context sensitive document matching Input Query: and head word detection Component 2: segment Component 1: candidate generation comparisons −> comparison Component 3: selective word expansion decision: comparisons −> comparison example: hotel price comparisons output: hotel comparisons hotel −> hotels Figure 1: System Components 3.2 Expansion candidate generation One of the ways to generate candidates is using the Porter stemmer [18].",
                "The Porter stemmer simply uses morphological rules to convert a word to its base form.",
                "It has no knowledge of the semantic meaning of the words and sometimes makes serious mistakes, such as executive to execution, news to new, and paste to past.",
                "A more conservative way is based on using corpus analysis to improve the Porter stemmer results [26].",
                "The corpus analysis we do is based on word distributional similarity [15].",
                "The rationale of using distributional word similarity is that true variants tend to be used in similar contexts.",
                "In the distributional word similarity calculation, each word is represented with a vector of features derived from the context of the word.",
                "We use the bigrams to the left and right of the word as its context features, by mining a huge Web corpus.",
                "The similarity between two words is the cosine similarity between the two corresponding feature vectors.",
                "The top 20 similar words to develop is shown in the following table. rank candidate score rank candidate score 0 develop 1 10 berts 0.119 1 developing 0.339 11 wads 0.116 2 developed 0.176 12 developer 0.107 3 incubator 0.160 13 promoting 0.100 4 develops 0.150 14 developmental 0.091 5 development 0.148 15 reengineering 0.090 6 tutoring 0.138 16 build 0.083 7 analyzing 0.128 17 construct 0.081 8 developement 0.128 18 educational 0.081 9 automation 0.126 19 institute 0.077 Table 1: Top 20 most similar candidates to word develop.",
                "Column score is the similarity score.",
                "To determine the <br>stemming</br> candidates, we apply a few Porter stemmer [18] morphological rules to the similarity list.",
                "After applying these rules, for the word develop, the <br>stemming</br> candidates are developing, developed, develops, development, developement, developer, developmental.",
                "For the pluralization handling purpose, only the candidate develops is retained.",
                "One thing we note from observing the distributionally similar words is that they are closely related semantically.",
                "These words might serve as candidates for general query expansion, a topic we will investigate in the future. 3.3 Segmentation and headword identification For long queries, it is quite important to detect the concepts in the query and the most important words for those concepts.",
                "We first break a query into segments, each segment representing a concept which normally is a noun phrase.",
                "For each of the noun phrases, we then detect the most important word which we call the head word.",
                "Segmentation is also used in document sensitive matching (section 3.5) to enforce proximity.",
                "To break a query into segments, we have to define a criteria to measure the strength of the relation between words.",
                "One effective method is to use mutual information as an indicator on whether or not to split two words [19].",
                "We use a log of 25M queries and collect the bigram and unigram frequencies from it.",
                "For every incoming query, we compute the mutual information of two adjacent words; if it passes a predefined threshold, we do not split the query between those two words and move on to next word.",
                "We continue this process until the mutual information between two words is below the threshold, then create a concept boundary here.",
                "Table 2 shows some examples of query segmentation.",
                "The ideal way of finding the head word of a concept is to do syntactic parsing to determine the dependency structure of the query.",
                "Query parsing is more difficult than sentence [running shoe] [best] [new york] [medical schools] [pictures] [of] [white house] [cookies] [in] [san francisco] [hotel] [price comparison] Table 2: Query segmentation: a segment is bracketed. parsing since many queries are not grammatical and are very short.",
                "Applying a parser trained on sentences from documents to queries will have poor performance.",
                "In our solution, we just use simple heuristics rules, and it works very well in practice for English.",
                "For an English noun phrase, the head word is typically the last nonstop word, unless the phrase is of a particular pattern, like XYZ of/in/at/from UVW.",
                "In such cases, the head word is typically the last nonstop word of XYZ. 3.4 Context sensitive word expansion After detecting which words are the most important words to expand, we have to decide whether the expansions will be useful.",
                "Our statistics show that about half of the queries can be transformed by pluralization via naive <br>stemming</br>.",
                "Among this half, about 25% of the queries improve relevance when transformed, the majority (about 50%) do not change their top 5 results, and the remaining 25% perform worse.",
                "Thus, it is extremely important to identify which queries should not be stemmed for the purpose of maximizing relevance improvement and minimizing <br>stemming</br> cost.",
                "In addition, for a query with multiple words that can be transformed, or a word with multiple variants, not all of the expansions are useful.",
                "Taking query hotel price comparison as an example, we decide that hotel and price comparison are two concepts.",
                "Head words hotel and comparison can be expanded to hotels and comparisons.",
                "Are both transformations useful?",
                "To test whether an expansion is useful, we have to know whether the expanded query is likely to get more relevant documents from the Web, which can be quantified by the probability of the query occurring as a string on the Web.",
                "The more likely a query to occur on the Web, the more relevant documents this query is able to return.",
                "Now the whole problem becomes how to calculate the probability of query to occur on the Web.",
                "Calculating the probability of string occurring in a corpus is a well known language modeling problem.",
                "The goal of language modeling is to predict the probability of naturally occurring word sequences, s = w1w2...wN ; or more simply, to put high probability on word sequences that actually occur (and low probability on word sequences that never occur).",
                "The simplest and most successful approach to language modeling is still based on the n-gram model.",
                "By the chain rule of probability one can write the probability of any word sequence as Pr(w1w2...wN ) = NY i=1 Pr(wi|w1...wi−1) (1) An n-gram model approximates this probability by assuming that the only words relevant to predicting Pr(wi|w1...wi−1) are the previous n − 1 words; i.e.",
                "Pr(wi|w1...wi−1) = Pr(wi|wi−n+1...wi−1) A straightforward maximum likelihood estimate of n-gram probabilities from a corpus is given by the observed frequency of each of the patterns Pr(wi|wi−n+1...wi−1) = #(wi−n+1...wi) #(wi−n+1...wi−1) (2) where #(.) denotes the number of occurrences of a specified gram in the training corpus.",
                "Although one could attempt to use simple n-gram models to capture long range dependencies in language, attempting to do so directly immediately creates sparse data problems: Using grams of length up to n entails estimating the probability of Wn events, where W is the size of the word vocabulary.",
                "This quickly overwhelms modern computational and data resources for even modest choices of n (beyond 3 to 6).",
                "Also, because of the heavy tailed nature of language (i.e.",
                "Zipfs law) one is likely to encounter novel n-grams that were never witnessed during training in any test corpus, and therefore some mechanism for assigning non-zero probability to novel n-grams is a central and unavoidable issue in statistical language modeling.",
                "One standard approach to smoothing probability estimates to cope with sparse data problems (and to cope with potentially missing n-grams) is to use some sort of back-off estimator.",
                "Pr(wi|wi−n+1...wi−1) = 8 >>< >>: ˆPr(wi|wi−n+1...wi−1), if #(wi−n+1...wi) > 0 β(wi−n+1...wi−1) × Pr(wi|wi−n+2...wi−1), otherwise (3) where ˆPr(wi|wi−n+1...wi−1) = discount #(wi−n+1...wi) #(wi−n+1...wi−1) (4) is the discounted probability and β(wi−n+1...wi−1) is a normalization constant β(wi−n+1...wi−1) = 1 − X x∈(wi−n+1...wi−1x) ˆPr(x|wi−n+1...wi−1) 1 − X x∈(wi−n+1...wi−1x) ˆPr(x|wi−n+2...wi−1) (5) The discounted probability (4) can be computed with different smoothing techniques, including absolute smoothing, Good-Turing smoothing, linear smoothing, and Witten-Bell smoothing [5].",
                "We used absolute smoothing in our experiments.",
                "Since the likelihood of a string, Pr(w1w2...wN ), is a very small number and hard to interpret, we use entropy as defined below to score the string.",
                "Entropy = − 1 N log2 Pr(w1w2...wN ) (6) Now getting back to the example of the query hotel price comparisons, there are four variants of this query, and the entropy of these four candidates are shown in Table 3.",
                "We can see that all alternatives are less likely than the input query.",
                "It is therefore not useful to make an expansion for this query.",
                "On the other hand, if the input query is hotel price comparisons which is the second alternative in the table, then there is a better alternative than the input query, and it should therefore be expanded.",
                "To tolerate the variations in probability estimation, we relax the selection criterion to those query alternatives if their scores are within a certain distance (10% in our experiments) to the best score.",
                "Query variations Entropy hotel price comparison 6.177 hotel price comparisons 6.597 hotels price comparison 6.937 hotels price comparisons 7.360 Table 3: Variations of query hotel price comparison ranked by entropy score, with the original query in bold face. 3.5 Context sensitive document matching Even after we know which word variants are likely to be useful, we have to be conservative in document matching for the expanded variants.",
                "For the query hotel price comparisons, we decided that word comparisons is expanded to include comparison.",
                "However, not every occurrence of comparison in the document is of interest.",
                "A page which is about comparing customer service can contain all of the words hotel price comparisons comparison.",
                "This page is not a good page for the query.",
                "If we accept matches of every occurrence of comparison, it will hurt retrieval precision and this is one of the main reasons why most <br>stemming</br> approaches do not work well for information retrieval.",
                "To address this problem, we have a proximity constraint that considers the context around the expanded variant in the document.",
                "A variant match is considered valid only if the variant occurs in the same context as the original word does.",
                "The context is the left or the right non-stop segments 1 of the original word.",
                "Taking the same query as an example, the context of comparisons is price.",
                "The expanded word comparison is only valid if it is in the same context of comparisons, which is after the word price.",
                "Thus, we should only match those occurrences of comparison in the document if they occur after the word price.",
                "Considering the fact that queries and documents may not represent the intent in exactly the same way, we relax this proximity constraint to allow variant occurrences within a window of some fixed size.",
                "If the expanded word comparison occurs within the context of price within a window, it is considered valid.",
                "The smaller the window size is, the more restrictive the matching.",
                "We use a window size of 4, which typically captures contexts that include the containing and adjacent noun phrases. 4.",
                "EXPERIMENTAL EVALUATION 4.1 Evaluation metrics We will measure both relevance improvement and the <br>stemming</br> cost required to achieve the relevance. 1 a context segment can not be a single stop word. 4.1.1 Relevance measurement We use a variant of the average Discounted Cumulative Gain (DCG), a recently popularized scheme to measure search engine relevance [1, 11].",
                "Given a query and a ranked list of K documents (K is set to 5 in our experiments), the DCG(K) score for this query is calculated as follows: DCG(K) = KX k=1 gk log2(1 + k) . (7) where gk is the weight for the document at rank k. Higher degree of relevance corresponds to a higher weight.",
                "A page is graded into one of the five scales: Perfect, Excellent, Good, Fair, Bad, with corresponding weights.",
                "We use dcg to represent the average DCG(5) over a set of test queries. 4.1.2 <br>stemming</br> cost Another metric is to measure the additional cost incurred by <br>stemming</br>.",
                "Given the same level of relevance improvement, we prefer a <br>stemming</br> method that has less additional cost.",
                "We measure this by the percentage of queries that are actually stemmed, over all the queries that could possibly be stemmed. 4.2 Data preparation We randomly sample 870 queries from a three month query log, with 290 from each month.",
                "Among all these 870 queries, we remove all misspelled queries since misspelled queries are not of interest to <br>stemming</br>.",
                "We also remove all one word queries since <br>stemming</br> one word queries without context has a high risk of changing query intent, especially for short words.",
                "In the end, we have 529 correctly spelled queries with at least 2 words. 4.3 Naive <br>stemming</br> for Web search Before explaining the experiments and results in detail, wed like to describe the traditional way of using <br>stemming</br> for Web search, referred as the naive model.",
                "This is to treat every word variant equivalent for all possible words in the query.",
                "The query book store will be transformed into (book OR books)(store OR stores) when limiting <br>stemming</br> to pluralization handling only, where OR is an operator that denotes the equivalence of the left and right arguments. 4.4 Experimental setup The baseline model is the model without <br>stemming</br>.",
                "We first run the naive model to see how well it performs over the baseline.",
                "Then we improve the naive <br>stemming</br> model by document sensitive matching, referred as document sensitive matching model.",
                "This model makes the same <br>stemming</br> as the naive model on the query side, but performs conservative matching on the document side using the strategy described in section 3.5.",
                "The naive model and document sensitive matching model stem the most queries.",
                "Out of the 529 queries, there are 408 queries that they stem, corresponding to 46.7% query traffic (out of a total of 870).",
                "We then further improve the document sensitive matching model from the query side with selective word <br>stemming</br> based on statistical language modeling (section 3.4), referred as selective <br>stemming</br> model.",
                "Based on language modeling prediction, this model stems only a subset of the 408 queries stemmed by the document sensitive matching model.",
                "We experiment with unigram language model and bigram language model.",
                "Since we only care how much we can improve the naive model, we will only use these 408 queries (all the queries that are affected by the naive <br>stemming</br> model) in the experiments.",
                "To get a sense of how these models perform, we also have an oracle model that gives the upper-bound performance a stemmer can achieve on this data.",
                "The oracle model only expands a word if the <br>stemming</br> will give better results.",
                "To analyze the pluralization handling influence on different query categories, we divide queries into short queries and long queries.",
                "Among the 408 queries stemmed by the naive model, there are 272 short queries with 2 or 3 words, and 136 long queries with at least 4 words. 4.5 Results We summarize the overall results in Table 4, and present the results on short queries and long queries separately in Table 5.",
                "Each row in Table 4 is a <br>stemming</br> strategy described in section 4.4.",
                "The first column is the name of the strategy.",
                "The second column is the number of queries affected by this strategy; this column measures the <br>stemming</br> cost, and the numbers should be low for the same level of dcg.",
                "The third column is the average dcg score over all tested queries in this category (including the ones that were not stemmed by the strategy).",
                "The fourth column is the relative improvement over the baseline, and the last column is the p-value of Wilcoxon significance test.",
                "There are several observations about the results.",
                "We can see the naively <br>stemming</br> only obtains a statistically insignificant improvement of 1.5%.",
                "Looking at Table 5, it gives an improvement of 2.7% on short queries.",
                "However, it also hurts long queries by -2.4%.",
                "Overall, the improvement is canceled out.",
                "The reason that it improves short queries is that most short queries only have one word that can be stemmed.",
                "Thus, blindly pluralizing short queries is relatively safe.",
                "However for long queries, most queries can have multiple words that can be pluralized.",
                "Expanding all of them without selection will significantly hurt precision.",
                "Document context sensitive <br>stemming</br> gives a significant lift to the performance, from 2.7% to 4.2% for short queries and from -2.4% to -1.6% for long queries, with an overall lift from 1.5% to 2.8%.",
                "The improvement comes from the conservative context sensitive document matching.",
                "An expanded word is valid only if it occurs within the context of original query in the document.",
                "This reduces many spurious matches.",
                "However, we still notice that for long queries, context sensitive <br>stemming</br> is not able to improve performance because it still selects too many documents and gives the ranking function a hard problem.",
                "While the chosen window size of 4 works the best amongst all the choices, it still allows spurious matches.",
                "It is possible that the window size needs to be chosen on a per query basis to ensure tighter proximity constraints for different types of noun phrases.",
                "Selective word pluralization further helps resolving the problem faced by document context sensitive <br>stemming</br>.",
                "It does not stem every word that places all the burden on the ranking algorithm, but tries to eliminate unnecessary <br>stemming</br> in the first place.",
                "By predicting which word variants are going to be useful, we can dramatically reduce the number of stemmed words, thus improving both the recall and the precision.",
                "With the unigram language model, we can reduce the <br>stemming</br> cost by 26.7% (from 408/408 to 300/408) and lift the overall dcg improvement from 2.8% to 3.4%.",
                "In particular, it gives significant improvements on long queries.",
                "The dcg gain is turned from negative to positive, from −1.6% to 1.1%.",
                "This confirms our hypothesis that reducing unnecessary word expansion leads to precision improvement.",
                "For short queries too, we observe both dcg improvement and <br>stemming</br> cost reduction with the unigram language model.",
                "The advantages of predictive word expansion with a language model is further boosted with a better bigram language model.",
                "The overall dcg gain is lifted from 3.4% to 3.9%, and <br>stemming</br> cost is dramatically reduced from 408/408 to 250/408, corresponding to only 29% of query traffic (250 out of 870) and an overall 1.8% dcg improvement overall all query traffic.",
                "For short queries, bigram language model improves the dcg gain from 4.4% to 4.7%, and reduces <br>stemming</br> cost from 272/272 to 150/272.",
                "For long queries, bigram language model improves dcg gain from 1.1% to 2.5%, and reduces <br>stemming</br> cost from 136/136 to 100/136.",
                "We observe that the bigram language model gives a larger lift for long queries.",
                "This is because the uncertainty in long queries is larger and a more powerful language model is needed.",
                "We hypothesize that a trigram language model would give a further lift for long queries and leave this for future investigation.",
                "Considering the tight upper-bound 2 on the improvement to be gained from pluralization handling (via the oracle model), the current performance on short queries is very satisfying.",
                "For short queries, the dcg gain upper-bound is 6.3% for perfect pluralization handling, our current gain is 4.7% with a bigram language model.",
                "For long queries, the dcg gain upper-bound is 4.6% for perfect pluralization handling, our current gain is 2.5% with a bigram language model.",
                "We may gain additional benefit with a more powerful language model for long queries.",
                "However, the difficulties of long queries come from many other aspects including the proximity and the segmentation problem.",
                "These problems have to be addressed separately.",
                "Looking at the the upper-bound of overhead reduction for oracle <br>stemming</br>, 75% (308/408) of the naive stemmings are wasteful.",
                "We currently capture about half of them.",
                "Further reduction of the overhead requires sacrificing the dcg gain.",
                "Now we can compare the <br>stemming</br> strategies from a different aspect.",
                "Instead of looking at the influence over all queries as we described above, Table 6 summarizes the dcg improvements over the affected queries only.",
                "We can see that the number of affected queries decreases as the <br>stemming</br> strategy becomes more accurate (dcg improvement).",
                "For the bigram language model, over the 250/408 stemmed queries, the dcg improvement is 6.1%.",
                "An interesting observation is the average dcg decreases with a better model, which indicates a better <br>stemming</br> strategy stems more difficult queries (low dcg queries). 5.",
                "DISCUSSIONS 5.1 Language models from query vs. from Web As we mentioned in Section 1, we are trying to predict the probability of a string occurring on the Web.",
                "The language model should describe the occurrence of the string on the Web.",
                "However, the query log is also a good resource. 2 Note that this upperbound is for pluralization handling only, not for general <br>stemming</br>.",
                "General <br>stemming</br> gives a 8% upperbound, which is quite substantial in terms of our metrics.",
                "Affected Queries dcg dcg Improvement p-value baseline 0/408 7.102 N/A N/A naive model 408/408 7.206 1.5% 0.22 document context sensitive model 408/408 7.302 2.8% 0.014 selective model: unigram LM 300/408 7.321 3.4% 0.001 selective model: bigram LM 250/408 7.381 3.9% 0.001 oracle model 100/408 7.519 5.9% 0.001 Table 4: Results comparison of different <br>stemming</br> strategies over all queries affected by naive <br>stemming</br> Short Query Results Affected Queries dcg Improvement p-value baseline 0/272 N/A N/A naive model 272/272 2.7% 0.48 document context sensitive model 272/272 4.2% 0.002 selective model: unigram LM 185/272 4.4% 0.001 selective model: bigram LM 150/272 4.7% 0.001 oracle model 71/272 6.3% 0.001 Long Query Results Affected Queries dcg Improvement p-value baseline 0/136 N/A N/A naive model 136/136 -2.4% 0.25 document context sensitive model 136/136 -1.6% 0.27 selective model: unigram LM 115/136 1.1% 0.001 selective model: bigram LM 100/136 2.5% 0.001 oracle model 29/136 4.6% 0.001 Table 5: Results comparison of different stemming strategies overall short queries and long queries Users reformulate a query using many different variants to get good results.",
                "To test the hypothesis that we can learn reliable transformation probabilities from the query log, we trained a language model from the same query top 25M queries as used to learn segmentation, and use that for prediction.",
                "We observed a slight performance decrease compared to the model trained on Web frequencies.",
                "In particular, the performance for unigram LM was not affected, but the dcg gain for bigram LM changed from 4.7% to 4.5% for short queries.",
                "Thus, the query log can serve as a good approximation of the Web frequencies. 5.2 How linguistics helps Some linguistic knowledge is useful in <br>stemming</br>.",
                "For the pluralization handling case, pluralization and de-pluralization is not symmetric.",
                "A plural word used in a query indicates a special intent.",
                "For example, the query new york hotels is looking for a list of hotels in new york, not the specific new york hotel which might be a hotel located in California.",
                "A simple equivalence of hotel to hotels might boost a particular page about new york hotel to top rank.",
                "To capture this intent, we have to make sure the document is a general page about hotels in new york.",
                "We do this by requiring that the plural word hotels appears in the document.",
                "On the other hand, converting a singular word to plural is safer since a general purpose page normally contains specific information.",
                "We observed a slight overall dcg decrease, although not statistically significant, for document context sensitive <br>stemming</br> if we do not consider this asymmetric property. 5.3 Error analysis One type of mistakes we noticed, though rare but seriously hurting relevance, is the search intent change after <br>stemming</br>.",
                "Generally speaking, pluralization or depluralization keeps the original intent.",
                "However, the intent could change in a few cases.",
                "For one example of such a query, job at apple, we pluralize job to jobs.",
                "This <br>stemming</br> makes the original query ambiguous.",
                "The query job OR jobs at apple has two intents.",
                "One is the employment opportunities at apple, and another is a person working at Apple, Steve Jobs, who is the CEO and co-founder of the company.",
                "Thus, the results after query <br>stemming</br> returns Steve Jobs as one of the results in top 5.",
                "One solution is performing results set based analysis to check if the intent is changed.",
                "This is similar to relevance feedback and requires second phase ranking.",
                "A second type of mistakes is the entity/concept recognition problem, These include two kinds.",
                "One is that the stemmed word variant now matches part of an entity or concept.",
                "For example, query cookies in san francisco is pluralized to cookies OR cookie in san francisco.",
                "The results will match cookie jar in san francisco.",
                "Although cookie still means the same thing as cookies, cookie jar is a different concept.",
                "Another kind is the unstemmed word matches an entity or concept because of the <br>stemming</br> of the other words.",
                "For example, quote ICE is pluralized to quote OR quotes ICE.",
                "The original intent for this query is searching for stock quote for ticker ICE.",
                "However, we noticed that among the top results, one of the results is Food quotes: Ice cream.",
                "This is matched because of Affected Queries old dcg new dcg dcg Improvement naive model 408/408 7.102 7.206 1.5% document context sensitive model 408/408 7.102 7.302 2.8% selective model: unigram LM 300/408 5.904 6.187 4.8% selective model: bigram LM 250/408 5.551 5.891 6.1% Table 6: Results comparison over the stemmed queries only: column old/new dcg is the dcg score over the affected queries before/after applying <br>stemming</br> the pluralized word quotes.",
                "The unchanged word ICE matches part of the noun phrase ice cream here.",
                "To solve this kind of problem, we have to analyze the documents and recognize cookie jar and ice cream as concepts instead of two independent words.",
                "A third type of mistakes occurs in long queries.",
                "For the query bar code reader software, two words are pluralized. code to codes and reader to readers.",
                "In fact, bar code reader in the original query is a strong concept and the internal words should not be changed.",
                "This is the segmentation and entity and noun phrase detection problem in queries, which we actively are attacking.",
                "For long queries, we should correctly identify the concepts in the query, and boost the proximity for the words within a concept. 6.",
                "CONCLUSIONS AND FUTURE WORK We have presented a simple yet elegant way of <br>stemming</br> for Web search.",
                "It improves naive <br>stemming</br> in two aspects: selective word expansion on the query side and conservative word occurrence matching on the document side.",
                "Using pluralization handling as an example, experiments on a major Web search engine data show it significantly improves the Web relevance and reduces the <br>stemming</br> cost.",
                "It also significantly improves Web click through rate (details not reported in the paper).",
                "For the future work, we are investigating the problems we identified in the error analysis section.",
                "These include: entity and noun phrase matching mistakes, and improved segmentation. 7.",
                "REFERENCES [1] E. Agichtein, E. Brill, and S. T. Dumais.",
                "Improving Web Search Ranking by Incorporating User Behavior Information.",
                "In SIGIR, 2006. [2] E. Airio.",
                "Word Normalization and Decompounding in Mono- and Bilingual IR.",
                "Information Retrieval, 9:249-271, 2006. [3] P. Anick.",
                "Using Terminological Feedback for Web Search Refinement: a Log-based Study.",
                "In SIGIR, 2003. [4] R. Baeza-Yates and B. Ribeiro-Neto.",
                "Modern Information Retrieval.",
                "ACM Press/Addison Wesley, 1999. [5] S. Chen and J. Goodman.",
                "An Empirical Study of Smoothing Techniques for Language Modeling.",
                "Technical Report TR-10-98, Harvard University, 1998. [6] S. Cronen-Townsend, Y. Zhou, and B. Croft.",
                "A Framework for Selective Query Expansion.",
                "In CIKM, 2004. [7] H. Fang and C. Zhai.",
                "Semantic Term Matching in Axiomatic Approaches to Information Retrieval.",
                "In SIGIR, 2006. [8] W. B. Frakes.",
                "Term Conflation for Information Retrieval.",
                "In C. J. Rijsbergen, editor, Research and Development in Information Retrieval, pages 383-389.",
                "Cambridge University Press, 1984. [9] D. Harman.",
                "How Effective is Suffixing?",
                "JASIS, 42(1):7-15, 1991. [10] D. Hull.",
                "<br>stemming</br> Algorithms - A Case Study for Detailed Evaluation.",
                "JASIS, 47(1):70-84, 1996. [11] K. Jarvelin and J. Kekalainen.",
                "Cumulated Gain-Based Evaluation Evaluation of IR Techniques.",
                "ACM TOIS, 20:422-446, 2002. [12] R. Jones, B. Rey, O. Madani, and W. Greiner.",
                "Generating Query Substitutions.",
                "In WWW, 2006. [13] W. Kraaij and R. Pohlmann.",
                "Viewing <br>stemming</br> as Recall Enhancement.",
                "In SIGIR, 1996. [14] R. Krovetz.",
                "Viewing Morphology as an Inference Process.",
                "In SIGIR, 1993. [15] D. Lin.",
                "Automatic Retrieval and Clustering of Similar Words.",
                "In COLING-ACL, 1998. [16] J.",
                "B. Lovins.",
                "Development of a <br>stemming</br> Algorithm.",
                "Mechanical Translation and Computational Linguistics, II:22-31, 1968. [17] M. Lennon and D. Peirce and B. Tarry and P. Willett.",
                "An Evaluation of Some Conflation Algorithms for Information Retrieval.",
                "Journal of Information Science, 3:177-188, 1981. [18] M. Porter.",
                "An Algorithm for Suffix Stripping.",
                "Program, 14(3):130-137, 1980. [19] K. M. Risvik, T. Mikolajewski, and P. Boros.",
                "Query Segmentation for Web Search.",
                "In WWW, 2003. [20] S. E. Robertson.",
                "On Term Selection for Query Expansion.",
                "Journal of Documentation, 46(4):359-364, 1990. [21] G. Salton and C. Buckley.",
                "Improving Retrieval Performance by Relevance Feedback.",
                "JASIS, 41(4):288 - 297, 1999. [22] R. Sun, C.-H. Ong, and T.-S. Chua.",
                "Mining Dependency Relations for Query Expansion in Passage Retrieval.",
                "In SIGIR, 2006. [23] C. Van Rijsbergen.",
                "Information Retrieval.",
                "Butterworths, second version, 1979. [24] B. V´elez, R. Weiss, M. A. Sheldon, and D. K. Gifford.",
                "Fast and Effective Query Refinement.",
                "In SIGIR, 1997. [25] J. Xu and B. Croft.",
                "Query Expansion using Local and Global Document Analysis.",
                "In SIGIR, 1996. [26] J. Xu and B. Croft.",
                "Corpus-based <br>stemming</br> using Cooccurrence of Word Variants.",
                "ACM TOIS, 16 (1):61-81, 1998."
            ],
            "original_annotated_samples": [
                "Context Sensitive <br>stemming</br> for Web Search Fuchun Peng Nawaaz Ahmed Xin Li Yumao Lu Yahoo!",
                "Inc. 701 First Avenue Sunnyvale, California 94089 {fuchun, nawaaz, xinli, yumaol}@yahoo-inc.com ABSTRACT Traditionally, <br>stemming</br> has been applied to Information Retrieval tasks by transforming words in documents to the their root form before indexing, and applying a similar transformation to query terms.",
                "In this paper, we propose a context sensitive <br>stemming</br> method that addresses these two issues.",
                "This conservative strategy serves as a safeguard against spurious <br>stemming</br>, and it turns out to be very important for improving precision.",
                "Using word pluralization handling as an example of our <br>stemming</br> approach, our experiments on a major Web search engine show that <br>stemming</br> only 29% of the query traffic, we can improve relevance as measured by average Discounted Cumulative Gain (DCG5) by 6.1% on these queries and 1.8% over all query traffic."
            ],
            "translated_annotated_samples": [
                "<br>Stemming</br> sensible al contexto para la búsqueda web Fuchun Peng Nawaaz Ahmed Xin Li Yumao Lu Yahoo!",
                "Tradicionalmente, el <br>truncamiento</br> se ha aplicado a tareas de Recuperación de Información transformando las palabras en documentos a su forma raíz antes de indexarlas, y aplicando una transformación similar a los términos de consulta.",
                "En este artículo, proponemos un método de <br>derivación sensible al contexto</br> que aborda estos dos problemas.",
                "Esta estrategia conservadora sirve como salvaguarda contra el <br>truncamiento</br> espurio, y resulta ser muy importante para mejorar la precisión.",
                "Usando el manejo de la pluralización de palabras como un ejemplo de nuestro enfoque de <br>derivación</br>, nuestros experimentos en un importante motor de búsqueda web muestran que al derivar solo el 29% del tráfico de consultas, podemos mejorar la relevancia medida por la Ganancia Acumulativa Descontada promedio (DCG5) en un 6.1% en estas consultas y en un 1.8% sobre todo el tráfico de consultas."
            ],
            "translated_text": "<br>Stemming</br> sensible al contexto para la búsqueda web Fuchun Peng Nawaaz Ahmed Xin Li Yumao Lu Yahoo! Tradicionalmente, el <br>truncamiento</br> se ha aplicado a tareas de Recuperación de Información transformando las palabras en documentos a su forma raíz antes de indexarlas, y aplicando una transformación similar a los términos de consulta. Aunque aumenta la recuperación, esta estrategia ingenua no funciona bien para la Búsqueda en la Web, ya que disminuye la precisión y requiere una cantidad significativa de cálculos adicionales. En este artículo, proponemos un método de <br>derivación sensible al contexto</br> que aborda estos dos problemas. Dos propiedades únicas hacen que nuestro enfoque sea factible para la Búsqueda en la Web. Primero, basados en modelado estadístico del lenguaje, realizamos un análisis sensible al contexto en el lado de la consulta. Predecimos con precisión cuál de sus variantes morfológicas es útil para expandir un término de consulta antes de enviar la consulta al motor de búsqueda. Esto reduce drásticamente la cantidad de expansiones incorrectas, lo que a su vez disminuye el costo de la computación adicional y mejora la precisión al mismo tiempo. Segundo, nuestro enfoque realiza una coincidencia de documentos sensible al contexto para esas variantes ampliadas. Esta estrategia conservadora sirve como salvaguarda contra el <br>truncamiento</br> espurio, y resulta ser muy importante para mejorar la precisión. Usando el manejo de la pluralización de palabras como un ejemplo de nuestro enfoque de <br>derivación</br>, nuestros experimentos en un importante motor de búsqueda web muestran que al derivar solo el 29% del tráfico de consultas, podemos mejorar la relevancia medida por la Ganancia Acumulativa Descontada promedio (DCG5) en un 6.1% en estas consultas y en un 1.8% sobre todo el tráfico de consultas. ",
            "candidates": [],
            "error": [
                [
                    "Stemming",
                    "truncamiento",
                    "derivación sensible al contexto",
                    "truncamiento",
                    "derivación"
                ]
            ]
        },
        "lovin stemmer": {
            "translated_key": "Amor de tallo",
            "is_in_text": false,
            "original_annotated_sentences": [
                "Context Sensitive Stemming for Web Search Fuchun Peng Nawaaz Ahmed Xin Li Yumao Lu Yahoo!",
                "Inc. 701 First Avenue Sunnyvale, California 94089 {fuchun, nawaaz, xinli, yumaol}@yahoo-inc.com ABSTRACT Traditionally, stemming has been applied to Information Retrieval tasks by transforming words in documents to the their root form before indexing, and applying a similar transformation to query terms.",
                "Although it increases recall, this naive strategy does not work well for Web Search since it lowers precision and requires a significant amount of additional computation.",
                "In this paper, we propose a context sensitive stemming method that addresses these two issues.",
                "Two unique properties make our approach feasible for Web Search.",
                "First, based on statistical language modeling, we perform context sensitive analysis on the query side.",
                "We accurately predict which of its morphological variants is useful to expand a query term with before submitting the query to the search engine.",
                "This dramatically reduces the number of bad expansions, which in turn reduces the cost of additional computation and improves the precision at the same time.",
                "Second, our approach performs a context sensitive document matching for those expanded variants.",
                "This conservative strategy serves as a safeguard against spurious stemming, and it turns out to be very important for improving precision.",
                "Using word pluralization handling as an example of our stemming approach, our experiments on a major Web search engine show that stemming only 29% of the query traffic, we can improve relevance as measured by average Discounted Cumulative Gain (DCG5) by 6.1% on these queries and 1.8% over all query traffic.",
                "Categories and Subject Descriptors H.3.3 [Information Systems]: Information Storage and Retrieval-Query formulation General Terms Algorithms, Experimentation 1.",
                "INTRODUCTION Web search has now become a major tool in our daily lives for information seeking.",
                "One of the important issues in Web search is that user queries are often not best formulated to get optimal results.",
                "For example, running shoe is a query that occurs frequently in query logs.",
                "However, the query running shoes is much more likely to give better search results than the original query because documents matching the intent of this query usually contain the words running shoes.",
                "Correctly formulating a query requires the user to accurately predict which word form is used in the documents that best satisfy his or her information needs.",
                "This is difficult even for experienced users, and especially difficult for non-native speakers.",
                "One traditional solution is to use stemming [16, 18], the process of transforming inflected or derived words to their root form so that a search term will match and retrieve documents containing all forms of the term.",
                "Thus, the word run will match running, ran, runs, and shoe will match shoes and shoeing.",
                "Stemming can be done either on the terms in a document during indexing (and applying the same transformation to the query terms during query processing) or by expanding the query with the variants during query processing.",
                "Stemming during indexing allows very little flexibility during query processing, while stemming by query expansion allows handling each query differently, and hence is preferred.",
                "Although traditional stemming increases recall by matching word variants [13], it can reduce precision by retrieving too many documents that have been incorrectly matched.",
                "When examining the results of applying stemming to a large number of queries, one usually finds that nearly equal numbers of queries are helped and hurt by the technique [6].",
                "In addition, it reduces system performance because the search engine has to match all the word variants.",
                "As we will show in the experiments, this is true even if we simplify stemming to pluralization handling, which is the process of converting a word from its plural to singular form, or vice versa.",
                "Thus, one needs to be very cautious when using stemming in Web search engines.",
                "One problem of traditional stemming is its blind transformation of all query terms, that is, it always performs the same transformation for the same query word without considering the context of the word.",
                "For example, the word book has four forms book, books, booking, booked, and store has four forms store, stores, storing, stored.",
                "For the query book store, expanding both words to all of their variants significantly increases computation cost and hurts precision, since not all of the variants are useful for this query.",
                "Transforming book store to match book stores is fine, but matching book storing or booking store is not.",
                "A weighting method that gives variant words smaller weights alleviates the problems to a certain extent if the weights accurately reflect the importance of the variant in this particular query.",
                "However uniform weighting is not going to work and a query dependent weighting is still a challenging unsolved problem [20].",
                "A second problem of traditional stemming is its blind matching of all occurrences in documents.",
                "For the query book store, a transformation that allows the variant stores to be matched will cause every occurrence of stores in the document to be treated equivalent to the query term store.",
                "Thus, a document containing the fragment reading a book in coffee stores will be matched, causing many wrong documents to be selected.",
                "Although we hope the ranking function can correctly handle these, with many more candidates to rank, the risk of making mistakes increases.",
                "To alleviate these two problems, we propose a context sensitive stemming approach for Web search.",
                "Our solution consists of two context sensitive analysis, one on the query side and the other on the document side.",
                "On the query side, we propose a statistical language modeling based approach to predict which word variants are better forms than the original word for search purpose and expanding the query with only those forms.",
                "On the document side, we propose a conservative context sensitive matching for the transformed word variants, only matching document occurrences in the context of other terms in the query.",
                "Our model is simple yet effective and efficient, making it feasible to be used in real commercial Web search engines.",
                "We use pluralization handling as a running example for our stemming approach.",
                "The motivation for using pluralization handling as an example is to show that even such simple stemming, if handled correctly, can give significant benefits to search relevance.",
                "As far as we know, no previous research has systematically investigated the usage of pluralization in Web search.",
                "As we have to point out, the method we propose is not limited to pluralization handling, it is a general stemming technique, and can also be applied to general query expansion.",
                "Experiments on general stemming yield additional significant improvements over pluralization handling for long queries, although details will not be reported in this paper.",
                "In the rest of the paper, we first present the related work and distinguish our method from previous work in Section 2.",
                "We describe the details of the context sensitive stemming approach in Section 3.",
                "We then perform extensive experiments on a major Web search engine to support our claims in Section 4, followed by discussions in Section 5.",
                "Finally, we conclude the paper in Section 6. 2.",
                "RELATED WORK Stemming is a long studied technology.",
                "Many stemmers have been developed, such as the Lovins stemmer [16] and the Porter stemmer [18].",
                "The Porter stemmer is widely used due to its simplicity and effectiveness in many applications.",
                "However, the Porter stemming makes many mistakes because its simple rules cannot fully describe English morphology.",
                "Corpus analysis is used to improve Porter stemmer [26] by creating equivalence classes for words that are morphologically similar and occur in similar context as measured by expected mutual information [23].",
                "We use a similar corpus based approach for stemming by computing the similarity between two words based on their distributional context features which can be more than just adjacent words [15], and then only keep the morphologically similar words as candidates.",
                "Using stemming in information retrieval is also a well known technique [8, 10].",
                "However, the effectiveness of stemming for English query systems was previously reported to be rather limited.",
                "Lennon et al. [17] compared the Lovins and Porter algorithms and found little improvement in retrieval performance.",
                "Later, Harman [9] compares three general stemming techniques in text retrieval experiments including pluralization handing (called S stemmer in the paper).",
                "They also proposed selective stemming based on query length and term importance, but no positive results were reported.",
                "On the other hand, Krovetz [14] performed comparisons over small numbers of documents (from 400 to 12k) and showed dramatic precision improvement (up to 45%).",
                "However, due to the limited number of tested queries (less than 100) and the small size of the collection, the results are hard to generalize to Web search.",
                "These mixed results, mostly failures, led early IR researchers to deem stemming irrelevant in general for English [4], although recent research has shown stemming has greater benefits for retrieval in other languages [2].",
                "We suspect the previous failures were mainly due to the two problems we mentioned in the introduction.",
                "Blind stemming, or a simple query length based selective stemming as used in [9] is not enough.",
                "Stemming has to be decided on case by case basis, not only at the query level but also at the document level.",
                "As we will show, if handled correctly, significant improvement can be achieved.",
                "A more general problem related to stemming is query reformulation [3, 12] and query expansion which expands words not only with word variants [7, 22, 24, 25].",
                "To decide which expanded words to use, people often use pseudorelevance feedback techniquesthat send the original query to a search engine and retrieve the top documents, extract relevant words from these top documents as additional query words, and resubmit the expanded query again [21].",
                "This normally requires sending a query multiple times to search engine and it is not cost effective for processing the huge amount of queries involved in Web search.",
                "In addition, query expansion, including query reformulation [3, 12], has a high risk of changing the user intent (called query drift).",
                "Since the expanded words may have different meanings, adding them to the query could potentially change the intent of the original query.",
                "Thus query expansion based on pseudorelevance and query reformulation can provide suggestions to users for interactive refinement but can hardly be directly used for Web search.",
                "On the other hand, stemming is much more conservative since most of the time, stemming preserves the original search intent.",
                "While most work on query expansion focuses on recall enhancement, our work focuses on increasing both recall and precision.",
                "The increase on recall is obvious.",
                "With quality stemming, good documents which were not selected before stemming will be pushed up and those low quality documents will be degraded.",
                "On selective query expansion, Cronen-Townsend et al. [6] proposed a method for selective query expansion based on comparing the Kullback-Leibler divergence of the results from the unexpanded query and the results from the expanded query.",
                "This is similar to the relevance feedback in the sense that it requires multiple passes retrieval.",
                "If a word can be expanded into several words, it requires running this process multiple times to decide which expanded word is useful.",
                "It is expensive to deploy this in production Web search engines.",
                "Our method predicts the quality of expansion based on oﬄine information without sending the query to a search engine.",
                "In summary, we propose a novel approach to attack an old, yet still important and challenging problem for Web search - stemming.",
                "Our approach is unique in that it performs predictive stemming on a per query basis without relevance feedback from the Web, using the context of the variants in documents to preserve precision.",
                "Its simple, yet very efficient and effective, making real time stemming feasible for Web search.",
                "Our results will affirm researchers that stemming is indeed very important to large scale information retrieval. 3.",
                "CONTEXT SENSITIVE STEMMING 3.1 Overview Our system has four components as illustrated in Figure 1: candidate generation, query segmentation and head word detection, context sensitive query stemming and context sensitive document matching.",
                "Candidate generation (component 1) is performed oﬄine and generated candidates are stored in a dictionary.",
                "For an input query, we first segment query into concepts and detect the head word for each concept (component 2).",
                "We then use statistical language modeling to decide whether a particular variant is useful (component 3), and finally for the expanded variants, we perform context sensitive document matching (component 4).",
                "Below we discuss each of the components in more detail.",
                "Component 4: context sensitive document matching Input Query: and head word detection Component 2: segment Component 1: candidate generation comparisons −> comparison Component 3: selective word expansion decision: comparisons −> comparison example: hotel price comparisons output: hotel comparisons hotel −> hotels Figure 1: System Components 3.2 Expansion candidate generation One of the ways to generate candidates is using the Porter stemmer [18].",
                "The Porter stemmer simply uses morphological rules to convert a word to its base form.",
                "It has no knowledge of the semantic meaning of the words and sometimes makes serious mistakes, such as executive to execution, news to new, and paste to past.",
                "A more conservative way is based on using corpus analysis to improve the Porter stemmer results [26].",
                "The corpus analysis we do is based on word distributional similarity [15].",
                "The rationale of using distributional word similarity is that true variants tend to be used in similar contexts.",
                "In the distributional word similarity calculation, each word is represented with a vector of features derived from the context of the word.",
                "We use the bigrams to the left and right of the word as its context features, by mining a huge Web corpus.",
                "The similarity between two words is the cosine similarity between the two corresponding feature vectors.",
                "The top 20 similar words to develop is shown in the following table. rank candidate score rank candidate score 0 develop 1 10 berts 0.119 1 developing 0.339 11 wads 0.116 2 developed 0.176 12 developer 0.107 3 incubator 0.160 13 promoting 0.100 4 develops 0.150 14 developmental 0.091 5 development 0.148 15 reengineering 0.090 6 tutoring 0.138 16 build 0.083 7 analyzing 0.128 17 construct 0.081 8 developement 0.128 18 educational 0.081 9 automation 0.126 19 institute 0.077 Table 1: Top 20 most similar candidates to word develop.",
                "Column score is the similarity score.",
                "To determine the stemming candidates, we apply a few Porter stemmer [18] morphological rules to the similarity list.",
                "After applying these rules, for the word develop, the stemming candidates are developing, developed, develops, development, developement, developer, developmental.",
                "For the pluralization handling purpose, only the candidate develops is retained.",
                "One thing we note from observing the distributionally similar words is that they are closely related semantically.",
                "These words might serve as candidates for general query expansion, a topic we will investigate in the future. 3.3 Segmentation and headword identification For long queries, it is quite important to detect the concepts in the query and the most important words for those concepts.",
                "We first break a query into segments, each segment representing a concept which normally is a noun phrase.",
                "For each of the noun phrases, we then detect the most important word which we call the head word.",
                "Segmentation is also used in document sensitive matching (section 3.5) to enforce proximity.",
                "To break a query into segments, we have to define a criteria to measure the strength of the relation between words.",
                "One effective method is to use mutual information as an indicator on whether or not to split two words [19].",
                "We use a log of 25M queries and collect the bigram and unigram frequencies from it.",
                "For every incoming query, we compute the mutual information of two adjacent words; if it passes a predefined threshold, we do not split the query between those two words and move on to next word.",
                "We continue this process until the mutual information between two words is below the threshold, then create a concept boundary here.",
                "Table 2 shows some examples of query segmentation.",
                "The ideal way of finding the head word of a concept is to do syntactic parsing to determine the dependency structure of the query.",
                "Query parsing is more difficult than sentence [running shoe] [best] [new york] [medical schools] [pictures] [of] [white house] [cookies] [in] [san francisco] [hotel] [price comparison] Table 2: Query segmentation: a segment is bracketed. parsing since many queries are not grammatical and are very short.",
                "Applying a parser trained on sentences from documents to queries will have poor performance.",
                "In our solution, we just use simple heuristics rules, and it works very well in practice for English.",
                "For an English noun phrase, the head word is typically the last nonstop word, unless the phrase is of a particular pattern, like XYZ of/in/at/from UVW.",
                "In such cases, the head word is typically the last nonstop word of XYZ. 3.4 Context sensitive word expansion After detecting which words are the most important words to expand, we have to decide whether the expansions will be useful.",
                "Our statistics show that about half of the queries can be transformed by pluralization via naive stemming.",
                "Among this half, about 25% of the queries improve relevance when transformed, the majority (about 50%) do not change their top 5 results, and the remaining 25% perform worse.",
                "Thus, it is extremely important to identify which queries should not be stemmed for the purpose of maximizing relevance improvement and minimizing stemming cost.",
                "In addition, for a query with multiple words that can be transformed, or a word with multiple variants, not all of the expansions are useful.",
                "Taking query hotel price comparison as an example, we decide that hotel and price comparison are two concepts.",
                "Head words hotel and comparison can be expanded to hotels and comparisons.",
                "Are both transformations useful?",
                "To test whether an expansion is useful, we have to know whether the expanded query is likely to get more relevant documents from the Web, which can be quantified by the probability of the query occurring as a string on the Web.",
                "The more likely a query to occur on the Web, the more relevant documents this query is able to return.",
                "Now the whole problem becomes how to calculate the probability of query to occur on the Web.",
                "Calculating the probability of string occurring in a corpus is a well known language modeling problem.",
                "The goal of language modeling is to predict the probability of naturally occurring word sequences, s = w1w2...wN ; or more simply, to put high probability on word sequences that actually occur (and low probability on word sequences that never occur).",
                "The simplest and most successful approach to language modeling is still based on the n-gram model.",
                "By the chain rule of probability one can write the probability of any word sequence as Pr(w1w2...wN ) = NY i=1 Pr(wi|w1...wi−1) (1) An n-gram model approximates this probability by assuming that the only words relevant to predicting Pr(wi|w1...wi−1) are the previous n − 1 words; i.e.",
                "Pr(wi|w1...wi−1) = Pr(wi|wi−n+1...wi−1) A straightforward maximum likelihood estimate of n-gram probabilities from a corpus is given by the observed frequency of each of the patterns Pr(wi|wi−n+1...wi−1) = #(wi−n+1...wi) #(wi−n+1...wi−1) (2) where #(.) denotes the number of occurrences of a specified gram in the training corpus.",
                "Although one could attempt to use simple n-gram models to capture long range dependencies in language, attempting to do so directly immediately creates sparse data problems: Using grams of length up to n entails estimating the probability of Wn events, where W is the size of the word vocabulary.",
                "This quickly overwhelms modern computational and data resources for even modest choices of n (beyond 3 to 6).",
                "Also, because of the heavy tailed nature of language (i.e.",
                "Zipfs law) one is likely to encounter novel n-grams that were never witnessed during training in any test corpus, and therefore some mechanism for assigning non-zero probability to novel n-grams is a central and unavoidable issue in statistical language modeling.",
                "One standard approach to smoothing probability estimates to cope with sparse data problems (and to cope with potentially missing n-grams) is to use some sort of back-off estimator.",
                "Pr(wi|wi−n+1...wi−1) = 8 >>< >>: ˆPr(wi|wi−n+1...wi−1), if #(wi−n+1...wi) > 0 β(wi−n+1...wi−1) × Pr(wi|wi−n+2...wi−1), otherwise (3) where ˆPr(wi|wi−n+1...wi−1) = discount #(wi−n+1...wi) #(wi−n+1...wi−1) (4) is the discounted probability and β(wi−n+1...wi−1) is a normalization constant β(wi−n+1...wi−1) = 1 − X x∈(wi−n+1...wi−1x) ˆPr(x|wi−n+1...wi−1) 1 − X x∈(wi−n+1...wi−1x) ˆPr(x|wi−n+2...wi−1) (5) The discounted probability (4) can be computed with different smoothing techniques, including absolute smoothing, Good-Turing smoothing, linear smoothing, and Witten-Bell smoothing [5].",
                "We used absolute smoothing in our experiments.",
                "Since the likelihood of a string, Pr(w1w2...wN ), is a very small number and hard to interpret, we use entropy as defined below to score the string.",
                "Entropy = − 1 N log2 Pr(w1w2...wN ) (6) Now getting back to the example of the query hotel price comparisons, there are four variants of this query, and the entropy of these four candidates are shown in Table 3.",
                "We can see that all alternatives are less likely than the input query.",
                "It is therefore not useful to make an expansion for this query.",
                "On the other hand, if the input query is hotel price comparisons which is the second alternative in the table, then there is a better alternative than the input query, and it should therefore be expanded.",
                "To tolerate the variations in probability estimation, we relax the selection criterion to those query alternatives if their scores are within a certain distance (10% in our experiments) to the best score.",
                "Query variations Entropy hotel price comparison 6.177 hotel price comparisons 6.597 hotels price comparison 6.937 hotels price comparisons 7.360 Table 3: Variations of query hotel price comparison ranked by entropy score, with the original query in bold face. 3.5 Context sensitive document matching Even after we know which word variants are likely to be useful, we have to be conservative in document matching for the expanded variants.",
                "For the query hotel price comparisons, we decided that word comparisons is expanded to include comparison.",
                "However, not every occurrence of comparison in the document is of interest.",
                "A page which is about comparing customer service can contain all of the words hotel price comparisons comparison.",
                "This page is not a good page for the query.",
                "If we accept matches of every occurrence of comparison, it will hurt retrieval precision and this is one of the main reasons why most stemming approaches do not work well for information retrieval.",
                "To address this problem, we have a proximity constraint that considers the context around the expanded variant in the document.",
                "A variant match is considered valid only if the variant occurs in the same context as the original word does.",
                "The context is the left or the right non-stop segments 1 of the original word.",
                "Taking the same query as an example, the context of comparisons is price.",
                "The expanded word comparison is only valid if it is in the same context of comparisons, which is after the word price.",
                "Thus, we should only match those occurrences of comparison in the document if they occur after the word price.",
                "Considering the fact that queries and documents may not represent the intent in exactly the same way, we relax this proximity constraint to allow variant occurrences within a window of some fixed size.",
                "If the expanded word comparison occurs within the context of price within a window, it is considered valid.",
                "The smaller the window size is, the more restrictive the matching.",
                "We use a window size of 4, which typically captures contexts that include the containing and adjacent noun phrases. 4.",
                "EXPERIMENTAL EVALUATION 4.1 Evaluation metrics We will measure both relevance improvement and the stemming cost required to achieve the relevance. 1 a context segment can not be a single stop word. 4.1.1 Relevance measurement We use a variant of the average Discounted Cumulative Gain (DCG), a recently popularized scheme to measure search engine relevance [1, 11].",
                "Given a query and a ranked list of K documents (K is set to 5 in our experiments), the DCG(K) score for this query is calculated as follows: DCG(K) = KX k=1 gk log2(1 + k) . (7) where gk is the weight for the document at rank k. Higher degree of relevance corresponds to a higher weight.",
                "A page is graded into one of the five scales: Perfect, Excellent, Good, Fair, Bad, with corresponding weights.",
                "We use dcg to represent the average DCG(5) over a set of test queries. 4.1.2 Stemming cost Another metric is to measure the additional cost incurred by stemming.",
                "Given the same level of relevance improvement, we prefer a stemming method that has less additional cost.",
                "We measure this by the percentage of queries that are actually stemmed, over all the queries that could possibly be stemmed. 4.2 Data preparation We randomly sample 870 queries from a three month query log, with 290 from each month.",
                "Among all these 870 queries, we remove all misspelled queries since misspelled queries are not of interest to stemming.",
                "We also remove all one word queries since stemming one word queries without context has a high risk of changing query intent, especially for short words.",
                "In the end, we have 529 correctly spelled queries with at least 2 words. 4.3 Naive stemming for Web search Before explaining the experiments and results in detail, wed like to describe the traditional way of using stemming for Web search, referred as the naive model.",
                "This is to treat every word variant equivalent for all possible words in the query.",
                "The query book store will be transformed into (book OR books)(store OR stores) when limiting stemming to pluralization handling only, where OR is an operator that denotes the equivalence of the left and right arguments. 4.4 Experimental setup The baseline model is the model without stemming.",
                "We first run the naive model to see how well it performs over the baseline.",
                "Then we improve the naive stemming model by document sensitive matching, referred as document sensitive matching model.",
                "This model makes the same stemming as the naive model on the query side, but performs conservative matching on the document side using the strategy described in section 3.5.",
                "The naive model and document sensitive matching model stem the most queries.",
                "Out of the 529 queries, there are 408 queries that they stem, corresponding to 46.7% query traffic (out of a total of 870).",
                "We then further improve the document sensitive matching model from the query side with selective word stemming based on statistical language modeling (section 3.4), referred as selective stemming model.",
                "Based on language modeling prediction, this model stems only a subset of the 408 queries stemmed by the document sensitive matching model.",
                "We experiment with unigram language model and bigram language model.",
                "Since we only care how much we can improve the naive model, we will only use these 408 queries (all the queries that are affected by the naive stemming model) in the experiments.",
                "To get a sense of how these models perform, we also have an oracle model that gives the upper-bound performance a stemmer can achieve on this data.",
                "The oracle model only expands a word if the stemming will give better results.",
                "To analyze the pluralization handling influence on different query categories, we divide queries into short queries and long queries.",
                "Among the 408 queries stemmed by the naive model, there are 272 short queries with 2 or 3 words, and 136 long queries with at least 4 words. 4.5 Results We summarize the overall results in Table 4, and present the results on short queries and long queries separately in Table 5.",
                "Each row in Table 4 is a stemming strategy described in section 4.4.",
                "The first column is the name of the strategy.",
                "The second column is the number of queries affected by this strategy; this column measures the stemming cost, and the numbers should be low for the same level of dcg.",
                "The third column is the average dcg score over all tested queries in this category (including the ones that were not stemmed by the strategy).",
                "The fourth column is the relative improvement over the baseline, and the last column is the p-value of Wilcoxon significance test.",
                "There are several observations about the results.",
                "We can see the naively stemming only obtains a statistically insignificant improvement of 1.5%.",
                "Looking at Table 5, it gives an improvement of 2.7% on short queries.",
                "However, it also hurts long queries by -2.4%.",
                "Overall, the improvement is canceled out.",
                "The reason that it improves short queries is that most short queries only have one word that can be stemmed.",
                "Thus, blindly pluralizing short queries is relatively safe.",
                "However for long queries, most queries can have multiple words that can be pluralized.",
                "Expanding all of them without selection will significantly hurt precision.",
                "Document context sensitive stemming gives a significant lift to the performance, from 2.7% to 4.2% for short queries and from -2.4% to -1.6% for long queries, with an overall lift from 1.5% to 2.8%.",
                "The improvement comes from the conservative context sensitive document matching.",
                "An expanded word is valid only if it occurs within the context of original query in the document.",
                "This reduces many spurious matches.",
                "However, we still notice that for long queries, context sensitive stemming is not able to improve performance because it still selects too many documents and gives the ranking function a hard problem.",
                "While the chosen window size of 4 works the best amongst all the choices, it still allows spurious matches.",
                "It is possible that the window size needs to be chosen on a per query basis to ensure tighter proximity constraints for different types of noun phrases.",
                "Selective word pluralization further helps resolving the problem faced by document context sensitive stemming.",
                "It does not stem every word that places all the burden on the ranking algorithm, but tries to eliminate unnecessary stemming in the first place.",
                "By predicting which word variants are going to be useful, we can dramatically reduce the number of stemmed words, thus improving both the recall and the precision.",
                "With the unigram language model, we can reduce the stemming cost by 26.7% (from 408/408 to 300/408) and lift the overall dcg improvement from 2.8% to 3.4%.",
                "In particular, it gives significant improvements on long queries.",
                "The dcg gain is turned from negative to positive, from −1.6% to 1.1%.",
                "This confirms our hypothesis that reducing unnecessary word expansion leads to precision improvement.",
                "For short queries too, we observe both dcg improvement and stemming cost reduction with the unigram language model.",
                "The advantages of predictive word expansion with a language model is further boosted with a better bigram language model.",
                "The overall dcg gain is lifted from 3.4% to 3.9%, and stemming cost is dramatically reduced from 408/408 to 250/408, corresponding to only 29% of query traffic (250 out of 870) and an overall 1.8% dcg improvement overall all query traffic.",
                "For short queries, bigram language model improves the dcg gain from 4.4% to 4.7%, and reduces stemming cost from 272/272 to 150/272.",
                "For long queries, bigram language model improves dcg gain from 1.1% to 2.5%, and reduces stemming cost from 136/136 to 100/136.",
                "We observe that the bigram language model gives a larger lift for long queries.",
                "This is because the uncertainty in long queries is larger and a more powerful language model is needed.",
                "We hypothesize that a trigram language model would give a further lift for long queries and leave this for future investigation.",
                "Considering the tight upper-bound 2 on the improvement to be gained from pluralization handling (via the oracle model), the current performance on short queries is very satisfying.",
                "For short queries, the dcg gain upper-bound is 6.3% for perfect pluralization handling, our current gain is 4.7% with a bigram language model.",
                "For long queries, the dcg gain upper-bound is 4.6% for perfect pluralization handling, our current gain is 2.5% with a bigram language model.",
                "We may gain additional benefit with a more powerful language model for long queries.",
                "However, the difficulties of long queries come from many other aspects including the proximity and the segmentation problem.",
                "These problems have to be addressed separately.",
                "Looking at the the upper-bound of overhead reduction for oracle stemming, 75% (308/408) of the naive stemmings are wasteful.",
                "We currently capture about half of them.",
                "Further reduction of the overhead requires sacrificing the dcg gain.",
                "Now we can compare the stemming strategies from a different aspect.",
                "Instead of looking at the influence over all queries as we described above, Table 6 summarizes the dcg improvements over the affected queries only.",
                "We can see that the number of affected queries decreases as the stemming strategy becomes more accurate (dcg improvement).",
                "For the bigram language model, over the 250/408 stemmed queries, the dcg improvement is 6.1%.",
                "An interesting observation is the average dcg decreases with a better model, which indicates a better stemming strategy stems more difficult queries (low dcg queries). 5.",
                "DISCUSSIONS 5.1 Language models from query vs. from Web As we mentioned in Section 1, we are trying to predict the probability of a string occurring on the Web.",
                "The language model should describe the occurrence of the string on the Web.",
                "However, the query log is also a good resource. 2 Note that this upperbound is for pluralization handling only, not for general stemming.",
                "General stemming gives a 8% upperbound, which is quite substantial in terms of our metrics.",
                "Affected Queries dcg dcg Improvement p-value baseline 0/408 7.102 N/A N/A naive model 408/408 7.206 1.5% 0.22 document context sensitive model 408/408 7.302 2.8% 0.014 selective model: unigram LM 300/408 7.321 3.4% 0.001 selective model: bigram LM 250/408 7.381 3.9% 0.001 oracle model 100/408 7.519 5.9% 0.001 Table 4: Results comparison of different stemming strategies over all queries affected by naive stemming Short Query Results Affected Queries dcg Improvement p-value baseline 0/272 N/A N/A naive model 272/272 2.7% 0.48 document context sensitive model 272/272 4.2% 0.002 selective model: unigram LM 185/272 4.4% 0.001 selective model: bigram LM 150/272 4.7% 0.001 oracle model 71/272 6.3% 0.001 Long Query Results Affected Queries dcg Improvement p-value baseline 0/136 N/A N/A naive model 136/136 -2.4% 0.25 document context sensitive model 136/136 -1.6% 0.27 selective model: unigram LM 115/136 1.1% 0.001 selective model: bigram LM 100/136 2.5% 0.001 oracle model 29/136 4.6% 0.001 Table 5: Results comparison of different stemming strategies overall short queries and long queries Users reformulate a query using many different variants to get good results.",
                "To test the hypothesis that we can learn reliable transformation probabilities from the query log, we trained a language model from the same query top 25M queries as used to learn segmentation, and use that for prediction.",
                "We observed a slight performance decrease compared to the model trained on Web frequencies.",
                "In particular, the performance for unigram LM was not affected, but the dcg gain for bigram LM changed from 4.7% to 4.5% for short queries.",
                "Thus, the query log can serve as a good approximation of the Web frequencies. 5.2 How linguistics helps Some linguistic knowledge is useful in stemming.",
                "For the pluralization handling case, pluralization and de-pluralization is not symmetric.",
                "A plural word used in a query indicates a special intent.",
                "For example, the query new york hotels is looking for a list of hotels in new york, not the specific new york hotel which might be a hotel located in California.",
                "A simple equivalence of hotel to hotels might boost a particular page about new york hotel to top rank.",
                "To capture this intent, we have to make sure the document is a general page about hotels in new york.",
                "We do this by requiring that the plural word hotels appears in the document.",
                "On the other hand, converting a singular word to plural is safer since a general purpose page normally contains specific information.",
                "We observed a slight overall dcg decrease, although not statistically significant, for document context sensitive stemming if we do not consider this asymmetric property. 5.3 Error analysis One type of mistakes we noticed, though rare but seriously hurting relevance, is the search intent change after stemming.",
                "Generally speaking, pluralization or depluralization keeps the original intent.",
                "However, the intent could change in a few cases.",
                "For one example of such a query, job at apple, we pluralize job to jobs.",
                "This stemming makes the original query ambiguous.",
                "The query job OR jobs at apple has two intents.",
                "One is the employment opportunities at apple, and another is a person working at Apple, Steve Jobs, who is the CEO and co-founder of the company.",
                "Thus, the results after query stemming returns Steve Jobs as one of the results in top 5.",
                "One solution is performing results set based analysis to check if the intent is changed.",
                "This is similar to relevance feedback and requires second phase ranking.",
                "A second type of mistakes is the entity/concept recognition problem, These include two kinds.",
                "One is that the stemmed word variant now matches part of an entity or concept.",
                "For example, query cookies in san francisco is pluralized to cookies OR cookie in san francisco.",
                "The results will match cookie jar in san francisco.",
                "Although cookie still means the same thing as cookies, cookie jar is a different concept.",
                "Another kind is the unstemmed word matches an entity or concept because of the stemming of the other words.",
                "For example, quote ICE is pluralized to quote OR quotes ICE.",
                "The original intent for this query is searching for stock quote for ticker ICE.",
                "However, we noticed that among the top results, one of the results is Food quotes: Ice cream.",
                "This is matched because of Affected Queries old dcg new dcg dcg Improvement naive model 408/408 7.102 7.206 1.5% document context sensitive model 408/408 7.102 7.302 2.8% selective model: unigram LM 300/408 5.904 6.187 4.8% selective model: bigram LM 250/408 5.551 5.891 6.1% Table 6: Results comparison over the stemmed queries only: column old/new dcg is the dcg score over the affected queries before/after applying stemming the pluralized word quotes.",
                "The unchanged word ICE matches part of the noun phrase ice cream here.",
                "To solve this kind of problem, we have to analyze the documents and recognize cookie jar and ice cream as concepts instead of two independent words.",
                "A third type of mistakes occurs in long queries.",
                "For the query bar code reader software, two words are pluralized. code to codes and reader to readers.",
                "In fact, bar code reader in the original query is a strong concept and the internal words should not be changed.",
                "This is the segmentation and entity and noun phrase detection problem in queries, which we actively are attacking.",
                "For long queries, we should correctly identify the concepts in the query, and boost the proximity for the words within a concept. 6.",
                "CONCLUSIONS AND FUTURE WORK We have presented a simple yet elegant way of stemming for Web search.",
                "It improves naive stemming in two aspects: selective word expansion on the query side and conservative word occurrence matching on the document side.",
                "Using pluralization handling as an example, experiments on a major Web search engine data show it significantly improves the Web relevance and reduces the stemming cost.",
                "It also significantly improves Web click through rate (details not reported in the paper).",
                "For the future work, we are investigating the problems we identified in the error analysis section.",
                "These include: entity and noun phrase matching mistakes, and improved segmentation. 7.",
                "REFERENCES [1] E. Agichtein, E. Brill, and S. T. Dumais.",
                "Improving Web Search Ranking by Incorporating User Behavior Information.",
                "In SIGIR, 2006. [2] E. Airio.",
                "Word Normalization and Decompounding in Mono- and Bilingual IR.",
                "Information Retrieval, 9:249-271, 2006. [3] P. Anick.",
                "Using Terminological Feedback for Web Search Refinement: a Log-based Study.",
                "In SIGIR, 2003. [4] R. Baeza-Yates and B. Ribeiro-Neto.",
                "Modern Information Retrieval.",
                "ACM Press/Addison Wesley, 1999. [5] S. Chen and J. Goodman.",
                "An Empirical Study of Smoothing Techniques for Language Modeling.",
                "Technical Report TR-10-98, Harvard University, 1998. [6] S. Cronen-Townsend, Y. Zhou, and B. Croft.",
                "A Framework for Selective Query Expansion.",
                "In CIKM, 2004. [7] H. Fang and C. Zhai.",
                "Semantic Term Matching in Axiomatic Approaches to Information Retrieval.",
                "In SIGIR, 2006. [8] W. B. Frakes.",
                "Term Conflation for Information Retrieval.",
                "In C. J. Rijsbergen, editor, Research and Development in Information Retrieval, pages 383-389.",
                "Cambridge University Press, 1984. [9] D. Harman.",
                "How Effective is Suffixing?",
                "JASIS, 42(1):7-15, 1991. [10] D. Hull.",
                "Stemming Algorithms - A Case Study for Detailed Evaluation.",
                "JASIS, 47(1):70-84, 1996. [11] K. Jarvelin and J. Kekalainen.",
                "Cumulated Gain-Based Evaluation Evaluation of IR Techniques.",
                "ACM TOIS, 20:422-446, 2002. [12] R. Jones, B. Rey, O. Madani, and W. Greiner.",
                "Generating Query Substitutions.",
                "In WWW, 2006. [13] W. Kraaij and R. Pohlmann.",
                "Viewing Stemming as Recall Enhancement.",
                "In SIGIR, 1996. [14] R. Krovetz.",
                "Viewing Morphology as an Inference Process.",
                "In SIGIR, 1993. [15] D. Lin.",
                "Automatic Retrieval and Clustering of Similar Words.",
                "In COLING-ACL, 1998. [16] J.",
                "B. Lovins.",
                "Development of a Stemming Algorithm.",
                "Mechanical Translation and Computational Linguistics, II:22-31, 1968. [17] M. Lennon and D. Peirce and B. Tarry and P. Willett.",
                "An Evaluation of Some Conflation Algorithms for Information Retrieval.",
                "Journal of Information Science, 3:177-188, 1981. [18] M. Porter.",
                "An Algorithm for Suffix Stripping.",
                "Program, 14(3):130-137, 1980. [19] K. M. Risvik, T. Mikolajewski, and P. Boros.",
                "Query Segmentation for Web Search.",
                "In WWW, 2003. [20] S. E. Robertson.",
                "On Term Selection for Query Expansion.",
                "Journal of Documentation, 46(4):359-364, 1990. [21] G. Salton and C. Buckley.",
                "Improving Retrieval Performance by Relevance Feedback.",
                "JASIS, 41(4):288 - 297, 1999. [22] R. Sun, C.-H. Ong, and T.-S. Chua.",
                "Mining Dependency Relations for Query Expansion in Passage Retrieval.",
                "In SIGIR, 2006. [23] C. Van Rijsbergen.",
                "Information Retrieval.",
                "Butterworths, second version, 1979. [24] B. V´elez, R. Weiss, M. A. Sheldon, and D. K. Gifford.",
                "Fast and Effective Query Refinement.",
                "In SIGIR, 1997. [25] J. Xu and B. Croft.",
                "Query Expansion using Local and Global Document Analysis.",
                "In SIGIR, 1996. [26] J. Xu and B. Croft.",
                "Corpus-based Stemming using Cooccurrence of Word Variants.",
                "ACM TOIS, 16 (1):61-81, 1998."
            ],
            "original_annotated_samples": [],
            "translated_annotated_samples": [],
            "translated_text": "",
            "candidates": [],
            "error": [
                []
            ]
        },
        "porter stemmer": {
            "translated_key": "stemmer de Porter",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Context Sensitive Stemming for Web Search Fuchun Peng Nawaaz Ahmed Xin Li Yumao Lu Yahoo!",
                "Inc. 701 First Avenue Sunnyvale, California 94089 {fuchun, nawaaz, xinli, yumaol}@yahoo-inc.com ABSTRACT Traditionally, stemming has been applied to Information Retrieval tasks by transforming words in documents to the their root form before indexing, and applying a similar transformation to query terms.",
                "Although it increases recall, this naive strategy does not work well for Web Search since it lowers precision and requires a significant amount of additional computation.",
                "In this paper, we propose a context sensitive stemming method that addresses these two issues.",
                "Two unique properties make our approach feasible for Web Search.",
                "First, based on statistical language modeling, we perform context sensitive analysis on the query side.",
                "We accurately predict which of its morphological variants is useful to expand a query term with before submitting the query to the search engine.",
                "This dramatically reduces the number of bad expansions, which in turn reduces the cost of additional computation and improves the precision at the same time.",
                "Second, our approach performs a context sensitive document matching for those expanded variants.",
                "This conservative strategy serves as a safeguard against spurious stemming, and it turns out to be very important for improving precision.",
                "Using word pluralization handling as an example of our stemming approach, our experiments on a major Web search engine show that stemming only 29% of the query traffic, we can improve relevance as measured by average Discounted Cumulative Gain (DCG5) by 6.1% on these queries and 1.8% over all query traffic.",
                "Categories and Subject Descriptors H.3.3 [Information Systems]: Information Storage and Retrieval-Query formulation General Terms Algorithms, Experimentation 1.",
                "INTRODUCTION Web search has now become a major tool in our daily lives for information seeking.",
                "One of the important issues in Web search is that user queries are often not best formulated to get optimal results.",
                "For example, running shoe is a query that occurs frequently in query logs.",
                "However, the query running shoes is much more likely to give better search results than the original query because documents matching the intent of this query usually contain the words running shoes.",
                "Correctly formulating a query requires the user to accurately predict which word form is used in the documents that best satisfy his or her information needs.",
                "This is difficult even for experienced users, and especially difficult for non-native speakers.",
                "One traditional solution is to use stemming [16, 18], the process of transforming inflected or derived words to their root form so that a search term will match and retrieve documents containing all forms of the term.",
                "Thus, the word run will match running, ran, runs, and shoe will match shoes and shoeing.",
                "Stemming can be done either on the terms in a document during indexing (and applying the same transformation to the query terms during query processing) or by expanding the query with the variants during query processing.",
                "Stemming during indexing allows very little flexibility during query processing, while stemming by query expansion allows handling each query differently, and hence is preferred.",
                "Although traditional stemming increases recall by matching word variants [13], it can reduce precision by retrieving too many documents that have been incorrectly matched.",
                "When examining the results of applying stemming to a large number of queries, one usually finds that nearly equal numbers of queries are helped and hurt by the technique [6].",
                "In addition, it reduces system performance because the search engine has to match all the word variants.",
                "As we will show in the experiments, this is true even if we simplify stemming to pluralization handling, which is the process of converting a word from its plural to singular form, or vice versa.",
                "Thus, one needs to be very cautious when using stemming in Web search engines.",
                "One problem of traditional stemming is its blind transformation of all query terms, that is, it always performs the same transformation for the same query word without considering the context of the word.",
                "For example, the word book has four forms book, books, booking, booked, and store has four forms store, stores, storing, stored.",
                "For the query book store, expanding both words to all of their variants significantly increases computation cost and hurts precision, since not all of the variants are useful for this query.",
                "Transforming book store to match book stores is fine, but matching book storing or booking store is not.",
                "A weighting method that gives variant words smaller weights alleviates the problems to a certain extent if the weights accurately reflect the importance of the variant in this particular query.",
                "However uniform weighting is not going to work and a query dependent weighting is still a challenging unsolved problem [20].",
                "A second problem of traditional stemming is its blind matching of all occurrences in documents.",
                "For the query book store, a transformation that allows the variant stores to be matched will cause every occurrence of stores in the document to be treated equivalent to the query term store.",
                "Thus, a document containing the fragment reading a book in coffee stores will be matched, causing many wrong documents to be selected.",
                "Although we hope the ranking function can correctly handle these, with many more candidates to rank, the risk of making mistakes increases.",
                "To alleviate these two problems, we propose a context sensitive stemming approach for Web search.",
                "Our solution consists of two context sensitive analysis, one on the query side and the other on the document side.",
                "On the query side, we propose a statistical language modeling based approach to predict which word variants are better forms than the original word for search purpose and expanding the query with only those forms.",
                "On the document side, we propose a conservative context sensitive matching for the transformed word variants, only matching document occurrences in the context of other terms in the query.",
                "Our model is simple yet effective and efficient, making it feasible to be used in real commercial Web search engines.",
                "We use pluralization handling as a running example for our stemming approach.",
                "The motivation for using pluralization handling as an example is to show that even such simple stemming, if handled correctly, can give significant benefits to search relevance.",
                "As far as we know, no previous research has systematically investigated the usage of pluralization in Web search.",
                "As we have to point out, the method we propose is not limited to pluralization handling, it is a general stemming technique, and can also be applied to general query expansion.",
                "Experiments on general stemming yield additional significant improvements over pluralization handling for long queries, although details will not be reported in this paper.",
                "In the rest of the paper, we first present the related work and distinguish our method from previous work in Section 2.",
                "We describe the details of the context sensitive stemming approach in Section 3.",
                "We then perform extensive experiments on a major Web search engine to support our claims in Section 4, followed by discussions in Section 5.",
                "Finally, we conclude the paper in Section 6. 2.",
                "RELATED WORK Stemming is a long studied technology.",
                "Many stemmers have been developed, such as the Lovins stemmer [16] and the <br>porter stemmer</br> [18].",
                "The <br>porter stemmer</br> is widely used due to its simplicity and effectiveness in many applications.",
                "However, the Porter stemming makes many mistakes because its simple rules cannot fully describe English morphology.",
                "Corpus analysis is used to improve <br>porter stemmer</br> [26] by creating equivalence classes for words that are morphologically similar and occur in similar context as measured by expected mutual information [23].",
                "We use a similar corpus based approach for stemming by computing the similarity between two words based on their distributional context features which can be more than just adjacent words [15], and then only keep the morphologically similar words as candidates.",
                "Using stemming in information retrieval is also a well known technique [8, 10].",
                "However, the effectiveness of stemming for English query systems was previously reported to be rather limited.",
                "Lennon et al. [17] compared the Lovins and Porter algorithms and found little improvement in retrieval performance.",
                "Later, Harman [9] compares three general stemming techniques in text retrieval experiments including pluralization handing (called S stemmer in the paper).",
                "They also proposed selective stemming based on query length and term importance, but no positive results were reported.",
                "On the other hand, Krovetz [14] performed comparisons over small numbers of documents (from 400 to 12k) and showed dramatic precision improvement (up to 45%).",
                "However, due to the limited number of tested queries (less than 100) and the small size of the collection, the results are hard to generalize to Web search.",
                "These mixed results, mostly failures, led early IR researchers to deem stemming irrelevant in general for English [4], although recent research has shown stemming has greater benefits for retrieval in other languages [2].",
                "We suspect the previous failures were mainly due to the two problems we mentioned in the introduction.",
                "Blind stemming, or a simple query length based selective stemming as used in [9] is not enough.",
                "Stemming has to be decided on case by case basis, not only at the query level but also at the document level.",
                "As we will show, if handled correctly, significant improvement can be achieved.",
                "A more general problem related to stemming is query reformulation [3, 12] and query expansion which expands words not only with word variants [7, 22, 24, 25].",
                "To decide which expanded words to use, people often use pseudorelevance feedback techniquesthat send the original query to a search engine and retrieve the top documents, extract relevant words from these top documents as additional query words, and resubmit the expanded query again [21].",
                "This normally requires sending a query multiple times to search engine and it is not cost effective for processing the huge amount of queries involved in Web search.",
                "In addition, query expansion, including query reformulation [3, 12], has a high risk of changing the user intent (called query drift).",
                "Since the expanded words may have different meanings, adding them to the query could potentially change the intent of the original query.",
                "Thus query expansion based on pseudorelevance and query reformulation can provide suggestions to users for interactive refinement but can hardly be directly used for Web search.",
                "On the other hand, stemming is much more conservative since most of the time, stemming preserves the original search intent.",
                "While most work on query expansion focuses on recall enhancement, our work focuses on increasing both recall and precision.",
                "The increase on recall is obvious.",
                "With quality stemming, good documents which were not selected before stemming will be pushed up and those low quality documents will be degraded.",
                "On selective query expansion, Cronen-Townsend et al. [6] proposed a method for selective query expansion based on comparing the Kullback-Leibler divergence of the results from the unexpanded query and the results from the expanded query.",
                "This is similar to the relevance feedback in the sense that it requires multiple passes retrieval.",
                "If a word can be expanded into several words, it requires running this process multiple times to decide which expanded word is useful.",
                "It is expensive to deploy this in production Web search engines.",
                "Our method predicts the quality of expansion based on oﬄine information without sending the query to a search engine.",
                "In summary, we propose a novel approach to attack an old, yet still important and challenging problem for Web search - stemming.",
                "Our approach is unique in that it performs predictive stemming on a per query basis without relevance feedback from the Web, using the context of the variants in documents to preserve precision.",
                "Its simple, yet very efficient and effective, making real time stemming feasible for Web search.",
                "Our results will affirm researchers that stemming is indeed very important to large scale information retrieval. 3.",
                "CONTEXT SENSITIVE STEMMING 3.1 Overview Our system has four components as illustrated in Figure 1: candidate generation, query segmentation and head word detection, context sensitive query stemming and context sensitive document matching.",
                "Candidate generation (component 1) is performed oﬄine and generated candidates are stored in a dictionary.",
                "For an input query, we first segment query into concepts and detect the head word for each concept (component 2).",
                "We then use statistical language modeling to decide whether a particular variant is useful (component 3), and finally for the expanded variants, we perform context sensitive document matching (component 4).",
                "Below we discuss each of the components in more detail.",
                "Component 4: context sensitive document matching Input Query: and head word detection Component 2: segment Component 1: candidate generation comparisons −> comparison Component 3: selective word expansion decision: comparisons −> comparison example: hotel price comparisons output: hotel comparisons hotel −> hotels Figure 1: System Components 3.2 Expansion candidate generation One of the ways to generate candidates is using the <br>porter stemmer</br> [18].",
                "The <br>porter stemmer</br> simply uses morphological rules to convert a word to its base form.",
                "It has no knowledge of the semantic meaning of the words and sometimes makes serious mistakes, such as executive to execution, news to new, and paste to past.",
                "A more conservative way is based on using corpus analysis to improve the <br>porter stemmer</br> results [26].",
                "The corpus analysis we do is based on word distributional similarity [15].",
                "The rationale of using distributional word similarity is that true variants tend to be used in similar contexts.",
                "In the distributional word similarity calculation, each word is represented with a vector of features derived from the context of the word.",
                "We use the bigrams to the left and right of the word as its context features, by mining a huge Web corpus.",
                "The similarity between two words is the cosine similarity between the two corresponding feature vectors.",
                "The top 20 similar words to develop is shown in the following table. rank candidate score rank candidate score 0 develop 1 10 berts 0.119 1 developing 0.339 11 wads 0.116 2 developed 0.176 12 developer 0.107 3 incubator 0.160 13 promoting 0.100 4 develops 0.150 14 developmental 0.091 5 development 0.148 15 reengineering 0.090 6 tutoring 0.138 16 build 0.083 7 analyzing 0.128 17 construct 0.081 8 developement 0.128 18 educational 0.081 9 automation 0.126 19 institute 0.077 Table 1: Top 20 most similar candidates to word develop.",
                "Column score is the similarity score.",
                "To determine the stemming candidates, we apply a few <br>porter stemmer</br> [18] morphological rules to the similarity list.",
                "After applying these rules, for the word develop, the stemming candidates are developing, developed, develops, development, developement, developer, developmental.",
                "For the pluralization handling purpose, only the candidate develops is retained.",
                "One thing we note from observing the distributionally similar words is that they are closely related semantically.",
                "These words might serve as candidates for general query expansion, a topic we will investigate in the future. 3.3 Segmentation and headword identification For long queries, it is quite important to detect the concepts in the query and the most important words for those concepts.",
                "We first break a query into segments, each segment representing a concept which normally is a noun phrase.",
                "For each of the noun phrases, we then detect the most important word which we call the head word.",
                "Segmentation is also used in document sensitive matching (section 3.5) to enforce proximity.",
                "To break a query into segments, we have to define a criteria to measure the strength of the relation between words.",
                "One effective method is to use mutual information as an indicator on whether or not to split two words [19].",
                "We use a log of 25M queries and collect the bigram and unigram frequencies from it.",
                "For every incoming query, we compute the mutual information of two adjacent words; if it passes a predefined threshold, we do not split the query between those two words and move on to next word.",
                "We continue this process until the mutual information between two words is below the threshold, then create a concept boundary here.",
                "Table 2 shows some examples of query segmentation.",
                "The ideal way of finding the head word of a concept is to do syntactic parsing to determine the dependency structure of the query.",
                "Query parsing is more difficult than sentence [running shoe] [best] [new york] [medical schools] [pictures] [of] [white house] [cookies] [in] [san francisco] [hotel] [price comparison] Table 2: Query segmentation: a segment is bracketed. parsing since many queries are not grammatical and are very short.",
                "Applying a parser trained on sentences from documents to queries will have poor performance.",
                "In our solution, we just use simple heuristics rules, and it works very well in practice for English.",
                "For an English noun phrase, the head word is typically the last nonstop word, unless the phrase is of a particular pattern, like XYZ of/in/at/from UVW.",
                "In such cases, the head word is typically the last nonstop word of XYZ. 3.4 Context sensitive word expansion After detecting which words are the most important words to expand, we have to decide whether the expansions will be useful.",
                "Our statistics show that about half of the queries can be transformed by pluralization via naive stemming.",
                "Among this half, about 25% of the queries improve relevance when transformed, the majority (about 50%) do not change their top 5 results, and the remaining 25% perform worse.",
                "Thus, it is extremely important to identify which queries should not be stemmed for the purpose of maximizing relevance improvement and minimizing stemming cost.",
                "In addition, for a query with multiple words that can be transformed, or a word with multiple variants, not all of the expansions are useful.",
                "Taking query hotel price comparison as an example, we decide that hotel and price comparison are two concepts.",
                "Head words hotel and comparison can be expanded to hotels and comparisons.",
                "Are both transformations useful?",
                "To test whether an expansion is useful, we have to know whether the expanded query is likely to get more relevant documents from the Web, which can be quantified by the probability of the query occurring as a string on the Web.",
                "The more likely a query to occur on the Web, the more relevant documents this query is able to return.",
                "Now the whole problem becomes how to calculate the probability of query to occur on the Web.",
                "Calculating the probability of string occurring in a corpus is a well known language modeling problem.",
                "The goal of language modeling is to predict the probability of naturally occurring word sequences, s = w1w2...wN ; or more simply, to put high probability on word sequences that actually occur (and low probability on word sequences that never occur).",
                "The simplest and most successful approach to language modeling is still based on the n-gram model.",
                "By the chain rule of probability one can write the probability of any word sequence as Pr(w1w2...wN ) = NY i=1 Pr(wi|w1...wi−1) (1) An n-gram model approximates this probability by assuming that the only words relevant to predicting Pr(wi|w1...wi−1) are the previous n − 1 words; i.e.",
                "Pr(wi|w1...wi−1) = Pr(wi|wi−n+1...wi−1) A straightforward maximum likelihood estimate of n-gram probabilities from a corpus is given by the observed frequency of each of the patterns Pr(wi|wi−n+1...wi−1) = #(wi−n+1...wi) #(wi−n+1...wi−1) (2) where #(.) denotes the number of occurrences of a specified gram in the training corpus.",
                "Although one could attempt to use simple n-gram models to capture long range dependencies in language, attempting to do so directly immediately creates sparse data problems: Using grams of length up to n entails estimating the probability of Wn events, where W is the size of the word vocabulary.",
                "This quickly overwhelms modern computational and data resources for even modest choices of n (beyond 3 to 6).",
                "Also, because of the heavy tailed nature of language (i.e.",
                "Zipfs law) one is likely to encounter novel n-grams that were never witnessed during training in any test corpus, and therefore some mechanism for assigning non-zero probability to novel n-grams is a central and unavoidable issue in statistical language modeling.",
                "One standard approach to smoothing probability estimates to cope with sparse data problems (and to cope with potentially missing n-grams) is to use some sort of back-off estimator.",
                "Pr(wi|wi−n+1...wi−1) = 8 >>< >>: ˆPr(wi|wi−n+1...wi−1), if #(wi−n+1...wi) > 0 β(wi−n+1...wi−1) × Pr(wi|wi−n+2...wi−1), otherwise (3) where ˆPr(wi|wi−n+1...wi−1) = discount #(wi−n+1...wi) #(wi−n+1...wi−1) (4) is the discounted probability and β(wi−n+1...wi−1) is a normalization constant β(wi−n+1...wi−1) = 1 − X x∈(wi−n+1...wi−1x) ˆPr(x|wi−n+1...wi−1) 1 − X x∈(wi−n+1...wi−1x) ˆPr(x|wi−n+2...wi−1) (5) The discounted probability (4) can be computed with different smoothing techniques, including absolute smoothing, Good-Turing smoothing, linear smoothing, and Witten-Bell smoothing [5].",
                "We used absolute smoothing in our experiments.",
                "Since the likelihood of a string, Pr(w1w2...wN ), is a very small number and hard to interpret, we use entropy as defined below to score the string.",
                "Entropy = − 1 N log2 Pr(w1w2...wN ) (6) Now getting back to the example of the query hotel price comparisons, there are four variants of this query, and the entropy of these four candidates are shown in Table 3.",
                "We can see that all alternatives are less likely than the input query.",
                "It is therefore not useful to make an expansion for this query.",
                "On the other hand, if the input query is hotel price comparisons which is the second alternative in the table, then there is a better alternative than the input query, and it should therefore be expanded.",
                "To tolerate the variations in probability estimation, we relax the selection criterion to those query alternatives if their scores are within a certain distance (10% in our experiments) to the best score.",
                "Query variations Entropy hotel price comparison 6.177 hotel price comparisons 6.597 hotels price comparison 6.937 hotels price comparisons 7.360 Table 3: Variations of query hotel price comparison ranked by entropy score, with the original query in bold face. 3.5 Context sensitive document matching Even after we know which word variants are likely to be useful, we have to be conservative in document matching for the expanded variants.",
                "For the query hotel price comparisons, we decided that word comparisons is expanded to include comparison.",
                "However, not every occurrence of comparison in the document is of interest.",
                "A page which is about comparing customer service can contain all of the words hotel price comparisons comparison.",
                "This page is not a good page for the query.",
                "If we accept matches of every occurrence of comparison, it will hurt retrieval precision and this is one of the main reasons why most stemming approaches do not work well for information retrieval.",
                "To address this problem, we have a proximity constraint that considers the context around the expanded variant in the document.",
                "A variant match is considered valid only if the variant occurs in the same context as the original word does.",
                "The context is the left or the right non-stop segments 1 of the original word.",
                "Taking the same query as an example, the context of comparisons is price.",
                "The expanded word comparison is only valid if it is in the same context of comparisons, which is after the word price.",
                "Thus, we should only match those occurrences of comparison in the document if they occur after the word price.",
                "Considering the fact that queries and documents may not represent the intent in exactly the same way, we relax this proximity constraint to allow variant occurrences within a window of some fixed size.",
                "If the expanded word comparison occurs within the context of price within a window, it is considered valid.",
                "The smaller the window size is, the more restrictive the matching.",
                "We use a window size of 4, which typically captures contexts that include the containing and adjacent noun phrases. 4.",
                "EXPERIMENTAL EVALUATION 4.1 Evaluation metrics We will measure both relevance improvement and the stemming cost required to achieve the relevance. 1 a context segment can not be a single stop word. 4.1.1 Relevance measurement We use a variant of the average Discounted Cumulative Gain (DCG), a recently popularized scheme to measure search engine relevance [1, 11].",
                "Given a query and a ranked list of K documents (K is set to 5 in our experiments), the DCG(K) score for this query is calculated as follows: DCG(K) = KX k=1 gk log2(1 + k) . (7) where gk is the weight for the document at rank k. Higher degree of relevance corresponds to a higher weight.",
                "A page is graded into one of the five scales: Perfect, Excellent, Good, Fair, Bad, with corresponding weights.",
                "We use dcg to represent the average DCG(5) over a set of test queries. 4.1.2 Stemming cost Another metric is to measure the additional cost incurred by stemming.",
                "Given the same level of relevance improvement, we prefer a stemming method that has less additional cost.",
                "We measure this by the percentage of queries that are actually stemmed, over all the queries that could possibly be stemmed. 4.2 Data preparation We randomly sample 870 queries from a three month query log, with 290 from each month.",
                "Among all these 870 queries, we remove all misspelled queries since misspelled queries are not of interest to stemming.",
                "We also remove all one word queries since stemming one word queries without context has a high risk of changing query intent, especially for short words.",
                "In the end, we have 529 correctly spelled queries with at least 2 words. 4.3 Naive stemming for Web search Before explaining the experiments and results in detail, wed like to describe the traditional way of using stemming for Web search, referred as the naive model.",
                "This is to treat every word variant equivalent for all possible words in the query.",
                "The query book store will be transformed into (book OR books)(store OR stores) when limiting stemming to pluralization handling only, where OR is an operator that denotes the equivalence of the left and right arguments. 4.4 Experimental setup The baseline model is the model without stemming.",
                "We first run the naive model to see how well it performs over the baseline.",
                "Then we improve the naive stemming model by document sensitive matching, referred as document sensitive matching model.",
                "This model makes the same stemming as the naive model on the query side, but performs conservative matching on the document side using the strategy described in section 3.5.",
                "The naive model and document sensitive matching model stem the most queries.",
                "Out of the 529 queries, there are 408 queries that they stem, corresponding to 46.7% query traffic (out of a total of 870).",
                "We then further improve the document sensitive matching model from the query side with selective word stemming based on statistical language modeling (section 3.4), referred as selective stemming model.",
                "Based on language modeling prediction, this model stems only a subset of the 408 queries stemmed by the document sensitive matching model.",
                "We experiment with unigram language model and bigram language model.",
                "Since we only care how much we can improve the naive model, we will only use these 408 queries (all the queries that are affected by the naive stemming model) in the experiments.",
                "To get a sense of how these models perform, we also have an oracle model that gives the upper-bound performance a stemmer can achieve on this data.",
                "The oracle model only expands a word if the stemming will give better results.",
                "To analyze the pluralization handling influence on different query categories, we divide queries into short queries and long queries.",
                "Among the 408 queries stemmed by the naive model, there are 272 short queries with 2 or 3 words, and 136 long queries with at least 4 words. 4.5 Results We summarize the overall results in Table 4, and present the results on short queries and long queries separately in Table 5.",
                "Each row in Table 4 is a stemming strategy described in section 4.4.",
                "The first column is the name of the strategy.",
                "The second column is the number of queries affected by this strategy; this column measures the stemming cost, and the numbers should be low for the same level of dcg.",
                "The third column is the average dcg score over all tested queries in this category (including the ones that were not stemmed by the strategy).",
                "The fourth column is the relative improvement over the baseline, and the last column is the p-value of Wilcoxon significance test.",
                "There are several observations about the results.",
                "We can see the naively stemming only obtains a statistically insignificant improvement of 1.5%.",
                "Looking at Table 5, it gives an improvement of 2.7% on short queries.",
                "However, it also hurts long queries by -2.4%.",
                "Overall, the improvement is canceled out.",
                "The reason that it improves short queries is that most short queries only have one word that can be stemmed.",
                "Thus, blindly pluralizing short queries is relatively safe.",
                "However for long queries, most queries can have multiple words that can be pluralized.",
                "Expanding all of them without selection will significantly hurt precision.",
                "Document context sensitive stemming gives a significant lift to the performance, from 2.7% to 4.2% for short queries and from -2.4% to -1.6% for long queries, with an overall lift from 1.5% to 2.8%.",
                "The improvement comes from the conservative context sensitive document matching.",
                "An expanded word is valid only if it occurs within the context of original query in the document.",
                "This reduces many spurious matches.",
                "However, we still notice that for long queries, context sensitive stemming is not able to improve performance because it still selects too many documents and gives the ranking function a hard problem.",
                "While the chosen window size of 4 works the best amongst all the choices, it still allows spurious matches.",
                "It is possible that the window size needs to be chosen on a per query basis to ensure tighter proximity constraints for different types of noun phrases.",
                "Selective word pluralization further helps resolving the problem faced by document context sensitive stemming.",
                "It does not stem every word that places all the burden on the ranking algorithm, but tries to eliminate unnecessary stemming in the first place.",
                "By predicting which word variants are going to be useful, we can dramatically reduce the number of stemmed words, thus improving both the recall and the precision.",
                "With the unigram language model, we can reduce the stemming cost by 26.7% (from 408/408 to 300/408) and lift the overall dcg improvement from 2.8% to 3.4%.",
                "In particular, it gives significant improvements on long queries.",
                "The dcg gain is turned from negative to positive, from −1.6% to 1.1%.",
                "This confirms our hypothesis that reducing unnecessary word expansion leads to precision improvement.",
                "For short queries too, we observe both dcg improvement and stemming cost reduction with the unigram language model.",
                "The advantages of predictive word expansion with a language model is further boosted with a better bigram language model.",
                "The overall dcg gain is lifted from 3.4% to 3.9%, and stemming cost is dramatically reduced from 408/408 to 250/408, corresponding to only 29% of query traffic (250 out of 870) and an overall 1.8% dcg improvement overall all query traffic.",
                "For short queries, bigram language model improves the dcg gain from 4.4% to 4.7%, and reduces stemming cost from 272/272 to 150/272.",
                "For long queries, bigram language model improves dcg gain from 1.1% to 2.5%, and reduces stemming cost from 136/136 to 100/136.",
                "We observe that the bigram language model gives a larger lift for long queries.",
                "This is because the uncertainty in long queries is larger and a more powerful language model is needed.",
                "We hypothesize that a trigram language model would give a further lift for long queries and leave this for future investigation.",
                "Considering the tight upper-bound 2 on the improvement to be gained from pluralization handling (via the oracle model), the current performance on short queries is very satisfying.",
                "For short queries, the dcg gain upper-bound is 6.3% for perfect pluralization handling, our current gain is 4.7% with a bigram language model.",
                "For long queries, the dcg gain upper-bound is 4.6% for perfect pluralization handling, our current gain is 2.5% with a bigram language model.",
                "We may gain additional benefit with a more powerful language model for long queries.",
                "However, the difficulties of long queries come from many other aspects including the proximity and the segmentation problem.",
                "These problems have to be addressed separately.",
                "Looking at the the upper-bound of overhead reduction for oracle stemming, 75% (308/408) of the naive stemmings are wasteful.",
                "We currently capture about half of them.",
                "Further reduction of the overhead requires sacrificing the dcg gain.",
                "Now we can compare the stemming strategies from a different aspect.",
                "Instead of looking at the influence over all queries as we described above, Table 6 summarizes the dcg improvements over the affected queries only.",
                "We can see that the number of affected queries decreases as the stemming strategy becomes more accurate (dcg improvement).",
                "For the bigram language model, over the 250/408 stemmed queries, the dcg improvement is 6.1%.",
                "An interesting observation is the average dcg decreases with a better model, which indicates a better stemming strategy stems more difficult queries (low dcg queries). 5.",
                "DISCUSSIONS 5.1 Language models from query vs. from Web As we mentioned in Section 1, we are trying to predict the probability of a string occurring on the Web.",
                "The language model should describe the occurrence of the string on the Web.",
                "However, the query log is also a good resource. 2 Note that this upperbound is for pluralization handling only, not for general stemming.",
                "General stemming gives a 8% upperbound, which is quite substantial in terms of our metrics.",
                "Affected Queries dcg dcg Improvement p-value baseline 0/408 7.102 N/A N/A naive model 408/408 7.206 1.5% 0.22 document context sensitive model 408/408 7.302 2.8% 0.014 selective model: unigram LM 300/408 7.321 3.4% 0.001 selective model: bigram LM 250/408 7.381 3.9% 0.001 oracle model 100/408 7.519 5.9% 0.001 Table 4: Results comparison of different stemming strategies over all queries affected by naive stemming Short Query Results Affected Queries dcg Improvement p-value baseline 0/272 N/A N/A naive model 272/272 2.7% 0.48 document context sensitive model 272/272 4.2% 0.002 selective model: unigram LM 185/272 4.4% 0.001 selective model: bigram LM 150/272 4.7% 0.001 oracle model 71/272 6.3% 0.001 Long Query Results Affected Queries dcg Improvement p-value baseline 0/136 N/A N/A naive model 136/136 -2.4% 0.25 document context sensitive model 136/136 -1.6% 0.27 selective model: unigram LM 115/136 1.1% 0.001 selective model: bigram LM 100/136 2.5% 0.001 oracle model 29/136 4.6% 0.001 Table 5: Results comparison of different stemming strategies overall short queries and long queries Users reformulate a query using many different variants to get good results.",
                "To test the hypothesis that we can learn reliable transformation probabilities from the query log, we trained a language model from the same query top 25M queries as used to learn segmentation, and use that for prediction.",
                "We observed a slight performance decrease compared to the model trained on Web frequencies.",
                "In particular, the performance for unigram LM was not affected, but the dcg gain for bigram LM changed from 4.7% to 4.5% for short queries.",
                "Thus, the query log can serve as a good approximation of the Web frequencies. 5.2 How linguistics helps Some linguistic knowledge is useful in stemming.",
                "For the pluralization handling case, pluralization and de-pluralization is not symmetric.",
                "A plural word used in a query indicates a special intent.",
                "For example, the query new york hotels is looking for a list of hotels in new york, not the specific new york hotel which might be a hotel located in California.",
                "A simple equivalence of hotel to hotels might boost a particular page about new york hotel to top rank.",
                "To capture this intent, we have to make sure the document is a general page about hotels in new york.",
                "We do this by requiring that the plural word hotels appears in the document.",
                "On the other hand, converting a singular word to plural is safer since a general purpose page normally contains specific information.",
                "We observed a slight overall dcg decrease, although not statistically significant, for document context sensitive stemming if we do not consider this asymmetric property. 5.3 Error analysis One type of mistakes we noticed, though rare but seriously hurting relevance, is the search intent change after stemming.",
                "Generally speaking, pluralization or depluralization keeps the original intent.",
                "However, the intent could change in a few cases.",
                "For one example of such a query, job at apple, we pluralize job to jobs.",
                "This stemming makes the original query ambiguous.",
                "The query job OR jobs at apple has two intents.",
                "One is the employment opportunities at apple, and another is a person working at Apple, Steve Jobs, who is the CEO and co-founder of the company.",
                "Thus, the results after query stemming returns Steve Jobs as one of the results in top 5.",
                "One solution is performing results set based analysis to check if the intent is changed.",
                "This is similar to relevance feedback and requires second phase ranking.",
                "A second type of mistakes is the entity/concept recognition problem, These include two kinds.",
                "One is that the stemmed word variant now matches part of an entity or concept.",
                "For example, query cookies in san francisco is pluralized to cookies OR cookie in san francisco.",
                "The results will match cookie jar in san francisco.",
                "Although cookie still means the same thing as cookies, cookie jar is a different concept.",
                "Another kind is the unstemmed word matches an entity or concept because of the stemming of the other words.",
                "For example, quote ICE is pluralized to quote OR quotes ICE.",
                "The original intent for this query is searching for stock quote for ticker ICE.",
                "However, we noticed that among the top results, one of the results is Food quotes: Ice cream.",
                "This is matched because of Affected Queries old dcg new dcg dcg Improvement naive model 408/408 7.102 7.206 1.5% document context sensitive model 408/408 7.102 7.302 2.8% selective model: unigram LM 300/408 5.904 6.187 4.8% selective model: bigram LM 250/408 5.551 5.891 6.1% Table 6: Results comparison over the stemmed queries only: column old/new dcg is the dcg score over the affected queries before/after applying stemming the pluralized word quotes.",
                "The unchanged word ICE matches part of the noun phrase ice cream here.",
                "To solve this kind of problem, we have to analyze the documents and recognize cookie jar and ice cream as concepts instead of two independent words.",
                "A third type of mistakes occurs in long queries.",
                "For the query bar code reader software, two words are pluralized. code to codes and reader to readers.",
                "In fact, bar code reader in the original query is a strong concept and the internal words should not be changed.",
                "This is the segmentation and entity and noun phrase detection problem in queries, which we actively are attacking.",
                "For long queries, we should correctly identify the concepts in the query, and boost the proximity for the words within a concept. 6.",
                "CONCLUSIONS AND FUTURE WORK We have presented a simple yet elegant way of stemming for Web search.",
                "It improves naive stemming in two aspects: selective word expansion on the query side and conservative word occurrence matching on the document side.",
                "Using pluralization handling as an example, experiments on a major Web search engine data show it significantly improves the Web relevance and reduces the stemming cost.",
                "It also significantly improves Web click through rate (details not reported in the paper).",
                "For the future work, we are investigating the problems we identified in the error analysis section.",
                "These include: entity and noun phrase matching mistakes, and improved segmentation. 7.",
                "REFERENCES [1] E. Agichtein, E. Brill, and S. T. Dumais.",
                "Improving Web Search Ranking by Incorporating User Behavior Information.",
                "In SIGIR, 2006. [2] E. Airio.",
                "Word Normalization and Decompounding in Mono- and Bilingual IR.",
                "Information Retrieval, 9:249-271, 2006. [3] P. Anick.",
                "Using Terminological Feedback for Web Search Refinement: a Log-based Study.",
                "In SIGIR, 2003. [4] R. Baeza-Yates and B. Ribeiro-Neto.",
                "Modern Information Retrieval.",
                "ACM Press/Addison Wesley, 1999. [5] S. Chen and J. Goodman.",
                "An Empirical Study of Smoothing Techniques for Language Modeling.",
                "Technical Report TR-10-98, Harvard University, 1998. [6] S. Cronen-Townsend, Y. Zhou, and B. Croft.",
                "A Framework for Selective Query Expansion.",
                "In CIKM, 2004. [7] H. Fang and C. Zhai.",
                "Semantic Term Matching in Axiomatic Approaches to Information Retrieval.",
                "In SIGIR, 2006. [8] W. B. Frakes.",
                "Term Conflation for Information Retrieval.",
                "In C. J. Rijsbergen, editor, Research and Development in Information Retrieval, pages 383-389.",
                "Cambridge University Press, 1984. [9] D. Harman.",
                "How Effective is Suffixing?",
                "JASIS, 42(1):7-15, 1991. [10] D. Hull.",
                "Stemming Algorithms - A Case Study for Detailed Evaluation.",
                "JASIS, 47(1):70-84, 1996. [11] K. Jarvelin and J. Kekalainen.",
                "Cumulated Gain-Based Evaluation Evaluation of IR Techniques.",
                "ACM TOIS, 20:422-446, 2002. [12] R. Jones, B. Rey, O. Madani, and W. Greiner.",
                "Generating Query Substitutions.",
                "In WWW, 2006. [13] W. Kraaij and R. Pohlmann.",
                "Viewing Stemming as Recall Enhancement.",
                "In SIGIR, 1996. [14] R. Krovetz.",
                "Viewing Morphology as an Inference Process.",
                "In SIGIR, 1993. [15] D. Lin.",
                "Automatic Retrieval and Clustering of Similar Words.",
                "In COLING-ACL, 1998. [16] J.",
                "B. Lovins.",
                "Development of a Stemming Algorithm.",
                "Mechanical Translation and Computational Linguistics, II:22-31, 1968. [17] M. Lennon and D. Peirce and B. Tarry and P. Willett.",
                "An Evaluation of Some Conflation Algorithms for Information Retrieval.",
                "Journal of Information Science, 3:177-188, 1981. [18] M. Porter.",
                "An Algorithm for Suffix Stripping.",
                "Program, 14(3):130-137, 1980. [19] K. M. Risvik, T. Mikolajewski, and P. Boros.",
                "Query Segmentation for Web Search.",
                "In WWW, 2003. [20] S. E. Robertson.",
                "On Term Selection for Query Expansion.",
                "Journal of Documentation, 46(4):359-364, 1990. [21] G. Salton and C. Buckley.",
                "Improving Retrieval Performance by Relevance Feedback.",
                "JASIS, 41(4):288 - 297, 1999. [22] R. Sun, C.-H. Ong, and T.-S. Chua.",
                "Mining Dependency Relations for Query Expansion in Passage Retrieval.",
                "In SIGIR, 2006. [23] C. Van Rijsbergen.",
                "Information Retrieval.",
                "Butterworths, second version, 1979. [24] B. V´elez, R. Weiss, M. A. Sheldon, and D. K. Gifford.",
                "Fast and Effective Query Refinement.",
                "In SIGIR, 1997. [25] J. Xu and B. Croft.",
                "Query Expansion using Local and Global Document Analysis.",
                "In SIGIR, 1996. [26] J. Xu and B. Croft.",
                "Corpus-based Stemming using Cooccurrence of Word Variants.",
                "ACM TOIS, 16 (1):61-81, 1998."
            ],
            "original_annotated_samples": [
                "Many stemmers have been developed, such as the Lovins stemmer [16] and the <br>porter stemmer</br> [18].",
                "The <br>porter stemmer</br> is widely used due to its simplicity and effectiveness in many applications.",
                "Corpus analysis is used to improve <br>porter stemmer</br> [26] by creating equivalence classes for words that are morphologically similar and occur in similar context as measured by expected mutual information [23].",
                "Component 4: context sensitive document matching Input Query: and head word detection Component 2: segment Component 1: candidate generation comparisons −> comparison Component 3: selective word expansion decision: comparisons −> comparison example: hotel price comparisons output: hotel comparisons hotel −> hotels Figure 1: System Components 3.2 Expansion candidate generation One of the ways to generate candidates is using the <br>porter stemmer</br> [18].",
                "The <br>porter stemmer</br> simply uses morphological rules to convert a word to its base form."
            ],
            "translated_annotated_samples": [
                "Se han desarrollado muchos stemmers, como el stemmer Lovins [16] y el <br>stemmer Porter</br> [18].",
                "El <br>stemmer de Porter</br> es ampliamente utilizado debido a su simplicidad y efectividad en muchas aplicaciones.",
                "El análisis de corpus se utiliza para mejorar el <br>stemmer de Porter</br> [26] mediante la creación de clases de equivalencia para palabras que son morfológicamente similares y que ocurren en un contexto similar, medido por la información mutua esperada [23].",
                "Componente 4: coincidencia de documentos sensibles al contexto Consulta de entrada: y detección de palabras clave Componente 2: segmento Componente 1: generación de candidatos comparaciones −> comparación Componente 3: decisión de expansión selectiva de palabras: comparaciones −> comparación ejemplo: comparaciones de precios de hoteles salida: comparaciones de hoteles hotel −> hoteles Figura 1: Componentes del sistema 3.2 Generación de candidatos de expansión Una de las formas de generar candidatos es utilizando el <br>stemmer de Porter</br> [18].",
                "El <br>stemmer de Porter</br> simplemente utiliza reglas morfológicas para convertir una palabra a su forma base."
            ],
            "translated_text": "Stemming sensible al contexto para la búsqueda web Fuchun Peng Nawaaz Ahmed Xin Li Yumao Lu Yahoo! Tradicionalmente, el truncamiento se ha aplicado a tareas de Recuperación de Información transformando las palabras en documentos a su forma raíz antes de indexarlas, y aplicando una transformación similar a los términos de consulta. Aunque aumenta la recuperación, esta estrategia ingenua no funciona bien para la Búsqueda en la Web, ya que disminuye la precisión y requiere una cantidad significativa de cálculos adicionales. En este artículo, proponemos un método de derivación sensible al contexto que aborda estos dos problemas. Dos propiedades únicas hacen que nuestro enfoque sea factible para la Búsqueda en la Web. Primero, basados en modelado estadístico del lenguaje, realizamos un análisis sensible al contexto en el lado de la consulta. Predecimos con precisión cuál de sus variantes morfológicas es útil para expandir un término de consulta antes de enviar la consulta al motor de búsqueda. Esto reduce drásticamente la cantidad de expansiones incorrectas, lo que a su vez disminuye el costo de la computación adicional y mejora la precisión al mismo tiempo. Segundo, nuestro enfoque realiza una coincidencia de documentos sensible al contexto para esas variantes ampliadas. Esta estrategia conservadora sirve como salvaguarda contra el truncamiento espurio, y resulta ser muy importante para mejorar la precisión. Usando el manejo de la pluralización de palabras como un ejemplo de nuestro enfoque de derivación, nuestros experimentos en un importante motor de búsqueda web muestran que al derivar solo el 29% del tráfico de consultas, podemos mejorar la relevancia medida por la Ganancia Acumulativa Descontada promedio (DCG5) en un 6.1% en estas consultas y en un 1.8% sobre todo el tráfico de consultas. Categorías y Descriptores de Asignaturas H.3.3 [Sistemas de Información]: Almacenamiento y Recuperación de Información-Formulación de Consultas Términos Generales Algoritmos, Experimentación 1. INTRODUCCIÓN La búsqueda en la web se ha convertido en una herramienta importante en nuestra vida diaria para buscar información. Uno de los problemas importantes en la búsqueda web es que las consultas de los usuarios a menudo no están formuladas de la mejor manera para obtener resultados óptimos. Por ejemplo, \"zapatilla para correr\" es una consulta que ocurre con frecuencia en los registros de consulta. Sin embargo, es mucho más probable que la búsqueda \"zapatillas para correr\" proporcione mejores resultados de búsqueda que la consulta original, ya que los documentos que coinciden con la intención de esta consulta suelen contener las palabras \"zapatillas para correr\". Formular correctamente una consulta requiere que el usuario prediga con precisión qué forma de palabra se utiliza en los documentos que mejor satisfacen sus necesidades de información. Esto es difícil incluso para usuarios experimentados, y especialmente difícil para hablantes no nativos. Una solución tradicional es utilizar el stemming [16, 18], el proceso de transformar palabras flexionadas o derivadas a su forma raíz para que un término de búsqueda coincida y recupere documentos que contengan todas las formas del término. Por lo tanto, la palabra \"run\" coincidirá con \"running\", \"ran\", \"runs\", y \"shoe\" coincidirá con \"shoes\" y \"shoeing\". El truncamiento se puede realizar tanto en los términos de un documento durante la indexación (y aplicando la misma transformación a los términos de la consulta durante el procesamiento de la consulta) o expandiendo la consulta con las variantes durante el procesamiento de la consulta. El truncamiento durante la indexación permite muy poca flexibilidad durante el procesamiento de consultas, mientras que el truncamiento mediante la expansión de consultas permite manejar cada consulta de manera diferente, y por lo tanto es preferible. Aunque el truncamiento tradicional aumenta la recuperación al emparejar variantes de palabras [13], puede reducir la precisión al recuperar demasiados documentos que han sido emparejados incorrectamente. Al examinar los resultados de aplicar el truncamiento a un gran número de consultas, generalmente se encuentra que casi igual cantidad de consultas se benefician y se ven perjudicadas por la técnica [6]. Además, reduce el rendimiento del sistema porque el motor de búsqueda tiene que hacer coincidir todas las variantes de palabras. Como mostraremos en los experimentos, esto es cierto incluso si simplificamos el proceso de derivación a la manipulación de pluralización, que es el proceso de convertir una palabra de su forma plural a singular, o viceversa. Por lo tanto, es necesario ser muy cauteloso al utilizar el stemming en los motores de búsqueda web. Un problema del truncamiento tradicional es su transformación ciega de todos los términos de consulta, es decir, siempre realiza la misma transformación para la misma palabra de consulta sin considerar el contexto de la palabra. Por ejemplo, la palabra \"book\" tiene cuatro formas: book, books, booking, booked, y la palabra \"store\" tiene cuatro formas: store, stores, storing, stored. Para la consulta de la librería, expandir ambas palabras a todas sus variantes aumenta significativamente el costo de computación y perjudica la precisión, ya que no todas las variantes son útiles para esta consulta. Transformar librería para que coincida con librerías está bien, pero hacer coincidir almacenamiento de libros o tienda de reservas no lo está. Un método de ponderación que otorga pesos más pequeños a las palabras variantes alivia los problemas hasta cierto punto si los pesos reflejan con precisión la importancia de la variante en esta consulta particular. Sin embargo, el peso uniforme no va a funcionar y un peso dependiente de la consulta sigue siendo un problema desafiante sin resolver [20]. Un segundo problema del truncamiento tradicional es su emparejamiento ciego de todas las ocurrencias en los documentos. Para la consulta de la librería, una transformación que permita que las tiendas variantes se emparejen hará que cada aparición de tiendas en el documento se trate de manera equivalente al término de consulta tienda. Por lo tanto, se emparejará un documento que contenga el fragmento de leer un libro en las cafeterías, lo que provocará que se seleccionen muchos documentos incorrectos. Aunque esperamos que la función de clasificación pueda manejar correctamente estos, con muchos más candidatos para clasificar, el riesgo de cometer errores aumenta. Para aliviar estos dos problemas, proponemos un enfoque de reducción de palabras raíz sensible al contexto para la búsqueda en la web. Nuestra solución consiste en dos análisis contextuales sensibles, uno en el lado de la consulta y otro en el lado del documento. En el lado de la consulta, proponemos un enfoque basado en modelado del lenguaje estadístico para predecir qué variantes de palabras son mejores formas que la palabra original con fines de búsqueda y expandir la consulta solo con esas formas. En el lado del documento, proponemos un emparejamiento conservador sensible al contexto para las variantes de palabras transformadas, solo emparejando las ocurrencias en el documento en el contexto de otros términos en la consulta. Nuestro modelo es simple pero efectivo y eficiente, lo que lo hace factible de ser utilizado en motores de búsqueda web comerciales reales. Utilizamos el manejo de pluralización como un ejemplo continuo para nuestro enfoque de derivación. La motivación para usar el manejo de pluralización como ejemplo es mostrar que incluso un truncamiento tan simple, si se maneja correctamente, puede brindar beneficios significativos a la relevancia de la búsqueda. Hasta donde sabemos, ninguna investigación previa ha investigado sistemáticamente el uso de la pluralización en la búsqueda en la web. Como debemos señalar, el método que proponemos no se limita al manejo de la pluralización, es una técnica de derivación general y también se puede aplicar a la expansión de consultas en general. Los experimentos sobre el truncamiento general producen mejoras significativas adicionales sobre el manejo de la pluralización para consultas largas, aunque los detalles no se informarán en este artículo. En el resto del documento, primero presentamos el trabajo relacionado y distinguimos nuestro método de trabajos anteriores en la Sección 2. Describimos los detalles del enfoque de derivación sensible al contexto en la Sección 3. Luego realizamos experimentos extensos en un importante motor de búsqueda web para respaldar nuestras afirmaciones en la Sección 4, seguidos de discusiones en la Sección 5. Finalmente, concluimos el artículo en la Sección 6.2. TRABAJO RELACIONADO El stemming es una tecnología estudiada desde hace mucho tiempo. Se han desarrollado muchos stemmers, como el stemmer Lovins [16] y el <br>stemmer Porter</br> [18]. El <br>stemmer de Porter</br> es ampliamente utilizado debido a su simplicidad y efectividad en muchas aplicaciones. Sin embargo, el algoritmo de Porter comete muchos errores porque sus reglas simples no pueden describir completamente la morfología del inglés. El análisis de corpus se utiliza para mejorar el <br>stemmer de Porter</br> [26] mediante la creación de clases de equivalencia para palabras que son morfológicamente similares y que ocurren en un contexto similar, medido por la información mutua esperada [23]. Utilizamos un enfoque de corpus similar para el stemming al calcular la similitud entre dos palabras basada en sus características de contexto distribucional, que pueden ser más que solo palabras adyacentes [15], y luego solo mantenemos las palabras morfológicamente similares como candidatas. El uso de la derivación en la recuperación de información también es una técnica bien conocida [8, 10]. Sin embargo, se informó previamente que la efectividad del truncamiento para los sistemas de consulta en inglés era bastante limitada. Lennon et al. [17] compararon los algoritmos de Lovins y Porter y encontraron poco mejoramiento en el rendimiento de recuperación. Más tarde, Harman [9] compara tres técnicas generales de derivación en experimentos de recuperación de texto, incluido el manejo de pluralización (llamado S stemmer en el artículo). También propusieron el truncamiento selectivo basado en la longitud de la consulta y la importancia del término, pero no se informaron resultados positivos. Por otro lado, Krovetz [14] realizó comparaciones sobre un pequeño número de documentos (de 400 a 12k) y mostró una mejora dramática en la precisión (de hasta un 45%). Sin embargo, debido al número limitado de consultas probadas (menos de 100) y al tamaño reducido de la colección, los resultados son difíciles de generalizar para la búsqueda en la web. Estos resultados mixtos, en su mayoría fracasos, llevaron a los primeros investigadores de IR a considerar que el truncamiento era irrelevante en general para el inglés [4], aunque investigaciones recientes han demostrado que el truncamiento tiene mayores beneficios para la recuperación en otros idiomas [2]. Sospechamos que los fracasos anteriores se debieron principalmente a los dos problemas que mencionamos en la introducción. El stemming ciego, o un stemming selectivo basado en la longitud de la consulta como se utiliza en [9], no es suficiente. El truncamiento debe decidirse caso por caso, no solo a nivel de consulta sino también a nivel de documento. Como demostraremos, si se maneja correctamente, se puede lograr una mejora significativa. Un problema más general relacionado con el stemming es la reformulación de consultas [3, 12] y la expansión de consultas que amplía las palabras no solo con variantes de palabras [7, 22, 24, 25]. Para decidir qué palabras expandidas usar, las personas a menudo utilizan técnicas de retroalimentación de seudorelevancia que envían la consulta original a un motor de búsqueda y recuperan los documentos principales, extraen palabras relevantes de estos documentos principales como palabras de consulta adicionales y vuelven a enviar la consulta expandida nuevamente [21]. Esto normalmente requiere enviar una consulta varias veces al motor de búsqueda y no es rentable para procesar la gran cantidad de consultas involucradas en la búsqueda web. Además, la expansión de consultas, incluida la reformulación de consultas [3, 12], tiene un alto riesgo de cambiar la intención del usuario (llamado desviación de consulta). Dado que las palabras expandidas pueden tener diferentes significados, agregarlas a la consulta podría potencialmente cambiar la intención de la consulta original. Por lo tanto, la expansión de consultas basada en pseudorelevancia y la reformulación de consultas pueden proporcionar sugerencias a los usuarios para su refinamiento interactivo, pero difícilmente pueden ser utilizadas directamente para la búsqueda en la web. Por otro lado, el truncamiento es mucho más conservador ya que la mayoría de las veces, conserva la intención de búsqueda original. Si bien la mayoría de los trabajos sobre la expansión de consultas se centran en mejorar la recuperación, nuestro trabajo se enfoca en aumentar tanto la recuperación como la precisión. El aumento en el recuerdo es evidente. Con el stemming de calidad, los buenos documentos que no fueron seleccionados antes del stemming serán promovidos y aquellos documentos de baja calidad serán degradados. En la expansión selectiva de consultas, Cronen-Townsend et al. [6] propusieron un método para la expansión selectiva de consultas basado en comparar la divergencia de Kullback-Leibler de los resultados de la consulta no expandida y los resultados de la consulta expandida. Esto es similar a la retroalimentación de relevancia en el sentido de que requiere múltiples pasadas de recuperación. Si una palabra puede expandirse en varias palabras, se requiere ejecutar este proceso varias veces para decidir cuál palabra expandida es útil. Es costoso implementar esto en motores de búsqueda web en producción. Nuestro método predice la calidad de la expansión basándose en información sin conexión sin enviar la consulta a un motor de búsqueda. En resumen, proponemos un enfoque novedoso para abordar un problema antiguo, pero aún importante y desafiante para la búsqueda en la web: el stemming. Nuestro enfoque es único en el sentido de que realiza el truncamiento predictivo de forma individualizada para cada consulta sin retroalimentación de relevancia de la Web, utilizando el contexto de las variantes en los documentos para preservar la precisión. Es simple, pero muy eficiente y efectivo, lo que hace factible el truncamiento en tiempo real para la búsqueda en la web. Nuestros resultados confirmarán a los investigadores que el truncamiento es realmente muy importante para la recuperación de información a gran escala. STEMMING CONTEXTUAL SENSIBLE 3.1 Resumen Nuestro sistema tiene cuatro componentes como se ilustra en la Figura 1: generación de candidatos, segmentación de consultas y detección de palabras clave, derivación de consultas sensible al contexto y coincidencia de documentos sensible al contexto. La generación de candidatos (componente 1) se realiza fuera de línea y los candidatos generados se almacenan en un diccionario. Para una consulta de entrada, primero segmentamos la consulta en conceptos y detectamos la palabra principal de cada concepto (componente 2). Luego utilizamos modelado de lenguaje estadístico para decidir si una variante particular es útil (componente 3), y finalmente, para las variantes expandidas, realizamos un emparejamiento de documentos sensible al contexto (componente 4). A continuación discutimos cada uno de los componentes con más detalle. Componente 4: coincidencia de documentos sensibles al contexto Consulta de entrada: y detección de palabras clave Componente 2: segmento Componente 1: generación de candidatos comparaciones −> comparación Componente 3: decisión de expansión selectiva de palabras: comparaciones −> comparación ejemplo: comparaciones de precios de hoteles salida: comparaciones de hoteles hotel −> hoteles Figura 1: Componentes del sistema 3.2 Generación de candidatos de expansión Una de las formas de generar candidatos es utilizando el <br>stemmer de Porter</br> [18]. El <br>stemmer de Porter</br> simplemente utiliza reglas morfológicas para convertir una palabra a su forma base. ",
            "candidates": [],
            "error": [
                [
                    "stemmer Porter",
                    "stemmer de Porter",
                    "stemmer de Porter",
                    "stemmer de Porter",
                    "stemmer de Porter"
                ]
            ]
        },
        "candidate generation": {
            "translated_key": "generación de candidatos",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Context Sensitive Stemming for Web Search Fuchun Peng Nawaaz Ahmed Xin Li Yumao Lu Yahoo!",
                "Inc. 701 First Avenue Sunnyvale, California 94089 {fuchun, nawaaz, xinli, yumaol}@yahoo-inc.com ABSTRACT Traditionally, stemming has been applied to Information Retrieval tasks by transforming words in documents to the their root form before indexing, and applying a similar transformation to query terms.",
                "Although it increases recall, this naive strategy does not work well for Web Search since it lowers precision and requires a significant amount of additional computation.",
                "In this paper, we propose a context sensitive stemming method that addresses these two issues.",
                "Two unique properties make our approach feasible for Web Search.",
                "First, based on statistical language modeling, we perform context sensitive analysis on the query side.",
                "We accurately predict which of its morphological variants is useful to expand a query term with before submitting the query to the search engine.",
                "This dramatically reduces the number of bad expansions, which in turn reduces the cost of additional computation and improves the precision at the same time.",
                "Second, our approach performs a context sensitive document matching for those expanded variants.",
                "This conservative strategy serves as a safeguard against spurious stemming, and it turns out to be very important for improving precision.",
                "Using word pluralization handling as an example of our stemming approach, our experiments on a major Web search engine show that stemming only 29% of the query traffic, we can improve relevance as measured by average Discounted Cumulative Gain (DCG5) by 6.1% on these queries and 1.8% over all query traffic.",
                "Categories and Subject Descriptors H.3.3 [Information Systems]: Information Storage and Retrieval-Query formulation General Terms Algorithms, Experimentation 1.",
                "INTRODUCTION Web search has now become a major tool in our daily lives for information seeking.",
                "One of the important issues in Web search is that user queries are often not best formulated to get optimal results.",
                "For example, running shoe is a query that occurs frequently in query logs.",
                "However, the query running shoes is much more likely to give better search results than the original query because documents matching the intent of this query usually contain the words running shoes.",
                "Correctly formulating a query requires the user to accurately predict which word form is used in the documents that best satisfy his or her information needs.",
                "This is difficult even for experienced users, and especially difficult for non-native speakers.",
                "One traditional solution is to use stemming [16, 18], the process of transforming inflected or derived words to their root form so that a search term will match and retrieve documents containing all forms of the term.",
                "Thus, the word run will match running, ran, runs, and shoe will match shoes and shoeing.",
                "Stemming can be done either on the terms in a document during indexing (and applying the same transformation to the query terms during query processing) or by expanding the query with the variants during query processing.",
                "Stemming during indexing allows very little flexibility during query processing, while stemming by query expansion allows handling each query differently, and hence is preferred.",
                "Although traditional stemming increases recall by matching word variants [13], it can reduce precision by retrieving too many documents that have been incorrectly matched.",
                "When examining the results of applying stemming to a large number of queries, one usually finds that nearly equal numbers of queries are helped and hurt by the technique [6].",
                "In addition, it reduces system performance because the search engine has to match all the word variants.",
                "As we will show in the experiments, this is true even if we simplify stemming to pluralization handling, which is the process of converting a word from its plural to singular form, or vice versa.",
                "Thus, one needs to be very cautious when using stemming in Web search engines.",
                "One problem of traditional stemming is its blind transformation of all query terms, that is, it always performs the same transformation for the same query word without considering the context of the word.",
                "For example, the word book has four forms book, books, booking, booked, and store has four forms store, stores, storing, stored.",
                "For the query book store, expanding both words to all of their variants significantly increases computation cost and hurts precision, since not all of the variants are useful for this query.",
                "Transforming book store to match book stores is fine, but matching book storing or booking store is not.",
                "A weighting method that gives variant words smaller weights alleviates the problems to a certain extent if the weights accurately reflect the importance of the variant in this particular query.",
                "However uniform weighting is not going to work and a query dependent weighting is still a challenging unsolved problem [20].",
                "A second problem of traditional stemming is its blind matching of all occurrences in documents.",
                "For the query book store, a transformation that allows the variant stores to be matched will cause every occurrence of stores in the document to be treated equivalent to the query term store.",
                "Thus, a document containing the fragment reading a book in coffee stores will be matched, causing many wrong documents to be selected.",
                "Although we hope the ranking function can correctly handle these, with many more candidates to rank, the risk of making mistakes increases.",
                "To alleviate these two problems, we propose a context sensitive stemming approach for Web search.",
                "Our solution consists of two context sensitive analysis, one on the query side and the other on the document side.",
                "On the query side, we propose a statistical language modeling based approach to predict which word variants are better forms than the original word for search purpose and expanding the query with only those forms.",
                "On the document side, we propose a conservative context sensitive matching for the transformed word variants, only matching document occurrences in the context of other terms in the query.",
                "Our model is simple yet effective and efficient, making it feasible to be used in real commercial Web search engines.",
                "We use pluralization handling as a running example for our stemming approach.",
                "The motivation for using pluralization handling as an example is to show that even such simple stemming, if handled correctly, can give significant benefits to search relevance.",
                "As far as we know, no previous research has systematically investigated the usage of pluralization in Web search.",
                "As we have to point out, the method we propose is not limited to pluralization handling, it is a general stemming technique, and can also be applied to general query expansion.",
                "Experiments on general stemming yield additional significant improvements over pluralization handling for long queries, although details will not be reported in this paper.",
                "In the rest of the paper, we first present the related work and distinguish our method from previous work in Section 2.",
                "We describe the details of the context sensitive stemming approach in Section 3.",
                "We then perform extensive experiments on a major Web search engine to support our claims in Section 4, followed by discussions in Section 5.",
                "Finally, we conclude the paper in Section 6. 2.",
                "RELATED WORK Stemming is a long studied technology.",
                "Many stemmers have been developed, such as the Lovins stemmer [16] and the Porter stemmer [18].",
                "The Porter stemmer is widely used due to its simplicity and effectiveness in many applications.",
                "However, the Porter stemming makes many mistakes because its simple rules cannot fully describe English morphology.",
                "Corpus analysis is used to improve Porter stemmer [26] by creating equivalence classes for words that are morphologically similar and occur in similar context as measured by expected mutual information [23].",
                "We use a similar corpus based approach for stemming by computing the similarity between two words based on their distributional context features which can be more than just adjacent words [15], and then only keep the morphologically similar words as candidates.",
                "Using stemming in information retrieval is also a well known technique [8, 10].",
                "However, the effectiveness of stemming for English query systems was previously reported to be rather limited.",
                "Lennon et al. [17] compared the Lovins and Porter algorithms and found little improvement in retrieval performance.",
                "Later, Harman [9] compares three general stemming techniques in text retrieval experiments including pluralization handing (called S stemmer in the paper).",
                "They also proposed selective stemming based on query length and term importance, but no positive results were reported.",
                "On the other hand, Krovetz [14] performed comparisons over small numbers of documents (from 400 to 12k) and showed dramatic precision improvement (up to 45%).",
                "However, due to the limited number of tested queries (less than 100) and the small size of the collection, the results are hard to generalize to Web search.",
                "These mixed results, mostly failures, led early IR researchers to deem stemming irrelevant in general for English [4], although recent research has shown stemming has greater benefits for retrieval in other languages [2].",
                "We suspect the previous failures were mainly due to the two problems we mentioned in the introduction.",
                "Blind stemming, or a simple query length based selective stemming as used in [9] is not enough.",
                "Stemming has to be decided on case by case basis, not only at the query level but also at the document level.",
                "As we will show, if handled correctly, significant improvement can be achieved.",
                "A more general problem related to stemming is query reformulation [3, 12] and query expansion which expands words not only with word variants [7, 22, 24, 25].",
                "To decide which expanded words to use, people often use pseudorelevance feedback techniquesthat send the original query to a search engine and retrieve the top documents, extract relevant words from these top documents as additional query words, and resubmit the expanded query again [21].",
                "This normally requires sending a query multiple times to search engine and it is not cost effective for processing the huge amount of queries involved in Web search.",
                "In addition, query expansion, including query reformulation [3, 12], has a high risk of changing the user intent (called query drift).",
                "Since the expanded words may have different meanings, adding them to the query could potentially change the intent of the original query.",
                "Thus query expansion based on pseudorelevance and query reformulation can provide suggestions to users for interactive refinement but can hardly be directly used for Web search.",
                "On the other hand, stemming is much more conservative since most of the time, stemming preserves the original search intent.",
                "While most work on query expansion focuses on recall enhancement, our work focuses on increasing both recall and precision.",
                "The increase on recall is obvious.",
                "With quality stemming, good documents which were not selected before stemming will be pushed up and those low quality documents will be degraded.",
                "On selective query expansion, Cronen-Townsend et al. [6] proposed a method for selective query expansion based on comparing the Kullback-Leibler divergence of the results from the unexpanded query and the results from the expanded query.",
                "This is similar to the relevance feedback in the sense that it requires multiple passes retrieval.",
                "If a word can be expanded into several words, it requires running this process multiple times to decide which expanded word is useful.",
                "It is expensive to deploy this in production Web search engines.",
                "Our method predicts the quality of expansion based on oﬄine information without sending the query to a search engine.",
                "In summary, we propose a novel approach to attack an old, yet still important and challenging problem for Web search - stemming.",
                "Our approach is unique in that it performs predictive stemming on a per query basis without relevance feedback from the Web, using the context of the variants in documents to preserve precision.",
                "Its simple, yet very efficient and effective, making real time stemming feasible for Web search.",
                "Our results will affirm researchers that stemming is indeed very important to large scale information retrieval. 3.",
                "CONTEXT SENSITIVE STEMMING 3.1 Overview Our system has four components as illustrated in Figure 1: <br>candidate generation</br>, query segmentation and head word detection, context sensitive query stemming and context sensitive document matching.",
                "<br>candidate generation</br> (component 1) is performed oﬄine and generated candidates are stored in a dictionary.",
                "For an input query, we first segment query into concepts and detect the head word for each concept (component 2).",
                "We then use statistical language modeling to decide whether a particular variant is useful (component 3), and finally for the expanded variants, we perform context sensitive document matching (component 4).",
                "Below we discuss each of the components in more detail.",
                "Component 4: context sensitive document matching Input Query: and head word detection Component 2: segment Component 1: <br>candidate generation</br> comparisons −> comparison Component 3: selective word expansion decision: comparisons −> comparison example: hotel price comparisons output: hotel comparisons hotel −> hotels Figure 1: System Components 3.2 Expansion <br>candidate generation</br> One of the ways to generate candidates is using the Porter stemmer [18].",
                "The Porter stemmer simply uses morphological rules to convert a word to its base form.",
                "It has no knowledge of the semantic meaning of the words and sometimes makes serious mistakes, such as executive to execution, news to new, and paste to past.",
                "A more conservative way is based on using corpus analysis to improve the Porter stemmer results [26].",
                "The corpus analysis we do is based on word distributional similarity [15].",
                "The rationale of using distributional word similarity is that true variants tend to be used in similar contexts.",
                "In the distributional word similarity calculation, each word is represented with a vector of features derived from the context of the word.",
                "We use the bigrams to the left and right of the word as its context features, by mining a huge Web corpus.",
                "The similarity between two words is the cosine similarity between the two corresponding feature vectors.",
                "The top 20 similar words to develop is shown in the following table. rank candidate score rank candidate score 0 develop 1 10 berts 0.119 1 developing 0.339 11 wads 0.116 2 developed 0.176 12 developer 0.107 3 incubator 0.160 13 promoting 0.100 4 develops 0.150 14 developmental 0.091 5 development 0.148 15 reengineering 0.090 6 tutoring 0.138 16 build 0.083 7 analyzing 0.128 17 construct 0.081 8 developement 0.128 18 educational 0.081 9 automation 0.126 19 institute 0.077 Table 1: Top 20 most similar candidates to word develop.",
                "Column score is the similarity score.",
                "To determine the stemming candidates, we apply a few Porter stemmer [18] morphological rules to the similarity list.",
                "After applying these rules, for the word develop, the stemming candidates are developing, developed, develops, development, developement, developer, developmental.",
                "For the pluralization handling purpose, only the candidate develops is retained.",
                "One thing we note from observing the distributionally similar words is that they are closely related semantically.",
                "These words might serve as candidates for general query expansion, a topic we will investigate in the future. 3.3 Segmentation and headword identification For long queries, it is quite important to detect the concepts in the query and the most important words for those concepts.",
                "We first break a query into segments, each segment representing a concept which normally is a noun phrase.",
                "For each of the noun phrases, we then detect the most important word which we call the head word.",
                "Segmentation is also used in document sensitive matching (section 3.5) to enforce proximity.",
                "To break a query into segments, we have to define a criteria to measure the strength of the relation between words.",
                "One effective method is to use mutual information as an indicator on whether or not to split two words [19].",
                "We use a log of 25M queries and collect the bigram and unigram frequencies from it.",
                "For every incoming query, we compute the mutual information of two adjacent words; if it passes a predefined threshold, we do not split the query between those two words and move on to next word.",
                "We continue this process until the mutual information between two words is below the threshold, then create a concept boundary here.",
                "Table 2 shows some examples of query segmentation.",
                "The ideal way of finding the head word of a concept is to do syntactic parsing to determine the dependency structure of the query.",
                "Query parsing is more difficult than sentence [running shoe] [best] [new york] [medical schools] [pictures] [of] [white house] [cookies] [in] [san francisco] [hotel] [price comparison] Table 2: Query segmentation: a segment is bracketed. parsing since many queries are not grammatical and are very short.",
                "Applying a parser trained on sentences from documents to queries will have poor performance.",
                "In our solution, we just use simple heuristics rules, and it works very well in practice for English.",
                "For an English noun phrase, the head word is typically the last nonstop word, unless the phrase is of a particular pattern, like XYZ of/in/at/from UVW.",
                "In such cases, the head word is typically the last nonstop word of XYZ. 3.4 Context sensitive word expansion After detecting which words are the most important words to expand, we have to decide whether the expansions will be useful.",
                "Our statistics show that about half of the queries can be transformed by pluralization via naive stemming.",
                "Among this half, about 25% of the queries improve relevance when transformed, the majority (about 50%) do not change their top 5 results, and the remaining 25% perform worse.",
                "Thus, it is extremely important to identify which queries should not be stemmed for the purpose of maximizing relevance improvement and minimizing stemming cost.",
                "In addition, for a query with multiple words that can be transformed, or a word with multiple variants, not all of the expansions are useful.",
                "Taking query hotel price comparison as an example, we decide that hotel and price comparison are two concepts.",
                "Head words hotel and comparison can be expanded to hotels and comparisons.",
                "Are both transformations useful?",
                "To test whether an expansion is useful, we have to know whether the expanded query is likely to get more relevant documents from the Web, which can be quantified by the probability of the query occurring as a string on the Web.",
                "The more likely a query to occur on the Web, the more relevant documents this query is able to return.",
                "Now the whole problem becomes how to calculate the probability of query to occur on the Web.",
                "Calculating the probability of string occurring in a corpus is a well known language modeling problem.",
                "The goal of language modeling is to predict the probability of naturally occurring word sequences, s = w1w2...wN ; or more simply, to put high probability on word sequences that actually occur (and low probability on word sequences that never occur).",
                "The simplest and most successful approach to language modeling is still based on the n-gram model.",
                "By the chain rule of probability one can write the probability of any word sequence as Pr(w1w2...wN ) = NY i=1 Pr(wi|w1...wi−1) (1) An n-gram model approximates this probability by assuming that the only words relevant to predicting Pr(wi|w1...wi−1) are the previous n − 1 words; i.e.",
                "Pr(wi|w1...wi−1) = Pr(wi|wi−n+1...wi−1) A straightforward maximum likelihood estimate of n-gram probabilities from a corpus is given by the observed frequency of each of the patterns Pr(wi|wi−n+1...wi−1) = #(wi−n+1...wi) #(wi−n+1...wi−1) (2) where #(.) denotes the number of occurrences of a specified gram in the training corpus.",
                "Although one could attempt to use simple n-gram models to capture long range dependencies in language, attempting to do so directly immediately creates sparse data problems: Using grams of length up to n entails estimating the probability of Wn events, where W is the size of the word vocabulary.",
                "This quickly overwhelms modern computational and data resources for even modest choices of n (beyond 3 to 6).",
                "Also, because of the heavy tailed nature of language (i.e.",
                "Zipfs law) one is likely to encounter novel n-grams that were never witnessed during training in any test corpus, and therefore some mechanism for assigning non-zero probability to novel n-grams is a central and unavoidable issue in statistical language modeling.",
                "One standard approach to smoothing probability estimates to cope with sparse data problems (and to cope with potentially missing n-grams) is to use some sort of back-off estimator.",
                "Pr(wi|wi−n+1...wi−1) = 8 >>< >>: ˆPr(wi|wi−n+1...wi−1), if #(wi−n+1...wi) > 0 β(wi−n+1...wi−1) × Pr(wi|wi−n+2...wi−1), otherwise (3) where ˆPr(wi|wi−n+1...wi−1) = discount #(wi−n+1...wi) #(wi−n+1...wi−1) (4) is the discounted probability and β(wi−n+1...wi−1) is a normalization constant β(wi−n+1...wi−1) = 1 − X x∈(wi−n+1...wi−1x) ˆPr(x|wi−n+1...wi−1) 1 − X x∈(wi−n+1...wi−1x) ˆPr(x|wi−n+2...wi−1) (5) The discounted probability (4) can be computed with different smoothing techniques, including absolute smoothing, Good-Turing smoothing, linear smoothing, and Witten-Bell smoothing [5].",
                "We used absolute smoothing in our experiments.",
                "Since the likelihood of a string, Pr(w1w2...wN ), is a very small number and hard to interpret, we use entropy as defined below to score the string.",
                "Entropy = − 1 N log2 Pr(w1w2...wN ) (6) Now getting back to the example of the query hotel price comparisons, there are four variants of this query, and the entropy of these four candidates are shown in Table 3.",
                "We can see that all alternatives are less likely than the input query.",
                "It is therefore not useful to make an expansion for this query.",
                "On the other hand, if the input query is hotel price comparisons which is the second alternative in the table, then there is a better alternative than the input query, and it should therefore be expanded.",
                "To tolerate the variations in probability estimation, we relax the selection criterion to those query alternatives if their scores are within a certain distance (10% in our experiments) to the best score.",
                "Query variations Entropy hotel price comparison 6.177 hotel price comparisons 6.597 hotels price comparison 6.937 hotels price comparisons 7.360 Table 3: Variations of query hotel price comparison ranked by entropy score, with the original query in bold face. 3.5 Context sensitive document matching Even after we know which word variants are likely to be useful, we have to be conservative in document matching for the expanded variants.",
                "For the query hotel price comparisons, we decided that word comparisons is expanded to include comparison.",
                "However, not every occurrence of comparison in the document is of interest.",
                "A page which is about comparing customer service can contain all of the words hotel price comparisons comparison.",
                "This page is not a good page for the query.",
                "If we accept matches of every occurrence of comparison, it will hurt retrieval precision and this is one of the main reasons why most stemming approaches do not work well for information retrieval.",
                "To address this problem, we have a proximity constraint that considers the context around the expanded variant in the document.",
                "A variant match is considered valid only if the variant occurs in the same context as the original word does.",
                "The context is the left or the right non-stop segments 1 of the original word.",
                "Taking the same query as an example, the context of comparisons is price.",
                "The expanded word comparison is only valid if it is in the same context of comparisons, which is after the word price.",
                "Thus, we should only match those occurrences of comparison in the document if they occur after the word price.",
                "Considering the fact that queries and documents may not represent the intent in exactly the same way, we relax this proximity constraint to allow variant occurrences within a window of some fixed size.",
                "If the expanded word comparison occurs within the context of price within a window, it is considered valid.",
                "The smaller the window size is, the more restrictive the matching.",
                "We use a window size of 4, which typically captures contexts that include the containing and adjacent noun phrases. 4.",
                "EXPERIMENTAL EVALUATION 4.1 Evaluation metrics We will measure both relevance improvement and the stemming cost required to achieve the relevance. 1 a context segment can not be a single stop word. 4.1.1 Relevance measurement We use a variant of the average Discounted Cumulative Gain (DCG), a recently popularized scheme to measure search engine relevance [1, 11].",
                "Given a query and a ranked list of K documents (K is set to 5 in our experiments), the DCG(K) score for this query is calculated as follows: DCG(K) = KX k=1 gk log2(1 + k) . (7) where gk is the weight for the document at rank k. Higher degree of relevance corresponds to a higher weight.",
                "A page is graded into one of the five scales: Perfect, Excellent, Good, Fair, Bad, with corresponding weights.",
                "We use dcg to represent the average DCG(5) over a set of test queries. 4.1.2 Stemming cost Another metric is to measure the additional cost incurred by stemming.",
                "Given the same level of relevance improvement, we prefer a stemming method that has less additional cost.",
                "We measure this by the percentage of queries that are actually stemmed, over all the queries that could possibly be stemmed. 4.2 Data preparation We randomly sample 870 queries from a three month query log, with 290 from each month.",
                "Among all these 870 queries, we remove all misspelled queries since misspelled queries are not of interest to stemming.",
                "We also remove all one word queries since stemming one word queries without context has a high risk of changing query intent, especially for short words.",
                "In the end, we have 529 correctly spelled queries with at least 2 words. 4.3 Naive stemming for Web search Before explaining the experiments and results in detail, wed like to describe the traditional way of using stemming for Web search, referred as the naive model.",
                "This is to treat every word variant equivalent for all possible words in the query.",
                "The query book store will be transformed into (book OR books)(store OR stores) when limiting stemming to pluralization handling only, where OR is an operator that denotes the equivalence of the left and right arguments. 4.4 Experimental setup The baseline model is the model without stemming.",
                "We first run the naive model to see how well it performs over the baseline.",
                "Then we improve the naive stemming model by document sensitive matching, referred as document sensitive matching model.",
                "This model makes the same stemming as the naive model on the query side, but performs conservative matching on the document side using the strategy described in section 3.5.",
                "The naive model and document sensitive matching model stem the most queries.",
                "Out of the 529 queries, there are 408 queries that they stem, corresponding to 46.7% query traffic (out of a total of 870).",
                "We then further improve the document sensitive matching model from the query side with selective word stemming based on statistical language modeling (section 3.4), referred as selective stemming model.",
                "Based on language modeling prediction, this model stems only a subset of the 408 queries stemmed by the document sensitive matching model.",
                "We experiment with unigram language model and bigram language model.",
                "Since we only care how much we can improve the naive model, we will only use these 408 queries (all the queries that are affected by the naive stemming model) in the experiments.",
                "To get a sense of how these models perform, we also have an oracle model that gives the upper-bound performance a stemmer can achieve on this data.",
                "The oracle model only expands a word if the stemming will give better results.",
                "To analyze the pluralization handling influence on different query categories, we divide queries into short queries and long queries.",
                "Among the 408 queries stemmed by the naive model, there are 272 short queries with 2 or 3 words, and 136 long queries with at least 4 words. 4.5 Results We summarize the overall results in Table 4, and present the results on short queries and long queries separately in Table 5.",
                "Each row in Table 4 is a stemming strategy described in section 4.4.",
                "The first column is the name of the strategy.",
                "The second column is the number of queries affected by this strategy; this column measures the stemming cost, and the numbers should be low for the same level of dcg.",
                "The third column is the average dcg score over all tested queries in this category (including the ones that were not stemmed by the strategy).",
                "The fourth column is the relative improvement over the baseline, and the last column is the p-value of Wilcoxon significance test.",
                "There are several observations about the results.",
                "We can see the naively stemming only obtains a statistically insignificant improvement of 1.5%.",
                "Looking at Table 5, it gives an improvement of 2.7% on short queries.",
                "However, it also hurts long queries by -2.4%.",
                "Overall, the improvement is canceled out.",
                "The reason that it improves short queries is that most short queries only have one word that can be stemmed.",
                "Thus, blindly pluralizing short queries is relatively safe.",
                "However for long queries, most queries can have multiple words that can be pluralized.",
                "Expanding all of them without selection will significantly hurt precision.",
                "Document context sensitive stemming gives a significant lift to the performance, from 2.7% to 4.2% for short queries and from -2.4% to -1.6% for long queries, with an overall lift from 1.5% to 2.8%.",
                "The improvement comes from the conservative context sensitive document matching.",
                "An expanded word is valid only if it occurs within the context of original query in the document.",
                "This reduces many spurious matches.",
                "However, we still notice that for long queries, context sensitive stemming is not able to improve performance because it still selects too many documents and gives the ranking function a hard problem.",
                "While the chosen window size of 4 works the best amongst all the choices, it still allows spurious matches.",
                "It is possible that the window size needs to be chosen on a per query basis to ensure tighter proximity constraints for different types of noun phrases.",
                "Selective word pluralization further helps resolving the problem faced by document context sensitive stemming.",
                "It does not stem every word that places all the burden on the ranking algorithm, but tries to eliminate unnecessary stemming in the first place.",
                "By predicting which word variants are going to be useful, we can dramatically reduce the number of stemmed words, thus improving both the recall and the precision.",
                "With the unigram language model, we can reduce the stemming cost by 26.7% (from 408/408 to 300/408) and lift the overall dcg improvement from 2.8% to 3.4%.",
                "In particular, it gives significant improvements on long queries.",
                "The dcg gain is turned from negative to positive, from −1.6% to 1.1%.",
                "This confirms our hypothesis that reducing unnecessary word expansion leads to precision improvement.",
                "For short queries too, we observe both dcg improvement and stemming cost reduction with the unigram language model.",
                "The advantages of predictive word expansion with a language model is further boosted with a better bigram language model.",
                "The overall dcg gain is lifted from 3.4% to 3.9%, and stemming cost is dramatically reduced from 408/408 to 250/408, corresponding to only 29% of query traffic (250 out of 870) and an overall 1.8% dcg improvement overall all query traffic.",
                "For short queries, bigram language model improves the dcg gain from 4.4% to 4.7%, and reduces stemming cost from 272/272 to 150/272.",
                "For long queries, bigram language model improves dcg gain from 1.1% to 2.5%, and reduces stemming cost from 136/136 to 100/136.",
                "We observe that the bigram language model gives a larger lift for long queries.",
                "This is because the uncertainty in long queries is larger and a more powerful language model is needed.",
                "We hypothesize that a trigram language model would give a further lift for long queries and leave this for future investigation.",
                "Considering the tight upper-bound 2 on the improvement to be gained from pluralization handling (via the oracle model), the current performance on short queries is very satisfying.",
                "For short queries, the dcg gain upper-bound is 6.3% for perfect pluralization handling, our current gain is 4.7% with a bigram language model.",
                "For long queries, the dcg gain upper-bound is 4.6% for perfect pluralization handling, our current gain is 2.5% with a bigram language model.",
                "We may gain additional benefit with a more powerful language model for long queries.",
                "However, the difficulties of long queries come from many other aspects including the proximity and the segmentation problem.",
                "These problems have to be addressed separately.",
                "Looking at the the upper-bound of overhead reduction for oracle stemming, 75% (308/408) of the naive stemmings are wasteful.",
                "We currently capture about half of them.",
                "Further reduction of the overhead requires sacrificing the dcg gain.",
                "Now we can compare the stemming strategies from a different aspect.",
                "Instead of looking at the influence over all queries as we described above, Table 6 summarizes the dcg improvements over the affected queries only.",
                "We can see that the number of affected queries decreases as the stemming strategy becomes more accurate (dcg improvement).",
                "For the bigram language model, over the 250/408 stemmed queries, the dcg improvement is 6.1%.",
                "An interesting observation is the average dcg decreases with a better model, which indicates a better stemming strategy stems more difficult queries (low dcg queries). 5.",
                "DISCUSSIONS 5.1 Language models from query vs. from Web As we mentioned in Section 1, we are trying to predict the probability of a string occurring on the Web.",
                "The language model should describe the occurrence of the string on the Web.",
                "However, the query log is also a good resource. 2 Note that this upperbound is for pluralization handling only, not for general stemming.",
                "General stemming gives a 8% upperbound, which is quite substantial in terms of our metrics.",
                "Affected Queries dcg dcg Improvement p-value baseline 0/408 7.102 N/A N/A naive model 408/408 7.206 1.5% 0.22 document context sensitive model 408/408 7.302 2.8% 0.014 selective model: unigram LM 300/408 7.321 3.4% 0.001 selective model: bigram LM 250/408 7.381 3.9% 0.001 oracle model 100/408 7.519 5.9% 0.001 Table 4: Results comparison of different stemming strategies over all queries affected by naive stemming Short Query Results Affected Queries dcg Improvement p-value baseline 0/272 N/A N/A naive model 272/272 2.7% 0.48 document context sensitive model 272/272 4.2% 0.002 selective model: unigram LM 185/272 4.4% 0.001 selective model: bigram LM 150/272 4.7% 0.001 oracle model 71/272 6.3% 0.001 Long Query Results Affected Queries dcg Improvement p-value baseline 0/136 N/A N/A naive model 136/136 -2.4% 0.25 document context sensitive model 136/136 -1.6% 0.27 selective model: unigram LM 115/136 1.1% 0.001 selective model: bigram LM 100/136 2.5% 0.001 oracle model 29/136 4.6% 0.001 Table 5: Results comparison of different stemming strategies overall short queries and long queries Users reformulate a query using many different variants to get good results.",
                "To test the hypothesis that we can learn reliable transformation probabilities from the query log, we trained a language model from the same query top 25M queries as used to learn segmentation, and use that for prediction.",
                "We observed a slight performance decrease compared to the model trained on Web frequencies.",
                "In particular, the performance for unigram LM was not affected, but the dcg gain for bigram LM changed from 4.7% to 4.5% for short queries.",
                "Thus, the query log can serve as a good approximation of the Web frequencies. 5.2 How linguistics helps Some linguistic knowledge is useful in stemming.",
                "For the pluralization handling case, pluralization and de-pluralization is not symmetric.",
                "A plural word used in a query indicates a special intent.",
                "For example, the query new york hotels is looking for a list of hotels in new york, not the specific new york hotel which might be a hotel located in California.",
                "A simple equivalence of hotel to hotels might boost a particular page about new york hotel to top rank.",
                "To capture this intent, we have to make sure the document is a general page about hotels in new york.",
                "We do this by requiring that the plural word hotels appears in the document.",
                "On the other hand, converting a singular word to plural is safer since a general purpose page normally contains specific information.",
                "We observed a slight overall dcg decrease, although not statistically significant, for document context sensitive stemming if we do not consider this asymmetric property. 5.3 Error analysis One type of mistakes we noticed, though rare but seriously hurting relevance, is the search intent change after stemming.",
                "Generally speaking, pluralization or depluralization keeps the original intent.",
                "However, the intent could change in a few cases.",
                "For one example of such a query, job at apple, we pluralize job to jobs.",
                "This stemming makes the original query ambiguous.",
                "The query job OR jobs at apple has two intents.",
                "One is the employment opportunities at apple, and another is a person working at Apple, Steve Jobs, who is the CEO and co-founder of the company.",
                "Thus, the results after query stemming returns Steve Jobs as one of the results in top 5.",
                "One solution is performing results set based analysis to check if the intent is changed.",
                "This is similar to relevance feedback and requires second phase ranking.",
                "A second type of mistakes is the entity/concept recognition problem, These include two kinds.",
                "One is that the stemmed word variant now matches part of an entity or concept.",
                "For example, query cookies in san francisco is pluralized to cookies OR cookie in san francisco.",
                "The results will match cookie jar in san francisco.",
                "Although cookie still means the same thing as cookies, cookie jar is a different concept.",
                "Another kind is the unstemmed word matches an entity or concept because of the stemming of the other words.",
                "For example, quote ICE is pluralized to quote OR quotes ICE.",
                "The original intent for this query is searching for stock quote for ticker ICE.",
                "However, we noticed that among the top results, one of the results is Food quotes: Ice cream.",
                "This is matched because of Affected Queries old dcg new dcg dcg Improvement naive model 408/408 7.102 7.206 1.5% document context sensitive model 408/408 7.102 7.302 2.8% selective model: unigram LM 300/408 5.904 6.187 4.8% selective model: bigram LM 250/408 5.551 5.891 6.1% Table 6: Results comparison over the stemmed queries only: column old/new dcg is the dcg score over the affected queries before/after applying stemming the pluralized word quotes.",
                "The unchanged word ICE matches part of the noun phrase ice cream here.",
                "To solve this kind of problem, we have to analyze the documents and recognize cookie jar and ice cream as concepts instead of two independent words.",
                "A third type of mistakes occurs in long queries.",
                "For the query bar code reader software, two words are pluralized. code to codes and reader to readers.",
                "In fact, bar code reader in the original query is a strong concept and the internal words should not be changed.",
                "This is the segmentation and entity and noun phrase detection problem in queries, which we actively are attacking.",
                "For long queries, we should correctly identify the concepts in the query, and boost the proximity for the words within a concept. 6.",
                "CONCLUSIONS AND FUTURE WORK We have presented a simple yet elegant way of stemming for Web search.",
                "It improves naive stemming in two aspects: selective word expansion on the query side and conservative word occurrence matching on the document side.",
                "Using pluralization handling as an example, experiments on a major Web search engine data show it significantly improves the Web relevance and reduces the stemming cost.",
                "It also significantly improves Web click through rate (details not reported in the paper).",
                "For the future work, we are investigating the problems we identified in the error analysis section.",
                "These include: entity and noun phrase matching mistakes, and improved segmentation. 7.",
                "REFERENCES [1] E. Agichtein, E. Brill, and S. T. Dumais.",
                "Improving Web Search Ranking by Incorporating User Behavior Information.",
                "In SIGIR, 2006. [2] E. Airio.",
                "Word Normalization and Decompounding in Mono- and Bilingual IR.",
                "Information Retrieval, 9:249-271, 2006. [3] P. Anick.",
                "Using Terminological Feedback for Web Search Refinement: a Log-based Study.",
                "In SIGIR, 2003. [4] R. Baeza-Yates and B. Ribeiro-Neto.",
                "Modern Information Retrieval.",
                "ACM Press/Addison Wesley, 1999. [5] S. Chen and J. Goodman.",
                "An Empirical Study of Smoothing Techniques for Language Modeling.",
                "Technical Report TR-10-98, Harvard University, 1998. [6] S. Cronen-Townsend, Y. Zhou, and B. Croft.",
                "A Framework for Selective Query Expansion.",
                "In CIKM, 2004. [7] H. Fang and C. Zhai.",
                "Semantic Term Matching in Axiomatic Approaches to Information Retrieval.",
                "In SIGIR, 2006. [8] W. B. Frakes.",
                "Term Conflation for Information Retrieval.",
                "In C. J. Rijsbergen, editor, Research and Development in Information Retrieval, pages 383-389.",
                "Cambridge University Press, 1984. [9] D. Harman.",
                "How Effective is Suffixing?",
                "JASIS, 42(1):7-15, 1991. [10] D. Hull.",
                "Stemming Algorithms - A Case Study for Detailed Evaluation.",
                "JASIS, 47(1):70-84, 1996. [11] K. Jarvelin and J. Kekalainen.",
                "Cumulated Gain-Based Evaluation Evaluation of IR Techniques.",
                "ACM TOIS, 20:422-446, 2002. [12] R. Jones, B. Rey, O. Madani, and W. Greiner.",
                "Generating Query Substitutions.",
                "In WWW, 2006. [13] W. Kraaij and R. Pohlmann.",
                "Viewing Stemming as Recall Enhancement.",
                "In SIGIR, 1996. [14] R. Krovetz.",
                "Viewing Morphology as an Inference Process.",
                "In SIGIR, 1993. [15] D. Lin.",
                "Automatic Retrieval and Clustering of Similar Words.",
                "In COLING-ACL, 1998. [16] J.",
                "B. Lovins.",
                "Development of a Stemming Algorithm.",
                "Mechanical Translation and Computational Linguistics, II:22-31, 1968. [17] M. Lennon and D. Peirce and B. Tarry and P. Willett.",
                "An Evaluation of Some Conflation Algorithms for Information Retrieval.",
                "Journal of Information Science, 3:177-188, 1981. [18] M. Porter.",
                "An Algorithm for Suffix Stripping.",
                "Program, 14(3):130-137, 1980. [19] K. M. Risvik, T. Mikolajewski, and P. Boros.",
                "Query Segmentation for Web Search.",
                "In WWW, 2003. [20] S. E. Robertson.",
                "On Term Selection for Query Expansion.",
                "Journal of Documentation, 46(4):359-364, 1990. [21] G. Salton and C. Buckley.",
                "Improving Retrieval Performance by Relevance Feedback.",
                "JASIS, 41(4):288 - 297, 1999. [22] R. Sun, C.-H. Ong, and T.-S. Chua.",
                "Mining Dependency Relations for Query Expansion in Passage Retrieval.",
                "In SIGIR, 2006. [23] C. Van Rijsbergen.",
                "Information Retrieval.",
                "Butterworths, second version, 1979. [24] B. V´elez, R. Weiss, M. A. Sheldon, and D. K. Gifford.",
                "Fast and Effective Query Refinement.",
                "In SIGIR, 1997. [25] J. Xu and B. Croft.",
                "Query Expansion using Local and Global Document Analysis.",
                "In SIGIR, 1996. [26] J. Xu and B. Croft.",
                "Corpus-based Stemming using Cooccurrence of Word Variants.",
                "ACM TOIS, 16 (1):61-81, 1998."
            ],
            "original_annotated_samples": [
                "CONTEXT SENSITIVE STEMMING 3.1 Overview Our system has four components as illustrated in Figure 1: <br>candidate generation</br>, query segmentation and head word detection, context sensitive query stemming and context sensitive document matching.",
                "<br>candidate generation</br> (component 1) is performed oﬄine and generated candidates are stored in a dictionary.",
                "Component 4: context sensitive document matching Input Query: and head word detection Component 2: segment Component 1: <br>candidate generation</br> comparisons −> comparison Component 3: selective word expansion decision: comparisons −> comparison example: hotel price comparisons output: hotel comparisons hotel −> hotels Figure 1: System Components 3.2 Expansion <br>candidate generation</br> One of the ways to generate candidates is using the Porter stemmer [18]."
            ],
            "translated_annotated_samples": [
                "STEMMING CONTEXTUAL SENSIBLE 3.1 Resumen Nuestro sistema tiene cuatro componentes como se ilustra en la Figura 1: generación de candidatos, segmentación de consultas y detección de palabras clave, derivación de consultas sensible al contexto y coincidencia de documentos sensible al contexto.",
                "La <br>generación de candidatos</br> (componente 1) se realiza fuera de línea y los candidatos generados se almacenan en un diccionario.",
                "Componente 4: coincidencia de documentos sensibles al contexto Consulta de entrada: y detección de palabras clave Componente 2: segmento Componente 1: <br>generación de candidatos</br> comparaciones −> comparación Componente 3: decisión de expansión selectiva de palabras: comparaciones −> comparación ejemplo: comparaciones de precios de hoteles salida: comparaciones de hoteles hotel −> hoteles Figura 1: Componentes del sistema 3.2 Generación de candidatos de expansión Una de las formas de generar candidatos es utilizando el stemmer de Porter [18]."
            ],
            "translated_text": "Stemming sensible al contexto para la búsqueda web Fuchun Peng Nawaaz Ahmed Xin Li Yumao Lu Yahoo! Tradicionalmente, el truncamiento se ha aplicado a tareas de Recuperación de Información transformando las palabras en documentos a su forma raíz antes de indexarlas, y aplicando una transformación similar a los términos de consulta. Aunque aumenta la recuperación, esta estrategia ingenua no funciona bien para la Búsqueda en la Web, ya que disminuye la precisión y requiere una cantidad significativa de cálculos adicionales. En este artículo, proponemos un método de derivación sensible al contexto que aborda estos dos problemas. Dos propiedades únicas hacen que nuestro enfoque sea factible para la Búsqueda en la Web. Primero, basados en modelado estadístico del lenguaje, realizamos un análisis sensible al contexto en el lado de la consulta. Predecimos con precisión cuál de sus variantes morfológicas es útil para expandir un término de consulta antes de enviar la consulta al motor de búsqueda. Esto reduce drásticamente la cantidad de expansiones incorrectas, lo que a su vez disminuye el costo de la computación adicional y mejora la precisión al mismo tiempo. Segundo, nuestro enfoque realiza una coincidencia de documentos sensible al contexto para esas variantes ampliadas. Esta estrategia conservadora sirve como salvaguarda contra el truncamiento espurio, y resulta ser muy importante para mejorar la precisión. Usando el manejo de la pluralización de palabras como un ejemplo de nuestro enfoque de derivación, nuestros experimentos en un importante motor de búsqueda web muestran que al derivar solo el 29% del tráfico de consultas, podemos mejorar la relevancia medida por la Ganancia Acumulativa Descontada promedio (DCG5) en un 6.1% en estas consultas y en un 1.8% sobre todo el tráfico de consultas. Categorías y Descriptores de Asignaturas H.3.3 [Sistemas de Información]: Almacenamiento y Recuperación de Información-Formulación de Consultas Términos Generales Algoritmos, Experimentación 1. INTRODUCCIÓN La búsqueda en la web se ha convertido en una herramienta importante en nuestra vida diaria para buscar información. Uno de los problemas importantes en la búsqueda web es que las consultas de los usuarios a menudo no están formuladas de la mejor manera para obtener resultados óptimos. Por ejemplo, \"zapatilla para correr\" es una consulta que ocurre con frecuencia en los registros de consulta. Sin embargo, es mucho más probable que la búsqueda \"zapatillas para correr\" proporcione mejores resultados de búsqueda que la consulta original, ya que los documentos que coinciden con la intención de esta consulta suelen contener las palabras \"zapatillas para correr\". Formular correctamente una consulta requiere que el usuario prediga con precisión qué forma de palabra se utiliza en los documentos que mejor satisfacen sus necesidades de información. Esto es difícil incluso para usuarios experimentados, y especialmente difícil para hablantes no nativos. Una solución tradicional es utilizar el stemming [16, 18], el proceso de transformar palabras flexionadas o derivadas a su forma raíz para que un término de búsqueda coincida y recupere documentos que contengan todas las formas del término. Por lo tanto, la palabra \"run\" coincidirá con \"running\", \"ran\", \"runs\", y \"shoe\" coincidirá con \"shoes\" y \"shoeing\". El truncamiento se puede realizar tanto en los términos de un documento durante la indexación (y aplicando la misma transformación a los términos de la consulta durante el procesamiento de la consulta) o expandiendo la consulta con las variantes durante el procesamiento de la consulta. El truncamiento durante la indexación permite muy poca flexibilidad durante el procesamiento de consultas, mientras que el truncamiento mediante la expansión de consultas permite manejar cada consulta de manera diferente, y por lo tanto es preferible. Aunque el truncamiento tradicional aumenta la recuperación al emparejar variantes de palabras [13], puede reducir la precisión al recuperar demasiados documentos que han sido emparejados incorrectamente. Al examinar los resultados de aplicar el truncamiento a un gran número de consultas, generalmente se encuentra que casi igual cantidad de consultas se benefician y se ven perjudicadas por la técnica [6]. Además, reduce el rendimiento del sistema porque el motor de búsqueda tiene que hacer coincidir todas las variantes de palabras. Como mostraremos en los experimentos, esto es cierto incluso si simplificamos el proceso de derivación a la manipulación de pluralización, que es el proceso de convertir una palabra de su forma plural a singular, o viceversa. Por lo tanto, es necesario ser muy cauteloso al utilizar el stemming en los motores de búsqueda web. Un problema del truncamiento tradicional es su transformación ciega de todos los términos de consulta, es decir, siempre realiza la misma transformación para la misma palabra de consulta sin considerar el contexto de la palabra. Por ejemplo, la palabra \"book\" tiene cuatro formas: book, books, booking, booked, y la palabra \"store\" tiene cuatro formas: store, stores, storing, stored. Para la consulta de la librería, expandir ambas palabras a todas sus variantes aumenta significativamente el costo de computación y perjudica la precisión, ya que no todas las variantes son útiles para esta consulta. Transformar librería para que coincida con librerías está bien, pero hacer coincidir almacenamiento de libros o tienda de reservas no lo está. Un método de ponderación que otorga pesos más pequeños a las palabras variantes alivia los problemas hasta cierto punto si los pesos reflejan con precisión la importancia de la variante en esta consulta particular. Sin embargo, el peso uniforme no va a funcionar y un peso dependiente de la consulta sigue siendo un problema desafiante sin resolver [20]. Un segundo problema del truncamiento tradicional es su emparejamiento ciego de todas las ocurrencias en los documentos. Para la consulta de la librería, una transformación que permita que las tiendas variantes se emparejen hará que cada aparición de tiendas en el documento se trate de manera equivalente al término de consulta tienda. Por lo tanto, se emparejará un documento que contenga el fragmento de leer un libro en las cafeterías, lo que provocará que se seleccionen muchos documentos incorrectos. Aunque esperamos que la función de clasificación pueda manejar correctamente estos, con muchos más candidatos para clasificar, el riesgo de cometer errores aumenta. Para aliviar estos dos problemas, proponemos un enfoque de reducción de palabras raíz sensible al contexto para la búsqueda en la web. Nuestra solución consiste en dos análisis contextuales sensibles, uno en el lado de la consulta y otro en el lado del documento. En el lado de la consulta, proponemos un enfoque basado en modelado del lenguaje estadístico para predecir qué variantes de palabras son mejores formas que la palabra original con fines de búsqueda y expandir la consulta solo con esas formas. En el lado del documento, proponemos un emparejamiento conservador sensible al contexto para las variantes de palabras transformadas, solo emparejando las ocurrencias en el documento en el contexto de otros términos en la consulta. Nuestro modelo es simple pero efectivo y eficiente, lo que lo hace factible de ser utilizado en motores de búsqueda web comerciales reales. Utilizamos el manejo de pluralización como un ejemplo continuo para nuestro enfoque de derivación. La motivación para usar el manejo de pluralización como ejemplo es mostrar que incluso un truncamiento tan simple, si se maneja correctamente, puede brindar beneficios significativos a la relevancia de la búsqueda. Hasta donde sabemos, ninguna investigación previa ha investigado sistemáticamente el uso de la pluralización en la búsqueda en la web. Como debemos señalar, el método que proponemos no se limita al manejo de la pluralización, es una técnica de derivación general y también se puede aplicar a la expansión de consultas en general. Los experimentos sobre el truncamiento general producen mejoras significativas adicionales sobre el manejo de la pluralización para consultas largas, aunque los detalles no se informarán en este artículo. En el resto del documento, primero presentamos el trabajo relacionado y distinguimos nuestro método de trabajos anteriores en la Sección 2. Describimos los detalles del enfoque de derivación sensible al contexto en la Sección 3. Luego realizamos experimentos extensos en un importante motor de búsqueda web para respaldar nuestras afirmaciones en la Sección 4, seguidos de discusiones en la Sección 5. Finalmente, concluimos el artículo en la Sección 6.2. TRABAJO RELACIONADO El stemming es una tecnología estudiada desde hace mucho tiempo. Se han desarrollado muchos stemmers, como el stemmer Lovins [16] y el stemmer Porter [18]. El stemmer de Porter es ampliamente utilizado debido a su simplicidad y efectividad en muchas aplicaciones. Sin embargo, el algoritmo de Porter comete muchos errores porque sus reglas simples no pueden describir completamente la morfología del inglés. El análisis de corpus se utiliza para mejorar el stemmer de Porter [26] mediante la creación de clases de equivalencia para palabras que son morfológicamente similares y que ocurren en un contexto similar, medido por la información mutua esperada [23]. Utilizamos un enfoque de corpus similar para el stemming al calcular la similitud entre dos palabras basada en sus características de contexto distribucional, que pueden ser más que solo palabras adyacentes [15], y luego solo mantenemos las palabras morfológicamente similares como candidatas. El uso de la derivación en la recuperación de información también es una técnica bien conocida [8, 10]. Sin embargo, se informó previamente que la efectividad del truncamiento para los sistemas de consulta en inglés era bastante limitada. Lennon et al. [17] compararon los algoritmos de Lovins y Porter y encontraron poco mejoramiento en el rendimiento de recuperación. Más tarde, Harman [9] compara tres técnicas generales de derivación en experimentos de recuperación de texto, incluido el manejo de pluralización (llamado S stemmer en el artículo). También propusieron el truncamiento selectivo basado en la longitud de la consulta y la importancia del término, pero no se informaron resultados positivos. Por otro lado, Krovetz [14] realizó comparaciones sobre un pequeño número de documentos (de 400 a 12k) y mostró una mejora dramática en la precisión (de hasta un 45%). Sin embargo, debido al número limitado de consultas probadas (menos de 100) y al tamaño reducido de la colección, los resultados son difíciles de generalizar para la búsqueda en la web. Estos resultados mixtos, en su mayoría fracasos, llevaron a los primeros investigadores de IR a considerar que el truncamiento era irrelevante en general para el inglés [4], aunque investigaciones recientes han demostrado que el truncamiento tiene mayores beneficios para la recuperación en otros idiomas [2]. Sospechamos que los fracasos anteriores se debieron principalmente a los dos problemas que mencionamos en la introducción. El stemming ciego, o un stemming selectivo basado en la longitud de la consulta como se utiliza en [9], no es suficiente. El truncamiento debe decidirse caso por caso, no solo a nivel de consulta sino también a nivel de documento. Como demostraremos, si se maneja correctamente, se puede lograr una mejora significativa. Un problema más general relacionado con el stemming es la reformulación de consultas [3, 12] y la expansión de consultas que amplía las palabras no solo con variantes de palabras [7, 22, 24, 25]. Para decidir qué palabras expandidas usar, las personas a menudo utilizan técnicas de retroalimentación de seudorelevancia que envían la consulta original a un motor de búsqueda y recuperan los documentos principales, extraen palabras relevantes de estos documentos principales como palabras de consulta adicionales y vuelven a enviar la consulta expandida nuevamente [21]. Esto normalmente requiere enviar una consulta varias veces al motor de búsqueda y no es rentable para procesar la gran cantidad de consultas involucradas en la búsqueda web. Además, la expansión de consultas, incluida la reformulación de consultas [3, 12], tiene un alto riesgo de cambiar la intención del usuario (llamado desviación de consulta). Dado que las palabras expandidas pueden tener diferentes significados, agregarlas a la consulta podría potencialmente cambiar la intención de la consulta original. Por lo tanto, la expansión de consultas basada en pseudorelevancia y la reformulación de consultas pueden proporcionar sugerencias a los usuarios para su refinamiento interactivo, pero difícilmente pueden ser utilizadas directamente para la búsqueda en la web. Por otro lado, el truncamiento es mucho más conservador ya que la mayoría de las veces, conserva la intención de búsqueda original. Si bien la mayoría de los trabajos sobre la expansión de consultas se centran en mejorar la recuperación, nuestro trabajo se enfoca en aumentar tanto la recuperación como la precisión. El aumento en el recuerdo es evidente. Con el stemming de calidad, los buenos documentos que no fueron seleccionados antes del stemming serán promovidos y aquellos documentos de baja calidad serán degradados. En la expansión selectiva de consultas, Cronen-Townsend et al. [6] propusieron un método para la expansión selectiva de consultas basado en comparar la divergencia de Kullback-Leibler de los resultados de la consulta no expandida y los resultados de la consulta expandida. Esto es similar a la retroalimentación de relevancia en el sentido de que requiere múltiples pasadas de recuperación. Si una palabra puede expandirse en varias palabras, se requiere ejecutar este proceso varias veces para decidir cuál palabra expandida es útil. Es costoso implementar esto en motores de búsqueda web en producción. Nuestro método predice la calidad de la expansión basándose en información sin conexión sin enviar la consulta a un motor de búsqueda. En resumen, proponemos un enfoque novedoso para abordar un problema antiguo, pero aún importante y desafiante para la búsqueda en la web: el stemming. Nuestro enfoque es único en el sentido de que realiza el truncamiento predictivo de forma individualizada para cada consulta sin retroalimentación de relevancia de la Web, utilizando el contexto de las variantes en los documentos para preservar la precisión. Es simple, pero muy eficiente y efectivo, lo que hace factible el truncamiento en tiempo real para la búsqueda en la web. Nuestros resultados confirmarán a los investigadores que el truncamiento es realmente muy importante para la recuperación de información a gran escala. STEMMING CONTEXTUAL SENSIBLE 3.1 Resumen Nuestro sistema tiene cuatro componentes como se ilustra en la Figura 1: generación de candidatos, segmentación de consultas y detección de palabras clave, derivación de consultas sensible al contexto y coincidencia de documentos sensible al contexto. La <br>generación de candidatos</br> (componente 1) se realiza fuera de línea y los candidatos generados se almacenan en un diccionario. Para una consulta de entrada, primero segmentamos la consulta en conceptos y detectamos la palabra principal de cada concepto (componente 2). Luego utilizamos modelado de lenguaje estadístico para decidir si una variante particular es útil (componente 3), y finalmente, para las variantes expandidas, realizamos un emparejamiento de documentos sensible al contexto (componente 4). A continuación discutimos cada uno de los componentes con más detalle. Componente 4: coincidencia de documentos sensibles al contexto Consulta de entrada: y detección de palabras clave Componente 2: segmento Componente 1: <br>generación de candidatos</br> comparaciones −> comparación Componente 3: decisión de expansión selectiva de palabras: comparaciones −> comparación ejemplo: comparaciones de precios de hoteles salida: comparaciones de hoteles hotel −> hoteles Figura 1: Componentes del sistema 3.2 Generación de candidatos de expansión Una de las formas de generar candidatos es utilizando el stemmer de Porter [18]. El stemmer de Porter simplemente utiliza reglas morfológicas para convertir una palabra a su forma base. No tiene conocimiento del significado semántico de las palabras y a veces comete errores graves, como cambiar \"executive\" por \"execution\", \"news\" por \"new\" y \"paste\" por \"past\". Una forma más conservadora se basa en utilizar análisis de corpus para mejorar los resultados del stemmer de Porter [26]. El análisis de corpus que realizamos se basa en la similitud distribucional de palabras [15]. La razón de utilizar la similitud distribucional de palabras es que las variantes verdaderas tienden a ser utilizadas en contextos similares. En el cálculo de similitud de palabras distribucionales, cada palabra se representa con un vector de características derivadas del contexto de la palabra. Utilizamos los bigramas a la izquierda y a la derecha de la palabra como sus características de contexto, mediante la extracción de un gran corpus web. La similitud entre dos palabras es la similitud coseno entre los dos vectores de características correspondientes. Las 20 palabras similares a \"desarrollar\" se muestran en la siguiente tabla. rango candidato puntaje rango candidato puntaje 0 desarrollar 1 10 berts 0.119 1 desarrollando 0.339 11 wads 0.116 2 desarrollado 0.176 12 desarrollador 0.107 3 incubadora 0.160 13 promoviendo 0.100 4 desarrolla 0.150 14 desarrollo 0.091 5 desarrollo 0.148 15 reingeniería 0.090 6 tutoría 0.138 16 construir 0.083 7 analizando 0.128 17 construir 0.081 8 desarrollo 0.128 18 educativo 0.081 9 automatización 0.126 19 instituto 0.077 Tabla 1: Los 20 candidatos más similares a la palabra \"desarrollar\". La puntuación de la columna es la puntuación de similitud. Para determinar los candidatos de derivación, aplicamos algunas reglas morfológicas del stemmer de Porter [18] a la lista de similitud. Después de aplicar estas reglas, para la palabra desarrollar, los candidatos de derivación son desarrollando, desarrollado, desarrolla, desarrollo, desarrollo, desarrollador, y desarrollo. Para el propósito de manejo de pluralización, solo se conserva el candidato desarrolla. Una cosa que observamos al observar las palabras distribucionalmente similares es que están estrechamente relacionadas semánticamente. Estas palabras podrían servir como candidatas para la expansión general de consultas, un tema que investigaremos en el futuro. 3.3 Segmentación e identificación de palabras clave Para consultas largas, es bastante importante detectar los conceptos en la consulta y las palabras más importantes para esos conceptos. Primero dividimos una consulta en segmentos, cada segmento representando un concepto que normalmente es una frase nominal. Para cada una de las frases nominales, luego detectamos la palabra más importante a la que llamamos la palabra principal. La segmentación también se utiliza en la coincidencia sensible a documentos (sección 3.5) para hacer cumplir la proximidad. Para dividir una consulta en segmentos, tenemos que definir un criterio para medir la fuerza de la relación entre las palabras. Un método efectivo es utilizar la información mutua como indicador para decidir si dividir o no dos palabras [19]. Utilizamos un registro de 25 millones de consultas y recopilamos las frecuencias de bigramas y unigramas a partir de él. Para cada consulta entrante, calculamos la información mutua de dos palabras adyacentes; si supera un umbral predefinido, no dividimos la consulta entre esas dos palabras y pasamos a la siguiente palabra. Continuamos este proceso hasta que la información mutua entre dos palabras esté por debajo del umbral, luego creamos un límite conceptual aquí. La Tabla 2 muestra algunos ejemplos de segmentación de consultas. La forma ideal de encontrar la palabra principal de un concepto es realizar un análisis sintáctico para determinar la estructura de dependencia de la consulta. El análisis de consultas es más difícil que el análisis de oraciones, ya que muchas consultas no son gramaticales y son muy cortas. Aplicar un analizador entrenado en oraciones de documentos a consultas tendrá un rendimiento deficiente. En nuestra solución, solo utilizamos reglas heurísticas simples, y funciona muy bien en la práctica para el inglés. Para una frase nominal en inglés, la palabra principal suele ser la última palabra no detenida, a menos que la frase siga un patrón particular, como XYZ de/en/a/desde UVW. En tales casos, la palabra principal suele ser la última palabra no detenida de XYZ. 3.4 Expansión de palabras sensibles al contexto Después de detectar cuáles son las palabras más importantes para expandir, debemos decidir si las expansiones serán útiles. Nuestras estadísticas muestran que aproximadamente la mitad de las consultas pueden ser transformadas mediante la pluralización a través de un truncamiento ingenuo. Entre esta mitad, aproximadamente el 25% de las consultas mejoran la relevancia cuando se transforman, la mayoría (alrededor del 50%) no cambian sus 5 resultados principales, y el 25% restante tiene un rendimiento peor. Por lo tanto, es extremadamente importante identificar qué consultas no deben ser truncadas con el fin de maximizar la mejora de relevancia y minimizar el costo de truncamiento. Además, para una consulta con múltiples palabras que pueden ser transformadas, o una palabra con múltiples variantes, no todas las expansiones son útiles. Tomando la comparación de precios de hoteles como ejemplo, decidimos que hotel y comparación de precios son dos conceptos. Las palabras clave hotel y comparación se pueden expandir a hoteles y comparaciones. ¿Son útiles ambas transformaciones? Para probar si una expansión es útil, tenemos que saber si es probable que la consulta expandida obtenga más documentos relevantes de la web, lo cual puede cuantificarse mediante la probabilidad de que la consulta ocurra como una cadena en la web. Cuanto más probable sea que ocurra una consulta en la web, más documentos relevantes puede devolver esta consulta. Ahora todo el problema se convierte en cómo calcular la probabilidad de que ocurra la consulta en la Web. Calcular la probabilidad de que una cadena ocurra en un corpus es un problema bien conocido de modelado del lenguaje. El objetivo del modelado del lenguaje es predecir la probabilidad de secuencias de palabras que ocurren naturalmente, s = w1w2...wN; o más simplemente, asignar una alta probabilidad a las secuencias de palabras que realmente ocurren (y una baja probabilidad a las secuencias de palabras que nunca ocurren). El enfoque más simple y exitoso para el modelado del lenguaje sigue estando basado en el modelo n-gramo. Por la regla de la cadena de probabilidad, se puede escribir la probabilidad de cualquier secuencia de palabras como Pr(w1w2...wN) = ΠY i=1 Pr(wi|w1...wi−1) (1). Un modelo n-grama aproxima esta probabilidad asumiendo que las únicas palabras relevantes para predecir Pr(wi|w1...wi−1) son las n − 1 palabras anteriores; es decir, La probabilidad de una palabra wi dado w1...wi−1 es igual a la probabilidad de wi dado wi−n+1...wi−1. Una estimación directa de máxima verosimilitud de las probabilidades de n-gramas a partir de un corpus se obtiene a partir de la frecuencia observada de cada uno de los patrones Pr(wi|wi−n+1...wi−1) = #(wi−n+1...wi) #(wi−n+1...wi−1) donde #(.) denota el número de ocurrencias de un n-grama específico en el corpus de entrenamiento. Aunque se podría intentar usar modelos de n-gramos simples para capturar dependencias a largo plazo en el lenguaje, intentar hacerlo directamente crea inmediatamente problemas de datos dispersos: Utilizar n-gramos de longitud hasta n implica estimar la probabilidad de eventos de longitud Wn, donde W es el tamaño del vocabulario de palabras. Esto rápidamente abruma los recursos computacionales y de datos modernos incluso para opciones modestas de n (más allá de 3 a 6). Además, debido a la naturaleza de cola pesada del lenguaje (es decir, La ley de Zipf) es probable que uno se encuentre con n-gramas novedosos que nunca fueron observados durante el entrenamiento en ningún corpus de prueba, por lo tanto, algún mecanismo para asignar una probabilidad distinta de cero a los n-gramas novedosos es un problema central e inevitable en la modelización estadística del lenguaje. Un enfoque estándar para suavizar las estimaciones de probabilidad para hacer frente a problemas de datos escasos (y para hacer frente a posibles n-gramas faltantes) es utilizar algún tipo de estimador de retroceso. Pr(wi|wi−n+1...wi−1) = 8 >>< >>: ˆPr(wi|wi−n+1...wi−1), si #(wi−n+1...wi) > 0 β(wi−n+1...wi−1) × Pr(wi|wi−n+2...wi−1), de lo contrario (3) donde ˆPr(wi|wi−n+1...wi−1) = descuento #(wi−n+1...wi) #(wi−n+1...wi−1) (4) es la probabilidad descontada y β(wi−n+1...wi−1) es una constante de normalización β(wi−n+1...wi−1) = 1 − X x∈(wi−n+1...wi−1x) ˆPr(x|wi−n+1...wi−1) 1 − X x∈(wi−n+1...wi−1x) ˆPr(x|wi−n+2...wi−1) (5) La probabilidad descontada (4) se puede calcular con diferentes técnicas de suavizado, incluido el suavizado absoluto, el suavizado de Good-Turing, el suavizado lineal y el suavizado de Witten-Bell [5]. Utilizamos suavizado absoluto en nuestros experimentos. Dado que la probabilidad de una cadena, Pr(w1w2...wN), es un número muy pequeño y difícil de interpretar, utilizamos la entropía, tal como se define a continuación, para puntuar la cadena. Entropía = − 1 N log2 Pr(w1w2...wN ) (6) Ahora volviendo al ejemplo de la comparación de precios de hoteles, hay cuatro variantes de esta consulta, y la entropía de estos cuatro candidatos se muestra en la Tabla 3. Podemos ver que todas las alternativas son menos probables que la consulta de entrada. Por lo tanto, no es útil hacer una expansión para esta consulta. Por otro lado, si la consulta de entrada son comparaciones de precios de hoteles, que es la segunda alternativa en la tabla, entonces hay una mejor alternativa que la consulta de entrada, y por lo tanto debería ser ampliada. Para tolerar las variaciones en la estimación de probabilidad, relajamos el criterio de selección para esas alternativas de consulta si sus puntuaciones están dentro de una cierta distancia (10% en nuestros experimentos) de la mejor puntuación. Variaciones de la consulta Comparación de precios de hoteles 6.177 comparaciones de precios de hoteles 6.597 comparación de precios de hoteles 6.937 comparaciones de precios de hoteles 7.360 Tabla 3: Variaciones de la consulta comparación de precios de hoteles clasificadas por puntaje de entropía, con la consulta original en negrita. 3.5 Coincidencia de documentos sensibles al contexto Aun después de saber qué variantes de palabras son probablemente útiles, debemos ser conservadores en la coincidencia de documentos para las variantes ampliadas. Para la consulta de comparaciones de precios de hoteles, decidimos que la palabra \"comparaciones\" se amplía para incluir \"comparación\". Sin embargo, no todos los casos de comparación en el documento son de interés. Una página que trata sobre comparar el servicio al cliente puede contener todas las palabras comparaciones de precios de hoteles comparación. Esta página no es una buena página para la consulta. Si aceptamos coincidencias de cada ocurrencia de comparación, afectará la precisión de recuperación y esta es una de las principales razones por las que la mayoría de los enfoques de derivación no funcionan bien para la recuperación de información. Para abordar este problema, tenemos una restricción de proximidad que considera el contexto alrededor de la variante expandida en el documento. Una coincidencia de variante se considera válida solo si la variante ocurre en el mismo contexto que la palabra original lo hace. El contexto son los segmentos continuos de la izquierda o de la derecha de la palabra original. Tomando la misma consulta como ejemplo, el contexto de las comparaciones es el precio. La comparación de palabras ampliada solo es válida si está en el mismo contexto de comparaciones, que es después de la palabra precio. Por lo tanto, solo debemos emparejar aquellas ocurrencias de comparación en el documento si ocurren después de la palabra precio. Considerando el hecho de que las consultas y los documentos pueden no representar la intención de la misma manera exacta, relajamos esta restricción de proximidad para permitir ocurrencias variantes dentro de una ventana de un tamaño fijo. Si la comparación de palabras expandidas ocurre dentro del contexto de precio dentro de una ventana, se considera válida. Cuanto más pequeño sea el tamaño de la ventana, más restrictiva será la coincidencia. Utilizamos un tamaño de ventana de 4, que normalmente captura contextos que incluyen las frases nominales que contienen y las adyacentes. 4. EVALUACIÓN EXPERIMENTAL 4.1 Métricas de evaluación Mediremos tanto la mejora de relevancia como el costo de derivación necesario para lograr la relevancia. 1 un segmento de contexto no puede ser una sola palabra de parada. 4.1.1 Medición de relevancia Utilizamos una variante de la Ganancia Acumulada Descontada Promedio (DCG), un esquema recientemente popularizado para medir la relevancia de los motores de búsqueda [1, 11]. Dada una consulta y una lista clasificada de K documentos (K se establece en 5 en nuestros experimentos), el puntaje DCG(K) para esta consulta se calcula de la siguiente manera: DCG(K) = Σ k=1 a K gk log2(1 + k) . (7) donde gk es el peso para el documento en la posición k. Un mayor grado de relevancia corresponde a un peso mayor. Una página se califica en una de las cinco escalas: Perfecto, Excelente, Bueno, Regular, Malo, con pesos correspondientes. Utilizamos DCG para representar el DCG promedio(5) sobre un conjunto de consultas de prueba. 4.1.2 Costo de derivación Otro métrica es medir el costo adicional incurrido por la derivación. Dado el mismo nivel de mejora en la relevancia, preferimos un método de truncamiento que tenga un menor costo adicional. Medimos esto por el porcentaje de consultas que realmente se reducen, sobre todas las consultas que podrían ser reducidas. 4.2 Preparación de datos Muestreamos aleatoriamente 870 consultas de un registro de consultas de tres meses, con 290 de cada mes. Entre todas estas 870 consultas, eliminamos todas las consultas con errores ortográficos ya que las consultas con errores ortográficos no son de interés para el stemming. También eliminamos todas las consultas de una sola palabra, ya que reducir las consultas de una sola palabra sin contexto tiene un alto riesgo de cambiar la intención de la consulta, especialmente para palabras cortas. Al final, tenemos 529 consultas correctamente escritas con al menos 2 palabras. 4.3 Stemming ingenuo para la búsqueda en la Web Antes de explicar en detalle los experimentos y resultados, nos gustaría describir la forma tradicional de usar el stemming para la búsqueda en la Web, conocida como el modelo ingenuo. Esto es para tratar cada variante de palabra equivalente para todas las posibles palabras en la consulta. La consulta de la librería se transformará en (libro O libros)(tienda O tiendas) al limitar el truncamiento al manejo de pluralización solamente, donde O es un operador que denota la equivalencia de los argumentos izquierdo y derecho. 4.4 Configuración experimental El modelo base es el modelo sin truncamiento. Primero ejecutamos el modelo ingenuo para ver qué tan bien se desempeña en comparación con el punto de referencia. Luego mejoramos el modelo de derivación ingenua mediante la coincidencia sensible al documento, denominado modelo de coincidencia sensible al documento. Este modelo realiza el mismo stemming que el modelo ingenuo en el lado de la consulta, pero realiza un emparejamiento conservador en el lado del documento utilizando la estrategia descrita en la sección 3.5. El modelo ingenuo y el modelo de coincidencia sensible al documento son los que mejor responden a la mayoría de las consultas. De las 529 consultas, hay 408 consultas que se originan, lo que corresponde al 46.7% del tráfico de consultas (de un total de 870). Luego mejoramos aún más el modelo de coincidencia sensible de documentos desde el lado de la consulta con un proceso de derivación de palabras selectivo basado en modelado estadístico del lenguaje (sección 3.4), denominado modelo de derivación selectiva. Basado en la predicción del modelado del lenguaje, este modelo deriva solo un subconjunto de las 408 consultas derivadas por el modelo de coincidencia sensible al documento. Experimentamos con un modelo de lenguaje unigrama y un modelo de lenguaje bigrama. Dado que solo nos importa cuánto podemos mejorar el modelo ingenuo, solo utilizaremos estas 408 consultas (todas las consultas que se ven afectadas por el modelo de derivación ingenuo) en los experimentos. Para tener una idea de cómo se desempeñan estos modelos, también tenemos un modelo oráculo que proporciona el rendimiento máximo que un stemmer puede lograr en estos datos. El modelo del oráculo solo expande una palabra si el truncamiento dará mejores resultados. Para analizar la influencia del manejo de la pluralización en diferentes categorías de consultas, dividimos las consultas en consultas cortas y consultas largas. Entre las 408 consultas generadas por el modelo ingenuo, hay 272 consultas cortas con 2 o 3 palabras, y 136 consultas largas con al menos 4 palabras. Resumimos los resultados generales en la Tabla 4, y presentamos los resultados de las consultas cortas y largas por separado en la Tabla 5. Cada fila en la Tabla 4 es una estrategia de derivación descrita en la sección 4.4. La primera columna es el nombre de la estrategia. La segunda columna es el número de consultas afectadas por esta estrategia; esta columna mide el costo de derivación, y los números deberían ser bajos para el mismo nivel de dcg. La tercera columna es la puntuación DCG promedio sobre todas las consultas probadas en esta categoría (incluyendo aquellas que no fueron truncadas por la estrategia). La cuarta columna es la mejora relativa sobre la línea base, y la última columna es el valor p de la prueba de significancia de Wilcoxon. Hay varias observaciones sobre los resultados. Podemos ver que el truncado ingenuo solo logra una mejora estadísticamente insignificante del 1.5%. Mirando la Tabla 5, se observa una mejora del 2.7% en las consultas cortas. Sin embargo, también perjudica las consultas largas en un -2.4%. En general, la mejora se cancela. La razón por la que mejora las consultas cortas es que la mayoría de las consultas cortas solo tienen una palabra que se puede reducir a su raíz. Por lo tanto, pluralizar ciegamente consultas cortas es relativamente seguro. Sin embargo, para consultas largas, la mayoría de las consultas pueden tener varias palabras que pueden ser pluralizadas. Expandir todos ellos sin selección perjudicará significativamente la precisión. La aplicación de un stemming sensible al contexto del documento proporciona un aumento significativo en el rendimiento, desde un 2.7% hasta un 4.2% para consultas cortas y desde un -2.4% hasta un -1.6% para consultas largas, con un aumento general del 1.5% al 2.8%. La mejora proviene de la coincidencia de documentos sensible al contexto conservador. Una palabra expandida es válida solo si ocurre dentro del contexto de la consulta original en el documento. Esto reduce muchas coincidencias falsas. Sin embargo, aún observamos que para consultas largas, el truncamiento sensible al contexto no logra mejorar el rendimiento porque sigue seleccionando demasiados documentos y le presenta a la función de clasificación un problema difícil. Si bien el tamaño de ventana elegido de 4 es el que mejor funciona entre todas las opciones, aún permite coincidencias espurias. Es posible que el tamaño de la ventana deba elegirse según la consulta para garantizar restricciones de proximidad más estrictas para diferentes tipos de frases nominales. La pluralización selectiva de palabras ayuda aún más a resolver el problema enfrentado por el truncamiento sensible al contexto del documento. No se aplica el truncamiento a cada palabra que coloca toda la carga en el algoritmo de clasificación, sino que intenta eliminar el truncamiento innecesario en primer lugar. Al predecir qué variantes de palabras van a ser útiles, podemos reducir drásticamente el número de palabras derivadas, mejorando así tanto la recuperación como la precisión. Con el modelo de lenguaje unigrama, podemos reducir el costo de derivación en un 26.7% (de 408/408 a 300/408) y aumentar la mejora general de DCG del 2.8% al 3.4%. En particular, proporciona mejoras significativas en consultas largas. La ganancia de DCG se cambia de negativa a positiva, de -1.6% a 1.1%. Esto confirma nuestra hipótesis de que reducir la expansión innecesaria de palabras conduce a una mejora en la precisión. Para consultas cortas también observamos tanto la mejora de dcg como la reducción del costo de derivación con el modelo de lenguaje unigrama. Las ventajas de la expansión predictiva de palabras con un modelo de lenguaje se potencian aún más con un mejor modelo de lenguaje de bigrama. La ganancia total de DCG aumenta de 3.4% a 3.9%, y el costo de derivación se reduce drásticamente de 408/408 a 250/408, correspondiente a solo el 29% del tráfico de consultas (250 de 870) y una mejora total de DCG del 1.8% en todo el tráfico de consultas. Para consultas cortas, el modelo de lenguaje de bigrama mejora la ganancia de DCG del 4.4% al 4.7%, y reduce el costo de derivación de 272/272 a 150/272. Para consultas largas, el modelo de lenguaje de bigrama mejora la ganancia de DCG del 1.1% al 2.5%, y reduce el costo de derivación de 136/136 a 100/136. Observamos que el modelo de lenguaje de bigrama proporciona un mayor aumento para consultas largas. Esto se debe a que la incertidumbre en las consultas largas es mayor y se necesita un modelo de lenguaje más potente. Hacemos la hipótesis de que un modelo de lenguaje de trigramas proporcionaría un impulso adicional para consultas largas y dejamos esto para investigaciones futuras. Considerando el límite superior estricto de 2 en la mejora que se puede obtener del manejo de la pluralización (a través del modelo oráculo), el rendimiento actual en consultas cortas es muy satisfactorio. Para consultas breves, la ganancia máxima de DCG es del 6.3% para el manejo perfecto de la pluralización, nuestra ganancia actual es del 4.7% con un modelo de lenguaje de bigrama. Para consultas largas, la ganancia máxima de DCG es del 4.6% para el manejo perfecto de la pluralización, nuestra ganancia actual es del 2.5% con un modelo de lenguaje de bigrama. Podríamos obtener beneficios adicionales con un modelo de lenguaje más potente para consultas largas. Sin embargo, las dificultades de las consultas largas provienen de muchos otros aspectos, incluyendo la proximidad y el problema de la segmentación. Estos problemas deben ser abordados por separado. Al observar el límite superior de reducción de gastos generales para el truncamiento de Oracle, el 75% (308/408) de los truncamientos ingenuos son inútiles. Actualmente capturamos alrededor de la mitad de ellos. La reducción adicional de los gastos generales requiere sacrificar la ganancia de la DCG. Ahora podemos comparar las estrategias de derivación desde un aspecto diferente. En lugar de analizar la influencia sobre todas las consultas como describimos anteriormente, la Tabla 6 resume las mejoras de DCG solo sobre las consultas afectadas. Podemos ver que el número de consultas afectadas disminuye a medida que la estrategia de derivación se vuelve más precisa (mejora en el dcg). Para el modelo de lenguaje de bigrama, sobre las 250/408 consultas truncadas, la mejora en DCG es del 6.1%. Una observación interesante es que el dcg promedio disminuye con un modelo mejor, lo que indica que una estrategia de derivación mejorada deriva consultas más difíciles (consultas con bajo dcg). 5. Como mencionamos en la Sección 1, estamos tratando de predecir la probabilidad de que una cadena ocurra en la Web. El modelo de lenguaje debe describir la ocurrencia de la cadena en la web. Sin embargo, el registro de consultas también es un buen recurso. Tenga en cuenta que este límite superior es solo para el manejo de pluralización, no para el truncamiento general. El stemming general proporciona un límite superior del 8%, lo cual es bastante sustancial en términos de nuestras métricas. Las consultas afectadas dcg dcg Mejora p-valor línea de base 0/408 7.102 N/A N/A modelo ingenuo 408/408 7.206 1.5% 0.22 modelo sensible al contexto del documento 408/408 7.302 2.8% 0.014 modelo selectivo: unigram LM 300/408 7.321 3.4% 0.001 modelo selectivo: bigram LM 250/408 7.381 3.9% 0.001 modelo oráculo 100/408 7.519 5.9% 0.001 Tabla 4: Comparación de resultados de diferentes estrategias de derivación en todas las consultas afectadas por la derivación ingenua Resultados de Consultas Cortas Consultas Afectadas dcg Mejora p-valor línea de base 0/272 N/A N/A modelo ingenuo 272/272 2.7% 0.48 modelo sensible al contexto del documento 272/272 4.2% 0.002 modelo selectivo: unigram LM 185/272 4.4% 0.001 modelo selectivo: bigram LM 150/272 4.7% 0.001 modelo oráculo 71/272 6.3% 0.001 Resultados de Consultas Largas Consultas Afectadas dcg Mejora p-valor línea de base 0/136 N/A N/A modelo ingenuo 136/136 -2.4% 0.25 modelo sensible al contexto del documento 136/136 -1.6% 0.27 modelo selectivo: unigram LM 115/136 1.1% 0.001 modelo selectivo: bigram LM 100/136 2.5% 0.001 modelo oráculo 29/136 4.6% 0.001 Tabla 5: Comparación de resultados de diferentes estrategias de derivación en consultas cortas y largas en general Los usuarios reformulan una consulta utilizando muchas variantes diferentes para obtener buenos resultados. Para probar la hipótesis de que podemos aprender probabilidades de transformación confiables a partir del registro de consultas, entrenamos un modelo de lenguaje con las mismas 25 millones de consultas principales utilizadas para aprender la segmentación, y lo utilizamos para la predicción. Observamos una ligera disminución en el rendimiento en comparación con el modelo entrenado en frecuencias web. En particular, el rendimiento para el modelo de lenguaje unigrama no se vio afectado, pero la ganancia de dcg para el modelo de lenguaje bigrama cambió de 4.7% a 4.5% para consultas cortas. Por lo tanto, el registro de consultas puede servir como una buena aproximación de las frecuencias web. 5.2 Cómo la lingüística ayuda. Algunos conocimientos lingüísticos son útiles en el stemming. Para el manejo de la pluralización, la pluralización y la despluralización no son simétricas. Una palabra en plural utilizada en una consulta indica una intención especial. Por ejemplo, la consulta hoteles en Nueva York está buscando una lista de hoteles en Nueva York, no el hotel específico de Nueva York que podría estar ubicado en California. Una simple equivalencia de hotel a hoteles podría impulsar una página en particular sobre hoteles en Nueva York al primer puesto. Para capturar esta intención, tenemos que asegurarnos de que el documento sea una página general sobre hoteles en Nueva York. Esto lo hacemos exigiendo que la palabra en plural hoteles aparezca en el documento. Por otro lado, convertir una palabra singular a plural es más seguro ya que una página de propósito general normalmente contiene información específica. Observamos una ligera disminución general en el dcg, aunque no estadísticamente significativa, para el stemming sensible al contexto del documento si no consideramos esta propiedad asimétrica. Análisis de errores. Un tipo de errores que notamos, aunque raros pero que afectan seriamente la relevancia, es el cambio de intención de búsqueda después del stemming. En general, la pluralización o despluralización mantiene la intención original. Sin embargo, la intención podría cambiar en algunos casos. Por ejemplo, para una consulta de este tipo, trabajo en Apple, pluralizamos trabajo a trabajos. Este truncamiento hace que la consulta original sea ambigua. El trabajo de consulta O trabajos en Apple tiene dos intenciones. Una de las oportunidades laborales en Apple, y otra es una persona que trabaja en Apple, Steve Jobs, quien es el CEO y cofundador de la empresa. Por lo tanto, los resultados después de la reducción de consultas devuelven a Steve Jobs como uno de los resultados en el top 5. Una solución es realizar un análisis basado en el conjunto de resultados para verificar si la intención ha cambiado. Esto es similar a la retroalimentación de relevancia y requiere una clasificación en la segunda fase. Un segundo tipo de errores es el problema de reconocimiento de entidades/conceptos. Estos incluyen dos tipos. Una de ellas es que la variante de la palabra derivada ahora coincide con parte de una entidad o concepto. Por ejemplo, la consulta \"cookies en San Francisco\" se pluraliza como \"cookies\" O \"cookie en San Francisco\". Los resultados coincidirán con el tarro de galletas en San Francisco. Aunque \"cookie\" todavía significa lo mismo que \"galletas\", el concepto de \"cookie jar\" es diferente. Otro tipo es la palabra no derivada que coincide con una entidad o concepto debido al truncamiento de las otras palabras. Por ejemplo, la cita ICE se pluraliza como cita OR citas ICE. La intención original de esta consulta es buscar la cotización de acciones para el símbolo ICE. Sin embargo, notamos que entre los resultados principales, uno de los resultados es Citas sobre comida: Helado. Esto se empareja debido a las consultas afectadas dcg antiguas nuevas dcg dcg Mejora del modelo ingenuo 408/408 7.102 7.206 1.5% modelo sensible al contexto del documento 408/408 7.102 7.302 2.8% modelo selectivo: unigram LM 300/408 5.904 6.187 4.8% modelo selectivo: bigram LM 250/408 5.551 5.891 6.1% Tabla 6: Comparación de resultados solo sobre las consultas derivadas: la columna dcg antigua/nueva es la puntuación dcg sobre las consultas afectadas antes/después de aplicar la pluralización de la palabra entre comillas. La palabra inalterada ICE coincide con parte de la frase nominal helado aquí. Para resolver este tipo de problema, tenemos que analizar los documentos y reconocer \"cookie jar\" y \"ice cream\" como conceptos en lugar de dos palabras independientes. Un tercer tipo de errores ocurre en consultas largas. Para la consulta de software lector de códigos de barras, se pluralizan dos palabras. Códigos y lector. De hecho, el lector de códigos de barras en la consulta original es un concepto sólido y las palabras internas no deben ser cambiadas. Este es el problema de segmentación y detección de entidades y frases nominales en consultas, el cual estamos abordando activamente. Para consultas largas, debemos identificar correctamente los conceptos en la consulta y aumentar la proximidad de las palabras dentro de un concepto. 6. CONCLUSIONES Y TRABAJOS FUTUROS Hemos presentado una forma simple pero elegante de derivar palabras para la búsqueda en la web. Mejora el stemming ingenuo en dos aspectos: la expansión selectiva de palabras en el lado de la consulta y la coincidencia conservadora de ocurrencias de palabras en el lado del documento. Usando el manejo de pluralización como ejemplo, experimentos con datos de un motor de búsqueda web importante muestran que mejora significativamente la relevancia web y reduce el costo de derivación. También mejora significativamente la tasa de clics en la web (detalles no reportados en el artículo). Para el trabajo futuro, estamos investigando los problemas que identificamos en la sección de análisis de errores. Estos incluyen: errores de concordancia entre entidades y frases nominales, y una segmentación mejorada. 7. REFERENCIAS [1] E. Agichtein, E. Brill y S. T. Dumais. Mejorando la clasificación de búsqueda web al incorporar información sobre el comportamiento del usuario. En SIGIR, 2006. [2] E. Airio. Normalización de palabras y descomposición en IR monolingüe y bilingüe. Recuperación de información, 9:249-271, 2006. [3] P. Anick. Utilizando retroalimentación terminológica para el refinamiento de la búsqueda web: un estudio basado en registros. En SIGIR, 2003. [4] R. Baeza-Yates y B. Ribeiro-Neto. Recuperación de información moderna. ACM Press/Addison Wesley, 1999. [5] S. Chen y J. Goodman. Un estudio empírico de técnicas de suavizado para modelado del lenguaje. Informe técnico TR-10-98, Universidad de Harvard, 1998. [6] S. Cronen-Townsend, Y. Zhou y B. Croft. Un marco para la expansión selectiva de consultas. En CIKM, 2004. [7] H. Fang y C. Zhai. Coincidencia de términos semánticos en enfoques axiomáticos para la recuperación de información. En SIGIR, 2006. [8] W. B. Frakes. Confluencia de términos para la recuperación de información. En C. J. Rijsbergen, editor, Investigación y Desarrollo en Recuperación de Información, páginas 383-389. Cambridge University Press, 1984. [9] D. Harman.\nCambridge University Press, 1984. [9] D. Harman. ¿Qué tan efectivo es el sufijado? JASIS, 42(1):7-15, 1991. [10] D. Hull.\nJASIS, 42(1):7-15, 1991. [10] D. Hull. Algoritmos de derivación: un estudio de caso para una evaluación detallada. JASIS, 47(1):70-84, 1996. [11] K. Jarvelin y J. Kekalainen. Evaluación basada en la ganancia acumulada de técnicas de RI. ACM TOIS, 20:422-446, 2002. [12] R. Jones, B. Rey, O. Madani y W. Greiner. Generando Sustituciones de Consultas. En WWW, 2006. [13] W. Kraaij y R. Pohlmann. Viendo el Stemming como Mejora de la Recuperación. En SIGIR, 1996. [14] R. Krovetz. Viendo la morfología como un proceso de inferencia. En SIGIR, 1993. [15] D. Lin. Recuperación automática y agrupamiento de palabras similares. En COLING-ACL, 1998. [16] J. B. Lovins. Desarrollo de un algoritmo de derivación. Traducción Mecánica y Lingüística Computacional, II:22-31, 1968. [17] M. Lennon, D. Peirce, B. Tarry y P. Willett. Una evaluación de algunos algoritmos de confluencia para la recuperación de información. Revista de Ciencia de la Información, 3:177-188, 1981. [18] M. Porter. Un algoritmo para el recorte de sufijos. Programa, 14(3):130-137, 1980. [19] K. M. Risvik, T. Mikolajewski y P. Boros. Segmentación de consultas para búsqueda web. En WWW, 2003. [20] S. E. Robertson. Selección de términos para la expansión de consultas. Revista de Documentación, 46(4):359-364, 1990. [21] G. Salton y C. Buckley. Mejorando el rendimiento de recuperación mediante retroalimentación de relevancia. JASIS, 41(4):288 - 297, 1999. [22] R. Sun, C.-H. Ong, y T.-S. Chua. Extracción de relaciones de dependencia para la expansión de consultas en la recuperación de pasajes. En SIGIR, 2006. [23] C. Van Rijsbergen. Recuperación de información. Butterworths, segunda versión, 1979. [24] B. Vélez, R. Weiss, M. A. Sheldon y D. K. Gifford. Refinamiento de consultas rápido y efectivo. En SIGIR, 1997. [25] J. Xu y B. Croft. Expansión de consultas utilizando análisis local y global de documentos. En SIGIR, 1996. [26] J. Xu y B. Croft. Extracción de raíces basada en corpus utilizando la coocurrencia de variantes de palabras. ACM TOIS, 16 (1):61-81, 1998. ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "query segmentation": {
            "translated_key": "segmentación de consultas",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Context Sensitive Stemming for Web Search Fuchun Peng Nawaaz Ahmed Xin Li Yumao Lu Yahoo!",
                "Inc. 701 First Avenue Sunnyvale, California 94089 {fuchun, nawaaz, xinli, yumaol}@yahoo-inc.com ABSTRACT Traditionally, stemming has been applied to Information Retrieval tasks by transforming words in documents to the their root form before indexing, and applying a similar transformation to query terms.",
                "Although it increases recall, this naive strategy does not work well for Web Search since it lowers precision and requires a significant amount of additional computation.",
                "In this paper, we propose a context sensitive stemming method that addresses these two issues.",
                "Two unique properties make our approach feasible for Web Search.",
                "First, based on statistical language modeling, we perform context sensitive analysis on the query side.",
                "We accurately predict which of its morphological variants is useful to expand a query term with before submitting the query to the search engine.",
                "This dramatically reduces the number of bad expansions, which in turn reduces the cost of additional computation and improves the precision at the same time.",
                "Second, our approach performs a context sensitive document matching for those expanded variants.",
                "This conservative strategy serves as a safeguard against spurious stemming, and it turns out to be very important for improving precision.",
                "Using word pluralization handling as an example of our stemming approach, our experiments on a major Web search engine show that stemming only 29% of the query traffic, we can improve relevance as measured by average Discounted Cumulative Gain (DCG5) by 6.1% on these queries and 1.8% over all query traffic.",
                "Categories and Subject Descriptors H.3.3 [Information Systems]: Information Storage and Retrieval-Query formulation General Terms Algorithms, Experimentation 1.",
                "INTRODUCTION Web search has now become a major tool in our daily lives for information seeking.",
                "One of the important issues in Web search is that user queries are often not best formulated to get optimal results.",
                "For example, running shoe is a query that occurs frequently in query logs.",
                "However, the query running shoes is much more likely to give better search results than the original query because documents matching the intent of this query usually contain the words running shoes.",
                "Correctly formulating a query requires the user to accurately predict which word form is used in the documents that best satisfy his or her information needs.",
                "This is difficult even for experienced users, and especially difficult for non-native speakers.",
                "One traditional solution is to use stemming [16, 18], the process of transforming inflected or derived words to their root form so that a search term will match and retrieve documents containing all forms of the term.",
                "Thus, the word run will match running, ran, runs, and shoe will match shoes and shoeing.",
                "Stemming can be done either on the terms in a document during indexing (and applying the same transformation to the query terms during query processing) or by expanding the query with the variants during query processing.",
                "Stemming during indexing allows very little flexibility during query processing, while stemming by query expansion allows handling each query differently, and hence is preferred.",
                "Although traditional stemming increases recall by matching word variants [13], it can reduce precision by retrieving too many documents that have been incorrectly matched.",
                "When examining the results of applying stemming to a large number of queries, one usually finds that nearly equal numbers of queries are helped and hurt by the technique [6].",
                "In addition, it reduces system performance because the search engine has to match all the word variants.",
                "As we will show in the experiments, this is true even if we simplify stemming to pluralization handling, which is the process of converting a word from its plural to singular form, or vice versa.",
                "Thus, one needs to be very cautious when using stemming in Web search engines.",
                "One problem of traditional stemming is its blind transformation of all query terms, that is, it always performs the same transformation for the same query word without considering the context of the word.",
                "For example, the word book has four forms book, books, booking, booked, and store has four forms store, stores, storing, stored.",
                "For the query book store, expanding both words to all of their variants significantly increases computation cost and hurts precision, since not all of the variants are useful for this query.",
                "Transforming book store to match book stores is fine, but matching book storing or booking store is not.",
                "A weighting method that gives variant words smaller weights alleviates the problems to a certain extent if the weights accurately reflect the importance of the variant in this particular query.",
                "However uniform weighting is not going to work and a query dependent weighting is still a challenging unsolved problem [20].",
                "A second problem of traditional stemming is its blind matching of all occurrences in documents.",
                "For the query book store, a transformation that allows the variant stores to be matched will cause every occurrence of stores in the document to be treated equivalent to the query term store.",
                "Thus, a document containing the fragment reading a book in coffee stores will be matched, causing many wrong documents to be selected.",
                "Although we hope the ranking function can correctly handle these, with many more candidates to rank, the risk of making mistakes increases.",
                "To alleviate these two problems, we propose a context sensitive stemming approach for Web search.",
                "Our solution consists of two context sensitive analysis, one on the query side and the other on the document side.",
                "On the query side, we propose a statistical language modeling based approach to predict which word variants are better forms than the original word for search purpose and expanding the query with only those forms.",
                "On the document side, we propose a conservative context sensitive matching for the transformed word variants, only matching document occurrences in the context of other terms in the query.",
                "Our model is simple yet effective and efficient, making it feasible to be used in real commercial Web search engines.",
                "We use pluralization handling as a running example for our stemming approach.",
                "The motivation for using pluralization handling as an example is to show that even such simple stemming, if handled correctly, can give significant benefits to search relevance.",
                "As far as we know, no previous research has systematically investigated the usage of pluralization in Web search.",
                "As we have to point out, the method we propose is not limited to pluralization handling, it is a general stemming technique, and can also be applied to general query expansion.",
                "Experiments on general stemming yield additional significant improvements over pluralization handling for long queries, although details will not be reported in this paper.",
                "In the rest of the paper, we first present the related work and distinguish our method from previous work in Section 2.",
                "We describe the details of the context sensitive stemming approach in Section 3.",
                "We then perform extensive experiments on a major Web search engine to support our claims in Section 4, followed by discussions in Section 5.",
                "Finally, we conclude the paper in Section 6. 2.",
                "RELATED WORK Stemming is a long studied technology.",
                "Many stemmers have been developed, such as the Lovins stemmer [16] and the Porter stemmer [18].",
                "The Porter stemmer is widely used due to its simplicity and effectiveness in many applications.",
                "However, the Porter stemming makes many mistakes because its simple rules cannot fully describe English morphology.",
                "Corpus analysis is used to improve Porter stemmer [26] by creating equivalence classes for words that are morphologically similar and occur in similar context as measured by expected mutual information [23].",
                "We use a similar corpus based approach for stemming by computing the similarity between two words based on their distributional context features which can be more than just adjacent words [15], and then only keep the morphologically similar words as candidates.",
                "Using stemming in information retrieval is also a well known technique [8, 10].",
                "However, the effectiveness of stemming for English query systems was previously reported to be rather limited.",
                "Lennon et al. [17] compared the Lovins and Porter algorithms and found little improvement in retrieval performance.",
                "Later, Harman [9] compares three general stemming techniques in text retrieval experiments including pluralization handing (called S stemmer in the paper).",
                "They also proposed selective stemming based on query length and term importance, but no positive results were reported.",
                "On the other hand, Krovetz [14] performed comparisons over small numbers of documents (from 400 to 12k) and showed dramatic precision improvement (up to 45%).",
                "However, due to the limited number of tested queries (less than 100) and the small size of the collection, the results are hard to generalize to Web search.",
                "These mixed results, mostly failures, led early IR researchers to deem stemming irrelevant in general for English [4], although recent research has shown stemming has greater benefits for retrieval in other languages [2].",
                "We suspect the previous failures were mainly due to the two problems we mentioned in the introduction.",
                "Blind stemming, or a simple query length based selective stemming as used in [9] is not enough.",
                "Stemming has to be decided on case by case basis, not only at the query level but also at the document level.",
                "As we will show, if handled correctly, significant improvement can be achieved.",
                "A more general problem related to stemming is query reformulation [3, 12] and query expansion which expands words not only with word variants [7, 22, 24, 25].",
                "To decide which expanded words to use, people often use pseudorelevance feedback techniquesthat send the original query to a search engine and retrieve the top documents, extract relevant words from these top documents as additional query words, and resubmit the expanded query again [21].",
                "This normally requires sending a query multiple times to search engine and it is not cost effective for processing the huge amount of queries involved in Web search.",
                "In addition, query expansion, including query reformulation [3, 12], has a high risk of changing the user intent (called query drift).",
                "Since the expanded words may have different meanings, adding them to the query could potentially change the intent of the original query.",
                "Thus query expansion based on pseudorelevance and query reformulation can provide suggestions to users for interactive refinement but can hardly be directly used for Web search.",
                "On the other hand, stemming is much more conservative since most of the time, stemming preserves the original search intent.",
                "While most work on query expansion focuses on recall enhancement, our work focuses on increasing both recall and precision.",
                "The increase on recall is obvious.",
                "With quality stemming, good documents which were not selected before stemming will be pushed up and those low quality documents will be degraded.",
                "On selective query expansion, Cronen-Townsend et al. [6] proposed a method for selective query expansion based on comparing the Kullback-Leibler divergence of the results from the unexpanded query and the results from the expanded query.",
                "This is similar to the relevance feedback in the sense that it requires multiple passes retrieval.",
                "If a word can be expanded into several words, it requires running this process multiple times to decide which expanded word is useful.",
                "It is expensive to deploy this in production Web search engines.",
                "Our method predicts the quality of expansion based on oﬄine information without sending the query to a search engine.",
                "In summary, we propose a novel approach to attack an old, yet still important and challenging problem for Web search - stemming.",
                "Our approach is unique in that it performs predictive stemming on a per query basis without relevance feedback from the Web, using the context of the variants in documents to preserve precision.",
                "Its simple, yet very efficient and effective, making real time stemming feasible for Web search.",
                "Our results will affirm researchers that stemming is indeed very important to large scale information retrieval. 3.",
                "CONTEXT SENSITIVE STEMMING 3.1 Overview Our system has four components as illustrated in Figure 1: candidate generation, <br>query segmentation</br> and head word detection, context sensitive query stemming and context sensitive document matching.",
                "Candidate generation (component 1) is performed oﬄine and generated candidates are stored in a dictionary.",
                "For an input query, we first segment query into concepts and detect the head word for each concept (component 2).",
                "We then use statistical language modeling to decide whether a particular variant is useful (component 3), and finally for the expanded variants, we perform context sensitive document matching (component 4).",
                "Below we discuss each of the components in more detail.",
                "Component 4: context sensitive document matching Input Query: and head word detection Component 2: segment Component 1: candidate generation comparisons −> comparison Component 3: selective word expansion decision: comparisons −> comparison example: hotel price comparisons output: hotel comparisons hotel −> hotels Figure 1: System Components 3.2 Expansion candidate generation One of the ways to generate candidates is using the Porter stemmer [18].",
                "The Porter stemmer simply uses morphological rules to convert a word to its base form.",
                "It has no knowledge of the semantic meaning of the words and sometimes makes serious mistakes, such as executive to execution, news to new, and paste to past.",
                "A more conservative way is based on using corpus analysis to improve the Porter stemmer results [26].",
                "The corpus analysis we do is based on word distributional similarity [15].",
                "The rationale of using distributional word similarity is that true variants tend to be used in similar contexts.",
                "In the distributional word similarity calculation, each word is represented with a vector of features derived from the context of the word.",
                "We use the bigrams to the left and right of the word as its context features, by mining a huge Web corpus.",
                "The similarity between two words is the cosine similarity between the two corresponding feature vectors.",
                "The top 20 similar words to develop is shown in the following table. rank candidate score rank candidate score 0 develop 1 10 berts 0.119 1 developing 0.339 11 wads 0.116 2 developed 0.176 12 developer 0.107 3 incubator 0.160 13 promoting 0.100 4 develops 0.150 14 developmental 0.091 5 development 0.148 15 reengineering 0.090 6 tutoring 0.138 16 build 0.083 7 analyzing 0.128 17 construct 0.081 8 developement 0.128 18 educational 0.081 9 automation 0.126 19 institute 0.077 Table 1: Top 20 most similar candidates to word develop.",
                "Column score is the similarity score.",
                "To determine the stemming candidates, we apply a few Porter stemmer [18] morphological rules to the similarity list.",
                "After applying these rules, for the word develop, the stemming candidates are developing, developed, develops, development, developement, developer, developmental.",
                "For the pluralization handling purpose, only the candidate develops is retained.",
                "One thing we note from observing the distributionally similar words is that they are closely related semantically.",
                "These words might serve as candidates for general query expansion, a topic we will investigate in the future. 3.3 Segmentation and headword identification For long queries, it is quite important to detect the concepts in the query and the most important words for those concepts.",
                "We first break a query into segments, each segment representing a concept which normally is a noun phrase.",
                "For each of the noun phrases, we then detect the most important word which we call the head word.",
                "Segmentation is also used in document sensitive matching (section 3.5) to enforce proximity.",
                "To break a query into segments, we have to define a criteria to measure the strength of the relation between words.",
                "One effective method is to use mutual information as an indicator on whether or not to split two words [19].",
                "We use a log of 25M queries and collect the bigram and unigram frequencies from it.",
                "For every incoming query, we compute the mutual information of two adjacent words; if it passes a predefined threshold, we do not split the query between those two words and move on to next word.",
                "We continue this process until the mutual information between two words is below the threshold, then create a concept boundary here.",
                "Table 2 shows some examples of <br>query segmentation</br>.",
                "The ideal way of finding the head word of a concept is to do syntactic parsing to determine the dependency structure of the query.",
                "Query parsing is more difficult than sentence [running shoe] [best] [new york] [medical schools] [pictures] [of] [white house] [cookies] [in] [san francisco] [hotel] [price comparison] Table 2: <br>query segmentation</br>: a segment is bracketed. parsing since many queries are not grammatical and are very short.",
                "Applying a parser trained on sentences from documents to queries will have poor performance.",
                "In our solution, we just use simple heuristics rules, and it works very well in practice for English.",
                "For an English noun phrase, the head word is typically the last nonstop word, unless the phrase is of a particular pattern, like XYZ of/in/at/from UVW.",
                "In such cases, the head word is typically the last nonstop word of XYZ. 3.4 Context sensitive word expansion After detecting which words are the most important words to expand, we have to decide whether the expansions will be useful.",
                "Our statistics show that about half of the queries can be transformed by pluralization via naive stemming.",
                "Among this half, about 25% of the queries improve relevance when transformed, the majority (about 50%) do not change their top 5 results, and the remaining 25% perform worse.",
                "Thus, it is extremely important to identify which queries should not be stemmed for the purpose of maximizing relevance improvement and minimizing stemming cost.",
                "In addition, for a query with multiple words that can be transformed, or a word with multiple variants, not all of the expansions are useful.",
                "Taking query hotel price comparison as an example, we decide that hotel and price comparison are two concepts.",
                "Head words hotel and comparison can be expanded to hotels and comparisons.",
                "Are both transformations useful?",
                "To test whether an expansion is useful, we have to know whether the expanded query is likely to get more relevant documents from the Web, which can be quantified by the probability of the query occurring as a string on the Web.",
                "The more likely a query to occur on the Web, the more relevant documents this query is able to return.",
                "Now the whole problem becomes how to calculate the probability of query to occur on the Web.",
                "Calculating the probability of string occurring in a corpus is a well known language modeling problem.",
                "The goal of language modeling is to predict the probability of naturally occurring word sequences, s = w1w2...wN ; or more simply, to put high probability on word sequences that actually occur (and low probability on word sequences that never occur).",
                "The simplest and most successful approach to language modeling is still based on the n-gram model.",
                "By the chain rule of probability one can write the probability of any word sequence as Pr(w1w2...wN ) = NY i=1 Pr(wi|w1...wi−1) (1) An n-gram model approximates this probability by assuming that the only words relevant to predicting Pr(wi|w1...wi−1) are the previous n − 1 words; i.e.",
                "Pr(wi|w1...wi−1) = Pr(wi|wi−n+1...wi−1) A straightforward maximum likelihood estimate of n-gram probabilities from a corpus is given by the observed frequency of each of the patterns Pr(wi|wi−n+1...wi−1) = #(wi−n+1...wi) #(wi−n+1...wi−1) (2) where #(.) denotes the number of occurrences of a specified gram in the training corpus.",
                "Although one could attempt to use simple n-gram models to capture long range dependencies in language, attempting to do so directly immediately creates sparse data problems: Using grams of length up to n entails estimating the probability of Wn events, where W is the size of the word vocabulary.",
                "This quickly overwhelms modern computational and data resources for even modest choices of n (beyond 3 to 6).",
                "Also, because of the heavy tailed nature of language (i.e.",
                "Zipfs law) one is likely to encounter novel n-grams that were never witnessed during training in any test corpus, and therefore some mechanism for assigning non-zero probability to novel n-grams is a central and unavoidable issue in statistical language modeling.",
                "One standard approach to smoothing probability estimates to cope with sparse data problems (and to cope with potentially missing n-grams) is to use some sort of back-off estimator.",
                "Pr(wi|wi−n+1...wi−1) = 8 >>< >>: ˆPr(wi|wi−n+1...wi−1), if #(wi−n+1...wi) > 0 β(wi−n+1...wi−1) × Pr(wi|wi−n+2...wi−1), otherwise (3) where ˆPr(wi|wi−n+1...wi−1) = discount #(wi−n+1...wi) #(wi−n+1...wi−1) (4) is the discounted probability and β(wi−n+1...wi−1) is a normalization constant β(wi−n+1...wi−1) = 1 − X x∈(wi−n+1...wi−1x) ˆPr(x|wi−n+1...wi−1) 1 − X x∈(wi−n+1...wi−1x) ˆPr(x|wi−n+2...wi−1) (5) The discounted probability (4) can be computed with different smoothing techniques, including absolute smoothing, Good-Turing smoothing, linear smoothing, and Witten-Bell smoothing [5].",
                "We used absolute smoothing in our experiments.",
                "Since the likelihood of a string, Pr(w1w2...wN ), is a very small number and hard to interpret, we use entropy as defined below to score the string.",
                "Entropy = − 1 N log2 Pr(w1w2...wN ) (6) Now getting back to the example of the query hotel price comparisons, there are four variants of this query, and the entropy of these four candidates are shown in Table 3.",
                "We can see that all alternatives are less likely than the input query.",
                "It is therefore not useful to make an expansion for this query.",
                "On the other hand, if the input query is hotel price comparisons which is the second alternative in the table, then there is a better alternative than the input query, and it should therefore be expanded.",
                "To tolerate the variations in probability estimation, we relax the selection criterion to those query alternatives if their scores are within a certain distance (10% in our experiments) to the best score.",
                "Query variations Entropy hotel price comparison 6.177 hotel price comparisons 6.597 hotels price comparison 6.937 hotels price comparisons 7.360 Table 3: Variations of query hotel price comparison ranked by entropy score, with the original query in bold face. 3.5 Context sensitive document matching Even after we know which word variants are likely to be useful, we have to be conservative in document matching for the expanded variants.",
                "For the query hotel price comparisons, we decided that word comparisons is expanded to include comparison.",
                "However, not every occurrence of comparison in the document is of interest.",
                "A page which is about comparing customer service can contain all of the words hotel price comparisons comparison.",
                "This page is not a good page for the query.",
                "If we accept matches of every occurrence of comparison, it will hurt retrieval precision and this is one of the main reasons why most stemming approaches do not work well for information retrieval.",
                "To address this problem, we have a proximity constraint that considers the context around the expanded variant in the document.",
                "A variant match is considered valid only if the variant occurs in the same context as the original word does.",
                "The context is the left or the right non-stop segments 1 of the original word.",
                "Taking the same query as an example, the context of comparisons is price.",
                "The expanded word comparison is only valid if it is in the same context of comparisons, which is after the word price.",
                "Thus, we should only match those occurrences of comparison in the document if they occur after the word price.",
                "Considering the fact that queries and documents may not represent the intent in exactly the same way, we relax this proximity constraint to allow variant occurrences within a window of some fixed size.",
                "If the expanded word comparison occurs within the context of price within a window, it is considered valid.",
                "The smaller the window size is, the more restrictive the matching.",
                "We use a window size of 4, which typically captures contexts that include the containing and adjacent noun phrases. 4.",
                "EXPERIMENTAL EVALUATION 4.1 Evaluation metrics We will measure both relevance improvement and the stemming cost required to achieve the relevance. 1 a context segment can not be a single stop word. 4.1.1 Relevance measurement We use a variant of the average Discounted Cumulative Gain (DCG), a recently popularized scheme to measure search engine relevance [1, 11].",
                "Given a query and a ranked list of K documents (K is set to 5 in our experiments), the DCG(K) score for this query is calculated as follows: DCG(K) = KX k=1 gk log2(1 + k) . (7) where gk is the weight for the document at rank k. Higher degree of relevance corresponds to a higher weight.",
                "A page is graded into one of the five scales: Perfect, Excellent, Good, Fair, Bad, with corresponding weights.",
                "We use dcg to represent the average DCG(5) over a set of test queries. 4.1.2 Stemming cost Another metric is to measure the additional cost incurred by stemming.",
                "Given the same level of relevance improvement, we prefer a stemming method that has less additional cost.",
                "We measure this by the percentage of queries that are actually stemmed, over all the queries that could possibly be stemmed. 4.2 Data preparation We randomly sample 870 queries from a three month query log, with 290 from each month.",
                "Among all these 870 queries, we remove all misspelled queries since misspelled queries are not of interest to stemming.",
                "We also remove all one word queries since stemming one word queries without context has a high risk of changing query intent, especially for short words.",
                "In the end, we have 529 correctly spelled queries with at least 2 words. 4.3 Naive stemming for Web search Before explaining the experiments and results in detail, wed like to describe the traditional way of using stemming for Web search, referred as the naive model.",
                "This is to treat every word variant equivalent for all possible words in the query.",
                "The query book store will be transformed into (book OR books)(store OR stores) when limiting stemming to pluralization handling only, where OR is an operator that denotes the equivalence of the left and right arguments. 4.4 Experimental setup The baseline model is the model without stemming.",
                "We first run the naive model to see how well it performs over the baseline.",
                "Then we improve the naive stemming model by document sensitive matching, referred as document sensitive matching model.",
                "This model makes the same stemming as the naive model on the query side, but performs conservative matching on the document side using the strategy described in section 3.5.",
                "The naive model and document sensitive matching model stem the most queries.",
                "Out of the 529 queries, there are 408 queries that they stem, corresponding to 46.7% query traffic (out of a total of 870).",
                "We then further improve the document sensitive matching model from the query side with selective word stemming based on statistical language modeling (section 3.4), referred as selective stemming model.",
                "Based on language modeling prediction, this model stems only a subset of the 408 queries stemmed by the document sensitive matching model.",
                "We experiment with unigram language model and bigram language model.",
                "Since we only care how much we can improve the naive model, we will only use these 408 queries (all the queries that are affected by the naive stemming model) in the experiments.",
                "To get a sense of how these models perform, we also have an oracle model that gives the upper-bound performance a stemmer can achieve on this data.",
                "The oracle model only expands a word if the stemming will give better results.",
                "To analyze the pluralization handling influence on different query categories, we divide queries into short queries and long queries.",
                "Among the 408 queries stemmed by the naive model, there are 272 short queries with 2 or 3 words, and 136 long queries with at least 4 words. 4.5 Results We summarize the overall results in Table 4, and present the results on short queries and long queries separately in Table 5.",
                "Each row in Table 4 is a stemming strategy described in section 4.4.",
                "The first column is the name of the strategy.",
                "The second column is the number of queries affected by this strategy; this column measures the stemming cost, and the numbers should be low for the same level of dcg.",
                "The third column is the average dcg score over all tested queries in this category (including the ones that were not stemmed by the strategy).",
                "The fourth column is the relative improvement over the baseline, and the last column is the p-value of Wilcoxon significance test.",
                "There are several observations about the results.",
                "We can see the naively stemming only obtains a statistically insignificant improvement of 1.5%.",
                "Looking at Table 5, it gives an improvement of 2.7% on short queries.",
                "However, it also hurts long queries by -2.4%.",
                "Overall, the improvement is canceled out.",
                "The reason that it improves short queries is that most short queries only have one word that can be stemmed.",
                "Thus, blindly pluralizing short queries is relatively safe.",
                "However for long queries, most queries can have multiple words that can be pluralized.",
                "Expanding all of them without selection will significantly hurt precision.",
                "Document context sensitive stemming gives a significant lift to the performance, from 2.7% to 4.2% for short queries and from -2.4% to -1.6% for long queries, with an overall lift from 1.5% to 2.8%.",
                "The improvement comes from the conservative context sensitive document matching.",
                "An expanded word is valid only if it occurs within the context of original query in the document.",
                "This reduces many spurious matches.",
                "However, we still notice that for long queries, context sensitive stemming is not able to improve performance because it still selects too many documents and gives the ranking function a hard problem.",
                "While the chosen window size of 4 works the best amongst all the choices, it still allows spurious matches.",
                "It is possible that the window size needs to be chosen on a per query basis to ensure tighter proximity constraints for different types of noun phrases.",
                "Selective word pluralization further helps resolving the problem faced by document context sensitive stemming.",
                "It does not stem every word that places all the burden on the ranking algorithm, but tries to eliminate unnecessary stemming in the first place.",
                "By predicting which word variants are going to be useful, we can dramatically reduce the number of stemmed words, thus improving both the recall and the precision.",
                "With the unigram language model, we can reduce the stemming cost by 26.7% (from 408/408 to 300/408) and lift the overall dcg improvement from 2.8% to 3.4%.",
                "In particular, it gives significant improvements on long queries.",
                "The dcg gain is turned from negative to positive, from −1.6% to 1.1%.",
                "This confirms our hypothesis that reducing unnecessary word expansion leads to precision improvement.",
                "For short queries too, we observe both dcg improvement and stemming cost reduction with the unigram language model.",
                "The advantages of predictive word expansion with a language model is further boosted with a better bigram language model.",
                "The overall dcg gain is lifted from 3.4% to 3.9%, and stemming cost is dramatically reduced from 408/408 to 250/408, corresponding to only 29% of query traffic (250 out of 870) and an overall 1.8% dcg improvement overall all query traffic.",
                "For short queries, bigram language model improves the dcg gain from 4.4% to 4.7%, and reduces stemming cost from 272/272 to 150/272.",
                "For long queries, bigram language model improves dcg gain from 1.1% to 2.5%, and reduces stemming cost from 136/136 to 100/136.",
                "We observe that the bigram language model gives a larger lift for long queries.",
                "This is because the uncertainty in long queries is larger and a more powerful language model is needed.",
                "We hypothesize that a trigram language model would give a further lift for long queries and leave this for future investigation.",
                "Considering the tight upper-bound 2 on the improvement to be gained from pluralization handling (via the oracle model), the current performance on short queries is very satisfying.",
                "For short queries, the dcg gain upper-bound is 6.3% for perfect pluralization handling, our current gain is 4.7% with a bigram language model.",
                "For long queries, the dcg gain upper-bound is 4.6% for perfect pluralization handling, our current gain is 2.5% with a bigram language model.",
                "We may gain additional benefit with a more powerful language model for long queries.",
                "However, the difficulties of long queries come from many other aspects including the proximity and the segmentation problem.",
                "These problems have to be addressed separately.",
                "Looking at the the upper-bound of overhead reduction for oracle stemming, 75% (308/408) of the naive stemmings are wasteful.",
                "We currently capture about half of them.",
                "Further reduction of the overhead requires sacrificing the dcg gain.",
                "Now we can compare the stemming strategies from a different aspect.",
                "Instead of looking at the influence over all queries as we described above, Table 6 summarizes the dcg improvements over the affected queries only.",
                "We can see that the number of affected queries decreases as the stemming strategy becomes more accurate (dcg improvement).",
                "For the bigram language model, over the 250/408 stemmed queries, the dcg improvement is 6.1%.",
                "An interesting observation is the average dcg decreases with a better model, which indicates a better stemming strategy stems more difficult queries (low dcg queries). 5.",
                "DISCUSSIONS 5.1 Language models from query vs. from Web As we mentioned in Section 1, we are trying to predict the probability of a string occurring on the Web.",
                "The language model should describe the occurrence of the string on the Web.",
                "However, the query log is also a good resource. 2 Note that this upperbound is for pluralization handling only, not for general stemming.",
                "General stemming gives a 8% upperbound, which is quite substantial in terms of our metrics.",
                "Affected Queries dcg dcg Improvement p-value baseline 0/408 7.102 N/A N/A naive model 408/408 7.206 1.5% 0.22 document context sensitive model 408/408 7.302 2.8% 0.014 selective model: unigram LM 300/408 7.321 3.4% 0.001 selective model: bigram LM 250/408 7.381 3.9% 0.001 oracle model 100/408 7.519 5.9% 0.001 Table 4: Results comparison of different stemming strategies over all queries affected by naive stemming Short Query Results Affected Queries dcg Improvement p-value baseline 0/272 N/A N/A naive model 272/272 2.7% 0.48 document context sensitive model 272/272 4.2% 0.002 selective model: unigram LM 185/272 4.4% 0.001 selective model: bigram LM 150/272 4.7% 0.001 oracle model 71/272 6.3% 0.001 Long Query Results Affected Queries dcg Improvement p-value baseline 0/136 N/A N/A naive model 136/136 -2.4% 0.25 document context sensitive model 136/136 -1.6% 0.27 selective model: unigram LM 115/136 1.1% 0.001 selective model: bigram LM 100/136 2.5% 0.001 oracle model 29/136 4.6% 0.001 Table 5: Results comparison of different stemming strategies overall short queries and long queries Users reformulate a query using many different variants to get good results.",
                "To test the hypothesis that we can learn reliable transformation probabilities from the query log, we trained a language model from the same query top 25M queries as used to learn segmentation, and use that for prediction.",
                "We observed a slight performance decrease compared to the model trained on Web frequencies.",
                "In particular, the performance for unigram LM was not affected, but the dcg gain for bigram LM changed from 4.7% to 4.5% for short queries.",
                "Thus, the query log can serve as a good approximation of the Web frequencies. 5.2 How linguistics helps Some linguistic knowledge is useful in stemming.",
                "For the pluralization handling case, pluralization and de-pluralization is not symmetric.",
                "A plural word used in a query indicates a special intent.",
                "For example, the query new york hotels is looking for a list of hotels in new york, not the specific new york hotel which might be a hotel located in California.",
                "A simple equivalence of hotel to hotels might boost a particular page about new york hotel to top rank.",
                "To capture this intent, we have to make sure the document is a general page about hotels in new york.",
                "We do this by requiring that the plural word hotels appears in the document.",
                "On the other hand, converting a singular word to plural is safer since a general purpose page normally contains specific information.",
                "We observed a slight overall dcg decrease, although not statistically significant, for document context sensitive stemming if we do not consider this asymmetric property. 5.3 Error analysis One type of mistakes we noticed, though rare but seriously hurting relevance, is the search intent change after stemming.",
                "Generally speaking, pluralization or depluralization keeps the original intent.",
                "However, the intent could change in a few cases.",
                "For one example of such a query, job at apple, we pluralize job to jobs.",
                "This stemming makes the original query ambiguous.",
                "The query job OR jobs at apple has two intents.",
                "One is the employment opportunities at apple, and another is a person working at Apple, Steve Jobs, who is the CEO and co-founder of the company.",
                "Thus, the results after query stemming returns Steve Jobs as one of the results in top 5.",
                "One solution is performing results set based analysis to check if the intent is changed.",
                "This is similar to relevance feedback and requires second phase ranking.",
                "A second type of mistakes is the entity/concept recognition problem, These include two kinds.",
                "One is that the stemmed word variant now matches part of an entity or concept.",
                "For example, query cookies in san francisco is pluralized to cookies OR cookie in san francisco.",
                "The results will match cookie jar in san francisco.",
                "Although cookie still means the same thing as cookies, cookie jar is a different concept.",
                "Another kind is the unstemmed word matches an entity or concept because of the stemming of the other words.",
                "For example, quote ICE is pluralized to quote OR quotes ICE.",
                "The original intent for this query is searching for stock quote for ticker ICE.",
                "However, we noticed that among the top results, one of the results is Food quotes: Ice cream.",
                "This is matched because of Affected Queries old dcg new dcg dcg Improvement naive model 408/408 7.102 7.206 1.5% document context sensitive model 408/408 7.102 7.302 2.8% selective model: unigram LM 300/408 5.904 6.187 4.8% selective model: bigram LM 250/408 5.551 5.891 6.1% Table 6: Results comparison over the stemmed queries only: column old/new dcg is the dcg score over the affected queries before/after applying stemming the pluralized word quotes.",
                "The unchanged word ICE matches part of the noun phrase ice cream here.",
                "To solve this kind of problem, we have to analyze the documents and recognize cookie jar and ice cream as concepts instead of two independent words.",
                "A third type of mistakes occurs in long queries.",
                "For the query bar code reader software, two words are pluralized. code to codes and reader to readers.",
                "In fact, bar code reader in the original query is a strong concept and the internal words should not be changed.",
                "This is the segmentation and entity and noun phrase detection problem in queries, which we actively are attacking.",
                "For long queries, we should correctly identify the concepts in the query, and boost the proximity for the words within a concept. 6.",
                "CONCLUSIONS AND FUTURE WORK We have presented a simple yet elegant way of stemming for Web search.",
                "It improves naive stemming in two aspects: selective word expansion on the query side and conservative word occurrence matching on the document side.",
                "Using pluralization handling as an example, experiments on a major Web search engine data show it significantly improves the Web relevance and reduces the stemming cost.",
                "It also significantly improves Web click through rate (details not reported in the paper).",
                "For the future work, we are investigating the problems we identified in the error analysis section.",
                "These include: entity and noun phrase matching mistakes, and improved segmentation. 7.",
                "REFERENCES [1] E. Agichtein, E. Brill, and S. T. Dumais.",
                "Improving Web Search Ranking by Incorporating User Behavior Information.",
                "In SIGIR, 2006. [2] E. Airio.",
                "Word Normalization and Decompounding in Mono- and Bilingual IR.",
                "Information Retrieval, 9:249-271, 2006. [3] P. Anick.",
                "Using Terminological Feedback for Web Search Refinement: a Log-based Study.",
                "In SIGIR, 2003. [4] R. Baeza-Yates and B. Ribeiro-Neto.",
                "Modern Information Retrieval.",
                "ACM Press/Addison Wesley, 1999. [5] S. Chen and J. Goodman.",
                "An Empirical Study of Smoothing Techniques for Language Modeling.",
                "Technical Report TR-10-98, Harvard University, 1998. [6] S. Cronen-Townsend, Y. Zhou, and B. Croft.",
                "A Framework for Selective Query Expansion.",
                "In CIKM, 2004. [7] H. Fang and C. Zhai.",
                "Semantic Term Matching in Axiomatic Approaches to Information Retrieval.",
                "In SIGIR, 2006. [8] W. B. Frakes.",
                "Term Conflation for Information Retrieval.",
                "In C. J. Rijsbergen, editor, Research and Development in Information Retrieval, pages 383-389.",
                "Cambridge University Press, 1984. [9] D. Harman.",
                "How Effective is Suffixing?",
                "JASIS, 42(1):7-15, 1991. [10] D. Hull.",
                "Stemming Algorithms - A Case Study for Detailed Evaluation.",
                "JASIS, 47(1):70-84, 1996. [11] K. Jarvelin and J. Kekalainen.",
                "Cumulated Gain-Based Evaluation Evaluation of IR Techniques.",
                "ACM TOIS, 20:422-446, 2002. [12] R. Jones, B. Rey, O. Madani, and W. Greiner.",
                "Generating Query Substitutions.",
                "In WWW, 2006. [13] W. Kraaij and R. Pohlmann.",
                "Viewing Stemming as Recall Enhancement.",
                "In SIGIR, 1996. [14] R. Krovetz.",
                "Viewing Morphology as an Inference Process.",
                "In SIGIR, 1993. [15] D. Lin.",
                "Automatic Retrieval and Clustering of Similar Words.",
                "In COLING-ACL, 1998. [16] J.",
                "B. Lovins.",
                "Development of a Stemming Algorithm.",
                "Mechanical Translation and Computational Linguistics, II:22-31, 1968. [17] M. Lennon and D. Peirce and B. Tarry and P. Willett.",
                "An Evaluation of Some Conflation Algorithms for Information Retrieval.",
                "Journal of Information Science, 3:177-188, 1981. [18] M. Porter.",
                "An Algorithm for Suffix Stripping.",
                "Program, 14(3):130-137, 1980. [19] K. M. Risvik, T. Mikolajewski, and P. Boros.",
                "<br>query segmentation</br> for Web Search.",
                "In WWW, 2003. [20] S. E. Robertson.",
                "On Term Selection for Query Expansion.",
                "Journal of Documentation, 46(4):359-364, 1990. [21] G. Salton and C. Buckley.",
                "Improving Retrieval Performance by Relevance Feedback.",
                "JASIS, 41(4):288 - 297, 1999. [22] R. Sun, C.-H. Ong, and T.-S. Chua.",
                "Mining Dependency Relations for Query Expansion in Passage Retrieval.",
                "In SIGIR, 2006. [23] C. Van Rijsbergen.",
                "Information Retrieval.",
                "Butterworths, second version, 1979. [24] B. V´elez, R. Weiss, M. A. Sheldon, and D. K. Gifford.",
                "Fast and Effective Query Refinement.",
                "In SIGIR, 1997. [25] J. Xu and B. Croft.",
                "Query Expansion using Local and Global Document Analysis.",
                "In SIGIR, 1996. [26] J. Xu and B. Croft.",
                "Corpus-based Stemming using Cooccurrence of Word Variants.",
                "ACM TOIS, 16 (1):61-81, 1998."
            ],
            "original_annotated_samples": [
                "CONTEXT SENSITIVE STEMMING 3.1 Overview Our system has four components as illustrated in Figure 1: candidate generation, <br>query segmentation</br> and head word detection, context sensitive query stemming and context sensitive document matching.",
                "Table 2 shows some examples of <br>query segmentation</br>.",
                "Query parsing is more difficult than sentence [running shoe] [best] [new york] [medical schools] [pictures] [of] [white house] [cookies] [in] [san francisco] [hotel] [price comparison] Table 2: <br>query segmentation</br>: a segment is bracketed. parsing since many queries are not grammatical and are very short.",
                "<br>query segmentation</br> for Web Search."
            ],
            "translated_annotated_samples": [
                "STEMMING CONTEXTUAL SENSIBLE 3.1 Resumen Nuestro sistema tiene cuatro componentes como se ilustra en la Figura 1: generación de candidatos, <br>segmentación de consultas</br> y detección de palabras clave, derivación de consultas sensible al contexto y coincidencia de documentos sensible al contexto.",
                "La Tabla 2 muestra algunos ejemplos de <br>segmentación de consultas</br>.",
                "El <br>análisis de consultas</br> es más difícil que el análisis de oraciones, ya que muchas consultas no son gramaticales y son muy cortas.",
                "Segmentación de consultas para búsqueda web."
            ],
            "translated_text": "Stemming sensible al contexto para la búsqueda web Fuchun Peng Nawaaz Ahmed Xin Li Yumao Lu Yahoo! Tradicionalmente, el truncamiento se ha aplicado a tareas de Recuperación de Información transformando las palabras en documentos a su forma raíz antes de indexarlas, y aplicando una transformación similar a los términos de consulta. Aunque aumenta la recuperación, esta estrategia ingenua no funciona bien para la Búsqueda en la Web, ya que disminuye la precisión y requiere una cantidad significativa de cálculos adicionales. En este artículo, proponemos un método de derivación sensible al contexto que aborda estos dos problemas. Dos propiedades únicas hacen que nuestro enfoque sea factible para la Búsqueda en la Web. Primero, basados en modelado estadístico del lenguaje, realizamos un análisis sensible al contexto en el lado de la consulta. Predecimos con precisión cuál de sus variantes morfológicas es útil para expandir un término de consulta antes de enviar la consulta al motor de búsqueda. Esto reduce drásticamente la cantidad de expansiones incorrectas, lo que a su vez disminuye el costo de la computación adicional y mejora la precisión al mismo tiempo. Segundo, nuestro enfoque realiza una coincidencia de documentos sensible al contexto para esas variantes ampliadas. Esta estrategia conservadora sirve como salvaguarda contra el truncamiento espurio, y resulta ser muy importante para mejorar la precisión. Usando el manejo de la pluralización de palabras como un ejemplo de nuestro enfoque de derivación, nuestros experimentos en un importante motor de búsqueda web muestran que al derivar solo el 29% del tráfico de consultas, podemos mejorar la relevancia medida por la Ganancia Acumulativa Descontada promedio (DCG5) en un 6.1% en estas consultas y en un 1.8% sobre todo el tráfico de consultas. Categorías y Descriptores de Asignaturas H.3.3 [Sistemas de Información]: Almacenamiento y Recuperación de Información-Formulación de Consultas Términos Generales Algoritmos, Experimentación 1. INTRODUCCIÓN La búsqueda en la web se ha convertido en una herramienta importante en nuestra vida diaria para buscar información. Uno de los problemas importantes en la búsqueda web es que las consultas de los usuarios a menudo no están formuladas de la mejor manera para obtener resultados óptimos. Por ejemplo, \"zapatilla para correr\" es una consulta que ocurre con frecuencia en los registros de consulta. Sin embargo, es mucho más probable que la búsqueda \"zapatillas para correr\" proporcione mejores resultados de búsqueda que la consulta original, ya que los documentos que coinciden con la intención de esta consulta suelen contener las palabras \"zapatillas para correr\". Formular correctamente una consulta requiere que el usuario prediga con precisión qué forma de palabra se utiliza en los documentos que mejor satisfacen sus necesidades de información. Esto es difícil incluso para usuarios experimentados, y especialmente difícil para hablantes no nativos. Una solución tradicional es utilizar el stemming [16, 18], el proceso de transformar palabras flexionadas o derivadas a su forma raíz para que un término de búsqueda coincida y recupere documentos que contengan todas las formas del término. Por lo tanto, la palabra \"run\" coincidirá con \"running\", \"ran\", \"runs\", y \"shoe\" coincidirá con \"shoes\" y \"shoeing\". El truncamiento se puede realizar tanto en los términos de un documento durante la indexación (y aplicando la misma transformación a los términos de la consulta durante el procesamiento de la consulta) o expandiendo la consulta con las variantes durante el procesamiento de la consulta. El truncamiento durante la indexación permite muy poca flexibilidad durante el procesamiento de consultas, mientras que el truncamiento mediante la expansión de consultas permite manejar cada consulta de manera diferente, y por lo tanto es preferible. Aunque el truncamiento tradicional aumenta la recuperación al emparejar variantes de palabras [13], puede reducir la precisión al recuperar demasiados documentos que han sido emparejados incorrectamente. Al examinar los resultados de aplicar el truncamiento a un gran número de consultas, generalmente se encuentra que casi igual cantidad de consultas se benefician y se ven perjudicadas por la técnica [6]. Además, reduce el rendimiento del sistema porque el motor de búsqueda tiene que hacer coincidir todas las variantes de palabras. Como mostraremos en los experimentos, esto es cierto incluso si simplificamos el proceso de derivación a la manipulación de pluralización, que es el proceso de convertir una palabra de su forma plural a singular, o viceversa. Por lo tanto, es necesario ser muy cauteloso al utilizar el stemming en los motores de búsqueda web. Un problema del truncamiento tradicional es su transformación ciega de todos los términos de consulta, es decir, siempre realiza la misma transformación para la misma palabra de consulta sin considerar el contexto de la palabra. Por ejemplo, la palabra \"book\" tiene cuatro formas: book, books, booking, booked, y la palabra \"store\" tiene cuatro formas: store, stores, storing, stored. Para la consulta de la librería, expandir ambas palabras a todas sus variantes aumenta significativamente el costo de computación y perjudica la precisión, ya que no todas las variantes son útiles para esta consulta. Transformar librería para que coincida con librerías está bien, pero hacer coincidir almacenamiento de libros o tienda de reservas no lo está. Un método de ponderación que otorga pesos más pequeños a las palabras variantes alivia los problemas hasta cierto punto si los pesos reflejan con precisión la importancia de la variante en esta consulta particular. Sin embargo, el peso uniforme no va a funcionar y un peso dependiente de la consulta sigue siendo un problema desafiante sin resolver [20]. Un segundo problema del truncamiento tradicional es su emparejamiento ciego de todas las ocurrencias en los documentos. Para la consulta de la librería, una transformación que permita que las tiendas variantes se emparejen hará que cada aparición de tiendas en el documento se trate de manera equivalente al término de consulta tienda. Por lo tanto, se emparejará un documento que contenga el fragmento de leer un libro en las cafeterías, lo que provocará que se seleccionen muchos documentos incorrectos. Aunque esperamos que la función de clasificación pueda manejar correctamente estos, con muchos más candidatos para clasificar, el riesgo de cometer errores aumenta. Para aliviar estos dos problemas, proponemos un enfoque de reducción de palabras raíz sensible al contexto para la búsqueda en la web. Nuestra solución consiste en dos análisis contextuales sensibles, uno en el lado de la consulta y otro en el lado del documento. En el lado de la consulta, proponemos un enfoque basado en modelado del lenguaje estadístico para predecir qué variantes de palabras son mejores formas que la palabra original con fines de búsqueda y expandir la consulta solo con esas formas. En el lado del documento, proponemos un emparejamiento conservador sensible al contexto para las variantes de palabras transformadas, solo emparejando las ocurrencias en el documento en el contexto de otros términos en la consulta. Nuestro modelo es simple pero efectivo y eficiente, lo que lo hace factible de ser utilizado en motores de búsqueda web comerciales reales. Utilizamos el manejo de pluralización como un ejemplo continuo para nuestro enfoque de derivación. La motivación para usar el manejo de pluralización como ejemplo es mostrar que incluso un truncamiento tan simple, si se maneja correctamente, puede brindar beneficios significativos a la relevancia de la búsqueda. Hasta donde sabemos, ninguna investigación previa ha investigado sistemáticamente el uso de la pluralización en la búsqueda en la web. Como debemos señalar, el método que proponemos no se limita al manejo de la pluralización, es una técnica de derivación general y también se puede aplicar a la expansión de consultas en general. Los experimentos sobre el truncamiento general producen mejoras significativas adicionales sobre el manejo de la pluralización para consultas largas, aunque los detalles no se informarán en este artículo. En el resto del documento, primero presentamos el trabajo relacionado y distinguimos nuestro método de trabajos anteriores en la Sección 2. Describimos los detalles del enfoque de derivación sensible al contexto en la Sección 3. Luego realizamos experimentos extensos en un importante motor de búsqueda web para respaldar nuestras afirmaciones en la Sección 4, seguidos de discusiones en la Sección 5. Finalmente, concluimos el artículo en la Sección 6.2. TRABAJO RELACIONADO El stemming es una tecnología estudiada desde hace mucho tiempo. Se han desarrollado muchos stemmers, como el stemmer Lovins [16] y el stemmer Porter [18]. El stemmer de Porter es ampliamente utilizado debido a su simplicidad y efectividad en muchas aplicaciones. Sin embargo, el algoritmo de Porter comete muchos errores porque sus reglas simples no pueden describir completamente la morfología del inglés. El análisis de corpus se utiliza para mejorar el stemmer de Porter [26] mediante la creación de clases de equivalencia para palabras que son morfológicamente similares y que ocurren en un contexto similar, medido por la información mutua esperada [23]. Utilizamos un enfoque de corpus similar para el stemming al calcular la similitud entre dos palabras basada en sus características de contexto distribucional, que pueden ser más que solo palabras adyacentes [15], y luego solo mantenemos las palabras morfológicamente similares como candidatas. El uso de la derivación en la recuperación de información también es una técnica bien conocida [8, 10]. Sin embargo, se informó previamente que la efectividad del truncamiento para los sistemas de consulta en inglés era bastante limitada. Lennon et al. [17] compararon los algoritmos de Lovins y Porter y encontraron poco mejoramiento en el rendimiento de recuperación. Más tarde, Harman [9] compara tres técnicas generales de derivación en experimentos de recuperación de texto, incluido el manejo de pluralización (llamado S stemmer en el artículo). También propusieron el truncamiento selectivo basado en la longitud de la consulta y la importancia del término, pero no se informaron resultados positivos. Por otro lado, Krovetz [14] realizó comparaciones sobre un pequeño número de documentos (de 400 a 12k) y mostró una mejora dramática en la precisión (de hasta un 45%). Sin embargo, debido al número limitado de consultas probadas (menos de 100) y al tamaño reducido de la colección, los resultados son difíciles de generalizar para la búsqueda en la web. Estos resultados mixtos, en su mayoría fracasos, llevaron a los primeros investigadores de IR a considerar que el truncamiento era irrelevante en general para el inglés [4], aunque investigaciones recientes han demostrado que el truncamiento tiene mayores beneficios para la recuperación en otros idiomas [2]. Sospechamos que los fracasos anteriores se debieron principalmente a los dos problemas que mencionamos en la introducción. El stemming ciego, o un stemming selectivo basado en la longitud de la consulta como se utiliza en [9], no es suficiente. El truncamiento debe decidirse caso por caso, no solo a nivel de consulta sino también a nivel de documento. Como demostraremos, si se maneja correctamente, se puede lograr una mejora significativa. Un problema más general relacionado con el stemming es la reformulación de consultas [3, 12] y la expansión de consultas que amplía las palabras no solo con variantes de palabras [7, 22, 24, 25]. Para decidir qué palabras expandidas usar, las personas a menudo utilizan técnicas de retroalimentación de seudorelevancia que envían la consulta original a un motor de búsqueda y recuperan los documentos principales, extraen palabras relevantes de estos documentos principales como palabras de consulta adicionales y vuelven a enviar la consulta expandida nuevamente [21]. Esto normalmente requiere enviar una consulta varias veces al motor de búsqueda y no es rentable para procesar la gran cantidad de consultas involucradas en la búsqueda web. Además, la expansión de consultas, incluida la reformulación de consultas [3, 12], tiene un alto riesgo de cambiar la intención del usuario (llamado desviación de consulta). Dado que las palabras expandidas pueden tener diferentes significados, agregarlas a la consulta podría potencialmente cambiar la intención de la consulta original. Por lo tanto, la expansión de consultas basada en pseudorelevancia y la reformulación de consultas pueden proporcionar sugerencias a los usuarios para su refinamiento interactivo, pero difícilmente pueden ser utilizadas directamente para la búsqueda en la web. Por otro lado, el truncamiento es mucho más conservador ya que la mayoría de las veces, conserva la intención de búsqueda original. Si bien la mayoría de los trabajos sobre la expansión de consultas se centran en mejorar la recuperación, nuestro trabajo se enfoca en aumentar tanto la recuperación como la precisión. El aumento en el recuerdo es evidente. Con el stemming de calidad, los buenos documentos que no fueron seleccionados antes del stemming serán promovidos y aquellos documentos de baja calidad serán degradados. En la expansión selectiva de consultas, Cronen-Townsend et al. [6] propusieron un método para la expansión selectiva de consultas basado en comparar la divergencia de Kullback-Leibler de los resultados de la consulta no expandida y los resultados de la consulta expandida. Esto es similar a la retroalimentación de relevancia en el sentido de que requiere múltiples pasadas de recuperación. Si una palabra puede expandirse en varias palabras, se requiere ejecutar este proceso varias veces para decidir cuál palabra expandida es útil. Es costoso implementar esto en motores de búsqueda web en producción. Nuestro método predice la calidad de la expansión basándose en información sin conexión sin enviar la consulta a un motor de búsqueda. En resumen, proponemos un enfoque novedoso para abordar un problema antiguo, pero aún importante y desafiante para la búsqueda en la web: el stemming. Nuestro enfoque es único en el sentido de que realiza el truncamiento predictivo de forma individualizada para cada consulta sin retroalimentación de relevancia de la Web, utilizando el contexto de las variantes en los documentos para preservar la precisión. Es simple, pero muy eficiente y efectivo, lo que hace factible el truncamiento en tiempo real para la búsqueda en la web. Nuestros resultados confirmarán a los investigadores que el truncamiento es realmente muy importante para la recuperación de información a gran escala. STEMMING CONTEXTUAL SENSIBLE 3.1 Resumen Nuestro sistema tiene cuatro componentes como se ilustra en la Figura 1: generación de candidatos, <br>segmentación de consultas</br> y detección de palabras clave, derivación de consultas sensible al contexto y coincidencia de documentos sensible al contexto. La generación de candidatos (componente 1) se realiza fuera de línea y los candidatos generados se almacenan en un diccionario. Para una consulta de entrada, primero segmentamos la consulta en conceptos y detectamos la palabra principal de cada concepto (componente 2). Luego utilizamos modelado de lenguaje estadístico para decidir si una variante particular es útil (componente 3), y finalmente, para las variantes expandidas, realizamos un emparejamiento de documentos sensible al contexto (componente 4). A continuación discutimos cada uno de los componentes con más detalle. Componente 4: coincidencia de documentos sensibles al contexto Consulta de entrada: y detección de palabras clave Componente 2: segmento Componente 1: generación de candidatos comparaciones −> comparación Componente 3: decisión de expansión selectiva de palabras: comparaciones −> comparación ejemplo: comparaciones de precios de hoteles salida: comparaciones de hoteles hotel −> hoteles Figura 1: Componentes del sistema 3.2 Generación de candidatos de expansión Una de las formas de generar candidatos es utilizando el stemmer de Porter [18]. El stemmer de Porter simplemente utiliza reglas morfológicas para convertir una palabra a su forma base. No tiene conocimiento del significado semántico de las palabras y a veces comete errores graves, como cambiar \"executive\" por \"execution\", \"news\" por \"new\" y \"paste\" por \"past\". Una forma más conservadora se basa en utilizar análisis de corpus para mejorar los resultados del stemmer de Porter [26]. El análisis de corpus que realizamos se basa en la similitud distribucional de palabras [15]. La razón de utilizar la similitud distribucional de palabras es que las variantes verdaderas tienden a ser utilizadas en contextos similares. En el cálculo de similitud de palabras distribucionales, cada palabra se representa con un vector de características derivadas del contexto de la palabra. Utilizamos los bigramas a la izquierda y a la derecha de la palabra como sus características de contexto, mediante la extracción de un gran corpus web. La similitud entre dos palabras es la similitud coseno entre los dos vectores de características correspondientes. Las 20 palabras similares a \"desarrollar\" se muestran en la siguiente tabla. rango candidato puntaje rango candidato puntaje 0 desarrollar 1 10 berts 0.119 1 desarrollando 0.339 11 wads 0.116 2 desarrollado 0.176 12 desarrollador 0.107 3 incubadora 0.160 13 promoviendo 0.100 4 desarrolla 0.150 14 desarrollo 0.091 5 desarrollo 0.148 15 reingeniería 0.090 6 tutoría 0.138 16 construir 0.083 7 analizando 0.128 17 construir 0.081 8 desarrollo 0.128 18 educativo 0.081 9 automatización 0.126 19 instituto 0.077 Tabla 1: Los 20 candidatos más similares a la palabra \"desarrollar\". La puntuación de la columna es la puntuación de similitud. Para determinar los candidatos de derivación, aplicamos algunas reglas morfológicas del stemmer de Porter [18] a la lista de similitud. Después de aplicar estas reglas, para la palabra desarrollar, los candidatos de derivación son desarrollando, desarrollado, desarrolla, desarrollo, desarrollo, desarrollador, y desarrollo. Para el propósito de manejo de pluralización, solo se conserva el candidato desarrolla. Una cosa que observamos al observar las palabras distribucionalmente similares es que están estrechamente relacionadas semánticamente. Estas palabras podrían servir como candidatas para la expansión general de consultas, un tema que investigaremos en el futuro. 3.3 Segmentación e identificación de palabras clave Para consultas largas, es bastante importante detectar los conceptos en la consulta y las palabras más importantes para esos conceptos. Primero dividimos una consulta en segmentos, cada segmento representando un concepto que normalmente es una frase nominal. Para cada una de las frases nominales, luego detectamos la palabra más importante a la que llamamos la palabra principal. La segmentación también se utiliza en la coincidencia sensible a documentos (sección 3.5) para hacer cumplir la proximidad. Para dividir una consulta en segmentos, tenemos que definir un criterio para medir la fuerza de la relación entre las palabras. Un método efectivo es utilizar la información mutua como indicador para decidir si dividir o no dos palabras [19]. Utilizamos un registro de 25 millones de consultas y recopilamos las frecuencias de bigramas y unigramas a partir de él. Para cada consulta entrante, calculamos la información mutua de dos palabras adyacentes; si supera un umbral predefinido, no dividimos la consulta entre esas dos palabras y pasamos a la siguiente palabra. Continuamos este proceso hasta que la información mutua entre dos palabras esté por debajo del umbral, luego creamos un límite conceptual aquí. La Tabla 2 muestra algunos ejemplos de <br>segmentación de consultas</br>. La forma ideal de encontrar la palabra principal de un concepto es realizar un análisis sintáctico para determinar la estructura de dependencia de la consulta. El <br>análisis de consultas</br> es más difícil que el análisis de oraciones, ya que muchas consultas no son gramaticales y son muy cortas. Aplicar un analizador entrenado en oraciones de documentos a consultas tendrá un rendimiento deficiente. En nuestra solución, solo utilizamos reglas heurísticas simples, y funciona muy bien en la práctica para el inglés. Para una frase nominal en inglés, la palabra principal suele ser la última palabra no detenida, a menos que la frase siga un patrón particular, como XYZ de/en/a/desde UVW. En tales casos, la palabra principal suele ser la última palabra no detenida de XYZ. 3.4 Expansión de palabras sensibles al contexto Después de detectar cuáles son las palabras más importantes para expandir, debemos decidir si las expansiones serán útiles. Nuestras estadísticas muestran que aproximadamente la mitad de las consultas pueden ser transformadas mediante la pluralización a través de un truncamiento ingenuo. Entre esta mitad, aproximadamente el 25% de las consultas mejoran la relevancia cuando se transforman, la mayoría (alrededor del 50%) no cambian sus 5 resultados principales, y el 25% restante tiene un rendimiento peor. Por lo tanto, es extremadamente importante identificar qué consultas no deben ser truncadas con el fin de maximizar la mejora de relevancia y minimizar el costo de truncamiento. Además, para una consulta con múltiples palabras que pueden ser transformadas, o una palabra con múltiples variantes, no todas las expansiones son útiles. Tomando la comparación de precios de hoteles como ejemplo, decidimos que hotel y comparación de precios son dos conceptos. Las palabras clave hotel y comparación se pueden expandir a hoteles y comparaciones. ¿Son útiles ambas transformaciones? Para probar si una expansión es útil, tenemos que saber si es probable que la consulta expandida obtenga más documentos relevantes de la web, lo cual puede cuantificarse mediante la probabilidad de que la consulta ocurra como una cadena en la web. Cuanto más probable sea que ocurra una consulta en la web, más documentos relevantes puede devolver esta consulta. Ahora todo el problema se convierte en cómo calcular la probabilidad de que ocurra la consulta en la Web. Calcular la probabilidad de que una cadena ocurra en un corpus es un problema bien conocido de modelado del lenguaje. El objetivo del modelado del lenguaje es predecir la probabilidad de secuencias de palabras que ocurren naturalmente, s = w1w2...wN; o más simplemente, asignar una alta probabilidad a las secuencias de palabras que realmente ocurren (y una baja probabilidad a las secuencias de palabras que nunca ocurren). El enfoque más simple y exitoso para el modelado del lenguaje sigue estando basado en el modelo n-gramo. Por la regla de la cadena de probabilidad, se puede escribir la probabilidad de cualquier secuencia de palabras como Pr(w1w2...wN) = ΠY i=1 Pr(wi|w1...wi−1) (1). Un modelo n-grama aproxima esta probabilidad asumiendo que las únicas palabras relevantes para predecir Pr(wi|w1...wi−1) son las n − 1 palabras anteriores; es decir, La probabilidad de una palabra wi dado w1...wi−1 es igual a la probabilidad de wi dado wi−n+1...wi−1. Una estimación directa de máxima verosimilitud de las probabilidades de n-gramas a partir de un corpus se obtiene a partir de la frecuencia observada de cada uno de los patrones Pr(wi|wi−n+1...wi−1) = #(wi−n+1...wi) #(wi−n+1...wi−1) donde #(.) denota el número de ocurrencias de un n-grama específico en el corpus de entrenamiento. Aunque se podría intentar usar modelos de n-gramos simples para capturar dependencias a largo plazo en el lenguaje, intentar hacerlo directamente crea inmediatamente problemas de datos dispersos: Utilizar n-gramos de longitud hasta n implica estimar la probabilidad de eventos de longitud Wn, donde W es el tamaño del vocabulario de palabras. Esto rápidamente abruma los recursos computacionales y de datos modernos incluso para opciones modestas de n (más allá de 3 a 6). Además, debido a la naturaleza de cola pesada del lenguaje (es decir, La ley de Zipf) es probable que uno se encuentre con n-gramas novedosos que nunca fueron observados durante el entrenamiento en ningún corpus de prueba, por lo tanto, algún mecanismo para asignar una probabilidad distinta de cero a los n-gramas novedosos es un problema central e inevitable en la modelización estadística del lenguaje. Un enfoque estándar para suavizar las estimaciones de probabilidad para hacer frente a problemas de datos escasos (y para hacer frente a posibles n-gramas faltantes) es utilizar algún tipo de estimador de retroceso. Pr(wi|wi−n+1...wi−1) = 8 >>< >>: ˆPr(wi|wi−n+1...wi−1), si #(wi−n+1...wi) > 0 β(wi−n+1...wi−1) × Pr(wi|wi−n+2...wi−1), de lo contrario (3) donde ˆPr(wi|wi−n+1...wi−1) = descuento #(wi−n+1...wi) #(wi−n+1...wi−1) (4) es la probabilidad descontada y β(wi−n+1...wi−1) es una constante de normalización β(wi−n+1...wi−1) = 1 − X x∈(wi−n+1...wi−1x) ˆPr(x|wi−n+1...wi−1) 1 − X x∈(wi−n+1...wi−1x) ˆPr(x|wi−n+2...wi−1) (5) La probabilidad descontada (4) se puede calcular con diferentes técnicas de suavizado, incluido el suavizado absoluto, el suavizado de Good-Turing, el suavizado lineal y el suavizado de Witten-Bell [5]. Utilizamos suavizado absoluto en nuestros experimentos. Dado que la probabilidad de una cadena, Pr(w1w2...wN), es un número muy pequeño y difícil de interpretar, utilizamos la entropía, tal como se define a continuación, para puntuar la cadena. Entropía = − 1 N log2 Pr(w1w2...wN ) (6) Ahora volviendo al ejemplo de la comparación de precios de hoteles, hay cuatro variantes de esta consulta, y la entropía de estos cuatro candidatos se muestra en la Tabla 3. Podemos ver que todas las alternativas son menos probables que la consulta de entrada. Por lo tanto, no es útil hacer una expansión para esta consulta. Por otro lado, si la consulta de entrada son comparaciones de precios de hoteles, que es la segunda alternativa en la tabla, entonces hay una mejor alternativa que la consulta de entrada, y por lo tanto debería ser ampliada. Para tolerar las variaciones en la estimación de probabilidad, relajamos el criterio de selección para esas alternativas de consulta si sus puntuaciones están dentro de una cierta distancia (10% en nuestros experimentos) de la mejor puntuación. Variaciones de la consulta Comparación de precios de hoteles 6.177 comparaciones de precios de hoteles 6.597 comparación de precios de hoteles 6.937 comparaciones de precios de hoteles 7.360 Tabla 3: Variaciones de la consulta comparación de precios de hoteles clasificadas por puntaje de entropía, con la consulta original en negrita. 3.5 Coincidencia de documentos sensibles al contexto Aun después de saber qué variantes de palabras son probablemente útiles, debemos ser conservadores en la coincidencia de documentos para las variantes ampliadas. Para la consulta de comparaciones de precios de hoteles, decidimos que la palabra \"comparaciones\" se amplía para incluir \"comparación\". Sin embargo, no todos los casos de comparación en el documento son de interés. Una página que trata sobre comparar el servicio al cliente puede contener todas las palabras comparaciones de precios de hoteles comparación. Esta página no es una buena página para la consulta. Si aceptamos coincidencias de cada ocurrencia de comparación, afectará la precisión de recuperación y esta es una de las principales razones por las que la mayoría de los enfoques de derivación no funcionan bien para la recuperación de información. Para abordar este problema, tenemos una restricción de proximidad que considera el contexto alrededor de la variante expandida en el documento. Una coincidencia de variante se considera válida solo si la variante ocurre en el mismo contexto que la palabra original lo hace. El contexto son los segmentos continuos de la izquierda o de la derecha de la palabra original. Tomando la misma consulta como ejemplo, el contexto de las comparaciones es el precio. La comparación de palabras ampliada solo es válida si está en el mismo contexto de comparaciones, que es después de la palabra precio. Por lo tanto, solo debemos emparejar aquellas ocurrencias de comparación en el documento si ocurren después de la palabra precio. Considerando el hecho de que las consultas y los documentos pueden no representar la intención de la misma manera exacta, relajamos esta restricción de proximidad para permitir ocurrencias variantes dentro de una ventana de un tamaño fijo. Si la comparación de palabras expandidas ocurre dentro del contexto de precio dentro de una ventana, se considera válida. Cuanto más pequeño sea el tamaño de la ventana, más restrictiva será la coincidencia. Utilizamos un tamaño de ventana de 4, que normalmente captura contextos que incluyen las frases nominales que contienen y las adyacentes. 4. EVALUACIÓN EXPERIMENTAL 4.1 Métricas de evaluación Mediremos tanto la mejora de relevancia como el costo de derivación necesario para lograr la relevancia. 1 un segmento de contexto no puede ser una sola palabra de parada. 4.1.1 Medición de relevancia Utilizamos una variante de la Ganancia Acumulada Descontada Promedio (DCG), un esquema recientemente popularizado para medir la relevancia de los motores de búsqueda [1, 11]. Dada una consulta y una lista clasificada de K documentos (K se establece en 5 en nuestros experimentos), el puntaje DCG(K) para esta consulta se calcula de la siguiente manera: DCG(K) = Σ k=1 a K gk log2(1 + k) . (7) donde gk es el peso para el documento en la posición k. Un mayor grado de relevancia corresponde a un peso mayor. Una página se califica en una de las cinco escalas: Perfecto, Excelente, Bueno, Regular, Malo, con pesos correspondientes. Utilizamos DCG para representar el DCG promedio(5) sobre un conjunto de consultas de prueba. 4.1.2 Costo de derivación Otro métrica es medir el costo adicional incurrido por la derivación. Dado el mismo nivel de mejora en la relevancia, preferimos un método de truncamiento que tenga un menor costo adicional. Medimos esto por el porcentaje de consultas que realmente se reducen, sobre todas las consultas que podrían ser reducidas. 4.2 Preparación de datos Muestreamos aleatoriamente 870 consultas de un registro de consultas de tres meses, con 290 de cada mes. Entre todas estas 870 consultas, eliminamos todas las consultas con errores ortográficos ya que las consultas con errores ortográficos no son de interés para el stemming. También eliminamos todas las consultas de una sola palabra, ya que reducir las consultas de una sola palabra sin contexto tiene un alto riesgo de cambiar la intención de la consulta, especialmente para palabras cortas. Al final, tenemos 529 consultas correctamente escritas con al menos 2 palabras. 4.3 Stemming ingenuo para la búsqueda en la Web Antes de explicar en detalle los experimentos y resultados, nos gustaría describir la forma tradicional de usar el stemming para la búsqueda en la Web, conocida como el modelo ingenuo. Esto es para tratar cada variante de palabra equivalente para todas las posibles palabras en la consulta. La consulta de la librería se transformará en (libro O libros)(tienda O tiendas) al limitar el truncamiento al manejo de pluralización solamente, donde O es un operador que denota la equivalencia de los argumentos izquierdo y derecho. 4.4 Configuración experimental El modelo base es el modelo sin truncamiento. Primero ejecutamos el modelo ingenuo para ver qué tan bien se desempeña en comparación con el punto de referencia. Luego mejoramos el modelo de derivación ingenua mediante la coincidencia sensible al documento, denominado modelo de coincidencia sensible al documento. Este modelo realiza el mismo stemming que el modelo ingenuo en el lado de la consulta, pero realiza un emparejamiento conservador en el lado del documento utilizando la estrategia descrita en la sección 3.5. El modelo ingenuo y el modelo de coincidencia sensible al documento son los que mejor responden a la mayoría de las consultas. De las 529 consultas, hay 408 consultas que se originan, lo que corresponde al 46.7% del tráfico de consultas (de un total de 870). Luego mejoramos aún más el modelo de coincidencia sensible de documentos desde el lado de la consulta con un proceso de derivación de palabras selectivo basado en modelado estadístico del lenguaje (sección 3.4), denominado modelo de derivación selectiva. Basado en la predicción del modelado del lenguaje, este modelo deriva solo un subconjunto de las 408 consultas derivadas por el modelo de coincidencia sensible al documento. Experimentamos con un modelo de lenguaje unigrama y un modelo de lenguaje bigrama. Dado que solo nos importa cuánto podemos mejorar el modelo ingenuo, solo utilizaremos estas 408 consultas (todas las consultas que se ven afectadas por el modelo de derivación ingenuo) en los experimentos. Para tener una idea de cómo se desempeñan estos modelos, también tenemos un modelo oráculo que proporciona el rendimiento máximo que un stemmer puede lograr en estos datos. El modelo del oráculo solo expande una palabra si el truncamiento dará mejores resultados. Para analizar la influencia del manejo de la pluralización en diferentes categorías de consultas, dividimos las consultas en consultas cortas y consultas largas. Entre las 408 consultas generadas por el modelo ingenuo, hay 272 consultas cortas con 2 o 3 palabras, y 136 consultas largas con al menos 4 palabras. Resumimos los resultados generales en la Tabla 4, y presentamos los resultados de las consultas cortas y largas por separado en la Tabla 5. Cada fila en la Tabla 4 es una estrategia de derivación descrita en la sección 4.4. La primera columna es el nombre de la estrategia. La segunda columna es el número de consultas afectadas por esta estrategia; esta columna mide el costo de derivación, y los números deberían ser bajos para el mismo nivel de dcg. La tercera columna es la puntuación DCG promedio sobre todas las consultas probadas en esta categoría (incluyendo aquellas que no fueron truncadas por la estrategia). La cuarta columna es la mejora relativa sobre la línea base, y la última columna es el valor p de la prueba de significancia de Wilcoxon. Hay varias observaciones sobre los resultados. Podemos ver que el truncado ingenuo solo logra una mejora estadísticamente insignificante del 1.5%. Mirando la Tabla 5, se observa una mejora del 2.7% en las consultas cortas. Sin embargo, también perjudica las consultas largas en un -2.4%. En general, la mejora se cancela. La razón por la que mejora las consultas cortas es que la mayoría de las consultas cortas solo tienen una palabra que se puede reducir a su raíz. Por lo tanto, pluralizar ciegamente consultas cortas es relativamente seguro. Sin embargo, para consultas largas, la mayoría de las consultas pueden tener varias palabras que pueden ser pluralizadas. Expandir todos ellos sin selección perjudicará significativamente la precisión. La aplicación de un stemming sensible al contexto del documento proporciona un aumento significativo en el rendimiento, desde un 2.7% hasta un 4.2% para consultas cortas y desde un -2.4% hasta un -1.6% para consultas largas, con un aumento general del 1.5% al 2.8%. La mejora proviene de la coincidencia de documentos sensible al contexto conservador. Una palabra expandida es válida solo si ocurre dentro del contexto de la consulta original en el documento. Esto reduce muchas coincidencias falsas. Sin embargo, aún observamos que para consultas largas, el truncamiento sensible al contexto no logra mejorar el rendimiento porque sigue seleccionando demasiados documentos y le presenta a la función de clasificación un problema difícil. Si bien el tamaño de ventana elegido de 4 es el que mejor funciona entre todas las opciones, aún permite coincidencias espurias. Es posible que el tamaño de la ventana deba elegirse según la consulta para garantizar restricciones de proximidad más estrictas para diferentes tipos de frases nominales. La pluralización selectiva de palabras ayuda aún más a resolver el problema enfrentado por el truncamiento sensible al contexto del documento. No se aplica el truncamiento a cada palabra que coloca toda la carga en el algoritmo de clasificación, sino que intenta eliminar el truncamiento innecesario en primer lugar. Al predecir qué variantes de palabras van a ser útiles, podemos reducir drásticamente el número de palabras derivadas, mejorando así tanto la recuperación como la precisión. Con el modelo de lenguaje unigrama, podemos reducir el costo de derivación en un 26.7% (de 408/408 a 300/408) y aumentar la mejora general de DCG del 2.8% al 3.4%. En particular, proporciona mejoras significativas en consultas largas. La ganancia de DCG se cambia de negativa a positiva, de -1.6% a 1.1%. Esto confirma nuestra hipótesis de que reducir la expansión innecesaria de palabras conduce a una mejora en la precisión. Para consultas cortas también observamos tanto la mejora de dcg como la reducción del costo de derivación con el modelo de lenguaje unigrama. Las ventajas de la expansión predictiva de palabras con un modelo de lenguaje se potencian aún más con un mejor modelo de lenguaje de bigrama. La ganancia total de DCG aumenta de 3.4% a 3.9%, y el costo de derivación se reduce drásticamente de 408/408 a 250/408, correspondiente a solo el 29% del tráfico de consultas (250 de 870) y una mejora total de DCG del 1.8% en todo el tráfico de consultas. Para consultas cortas, el modelo de lenguaje de bigrama mejora la ganancia de DCG del 4.4% al 4.7%, y reduce el costo de derivación de 272/272 a 150/272. Para consultas largas, el modelo de lenguaje de bigrama mejora la ganancia de DCG del 1.1% al 2.5%, y reduce el costo de derivación de 136/136 a 100/136. Observamos que el modelo de lenguaje de bigrama proporciona un mayor aumento para consultas largas. Esto se debe a que la incertidumbre en las consultas largas es mayor y se necesita un modelo de lenguaje más potente. Hacemos la hipótesis de que un modelo de lenguaje de trigramas proporcionaría un impulso adicional para consultas largas y dejamos esto para investigaciones futuras. Considerando el límite superior estricto de 2 en la mejora que se puede obtener del manejo de la pluralización (a través del modelo oráculo), el rendimiento actual en consultas cortas es muy satisfactorio. Para consultas breves, la ganancia máxima de DCG es del 6.3% para el manejo perfecto de la pluralización, nuestra ganancia actual es del 4.7% con un modelo de lenguaje de bigrama. Para consultas largas, la ganancia máxima de DCG es del 4.6% para el manejo perfecto de la pluralización, nuestra ganancia actual es del 2.5% con un modelo de lenguaje de bigrama. Podríamos obtener beneficios adicionales con un modelo de lenguaje más potente para consultas largas. Sin embargo, las dificultades de las consultas largas provienen de muchos otros aspectos, incluyendo la proximidad y el problema de la segmentación. Estos problemas deben ser abordados por separado. Al observar el límite superior de reducción de gastos generales para el truncamiento de Oracle, el 75% (308/408) de los truncamientos ingenuos son inútiles. Actualmente capturamos alrededor de la mitad de ellos. La reducción adicional de los gastos generales requiere sacrificar la ganancia de la DCG. Ahora podemos comparar las estrategias de derivación desde un aspecto diferente. En lugar de analizar la influencia sobre todas las consultas como describimos anteriormente, la Tabla 6 resume las mejoras de DCG solo sobre las consultas afectadas. Podemos ver que el número de consultas afectadas disminuye a medida que la estrategia de derivación se vuelve más precisa (mejora en el dcg). Para el modelo de lenguaje de bigrama, sobre las 250/408 consultas truncadas, la mejora en DCG es del 6.1%. Una observación interesante es que el dcg promedio disminuye con un modelo mejor, lo que indica que una estrategia de derivación mejorada deriva consultas más difíciles (consultas con bajo dcg). 5. Como mencionamos en la Sección 1, estamos tratando de predecir la probabilidad de que una cadena ocurra en la Web. El modelo de lenguaje debe describir la ocurrencia de la cadena en la web. Sin embargo, el registro de consultas también es un buen recurso. Tenga en cuenta que este límite superior es solo para el manejo de pluralización, no para el truncamiento general. El stemming general proporciona un límite superior del 8%, lo cual es bastante sustancial en términos de nuestras métricas. Las consultas afectadas dcg dcg Mejora p-valor línea de base 0/408 7.102 N/A N/A modelo ingenuo 408/408 7.206 1.5% 0.22 modelo sensible al contexto del documento 408/408 7.302 2.8% 0.014 modelo selectivo: unigram LM 300/408 7.321 3.4% 0.001 modelo selectivo: bigram LM 250/408 7.381 3.9% 0.001 modelo oráculo 100/408 7.519 5.9% 0.001 Tabla 4: Comparación de resultados de diferentes estrategias de derivación en todas las consultas afectadas por la derivación ingenua Resultados de Consultas Cortas Consultas Afectadas dcg Mejora p-valor línea de base 0/272 N/A N/A modelo ingenuo 272/272 2.7% 0.48 modelo sensible al contexto del documento 272/272 4.2% 0.002 modelo selectivo: unigram LM 185/272 4.4% 0.001 modelo selectivo: bigram LM 150/272 4.7% 0.001 modelo oráculo 71/272 6.3% 0.001 Resultados de Consultas Largas Consultas Afectadas dcg Mejora p-valor línea de base 0/136 N/A N/A modelo ingenuo 136/136 -2.4% 0.25 modelo sensible al contexto del documento 136/136 -1.6% 0.27 modelo selectivo: unigram LM 115/136 1.1% 0.001 modelo selectivo: bigram LM 100/136 2.5% 0.001 modelo oráculo 29/136 4.6% 0.001 Tabla 5: Comparación de resultados de diferentes estrategias de derivación en consultas cortas y largas en general Los usuarios reformulan una consulta utilizando muchas variantes diferentes para obtener buenos resultados. Para probar la hipótesis de que podemos aprender probabilidades de transformación confiables a partir del registro de consultas, entrenamos un modelo de lenguaje con las mismas 25 millones de consultas principales utilizadas para aprender la segmentación, y lo utilizamos para la predicción. Observamos una ligera disminución en el rendimiento en comparación con el modelo entrenado en frecuencias web. En particular, el rendimiento para el modelo de lenguaje unigrama no se vio afectado, pero la ganancia de dcg para el modelo de lenguaje bigrama cambió de 4.7% a 4.5% para consultas cortas. Por lo tanto, el registro de consultas puede servir como una buena aproximación de las frecuencias web. 5.2 Cómo la lingüística ayuda. Algunos conocimientos lingüísticos son útiles en el stemming. Para el manejo de la pluralización, la pluralización y la despluralización no son simétricas. Una palabra en plural utilizada en una consulta indica una intención especial. Por ejemplo, la consulta hoteles en Nueva York está buscando una lista de hoteles en Nueva York, no el hotel específico de Nueva York que podría estar ubicado en California. Una simple equivalencia de hotel a hoteles podría impulsar una página en particular sobre hoteles en Nueva York al primer puesto. Para capturar esta intención, tenemos que asegurarnos de que el documento sea una página general sobre hoteles en Nueva York. Esto lo hacemos exigiendo que la palabra en plural hoteles aparezca en el documento. Por otro lado, convertir una palabra singular a plural es más seguro ya que una página de propósito general normalmente contiene información específica. Observamos una ligera disminución general en el dcg, aunque no estadísticamente significativa, para el stemming sensible al contexto del documento si no consideramos esta propiedad asimétrica. Análisis de errores. Un tipo de errores que notamos, aunque raros pero que afectan seriamente la relevancia, es el cambio de intención de búsqueda después del stemming. En general, la pluralización o despluralización mantiene la intención original. Sin embargo, la intención podría cambiar en algunos casos. Por ejemplo, para una consulta de este tipo, trabajo en Apple, pluralizamos trabajo a trabajos. Este truncamiento hace que la consulta original sea ambigua. El trabajo de consulta O trabajos en Apple tiene dos intenciones. Una de las oportunidades laborales en Apple, y otra es una persona que trabaja en Apple, Steve Jobs, quien es el CEO y cofundador de la empresa. Por lo tanto, los resultados después de la reducción de consultas devuelven a Steve Jobs como uno de los resultados en el top 5. Una solución es realizar un análisis basado en el conjunto de resultados para verificar si la intención ha cambiado. Esto es similar a la retroalimentación de relevancia y requiere una clasificación en la segunda fase. Un segundo tipo de errores es el problema de reconocimiento de entidades/conceptos. Estos incluyen dos tipos. Una de ellas es que la variante de la palabra derivada ahora coincide con parte de una entidad o concepto. Por ejemplo, la consulta \"cookies en San Francisco\" se pluraliza como \"cookies\" O \"cookie en San Francisco\". Los resultados coincidirán con el tarro de galletas en San Francisco. Aunque \"cookie\" todavía significa lo mismo que \"galletas\", el concepto de \"cookie jar\" es diferente. Otro tipo es la palabra no derivada que coincide con una entidad o concepto debido al truncamiento de las otras palabras. Por ejemplo, la cita ICE se pluraliza como cita OR citas ICE. La intención original de esta consulta es buscar la cotización de acciones para el símbolo ICE. Sin embargo, notamos que entre los resultados principales, uno de los resultados es Citas sobre comida: Helado. Esto se empareja debido a las consultas afectadas dcg antiguas nuevas dcg dcg Mejora del modelo ingenuo 408/408 7.102 7.206 1.5% modelo sensible al contexto del documento 408/408 7.102 7.302 2.8% modelo selectivo: unigram LM 300/408 5.904 6.187 4.8% modelo selectivo: bigram LM 250/408 5.551 5.891 6.1% Tabla 6: Comparación de resultados solo sobre las consultas derivadas: la columna dcg antigua/nueva es la puntuación dcg sobre las consultas afectadas antes/después de aplicar la pluralización de la palabra entre comillas. La palabra inalterada ICE coincide con parte de la frase nominal helado aquí. Para resolver este tipo de problema, tenemos que analizar los documentos y reconocer \"cookie jar\" y \"ice cream\" como conceptos en lugar de dos palabras independientes. Un tercer tipo de errores ocurre en consultas largas. Para la consulta de software lector de códigos de barras, se pluralizan dos palabras. Códigos y lector. De hecho, el lector de códigos de barras en la consulta original es un concepto sólido y las palabras internas no deben ser cambiadas. Este es el problema de segmentación y detección de entidades y frases nominales en consultas, el cual estamos abordando activamente. Para consultas largas, debemos identificar correctamente los conceptos en la consulta y aumentar la proximidad de las palabras dentro de un concepto. 6. CONCLUSIONES Y TRABAJOS FUTUROS Hemos presentado una forma simple pero elegante de derivar palabras para la búsqueda en la web. Mejora el stemming ingenuo en dos aspectos: la expansión selectiva de palabras en el lado de la consulta y la coincidencia conservadora de ocurrencias de palabras en el lado del documento. Usando el manejo de pluralización como ejemplo, experimentos con datos de un motor de búsqueda web importante muestran que mejora significativamente la relevancia web y reduce el costo de derivación. También mejora significativamente la tasa de clics en la web (detalles no reportados en el artículo). Para el trabajo futuro, estamos investigando los problemas que identificamos en la sección de análisis de errores. Estos incluyen: errores de concordancia entre entidades y frases nominales, y una segmentación mejorada. 7. REFERENCIAS [1] E. Agichtein, E. Brill y S. T. Dumais. Mejorando la clasificación de búsqueda web al incorporar información sobre el comportamiento del usuario. En SIGIR, 2006. [2] E. Airio. Normalización de palabras y descomposición en IR monolingüe y bilingüe. Recuperación de información, 9:249-271, 2006. [3] P. Anick. Utilizando retroalimentación terminológica para el refinamiento de la búsqueda web: un estudio basado en registros. En SIGIR, 2003. [4] R. Baeza-Yates y B. Ribeiro-Neto. Recuperación de información moderna. ACM Press/Addison Wesley, 1999. [5] S. Chen y J. Goodman. Un estudio empírico de técnicas de suavizado para modelado del lenguaje. Informe técnico TR-10-98, Universidad de Harvard, 1998. [6] S. Cronen-Townsend, Y. Zhou y B. Croft. Un marco para la expansión selectiva de consultas. En CIKM, 2004. [7] H. Fang y C. Zhai. Coincidencia de términos semánticos en enfoques axiomáticos para la recuperación de información. En SIGIR, 2006. [8] W. B. Frakes. Confluencia de términos para la recuperación de información. En C. J. Rijsbergen, editor, Investigación y Desarrollo en Recuperación de Información, páginas 383-389. Cambridge University Press, 1984. [9] D. Harman.\nCambridge University Press, 1984. [9] D. Harman. ¿Qué tan efectivo es el sufijado? JASIS, 42(1):7-15, 1991. [10] D. Hull.\nJASIS, 42(1):7-15, 1991. [10] D. Hull. Algoritmos de derivación: un estudio de caso para una evaluación detallada. JASIS, 47(1):70-84, 1996. [11] K. Jarvelin y J. Kekalainen. Evaluación basada en la ganancia acumulada de técnicas de RI. ACM TOIS, 20:422-446, 2002. [12] R. Jones, B. Rey, O. Madani y W. Greiner. Generando Sustituciones de Consultas. En WWW, 2006. [13] W. Kraaij y R. Pohlmann. Viendo el Stemming como Mejora de la Recuperación. En SIGIR, 1996. [14] R. Krovetz. Viendo la morfología como un proceso de inferencia. En SIGIR, 1993. [15] D. Lin. Recuperación automática y agrupamiento de palabras similares. En COLING-ACL, 1998. [16] J. B. Lovins. Desarrollo de un algoritmo de derivación. Traducción Mecánica y Lingüística Computacional, II:22-31, 1968. [17] M. Lennon, D. Peirce, B. Tarry y P. Willett. Una evaluación de algunos algoritmos de confluencia para la recuperación de información. Revista de Ciencia de la Información, 3:177-188, 1981. [18] M. Porter. Un algoritmo para el recorte de sufijos. Programa, 14(3):130-137, 1980. [19] K. M. Risvik, T. Mikolajewski y P. Boros. Segmentación de consultas para búsqueda web. En WWW, 2003. [20] S. E. Robertson. Selección de términos para la expansión de consultas. Revista de Documentación, 46(4):359-364, 1990. [21] G. Salton y C. Buckley. Mejorando el rendimiento de recuperación mediante retroalimentación de relevancia. JASIS, 41(4):288 - 297, 1999. [22] R. Sun, C.-H. Ong, y T.-S. Chua. Extracción de relaciones de dependencia para la expansión de consultas en la recuperación de pasajes. En SIGIR, 2006. [23] C. Van Rijsbergen. Recuperación de información. Butterworths, segunda versión, 1979. [24] B. Vélez, R. Weiss, M. A. Sheldon y D. K. Gifford. Refinamiento de consultas rápido y efectivo. En SIGIR, 1997. [25] J. Xu y B. Croft. Expansión de consultas utilizando análisis local y global de documentos. En SIGIR, 1996. [26] J. Xu y B. Croft. Extracción de raíces basada en corpus utilizando la coocurrencia de variantes de palabras. ACM TOIS, 16 (1):61-81, 1998. ",
            "candidates": [],
            "error": [
                [
                    "segmentación de consultas",
                    "segmentación de consultas",
                    "análisis de consultas"
                ]
            ]
        },
        "head word detection": {
            "translated_key": "detección de palabras clave",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Context Sensitive Stemming for Web Search Fuchun Peng Nawaaz Ahmed Xin Li Yumao Lu Yahoo!",
                "Inc. 701 First Avenue Sunnyvale, California 94089 {fuchun, nawaaz, xinli, yumaol}@yahoo-inc.com ABSTRACT Traditionally, stemming has been applied to Information Retrieval tasks by transforming words in documents to the their root form before indexing, and applying a similar transformation to query terms.",
                "Although it increases recall, this naive strategy does not work well for Web Search since it lowers precision and requires a significant amount of additional computation.",
                "In this paper, we propose a context sensitive stemming method that addresses these two issues.",
                "Two unique properties make our approach feasible for Web Search.",
                "First, based on statistical language modeling, we perform context sensitive analysis on the query side.",
                "We accurately predict which of its morphological variants is useful to expand a query term with before submitting the query to the search engine.",
                "This dramatically reduces the number of bad expansions, which in turn reduces the cost of additional computation and improves the precision at the same time.",
                "Second, our approach performs a context sensitive document matching for those expanded variants.",
                "This conservative strategy serves as a safeguard against spurious stemming, and it turns out to be very important for improving precision.",
                "Using word pluralization handling as an example of our stemming approach, our experiments on a major Web search engine show that stemming only 29% of the query traffic, we can improve relevance as measured by average Discounted Cumulative Gain (DCG5) by 6.1% on these queries and 1.8% over all query traffic.",
                "Categories and Subject Descriptors H.3.3 [Information Systems]: Information Storage and Retrieval-Query formulation General Terms Algorithms, Experimentation 1.",
                "INTRODUCTION Web search has now become a major tool in our daily lives for information seeking.",
                "One of the important issues in Web search is that user queries are often not best formulated to get optimal results.",
                "For example, running shoe is a query that occurs frequently in query logs.",
                "However, the query running shoes is much more likely to give better search results than the original query because documents matching the intent of this query usually contain the words running shoes.",
                "Correctly formulating a query requires the user to accurately predict which word form is used in the documents that best satisfy his or her information needs.",
                "This is difficult even for experienced users, and especially difficult for non-native speakers.",
                "One traditional solution is to use stemming [16, 18], the process of transforming inflected or derived words to their root form so that a search term will match and retrieve documents containing all forms of the term.",
                "Thus, the word run will match running, ran, runs, and shoe will match shoes and shoeing.",
                "Stemming can be done either on the terms in a document during indexing (and applying the same transformation to the query terms during query processing) or by expanding the query with the variants during query processing.",
                "Stemming during indexing allows very little flexibility during query processing, while stemming by query expansion allows handling each query differently, and hence is preferred.",
                "Although traditional stemming increases recall by matching word variants [13], it can reduce precision by retrieving too many documents that have been incorrectly matched.",
                "When examining the results of applying stemming to a large number of queries, one usually finds that nearly equal numbers of queries are helped and hurt by the technique [6].",
                "In addition, it reduces system performance because the search engine has to match all the word variants.",
                "As we will show in the experiments, this is true even if we simplify stemming to pluralization handling, which is the process of converting a word from its plural to singular form, or vice versa.",
                "Thus, one needs to be very cautious when using stemming in Web search engines.",
                "One problem of traditional stemming is its blind transformation of all query terms, that is, it always performs the same transformation for the same query word without considering the context of the word.",
                "For example, the word book has four forms book, books, booking, booked, and store has four forms store, stores, storing, stored.",
                "For the query book store, expanding both words to all of their variants significantly increases computation cost and hurts precision, since not all of the variants are useful for this query.",
                "Transforming book store to match book stores is fine, but matching book storing or booking store is not.",
                "A weighting method that gives variant words smaller weights alleviates the problems to a certain extent if the weights accurately reflect the importance of the variant in this particular query.",
                "However uniform weighting is not going to work and a query dependent weighting is still a challenging unsolved problem [20].",
                "A second problem of traditional stemming is its blind matching of all occurrences in documents.",
                "For the query book store, a transformation that allows the variant stores to be matched will cause every occurrence of stores in the document to be treated equivalent to the query term store.",
                "Thus, a document containing the fragment reading a book in coffee stores will be matched, causing many wrong documents to be selected.",
                "Although we hope the ranking function can correctly handle these, with many more candidates to rank, the risk of making mistakes increases.",
                "To alleviate these two problems, we propose a context sensitive stemming approach for Web search.",
                "Our solution consists of two context sensitive analysis, one on the query side and the other on the document side.",
                "On the query side, we propose a statistical language modeling based approach to predict which word variants are better forms than the original word for search purpose and expanding the query with only those forms.",
                "On the document side, we propose a conservative context sensitive matching for the transformed word variants, only matching document occurrences in the context of other terms in the query.",
                "Our model is simple yet effective and efficient, making it feasible to be used in real commercial Web search engines.",
                "We use pluralization handling as a running example for our stemming approach.",
                "The motivation for using pluralization handling as an example is to show that even such simple stemming, if handled correctly, can give significant benefits to search relevance.",
                "As far as we know, no previous research has systematically investigated the usage of pluralization in Web search.",
                "As we have to point out, the method we propose is not limited to pluralization handling, it is a general stemming technique, and can also be applied to general query expansion.",
                "Experiments on general stemming yield additional significant improvements over pluralization handling for long queries, although details will not be reported in this paper.",
                "In the rest of the paper, we first present the related work and distinguish our method from previous work in Section 2.",
                "We describe the details of the context sensitive stemming approach in Section 3.",
                "We then perform extensive experiments on a major Web search engine to support our claims in Section 4, followed by discussions in Section 5.",
                "Finally, we conclude the paper in Section 6. 2.",
                "RELATED WORK Stemming is a long studied technology.",
                "Many stemmers have been developed, such as the Lovins stemmer [16] and the Porter stemmer [18].",
                "The Porter stemmer is widely used due to its simplicity and effectiveness in many applications.",
                "However, the Porter stemming makes many mistakes because its simple rules cannot fully describe English morphology.",
                "Corpus analysis is used to improve Porter stemmer [26] by creating equivalence classes for words that are morphologically similar and occur in similar context as measured by expected mutual information [23].",
                "We use a similar corpus based approach for stemming by computing the similarity between two words based on their distributional context features which can be more than just adjacent words [15], and then only keep the morphologically similar words as candidates.",
                "Using stemming in information retrieval is also a well known technique [8, 10].",
                "However, the effectiveness of stemming for English query systems was previously reported to be rather limited.",
                "Lennon et al. [17] compared the Lovins and Porter algorithms and found little improvement in retrieval performance.",
                "Later, Harman [9] compares three general stemming techniques in text retrieval experiments including pluralization handing (called S stemmer in the paper).",
                "They also proposed selective stemming based on query length and term importance, but no positive results were reported.",
                "On the other hand, Krovetz [14] performed comparisons over small numbers of documents (from 400 to 12k) and showed dramatic precision improvement (up to 45%).",
                "However, due to the limited number of tested queries (less than 100) and the small size of the collection, the results are hard to generalize to Web search.",
                "These mixed results, mostly failures, led early IR researchers to deem stemming irrelevant in general for English [4], although recent research has shown stemming has greater benefits for retrieval in other languages [2].",
                "We suspect the previous failures were mainly due to the two problems we mentioned in the introduction.",
                "Blind stemming, or a simple query length based selective stemming as used in [9] is not enough.",
                "Stemming has to be decided on case by case basis, not only at the query level but also at the document level.",
                "As we will show, if handled correctly, significant improvement can be achieved.",
                "A more general problem related to stemming is query reformulation [3, 12] and query expansion which expands words not only with word variants [7, 22, 24, 25].",
                "To decide which expanded words to use, people often use pseudorelevance feedback techniquesthat send the original query to a search engine and retrieve the top documents, extract relevant words from these top documents as additional query words, and resubmit the expanded query again [21].",
                "This normally requires sending a query multiple times to search engine and it is not cost effective for processing the huge amount of queries involved in Web search.",
                "In addition, query expansion, including query reformulation [3, 12], has a high risk of changing the user intent (called query drift).",
                "Since the expanded words may have different meanings, adding them to the query could potentially change the intent of the original query.",
                "Thus query expansion based on pseudorelevance and query reformulation can provide suggestions to users for interactive refinement but can hardly be directly used for Web search.",
                "On the other hand, stemming is much more conservative since most of the time, stemming preserves the original search intent.",
                "While most work on query expansion focuses on recall enhancement, our work focuses on increasing both recall and precision.",
                "The increase on recall is obvious.",
                "With quality stemming, good documents which were not selected before stemming will be pushed up and those low quality documents will be degraded.",
                "On selective query expansion, Cronen-Townsend et al. [6] proposed a method for selective query expansion based on comparing the Kullback-Leibler divergence of the results from the unexpanded query and the results from the expanded query.",
                "This is similar to the relevance feedback in the sense that it requires multiple passes retrieval.",
                "If a word can be expanded into several words, it requires running this process multiple times to decide which expanded word is useful.",
                "It is expensive to deploy this in production Web search engines.",
                "Our method predicts the quality of expansion based on oﬄine information without sending the query to a search engine.",
                "In summary, we propose a novel approach to attack an old, yet still important and challenging problem for Web search - stemming.",
                "Our approach is unique in that it performs predictive stemming on a per query basis without relevance feedback from the Web, using the context of the variants in documents to preserve precision.",
                "Its simple, yet very efficient and effective, making real time stemming feasible for Web search.",
                "Our results will affirm researchers that stemming is indeed very important to large scale information retrieval. 3.",
                "CONTEXT SENSITIVE STEMMING 3.1 Overview Our system has four components as illustrated in Figure 1: candidate generation, query segmentation and <br>head word detection</br>, context sensitive query stemming and context sensitive document matching.",
                "Candidate generation (component 1) is performed oﬄine and generated candidates are stored in a dictionary.",
                "For an input query, we first segment query into concepts and detect the head word for each concept (component 2).",
                "We then use statistical language modeling to decide whether a particular variant is useful (component 3), and finally for the expanded variants, we perform context sensitive document matching (component 4).",
                "Below we discuss each of the components in more detail.",
                "Component 4: context sensitive document matching Input Query: and <br>head word detection</br> Component 2: segment Component 1: candidate generation comparisons −> comparison Component 3: selective word expansion decision: comparisons −> comparison example: hotel price comparisons output: hotel comparisons hotel −> hotels Figure 1: System Components 3.2 Expansion candidate generation One of the ways to generate candidates is using the Porter stemmer [18].",
                "The Porter stemmer simply uses morphological rules to convert a word to its base form.",
                "It has no knowledge of the semantic meaning of the words and sometimes makes serious mistakes, such as executive to execution, news to new, and paste to past.",
                "A more conservative way is based on using corpus analysis to improve the Porter stemmer results [26].",
                "The corpus analysis we do is based on word distributional similarity [15].",
                "The rationale of using distributional word similarity is that true variants tend to be used in similar contexts.",
                "In the distributional word similarity calculation, each word is represented with a vector of features derived from the context of the word.",
                "We use the bigrams to the left and right of the word as its context features, by mining a huge Web corpus.",
                "The similarity between two words is the cosine similarity between the two corresponding feature vectors.",
                "The top 20 similar words to develop is shown in the following table. rank candidate score rank candidate score 0 develop 1 10 berts 0.119 1 developing 0.339 11 wads 0.116 2 developed 0.176 12 developer 0.107 3 incubator 0.160 13 promoting 0.100 4 develops 0.150 14 developmental 0.091 5 development 0.148 15 reengineering 0.090 6 tutoring 0.138 16 build 0.083 7 analyzing 0.128 17 construct 0.081 8 developement 0.128 18 educational 0.081 9 automation 0.126 19 institute 0.077 Table 1: Top 20 most similar candidates to word develop.",
                "Column score is the similarity score.",
                "To determine the stemming candidates, we apply a few Porter stemmer [18] morphological rules to the similarity list.",
                "After applying these rules, for the word develop, the stemming candidates are developing, developed, develops, development, developement, developer, developmental.",
                "For the pluralization handling purpose, only the candidate develops is retained.",
                "One thing we note from observing the distributionally similar words is that they are closely related semantically.",
                "These words might serve as candidates for general query expansion, a topic we will investigate in the future. 3.3 Segmentation and headword identification For long queries, it is quite important to detect the concepts in the query and the most important words for those concepts.",
                "We first break a query into segments, each segment representing a concept which normally is a noun phrase.",
                "For each of the noun phrases, we then detect the most important word which we call the head word.",
                "Segmentation is also used in document sensitive matching (section 3.5) to enforce proximity.",
                "To break a query into segments, we have to define a criteria to measure the strength of the relation between words.",
                "One effective method is to use mutual information as an indicator on whether or not to split two words [19].",
                "We use a log of 25M queries and collect the bigram and unigram frequencies from it.",
                "For every incoming query, we compute the mutual information of two adjacent words; if it passes a predefined threshold, we do not split the query between those two words and move on to next word.",
                "We continue this process until the mutual information between two words is below the threshold, then create a concept boundary here.",
                "Table 2 shows some examples of query segmentation.",
                "The ideal way of finding the head word of a concept is to do syntactic parsing to determine the dependency structure of the query.",
                "Query parsing is more difficult than sentence [running shoe] [best] [new york] [medical schools] [pictures] [of] [white house] [cookies] [in] [san francisco] [hotel] [price comparison] Table 2: Query segmentation: a segment is bracketed. parsing since many queries are not grammatical and are very short.",
                "Applying a parser trained on sentences from documents to queries will have poor performance.",
                "In our solution, we just use simple heuristics rules, and it works very well in practice for English.",
                "For an English noun phrase, the head word is typically the last nonstop word, unless the phrase is of a particular pattern, like XYZ of/in/at/from UVW.",
                "In such cases, the head word is typically the last nonstop word of XYZ. 3.4 Context sensitive word expansion After detecting which words are the most important words to expand, we have to decide whether the expansions will be useful.",
                "Our statistics show that about half of the queries can be transformed by pluralization via naive stemming.",
                "Among this half, about 25% of the queries improve relevance when transformed, the majority (about 50%) do not change their top 5 results, and the remaining 25% perform worse.",
                "Thus, it is extremely important to identify which queries should not be stemmed for the purpose of maximizing relevance improvement and minimizing stemming cost.",
                "In addition, for a query with multiple words that can be transformed, or a word with multiple variants, not all of the expansions are useful.",
                "Taking query hotel price comparison as an example, we decide that hotel and price comparison are two concepts.",
                "Head words hotel and comparison can be expanded to hotels and comparisons.",
                "Are both transformations useful?",
                "To test whether an expansion is useful, we have to know whether the expanded query is likely to get more relevant documents from the Web, which can be quantified by the probability of the query occurring as a string on the Web.",
                "The more likely a query to occur on the Web, the more relevant documents this query is able to return.",
                "Now the whole problem becomes how to calculate the probability of query to occur on the Web.",
                "Calculating the probability of string occurring in a corpus is a well known language modeling problem.",
                "The goal of language modeling is to predict the probability of naturally occurring word sequences, s = w1w2...wN ; or more simply, to put high probability on word sequences that actually occur (and low probability on word sequences that never occur).",
                "The simplest and most successful approach to language modeling is still based on the n-gram model.",
                "By the chain rule of probability one can write the probability of any word sequence as Pr(w1w2...wN ) = NY i=1 Pr(wi|w1...wi−1) (1) An n-gram model approximates this probability by assuming that the only words relevant to predicting Pr(wi|w1...wi−1) are the previous n − 1 words; i.e.",
                "Pr(wi|w1...wi−1) = Pr(wi|wi−n+1...wi−1) A straightforward maximum likelihood estimate of n-gram probabilities from a corpus is given by the observed frequency of each of the patterns Pr(wi|wi−n+1...wi−1) = #(wi−n+1...wi) #(wi−n+1...wi−1) (2) where #(.) denotes the number of occurrences of a specified gram in the training corpus.",
                "Although one could attempt to use simple n-gram models to capture long range dependencies in language, attempting to do so directly immediately creates sparse data problems: Using grams of length up to n entails estimating the probability of Wn events, where W is the size of the word vocabulary.",
                "This quickly overwhelms modern computational and data resources for even modest choices of n (beyond 3 to 6).",
                "Also, because of the heavy tailed nature of language (i.e.",
                "Zipfs law) one is likely to encounter novel n-grams that were never witnessed during training in any test corpus, and therefore some mechanism for assigning non-zero probability to novel n-grams is a central and unavoidable issue in statistical language modeling.",
                "One standard approach to smoothing probability estimates to cope with sparse data problems (and to cope with potentially missing n-grams) is to use some sort of back-off estimator.",
                "Pr(wi|wi−n+1...wi−1) = 8 >>< >>: ˆPr(wi|wi−n+1...wi−1), if #(wi−n+1...wi) > 0 β(wi−n+1...wi−1) × Pr(wi|wi−n+2...wi−1), otherwise (3) where ˆPr(wi|wi−n+1...wi−1) = discount #(wi−n+1...wi) #(wi−n+1...wi−1) (4) is the discounted probability and β(wi−n+1...wi−1) is a normalization constant β(wi−n+1...wi−1) = 1 − X x∈(wi−n+1...wi−1x) ˆPr(x|wi−n+1...wi−1) 1 − X x∈(wi−n+1...wi−1x) ˆPr(x|wi−n+2...wi−1) (5) The discounted probability (4) can be computed with different smoothing techniques, including absolute smoothing, Good-Turing smoothing, linear smoothing, and Witten-Bell smoothing [5].",
                "We used absolute smoothing in our experiments.",
                "Since the likelihood of a string, Pr(w1w2...wN ), is a very small number and hard to interpret, we use entropy as defined below to score the string.",
                "Entropy = − 1 N log2 Pr(w1w2...wN ) (6) Now getting back to the example of the query hotel price comparisons, there are four variants of this query, and the entropy of these four candidates are shown in Table 3.",
                "We can see that all alternatives are less likely than the input query.",
                "It is therefore not useful to make an expansion for this query.",
                "On the other hand, if the input query is hotel price comparisons which is the second alternative in the table, then there is a better alternative than the input query, and it should therefore be expanded.",
                "To tolerate the variations in probability estimation, we relax the selection criterion to those query alternatives if their scores are within a certain distance (10% in our experiments) to the best score.",
                "Query variations Entropy hotel price comparison 6.177 hotel price comparisons 6.597 hotels price comparison 6.937 hotels price comparisons 7.360 Table 3: Variations of query hotel price comparison ranked by entropy score, with the original query in bold face. 3.5 Context sensitive document matching Even after we know which word variants are likely to be useful, we have to be conservative in document matching for the expanded variants.",
                "For the query hotel price comparisons, we decided that word comparisons is expanded to include comparison.",
                "However, not every occurrence of comparison in the document is of interest.",
                "A page which is about comparing customer service can contain all of the words hotel price comparisons comparison.",
                "This page is not a good page for the query.",
                "If we accept matches of every occurrence of comparison, it will hurt retrieval precision and this is one of the main reasons why most stemming approaches do not work well for information retrieval.",
                "To address this problem, we have a proximity constraint that considers the context around the expanded variant in the document.",
                "A variant match is considered valid only if the variant occurs in the same context as the original word does.",
                "The context is the left or the right non-stop segments 1 of the original word.",
                "Taking the same query as an example, the context of comparisons is price.",
                "The expanded word comparison is only valid if it is in the same context of comparisons, which is after the word price.",
                "Thus, we should only match those occurrences of comparison in the document if they occur after the word price.",
                "Considering the fact that queries and documents may not represent the intent in exactly the same way, we relax this proximity constraint to allow variant occurrences within a window of some fixed size.",
                "If the expanded word comparison occurs within the context of price within a window, it is considered valid.",
                "The smaller the window size is, the more restrictive the matching.",
                "We use a window size of 4, which typically captures contexts that include the containing and adjacent noun phrases. 4.",
                "EXPERIMENTAL EVALUATION 4.1 Evaluation metrics We will measure both relevance improvement and the stemming cost required to achieve the relevance. 1 a context segment can not be a single stop word. 4.1.1 Relevance measurement We use a variant of the average Discounted Cumulative Gain (DCG), a recently popularized scheme to measure search engine relevance [1, 11].",
                "Given a query and a ranked list of K documents (K is set to 5 in our experiments), the DCG(K) score for this query is calculated as follows: DCG(K) = KX k=1 gk log2(1 + k) . (7) where gk is the weight for the document at rank k. Higher degree of relevance corresponds to a higher weight.",
                "A page is graded into one of the five scales: Perfect, Excellent, Good, Fair, Bad, with corresponding weights.",
                "We use dcg to represent the average DCG(5) over a set of test queries. 4.1.2 Stemming cost Another metric is to measure the additional cost incurred by stemming.",
                "Given the same level of relevance improvement, we prefer a stemming method that has less additional cost.",
                "We measure this by the percentage of queries that are actually stemmed, over all the queries that could possibly be stemmed. 4.2 Data preparation We randomly sample 870 queries from a three month query log, with 290 from each month.",
                "Among all these 870 queries, we remove all misspelled queries since misspelled queries are not of interest to stemming.",
                "We also remove all one word queries since stemming one word queries without context has a high risk of changing query intent, especially for short words.",
                "In the end, we have 529 correctly spelled queries with at least 2 words. 4.3 Naive stemming for Web search Before explaining the experiments and results in detail, wed like to describe the traditional way of using stemming for Web search, referred as the naive model.",
                "This is to treat every word variant equivalent for all possible words in the query.",
                "The query book store will be transformed into (book OR books)(store OR stores) when limiting stemming to pluralization handling only, where OR is an operator that denotes the equivalence of the left and right arguments. 4.4 Experimental setup The baseline model is the model without stemming.",
                "We first run the naive model to see how well it performs over the baseline.",
                "Then we improve the naive stemming model by document sensitive matching, referred as document sensitive matching model.",
                "This model makes the same stemming as the naive model on the query side, but performs conservative matching on the document side using the strategy described in section 3.5.",
                "The naive model and document sensitive matching model stem the most queries.",
                "Out of the 529 queries, there are 408 queries that they stem, corresponding to 46.7% query traffic (out of a total of 870).",
                "We then further improve the document sensitive matching model from the query side with selective word stemming based on statistical language modeling (section 3.4), referred as selective stemming model.",
                "Based on language modeling prediction, this model stems only a subset of the 408 queries stemmed by the document sensitive matching model.",
                "We experiment with unigram language model and bigram language model.",
                "Since we only care how much we can improve the naive model, we will only use these 408 queries (all the queries that are affected by the naive stemming model) in the experiments.",
                "To get a sense of how these models perform, we also have an oracle model that gives the upper-bound performance a stemmer can achieve on this data.",
                "The oracle model only expands a word if the stemming will give better results.",
                "To analyze the pluralization handling influence on different query categories, we divide queries into short queries and long queries.",
                "Among the 408 queries stemmed by the naive model, there are 272 short queries with 2 or 3 words, and 136 long queries with at least 4 words. 4.5 Results We summarize the overall results in Table 4, and present the results on short queries and long queries separately in Table 5.",
                "Each row in Table 4 is a stemming strategy described in section 4.4.",
                "The first column is the name of the strategy.",
                "The second column is the number of queries affected by this strategy; this column measures the stemming cost, and the numbers should be low for the same level of dcg.",
                "The third column is the average dcg score over all tested queries in this category (including the ones that were not stemmed by the strategy).",
                "The fourth column is the relative improvement over the baseline, and the last column is the p-value of Wilcoxon significance test.",
                "There are several observations about the results.",
                "We can see the naively stemming only obtains a statistically insignificant improvement of 1.5%.",
                "Looking at Table 5, it gives an improvement of 2.7% on short queries.",
                "However, it also hurts long queries by -2.4%.",
                "Overall, the improvement is canceled out.",
                "The reason that it improves short queries is that most short queries only have one word that can be stemmed.",
                "Thus, blindly pluralizing short queries is relatively safe.",
                "However for long queries, most queries can have multiple words that can be pluralized.",
                "Expanding all of them without selection will significantly hurt precision.",
                "Document context sensitive stemming gives a significant lift to the performance, from 2.7% to 4.2% for short queries and from -2.4% to -1.6% for long queries, with an overall lift from 1.5% to 2.8%.",
                "The improvement comes from the conservative context sensitive document matching.",
                "An expanded word is valid only if it occurs within the context of original query in the document.",
                "This reduces many spurious matches.",
                "However, we still notice that for long queries, context sensitive stemming is not able to improve performance because it still selects too many documents and gives the ranking function a hard problem.",
                "While the chosen window size of 4 works the best amongst all the choices, it still allows spurious matches.",
                "It is possible that the window size needs to be chosen on a per query basis to ensure tighter proximity constraints for different types of noun phrases.",
                "Selective word pluralization further helps resolving the problem faced by document context sensitive stemming.",
                "It does not stem every word that places all the burden on the ranking algorithm, but tries to eliminate unnecessary stemming in the first place.",
                "By predicting which word variants are going to be useful, we can dramatically reduce the number of stemmed words, thus improving both the recall and the precision.",
                "With the unigram language model, we can reduce the stemming cost by 26.7% (from 408/408 to 300/408) and lift the overall dcg improvement from 2.8% to 3.4%.",
                "In particular, it gives significant improvements on long queries.",
                "The dcg gain is turned from negative to positive, from −1.6% to 1.1%.",
                "This confirms our hypothesis that reducing unnecessary word expansion leads to precision improvement.",
                "For short queries too, we observe both dcg improvement and stemming cost reduction with the unigram language model.",
                "The advantages of predictive word expansion with a language model is further boosted with a better bigram language model.",
                "The overall dcg gain is lifted from 3.4% to 3.9%, and stemming cost is dramatically reduced from 408/408 to 250/408, corresponding to only 29% of query traffic (250 out of 870) and an overall 1.8% dcg improvement overall all query traffic.",
                "For short queries, bigram language model improves the dcg gain from 4.4% to 4.7%, and reduces stemming cost from 272/272 to 150/272.",
                "For long queries, bigram language model improves dcg gain from 1.1% to 2.5%, and reduces stemming cost from 136/136 to 100/136.",
                "We observe that the bigram language model gives a larger lift for long queries.",
                "This is because the uncertainty in long queries is larger and a more powerful language model is needed.",
                "We hypothesize that a trigram language model would give a further lift for long queries and leave this for future investigation.",
                "Considering the tight upper-bound 2 on the improvement to be gained from pluralization handling (via the oracle model), the current performance on short queries is very satisfying.",
                "For short queries, the dcg gain upper-bound is 6.3% for perfect pluralization handling, our current gain is 4.7% with a bigram language model.",
                "For long queries, the dcg gain upper-bound is 4.6% for perfect pluralization handling, our current gain is 2.5% with a bigram language model.",
                "We may gain additional benefit with a more powerful language model for long queries.",
                "However, the difficulties of long queries come from many other aspects including the proximity and the segmentation problem.",
                "These problems have to be addressed separately.",
                "Looking at the the upper-bound of overhead reduction for oracle stemming, 75% (308/408) of the naive stemmings are wasteful.",
                "We currently capture about half of them.",
                "Further reduction of the overhead requires sacrificing the dcg gain.",
                "Now we can compare the stemming strategies from a different aspect.",
                "Instead of looking at the influence over all queries as we described above, Table 6 summarizes the dcg improvements over the affected queries only.",
                "We can see that the number of affected queries decreases as the stemming strategy becomes more accurate (dcg improvement).",
                "For the bigram language model, over the 250/408 stemmed queries, the dcg improvement is 6.1%.",
                "An interesting observation is the average dcg decreases with a better model, which indicates a better stemming strategy stems more difficult queries (low dcg queries). 5.",
                "DISCUSSIONS 5.1 Language models from query vs. from Web As we mentioned in Section 1, we are trying to predict the probability of a string occurring on the Web.",
                "The language model should describe the occurrence of the string on the Web.",
                "However, the query log is also a good resource. 2 Note that this upperbound is for pluralization handling only, not for general stemming.",
                "General stemming gives a 8% upperbound, which is quite substantial in terms of our metrics.",
                "Affected Queries dcg dcg Improvement p-value baseline 0/408 7.102 N/A N/A naive model 408/408 7.206 1.5% 0.22 document context sensitive model 408/408 7.302 2.8% 0.014 selective model: unigram LM 300/408 7.321 3.4% 0.001 selective model: bigram LM 250/408 7.381 3.9% 0.001 oracle model 100/408 7.519 5.9% 0.001 Table 4: Results comparison of different stemming strategies over all queries affected by naive stemming Short Query Results Affected Queries dcg Improvement p-value baseline 0/272 N/A N/A naive model 272/272 2.7% 0.48 document context sensitive model 272/272 4.2% 0.002 selective model: unigram LM 185/272 4.4% 0.001 selective model: bigram LM 150/272 4.7% 0.001 oracle model 71/272 6.3% 0.001 Long Query Results Affected Queries dcg Improvement p-value baseline 0/136 N/A N/A naive model 136/136 -2.4% 0.25 document context sensitive model 136/136 -1.6% 0.27 selective model: unigram LM 115/136 1.1% 0.001 selective model: bigram LM 100/136 2.5% 0.001 oracle model 29/136 4.6% 0.001 Table 5: Results comparison of different stemming strategies overall short queries and long queries Users reformulate a query using many different variants to get good results.",
                "To test the hypothesis that we can learn reliable transformation probabilities from the query log, we trained a language model from the same query top 25M queries as used to learn segmentation, and use that for prediction.",
                "We observed a slight performance decrease compared to the model trained on Web frequencies.",
                "In particular, the performance for unigram LM was not affected, but the dcg gain for bigram LM changed from 4.7% to 4.5% for short queries.",
                "Thus, the query log can serve as a good approximation of the Web frequencies. 5.2 How linguistics helps Some linguistic knowledge is useful in stemming.",
                "For the pluralization handling case, pluralization and de-pluralization is not symmetric.",
                "A plural word used in a query indicates a special intent.",
                "For example, the query new york hotels is looking for a list of hotels in new york, not the specific new york hotel which might be a hotel located in California.",
                "A simple equivalence of hotel to hotels might boost a particular page about new york hotel to top rank.",
                "To capture this intent, we have to make sure the document is a general page about hotels in new york.",
                "We do this by requiring that the plural word hotels appears in the document.",
                "On the other hand, converting a singular word to plural is safer since a general purpose page normally contains specific information.",
                "We observed a slight overall dcg decrease, although not statistically significant, for document context sensitive stemming if we do not consider this asymmetric property. 5.3 Error analysis One type of mistakes we noticed, though rare but seriously hurting relevance, is the search intent change after stemming.",
                "Generally speaking, pluralization or depluralization keeps the original intent.",
                "However, the intent could change in a few cases.",
                "For one example of such a query, job at apple, we pluralize job to jobs.",
                "This stemming makes the original query ambiguous.",
                "The query job OR jobs at apple has two intents.",
                "One is the employment opportunities at apple, and another is a person working at Apple, Steve Jobs, who is the CEO and co-founder of the company.",
                "Thus, the results after query stemming returns Steve Jobs as one of the results in top 5.",
                "One solution is performing results set based analysis to check if the intent is changed.",
                "This is similar to relevance feedback and requires second phase ranking.",
                "A second type of mistakes is the entity/concept recognition problem, These include two kinds.",
                "One is that the stemmed word variant now matches part of an entity or concept.",
                "For example, query cookies in san francisco is pluralized to cookies OR cookie in san francisco.",
                "The results will match cookie jar in san francisco.",
                "Although cookie still means the same thing as cookies, cookie jar is a different concept.",
                "Another kind is the unstemmed word matches an entity or concept because of the stemming of the other words.",
                "For example, quote ICE is pluralized to quote OR quotes ICE.",
                "The original intent for this query is searching for stock quote for ticker ICE.",
                "However, we noticed that among the top results, one of the results is Food quotes: Ice cream.",
                "This is matched because of Affected Queries old dcg new dcg dcg Improvement naive model 408/408 7.102 7.206 1.5% document context sensitive model 408/408 7.102 7.302 2.8% selective model: unigram LM 300/408 5.904 6.187 4.8% selective model: bigram LM 250/408 5.551 5.891 6.1% Table 6: Results comparison over the stemmed queries only: column old/new dcg is the dcg score over the affected queries before/after applying stemming the pluralized word quotes.",
                "The unchanged word ICE matches part of the noun phrase ice cream here.",
                "To solve this kind of problem, we have to analyze the documents and recognize cookie jar and ice cream as concepts instead of two independent words.",
                "A third type of mistakes occurs in long queries.",
                "For the query bar code reader software, two words are pluralized. code to codes and reader to readers.",
                "In fact, bar code reader in the original query is a strong concept and the internal words should not be changed.",
                "This is the segmentation and entity and noun phrase detection problem in queries, which we actively are attacking.",
                "For long queries, we should correctly identify the concepts in the query, and boost the proximity for the words within a concept. 6.",
                "CONCLUSIONS AND FUTURE WORK We have presented a simple yet elegant way of stemming for Web search.",
                "It improves naive stemming in two aspects: selective word expansion on the query side and conservative word occurrence matching on the document side.",
                "Using pluralization handling as an example, experiments on a major Web search engine data show it significantly improves the Web relevance and reduces the stemming cost.",
                "It also significantly improves Web click through rate (details not reported in the paper).",
                "For the future work, we are investigating the problems we identified in the error analysis section.",
                "These include: entity and noun phrase matching mistakes, and improved segmentation. 7.",
                "REFERENCES [1] E. Agichtein, E. Brill, and S. T. Dumais.",
                "Improving Web Search Ranking by Incorporating User Behavior Information.",
                "In SIGIR, 2006. [2] E. Airio.",
                "Word Normalization and Decompounding in Mono- and Bilingual IR.",
                "Information Retrieval, 9:249-271, 2006. [3] P. Anick.",
                "Using Terminological Feedback for Web Search Refinement: a Log-based Study.",
                "In SIGIR, 2003. [4] R. Baeza-Yates and B. Ribeiro-Neto.",
                "Modern Information Retrieval.",
                "ACM Press/Addison Wesley, 1999. [5] S. Chen and J. Goodman.",
                "An Empirical Study of Smoothing Techniques for Language Modeling.",
                "Technical Report TR-10-98, Harvard University, 1998. [6] S. Cronen-Townsend, Y. Zhou, and B. Croft.",
                "A Framework for Selective Query Expansion.",
                "In CIKM, 2004. [7] H. Fang and C. Zhai.",
                "Semantic Term Matching in Axiomatic Approaches to Information Retrieval.",
                "In SIGIR, 2006. [8] W. B. Frakes.",
                "Term Conflation for Information Retrieval.",
                "In C. J. Rijsbergen, editor, Research and Development in Information Retrieval, pages 383-389.",
                "Cambridge University Press, 1984. [9] D. Harman.",
                "How Effective is Suffixing?",
                "JASIS, 42(1):7-15, 1991. [10] D. Hull.",
                "Stemming Algorithms - A Case Study for Detailed Evaluation.",
                "JASIS, 47(1):70-84, 1996. [11] K. Jarvelin and J. Kekalainen.",
                "Cumulated Gain-Based Evaluation Evaluation of IR Techniques.",
                "ACM TOIS, 20:422-446, 2002. [12] R. Jones, B. Rey, O. Madani, and W. Greiner.",
                "Generating Query Substitutions.",
                "In WWW, 2006. [13] W. Kraaij and R. Pohlmann.",
                "Viewing Stemming as Recall Enhancement.",
                "In SIGIR, 1996. [14] R. Krovetz.",
                "Viewing Morphology as an Inference Process.",
                "In SIGIR, 1993. [15] D. Lin.",
                "Automatic Retrieval and Clustering of Similar Words.",
                "In COLING-ACL, 1998. [16] J.",
                "B. Lovins.",
                "Development of a Stemming Algorithm.",
                "Mechanical Translation and Computational Linguistics, II:22-31, 1968. [17] M. Lennon and D. Peirce and B. Tarry and P. Willett.",
                "An Evaluation of Some Conflation Algorithms for Information Retrieval.",
                "Journal of Information Science, 3:177-188, 1981. [18] M. Porter.",
                "An Algorithm for Suffix Stripping.",
                "Program, 14(3):130-137, 1980. [19] K. M. Risvik, T. Mikolajewski, and P. Boros.",
                "Query Segmentation for Web Search.",
                "In WWW, 2003. [20] S. E. Robertson.",
                "On Term Selection for Query Expansion.",
                "Journal of Documentation, 46(4):359-364, 1990. [21] G. Salton and C. Buckley.",
                "Improving Retrieval Performance by Relevance Feedback.",
                "JASIS, 41(4):288 - 297, 1999. [22] R. Sun, C.-H. Ong, and T.-S. Chua.",
                "Mining Dependency Relations for Query Expansion in Passage Retrieval.",
                "In SIGIR, 2006. [23] C. Van Rijsbergen.",
                "Information Retrieval.",
                "Butterworths, second version, 1979. [24] B. V´elez, R. Weiss, M. A. Sheldon, and D. K. Gifford.",
                "Fast and Effective Query Refinement.",
                "In SIGIR, 1997. [25] J. Xu and B. Croft.",
                "Query Expansion using Local and Global Document Analysis.",
                "In SIGIR, 1996. [26] J. Xu and B. Croft.",
                "Corpus-based Stemming using Cooccurrence of Word Variants.",
                "ACM TOIS, 16 (1):61-81, 1998."
            ],
            "original_annotated_samples": [
                "CONTEXT SENSITIVE STEMMING 3.1 Overview Our system has four components as illustrated in Figure 1: candidate generation, query segmentation and <br>head word detection</br>, context sensitive query stemming and context sensitive document matching.",
                "Component 4: context sensitive document matching Input Query: and <br>head word detection</br> Component 2: segment Component 1: candidate generation comparisons −> comparison Component 3: selective word expansion decision: comparisons −> comparison example: hotel price comparisons output: hotel comparisons hotel −> hotels Figure 1: System Components 3.2 Expansion candidate generation One of the ways to generate candidates is using the Porter stemmer [18]."
            ],
            "translated_annotated_samples": [
                "STEMMING CONTEXTUAL SENSIBLE 3.1 Resumen Nuestro sistema tiene cuatro componentes como se ilustra en la Figura 1: generación de candidatos, segmentación de consultas y <br>detección de palabras clave</br>, derivación de consultas sensible al contexto y coincidencia de documentos sensible al contexto.",
                "Componente 4: coincidencia de documentos sensibles al contexto Consulta de entrada: y <br>detección de palabras clave</br> Componente 2: segmento Componente 1: generación de candidatos comparaciones −> comparación Componente 3: decisión de expansión selectiva de palabras: comparaciones −> comparación ejemplo: comparaciones de precios de hoteles salida: comparaciones de hoteles hotel −> hoteles Figura 1: Componentes del sistema 3.2 Generación de candidatos de expansión Una de las formas de generar candidatos es utilizando el stemmer de Porter [18]."
            ],
            "translated_text": "Stemming sensible al contexto para la búsqueda web Fuchun Peng Nawaaz Ahmed Xin Li Yumao Lu Yahoo! Tradicionalmente, el truncamiento se ha aplicado a tareas de Recuperación de Información transformando las palabras en documentos a su forma raíz antes de indexarlas, y aplicando una transformación similar a los términos de consulta. Aunque aumenta la recuperación, esta estrategia ingenua no funciona bien para la Búsqueda en la Web, ya que disminuye la precisión y requiere una cantidad significativa de cálculos adicionales. En este artículo, proponemos un método de derivación sensible al contexto que aborda estos dos problemas. Dos propiedades únicas hacen que nuestro enfoque sea factible para la Búsqueda en la Web. Primero, basados en modelado estadístico del lenguaje, realizamos un análisis sensible al contexto en el lado de la consulta. Predecimos con precisión cuál de sus variantes morfológicas es útil para expandir un término de consulta antes de enviar la consulta al motor de búsqueda. Esto reduce drásticamente la cantidad de expansiones incorrectas, lo que a su vez disminuye el costo de la computación adicional y mejora la precisión al mismo tiempo. Segundo, nuestro enfoque realiza una coincidencia de documentos sensible al contexto para esas variantes ampliadas. Esta estrategia conservadora sirve como salvaguarda contra el truncamiento espurio, y resulta ser muy importante para mejorar la precisión. Usando el manejo de la pluralización de palabras como un ejemplo de nuestro enfoque de derivación, nuestros experimentos en un importante motor de búsqueda web muestran que al derivar solo el 29% del tráfico de consultas, podemos mejorar la relevancia medida por la Ganancia Acumulativa Descontada promedio (DCG5) en un 6.1% en estas consultas y en un 1.8% sobre todo el tráfico de consultas. Categorías y Descriptores de Asignaturas H.3.3 [Sistemas de Información]: Almacenamiento y Recuperación de Información-Formulación de Consultas Términos Generales Algoritmos, Experimentación 1. INTRODUCCIÓN La búsqueda en la web se ha convertido en una herramienta importante en nuestra vida diaria para buscar información. Uno de los problemas importantes en la búsqueda web es que las consultas de los usuarios a menudo no están formuladas de la mejor manera para obtener resultados óptimos. Por ejemplo, \"zapatilla para correr\" es una consulta que ocurre con frecuencia en los registros de consulta. Sin embargo, es mucho más probable que la búsqueda \"zapatillas para correr\" proporcione mejores resultados de búsqueda que la consulta original, ya que los documentos que coinciden con la intención de esta consulta suelen contener las palabras \"zapatillas para correr\". Formular correctamente una consulta requiere que el usuario prediga con precisión qué forma de palabra se utiliza en los documentos que mejor satisfacen sus necesidades de información. Esto es difícil incluso para usuarios experimentados, y especialmente difícil para hablantes no nativos. Una solución tradicional es utilizar el stemming [16, 18], el proceso de transformar palabras flexionadas o derivadas a su forma raíz para que un término de búsqueda coincida y recupere documentos que contengan todas las formas del término. Por lo tanto, la palabra \"run\" coincidirá con \"running\", \"ran\", \"runs\", y \"shoe\" coincidirá con \"shoes\" y \"shoeing\". El truncamiento se puede realizar tanto en los términos de un documento durante la indexación (y aplicando la misma transformación a los términos de la consulta durante el procesamiento de la consulta) o expandiendo la consulta con las variantes durante el procesamiento de la consulta. El truncamiento durante la indexación permite muy poca flexibilidad durante el procesamiento de consultas, mientras que el truncamiento mediante la expansión de consultas permite manejar cada consulta de manera diferente, y por lo tanto es preferible. Aunque el truncamiento tradicional aumenta la recuperación al emparejar variantes de palabras [13], puede reducir la precisión al recuperar demasiados documentos que han sido emparejados incorrectamente. Al examinar los resultados de aplicar el truncamiento a un gran número de consultas, generalmente se encuentra que casi igual cantidad de consultas se benefician y se ven perjudicadas por la técnica [6]. Además, reduce el rendimiento del sistema porque el motor de búsqueda tiene que hacer coincidir todas las variantes de palabras. Como mostraremos en los experimentos, esto es cierto incluso si simplificamos el proceso de derivación a la manipulación de pluralización, que es el proceso de convertir una palabra de su forma plural a singular, o viceversa. Por lo tanto, es necesario ser muy cauteloso al utilizar el stemming en los motores de búsqueda web. Un problema del truncamiento tradicional es su transformación ciega de todos los términos de consulta, es decir, siempre realiza la misma transformación para la misma palabra de consulta sin considerar el contexto de la palabra. Por ejemplo, la palabra \"book\" tiene cuatro formas: book, books, booking, booked, y la palabra \"store\" tiene cuatro formas: store, stores, storing, stored. Para la consulta de la librería, expandir ambas palabras a todas sus variantes aumenta significativamente el costo de computación y perjudica la precisión, ya que no todas las variantes son útiles para esta consulta. Transformar librería para que coincida con librerías está bien, pero hacer coincidir almacenamiento de libros o tienda de reservas no lo está. Un método de ponderación que otorga pesos más pequeños a las palabras variantes alivia los problemas hasta cierto punto si los pesos reflejan con precisión la importancia de la variante en esta consulta particular. Sin embargo, el peso uniforme no va a funcionar y un peso dependiente de la consulta sigue siendo un problema desafiante sin resolver [20]. Un segundo problema del truncamiento tradicional es su emparejamiento ciego de todas las ocurrencias en los documentos. Para la consulta de la librería, una transformación que permita que las tiendas variantes se emparejen hará que cada aparición de tiendas en el documento se trate de manera equivalente al término de consulta tienda. Por lo tanto, se emparejará un documento que contenga el fragmento de leer un libro en las cafeterías, lo que provocará que se seleccionen muchos documentos incorrectos. Aunque esperamos que la función de clasificación pueda manejar correctamente estos, con muchos más candidatos para clasificar, el riesgo de cometer errores aumenta. Para aliviar estos dos problemas, proponemos un enfoque de reducción de palabras raíz sensible al contexto para la búsqueda en la web. Nuestra solución consiste en dos análisis contextuales sensibles, uno en el lado de la consulta y otro en el lado del documento. En el lado de la consulta, proponemos un enfoque basado en modelado del lenguaje estadístico para predecir qué variantes de palabras son mejores formas que la palabra original con fines de búsqueda y expandir la consulta solo con esas formas. En el lado del documento, proponemos un emparejamiento conservador sensible al contexto para las variantes de palabras transformadas, solo emparejando las ocurrencias en el documento en el contexto de otros términos en la consulta. Nuestro modelo es simple pero efectivo y eficiente, lo que lo hace factible de ser utilizado en motores de búsqueda web comerciales reales. Utilizamos el manejo de pluralización como un ejemplo continuo para nuestro enfoque de derivación. La motivación para usar el manejo de pluralización como ejemplo es mostrar que incluso un truncamiento tan simple, si se maneja correctamente, puede brindar beneficios significativos a la relevancia de la búsqueda. Hasta donde sabemos, ninguna investigación previa ha investigado sistemáticamente el uso de la pluralización en la búsqueda en la web. Como debemos señalar, el método que proponemos no se limita al manejo de la pluralización, es una técnica de derivación general y también se puede aplicar a la expansión de consultas en general. Los experimentos sobre el truncamiento general producen mejoras significativas adicionales sobre el manejo de la pluralización para consultas largas, aunque los detalles no se informarán en este artículo. En el resto del documento, primero presentamos el trabajo relacionado y distinguimos nuestro método de trabajos anteriores en la Sección 2. Describimos los detalles del enfoque de derivación sensible al contexto en la Sección 3. Luego realizamos experimentos extensos en un importante motor de búsqueda web para respaldar nuestras afirmaciones en la Sección 4, seguidos de discusiones en la Sección 5. Finalmente, concluimos el artículo en la Sección 6.2. TRABAJO RELACIONADO El stemming es una tecnología estudiada desde hace mucho tiempo. Se han desarrollado muchos stemmers, como el stemmer Lovins [16] y el stemmer Porter [18]. El stemmer de Porter es ampliamente utilizado debido a su simplicidad y efectividad en muchas aplicaciones. Sin embargo, el algoritmo de Porter comete muchos errores porque sus reglas simples no pueden describir completamente la morfología del inglés. El análisis de corpus se utiliza para mejorar el stemmer de Porter [26] mediante la creación de clases de equivalencia para palabras que son morfológicamente similares y que ocurren en un contexto similar, medido por la información mutua esperada [23]. Utilizamos un enfoque de corpus similar para el stemming al calcular la similitud entre dos palabras basada en sus características de contexto distribucional, que pueden ser más que solo palabras adyacentes [15], y luego solo mantenemos las palabras morfológicamente similares como candidatas. El uso de la derivación en la recuperación de información también es una técnica bien conocida [8, 10]. Sin embargo, se informó previamente que la efectividad del truncamiento para los sistemas de consulta en inglés era bastante limitada. Lennon et al. [17] compararon los algoritmos de Lovins y Porter y encontraron poco mejoramiento en el rendimiento de recuperación. Más tarde, Harman [9] compara tres técnicas generales de derivación en experimentos de recuperación de texto, incluido el manejo de pluralización (llamado S stemmer en el artículo). También propusieron el truncamiento selectivo basado en la longitud de la consulta y la importancia del término, pero no se informaron resultados positivos. Por otro lado, Krovetz [14] realizó comparaciones sobre un pequeño número de documentos (de 400 a 12k) y mostró una mejora dramática en la precisión (de hasta un 45%). Sin embargo, debido al número limitado de consultas probadas (menos de 100) y al tamaño reducido de la colección, los resultados son difíciles de generalizar para la búsqueda en la web. Estos resultados mixtos, en su mayoría fracasos, llevaron a los primeros investigadores de IR a considerar que el truncamiento era irrelevante en general para el inglés [4], aunque investigaciones recientes han demostrado que el truncamiento tiene mayores beneficios para la recuperación en otros idiomas [2]. Sospechamos que los fracasos anteriores se debieron principalmente a los dos problemas que mencionamos en la introducción. El stemming ciego, o un stemming selectivo basado en la longitud de la consulta como se utiliza en [9], no es suficiente. El truncamiento debe decidirse caso por caso, no solo a nivel de consulta sino también a nivel de documento. Como demostraremos, si se maneja correctamente, se puede lograr una mejora significativa. Un problema más general relacionado con el stemming es la reformulación de consultas [3, 12] y la expansión de consultas que amplía las palabras no solo con variantes de palabras [7, 22, 24, 25]. Para decidir qué palabras expandidas usar, las personas a menudo utilizan técnicas de retroalimentación de seudorelevancia que envían la consulta original a un motor de búsqueda y recuperan los documentos principales, extraen palabras relevantes de estos documentos principales como palabras de consulta adicionales y vuelven a enviar la consulta expandida nuevamente [21]. Esto normalmente requiere enviar una consulta varias veces al motor de búsqueda y no es rentable para procesar la gran cantidad de consultas involucradas en la búsqueda web. Además, la expansión de consultas, incluida la reformulación de consultas [3, 12], tiene un alto riesgo de cambiar la intención del usuario (llamado desviación de consulta). Dado que las palabras expandidas pueden tener diferentes significados, agregarlas a la consulta podría potencialmente cambiar la intención de la consulta original. Por lo tanto, la expansión de consultas basada en pseudorelevancia y la reformulación de consultas pueden proporcionar sugerencias a los usuarios para su refinamiento interactivo, pero difícilmente pueden ser utilizadas directamente para la búsqueda en la web. Por otro lado, el truncamiento es mucho más conservador ya que la mayoría de las veces, conserva la intención de búsqueda original. Si bien la mayoría de los trabajos sobre la expansión de consultas se centran en mejorar la recuperación, nuestro trabajo se enfoca en aumentar tanto la recuperación como la precisión. El aumento en el recuerdo es evidente. Con el stemming de calidad, los buenos documentos que no fueron seleccionados antes del stemming serán promovidos y aquellos documentos de baja calidad serán degradados. En la expansión selectiva de consultas, Cronen-Townsend et al. [6] propusieron un método para la expansión selectiva de consultas basado en comparar la divergencia de Kullback-Leibler de los resultados de la consulta no expandida y los resultados de la consulta expandida. Esto es similar a la retroalimentación de relevancia en el sentido de que requiere múltiples pasadas de recuperación. Si una palabra puede expandirse en varias palabras, se requiere ejecutar este proceso varias veces para decidir cuál palabra expandida es útil. Es costoso implementar esto en motores de búsqueda web en producción. Nuestro método predice la calidad de la expansión basándose en información sin conexión sin enviar la consulta a un motor de búsqueda. En resumen, proponemos un enfoque novedoso para abordar un problema antiguo, pero aún importante y desafiante para la búsqueda en la web: el stemming. Nuestro enfoque es único en el sentido de que realiza el truncamiento predictivo de forma individualizada para cada consulta sin retroalimentación de relevancia de la Web, utilizando el contexto de las variantes en los documentos para preservar la precisión. Es simple, pero muy eficiente y efectivo, lo que hace factible el truncamiento en tiempo real para la búsqueda en la web. Nuestros resultados confirmarán a los investigadores que el truncamiento es realmente muy importante para la recuperación de información a gran escala. STEMMING CONTEXTUAL SENSIBLE 3.1 Resumen Nuestro sistema tiene cuatro componentes como se ilustra en la Figura 1: generación de candidatos, segmentación de consultas y <br>detección de palabras clave</br>, derivación de consultas sensible al contexto y coincidencia de documentos sensible al contexto. La generación de candidatos (componente 1) se realiza fuera de línea y los candidatos generados se almacenan en un diccionario. Para una consulta de entrada, primero segmentamos la consulta en conceptos y detectamos la palabra principal de cada concepto (componente 2). Luego utilizamos modelado de lenguaje estadístico para decidir si una variante particular es útil (componente 3), y finalmente, para las variantes expandidas, realizamos un emparejamiento de documentos sensible al contexto (componente 4). A continuación discutimos cada uno de los componentes con más detalle. Componente 4: coincidencia de documentos sensibles al contexto Consulta de entrada: y <br>detección de palabras clave</br> Componente 2: segmento Componente 1: generación de candidatos comparaciones −> comparación Componente 3: decisión de expansión selectiva de palabras: comparaciones −> comparación ejemplo: comparaciones de precios de hoteles salida: comparaciones de hoteles hotel −> hoteles Figura 1: Componentes del sistema 3.2 Generación de candidatos de expansión Una de las formas de generar candidatos es utilizando el stemmer de Porter [18]. El stemmer de Porter simplemente utiliza reglas morfológicas para convertir una palabra a su forma base. No tiene conocimiento del significado semántico de las palabras y a veces comete errores graves, como cambiar \"executive\" por \"execution\", \"news\" por \"new\" y \"paste\" por \"past\". Una forma más conservadora se basa en utilizar análisis de corpus para mejorar los resultados del stemmer de Porter [26]. El análisis de corpus que realizamos se basa en la similitud distribucional de palabras [15]. La razón de utilizar la similitud distribucional de palabras es que las variantes verdaderas tienden a ser utilizadas en contextos similares. En el cálculo de similitud de palabras distribucionales, cada palabra se representa con un vector de características derivadas del contexto de la palabra. Utilizamos los bigramas a la izquierda y a la derecha de la palabra como sus características de contexto, mediante la extracción de un gran corpus web. La similitud entre dos palabras es la similitud coseno entre los dos vectores de características correspondientes. Las 20 palabras similares a \"desarrollar\" se muestran en la siguiente tabla. rango candidato puntaje rango candidato puntaje 0 desarrollar 1 10 berts 0.119 1 desarrollando 0.339 11 wads 0.116 2 desarrollado 0.176 12 desarrollador 0.107 3 incubadora 0.160 13 promoviendo 0.100 4 desarrolla 0.150 14 desarrollo 0.091 5 desarrollo 0.148 15 reingeniería 0.090 6 tutoría 0.138 16 construir 0.083 7 analizando 0.128 17 construir 0.081 8 desarrollo 0.128 18 educativo 0.081 9 automatización 0.126 19 instituto 0.077 Tabla 1: Los 20 candidatos más similares a la palabra \"desarrollar\". La puntuación de la columna es la puntuación de similitud. Para determinar los candidatos de derivación, aplicamos algunas reglas morfológicas del stemmer de Porter [18] a la lista de similitud. Después de aplicar estas reglas, para la palabra desarrollar, los candidatos de derivación son desarrollando, desarrollado, desarrolla, desarrollo, desarrollo, desarrollador, y desarrollo. Para el propósito de manejo de pluralización, solo se conserva el candidato desarrolla. Una cosa que observamos al observar las palabras distribucionalmente similares es que están estrechamente relacionadas semánticamente. Estas palabras podrían servir como candidatas para la expansión general de consultas, un tema que investigaremos en el futuro. 3.3 Segmentación e identificación de palabras clave Para consultas largas, es bastante importante detectar los conceptos en la consulta y las palabras más importantes para esos conceptos. Primero dividimos una consulta en segmentos, cada segmento representando un concepto que normalmente es una frase nominal. Para cada una de las frases nominales, luego detectamos la palabra más importante a la que llamamos la palabra principal. La segmentación también se utiliza en la coincidencia sensible a documentos (sección 3.5) para hacer cumplir la proximidad. Para dividir una consulta en segmentos, tenemos que definir un criterio para medir la fuerza de la relación entre las palabras. Un método efectivo es utilizar la información mutua como indicador para decidir si dividir o no dos palabras [19]. Utilizamos un registro de 25 millones de consultas y recopilamos las frecuencias de bigramas y unigramas a partir de él. Para cada consulta entrante, calculamos la información mutua de dos palabras adyacentes; si supera un umbral predefinido, no dividimos la consulta entre esas dos palabras y pasamos a la siguiente palabra. Continuamos este proceso hasta que la información mutua entre dos palabras esté por debajo del umbral, luego creamos un límite conceptual aquí. La Tabla 2 muestra algunos ejemplos de segmentación de consultas. La forma ideal de encontrar la palabra principal de un concepto es realizar un análisis sintáctico para determinar la estructura de dependencia de la consulta. El análisis de consultas es más difícil que el análisis de oraciones, ya que muchas consultas no son gramaticales y son muy cortas. Aplicar un analizador entrenado en oraciones de documentos a consultas tendrá un rendimiento deficiente. En nuestra solución, solo utilizamos reglas heurísticas simples, y funciona muy bien en la práctica para el inglés. Para una frase nominal en inglés, la palabra principal suele ser la última palabra no detenida, a menos que la frase siga un patrón particular, como XYZ de/en/a/desde UVW. En tales casos, la palabra principal suele ser la última palabra no detenida de XYZ. 3.4 Expansión de palabras sensibles al contexto Después de detectar cuáles son las palabras más importantes para expandir, debemos decidir si las expansiones serán útiles. Nuestras estadísticas muestran que aproximadamente la mitad de las consultas pueden ser transformadas mediante la pluralización a través de un truncamiento ingenuo. Entre esta mitad, aproximadamente el 25% de las consultas mejoran la relevancia cuando se transforman, la mayoría (alrededor del 50%) no cambian sus 5 resultados principales, y el 25% restante tiene un rendimiento peor. Por lo tanto, es extremadamente importante identificar qué consultas no deben ser truncadas con el fin de maximizar la mejora de relevancia y minimizar el costo de truncamiento. Además, para una consulta con múltiples palabras que pueden ser transformadas, o una palabra con múltiples variantes, no todas las expansiones son útiles. Tomando la comparación de precios de hoteles como ejemplo, decidimos que hotel y comparación de precios son dos conceptos. Las palabras clave hotel y comparación se pueden expandir a hoteles y comparaciones. ¿Son útiles ambas transformaciones? Para probar si una expansión es útil, tenemos que saber si es probable que la consulta expandida obtenga más documentos relevantes de la web, lo cual puede cuantificarse mediante la probabilidad de que la consulta ocurra como una cadena en la web. Cuanto más probable sea que ocurra una consulta en la web, más documentos relevantes puede devolver esta consulta. Ahora todo el problema se convierte en cómo calcular la probabilidad de que ocurra la consulta en la Web. Calcular la probabilidad de que una cadena ocurra en un corpus es un problema bien conocido de modelado del lenguaje. El objetivo del modelado del lenguaje es predecir la probabilidad de secuencias de palabras que ocurren naturalmente, s = w1w2...wN; o más simplemente, asignar una alta probabilidad a las secuencias de palabras que realmente ocurren (y una baja probabilidad a las secuencias de palabras que nunca ocurren). El enfoque más simple y exitoso para el modelado del lenguaje sigue estando basado en el modelo n-gramo. Por la regla de la cadena de probabilidad, se puede escribir la probabilidad de cualquier secuencia de palabras como Pr(w1w2...wN) = ΠY i=1 Pr(wi|w1...wi−1) (1). Un modelo n-grama aproxima esta probabilidad asumiendo que las únicas palabras relevantes para predecir Pr(wi|w1...wi−1) son las n − 1 palabras anteriores; es decir, La probabilidad de una palabra wi dado w1...wi−1 es igual a la probabilidad de wi dado wi−n+1...wi−1. Una estimación directa de máxima verosimilitud de las probabilidades de n-gramas a partir de un corpus se obtiene a partir de la frecuencia observada de cada uno de los patrones Pr(wi|wi−n+1...wi−1) = #(wi−n+1...wi) #(wi−n+1...wi−1) donde #(.) denota el número de ocurrencias de un n-grama específico en el corpus de entrenamiento. Aunque se podría intentar usar modelos de n-gramos simples para capturar dependencias a largo plazo en el lenguaje, intentar hacerlo directamente crea inmediatamente problemas de datos dispersos: Utilizar n-gramos de longitud hasta n implica estimar la probabilidad de eventos de longitud Wn, donde W es el tamaño del vocabulario de palabras. Esto rápidamente abruma los recursos computacionales y de datos modernos incluso para opciones modestas de n (más allá de 3 a 6). Además, debido a la naturaleza de cola pesada del lenguaje (es decir, La ley de Zipf) es probable que uno se encuentre con n-gramas novedosos que nunca fueron observados durante el entrenamiento en ningún corpus de prueba, por lo tanto, algún mecanismo para asignar una probabilidad distinta de cero a los n-gramas novedosos es un problema central e inevitable en la modelización estadística del lenguaje. Un enfoque estándar para suavizar las estimaciones de probabilidad para hacer frente a problemas de datos escasos (y para hacer frente a posibles n-gramas faltantes) es utilizar algún tipo de estimador de retroceso. Pr(wi|wi−n+1...wi−1) = 8 >>< >>: ˆPr(wi|wi−n+1...wi−1), si #(wi−n+1...wi) > 0 β(wi−n+1...wi−1) × Pr(wi|wi−n+2...wi−1), de lo contrario (3) donde ˆPr(wi|wi−n+1...wi−1) = descuento #(wi−n+1...wi) #(wi−n+1...wi−1) (4) es la probabilidad descontada y β(wi−n+1...wi−1) es una constante de normalización β(wi−n+1...wi−1) = 1 − X x∈(wi−n+1...wi−1x) ˆPr(x|wi−n+1...wi−1) 1 − X x∈(wi−n+1...wi−1x) ˆPr(x|wi−n+2...wi−1) (5) La probabilidad descontada (4) se puede calcular con diferentes técnicas de suavizado, incluido el suavizado absoluto, el suavizado de Good-Turing, el suavizado lineal y el suavizado de Witten-Bell [5]. Utilizamos suavizado absoluto en nuestros experimentos. Dado que la probabilidad de una cadena, Pr(w1w2...wN), es un número muy pequeño y difícil de interpretar, utilizamos la entropía, tal como se define a continuación, para puntuar la cadena. Entropía = − 1 N log2 Pr(w1w2...wN ) (6) Ahora volviendo al ejemplo de la comparación de precios de hoteles, hay cuatro variantes de esta consulta, y la entropía de estos cuatro candidatos se muestra en la Tabla 3. Podemos ver que todas las alternativas son menos probables que la consulta de entrada. Por lo tanto, no es útil hacer una expansión para esta consulta. Por otro lado, si la consulta de entrada son comparaciones de precios de hoteles, que es la segunda alternativa en la tabla, entonces hay una mejor alternativa que la consulta de entrada, y por lo tanto debería ser ampliada. Para tolerar las variaciones en la estimación de probabilidad, relajamos el criterio de selección para esas alternativas de consulta si sus puntuaciones están dentro de una cierta distancia (10% en nuestros experimentos) de la mejor puntuación. Variaciones de la consulta Comparación de precios de hoteles 6.177 comparaciones de precios de hoteles 6.597 comparación de precios de hoteles 6.937 comparaciones de precios de hoteles 7.360 Tabla 3: Variaciones de la consulta comparación de precios de hoteles clasificadas por puntaje de entropía, con la consulta original en negrita. 3.5 Coincidencia de documentos sensibles al contexto Aun después de saber qué variantes de palabras son probablemente útiles, debemos ser conservadores en la coincidencia de documentos para las variantes ampliadas. Para la consulta de comparaciones de precios de hoteles, decidimos que la palabra \"comparaciones\" se amplía para incluir \"comparación\". Sin embargo, no todos los casos de comparación en el documento son de interés. Una página que trata sobre comparar el servicio al cliente puede contener todas las palabras comparaciones de precios de hoteles comparación. Esta página no es una buena página para la consulta. Si aceptamos coincidencias de cada ocurrencia de comparación, afectará la precisión de recuperación y esta es una de las principales razones por las que la mayoría de los enfoques de derivación no funcionan bien para la recuperación de información. Para abordar este problema, tenemos una restricción de proximidad que considera el contexto alrededor de la variante expandida en el documento. Una coincidencia de variante se considera válida solo si la variante ocurre en el mismo contexto que la palabra original lo hace. El contexto son los segmentos continuos de la izquierda o de la derecha de la palabra original. Tomando la misma consulta como ejemplo, el contexto de las comparaciones es el precio. La comparación de palabras ampliada solo es válida si está en el mismo contexto de comparaciones, que es después de la palabra precio. Por lo tanto, solo debemos emparejar aquellas ocurrencias de comparación en el documento si ocurren después de la palabra precio. Considerando el hecho de que las consultas y los documentos pueden no representar la intención de la misma manera exacta, relajamos esta restricción de proximidad para permitir ocurrencias variantes dentro de una ventana de un tamaño fijo. Si la comparación de palabras expandidas ocurre dentro del contexto de precio dentro de una ventana, se considera válida. Cuanto más pequeño sea el tamaño de la ventana, más restrictiva será la coincidencia. Utilizamos un tamaño de ventana de 4, que normalmente captura contextos que incluyen las frases nominales que contienen y las adyacentes. 4. EVALUACIÓN EXPERIMENTAL 4.1 Métricas de evaluación Mediremos tanto la mejora de relevancia como el costo de derivación necesario para lograr la relevancia. 1 un segmento de contexto no puede ser una sola palabra de parada. 4.1.1 Medición de relevancia Utilizamos una variante de la Ganancia Acumulada Descontada Promedio (DCG), un esquema recientemente popularizado para medir la relevancia de los motores de búsqueda [1, 11]. Dada una consulta y una lista clasificada de K documentos (K se establece en 5 en nuestros experimentos), el puntaje DCG(K) para esta consulta se calcula de la siguiente manera: DCG(K) = Σ k=1 a K gk log2(1 + k) . (7) donde gk es el peso para el documento en la posición k. Un mayor grado de relevancia corresponde a un peso mayor. Una página se califica en una de las cinco escalas: Perfecto, Excelente, Bueno, Regular, Malo, con pesos correspondientes. Utilizamos DCG para representar el DCG promedio(5) sobre un conjunto de consultas de prueba. 4.1.2 Costo de derivación Otro métrica es medir el costo adicional incurrido por la derivación. Dado el mismo nivel de mejora en la relevancia, preferimos un método de truncamiento que tenga un menor costo adicional. Medimos esto por el porcentaje de consultas que realmente se reducen, sobre todas las consultas que podrían ser reducidas. 4.2 Preparación de datos Muestreamos aleatoriamente 870 consultas de un registro de consultas de tres meses, con 290 de cada mes. Entre todas estas 870 consultas, eliminamos todas las consultas con errores ortográficos ya que las consultas con errores ortográficos no son de interés para el stemming. También eliminamos todas las consultas de una sola palabra, ya que reducir las consultas de una sola palabra sin contexto tiene un alto riesgo de cambiar la intención de la consulta, especialmente para palabras cortas. Al final, tenemos 529 consultas correctamente escritas con al menos 2 palabras. 4.3 Stemming ingenuo para la búsqueda en la Web Antes de explicar en detalle los experimentos y resultados, nos gustaría describir la forma tradicional de usar el stemming para la búsqueda en la Web, conocida como el modelo ingenuo. Esto es para tratar cada variante de palabra equivalente para todas las posibles palabras en la consulta. La consulta de la librería se transformará en (libro O libros)(tienda O tiendas) al limitar el truncamiento al manejo de pluralización solamente, donde O es un operador que denota la equivalencia de los argumentos izquierdo y derecho. 4.4 Configuración experimental El modelo base es el modelo sin truncamiento. Primero ejecutamos el modelo ingenuo para ver qué tan bien se desempeña en comparación con el punto de referencia. Luego mejoramos el modelo de derivación ingenua mediante la coincidencia sensible al documento, denominado modelo de coincidencia sensible al documento. Este modelo realiza el mismo stemming que el modelo ingenuo en el lado de la consulta, pero realiza un emparejamiento conservador en el lado del documento utilizando la estrategia descrita en la sección 3.5. El modelo ingenuo y el modelo de coincidencia sensible al documento son los que mejor responden a la mayoría de las consultas. De las 529 consultas, hay 408 consultas que se originan, lo que corresponde al 46.7% del tráfico de consultas (de un total de 870). Luego mejoramos aún más el modelo de coincidencia sensible de documentos desde el lado de la consulta con un proceso de derivación de palabras selectivo basado en modelado estadístico del lenguaje (sección 3.4), denominado modelo de derivación selectiva. Basado en la predicción del modelado del lenguaje, este modelo deriva solo un subconjunto de las 408 consultas derivadas por el modelo de coincidencia sensible al documento. Experimentamos con un modelo de lenguaje unigrama y un modelo de lenguaje bigrama. Dado que solo nos importa cuánto podemos mejorar el modelo ingenuo, solo utilizaremos estas 408 consultas (todas las consultas que se ven afectadas por el modelo de derivación ingenuo) en los experimentos. Para tener una idea de cómo se desempeñan estos modelos, también tenemos un modelo oráculo que proporciona el rendimiento máximo que un stemmer puede lograr en estos datos. El modelo del oráculo solo expande una palabra si el truncamiento dará mejores resultados. Para analizar la influencia del manejo de la pluralización en diferentes categorías de consultas, dividimos las consultas en consultas cortas y consultas largas. Entre las 408 consultas generadas por el modelo ingenuo, hay 272 consultas cortas con 2 o 3 palabras, y 136 consultas largas con al menos 4 palabras. Resumimos los resultados generales en la Tabla 4, y presentamos los resultados de las consultas cortas y largas por separado en la Tabla 5. Cada fila en la Tabla 4 es una estrategia de derivación descrita en la sección 4.4. La primera columna es el nombre de la estrategia. La segunda columna es el número de consultas afectadas por esta estrategia; esta columna mide el costo de derivación, y los números deberían ser bajos para el mismo nivel de dcg. La tercera columna es la puntuación DCG promedio sobre todas las consultas probadas en esta categoría (incluyendo aquellas que no fueron truncadas por la estrategia). La cuarta columna es la mejora relativa sobre la línea base, y la última columna es el valor p de la prueba de significancia de Wilcoxon. Hay varias observaciones sobre los resultados. Podemos ver que el truncado ingenuo solo logra una mejora estadísticamente insignificante del 1.5%. Mirando la Tabla 5, se observa una mejora del 2.7% en las consultas cortas. Sin embargo, también perjudica las consultas largas en un -2.4%. En general, la mejora se cancela. La razón por la que mejora las consultas cortas es que la mayoría de las consultas cortas solo tienen una palabra que se puede reducir a su raíz. Por lo tanto, pluralizar ciegamente consultas cortas es relativamente seguro. Sin embargo, para consultas largas, la mayoría de las consultas pueden tener varias palabras que pueden ser pluralizadas. Expandir todos ellos sin selección perjudicará significativamente la precisión. La aplicación de un stemming sensible al contexto del documento proporciona un aumento significativo en el rendimiento, desde un 2.7% hasta un 4.2% para consultas cortas y desde un -2.4% hasta un -1.6% para consultas largas, con un aumento general del 1.5% al 2.8%. La mejora proviene de la coincidencia de documentos sensible al contexto conservador. Una palabra expandida es válida solo si ocurre dentro del contexto de la consulta original en el documento. Esto reduce muchas coincidencias falsas. Sin embargo, aún observamos que para consultas largas, el truncamiento sensible al contexto no logra mejorar el rendimiento porque sigue seleccionando demasiados documentos y le presenta a la función de clasificación un problema difícil. Si bien el tamaño de ventana elegido de 4 es el que mejor funciona entre todas las opciones, aún permite coincidencias espurias. Es posible que el tamaño de la ventana deba elegirse según la consulta para garantizar restricciones de proximidad más estrictas para diferentes tipos de frases nominales. La pluralización selectiva de palabras ayuda aún más a resolver el problema enfrentado por el truncamiento sensible al contexto del documento. No se aplica el truncamiento a cada palabra que coloca toda la carga en el algoritmo de clasificación, sino que intenta eliminar el truncamiento innecesario en primer lugar. Al predecir qué variantes de palabras van a ser útiles, podemos reducir drásticamente el número de palabras derivadas, mejorando así tanto la recuperación como la precisión. Con el modelo de lenguaje unigrama, podemos reducir el costo de derivación en un 26.7% (de 408/408 a 300/408) y aumentar la mejora general de DCG del 2.8% al 3.4%. En particular, proporciona mejoras significativas en consultas largas. La ganancia de DCG se cambia de negativa a positiva, de -1.6% a 1.1%. Esto confirma nuestra hipótesis de que reducir la expansión innecesaria de palabras conduce a una mejora en la precisión. Para consultas cortas también observamos tanto la mejora de dcg como la reducción del costo de derivación con el modelo de lenguaje unigrama. Las ventajas de la expansión predictiva de palabras con un modelo de lenguaje se potencian aún más con un mejor modelo de lenguaje de bigrama. La ganancia total de DCG aumenta de 3.4% a 3.9%, y el costo de derivación se reduce drásticamente de 408/408 a 250/408, correspondiente a solo el 29% del tráfico de consultas (250 de 870) y una mejora total de DCG del 1.8% en todo el tráfico de consultas. Para consultas cortas, el modelo de lenguaje de bigrama mejora la ganancia de DCG del 4.4% al 4.7%, y reduce el costo de derivación de 272/272 a 150/272. Para consultas largas, el modelo de lenguaje de bigrama mejora la ganancia de DCG del 1.1% al 2.5%, y reduce el costo de derivación de 136/136 a 100/136. Observamos que el modelo de lenguaje de bigrama proporciona un mayor aumento para consultas largas. Esto se debe a que la incertidumbre en las consultas largas es mayor y se necesita un modelo de lenguaje más potente. Hacemos la hipótesis de que un modelo de lenguaje de trigramas proporcionaría un impulso adicional para consultas largas y dejamos esto para investigaciones futuras. Considerando el límite superior estricto de 2 en la mejora que se puede obtener del manejo de la pluralización (a través del modelo oráculo), el rendimiento actual en consultas cortas es muy satisfactorio. Para consultas breves, la ganancia máxima de DCG es del 6.3% para el manejo perfecto de la pluralización, nuestra ganancia actual es del 4.7% con un modelo de lenguaje de bigrama. Para consultas largas, la ganancia máxima de DCG es del 4.6% para el manejo perfecto de la pluralización, nuestra ganancia actual es del 2.5% con un modelo de lenguaje de bigrama. Podríamos obtener beneficios adicionales con un modelo de lenguaje más potente para consultas largas. Sin embargo, las dificultades de las consultas largas provienen de muchos otros aspectos, incluyendo la proximidad y el problema de la segmentación. Estos problemas deben ser abordados por separado. Al observar el límite superior de reducción de gastos generales para el truncamiento de Oracle, el 75% (308/408) de los truncamientos ingenuos son inútiles. Actualmente capturamos alrededor de la mitad de ellos. La reducción adicional de los gastos generales requiere sacrificar la ganancia de la DCG. Ahora podemos comparar las estrategias de derivación desde un aspecto diferente. En lugar de analizar la influencia sobre todas las consultas como describimos anteriormente, la Tabla 6 resume las mejoras de DCG solo sobre las consultas afectadas. Podemos ver que el número de consultas afectadas disminuye a medida que la estrategia de derivación se vuelve más precisa (mejora en el dcg). Para el modelo de lenguaje de bigrama, sobre las 250/408 consultas truncadas, la mejora en DCG es del 6.1%. Una observación interesante es que el dcg promedio disminuye con un modelo mejor, lo que indica que una estrategia de derivación mejorada deriva consultas más difíciles (consultas con bajo dcg). 5. Como mencionamos en la Sección 1, estamos tratando de predecir la probabilidad de que una cadena ocurra en la Web. El modelo de lenguaje debe describir la ocurrencia de la cadena en la web. Sin embargo, el registro de consultas también es un buen recurso. Tenga en cuenta que este límite superior es solo para el manejo de pluralización, no para el truncamiento general. El stemming general proporciona un límite superior del 8%, lo cual es bastante sustancial en términos de nuestras métricas. Las consultas afectadas dcg dcg Mejora p-valor línea de base 0/408 7.102 N/A N/A modelo ingenuo 408/408 7.206 1.5% 0.22 modelo sensible al contexto del documento 408/408 7.302 2.8% 0.014 modelo selectivo: unigram LM 300/408 7.321 3.4% 0.001 modelo selectivo: bigram LM 250/408 7.381 3.9% 0.001 modelo oráculo 100/408 7.519 5.9% 0.001 Tabla 4: Comparación de resultados de diferentes estrategias de derivación en todas las consultas afectadas por la derivación ingenua Resultados de Consultas Cortas Consultas Afectadas dcg Mejora p-valor línea de base 0/272 N/A N/A modelo ingenuo 272/272 2.7% 0.48 modelo sensible al contexto del documento 272/272 4.2% 0.002 modelo selectivo: unigram LM 185/272 4.4% 0.001 modelo selectivo: bigram LM 150/272 4.7% 0.001 modelo oráculo 71/272 6.3% 0.001 Resultados de Consultas Largas Consultas Afectadas dcg Mejora p-valor línea de base 0/136 N/A N/A modelo ingenuo 136/136 -2.4% 0.25 modelo sensible al contexto del documento 136/136 -1.6% 0.27 modelo selectivo: unigram LM 115/136 1.1% 0.001 modelo selectivo: bigram LM 100/136 2.5% 0.001 modelo oráculo 29/136 4.6% 0.001 Tabla 5: Comparación de resultados de diferentes estrategias de derivación en consultas cortas y largas en general Los usuarios reformulan una consulta utilizando muchas variantes diferentes para obtener buenos resultados. Para probar la hipótesis de que podemos aprender probabilidades de transformación confiables a partir del registro de consultas, entrenamos un modelo de lenguaje con las mismas 25 millones de consultas principales utilizadas para aprender la segmentación, y lo utilizamos para la predicción. Observamos una ligera disminución en el rendimiento en comparación con el modelo entrenado en frecuencias web. En particular, el rendimiento para el modelo de lenguaje unigrama no se vio afectado, pero la ganancia de dcg para el modelo de lenguaje bigrama cambió de 4.7% a 4.5% para consultas cortas. Por lo tanto, el registro de consultas puede servir como una buena aproximación de las frecuencias web. 5.2 Cómo la lingüística ayuda. Algunos conocimientos lingüísticos son útiles en el stemming. Para el manejo de la pluralización, la pluralización y la despluralización no son simétricas. Una palabra en plural utilizada en una consulta indica una intención especial. Por ejemplo, la consulta hoteles en Nueva York está buscando una lista de hoteles en Nueva York, no el hotel específico de Nueva York que podría estar ubicado en California. Una simple equivalencia de hotel a hoteles podría impulsar una página en particular sobre hoteles en Nueva York al primer puesto. Para capturar esta intención, tenemos que asegurarnos de que el documento sea una página general sobre hoteles en Nueva York. Esto lo hacemos exigiendo que la palabra en plural hoteles aparezca en el documento. Por otro lado, convertir una palabra singular a plural es más seguro ya que una página de propósito general normalmente contiene información específica. Observamos una ligera disminución general en el dcg, aunque no estadísticamente significativa, para el stemming sensible al contexto del documento si no consideramos esta propiedad asimétrica. Análisis de errores. Un tipo de errores que notamos, aunque raros pero que afectan seriamente la relevancia, es el cambio de intención de búsqueda después del stemming. En general, la pluralización o despluralización mantiene la intención original. Sin embargo, la intención podría cambiar en algunos casos. Por ejemplo, para una consulta de este tipo, trabajo en Apple, pluralizamos trabajo a trabajos. Este truncamiento hace que la consulta original sea ambigua. El trabajo de consulta O trabajos en Apple tiene dos intenciones. Una de las oportunidades laborales en Apple, y otra es una persona que trabaja en Apple, Steve Jobs, quien es el CEO y cofundador de la empresa. Por lo tanto, los resultados después de la reducción de consultas devuelven a Steve Jobs como uno de los resultados en el top 5. Una solución es realizar un análisis basado en el conjunto de resultados para verificar si la intención ha cambiado. Esto es similar a la retroalimentación de relevancia y requiere una clasificación en la segunda fase. Un segundo tipo de errores es el problema de reconocimiento de entidades/conceptos. Estos incluyen dos tipos. Una de ellas es que la variante de la palabra derivada ahora coincide con parte de una entidad o concepto. Por ejemplo, la consulta \"cookies en San Francisco\" se pluraliza como \"cookies\" O \"cookie en San Francisco\". Los resultados coincidirán con el tarro de galletas en San Francisco. Aunque \"cookie\" todavía significa lo mismo que \"galletas\", el concepto de \"cookie jar\" es diferente. Otro tipo es la palabra no derivada que coincide con una entidad o concepto debido al truncamiento de las otras palabras. Por ejemplo, la cita ICE se pluraliza como cita OR citas ICE. La intención original de esta consulta es buscar la cotización de acciones para el símbolo ICE. Sin embargo, notamos que entre los resultados principales, uno de los resultados es Citas sobre comida: Helado. Esto se empareja debido a las consultas afectadas dcg antiguas nuevas dcg dcg Mejora del modelo ingenuo 408/408 7.102 7.206 1.5% modelo sensible al contexto del documento 408/408 7.102 7.302 2.8% modelo selectivo: unigram LM 300/408 5.904 6.187 4.8% modelo selectivo: bigram LM 250/408 5.551 5.891 6.1% Tabla 6: Comparación de resultados solo sobre las consultas derivadas: la columna dcg antigua/nueva es la puntuación dcg sobre las consultas afectadas antes/después de aplicar la pluralización de la palabra entre comillas. La palabra inalterada ICE coincide con parte de la frase nominal helado aquí. Para resolver este tipo de problema, tenemos que analizar los documentos y reconocer \"cookie jar\" y \"ice cream\" como conceptos en lugar de dos palabras independientes. Un tercer tipo de errores ocurre en consultas largas. Para la consulta de software lector de códigos de barras, se pluralizan dos palabras. Códigos y lector. De hecho, el lector de códigos de barras en la consulta original es un concepto sólido y las palabras internas no deben ser cambiadas. Este es el problema de segmentación y detección de entidades y frases nominales en consultas, el cual estamos abordando activamente. Para consultas largas, debemos identificar correctamente los conceptos en la consulta y aumentar la proximidad de las palabras dentro de un concepto. 6. CONCLUSIONES Y TRABAJOS FUTUROS Hemos presentado una forma simple pero elegante de derivar palabras para la búsqueda en la web. Mejora el stemming ingenuo en dos aspectos: la expansión selectiva de palabras en el lado de la consulta y la coincidencia conservadora de ocurrencias de palabras en el lado del documento. Usando el manejo de pluralización como ejemplo, experimentos con datos de un motor de búsqueda web importante muestran que mejora significativamente la relevancia web y reduce el costo de derivación. También mejora significativamente la tasa de clics en la web (detalles no reportados en el artículo). Para el trabajo futuro, estamos investigando los problemas que identificamos en la sección de análisis de errores. Estos incluyen: errores de concordancia entre entidades y frases nominales, y una segmentación mejorada. 7. REFERENCIAS [1] E. Agichtein, E. Brill y S. T. Dumais. Mejorando la clasificación de búsqueda web al incorporar información sobre el comportamiento del usuario. En SIGIR, 2006. [2] E. Airio. Normalización de palabras y descomposición en IR monolingüe y bilingüe. Recuperación de información, 9:249-271, 2006. [3] P. Anick. Utilizando retroalimentación terminológica para el refinamiento de la búsqueda web: un estudio basado en registros. En SIGIR, 2003. [4] R. Baeza-Yates y B. Ribeiro-Neto. Recuperación de información moderna. ACM Press/Addison Wesley, 1999. [5] S. Chen y J. Goodman. Un estudio empírico de técnicas de suavizado para modelado del lenguaje. Informe técnico TR-10-98, Universidad de Harvard, 1998. [6] S. Cronen-Townsend, Y. Zhou y B. Croft. Un marco para la expansión selectiva de consultas. En CIKM, 2004. [7] H. Fang y C. Zhai. Coincidencia de términos semánticos en enfoques axiomáticos para la recuperación de información. En SIGIR, 2006. [8] W. B. Frakes. Confluencia de términos para la recuperación de información. En C. J. Rijsbergen, editor, Investigación y Desarrollo en Recuperación de Información, páginas 383-389. Cambridge University Press, 1984. [9] D. Harman.\nCambridge University Press, 1984. [9] D. Harman. ¿Qué tan efectivo es el sufijado? JASIS, 42(1):7-15, 1991. [10] D. Hull.\nJASIS, 42(1):7-15, 1991. [10] D. Hull. Algoritmos de derivación: un estudio de caso para una evaluación detallada. JASIS, 47(1):70-84, 1996. [11] K. Jarvelin y J. Kekalainen. Evaluación basada en la ganancia acumulada de técnicas de RI. ACM TOIS, 20:422-446, 2002. [12] R. Jones, B. Rey, O. Madani y W. Greiner. Generando Sustituciones de Consultas. En WWW, 2006. [13] W. Kraaij y R. Pohlmann. Viendo el Stemming como Mejora de la Recuperación. En SIGIR, 1996. [14] R. Krovetz. Viendo la morfología como un proceso de inferencia. En SIGIR, 1993. [15] D. Lin. Recuperación automática y agrupamiento de palabras similares. En COLING-ACL, 1998. [16] J. B. Lovins. Desarrollo de un algoritmo de derivación. Traducción Mecánica y Lingüística Computacional, II:22-31, 1968. [17] M. Lennon, D. Peirce, B. Tarry y P. Willett. Una evaluación de algunos algoritmos de confluencia para la recuperación de información. Revista de Ciencia de la Información, 3:177-188, 1981. [18] M. Porter. Un algoritmo para el recorte de sufijos. Programa, 14(3):130-137, 1980. [19] K. M. Risvik, T. Mikolajewski y P. Boros. Segmentación de consultas para búsqueda web. En WWW, 2003. [20] S. E. Robertson. Selección de términos para la expansión de consultas. Revista de Documentación, 46(4):359-364, 1990. [21] G. Salton y C. Buckley. Mejorando el rendimiento de recuperación mediante retroalimentación de relevancia. JASIS, 41(4):288 - 297, 1999. [22] R. Sun, C.-H. Ong, y T.-S. Chua. Extracción de relaciones de dependencia para la expansión de consultas en la recuperación de pasajes. En SIGIR, 2006. [23] C. Van Rijsbergen. Recuperación de información. Butterworths, segunda versión, 1979. [24] B. Vélez, R. Weiss, M. A. Sheldon y D. K. Gifford. Refinamiento de consultas rápido y efectivo. En SIGIR, 1997. [25] J. Xu y B. Croft. Expansión de consultas utilizando análisis local y global de documentos. En SIGIR, 1996. [26] J. Xu y B. Croft. Extracción de raíces basada en corpus utilizando la coocurrencia de variantes de palabras. ACM TOIS, 16 (1):61-81, 1998. ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "context sensitive query stemming": {
            "translated_key": "derivación de consultas sensible al contexto",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Context Sensitive Stemming for Web Search Fuchun Peng Nawaaz Ahmed Xin Li Yumao Lu Yahoo!",
                "Inc. 701 First Avenue Sunnyvale, California 94089 {fuchun, nawaaz, xinli, yumaol}@yahoo-inc.com ABSTRACT Traditionally, stemming has been applied to Information Retrieval tasks by transforming words in documents to the their root form before indexing, and applying a similar transformation to query terms.",
                "Although it increases recall, this naive strategy does not work well for Web Search since it lowers precision and requires a significant amount of additional computation.",
                "In this paper, we propose a context sensitive stemming method that addresses these two issues.",
                "Two unique properties make our approach feasible for Web Search.",
                "First, based on statistical language modeling, we perform context sensitive analysis on the query side.",
                "We accurately predict which of its morphological variants is useful to expand a query term with before submitting the query to the search engine.",
                "This dramatically reduces the number of bad expansions, which in turn reduces the cost of additional computation and improves the precision at the same time.",
                "Second, our approach performs a context sensitive document matching for those expanded variants.",
                "This conservative strategy serves as a safeguard against spurious stemming, and it turns out to be very important for improving precision.",
                "Using word pluralization handling as an example of our stemming approach, our experiments on a major Web search engine show that stemming only 29% of the query traffic, we can improve relevance as measured by average Discounted Cumulative Gain (DCG5) by 6.1% on these queries and 1.8% over all query traffic.",
                "Categories and Subject Descriptors H.3.3 [Information Systems]: Information Storage and Retrieval-Query formulation General Terms Algorithms, Experimentation 1.",
                "INTRODUCTION Web search has now become a major tool in our daily lives for information seeking.",
                "One of the important issues in Web search is that user queries are often not best formulated to get optimal results.",
                "For example, running shoe is a query that occurs frequently in query logs.",
                "However, the query running shoes is much more likely to give better search results than the original query because documents matching the intent of this query usually contain the words running shoes.",
                "Correctly formulating a query requires the user to accurately predict which word form is used in the documents that best satisfy his or her information needs.",
                "This is difficult even for experienced users, and especially difficult for non-native speakers.",
                "One traditional solution is to use stemming [16, 18], the process of transforming inflected or derived words to their root form so that a search term will match and retrieve documents containing all forms of the term.",
                "Thus, the word run will match running, ran, runs, and shoe will match shoes and shoeing.",
                "Stemming can be done either on the terms in a document during indexing (and applying the same transformation to the query terms during query processing) or by expanding the query with the variants during query processing.",
                "Stemming during indexing allows very little flexibility during query processing, while stemming by query expansion allows handling each query differently, and hence is preferred.",
                "Although traditional stemming increases recall by matching word variants [13], it can reduce precision by retrieving too many documents that have been incorrectly matched.",
                "When examining the results of applying stemming to a large number of queries, one usually finds that nearly equal numbers of queries are helped and hurt by the technique [6].",
                "In addition, it reduces system performance because the search engine has to match all the word variants.",
                "As we will show in the experiments, this is true even if we simplify stemming to pluralization handling, which is the process of converting a word from its plural to singular form, or vice versa.",
                "Thus, one needs to be very cautious when using stemming in Web search engines.",
                "One problem of traditional stemming is its blind transformation of all query terms, that is, it always performs the same transformation for the same query word without considering the context of the word.",
                "For example, the word book has four forms book, books, booking, booked, and store has four forms store, stores, storing, stored.",
                "For the query book store, expanding both words to all of their variants significantly increases computation cost and hurts precision, since not all of the variants are useful for this query.",
                "Transforming book store to match book stores is fine, but matching book storing or booking store is not.",
                "A weighting method that gives variant words smaller weights alleviates the problems to a certain extent if the weights accurately reflect the importance of the variant in this particular query.",
                "However uniform weighting is not going to work and a query dependent weighting is still a challenging unsolved problem [20].",
                "A second problem of traditional stemming is its blind matching of all occurrences in documents.",
                "For the query book store, a transformation that allows the variant stores to be matched will cause every occurrence of stores in the document to be treated equivalent to the query term store.",
                "Thus, a document containing the fragment reading a book in coffee stores will be matched, causing many wrong documents to be selected.",
                "Although we hope the ranking function can correctly handle these, with many more candidates to rank, the risk of making mistakes increases.",
                "To alleviate these two problems, we propose a context sensitive stemming approach for Web search.",
                "Our solution consists of two context sensitive analysis, one on the query side and the other on the document side.",
                "On the query side, we propose a statistical language modeling based approach to predict which word variants are better forms than the original word for search purpose and expanding the query with only those forms.",
                "On the document side, we propose a conservative context sensitive matching for the transformed word variants, only matching document occurrences in the context of other terms in the query.",
                "Our model is simple yet effective and efficient, making it feasible to be used in real commercial Web search engines.",
                "We use pluralization handling as a running example for our stemming approach.",
                "The motivation for using pluralization handling as an example is to show that even such simple stemming, if handled correctly, can give significant benefits to search relevance.",
                "As far as we know, no previous research has systematically investigated the usage of pluralization in Web search.",
                "As we have to point out, the method we propose is not limited to pluralization handling, it is a general stemming technique, and can also be applied to general query expansion.",
                "Experiments on general stemming yield additional significant improvements over pluralization handling for long queries, although details will not be reported in this paper.",
                "In the rest of the paper, we first present the related work and distinguish our method from previous work in Section 2.",
                "We describe the details of the context sensitive stemming approach in Section 3.",
                "We then perform extensive experiments on a major Web search engine to support our claims in Section 4, followed by discussions in Section 5.",
                "Finally, we conclude the paper in Section 6. 2.",
                "RELATED WORK Stemming is a long studied technology.",
                "Many stemmers have been developed, such as the Lovins stemmer [16] and the Porter stemmer [18].",
                "The Porter stemmer is widely used due to its simplicity and effectiveness in many applications.",
                "However, the Porter stemming makes many mistakes because its simple rules cannot fully describe English morphology.",
                "Corpus analysis is used to improve Porter stemmer [26] by creating equivalence classes for words that are morphologically similar and occur in similar context as measured by expected mutual information [23].",
                "We use a similar corpus based approach for stemming by computing the similarity between two words based on their distributional context features which can be more than just adjacent words [15], and then only keep the morphologically similar words as candidates.",
                "Using stemming in information retrieval is also a well known technique [8, 10].",
                "However, the effectiveness of stemming for English query systems was previously reported to be rather limited.",
                "Lennon et al. [17] compared the Lovins and Porter algorithms and found little improvement in retrieval performance.",
                "Later, Harman [9] compares three general stemming techniques in text retrieval experiments including pluralization handing (called S stemmer in the paper).",
                "They also proposed selective stemming based on query length and term importance, but no positive results were reported.",
                "On the other hand, Krovetz [14] performed comparisons over small numbers of documents (from 400 to 12k) and showed dramatic precision improvement (up to 45%).",
                "However, due to the limited number of tested queries (less than 100) and the small size of the collection, the results are hard to generalize to Web search.",
                "These mixed results, mostly failures, led early IR researchers to deem stemming irrelevant in general for English [4], although recent research has shown stemming has greater benefits for retrieval in other languages [2].",
                "We suspect the previous failures were mainly due to the two problems we mentioned in the introduction.",
                "Blind stemming, or a simple query length based selective stemming as used in [9] is not enough.",
                "Stemming has to be decided on case by case basis, not only at the query level but also at the document level.",
                "As we will show, if handled correctly, significant improvement can be achieved.",
                "A more general problem related to stemming is query reformulation [3, 12] and query expansion which expands words not only with word variants [7, 22, 24, 25].",
                "To decide which expanded words to use, people often use pseudorelevance feedback techniquesthat send the original query to a search engine and retrieve the top documents, extract relevant words from these top documents as additional query words, and resubmit the expanded query again [21].",
                "This normally requires sending a query multiple times to search engine and it is not cost effective for processing the huge amount of queries involved in Web search.",
                "In addition, query expansion, including query reformulation [3, 12], has a high risk of changing the user intent (called query drift).",
                "Since the expanded words may have different meanings, adding them to the query could potentially change the intent of the original query.",
                "Thus query expansion based on pseudorelevance and query reformulation can provide suggestions to users for interactive refinement but can hardly be directly used for Web search.",
                "On the other hand, stemming is much more conservative since most of the time, stemming preserves the original search intent.",
                "While most work on query expansion focuses on recall enhancement, our work focuses on increasing both recall and precision.",
                "The increase on recall is obvious.",
                "With quality stemming, good documents which were not selected before stemming will be pushed up and those low quality documents will be degraded.",
                "On selective query expansion, Cronen-Townsend et al. [6] proposed a method for selective query expansion based on comparing the Kullback-Leibler divergence of the results from the unexpanded query and the results from the expanded query.",
                "This is similar to the relevance feedback in the sense that it requires multiple passes retrieval.",
                "If a word can be expanded into several words, it requires running this process multiple times to decide which expanded word is useful.",
                "It is expensive to deploy this in production Web search engines.",
                "Our method predicts the quality of expansion based on oﬄine information without sending the query to a search engine.",
                "In summary, we propose a novel approach to attack an old, yet still important and challenging problem for Web search - stemming.",
                "Our approach is unique in that it performs predictive stemming on a per query basis without relevance feedback from the Web, using the context of the variants in documents to preserve precision.",
                "Its simple, yet very efficient and effective, making real time stemming feasible for Web search.",
                "Our results will affirm researchers that stemming is indeed very important to large scale information retrieval. 3.",
                "CONTEXT SENSITIVE STEMMING 3.1 Overview Our system has four components as illustrated in Figure 1: candidate generation, query segmentation and head word detection, <br>context sensitive query stemming</br> and context sensitive document matching.",
                "Candidate generation (component 1) is performed oﬄine and generated candidates are stored in a dictionary.",
                "For an input query, we first segment query into concepts and detect the head word for each concept (component 2).",
                "We then use statistical language modeling to decide whether a particular variant is useful (component 3), and finally for the expanded variants, we perform context sensitive document matching (component 4).",
                "Below we discuss each of the components in more detail.",
                "Component 4: context sensitive document matching Input Query: and head word detection Component 2: segment Component 1: candidate generation comparisons −> comparison Component 3: selective word expansion decision: comparisons −> comparison example: hotel price comparisons output: hotel comparisons hotel −> hotels Figure 1: System Components 3.2 Expansion candidate generation One of the ways to generate candidates is using the Porter stemmer [18].",
                "The Porter stemmer simply uses morphological rules to convert a word to its base form.",
                "It has no knowledge of the semantic meaning of the words and sometimes makes serious mistakes, such as executive to execution, news to new, and paste to past.",
                "A more conservative way is based on using corpus analysis to improve the Porter stemmer results [26].",
                "The corpus analysis we do is based on word distributional similarity [15].",
                "The rationale of using distributional word similarity is that true variants tend to be used in similar contexts.",
                "In the distributional word similarity calculation, each word is represented with a vector of features derived from the context of the word.",
                "We use the bigrams to the left and right of the word as its context features, by mining a huge Web corpus.",
                "The similarity between two words is the cosine similarity between the two corresponding feature vectors.",
                "The top 20 similar words to develop is shown in the following table. rank candidate score rank candidate score 0 develop 1 10 berts 0.119 1 developing 0.339 11 wads 0.116 2 developed 0.176 12 developer 0.107 3 incubator 0.160 13 promoting 0.100 4 develops 0.150 14 developmental 0.091 5 development 0.148 15 reengineering 0.090 6 tutoring 0.138 16 build 0.083 7 analyzing 0.128 17 construct 0.081 8 developement 0.128 18 educational 0.081 9 automation 0.126 19 institute 0.077 Table 1: Top 20 most similar candidates to word develop.",
                "Column score is the similarity score.",
                "To determine the stemming candidates, we apply a few Porter stemmer [18] morphological rules to the similarity list.",
                "After applying these rules, for the word develop, the stemming candidates are developing, developed, develops, development, developement, developer, developmental.",
                "For the pluralization handling purpose, only the candidate develops is retained.",
                "One thing we note from observing the distributionally similar words is that they are closely related semantically.",
                "These words might serve as candidates for general query expansion, a topic we will investigate in the future. 3.3 Segmentation and headword identification For long queries, it is quite important to detect the concepts in the query and the most important words for those concepts.",
                "We first break a query into segments, each segment representing a concept which normally is a noun phrase.",
                "For each of the noun phrases, we then detect the most important word which we call the head word.",
                "Segmentation is also used in document sensitive matching (section 3.5) to enforce proximity.",
                "To break a query into segments, we have to define a criteria to measure the strength of the relation between words.",
                "One effective method is to use mutual information as an indicator on whether or not to split two words [19].",
                "We use a log of 25M queries and collect the bigram and unigram frequencies from it.",
                "For every incoming query, we compute the mutual information of two adjacent words; if it passes a predefined threshold, we do not split the query between those two words and move on to next word.",
                "We continue this process until the mutual information between two words is below the threshold, then create a concept boundary here.",
                "Table 2 shows some examples of query segmentation.",
                "The ideal way of finding the head word of a concept is to do syntactic parsing to determine the dependency structure of the query.",
                "Query parsing is more difficult than sentence [running shoe] [best] [new york] [medical schools] [pictures] [of] [white house] [cookies] [in] [san francisco] [hotel] [price comparison] Table 2: Query segmentation: a segment is bracketed. parsing since many queries are not grammatical and are very short.",
                "Applying a parser trained on sentences from documents to queries will have poor performance.",
                "In our solution, we just use simple heuristics rules, and it works very well in practice for English.",
                "For an English noun phrase, the head word is typically the last nonstop word, unless the phrase is of a particular pattern, like XYZ of/in/at/from UVW.",
                "In such cases, the head word is typically the last nonstop word of XYZ. 3.4 Context sensitive word expansion After detecting which words are the most important words to expand, we have to decide whether the expansions will be useful.",
                "Our statistics show that about half of the queries can be transformed by pluralization via naive stemming.",
                "Among this half, about 25% of the queries improve relevance when transformed, the majority (about 50%) do not change their top 5 results, and the remaining 25% perform worse.",
                "Thus, it is extremely important to identify which queries should not be stemmed for the purpose of maximizing relevance improvement and minimizing stemming cost.",
                "In addition, for a query with multiple words that can be transformed, or a word with multiple variants, not all of the expansions are useful.",
                "Taking query hotel price comparison as an example, we decide that hotel and price comparison are two concepts.",
                "Head words hotel and comparison can be expanded to hotels and comparisons.",
                "Are both transformations useful?",
                "To test whether an expansion is useful, we have to know whether the expanded query is likely to get more relevant documents from the Web, which can be quantified by the probability of the query occurring as a string on the Web.",
                "The more likely a query to occur on the Web, the more relevant documents this query is able to return.",
                "Now the whole problem becomes how to calculate the probability of query to occur on the Web.",
                "Calculating the probability of string occurring in a corpus is a well known language modeling problem.",
                "The goal of language modeling is to predict the probability of naturally occurring word sequences, s = w1w2...wN ; or more simply, to put high probability on word sequences that actually occur (and low probability on word sequences that never occur).",
                "The simplest and most successful approach to language modeling is still based on the n-gram model.",
                "By the chain rule of probability one can write the probability of any word sequence as Pr(w1w2...wN ) = NY i=1 Pr(wi|w1...wi−1) (1) An n-gram model approximates this probability by assuming that the only words relevant to predicting Pr(wi|w1...wi−1) are the previous n − 1 words; i.e.",
                "Pr(wi|w1...wi−1) = Pr(wi|wi−n+1...wi−1) A straightforward maximum likelihood estimate of n-gram probabilities from a corpus is given by the observed frequency of each of the patterns Pr(wi|wi−n+1...wi−1) = #(wi−n+1...wi) #(wi−n+1...wi−1) (2) where #(.) denotes the number of occurrences of a specified gram in the training corpus.",
                "Although one could attempt to use simple n-gram models to capture long range dependencies in language, attempting to do so directly immediately creates sparse data problems: Using grams of length up to n entails estimating the probability of Wn events, where W is the size of the word vocabulary.",
                "This quickly overwhelms modern computational and data resources for even modest choices of n (beyond 3 to 6).",
                "Also, because of the heavy tailed nature of language (i.e.",
                "Zipfs law) one is likely to encounter novel n-grams that were never witnessed during training in any test corpus, and therefore some mechanism for assigning non-zero probability to novel n-grams is a central and unavoidable issue in statistical language modeling.",
                "One standard approach to smoothing probability estimates to cope with sparse data problems (and to cope with potentially missing n-grams) is to use some sort of back-off estimator.",
                "Pr(wi|wi−n+1...wi−1) = 8 >>< >>: ˆPr(wi|wi−n+1...wi−1), if #(wi−n+1...wi) > 0 β(wi−n+1...wi−1) × Pr(wi|wi−n+2...wi−1), otherwise (3) where ˆPr(wi|wi−n+1...wi−1) = discount #(wi−n+1...wi) #(wi−n+1...wi−1) (4) is the discounted probability and β(wi−n+1...wi−1) is a normalization constant β(wi−n+1...wi−1) = 1 − X x∈(wi−n+1...wi−1x) ˆPr(x|wi−n+1...wi−1) 1 − X x∈(wi−n+1...wi−1x) ˆPr(x|wi−n+2...wi−1) (5) The discounted probability (4) can be computed with different smoothing techniques, including absolute smoothing, Good-Turing smoothing, linear smoothing, and Witten-Bell smoothing [5].",
                "We used absolute smoothing in our experiments.",
                "Since the likelihood of a string, Pr(w1w2...wN ), is a very small number and hard to interpret, we use entropy as defined below to score the string.",
                "Entropy = − 1 N log2 Pr(w1w2...wN ) (6) Now getting back to the example of the query hotel price comparisons, there are four variants of this query, and the entropy of these four candidates are shown in Table 3.",
                "We can see that all alternatives are less likely than the input query.",
                "It is therefore not useful to make an expansion for this query.",
                "On the other hand, if the input query is hotel price comparisons which is the second alternative in the table, then there is a better alternative than the input query, and it should therefore be expanded.",
                "To tolerate the variations in probability estimation, we relax the selection criterion to those query alternatives if their scores are within a certain distance (10% in our experiments) to the best score.",
                "Query variations Entropy hotel price comparison 6.177 hotel price comparisons 6.597 hotels price comparison 6.937 hotels price comparisons 7.360 Table 3: Variations of query hotel price comparison ranked by entropy score, with the original query in bold face. 3.5 Context sensitive document matching Even after we know which word variants are likely to be useful, we have to be conservative in document matching for the expanded variants.",
                "For the query hotel price comparisons, we decided that word comparisons is expanded to include comparison.",
                "However, not every occurrence of comparison in the document is of interest.",
                "A page which is about comparing customer service can contain all of the words hotel price comparisons comparison.",
                "This page is not a good page for the query.",
                "If we accept matches of every occurrence of comparison, it will hurt retrieval precision and this is one of the main reasons why most stemming approaches do not work well for information retrieval.",
                "To address this problem, we have a proximity constraint that considers the context around the expanded variant in the document.",
                "A variant match is considered valid only if the variant occurs in the same context as the original word does.",
                "The context is the left or the right non-stop segments 1 of the original word.",
                "Taking the same query as an example, the context of comparisons is price.",
                "The expanded word comparison is only valid if it is in the same context of comparisons, which is after the word price.",
                "Thus, we should only match those occurrences of comparison in the document if they occur after the word price.",
                "Considering the fact that queries and documents may not represent the intent in exactly the same way, we relax this proximity constraint to allow variant occurrences within a window of some fixed size.",
                "If the expanded word comparison occurs within the context of price within a window, it is considered valid.",
                "The smaller the window size is, the more restrictive the matching.",
                "We use a window size of 4, which typically captures contexts that include the containing and adjacent noun phrases. 4.",
                "EXPERIMENTAL EVALUATION 4.1 Evaluation metrics We will measure both relevance improvement and the stemming cost required to achieve the relevance. 1 a context segment can not be a single stop word. 4.1.1 Relevance measurement We use a variant of the average Discounted Cumulative Gain (DCG), a recently popularized scheme to measure search engine relevance [1, 11].",
                "Given a query and a ranked list of K documents (K is set to 5 in our experiments), the DCG(K) score for this query is calculated as follows: DCG(K) = KX k=1 gk log2(1 + k) . (7) where gk is the weight for the document at rank k. Higher degree of relevance corresponds to a higher weight.",
                "A page is graded into one of the five scales: Perfect, Excellent, Good, Fair, Bad, with corresponding weights.",
                "We use dcg to represent the average DCG(5) over a set of test queries. 4.1.2 Stemming cost Another metric is to measure the additional cost incurred by stemming.",
                "Given the same level of relevance improvement, we prefer a stemming method that has less additional cost.",
                "We measure this by the percentage of queries that are actually stemmed, over all the queries that could possibly be stemmed. 4.2 Data preparation We randomly sample 870 queries from a three month query log, with 290 from each month.",
                "Among all these 870 queries, we remove all misspelled queries since misspelled queries are not of interest to stemming.",
                "We also remove all one word queries since stemming one word queries without context has a high risk of changing query intent, especially for short words.",
                "In the end, we have 529 correctly spelled queries with at least 2 words. 4.3 Naive stemming for Web search Before explaining the experiments and results in detail, wed like to describe the traditional way of using stemming for Web search, referred as the naive model.",
                "This is to treat every word variant equivalent for all possible words in the query.",
                "The query book store will be transformed into (book OR books)(store OR stores) when limiting stemming to pluralization handling only, where OR is an operator that denotes the equivalence of the left and right arguments. 4.4 Experimental setup The baseline model is the model without stemming.",
                "We first run the naive model to see how well it performs over the baseline.",
                "Then we improve the naive stemming model by document sensitive matching, referred as document sensitive matching model.",
                "This model makes the same stemming as the naive model on the query side, but performs conservative matching on the document side using the strategy described in section 3.5.",
                "The naive model and document sensitive matching model stem the most queries.",
                "Out of the 529 queries, there are 408 queries that they stem, corresponding to 46.7% query traffic (out of a total of 870).",
                "We then further improve the document sensitive matching model from the query side with selective word stemming based on statistical language modeling (section 3.4), referred as selective stemming model.",
                "Based on language modeling prediction, this model stems only a subset of the 408 queries stemmed by the document sensitive matching model.",
                "We experiment with unigram language model and bigram language model.",
                "Since we only care how much we can improve the naive model, we will only use these 408 queries (all the queries that are affected by the naive stemming model) in the experiments.",
                "To get a sense of how these models perform, we also have an oracle model that gives the upper-bound performance a stemmer can achieve on this data.",
                "The oracle model only expands a word if the stemming will give better results.",
                "To analyze the pluralization handling influence on different query categories, we divide queries into short queries and long queries.",
                "Among the 408 queries stemmed by the naive model, there are 272 short queries with 2 or 3 words, and 136 long queries with at least 4 words. 4.5 Results We summarize the overall results in Table 4, and present the results on short queries and long queries separately in Table 5.",
                "Each row in Table 4 is a stemming strategy described in section 4.4.",
                "The first column is the name of the strategy.",
                "The second column is the number of queries affected by this strategy; this column measures the stemming cost, and the numbers should be low for the same level of dcg.",
                "The third column is the average dcg score over all tested queries in this category (including the ones that were not stemmed by the strategy).",
                "The fourth column is the relative improvement over the baseline, and the last column is the p-value of Wilcoxon significance test.",
                "There are several observations about the results.",
                "We can see the naively stemming only obtains a statistically insignificant improvement of 1.5%.",
                "Looking at Table 5, it gives an improvement of 2.7% on short queries.",
                "However, it also hurts long queries by -2.4%.",
                "Overall, the improvement is canceled out.",
                "The reason that it improves short queries is that most short queries only have one word that can be stemmed.",
                "Thus, blindly pluralizing short queries is relatively safe.",
                "However for long queries, most queries can have multiple words that can be pluralized.",
                "Expanding all of them without selection will significantly hurt precision.",
                "Document context sensitive stemming gives a significant lift to the performance, from 2.7% to 4.2% for short queries and from -2.4% to -1.6% for long queries, with an overall lift from 1.5% to 2.8%.",
                "The improvement comes from the conservative context sensitive document matching.",
                "An expanded word is valid only if it occurs within the context of original query in the document.",
                "This reduces many spurious matches.",
                "However, we still notice that for long queries, context sensitive stemming is not able to improve performance because it still selects too many documents and gives the ranking function a hard problem.",
                "While the chosen window size of 4 works the best amongst all the choices, it still allows spurious matches.",
                "It is possible that the window size needs to be chosen on a per query basis to ensure tighter proximity constraints for different types of noun phrases.",
                "Selective word pluralization further helps resolving the problem faced by document context sensitive stemming.",
                "It does not stem every word that places all the burden on the ranking algorithm, but tries to eliminate unnecessary stemming in the first place.",
                "By predicting which word variants are going to be useful, we can dramatically reduce the number of stemmed words, thus improving both the recall and the precision.",
                "With the unigram language model, we can reduce the stemming cost by 26.7% (from 408/408 to 300/408) and lift the overall dcg improvement from 2.8% to 3.4%.",
                "In particular, it gives significant improvements on long queries.",
                "The dcg gain is turned from negative to positive, from −1.6% to 1.1%.",
                "This confirms our hypothesis that reducing unnecessary word expansion leads to precision improvement.",
                "For short queries too, we observe both dcg improvement and stemming cost reduction with the unigram language model.",
                "The advantages of predictive word expansion with a language model is further boosted with a better bigram language model.",
                "The overall dcg gain is lifted from 3.4% to 3.9%, and stemming cost is dramatically reduced from 408/408 to 250/408, corresponding to only 29% of query traffic (250 out of 870) and an overall 1.8% dcg improvement overall all query traffic.",
                "For short queries, bigram language model improves the dcg gain from 4.4% to 4.7%, and reduces stemming cost from 272/272 to 150/272.",
                "For long queries, bigram language model improves dcg gain from 1.1% to 2.5%, and reduces stemming cost from 136/136 to 100/136.",
                "We observe that the bigram language model gives a larger lift for long queries.",
                "This is because the uncertainty in long queries is larger and a more powerful language model is needed.",
                "We hypothesize that a trigram language model would give a further lift for long queries and leave this for future investigation.",
                "Considering the tight upper-bound 2 on the improvement to be gained from pluralization handling (via the oracle model), the current performance on short queries is very satisfying.",
                "For short queries, the dcg gain upper-bound is 6.3% for perfect pluralization handling, our current gain is 4.7% with a bigram language model.",
                "For long queries, the dcg gain upper-bound is 4.6% for perfect pluralization handling, our current gain is 2.5% with a bigram language model.",
                "We may gain additional benefit with a more powerful language model for long queries.",
                "However, the difficulties of long queries come from many other aspects including the proximity and the segmentation problem.",
                "These problems have to be addressed separately.",
                "Looking at the the upper-bound of overhead reduction for oracle stemming, 75% (308/408) of the naive stemmings are wasteful.",
                "We currently capture about half of them.",
                "Further reduction of the overhead requires sacrificing the dcg gain.",
                "Now we can compare the stemming strategies from a different aspect.",
                "Instead of looking at the influence over all queries as we described above, Table 6 summarizes the dcg improvements over the affected queries only.",
                "We can see that the number of affected queries decreases as the stemming strategy becomes more accurate (dcg improvement).",
                "For the bigram language model, over the 250/408 stemmed queries, the dcg improvement is 6.1%.",
                "An interesting observation is the average dcg decreases with a better model, which indicates a better stemming strategy stems more difficult queries (low dcg queries). 5.",
                "DISCUSSIONS 5.1 Language models from query vs. from Web As we mentioned in Section 1, we are trying to predict the probability of a string occurring on the Web.",
                "The language model should describe the occurrence of the string on the Web.",
                "However, the query log is also a good resource. 2 Note that this upperbound is for pluralization handling only, not for general stemming.",
                "General stemming gives a 8% upperbound, which is quite substantial in terms of our metrics.",
                "Affected Queries dcg dcg Improvement p-value baseline 0/408 7.102 N/A N/A naive model 408/408 7.206 1.5% 0.22 document context sensitive model 408/408 7.302 2.8% 0.014 selective model: unigram LM 300/408 7.321 3.4% 0.001 selective model: bigram LM 250/408 7.381 3.9% 0.001 oracle model 100/408 7.519 5.9% 0.001 Table 4: Results comparison of different stemming strategies over all queries affected by naive stemming Short Query Results Affected Queries dcg Improvement p-value baseline 0/272 N/A N/A naive model 272/272 2.7% 0.48 document context sensitive model 272/272 4.2% 0.002 selective model: unigram LM 185/272 4.4% 0.001 selective model: bigram LM 150/272 4.7% 0.001 oracle model 71/272 6.3% 0.001 Long Query Results Affected Queries dcg Improvement p-value baseline 0/136 N/A N/A naive model 136/136 -2.4% 0.25 document context sensitive model 136/136 -1.6% 0.27 selective model: unigram LM 115/136 1.1% 0.001 selective model: bigram LM 100/136 2.5% 0.001 oracle model 29/136 4.6% 0.001 Table 5: Results comparison of different stemming strategies overall short queries and long queries Users reformulate a query using many different variants to get good results.",
                "To test the hypothesis that we can learn reliable transformation probabilities from the query log, we trained a language model from the same query top 25M queries as used to learn segmentation, and use that for prediction.",
                "We observed a slight performance decrease compared to the model trained on Web frequencies.",
                "In particular, the performance for unigram LM was not affected, but the dcg gain for bigram LM changed from 4.7% to 4.5% for short queries.",
                "Thus, the query log can serve as a good approximation of the Web frequencies. 5.2 How linguistics helps Some linguistic knowledge is useful in stemming.",
                "For the pluralization handling case, pluralization and de-pluralization is not symmetric.",
                "A plural word used in a query indicates a special intent.",
                "For example, the query new york hotels is looking for a list of hotels in new york, not the specific new york hotel which might be a hotel located in California.",
                "A simple equivalence of hotel to hotels might boost a particular page about new york hotel to top rank.",
                "To capture this intent, we have to make sure the document is a general page about hotels in new york.",
                "We do this by requiring that the plural word hotels appears in the document.",
                "On the other hand, converting a singular word to plural is safer since a general purpose page normally contains specific information.",
                "We observed a slight overall dcg decrease, although not statistically significant, for document context sensitive stemming if we do not consider this asymmetric property. 5.3 Error analysis One type of mistakes we noticed, though rare but seriously hurting relevance, is the search intent change after stemming.",
                "Generally speaking, pluralization or depluralization keeps the original intent.",
                "However, the intent could change in a few cases.",
                "For one example of such a query, job at apple, we pluralize job to jobs.",
                "This stemming makes the original query ambiguous.",
                "The query job OR jobs at apple has two intents.",
                "One is the employment opportunities at apple, and another is a person working at Apple, Steve Jobs, who is the CEO and co-founder of the company.",
                "Thus, the results after query stemming returns Steve Jobs as one of the results in top 5.",
                "One solution is performing results set based analysis to check if the intent is changed.",
                "This is similar to relevance feedback and requires second phase ranking.",
                "A second type of mistakes is the entity/concept recognition problem, These include two kinds.",
                "One is that the stemmed word variant now matches part of an entity or concept.",
                "For example, query cookies in san francisco is pluralized to cookies OR cookie in san francisco.",
                "The results will match cookie jar in san francisco.",
                "Although cookie still means the same thing as cookies, cookie jar is a different concept.",
                "Another kind is the unstemmed word matches an entity or concept because of the stemming of the other words.",
                "For example, quote ICE is pluralized to quote OR quotes ICE.",
                "The original intent for this query is searching for stock quote for ticker ICE.",
                "However, we noticed that among the top results, one of the results is Food quotes: Ice cream.",
                "This is matched because of Affected Queries old dcg new dcg dcg Improvement naive model 408/408 7.102 7.206 1.5% document context sensitive model 408/408 7.102 7.302 2.8% selective model: unigram LM 300/408 5.904 6.187 4.8% selective model: bigram LM 250/408 5.551 5.891 6.1% Table 6: Results comparison over the stemmed queries only: column old/new dcg is the dcg score over the affected queries before/after applying stemming the pluralized word quotes.",
                "The unchanged word ICE matches part of the noun phrase ice cream here.",
                "To solve this kind of problem, we have to analyze the documents and recognize cookie jar and ice cream as concepts instead of two independent words.",
                "A third type of mistakes occurs in long queries.",
                "For the query bar code reader software, two words are pluralized. code to codes and reader to readers.",
                "In fact, bar code reader in the original query is a strong concept and the internal words should not be changed.",
                "This is the segmentation and entity and noun phrase detection problem in queries, which we actively are attacking.",
                "For long queries, we should correctly identify the concepts in the query, and boost the proximity for the words within a concept. 6.",
                "CONCLUSIONS AND FUTURE WORK We have presented a simple yet elegant way of stemming for Web search.",
                "It improves naive stemming in two aspects: selective word expansion on the query side and conservative word occurrence matching on the document side.",
                "Using pluralization handling as an example, experiments on a major Web search engine data show it significantly improves the Web relevance and reduces the stemming cost.",
                "It also significantly improves Web click through rate (details not reported in the paper).",
                "For the future work, we are investigating the problems we identified in the error analysis section.",
                "These include: entity and noun phrase matching mistakes, and improved segmentation. 7.",
                "REFERENCES [1] E. Agichtein, E. Brill, and S. T. Dumais.",
                "Improving Web Search Ranking by Incorporating User Behavior Information.",
                "In SIGIR, 2006. [2] E. Airio.",
                "Word Normalization and Decompounding in Mono- and Bilingual IR.",
                "Information Retrieval, 9:249-271, 2006. [3] P. Anick.",
                "Using Terminological Feedback for Web Search Refinement: a Log-based Study.",
                "In SIGIR, 2003. [4] R. Baeza-Yates and B. Ribeiro-Neto.",
                "Modern Information Retrieval.",
                "ACM Press/Addison Wesley, 1999. [5] S. Chen and J. Goodman.",
                "An Empirical Study of Smoothing Techniques for Language Modeling.",
                "Technical Report TR-10-98, Harvard University, 1998. [6] S. Cronen-Townsend, Y. Zhou, and B. Croft.",
                "A Framework for Selective Query Expansion.",
                "In CIKM, 2004. [7] H. Fang and C. Zhai.",
                "Semantic Term Matching in Axiomatic Approaches to Information Retrieval.",
                "In SIGIR, 2006. [8] W. B. Frakes.",
                "Term Conflation for Information Retrieval.",
                "In C. J. Rijsbergen, editor, Research and Development in Information Retrieval, pages 383-389.",
                "Cambridge University Press, 1984. [9] D. Harman.",
                "How Effective is Suffixing?",
                "JASIS, 42(1):7-15, 1991. [10] D. Hull.",
                "Stemming Algorithms - A Case Study for Detailed Evaluation.",
                "JASIS, 47(1):70-84, 1996. [11] K. Jarvelin and J. Kekalainen.",
                "Cumulated Gain-Based Evaluation Evaluation of IR Techniques.",
                "ACM TOIS, 20:422-446, 2002. [12] R. Jones, B. Rey, O. Madani, and W. Greiner.",
                "Generating Query Substitutions.",
                "In WWW, 2006. [13] W. Kraaij and R. Pohlmann.",
                "Viewing Stemming as Recall Enhancement.",
                "In SIGIR, 1996. [14] R. Krovetz.",
                "Viewing Morphology as an Inference Process.",
                "In SIGIR, 1993. [15] D. Lin.",
                "Automatic Retrieval and Clustering of Similar Words.",
                "In COLING-ACL, 1998. [16] J.",
                "B. Lovins.",
                "Development of a Stemming Algorithm.",
                "Mechanical Translation and Computational Linguistics, II:22-31, 1968. [17] M. Lennon and D. Peirce and B. Tarry and P. Willett.",
                "An Evaluation of Some Conflation Algorithms for Information Retrieval.",
                "Journal of Information Science, 3:177-188, 1981. [18] M. Porter.",
                "An Algorithm for Suffix Stripping.",
                "Program, 14(3):130-137, 1980. [19] K. M. Risvik, T. Mikolajewski, and P. Boros.",
                "Query Segmentation for Web Search.",
                "In WWW, 2003. [20] S. E. Robertson.",
                "On Term Selection for Query Expansion.",
                "Journal of Documentation, 46(4):359-364, 1990. [21] G. Salton and C. Buckley.",
                "Improving Retrieval Performance by Relevance Feedback.",
                "JASIS, 41(4):288 - 297, 1999. [22] R. Sun, C.-H. Ong, and T.-S. Chua.",
                "Mining Dependency Relations for Query Expansion in Passage Retrieval.",
                "In SIGIR, 2006. [23] C. Van Rijsbergen.",
                "Information Retrieval.",
                "Butterworths, second version, 1979. [24] B. V´elez, R. Weiss, M. A. Sheldon, and D. K. Gifford.",
                "Fast and Effective Query Refinement.",
                "In SIGIR, 1997. [25] J. Xu and B. Croft.",
                "Query Expansion using Local and Global Document Analysis.",
                "In SIGIR, 1996. [26] J. Xu and B. Croft.",
                "Corpus-based Stemming using Cooccurrence of Word Variants.",
                "ACM TOIS, 16 (1):61-81, 1998."
            ],
            "original_annotated_samples": [
                "CONTEXT SENSITIVE STEMMING 3.1 Overview Our system has four components as illustrated in Figure 1: candidate generation, query segmentation and head word detection, <br>context sensitive query stemming</br> and context sensitive document matching."
            ],
            "translated_annotated_samples": [
                "STEMMING CONTEXTUAL SENSIBLE 3.1 Resumen Nuestro sistema tiene cuatro componentes como se ilustra en la Figura 1: generación de candidatos, segmentación de consultas y detección de palabras clave, <br>derivación de consultas sensible al contexto</br> y coincidencia de documentos sensible al contexto."
            ],
            "translated_text": "Stemming sensible al contexto para la búsqueda web Fuchun Peng Nawaaz Ahmed Xin Li Yumao Lu Yahoo! Tradicionalmente, el truncamiento se ha aplicado a tareas de Recuperación de Información transformando las palabras en documentos a su forma raíz antes de indexarlas, y aplicando una transformación similar a los términos de consulta. Aunque aumenta la recuperación, esta estrategia ingenua no funciona bien para la Búsqueda en la Web, ya que disminuye la precisión y requiere una cantidad significativa de cálculos adicionales. En este artículo, proponemos un método de derivación sensible al contexto que aborda estos dos problemas. Dos propiedades únicas hacen que nuestro enfoque sea factible para la Búsqueda en la Web. Primero, basados en modelado estadístico del lenguaje, realizamos un análisis sensible al contexto en el lado de la consulta. Predecimos con precisión cuál de sus variantes morfológicas es útil para expandir un término de consulta antes de enviar la consulta al motor de búsqueda. Esto reduce drásticamente la cantidad de expansiones incorrectas, lo que a su vez disminuye el costo de la computación adicional y mejora la precisión al mismo tiempo. Segundo, nuestro enfoque realiza una coincidencia de documentos sensible al contexto para esas variantes ampliadas. Esta estrategia conservadora sirve como salvaguarda contra el truncamiento espurio, y resulta ser muy importante para mejorar la precisión. Usando el manejo de la pluralización de palabras como un ejemplo de nuestro enfoque de derivación, nuestros experimentos en un importante motor de búsqueda web muestran que al derivar solo el 29% del tráfico de consultas, podemos mejorar la relevancia medida por la Ganancia Acumulativa Descontada promedio (DCG5) en un 6.1% en estas consultas y en un 1.8% sobre todo el tráfico de consultas. Categorías y Descriptores de Asignaturas H.3.3 [Sistemas de Información]: Almacenamiento y Recuperación de Información-Formulación de Consultas Términos Generales Algoritmos, Experimentación 1. INTRODUCCIÓN La búsqueda en la web se ha convertido en una herramienta importante en nuestra vida diaria para buscar información. Uno de los problemas importantes en la búsqueda web es que las consultas de los usuarios a menudo no están formuladas de la mejor manera para obtener resultados óptimos. Por ejemplo, \"zapatilla para correr\" es una consulta que ocurre con frecuencia en los registros de consulta. Sin embargo, es mucho más probable que la búsqueda \"zapatillas para correr\" proporcione mejores resultados de búsqueda que la consulta original, ya que los documentos que coinciden con la intención de esta consulta suelen contener las palabras \"zapatillas para correr\". Formular correctamente una consulta requiere que el usuario prediga con precisión qué forma de palabra se utiliza en los documentos que mejor satisfacen sus necesidades de información. Esto es difícil incluso para usuarios experimentados, y especialmente difícil para hablantes no nativos. Una solución tradicional es utilizar el stemming [16, 18], el proceso de transformar palabras flexionadas o derivadas a su forma raíz para que un término de búsqueda coincida y recupere documentos que contengan todas las formas del término. Por lo tanto, la palabra \"run\" coincidirá con \"running\", \"ran\", \"runs\", y \"shoe\" coincidirá con \"shoes\" y \"shoeing\". El truncamiento se puede realizar tanto en los términos de un documento durante la indexación (y aplicando la misma transformación a los términos de la consulta durante el procesamiento de la consulta) o expandiendo la consulta con las variantes durante el procesamiento de la consulta. El truncamiento durante la indexación permite muy poca flexibilidad durante el procesamiento de consultas, mientras que el truncamiento mediante la expansión de consultas permite manejar cada consulta de manera diferente, y por lo tanto es preferible. Aunque el truncamiento tradicional aumenta la recuperación al emparejar variantes de palabras [13], puede reducir la precisión al recuperar demasiados documentos que han sido emparejados incorrectamente. Al examinar los resultados de aplicar el truncamiento a un gran número de consultas, generalmente se encuentra que casi igual cantidad de consultas se benefician y se ven perjudicadas por la técnica [6]. Además, reduce el rendimiento del sistema porque el motor de búsqueda tiene que hacer coincidir todas las variantes de palabras. Como mostraremos en los experimentos, esto es cierto incluso si simplificamos el proceso de derivación a la manipulación de pluralización, que es el proceso de convertir una palabra de su forma plural a singular, o viceversa. Por lo tanto, es necesario ser muy cauteloso al utilizar el stemming en los motores de búsqueda web. Un problema del truncamiento tradicional es su transformación ciega de todos los términos de consulta, es decir, siempre realiza la misma transformación para la misma palabra de consulta sin considerar el contexto de la palabra. Por ejemplo, la palabra \"book\" tiene cuatro formas: book, books, booking, booked, y la palabra \"store\" tiene cuatro formas: store, stores, storing, stored. Para la consulta de la librería, expandir ambas palabras a todas sus variantes aumenta significativamente el costo de computación y perjudica la precisión, ya que no todas las variantes son útiles para esta consulta. Transformar librería para que coincida con librerías está bien, pero hacer coincidir almacenamiento de libros o tienda de reservas no lo está. Un método de ponderación que otorga pesos más pequeños a las palabras variantes alivia los problemas hasta cierto punto si los pesos reflejan con precisión la importancia de la variante en esta consulta particular. Sin embargo, el peso uniforme no va a funcionar y un peso dependiente de la consulta sigue siendo un problema desafiante sin resolver [20]. Un segundo problema del truncamiento tradicional es su emparejamiento ciego de todas las ocurrencias en los documentos. Para la consulta de la librería, una transformación que permita que las tiendas variantes se emparejen hará que cada aparición de tiendas en el documento se trate de manera equivalente al término de consulta tienda. Por lo tanto, se emparejará un documento que contenga el fragmento de leer un libro en las cafeterías, lo que provocará que se seleccionen muchos documentos incorrectos. Aunque esperamos que la función de clasificación pueda manejar correctamente estos, con muchos más candidatos para clasificar, el riesgo de cometer errores aumenta. Para aliviar estos dos problemas, proponemos un enfoque de reducción de palabras raíz sensible al contexto para la búsqueda en la web. Nuestra solución consiste en dos análisis contextuales sensibles, uno en el lado de la consulta y otro en el lado del documento. En el lado de la consulta, proponemos un enfoque basado en modelado del lenguaje estadístico para predecir qué variantes de palabras son mejores formas que la palabra original con fines de búsqueda y expandir la consulta solo con esas formas. En el lado del documento, proponemos un emparejamiento conservador sensible al contexto para las variantes de palabras transformadas, solo emparejando las ocurrencias en el documento en el contexto de otros términos en la consulta. Nuestro modelo es simple pero efectivo y eficiente, lo que lo hace factible de ser utilizado en motores de búsqueda web comerciales reales. Utilizamos el manejo de pluralización como un ejemplo continuo para nuestro enfoque de derivación. La motivación para usar el manejo de pluralización como ejemplo es mostrar que incluso un truncamiento tan simple, si se maneja correctamente, puede brindar beneficios significativos a la relevancia de la búsqueda. Hasta donde sabemos, ninguna investigación previa ha investigado sistemáticamente el uso de la pluralización en la búsqueda en la web. Como debemos señalar, el método que proponemos no se limita al manejo de la pluralización, es una técnica de derivación general y también se puede aplicar a la expansión de consultas en general. Los experimentos sobre el truncamiento general producen mejoras significativas adicionales sobre el manejo de la pluralización para consultas largas, aunque los detalles no se informarán en este artículo. En el resto del documento, primero presentamos el trabajo relacionado y distinguimos nuestro método de trabajos anteriores en la Sección 2. Describimos los detalles del enfoque de derivación sensible al contexto en la Sección 3. Luego realizamos experimentos extensos en un importante motor de búsqueda web para respaldar nuestras afirmaciones en la Sección 4, seguidos de discusiones en la Sección 5. Finalmente, concluimos el artículo en la Sección 6.2. TRABAJO RELACIONADO El stemming es una tecnología estudiada desde hace mucho tiempo. Se han desarrollado muchos stemmers, como el stemmer Lovins [16] y el stemmer Porter [18]. El stemmer de Porter es ampliamente utilizado debido a su simplicidad y efectividad en muchas aplicaciones. Sin embargo, el algoritmo de Porter comete muchos errores porque sus reglas simples no pueden describir completamente la morfología del inglés. El análisis de corpus se utiliza para mejorar el stemmer de Porter [26] mediante la creación de clases de equivalencia para palabras que son morfológicamente similares y que ocurren en un contexto similar, medido por la información mutua esperada [23]. Utilizamos un enfoque de corpus similar para el stemming al calcular la similitud entre dos palabras basada en sus características de contexto distribucional, que pueden ser más que solo palabras adyacentes [15], y luego solo mantenemos las palabras morfológicamente similares como candidatas. El uso de la derivación en la recuperación de información también es una técnica bien conocida [8, 10]. Sin embargo, se informó previamente que la efectividad del truncamiento para los sistemas de consulta en inglés era bastante limitada. Lennon et al. [17] compararon los algoritmos de Lovins y Porter y encontraron poco mejoramiento en el rendimiento de recuperación. Más tarde, Harman [9] compara tres técnicas generales de derivación en experimentos de recuperación de texto, incluido el manejo de pluralización (llamado S stemmer en el artículo). También propusieron el truncamiento selectivo basado en la longitud de la consulta y la importancia del término, pero no se informaron resultados positivos. Por otro lado, Krovetz [14] realizó comparaciones sobre un pequeño número de documentos (de 400 a 12k) y mostró una mejora dramática en la precisión (de hasta un 45%). Sin embargo, debido al número limitado de consultas probadas (menos de 100) y al tamaño reducido de la colección, los resultados son difíciles de generalizar para la búsqueda en la web. Estos resultados mixtos, en su mayoría fracasos, llevaron a los primeros investigadores de IR a considerar que el truncamiento era irrelevante en general para el inglés [4], aunque investigaciones recientes han demostrado que el truncamiento tiene mayores beneficios para la recuperación en otros idiomas [2]. Sospechamos que los fracasos anteriores se debieron principalmente a los dos problemas que mencionamos en la introducción. El stemming ciego, o un stemming selectivo basado en la longitud de la consulta como se utiliza en [9], no es suficiente. El truncamiento debe decidirse caso por caso, no solo a nivel de consulta sino también a nivel de documento. Como demostraremos, si se maneja correctamente, se puede lograr una mejora significativa. Un problema más general relacionado con el stemming es la reformulación de consultas [3, 12] y la expansión de consultas que amplía las palabras no solo con variantes de palabras [7, 22, 24, 25]. Para decidir qué palabras expandidas usar, las personas a menudo utilizan técnicas de retroalimentación de seudorelevancia que envían la consulta original a un motor de búsqueda y recuperan los documentos principales, extraen palabras relevantes de estos documentos principales como palabras de consulta adicionales y vuelven a enviar la consulta expandida nuevamente [21]. Esto normalmente requiere enviar una consulta varias veces al motor de búsqueda y no es rentable para procesar la gran cantidad de consultas involucradas en la búsqueda web. Además, la expansión de consultas, incluida la reformulación de consultas [3, 12], tiene un alto riesgo de cambiar la intención del usuario (llamado desviación de consulta). Dado que las palabras expandidas pueden tener diferentes significados, agregarlas a la consulta podría potencialmente cambiar la intención de la consulta original. Por lo tanto, la expansión de consultas basada en pseudorelevancia y la reformulación de consultas pueden proporcionar sugerencias a los usuarios para su refinamiento interactivo, pero difícilmente pueden ser utilizadas directamente para la búsqueda en la web. Por otro lado, el truncamiento es mucho más conservador ya que la mayoría de las veces, conserva la intención de búsqueda original. Si bien la mayoría de los trabajos sobre la expansión de consultas se centran en mejorar la recuperación, nuestro trabajo se enfoca en aumentar tanto la recuperación como la precisión. El aumento en el recuerdo es evidente. Con el stemming de calidad, los buenos documentos que no fueron seleccionados antes del stemming serán promovidos y aquellos documentos de baja calidad serán degradados. En la expansión selectiva de consultas, Cronen-Townsend et al. [6] propusieron un método para la expansión selectiva de consultas basado en comparar la divergencia de Kullback-Leibler de los resultados de la consulta no expandida y los resultados de la consulta expandida. Esto es similar a la retroalimentación de relevancia en el sentido de que requiere múltiples pasadas de recuperación. Si una palabra puede expandirse en varias palabras, se requiere ejecutar este proceso varias veces para decidir cuál palabra expandida es útil. Es costoso implementar esto en motores de búsqueda web en producción. Nuestro método predice la calidad de la expansión basándose en información sin conexión sin enviar la consulta a un motor de búsqueda. En resumen, proponemos un enfoque novedoso para abordar un problema antiguo, pero aún importante y desafiante para la búsqueda en la web: el stemming. Nuestro enfoque es único en el sentido de que realiza el truncamiento predictivo de forma individualizada para cada consulta sin retroalimentación de relevancia de la Web, utilizando el contexto de las variantes en los documentos para preservar la precisión. Es simple, pero muy eficiente y efectivo, lo que hace factible el truncamiento en tiempo real para la búsqueda en la web. Nuestros resultados confirmarán a los investigadores que el truncamiento es realmente muy importante para la recuperación de información a gran escala. STEMMING CONTEXTUAL SENSIBLE 3.1 Resumen Nuestro sistema tiene cuatro componentes como se ilustra en la Figura 1: generación de candidatos, segmentación de consultas y detección de palabras clave, <br>derivación de consultas sensible al contexto</br> y coincidencia de documentos sensible al contexto. La generación de candidatos (componente 1) se realiza fuera de línea y los candidatos generados se almacenan en un diccionario. Para una consulta de entrada, primero segmentamos la consulta en conceptos y detectamos la palabra principal de cada concepto (componente 2). Luego utilizamos modelado de lenguaje estadístico para decidir si una variante particular es útil (componente 3), y finalmente, para las variantes expandidas, realizamos un emparejamiento de documentos sensible al contexto (componente 4). A continuación discutimos cada uno de los componentes con más detalle. Componente 4: coincidencia de documentos sensibles al contexto Consulta de entrada: y detección de palabras clave Componente 2: segmento Componente 1: generación de candidatos comparaciones −> comparación Componente 3: decisión de expansión selectiva de palabras: comparaciones −> comparación ejemplo: comparaciones de precios de hoteles salida: comparaciones de hoteles hotel −> hoteles Figura 1: Componentes del sistema 3.2 Generación de candidatos de expansión Una de las formas de generar candidatos es utilizando el stemmer de Porter [18]. El stemmer de Porter simplemente utiliza reglas morfológicas para convertir una palabra a su forma base. No tiene conocimiento del significado semántico de las palabras y a veces comete errores graves, como cambiar \"executive\" por \"execution\", \"news\" por \"new\" y \"paste\" por \"past\". Una forma más conservadora se basa en utilizar análisis de corpus para mejorar los resultados del stemmer de Porter [26]. El análisis de corpus que realizamos se basa en la similitud distribucional de palabras [15]. La razón de utilizar la similitud distribucional de palabras es que las variantes verdaderas tienden a ser utilizadas en contextos similares. En el cálculo de similitud de palabras distribucionales, cada palabra se representa con un vector de características derivadas del contexto de la palabra. Utilizamos los bigramas a la izquierda y a la derecha de la palabra como sus características de contexto, mediante la extracción de un gran corpus web. La similitud entre dos palabras es la similitud coseno entre los dos vectores de características correspondientes. Las 20 palabras similares a \"desarrollar\" se muestran en la siguiente tabla. rango candidato puntaje rango candidato puntaje 0 desarrollar 1 10 berts 0.119 1 desarrollando 0.339 11 wads 0.116 2 desarrollado 0.176 12 desarrollador 0.107 3 incubadora 0.160 13 promoviendo 0.100 4 desarrolla 0.150 14 desarrollo 0.091 5 desarrollo 0.148 15 reingeniería 0.090 6 tutoría 0.138 16 construir 0.083 7 analizando 0.128 17 construir 0.081 8 desarrollo 0.128 18 educativo 0.081 9 automatización 0.126 19 instituto 0.077 Tabla 1: Los 20 candidatos más similares a la palabra \"desarrollar\". La puntuación de la columna es la puntuación de similitud. Para determinar los candidatos de derivación, aplicamos algunas reglas morfológicas del stemmer de Porter [18] a la lista de similitud. Después de aplicar estas reglas, para la palabra desarrollar, los candidatos de derivación son desarrollando, desarrollado, desarrolla, desarrollo, desarrollo, desarrollador, y desarrollo. Para el propósito de manejo de pluralización, solo se conserva el candidato desarrolla. Una cosa que observamos al observar las palabras distribucionalmente similares es que están estrechamente relacionadas semánticamente. Estas palabras podrían servir como candidatas para la expansión general de consultas, un tema que investigaremos en el futuro. 3.3 Segmentación e identificación de palabras clave Para consultas largas, es bastante importante detectar los conceptos en la consulta y las palabras más importantes para esos conceptos. Primero dividimos una consulta en segmentos, cada segmento representando un concepto que normalmente es una frase nominal. Para cada una de las frases nominales, luego detectamos la palabra más importante a la que llamamos la palabra principal. La segmentación también se utiliza en la coincidencia sensible a documentos (sección 3.5) para hacer cumplir la proximidad. Para dividir una consulta en segmentos, tenemos que definir un criterio para medir la fuerza de la relación entre las palabras. Un método efectivo es utilizar la información mutua como indicador para decidir si dividir o no dos palabras [19]. Utilizamos un registro de 25 millones de consultas y recopilamos las frecuencias de bigramas y unigramas a partir de él. Para cada consulta entrante, calculamos la información mutua de dos palabras adyacentes; si supera un umbral predefinido, no dividimos la consulta entre esas dos palabras y pasamos a la siguiente palabra. Continuamos este proceso hasta que la información mutua entre dos palabras esté por debajo del umbral, luego creamos un límite conceptual aquí. La Tabla 2 muestra algunos ejemplos de segmentación de consultas. La forma ideal de encontrar la palabra principal de un concepto es realizar un análisis sintáctico para determinar la estructura de dependencia de la consulta. El análisis de consultas es más difícil que el análisis de oraciones, ya que muchas consultas no son gramaticales y son muy cortas. Aplicar un analizador entrenado en oraciones de documentos a consultas tendrá un rendimiento deficiente. En nuestra solución, solo utilizamos reglas heurísticas simples, y funciona muy bien en la práctica para el inglés. Para una frase nominal en inglés, la palabra principal suele ser la última palabra no detenida, a menos que la frase siga un patrón particular, como XYZ de/en/a/desde UVW. En tales casos, la palabra principal suele ser la última palabra no detenida de XYZ. 3.4 Expansión de palabras sensibles al contexto Después de detectar cuáles son las palabras más importantes para expandir, debemos decidir si las expansiones serán útiles. Nuestras estadísticas muestran que aproximadamente la mitad de las consultas pueden ser transformadas mediante la pluralización a través de un truncamiento ingenuo. Entre esta mitad, aproximadamente el 25% de las consultas mejoran la relevancia cuando se transforman, la mayoría (alrededor del 50%) no cambian sus 5 resultados principales, y el 25% restante tiene un rendimiento peor. Por lo tanto, es extremadamente importante identificar qué consultas no deben ser truncadas con el fin de maximizar la mejora de relevancia y minimizar el costo de truncamiento. Además, para una consulta con múltiples palabras que pueden ser transformadas, o una palabra con múltiples variantes, no todas las expansiones son útiles. Tomando la comparación de precios de hoteles como ejemplo, decidimos que hotel y comparación de precios son dos conceptos. Las palabras clave hotel y comparación se pueden expandir a hoteles y comparaciones. ¿Son útiles ambas transformaciones? Para probar si una expansión es útil, tenemos que saber si es probable que la consulta expandida obtenga más documentos relevantes de la web, lo cual puede cuantificarse mediante la probabilidad de que la consulta ocurra como una cadena en la web. Cuanto más probable sea que ocurra una consulta en la web, más documentos relevantes puede devolver esta consulta. Ahora todo el problema se convierte en cómo calcular la probabilidad de que ocurra la consulta en la Web. Calcular la probabilidad de que una cadena ocurra en un corpus es un problema bien conocido de modelado del lenguaje. El objetivo del modelado del lenguaje es predecir la probabilidad de secuencias de palabras que ocurren naturalmente, s = w1w2...wN; o más simplemente, asignar una alta probabilidad a las secuencias de palabras que realmente ocurren (y una baja probabilidad a las secuencias de palabras que nunca ocurren). El enfoque más simple y exitoso para el modelado del lenguaje sigue estando basado en el modelo n-gramo. Por la regla de la cadena de probabilidad, se puede escribir la probabilidad de cualquier secuencia de palabras como Pr(w1w2...wN) = ΠY i=1 Pr(wi|w1...wi−1) (1). Un modelo n-grama aproxima esta probabilidad asumiendo que las únicas palabras relevantes para predecir Pr(wi|w1...wi−1) son las n − 1 palabras anteriores; es decir, La probabilidad de una palabra wi dado w1...wi−1 es igual a la probabilidad de wi dado wi−n+1...wi−1. Una estimación directa de máxima verosimilitud de las probabilidades de n-gramas a partir de un corpus se obtiene a partir de la frecuencia observada de cada uno de los patrones Pr(wi|wi−n+1...wi−1) = #(wi−n+1...wi) #(wi−n+1...wi−1) donde #(.) denota el número de ocurrencias de un n-grama específico en el corpus de entrenamiento. Aunque se podría intentar usar modelos de n-gramos simples para capturar dependencias a largo plazo en el lenguaje, intentar hacerlo directamente crea inmediatamente problemas de datos dispersos: Utilizar n-gramos de longitud hasta n implica estimar la probabilidad de eventos de longitud Wn, donde W es el tamaño del vocabulario de palabras. Esto rápidamente abruma los recursos computacionales y de datos modernos incluso para opciones modestas de n (más allá de 3 a 6). Además, debido a la naturaleza de cola pesada del lenguaje (es decir, La ley de Zipf) es probable que uno se encuentre con n-gramas novedosos que nunca fueron observados durante el entrenamiento en ningún corpus de prueba, por lo tanto, algún mecanismo para asignar una probabilidad distinta de cero a los n-gramas novedosos es un problema central e inevitable en la modelización estadística del lenguaje. Un enfoque estándar para suavizar las estimaciones de probabilidad para hacer frente a problemas de datos escasos (y para hacer frente a posibles n-gramas faltantes) es utilizar algún tipo de estimador de retroceso. Pr(wi|wi−n+1...wi−1) = 8 >>< >>: ˆPr(wi|wi−n+1...wi−1), si #(wi−n+1...wi) > 0 β(wi−n+1...wi−1) × Pr(wi|wi−n+2...wi−1), de lo contrario (3) donde ˆPr(wi|wi−n+1...wi−1) = descuento #(wi−n+1...wi) #(wi−n+1...wi−1) (4) es la probabilidad descontada y β(wi−n+1...wi−1) es una constante de normalización β(wi−n+1...wi−1) = 1 − X x∈(wi−n+1...wi−1x) ˆPr(x|wi−n+1...wi−1) 1 − X x∈(wi−n+1...wi−1x) ˆPr(x|wi−n+2...wi−1) (5) La probabilidad descontada (4) se puede calcular con diferentes técnicas de suavizado, incluido el suavizado absoluto, el suavizado de Good-Turing, el suavizado lineal y el suavizado de Witten-Bell [5]. Utilizamos suavizado absoluto en nuestros experimentos. Dado que la probabilidad de una cadena, Pr(w1w2...wN), es un número muy pequeño y difícil de interpretar, utilizamos la entropía, tal como se define a continuación, para puntuar la cadena. Entropía = − 1 N log2 Pr(w1w2...wN ) (6) Ahora volviendo al ejemplo de la comparación de precios de hoteles, hay cuatro variantes de esta consulta, y la entropía de estos cuatro candidatos se muestra en la Tabla 3. Podemos ver que todas las alternativas son menos probables que la consulta de entrada. Por lo tanto, no es útil hacer una expansión para esta consulta. Por otro lado, si la consulta de entrada son comparaciones de precios de hoteles, que es la segunda alternativa en la tabla, entonces hay una mejor alternativa que la consulta de entrada, y por lo tanto debería ser ampliada. Para tolerar las variaciones en la estimación de probabilidad, relajamos el criterio de selección para esas alternativas de consulta si sus puntuaciones están dentro de una cierta distancia (10% en nuestros experimentos) de la mejor puntuación. Variaciones de la consulta Comparación de precios de hoteles 6.177 comparaciones de precios de hoteles 6.597 comparación de precios de hoteles 6.937 comparaciones de precios de hoteles 7.360 Tabla 3: Variaciones de la consulta comparación de precios de hoteles clasificadas por puntaje de entropía, con la consulta original en negrita. 3.5 Coincidencia de documentos sensibles al contexto Aun después de saber qué variantes de palabras son probablemente útiles, debemos ser conservadores en la coincidencia de documentos para las variantes ampliadas. Para la consulta de comparaciones de precios de hoteles, decidimos que la palabra \"comparaciones\" se amplía para incluir \"comparación\". Sin embargo, no todos los casos de comparación en el documento son de interés. Una página que trata sobre comparar el servicio al cliente puede contener todas las palabras comparaciones de precios de hoteles comparación. Esta página no es una buena página para la consulta. Si aceptamos coincidencias de cada ocurrencia de comparación, afectará la precisión de recuperación y esta es una de las principales razones por las que la mayoría de los enfoques de derivación no funcionan bien para la recuperación de información. Para abordar este problema, tenemos una restricción de proximidad que considera el contexto alrededor de la variante expandida en el documento. Una coincidencia de variante se considera válida solo si la variante ocurre en el mismo contexto que la palabra original lo hace. El contexto son los segmentos continuos de la izquierda o de la derecha de la palabra original. Tomando la misma consulta como ejemplo, el contexto de las comparaciones es el precio. La comparación de palabras ampliada solo es válida si está en el mismo contexto de comparaciones, que es después de la palabra precio. Por lo tanto, solo debemos emparejar aquellas ocurrencias de comparación en el documento si ocurren después de la palabra precio. Considerando el hecho de que las consultas y los documentos pueden no representar la intención de la misma manera exacta, relajamos esta restricción de proximidad para permitir ocurrencias variantes dentro de una ventana de un tamaño fijo. Si la comparación de palabras expandidas ocurre dentro del contexto de precio dentro de una ventana, se considera válida. Cuanto más pequeño sea el tamaño de la ventana, más restrictiva será la coincidencia. Utilizamos un tamaño de ventana de 4, que normalmente captura contextos que incluyen las frases nominales que contienen y las adyacentes. 4. EVALUACIÓN EXPERIMENTAL 4.1 Métricas de evaluación Mediremos tanto la mejora de relevancia como el costo de derivación necesario para lograr la relevancia. 1 un segmento de contexto no puede ser una sola palabra de parada. 4.1.1 Medición de relevancia Utilizamos una variante de la Ganancia Acumulada Descontada Promedio (DCG), un esquema recientemente popularizado para medir la relevancia de los motores de búsqueda [1, 11]. Dada una consulta y una lista clasificada de K documentos (K se establece en 5 en nuestros experimentos), el puntaje DCG(K) para esta consulta se calcula de la siguiente manera: DCG(K) = Σ k=1 a K gk log2(1 + k) . (7) donde gk es el peso para el documento en la posición k. Un mayor grado de relevancia corresponde a un peso mayor. Una página se califica en una de las cinco escalas: Perfecto, Excelente, Bueno, Regular, Malo, con pesos correspondientes. Utilizamos DCG para representar el DCG promedio(5) sobre un conjunto de consultas de prueba. 4.1.2 Costo de derivación Otro métrica es medir el costo adicional incurrido por la derivación. Dado el mismo nivel de mejora en la relevancia, preferimos un método de truncamiento que tenga un menor costo adicional. Medimos esto por el porcentaje de consultas que realmente se reducen, sobre todas las consultas que podrían ser reducidas. 4.2 Preparación de datos Muestreamos aleatoriamente 870 consultas de un registro de consultas de tres meses, con 290 de cada mes. Entre todas estas 870 consultas, eliminamos todas las consultas con errores ortográficos ya que las consultas con errores ortográficos no son de interés para el stemming. También eliminamos todas las consultas de una sola palabra, ya que reducir las consultas de una sola palabra sin contexto tiene un alto riesgo de cambiar la intención de la consulta, especialmente para palabras cortas. Al final, tenemos 529 consultas correctamente escritas con al menos 2 palabras. 4.3 Stemming ingenuo para la búsqueda en la Web Antes de explicar en detalle los experimentos y resultados, nos gustaría describir la forma tradicional de usar el stemming para la búsqueda en la Web, conocida como el modelo ingenuo. Esto es para tratar cada variante de palabra equivalente para todas las posibles palabras en la consulta. La consulta de la librería se transformará en (libro O libros)(tienda O tiendas) al limitar el truncamiento al manejo de pluralización solamente, donde O es un operador que denota la equivalencia de los argumentos izquierdo y derecho. 4.4 Configuración experimental El modelo base es el modelo sin truncamiento. Primero ejecutamos el modelo ingenuo para ver qué tan bien se desempeña en comparación con el punto de referencia. Luego mejoramos el modelo de derivación ingenua mediante la coincidencia sensible al documento, denominado modelo de coincidencia sensible al documento. Este modelo realiza el mismo stemming que el modelo ingenuo en el lado de la consulta, pero realiza un emparejamiento conservador en el lado del documento utilizando la estrategia descrita en la sección 3.5. El modelo ingenuo y el modelo de coincidencia sensible al documento son los que mejor responden a la mayoría de las consultas. De las 529 consultas, hay 408 consultas que se originan, lo que corresponde al 46.7% del tráfico de consultas (de un total de 870). Luego mejoramos aún más el modelo de coincidencia sensible de documentos desde el lado de la consulta con un proceso de derivación de palabras selectivo basado en modelado estadístico del lenguaje (sección 3.4), denominado modelo de derivación selectiva. Basado en la predicción del modelado del lenguaje, este modelo deriva solo un subconjunto de las 408 consultas derivadas por el modelo de coincidencia sensible al documento. Experimentamos con un modelo de lenguaje unigrama y un modelo de lenguaje bigrama. Dado que solo nos importa cuánto podemos mejorar el modelo ingenuo, solo utilizaremos estas 408 consultas (todas las consultas que se ven afectadas por el modelo de derivación ingenuo) en los experimentos. Para tener una idea de cómo se desempeñan estos modelos, también tenemos un modelo oráculo que proporciona el rendimiento máximo que un stemmer puede lograr en estos datos. El modelo del oráculo solo expande una palabra si el truncamiento dará mejores resultados. Para analizar la influencia del manejo de la pluralización en diferentes categorías de consultas, dividimos las consultas en consultas cortas y consultas largas. Entre las 408 consultas generadas por el modelo ingenuo, hay 272 consultas cortas con 2 o 3 palabras, y 136 consultas largas con al menos 4 palabras. Resumimos los resultados generales en la Tabla 4, y presentamos los resultados de las consultas cortas y largas por separado en la Tabla 5. Cada fila en la Tabla 4 es una estrategia de derivación descrita en la sección 4.4. La primera columna es el nombre de la estrategia. La segunda columna es el número de consultas afectadas por esta estrategia; esta columna mide el costo de derivación, y los números deberían ser bajos para el mismo nivel de dcg. La tercera columna es la puntuación DCG promedio sobre todas las consultas probadas en esta categoría (incluyendo aquellas que no fueron truncadas por la estrategia). La cuarta columna es la mejora relativa sobre la línea base, y la última columna es el valor p de la prueba de significancia de Wilcoxon. Hay varias observaciones sobre los resultados. Podemos ver que el truncado ingenuo solo logra una mejora estadísticamente insignificante del 1.5%. Mirando la Tabla 5, se observa una mejora del 2.7% en las consultas cortas. Sin embargo, también perjudica las consultas largas en un -2.4%. En general, la mejora se cancela. La razón por la que mejora las consultas cortas es que la mayoría de las consultas cortas solo tienen una palabra que se puede reducir a su raíz. Por lo tanto, pluralizar ciegamente consultas cortas es relativamente seguro. Sin embargo, para consultas largas, la mayoría de las consultas pueden tener varias palabras que pueden ser pluralizadas. Expandir todos ellos sin selección perjudicará significativamente la precisión. La aplicación de un stemming sensible al contexto del documento proporciona un aumento significativo en el rendimiento, desde un 2.7% hasta un 4.2% para consultas cortas y desde un -2.4% hasta un -1.6% para consultas largas, con un aumento general del 1.5% al 2.8%. La mejora proviene de la coincidencia de documentos sensible al contexto conservador. Una palabra expandida es válida solo si ocurre dentro del contexto de la consulta original en el documento. Esto reduce muchas coincidencias falsas. Sin embargo, aún observamos que para consultas largas, el truncamiento sensible al contexto no logra mejorar el rendimiento porque sigue seleccionando demasiados documentos y le presenta a la función de clasificación un problema difícil. Si bien el tamaño de ventana elegido de 4 es el que mejor funciona entre todas las opciones, aún permite coincidencias espurias. Es posible que el tamaño de la ventana deba elegirse según la consulta para garantizar restricciones de proximidad más estrictas para diferentes tipos de frases nominales. La pluralización selectiva de palabras ayuda aún más a resolver el problema enfrentado por el truncamiento sensible al contexto del documento. No se aplica el truncamiento a cada palabra que coloca toda la carga en el algoritmo de clasificación, sino que intenta eliminar el truncamiento innecesario en primer lugar. Al predecir qué variantes de palabras van a ser útiles, podemos reducir drásticamente el número de palabras derivadas, mejorando así tanto la recuperación como la precisión. Con el modelo de lenguaje unigrama, podemos reducir el costo de derivación en un 26.7% (de 408/408 a 300/408) y aumentar la mejora general de DCG del 2.8% al 3.4%. En particular, proporciona mejoras significativas en consultas largas. La ganancia de DCG se cambia de negativa a positiva, de -1.6% a 1.1%. Esto confirma nuestra hipótesis de que reducir la expansión innecesaria de palabras conduce a una mejora en la precisión. Para consultas cortas también observamos tanto la mejora de dcg como la reducción del costo de derivación con el modelo de lenguaje unigrama. Las ventajas de la expansión predictiva de palabras con un modelo de lenguaje se potencian aún más con un mejor modelo de lenguaje de bigrama. La ganancia total de DCG aumenta de 3.4% a 3.9%, y el costo de derivación se reduce drásticamente de 408/408 a 250/408, correspondiente a solo el 29% del tráfico de consultas (250 de 870) y una mejora total de DCG del 1.8% en todo el tráfico de consultas. Para consultas cortas, el modelo de lenguaje de bigrama mejora la ganancia de DCG del 4.4% al 4.7%, y reduce el costo de derivación de 272/272 a 150/272. Para consultas largas, el modelo de lenguaje de bigrama mejora la ganancia de DCG del 1.1% al 2.5%, y reduce el costo de derivación de 136/136 a 100/136. Observamos que el modelo de lenguaje de bigrama proporciona un mayor aumento para consultas largas. Esto se debe a que la incertidumbre en las consultas largas es mayor y se necesita un modelo de lenguaje más potente. Hacemos la hipótesis de que un modelo de lenguaje de trigramas proporcionaría un impulso adicional para consultas largas y dejamos esto para investigaciones futuras. Considerando el límite superior estricto de 2 en la mejora que se puede obtener del manejo de la pluralización (a través del modelo oráculo), el rendimiento actual en consultas cortas es muy satisfactorio. Para consultas breves, la ganancia máxima de DCG es del 6.3% para el manejo perfecto de la pluralización, nuestra ganancia actual es del 4.7% con un modelo de lenguaje de bigrama. Para consultas largas, la ganancia máxima de DCG es del 4.6% para el manejo perfecto de la pluralización, nuestra ganancia actual es del 2.5% con un modelo de lenguaje de bigrama. Podríamos obtener beneficios adicionales con un modelo de lenguaje más potente para consultas largas. Sin embargo, las dificultades de las consultas largas provienen de muchos otros aspectos, incluyendo la proximidad y el problema de la segmentación. Estos problemas deben ser abordados por separado. Al observar el límite superior de reducción de gastos generales para el truncamiento de Oracle, el 75% (308/408) de los truncamientos ingenuos son inútiles. Actualmente capturamos alrededor de la mitad de ellos. La reducción adicional de los gastos generales requiere sacrificar la ganancia de la DCG. Ahora podemos comparar las estrategias de derivación desde un aspecto diferente. En lugar de analizar la influencia sobre todas las consultas como describimos anteriormente, la Tabla 6 resume las mejoras de DCG solo sobre las consultas afectadas. Podemos ver que el número de consultas afectadas disminuye a medida que la estrategia de derivación se vuelve más precisa (mejora en el dcg). Para el modelo de lenguaje de bigrama, sobre las 250/408 consultas truncadas, la mejora en DCG es del 6.1%. Una observación interesante es que el dcg promedio disminuye con un modelo mejor, lo que indica que una estrategia de derivación mejorada deriva consultas más difíciles (consultas con bajo dcg). 5. Como mencionamos en la Sección 1, estamos tratando de predecir la probabilidad de que una cadena ocurra en la Web. El modelo de lenguaje debe describir la ocurrencia de la cadena en la web. Sin embargo, el registro de consultas también es un buen recurso. Tenga en cuenta que este límite superior es solo para el manejo de pluralización, no para el truncamiento general. El stemming general proporciona un límite superior del 8%, lo cual es bastante sustancial en términos de nuestras métricas. Las consultas afectadas dcg dcg Mejora p-valor línea de base 0/408 7.102 N/A N/A modelo ingenuo 408/408 7.206 1.5% 0.22 modelo sensible al contexto del documento 408/408 7.302 2.8% 0.014 modelo selectivo: unigram LM 300/408 7.321 3.4% 0.001 modelo selectivo: bigram LM 250/408 7.381 3.9% 0.001 modelo oráculo 100/408 7.519 5.9% 0.001 Tabla 4: Comparación de resultados de diferentes estrategias de derivación en todas las consultas afectadas por la derivación ingenua Resultados de Consultas Cortas Consultas Afectadas dcg Mejora p-valor línea de base 0/272 N/A N/A modelo ingenuo 272/272 2.7% 0.48 modelo sensible al contexto del documento 272/272 4.2% 0.002 modelo selectivo: unigram LM 185/272 4.4% 0.001 modelo selectivo: bigram LM 150/272 4.7% 0.001 modelo oráculo 71/272 6.3% 0.001 Resultados de Consultas Largas Consultas Afectadas dcg Mejora p-valor línea de base 0/136 N/A N/A modelo ingenuo 136/136 -2.4% 0.25 modelo sensible al contexto del documento 136/136 -1.6% 0.27 modelo selectivo: unigram LM 115/136 1.1% 0.001 modelo selectivo: bigram LM 100/136 2.5% 0.001 modelo oráculo 29/136 4.6% 0.001 Tabla 5: Comparación de resultados de diferentes estrategias de derivación en consultas cortas y largas en general Los usuarios reformulan una consulta utilizando muchas variantes diferentes para obtener buenos resultados. Para probar la hipótesis de que podemos aprender probabilidades de transformación confiables a partir del registro de consultas, entrenamos un modelo de lenguaje con las mismas 25 millones de consultas principales utilizadas para aprender la segmentación, y lo utilizamos para la predicción. Observamos una ligera disminución en el rendimiento en comparación con el modelo entrenado en frecuencias web. En particular, el rendimiento para el modelo de lenguaje unigrama no se vio afectado, pero la ganancia de dcg para el modelo de lenguaje bigrama cambió de 4.7% a 4.5% para consultas cortas. Por lo tanto, el registro de consultas puede servir como una buena aproximación de las frecuencias web. 5.2 Cómo la lingüística ayuda. Algunos conocimientos lingüísticos son útiles en el stemming. Para el manejo de la pluralización, la pluralización y la despluralización no son simétricas. Una palabra en plural utilizada en una consulta indica una intención especial. Por ejemplo, la consulta hoteles en Nueva York está buscando una lista de hoteles en Nueva York, no el hotel específico de Nueva York que podría estar ubicado en California. Una simple equivalencia de hotel a hoteles podría impulsar una página en particular sobre hoteles en Nueva York al primer puesto. Para capturar esta intención, tenemos que asegurarnos de que el documento sea una página general sobre hoteles en Nueva York. Esto lo hacemos exigiendo que la palabra en plural hoteles aparezca en el documento. Por otro lado, convertir una palabra singular a plural es más seguro ya que una página de propósito general normalmente contiene información específica. Observamos una ligera disminución general en el dcg, aunque no estadísticamente significativa, para el stemming sensible al contexto del documento si no consideramos esta propiedad asimétrica. Análisis de errores. Un tipo de errores que notamos, aunque raros pero que afectan seriamente la relevancia, es el cambio de intención de búsqueda después del stemming. En general, la pluralización o despluralización mantiene la intención original. Sin embargo, la intención podría cambiar en algunos casos. Por ejemplo, para una consulta de este tipo, trabajo en Apple, pluralizamos trabajo a trabajos. Este truncamiento hace que la consulta original sea ambigua. El trabajo de consulta O trabajos en Apple tiene dos intenciones. Una de las oportunidades laborales en Apple, y otra es una persona que trabaja en Apple, Steve Jobs, quien es el CEO y cofundador de la empresa. Por lo tanto, los resultados después de la reducción de consultas devuelven a Steve Jobs como uno de los resultados en el top 5. Una solución es realizar un análisis basado en el conjunto de resultados para verificar si la intención ha cambiado. Esto es similar a la retroalimentación de relevancia y requiere una clasificación en la segunda fase. Un segundo tipo de errores es el problema de reconocimiento de entidades/conceptos. Estos incluyen dos tipos. Una de ellas es que la variante de la palabra derivada ahora coincide con parte de una entidad o concepto. Por ejemplo, la consulta \"cookies en San Francisco\" se pluraliza como \"cookies\" O \"cookie en San Francisco\". Los resultados coincidirán con el tarro de galletas en San Francisco. Aunque \"cookie\" todavía significa lo mismo que \"galletas\", el concepto de \"cookie jar\" es diferente. Otro tipo es la palabra no derivada que coincide con una entidad o concepto debido al truncamiento de las otras palabras. Por ejemplo, la cita ICE se pluraliza como cita OR citas ICE. La intención original de esta consulta es buscar la cotización de acciones para el símbolo ICE. Sin embargo, notamos que entre los resultados principales, uno de los resultados es Citas sobre comida: Helado. Esto se empareja debido a las consultas afectadas dcg antiguas nuevas dcg dcg Mejora del modelo ingenuo 408/408 7.102 7.206 1.5% modelo sensible al contexto del documento 408/408 7.102 7.302 2.8% modelo selectivo: unigram LM 300/408 5.904 6.187 4.8% modelo selectivo: bigram LM 250/408 5.551 5.891 6.1% Tabla 6: Comparación de resultados solo sobre las consultas derivadas: la columna dcg antigua/nueva es la puntuación dcg sobre las consultas afectadas antes/después de aplicar la pluralización de la palabra entre comillas. La palabra inalterada ICE coincide con parte de la frase nominal helado aquí. Para resolver este tipo de problema, tenemos que analizar los documentos y reconocer \"cookie jar\" y \"ice cream\" como conceptos en lugar de dos palabras independientes. Un tercer tipo de errores ocurre en consultas largas. Para la consulta de software lector de códigos de barras, se pluralizan dos palabras. Códigos y lector. De hecho, el lector de códigos de barras en la consulta original es un concepto sólido y las palabras internas no deben ser cambiadas. Este es el problema de segmentación y detección de entidades y frases nominales en consultas, el cual estamos abordando activamente. Para consultas largas, debemos identificar correctamente los conceptos en la consulta y aumentar la proximidad de las palabras dentro de un concepto. 6. CONCLUSIONES Y TRABAJOS FUTUROS Hemos presentado una forma simple pero elegante de derivar palabras para la búsqueda en la web. Mejora el stemming ingenuo en dos aspectos: la expansión selectiva de palabras en el lado de la consulta y la coincidencia conservadora de ocurrencias de palabras en el lado del documento. Usando el manejo de pluralización como ejemplo, experimentos con datos de un motor de búsqueda web importante muestran que mejora significativamente la relevancia web y reduce el costo de derivación. También mejora significativamente la tasa de clics en la web (detalles no reportados en el artículo). Para el trabajo futuro, estamos investigando los problemas que identificamos en la sección de análisis de errores. Estos incluyen: errores de concordancia entre entidades y frases nominales, y una segmentación mejorada. 7. REFERENCIAS [1] E. Agichtein, E. Brill y S. T. Dumais. Mejorando la clasificación de búsqueda web al incorporar información sobre el comportamiento del usuario. En SIGIR, 2006. [2] E. Airio. Normalización de palabras y descomposición en IR monolingüe y bilingüe. Recuperación de información, 9:249-271, 2006. [3] P. Anick. Utilizando retroalimentación terminológica para el refinamiento de la búsqueda web: un estudio basado en registros. En SIGIR, 2003. [4] R. Baeza-Yates y B. Ribeiro-Neto. Recuperación de información moderna. ACM Press/Addison Wesley, 1999. [5] S. Chen y J. Goodman. Un estudio empírico de técnicas de suavizado para modelado del lenguaje. Informe técnico TR-10-98, Universidad de Harvard, 1998. [6] S. Cronen-Townsend, Y. Zhou y B. Croft. Un marco para la expansión selectiva de consultas. En CIKM, 2004. [7] H. Fang y C. Zhai. Coincidencia de términos semánticos en enfoques axiomáticos para la recuperación de información. En SIGIR, 2006. [8] W. B. Frakes. Confluencia de términos para la recuperación de información. En C. J. Rijsbergen, editor, Investigación y Desarrollo en Recuperación de Información, páginas 383-389. Cambridge University Press, 1984. [9] D. Harman.\nCambridge University Press, 1984. [9] D. Harman. ¿Qué tan efectivo es el sufijado? JASIS, 42(1):7-15, 1991. [10] D. Hull.\nJASIS, 42(1):7-15, 1991. [10] D. Hull. Algoritmos de derivación: un estudio de caso para una evaluación detallada. JASIS, 47(1):70-84, 1996. [11] K. Jarvelin y J. Kekalainen. Evaluación basada en la ganancia acumulada de técnicas de RI. ACM TOIS, 20:422-446, 2002. [12] R. Jones, B. Rey, O. Madani y W. Greiner. Generando Sustituciones de Consultas. En WWW, 2006. [13] W. Kraaij y R. Pohlmann. Viendo el Stemming como Mejora de la Recuperación. En SIGIR, 1996. [14] R. Krovetz. Viendo la morfología como un proceso de inferencia. En SIGIR, 1993. [15] D. Lin. Recuperación automática y agrupamiento de palabras similares. En COLING-ACL, 1998. [16] J. B. Lovins. Desarrollo de un algoritmo de derivación. Traducción Mecánica y Lingüística Computacional, II:22-31, 1968. [17] M. Lennon, D. Peirce, B. Tarry y P. Willett. Una evaluación de algunos algoritmos de confluencia para la recuperación de información. Revista de Ciencia de la Información, 3:177-188, 1981. [18] M. Porter. Un algoritmo para el recorte de sufijos. Programa, 14(3):130-137, 1980. [19] K. M. Risvik, T. Mikolajewski y P. Boros. Segmentación de consultas para búsqueda web. En WWW, 2003. [20] S. E. Robertson. Selección de términos para la expansión de consultas. Revista de Documentación, 46(4):359-364, 1990. [21] G. Salton y C. Buckley. Mejorando el rendimiento de recuperación mediante retroalimentación de relevancia. JASIS, 41(4):288 - 297, 1999. [22] R. Sun, C.-H. Ong, y T.-S. Chua. Extracción de relaciones de dependencia para la expansión de consultas en la recuperación de pasajes. En SIGIR, 2006. [23] C. Van Rijsbergen. Recuperación de información. Butterworths, segunda versión, 1979. [24] B. Vélez, R. Weiss, M. A. Sheldon y D. K. Gifford. Refinamiento de consultas rápido y efectivo. En SIGIR, 1997. [25] J. Xu y B. Croft. Expansión de consultas utilizando análisis local y global de documentos. En SIGIR, 1996. [26] J. Xu y B. Croft. Extracción de raíces basada en corpus utilizando la coocurrencia de variantes de palabras. ACM TOIS, 16 (1):61-81, 1998. ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "context sensitive document matching": {
            "translated_key": "coincidencia de documentos sensible al contexto",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Context Sensitive Stemming for Web Search Fuchun Peng Nawaaz Ahmed Xin Li Yumao Lu Yahoo!",
                "Inc. 701 First Avenue Sunnyvale, California 94089 {fuchun, nawaaz, xinli, yumaol}@yahoo-inc.com ABSTRACT Traditionally, stemming has been applied to Information Retrieval tasks by transforming words in documents to the their root form before indexing, and applying a similar transformation to query terms.",
                "Although it increases recall, this naive strategy does not work well for Web Search since it lowers precision and requires a significant amount of additional computation.",
                "In this paper, we propose a context sensitive stemming method that addresses these two issues.",
                "Two unique properties make our approach feasible for Web Search.",
                "First, based on statistical language modeling, we perform context sensitive analysis on the query side.",
                "We accurately predict which of its morphological variants is useful to expand a query term with before submitting the query to the search engine.",
                "This dramatically reduces the number of bad expansions, which in turn reduces the cost of additional computation and improves the precision at the same time.",
                "Second, our approach performs a <br>context sensitive document matching</br> for those expanded variants.",
                "This conservative strategy serves as a safeguard against spurious stemming, and it turns out to be very important for improving precision.",
                "Using word pluralization handling as an example of our stemming approach, our experiments on a major Web search engine show that stemming only 29% of the query traffic, we can improve relevance as measured by average Discounted Cumulative Gain (DCG5) by 6.1% on these queries and 1.8% over all query traffic.",
                "Categories and Subject Descriptors H.3.3 [Information Systems]: Information Storage and Retrieval-Query formulation General Terms Algorithms, Experimentation 1.",
                "INTRODUCTION Web search has now become a major tool in our daily lives for information seeking.",
                "One of the important issues in Web search is that user queries are often not best formulated to get optimal results.",
                "For example, running shoe is a query that occurs frequently in query logs.",
                "However, the query running shoes is much more likely to give better search results than the original query because documents matching the intent of this query usually contain the words running shoes.",
                "Correctly formulating a query requires the user to accurately predict which word form is used in the documents that best satisfy his or her information needs.",
                "This is difficult even for experienced users, and especially difficult for non-native speakers.",
                "One traditional solution is to use stemming [16, 18], the process of transforming inflected or derived words to their root form so that a search term will match and retrieve documents containing all forms of the term.",
                "Thus, the word run will match running, ran, runs, and shoe will match shoes and shoeing.",
                "Stemming can be done either on the terms in a document during indexing (and applying the same transformation to the query terms during query processing) or by expanding the query with the variants during query processing.",
                "Stemming during indexing allows very little flexibility during query processing, while stemming by query expansion allows handling each query differently, and hence is preferred.",
                "Although traditional stemming increases recall by matching word variants [13], it can reduce precision by retrieving too many documents that have been incorrectly matched.",
                "When examining the results of applying stemming to a large number of queries, one usually finds that nearly equal numbers of queries are helped and hurt by the technique [6].",
                "In addition, it reduces system performance because the search engine has to match all the word variants.",
                "As we will show in the experiments, this is true even if we simplify stemming to pluralization handling, which is the process of converting a word from its plural to singular form, or vice versa.",
                "Thus, one needs to be very cautious when using stemming in Web search engines.",
                "One problem of traditional stemming is its blind transformation of all query terms, that is, it always performs the same transformation for the same query word without considering the context of the word.",
                "For example, the word book has four forms book, books, booking, booked, and store has four forms store, stores, storing, stored.",
                "For the query book store, expanding both words to all of their variants significantly increases computation cost and hurts precision, since not all of the variants are useful for this query.",
                "Transforming book store to match book stores is fine, but matching book storing or booking store is not.",
                "A weighting method that gives variant words smaller weights alleviates the problems to a certain extent if the weights accurately reflect the importance of the variant in this particular query.",
                "However uniform weighting is not going to work and a query dependent weighting is still a challenging unsolved problem [20].",
                "A second problem of traditional stemming is its blind matching of all occurrences in documents.",
                "For the query book store, a transformation that allows the variant stores to be matched will cause every occurrence of stores in the document to be treated equivalent to the query term store.",
                "Thus, a document containing the fragment reading a book in coffee stores will be matched, causing many wrong documents to be selected.",
                "Although we hope the ranking function can correctly handle these, with many more candidates to rank, the risk of making mistakes increases.",
                "To alleviate these two problems, we propose a context sensitive stemming approach for Web search.",
                "Our solution consists of two context sensitive analysis, one on the query side and the other on the document side.",
                "On the query side, we propose a statistical language modeling based approach to predict which word variants are better forms than the original word for search purpose and expanding the query with only those forms.",
                "On the document side, we propose a conservative context sensitive matching for the transformed word variants, only matching document occurrences in the context of other terms in the query.",
                "Our model is simple yet effective and efficient, making it feasible to be used in real commercial Web search engines.",
                "We use pluralization handling as a running example for our stemming approach.",
                "The motivation for using pluralization handling as an example is to show that even such simple stemming, if handled correctly, can give significant benefits to search relevance.",
                "As far as we know, no previous research has systematically investigated the usage of pluralization in Web search.",
                "As we have to point out, the method we propose is not limited to pluralization handling, it is a general stemming technique, and can also be applied to general query expansion.",
                "Experiments on general stemming yield additional significant improvements over pluralization handling for long queries, although details will not be reported in this paper.",
                "In the rest of the paper, we first present the related work and distinguish our method from previous work in Section 2.",
                "We describe the details of the context sensitive stemming approach in Section 3.",
                "We then perform extensive experiments on a major Web search engine to support our claims in Section 4, followed by discussions in Section 5.",
                "Finally, we conclude the paper in Section 6. 2.",
                "RELATED WORK Stemming is a long studied technology.",
                "Many stemmers have been developed, such as the Lovins stemmer [16] and the Porter stemmer [18].",
                "The Porter stemmer is widely used due to its simplicity and effectiveness in many applications.",
                "However, the Porter stemming makes many mistakes because its simple rules cannot fully describe English morphology.",
                "Corpus analysis is used to improve Porter stemmer [26] by creating equivalence classes for words that are morphologically similar and occur in similar context as measured by expected mutual information [23].",
                "We use a similar corpus based approach for stemming by computing the similarity between two words based on their distributional context features which can be more than just adjacent words [15], and then only keep the morphologically similar words as candidates.",
                "Using stemming in information retrieval is also a well known technique [8, 10].",
                "However, the effectiveness of stemming for English query systems was previously reported to be rather limited.",
                "Lennon et al. [17] compared the Lovins and Porter algorithms and found little improvement in retrieval performance.",
                "Later, Harman [9] compares three general stemming techniques in text retrieval experiments including pluralization handing (called S stemmer in the paper).",
                "They also proposed selective stemming based on query length and term importance, but no positive results were reported.",
                "On the other hand, Krovetz [14] performed comparisons over small numbers of documents (from 400 to 12k) and showed dramatic precision improvement (up to 45%).",
                "However, due to the limited number of tested queries (less than 100) and the small size of the collection, the results are hard to generalize to Web search.",
                "These mixed results, mostly failures, led early IR researchers to deem stemming irrelevant in general for English [4], although recent research has shown stemming has greater benefits for retrieval in other languages [2].",
                "We suspect the previous failures were mainly due to the two problems we mentioned in the introduction.",
                "Blind stemming, or a simple query length based selective stemming as used in [9] is not enough.",
                "Stemming has to be decided on case by case basis, not only at the query level but also at the document level.",
                "As we will show, if handled correctly, significant improvement can be achieved.",
                "A more general problem related to stemming is query reformulation [3, 12] and query expansion which expands words not only with word variants [7, 22, 24, 25].",
                "To decide which expanded words to use, people often use pseudorelevance feedback techniquesthat send the original query to a search engine and retrieve the top documents, extract relevant words from these top documents as additional query words, and resubmit the expanded query again [21].",
                "This normally requires sending a query multiple times to search engine and it is not cost effective for processing the huge amount of queries involved in Web search.",
                "In addition, query expansion, including query reformulation [3, 12], has a high risk of changing the user intent (called query drift).",
                "Since the expanded words may have different meanings, adding them to the query could potentially change the intent of the original query.",
                "Thus query expansion based on pseudorelevance and query reformulation can provide suggestions to users for interactive refinement but can hardly be directly used for Web search.",
                "On the other hand, stemming is much more conservative since most of the time, stemming preserves the original search intent.",
                "While most work on query expansion focuses on recall enhancement, our work focuses on increasing both recall and precision.",
                "The increase on recall is obvious.",
                "With quality stemming, good documents which were not selected before stemming will be pushed up and those low quality documents will be degraded.",
                "On selective query expansion, Cronen-Townsend et al. [6] proposed a method for selective query expansion based on comparing the Kullback-Leibler divergence of the results from the unexpanded query and the results from the expanded query.",
                "This is similar to the relevance feedback in the sense that it requires multiple passes retrieval.",
                "If a word can be expanded into several words, it requires running this process multiple times to decide which expanded word is useful.",
                "It is expensive to deploy this in production Web search engines.",
                "Our method predicts the quality of expansion based on oﬄine information without sending the query to a search engine.",
                "In summary, we propose a novel approach to attack an old, yet still important and challenging problem for Web search - stemming.",
                "Our approach is unique in that it performs predictive stemming on a per query basis without relevance feedback from the Web, using the context of the variants in documents to preserve precision.",
                "Its simple, yet very efficient and effective, making real time stemming feasible for Web search.",
                "Our results will affirm researchers that stemming is indeed very important to large scale information retrieval. 3.",
                "CONTEXT SENSITIVE STEMMING 3.1 Overview Our system has four components as illustrated in Figure 1: candidate generation, query segmentation and head word detection, context sensitive query stemming and <br>context sensitive document matching</br>.",
                "Candidate generation (component 1) is performed oﬄine and generated candidates are stored in a dictionary.",
                "For an input query, we first segment query into concepts and detect the head word for each concept (component 2).",
                "We then use statistical language modeling to decide whether a particular variant is useful (component 3), and finally for the expanded variants, we perform <br>context sensitive document matching</br> (component 4).",
                "Below we discuss each of the components in more detail.",
                "Component 4: <br>context sensitive document matching</br> Input Query: and head word detection Component 2: segment Component 1: candidate generation comparisons −> comparison Component 3: selective word expansion decision: comparisons −> comparison example: hotel price comparisons output: hotel comparisons hotel −> hotels Figure 1: System Components 3.2 Expansion candidate generation One of the ways to generate candidates is using the Porter stemmer [18].",
                "The Porter stemmer simply uses morphological rules to convert a word to its base form.",
                "It has no knowledge of the semantic meaning of the words and sometimes makes serious mistakes, such as executive to execution, news to new, and paste to past.",
                "A more conservative way is based on using corpus analysis to improve the Porter stemmer results [26].",
                "The corpus analysis we do is based on word distributional similarity [15].",
                "The rationale of using distributional word similarity is that true variants tend to be used in similar contexts.",
                "In the distributional word similarity calculation, each word is represented with a vector of features derived from the context of the word.",
                "We use the bigrams to the left and right of the word as its context features, by mining a huge Web corpus.",
                "The similarity between two words is the cosine similarity between the two corresponding feature vectors.",
                "The top 20 similar words to develop is shown in the following table. rank candidate score rank candidate score 0 develop 1 10 berts 0.119 1 developing 0.339 11 wads 0.116 2 developed 0.176 12 developer 0.107 3 incubator 0.160 13 promoting 0.100 4 develops 0.150 14 developmental 0.091 5 development 0.148 15 reengineering 0.090 6 tutoring 0.138 16 build 0.083 7 analyzing 0.128 17 construct 0.081 8 developement 0.128 18 educational 0.081 9 automation 0.126 19 institute 0.077 Table 1: Top 20 most similar candidates to word develop.",
                "Column score is the similarity score.",
                "To determine the stemming candidates, we apply a few Porter stemmer [18] morphological rules to the similarity list.",
                "After applying these rules, for the word develop, the stemming candidates are developing, developed, develops, development, developement, developer, developmental.",
                "For the pluralization handling purpose, only the candidate develops is retained.",
                "One thing we note from observing the distributionally similar words is that they are closely related semantically.",
                "These words might serve as candidates for general query expansion, a topic we will investigate in the future. 3.3 Segmentation and headword identification For long queries, it is quite important to detect the concepts in the query and the most important words for those concepts.",
                "We first break a query into segments, each segment representing a concept which normally is a noun phrase.",
                "For each of the noun phrases, we then detect the most important word which we call the head word.",
                "Segmentation is also used in document sensitive matching (section 3.5) to enforce proximity.",
                "To break a query into segments, we have to define a criteria to measure the strength of the relation between words.",
                "One effective method is to use mutual information as an indicator on whether or not to split two words [19].",
                "We use a log of 25M queries and collect the bigram and unigram frequencies from it.",
                "For every incoming query, we compute the mutual information of two adjacent words; if it passes a predefined threshold, we do not split the query between those two words and move on to next word.",
                "We continue this process until the mutual information between two words is below the threshold, then create a concept boundary here.",
                "Table 2 shows some examples of query segmentation.",
                "The ideal way of finding the head word of a concept is to do syntactic parsing to determine the dependency structure of the query.",
                "Query parsing is more difficult than sentence [running shoe] [best] [new york] [medical schools] [pictures] [of] [white house] [cookies] [in] [san francisco] [hotel] [price comparison] Table 2: Query segmentation: a segment is bracketed. parsing since many queries are not grammatical and are very short.",
                "Applying a parser trained on sentences from documents to queries will have poor performance.",
                "In our solution, we just use simple heuristics rules, and it works very well in practice for English.",
                "For an English noun phrase, the head word is typically the last nonstop word, unless the phrase is of a particular pattern, like XYZ of/in/at/from UVW.",
                "In such cases, the head word is typically the last nonstop word of XYZ. 3.4 Context sensitive word expansion After detecting which words are the most important words to expand, we have to decide whether the expansions will be useful.",
                "Our statistics show that about half of the queries can be transformed by pluralization via naive stemming.",
                "Among this half, about 25% of the queries improve relevance when transformed, the majority (about 50%) do not change their top 5 results, and the remaining 25% perform worse.",
                "Thus, it is extremely important to identify which queries should not be stemmed for the purpose of maximizing relevance improvement and minimizing stemming cost.",
                "In addition, for a query with multiple words that can be transformed, or a word with multiple variants, not all of the expansions are useful.",
                "Taking query hotel price comparison as an example, we decide that hotel and price comparison are two concepts.",
                "Head words hotel and comparison can be expanded to hotels and comparisons.",
                "Are both transformations useful?",
                "To test whether an expansion is useful, we have to know whether the expanded query is likely to get more relevant documents from the Web, which can be quantified by the probability of the query occurring as a string on the Web.",
                "The more likely a query to occur on the Web, the more relevant documents this query is able to return.",
                "Now the whole problem becomes how to calculate the probability of query to occur on the Web.",
                "Calculating the probability of string occurring in a corpus is a well known language modeling problem.",
                "The goal of language modeling is to predict the probability of naturally occurring word sequences, s = w1w2...wN ; or more simply, to put high probability on word sequences that actually occur (and low probability on word sequences that never occur).",
                "The simplest and most successful approach to language modeling is still based on the n-gram model.",
                "By the chain rule of probability one can write the probability of any word sequence as Pr(w1w2...wN ) = NY i=1 Pr(wi|w1...wi−1) (1) An n-gram model approximates this probability by assuming that the only words relevant to predicting Pr(wi|w1...wi−1) are the previous n − 1 words; i.e.",
                "Pr(wi|w1...wi−1) = Pr(wi|wi−n+1...wi−1) A straightforward maximum likelihood estimate of n-gram probabilities from a corpus is given by the observed frequency of each of the patterns Pr(wi|wi−n+1...wi−1) = #(wi−n+1...wi) #(wi−n+1...wi−1) (2) where #(.) denotes the number of occurrences of a specified gram in the training corpus.",
                "Although one could attempt to use simple n-gram models to capture long range dependencies in language, attempting to do so directly immediately creates sparse data problems: Using grams of length up to n entails estimating the probability of Wn events, where W is the size of the word vocabulary.",
                "This quickly overwhelms modern computational and data resources for even modest choices of n (beyond 3 to 6).",
                "Also, because of the heavy tailed nature of language (i.e.",
                "Zipfs law) one is likely to encounter novel n-grams that were never witnessed during training in any test corpus, and therefore some mechanism for assigning non-zero probability to novel n-grams is a central and unavoidable issue in statistical language modeling.",
                "One standard approach to smoothing probability estimates to cope with sparse data problems (and to cope with potentially missing n-grams) is to use some sort of back-off estimator.",
                "Pr(wi|wi−n+1...wi−1) = 8 >>< >>: ˆPr(wi|wi−n+1...wi−1), if #(wi−n+1...wi) > 0 β(wi−n+1...wi−1) × Pr(wi|wi−n+2...wi−1), otherwise (3) where ˆPr(wi|wi−n+1...wi−1) = discount #(wi−n+1...wi) #(wi−n+1...wi−1) (4) is the discounted probability and β(wi−n+1...wi−1) is a normalization constant β(wi−n+1...wi−1) = 1 − X x∈(wi−n+1...wi−1x) ˆPr(x|wi−n+1...wi−1) 1 − X x∈(wi−n+1...wi−1x) ˆPr(x|wi−n+2...wi−1) (5) The discounted probability (4) can be computed with different smoothing techniques, including absolute smoothing, Good-Turing smoothing, linear smoothing, and Witten-Bell smoothing [5].",
                "We used absolute smoothing in our experiments.",
                "Since the likelihood of a string, Pr(w1w2...wN ), is a very small number and hard to interpret, we use entropy as defined below to score the string.",
                "Entropy = − 1 N log2 Pr(w1w2...wN ) (6) Now getting back to the example of the query hotel price comparisons, there are four variants of this query, and the entropy of these four candidates are shown in Table 3.",
                "We can see that all alternatives are less likely than the input query.",
                "It is therefore not useful to make an expansion for this query.",
                "On the other hand, if the input query is hotel price comparisons which is the second alternative in the table, then there is a better alternative than the input query, and it should therefore be expanded.",
                "To tolerate the variations in probability estimation, we relax the selection criterion to those query alternatives if their scores are within a certain distance (10% in our experiments) to the best score.",
                "Query variations Entropy hotel price comparison 6.177 hotel price comparisons 6.597 hotels price comparison 6.937 hotels price comparisons 7.360 Table 3: Variations of query hotel price comparison ranked by entropy score, with the original query in bold face. 3.5 <br>context sensitive document matching</br> Even after we know which word variants are likely to be useful, we have to be conservative in document matching for the expanded variants.",
                "For the query hotel price comparisons, we decided that word comparisons is expanded to include comparison.",
                "However, not every occurrence of comparison in the document is of interest.",
                "A page which is about comparing customer service can contain all of the words hotel price comparisons comparison.",
                "This page is not a good page for the query.",
                "If we accept matches of every occurrence of comparison, it will hurt retrieval precision and this is one of the main reasons why most stemming approaches do not work well for information retrieval.",
                "To address this problem, we have a proximity constraint that considers the context around the expanded variant in the document.",
                "A variant match is considered valid only if the variant occurs in the same context as the original word does.",
                "The context is the left or the right non-stop segments 1 of the original word.",
                "Taking the same query as an example, the context of comparisons is price.",
                "The expanded word comparison is only valid if it is in the same context of comparisons, which is after the word price.",
                "Thus, we should only match those occurrences of comparison in the document if they occur after the word price.",
                "Considering the fact that queries and documents may not represent the intent in exactly the same way, we relax this proximity constraint to allow variant occurrences within a window of some fixed size.",
                "If the expanded word comparison occurs within the context of price within a window, it is considered valid.",
                "The smaller the window size is, the more restrictive the matching.",
                "We use a window size of 4, which typically captures contexts that include the containing and adjacent noun phrases. 4.",
                "EXPERIMENTAL EVALUATION 4.1 Evaluation metrics We will measure both relevance improvement and the stemming cost required to achieve the relevance. 1 a context segment can not be a single stop word. 4.1.1 Relevance measurement We use a variant of the average Discounted Cumulative Gain (DCG), a recently popularized scheme to measure search engine relevance [1, 11].",
                "Given a query and a ranked list of K documents (K is set to 5 in our experiments), the DCG(K) score for this query is calculated as follows: DCG(K) = KX k=1 gk log2(1 + k) . (7) where gk is the weight for the document at rank k. Higher degree of relevance corresponds to a higher weight.",
                "A page is graded into one of the five scales: Perfect, Excellent, Good, Fair, Bad, with corresponding weights.",
                "We use dcg to represent the average DCG(5) over a set of test queries. 4.1.2 Stemming cost Another metric is to measure the additional cost incurred by stemming.",
                "Given the same level of relevance improvement, we prefer a stemming method that has less additional cost.",
                "We measure this by the percentage of queries that are actually stemmed, over all the queries that could possibly be stemmed. 4.2 Data preparation We randomly sample 870 queries from a three month query log, with 290 from each month.",
                "Among all these 870 queries, we remove all misspelled queries since misspelled queries are not of interest to stemming.",
                "We also remove all one word queries since stemming one word queries without context has a high risk of changing query intent, especially for short words.",
                "In the end, we have 529 correctly spelled queries with at least 2 words. 4.3 Naive stemming for Web search Before explaining the experiments and results in detail, wed like to describe the traditional way of using stemming for Web search, referred as the naive model.",
                "This is to treat every word variant equivalent for all possible words in the query.",
                "The query book store will be transformed into (book OR books)(store OR stores) when limiting stemming to pluralization handling only, where OR is an operator that denotes the equivalence of the left and right arguments. 4.4 Experimental setup The baseline model is the model without stemming.",
                "We first run the naive model to see how well it performs over the baseline.",
                "Then we improve the naive stemming model by document sensitive matching, referred as document sensitive matching model.",
                "This model makes the same stemming as the naive model on the query side, but performs conservative matching on the document side using the strategy described in section 3.5.",
                "The naive model and document sensitive matching model stem the most queries.",
                "Out of the 529 queries, there are 408 queries that they stem, corresponding to 46.7% query traffic (out of a total of 870).",
                "We then further improve the document sensitive matching model from the query side with selective word stemming based on statistical language modeling (section 3.4), referred as selective stemming model.",
                "Based on language modeling prediction, this model stems only a subset of the 408 queries stemmed by the document sensitive matching model.",
                "We experiment with unigram language model and bigram language model.",
                "Since we only care how much we can improve the naive model, we will only use these 408 queries (all the queries that are affected by the naive stemming model) in the experiments.",
                "To get a sense of how these models perform, we also have an oracle model that gives the upper-bound performance a stemmer can achieve on this data.",
                "The oracle model only expands a word if the stemming will give better results.",
                "To analyze the pluralization handling influence on different query categories, we divide queries into short queries and long queries.",
                "Among the 408 queries stemmed by the naive model, there are 272 short queries with 2 or 3 words, and 136 long queries with at least 4 words. 4.5 Results We summarize the overall results in Table 4, and present the results on short queries and long queries separately in Table 5.",
                "Each row in Table 4 is a stemming strategy described in section 4.4.",
                "The first column is the name of the strategy.",
                "The second column is the number of queries affected by this strategy; this column measures the stemming cost, and the numbers should be low for the same level of dcg.",
                "The third column is the average dcg score over all tested queries in this category (including the ones that were not stemmed by the strategy).",
                "The fourth column is the relative improvement over the baseline, and the last column is the p-value of Wilcoxon significance test.",
                "There are several observations about the results.",
                "We can see the naively stemming only obtains a statistically insignificant improvement of 1.5%.",
                "Looking at Table 5, it gives an improvement of 2.7% on short queries.",
                "However, it also hurts long queries by -2.4%.",
                "Overall, the improvement is canceled out.",
                "The reason that it improves short queries is that most short queries only have one word that can be stemmed.",
                "Thus, blindly pluralizing short queries is relatively safe.",
                "However for long queries, most queries can have multiple words that can be pluralized.",
                "Expanding all of them without selection will significantly hurt precision.",
                "Document context sensitive stemming gives a significant lift to the performance, from 2.7% to 4.2% for short queries and from -2.4% to -1.6% for long queries, with an overall lift from 1.5% to 2.8%.",
                "The improvement comes from the conservative <br>context sensitive document matching</br>.",
                "An expanded word is valid only if it occurs within the context of original query in the document.",
                "This reduces many spurious matches.",
                "However, we still notice that for long queries, context sensitive stemming is not able to improve performance because it still selects too many documents and gives the ranking function a hard problem.",
                "While the chosen window size of 4 works the best amongst all the choices, it still allows spurious matches.",
                "It is possible that the window size needs to be chosen on a per query basis to ensure tighter proximity constraints for different types of noun phrases.",
                "Selective word pluralization further helps resolving the problem faced by document context sensitive stemming.",
                "It does not stem every word that places all the burden on the ranking algorithm, but tries to eliminate unnecessary stemming in the first place.",
                "By predicting which word variants are going to be useful, we can dramatically reduce the number of stemmed words, thus improving both the recall and the precision.",
                "With the unigram language model, we can reduce the stemming cost by 26.7% (from 408/408 to 300/408) and lift the overall dcg improvement from 2.8% to 3.4%.",
                "In particular, it gives significant improvements on long queries.",
                "The dcg gain is turned from negative to positive, from −1.6% to 1.1%.",
                "This confirms our hypothesis that reducing unnecessary word expansion leads to precision improvement.",
                "For short queries too, we observe both dcg improvement and stemming cost reduction with the unigram language model.",
                "The advantages of predictive word expansion with a language model is further boosted with a better bigram language model.",
                "The overall dcg gain is lifted from 3.4% to 3.9%, and stemming cost is dramatically reduced from 408/408 to 250/408, corresponding to only 29% of query traffic (250 out of 870) and an overall 1.8% dcg improvement overall all query traffic.",
                "For short queries, bigram language model improves the dcg gain from 4.4% to 4.7%, and reduces stemming cost from 272/272 to 150/272.",
                "For long queries, bigram language model improves dcg gain from 1.1% to 2.5%, and reduces stemming cost from 136/136 to 100/136.",
                "We observe that the bigram language model gives a larger lift for long queries.",
                "This is because the uncertainty in long queries is larger and a more powerful language model is needed.",
                "We hypothesize that a trigram language model would give a further lift for long queries and leave this for future investigation.",
                "Considering the tight upper-bound 2 on the improvement to be gained from pluralization handling (via the oracle model), the current performance on short queries is very satisfying.",
                "For short queries, the dcg gain upper-bound is 6.3% for perfect pluralization handling, our current gain is 4.7% with a bigram language model.",
                "For long queries, the dcg gain upper-bound is 4.6% for perfect pluralization handling, our current gain is 2.5% with a bigram language model.",
                "We may gain additional benefit with a more powerful language model for long queries.",
                "However, the difficulties of long queries come from many other aspects including the proximity and the segmentation problem.",
                "These problems have to be addressed separately.",
                "Looking at the the upper-bound of overhead reduction for oracle stemming, 75% (308/408) of the naive stemmings are wasteful.",
                "We currently capture about half of them.",
                "Further reduction of the overhead requires sacrificing the dcg gain.",
                "Now we can compare the stemming strategies from a different aspect.",
                "Instead of looking at the influence over all queries as we described above, Table 6 summarizes the dcg improvements over the affected queries only.",
                "We can see that the number of affected queries decreases as the stemming strategy becomes more accurate (dcg improvement).",
                "For the bigram language model, over the 250/408 stemmed queries, the dcg improvement is 6.1%.",
                "An interesting observation is the average dcg decreases with a better model, which indicates a better stemming strategy stems more difficult queries (low dcg queries). 5.",
                "DISCUSSIONS 5.1 Language models from query vs. from Web As we mentioned in Section 1, we are trying to predict the probability of a string occurring on the Web.",
                "The language model should describe the occurrence of the string on the Web.",
                "However, the query log is also a good resource. 2 Note that this upperbound is for pluralization handling only, not for general stemming.",
                "General stemming gives a 8% upperbound, which is quite substantial in terms of our metrics.",
                "Affected Queries dcg dcg Improvement p-value baseline 0/408 7.102 N/A N/A naive model 408/408 7.206 1.5% 0.22 document context sensitive model 408/408 7.302 2.8% 0.014 selective model: unigram LM 300/408 7.321 3.4% 0.001 selective model: bigram LM 250/408 7.381 3.9% 0.001 oracle model 100/408 7.519 5.9% 0.001 Table 4: Results comparison of different stemming strategies over all queries affected by naive stemming Short Query Results Affected Queries dcg Improvement p-value baseline 0/272 N/A N/A naive model 272/272 2.7% 0.48 document context sensitive model 272/272 4.2% 0.002 selective model: unigram LM 185/272 4.4% 0.001 selective model: bigram LM 150/272 4.7% 0.001 oracle model 71/272 6.3% 0.001 Long Query Results Affected Queries dcg Improvement p-value baseline 0/136 N/A N/A naive model 136/136 -2.4% 0.25 document context sensitive model 136/136 -1.6% 0.27 selective model: unigram LM 115/136 1.1% 0.001 selective model: bigram LM 100/136 2.5% 0.001 oracle model 29/136 4.6% 0.001 Table 5: Results comparison of different stemming strategies overall short queries and long queries Users reformulate a query using many different variants to get good results.",
                "To test the hypothesis that we can learn reliable transformation probabilities from the query log, we trained a language model from the same query top 25M queries as used to learn segmentation, and use that for prediction.",
                "We observed a slight performance decrease compared to the model trained on Web frequencies.",
                "In particular, the performance for unigram LM was not affected, but the dcg gain for bigram LM changed from 4.7% to 4.5% for short queries.",
                "Thus, the query log can serve as a good approximation of the Web frequencies. 5.2 How linguistics helps Some linguistic knowledge is useful in stemming.",
                "For the pluralization handling case, pluralization and de-pluralization is not symmetric.",
                "A plural word used in a query indicates a special intent.",
                "For example, the query new york hotels is looking for a list of hotels in new york, not the specific new york hotel which might be a hotel located in California.",
                "A simple equivalence of hotel to hotels might boost a particular page about new york hotel to top rank.",
                "To capture this intent, we have to make sure the document is a general page about hotels in new york.",
                "We do this by requiring that the plural word hotels appears in the document.",
                "On the other hand, converting a singular word to plural is safer since a general purpose page normally contains specific information.",
                "We observed a slight overall dcg decrease, although not statistically significant, for document context sensitive stemming if we do not consider this asymmetric property. 5.3 Error analysis One type of mistakes we noticed, though rare but seriously hurting relevance, is the search intent change after stemming.",
                "Generally speaking, pluralization or depluralization keeps the original intent.",
                "However, the intent could change in a few cases.",
                "For one example of such a query, job at apple, we pluralize job to jobs.",
                "This stemming makes the original query ambiguous.",
                "The query job OR jobs at apple has two intents.",
                "One is the employment opportunities at apple, and another is a person working at Apple, Steve Jobs, who is the CEO and co-founder of the company.",
                "Thus, the results after query stemming returns Steve Jobs as one of the results in top 5.",
                "One solution is performing results set based analysis to check if the intent is changed.",
                "This is similar to relevance feedback and requires second phase ranking.",
                "A second type of mistakes is the entity/concept recognition problem, These include two kinds.",
                "One is that the stemmed word variant now matches part of an entity or concept.",
                "For example, query cookies in san francisco is pluralized to cookies OR cookie in san francisco.",
                "The results will match cookie jar in san francisco.",
                "Although cookie still means the same thing as cookies, cookie jar is a different concept.",
                "Another kind is the unstemmed word matches an entity or concept because of the stemming of the other words.",
                "For example, quote ICE is pluralized to quote OR quotes ICE.",
                "The original intent for this query is searching for stock quote for ticker ICE.",
                "However, we noticed that among the top results, one of the results is Food quotes: Ice cream.",
                "This is matched because of Affected Queries old dcg new dcg dcg Improvement naive model 408/408 7.102 7.206 1.5% document context sensitive model 408/408 7.102 7.302 2.8% selective model: unigram LM 300/408 5.904 6.187 4.8% selective model: bigram LM 250/408 5.551 5.891 6.1% Table 6: Results comparison over the stemmed queries only: column old/new dcg is the dcg score over the affected queries before/after applying stemming the pluralized word quotes.",
                "The unchanged word ICE matches part of the noun phrase ice cream here.",
                "To solve this kind of problem, we have to analyze the documents and recognize cookie jar and ice cream as concepts instead of two independent words.",
                "A third type of mistakes occurs in long queries.",
                "For the query bar code reader software, two words are pluralized. code to codes and reader to readers.",
                "In fact, bar code reader in the original query is a strong concept and the internal words should not be changed.",
                "This is the segmentation and entity and noun phrase detection problem in queries, which we actively are attacking.",
                "For long queries, we should correctly identify the concepts in the query, and boost the proximity for the words within a concept. 6.",
                "CONCLUSIONS AND FUTURE WORK We have presented a simple yet elegant way of stemming for Web search.",
                "It improves naive stemming in two aspects: selective word expansion on the query side and conservative word occurrence matching on the document side.",
                "Using pluralization handling as an example, experiments on a major Web search engine data show it significantly improves the Web relevance and reduces the stemming cost.",
                "It also significantly improves Web click through rate (details not reported in the paper).",
                "For the future work, we are investigating the problems we identified in the error analysis section.",
                "These include: entity and noun phrase matching mistakes, and improved segmentation. 7.",
                "REFERENCES [1] E. Agichtein, E. Brill, and S. T. Dumais.",
                "Improving Web Search Ranking by Incorporating User Behavior Information.",
                "In SIGIR, 2006. [2] E. Airio.",
                "Word Normalization and Decompounding in Mono- and Bilingual IR.",
                "Information Retrieval, 9:249-271, 2006. [3] P. Anick.",
                "Using Terminological Feedback for Web Search Refinement: a Log-based Study.",
                "In SIGIR, 2003. [4] R. Baeza-Yates and B. Ribeiro-Neto.",
                "Modern Information Retrieval.",
                "ACM Press/Addison Wesley, 1999. [5] S. Chen and J. Goodman.",
                "An Empirical Study of Smoothing Techniques for Language Modeling.",
                "Technical Report TR-10-98, Harvard University, 1998. [6] S. Cronen-Townsend, Y. Zhou, and B. Croft.",
                "A Framework for Selective Query Expansion.",
                "In CIKM, 2004. [7] H. Fang and C. Zhai.",
                "Semantic Term Matching in Axiomatic Approaches to Information Retrieval.",
                "In SIGIR, 2006. [8] W. B. Frakes.",
                "Term Conflation for Information Retrieval.",
                "In C. J. Rijsbergen, editor, Research and Development in Information Retrieval, pages 383-389.",
                "Cambridge University Press, 1984. [9] D. Harman.",
                "How Effective is Suffixing?",
                "JASIS, 42(1):7-15, 1991. [10] D. Hull.",
                "Stemming Algorithms - A Case Study for Detailed Evaluation.",
                "JASIS, 47(1):70-84, 1996. [11] K. Jarvelin and J. Kekalainen.",
                "Cumulated Gain-Based Evaluation Evaluation of IR Techniques.",
                "ACM TOIS, 20:422-446, 2002. [12] R. Jones, B. Rey, O. Madani, and W. Greiner.",
                "Generating Query Substitutions.",
                "In WWW, 2006. [13] W. Kraaij and R. Pohlmann.",
                "Viewing Stemming as Recall Enhancement.",
                "In SIGIR, 1996. [14] R. Krovetz.",
                "Viewing Morphology as an Inference Process.",
                "In SIGIR, 1993. [15] D. Lin.",
                "Automatic Retrieval and Clustering of Similar Words.",
                "In COLING-ACL, 1998. [16] J.",
                "B. Lovins.",
                "Development of a Stemming Algorithm.",
                "Mechanical Translation and Computational Linguistics, II:22-31, 1968. [17] M. Lennon and D. Peirce and B. Tarry and P. Willett.",
                "An Evaluation of Some Conflation Algorithms for Information Retrieval.",
                "Journal of Information Science, 3:177-188, 1981. [18] M. Porter.",
                "An Algorithm for Suffix Stripping.",
                "Program, 14(3):130-137, 1980. [19] K. M. Risvik, T. Mikolajewski, and P. Boros.",
                "Query Segmentation for Web Search.",
                "In WWW, 2003. [20] S. E. Robertson.",
                "On Term Selection for Query Expansion.",
                "Journal of Documentation, 46(4):359-364, 1990. [21] G. Salton and C. Buckley.",
                "Improving Retrieval Performance by Relevance Feedback.",
                "JASIS, 41(4):288 - 297, 1999. [22] R. Sun, C.-H. Ong, and T.-S. Chua.",
                "Mining Dependency Relations for Query Expansion in Passage Retrieval.",
                "In SIGIR, 2006. [23] C. Van Rijsbergen.",
                "Information Retrieval.",
                "Butterworths, second version, 1979. [24] B. V´elez, R. Weiss, M. A. Sheldon, and D. K. Gifford.",
                "Fast and Effective Query Refinement.",
                "In SIGIR, 1997. [25] J. Xu and B. Croft.",
                "Query Expansion using Local and Global Document Analysis.",
                "In SIGIR, 1996. [26] J. Xu and B. Croft.",
                "Corpus-based Stemming using Cooccurrence of Word Variants.",
                "ACM TOIS, 16 (1):61-81, 1998."
            ],
            "original_annotated_samples": [
                "Second, our approach performs a <br>context sensitive document matching</br> for those expanded variants.",
                "CONTEXT SENSITIVE STEMMING 3.1 Overview Our system has four components as illustrated in Figure 1: candidate generation, query segmentation and head word detection, context sensitive query stemming and <br>context sensitive document matching</br>.",
                "We then use statistical language modeling to decide whether a particular variant is useful (component 3), and finally for the expanded variants, we perform <br>context sensitive document matching</br> (component 4).",
                "Component 4: <br>context sensitive document matching</br> Input Query: and head word detection Component 2: segment Component 1: candidate generation comparisons −> comparison Component 3: selective word expansion decision: comparisons −> comparison example: hotel price comparisons output: hotel comparisons hotel −> hotels Figure 1: System Components 3.2 Expansion candidate generation One of the ways to generate candidates is using the Porter stemmer [18].",
                "Query variations Entropy hotel price comparison 6.177 hotel price comparisons 6.597 hotels price comparison 6.937 hotels price comparisons 7.360 Table 3: Variations of query hotel price comparison ranked by entropy score, with the original query in bold face. 3.5 <br>context sensitive document matching</br> Even after we know which word variants are likely to be useful, we have to be conservative in document matching for the expanded variants."
            ],
            "translated_annotated_samples": [
                "Segundo, nuestro enfoque realiza una <br>coincidencia de documentos sensible al contexto</br> para esas variantes ampliadas.",
                "STEMMING CONTEXTUAL SENSIBLE 3.1 Resumen Nuestro sistema tiene cuatro componentes como se ilustra en la Figura 1: generación de candidatos, segmentación de consultas y detección de palabras clave, derivación de consultas sensible al contexto y <br>coincidencia de documentos sensible al contexto</br>.",
                "Luego utilizamos modelado de lenguaje estadístico para decidir si una variante particular es útil (componente 3), y finalmente, para las variantes expandidas, realizamos un <br>emparejamiento de documentos sensible al contexto</br> (componente 4).",
                "Componente 4: <br>coincidencia de documentos sensibles al contexto</br> Consulta de entrada: y detección de palabras clave Componente 2: segmento Componente 1: generación de candidatos comparaciones −> comparación Componente 3: decisión de expansión selectiva de palabras: comparaciones −> comparación ejemplo: comparaciones de precios de hoteles salida: comparaciones de hoteles hotel −> hoteles Figura 1: Componentes del sistema 3.2 Generación de candidatos de expansión Una de las formas de generar candidatos es utilizando el stemmer de Porter [18].",
                "Variaciones de la consulta Comparación de precios de hoteles 6.177 comparaciones de precios de hoteles 6.597 comparación de precios de hoteles 6.937 comparaciones de precios de hoteles 7.360 Tabla 3: Variaciones de la consulta comparación de precios de hoteles clasificadas por puntaje de entropía, con la consulta original en negrita. 3.5 Coincidencia de documentos sensibles al contexto Aun después de saber qué variantes de palabras son probablemente útiles, debemos ser conservadores en la coincidencia de documentos para las variantes ampliadas."
            ],
            "translated_text": "Stemming sensible al contexto para la búsqueda web Fuchun Peng Nawaaz Ahmed Xin Li Yumao Lu Yahoo! Tradicionalmente, el truncamiento se ha aplicado a tareas de Recuperación de Información transformando las palabras en documentos a su forma raíz antes de indexarlas, y aplicando una transformación similar a los términos de consulta. Aunque aumenta la recuperación, esta estrategia ingenua no funciona bien para la Búsqueda en la Web, ya que disminuye la precisión y requiere una cantidad significativa de cálculos adicionales. En este artículo, proponemos un método de derivación sensible al contexto que aborda estos dos problemas. Dos propiedades únicas hacen que nuestro enfoque sea factible para la Búsqueda en la Web. Primero, basados en modelado estadístico del lenguaje, realizamos un análisis sensible al contexto en el lado de la consulta. Predecimos con precisión cuál de sus variantes morfológicas es útil para expandir un término de consulta antes de enviar la consulta al motor de búsqueda. Esto reduce drásticamente la cantidad de expansiones incorrectas, lo que a su vez disminuye el costo de la computación adicional y mejora la precisión al mismo tiempo. Segundo, nuestro enfoque realiza una <br>coincidencia de documentos sensible al contexto</br> para esas variantes ampliadas. Esta estrategia conservadora sirve como salvaguarda contra el truncamiento espurio, y resulta ser muy importante para mejorar la precisión. Usando el manejo de la pluralización de palabras como un ejemplo de nuestro enfoque de derivación, nuestros experimentos en un importante motor de búsqueda web muestran que al derivar solo el 29% del tráfico de consultas, podemos mejorar la relevancia medida por la Ganancia Acumulativa Descontada promedio (DCG5) en un 6.1% en estas consultas y en un 1.8% sobre todo el tráfico de consultas. Categorías y Descriptores de Asignaturas H.3.3 [Sistemas de Información]: Almacenamiento y Recuperación de Información-Formulación de Consultas Términos Generales Algoritmos, Experimentación 1. INTRODUCCIÓN La búsqueda en la web se ha convertido en una herramienta importante en nuestra vida diaria para buscar información. Uno de los problemas importantes en la búsqueda web es que las consultas de los usuarios a menudo no están formuladas de la mejor manera para obtener resultados óptimos. Por ejemplo, \"zapatilla para correr\" es una consulta que ocurre con frecuencia en los registros de consulta. Sin embargo, es mucho más probable que la búsqueda \"zapatillas para correr\" proporcione mejores resultados de búsqueda que la consulta original, ya que los documentos que coinciden con la intención de esta consulta suelen contener las palabras \"zapatillas para correr\". Formular correctamente una consulta requiere que el usuario prediga con precisión qué forma de palabra se utiliza en los documentos que mejor satisfacen sus necesidades de información. Esto es difícil incluso para usuarios experimentados, y especialmente difícil para hablantes no nativos. Una solución tradicional es utilizar el stemming [16, 18], el proceso de transformar palabras flexionadas o derivadas a su forma raíz para que un término de búsqueda coincida y recupere documentos que contengan todas las formas del término. Por lo tanto, la palabra \"run\" coincidirá con \"running\", \"ran\", \"runs\", y \"shoe\" coincidirá con \"shoes\" y \"shoeing\". El truncamiento se puede realizar tanto en los términos de un documento durante la indexación (y aplicando la misma transformación a los términos de la consulta durante el procesamiento de la consulta) o expandiendo la consulta con las variantes durante el procesamiento de la consulta. El truncamiento durante la indexación permite muy poca flexibilidad durante el procesamiento de consultas, mientras que el truncamiento mediante la expansión de consultas permite manejar cada consulta de manera diferente, y por lo tanto es preferible. Aunque el truncamiento tradicional aumenta la recuperación al emparejar variantes de palabras [13], puede reducir la precisión al recuperar demasiados documentos que han sido emparejados incorrectamente. Al examinar los resultados de aplicar el truncamiento a un gran número de consultas, generalmente se encuentra que casi igual cantidad de consultas se benefician y se ven perjudicadas por la técnica [6]. Además, reduce el rendimiento del sistema porque el motor de búsqueda tiene que hacer coincidir todas las variantes de palabras. Como mostraremos en los experimentos, esto es cierto incluso si simplificamos el proceso de derivación a la manipulación de pluralización, que es el proceso de convertir una palabra de su forma plural a singular, o viceversa. Por lo tanto, es necesario ser muy cauteloso al utilizar el stemming en los motores de búsqueda web. Un problema del truncamiento tradicional es su transformación ciega de todos los términos de consulta, es decir, siempre realiza la misma transformación para la misma palabra de consulta sin considerar el contexto de la palabra. Por ejemplo, la palabra \"book\" tiene cuatro formas: book, books, booking, booked, y la palabra \"store\" tiene cuatro formas: store, stores, storing, stored. Para la consulta de la librería, expandir ambas palabras a todas sus variantes aumenta significativamente el costo de computación y perjudica la precisión, ya que no todas las variantes son útiles para esta consulta. Transformar librería para que coincida con librerías está bien, pero hacer coincidir almacenamiento de libros o tienda de reservas no lo está. Un método de ponderación que otorga pesos más pequeños a las palabras variantes alivia los problemas hasta cierto punto si los pesos reflejan con precisión la importancia de la variante en esta consulta particular. Sin embargo, el peso uniforme no va a funcionar y un peso dependiente de la consulta sigue siendo un problema desafiante sin resolver [20]. Un segundo problema del truncamiento tradicional es su emparejamiento ciego de todas las ocurrencias en los documentos. Para la consulta de la librería, una transformación que permita que las tiendas variantes se emparejen hará que cada aparición de tiendas en el documento se trate de manera equivalente al término de consulta tienda. Por lo tanto, se emparejará un documento que contenga el fragmento de leer un libro en las cafeterías, lo que provocará que se seleccionen muchos documentos incorrectos. Aunque esperamos que la función de clasificación pueda manejar correctamente estos, con muchos más candidatos para clasificar, el riesgo de cometer errores aumenta. Para aliviar estos dos problemas, proponemos un enfoque de reducción de palabras raíz sensible al contexto para la búsqueda en la web. Nuestra solución consiste en dos análisis contextuales sensibles, uno en el lado de la consulta y otro en el lado del documento. En el lado de la consulta, proponemos un enfoque basado en modelado del lenguaje estadístico para predecir qué variantes de palabras son mejores formas que la palabra original con fines de búsqueda y expandir la consulta solo con esas formas. En el lado del documento, proponemos un emparejamiento conservador sensible al contexto para las variantes de palabras transformadas, solo emparejando las ocurrencias en el documento en el contexto de otros términos en la consulta. Nuestro modelo es simple pero efectivo y eficiente, lo que lo hace factible de ser utilizado en motores de búsqueda web comerciales reales. Utilizamos el manejo de pluralización como un ejemplo continuo para nuestro enfoque de derivación. La motivación para usar el manejo de pluralización como ejemplo es mostrar que incluso un truncamiento tan simple, si se maneja correctamente, puede brindar beneficios significativos a la relevancia de la búsqueda. Hasta donde sabemos, ninguna investigación previa ha investigado sistemáticamente el uso de la pluralización en la búsqueda en la web. Como debemos señalar, el método que proponemos no se limita al manejo de la pluralización, es una técnica de derivación general y también se puede aplicar a la expansión de consultas en general. Los experimentos sobre el truncamiento general producen mejoras significativas adicionales sobre el manejo de la pluralización para consultas largas, aunque los detalles no se informarán en este artículo. En el resto del documento, primero presentamos el trabajo relacionado y distinguimos nuestro método de trabajos anteriores en la Sección 2. Describimos los detalles del enfoque de derivación sensible al contexto en la Sección 3. Luego realizamos experimentos extensos en un importante motor de búsqueda web para respaldar nuestras afirmaciones en la Sección 4, seguidos de discusiones en la Sección 5. Finalmente, concluimos el artículo en la Sección 6.2. TRABAJO RELACIONADO El stemming es una tecnología estudiada desde hace mucho tiempo. Se han desarrollado muchos stemmers, como el stemmer Lovins [16] y el stemmer Porter [18]. El stemmer de Porter es ampliamente utilizado debido a su simplicidad y efectividad en muchas aplicaciones. Sin embargo, el algoritmo de Porter comete muchos errores porque sus reglas simples no pueden describir completamente la morfología del inglés. El análisis de corpus se utiliza para mejorar el stemmer de Porter [26] mediante la creación de clases de equivalencia para palabras que son morfológicamente similares y que ocurren en un contexto similar, medido por la información mutua esperada [23]. Utilizamos un enfoque de corpus similar para el stemming al calcular la similitud entre dos palabras basada en sus características de contexto distribucional, que pueden ser más que solo palabras adyacentes [15], y luego solo mantenemos las palabras morfológicamente similares como candidatas. El uso de la derivación en la recuperación de información también es una técnica bien conocida [8, 10]. Sin embargo, se informó previamente que la efectividad del truncamiento para los sistemas de consulta en inglés era bastante limitada. Lennon et al. [17] compararon los algoritmos de Lovins y Porter y encontraron poco mejoramiento en el rendimiento de recuperación. Más tarde, Harman [9] compara tres técnicas generales de derivación en experimentos de recuperación de texto, incluido el manejo de pluralización (llamado S stemmer en el artículo). También propusieron el truncamiento selectivo basado en la longitud de la consulta y la importancia del término, pero no se informaron resultados positivos. Por otro lado, Krovetz [14] realizó comparaciones sobre un pequeño número de documentos (de 400 a 12k) y mostró una mejora dramática en la precisión (de hasta un 45%). Sin embargo, debido al número limitado de consultas probadas (menos de 100) y al tamaño reducido de la colección, los resultados son difíciles de generalizar para la búsqueda en la web. Estos resultados mixtos, en su mayoría fracasos, llevaron a los primeros investigadores de IR a considerar que el truncamiento era irrelevante en general para el inglés [4], aunque investigaciones recientes han demostrado que el truncamiento tiene mayores beneficios para la recuperación en otros idiomas [2]. Sospechamos que los fracasos anteriores se debieron principalmente a los dos problemas que mencionamos en la introducción. El stemming ciego, o un stemming selectivo basado en la longitud de la consulta como se utiliza en [9], no es suficiente. El truncamiento debe decidirse caso por caso, no solo a nivel de consulta sino también a nivel de documento. Como demostraremos, si se maneja correctamente, se puede lograr una mejora significativa. Un problema más general relacionado con el stemming es la reformulación de consultas [3, 12] y la expansión de consultas que amplía las palabras no solo con variantes de palabras [7, 22, 24, 25]. Para decidir qué palabras expandidas usar, las personas a menudo utilizan técnicas de retroalimentación de seudorelevancia que envían la consulta original a un motor de búsqueda y recuperan los documentos principales, extraen palabras relevantes de estos documentos principales como palabras de consulta adicionales y vuelven a enviar la consulta expandida nuevamente [21]. Esto normalmente requiere enviar una consulta varias veces al motor de búsqueda y no es rentable para procesar la gran cantidad de consultas involucradas en la búsqueda web. Además, la expansión de consultas, incluida la reformulación de consultas [3, 12], tiene un alto riesgo de cambiar la intención del usuario (llamado desviación de consulta). Dado que las palabras expandidas pueden tener diferentes significados, agregarlas a la consulta podría potencialmente cambiar la intención de la consulta original. Por lo tanto, la expansión de consultas basada en pseudorelevancia y la reformulación de consultas pueden proporcionar sugerencias a los usuarios para su refinamiento interactivo, pero difícilmente pueden ser utilizadas directamente para la búsqueda en la web. Por otro lado, el truncamiento es mucho más conservador ya que la mayoría de las veces, conserva la intención de búsqueda original. Si bien la mayoría de los trabajos sobre la expansión de consultas se centran en mejorar la recuperación, nuestro trabajo se enfoca en aumentar tanto la recuperación como la precisión. El aumento en el recuerdo es evidente. Con el stemming de calidad, los buenos documentos que no fueron seleccionados antes del stemming serán promovidos y aquellos documentos de baja calidad serán degradados. En la expansión selectiva de consultas, Cronen-Townsend et al. [6] propusieron un método para la expansión selectiva de consultas basado en comparar la divergencia de Kullback-Leibler de los resultados de la consulta no expandida y los resultados de la consulta expandida. Esto es similar a la retroalimentación de relevancia en el sentido de que requiere múltiples pasadas de recuperación. Si una palabra puede expandirse en varias palabras, se requiere ejecutar este proceso varias veces para decidir cuál palabra expandida es útil. Es costoso implementar esto en motores de búsqueda web en producción. Nuestro método predice la calidad de la expansión basándose en información sin conexión sin enviar la consulta a un motor de búsqueda. En resumen, proponemos un enfoque novedoso para abordar un problema antiguo, pero aún importante y desafiante para la búsqueda en la web: el stemming. Nuestro enfoque es único en el sentido de que realiza el truncamiento predictivo de forma individualizada para cada consulta sin retroalimentación de relevancia de la Web, utilizando el contexto de las variantes en los documentos para preservar la precisión. Es simple, pero muy eficiente y efectivo, lo que hace factible el truncamiento en tiempo real para la búsqueda en la web. Nuestros resultados confirmarán a los investigadores que el truncamiento es realmente muy importante para la recuperación de información a gran escala. STEMMING CONTEXTUAL SENSIBLE 3.1 Resumen Nuestro sistema tiene cuatro componentes como se ilustra en la Figura 1: generación de candidatos, segmentación de consultas y detección de palabras clave, derivación de consultas sensible al contexto y <br>coincidencia de documentos sensible al contexto</br>. La generación de candidatos (componente 1) se realiza fuera de línea y los candidatos generados se almacenan en un diccionario. Para una consulta de entrada, primero segmentamos la consulta en conceptos y detectamos la palabra principal de cada concepto (componente 2). Luego utilizamos modelado de lenguaje estadístico para decidir si una variante particular es útil (componente 3), y finalmente, para las variantes expandidas, realizamos un <br>emparejamiento de documentos sensible al contexto</br> (componente 4). A continuación discutimos cada uno de los componentes con más detalle. Componente 4: <br>coincidencia de documentos sensibles al contexto</br> Consulta de entrada: y detección de palabras clave Componente 2: segmento Componente 1: generación de candidatos comparaciones −> comparación Componente 3: decisión de expansión selectiva de palabras: comparaciones −> comparación ejemplo: comparaciones de precios de hoteles salida: comparaciones de hoteles hotel −> hoteles Figura 1: Componentes del sistema 3.2 Generación de candidatos de expansión Una de las formas de generar candidatos es utilizando el stemmer de Porter [18]. El stemmer de Porter simplemente utiliza reglas morfológicas para convertir una palabra a su forma base. No tiene conocimiento del significado semántico de las palabras y a veces comete errores graves, como cambiar \"executive\" por \"execution\", \"news\" por \"new\" y \"paste\" por \"past\". Una forma más conservadora se basa en utilizar análisis de corpus para mejorar los resultados del stemmer de Porter [26]. El análisis de corpus que realizamos se basa en la similitud distribucional de palabras [15]. La razón de utilizar la similitud distribucional de palabras es que las variantes verdaderas tienden a ser utilizadas en contextos similares. En el cálculo de similitud de palabras distribucionales, cada palabra se representa con un vector de características derivadas del contexto de la palabra. Utilizamos los bigramas a la izquierda y a la derecha de la palabra como sus características de contexto, mediante la extracción de un gran corpus web. La similitud entre dos palabras es la similitud coseno entre los dos vectores de características correspondientes. Las 20 palabras similares a \"desarrollar\" se muestran en la siguiente tabla. rango candidato puntaje rango candidato puntaje 0 desarrollar 1 10 berts 0.119 1 desarrollando 0.339 11 wads 0.116 2 desarrollado 0.176 12 desarrollador 0.107 3 incubadora 0.160 13 promoviendo 0.100 4 desarrolla 0.150 14 desarrollo 0.091 5 desarrollo 0.148 15 reingeniería 0.090 6 tutoría 0.138 16 construir 0.083 7 analizando 0.128 17 construir 0.081 8 desarrollo 0.128 18 educativo 0.081 9 automatización 0.126 19 instituto 0.077 Tabla 1: Los 20 candidatos más similares a la palabra \"desarrollar\". La puntuación de la columna es la puntuación de similitud. Para determinar los candidatos de derivación, aplicamos algunas reglas morfológicas del stemmer de Porter [18] a la lista de similitud. Después de aplicar estas reglas, para la palabra desarrollar, los candidatos de derivación son desarrollando, desarrollado, desarrolla, desarrollo, desarrollo, desarrollador, y desarrollo. Para el propósito de manejo de pluralización, solo se conserva el candidato desarrolla. Una cosa que observamos al observar las palabras distribucionalmente similares es que están estrechamente relacionadas semánticamente. Estas palabras podrían servir como candidatas para la expansión general de consultas, un tema que investigaremos en el futuro. 3.3 Segmentación e identificación de palabras clave Para consultas largas, es bastante importante detectar los conceptos en la consulta y las palabras más importantes para esos conceptos. Primero dividimos una consulta en segmentos, cada segmento representando un concepto que normalmente es una frase nominal. Para cada una de las frases nominales, luego detectamos la palabra más importante a la que llamamos la palabra principal. La segmentación también se utiliza en la coincidencia sensible a documentos (sección 3.5) para hacer cumplir la proximidad. Para dividir una consulta en segmentos, tenemos que definir un criterio para medir la fuerza de la relación entre las palabras. Un método efectivo es utilizar la información mutua como indicador para decidir si dividir o no dos palabras [19]. Utilizamos un registro de 25 millones de consultas y recopilamos las frecuencias de bigramas y unigramas a partir de él. Para cada consulta entrante, calculamos la información mutua de dos palabras adyacentes; si supera un umbral predefinido, no dividimos la consulta entre esas dos palabras y pasamos a la siguiente palabra. Continuamos este proceso hasta que la información mutua entre dos palabras esté por debajo del umbral, luego creamos un límite conceptual aquí. La Tabla 2 muestra algunos ejemplos de segmentación de consultas. La forma ideal de encontrar la palabra principal de un concepto es realizar un análisis sintáctico para determinar la estructura de dependencia de la consulta. El análisis de consultas es más difícil que el análisis de oraciones, ya que muchas consultas no son gramaticales y son muy cortas. Aplicar un analizador entrenado en oraciones de documentos a consultas tendrá un rendimiento deficiente. En nuestra solución, solo utilizamos reglas heurísticas simples, y funciona muy bien en la práctica para el inglés. Para una frase nominal en inglés, la palabra principal suele ser la última palabra no detenida, a menos que la frase siga un patrón particular, como XYZ de/en/a/desde UVW. En tales casos, la palabra principal suele ser la última palabra no detenida de XYZ. 3.4 Expansión de palabras sensibles al contexto Después de detectar cuáles son las palabras más importantes para expandir, debemos decidir si las expansiones serán útiles. Nuestras estadísticas muestran que aproximadamente la mitad de las consultas pueden ser transformadas mediante la pluralización a través de un truncamiento ingenuo. Entre esta mitad, aproximadamente el 25% de las consultas mejoran la relevancia cuando se transforman, la mayoría (alrededor del 50%) no cambian sus 5 resultados principales, y el 25% restante tiene un rendimiento peor. Por lo tanto, es extremadamente importante identificar qué consultas no deben ser truncadas con el fin de maximizar la mejora de relevancia y minimizar el costo de truncamiento. Además, para una consulta con múltiples palabras que pueden ser transformadas, o una palabra con múltiples variantes, no todas las expansiones son útiles. Tomando la comparación de precios de hoteles como ejemplo, decidimos que hotel y comparación de precios son dos conceptos. Las palabras clave hotel y comparación se pueden expandir a hoteles y comparaciones. ¿Son útiles ambas transformaciones? Para probar si una expansión es útil, tenemos que saber si es probable que la consulta expandida obtenga más documentos relevantes de la web, lo cual puede cuantificarse mediante la probabilidad de que la consulta ocurra como una cadena en la web. Cuanto más probable sea que ocurra una consulta en la web, más documentos relevantes puede devolver esta consulta. Ahora todo el problema se convierte en cómo calcular la probabilidad de que ocurra la consulta en la Web. Calcular la probabilidad de que una cadena ocurra en un corpus es un problema bien conocido de modelado del lenguaje. El objetivo del modelado del lenguaje es predecir la probabilidad de secuencias de palabras que ocurren naturalmente, s = w1w2...wN; o más simplemente, asignar una alta probabilidad a las secuencias de palabras que realmente ocurren (y una baja probabilidad a las secuencias de palabras que nunca ocurren). El enfoque más simple y exitoso para el modelado del lenguaje sigue estando basado en el modelo n-gramo. Por la regla de la cadena de probabilidad, se puede escribir la probabilidad de cualquier secuencia de palabras como Pr(w1w2...wN) = ΠY i=1 Pr(wi|w1...wi−1) (1). Un modelo n-grama aproxima esta probabilidad asumiendo que las únicas palabras relevantes para predecir Pr(wi|w1...wi−1) son las n − 1 palabras anteriores; es decir, La probabilidad de una palabra wi dado w1...wi−1 es igual a la probabilidad de wi dado wi−n+1...wi−1. Una estimación directa de máxima verosimilitud de las probabilidades de n-gramas a partir de un corpus se obtiene a partir de la frecuencia observada de cada uno de los patrones Pr(wi|wi−n+1...wi−1) = #(wi−n+1...wi) #(wi−n+1...wi−1) donde #(.) denota el número de ocurrencias de un n-grama específico en el corpus de entrenamiento. Aunque se podría intentar usar modelos de n-gramos simples para capturar dependencias a largo plazo en el lenguaje, intentar hacerlo directamente crea inmediatamente problemas de datos dispersos: Utilizar n-gramos de longitud hasta n implica estimar la probabilidad de eventos de longitud Wn, donde W es el tamaño del vocabulario de palabras. Esto rápidamente abruma los recursos computacionales y de datos modernos incluso para opciones modestas de n (más allá de 3 a 6). Además, debido a la naturaleza de cola pesada del lenguaje (es decir, La ley de Zipf) es probable que uno se encuentre con n-gramas novedosos que nunca fueron observados durante el entrenamiento en ningún corpus de prueba, por lo tanto, algún mecanismo para asignar una probabilidad distinta de cero a los n-gramas novedosos es un problema central e inevitable en la modelización estadística del lenguaje. Un enfoque estándar para suavizar las estimaciones de probabilidad para hacer frente a problemas de datos escasos (y para hacer frente a posibles n-gramas faltantes) es utilizar algún tipo de estimador de retroceso. Pr(wi|wi−n+1...wi−1) = 8 >>< >>: ˆPr(wi|wi−n+1...wi−1), si #(wi−n+1...wi) > 0 β(wi−n+1...wi−1) × Pr(wi|wi−n+2...wi−1), de lo contrario (3) donde ˆPr(wi|wi−n+1...wi−1) = descuento #(wi−n+1...wi) #(wi−n+1...wi−1) (4) es la probabilidad descontada y β(wi−n+1...wi−1) es una constante de normalización β(wi−n+1...wi−1) = 1 − X x∈(wi−n+1...wi−1x) ˆPr(x|wi−n+1...wi−1) 1 − X x∈(wi−n+1...wi−1x) ˆPr(x|wi−n+2...wi−1) (5) La probabilidad descontada (4) se puede calcular con diferentes técnicas de suavizado, incluido el suavizado absoluto, el suavizado de Good-Turing, el suavizado lineal y el suavizado de Witten-Bell [5]. Utilizamos suavizado absoluto en nuestros experimentos. Dado que la probabilidad de una cadena, Pr(w1w2...wN), es un número muy pequeño y difícil de interpretar, utilizamos la entropía, tal como se define a continuación, para puntuar la cadena. Entropía = − 1 N log2 Pr(w1w2...wN ) (6) Ahora volviendo al ejemplo de la comparación de precios de hoteles, hay cuatro variantes de esta consulta, y la entropía de estos cuatro candidatos se muestra en la Tabla 3. Podemos ver que todas las alternativas son menos probables que la consulta de entrada. Por lo tanto, no es útil hacer una expansión para esta consulta. Por otro lado, si la consulta de entrada son comparaciones de precios de hoteles, que es la segunda alternativa en la tabla, entonces hay una mejor alternativa que la consulta de entrada, y por lo tanto debería ser ampliada. Para tolerar las variaciones en la estimación de probabilidad, relajamos el criterio de selección para esas alternativas de consulta si sus puntuaciones están dentro de una cierta distancia (10% en nuestros experimentos) de la mejor puntuación. Variaciones de la consulta Comparación de precios de hoteles 6.177 comparaciones de precios de hoteles 6.597 comparación de precios de hoteles 6.937 comparaciones de precios de hoteles 7.360 Tabla 3: Variaciones de la consulta comparación de precios de hoteles clasificadas por puntaje de entropía, con la consulta original en negrita. 3.5 Coincidencia de documentos sensibles al contexto Aun después de saber qué variantes de palabras son probablemente útiles, debemos ser conservadores en la coincidencia de documentos para las variantes ampliadas. ",
            "candidates": [],
            "error": [
                [
                    "coincidencia de documentos sensible al contexto",
                    "coincidencia de documentos sensible al contexto",
                    "emparejamiento de documentos sensible al contexto",
                    "coincidencia de documentos sensibles al contexto"
                ]
            ]
        },
        "unigram language model": {
            "translated_key": "modelo de lenguaje unigrama",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Context Sensitive Stemming for Web Search Fuchun Peng Nawaaz Ahmed Xin Li Yumao Lu Yahoo!",
                "Inc. 701 First Avenue Sunnyvale, California 94089 {fuchun, nawaaz, xinli, yumaol}@yahoo-inc.com ABSTRACT Traditionally, stemming has been applied to Information Retrieval tasks by transforming words in documents to the their root form before indexing, and applying a similar transformation to query terms.",
                "Although it increases recall, this naive strategy does not work well for Web Search since it lowers precision and requires a significant amount of additional computation.",
                "In this paper, we propose a context sensitive stemming method that addresses these two issues.",
                "Two unique properties make our approach feasible for Web Search.",
                "First, based on statistical language modeling, we perform context sensitive analysis on the query side.",
                "We accurately predict which of its morphological variants is useful to expand a query term with before submitting the query to the search engine.",
                "This dramatically reduces the number of bad expansions, which in turn reduces the cost of additional computation and improves the precision at the same time.",
                "Second, our approach performs a context sensitive document matching for those expanded variants.",
                "This conservative strategy serves as a safeguard against spurious stemming, and it turns out to be very important for improving precision.",
                "Using word pluralization handling as an example of our stemming approach, our experiments on a major Web search engine show that stemming only 29% of the query traffic, we can improve relevance as measured by average Discounted Cumulative Gain (DCG5) by 6.1% on these queries and 1.8% over all query traffic.",
                "Categories and Subject Descriptors H.3.3 [Information Systems]: Information Storage and Retrieval-Query formulation General Terms Algorithms, Experimentation 1.",
                "INTRODUCTION Web search has now become a major tool in our daily lives for information seeking.",
                "One of the important issues in Web search is that user queries are often not best formulated to get optimal results.",
                "For example, running shoe is a query that occurs frequently in query logs.",
                "However, the query running shoes is much more likely to give better search results than the original query because documents matching the intent of this query usually contain the words running shoes.",
                "Correctly formulating a query requires the user to accurately predict which word form is used in the documents that best satisfy his or her information needs.",
                "This is difficult even for experienced users, and especially difficult for non-native speakers.",
                "One traditional solution is to use stemming [16, 18], the process of transforming inflected or derived words to their root form so that a search term will match and retrieve documents containing all forms of the term.",
                "Thus, the word run will match running, ran, runs, and shoe will match shoes and shoeing.",
                "Stemming can be done either on the terms in a document during indexing (and applying the same transformation to the query terms during query processing) or by expanding the query with the variants during query processing.",
                "Stemming during indexing allows very little flexibility during query processing, while stemming by query expansion allows handling each query differently, and hence is preferred.",
                "Although traditional stemming increases recall by matching word variants [13], it can reduce precision by retrieving too many documents that have been incorrectly matched.",
                "When examining the results of applying stemming to a large number of queries, one usually finds that nearly equal numbers of queries are helped and hurt by the technique [6].",
                "In addition, it reduces system performance because the search engine has to match all the word variants.",
                "As we will show in the experiments, this is true even if we simplify stemming to pluralization handling, which is the process of converting a word from its plural to singular form, or vice versa.",
                "Thus, one needs to be very cautious when using stemming in Web search engines.",
                "One problem of traditional stemming is its blind transformation of all query terms, that is, it always performs the same transformation for the same query word without considering the context of the word.",
                "For example, the word book has four forms book, books, booking, booked, and store has four forms store, stores, storing, stored.",
                "For the query book store, expanding both words to all of their variants significantly increases computation cost and hurts precision, since not all of the variants are useful for this query.",
                "Transforming book store to match book stores is fine, but matching book storing or booking store is not.",
                "A weighting method that gives variant words smaller weights alleviates the problems to a certain extent if the weights accurately reflect the importance of the variant in this particular query.",
                "However uniform weighting is not going to work and a query dependent weighting is still a challenging unsolved problem [20].",
                "A second problem of traditional stemming is its blind matching of all occurrences in documents.",
                "For the query book store, a transformation that allows the variant stores to be matched will cause every occurrence of stores in the document to be treated equivalent to the query term store.",
                "Thus, a document containing the fragment reading a book in coffee stores will be matched, causing many wrong documents to be selected.",
                "Although we hope the ranking function can correctly handle these, with many more candidates to rank, the risk of making mistakes increases.",
                "To alleviate these two problems, we propose a context sensitive stemming approach for Web search.",
                "Our solution consists of two context sensitive analysis, one on the query side and the other on the document side.",
                "On the query side, we propose a statistical language modeling based approach to predict which word variants are better forms than the original word for search purpose and expanding the query with only those forms.",
                "On the document side, we propose a conservative context sensitive matching for the transformed word variants, only matching document occurrences in the context of other terms in the query.",
                "Our model is simple yet effective and efficient, making it feasible to be used in real commercial Web search engines.",
                "We use pluralization handling as a running example for our stemming approach.",
                "The motivation for using pluralization handling as an example is to show that even such simple stemming, if handled correctly, can give significant benefits to search relevance.",
                "As far as we know, no previous research has systematically investigated the usage of pluralization in Web search.",
                "As we have to point out, the method we propose is not limited to pluralization handling, it is a general stemming technique, and can also be applied to general query expansion.",
                "Experiments on general stemming yield additional significant improvements over pluralization handling for long queries, although details will not be reported in this paper.",
                "In the rest of the paper, we first present the related work and distinguish our method from previous work in Section 2.",
                "We describe the details of the context sensitive stemming approach in Section 3.",
                "We then perform extensive experiments on a major Web search engine to support our claims in Section 4, followed by discussions in Section 5.",
                "Finally, we conclude the paper in Section 6. 2.",
                "RELATED WORK Stemming is a long studied technology.",
                "Many stemmers have been developed, such as the Lovins stemmer [16] and the Porter stemmer [18].",
                "The Porter stemmer is widely used due to its simplicity and effectiveness in many applications.",
                "However, the Porter stemming makes many mistakes because its simple rules cannot fully describe English morphology.",
                "Corpus analysis is used to improve Porter stemmer [26] by creating equivalence classes for words that are morphologically similar and occur in similar context as measured by expected mutual information [23].",
                "We use a similar corpus based approach for stemming by computing the similarity between two words based on their distributional context features which can be more than just adjacent words [15], and then only keep the morphologically similar words as candidates.",
                "Using stemming in information retrieval is also a well known technique [8, 10].",
                "However, the effectiveness of stemming for English query systems was previously reported to be rather limited.",
                "Lennon et al. [17] compared the Lovins and Porter algorithms and found little improvement in retrieval performance.",
                "Later, Harman [9] compares three general stemming techniques in text retrieval experiments including pluralization handing (called S stemmer in the paper).",
                "They also proposed selective stemming based on query length and term importance, but no positive results were reported.",
                "On the other hand, Krovetz [14] performed comparisons over small numbers of documents (from 400 to 12k) and showed dramatic precision improvement (up to 45%).",
                "However, due to the limited number of tested queries (less than 100) and the small size of the collection, the results are hard to generalize to Web search.",
                "These mixed results, mostly failures, led early IR researchers to deem stemming irrelevant in general for English [4], although recent research has shown stemming has greater benefits for retrieval in other languages [2].",
                "We suspect the previous failures were mainly due to the two problems we mentioned in the introduction.",
                "Blind stemming, or a simple query length based selective stemming as used in [9] is not enough.",
                "Stemming has to be decided on case by case basis, not only at the query level but also at the document level.",
                "As we will show, if handled correctly, significant improvement can be achieved.",
                "A more general problem related to stemming is query reformulation [3, 12] and query expansion which expands words not only with word variants [7, 22, 24, 25].",
                "To decide which expanded words to use, people often use pseudorelevance feedback techniquesthat send the original query to a search engine and retrieve the top documents, extract relevant words from these top documents as additional query words, and resubmit the expanded query again [21].",
                "This normally requires sending a query multiple times to search engine and it is not cost effective for processing the huge amount of queries involved in Web search.",
                "In addition, query expansion, including query reformulation [3, 12], has a high risk of changing the user intent (called query drift).",
                "Since the expanded words may have different meanings, adding them to the query could potentially change the intent of the original query.",
                "Thus query expansion based on pseudorelevance and query reformulation can provide suggestions to users for interactive refinement but can hardly be directly used for Web search.",
                "On the other hand, stemming is much more conservative since most of the time, stemming preserves the original search intent.",
                "While most work on query expansion focuses on recall enhancement, our work focuses on increasing both recall and precision.",
                "The increase on recall is obvious.",
                "With quality stemming, good documents which were not selected before stemming will be pushed up and those low quality documents will be degraded.",
                "On selective query expansion, Cronen-Townsend et al. [6] proposed a method for selective query expansion based on comparing the Kullback-Leibler divergence of the results from the unexpanded query and the results from the expanded query.",
                "This is similar to the relevance feedback in the sense that it requires multiple passes retrieval.",
                "If a word can be expanded into several words, it requires running this process multiple times to decide which expanded word is useful.",
                "It is expensive to deploy this in production Web search engines.",
                "Our method predicts the quality of expansion based on oﬄine information without sending the query to a search engine.",
                "In summary, we propose a novel approach to attack an old, yet still important and challenging problem for Web search - stemming.",
                "Our approach is unique in that it performs predictive stemming on a per query basis without relevance feedback from the Web, using the context of the variants in documents to preserve precision.",
                "Its simple, yet very efficient and effective, making real time stemming feasible for Web search.",
                "Our results will affirm researchers that stemming is indeed very important to large scale information retrieval. 3.",
                "CONTEXT SENSITIVE STEMMING 3.1 Overview Our system has four components as illustrated in Figure 1: candidate generation, query segmentation and head word detection, context sensitive query stemming and context sensitive document matching.",
                "Candidate generation (component 1) is performed oﬄine and generated candidates are stored in a dictionary.",
                "For an input query, we first segment query into concepts and detect the head word for each concept (component 2).",
                "We then use statistical language modeling to decide whether a particular variant is useful (component 3), and finally for the expanded variants, we perform context sensitive document matching (component 4).",
                "Below we discuss each of the components in more detail.",
                "Component 4: context sensitive document matching Input Query: and head word detection Component 2: segment Component 1: candidate generation comparisons −> comparison Component 3: selective word expansion decision: comparisons −> comparison example: hotel price comparisons output: hotel comparisons hotel −> hotels Figure 1: System Components 3.2 Expansion candidate generation One of the ways to generate candidates is using the Porter stemmer [18].",
                "The Porter stemmer simply uses morphological rules to convert a word to its base form.",
                "It has no knowledge of the semantic meaning of the words and sometimes makes serious mistakes, such as executive to execution, news to new, and paste to past.",
                "A more conservative way is based on using corpus analysis to improve the Porter stemmer results [26].",
                "The corpus analysis we do is based on word distributional similarity [15].",
                "The rationale of using distributional word similarity is that true variants tend to be used in similar contexts.",
                "In the distributional word similarity calculation, each word is represented with a vector of features derived from the context of the word.",
                "We use the bigrams to the left and right of the word as its context features, by mining a huge Web corpus.",
                "The similarity between two words is the cosine similarity between the two corresponding feature vectors.",
                "The top 20 similar words to develop is shown in the following table. rank candidate score rank candidate score 0 develop 1 10 berts 0.119 1 developing 0.339 11 wads 0.116 2 developed 0.176 12 developer 0.107 3 incubator 0.160 13 promoting 0.100 4 develops 0.150 14 developmental 0.091 5 development 0.148 15 reengineering 0.090 6 tutoring 0.138 16 build 0.083 7 analyzing 0.128 17 construct 0.081 8 developement 0.128 18 educational 0.081 9 automation 0.126 19 institute 0.077 Table 1: Top 20 most similar candidates to word develop.",
                "Column score is the similarity score.",
                "To determine the stemming candidates, we apply a few Porter stemmer [18] morphological rules to the similarity list.",
                "After applying these rules, for the word develop, the stemming candidates are developing, developed, develops, development, developement, developer, developmental.",
                "For the pluralization handling purpose, only the candidate develops is retained.",
                "One thing we note from observing the distributionally similar words is that they are closely related semantically.",
                "These words might serve as candidates for general query expansion, a topic we will investigate in the future. 3.3 Segmentation and headword identification For long queries, it is quite important to detect the concepts in the query and the most important words for those concepts.",
                "We first break a query into segments, each segment representing a concept which normally is a noun phrase.",
                "For each of the noun phrases, we then detect the most important word which we call the head word.",
                "Segmentation is also used in document sensitive matching (section 3.5) to enforce proximity.",
                "To break a query into segments, we have to define a criteria to measure the strength of the relation between words.",
                "One effective method is to use mutual information as an indicator on whether or not to split two words [19].",
                "We use a log of 25M queries and collect the bigram and unigram frequencies from it.",
                "For every incoming query, we compute the mutual information of two adjacent words; if it passes a predefined threshold, we do not split the query between those two words and move on to next word.",
                "We continue this process until the mutual information between two words is below the threshold, then create a concept boundary here.",
                "Table 2 shows some examples of query segmentation.",
                "The ideal way of finding the head word of a concept is to do syntactic parsing to determine the dependency structure of the query.",
                "Query parsing is more difficult than sentence [running shoe] [best] [new york] [medical schools] [pictures] [of] [white house] [cookies] [in] [san francisco] [hotel] [price comparison] Table 2: Query segmentation: a segment is bracketed. parsing since many queries are not grammatical and are very short.",
                "Applying a parser trained on sentences from documents to queries will have poor performance.",
                "In our solution, we just use simple heuristics rules, and it works very well in practice for English.",
                "For an English noun phrase, the head word is typically the last nonstop word, unless the phrase is of a particular pattern, like XYZ of/in/at/from UVW.",
                "In such cases, the head word is typically the last nonstop word of XYZ. 3.4 Context sensitive word expansion After detecting which words are the most important words to expand, we have to decide whether the expansions will be useful.",
                "Our statistics show that about half of the queries can be transformed by pluralization via naive stemming.",
                "Among this half, about 25% of the queries improve relevance when transformed, the majority (about 50%) do not change their top 5 results, and the remaining 25% perform worse.",
                "Thus, it is extremely important to identify which queries should not be stemmed for the purpose of maximizing relevance improvement and minimizing stemming cost.",
                "In addition, for a query with multiple words that can be transformed, or a word with multiple variants, not all of the expansions are useful.",
                "Taking query hotel price comparison as an example, we decide that hotel and price comparison are two concepts.",
                "Head words hotel and comparison can be expanded to hotels and comparisons.",
                "Are both transformations useful?",
                "To test whether an expansion is useful, we have to know whether the expanded query is likely to get more relevant documents from the Web, which can be quantified by the probability of the query occurring as a string on the Web.",
                "The more likely a query to occur on the Web, the more relevant documents this query is able to return.",
                "Now the whole problem becomes how to calculate the probability of query to occur on the Web.",
                "Calculating the probability of string occurring in a corpus is a well known language modeling problem.",
                "The goal of language modeling is to predict the probability of naturally occurring word sequences, s = w1w2...wN ; or more simply, to put high probability on word sequences that actually occur (and low probability on word sequences that never occur).",
                "The simplest and most successful approach to language modeling is still based on the n-gram model.",
                "By the chain rule of probability one can write the probability of any word sequence as Pr(w1w2...wN ) = NY i=1 Pr(wi|w1...wi−1) (1) An n-gram model approximates this probability by assuming that the only words relevant to predicting Pr(wi|w1...wi−1) are the previous n − 1 words; i.e.",
                "Pr(wi|w1...wi−1) = Pr(wi|wi−n+1...wi−1) A straightforward maximum likelihood estimate of n-gram probabilities from a corpus is given by the observed frequency of each of the patterns Pr(wi|wi−n+1...wi−1) = #(wi−n+1...wi) #(wi−n+1...wi−1) (2) where #(.) denotes the number of occurrences of a specified gram in the training corpus.",
                "Although one could attempt to use simple n-gram models to capture long range dependencies in language, attempting to do so directly immediately creates sparse data problems: Using grams of length up to n entails estimating the probability of Wn events, where W is the size of the word vocabulary.",
                "This quickly overwhelms modern computational and data resources for even modest choices of n (beyond 3 to 6).",
                "Also, because of the heavy tailed nature of language (i.e.",
                "Zipfs law) one is likely to encounter novel n-grams that were never witnessed during training in any test corpus, and therefore some mechanism for assigning non-zero probability to novel n-grams is a central and unavoidable issue in statistical language modeling.",
                "One standard approach to smoothing probability estimates to cope with sparse data problems (and to cope with potentially missing n-grams) is to use some sort of back-off estimator.",
                "Pr(wi|wi−n+1...wi−1) = 8 >>< >>: ˆPr(wi|wi−n+1...wi−1), if #(wi−n+1...wi) > 0 β(wi−n+1...wi−1) × Pr(wi|wi−n+2...wi−1), otherwise (3) where ˆPr(wi|wi−n+1...wi−1) = discount #(wi−n+1...wi) #(wi−n+1...wi−1) (4) is the discounted probability and β(wi−n+1...wi−1) is a normalization constant β(wi−n+1...wi−1) = 1 − X x∈(wi−n+1...wi−1x) ˆPr(x|wi−n+1...wi−1) 1 − X x∈(wi−n+1...wi−1x) ˆPr(x|wi−n+2...wi−1) (5) The discounted probability (4) can be computed with different smoothing techniques, including absolute smoothing, Good-Turing smoothing, linear smoothing, and Witten-Bell smoothing [5].",
                "We used absolute smoothing in our experiments.",
                "Since the likelihood of a string, Pr(w1w2...wN ), is a very small number and hard to interpret, we use entropy as defined below to score the string.",
                "Entropy = − 1 N log2 Pr(w1w2...wN ) (6) Now getting back to the example of the query hotel price comparisons, there are four variants of this query, and the entropy of these four candidates are shown in Table 3.",
                "We can see that all alternatives are less likely than the input query.",
                "It is therefore not useful to make an expansion for this query.",
                "On the other hand, if the input query is hotel price comparisons which is the second alternative in the table, then there is a better alternative than the input query, and it should therefore be expanded.",
                "To tolerate the variations in probability estimation, we relax the selection criterion to those query alternatives if their scores are within a certain distance (10% in our experiments) to the best score.",
                "Query variations Entropy hotel price comparison 6.177 hotel price comparisons 6.597 hotels price comparison 6.937 hotels price comparisons 7.360 Table 3: Variations of query hotel price comparison ranked by entropy score, with the original query in bold face. 3.5 Context sensitive document matching Even after we know which word variants are likely to be useful, we have to be conservative in document matching for the expanded variants.",
                "For the query hotel price comparisons, we decided that word comparisons is expanded to include comparison.",
                "However, not every occurrence of comparison in the document is of interest.",
                "A page which is about comparing customer service can contain all of the words hotel price comparisons comparison.",
                "This page is not a good page for the query.",
                "If we accept matches of every occurrence of comparison, it will hurt retrieval precision and this is one of the main reasons why most stemming approaches do not work well for information retrieval.",
                "To address this problem, we have a proximity constraint that considers the context around the expanded variant in the document.",
                "A variant match is considered valid only if the variant occurs in the same context as the original word does.",
                "The context is the left or the right non-stop segments 1 of the original word.",
                "Taking the same query as an example, the context of comparisons is price.",
                "The expanded word comparison is only valid if it is in the same context of comparisons, which is after the word price.",
                "Thus, we should only match those occurrences of comparison in the document if they occur after the word price.",
                "Considering the fact that queries and documents may not represent the intent in exactly the same way, we relax this proximity constraint to allow variant occurrences within a window of some fixed size.",
                "If the expanded word comparison occurs within the context of price within a window, it is considered valid.",
                "The smaller the window size is, the more restrictive the matching.",
                "We use a window size of 4, which typically captures contexts that include the containing and adjacent noun phrases. 4.",
                "EXPERIMENTAL EVALUATION 4.1 Evaluation metrics We will measure both relevance improvement and the stemming cost required to achieve the relevance. 1 a context segment can not be a single stop word. 4.1.1 Relevance measurement We use a variant of the average Discounted Cumulative Gain (DCG), a recently popularized scheme to measure search engine relevance [1, 11].",
                "Given a query and a ranked list of K documents (K is set to 5 in our experiments), the DCG(K) score for this query is calculated as follows: DCG(K) = KX k=1 gk log2(1 + k) . (7) where gk is the weight for the document at rank k. Higher degree of relevance corresponds to a higher weight.",
                "A page is graded into one of the five scales: Perfect, Excellent, Good, Fair, Bad, with corresponding weights.",
                "We use dcg to represent the average DCG(5) over a set of test queries. 4.1.2 Stemming cost Another metric is to measure the additional cost incurred by stemming.",
                "Given the same level of relevance improvement, we prefer a stemming method that has less additional cost.",
                "We measure this by the percentage of queries that are actually stemmed, over all the queries that could possibly be stemmed. 4.2 Data preparation We randomly sample 870 queries from a three month query log, with 290 from each month.",
                "Among all these 870 queries, we remove all misspelled queries since misspelled queries are not of interest to stemming.",
                "We also remove all one word queries since stemming one word queries without context has a high risk of changing query intent, especially for short words.",
                "In the end, we have 529 correctly spelled queries with at least 2 words. 4.3 Naive stemming for Web search Before explaining the experiments and results in detail, wed like to describe the traditional way of using stemming for Web search, referred as the naive model.",
                "This is to treat every word variant equivalent for all possible words in the query.",
                "The query book store will be transformed into (book OR books)(store OR stores) when limiting stemming to pluralization handling only, where OR is an operator that denotes the equivalence of the left and right arguments. 4.4 Experimental setup The baseline model is the model without stemming.",
                "We first run the naive model to see how well it performs over the baseline.",
                "Then we improve the naive stemming model by document sensitive matching, referred as document sensitive matching model.",
                "This model makes the same stemming as the naive model on the query side, but performs conservative matching on the document side using the strategy described in section 3.5.",
                "The naive model and document sensitive matching model stem the most queries.",
                "Out of the 529 queries, there are 408 queries that they stem, corresponding to 46.7% query traffic (out of a total of 870).",
                "We then further improve the document sensitive matching model from the query side with selective word stemming based on statistical language modeling (section 3.4), referred as selective stemming model.",
                "Based on language modeling prediction, this model stems only a subset of the 408 queries stemmed by the document sensitive matching model.",
                "We experiment with <br>unigram language model</br> and bigram language model.",
                "Since we only care how much we can improve the naive model, we will only use these 408 queries (all the queries that are affected by the naive stemming model) in the experiments.",
                "To get a sense of how these models perform, we also have an oracle model that gives the upper-bound performance a stemmer can achieve on this data.",
                "The oracle model only expands a word if the stemming will give better results.",
                "To analyze the pluralization handling influence on different query categories, we divide queries into short queries and long queries.",
                "Among the 408 queries stemmed by the naive model, there are 272 short queries with 2 or 3 words, and 136 long queries with at least 4 words. 4.5 Results We summarize the overall results in Table 4, and present the results on short queries and long queries separately in Table 5.",
                "Each row in Table 4 is a stemming strategy described in section 4.4.",
                "The first column is the name of the strategy.",
                "The second column is the number of queries affected by this strategy; this column measures the stemming cost, and the numbers should be low for the same level of dcg.",
                "The third column is the average dcg score over all tested queries in this category (including the ones that were not stemmed by the strategy).",
                "The fourth column is the relative improvement over the baseline, and the last column is the p-value of Wilcoxon significance test.",
                "There are several observations about the results.",
                "We can see the naively stemming only obtains a statistically insignificant improvement of 1.5%.",
                "Looking at Table 5, it gives an improvement of 2.7% on short queries.",
                "However, it also hurts long queries by -2.4%.",
                "Overall, the improvement is canceled out.",
                "The reason that it improves short queries is that most short queries only have one word that can be stemmed.",
                "Thus, blindly pluralizing short queries is relatively safe.",
                "However for long queries, most queries can have multiple words that can be pluralized.",
                "Expanding all of them without selection will significantly hurt precision.",
                "Document context sensitive stemming gives a significant lift to the performance, from 2.7% to 4.2% for short queries and from -2.4% to -1.6% for long queries, with an overall lift from 1.5% to 2.8%.",
                "The improvement comes from the conservative context sensitive document matching.",
                "An expanded word is valid only if it occurs within the context of original query in the document.",
                "This reduces many spurious matches.",
                "However, we still notice that for long queries, context sensitive stemming is not able to improve performance because it still selects too many documents and gives the ranking function a hard problem.",
                "While the chosen window size of 4 works the best amongst all the choices, it still allows spurious matches.",
                "It is possible that the window size needs to be chosen on a per query basis to ensure tighter proximity constraints for different types of noun phrases.",
                "Selective word pluralization further helps resolving the problem faced by document context sensitive stemming.",
                "It does not stem every word that places all the burden on the ranking algorithm, but tries to eliminate unnecessary stemming in the first place.",
                "By predicting which word variants are going to be useful, we can dramatically reduce the number of stemmed words, thus improving both the recall and the precision.",
                "With the <br>unigram language model</br>, we can reduce the stemming cost by 26.7% (from 408/408 to 300/408) and lift the overall dcg improvement from 2.8% to 3.4%.",
                "In particular, it gives significant improvements on long queries.",
                "The dcg gain is turned from negative to positive, from −1.6% to 1.1%.",
                "This confirms our hypothesis that reducing unnecessary word expansion leads to precision improvement.",
                "For short queries too, we observe both dcg improvement and stemming cost reduction with the <br>unigram language model</br>.",
                "The advantages of predictive word expansion with a language model is further boosted with a better bigram language model.",
                "The overall dcg gain is lifted from 3.4% to 3.9%, and stemming cost is dramatically reduced from 408/408 to 250/408, corresponding to only 29% of query traffic (250 out of 870) and an overall 1.8% dcg improvement overall all query traffic.",
                "For short queries, bigram language model improves the dcg gain from 4.4% to 4.7%, and reduces stemming cost from 272/272 to 150/272.",
                "For long queries, bigram language model improves dcg gain from 1.1% to 2.5%, and reduces stemming cost from 136/136 to 100/136.",
                "We observe that the bigram language model gives a larger lift for long queries.",
                "This is because the uncertainty in long queries is larger and a more powerful language model is needed.",
                "We hypothesize that a trigram language model would give a further lift for long queries and leave this for future investigation.",
                "Considering the tight upper-bound 2 on the improvement to be gained from pluralization handling (via the oracle model), the current performance on short queries is very satisfying.",
                "For short queries, the dcg gain upper-bound is 6.3% for perfect pluralization handling, our current gain is 4.7% with a bigram language model.",
                "For long queries, the dcg gain upper-bound is 4.6% for perfect pluralization handling, our current gain is 2.5% with a bigram language model.",
                "We may gain additional benefit with a more powerful language model for long queries.",
                "However, the difficulties of long queries come from many other aspects including the proximity and the segmentation problem.",
                "These problems have to be addressed separately.",
                "Looking at the the upper-bound of overhead reduction for oracle stemming, 75% (308/408) of the naive stemmings are wasteful.",
                "We currently capture about half of them.",
                "Further reduction of the overhead requires sacrificing the dcg gain.",
                "Now we can compare the stemming strategies from a different aspect.",
                "Instead of looking at the influence over all queries as we described above, Table 6 summarizes the dcg improvements over the affected queries only.",
                "We can see that the number of affected queries decreases as the stemming strategy becomes more accurate (dcg improvement).",
                "For the bigram language model, over the 250/408 stemmed queries, the dcg improvement is 6.1%.",
                "An interesting observation is the average dcg decreases with a better model, which indicates a better stemming strategy stems more difficult queries (low dcg queries). 5.",
                "DISCUSSIONS 5.1 Language models from query vs. from Web As we mentioned in Section 1, we are trying to predict the probability of a string occurring on the Web.",
                "The language model should describe the occurrence of the string on the Web.",
                "However, the query log is also a good resource. 2 Note that this upperbound is for pluralization handling only, not for general stemming.",
                "General stemming gives a 8% upperbound, which is quite substantial in terms of our metrics.",
                "Affected Queries dcg dcg Improvement p-value baseline 0/408 7.102 N/A N/A naive model 408/408 7.206 1.5% 0.22 document context sensitive model 408/408 7.302 2.8% 0.014 selective model: unigram LM 300/408 7.321 3.4% 0.001 selective model: bigram LM 250/408 7.381 3.9% 0.001 oracle model 100/408 7.519 5.9% 0.001 Table 4: Results comparison of different stemming strategies over all queries affected by naive stemming Short Query Results Affected Queries dcg Improvement p-value baseline 0/272 N/A N/A naive model 272/272 2.7% 0.48 document context sensitive model 272/272 4.2% 0.002 selective model: unigram LM 185/272 4.4% 0.001 selective model: bigram LM 150/272 4.7% 0.001 oracle model 71/272 6.3% 0.001 Long Query Results Affected Queries dcg Improvement p-value baseline 0/136 N/A N/A naive model 136/136 -2.4% 0.25 document context sensitive model 136/136 -1.6% 0.27 selective model: unigram LM 115/136 1.1% 0.001 selective model: bigram LM 100/136 2.5% 0.001 oracle model 29/136 4.6% 0.001 Table 5: Results comparison of different stemming strategies overall short queries and long queries Users reformulate a query using many different variants to get good results.",
                "To test the hypothesis that we can learn reliable transformation probabilities from the query log, we trained a language model from the same query top 25M queries as used to learn segmentation, and use that for prediction.",
                "We observed a slight performance decrease compared to the model trained on Web frequencies.",
                "In particular, the performance for unigram LM was not affected, but the dcg gain for bigram LM changed from 4.7% to 4.5% for short queries.",
                "Thus, the query log can serve as a good approximation of the Web frequencies. 5.2 How linguistics helps Some linguistic knowledge is useful in stemming.",
                "For the pluralization handling case, pluralization and de-pluralization is not symmetric.",
                "A plural word used in a query indicates a special intent.",
                "For example, the query new york hotels is looking for a list of hotels in new york, not the specific new york hotel which might be a hotel located in California.",
                "A simple equivalence of hotel to hotels might boost a particular page about new york hotel to top rank.",
                "To capture this intent, we have to make sure the document is a general page about hotels in new york.",
                "We do this by requiring that the plural word hotels appears in the document.",
                "On the other hand, converting a singular word to plural is safer since a general purpose page normally contains specific information.",
                "We observed a slight overall dcg decrease, although not statistically significant, for document context sensitive stemming if we do not consider this asymmetric property. 5.3 Error analysis One type of mistakes we noticed, though rare but seriously hurting relevance, is the search intent change after stemming.",
                "Generally speaking, pluralization or depluralization keeps the original intent.",
                "However, the intent could change in a few cases.",
                "For one example of such a query, job at apple, we pluralize job to jobs.",
                "This stemming makes the original query ambiguous.",
                "The query job OR jobs at apple has two intents.",
                "One is the employment opportunities at apple, and another is a person working at Apple, Steve Jobs, who is the CEO and co-founder of the company.",
                "Thus, the results after query stemming returns Steve Jobs as one of the results in top 5.",
                "One solution is performing results set based analysis to check if the intent is changed.",
                "This is similar to relevance feedback and requires second phase ranking.",
                "A second type of mistakes is the entity/concept recognition problem, These include two kinds.",
                "One is that the stemmed word variant now matches part of an entity or concept.",
                "For example, query cookies in san francisco is pluralized to cookies OR cookie in san francisco.",
                "The results will match cookie jar in san francisco.",
                "Although cookie still means the same thing as cookies, cookie jar is a different concept.",
                "Another kind is the unstemmed word matches an entity or concept because of the stemming of the other words.",
                "For example, quote ICE is pluralized to quote OR quotes ICE.",
                "The original intent for this query is searching for stock quote for ticker ICE.",
                "However, we noticed that among the top results, one of the results is Food quotes: Ice cream.",
                "This is matched because of Affected Queries old dcg new dcg dcg Improvement naive model 408/408 7.102 7.206 1.5% document context sensitive model 408/408 7.102 7.302 2.8% selective model: unigram LM 300/408 5.904 6.187 4.8% selective model: bigram LM 250/408 5.551 5.891 6.1% Table 6: Results comparison over the stemmed queries only: column old/new dcg is the dcg score over the affected queries before/after applying stemming the pluralized word quotes.",
                "The unchanged word ICE matches part of the noun phrase ice cream here.",
                "To solve this kind of problem, we have to analyze the documents and recognize cookie jar and ice cream as concepts instead of two independent words.",
                "A third type of mistakes occurs in long queries.",
                "For the query bar code reader software, two words are pluralized. code to codes and reader to readers.",
                "In fact, bar code reader in the original query is a strong concept and the internal words should not be changed.",
                "This is the segmentation and entity and noun phrase detection problem in queries, which we actively are attacking.",
                "For long queries, we should correctly identify the concepts in the query, and boost the proximity for the words within a concept. 6.",
                "CONCLUSIONS AND FUTURE WORK We have presented a simple yet elegant way of stemming for Web search.",
                "It improves naive stemming in two aspects: selective word expansion on the query side and conservative word occurrence matching on the document side.",
                "Using pluralization handling as an example, experiments on a major Web search engine data show it significantly improves the Web relevance and reduces the stemming cost.",
                "It also significantly improves Web click through rate (details not reported in the paper).",
                "For the future work, we are investigating the problems we identified in the error analysis section.",
                "These include: entity and noun phrase matching mistakes, and improved segmentation. 7.",
                "REFERENCES [1] E. Agichtein, E. Brill, and S. T. Dumais.",
                "Improving Web Search Ranking by Incorporating User Behavior Information.",
                "In SIGIR, 2006. [2] E. Airio.",
                "Word Normalization and Decompounding in Mono- and Bilingual IR.",
                "Information Retrieval, 9:249-271, 2006. [3] P. Anick.",
                "Using Terminological Feedback for Web Search Refinement: a Log-based Study.",
                "In SIGIR, 2003. [4] R. Baeza-Yates and B. Ribeiro-Neto.",
                "Modern Information Retrieval.",
                "ACM Press/Addison Wesley, 1999. [5] S. Chen and J. Goodman.",
                "An Empirical Study of Smoothing Techniques for Language Modeling.",
                "Technical Report TR-10-98, Harvard University, 1998. [6] S. Cronen-Townsend, Y. Zhou, and B. Croft.",
                "A Framework for Selective Query Expansion.",
                "In CIKM, 2004. [7] H. Fang and C. Zhai.",
                "Semantic Term Matching in Axiomatic Approaches to Information Retrieval.",
                "In SIGIR, 2006. [8] W. B. Frakes.",
                "Term Conflation for Information Retrieval.",
                "In C. J. Rijsbergen, editor, Research and Development in Information Retrieval, pages 383-389.",
                "Cambridge University Press, 1984. [9] D. Harman.",
                "How Effective is Suffixing?",
                "JASIS, 42(1):7-15, 1991. [10] D. Hull.",
                "Stemming Algorithms - A Case Study for Detailed Evaluation.",
                "JASIS, 47(1):70-84, 1996. [11] K. Jarvelin and J. Kekalainen.",
                "Cumulated Gain-Based Evaluation Evaluation of IR Techniques.",
                "ACM TOIS, 20:422-446, 2002. [12] R. Jones, B. Rey, O. Madani, and W. Greiner.",
                "Generating Query Substitutions.",
                "In WWW, 2006. [13] W. Kraaij and R. Pohlmann.",
                "Viewing Stemming as Recall Enhancement.",
                "In SIGIR, 1996. [14] R. Krovetz.",
                "Viewing Morphology as an Inference Process.",
                "In SIGIR, 1993. [15] D. Lin.",
                "Automatic Retrieval and Clustering of Similar Words.",
                "In COLING-ACL, 1998. [16] J.",
                "B. Lovins.",
                "Development of a Stemming Algorithm.",
                "Mechanical Translation and Computational Linguistics, II:22-31, 1968. [17] M. Lennon and D. Peirce and B. Tarry and P. Willett.",
                "An Evaluation of Some Conflation Algorithms for Information Retrieval.",
                "Journal of Information Science, 3:177-188, 1981. [18] M. Porter.",
                "An Algorithm for Suffix Stripping.",
                "Program, 14(3):130-137, 1980. [19] K. M. Risvik, T. Mikolajewski, and P. Boros.",
                "Query Segmentation for Web Search.",
                "In WWW, 2003. [20] S. E. Robertson.",
                "On Term Selection for Query Expansion.",
                "Journal of Documentation, 46(4):359-364, 1990. [21] G. Salton and C. Buckley.",
                "Improving Retrieval Performance by Relevance Feedback.",
                "JASIS, 41(4):288 - 297, 1999. [22] R. Sun, C.-H. Ong, and T.-S. Chua.",
                "Mining Dependency Relations for Query Expansion in Passage Retrieval.",
                "In SIGIR, 2006. [23] C. Van Rijsbergen.",
                "Information Retrieval.",
                "Butterworths, second version, 1979. [24] B. V´elez, R. Weiss, M. A. Sheldon, and D. K. Gifford.",
                "Fast and Effective Query Refinement.",
                "In SIGIR, 1997. [25] J. Xu and B. Croft.",
                "Query Expansion using Local and Global Document Analysis.",
                "In SIGIR, 1996. [26] J. Xu and B. Croft.",
                "Corpus-based Stemming using Cooccurrence of Word Variants.",
                "ACM TOIS, 16 (1):61-81, 1998."
            ],
            "original_annotated_samples": [
                "We experiment with <br>unigram language model</br> and bigram language model.",
                "With the <br>unigram language model</br>, we can reduce the stemming cost by 26.7% (from 408/408 to 300/408) and lift the overall dcg improvement from 2.8% to 3.4%.",
                "For short queries too, we observe both dcg improvement and stemming cost reduction with the <br>unigram language model</br>."
            ],
            "translated_annotated_samples": [
                "Experimentamos con un <br>modelo de lenguaje unigrama</br> y un modelo de lenguaje bigrama.",
                "Con el <br>modelo de lenguaje unigrama</br>, podemos reducir el costo de derivación en un 26.7% (de 408/408 a 300/408) y aumentar la mejora general de DCG del 2.8% al 3.4%.",
                "Para consultas cortas también observamos tanto la mejora de dcg como la reducción del costo de derivación con el <br>modelo de lenguaje unigrama</br>."
            ],
            "translated_text": "Stemming sensible al contexto para la búsqueda web Fuchun Peng Nawaaz Ahmed Xin Li Yumao Lu Yahoo! Tradicionalmente, el truncamiento se ha aplicado a tareas de Recuperación de Información transformando las palabras en documentos a su forma raíz antes de indexarlas, y aplicando una transformación similar a los términos de consulta. Aunque aumenta la recuperación, esta estrategia ingenua no funciona bien para la Búsqueda en la Web, ya que disminuye la precisión y requiere una cantidad significativa de cálculos adicionales. En este artículo, proponemos un método de derivación sensible al contexto que aborda estos dos problemas. Dos propiedades únicas hacen que nuestro enfoque sea factible para la Búsqueda en la Web. Primero, basados en modelado estadístico del lenguaje, realizamos un análisis sensible al contexto en el lado de la consulta. Predecimos con precisión cuál de sus variantes morfológicas es útil para expandir un término de consulta antes de enviar la consulta al motor de búsqueda. Esto reduce drásticamente la cantidad de expansiones incorrectas, lo que a su vez disminuye el costo de la computación adicional y mejora la precisión al mismo tiempo. Segundo, nuestro enfoque realiza una coincidencia de documentos sensible al contexto para esas variantes ampliadas. Esta estrategia conservadora sirve como salvaguarda contra el truncamiento espurio, y resulta ser muy importante para mejorar la precisión. Usando el manejo de la pluralización de palabras como un ejemplo de nuestro enfoque de derivación, nuestros experimentos en un importante motor de búsqueda web muestran que al derivar solo el 29% del tráfico de consultas, podemos mejorar la relevancia medida por la Ganancia Acumulativa Descontada promedio (DCG5) en un 6.1% en estas consultas y en un 1.8% sobre todo el tráfico de consultas. Categorías y Descriptores de Asignaturas H.3.3 [Sistemas de Información]: Almacenamiento y Recuperación de Información-Formulación de Consultas Términos Generales Algoritmos, Experimentación 1. INTRODUCCIÓN La búsqueda en la web se ha convertido en una herramienta importante en nuestra vida diaria para buscar información. Uno de los problemas importantes en la búsqueda web es que las consultas de los usuarios a menudo no están formuladas de la mejor manera para obtener resultados óptimos. Por ejemplo, \"zapatilla para correr\" es una consulta que ocurre con frecuencia en los registros de consulta. Sin embargo, es mucho más probable que la búsqueda \"zapatillas para correr\" proporcione mejores resultados de búsqueda que la consulta original, ya que los documentos que coinciden con la intención de esta consulta suelen contener las palabras \"zapatillas para correr\". Formular correctamente una consulta requiere que el usuario prediga con precisión qué forma de palabra se utiliza en los documentos que mejor satisfacen sus necesidades de información. Esto es difícil incluso para usuarios experimentados, y especialmente difícil para hablantes no nativos. Una solución tradicional es utilizar el stemming [16, 18], el proceso de transformar palabras flexionadas o derivadas a su forma raíz para que un término de búsqueda coincida y recupere documentos que contengan todas las formas del término. Por lo tanto, la palabra \"run\" coincidirá con \"running\", \"ran\", \"runs\", y \"shoe\" coincidirá con \"shoes\" y \"shoeing\". El truncamiento se puede realizar tanto en los términos de un documento durante la indexación (y aplicando la misma transformación a los términos de la consulta durante el procesamiento de la consulta) o expandiendo la consulta con las variantes durante el procesamiento de la consulta. El truncamiento durante la indexación permite muy poca flexibilidad durante el procesamiento de consultas, mientras que el truncamiento mediante la expansión de consultas permite manejar cada consulta de manera diferente, y por lo tanto es preferible. Aunque el truncamiento tradicional aumenta la recuperación al emparejar variantes de palabras [13], puede reducir la precisión al recuperar demasiados documentos que han sido emparejados incorrectamente. Al examinar los resultados de aplicar el truncamiento a un gran número de consultas, generalmente se encuentra que casi igual cantidad de consultas se benefician y se ven perjudicadas por la técnica [6]. Además, reduce el rendimiento del sistema porque el motor de búsqueda tiene que hacer coincidir todas las variantes de palabras. Como mostraremos en los experimentos, esto es cierto incluso si simplificamos el proceso de derivación a la manipulación de pluralización, que es el proceso de convertir una palabra de su forma plural a singular, o viceversa. Por lo tanto, es necesario ser muy cauteloso al utilizar el stemming en los motores de búsqueda web. Un problema del truncamiento tradicional es su transformación ciega de todos los términos de consulta, es decir, siempre realiza la misma transformación para la misma palabra de consulta sin considerar el contexto de la palabra. Por ejemplo, la palabra \"book\" tiene cuatro formas: book, books, booking, booked, y la palabra \"store\" tiene cuatro formas: store, stores, storing, stored. Para la consulta de la librería, expandir ambas palabras a todas sus variantes aumenta significativamente el costo de computación y perjudica la precisión, ya que no todas las variantes son útiles para esta consulta. Transformar librería para que coincida con librerías está bien, pero hacer coincidir almacenamiento de libros o tienda de reservas no lo está. Un método de ponderación que otorga pesos más pequeños a las palabras variantes alivia los problemas hasta cierto punto si los pesos reflejan con precisión la importancia de la variante en esta consulta particular. Sin embargo, el peso uniforme no va a funcionar y un peso dependiente de la consulta sigue siendo un problema desafiante sin resolver [20]. Un segundo problema del truncamiento tradicional es su emparejamiento ciego de todas las ocurrencias en los documentos. Para la consulta de la librería, una transformación que permita que las tiendas variantes se emparejen hará que cada aparición de tiendas en el documento se trate de manera equivalente al término de consulta tienda. Por lo tanto, se emparejará un documento que contenga el fragmento de leer un libro en las cafeterías, lo que provocará que se seleccionen muchos documentos incorrectos. Aunque esperamos que la función de clasificación pueda manejar correctamente estos, con muchos más candidatos para clasificar, el riesgo de cometer errores aumenta. Para aliviar estos dos problemas, proponemos un enfoque de reducción de palabras raíz sensible al contexto para la búsqueda en la web. Nuestra solución consiste en dos análisis contextuales sensibles, uno en el lado de la consulta y otro en el lado del documento. En el lado de la consulta, proponemos un enfoque basado en modelado del lenguaje estadístico para predecir qué variantes de palabras son mejores formas que la palabra original con fines de búsqueda y expandir la consulta solo con esas formas. En el lado del documento, proponemos un emparejamiento conservador sensible al contexto para las variantes de palabras transformadas, solo emparejando las ocurrencias en el documento en el contexto de otros términos en la consulta. Nuestro modelo es simple pero efectivo y eficiente, lo que lo hace factible de ser utilizado en motores de búsqueda web comerciales reales. Utilizamos el manejo de pluralización como un ejemplo continuo para nuestro enfoque de derivación. La motivación para usar el manejo de pluralización como ejemplo es mostrar que incluso un truncamiento tan simple, si se maneja correctamente, puede brindar beneficios significativos a la relevancia de la búsqueda. Hasta donde sabemos, ninguna investigación previa ha investigado sistemáticamente el uso de la pluralización en la búsqueda en la web. Como debemos señalar, el método que proponemos no se limita al manejo de la pluralización, es una técnica de derivación general y también se puede aplicar a la expansión de consultas en general. Los experimentos sobre el truncamiento general producen mejoras significativas adicionales sobre el manejo de la pluralización para consultas largas, aunque los detalles no se informarán en este artículo. En el resto del documento, primero presentamos el trabajo relacionado y distinguimos nuestro método de trabajos anteriores en la Sección 2. Describimos los detalles del enfoque de derivación sensible al contexto en la Sección 3. Luego realizamos experimentos extensos en un importante motor de búsqueda web para respaldar nuestras afirmaciones en la Sección 4, seguidos de discusiones en la Sección 5. Finalmente, concluimos el artículo en la Sección 6.2. TRABAJO RELACIONADO El stemming es una tecnología estudiada desde hace mucho tiempo. Se han desarrollado muchos stemmers, como el stemmer Lovins [16] y el stemmer Porter [18]. El stemmer de Porter es ampliamente utilizado debido a su simplicidad y efectividad en muchas aplicaciones. Sin embargo, el algoritmo de Porter comete muchos errores porque sus reglas simples no pueden describir completamente la morfología del inglés. El análisis de corpus se utiliza para mejorar el stemmer de Porter [26] mediante la creación de clases de equivalencia para palabras que son morfológicamente similares y que ocurren en un contexto similar, medido por la información mutua esperada [23]. Utilizamos un enfoque de corpus similar para el stemming al calcular la similitud entre dos palabras basada en sus características de contexto distribucional, que pueden ser más que solo palabras adyacentes [15], y luego solo mantenemos las palabras morfológicamente similares como candidatas. El uso de la derivación en la recuperación de información también es una técnica bien conocida [8, 10]. Sin embargo, se informó previamente que la efectividad del truncamiento para los sistemas de consulta en inglés era bastante limitada. Lennon et al. [17] compararon los algoritmos de Lovins y Porter y encontraron poco mejoramiento en el rendimiento de recuperación. Más tarde, Harman [9] compara tres técnicas generales de derivación en experimentos de recuperación de texto, incluido el manejo de pluralización (llamado S stemmer en el artículo). También propusieron el truncamiento selectivo basado en la longitud de la consulta y la importancia del término, pero no se informaron resultados positivos. Por otro lado, Krovetz [14] realizó comparaciones sobre un pequeño número de documentos (de 400 a 12k) y mostró una mejora dramática en la precisión (de hasta un 45%). Sin embargo, debido al número limitado de consultas probadas (menos de 100) y al tamaño reducido de la colección, los resultados son difíciles de generalizar para la búsqueda en la web. Estos resultados mixtos, en su mayoría fracasos, llevaron a los primeros investigadores de IR a considerar que el truncamiento era irrelevante en general para el inglés [4], aunque investigaciones recientes han demostrado que el truncamiento tiene mayores beneficios para la recuperación en otros idiomas [2]. Sospechamos que los fracasos anteriores se debieron principalmente a los dos problemas que mencionamos en la introducción. El stemming ciego, o un stemming selectivo basado en la longitud de la consulta como se utiliza en [9], no es suficiente. El truncamiento debe decidirse caso por caso, no solo a nivel de consulta sino también a nivel de documento. Como demostraremos, si se maneja correctamente, se puede lograr una mejora significativa. Un problema más general relacionado con el stemming es la reformulación de consultas [3, 12] y la expansión de consultas que amplía las palabras no solo con variantes de palabras [7, 22, 24, 25]. Para decidir qué palabras expandidas usar, las personas a menudo utilizan técnicas de retroalimentación de seudorelevancia que envían la consulta original a un motor de búsqueda y recuperan los documentos principales, extraen palabras relevantes de estos documentos principales como palabras de consulta adicionales y vuelven a enviar la consulta expandida nuevamente [21]. Esto normalmente requiere enviar una consulta varias veces al motor de búsqueda y no es rentable para procesar la gran cantidad de consultas involucradas en la búsqueda web. Además, la expansión de consultas, incluida la reformulación de consultas [3, 12], tiene un alto riesgo de cambiar la intención del usuario (llamado desviación de consulta). Dado que las palabras expandidas pueden tener diferentes significados, agregarlas a la consulta podría potencialmente cambiar la intención de la consulta original. Por lo tanto, la expansión de consultas basada en pseudorelevancia y la reformulación de consultas pueden proporcionar sugerencias a los usuarios para su refinamiento interactivo, pero difícilmente pueden ser utilizadas directamente para la búsqueda en la web. Por otro lado, el truncamiento es mucho más conservador ya que la mayoría de las veces, conserva la intención de búsqueda original. Si bien la mayoría de los trabajos sobre la expansión de consultas se centran en mejorar la recuperación, nuestro trabajo se enfoca en aumentar tanto la recuperación como la precisión. El aumento en el recuerdo es evidente. Con el stemming de calidad, los buenos documentos que no fueron seleccionados antes del stemming serán promovidos y aquellos documentos de baja calidad serán degradados. En la expansión selectiva de consultas, Cronen-Townsend et al. [6] propusieron un método para la expansión selectiva de consultas basado en comparar la divergencia de Kullback-Leibler de los resultados de la consulta no expandida y los resultados de la consulta expandida. Esto es similar a la retroalimentación de relevancia en el sentido de que requiere múltiples pasadas de recuperación. Si una palabra puede expandirse en varias palabras, se requiere ejecutar este proceso varias veces para decidir cuál palabra expandida es útil. Es costoso implementar esto en motores de búsqueda web en producción. Nuestro método predice la calidad de la expansión basándose en información sin conexión sin enviar la consulta a un motor de búsqueda. En resumen, proponemos un enfoque novedoso para abordar un problema antiguo, pero aún importante y desafiante para la búsqueda en la web: el stemming. Nuestro enfoque es único en el sentido de que realiza el truncamiento predictivo de forma individualizada para cada consulta sin retroalimentación de relevancia de la Web, utilizando el contexto de las variantes en los documentos para preservar la precisión. Es simple, pero muy eficiente y efectivo, lo que hace factible el truncamiento en tiempo real para la búsqueda en la web. Nuestros resultados confirmarán a los investigadores que el truncamiento es realmente muy importante para la recuperación de información a gran escala. STEMMING CONTEXTUAL SENSIBLE 3.1 Resumen Nuestro sistema tiene cuatro componentes como se ilustra en la Figura 1: generación de candidatos, segmentación de consultas y detección de palabras clave, derivación de consultas sensible al contexto y coincidencia de documentos sensible al contexto. La generación de candidatos (componente 1) se realiza fuera de línea y los candidatos generados se almacenan en un diccionario. Para una consulta de entrada, primero segmentamos la consulta en conceptos y detectamos la palabra principal de cada concepto (componente 2). Luego utilizamos modelado de lenguaje estadístico para decidir si una variante particular es útil (componente 3), y finalmente, para las variantes expandidas, realizamos un emparejamiento de documentos sensible al contexto (componente 4). A continuación discutimos cada uno de los componentes con más detalle. Componente 4: coincidencia de documentos sensibles al contexto Consulta de entrada: y detección de palabras clave Componente 2: segmento Componente 1: generación de candidatos comparaciones −> comparación Componente 3: decisión de expansión selectiva de palabras: comparaciones −> comparación ejemplo: comparaciones de precios de hoteles salida: comparaciones de hoteles hotel −> hoteles Figura 1: Componentes del sistema 3.2 Generación de candidatos de expansión Una de las formas de generar candidatos es utilizando el stemmer de Porter [18]. El stemmer de Porter simplemente utiliza reglas morfológicas para convertir una palabra a su forma base. No tiene conocimiento del significado semántico de las palabras y a veces comete errores graves, como cambiar \"executive\" por \"execution\", \"news\" por \"new\" y \"paste\" por \"past\". Una forma más conservadora se basa en utilizar análisis de corpus para mejorar los resultados del stemmer de Porter [26]. El análisis de corpus que realizamos se basa en la similitud distribucional de palabras [15]. La razón de utilizar la similitud distribucional de palabras es que las variantes verdaderas tienden a ser utilizadas en contextos similares. En el cálculo de similitud de palabras distribucionales, cada palabra se representa con un vector de características derivadas del contexto de la palabra. Utilizamos los bigramas a la izquierda y a la derecha de la palabra como sus características de contexto, mediante la extracción de un gran corpus web. La similitud entre dos palabras es la similitud coseno entre los dos vectores de características correspondientes. Las 20 palabras similares a \"desarrollar\" se muestran en la siguiente tabla. rango candidato puntaje rango candidato puntaje 0 desarrollar 1 10 berts 0.119 1 desarrollando 0.339 11 wads 0.116 2 desarrollado 0.176 12 desarrollador 0.107 3 incubadora 0.160 13 promoviendo 0.100 4 desarrolla 0.150 14 desarrollo 0.091 5 desarrollo 0.148 15 reingeniería 0.090 6 tutoría 0.138 16 construir 0.083 7 analizando 0.128 17 construir 0.081 8 desarrollo 0.128 18 educativo 0.081 9 automatización 0.126 19 instituto 0.077 Tabla 1: Los 20 candidatos más similares a la palabra \"desarrollar\". La puntuación de la columna es la puntuación de similitud. Para determinar los candidatos de derivación, aplicamos algunas reglas morfológicas del stemmer de Porter [18] a la lista de similitud. Después de aplicar estas reglas, para la palabra desarrollar, los candidatos de derivación son desarrollando, desarrollado, desarrolla, desarrollo, desarrollo, desarrollador, y desarrollo. Para el propósito de manejo de pluralización, solo se conserva el candidato desarrolla. Una cosa que observamos al observar las palabras distribucionalmente similares es que están estrechamente relacionadas semánticamente. Estas palabras podrían servir como candidatas para la expansión general de consultas, un tema que investigaremos en el futuro. 3.3 Segmentación e identificación de palabras clave Para consultas largas, es bastante importante detectar los conceptos en la consulta y las palabras más importantes para esos conceptos. Primero dividimos una consulta en segmentos, cada segmento representando un concepto que normalmente es una frase nominal. Para cada una de las frases nominales, luego detectamos la palabra más importante a la que llamamos la palabra principal. La segmentación también se utiliza en la coincidencia sensible a documentos (sección 3.5) para hacer cumplir la proximidad. Para dividir una consulta en segmentos, tenemos que definir un criterio para medir la fuerza de la relación entre las palabras. Un método efectivo es utilizar la información mutua como indicador para decidir si dividir o no dos palabras [19]. Utilizamos un registro de 25 millones de consultas y recopilamos las frecuencias de bigramas y unigramas a partir de él. Para cada consulta entrante, calculamos la información mutua de dos palabras adyacentes; si supera un umbral predefinido, no dividimos la consulta entre esas dos palabras y pasamos a la siguiente palabra. Continuamos este proceso hasta que la información mutua entre dos palabras esté por debajo del umbral, luego creamos un límite conceptual aquí. La Tabla 2 muestra algunos ejemplos de segmentación de consultas. La forma ideal de encontrar la palabra principal de un concepto es realizar un análisis sintáctico para determinar la estructura de dependencia de la consulta. El análisis de consultas es más difícil que el análisis de oraciones, ya que muchas consultas no son gramaticales y son muy cortas. Aplicar un analizador entrenado en oraciones de documentos a consultas tendrá un rendimiento deficiente. En nuestra solución, solo utilizamos reglas heurísticas simples, y funciona muy bien en la práctica para el inglés. Para una frase nominal en inglés, la palabra principal suele ser la última palabra no detenida, a menos que la frase siga un patrón particular, como XYZ de/en/a/desde UVW. En tales casos, la palabra principal suele ser la última palabra no detenida de XYZ. 3.4 Expansión de palabras sensibles al contexto Después de detectar cuáles son las palabras más importantes para expandir, debemos decidir si las expansiones serán útiles. Nuestras estadísticas muestran que aproximadamente la mitad de las consultas pueden ser transformadas mediante la pluralización a través de un truncamiento ingenuo. Entre esta mitad, aproximadamente el 25% de las consultas mejoran la relevancia cuando se transforman, la mayoría (alrededor del 50%) no cambian sus 5 resultados principales, y el 25% restante tiene un rendimiento peor. Por lo tanto, es extremadamente importante identificar qué consultas no deben ser truncadas con el fin de maximizar la mejora de relevancia y minimizar el costo de truncamiento. Además, para una consulta con múltiples palabras que pueden ser transformadas, o una palabra con múltiples variantes, no todas las expansiones son útiles. Tomando la comparación de precios de hoteles como ejemplo, decidimos que hotel y comparación de precios son dos conceptos. Las palabras clave hotel y comparación se pueden expandir a hoteles y comparaciones. ¿Son útiles ambas transformaciones? Para probar si una expansión es útil, tenemos que saber si es probable que la consulta expandida obtenga más documentos relevantes de la web, lo cual puede cuantificarse mediante la probabilidad de que la consulta ocurra como una cadena en la web. Cuanto más probable sea que ocurra una consulta en la web, más documentos relevantes puede devolver esta consulta. Ahora todo el problema se convierte en cómo calcular la probabilidad de que ocurra la consulta en la Web. Calcular la probabilidad de que una cadena ocurra en un corpus es un problema bien conocido de modelado del lenguaje. El objetivo del modelado del lenguaje es predecir la probabilidad de secuencias de palabras que ocurren naturalmente, s = w1w2...wN; o más simplemente, asignar una alta probabilidad a las secuencias de palabras que realmente ocurren (y una baja probabilidad a las secuencias de palabras que nunca ocurren). El enfoque más simple y exitoso para el modelado del lenguaje sigue estando basado en el modelo n-gramo. Por la regla de la cadena de probabilidad, se puede escribir la probabilidad de cualquier secuencia de palabras como Pr(w1w2...wN) = ΠY i=1 Pr(wi|w1...wi−1) (1). Un modelo n-grama aproxima esta probabilidad asumiendo que las únicas palabras relevantes para predecir Pr(wi|w1...wi−1) son las n − 1 palabras anteriores; es decir, La probabilidad de una palabra wi dado w1...wi−1 es igual a la probabilidad de wi dado wi−n+1...wi−1. Una estimación directa de máxima verosimilitud de las probabilidades de n-gramas a partir de un corpus se obtiene a partir de la frecuencia observada de cada uno de los patrones Pr(wi|wi−n+1...wi−1) = #(wi−n+1...wi) #(wi−n+1...wi−1) donde #(.) denota el número de ocurrencias de un n-grama específico en el corpus de entrenamiento. Aunque se podría intentar usar modelos de n-gramos simples para capturar dependencias a largo plazo en el lenguaje, intentar hacerlo directamente crea inmediatamente problemas de datos dispersos: Utilizar n-gramos de longitud hasta n implica estimar la probabilidad de eventos de longitud Wn, donde W es el tamaño del vocabulario de palabras. Esto rápidamente abruma los recursos computacionales y de datos modernos incluso para opciones modestas de n (más allá de 3 a 6). Además, debido a la naturaleza de cola pesada del lenguaje (es decir, La ley de Zipf) es probable que uno se encuentre con n-gramas novedosos que nunca fueron observados durante el entrenamiento en ningún corpus de prueba, por lo tanto, algún mecanismo para asignar una probabilidad distinta de cero a los n-gramas novedosos es un problema central e inevitable en la modelización estadística del lenguaje. Un enfoque estándar para suavizar las estimaciones de probabilidad para hacer frente a problemas de datos escasos (y para hacer frente a posibles n-gramas faltantes) es utilizar algún tipo de estimador de retroceso. Pr(wi|wi−n+1...wi−1) = 8 >>< >>: ˆPr(wi|wi−n+1...wi−1), si #(wi−n+1...wi) > 0 β(wi−n+1...wi−1) × Pr(wi|wi−n+2...wi−1), de lo contrario (3) donde ˆPr(wi|wi−n+1...wi−1) = descuento #(wi−n+1...wi) #(wi−n+1...wi−1) (4) es la probabilidad descontada y β(wi−n+1...wi−1) es una constante de normalización β(wi−n+1...wi−1) = 1 − X x∈(wi−n+1...wi−1x) ˆPr(x|wi−n+1...wi−1) 1 − X x∈(wi−n+1...wi−1x) ˆPr(x|wi−n+2...wi−1) (5) La probabilidad descontada (4) se puede calcular con diferentes técnicas de suavizado, incluido el suavizado absoluto, el suavizado de Good-Turing, el suavizado lineal y el suavizado de Witten-Bell [5]. Utilizamos suavizado absoluto en nuestros experimentos. Dado que la probabilidad de una cadena, Pr(w1w2...wN), es un número muy pequeño y difícil de interpretar, utilizamos la entropía, tal como se define a continuación, para puntuar la cadena. Entropía = − 1 N log2 Pr(w1w2...wN ) (6) Ahora volviendo al ejemplo de la comparación de precios de hoteles, hay cuatro variantes de esta consulta, y la entropía de estos cuatro candidatos se muestra en la Tabla 3. Podemos ver que todas las alternativas son menos probables que la consulta de entrada. Por lo tanto, no es útil hacer una expansión para esta consulta. Por otro lado, si la consulta de entrada son comparaciones de precios de hoteles, que es la segunda alternativa en la tabla, entonces hay una mejor alternativa que la consulta de entrada, y por lo tanto debería ser ampliada. Para tolerar las variaciones en la estimación de probabilidad, relajamos el criterio de selección para esas alternativas de consulta si sus puntuaciones están dentro de una cierta distancia (10% en nuestros experimentos) de la mejor puntuación. Variaciones de la consulta Comparación de precios de hoteles 6.177 comparaciones de precios de hoteles 6.597 comparación de precios de hoteles 6.937 comparaciones de precios de hoteles 7.360 Tabla 3: Variaciones de la consulta comparación de precios de hoteles clasificadas por puntaje de entropía, con la consulta original en negrita. 3.5 Coincidencia de documentos sensibles al contexto Aun después de saber qué variantes de palabras son probablemente útiles, debemos ser conservadores en la coincidencia de documentos para las variantes ampliadas. Para la consulta de comparaciones de precios de hoteles, decidimos que la palabra \"comparaciones\" se amplía para incluir \"comparación\". Sin embargo, no todos los casos de comparación en el documento son de interés. Una página que trata sobre comparar el servicio al cliente puede contener todas las palabras comparaciones de precios de hoteles comparación. Esta página no es una buena página para la consulta. Si aceptamos coincidencias de cada ocurrencia de comparación, afectará la precisión de recuperación y esta es una de las principales razones por las que la mayoría de los enfoques de derivación no funcionan bien para la recuperación de información. Para abordar este problema, tenemos una restricción de proximidad que considera el contexto alrededor de la variante expandida en el documento. Una coincidencia de variante se considera válida solo si la variante ocurre en el mismo contexto que la palabra original lo hace. El contexto son los segmentos continuos de la izquierda o de la derecha de la palabra original. Tomando la misma consulta como ejemplo, el contexto de las comparaciones es el precio. La comparación de palabras ampliada solo es válida si está en el mismo contexto de comparaciones, que es después de la palabra precio. Por lo tanto, solo debemos emparejar aquellas ocurrencias de comparación en el documento si ocurren después de la palabra precio. Considerando el hecho de que las consultas y los documentos pueden no representar la intención de la misma manera exacta, relajamos esta restricción de proximidad para permitir ocurrencias variantes dentro de una ventana de un tamaño fijo. Si la comparación de palabras expandidas ocurre dentro del contexto de precio dentro de una ventana, se considera válida. Cuanto más pequeño sea el tamaño de la ventana, más restrictiva será la coincidencia. Utilizamos un tamaño de ventana de 4, que normalmente captura contextos que incluyen las frases nominales que contienen y las adyacentes. 4. EVALUACIÓN EXPERIMENTAL 4.1 Métricas de evaluación Mediremos tanto la mejora de relevancia como el costo de derivación necesario para lograr la relevancia. 1 un segmento de contexto no puede ser una sola palabra de parada. 4.1.1 Medición de relevancia Utilizamos una variante de la Ganancia Acumulada Descontada Promedio (DCG), un esquema recientemente popularizado para medir la relevancia de los motores de búsqueda [1, 11]. Dada una consulta y una lista clasificada de K documentos (K se establece en 5 en nuestros experimentos), el puntaje DCG(K) para esta consulta se calcula de la siguiente manera: DCG(K) = Σ k=1 a K gk log2(1 + k) . (7) donde gk es el peso para el documento en la posición k. Un mayor grado de relevancia corresponde a un peso mayor. Una página se califica en una de las cinco escalas: Perfecto, Excelente, Bueno, Regular, Malo, con pesos correspondientes. Utilizamos DCG para representar el DCG promedio(5) sobre un conjunto de consultas de prueba. 4.1.2 Costo de derivación Otro métrica es medir el costo adicional incurrido por la derivación. Dado el mismo nivel de mejora en la relevancia, preferimos un método de truncamiento que tenga un menor costo adicional. Medimos esto por el porcentaje de consultas que realmente se reducen, sobre todas las consultas que podrían ser reducidas. 4.2 Preparación de datos Muestreamos aleatoriamente 870 consultas de un registro de consultas de tres meses, con 290 de cada mes. Entre todas estas 870 consultas, eliminamos todas las consultas con errores ortográficos ya que las consultas con errores ortográficos no son de interés para el stemming. También eliminamos todas las consultas de una sola palabra, ya que reducir las consultas de una sola palabra sin contexto tiene un alto riesgo de cambiar la intención de la consulta, especialmente para palabras cortas. Al final, tenemos 529 consultas correctamente escritas con al menos 2 palabras. 4.3 Stemming ingenuo para la búsqueda en la Web Antes de explicar en detalle los experimentos y resultados, nos gustaría describir la forma tradicional de usar el stemming para la búsqueda en la Web, conocida como el modelo ingenuo. Esto es para tratar cada variante de palabra equivalente para todas las posibles palabras en la consulta. La consulta de la librería se transformará en (libro O libros)(tienda O tiendas) al limitar el truncamiento al manejo de pluralización solamente, donde O es un operador que denota la equivalencia de los argumentos izquierdo y derecho. 4.4 Configuración experimental El modelo base es el modelo sin truncamiento. Primero ejecutamos el modelo ingenuo para ver qué tan bien se desempeña en comparación con el punto de referencia. Luego mejoramos el modelo de derivación ingenua mediante la coincidencia sensible al documento, denominado modelo de coincidencia sensible al documento. Este modelo realiza el mismo stemming que el modelo ingenuo en el lado de la consulta, pero realiza un emparejamiento conservador en el lado del documento utilizando la estrategia descrita en la sección 3.5. El modelo ingenuo y el modelo de coincidencia sensible al documento son los que mejor responden a la mayoría de las consultas. De las 529 consultas, hay 408 consultas que se originan, lo que corresponde al 46.7% del tráfico de consultas (de un total de 870). Luego mejoramos aún más el modelo de coincidencia sensible de documentos desde el lado de la consulta con un proceso de derivación de palabras selectivo basado en modelado estadístico del lenguaje (sección 3.4), denominado modelo de derivación selectiva. Basado en la predicción del modelado del lenguaje, este modelo deriva solo un subconjunto de las 408 consultas derivadas por el modelo de coincidencia sensible al documento. Experimentamos con un <br>modelo de lenguaje unigrama</br> y un modelo de lenguaje bigrama. Dado que solo nos importa cuánto podemos mejorar el modelo ingenuo, solo utilizaremos estas 408 consultas (todas las consultas que se ven afectadas por el modelo de derivación ingenuo) en los experimentos. Para tener una idea de cómo se desempeñan estos modelos, también tenemos un modelo oráculo que proporciona el rendimiento máximo que un stemmer puede lograr en estos datos. El modelo del oráculo solo expande una palabra si el truncamiento dará mejores resultados. Para analizar la influencia del manejo de la pluralización en diferentes categorías de consultas, dividimos las consultas en consultas cortas y consultas largas. Entre las 408 consultas generadas por el modelo ingenuo, hay 272 consultas cortas con 2 o 3 palabras, y 136 consultas largas con al menos 4 palabras. Resumimos los resultados generales en la Tabla 4, y presentamos los resultados de las consultas cortas y largas por separado en la Tabla 5. Cada fila en la Tabla 4 es una estrategia de derivación descrita en la sección 4.4. La primera columna es el nombre de la estrategia. La segunda columna es el número de consultas afectadas por esta estrategia; esta columna mide el costo de derivación, y los números deberían ser bajos para el mismo nivel de dcg. La tercera columna es la puntuación DCG promedio sobre todas las consultas probadas en esta categoría (incluyendo aquellas que no fueron truncadas por la estrategia). La cuarta columna es la mejora relativa sobre la línea base, y la última columna es el valor p de la prueba de significancia de Wilcoxon. Hay varias observaciones sobre los resultados. Podemos ver que el truncado ingenuo solo logra una mejora estadísticamente insignificante del 1.5%. Mirando la Tabla 5, se observa una mejora del 2.7% en las consultas cortas. Sin embargo, también perjudica las consultas largas en un -2.4%. En general, la mejora se cancela. La razón por la que mejora las consultas cortas es que la mayoría de las consultas cortas solo tienen una palabra que se puede reducir a su raíz. Por lo tanto, pluralizar ciegamente consultas cortas es relativamente seguro. Sin embargo, para consultas largas, la mayoría de las consultas pueden tener varias palabras que pueden ser pluralizadas. Expandir todos ellos sin selección perjudicará significativamente la precisión. La aplicación de un stemming sensible al contexto del documento proporciona un aumento significativo en el rendimiento, desde un 2.7% hasta un 4.2% para consultas cortas y desde un -2.4% hasta un -1.6% para consultas largas, con un aumento general del 1.5% al 2.8%. La mejora proviene de la coincidencia de documentos sensible al contexto conservador. Una palabra expandida es válida solo si ocurre dentro del contexto de la consulta original en el documento. Esto reduce muchas coincidencias falsas. Sin embargo, aún observamos que para consultas largas, el truncamiento sensible al contexto no logra mejorar el rendimiento porque sigue seleccionando demasiados documentos y le presenta a la función de clasificación un problema difícil. Si bien el tamaño de ventana elegido de 4 es el que mejor funciona entre todas las opciones, aún permite coincidencias espurias. Es posible que el tamaño de la ventana deba elegirse según la consulta para garantizar restricciones de proximidad más estrictas para diferentes tipos de frases nominales. La pluralización selectiva de palabras ayuda aún más a resolver el problema enfrentado por el truncamiento sensible al contexto del documento. No se aplica el truncamiento a cada palabra que coloca toda la carga en el algoritmo de clasificación, sino que intenta eliminar el truncamiento innecesario en primer lugar. Al predecir qué variantes de palabras van a ser útiles, podemos reducir drásticamente el número de palabras derivadas, mejorando así tanto la recuperación como la precisión. Con el <br>modelo de lenguaje unigrama</br>, podemos reducir el costo de derivación en un 26.7% (de 408/408 a 300/408) y aumentar la mejora general de DCG del 2.8% al 3.4%. En particular, proporciona mejoras significativas en consultas largas. La ganancia de DCG se cambia de negativa a positiva, de -1.6% a 1.1%. Esto confirma nuestra hipótesis de que reducir la expansión innecesaria de palabras conduce a una mejora en la precisión. Para consultas cortas también observamos tanto la mejora de dcg como la reducción del costo de derivación con el <br>modelo de lenguaje unigrama</br>. Las ventajas de la expansión predictiva de palabras con un modelo de lenguaje se potencian aún más con un mejor modelo de lenguaje de bigrama. La ganancia total de DCG aumenta de 3.4% a 3.9%, y el costo de derivación se reduce drásticamente de 408/408 a 250/408, correspondiente a solo el 29% del tráfico de consultas (250 de 870) y una mejora total de DCG del 1.8% en todo el tráfico de consultas. Para consultas cortas, el modelo de lenguaje de bigrama mejora la ganancia de DCG del 4.4% al 4.7%, y reduce el costo de derivación de 272/272 a 150/272. Para consultas largas, el modelo de lenguaje de bigrama mejora la ganancia de DCG del 1.1% al 2.5%, y reduce el costo de derivación de 136/136 a 100/136. Observamos que el modelo de lenguaje de bigrama proporciona un mayor aumento para consultas largas. Esto se debe a que la incertidumbre en las consultas largas es mayor y se necesita un modelo de lenguaje más potente. Hacemos la hipótesis de que un modelo de lenguaje de trigramas proporcionaría un impulso adicional para consultas largas y dejamos esto para investigaciones futuras. Considerando el límite superior estricto de 2 en la mejora que se puede obtener del manejo de la pluralización (a través del modelo oráculo), el rendimiento actual en consultas cortas es muy satisfactorio. Para consultas breves, la ganancia máxima de DCG es del 6.3% para el manejo perfecto de la pluralización, nuestra ganancia actual es del 4.7% con un modelo de lenguaje de bigrama. Para consultas largas, la ganancia máxima de DCG es del 4.6% para el manejo perfecto de la pluralización, nuestra ganancia actual es del 2.5% con un modelo de lenguaje de bigrama. Podríamos obtener beneficios adicionales con un modelo de lenguaje más potente para consultas largas. Sin embargo, las dificultades de las consultas largas provienen de muchos otros aspectos, incluyendo la proximidad y el problema de la segmentación. Estos problemas deben ser abordados por separado. Al observar el límite superior de reducción de gastos generales para el truncamiento de Oracle, el 75% (308/408) de los truncamientos ingenuos son inútiles. Actualmente capturamos alrededor de la mitad de ellos. La reducción adicional de los gastos generales requiere sacrificar la ganancia de la DCG. Ahora podemos comparar las estrategias de derivación desde un aspecto diferente. En lugar de analizar la influencia sobre todas las consultas como describimos anteriormente, la Tabla 6 resume las mejoras de DCG solo sobre las consultas afectadas. Podemos ver que el número de consultas afectadas disminuye a medida que la estrategia de derivación se vuelve más precisa (mejora en el dcg). Para el modelo de lenguaje de bigrama, sobre las 250/408 consultas truncadas, la mejora en DCG es del 6.1%. Una observación interesante es que el dcg promedio disminuye con un modelo mejor, lo que indica que una estrategia de derivación mejorada deriva consultas más difíciles (consultas con bajo dcg). 5. Como mencionamos en la Sección 1, estamos tratando de predecir la probabilidad de que una cadena ocurra en la Web. El modelo de lenguaje debe describir la ocurrencia de la cadena en la web. Sin embargo, el registro de consultas también es un buen recurso. Tenga en cuenta que este límite superior es solo para el manejo de pluralización, no para el truncamiento general. El stemming general proporciona un límite superior del 8%, lo cual es bastante sustancial en términos de nuestras métricas. Las consultas afectadas dcg dcg Mejora p-valor línea de base 0/408 7.102 N/A N/A modelo ingenuo 408/408 7.206 1.5% 0.22 modelo sensible al contexto del documento 408/408 7.302 2.8% 0.014 modelo selectivo: unigram LM 300/408 7.321 3.4% 0.001 modelo selectivo: bigram LM 250/408 7.381 3.9% 0.001 modelo oráculo 100/408 7.519 5.9% 0.001 Tabla 4: Comparación de resultados de diferentes estrategias de derivación en todas las consultas afectadas por la derivación ingenua Resultados de Consultas Cortas Consultas Afectadas dcg Mejora p-valor línea de base 0/272 N/A N/A modelo ingenuo 272/272 2.7% 0.48 modelo sensible al contexto del documento 272/272 4.2% 0.002 modelo selectivo: unigram LM 185/272 4.4% 0.001 modelo selectivo: bigram LM 150/272 4.7% 0.001 modelo oráculo 71/272 6.3% 0.001 Resultados de Consultas Largas Consultas Afectadas dcg Mejora p-valor línea de base 0/136 N/A N/A modelo ingenuo 136/136 -2.4% 0.25 modelo sensible al contexto del documento 136/136 -1.6% 0.27 modelo selectivo: unigram LM 115/136 1.1% 0.001 modelo selectivo: bigram LM 100/136 2.5% 0.001 modelo oráculo 29/136 4.6% 0.001 Tabla 5: Comparación de resultados de diferentes estrategias de derivación en consultas cortas y largas en general Los usuarios reformulan una consulta utilizando muchas variantes diferentes para obtener buenos resultados. Para probar la hipótesis de que podemos aprender probabilidades de transformación confiables a partir del registro de consultas, entrenamos un modelo de lenguaje con las mismas 25 millones de consultas principales utilizadas para aprender la segmentación, y lo utilizamos para la predicción. Observamos una ligera disminución en el rendimiento en comparación con el modelo entrenado en frecuencias web. En particular, el rendimiento para el modelo de lenguaje unigrama no se vio afectado, pero la ganancia de dcg para el modelo de lenguaje bigrama cambió de 4.7% a 4.5% para consultas cortas. Por lo tanto, el registro de consultas puede servir como una buena aproximación de las frecuencias web. 5.2 Cómo la lingüística ayuda. Algunos conocimientos lingüísticos son útiles en el stemming. Para el manejo de la pluralización, la pluralización y la despluralización no son simétricas. Una palabra en plural utilizada en una consulta indica una intención especial. Por ejemplo, la consulta hoteles en Nueva York está buscando una lista de hoteles en Nueva York, no el hotel específico de Nueva York que podría estar ubicado en California. Una simple equivalencia de hotel a hoteles podría impulsar una página en particular sobre hoteles en Nueva York al primer puesto. Para capturar esta intención, tenemos que asegurarnos de que el documento sea una página general sobre hoteles en Nueva York. Esto lo hacemos exigiendo que la palabra en plural hoteles aparezca en el documento. Por otro lado, convertir una palabra singular a plural es más seguro ya que una página de propósito general normalmente contiene información específica. Observamos una ligera disminución general en el dcg, aunque no estadísticamente significativa, para el stemming sensible al contexto del documento si no consideramos esta propiedad asimétrica. Análisis de errores. Un tipo de errores que notamos, aunque raros pero que afectan seriamente la relevancia, es el cambio de intención de búsqueda después del stemming. En general, la pluralización o despluralización mantiene la intención original. Sin embargo, la intención podría cambiar en algunos casos. Por ejemplo, para una consulta de este tipo, trabajo en Apple, pluralizamos trabajo a trabajos. Este truncamiento hace que la consulta original sea ambigua. El trabajo de consulta O trabajos en Apple tiene dos intenciones. Una de las oportunidades laborales en Apple, y otra es una persona que trabaja en Apple, Steve Jobs, quien es el CEO y cofundador de la empresa. Por lo tanto, los resultados después de la reducción de consultas devuelven a Steve Jobs como uno de los resultados en el top 5. Una solución es realizar un análisis basado en el conjunto de resultados para verificar si la intención ha cambiado. Esto es similar a la retroalimentación de relevancia y requiere una clasificación en la segunda fase. Un segundo tipo de errores es el problema de reconocimiento de entidades/conceptos. Estos incluyen dos tipos. Una de ellas es que la variante de la palabra derivada ahora coincide con parte de una entidad o concepto. Por ejemplo, la consulta \"cookies en San Francisco\" se pluraliza como \"cookies\" O \"cookie en San Francisco\". Los resultados coincidirán con el tarro de galletas en San Francisco. Aunque \"cookie\" todavía significa lo mismo que \"galletas\", el concepto de \"cookie jar\" es diferente. Otro tipo es la palabra no derivada que coincide con una entidad o concepto debido al truncamiento de las otras palabras. Por ejemplo, la cita ICE se pluraliza como cita OR citas ICE. La intención original de esta consulta es buscar la cotización de acciones para el símbolo ICE. Sin embargo, notamos que entre los resultados principales, uno de los resultados es Citas sobre comida: Helado. Esto se empareja debido a las consultas afectadas dcg antiguas nuevas dcg dcg Mejora del modelo ingenuo 408/408 7.102 7.206 1.5% modelo sensible al contexto del documento 408/408 7.102 7.302 2.8% modelo selectivo: unigram LM 300/408 5.904 6.187 4.8% modelo selectivo: bigram LM 250/408 5.551 5.891 6.1% Tabla 6: Comparación de resultados solo sobre las consultas derivadas: la columna dcg antigua/nueva es la puntuación dcg sobre las consultas afectadas antes/después de aplicar la pluralización de la palabra entre comillas. La palabra inalterada ICE coincide con parte de la frase nominal helado aquí. Para resolver este tipo de problema, tenemos que analizar los documentos y reconocer \"cookie jar\" y \"ice cream\" como conceptos en lugar de dos palabras independientes. Un tercer tipo de errores ocurre en consultas largas. Para la consulta de software lector de códigos de barras, se pluralizan dos palabras. Códigos y lector. De hecho, el lector de códigos de barras en la consulta original es un concepto sólido y las palabras internas no deben ser cambiadas. Este es el problema de segmentación y detección de entidades y frases nominales en consultas, el cual estamos abordando activamente. Para consultas largas, debemos identificar correctamente los conceptos en la consulta y aumentar la proximidad de las palabras dentro de un concepto. 6. CONCLUSIONES Y TRABAJOS FUTUROS Hemos presentado una forma simple pero elegante de derivar palabras para la búsqueda en la web. Mejora el stemming ingenuo en dos aspectos: la expansión selectiva de palabras en el lado de la consulta y la coincidencia conservadora de ocurrencias de palabras en el lado del documento. Usando el manejo de pluralización como ejemplo, experimentos con datos de un motor de búsqueda web importante muestran que mejora significativamente la relevancia web y reduce el costo de derivación. También mejora significativamente la tasa de clics en la web (detalles no reportados en el artículo). Para el trabajo futuro, estamos investigando los problemas que identificamos en la sección de análisis de errores. Estos incluyen: errores de concordancia entre entidades y frases nominales, y una segmentación mejorada. 7. REFERENCIAS [1] E. Agichtein, E. Brill y S. T. Dumais. Mejorando la clasificación de búsqueda web al incorporar información sobre el comportamiento del usuario. En SIGIR, 2006. [2] E. Airio. Normalización de palabras y descomposición en IR monolingüe y bilingüe. Recuperación de información, 9:249-271, 2006. [3] P. Anick. Utilizando retroalimentación terminológica para el refinamiento de la búsqueda web: un estudio basado en registros. En SIGIR, 2003. [4] R. Baeza-Yates y B. Ribeiro-Neto. Recuperación de información moderna. ACM Press/Addison Wesley, 1999. [5] S. Chen y J. Goodman. Un estudio empírico de técnicas de suavizado para modelado del lenguaje. Informe técnico TR-10-98, Universidad de Harvard, 1998. [6] S. Cronen-Townsend, Y. Zhou y B. Croft. Un marco para la expansión selectiva de consultas. En CIKM, 2004. [7] H. Fang y C. Zhai. Coincidencia de términos semánticos en enfoques axiomáticos para la recuperación de información. En SIGIR, 2006. [8] W. B. Frakes. Confluencia de términos para la recuperación de información. En C. J. Rijsbergen, editor, Investigación y Desarrollo en Recuperación de Información, páginas 383-389. Cambridge University Press, 1984. [9] D. Harman.\nCambridge University Press, 1984. [9] D. Harman. ¿Qué tan efectivo es el sufijado? JASIS, 42(1):7-15, 1991. [10] D. Hull.\nJASIS, 42(1):7-15, 1991. [10] D. Hull. Algoritmos de derivación: un estudio de caso para una evaluación detallada. JASIS, 47(1):70-84, 1996. [11] K. Jarvelin y J. Kekalainen. Evaluación basada en la ganancia acumulada de técnicas de RI. ACM TOIS, 20:422-446, 2002. [12] R. Jones, B. Rey, O. Madani y W. Greiner. Generando Sustituciones de Consultas. En WWW, 2006. [13] W. Kraaij y R. Pohlmann. Viendo el Stemming como Mejora de la Recuperación. En SIGIR, 1996. [14] R. Krovetz. Viendo la morfología como un proceso de inferencia. En SIGIR, 1993. [15] D. Lin. Recuperación automática y agrupamiento de palabras similares. En COLING-ACL, 1998. [16] J. B. Lovins. Desarrollo de un algoritmo de derivación. Traducción Mecánica y Lingüística Computacional, II:22-31, 1968. [17] M. Lennon, D. Peirce, B. Tarry y P. Willett. Una evaluación de algunos algoritmos de confluencia para la recuperación de información. Revista de Ciencia de la Información, 3:177-188, 1981. [18] M. Porter. Un algoritmo para el recorte de sufijos. Programa, 14(3):130-137, 1980. [19] K. M. Risvik, T. Mikolajewski y P. Boros. Segmentación de consultas para búsqueda web. En WWW, 2003. [20] S. E. Robertson. Selección de términos para la expansión de consultas. Revista de Documentación, 46(4):359-364, 1990. [21] G. Salton y C. Buckley. Mejorando el rendimiento de recuperación mediante retroalimentación de relevancia. JASIS, 41(4):288 - 297, 1999. [22] R. Sun, C.-H. Ong, y T.-S. Chua. Extracción de relaciones de dependencia para la expansión de consultas en la recuperación de pasajes. En SIGIR, 2006. [23] C. Van Rijsbergen. Recuperación de información. Butterworths, segunda versión, 1979. [24] B. Vélez, R. Weiss, M. A. Sheldon y D. K. Gifford. Refinamiento de consultas rápido y efectivo. En SIGIR, 1997. [25] J. Xu y B. Croft. Expansión de consultas utilizando análisis local y global de documentos. En SIGIR, 1996. [26] J. Xu y B. Croft. Extracción de raíces basada en corpus utilizando la coocurrencia de variantes de palabras. ACM TOIS, 16 (1):61-81, 1998. ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "bigram language model": {
            "translated_key": "modelo de lenguaje de bigrama",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Context Sensitive Stemming for Web Search Fuchun Peng Nawaaz Ahmed Xin Li Yumao Lu Yahoo!",
                "Inc. 701 First Avenue Sunnyvale, California 94089 {fuchun, nawaaz, xinli, yumaol}@yahoo-inc.com ABSTRACT Traditionally, stemming has been applied to Information Retrieval tasks by transforming words in documents to the their root form before indexing, and applying a similar transformation to query terms.",
                "Although it increases recall, this naive strategy does not work well for Web Search since it lowers precision and requires a significant amount of additional computation.",
                "In this paper, we propose a context sensitive stemming method that addresses these two issues.",
                "Two unique properties make our approach feasible for Web Search.",
                "First, based on statistical language modeling, we perform context sensitive analysis on the query side.",
                "We accurately predict which of its morphological variants is useful to expand a query term with before submitting the query to the search engine.",
                "This dramatically reduces the number of bad expansions, which in turn reduces the cost of additional computation and improves the precision at the same time.",
                "Second, our approach performs a context sensitive document matching for those expanded variants.",
                "This conservative strategy serves as a safeguard against spurious stemming, and it turns out to be very important for improving precision.",
                "Using word pluralization handling as an example of our stemming approach, our experiments on a major Web search engine show that stemming only 29% of the query traffic, we can improve relevance as measured by average Discounted Cumulative Gain (DCG5) by 6.1% on these queries and 1.8% over all query traffic.",
                "Categories and Subject Descriptors H.3.3 [Information Systems]: Information Storage and Retrieval-Query formulation General Terms Algorithms, Experimentation 1.",
                "INTRODUCTION Web search has now become a major tool in our daily lives for information seeking.",
                "One of the important issues in Web search is that user queries are often not best formulated to get optimal results.",
                "For example, running shoe is a query that occurs frequently in query logs.",
                "However, the query running shoes is much more likely to give better search results than the original query because documents matching the intent of this query usually contain the words running shoes.",
                "Correctly formulating a query requires the user to accurately predict which word form is used in the documents that best satisfy his or her information needs.",
                "This is difficult even for experienced users, and especially difficult for non-native speakers.",
                "One traditional solution is to use stemming [16, 18], the process of transforming inflected or derived words to their root form so that a search term will match and retrieve documents containing all forms of the term.",
                "Thus, the word run will match running, ran, runs, and shoe will match shoes and shoeing.",
                "Stemming can be done either on the terms in a document during indexing (and applying the same transformation to the query terms during query processing) or by expanding the query with the variants during query processing.",
                "Stemming during indexing allows very little flexibility during query processing, while stemming by query expansion allows handling each query differently, and hence is preferred.",
                "Although traditional stemming increases recall by matching word variants [13], it can reduce precision by retrieving too many documents that have been incorrectly matched.",
                "When examining the results of applying stemming to a large number of queries, one usually finds that nearly equal numbers of queries are helped and hurt by the technique [6].",
                "In addition, it reduces system performance because the search engine has to match all the word variants.",
                "As we will show in the experiments, this is true even if we simplify stemming to pluralization handling, which is the process of converting a word from its plural to singular form, or vice versa.",
                "Thus, one needs to be very cautious when using stemming in Web search engines.",
                "One problem of traditional stemming is its blind transformation of all query terms, that is, it always performs the same transformation for the same query word without considering the context of the word.",
                "For example, the word book has four forms book, books, booking, booked, and store has four forms store, stores, storing, stored.",
                "For the query book store, expanding both words to all of their variants significantly increases computation cost and hurts precision, since not all of the variants are useful for this query.",
                "Transforming book store to match book stores is fine, but matching book storing or booking store is not.",
                "A weighting method that gives variant words smaller weights alleviates the problems to a certain extent if the weights accurately reflect the importance of the variant in this particular query.",
                "However uniform weighting is not going to work and a query dependent weighting is still a challenging unsolved problem [20].",
                "A second problem of traditional stemming is its blind matching of all occurrences in documents.",
                "For the query book store, a transformation that allows the variant stores to be matched will cause every occurrence of stores in the document to be treated equivalent to the query term store.",
                "Thus, a document containing the fragment reading a book in coffee stores will be matched, causing many wrong documents to be selected.",
                "Although we hope the ranking function can correctly handle these, with many more candidates to rank, the risk of making mistakes increases.",
                "To alleviate these two problems, we propose a context sensitive stemming approach for Web search.",
                "Our solution consists of two context sensitive analysis, one on the query side and the other on the document side.",
                "On the query side, we propose a statistical language modeling based approach to predict which word variants are better forms than the original word for search purpose and expanding the query with only those forms.",
                "On the document side, we propose a conservative context sensitive matching for the transformed word variants, only matching document occurrences in the context of other terms in the query.",
                "Our model is simple yet effective and efficient, making it feasible to be used in real commercial Web search engines.",
                "We use pluralization handling as a running example for our stemming approach.",
                "The motivation for using pluralization handling as an example is to show that even such simple stemming, if handled correctly, can give significant benefits to search relevance.",
                "As far as we know, no previous research has systematically investigated the usage of pluralization in Web search.",
                "As we have to point out, the method we propose is not limited to pluralization handling, it is a general stemming technique, and can also be applied to general query expansion.",
                "Experiments on general stemming yield additional significant improvements over pluralization handling for long queries, although details will not be reported in this paper.",
                "In the rest of the paper, we first present the related work and distinguish our method from previous work in Section 2.",
                "We describe the details of the context sensitive stemming approach in Section 3.",
                "We then perform extensive experiments on a major Web search engine to support our claims in Section 4, followed by discussions in Section 5.",
                "Finally, we conclude the paper in Section 6. 2.",
                "RELATED WORK Stemming is a long studied technology.",
                "Many stemmers have been developed, such as the Lovins stemmer [16] and the Porter stemmer [18].",
                "The Porter stemmer is widely used due to its simplicity and effectiveness in many applications.",
                "However, the Porter stemming makes many mistakes because its simple rules cannot fully describe English morphology.",
                "Corpus analysis is used to improve Porter stemmer [26] by creating equivalence classes for words that are morphologically similar and occur in similar context as measured by expected mutual information [23].",
                "We use a similar corpus based approach for stemming by computing the similarity between two words based on their distributional context features which can be more than just adjacent words [15], and then only keep the morphologically similar words as candidates.",
                "Using stemming in information retrieval is also a well known technique [8, 10].",
                "However, the effectiveness of stemming for English query systems was previously reported to be rather limited.",
                "Lennon et al. [17] compared the Lovins and Porter algorithms and found little improvement in retrieval performance.",
                "Later, Harman [9] compares three general stemming techniques in text retrieval experiments including pluralization handing (called S stemmer in the paper).",
                "They also proposed selective stemming based on query length and term importance, but no positive results were reported.",
                "On the other hand, Krovetz [14] performed comparisons over small numbers of documents (from 400 to 12k) and showed dramatic precision improvement (up to 45%).",
                "However, due to the limited number of tested queries (less than 100) and the small size of the collection, the results are hard to generalize to Web search.",
                "These mixed results, mostly failures, led early IR researchers to deem stemming irrelevant in general for English [4], although recent research has shown stemming has greater benefits for retrieval in other languages [2].",
                "We suspect the previous failures were mainly due to the two problems we mentioned in the introduction.",
                "Blind stemming, or a simple query length based selective stemming as used in [9] is not enough.",
                "Stemming has to be decided on case by case basis, not only at the query level but also at the document level.",
                "As we will show, if handled correctly, significant improvement can be achieved.",
                "A more general problem related to stemming is query reformulation [3, 12] and query expansion which expands words not only with word variants [7, 22, 24, 25].",
                "To decide which expanded words to use, people often use pseudorelevance feedback techniquesthat send the original query to a search engine and retrieve the top documents, extract relevant words from these top documents as additional query words, and resubmit the expanded query again [21].",
                "This normally requires sending a query multiple times to search engine and it is not cost effective for processing the huge amount of queries involved in Web search.",
                "In addition, query expansion, including query reformulation [3, 12], has a high risk of changing the user intent (called query drift).",
                "Since the expanded words may have different meanings, adding them to the query could potentially change the intent of the original query.",
                "Thus query expansion based on pseudorelevance and query reformulation can provide suggestions to users for interactive refinement but can hardly be directly used for Web search.",
                "On the other hand, stemming is much more conservative since most of the time, stemming preserves the original search intent.",
                "While most work on query expansion focuses on recall enhancement, our work focuses on increasing both recall and precision.",
                "The increase on recall is obvious.",
                "With quality stemming, good documents which were not selected before stemming will be pushed up and those low quality documents will be degraded.",
                "On selective query expansion, Cronen-Townsend et al. [6] proposed a method for selective query expansion based on comparing the Kullback-Leibler divergence of the results from the unexpanded query and the results from the expanded query.",
                "This is similar to the relevance feedback in the sense that it requires multiple passes retrieval.",
                "If a word can be expanded into several words, it requires running this process multiple times to decide which expanded word is useful.",
                "It is expensive to deploy this in production Web search engines.",
                "Our method predicts the quality of expansion based on oﬄine information without sending the query to a search engine.",
                "In summary, we propose a novel approach to attack an old, yet still important and challenging problem for Web search - stemming.",
                "Our approach is unique in that it performs predictive stemming on a per query basis without relevance feedback from the Web, using the context of the variants in documents to preserve precision.",
                "Its simple, yet very efficient and effective, making real time stemming feasible for Web search.",
                "Our results will affirm researchers that stemming is indeed very important to large scale information retrieval. 3.",
                "CONTEXT SENSITIVE STEMMING 3.1 Overview Our system has four components as illustrated in Figure 1: candidate generation, query segmentation and head word detection, context sensitive query stemming and context sensitive document matching.",
                "Candidate generation (component 1) is performed oﬄine and generated candidates are stored in a dictionary.",
                "For an input query, we first segment query into concepts and detect the head word for each concept (component 2).",
                "We then use statistical language modeling to decide whether a particular variant is useful (component 3), and finally for the expanded variants, we perform context sensitive document matching (component 4).",
                "Below we discuss each of the components in more detail.",
                "Component 4: context sensitive document matching Input Query: and head word detection Component 2: segment Component 1: candidate generation comparisons −> comparison Component 3: selective word expansion decision: comparisons −> comparison example: hotel price comparisons output: hotel comparisons hotel −> hotels Figure 1: System Components 3.2 Expansion candidate generation One of the ways to generate candidates is using the Porter stemmer [18].",
                "The Porter stemmer simply uses morphological rules to convert a word to its base form.",
                "It has no knowledge of the semantic meaning of the words and sometimes makes serious mistakes, such as executive to execution, news to new, and paste to past.",
                "A more conservative way is based on using corpus analysis to improve the Porter stemmer results [26].",
                "The corpus analysis we do is based on word distributional similarity [15].",
                "The rationale of using distributional word similarity is that true variants tend to be used in similar contexts.",
                "In the distributional word similarity calculation, each word is represented with a vector of features derived from the context of the word.",
                "We use the bigrams to the left and right of the word as its context features, by mining a huge Web corpus.",
                "The similarity between two words is the cosine similarity between the two corresponding feature vectors.",
                "The top 20 similar words to develop is shown in the following table. rank candidate score rank candidate score 0 develop 1 10 berts 0.119 1 developing 0.339 11 wads 0.116 2 developed 0.176 12 developer 0.107 3 incubator 0.160 13 promoting 0.100 4 develops 0.150 14 developmental 0.091 5 development 0.148 15 reengineering 0.090 6 tutoring 0.138 16 build 0.083 7 analyzing 0.128 17 construct 0.081 8 developement 0.128 18 educational 0.081 9 automation 0.126 19 institute 0.077 Table 1: Top 20 most similar candidates to word develop.",
                "Column score is the similarity score.",
                "To determine the stemming candidates, we apply a few Porter stemmer [18] morphological rules to the similarity list.",
                "After applying these rules, for the word develop, the stemming candidates are developing, developed, develops, development, developement, developer, developmental.",
                "For the pluralization handling purpose, only the candidate develops is retained.",
                "One thing we note from observing the distributionally similar words is that they are closely related semantically.",
                "These words might serve as candidates for general query expansion, a topic we will investigate in the future. 3.3 Segmentation and headword identification For long queries, it is quite important to detect the concepts in the query and the most important words for those concepts.",
                "We first break a query into segments, each segment representing a concept which normally is a noun phrase.",
                "For each of the noun phrases, we then detect the most important word which we call the head word.",
                "Segmentation is also used in document sensitive matching (section 3.5) to enforce proximity.",
                "To break a query into segments, we have to define a criteria to measure the strength of the relation between words.",
                "One effective method is to use mutual information as an indicator on whether or not to split two words [19].",
                "We use a log of 25M queries and collect the bigram and unigram frequencies from it.",
                "For every incoming query, we compute the mutual information of two adjacent words; if it passes a predefined threshold, we do not split the query between those two words and move on to next word.",
                "We continue this process until the mutual information between two words is below the threshold, then create a concept boundary here.",
                "Table 2 shows some examples of query segmentation.",
                "The ideal way of finding the head word of a concept is to do syntactic parsing to determine the dependency structure of the query.",
                "Query parsing is more difficult than sentence [running shoe] [best] [new york] [medical schools] [pictures] [of] [white house] [cookies] [in] [san francisco] [hotel] [price comparison] Table 2: Query segmentation: a segment is bracketed. parsing since many queries are not grammatical and are very short.",
                "Applying a parser trained on sentences from documents to queries will have poor performance.",
                "In our solution, we just use simple heuristics rules, and it works very well in practice for English.",
                "For an English noun phrase, the head word is typically the last nonstop word, unless the phrase is of a particular pattern, like XYZ of/in/at/from UVW.",
                "In such cases, the head word is typically the last nonstop word of XYZ. 3.4 Context sensitive word expansion After detecting which words are the most important words to expand, we have to decide whether the expansions will be useful.",
                "Our statistics show that about half of the queries can be transformed by pluralization via naive stemming.",
                "Among this half, about 25% of the queries improve relevance when transformed, the majority (about 50%) do not change their top 5 results, and the remaining 25% perform worse.",
                "Thus, it is extremely important to identify which queries should not be stemmed for the purpose of maximizing relevance improvement and minimizing stemming cost.",
                "In addition, for a query with multiple words that can be transformed, or a word with multiple variants, not all of the expansions are useful.",
                "Taking query hotel price comparison as an example, we decide that hotel and price comparison are two concepts.",
                "Head words hotel and comparison can be expanded to hotels and comparisons.",
                "Are both transformations useful?",
                "To test whether an expansion is useful, we have to know whether the expanded query is likely to get more relevant documents from the Web, which can be quantified by the probability of the query occurring as a string on the Web.",
                "The more likely a query to occur on the Web, the more relevant documents this query is able to return.",
                "Now the whole problem becomes how to calculate the probability of query to occur on the Web.",
                "Calculating the probability of string occurring in a corpus is a well known language modeling problem.",
                "The goal of language modeling is to predict the probability of naturally occurring word sequences, s = w1w2...wN ; or more simply, to put high probability on word sequences that actually occur (and low probability on word sequences that never occur).",
                "The simplest and most successful approach to language modeling is still based on the n-gram model.",
                "By the chain rule of probability one can write the probability of any word sequence as Pr(w1w2...wN ) = NY i=1 Pr(wi|w1...wi−1) (1) An n-gram model approximates this probability by assuming that the only words relevant to predicting Pr(wi|w1...wi−1) are the previous n − 1 words; i.e.",
                "Pr(wi|w1...wi−1) = Pr(wi|wi−n+1...wi−1) A straightforward maximum likelihood estimate of n-gram probabilities from a corpus is given by the observed frequency of each of the patterns Pr(wi|wi−n+1...wi−1) = #(wi−n+1...wi) #(wi−n+1...wi−1) (2) where #(.) denotes the number of occurrences of a specified gram in the training corpus.",
                "Although one could attempt to use simple n-gram models to capture long range dependencies in language, attempting to do so directly immediately creates sparse data problems: Using grams of length up to n entails estimating the probability of Wn events, where W is the size of the word vocabulary.",
                "This quickly overwhelms modern computational and data resources for even modest choices of n (beyond 3 to 6).",
                "Also, because of the heavy tailed nature of language (i.e.",
                "Zipfs law) one is likely to encounter novel n-grams that were never witnessed during training in any test corpus, and therefore some mechanism for assigning non-zero probability to novel n-grams is a central and unavoidable issue in statistical language modeling.",
                "One standard approach to smoothing probability estimates to cope with sparse data problems (and to cope with potentially missing n-grams) is to use some sort of back-off estimator.",
                "Pr(wi|wi−n+1...wi−1) = 8 >>< >>: ˆPr(wi|wi−n+1...wi−1), if #(wi−n+1...wi) > 0 β(wi−n+1...wi−1) × Pr(wi|wi−n+2...wi−1), otherwise (3) where ˆPr(wi|wi−n+1...wi−1) = discount #(wi−n+1...wi) #(wi−n+1...wi−1) (4) is the discounted probability and β(wi−n+1...wi−1) is a normalization constant β(wi−n+1...wi−1) = 1 − X x∈(wi−n+1...wi−1x) ˆPr(x|wi−n+1...wi−1) 1 − X x∈(wi−n+1...wi−1x) ˆPr(x|wi−n+2...wi−1) (5) The discounted probability (4) can be computed with different smoothing techniques, including absolute smoothing, Good-Turing smoothing, linear smoothing, and Witten-Bell smoothing [5].",
                "We used absolute smoothing in our experiments.",
                "Since the likelihood of a string, Pr(w1w2...wN ), is a very small number and hard to interpret, we use entropy as defined below to score the string.",
                "Entropy = − 1 N log2 Pr(w1w2...wN ) (6) Now getting back to the example of the query hotel price comparisons, there are four variants of this query, and the entropy of these four candidates are shown in Table 3.",
                "We can see that all alternatives are less likely than the input query.",
                "It is therefore not useful to make an expansion for this query.",
                "On the other hand, if the input query is hotel price comparisons which is the second alternative in the table, then there is a better alternative than the input query, and it should therefore be expanded.",
                "To tolerate the variations in probability estimation, we relax the selection criterion to those query alternatives if their scores are within a certain distance (10% in our experiments) to the best score.",
                "Query variations Entropy hotel price comparison 6.177 hotel price comparisons 6.597 hotels price comparison 6.937 hotels price comparisons 7.360 Table 3: Variations of query hotel price comparison ranked by entropy score, with the original query in bold face. 3.5 Context sensitive document matching Even after we know which word variants are likely to be useful, we have to be conservative in document matching for the expanded variants.",
                "For the query hotel price comparisons, we decided that word comparisons is expanded to include comparison.",
                "However, not every occurrence of comparison in the document is of interest.",
                "A page which is about comparing customer service can contain all of the words hotel price comparisons comparison.",
                "This page is not a good page for the query.",
                "If we accept matches of every occurrence of comparison, it will hurt retrieval precision and this is one of the main reasons why most stemming approaches do not work well for information retrieval.",
                "To address this problem, we have a proximity constraint that considers the context around the expanded variant in the document.",
                "A variant match is considered valid only if the variant occurs in the same context as the original word does.",
                "The context is the left or the right non-stop segments 1 of the original word.",
                "Taking the same query as an example, the context of comparisons is price.",
                "The expanded word comparison is only valid if it is in the same context of comparisons, which is after the word price.",
                "Thus, we should only match those occurrences of comparison in the document if they occur after the word price.",
                "Considering the fact that queries and documents may not represent the intent in exactly the same way, we relax this proximity constraint to allow variant occurrences within a window of some fixed size.",
                "If the expanded word comparison occurs within the context of price within a window, it is considered valid.",
                "The smaller the window size is, the more restrictive the matching.",
                "We use a window size of 4, which typically captures contexts that include the containing and adjacent noun phrases. 4.",
                "EXPERIMENTAL EVALUATION 4.1 Evaluation metrics We will measure both relevance improvement and the stemming cost required to achieve the relevance. 1 a context segment can not be a single stop word. 4.1.1 Relevance measurement We use a variant of the average Discounted Cumulative Gain (DCG), a recently popularized scheme to measure search engine relevance [1, 11].",
                "Given a query and a ranked list of K documents (K is set to 5 in our experiments), the DCG(K) score for this query is calculated as follows: DCG(K) = KX k=1 gk log2(1 + k) . (7) where gk is the weight for the document at rank k. Higher degree of relevance corresponds to a higher weight.",
                "A page is graded into one of the five scales: Perfect, Excellent, Good, Fair, Bad, with corresponding weights.",
                "We use dcg to represent the average DCG(5) over a set of test queries. 4.1.2 Stemming cost Another metric is to measure the additional cost incurred by stemming.",
                "Given the same level of relevance improvement, we prefer a stemming method that has less additional cost.",
                "We measure this by the percentage of queries that are actually stemmed, over all the queries that could possibly be stemmed. 4.2 Data preparation We randomly sample 870 queries from a three month query log, with 290 from each month.",
                "Among all these 870 queries, we remove all misspelled queries since misspelled queries are not of interest to stemming.",
                "We also remove all one word queries since stemming one word queries without context has a high risk of changing query intent, especially for short words.",
                "In the end, we have 529 correctly spelled queries with at least 2 words. 4.3 Naive stemming for Web search Before explaining the experiments and results in detail, wed like to describe the traditional way of using stemming for Web search, referred as the naive model.",
                "This is to treat every word variant equivalent for all possible words in the query.",
                "The query book store will be transformed into (book OR books)(store OR stores) when limiting stemming to pluralization handling only, where OR is an operator that denotes the equivalence of the left and right arguments. 4.4 Experimental setup The baseline model is the model without stemming.",
                "We first run the naive model to see how well it performs over the baseline.",
                "Then we improve the naive stemming model by document sensitive matching, referred as document sensitive matching model.",
                "This model makes the same stemming as the naive model on the query side, but performs conservative matching on the document side using the strategy described in section 3.5.",
                "The naive model and document sensitive matching model stem the most queries.",
                "Out of the 529 queries, there are 408 queries that they stem, corresponding to 46.7% query traffic (out of a total of 870).",
                "We then further improve the document sensitive matching model from the query side with selective word stemming based on statistical language modeling (section 3.4), referred as selective stemming model.",
                "Based on language modeling prediction, this model stems only a subset of the 408 queries stemmed by the document sensitive matching model.",
                "We experiment with unigram language model and <br>bigram language model</br>.",
                "Since we only care how much we can improve the naive model, we will only use these 408 queries (all the queries that are affected by the naive stemming model) in the experiments.",
                "To get a sense of how these models perform, we also have an oracle model that gives the upper-bound performance a stemmer can achieve on this data.",
                "The oracle model only expands a word if the stemming will give better results.",
                "To analyze the pluralization handling influence on different query categories, we divide queries into short queries and long queries.",
                "Among the 408 queries stemmed by the naive model, there are 272 short queries with 2 or 3 words, and 136 long queries with at least 4 words. 4.5 Results We summarize the overall results in Table 4, and present the results on short queries and long queries separately in Table 5.",
                "Each row in Table 4 is a stemming strategy described in section 4.4.",
                "The first column is the name of the strategy.",
                "The second column is the number of queries affected by this strategy; this column measures the stemming cost, and the numbers should be low for the same level of dcg.",
                "The third column is the average dcg score over all tested queries in this category (including the ones that were not stemmed by the strategy).",
                "The fourth column is the relative improvement over the baseline, and the last column is the p-value of Wilcoxon significance test.",
                "There are several observations about the results.",
                "We can see the naively stemming only obtains a statistically insignificant improvement of 1.5%.",
                "Looking at Table 5, it gives an improvement of 2.7% on short queries.",
                "However, it also hurts long queries by -2.4%.",
                "Overall, the improvement is canceled out.",
                "The reason that it improves short queries is that most short queries only have one word that can be stemmed.",
                "Thus, blindly pluralizing short queries is relatively safe.",
                "However for long queries, most queries can have multiple words that can be pluralized.",
                "Expanding all of them without selection will significantly hurt precision.",
                "Document context sensitive stemming gives a significant lift to the performance, from 2.7% to 4.2% for short queries and from -2.4% to -1.6% for long queries, with an overall lift from 1.5% to 2.8%.",
                "The improvement comes from the conservative context sensitive document matching.",
                "An expanded word is valid only if it occurs within the context of original query in the document.",
                "This reduces many spurious matches.",
                "However, we still notice that for long queries, context sensitive stemming is not able to improve performance because it still selects too many documents and gives the ranking function a hard problem.",
                "While the chosen window size of 4 works the best amongst all the choices, it still allows spurious matches.",
                "It is possible that the window size needs to be chosen on a per query basis to ensure tighter proximity constraints for different types of noun phrases.",
                "Selective word pluralization further helps resolving the problem faced by document context sensitive stemming.",
                "It does not stem every word that places all the burden on the ranking algorithm, but tries to eliminate unnecessary stemming in the first place.",
                "By predicting which word variants are going to be useful, we can dramatically reduce the number of stemmed words, thus improving both the recall and the precision.",
                "With the unigram language model, we can reduce the stemming cost by 26.7% (from 408/408 to 300/408) and lift the overall dcg improvement from 2.8% to 3.4%.",
                "In particular, it gives significant improvements on long queries.",
                "The dcg gain is turned from negative to positive, from −1.6% to 1.1%.",
                "This confirms our hypothesis that reducing unnecessary word expansion leads to precision improvement.",
                "For short queries too, we observe both dcg improvement and stemming cost reduction with the unigram language model.",
                "The advantages of predictive word expansion with a language model is further boosted with a better <br>bigram language model</br>.",
                "The overall dcg gain is lifted from 3.4% to 3.9%, and stemming cost is dramatically reduced from 408/408 to 250/408, corresponding to only 29% of query traffic (250 out of 870) and an overall 1.8% dcg improvement overall all query traffic.",
                "For short queries, <br>bigram language model</br> improves the dcg gain from 4.4% to 4.7%, and reduces stemming cost from 272/272 to 150/272.",
                "For long queries, <br>bigram language model</br> improves dcg gain from 1.1% to 2.5%, and reduces stemming cost from 136/136 to 100/136.",
                "We observe that the <br>bigram language model</br> gives a larger lift for long queries.",
                "This is because the uncertainty in long queries is larger and a more powerful language model is needed.",
                "We hypothesize that a trigram language model would give a further lift for long queries and leave this for future investigation.",
                "Considering the tight upper-bound 2 on the improvement to be gained from pluralization handling (via the oracle model), the current performance on short queries is very satisfying.",
                "For short queries, the dcg gain upper-bound is 6.3% for perfect pluralization handling, our current gain is 4.7% with a <br>bigram language model</br>.",
                "For long queries, the dcg gain upper-bound is 4.6% for perfect pluralization handling, our current gain is 2.5% with a <br>bigram language model</br>.",
                "We may gain additional benefit with a more powerful language model for long queries.",
                "However, the difficulties of long queries come from many other aspects including the proximity and the segmentation problem.",
                "These problems have to be addressed separately.",
                "Looking at the the upper-bound of overhead reduction for oracle stemming, 75% (308/408) of the naive stemmings are wasteful.",
                "We currently capture about half of them.",
                "Further reduction of the overhead requires sacrificing the dcg gain.",
                "Now we can compare the stemming strategies from a different aspect.",
                "Instead of looking at the influence over all queries as we described above, Table 6 summarizes the dcg improvements over the affected queries only.",
                "We can see that the number of affected queries decreases as the stemming strategy becomes more accurate (dcg improvement).",
                "For the <br>bigram language model</br>, over the 250/408 stemmed queries, the dcg improvement is 6.1%.",
                "An interesting observation is the average dcg decreases with a better model, which indicates a better stemming strategy stems more difficult queries (low dcg queries). 5.",
                "DISCUSSIONS 5.1 Language models from query vs. from Web As we mentioned in Section 1, we are trying to predict the probability of a string occurring on the Web.",
                "The language model should describe the occurrence of the string on the Web.",
                "However, the query log is also a good resource. 2 Note that this upperbound is for pluralization handling only, not for general stemming.",
                "General stemming gives a 8% upperbound, which is quite substantial in terms of our metrics.",
                "Affected Queries dcg dcg Improvement p-value baseline 0/408 7.102 N/A N/A naive model 408/408 7.206 1.5% 0.22 document context sensitive model 408/408 7.302 2.8% 0.014 selective model: unigram LM 300/408 7.321 3.4% 0.001 selective model: bigram LM 250/408 7.381 3.9% 0.001 oracle model 100/408 7.519 5.9% 0.001 Table 4: Results comparison of different stemming strategies over all queries affected by naive stemming Short Query Results Affected Queries dcg Improvement p-value baseline 0/272 N/A N/A naive model 272/272 2.7% 0.48 document context sensitive model 272/272 4.2% 0.002 selective model: unigram LM 185/272 4.4% 0.001 selective model: bigram LM 150/272 4.7% 0.001 oracle model 71/272 6.3% 0.001 Long Query Results Affected Queries dcg Improvement p-value baseline 0/136 N/A N/A naive model 136/136 -2.4% 0.25 document context sensitive model 136/136 -1.6% 0.27 selective model: unigram LM 115/136 1.1% 0.001 selective model: bigram LM 100/136 2.5% 0.001 oracle model 29/136 4.6% 0.001 Table 5: Results comparison of different stemming strategies overall short queries and long queries Users reformulate a query using many different variants to get good results.",
                "To test the hypothesis that we can learn reliable transformation probabilities from the query log, we trained a language model from the same query top 25M queries as used to learn segmentation, and use that for prediction.",
                "We observed a slight performance decrease compared to the model trained on Web frequencies.",
                "In particular, the performance for unigram LM was not affected, but the dcg gain for bigram LM changed from 4.7% to 4.5% for short queries.",
                "Thus, the query log can serve as a good approximation of the Web frequencies. 5.2 How linguistics helps Some linguistic knowledge is useful in stemming.",
                "For the pluralization handling case, pluralization and de-pluralization is not symmetric.",
                "A plural word used in a query indicates a special intent.",
                "For example, the query new york hotels is looking for a list of hotels in new york, not the specific new york hotel which might be a hotel located in California.",
                "A simple equivalence of hotel to hotels might boost a particular page about new york hotel to top rank.",
                "To capture this intent, we have to make sure the document is a general page about hotels in new york.",
                "We do this by requiring that the plural word hotels appears in the document.",
                "On the other hand, converting a singular word to plural is safer since a general purpose page normally contains specific information.",
                "We observed a slight overall dcg decrease, although not statistically significant, for document context sensitive stemming if we do not consider this asymmetric property. 5.3 Error analysis One type of mistakes we noticed, though rare but seriously hurting relevance, is the search intent change after stemming.",
                "Generally speaking, pluralization or depluralization keeps the original intent.",
                "However, the intent could change in a few cases.",
                "For one example of such a query, job at apple, we pluralize job to jobs.",
                "This stemming makes the original query ambiguous.",
                "The query job OR jobs at apple has two intents.",
                "One is the employment opportunities at apple, and another is a person working at Apple, Steve Jobs, who is the CEO and co-founder of the company.",
                "Thus, the results after query stemming returns Steve Jobs as one of the results in top 5.",
                "One solution is performing results set based analysis to check if the intent is changed.",
                "This is similar to relevance feedback and requires second phase ranking.",
                "A second type of mistakes is the entity/concept recognition problem, These include two kinds.",
                "One is that the stemmed word variant now matches part of an entity or concept.",
                "For example, query cookies in san francisco is pluralized to cookies OR cookie in san francisco.",
                "The results will match cookie jar in san francisco.",
                "Although cookie still means the same thing as cookies, cookie jar is a different concept.",
                "Another kind is the unstemmed word matches an entity or concept because of the stemming of the other words.",
                "For example, quote ICE is pluralized to quote OR quotes ICE.",
                "The original intent for this query is searching for stock quote for ticker ICE.",
                "However, we noticed that among the top results, one of the results is Food quotes: Ice cream.",
                "This is matched because of Affected Queries old dcg new dcg dcg Improvement naive model 408/408 7.102 7.206 1.5% document context sensitive model 408/408 7.102 7.302 2.8% selective model: unigram LM 300/408 5.904 6.187 4.8% selective model: bigram LM 250/408 5.551 5.891 6.1% Table 6: Results comparison over the stemmed queries only: column old/new dcg is the dcg score over the affected queries before/after applying stemming the pluralized word quotes.",
                "The unchanged word ICE matches part of the noun phrase ice cream here.",
                "To solve this kind of problem, we have to analyze the documents and recognize cookie jar and ice cream as concepts instead of two independent words.",
                "A third type of mistakes occurs in long queries.",
                "For the query bar code reader software, two words are pluralized. code to codes and reader to readers.",
                "In fact, bar code reader in the original query is a strong concept and the internal words should not be changed.",
                "This is the segmentation and entity and noun phrase detection problem in queries, which we actively are attacking.",
                "For long queries, we should correctly identify the concepts in the query, and boost the proximity for the words within a concept. 6.",
                "CONCLUSIONS AND FUTURE WORK We have presented a simple yet elegant way of stemming for Web search.",
                "It improves naive stemming in two aspects: selective word expansion on the query side and conservative word occurrence matching on the document side.",
                "Using pluralization handling as an example, experiments on a major Web search engine data show it significantly improves the Web relevance and reduces the stemming cost.",
                "It also significantly improves Web click through rate (details not reported in the paper).",
                "For the future work, we are investigating the problems we identified in the error analysis section.",
                "These include: entity and noun phrase matching mistakes, and improved segmentation. 7.",
                "REFERENCES [1] E. Agichtein, E. Brill, and S. T. Dumais.",
                "Improving Web Search Ranking by Incorporating User Behavior Information.",
                "In SIGIR, 2006. [2] E. Airio.",
                "Word Normalization and Decompounding in Mono- and Bilingual IR.",
                "Information Retrieval, 9:249-271, 2006. [3] P. Anick.",
                "Using Terminological Feedback for Web Search Refinement: a Log-based Study.",
                "In SIGIR, 2003. [4] R. Baeza-Yates and B. Ribeiro-Neto.",
                "Modern Information Retrieval.",
                "ACM Press/Addison Wesley, 1999. [5] S. Chen and J. Goodman.",
                "An Empirical Study of Smoothing Techniques for Language Modeling.",
                "Technical Report TR-10-98, Harvard University, 1998. [6] S. Cronen-Townsend, Y. Zhou, and B. Croft.",
                "A Framework for Selective Query Expansion.",
                "In CIKM, 2004. [7] H. Fang and C. Zhai.",
                "Semantic Term Matching in Axiomatic Approaches to Information Retrieval.",
                "In SIGIR, 2006. [8] W. B. Frakes.",
                "Term Conflation for Information Retrieval.",
                "In C. J. Rijsbergen, editor, Research and Development in Information Retrieval, pages 383-389.",
                "Cambridge University Press, 1984. [9] D. Harman.",
                "How Effective is Suffixing?",
                "JASIS, 42(1):7-15, 1991. [10] D. Hull.",
                "Stemming Algorithms - A Case Study for Detailed Evaluation.",
                "JASIS, 47(1):70-84, 1996. [11] K. Jarvelin and J. Kekalainen.",
                "Cumulated Gain-Based Evaluation Evaluation of IR Techniques.",
                "ACM TOIS, 20:422-446, 2002. [12] R. Jones, B. Rey, O. Madani, and W. Greiner.",
                "Generating Query Substitutions.",
                "In WWW, 2006. [13] W. Kraaij and R. Pohlmann.",
                "Viewing Stemming as Recall Enhancement.",
                "In SIGIR, 1996. [14] R. Krovetz.",
                "Viewing Morphology as an Inference Process.",
                "In SIGIR, 1993. [15] D. Lin.",
                "Automatic Retrieval and Clustering of Similar Words.",
                "In COLING-ACL, 1998. [16] J.",
                "B. Lovins.",
                "Development of a Stemming Algorithm.",
                "Mechanical Translation and Computational Linguistics, II:22-31, 1968. [17] M. Lennon and D. Peirce and B. Tarry and P. Willett.",
                "An Evaluation of Some Conflation Algorithms for Information Retrieval.",
                "Journal of Information Science, 3:177-188, 1981. [18] M. Porter.",
                "An Algorithm for Suffix Stripping.",
                "Program, 14(3):130-137, 1980. [19] K. M. Risvik, T. Mikolajewski, and P. Boros.",
                "Query Segmentation for Web Search.",
                "In WWW, 2003. [20] S. E. Robertson.",
                "On Term Selection for Query Expansion.",
                "Journal of Documentation, 46(4):359-364, 1990. [21] G. Salton and C. Buckley.",
                "Improving Retrieval Performance by Relevance Feedback.",
                "JASIS, 41(4):288 - 297, 1999. [22] R. Sun, C.-H. Ong, and T.-S. Chua.",
                "Mining Dependency Relations for Query Expansion in Passage Retrieval.",
                "In SIGIR, 2006. [23] C. Van Rijsbergen.",
                "Information Retrieval.",
                "Butterworths, second version, 1979. [24] B. V´elez, R. Weiss, M. A. Sheldon, and D. K. Gifford.",
                "Fast and Effective Query Refinement.",
                "In SIGIR, 1997. [25] J. Xu and B. Croft.",
                "Query Expansion using Local and Global Document Analysis.",
                "In SIGIR, 1996. [26] J. Xu and B. Croft.",
                "Corpus-based Stemming using Cooccurrence of Word Variants.",
                "ACM TOIS, 16 (1):61-81, 1998."
            ],
            "original_annotated_samples": [
                "We experiment with unigram language model and <br>bigram language model</br>.",
                "The advantages of predictive word expansion with a language model is further boosted with a better <br>bigram language model</br>.",
                "For short queries, <br>bigram language model</br> improves the dcg gain from 4.4% to 4.7%, and reduces stemming cost from 272/272 to 150/272.",
                "For long queries, <br>bigram language model</br> improves dcg gain from 1.1% to 2.5%, and reduces stemming cost from 136/136 to 100/136.",
                "We observe that the <br>bigram language model</br> gives a larger lift for long queries."
            ],
            "translated_annotated_samples": [
                "Experimentamos con un modelo de lenguaje unigrama y un <br>modelo de lenguaje bigrama</br>.",
                "Las ventajas de la expansión predictiva de palabras con un modelo de lenguaje se potencian aún más con un mejor <br>modelo de lenguaje de bigrama</br>.",
                "Para consultas cortas, el <br>modelo de lenguaje de bigrama</br> mejora la ganancia de DCG del 4.4% al 4.7%, y reduce el costo de derivación de 272/272 a 150/272.",
                "Para consultas largas, el <br>modelo de lenguaje de bigrama</br> mejora la ganancia de DCG del 1.1% al 2.5%, y reduce el costo de derivación de 136/136 a 100/136.",
                "Observamos que el <br>modelo de lenguaje de bigrama</br> proporciona un mayor aumento para consultas largas."
            ],
            "translated_text": "Stemming sensible al contexto para la búsqueda web Fuchun Peng Nawaaz Ahmed Xin Li Yumao Lu Yahoo! Tradicionalmente, el truncamiento se ha aplicado a tareas de Recuperación de Información transformando las palabras en documentos a su forma raíz antes de indexarlas, y aplicando una transformación similar a los términos de consulta. Aunque aumenta la recuperación, esta estrategia ingenua no funciona bien para la Búsqueda en la Web, ya que disminuye la precisión y requiere una cantidad significativa de cálculos adicionales. En este artículo, proponemos un método de derivación sensible al contexto que aborda estos dos problemas. Dos propiedades únicas hacen que nuestro enfoque sea factible para la Búsqueda en la Web. Primero, basados en modelado estadístico del lenguaje, realizamos un análisis sensible al contexto en el lado de la consulta. Predecimos con precisión cuál de sus variantes morfológicas es útil para expandir un término de consulta antes de enviar la consulta al motor de búsqueda. Esto reduce drásticamente la cantidad de expansiones incorrectas, lo que a su vez disminuye el costo de la computación adicional y mejora la precisión al mismo tiempo. Segundo, nuestro enfoque realiza una coincidencia de documentos sensible al contexto para esas variantes ampliadas. Esta estrategia conservadora sirve como salvaguarda contra el truncamiento espurio, y resulta ser muy importante para mejorar la precisión. Usando el manejo de la pluralización de palabras como un ejemplo de nuestro enfoque de derivación, nuestros experimentos en un importante motor de búsqueda web muestran que al derivar solo el 29% del tráfico de consultas, podemos mejorar la relevancia medida por la Ganancia Acumulativa Descontada promedio (DCG5) en un 6.1% en estas consultas y en un 1.8% sobre todo el tráfico de consultas. Categorías y Descriptores de Asignaturas H.3.3 [Sistemas de Información]: Almacenamiento y Recuperación de Información-Formulación de Consultas Términos Generales Algoritmos, Experimentación 1. INTRODUCCIÓN La búsqueda en la web se ha convertido en una herramienta importante en nuestra vida diaria para buscar información. Uno de los problemas importantes en la búsqueda web es que las consultas de los usuarios a menudo no están formuladas de la mejor manera para obtener resultados óptimos. Por ejemplo, \"zapatilla para correr\" es una consulta que ocurre con frecuencia en los registros de consulta. Sin embargo, es mucho más probable que la búsqueda \"zapatillas para correr\" proporcione mejores resultados de búsqueda que la consulta original, ya que los documentos que coinciden con la intención de esta consulta suelen contener las palabras \"zapatillas para correr\". Formular correctamente una consulta requiere que el usuario prediga con precisión qué forma de palabra se utiliza en los documentos que mejor satisfacen sus necesidades de información. Esto es difícil incluso para usuarios experimentados, y especialmente difícil para hablantes no nativos. Una solución tradicional es utilizar el stemming [16, 18], el proceso de transformar palabras flexionadas o derivadas a su forma raíz para que un término de búsqueda coincida y recupere documentos que contengan todas las formas del término. Por lo tanto, la palabra \"run\" coincidirá con \"running\", \"ran\", \"runs\", y \"shoe\" coincidirá con \"shoes\" y \"shoeing\". El truncamiento se puede realizar tanto en los términos de un documento durante la indexación (y aplicando la misma transformación a los términos de la consulta durante el procesamiento de la consulta) o expandiendo la consulta con las variantes durante el procesamiento de la consulta. El truncamiento durante la indexación permite muy poca flexibilidad durante el procesamiento de consultas, mientras que el truncamiento mediante la expansión de consultas permite manejar cada consulta de manera diferente, y por lo tanto es preferible. Aunque el truncamiento tradicional aumenta la recuperación al emparejar variantes de palabras [13], puede reducir la precisión al recuperar demasiados documentos que han sido emparejados incorrectamente. Al examinar los resultados de aplicar el truncamiento a un gran número de consultas, generalmente se encuentra que casi igual cantidad de consultas se benefician y se ven perjudicadas por la técnica [6]. Además, reduce el rendimiento del sistema porque el motor de búsqueda tiene que hacer coincidir todas las variantes de palabras. Como mostraremos en los experimentos, esto es cierto incluso si simplificamos el proceso de derivación a la manipulación de pluralización, que es el proceso de convertir una palabra de su forma plural a singular, o viceversa. Por lo tanto, es necesario ser muy cauteloso al utilizar el stemming en los motores de búsqueda web. Un problema del truncamiento tradicional es su transformación ciega de todos los términos de consulta, es decir, siempre realiza la misma transformación para la misma palabra de consulta sin considerar el contexto de la palabra. Por ejemplo, la palabra \"book\" tiene cuatro formas: book, books, booking, booked, y la palabra \"store\" tiene cuatro formas: store, stores, storing, stored. Para la consulta de la librería, expandir ambas palabras a todas sus variantes aumenta significativamente el costo de computación y perjudica la precisión, ya que no todas las variantes son útiles para esta consulta. Transformar librería para que coincida con librerías está bien, pero hacer coincidir almacenamiento de libros o tienda de reservas no lo está. Un método de ponderación que otorga pesos más pequeños a las palabras variantes alivia los problemas hasta cierto punto si los pesos reflejan con precisión la importancia de la variante en esta consulta particular. Sin embargo, el peso uniforme no va a funcionar y un peso dependiente de la consulta sigue siendo un problema desafiante sin resolver [20]. Un segundo problema del truncamiento tradicional es su emparejamiento ciego de todas las ocurrencias en los documentos. Para la consulta de la librería, una transformación que permita que las tiendas variantes se emparejen hará que cada aparición de tiendas en el documento se trate de manera equivalente al término de consulta tienda. Por lo tanto, se emparejará un documento que contenga el fragmento de leer un libro en las cafeterías, lo que provocará que se seleccionen muchos documentos incorrectos. Aunque esperamos que la función de clasificación pueda manejar correctamente estos, con muchos más candidatos para clasificar, el riesgo de cometer errores aumenta. Para aliviar estos dos problemas, proponemos un enfoque de reducción de palabras raíz sensible al contexto para la búsqueda en la web. Nuestra solución consiste en dos análisis contextuales sensibles, uno en el lado de la consulta y otro en el lado del documento. En el lado de la consulta, proponemos un enfoque basado en modelado del lenguaje estadístico para predecir qué variantes de palabras son mejores formas que la palabra original con fines de búsqueda y expandir la consulta solo con esas formas. En el lado del documento, proponemos un emparejamiento conservador sensible al contexto para las variantes de palabras transformadas, solo emparejando las ocurrencias en el documento en el contexto de otros términos en la consulta. Nuestro modelo es simple pero efectivo y eficiente, lo que lo hace factible de ser utilizado en motores de búsqueda web comerciales reales. Utilizamos el manejo de pluralización como un ejemplo continuo para nuestro enfoque de derivación. La motivación para usar el manejo de pluralización como ejemplo es mostrar que incluso un truncamiento tan simple, si se maneja correctamente, puede brindar beneficios significativos a la relevancia de la búsqueda. Hasta donde sabemos, ninguna investigación previa ha investigado sistemáticamente el uso de la pluralización en la búsqueda en la web. Como debemos señalar, el método que proponemos no se limita al manejo de la pluralización, es una técnica de derivación general y también se puede aplicar a la expansión de consultas en general. Los experimentos sobre el truncamiento general producen mejoras significativas adicionales sobre el manejo de la pluralización para consultas largas, aunque los detalles no se informarán en este artículo. En el resto del documento, primero presentamos el trabajo relacionado y distinguimos nuestro método de trabajos anteriores en la Sección 2. Describimos los detalles del enfoque de derivación sensible al contexto en la Sección 3. Luego realizamos experimentos extensos en un importante motor de búsqueda web para respaldar nuestras afirmaciones en la Sección 4, seguidos de discusiones en la Sección 5. Finalmente, concluimos el artículo en la Sección 6.2. TRABAJO RELACIONADO El stemming es una tecnología estudiada desde hace mucho tiempo. Se han desarrollado muchos stemmers, como el stemmer Lovins [16] y el stemmer Porter [18]. El stemmer de Porter es ampliamente utilizado debido a su simplicidad y efectividad en muchas aplicaciones. Sin embargo, el algoritmo de Porter comete muchos errores porque sus reglas simples no pueden describir completamente la morfología del inglés. El análisis de corpus se utiliza para mejorar el stemmer de Porter [26] mediante la creación de clases de equivalencia para palabras que son morfológicamente similares y que ocurren en un contexto similar, medido por la información mutua esperada [23]. Utilizamos un enfoque de corpus similar para el stemming al calcular la similitud entre dos palabras basada en sus características de contexto distribucional, que pueden ser más que solo palabras adyacentes [15], y luego solo mantenemos las palabras morfológicamente similares como candidatas. El uso de la derivación en la recuperación de información también es una técnica bien conocida [8, 10]. Sin embargo, se informó previamente que la efectividad del truncamiento para los sistemas de consulta en inglés era bastante limitada. Lennon et al. [17] compararon los algoritmos de Lovins y Porter y encontraron poco mejoramiento en el rendimiento de recuperación. Más tarde, Harman [9] compara tres técnicas generales de derivación en experimentos de recuperación de texto, incluido el manejo de pluralización (llamado S stemmer en el artículo). También propusieron el truncamiento selectivo basado en la longitud de la consulta y la importancia del término, pero no se informaron resultados positivos. Por otro lado, Krovetz [14] realizó comparaciones sobre un pequeño número de documentos (de 400 a 12k) y mostró una mejora dramática en la precisión (de hasta un 45%). Sin embargo, debido al número limitado de consultas probadas (menos de 100) y al tamaño reducido de la colección, los resultados son difíciles de generalizar para la búsqueda en la web. Estos resultados mixtos, en su mayoría fracasos, llevaron a los primeros investigadores de IR a considerar que el truncamiento era irrelevante en general para el inglés [4], aunque investigaciones recientes han demostrado que el truncamiento tiene mayores beneficios para la recuperación en otros idiomas [2]. Sospechamos que los fracasos anteriores se debieron principalmente a los dos problemas que mencionamos en la introducción. El stemming ciego, o un stemming selectivo basado en la longitud de la consulta como se utiliza en [9], no es suficiente. El truncamiento debe decidirse caso por caso, no solo a nivel de consulta sino también a nivel de documento. Como demostraremos, si se maneja correctamente, se puede lograr una mejora significativa. Un problema más general relacionado con el stemming es la reformulación de consultas [3, 12] y la expansión de consultas que amplía las palabras no solo con variantes de palabras [7, 22, 24, 25]. Para decidir qué palabras expandidas usar, las personas a menudo utilizan técnicas de retroalimentación de seudorelevancia que envían la consulta original a un motor de búsqueda y recuperan los documentos principales, extraen palabras relevantes de estos documentos principales como palabras de consulta adicionales y vuelven a enviar la consulta expandida nuevamente [21]. Esto normalmente requiere enviar una consulta varias veces al motor de búsqueda y no es rentable para procesar la gran cantidad de consultas involucradas en la búsqueda web. Además, la expansión de consultas, incluida la reformulación de consultas [3, 12], tiene un alto riesgo de cambiar la intención del usuario (llamado desviación de consulta). Dado que las palabras expandidas pueden tener diferentes significados, agregarlas a la consulta podría potencialmente cambiar la intención de la consulta original. Por lo tanto, la expansión de consultas basada en pseudorelevancia y la reformulación de consultas pueden proporcionar sugerencias a los usuarios para su refinamiento interactivo, pero difícilmente pueden ser utilizadas directamente para la búsqueda en la web. Por otro lado, el truncamiento es mucho más conservador ya que la mayoría de las veces, conserva la intención de búsqueda original. Si bien la mayoría de los trabajos sobre la expansión de consultas se centran en mejorar la recuperación, nuestro trabajo se enfoca en aumentar tanto la recuperación como la precisión. El aumento en el recuerdo es evidente. Con el stemming de calidad, los buenos documentos que no fueron seleccionados antes del stemming serán promovidos y aquellos documentos de baja calidad serán degradados. En la expansión selectiva de consultas, Cronen-Townsend et al. [6] propusieron un método para la expansión selectiva de consultas basado en comparar la divergencia de Kullback-Leibler de los resultados de la consulta no expandida y los resultados de la consulta expandida. Esto es similar a la retroalimentación de relevancia en el sentido de que requiere múltiples pasadas de recuperación. Si una palabra puede expandirse en varias palabras, se requiere ejecutar este proceso varias veces para decidir cuál palabra expandida es útil. Es costoso implementar esto en motores de búsqueda web en producción. Nuestro método predice la calidad de la expansión basándose en información sin conexión sin enviar la consulta a un motor de búsqueda. En resumen, proponemos un enfoque novedoso para abordar un problema antiguo, pero aún importante y desafiante para la búsqueda en la web: el stemming. Nuestro enfoque es único en el sentido de que realiza el truncamiento predictivo de forma individualizada para cada consulta sin retroalimentación de relevancia de la Web, utilizando el contexto de las variantes en los documentos para preservar la precisión. Es simple, pero muy eficiente y efectivo, lo que hace factible el truncamiento en tiempo real para la búsqueda en la web. Nuestros resultados confirmarán a los investigadores que el truncamiento es realmente muy importante para la recuperación de información a gran escala. STEMMING CONTEXTUAL SENSIBLE 3.1 Resumen Nuestro sistema tiene cuatro componentes como se ilustra en la Figura 1: generación de candidatos, segmentación de consultas y detección de palabras clave, derivación de consultas sensible al contexto y coincidencia de documentos sensible al contexto. La generación de candidatos (componente 1) se realiza fuera de línea y los candidatos generados se almacenan en un diccionario. Para una consulta de entrada, primero segmentamos la consulta en conceptos y detectamos la palabra principal de cada concepto (componente 2). Luego utilizamos modelado de lenguaje estadístico para decidir si una variante particular es útil (componente 3), y finalmente, para las variantes expandidas, realizamos un emparejamiento de documentos sensible al contexto (componente 4). A continuación discutimos cada uno de los componentes con más detalle. Componente 4: coincidencia de documentos sensibles al contexto Consulta de entrada: y detección de palabras clave Componente 2: segmento Componente 1: generación de candidatos comparaciones −> comparación Componente 3: decisión de expansión selectiva de palabras: comparaciones −> comparación ejemplo: comparaciones de precios de hoteles salida: comparaciones de hoteles hotel −> hoteles Figura 1: Componentes del sistema 3.2 Generación de candidatos de expansión Una de las formas de generar candidatos es utilizando el stemmer de Porter [18]. El stemmer de Porter simplemente utiliza reglas morfológicas para convertir una palabra a su forma base. No tiene conocimiento del significado semántico de las palabras y a veces comete errores graves, como cambiar \"executive\" por \"execution\", \"news\" por \"new\" y \"paste\" por \"past\". Una forma más conservadora se basa en utilizar análisis de corpus para mejorar los resultados del stemmer de Porter [26]. El análisis de corpus que realizamos se basa en la similitud distribucional de palabras [15]. La razón de utilizar la similitud distribucional de palabras es que las variantes verdaderas tienden a ser utilizadas en contextos similares. En el cálculo de similitud de palabras distribucionales, cada palabra se representa con un vector de características derivadas del contexto de la palabra. Utilizamos los bigramas a la izquierda y a la derecha de la palabra como sus características de contexto, mediante la extracción de un gran corpus web. La similitud entre dos palabras es la similitud coseno entre los dos vectores de características correspondientes. Las 20 palabras similares a \"desarrollar\" se muestran en la siguiente tabla. rango candidato puntaje rango candidato puntaje 0 desarrollar 1 10 berts 0.119 1 desarrollando 0.339 11 wads 0.116 2 desarrollado 0.176 12 desarrollador 0.107 3 incubadora 0.160 13 promoviendo 0.100 4 desarrolla 0.150 14 desarrollo 0.091 5 desarrollo 0.148 15 reingeniería 0.090 6 tutoría 0.138 16 construir 0.083 7 analizando 0.128 17 construir 0.081 8 desarrollo 0.128 18 educativo 0.081 9 automatización 0.126 19 instituto 0.077 Tabla 1: Los 20 candidatos más similares a la palabra \"desarrollar\". La puntuación de la columna es la puntuación de similitud. Para determinar los candidatos de derivación, aplicamos algunas reglas morfológicas del stemmer de Porter [18] a la lista de similitud. Después de aplicar estas reglas, para la palabra desarrollar, los candidatos de derivación son desarrollando, desarrollado, desarrolla, desarrollo, desarrollo, desarrollador, y desarrollo. Para el propósito de manejo de pluralización, solo se conserva el candidato desarrolla. Una cosa que observamos al observar las palabras distribucionalmente similares es que están estrechamente relacionadas semánticamente. Estas palabras podrían servir como candidatas para la expansión general de consultas, un tema que investigaremos en el futuro. 3.3 Segmentación e identificación de palabras clave Para consultas largas, es bastante importante detectar los conceptos en la consulta y las palabras más importantes para esos conceptos. Primero dividimos una consulta en segmentos, cada segmento representando un concepto que normalmente es una frase nominal. Para cada una de las frases nominales, luego detectamos la palabra más importante a la que llamamos la palabra principal. La segmentación también se utiliza en la coincidencia sensible a documentos (sección 3.5) para hacer cumplir la proximidad. Para dividir una consulta en segmentos, tenemos que definir un criterio para medir la fuerza de la relación entre las palabras. Un método efectivo es utilizar la información mutua como indicador para decidir si dividir o no dos palabras [19]. Utilizamos un registro de 25 millones de consultas y recopilamos las frecuencias de bigramas y unigramas a partir de él. Para cada consulta entrante, calculamos la información mutua de dos palabras adyacentes; si supera un umbral predefinido, no dividimos la consulta entre esas dos palabras y pasamos a la siguiente palabra. Continuamos este proceso hasta que la información mutua entre dos palabras esté por debajo del umbral, luego creamos un límite conceptual aquí. La Tabla 2 muestra algunos ejemplos de segmentación de consultas. La forma ideal de encontrar la palabra principal de un concepto es realizar un análisis sintáctico para determinar la estructura de dependencia de la consulta. El análisis de consultas es más difícil que el análisis de oraciones, ya que muchas consultas no son gramaticales y son muy cortas. Aplicar un analizador entrenado en oraciones de documentos a consultas tendrá un rendimiento deficiente. En nuestra solución, solo utilizamos reglas heurísticas simples, y funciona muy bien en la práctica para el inglés. Para una frase nominal en inglés, la palabra principal suele ser la última palabra no detenida, a menos que la frase siga un patrón particular, como XYZ de/en/a/desde UVW. En tales casos, la palabra principal suele ser la última palabra no detenida de XYZ. 3.4 Expansión de palabras sensibles al contexto Después de detectar cuáles son las palabras más importantes para expandir, debemos decidir si las expansiones serán útiles. Nuestras estadísticas muestran que aproximadamente la mitad de las consultas pueden ser transformadas mediante la pluralización a través de un truncamiento ingenuo. Entre esta mitad, aproximadamente el 25% de las consultas mejoran la relevancia cuando se transforman, la mayoría (alrededor del 50%) no cambian sus 5 resultados principales, y el 25% restante tiene un rendimiento peor. Por lo tanto, es extremadamente importante identificar qué consultas no deben ser truncadas con el fin de maximizar la mejora de relevancia y minimizar el costo de truncamiento. Además, para una consulta con múltiples palabras que pueden ser transformadas, o una palabra con múltiples variantes, no todas las expansiones son útiles. Tomando la comparación de precios de hoteles como ejemplo, decidimos que hotel y comparación de precios son dos conceptos. Las palabras clave hotel y comparación se pueden expandir a hoteles y comparaciones. ¿Son útiles ambas transformaciones? Para probar si una expansión es útil, tenemos que saber si es probable que la consulta expandida obtenga más documentos relevantes de la web, lo cual puede cuantificarse mediante la probabilidad de que la consulta ocurra como una cadena en la web. Cuanto más probable sea que ocurra una consulta en la web, más documentos relevantes puede devolver esta consulta. Ahora todo el problema se convierte en cómo calcular la probabilidad de que ocurra la consulta en la Web. Calcular la probabilidad de que una cadena ocurra en un corpus es un problema bien conocido de modelado del lenguaje. El objetivo del modelado del lenguaje es predecir la probabilidad de secuencias de palabras que ocurren naturalmente, s = w1w2...wN; o más simplemente, asignar una alta probabilidad a las secuencias de palabras que realmente ocurren (y una baja probabilidad a las secuencias de palabras que nunca ocurren). El enfoque más simple y exitoso para el modelado del lenguaje sigue estando basado en el modelo n-gramo. Por la regla de la cadena de probabilidad, se puede escribir la probabilidad de cualquier secuencia de palabras como Pr(w1w2...wN) = ΠY i=1 Pr(wi|w1...wi−1) (1). Un modelo n-grama aproxima esta probabilidad asumiendo que las únicas palabras relevantes para predecir Pr(wi|w1...wi−1) son las n − 1 palabras anteriores; es decir, La probabilidad de una palabra wi dado w1...wi−1 es igual a la probabilidad de wi dado wi−n+1...wi−1. Una estimación directa de máxima verosimilitud de las probabilidades de n-gramas a partir de un corpus se obtiene a partir de la frecuencia observada de cada uno de los patrones Pr(wi|wi−n+1...wi−1) = #(wi−n+1...wi) #(wi−n+1...wi−1) donde #(.) denota el número de ocurrencias de un n-grama específico en el corpus de entrenamiento. Aunque se podría intentar usar modelos de n-gramos simples para capturar dependencias a largo plazo en el lenguaje, intentar hacerlo directamente crea inmediatamente problemas de datos dispersos: Utilizar n-gramos de longitud hasta n implica estimar la probabilidad de eventos de longitud Wn, donde W es el tamaño del vocabulario de palabras. Esto rápidamente abruma los recursos computacionales y de datos modernos incluso para opciones modestas de n (más allá de 3 a 6). Además, debido a la naturaleza de cola pesada del lenguaje (es decir, La ley de Zipf) es probable que uno se encuentre con n-gramas novedosos que nunca fueron observados durante el entrenamiento en ningún corpus de prueba, por lo tanto, algún mecanismo para asignar una probabilidad distinta de cero a los n-gramas novedosos es un problema central e inevitable en la modelización estadística del lenguaje. Un enfoque estándar para suavizar las estimaciones de probabilidad para hacer frente a problemas de datos escasos (y para hacer frente a posibles n-gramas faltantes) es utilizar algún tipo de estimador de retroceso. Pr(wi|wi−n+1...wi−1) = 8 >>< >>: ˆPr(wi|wi−n+1...wi−1), si #(wi−n+1...wi) > 0 β(wi−n+1...wi−1) × Pr(wi|wi−n+2...wi−1), de lo contrario (3) donde ˆPr(wi|wi−n+1...wi−1) = descuento #(wi−n+1...wi) #(wi−n+1...wi−1) (4) es la probabilidad descontada y β(wi−n+1...wi−1) es una constante de normalización β(wi−n+1...wi−1) = 1 − X x∈(wi−n+1...wi−1x) ˆPr(x|wi−n+1...wi−1) 1 − X x∈(wi−n+1...wi−1x) ˆPr(x|wi−n+2...wi−1) (5) La probabilidad descontada (4) se puede calcular con diferentes técnicas de suavizado, incluido el suavizado absoluto, el suavizado de Good-Turing, el suavizado lineal y el suavizado de Witten-Bell [5]. Utilizamos suavizado absoluto en nuestros experimentos. Dado que la probabilidad de una cadena, Pr(w1w2...wN), es un número muy pequeño y difícil de interpretar, utilizamos la entropía, tal como se define a continuación, para puntuar la cadena. Entropía = − 1 N log2 Pr(w1w2...wN ) (6) Ahora volviendo al ejemplo de la comparación de precios de hoteles, hay cuatro variantes de esta consulta, y la entropía de estos cuatro candidatos se muestra en la Tabla 3. Podemos ver que todas las alternativas son menos probables que la consulta de entrada. Por lo tanto, no es útil hacer una expansión para esta consulta. Por otro lado, si la consulta de entrada son comparaciones de precios de hoteles, que es la segunda alternativa en la tabla, entonces hay una mejor alternativa que la consulta de entrada, y por lo tanto debería ser ampliada. Para tolerar las variaciones en la estimación de probabilidad, relajamos el criterio de selección para esas alternativas de consulta si sus puntuaciones están dentro de una cierta distancia (10% en nuestros experimentos) de la mejor puntuación. Variaciones de la consulta Comparación de precios de hoteles 6.177 comparaciones de precios de hoteles 6.597 comparación de precios de hoteles 6.937 comparaciones de precios de hoteles 7.360 Tabla 3: Variaciones de la consulta comparación de precios de hoteles clasificadas por puntaje de entropía, con la consulta original en negrita. 3.5 Coincidencia de documentos sensibles al contexto Aun después de saber qué variantes de palabras son probablemente útiles, debemos ser conservadores en la coincidencia de documentos para las variantes ampliadas. Para la consulta de comparaciones de precios de hoteles, decidimos que la palabra \"comparaciones\" se amplía para incluir \"comparación\". Sin embargo, no todos los casos de comparación en el documento son de interés. Una página que trata sobre comparar el servicio al cliente puede contener todas las palabras comparaciones de precios de hoteles comparación. Esta página no es una buena página para la consulta. Si aceptamos coincidencias de cada ocurrencia de comparación, afectará la precisión de recuperación y esta es una de las principales razones por las que la mayoría de los enfoques de derivación no funcionan bien para la recuperación de información. Para abordar este problema, tenemos una restricción de proximidad que considera el contexto alrededor de la variante expandida en el documento. Una coincidencia de variante se considera válida solo si la variante ocurre en el mismo contexto que la palabra original lo hace. El contexto son los segmentos continuos de la izquierda o de la derecha de la palabra original. Tomando la misma consulta como ejemplo, el contexto de las comparaciones es el precio. La comparación de palabras ampliada solo es válida si está en el mismo contexto de comparaciones, que es después de la palabra precio. Por lo tanto, solo debemos emparejar aquellas ocurrencias de comparación en el documento si ocurren después de la palabra precio. Considerando el hecho de que las consultas y los documentos pueden no representar la intención de la misma manera exacta, relajamos esta restricción de proximidad para permitir ocurrencias variantes dentro de una ventana de un tamaño fijo. Si la comparación de palabras expandidas ocurre dentro del contexto de precio dentro de una ventana, se considera válida. Cuanto más pequeño sea el tamaño de la ventana, más restrictiva será la coincidencia. Utilizamos un tamaño de ventana de 4, que normalmente captura contextos que incluyen las frases nominales que contienen y las adyacentes. 4. EVALUACIÓN EXPERIMENTAL 4.1 Métricas de evaluación Mediremos tanto la mejora de relevancia como el costo de derivación necesario para lograr la relevancia. 1 un segmento de contexto no puede ser una sola palabra de parada. 4.1.1 Medición de relevancia Utilizamos una variante de la Ganancia Acumulada Descontada Promedio (DCG), un esquema recientemente popularizado para medir la relevancia de los motores de búsqueda [1, 11]. Dada una consulta y una lista clasificada de K documentos (K se establece en 5 en nuestros experimentos), el puntaje DCG(K) para esta consulta se calcula de la siguiente manera: DCG(K) = Σ k=1 a K gk log2(1 + k) . (7) donde gk es el peso para el documento en la posición k. Un mayor grado de relevancia corresponde a un peso mayor. Una página se califica en una de las cinco escalas: Perfecto, Excelente, Bueno, Regular, Malo, con pesos correspondientes. Utilizamos DCG para representar el DCG promedio(5) sobre un conjunto de consultas de prueba. 4.1.2 Costo de derivación Otro métrica es medir el costo adicional incurrido por la derivación. Dado el mismo nivel de mejora en la relevancia, preferimos un método de truncamiento que tenga un menor costo adicional. Medimos esto por el porcentaje de consultas que realmente se reducen, sobre todas las consultas que podrían ser reducidas. 4.2 Preparación de datos Muestreamos aleatoriamente 870 consultas de un registro de consultas de tres meses, con 290 de cada mes. Entre todas estas 870 consultas, eliminamos todas las consultas con errores ortográficos ya que las consultas con errores ortográficos no son de interés para el stemming. También eliminamos todas las consultas de una sola palabra, ya que reducir las consultas de una sola palabra sin contexto tiene un alto riesgo de cambiar la intención de la consulta, especialmente para palabras cortas. Al final, tenemos 529 consultas correctamente escritas con al menos 2 palabras. 4.3 Stemming ingenuo para la búsqueda en la Web Antes de explicar en detalle los experimentos y resultados, nos gustaría describir la forma tradicional de usar el stemming para la búsqueda en la Web, conocida como el modelo ingenuo. Esto es para tratar cada variante de palabra equivalente para todas las posibles palabras en la consulta. La consulta de la librería se transformará en (libro O libros)(tienda O tiendas) al limitar el truncamiento al manejo de pluralización solamente, donde O es un operador que denota la equivalencia de los argumentos izquierdo y derecho. 4.4 Configuración experimental El modelo base es el modelo sin truncamiento. Primero ejecutamos el modelo ingenuo para ver qué tan bien se desempeña en comparación con el punto de referencia. Luego mejoramos el modelo de derivación ingenua mediante la coincidencia sensible al documento, denominado modelo de coincidencia sensible al documento. Este modelo realiza el mismo stemming que el modelo ingenuo en el lado de la consulta, pero realiza un emparejamiento conservador en el lado del documento utilizando la estrategia descrita en la sección 3.5. El modelo ingenuo y el modelo de coincidencia sensible al documento son los que mejor responden a la mayoría de las consultas. De las 529 consultas, hay 408 consultas que se originan, lo que corresponde al 46.7% del tráfico de consultas (de un total de 870). Luego mejoramos aún más el modelo de coincidencia sensible de documentos desde el lado de la consulta con un proceso de derivación de palabras selectivo basado en modelado estadístico del lenguaje (sección 3.4), denominado modelo de derivación selectiva. Basado en la predicción del modelado del lenguaje, este modelo deriva solo un subconjunto de las 408 consultas derivadas por el modelo de coincidencia sensible al documento. Experimentamos con un modelo de lenguaje unigrama y un <br>modelo de lenguaje bigrama</br>. Dado que solo nos importa cuánto podemos mejorar el modelo ingenuo, solo utilizaremos estas 408 consultas (todas las consultas que se ven afectadas por el modelo de derivación ingenuo) en los experimentos. Para tener una idea de cómo se desempeñan estos modelos, también tenemos un modelo oráculo que proporciona el rendimiento máximo que un stemmer puede lograr en estos datos. El modelo del oráculo solo expande una palabra si el truncamiento dará mejores resultados. Para analizar la influencia del manejo de la pluralización en diferentes categorías de consultas, dividimos las consultas en consultas cortas y consultas largas. Entre las 408 consultas generadas por el modelo ingenuo, hay 272 consultas cortas con 2 o 3 palabras, y 136 consultas largas con al menos 4 palabras. Resumimos los resultados generales en la Tabla 4, y presentamos los resultados de las consultas cortas y largas por separado en la Tabla 5. Cada fila en la Tabla 4 es una estrategia de derivación descrita en la sección 4.4. La primera columna es el nombre de la estrategia. La segunda columna es el número de consultas afectadas por esta estrategia; esta columna mide el costo de derivación, y los números deberían ser bajos para el mismo nivel de dcg. La tercera columna es la puntuación DCG promedio sobre todas las consultas probadas en esta categoría (incluyendo aquellas que no fueron truncadas por la estrategia). La cuarta columna es la mejora relativa sobre la línea base, y la última columna es el valor p de la prueba de significancia de Wilcoxon. Hay varias observaciones sobre los resultados. Podemos ver que el truncado ingenuo solo logra una mejora estadísticamente insignificante del 1.5%. Mirando la Tabla 5, se observa una mejora del 2.7% en las consultas cortas. Sin embargo, también perjudica las consultas largas en un -2.4%. En general, la mejora se cancela. La razón por la que mejora las consultas cortas es que la mayoría de las consultas cortas solo tienen una palabra que se puede reducir a su raíz. Por lo tanto, pluralizar ciegamente consultas cortas es relativamente seguro. Sin embargo, para consultas largas, la mayoría de las consultas pueden tener varias palabras que pueden ser pluralizadas. Expandir todos ellos sin selección perjudicará significativamente la precisión. La aplicación de un stemming sensible al contexto del documento proporciona un aumento significativo en el rendimiento, desde un 2.7% hasta un 4.2% para consultas cortas y desde un -2.4% hasta un -1.6% para consultas largas, con un aumento general del 1.5% al 2.8%. La mejora proviene de la coincidencia de documentos sensible al contexto conservador. Una palabra expandida es válida solo si ocurre dentro del contexto de la consulta original en el documento. Esto reduce muchas coincidencias falsas. Sin embargo, aún observamos que para consultas largas, el truncamiento sensible al contexto no logra mejorar el rendimiento porque sigue seleccionando demasiados documentos y le presenta a la función de clasificación un problema difícil. Si bien el tamaño de ventana elegido de 4 es el que mejor funciona entre todas las opciones, aún permite coincidencias espurias. Es posible que el tamaño de la ventana deba elegirse según la consulta para garantizar restricciones de proximidad más estrictas para diferentes tipos de frases nominales. La pluralización selectiva de palabras ayuda aún más a resolver el problema enfrentado por el truncamiento sensible al contexto del documento. No se aplica el truncamiento a cada palabra que coloca toda la carga en el algoritmo de clasificación, sino que intenta eliminar el truncamiento innecesario en primer lugar. Al predecir qué variantes de palabras van a ser útiles, podemos reducir drásticamente el número de palabras derivadas, mejorando así tanto la recuperación como la precisión. Con el modelo de lenguaje unigrama, podemos reducir el costo de derivación en un 26.7% (de 408/408 a 300/408) y aumentar la mejora general de DCG del 2.8% al 3.4%. En particular, proporciona mejoras significativas en consultas largas. La ganancia de DCG se cambia de negativa a positiva, de -1.6% a 1.1%. Esto confirma nuestra hipótesis de que reducir la expansión innecesaria de palabras conduce a una mejora en la precisión. Para consultas cortas también observamos tanto la mejora de dcg como la reducción del costo de derivación con el modelo de lenguaje unigrama. Las ventajas de la expansión predictiva de palabras con un modelo de lenguaje se potencian aún más con un mejor <br>modelo de lenguaje de bigrama</br>. La ganancia total de DCG aumenta de 3.4% a 3.9%, y el costo de derivación se reduce drásticamente de 408/408 a 250/408, correspondiente a solo el 29% del tráfico de consultas (250 de 870) y una mejora total de DCG del 1.8% en todo el tráfico de consultas. Para consultas cortas, el <br>modelo de lenguaje de bigrama</br> mejora la ganancia de DCG del 4.4% al 4.7%, y reduce el costo de derivación de 272/272 a 150/272. Para consultas largas, el <br>modelo de lenguaje de bigrama</br> mejora la ganancia de DCG del 1.1% al 2.5%, y reduce el costo de derivación de 136/136 a 100/136. Observamos que el <br>modelo de lenguaje de bigrama</br> proporciona un mayor aumento para consultas largas. ",
            "candidates": [],
            "error": [
                [
                    "modelo de lenguaje bigrama",
                    "modelo de lenguaje de bigrama",
                    "modelo de lenguaje de bigrama",
                    "modelo de lenguaje de bigrama",
                    "modelo de lenguaje de bigrama"
                ]
            ]
        },
        "stem": {
            "translated_key": "truncamiento",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Context Sensitive Stemming for Web Search Fuchun Peng Nawaaz Ahmed Xin Li Yumao Lu Yahoo!",
                "Inc. 701 First Avenue Sunnyvale, California 94089 {fuchun, nawaaz, xinli, yumaol}@yahoo-inc.com ABSTRACT Traditionally, stemming has been applied to Information Retrieval tasks by transforming words in documents to the their root form before indexing, and applying a similar transformation to query terms.",
                "Although it increases recall, this naive strategy does not work well for Web Search since it lowers precision and requires a significant amount of additional computation.",
                "In this paper, we propose a context sensitive stemming method that addresses these two issues.",
                "Two unique properties make our approach feasible for Web Search.",
                "First, based on statistical language modeling, we perform context sensitive analysis on the query side.",
                "We accurately predict which of its morphological variants is useful to expand a query term with before submitting the query to the search engine.",
                "This dramatically reduces the number of bad expansions, which in turn reduces the cost of additional computation and improves the precision at the same time.",
                "Second, our approach performs a context sensitive document matching for those expanded variants.",
                "This conservative strategy serves as a safeguard against spurious stemming, and it turns out to be very important for improving precision.",
                "Using word pluralization handling as an example of our stemming approach, our experiments on a major Web search engine show that stemming only 29% of the query traffic, we can improve relevance as measured by average Discounted Cumulative Gain (DCG5) by 6.1% on these queries and 1.8% over all query traffic.",
                "Categories and Subject Descriptors H.3.3 [Information Systems]: Information Storage and Retrieval-Query formulation General Terms Algorithms, Experimentation 1.",
                "INTRODUCTION Web search has now become a major tool in our daily lives for information seeking.",
                "One of the important issues in Web search is that user queries are often not best formulated to get optimal results.",
                "For example, running shoe is a query that occurs frequently in query logs.",
                "However, the query running shoes is much more likely to give better search results than the original query because documents matching the intent of this query usually contain the words running shoes.",
                "Correctly formulating a query requires the user to accurately predict which word form is used in the documents that best satisfy his or her information needs.",
                "This is difficult even for experienced users, and especially difficult for non-native speakers.",
                "One traditional solution is to use stemming [16, 18], the process of transforming inflected or derived words to their root form so that a search term will match and retrieve documents containing all forms of the term.",
                "Thus, the word run will match running, ran, runs, and shoe will match shoes and shoeing.",
                "Stemming can be done either on the terms in a document during indexing (and applying the same transformation to the query terms during query processing) or by expanding the query with the variants during query processing.",
                "Stemming during indexing allows very little flexibility during query processing, while stemming by query expansion allows handling each query differently, and hence is preferred.",
                "Although traditional stemming increases recall by matching word variants [13], it can reduce precision by retrieving too many documents that have been incorrectly matched.",
                "When examining the results of applying stemming to a large number of queries, one usually finds that nearly equal numbers of queries are helped and hurt by the technique [6].",
                "In addition, it reduces system performance because the search engine has to match all the word variants.",
                "As we will show in the experiments, this is true even if we simplify stemming to pluralization handling, which is the process of converting a word from its plural to singular form, or vice versa.",
                "Thus, one needs to be very cautious when using stemming in Web search engines.",
                "One problem of traditional stemming is its blind transformation of all query terms, that is, it always performs the same transformation for the same query word without considering the context of the word.",
                "For example, the word book has four forms book, books, booking, booked, and store has four forms store, stores, storing, stored.",
                "For the query book store, expanding both words to all of their variants significantly increases computation cost and hurts precision, since not all of the variants are useful for this query.",
                "Transforming book store to match book stores is fine, but matching book storing or booking store is not.",
                "A weighting method that gives variant words smaller weights alleviates the problems to a certain extent if the weights accurately reflect the importance of the variant in this particular query.",
                "However uniform weighting is not going to work and a query dependent weighting is still a challenging unsolved problem [20].",
                "A second problem of traditional stemming is its blind matching of all occurrences in documents.",
                "For the query book store, a transformation that allows the variant stores to be matched will cause every occurrence of stores in the document to be treated equivalent to the query term store.",
                "Thus, a document containing the fragment reading a book in coffee stores will be matched, causing many wrong documents to be selected.",
                "Although we hope the ranking function can correctly handle these, with many more candidates to rank, the risk of making mistakes increases.",
                "To alleviate these two problems, we propose a context sensitive stemming approach for Web search.",
                "Our solution consists of two context sensitive analysis, one on the query side and the other on the document side.",
                "On the query side, we propose a statistical language modeling based approach to predict which word variants are better forms than the original word for search purpose and expanding the query with only those forms.",
                "On the document side, we propose a conservative context sensitive matching for the transformed word variants, only matching document occurrences in the context of other terms in the query.",
                "Our model is simple yet effective and efficient, making it feasible to be used in real commercial Web search engines.",
                "We use pluralization handling as a running example for our stemming approach.",
                "The motivation for using pluralization handling as an example is to show that even such simple stemming, if handled correctly, can give significant benefits to search relevance.",
                "As far as we know, no previous research has systematically investigated the usage of pluralization in Web search.",
                "As we have to point out, the method we propose is not limited to pluralization handling, it is a general stemming technique, and can also be applied to general query expansion.",
                "Experiments on general stemming yield additional significant improvements over pluralization handling for long queries, although details will not be reported in this paper.",
                "In the rest of the paper, we first present the related work and distinguish our method from previous work in Section 2.",
                "We describe the details of the context sensitive stemming approach in Section 3.",
                "We then perform extensive experiments on a major Web search engine to support our claims in Section 4, followed by discussions in Section 5.",
                "Finally, we conclude the paper in Section 6. 2.",
                "RELATED WORK Stemming is a long studied technology.",
                "Many stemmers have been developed, such as the Lovins stemmer [16] and the Porter stemmer [18].",
                "The Porter stemmer is widely used due to its simplicity and effectiveness in many applications.",
                "However, the Porter stemming makes many mistakes because its simple rules cannot fully describe English morphology.",
                "Corpus analysis is used to improve Porter stemmer [26] by creating equivalence classes for words that are morphologically similar and occur in similar context as measured by expected mutual information [23].",
                "We use a similar corpus based approach for stemming by computing the similarity between two words based on their distributional context features which can be more than just adjacent words [15], and then only keep the morphologically similar words as candidates.",
                "Using stemming in information retrieval is also a well known technique [8, 10].",
                "However, the effectiveness of stemming for English query systems was previously reported to be rather limited.",
                "Lennon et al. [17] compared the Lovins and Porter algorithms and found little improvement in retrieval performance.",
                "Later, Harman [9] compares three general stemming techniques in text retrieval experiments including pluralization handing (called S stemmer in the paper).",
                "They also proposed selective stemming based on query length and term importance, but no positive results were reported.",
                "On the other hand, Krovetz [14] performed comparisons over small numbers of documents (from 400 to 12k) and showed dramatic precision improvement (up to 45%).",
                "However, due to the limited number of tested queries (less than 100) and the small size of the collection, the results are hard to generalize to Web search.",
                "These mixed results, mostly failures, led early IR researchers to deem stemming irrelevant in general for English [4], although recent research has shown stemming has greater benefits for retrieval in other languages [2].",
                "We suspect the previous failures were mainly due to the two problems we mentioned in the introduction.",
                "Blind stemming, or a simple query length based selective stemming as used in [9] is not enough.",
                "Stemming has to be decided on case by case basis, not only at the query level but also at the document level.",
                "As we will show, if handled correctly, significant improvement can be achieved.",
                "A more general problem related to stemming is query reformulation [3, 12] and query expansion which expands words not only with word variants [7, 22, 24, 25].",
                "To decide which expanded words to use, people often use pseudorelevance feedback techniquesthat send the original query to a search engine and retrieve the top documents, extract relevant words from these top documents as additional query words, and resubmit the expanded query again [21].",
                "This normally requires sending a query multiple times to search engine and it is not cost effective for processing the huge amount of queries involved in Web search.",
                "In addition, query expansion, including query reformulation [3, 12], has a high risk of changing the user intent (called query drift).",
                "Since the expanded words may have different meanings, adding them to the query could potentially change the intent of the original query.",
                "Thus query expansion based on pseudorelevance and query reformulation can provide suggestions to users for interactive refinement but can hardly be directly used for Web search.",
                "On the other hand, stemming is much more conservative since most of the time, stemming preserves the original search intent.",
                "While most work on query expansion focuses on recall enhancement, our work focuses on increasing both recall and precision.",
                "The increase on recall is obvious.",
                "With quality stemming, good documents which were not selected before stemming will be pushed up and those low quality documents will be degraded.",
                "On selective query expansion, Cronen-Townsend et al. [6] proposed a method for selective query expansion based on comparing the Kullback-Leibler divergence of the results from the unexpanded query and the results from the expanded query.",
                "This is similar to the relevance feedback in the sense that it requires multiple passes retrieval.",
                "If a word can be expanded into several words, it requires running this process multiple times to decide which expanded word is useful.",
                "It is expensive to deploy this in production Web search engines.",
                "Our method predicts the quality of expansion based on oﬄine information without sending the query to a search engine.",
                "In summary, we propose a novel approach to attack an old, yet still important and challenging problem for Web search - stemming.",
                "Our approach is unique in that it performs predictive stemming on a per query basis without relevance feedback from the Web, using the context of the variants in documents to preserve precision.",
                "Its simple, yet very efficient and effective, making real time stemming feasible for Web search.",
                "Our results will affirm researchers that stemming is indeed very important to large scale information retrieval. 3.",
                "CONTEXT SENSITIVE STEMMING 3.1 Overview Our system has four components as illustrated in Figure 1: candidate generation, query segmentation and head word detection, context sensitive query stemming and context sensitive document matching.",
                "Candidate generation (component 1) is performed oﬄine and generated candidates are stored in a dictionary.",
                "For an input query, we first segment query into concepts and detect the head word for each concept (component 2).",
                "We then use statistical language modeling to decide whether a particular variant is useful (component 3), and finally for the expanded variants, we perform context sensitive document matching (component 4).",
                "Below we discuss each of the components in more detail.",
                "Component 4: context sensitive document matching Input Query: and head word detection Component 2: segment Component 1: candidate generation comparisons −> comparison Component 3: selective word expansion decision: comparisons −> comparison example: hotel price comparisons output: hotel comparisons hotel −> hotels Figure 1: System Components 3.2 Expansion candidate generation One of the ways to generate candidates is using the Porter stemmer [18].",
                "The Porter stemmer simply uses morphological rules to convert a word to its base form.",
                "It has no knowledge of the semantic meaning of the words and sometimes makes serious mistakes, such as executive to execution, news to new, and paste to past.",
                "A more conservative way is based on using corpus analysis to improve the Porter stemmer results [26].",
                "The corpus analysis we do is based on word distributional similarity [15].",
                "The rationale of using distributional word similarity is that true variants tend to be used in similar contexts.",
                "In the distributional word similarity calculation, each word is represented with a vector of features derived from the context of the word.",
                "We use the bigrams to the left and right of the word as its context features, by mining a huge Web corpus.",
                "The similarity between two words is the cosine similarity between the two corresponding feature vectors.",
                "The top 20 similar words to develop is shown in the following table. rank candidate score rank candidate score 0 develop 1 10 berts 0.119 1 developing 0.339 11 wads 0.116 2 developed 0.176 12 developer 0.107 3 incubator 0.160 13 promoting 0.100 4 develops 0.150 14 developmental 0.091 5 development 0.148 15 reengineering 0.090 6 tutoring 0.138 16 build 0.083 7 analyzing 0.128 17 construct 0.081 8 developement 0.128 18 educational 0.081 9 automation 0.126 19 institute 0.077 Table 1: Top 20 most similar candidates to word develop.",
                "Column score is the similarity score.",
                "To determine the stemming candidates, we apply a few Porter stemmer [18] morphological rules to the similarity list.",
                "After applying these rules, for the word develop, the stemming candidates are developing, developed, develops, development, developement, developer, developmental.",
                "For the pluralization handling purpose, only the candidate develops is retained.",
                "One thing we note from observing the distributionally similar words is that they are closely related semantically.",
                "These words might serve as candidates for general query expansion, a topic we will investigate in the future. 3.3 Segmentation and headword identification For long queries, it is quite important to detect the concepts in the query and the most important words for those concepts.",
                "We first break a query into segments, each segment representing a concept which normally is a noun phrase.",
                "For each of the noun phrases, we then detect the most important word which we call the head word.",
                "Segmentation is also used in document sensitive matching (section 3.5) to enforce proximity.",
                "To break a query into segments, we have to define a criteria to measure the strength of the relation between words.",
                "One effective method is to use mutual information as an indicator on whether or not to split two words [19].",
                "We use a log of 25M queries and collect the bigram and unigram frequencies from it.",
                "For every incoming query, we compute the mutual information of two adjacent words; if it passes a predefined threshold, we do not split the query between those two words and move on to next word.",
                "We continue this process until the mutual information between two words is below the threshold, then create a concept boundary here.",
                "Table 2 shows some examples of query segmentation.",
                "The ideal way of finding the head word of a concept is to do syntactic parsing to determine the dependency structure of the query.",
                "Query parsing is more difficult than sentence [running shoe] [best] [new york] [medical schools] [pictures] [of] [white house] [cookies] [in] [san francisco] [hotel] [price comparison] Table 2: Query segmentation: a segment is bracketed. parsing since many queries are not grammatical and are very short.",
                "Applying a parser trained on sentences from documents to queries will have poor performance.",
                "In our solution, we just use simple heuristics rules, and it works very well in practice for English.",
                "For an English noun phrase, the head word is typically the last nonstop word, unless the phrase is of a particular pattern, like XYZ of/in/at/from UVW.",
                "In such cases, the head word is typically the last nonstop word of XYZ. 3.4 Context sensitive word expansion After detecting which words are the most important words to expand, we have to decide whether the expansions will be useful.",
                "Our statistics show that about half of the queries can be transformed by pluralization via naive stemming.",
                "Among this half, about 25% of the queries improve relevance when transformed, the majority (about 50%) do not change their top 5 results, and the remaining 25% perform worse.",
                "Thus, it is extremely important to identify which queries should not be stemmed for the purpose of maximizing relevance improvement and minimizing stemming cost.",
                "In addition, for a query with multiple words that can be transformed, or a word with multiple variants, not all of the expansions are useful.",
                "Taking query hotel price comparison as an example, we decide that hotel and price comparison are two concepts.",
                "Head words hotel and comparison can be expanded to hotels and comparisons.",
                "Are both transformations useful?",
                "To test whether an expansion is useful, we have to know whether the expanded query is likely to get more relevant documents from the Web, which can be quantified by the probability of the query occurring as a string on the Web.",
                "The more likely a query to occur on the Web, the more relevant documents this query is able to return.",
                "Now the whole problem becomes how to calculate the probability of query to occur on the Web.",
                "Calculating the probability of string occurring in a corpus is a well known language modeling problem.",
                "The goal of language modeling is to predict the probability of naturally occurring word sequences, s = w1w2...wN ; or more simply, to put high probability on word sequences that actually occur (and low probability on word sequences that never occur).",
                "The simplest and most successful approach to language modeling is still based on the n-gram model.",
                "By the chain rule of probability one can write the probability of any word sequence as Pr(w1w2...wN ) = NY i=1 Pr(wi|w1...wi−1) (1) An n-gram model approximates this probability by assuming that the only words relevant to predicting Pr(wi|w1...wi−1) are the previous n − 1 words; i.e.",
                "Pr(wi|w1...wi−1) = Pr(wi|wi−n+1...wi−1) A straightforward maximum likelihood estimate of n-gram probabilities from a corpus is given by the observed frequency of each of the patterns Pr(wi|wi−n+1...wi−1) = #(wi−n+1...wi) #(wi−n+1...wi−1) (2) where #(.) denotes the number of occurrences of a specified gram in the training corpus.",
                "Although one could attempt to use simple n-gram models to capture long range dependencies in language, attempting to do so directly immediately creates sparse data problems: Using grams of length up to n entails estimating the probability of Wn events, where W is the size of the word vocabulary.",
                "This quickly overwhelms modern computational and data resources for even modest choices of n (beyond 3 to 6).",
                "Also, because of the heavy tailed nature of language (i.e.",
                "Zipfs law) one is likely to encounter novel n-grams that were never witnessed during training in any test corpus, and therefore some mechanism for assigning non-zero probability to novel n-grams is a central and unavoidable issue in statistical language modeling.",
                "One standard approach to smoothing probability estimates to cope with sparse data problems (and to cope with potentially missing n-grams) is to use some sort of back-off estimator.",
                "Pr(wi|wi−n+1...wi−1) = 8 >>< >>: ˆPr(wi|wi−n+1...wi−1), if #(wi−n+1...wi) > 0 β(wi−n+1...wi−1) × Pr(wi|wi−n+2...wi−1), otherwise (3) where ˆPr(wi|wi−n+1...wi−1) = discount #(wi−n+1...wi) #(wi−n+1...wi−1) (4) is the discounted probability and β(wi−n+1...wi−1) is a normalization constant β(wi−n+1...wi−1) = 1 − X x∈(wi−n+1...wi−1x) ˆPr(x|wi−n+1...wi−1) 1 − X x∈(wi−n+1...wi−1x) ˆPr(x|wi−n+2...wi−1) (5) The discounted probability (4) can be computed with different smoothing techniques, including absolute smoothing, Good-Turing smoothing, linear smoothing, and Witten-Bell smoothing [5].",
                "We used absolute smoothing in our experiments.",
                "Since the likelihood of a string, Pr(w1w2...wN ), is a very small number and hard to interpret, we use entropy as defined below to score the string.",
                "Entropy = − 1 N log2 Pr(w1w2...wN ) (6) Now getting back to the example of the query hotel price comparisons, there are four variants of this query, and the entropy of these four candidates are shown in Table 3.",
                "We can see that all alternatives are less likely than the input query.",
                "It is therefore not useful to make an expansion for this query.",
                "On the other hand, if the input query is hotel price comparisons which is the second alternative in the table, then there is a better alternative than the input query, and it should therefore be expanded.",
                "To tolerate the variations in probability estimation, we relax the selection criterion to those query alternatives if their scores are within a certain distance (10% in our experiments) to the best score.",
                "Query variations Entropy hotel price comparison 6.177 hotel price comparisons 6.597 hotels price comparison 6.937 hotels price comparisons 7.360 Table 3: Variations of query hotel price comparison ranked by entropy score, with the original query in bold face. 3.5 Context sensitive document matching Even after we know which word variants are likely to be useful, we have to be conservative in document matching for the expanded variants.",
                "For the query hotel price comparisons, we decided that word comparisons is expanded to include comparison.",
                "However, not every occurrence of comparison in the document is of interest.",
                "A page which is about comparing customer service can contain all of the words hotel price comparisons comparison.",
                "This page is not a good page for the query.",
                "If we accept matches of every occurrence of comparison, it will hurt retrieval precision and this is one of the main reasons why most stemming approaches do not work well for information retrieval.",
                "To address this problem, we have a proximity constraint that considers the context around the expanded variant in the document.",
                "A variant match is considered valid only if the variant occurs in the same context as the original word does.",
                "The context is the left or the right non-stop segments 1 of the original word.",
                "Taking the same query as an example, the context of comparisons is price.",
                "The expanded word comparison is only valid if it is in the same context of comparisons, which is after the word price.",
                "Thus, we should only match those occurrences of comparison in the document if they occur after the word price.",
                "Considering the fact that queries and documents may not represent the intent in exactly the same way, we relax this proximity constraint to allow variant occurrences within a window of some fixed size.",
                "If the expanded word comparison occurs within the context of price within a window, it is considered valid.",
                "The smaller the window size is, the more restrictive the matching.",
                "We use a window size of 4, which typically captures contexts that include the containing and adjacent noun phrases. 4.",
                "EXPERIMENTAL EVALUATION 4.1 Evaluation metrics We will measure both relevance improvement and the stemming cost required to achieve the relevance. 1 a context segment can not be a single stop word. 4.1.1 Relevance measurement We use a variant of the average Discounted Cumulative Gain (DCG), a recently popularized scheme to measure search engine relevance [1, 11].",
                "Given a query and a ranked list of K documents (K is set to 5 in our experiments), the DCG(K) score for this query is calculated as follows: DCG(K) = KX k=1 gk log2(1 + k) . (7) where gk is the weight for the document at rank k. Higher degree of relevance corresponds to a higher weight.",
                "A page is graded into one of the five scales: Perfect, Excellent, Good, Fair, Bad, with corresponding weights.",
                "We use dcg to represent the average DCG(5) over a set of test queries. 4.1.2 Stemming cost Another metric is to measure the additional cost incurred by stemming.",
                "Given the same level of relevance improvement, we prefer a stemming method that has less additional cost.",
                "We measure this by the percentage of queries that are actually stemmed, over all the queries that could possibly be stemmed. 4.2 Data preparation We randomly sample 870 queries from a three month query log, with 290 from each month.",
                "Among all these 870 queries, we remove all misspelled queries since misspelled queries are not of interest to stemming.",
                "We also remove all one word queries since stemming one word queries without context has a high risk of changing query intent, especially for short words.",
                "In the end, we have 529 correctly spelled queries with at least 2 words. 4.3 Naive stemming for Web search Before explaining the experiments and results in detail, wed like to describe the traditional way of using stemming for Web search, referred as the naive model.",
                "This is to treat every word variant equivalent for all possible words in the query.",
                "The query book store will be transformed into (book OR books)(store OR stores) when limiting stemming to pluralization handling only, where OR is an operator that denotes the equivalence of the left and right arguments. 4.4 Experimental setup The baseline model is the model without stemming.",
                "We first run the naive model to see how well it performs over the baseline.",
                "Then we improve the naive stemming model by document sensitive matching, referred as document sensitive matching model.",
                "This model makes the same stemming as the naive model on the query side, but performs conservative matching on the document side using the strategy described in section 3.5.",
                "The naive model and document sensitive matching model <br>stem</br> the most queries.",
                "Out of the 529 queries, there are 408 queries that they <br>stem</br>, corresponding to 46.7% query traffic (out of a total of 870).",
                "We then further improve the document sensitive matching model from the query side with selective word stemming based on statistical language modeling (section 3.4), referred as selective stemming model.",
                "Based on language modeling prediction, this model stems only a subset of the 408 queries stemmed by the document sensitive matching model.",
                "We experiment with unigram language model and bigram language model.",
                "Since we only care how much we can improve the naive model, we will only use these 408 queries (all the queries that are affected by the naive stemming model) in the experiments.",
                "To get a sense of how these models perform, we also have an oracle model that gives the upper-bound performance a stemmer can achieve on this data.",
                "The oracle model only expands a word if the stemming will give better results.",
                "To analyze the pluralization handling influence on different query categories, we divide queries into short queries and long queries.",
                "Among the 408 queries stemmed by the naive model, there are 272 short queries with 2 or 3 words, and 136 long queries with at least 4 words. 4.5 Results We summarize the overall results in Table 4, and present the results on short queries and long queries separately in Table 5.",
                "Each row in Table 4 is a stemming strategy described in section 4.4.",
                "The first column is the name of the strategy.",
                "The second column is the number of queries affected by this strategy; this column measures the stemming cost, and the numbers should be low for the same level of dcg.",
                "The third column is the average dcg score over all tested queries in this category (including the ones that were not stemmed by the strategy).",
                "The fourth column is the relative improvement over the baseline, and the last column is the p-value of Wilcoxon significance test.",
                "There are several observations about the results.",
                "We can see the naively stemming only obtains a statistically insignificant improvement of 1.5%.",
                "Looking at Table 5, it gives an improvement of 2.7% on short queries.",
                "However, it also hurts long queries by -2.4%.",
                "Overall, the improvement is canceled out.",
                "The reason that it improves short queries is that most short queries only have one word that can be stemmed.",
                "Thus, blindly pluralizing short queries is relatively safe.",
                "However for long queries, most queries can have multiple words that can be pluralized.",
                "Expanding all of them without selection will significantly hurt precision.",
                "Document context sensitive stemming gives a significant lift to the performance, from 2.7% to 4.2% for short queries and from -2.4% to -1.6% for long queries, with an overall lift from 1.5% to 2.8%.",
                "The improvement comes from the conservative context sensitive document matching.",
                "An expanded word is valid only if it occurs within the context of original query in the document.",
                "This reduces many spurious matches.",
                "However, we still notice that for long queries, context sensitive stemming is not able to improve performance because it still selects too many documents and gives the ranking function a hard problem.",
                "While the chosen window size of 4 works the best amongst all the choices, it still allows spurious matches.",
                "It is possible that the window size needs to be chosen on a per query basis to ensure tighter proximity constraints for different types of noun phrases.",
                "Selective word pluralization further helps resolving the problem faced by document context sensitive stemming.",
                "It does not <br>stem</br> every word that places all the burden on the ranking algorithm, but tries to eliminate unnecessary stemming in the first place.",
                "By predicting which word variants are going to be useful, we can dramatically reduce the number of stemmed words, thus improving both the recall and the precision.",
                "With the unigram language model, we can reduce the stemming cost by 26.7% (from 408/408 to 300/408) and lift the overall dcg improvement from 2.8% to 3.4%.",
                "In particular, it gives significant improvements on long queries.",
                "The dcg gain is turned from negative to positive, from −1.6% to 1.1%.",
                "This confirms our hypothesis that reducing unnecessary word expansion leads to precision improvement.",
                "For short queries too, we observe both dcg improvement and stemming cost reduction with the unigram language model.",
                "The advantages of predictive word expansion with a language model is further boosted with a better bigram language model.",
                "The overall dcg gain is lifted from 3.4% to 3.9%, and stemming cost is dramatically reduced from 408/408 to 250/408, corresponding to only 29% of query traffic (250 out of 870) and an overall 1.8% dcg improvement overall all query traffic.",
                "For short queries, bigram language model improves the dcg gain from 4.4% to 4.7%, and reduces stemming cost from 272/272 to 150/272.",
                "For long queries, bigram language model improves dcg gain from 1.1% to 2.5%, and reduces stemming cost from 136/136 to 100/136.",
                "We observe that the bigram language model gives a larger lift for long queries.",
                "This is because the uncertainty in long queries is larger and a more powerful language model is needed.",
                "We hypothesize that a trigram language model would give a further lift for long queries and leave this for future investigation.",
                "Considering the tight upper-bound 2 on the improvement to be gained from pluralization handling (via the oracle model), the current performance on short queries is very satisfying.",
                "For short queries, the dcg gain upper-bound is 6.3% for perfect pluralization handling, our current gain is 4.7% with a bigram language model.",
                "For long queries, the dcg gain upper-bound is 4.6% for perfect pluralization handling, our current gain is 2.5% with a bigram language model.",
                "We may gain additional benefit with a more powerful language model for long queries.",
                "However, the difficulties of long queries come from many other aspects including the proximity and the segmentation problem.",
                "These problems have to be addressed separately.",
                "Looking at the the upper-bound of overhead reduction for oracle stemming, 75% (308/408) of the naive stemmings are wasteful.",
                "We currently capture about half of them.",
                "Further reduction of the overhead requires sacrificing the dcg gain.",
                "Now we can compare the stemming strategies from a different aspect.",
                "Instead of looking at the influence over all queries as we described above, Table 6 summarizes the dcg improvements over the affected queries only.",
                "We can see that the number of affected queries decreases as the stemming strategy becomes more accurate (dcg improvement).",
                "For the bigram language model, over the 250/408 stemmed queries, the dcg improvement is 6.1%.",
                "An interesting observation is the average dcg decreases with a better model, which indicates a better stemming strategy stems more difficult queries (low dcg queries). 5.",
                "DISCUSSIONS 5.1 Language models from query vs. from Web As we mentioned in Section 1, we are trying to predict the probability of a string occurring on the Web.",
                "The language model should describe the occurrence of the string on the Web.",
                "However, the query log is also a good resource. 2 Note that this upperbound is for pluralization handling only, not for general stemming.",
                "General stemming gives a 8% upperbound, which is quite substantial in terms of our metrics.",
                "Affected Queries dcg dcg Improvement p-value baseline 0/408 7.102 N/A N/A naive model 408/408 7.206 1.5% 0.22 document context sensitive model 408/408 7.302 2.8% 0.014 selective model: unigram LM 300/408 7.321 3.4% 0.001 selective model: bigram LM 250/408 7.381 3.9% 0.001 oracle model 100/408 7.519 5.9% 0.001 Table 4: Results comparison of different stemming strategies over all queries affected by naive stemming Short Query Results Affected Queries dcg Improvement p-value baseline 0/272 N/A N/A naive model 272/272 2.7% 0.48 document context sensitive model 272/272 4.2% 0.002 selective model: unigram LM 185/272 4.4% 0.001 selective model: bigram LM 150/272 4.7% 0.001 oracle model 71/272 6.3% 0.001 Long Query Results Affected Queries dcg Improvement p-value baseline 0/136 N/A N/A naive model 136/136 -2.4% 0.25 document context sensitive model 136/136 -1.6% 0.27 selective model: unigram LM 115/136 1.1% 0.001 selective model: bigram LM 100/136 2.5% 0.001 oracle model 29/136 4.6% 0.001 Table 5: Results comparison of different stemming strategies overall short queries and long queries Users reformulate a query using many different variants to get good results.",
                "To test the hypothesis that we can learn reliable transformation probabilities from the query log, we trained a language model from the same query top 25M queries as used to learn segmentation, and use that for prediction.",
                "We observed a slight performance decrease compared to the model trained on Web frequencies.",
                "In particular, the performance for unigram LM was not affected, but the dcg gain for bigram LM changed from 4.7% to 4.5% for short queries.",
                "Thus, the query log can serve as a good approximation of the Web frequencies. 5.2 How linguistics helps Some linguistic knowledge is useful in stemming.",
                "For the pluralization handling case, pluralization and de-pluralization is not symmetric.",
                "A plural word used in a query indicates a special intent.",
                "For example, the query new york hotels is looking for a list of hotels in new york, not the specific new york hotel which might be a hotel located in California.",
                "A simple equivalence of hotel to hotels might boost a particular page about new york hotel to top rank.",
                "To capture this intent, we have to make sure the document is a general page about hotels in new york.",
                "We do this by requiring that the plural word hotels appears in the document.",
                "On the other hand, converting a singular word to plural is safer since a general purpose page normally contains specific information.",
                "We observed a slight overall dcg decrease, although not statistically significant, for document context sensitive stemming if we do not consider this asymmetric property. 5.3 Error analysis One type of mistakes we noticed, though rare but seriously hurting relevance, is the search intent change after stemming.",
                "Generally speaking, pluralization or depluralization keeps the original intent.",
                "However, the intent could change in a few cases.",
                "For one example of such a query, job at apple, we pluralize job to jobs.",
                "This stemming makes the original query ambiguous.",
                "The query job OR jobs at apple has two intents.",
                "One is the employment opportunities at apple, and another is a person working at Apple, Steve Jobs, who is the CEO and co-founder of the company.",
                "Thus, the results after query stemming returns Steve Jobs as one of the results in top 5.",
                "One solution is performing results set based analysis to check if the intent is changed.",
                "This is similar to relevance feedback and requires second phase ranking.",
                "A second type of mistakes is the entity/concept recognition problem, These include two kinds.",
                "One is that the stemmed word variant now matches part of an entity or concept.",
                "For example, query cookies in san francisco is pluralized to cookies OR cookie in san francisco.",
                "The results will match cookie jar in san francisco.",
                "Although cookie still means the same thing as cookies, cookie jar is a different concept.",
                "Another kind is the unstemmed word matches an entity or concept because of the stemming of the other words.",
                "For example, quote ICE is pluralized to quote OR quotes ICE.",
                "The original intent for this query is searching for stock quote for ticker ICE.",
                "However, we noticed that among the top results, one of the results is Food quotes: Ice cream.",
                "This is matched because of Affected Queries old dcg new dcg dcg Improvement naive model 408/408 7.102 7.206 1.5% document context sensitive model 408/408 7.102 7.302 2.8% selective model: unigram LM 300/408 5.904 6.187 4.8% selective model: bigram LM 250/408 5.551 5.891 6.1% Table 6: Results comparison over the stemmed queries only: column old/new dcg is the dcg score over the affected queries before/after applying stemming the pluralized word quotes.",
                "The unchanged word ICE matches part of the noun phrase ice cream here.",
                "To solve this kind of problem, we have to analyze the documents and recognize cookie jar and ice cream as concepts instead of two independent words.",
                "A third type of mistakes occurs in long queries.",
                "For the query bar code reader software, two words are pluralized. code to codes and reader to readers.",
                "In fact, bar code reader in the original query is a strong concept and the internal words should not be changed.",
                "This is the segmentation and entity and noun phrase detection problem in queries, which we actively are attacking.",
                "For long queries, we should correctly identify the concepts in the query, and boost the proximity for the words within a concept. 6.",
                "CONCLUSIONS AND FUTURE WORK We have presented a simple yet elegant way of stemming for Web search.",
                "It improves naive stemming in two aspects: selective word expansion on the query side and conservative word occurrence matching on the document side.",
                "Using pluralization handling as an example, experiments on a major Web search engine data show it significantly improves the Web relevance and reduces the stemming cost.",
                "It also significantly improves Web click through rate (details not reported in the paper).",
                "For the future work, we are investigating the problems we identified in the error analysis section.",
                "These include: entity and noun phrase matching mistakes, and improved segmentation. 7.",
                "REFERENCES [1] E. Agichtein, E. Brill, and S. T. Dumais.",
                "Improving Web Search Ranking by Incorporating User Behavior Information.",
                "In SIGIR, 2006. [2] E. Airio.",
                "Word Normalization and Decompounding in Mono- and Bilingual IR.",
                "Information Retrieval, 9:249-271, 2006. [3] P. Anick.",
                "Using Terminological Feedback for Web Search Refinement: a Log-based Study.",
                "In SIGIR, 2003. [4] R. Baeza-Yates and B. Ribeiro-Neto.",
                "Modern Information Retrieval.",
                "ACM Press/Addison Wesley, 1999. [5] S. Chen and J. Goodman.",
                "An Empirical Study of Smoothing Techniques for Language Modeling.",
                "Technical Report TR-10-98, Harvard University, 1998. [6] S. Cronen-Townsend, Y. Zhou, and B. Croft.",
                "A Framework for Selective Query Expansion.",
                "In CIKM, 2004. [7] H. Fang and C. Zhai.",
                "Semantic Term Matching in Axiomatic Approaches to Information Retrieval.",
                "In SIGIR, 2006. [8] W. B. Frakes.",
                "Term Conflation for Information Retrieval.",
                "In C. J. Rijsbergen, editor, Research and Development in Information Retrieval, pages 383-389.",
                "Cambridge University Press, 1984. [9] D. Harman.",
                "How Effective is Suffixing?",
                "JASIS, 42(1):7-15, 1991. [10] D. Hull.",
                "Stemming Algorithms - A Case Study for Detailed Evaluation.",
                "JASIS, 47(1):70-84, 1996. [11] K. Jarvelin and J. Kekalainen.",
                "Cumulated Gain-Based Evaluation Evaluation of IR Techniques.",
                "ACM TOIS, 20:422-446, 2002. [12] R. Jones, B. Rey, O. Madani, and W. Greiner.",
                "Generating Query Substitutions.",
                "In WWW, 2006. [13] W. Kraaij and R. Pohlmann.",
                "Viewing Stemming as Recall Enhancement.",
                "In SIGIR, 1996. [14] R. Krovetz.",
                "Viewing Morphology as an Inference Process.",
                "In SIGIR, 1993. [15] D. Lin.",
                "Automatic Retrieval and Clustering of Similar Words.",
                "In COLING-ACL, 1998. [16] J.",
                "B. Lovins.",
                "Development of a Stemming Algorithm.",
                "Mechanical Translation and Computational Linguistics, II:22-31, 1968. [17] M. Lennon and D. Peirce and B. Tarry and P. Willett.",
                "An Evaluation of Some Conflation Algorithms for Information Retrieval.",
                "Journal of Information Science, 3:177-188, 1981. [18] M. Porter.",
                "An Algorithm for Suffix Stripping.",
                "Program, 14(3):130-137, 1980. [19] K. M. Risvik, T. Mikolajewski, and P. Boros.",
                "Query Segmentation for Web Search.",
                "In WWW, 2003. [20] S. E. Robertson.",
                "On Term Selection for Query Expansion.",
                "Journal of Documentation, 46(4):359-364, 1990. [21] G. Salton and C. Buckley.",
                "Improving Retrieval Performance by Relevance Feedback.",
                "JASIS, 41(4):288 - 297, 1999. [22] R. Sun, C.-H. Ong, and T.-S. Chua.",
                "Mining Dependency Relations for Query Expansion in Passage Retrieval.",
                "In SIGIR, 2006. [23] C. Van Rijsbergen.",
                "Information Retrieval.",
                "Butterworths, second version, 1979. [24] B. V´elez, R. Weiss, M. A. Sheldon, and D. K. Gifford.",
                "Fast and Effective Query Refinement.",
                "In SIGIR, 1997. [25] J. Xu and B. Croft.",
                "Query Expansion using Local and Global Document Analysis.",
                "In SIGIR, 1996. [26] J. Xu and B. Croft.",
                "Corpus-based Stemming using Cooccurrence of Word Variants.",
                "ACM TOIS, 16 (1):61-81, 1998."
            ],
            "original_annotated_samples": [
                "The naive model and document sensitive matching model <br>stem</br> the most queries.",
                "Out of the 529 queries, there are 408 queries that they <br>stem</br>, corresponding to 46.7% query traffic (out of a total of 870).",
                "It does not <br>stem</br> every word that places all the burden on the ranking algorithm, but tries to eliminate unnecessary stemming in the first place."
            ],
            "translated_annotated_samples": [
                "El modelo ingenuo y el modelo de coincidencia sensible al documento son los que mejor responden a la mayoría de las consultas.",
                "De las 529 consultas, hay 408 consultas que <br>se originan</br>, lo que corresponde al 46.7% del tráfico de consultas (de un total de 870).",
                "No se aplica el <br>truncamiento</br> a cada palabra que coloca toda la carga en el algoritmo de clasificación, sino que intenta eliminar el <br>truncamiento</br> innecesario en primer lugar."
            ],
            "translated_text": "Stemming sensible al contexto para la búsqueda web Fuchun Peng Nawaaz Ahmed Xin Li Yumao Lu Yahoo! Tradicionalmente, el truncamiento se ha aplicado a tareas de Recuperación de Información transformando las palabras en documentos a su forma raíz antes de indexarlas, y aplicando una transformación similar a los términos de consulta. Aunque aumenta la recuperación, esta estrategia ingenua no funciona bien para la Búsqueda en la Web, ya que disminuye la precisión y requiere una cantidad significativa de cálculos adicionales. En este artículo, proponemos un método de derivación sensible al contexto que aborda estos dos problemas. Dos propiedades únicas hacen que nuestro enfoque sea factible para la Búsqueda en la Web. Primero, basados en modelado estadístico del lenguaje, realizamos un análisis sensible al contexto en el lado de la consulta. Predecimos con precisión cuál de sus variantes morfológicas es útil para expandir un término de consulta antes de enviar la consulta al motor de búsqueda. Esto reduce drásticamente la cantidad de expansiones incorrectas, lo que a su vez disminuye el costo de la computación adicional y mejora la precisión al mismo tiempo. Segundo, nuestro enfoque realiza una coincidencia de documentos sensible al contexto para esas variantes ampliadas. Esta estrategia conservadora sirve como salvaguarda contra el truncamiento espurio, y resulta ser muy importante para mejorar la precisión. Usando el manejo de la pluralización de palabras como un ejemplo de nuestro enfoque de derivación, nuestros experimentos en un importante motor de búsqueda web muestran que al derivar solo el 29% del tráfico de consultas, podemos mejorar la relevancia medida por la Ganancia Acumulativa Descontada promedio (DCG5) en un 6.1% en estas consultas y en un 1.8% sobre todo el tráfico de consultas. Categorías y Descriptores de Asignaturas H.3.3 [Sistemas de Información]: Almacenamiento y Recuperación de Información-Formulación de Consultas Términos Generales Algoritmos, Experimentación 1. INTRODUCCIÓN La búsqueda en la web se ha convertido en una herramienta importante en nuestra vida diaria para buscar información. Uno de los problemas importantes en la búsqueda web es que las consultas de los usuarios a menudo no están formuladas de la mejor manera para obtener resultados óptimos. Por ejemplo, \"zapatilla para correr\" es una consulta que ocurre con frecuencia en los registros de consulta. Sin embargo, es mucho más probable que la búsqueda \"zapatillas para correr\" proporcione mejores resultados de búsqueda que la consulta original, ya que los documentos que coinciden con la intención de esta consulta suelen contener las palabras \"zapatillas para correr\". Formular correctamente una consulta requiere que el usuario prediga con precisión qué forma de palabra se utiliza en los documentos que mejor satisfacen sus necesidades de información. Esto es difícil incluso para usuarios experimentados, y especialmente difícil para hablantes no nativos. Una solución tradicional es utilizar el stemming [16, 18], el proceso de transformar palabras flexionadas o derivadas a su forma raíz para que un término de búsqueda coincida y recupere documentos que contengan todas las formas del término. Por lo tanto, la palabra \"run\" coincidirá con \"running\", \"ran\", \"runs\", y \"shoe\" coincidirá con \"shoes\" y \"shoeing\". El truncamiento se puede realizar tanto en los términos de un documento durante la indexación (y aplicando la misma transformación a los términos de la consulta durante el procesamiento de la consulta) o expandiendo la consulta con las variantes durante el procesamiento de la consulta. El truncamiento durante la indexación permite muy poca flexibilidad durante el procesamiento de consultas, mientras que el truncamiento mediante la expansión de consultas permite manejar cada consulta de manera diferente, y por lo tanto es preferible. Aunque el truncamiento tradicional aumenta la recuperación al emparejar variantes de palabras [13], puede reducir la precisión al recuperar demasiados documentos que han sido emparejados incorrectamente. Al examinar los resultados de aplicar el truncamiento a un gran número de consultas, generalmente se encuentra que casi igual cantidad de consultas se benefician y se ven perjudicadas por la técnica [6]. Además, reduce el rendimiento del sistema porque el motor de búsqueda tiene que hacer coincidir todas las variantes de palabras. Como mostraremos en los experimentos, esto es cierto incluso si simplificamos el proceso de derivación a la manipulación de pluralización, que es el proceso de convertir una palabra de su forma plural a singular, o viceversa. Por lo tanto, es necesario ser muy cauteloso al utilizar el stemming en los motores de búsqueda web. Un problema del truncamiento tradicional es su transformación ciega de todos los términos de consulta, es decir, siempre realiza la misma transformación para la misma palabra de consulta sin considerar el contexto de la palabra. Por ejemplo, la palabra \"book\" tiene cuatro formas: book, books, booking, booked, y la palabra \"store\" tiene cuatro formas: store, stores, storing, stored. Para la consulta de la librería, expandir ambas palabras a todas sus variantes aumenta significativamente el costo de computación y perjudica la precisión, ya que no todas las variantes son útiles para esta consulta. Transformar librería para que coincida con librerías está bien, pero hacer coincidir almacenamiento de libros o tienda de reservas no lo está. Un método de ponderación que otorga pesos más pequeños a las palabras variantes alivia los problemas hasta cierto punto si los pesos reflejan con precisión la importancia de la variante en esta consulta particular. Sin embargo, el peso uniforme no va a funcionar y un peso dependiente de la consulta sigue siendo un problema desafiante sin resolver [20]. Un segundo problema del truncamiento tradicional es su emparejamiento ciego de todas las ocurrencias en los documentos. Para la consulta de la librería, una transformación que permita que las tiendas variantes se emparejen hará que cada aparición de tiendas en el documento se trate de manera equivalente al término de consulta tienda. Por lo tanto, se emparejará un documento que contenga el fragmento de leer un libro en las cafeterías, lo que provocará que se seleccionen muchos documentos incorrectos. Aunque esperamos que la función de clasificación pueda manejar correctamente estos, con muchos más candidatos para clasificar, el riesgo de cometer errores aumenta. Para aliviar estos dos problemas, proponemos un enfoque de reducción de palabras raíz sensible al contexto para la búsqueda en la web. Nuestra solución consiste en dos análisis contextuales sensibles, uno en el lado de la consulta y otro en el lado del documento. En el lado de la consulta, proponemos un enfoque basado en modelado del lenguaje estadístico para predecir qué variantes de palabras son mejores formas que la palabra original con fines de búsqueda y expandir la consulta solo con esas formas. En el lado del documento, proponemos un emparejamiento conservador sensible al contexto para las variantes de palabras transformadas, solo emparejando las ocurrencias en el documento en el contexto de otros términos en la consulta. Nuestro modelo es simple pero efectivo y eficiente, lo que lo hace factible de ser utilizado en motores de búsqueda web comerciales reales. Utilizamos el manejo de pluralización como un ejemplo continuo para nuestro enfoque de derivación. La motivación para usar el manejo de pluralización como ejemplo es mostrar que incluso un truncamiento tan simple, si se maneja correctamente, puede brindar beneficios significativos a la relevancia de la búsqueda. Hasta donde sabemos, ninguna investigación previa ha investigado sistemáticamente el uso de la pluralización en la búsqueda en la web. Como debemos señalar, el método que proponemos no se limita al manejo de la pluralización, es una técnica de derivación general y también se puede aplicar a la expansión de consultas en general. Los experimentos sobre el truncamiento general producen mejoras significativas adicionales sobre el manejo de la pluralización para consultas largas, aunque los detalles no se informarán en este artículo. En el resto del documento, primero presentamos el trabajo relacionado y distinguimos nuestro método de trabajos anteriores en la Sección 2. Describimos los detalles del enfoque de derivación sensible al contexto en la Sección 3. Luego realizamos experimentos extensos en un importante motor de búsqueda web para respaldar nuestras afirmaciones en la Sección 4, seguidos de discusiones en la Sección 5. Finalmente, concluimos el artículo en la Sección 6.2. TRABAJO RELACIONADO El stemming es una tecnología estudiada desde hace mucho tiempo. Se han desarrollado muchos stemmers, como el stemmer Lovins [16] y el stemmer Porter [18]. El stemmer de Porter es ampliamente utilizado debido a su simplicidad y efectividad en muchas aplicaciones. Sin embargo, el algoritmo de Porter comete muchos errores porque sus reglas simples no pueden describir completamente la morfología del inglés. El análisis de corpus se utiliza para mejorar el stemmer de Porter [26] mediante la creación de clases de equivalencia para palabras que son morfológicamente similares y que ocurren en un contexto similar, medido por la información mutua esperada [23]. Utilizamos un enfoque de corpus similar para el stemming al calcular la similitud entre dos palabras basada en sus características de contexto distribucional, que pueden ser más que solo palabras adyacentes [15], y luego solo mantenemos las palabras morfológicamente similares como candidatas. El uso de la derivación en la recuperación de información también es una técnica bien conocida [8, 10]. Sin embargo, se informó previamente que la efectividad del truncamiento para los sistemas de consulta en inglés era bastante limitada. Lennon et al. [17] compararon los algoritmos de Lovins y Porter y encontraron poco mejoramiento en el rendimiento de recuperación. Más tarde, Harman [9] compara tres técnicas generales de derivación en experimentos de recuperación de texto, incluido el manejo de pluralización (llamado S stemmer en el artículo). También propusieron el truncamiento selectivo basado en la longitud de la consulta y la importancia del término, pero no se informaron resultados positivos. Por otro lado, Krovetz [14] realizó comparaciones sobre un pequeño número de documentos (de 400 a 12k) y mostró una mejora dramática en la precisión (de hasta un 45%). Sin embargo, debido al número limitado de consultas probadas (menos de 100) y al tamaño reducido de la colección, los resultados son difíciles de generalizar para la búsqueda en la web. Estos resultados mixtos, en su mayoría fracasos, llevaron a los primeros investigadores de IR a considerar que el truncamiento era irrelevante en general para el inglés [4], aunque investigaciones recientes han demostrado que el truncamiento tiene mayores beneficios para la recuperación en otros idiomas [2]. Sospechamos que los fracasos anteriores se debieron principalmente a los dos problemas que mencionamos en la introducción. El stemming ciego, o un stemming selectivo basado en la longitud de la consulta como se utiliza en [9], no es suficiente. El truncamiento debe decidirse caso por caso, no solo a nivel de consulta sino también a nivel de documento. Como demostraremos, si se maneja correctamente, se puede lograr una mejora significativa. Un problema más general relacionado con el stemming es la reformulación de consultas [3, 12] y la expansión de consultas que amplía las palabras no solo con variantes de palabras [7, 22, 24, 25]. Para decidir qué palabras expandidas usar, las personas a menudo utilizan técnicas de retroalimentación de seudorelevancia que envían la consulta original a un motor de búsqueda y recuperan los documentos principales, extraen palabras relevantes de estos documentos principales como palabras de consulta adicionales y vuelven a enviar la consulta expandida nuevamente [21]. Esto normalmente requiere enviar una consulta varias veces al motor de búsqueda y no es rentable para procesar la gran cantidad de consultas involucradas en la búsqueda web. Además, la expansión de consultas, incluida la reformulación de consultas [3, 12], tiene un alto riesgo de cambiar la intención del usuario (llamado desviación de consulta). Dado que las palabras expandidas pueden tener diferentes significados, agregarlas a la consulta podría potencialmente cambiar la intención de la consulta original. Por lo tanto, la expansión de consultas basada en pseudorelevancia y la reformulación de consultas pueden proporcionar sugerencias a los usuarios para su refinamiento interactivo, pero difícilmente pueden ser utilizadas directamente para la búsqueda en la web. Por otro lado, el truncamiento es mucho más conservador ya que la mayoría de las veces, conserva la intención de búsqueda original. Si bien la mayoría de los trabajos sobre la expansión de consultas se centran en mejorar la recuperación, nuestro trabajo se enfoca en aumentar tanto la recuperación como la precisión. El aumento en el recuerdo es evidente. Con el stemming de calidad, los buenos documentos que no fueron seleccionados antes del stemming serán promovidos y aquellos documentos de baja calidad serán degradados. En la expansión selectiva de consultas, Cronen-Townsend et al. [6] propusieron un método para la expansión selectiva de consultas basado en comparar la divergencia de Kullback-Leibler de los resultados de la consulta no expandida y los resultados de la consulta expandida. Esto es similar a la retroalimentación de relevancia en el sentido de que requiere múltiples pasadas de recuperación. Si una palabra puede expandirse en varias palabras, se requiere ejecutar este proceso varias veces para decidir cuál palabra expandida es útil. Es costoso implementar esto en motores de búsqueda web en producción. Nuestro método predice la calidad de la expansión basándose en información sin conexión sin enviar la consulta a un motor de búsqueda. En resumen, proponemos un enfoque novedoso para abordar un problema antiguo, pero aún importante y desafiante para la búsqueda en la web: el stemming. Nuestro enfoque es único en el sentido de que realiza el truncamiento predictivo de forma individualizada para cada consulta sin retroalimentación de relevancia de la Web, utilizando el contexto de las variantes en los documentos para preservar la precisión. Es simple, pero muy eficiente y efectivo, lo que hace factible el truncamiento en tiempo real para la búsqueda en la web. Nuestros resultados confirmarán a los investigadores que el truncamiento es realmente muy importante para la recuperación de información a gran escala. STEMMING CONTEXTUAL SENSIBLE 3.1 Resumen Nuestro sistema tiene cuatro componentes como se ilustra en la Figura 1: generación de candidatos, segmentación de consultas y detección de palabras clave, derivación de consultas sensible al contexto y coincidencia de documentos sensible al contexto. La generación de candidatos (componente 1) se realiza fuera de línea y los candidatos generados se almacenan en un diccionario. Para una consulta de entrada, primero segmentamos la consulta en conceptos y detectamos la palabra principal de cada concepto (componente 2). Luego utilizamos modelado de lenguaje estadístico para decidir si una variante particular es útil (componente 3), y finalmente, para las variantes expandidas, realizamos un emparejamiento de documentos sensible al contexto (componente 4). A continuación discutimos cada uno de los componentes con más detalle. Componente 4: coincidencia de documentos sensibles al contexto Consulta de entrada: y detección de palabras clave Componente 2: segmento Componente 1: generación de candidatos comparaciones −> comparación Componente 3: decisión de expansión selectiva de palabras: comparaciones −> comparación ejemplo: comparaciones de precios de hoteles salida: comparaciones de hoteles hotel −> hoteles Figura 1: Componentes del sistema 3.2 Generación de candidatos de expansión Una de las formas de generar candidatos es utilizando el stemmer de Porter [18]. El stemmer de Porter simplemente utiliza reglas morfológicas para convertir una palabra a su forma base. No tiene conocimiento del significado semántico de las palabras y a veces comete errores graves, como cambiar \"executive\" por \"execution\", \"news\" por \"new\" y \"paste\" por \"past\". Una forma más conservadora se basa en utilizar análisis de corpus para mejorar los resultados del stemmer de Porter [26]. El análisis de corpus que realizamos se basa en la similitud distribucional de palabras [15]. La razón de utilizar la similitud distribucional de palabras es que las variantes verdaderas tienden a ser utilizadas en contextos similares. En el cálculo de similitud de palabras distribucionales, cada palabra se representa con un vector de características derivadas del contexto de la palabra. Utilizamos los bigramas a la izquierda y a la derecha de la palabra como sus características de contexto, mediante la extracción de un gran corpus web. La similitud entre dos palabras es la similitud coseno entre los dos vectores de características correspondientes. Las 20 palabras similares a \"desarrollar\" se muestran en la siguiente tabla. rango candidato puntaje rango candidato puntaje 0 desarrollar 1 10 berts 0.119 1 desarrollando 0.339 11 wads 0.116 2 desarrollado 0.176 12 desarrollador 0.107 3 incubadora 0.160 13 promoviendo 0.100 4 desarrolla 0.150 14 desarrollo 0.091 5 desarrollo 0.148 15 reingeniería 0.090 6 tutoría 0.138 16 construir 0.083 7 analizando 0.128 17 construir 0.081 8 desarrollo 0.128 18 educativo 0.081 9 automatización 0.126 19 instituto 0.077 Tabla 1: Los 20 candidatos más similares a la palabra \"desarrollar\". La puntuación de la columna es la puntuación de similitud. Para determinar los candidatos de derivación, aplicamos algunas reglas morfológicas del stemmer de Porter [18] a la lista de similitud. Después de aplicar estas reglas, para la palabra desarrollar, los candidatos de derivación son desarrollando, desarrollado, desarrolla, desarrollo, desarrollo, desarrollador, y desarrollo. Para el propósito de manejo de pluralización, solo se conserva el candidato desarrolla. Una cosa que observamos al observar las palabras distribucionalmente similares es que están estrechamente relacionadas semánticamente. Estas palabras podrían servir como candidatas para la expansión general de consultas, un tema que investigaremos en el futuro. 3.3 Segmentación e identificación de palabras clave Para consultas largas, es bastante importante detectar los conceptos en la consulta y las palabras más importantes para esos conceptos. Primero dividimos una consulta en segmentos, cada segmento representando un concepto que normalmente es una frase nominal. Para cada una de las frases nominales, luego detectamos la palabra más importante a la que llamamos la palabra principal. La segmentación también se utiliza en la coincidencia sensible a documentos (sección 3.5) para hacer cumplir la proximidad. Para dividir una consulta en segmentos, tenemos que definir un criterio para medir la fuerza de la relación entre las palabras. Un método efectivo es utilizar la información mutua como indicador para decidir si dividir o no dos palabras [19]. Utilizamos un registro de 25 millones de consultas y recopilamos las frecuencias de bigramas y unigramas a partir de él. Para cada consulta entrante, calculamos la información mutua de dos palabras adyacentes; si supera un umbral predefinido, no dividimos la consulta entre esas dos palabras y pasamos a la siguiente palabra. Continuamos este proceso hasta que la información mutua entre dos palabras esté por debajo del umbral, luego creamos un límite conceptual aquí. La Tabla 2 muestra algunos ejemplos de segmentación de consultas. La forma ideal de encontrar la palabra principal de un concepto es realizar un análisis sintáctico para determinar la estructura de dependencia de la consulta. El análisis de consultas es más difícil que el análisis de oraciones, ya que muchas consultas no son gramaticales y son muy cortas. Aplicar un analizador entrenado en oraciones de documentos a consultas tendrá un rendimiento deficiente. En nuestra solución, solo utilizamos reglas heurísticas simples, y funciona muy bien en la práctica para el inglés. Para una frase nominal en inglés, la palabra principal suele ser la última palabra no detenida, a menos que la frase siga un patrón particular, como XYZ de/en/a/desde UVW. En tales casos, la palabra principal suele ser la última palabra no detenida de XYZ. 3.4 Expansión de palabras sensibles al contexto Después de detectar cuáles son las palabras más importantes para expandir, debemos decidir si las expansiones serán útiles. Nuestras estadísticas muestran que aproximadamente la mitad de las consultas pueden ser transformadas mediante la pluralización a través de un truncamiento ingenuo. Entre esta mitad, aproximadamente el 25% de las consultas mejoran la relevancia cuando se transforman, la mayoría (alrededor del 50%) no cambian sus 5 resultados principales, y el 25% restante tiene un rendimiento peor. Por lo tanto, es extremadamente importante identificar qué consultas no deben ser truncadas con el fin de maximizar la mejora de relevancia y minimizar el costo de truncamiento. Además, para una consulta con múltiples palabras que pueden ser transformadas, o una palabra con múltiples variantes, no todas las expansiones son útiles. Tomando la comparación de precios de hoteles como ejemplo, decidimos que hotel y comparación de precios son dos conceptos. Las palabras clave hotel y comparación se pueden expandir a hoteles y comparaciones. ¿Son útiles ambas transformaciones? Para probar si una expansión es útil, tenemos que saber si es probable que la consulta expandida obtenga más documentos relevantes de la web, lo cual puede cuantificarse mediante la probabilidad de que la consulta ocurra como una cadena en la web. Cuanto más probable sea que ocurra una consulta en la web, más documentos relevantes puede devolver esta consulta. Ahora todo el problema se convierte en cómo calcular la probabilidad de que ocurra la consulta en la Web. Calcular la probabilidad de que una cadena ocurra en un corpus es un problema bien conocido de modelado del lenguaje. El objetivo del modelado del lenguaje es predecir la probabilidad de secuencias de palabras que ocurren naturalmente, s = w1w2...wN; o más simplemente, asignar una alta probabilidad a las secuencias de palabras que realmente ocurren (y una baja probabilidad a las secuencias de palabras que nunca ocurren). El enfoque más simple y exitoso para el modelado del lenguaje sigue estando basado en el modelo n-gramo. Por la regla de la cadena de probabilidad, se puede escribir la probabilidad de cualquier secuencia de palabras como Pr(w1w2...wN) = ΠY i=1 Pr(wi|w1...wi−1) (1). Un modelo n-grama aproxima esta probabilidad asumiendo que las únicas palabras relevantes para predecir Pr(wi|w1...wi−1) son las n − 1 palabras anteriores; es decir, La probabilidad de una palabra wi dado w1...wi−1 es igual a la probabilidad de wi dado wi−n+1...wi−1. Una estimación directa de máxima verosimilitud de las probabilidades de n-gramas a partir de un corpus se obtiene a partir de la frecuencia observada de cada uno de los patrones Pr(wi|wi−n+1...wi−1) = #(wi−n+1...wi) #(wi−n+1...wi−1) donde #(.) denota el número de ocurrencias de un n-grama específico en el corpus de entrenamiento. Aunque se podría intentar usar modelos de n-gramos simples para capturar dependencias a largo plazo en el lenguaje, intentar hacerlo directamente crea inmediatamente problemas de datos dispersos: Utilizar n-gramos de longitud hasta n implica estimar la probabilidad de eventos de longitud Wn, donde W es el tamaño del vocabulario de palabras. Esto rápidamente abruma los recursos computacionales y de datos modernos incluso para opciones modestas de n (más allá de 3 a 6). Además, debido a la naturaleza de cola pesada del lenguaje (es decir, La ley de Zipf) es probable que uno se encuentre con n-gramas novedosos que nunca fueron observados durante el entrenamiento en ningún corpus de prueba, por lo tanto, algún mecanismo para asignar una probabilidad distinta de cero a los n-gramas novedosos es un problema central e inevitable en la modelización estadística del lenguaje. Un enfoque estándar para suavizar las estimaciones de probabilidad para hacer frente a problemas de datos escasos (y para hacer frente a posibles n-gramas faltantes) es utilizar algún tipo de estimador de retroceso. Pr(wi|wi−n+1...wi−1) = 8 >>< >>: ˆPr(wi|wi−n+1...wi−1), si #(wi−n+1...wi) > 0 β(wi−n+1...wi−1) × Pr(wi|wi−n+2...wi−1), de lo contrario (3) donde ˆPr(wi|wi−n+1...wi−1) = descuento #(wi−n+1...wi) #(wi−n+1...wi−1) (4) es la probabilidad descontada y β(wi−n+1...wi−1) es una constante de normalización β(wi−n+1...wi−1) = 1 − X x∈(wi−n+1...wi−1x) ˆPr(x|wi−n+1...wi−1) 1 − X x∈(wi−n+1...wi−1x) ˆPr(x|wi−n+2...wi−1) (5) La probabilidad descontada (4) se puede calcular con diferentes técnicas de suavizado, incluido el suavizado absoluto, el suavizado de Good-Turing, el suavizado lineal y el suavizado de Witten-Bell [5]. Utilizamos suavizado absoluto en nuestros experimentos. Dado que la probabilidad de una cadena, Pr(w1w2...wN), es un número muy pequeño y difícil de interpretar, utilizamos la entropía, tal como se define a continuación, para puntuar la cadena. Entropía = − 1 N log2 Pr(w1w2...wN ) (6) Ahora volviendo al ejemplo de la comparación de precios de hoteles, hay cuatro variantes de esta consulta, y la entropía de estos cuatro candidatos se muestra en la Tabla 3. Podemos ver que todas las alternativas son menos probables que la consulta de entrada. Por lo tanto, no es útil hacer una expansión para esta consulta. Por otro lado, si la consulta de entrada son comparaciones de precios de hoteles, que es la segunda alternativa en la tabla, entonces hay una mejor alternativa que la consulta de entrada, y por lo tanto debería ser ampliada. Para tolerar las variaciones en la estimación de probabilidad, relajamos el criterio de selección para esas alternativas de consulta si sus puntuaciones están dentro de una cierta distancia (10% en nuestros experimentos) de la mejor puntuación. Variaciones de la consulta Comparación de precios de hoteles 6.177 comparaciones de precios de hoteles 6.597 comparación de precios de hoteles 6.937 comparaciones de precios de hoteles 7.360 Tabla 3: Variaciones de la consulta comparación de precios de hoteles clasificadas por puntaje de entropía, con la consulta original en negrita. 3.5 Coincidencia de documentos sensibles al contexto Aun después de saber qué variantes de palabras son probablemente útiles, debemos ser conservadores en la coincidencia de documentos para las variantes ampliadas. Para la consulta de comparaciones de precios de hoteles, decidimos que la palabra \"comparaciones\" se amplía para incluir \"comparación\". Sin embargo, no todos los casos de comparación en el documento son de interés. Una página que trata sobre comparar el servicio al cliente puede contener todas las palabras comparaciones de precios de hoteles comparación. Esta página no es una buena página para la consulta. Si aceptamos coincidencias de cada ocurrencia de comparación, afectará la precisión de recuperación y esta es una de las principales razones por las que la mayoría de los enfoques de derivación no funcionan bien para la recuperación de información. Para abordar este problema, tenemos una restricción de proximidad que considera el contexto alrededor de la variante expandida en el documento. Una coincidencia de variante se considera válida solo si la variante ocurre en el mismo contexto que la palabra original lo hace. El contexto son los segmentos continuos de la izquierda o de la derecha de la palabra original. Tomando la misma consulta como ejemplo, el contexto de las comparaciones es el precio. La comparación de palabras ampliada solo es válida si está en el mismo contexto de comparaciones, que es después de la palabra precio. Por lo tanto, solo debemos emparejar aquellas ocurrencias de comparación en el documento si ocurren después de la palabra precio. Considerando el hecho de que las consultas y los documentos pueden no representar la intención de la misma manera exacta, relajamos esta restricción de proximidad para permitir ocurrencias variantes dentro de una ventana de un tamaño fijo. Si la comparación de palabras expandidas ocurre dentro del contexto de precio dentro de una ventana, se considera válida. Cuanto más pequeño sea el tamaño de la ventana, más restrictiva será la coincidencia. Utilizamos un tamaño de ventana de 4, que normalmente captura contextos que incluyen las frases nominales que contienen y las adyacentes. 4. EVALUACIÓN EXPERIMENTAL 4.1 Métricas de evaluación Mediremos tanto la mejora de relevancia como el costo de derivación necesario para lograr la relevancia. 1 un segmento de contexto no puede ser una sola palabra de parada. 4.1.1 Medición de relevancia Utilizamos una variante de la Ganancia Acumulada Descontada Promedio (DCG), un esquema recientemente popularizado para medir la relevancia de los motores de búsqueda [1, 11]. Dada una consulta y una lista clasificada de K documentos (K se establece en 5 en nuestros experimentos), el puntaje DCG(K) para esta consulta se calcula de la siguiente manera: DCG(K) = Σ k=1 a K gk log2(1 + k) . (7) donde gk es el peso para el documento en la posición k. Un mayor grado de relevancia corresponde a un peso mayor. Una página se califica en una de las cinco escalas: Perfecto, Excelente, Bueno, Regular, Malo, con pesos correspondientes. Utilizamos DCG para representar el DCG promedio(5) sobre un conjunto de consultas de prueba. 4.1.2 Costo de derivación Otro métrica es medir el costo adicional incurrido por la derivación. Dado el mismo nivel de mejora en la relevancia, preferimos un método de truncamiento que tenga un menor costo adicional. Medimos esto por el porcentaje de consultas que realmente se reducen, sobre todas las consultas que podrían ser reducidas. 4.2 Preparación de datos Muestreamos aleatoriamente 870 consultas de un registro de consultas de tres meses, con 290 de cada mes. Entre todas estas 870 consultas, eliminamos todas las consultas con errores ortográficos ya que las consultas con errores ortográficos no son de interés para el stemming. También eliminamos todas las consultas de una sola palabra, ya que reducir las consultas de una sola palabra sin contexto tiene un alto riesgo de cambiar la intención de la consulta, especialmente para palabras cortas. Al final, tenemos 529 consultas correctamente escritas con al menos 2 palabras. 4.3 Stemming ingenuo para la búsqueda en la Web Antes de explicar en detalle los experimentos y resultados, nos gustaría describir la forma tradicional de usar el stemming para la búsqueda en la Web, conocida como el modelo ingenuo. Esto es para tratar cada variante de palabra equivalente para todas las posibles palabras en la consulta. La consulta de la librería se transformará en (libro O libros)(tienda O tiendas) al limitar el truncamiento al manejo de pluralización solamente, donde O es un operador que denota la equivalencia de los argumentos izquierdo y derecho. 4.4 Configuración experimental El modelo base es el modelo sin truncamiento. Primero ejecutamos el modelo ingenuo para ver qué tan bien se desempeña en comparación con el punto de referencia. Luego mejoramos el modelo de derivación ingenua mediante la coincidencia sensible al documento, denominado modelo de coincidencia sensible al documento. Este modelo realiza el mismo stemming que el modelo ingenuo en el lado de la consulta, pero realiza un emparejamiento conservador en el lado del documento utilizando la estrategia descrita en la sección 3.5. El modelo ingenuo y el modelo de coincidencia sensible al documento son los que mejor responden a la mayoría de las consultas. De las 529 consultas, hay 408 consultas que <br>se originan</br>, lo que corresponde al 46.7% del tráfico de consultas (de un total de 870). Luego mejoramos aún más el modelo de coincidencia sensible de documentos desde el lado de la consulta con un proceso de derivación de palabras selectivo basado en modelado estadístico del lenguaje (sección 3.4), denominado modelo de derivación selectiva. Basado en la predicción del modelado del lenguaje, este modelo deriva solo un subconjunto de las 408 consultas derivadas por el modelo de coincidencia sensible al documento. Experimentamos con un modelo de lenguaje unigrama y un modelo de lenguaje bigrama. Dado que solo nos importa cuánto podemos mejorar el modelo ingenuo, solo utilizaremos estas 408 consultas (todas las consultas que se ven afectadas por el modelo de derivación ingenuo) en los experimentos. Para tener una idea de cómo se desempeñan estos modelos, también tenemos un modelo oráculo que proporciona el rendimiento máximo que un stemmer puede lograr en estos datos. El modelo del oráculo solo expande una palabra si el truncamiento dará mejores resultados. Para analizar la influencia del manejo de la pluralización en diferentes categorías de consultas, dividimos las consultas en consultas cortas y consultas largas. Entre las 408 consultas generadas por el modelo ingenuo, hay 272 consultas cortas con 2 o 3 palabras, y 136 consultas largas con al menos 4 palabras. Resumimos los resultados generales en la Tabla 4, y presentamos los resultados de las consultas cortas y largas por separado en la Tabla 5. Cada fila en la Tabla 4 es una estrategia de derivación descrita en la sección 4.4. La primera columna es el nombre de la estrategia. La segunda columna es el número de consultas afectadas por esta estrategia; esta columna mide el costo de derivación, y los números deberían ser bajos para el mismo nivel de dcg. La tercera columna es la puntuación DCG promedio sobre todas las consultas probadas en esta categoría (incluyendo aquellas que no fueron truncadas por la estrategia). La cuarta columna es la mejora relativa sobre la línea base, y la última columna es el valor p de la prueba de significancia de Wilcoxon. Hay varias observaciones sobre los resultados. Podemos ver que el truncado ingenuo solo logra una mejora estadísticamente insignificante del 1.5%. Mirando la Tabla 5, se observa una mejora del 2.7% en las consultas cortas. Sin embargo, también perjudica las consultas largas en un -2.4%. En general, la mejora se cancela. La razón por la que mejora las consultas cortas es que la mayoría de las consultas cortas solo tienen una palabra que se puede reducir a su raíz. Por lo tanto, pluralizar ciegamente consultas cortas es relativamente seguro. Sin embargo, para consultas largas, la mayoría de las consultas pueden tener varias palabras que pueden ser pluralizadas. Expandir todos ellos sin selección perjudicará significativamente la precisión. La aplicación de un stemming sensible al contexto del documento proporciona un aumento significativo en el rendimiento, desde un 2.7% hasta un 4.2% para consultas cortas y desde un -2.4% hasta un -1.6% para consultas largas, con un aumento general del 1.5% al 2.8%. La mejora proviene de la coincidencia de documentos sensible al contexto conservador. Una palabra expandida es válida solo si ocurre dentro del contexto de la consulta original en el documento. Esto reduce muchas coincidencias falsas. Sin embargo, aún observamos que para consultas largas, el truncamiento sensible al contexto no logra mejorar el rendimiento porque sigue seleccionando demasiados documentos y le presenta a la función de clasificación un problema difícil. Si bien el tamaño de ventana elegido de 4 es el que mejor funciona entre todas las opciones, aún permite coincidencias espurias. Es posible que el tamaño de la ventana deba elegirse según la consulta para garantizar restricciones de proximidad más estrictas para diferentes tipos de frases nominales. La pluralización selectiva de palabras ayuda aún más a resolver el problema enfrentado por el truncamiento sensible al contexto del documento. No se aplica el <br>truncamiento</br> a cada palabra que coloca toda la carga en el algoritmo de clasificación, sino que intenta eliminar el <br>truncamiento</br> innecesario en primer lugar. Al predecir qué variantes de palabras van a ser útiles, podemos reducir drásticamente el número de palabras derivadas, mejorando así tanto la recuperación como la precisión. Con el modelo de lenguaje unigrama, podemos reducir el costo de derivación en un 26.7% (de 408/408 a 300/408) y aumentar la mejora general de DCG del 2.8% al 3.4%. En particular, proporciona mejoras significativas en consultas largas. La ganancia de DCG se cambia de negativa a positiva, de -1.6% a 1.1%. Esto confirma nuestra hipótesis de que reducir la expansión innecesaria de palabras conduce a una mejora en la precisión. Para consultas cortas también observamos tanto la mejora de dcg como la reducción del costo de derivación con el modelo de lenguaje unigrama. Las ventajas de la expansión predictiva de palabras con un modelo de lenguaje se potencian aún más con un mejor modelo de lenguaje de bigrama. La ganancia total de DCG aumenta de 3.4% a 3.9%, y el costo de derivación se reduce drásticamente de 408/408 a 250/408, correspondiente a solo el 29% del tráfico de consultas (250 de 870) y una mejora total de DCG del 1.8% en todo el tráfico de consultas. Para consultas cortas, el modelo de lenguaje de bigrama mejora la ganancia de DCG del 4.4% al 4.7%, y reduce el costo de derivación de 272/272 a 150/272. Para consultas largas, el modelo de lenguaje de bigrama mejora la ganancia de DCG del 1.1% al 2.5%, y reduce el costo de derivación de 136/136 a 100/136. Observamos que el modelo de lenguaje de bigrama proporciona un mayor aumento para consultas largas. Esto se debe a que la incertidumbre en las consultas largas es mayor y se necesita un modelo de lenguaje más potente. Hacemos la hipótesis de que un modelo de lenguaje de trigramas proporcionaría un impulso adicional para consultas largas y dejamos esto para investigaciones futuras. Considerando el límite superior estricto de 2 en la mejora que se puede obtener del manejo de la pluralización (a través del modelo oráculo), el rendimiento actual en consultas cortas es muy satisfactorio. Para consultas breves, la ganancia máxima de DCG es del 6.3% para el manejo perfecto de la pluralización, nuestra ganancia actual es del 4.7% con un modelo de lenguaje de bigrama. Para consultas largas, la ganancia máxima de DCG es del 4.6% para el manejo perfecto de la pluralización, nuestra ganancia actual es del 2.5% con un modelo de lenguaje de bigrama. Podríamos obtener beneficios adicionales con un modelo de lenguaje más potente para consultas largas. Sin embargo, las dificultades de las consultas largas provienen de muchos otros aspectos, incluyendo la proximidad y el problema de la segmentación. Estos problemas deben ser abordados por separado. Al observar el límite superior de reducción de gastos generales para el truncamiento de Oracle, el 75% (308/408) de los truncamientos ingenuos son inútiles. Actualmente capturamos alrededor de la mitad de ellos. La reducción adicional de los gastos generales requiere sacrificar la ganancia de la DCG. Ahora podemos comparar las estrategias de derivación desde un aspecto diferente. En lugar de analizar la influencia sobre todas las consultas como describimos anteriormente, la Tabla 6 resume las mejoras de DCG solo sobre las consultas afectadas. Podemos ver que el número de consultas afectadas disminuye a medida que la estrategia de derivación se vuelve más precisa (mejora en el dcg). Para el modelo de lenguaje de bigrama, sobre las 250/408 consultas truncadas, la mejora en DCG es del 6.1%. Una observación interesante es que el dcg promedio disminuye con un modelo mejor, lo que indica que una estrategia de derivación mejorada deriva consultas más difíciles (consultas con bajo dcg). 5. Como mencionamos en la Sección 1, estamos tratando de predecir la probabilidad de que una cadena ocurra en la Web. El modelo de lenguaje debe describir la ocurrencia de la cadena en la web. Sin embargo, el registro de consultas también es un buen recurso. Tenga en cuenta que este límite superior es solo para el manejo de pluralización, no para el truncamiento general. El stemming general proporciona un límite superior del 8%, lo cual es bastante sustancial en términos de nuestras métricas. Las consultas afectadas dcg dcg Mejora p-valor línea de base 0/408 7.102 N/A N/A modelo ingenuo 408/408 7.206 1.5% 0.22 modelo sensible al contexto del documento 408/408 7.302 2.8% 0.014 modelo selectivo: unigram LM 300/408 7.321 3.4% 0.001 modelo selectivo: bigram LM 250/408 7.381 3.9% 0.001 modelo oráculo 100/408 7.519 5.9% 0.001 Tabla 4: Comparación de resultados de diferentes estrategias de derivación en todas las consultas afectadas por la derivación ingenua Resultados de Consultas Cortas Consultas Afectadas dcg Mejora p-valor línea de base 0/272 N/A N/A modelo ingenuo 272/272 2.7% 0.48 modelo sensible al contexto del documento 272/272 4.2% 0.002 modelo selectivo: unigram LM 185/272 4.4% 0.001 modelo selectivo: bigram LM 150/272 4.7% 0.001 modelo oráculo 71/272 6.3% 0.001 Resultados de Consultas Largas Consultas Afectadas dcg Mejora p-valor línea de base 0/136 N/A N/A modelo ingenuo 136/136 -2.4% 0.25 modelo sensible al contexto del documento 136/136 -1.6% 0.27 modelo selectivo: unigram LM 115/136 1.1% 0.001 modelo selectivo: bigram LM 100/136 2.5% 0.001 modelo oráculo 29/136 4.6% 0.001 Tabla 5: Comparación de resultados de diferentes estrategias de derivación en consultas cortas y largas en general Los usuarios reformulan una consulta utilizando muchas variantes diferentes para obtener buenos resultados. Para probar la hipótesis de que podemos aprender probabilidades de transformación confiables a partir del registro de consultas, entrenamos un modelo de lenguaje con las mismas 25 millones de consultas principales utilizadas para aprender la segmentación, y lo utilizamos para la predicción. Observamos una ligera disminución en el rendimiento en comparación con el modelo entrenado en frecuencias web. En particular, el rendimiento para el modelo de lenguaje unigrama no se vio afectado, pero la ganancia de dcg para el modelo de lenguaje bigrama cambió de 4.7% a 4.5% para consultas cortas. Por lo tanto, el registro de consultas puede servir como una buena aproximación de las frecuencias web. 5.2 Cómo la lingüística ayuda. Algunos conocimientos lingüísticos son útiles en el stemming. Para el manejo de la pluralización, la pluralización y la despluralización no son simétricas. Una palabra en plural utilizada en una consulta indica una intención especial. Por ejemplo, la consulta hoteles en Nueva York está buscando una lista de hoteles en Nueva York, no el hotel específico de Nueva York que podría estar ubicado en California. Una simple equivalencia de hotel a hoteles podría impulsar una página en particular sobre hoteles en Nueva York al primer puesto. Para capturar esta intención, tenemos que asegurarnos de que el documento sea una página general sobre hoteles en Nueva York. Esto lo hacemos exigiendo que la palabra en plural hoteles aparezca en el documento. Por otro lado, convertir una palabra singular a plural es más seguro ya que una página de propósito general normalmente contiene información específica. Observamos una ligera disminución general en el dcg, aunque no estadísticamente significativa, para el stemming sensible al contexto del documento si no consideramos esta propiedad asimétrica. Análisis de errores. Un tipo de errores que notamos, aunque raros pero que afectan seriamente la relevancia, es el cambio de intención de búsqueda después del stemming. En general, la pluralización o despluralización mantiene la intención original. Sin embargo, la intención podría cambiar en algunos casos. Por ejemplo, para una consulta de este tipo, trabajo en Apple, pluralizamos trabajo a trabajos. Este truncamiento hace que la consulta original sea ambigua. El trabajo de consulta O trabajos en Apple tiene dos intenciones. Una de las oportunidades laborales en Apple, y otra es una persona que trabaja en Apple, Steve Jobs, quien es el CEO y cofundador de la empresa. Por lo tanto, los resultados después de la reducción de consultas devuelven a Steve Jobs como uno de los resultados en el top 5. Una solución es realizar un análisis basado en el conjunto de resultados para verificar si la intención ha cambiado. Esto es similar a la retroalimentación de relevancia y requiere una clasificación en la segunda fase. Un segundo tipo de errores es el problema de reconocimiento de entidades/conceptos. Estos incluyen dos tipos. Una de ellas es que la variante de la palabra derivada ahora coincide con parte de una entidad o concepto. Por ejemplo, la consulta \"cookies en San Francisco\" se pluraliza como \"cookies\" O \"cookie en San Francisco\". Los resultados coincidirán con el tarro de galletas en San Francisco. Aunque \"cookie\" todavía significa lo mismo que \"galletas\", el concepto de \"cookie jar\" es diferente. Otro tipo es la palabra no derivada que coincide con una entidad o concepto debido al truncamiento de las otras palabras. Por ejemplo, la cita ICE se pluraliza como cita OR citas ICE. La intención original de esta consulta es buscar la cotización de acciones para el símbolo ICE. Sin embargo, notamos que entre los resultados principales, uno de los resultados es Citas sobre comida: Helado. Esto se empareja debido a las consultas afectadas dcg antiguas nuevas dcg dcg Mejora del modelo ingenuo 408/408 7.102 7.206 1.5% modelo sensible al contexto del documento 408/408 7.102 7.302 2.8% modelo selectivo: unigram LM 300/408 5.904 6.187 4.8% modelo selectivo: bigram LM 250/408 5.551 5.891 6.1% Tabla 6: Comparación de resultados solo sobre las consultas derivadas: la columna dcg antigua/nueva es la puntuación dcg sobre las consultas afectadas antes/después de aplicar la pluralización de la palabra entre comillas. La palabra inalterada ICE coincide con parte de la frase nominal helado aquí. Para resolver este tipo de problema, tenemos que analizar los documentos y reconocer \"cookie jar\" y \"ice cream\" como conceptos en lugar de dos palabras independientes. Un tercer tipo de errores ocurre en consultas largas. Para la consulta de software lector de códigos de barras, se pluralizan dos palabras. Códigos y lector. De hecho, el lector de códigos de barras en la consulta original es un concepto sólido y las palabras internas no deben ser cambiadas. Este es el problema de segmentación y detección de entidades y frases nominales en consultas, el cual estamos abordando activamente. Para consultas largas, debemos identificar correctamente los conceptos en la consulta y aumentar la proximidad de las palabras dentro de un concepto. 6. CONCLUSIONES Y TRABAJOS FUTUROS Hemos presentado una forma simple pero elegante de derivar palabras para la búsqueda en la web. Mejora el stemming ingenuo en dos aspectos: la expansión selectiva de palabras en el lado de la consulta y la coincidencia conservadora de ocurrencias de palabras en el lado del documento. Usando el manejo de pluralización como ejemplo, experimentos con datos de un motor de búsqueda web importante muestran que mejora significativamente la relevancia web y reduce el costo de derivación. También mejora significativamente la tasa de clics en la web (detalles no reportados en el artículo). Para el trabajo futuro, estamos investigando los problemas que identificamos en la sección de análisis de errores. Estos incluyen: errores de concordancia entre entidades y frases nominales, y una segmentación mejorada. 7. REFERENCIAS [1] E. Agichtein, E. Brill y S. T. Dumais. Mejorando la clasificación de búsqueda web al incorporar información sobre el comportamiento del usuario. En SIGIR, 2006. [2] E. Airio. Normalización de palabras y descomposición en IR monolingüe y bilingüe. Recuperación de información, 9:249-271, 2006. [3] P. Anick. Utilizando retroalimentación terminológica para el refinamiento de la búsqueda web: un estudio basado en registros. En SIGIR, 2003. [4] R. Baeza-Yates y B. Ribeiro-Neto. Recuperación de información moderna. ACM Press/Addison Wesley, 1999. [5] S. Chen y J. Goodman. Un estudio empírico de técnicas de suavizado para modelado del lenguaje. Informe técnico TR-10-98, Universidad de Harvard, 1998. [6] S. Cronen-Townsend, Y. Zhou y B. Croft. Un marco para la expansión selectiva de consultas. En CIKM, 2004. [7] H. Fang y C. Zhai. Coincidencia de términos semánticos en enfoques axiomáticos para la recuperación de información. En SIGIR, 2006. [8] W. B. Frakes. Confluencia de términos para la recuperación de información. En C. J. Rijsbergen, editor, Investigación y Desarrollo en Recuperación de Información, páginas 383-389. Cambridge University Press, 1984. [9] D. Harman.\nCambridge University Press, 1984. [9] D. Harman. ¿Qué tan efectivo es el sufijado? JASIS, 42(1):7-15, 1991. [10] D. Hull.\nJASIS, 42(1):7-15, 1991. [10] D. Hull. Algoritmos de derivación: un estudio de caso para una evaluación detallada. JASIS, 47(1):70-84, 1996. [11] K. Jarvelin y J. Kekalainen. Evaluación basada en la ganancia acumulada de técnicas de RI. ACM TOIS, 20:422-446, 2002. [12] R. Jones, B. Rey, O. Madani y W. Greiner. Generando Sustituciones de Consultas. En WWW, 2006. [13] W. Kraaij y R. Pohlmann. Viendo el Stemming como Mejora de la Recuperación. En SIGIR, 1996. [14] R. Krovetz. Viendo la morfología como un proceso de inferencia. En SIGIR, 1993. [15] D. Lin. Recuperación automática y agrupamiento de palabras similares. En COLING-ACL, 1998. [16] J. B. Lovins. Desarrollo de un algoritmo de derivación. Traducción Mecánica y Lingüística Computacional, II:22-31, 1968. [17] M. Lennon, D. Peirce, B. Tarry y P. Willett. Una evaluación de algunos algoritmos de confluencia para la recuperación de información. Revista de Ciencia de la Información, 3:177-188, 1981. [18] M. Porter. Un algoritmo para el recorte de sufijos. Programa, 14(3):130-137, 1980. [19] K. M. Risvik, T. Mikolajewski y P. Boros. Segmentación de consultas para búsqueda web. En WWW, 2003. [20] S. E. Robertson. Selección de términos para la expansión de consultas. Revista de Documentación, 46(4):359-364, 1990. [21] G. Salton y C. Buckley. Mejorando el rendimiento de recuperación mediante retroalimentación de relevancia. JASIS, 41(4):288 - 297, 1999. [22] R. Sun, C.-H. Ong, y T.-S. Chua. Extracción de relaciones de dependencia para la expansión de consultas en la recuperación de pasajes. En SIGIR, 2006. [23] C. Van Rijsbergen. Recuperación de información. Butterworths, segunda versión, 1979. [24] B. Vélez, R. Weiss, M. A. Sheldon y D. K. Gifford. Refinamiento de consultas rápido y efectivo. En SIGIR, 1997. [25] J. Xu y B. Croft. Expansión de consultas utilizando análisis local y global de documentos. En SIGIR, 1996. [26] J. Xu y B. Croft. Extracción de raíces basada en corpus utilizando la coocurrencia de variantes de palabras. ACM TOIS, 16 (1):61-81, 1998. ",
            "candidates": [],
            "error": [
                [
                    "se originan",
                    "truncamiento",
                    "truncamiento"
                ]
            ]
        },
        "language model": {
            "translated_key": "modelo de lenguaje",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Context Sensitive Stemming for Web Search Fuchun Peng Nawaaz Ahmed Xin Li Yumao Lu Yahoo!",
                "Inc. 701 First Avenue Sunnyvale, California 94089 {fuchun, nawaaz, xinli, yumaol}@yahoo-inc.com ABSTRACT Traditionally, stemming has been applied to Information Retrieval tasks by transforming words in documents to the their root form before indexing, and applying a similar transformation to query terms.",
                "Although it increases recall, this naive strategy does not work well for Web Search since it lowers precision and requires a significant amount of additional computation.",
                "In this paper, we propose a context sensitive stemming method that addresses these two issues.",
                "Two unique properties make our approach feasible for Web Search.",
                "First, based on statistical language modeling, we perform context sensitive analysis on the query side.",
                "We accurately predict which of its morphological variants is useful to expand a query term with before submitting the query to the search engine.",
                "This dramatically reduces the number of bad expansions, which in turn reduces the cost of additional computation and improves the precision at the same time.",
                "Second, our approach performs a context sensitive document matching for those expanded variants.",
                "This conservative strategy serves as a safeguard against spurious stemming, and it turns out to be very important for improving precision.",
                "Using word pluralization handling as an example of our stemming approach, our experiments on a major Web search engine show that stemming only 29% of the query traffic, we can improve relevance as measured by average Discounted Cumulative Gain (DCG5) by 6.1% on these queries and 1.8% over all query traffic.",
                "Categories and Subject Descriptors H.3.3 [Information Systems]: Information Storage and Retrieval-Query formulation General Terms Algorithms, Experimentation 1.",
                "INTRODUCTION Web search has now become a major tool in our daily lives for information seeking.",
                "One of the important issues in Web search is that user queries are often not best formulated to get optimal results.",
                "For example, running shoe is a query that occurs frequently in query logs.",
                "However, the query running shoes is much more likely to give better search results than the original query because documents matching the intent of this query usually contain the words running shoes.",
                "Correctly formulating a query requires the user to accurately predict which word form is used in the documents that best satisfy his or her information needs.",
                "This is difficult even for experienced users, and especially difficult for non-native speakers.",
                "One traditional solution is to use stemming [16, 18], the process of transforming inflected or derived words to their root form so that a search term will match and retrieve documents containing all forms of the term.",
                "Thus, the word run will match running, ran, runs, and shoe will match shoes and shoeing.",
                "Stemming can be done either on the terms in a document during indexing (and applying the same transformation to the query terms during query processing) or by expanding the query with the variants during query processing.",
                "Stemming during indexing allows very little flexibility during query processing, while stemming by query expansion allows handling each query differently, and hence is preferred.",
                "Although traditional stemming increases recall by matching word variants [13], it can reduce precision by retrieving too many documents that have been incorrectly matched.",
                "When examining the results of applying stemming to a large number of queries, one usually finds that nearly equal numbers of queries are helped and hurt by the technique [6].",
                "In addition, it reduces system performance because the search engine has to match all the word variants.",
                "As we will show in the experiments, this is true even if we simplify stemming to pluralization handling, which is the process of converting a word from its plural to singular form, or vice versa.",
                "Thus, one needs to be very cautious when using stemming in Web search engines.",
                "One problem of traditional stemming is its blind transformation of all query terms, that is, it always performs the same transformation for the same query word without considering the context of the word.",
                "For example, the word book has four forms book, books, booking, booked, and store has four forms store, stores, storing, stored.",
                "For the query book store, expanding both words to all of their variants significantly increases computation cost and hurts precision, since not all of the variants are useful for this query.",
                "Transforming book store to match book stores is fine, but matching book storing or booking store is not.",
                "A weighting method that gives variant words smaller weights alleviates the problems to a certain extent if the weights accurately reflect the importance of the variant in this particular query.",
                "However uniform weighting is not going to work and a query dependent weighting is still a challenging unsolved problem [20].",
                "A second problem of traditional stemming is its blind matching of all occurrences in documents.",
                "For the query book store, a transformation that allows the variant stores to be matched will cause every occurrence of stores in the document to be treated equivalent to the query term store.",
                "Thus, a document containing the fragment reading a book in coffee stores will be matched, causing many wrong documents to be selected.",
                "Although we hope the ranking function can correctly handle these, with many more candidates to rank, the risk of making mistakes increases.",
                "To alleviate these two problems, we propose a context sensitive stemming approach for Web search.",
                "Our solution consists of two context sensitive analysis, one on the query side and the other on the document side.",
                "On the query side, we propose a statistical language modeling based approach to predict which word variants are better forms than the original word for search purpose and expanding the query with only those forms.",
                "On the document side, we propose a conservative context sensitive matching for the transformed word variants, only matching document occurrences in the context of other terms in the query.",
                "Our model is simple yet effective and efficient, making it feasible to be used in real commercial Web search engines.",
                "We use pluralization handling as a running example for our stemming approach.",
                "The motivation for using pluralization handling as an example is to show that even such simple stemming, if handled correctly, can give significant benefits to search relevance.",
                "As far as we know, no previous research has systematically investigated the usage of pluralization in Web search.",
                "As we have to point out, the method we propose is not limited to pluralization handling, it is a general stemming technique, and can also be applied to general query expansion.",
                "Experiments on general stemming yield additional significant improvements over pluralization handling for long queries, although details will not be reported in this paper.",
                "In the rest of the paper, we first present the related work and distinguish our method from previous work in Section 2.",
                "We describe the details of the context sensitive stemming approach in Section 3.",
                "We then perform extensive experiments on a major Web search engine to support our claims in Section 4, followed by discussions in Section 5.",
                "Finally, we conclude the paper in Section 6. 2.",
                "RELATED WORK Stemming is a long studied technology.",
                "Many stemmers have been developed, such as the Lovins stemmer [16] and the Porter stemmer [18].",
                "The Porter stemmer is widely used due to its simplicity and effectiveness in many applications.",
                "However, the Porter stemming makes many mistakes because its simple rules cannot fully describe English morphology.",
                "Corpus analysis is used to improve Porter stemmer [26] by creating equivalence classes for words that are morphologically similar and occur in similar context as measured by expected mutual information [23].",
                "We use a similar corpus based approach for stemming by computing the similarity between two words based on their distributional context features which can be more than just adjacent words [15], and then only keep the morphologically similar words as candidates.",
                "Using stemming in information retrieval is also a well known technique [8, 10].",
                "However, the effectiveness of stemming for English query systems was previously reported to be rather limited.",
                "Lennon et al. [17] compared the Lovins and Porter algorithms and found little improvement in retrieval performance.",
                "Later, Harman [9] compares three general stemming techniques in text retrieval experiments including pluralization handing (called S stemmer in the paper).",
                "They also proposed selective stemming based on query length and term importance, but no positive results were reported.",
                "On the other hand, Krovetz [14] performed comparisons over small numbers of documents (from 400 to 12k) and showed dramatic precision improvement (up to 45%).",
                "However, due to the limited number of tested queries (less than 100) and the small size of the collection, the results are hard to generalize to Web search.",
                "These mixed results, mostly failures, led early IR researchers to deem stemming irrelevant in general for English [4], although recent research has shown stemming has greater benefits for retrieval in other languages [2].",
                "We suspect the previous failures were mainly due to the two problems we mentioned in the introduction.",
                "Blind stemming, or a simple query length based selective stemming as used in [9] is not enough.",
                "Stemming has to be decided on case by case basis, not only at the query level but also at the document level.",
                "As we will show, if handled correctly, significant improvement can be achieved.",
                "A more general problem related to stemming is query reformulation [3, 12] and query expansion which expands words not only with word variants [7, 22, 24, 25].",
                "To decide which expanded words to use, people often use pseudorelevance feedback techniquesthat send the original query to a search engine and retrieve the top documents, extract relevant words from these top documents as additional query words, and resubmit the expanded query again [21].",
                "This normally requires sending a query multiple times to search engine and it is not cost effective for processing the huge amount of queries involved in Web search.",
                "In addition, query expansion, including query reformulation [3, 12], has a high risk of changing the user intent (called query drift).",
                "Since the expanded words may have different meanings, adding them to the query could potentially change the intent of the original query.",
                "Thus query expansion based on pseudorelevance and query reformulation can provide suggestions to users for interactive refinement but can hardly be directly used for Web search.",
                "On the other hand, stemming is much more conservative since most of the time, stemming preserves the original search intent.",
                "While most work on query expansion focuses on recall enhancement, our work focuses on increasing both recall and precision.",
                "The increase on recall is obvious.",
                "With quality stemming, good documents which were not selected before stemming will be pushed up and those low quality documents will be degraded.",
                "On selective query expansion, Cronen-Townsend et al. [6] proposed a method for selective query expansion based on comparing the Kullback-Leibler divergence of the results from the unexpanded query and the results from the expanded query.",
                "This is similar to the relevance feedback in the sense that it requires multiple passes retrieval.",
                "If a word can be expanded into several words, it requires running this process multiple times to decide which expanded word is useful.",
                "It is expensive to deploy this in production Web search engines.",
                "Our method predicts the quality of expansion based on oﬄine information without sending the query to a search engine.",
                "In summary, we propose a novel approach to attack an old, yet still important and challenging problem for Web search - stemming.",
                "Our approach is unique in that it performs predictive stemming on a per query basis without relevance feedback from the Web, using the context of the variants in documents to preserve precision.",
                "Its simple, yet very efficient and effective, making real time stemming feasible for Web search.",
                "Our results will affirm researchers that stemming is indeed very important to large scale information retrieval. 3.",
                "CONTEXT SENSITIVE STEMMING 3.1 Overview Our system has four components as illustrated in Figure 1: candidate generation, query segmentation and head word detection, context sensitive query stemming and context sensitive document matching.",
                "Candidate generation (component 1) is performed oﬄine and generated candidates are stored in a dictionary.",
                "For an input query, we first segment query into concepts and detect the head word for each concept (component 2).",
                "We then use statistical language modeling to decide whether a particular variant is useful (component 3), and finally for the expanded variants, we perform context sensitive document matching (component 4).",
                "Below we discuss each of the components in more detail.",
                "Component 4: context sensitive document matching Input Query: and head word detection Component 2: segment Component 1: candidate generation comparisons −> comparison Component 3: selective word expansion decision: comparisons −> comparison example: hotel price comparisons output: hotel comparisons hotel −> hotels Figure 1: System Components 3.2 Expansion candidate generation One of the ways to generate candidates is using the Porter stemmer [18].",
                "The Porter stemmer simply uses morphological rules to convert a word to its base form.",
                "It has no knowledge of the semantic meaning of the words and sometimes makes serious mistakes, such as executive to execution, news to new, and paste to past.",
                "A more conservative way is based on using corpus analysis to improve the Porter stemmer results [26].",
                "The corpus analysis we do is based on word distributional similarity [15].",
                "The rationale of using distributional word similarity is that true variants tend to be used in similar contexts.",
                "In the distributional word similarity calculation, each word is represented with a vector of features derived from the context of the word.",
                "We use the bigrams to the left and right of the word as its context features, by mining a huge Web corpus.",
                "The similarity between two words is the cosine similarity between the two corresponding feature vectors.",
                "The top 20 similar words to develop is shown in the following table. rank candidate score rank candidate score 0 develop 1 10 berts 0.119 1 developing 0.339 11 wads 0.116 2 developed 0.176 12 developer 0.107 3 incubator 0.160 13 promoting 0.100 4 develops 0.150 14 developmental 0.091 5 development 0.148 15 reengineering 0.090 6 tutoring 0.138 16 build 0.083 7 analyzing 0.128 17 construct 0.081 8 developement 0.128 18 educational 0.081 9 automation 0.126 19 institute 0.077 Table 1: Top 20 most similar candidates to word develop.",
                "Column score is the similarity score.",
                "To determine the stemming candidates, we apply a few Porter stemmer [18] morphological rules to the similarity list.",
                "After applying these rules, for the word develop, the stemming candidates are developing, developed, develops, development, developement, developer, developmental.",
                "For the pluralization handling purpose, only the candidate develops is retained.",
                "One thing we note from observing the distributionally similar words is that they are closely related semantically.",
                "These words might serve as candidates for general query expansion, a topic we will investigate in the future. 3.3 Segmentation and headword identification For long queries, it is quite important to detect the concepts in the query and the most important words for those concepts.",
                "We first break a query into segments, each segment representing a concept which normally is a noun phrase.",
                "For each of the noun phrases, we then detect the most important word which we call the head word.",
                "Segmentation is also used in document sensitive matching (section 3.5) to enforce proximity.",
                "To break a query into segments, we have to define a criteria to measure the strength of the relation between words.",
                "One effective method is to use mutual information as an indicator on whether or not to split two words [19].",
                "We use a log of 25M queries and collect the bigram and unigram frequencies from it.",
                "For every incoming query, we compute the mutual information of two adjacent words; if it passes a predefined threshold, we do not split the query between those two words and move on to next word.",
                "We continue this process until the mutual information between two words is below the threshold, then create a concept boundary here.",
                "Table 2 shows some examples of query segmentation.",
                "The ideal way of finding the head word of a concept is to do syntactic parsing to determine the dependency structure of the query.",
                "Query parsing is more difficult than sentence [running shoe] [best] [new york] [medical schools] [pictures] [of] [white house] [cookies] [in] [san francisco] [hotel] [price comparison] Table 2: Query segmentation: a segment is bracketed. parsing since many queries are not grammatical and are very short.",
                "Applying a parser trained on sentences from documents to queries will have poor performance.",
                "In our solution, we just use simple heuristics rules, and it works very well in practice for English.",
                "For an English noun phrase, the head word is typically the last nonstop word, unless the phrase is of a particular pattern, like XYZ of/in/at/from UVW.",
                "In such cases, the head word is typically the last nonstop word of XYZ. 3.4 Context sensitive word expansion After detecting which words are the most important words to expand, we have to decide whether the expansions will be useful.",
                "Our statistics show that about half of the queries can be transformed by pluralization via naive stemming.",
                "Among this half, about 25% of the queries improve relevance when transformed, the majority (about 50%) do not change their top 5 results, and the remaining 25% perform worse.",
                "Thus, it is extremely important to identify which queries should not be stemmed for the purpose of maximizing relevance improvement and minimizing stemming cost.",
                "In addition, for a query with multiple words that can be transformed, or a word with multiple variants, not all of the expansions are useful.",
                "Taking query hotel price comparison as an example, we decide that hotel and price comparison are two concepts.",
                "Head words hotel and comparison can be expanded to hotels and comparisons.",
                "Are both transformations useful?",
                "To test whether an expansion is useful, we have to know whether the expanded query is likely to get more relevant documents from the Web, which can be quantified by the probability of the query occurring as a string on the Web.",
                "The more likely a query to occur on the Web, the more relevant documents this query is able to return.",
                "Now the whole problem becomes how to calculate the probability of query to occur on the Web.",
                "Calculating the probability of string occurring in a corpus is a well known language modeling problem.",
                "The goal of language modeling is to predict the probability of naturally occurring word sequences, s = w1w2...wN ; or more simply, to put high probability on word sequences that actually occur (and low probability on word sequences that never occur).",
                "The simplest and most successful approach to language modeling is still based on the n-gram model.",
                "By the chain rule of probability one can write the probability of any word sequence as Pr(w1w2...wN ) = NY i=1 Pr(wi|w1...wi−1) (1) An n-gram model approximates this probability by assuming that the only words relevant to predicting Pr(wi|w1...wi−1) are the previous n − 1 words; i.e.",
                "Pr(wi|w1...wi−1) = Pr(wi|wi−n+1...wi−1) A straightforward maximum likelihood estimate of n-gram probabilities from a corpus is given by the observed frequency of each of the patterns Pr(wi|wi−n+1...wi−1) = #(wi−n+1...wi) #(wi−n+1...wi−1) (2) where #(.) denotes the number of occurrences of a specified gram in the training corpus.",
                "Although one could attempt to use simple n-gram models to capture long range dependencies in language, attempting to do so directly immediately creates sparse data problems: Using grams of length up to n entails estimating the probability of Wn events, where W is the size of the word vocabulary.",
                "This quickly overwhelms modern computational and data resources for even modest choices of n (beyond 3 to 6).",
                "Also, because of the heavy tailed nature of language (i.e.",
                "Zipfs law) one is likely to encounter novel n-grams that were never witnessed during training in any test corpus, and therefore some mechanism for assigning non-zero probability to novel n-grams is a central and unavoidable issue in statistical language modeling.",
                "One standard approach to smoothing probability estimates to cope with sparse data problems (and to cope with potentially missing n-grams) is to use some sort of back-off estimator.",
                "Pr(wi|wi−n+1...wi−1) = 8 >>< >>: ˆPr(wi|wi−n+1...wi−1), if #(wi−n+1...wi) > 0 β(wi−n+1...wi−1) × Pr(wi|wi−n+2...wi−1), otherwise (3) where ˆPr(wi|wi−n+1...wi−1) = discount #(wi−n+1...wi) #(wi−n+1...wi−1) (4) is the discounted probability and β(wi−n+1...wi−1) is a normalization constant β(wi−n+1...wi−1) = 1 − X x∈(wi−n+1...wi−1x) ˆPr(x|wi−n+1...wi−1) 1 − X x∈(wi−n+1...wi−1x) ˆPr(x|wi−n+2...wi−1) (5) The discounted probability (4) can be computed with different smoothing techniques, including absolute smoothing, Good-Turing smoothing, linear smoothing, and Witten-Bell smoothing [5].",
                "We used absolute smoothing in our experiments.",
                "Since the likelihood of a string, Pr(w1w2...wN ), is a very small number and hard to interpret, we use entropy as defined below to score the string.",
                "Entropy = − 1 N log2 Pr(w1w2...wN ) (6) Now getting back to the example of the query hotel price comparisons, there are four variants of this query, and the entropy of these four candidates are shown in Table 3.",
                "We can see that all alternatives are less likely than the input query.",
                "It is therefore not useful to make an expansion for this query.",
                "On the other hand, if the input query is hotel price comparisons which is the second alternative in the table, then there is a better alternative than the input query, and it should therefore be expanded.",
                "To tolerate the variations in probability estimation, we relax the selection criterion to those query alternatives if their scores are within a certain distance (10% in our experiments) to the best score.",
                "Query variations Entropy hotel price comparison 6.177 hotel price comparisons 6.597 hotels price comparison 6.937 hotels price comparisons 7.360 Table 3: Variations of query hotel price comparison ranked by entropy score, with the original query in bold face. 3.5 Context sensitive document matching Even after we know which word variants are likely to be useful, we have to be conservative in document matching for the expanded variants.",
                "For the query hotel price comparisons, we decided that word comparisons is expanded to include comparison.",
                "However, not every occurrence of comparison in the document is of interest.",
                "A page which is about comparing customer service can contain all of the words hotel price comparisons comparison.",
                "This page is not a good page for the query.",
                "If we accept matches of every occurrence of comparison, it will hurt retrieval precision and this is one of the main reasons why most stemming approaches do not work well for information retrieval.",
                "To address this problem, we have a proximity constraint that considers the context around the expanded variant in the document.",
                "A variant match is considered valid only if the variant occurs in the same context as the original word does.",
                "The context is the left or the right non-stop segments 1 of the original word.",
                "Taking the same query as an example, the context of comparisons is price.",
                "The expanded word comparison is only valid if it is in the same context of comparisons, which is after the word price.",
                "Thus, we should only match those occurrences of comparison in the document if they occur after the word price.",
                "Considering the fact that queries and documents may not represent the intent in exactly the same way, we relax this proximity constraint to allow variant occurrences within a window of some fixed size.",
                "If the expanded word comparison occurs within the context of price within a window, it is considered valid.",
                "The smaller the window size is, the more restrictive the matching.",
                "We use a window size of 4, which typically captures contexts that include the containing and adjacent noun phrases. 4.",
                "EXPERIMENTAL EVALUATION 4.1 Evaluation metrics We will measure both relevance improvement and the stemming cost required to achieve the relevance. 1 a context segment can not be a single stop word. 4.1.1 Relevance measurement We use a variant of the average Discounted Cumulative Gain (DCG), a recently popularized scheme to measure search engine relevance [1, 11].",
                "Given a query and a ranked list of K documents (K is set to 5 in our experiments), the DCG(K) score for this query is calculated as follows: DCG(K) = KX k=1 gk log2(1 + k) . (7) where gk is the weight for the document at rank k. Higher degree of relevance corresponds to a higher weight.",
                "A page is graded into one of the five scales: Perfect, Excellent, Good, Fair, Bad, with corresponding weights.",
                "We use dcg to represent the average DCG(5) over a set of test queries. 4.1.2 Stemming cost Another metric is to measure the additional cost incurred by stemming.",
                "Given the same level of relevance improvement, we prefer a stemming method that has less additional cost.",
                "We measure this by the percentage of queries that are actually stemmed, over all the queries that could possibly be stemmed. 4.2 Data preparation We randomly sample 870 queries from a three month query log, with 290 from each month.",
                "Among all these 870 queries, we remove all misspelled queries since misspelled queries are not of interest to stemming.",
                "We also remove all one word queries since stemming one word queries without context has a high risk of changing query intent, especially for short words.",
                "In the end, we have 529 correctly spelled queries with at least 2 words. 4.3 Naive stemming for Web search Before explaining the experiments and results in detail, wed like to describe the traditional way of using stemming for Web search, referred as the naive model.",
                "This is to treat every word variant equivalent for all possible words in the query.",
                "The query book store will be transformed into (book OR books)(store OR stores) when limiting stemming to pluralization handling only, where OR is an operator that denotes the equivalence of the left and right arguments. 4.4 Experimental setup The baseline model is the model without stemming.",
                "We first run the naive model to see how well it performs over the baseline.",
                "Then we improve the naive stemming model by document sensitive matching, referred as document sensitive matching model.",
                "This model makes the same stemming as the naive model on the query side, but performs conservative matching on the document side using the strategy described in section 3.5.",
                "The naive model and document sensitive matching model stem the most queries.",
                "Out of the 529 queries, there are 408 queries that they stem, corresponding to 46.7% query traffic (out of a total of 870).",
                "We then further improve the document sensitive matching model from the query side with selective word stemming based on statistical language modeling (section 3.4), referred as selective stemming model.",
                "Based on language modeling prediction, this model stems only a subset of the 408 queries stemmed by the document sensitive matching model.",
                "We experiment with unigram <br>language model</br> and bigram <br>language model</br>.",
                "Since we only care how much we can improve the naive model, we will only use these 408 queries (all the queries that are affected by the naive stemming model) in the experiments.",
                "To get a sense of how these models perform, we also have an oracle model that gives the upper-bound performance a stemmer can achieve on this data.",
                "The oracle model only expands a word if the stemming will give better results.",
                "To analyze the pluralization handling influence on different query categories, we divide queries into short queries and long queries.",
                "Among the 408 queries stemmed by the naive model, there are 272 short queries with 2 or 3 words, and 136 long queries with at least 4 words. 4.5 Results We summarize the overall results in Table 4, and present the results on short queries and long queries separately in Table 5.",
                "Each row in Table 4 is a stemming strategy described in section 4.4.",
                "The first column is the name of the strategy.",
                "The second column is the number of queries affected by this strategy; this column measures the stemming cost, and the numbers should be low for the same level of dcg.",
                "The third column is the average dcg score over all tested queries in this category (including the ones that were not stemmed by the strategy).",
                "The fourth column is the relative improvement over the baseline, and the last column is the p-value of Wilcoxon significance test.",
                "There are several observations about the results.",
                "We can see the naively stemming only obtains a statistically insignificant improvement of 1.5%.",
                "Looking at Table 5, it gives an improvement of 2.7% on short queries.",
                "However, it also hurts long queries by -2.4%.",
                "Overall, the improvement is canceled out.",
                "The reason that it improves short queries is that most short queries only have one word that can be stemmed.",
                "Thus, blindly pluralizing short queries is relatively safe.",
                "However for long queries, most queries can have multiple words that can be pluralized.",
                "Expanding all of them without selection will significantly hurt precision.",
                "Document context sensitive stemming gives a significant lift to the performance, from 2.7% to 4.2% for short queries and from -2.4% to -1.6% for long queries, with an overall lift from 1.5% to 2.8%.",
                "The improvement comes from the conservative context sensitive document matching.",
                "An expanded word is valid only if it occurs within the context of original query in the document.",
                "This reduces many spurious matches.",
                "However, we still notice that for long queries, context sensitive stemming is not able to improve performance because it still selects too many documents and gives the ranking function a hard problem.",
                "While the chosen window size of 4 works the best amongst all the choices, it still allows spurious matches.",
                "It is possible that the window size needs to be chosen on a per query basis to ensure tighter proximity constraints for different types of noun phrases.",
                "Selective word pluralization further helps resolving the problem faced by document context sensitive stemming.",
                "It does not stem every word that places all the burden on the ranking algorithm, but tries to eliminate unnecessary stemming in the first place.",
                "By predicting which word variants are going to be useful, we can dramatically reduce the number of stemmed words, thus improving both the recall and the precision.",
                "With the unigram <br>language model</br>, we can reduce the stemming cost by 26.7% (from 408/408 to 300/408) and lift the overall dcg improvement from 2.8% to 3.4%.",
                "In particular, it gives significant improvements on long queries.",
                "The dcg gain is turned from negative to positive, from −1.6% to 1.1%.",
                "This confirms our hypothesis that reducing unnecessary word expansion leads to precision improvement.",
                "For short queries too, we observe both dcg improvement and stemming cost reduction with the unigram <br>language model</br>.",
                "The advantages of predictive word expansion with a <br>language model</br> is further boosted with a better bigram <br>language model</br>.",
                "The overall dcg gain is lifted from 3.4% to 3.9%, and stemming cost is dramatically reduced from 408/408 to 250/408, corresponding to only 29% of query traffic (250 out of 870) and an overall 1.8% dcg improvement overall all query traffic.",
                "For short queries, bigram <br>language model</br> improves the dcg gain from 4.4% to 4.7%, and reduces stemming cost from 272/272 to 150/272.",
                "For long queries, bigram <br>language model</br> improves dcg gain from 1.1% to 2.5%, and reduces stemming cost from 136/136 to 100/136.",
                "We observe that the bigram <br>language model</br> gives a larger lift for long queries.",
                "This is because the uncertainty in long queries is larger and a more powerful <br>language model</br> is needed.",
                "We hypothesize that a trigram <br>language model</br> would give a further lift for long queries and leave this for future investigation.",
                "Considering the tight upper-bound 2 on the improvement to be gained from pluralization handling (via the oracle model), the current performance on short queries is very satisfying.",
                "For short queries, the dcg gain upper-bound is 6.3% for perfect pluralization handling, our current gain is 4.7% with a bigram <br>language model</br>.",
                "For long queries, the dcg gain upper-bound is 4.6% for perfect pluralization handling, our current gain is 2.5% with a bigram <br>language model</br>.",
                "We may gain additional benefit with a more powerful <br>language model</br> for long queries.",
                "However, the difficulties of long queries come from many other aspects including the proximity and the segmentation problem.",
                "These problems have to be addressed separately.",
                "Looking at the the upper-bound of overhead reduction for oracle stemming, 75% (308/408) of the naive stemmings are wasteful.",
                "We currently capture about half of them.",
                "Further reduction of the overhead requires sacrificing the dcg gain.",
                "Now we can compare the stemming strategies from a different aspect.",
                "Instead of looking at the influence over all queries as we described above, Table 6 summarizes the dcg improvements over the affected queries only.",
                "We can see that the number of affected queries decreases as the stemming strategy becomes more accurate (dcg improvement).",
                "For the bigram <br>language model</br>, over the 250/408 stemmed queries, the dcg improvement is 6.1%.",
                "An interesting observation is the average dcg decreases with a better model, which indicates a better stemming strategy stems more difficult queries (low dcg queries). 5.",
                "DISCUSSIONS 5.1 Language models from query vs. from Web As we mentioned in Section 1, we are trying to predict the probability of a string occurring on the Web.",
                "The <br>language model</br> should describe the occurrence of the string on the Web.",
                "However, the query log is also a good resource. 2 Note that this upperbound is for pluralization handling only, not for general stemming.",
                "General stemming gives a 8% upperbound, which is quite substantial in terms of our metrics.",
                "Affected Queries dcg dcg Improvement p-value baseline 0/408 7.102 N/A N/A naive model 408/408 7.206 1.5% 0.22 document context sensitive model 408/408 7.302 2.8% 0.014 selective model: unigram LM 300/408 7.321 3.4% 0.001 selective model: bigram LM 250/408 7.381 3.9% 0.001 oracle model 100/408 7.519 5.9% 0.001 Table 4: Results comparison of different stemming strategies over all queries affected by naive stemming Short Query Results Affected Queries dcg Improvement p-value baseline 0/272 N/A N/A naive model 272/272 2.7% 0.48 document context sensitive model 272/272 4.2% 0.002 selective model: unigram LM 185/272 4.4% 0.001 selective model: bigram LM 150/272 4.7% 0.001 oracle model 71/272 6.3% 0.001 Long Query Results Affected Queries dcg Improvement p-value baseline 0/136 N/A N/A naive model 136/136 -2.4% 0.25 document context sensitive model 136/136 -1.6% 0.27 selective model: unigram LM 115/136 1.1% 0.001 selective model: bigram LM 100/136 2.5% 0.001 oracle model 29/136 4.6% 0.001 Table 5: Results comparison of different stemming strategies overall short queries and long queries Users reformulate a query using many different variants to get good results.",
                "To test the hypothesis that we can learn reliable transformation probabilities from the query log, we trained a <br>language model</br> from the same query top 25M queries as used to learn segmentation, and use that for prediction.",
                "We observed a slight performance decrease compared to the model trained on Web frequencies.",
                "In particular, the performance for unigram LM was not affected, but the dcg gain for bigram LM changed from 4.7% to 4.5% for short queries.",
                "Thus, the query log can serve as a good approximation of the Web frequencies. 5.2 How linguistics helps Some linguistic knowledge is useful in stemming.",
                "For the pluralization handling case, pluralization and de-pluralization is not symmetric.",
                "A plural word used in a query indicates a special intent.",
                "For example, the query new york hotels is looking for a list of hotels in new york, not the specific new york hotel which might be a hotel located in California.",
                "A simple equivalence of hotel to hotels might boost a particular page about new york hotel to top rank.",
                "To capture this intent, we have to make sure the document is a general page about hotels in new york.",
                "We do this by requiring that the plural word hotels appears in the document.",
                "On the other hand, converting a singular word to plural is safer since a general purpose page normally contains specific information.",
                "We observed a slight overall dcg decrease, although not statistically significant, for document context sensitive stemming if we do not consider this asymmetric property. 5.3 Error analysis One type of mistakes we noticed, though rare but seriously hurting relevance, is the search intent change after stemming.",
                "Generally speaking, pluralization or depluralization keeps the original intent.",
                "However, the intent could change in a few cases.",
                "For one example of such a query, job at apple, we pluralize job to jobs.",
                "This stemming makes the original query ambiguous.",
                "The query job OR jobs at apple has two intents.",
                "One is the employment opportunities at apple, and another is a person working at Apple, Steve Jobs, who is the CEO and co-founder of the company.",
                "Thus, the results after query stemming returns Steve Jobs as one of the results in top 5.",
                "One solution is performing results set based analysis to check if the intent is changed.",
                "This is similar to relevance feedback and requires second phase ranking.",
                "A second type of mistakes is the entity/concept recognition problem, These include two kinds.",
                "One is that the stemmed word variant now matches part of an entity or concept.",
                "For example, query cookies in san francisco is pluralized to cookies OR cookie in san francisco.",
                "The results will match cookie jar in san francisco.",
                "Although cookie still means the same thing as cookies, cookie jar is a different concept.",
                "Another kind is the unstemmed word matches an entity or concept because of the stemming of the other words.",
                "For example, quote ICE is pluralized to quote OR quotes ICE.",
                "The original intent for this query is searching for stock quote for ticker ICE.",
                "However, we noticed that among the top results, one of the results is Food quotes: Ice cream.",
                "This is matched because of Affected Queries old dcg new dcg dcg Improvement naive model 408/408 7.102 7.206 1.5% document context sensitive model 408/408 7.102 7.302 2.8% selective model: unigram LM 300/408 5.904 6.187 4.8% selective model: bigram LM 250/408 5.551 5.891 6.1% Table 6: Results comparison over the stemmed queries only: column old/new dcg is the dcg score over the affected queries before/after applying stemming the pluralized word quotes.",
                "The unchanged word ICE matches part of the noun phrase ice cream here.",
                "To solve this kind of problem, we have to analyze the documents and recognize cookie jar and ice cream as concepts instead of two independent words.",
                "A third type of mistakes occurs in long queries.",
                "For the query bar code reader software, two words are pluralized. code to codes and reader to readers.",
                "In fact, bar code reader in the original query is a strong concept and the internal words should not be changed.",
                "This is the segmentation and entity and noun phrase detection problem in queries, which we actively are attacking.",
                "For long queries, we should correctly identify the concepts in the query, and boost the proximity for the words within a concept. 6.",
                "CONCLUSIONS AND FUTURE WORK We have presented a simple yet elegant way of stemming for Web search.",
                "It improves naive stemming in two aspects: selective word expansion on the query side and conservative word occurrence matching on the document side.",
                "Using pluralization handling as an example, experiments on a major Web search engine data show it significantly improves the Web relevance and reduces the stemming cost.",
                "It also significantly improves Web click through rate (details not reported in the paper).",
                "For the future work, we are investigating the problems we identified in the error analysis section.",
                "These include: entity and noun phrase matching mistakes, and improved segmentation. 7.",
                "REFERENCES [1] E. Agichtein, E. Brill, and S. T. Dumais.",
                "Improving Web Search Ranking by Incorporating User Behavior Information.",
                "In SIGIR, 2006. [2] E. Airio.",
                "Word Normalization and Decompounding in Mono- and Bilingual IR.",
                "Information Retrieval, 9:249-271, 2006. [3] P. Anick.",
                "Using Terminological Feedback for Web Search Refinement: a Log-based Study.",
                "In SIGIR, 2003. [4] R. Baeza-Yates and B. Ribeiro-Neto.",
                "Modern Information Retrieval.",
                "ACM Press/Addison Wesley, 1999. [5] S. Chen and J. Goodman.",
                "An Empirical Study of Smoothing Techniques for Language Modeling.",
                "Technical Report TR-10-98, Harvard University, 1998. [6] S. Cronen-Townsend, Y. Zhou, and B. Croft.",
                "A Framework for Selective Query Expansion.",
                "In CIKM, 2004. [7] H. Fang and C. Zhai.",
                "Semantic Term Matching in Axiomatic Approaches to Information Retrieval.",
                "In SIGIR, 2006. [8] W. B. Frakes.",
                "Term Conflation for Information Retrieval.",
                "In C. J. Rijsbergen, editor, Research and Development in Information Retrieval, pages 383-389.",
                "Cambridge University Press, 1984. [9] D. Harman.",
                "How Effective is Suffixing?",
                "JASIS, 42(1):7-15, 1991. [10] D. Hull.",
                "Stemming Algorithms - A Case Study for Detailed Evaluation.",
                "JASIS, 47(1):70-84, 1996. [11] K. Jarvelin and J. Kekalainen.",
                "Cumulated Gain-Based Evaluation Evaluation of IR Techniques.",
                "ACM TOIS, 20:422-446, 2002. [12] R. Jones, B. Rey, O. Madani, and W. Greiner.",
                "Generating Query Substitutions.",
                "In WWW, 2006. [13] W. Kraaij and R. Pohlmann.",
                "Viewing Stemming as Recall Enhancement.",
                "In SIGIR, 1996. [14] R. Krovetz.",
                "Viewing Morphology as an Inference Process.",
                "In SIGIR, 1993. [15] D. Lin.",
                "Automatic Retrieval and Clustering of Similar Words.",
                "In COLING-ACL, 1998. [16] J.",
                "B. Lovins.",
                "Development of a Stemming Algorithm.",
                "Mechanical Translation and Computational Linguistics, II:22-31, 1968. [17] M. Lennon and D. Peirce and B. Tarry and P. Willett.",
                "An Evaluation of Some Conflation Algorithms for Information Retrieval.",
                "Journal of Information Science, 3:177-188, 1981. [18] M. Porter.",
                "An Algorithm for Suffix Stripping.",
                "Program, 14(3):130-137, 1980. [19] K. M. Risvik, T. Mikolajewski, and P. Boros.",
                "Query Segmentation for Web Search.",
                "In WWW, 2003. [20] S. E. Robertson.",
                "On Term Selection for Query Expansion.",
                "Journal of Documentation, 46(4):359-364, 1990. [21] G. Salton and C. Buckley.",
                "Improving Retrieval Performance by Relevance Feedback.",
                "JASIS, 41(4):288 - 297, 1999. [22] R. Sun, C.-H. Ong, and T.-S. Chua.",
                "Mining Dependency Relations for Query Expansion in Passage Retrieval.",
                "In SIGIR, 2006. [23] C. Van Rijsbergen.",
                "Information Retrieval.",
                "Butterworths, second version, 1979. [24] B. V´elez, R. Weiss, M. A. Sheldon, and D. K. Gifford.",
                "Fast and Effective Query Refinement.",
                "In SIGIR, 1997. [25] J. Xu and B. Croft.",
                "Query Expansion using Local and Global Document Analysis.",
                "In SIGIR, 1996. [26] J. Xu and B. Croft.",
                "Corpus-based Stemming using Cooccurrence of Word Variants.",
                "ACM TOIS, 16 (1):61-81, 1998."
            ],
            "original_annotated_samples": [
                "We experiment with unigram <br>language model</br> and bigram <br>language model</br>.",
                "With the unigram <br>language model</br>, we can reduce the stemming cost by 26.7% (from 408/408 to 300/408) and lift the overall dcg improvement from 2.8% to 3.4%.",
                "For short queries too, we observe both dcg improvement and stemming cost reduction with the unigram <br>language model</br>.",
                "The advantages of predictive word expansion with a <br>language model</br> is further boosted with a better bigram <br>language model</br>.",
                "For short queries, bigram <br>language model</br> improves the dcg gain from 4.4% to 4.7%, and reduces stemming cost from 272/272 to 150/272."
            ],
            "translated_annotated_samples": [
                "Experimentamos con un <br>modelo de lenguaje</br> unigrama y un <br>modelo de lenguaje</br> bigrama.",
                "Con el <br>modelo de lenguaje</br> unigrama, podemos reducir el costo de derivación en un 26.7% (de 408/408 a 300/408) y aumentar la mejora general de DCG del 2.8% al 3.4%.",
                "Para consultas cortas también observamos tanto la mejora de dcg como la reducción del costo de derivación con el <br>modelo de lenguaje</br> unigrama.",
                "Las ventajas de la expansión predictiva de palabras con un <br>modelo de lenguaje</br> se potencian aún más con un mejor <br>modelo de lenguaje</br> de bigrama.",
                "Para consultas cortas, el <br>modelo de lenguaje</br> de bigrama mejora la ganancia de DCG del 4.4% al 4.7%, y reduce el costo de derivación de 272/272 a 150/272."
            ],
            "translated_text": "Stemming sensible al contexto para la búsqueda web Fuchun Peng Nawaaz Ahmed Xin Li Yumao Lu Yahoo! Tradicionalmente, el truncamiento se ha aplicado a tareas de Recuperación de Información transformando las palabras en documentos a su forma raíz antes de indexarlas, y aplicando una transformación similar a los términos de consulta. Aunque aumenta la recuperación, esta estrategia ingenua no funciona bien para la Búsqueda en la Web, ya que disminuye la precisión y requiere una cantidad significativa de cálculos adicionales. En este artículo, proponemos un método de derivación sensible al contexto que aborda estos dos problemas. Dos propiedades únicas hacen que nuestro enfoque sea factible para la Búsqueda en la Web. Primero, basados en modelado estadístico del lenguaje, realizamos un análisis sensible al contexto en el lado de la consulta. Predecimos con precisión cuál de sus variantes morfológicas es útil para expandir un término de consulta antes de enviar la consulta al motor de búsqueda. Esto reduce drásticamente la cantidad de expansiones incorrectas, lo que a su vez disminuye el costo de la computación adicional y mejora la precisión al mismo tiempo. Segundo, nuestro enfoque realiza una coincidencia de documentos sensible al contexto para esas variantes ampliadas. Esta estrategia conservadora sirve como salvaguarda contra el truncamiento espurio, y resulta ser muy importante para mejorar la precisión. Usando el manejo de la pluralización de palabras como un ejemplo de nuestro enfoque de derivación, nuestros experimentos en un importante motor de búsqueda web muestran que al derivar solo el 29% del tráfico de consultas, podemos mejorar la relevancia medida por la Ganancia Acumulativa Descontada promedio (DCG5) en un 6.1% en estas consultas y en un 1.8% sobre todo el tráfico de consultas. Categorías y Descriptores de Asignaturas H.3.3 [Sistemas de Información]: Almacenamiento y Recuperación de Información-Formulación de Consultas Términos Generales Algoritmos, Experimentación 1. INTRODUCCIÓN La búsqueda en la web se ha convertido en una herramienta importante en nuestra vida diaria para buscar información. Uno de los problemas importantes en la búsqueda web es que las consultas de los usuarios a menudo no están formuladas de la mejor manera para obtener resultados óptimos. Por ejemplo, \"zapatilla para correr\" es una consulta que ocurre con frecuencia en los registros de consulta. Sin embargo, es mucho más probable que la búsqueda \"zapatillas para correr\" proporcione mejores resultados de búsqueda que la consulta original, ya que los documentos que coinciden con la intención de esta consulta suelen contener las palabras \"zapatillas para correr\". Formular correctamente una consulta requiere que el usuario prediga con precisión qué forma de palabra se utiliza en los documentos que mejor satisfacen sus necesidades de información. Esto es difícil incluso para usuarios experimentados, y especialmente difícil para hablantes no nativos. Una solución tradicional es utilizar el stemming [16, 18], el proceso de transformar palabras flexionadas o derivadas a su forma raíz para que un término de búsqueda coincida y recupere documentos que contengan todas las formas del término. Por lo tanto, la palabra \"run\" coincidirá con \"running\", \"ran\", \"runs\", y \"shoe\" coincidirá con \"shoes\" y \"shoeing\". El truncamiento se puede realizar tanto en los términos de un documento durante la indexación (y aplicando la misma transformación a los términos de la consulta durante el procesamiento de la consulta) o expandiendo la consulta con las variantes durante el procesamiento de la consulta. El truncamiento durante la indexación permite muy poca flexibilidad durante el procesamiento de consultas, mientras que el truncamiento mediante la expansión de consultas permite manejar cada consulta de manera diferente, y por lo tanto es preferible. Aunque el truncamiento tradicional aumenta la recuperación al emparejar variantes de palabras [13], puede reducir la precisión al recuperar demasiados documentos que han sido emparejados incorrectamente. Al examinar los resultados de aplicar el truncamiento a un gran número de consultas, generalmente se encuentra que casi igual cantidad de consultas se benefician y se ven perjudicadas por la técnica [6]. Además, reduce el rendimiento del sistema porque el motor de búsqueda tiene que hacer coincidir todas las variantes de palabras. Como mostraremos en los experimentos, esto es cierto incluso si simplificamos el proceso de derivación a la manipulación de pluralización, que es el proceso de convertir una palabra de su forma plural a singular, o viceversa. Por lo tanto, es necesario ser muy cauteloso al utilizar el stemming en los motores de búsqueda web. Un problema del truncamiento tradicional es su transformación ciega de todos los términos de consulta, es decir, siempre realiza la misma transformación para la misma palabra de consulta sin considerar el contexto de la palabra. Por ejemplo, la palabra \"book\" tiene cuatro formas: book, books, booking, booked, y la palabra \"store\" tiene cuatro formas: store, stores, storing, stored. Para la consulta de la librería, expandir ambas palabras a todas sus variantes aumenta significativamente el costo de computación y perjudica la precisión, ya que no todas las variantes son útiles para esta consulta. Transformar librería para que coincida con librerías está bien, pero hacer coincidir almacenamiento de libros o tienda de reservas no lo está. Un método de ponderación que otorga pesos más pequeños a las palabras variantes alivia los problemas hasta cierto punto si los pesos reflejan con precisión la importancia de la variante en esta consulta particular. Sin embargo, el peso uniforme no va a funcionar y un peso dependiente de la consulta sigue siendo un problema desafiante sin resolver [20]. Un segundo problema del truncamiento tradicional es su emparejamiento ciego de todas las ocurrencias en los documentos. Para la consulta de la librería, una transformación que permita que las tiendas variantes se emparejen hará que cada aparición de tiendas en el documento se trate de manera equivalente al término de consulta tienda. Por lo tanto, se emparejará un documento que contenga el fragmento de leer un libro en las cafeterías, lo que provocará que se seleccionen muchos documentos incorrectos. Aunque esperamos que la función de clasificación pueda manejar correctamente estos, con muchos más candidatos para clasificar, el riesgo de cometer errores aumenta. Para aliviar estos dos problemas, proponemos un enfoque de reducción de palabras raíz sensible al contexto para la búsqueda en la web. Nuestra solución consiste en dos análisis contextuales sensibles, uno en el lado de la consulta y otro en el lado del documento. En el lado de la consulta, proponemos un enfoque basado en modelado del lenguaje estadístico para predecir qué variantes de palabras son mejores formas que la palabra original con fines de búsqueda y expandir la consulta solo con esas formas. En el lado del documento, proponemos un emparejamiento conservador sensible al contexto para las variantes de palabras transformadas, solo emparejando las ocurrencias en el documento en el contexto de otros términos en la consulta. Nuestro modelo es simple pero efectivo y eficiente, lo que lo hace factible de ser utilizado en motores de búsqueda web comerciales reales. Utilizamos el manejo de pluralización como un ejemplo continuo para nuestro enfoque de derivación. La motivación para usar el manejo de pluralización como ejemplo es mostrar que incluso un truncamiento tan simple, si se maneja correctamente, puede brindar beneficios significativos a la relevancia de la búsqueda. Hasta donde sabemos, ninguna investigación previa ha investigado sistemáticamente el uso de la pluralización en la búsqueda en la web. Como debemos señalar, el método que proponemos no se limita al manejo de la pluralización, es una técnica de derivación general y también se puede aplicar a la expansión de consultas en general. Los experimentos sobre el truncamiento general producen mejoras significativas adicionales sobre el manejo de la pluralización para consultas largas, aunque los detalles no se informarán en este artículo. En el resto del documento, primero presentamos el trabajo relacionado y distinguimos nuestro método de trabajos anteriores en la Sección 2. Describimos los detalles del enfoque de derivación sensible al contexto en la Sección 3. Luego realizamos experimentos extensos en un importante motor de búsqueda web para respaldar nuestras afirmaciones en la Sección 4, seguidos de discusiones en la Sección 5. Finalmente, concluimos el artículo en la Sección 6.2. TRABAJO RELACIONADO El stemming es una tecnología estudiada desde hace mucho tiempo. Se han desarrollado muchos stemmers, como el stemmer Lovins [16] y el stemmer Porter [18]. El stemmer de Porter es ampliamente utilizado debido a su simplicidad y efectividad en muchas aplicaciones. Sin embargo, el algoritmo de Porter comete muchos errores porque sus reglas simples no pueden describir completamente la morfología del inglés. El análisis de corpus se utiliza para mejorar el stemmer de Porter [26] mediante la creación de clases de equivalencia para palabras que son morfológicamente similares y que ocurren en un contexto similar, medido por la información mutua esperada [23]. Utilizamos un enfoque de corpus similar para el stemming al calcular la similitud entre dos palabras basada en sus características de contexto distribucional, que pueden ser más que solo palabras adyacentes [15], y luego solo mantenemos las palabras morfológicamente similares como candidatas. El uso de la derivación en la recuperación de información también es una técnica bien conocida [8, 10]. Sin embargo, se informó previamente que la efectividad del truncamiento para los sistemas de consulta en inglés era bastante limitada. Lennon et al. [17] compararon los algoritmos de Lovins y Porter y encontraron poco mejoramiento en el rendimiento de recuperación. Más tarde, Harman [9] compara tres técnicas generales de derivación en experimentos de recuperación de texto, incluido el manejo de pluralización (llamado S stemmer en el artículo). También propusieron el truncamiento selectivo basado en la longitud de la consulta y la importancia del término, pero no se informaron resultados positivos. Por otro lado, Krovetz [14] realizó comparaciones sobre un pequeño número de documentos (de 400 a 12k) y mostró una mejora dramática en la precisión (de hasta un 45%). Sin embargo, debido al número limitado de consultas probadas (menos de 100) y al tamaño reducido de la colección, los resultados son difíciles de generalizar para la búsqueda en la web. Estos resultados mixtos, en su mayoría fracasos, llevaron a los primeros investigadores de IR a considerar que el truncamiento era irrelevante en general para el inglés [4], aunque investigaciones recientes han demostrado que el truncamiento tiene mayores beneficios para la recuperación en otros idiomas [2]. Sospechamos que los fracasos anteriores se debieron principalmente a los dos problemas que mencionamos en la introducción. El stemming ciego, o un stemming selectivo basado en la longitud de la consulta como se utiliza en [9], no es suficiente. El truncamiento debe decidirse caso por caso, no solo a nivel de consulta sino también a nivel de documento. Como demostraremos, si se maneja correctamente, se puede lograr una mejora significativa. Un problema más general relacionado con el stemming es la reformulación de consultas [3, 12] y la expansión de consultas que amplía las palabras no solo con variantes de palabras [7, 22, 24, 25]. Para decidir qué palabras expandidas usar, las personas a menudo utilizan técnicas de retroalimentación de seudorelevancia que envían la consulta original a un motor de búsqueda y recuperan los documentos principales, extraen palabras relevantes de estos documentos principales como palabras de consulta adicionales y vuelven a enviar la consulta expandida nuevamente [21]. Esto normalmente requiere enviar una consulta varias veces al motor de búsqueda y no es rentable para procesar la gran cantidad de consultas involucradas en la búsqueda web. Además, la expansión de consultas, incluida la reformulación de consultas [3, 12], tiene un alto riesgo de cambiar la intención del usuario (llamado desviación de consulta). Dado que las palabras expandidas pueden tener diferentes significados, agregarlas a la consulta podría potencialmente cambiar la intención de la consulta original. Por lo tanto, la expansión de consultas basada en pseudorelevancia y la reformulación de consultas pueden proporcionar sugerencias a los usuarios para su refinamiento interactivo, pero difícilmente pueden ser utilizadas directamente para la búsqueda en la web. Por otro lado, el truncamiento es mucho más conservador ya que la mayoría de las veces, conserva la intención de búsqueda original. Si bien la mayoría de los trabajos sobre la expansión de consultas se centran en mejorar la recuperación, nuestro trabajo se enfoca en aumentar tanto la recuperación como la precisión. El aumento en el recuerdo es evidente. Con el stemming de calidad, los buenos documentos que no fueron seleccionados antes del stemming serán promovidos y aquellos documentos de baja calidad serán degradados. En la expansión selectiva de consultas, Cronen-Townsend et al. [6] propusieron un método para la expansión selectiva de consultas basado en comparar la divergencia de Kullback-Leibler de los resultados de la consulta no expandida y los resultados de la consulta expandida. Esto es similar a la retroalimentación de relevancia en el sentido de que requiere múltiples pasadas de recuperación. Si una palabra puede expandirse en varias palabras, se requiere ejecutar este proceso varias veces para decidir cuál palabra expandida es útil. Es costoso implementar esto en motores de búsqueda web en producción. Nuestro método predice la calidad de la expansión basándose en información sin conexión sin enviar la consulta a un motor de búsqueda. En resumen, proponemos un enfoque novedoso para abordar un problema antiguo, pero aún importante y desafiante para la búsqueda en la web: el stemming. Nuestro enfoque es único en el sentido de que realiza el truncamiento predictivo de forma individualizada para cada consulta sin retroalimentación de relevancia de la Web, utilizando el contexto de las variantes en los documentos para preservar la precisión. Es simple, pero muy eficiente y efectivo, lo que hace factible el truncamiento en tiempo real para la búsqueda en la web. Nuestros resultados confirmarán a los investigadores que el truncamiento es realmente muy importante para la recuperación de información a gran escala. STEMMING CONTEXTUAL SENSIBLE 3.1 Resumen Nuestro sistema tiene cuatro componentes como se ilustra en la Figura 1: generación de candidatos, segmentación de consultas y detección de palabras clave, derivación de consultas sensible al contexto y coincidencia de documentos sensible al contexto. La generación de candidatos (componente 1) se realiza fuera de línea y los candidatos generados se almacenan en un diccionario. Para una consulta de entrada, primero segmentamos la consulta en conceptos y detectamos la palabra principal de cada concepto (componente 2). Luego utilizamos modelado de lenguaje estadístico para decidir si una variante particular es útil (componente 3), y finalmente, para las variantes expandidas, realizamos un emparejamiento de documentos sensible al contexto (componente 4). A continuación discutimos cada uno de los componentes con más detalle. Componente 4: coincidencia de documentos sensibles al contexto Consulta de entrada: y detección de palabras clave Componente 2: segmento Componente 1: generación de candidatos comparaciones −> comparación Componente 3: decisión de expansión selectiva de palabras: comparaciones −> comparación ejemplo: comparaciones de precios de hoteles salida: comparaciones de hoteles hotel −> hoteles Figura 1: Componentes del sistema 3.2 Generación de candidatos de expansión Una de las formas de generar candidatos es utilizando el stemmer de Porter [18]. El stemmer de Porter simplemente utiliza reglas morfológicas para convertir una palabra a su forma base. No tiene conocimiento del significado semántico de las palabras y a veces comete errores graves, como cambiar \"executive\" por \"execution\", \"news\" por \"new\" y \"paste\" por \"past\". Una forma más conservadora se basa en utilizar análisis de corpus para mejorar los resultados del stemmer de Porter [26]. El análisis de corpus que realizamos se basa en la similitud distribucional de palabras [15]. La razón de utilizar la similitud distribucional de palabras es que las variantes verdaderas tienden a ser utilizadas en contextos similares. En el cálculo de similitud de palabras distribucionales, cada palabra se representa con un vector de características derivadas del contexto de la palabra. Utilizamos los bigramas a la izquierda y a la derecha de la palabra como sus características de contexto, mediante la extracción de un gran corpus web. La similitud entre dos palabras es la similitud coseno entre los dos vectores de características correspondientes. Las 20 palabras similares a \"desarrollar\" se muestran en la siguiente tabla. rango candidato puntaje rango candidato puntaje 0 desarrollar 1 10 berts 0.119 1 desarrollando 0.339 11 wads 0.116 2 desarrollado 0.176 12 desarrollador 0.107 3 incubadora 0.160 13 promoviendo 0.100 4 desarrolla 0.150 14 desarrollo 0.091 5 desarrollo 0.148 15 reingeniería 0.090 6 tutoría 0.138 16 construir 0.083 7 analizando 0.128 17 construir 0.081 8 desarrollo 0.128 18 educativo 0.081 9 automatización 0.126 19 instituto 0.077 Tabla 1: Los 20 candidatos más similares a la palabra \"desarrollar\". La puntuación de la columna es la puntuación de similitud. Para determinar los candidatos de derivación, aplicamos algunas reglas morfológicas del stemmer de Porter [18] a la lista de similitud. Después de aplicar estas reglas, para la palabra desarrollar, los candidatos de derivación son desarrollando, desarrollado, desarrolla, desarrollo, desarrollo, desarrollador, y desarrollo. Para el propósito de manejo de pluralización, solo se conserva el candidato desarrolla. Una cosa que observamos al observar las palabras distribucionalmente similares es que están estrechamente relacionadas semánticamente. Estas palabras podrían servir como candidatas para la expansión general de consultas, un tema que investigaremos en el futuro. 3.3 Segmentación e identificación de palabras clave Para consultas largas, es bastante importante detectar los conceptos en la consulta y las palabras más importantes para esos conceptos. Primero dividimos una consulta en segmentos, cada segmento representando un concepto que normalmente es una frase nominal. Para cada una de las frases nominales, luego detectamos la palabra más importante a la que llamamos la palabra principal. La segmentación también se utiliza en la coincidencia sensible a documentos (sección 3.5) para hacer cumplir la proximidad. Para dividir una consulta en segmentos, tenemos que definir un criterio para medir la fuerza de la relación entre las palabras. Un método efectivo es utilizar la información mutua como indicador para decidir si dividir o no dos palabras [19]. Utilizamos un registro de 25 millones de consultas y recopilamos las frecuencias de bigramas y unigramas a partir de él. Para cada consulta entrante, calculamos la información mutua de dos palabras adyacentes; si supera un umbral predefinido, no dividimos la consulta entre esas dos palabras y pasamos a la siguiente palabra. Continuamos este proceso hasta que la información mutua entre dos palabras esté por debajo del umbral, luego creamos un límite conceptual aquí. La Tabla 2 muestra algunos ejemplos de segmentación de consultas. La forma ideal de encontrar la palabra principal de un concepto es realizar un análisis sintáctico para determinar la estructura de dependencia de la consulta. El análisis de consultas es más difícil que el análisis de oraciones, ya que muchas consultas no son gramaticales y son muy cortas. Aplicar un analizador entrenado en oraciones de documentos a consultas tendrá un rendimiento deficiente. En nuestra solución, solo utilizamos reglas heurísticas simples, y funciona muy bien en la práctica para el inglés. Para una frase nominal en inglés, la palabra principal suele ser la última palabra no detenida, a menos que la frase siga un patrón particular, como XYZ de/en/a/desde UVW. En tales casos, la palabra principal suele ser la última palabra no detenida de XYZ. 3.4 Expansión de palabras sensibles al contexto Después de detectar cuáles son las palabras más importantes para expandir, debemos decidir si las expansiones serán útiles. Nuestras estadísticas muestran que aproximadamente la mitad de las consultas pueden ser transformadas mediante la pluralización a través de un truncamiento ingenuo. Entre esta mitad, aproximadamente el 25% de las consultas mejoran la relevancia cuando se transforman, la mayoría (alrededor del 50%) no cambian sus 5 resultados principales, y el 25% restante tiene un rendimiento peor. Por lo tanto, es extremadamente importante identificar qué consultas no deben ser truncadas con el fin de maximizar la mejora de relevancia y minimizar el costo de truncamiento. Además, para una consulta con múltiples palabras que pueden ser transformadas, o una palabra con múltiples variantes, no todas las expansiones son útiles. Tomando la comparación de precios de hoteles como ejemplo, decidimos que hotel y comparación de precios son dos conceptos. Las palabras clave hotel y comparación se pueden expandir a hoteles y comparaciones. ¿Son útiles ambas transformaciones? Para probar si una expansión es útil, tenemos que saber si es probable que la consulta expandida obtenga más documentos relevantes de la web, lo cual puede cuantificarse mediante la probabilidad de que la consulta ocurra como una cadena en la web. Cuanto más probable sea que ocurra una consulta en la web, más documentos relevantes puede devolver esta consulta. Ahora todo el problema se convierte en cómo calcular la probabilidad de que ocurra la consulta en la Web. Calcular la probabilidad de que una cadena ocurra en un corpus es un problema bien conocido de modelado del lenguaje. El objetivo del modelado del lenguaje es predecir la probabilidad de secuencias de palabras que ocurren naturalmente, s = w1w2...wN; o más simplemente, asignar una alta probabilidad a las secuencias de palabras que realmente ocurren (y una baja probabilidad a las secuencias de palabras que nunca ocurren). El enfoque más simple y exitoso para el modelado del lenguaje sigue estando basado en el modelo n-gramo. Por la regla de la cadena de probabilidad, se puede escribir la probabilidad de cualquier secuencia de palabras como Pr(w1w2...wN) = ΠY i=1 Pr(wi|w1...wi−1) (1). Un modelo n-grama aproxima esta probabilidad asumiendo que las únicas palabras relevantes para predecir Pr(wi|w1...wi−1) son las n − 1 palabras anteriores; es decir, La probabilidad de una palabra wi dado w1...wi−1 es igual a la probabilidad de wi dado wi−n+1...wi−1. Una estimación directa de máxima verosimilitud de las probabilidades de n-gramas a partir de un corpus se obtiene a partir de la frecuencia observada de cada uno de los patrones Pr(wi|wi−n+1...wi−1) = #(wi−n+1...wi) #(wi−n+1...wi−1) donde #(.) denota el número de ocurrencias de un n-grama específico en el corpus de entrenamiento. Aunque se podría intentar usar modelos de n-gramos simples para capturar dependencias a largo plazo en el lenguaje, intentar hacerlo directamente crea inmediatamente problemas de datos dispersos: Utilizar n-gramos de longitud hasta n implica estimar la probabilidad de eventos de longitud Wn, donde W es el tamaño del vocabulario de palabras. Esto rápidamente abruma los recursos computacionales y de datos modernos incluso para opciones modestas de n (más allá de 3 a 6). Además, debido a la naturaleza de cola pesada del lenguaje (es decir, La ley de Zipf) es probable que uno se encuentre con n-gramas novedosos que nunca fueron observados durante el entrenamiento en ningún corpus de prueba, por lo tanto, algún mecanismo para asignar una probabilidad distinta de cero a los n-gramas novedosos es un problema central e inevitable en la modelización estadística del lenguaje. Un enfoque estándar para suavizar las estimaciones de probabilidad para hacer frente a problemas de datos escasos (y para hacer frente a posibles n-gramas faltantes) es utilizar algún tipo de estimador de retroceso. Pr(wi|wi−n+1...wi−1) = 8 >>< >>: ˆPr(wi|wi−n+1...wi−1), si #(wi−n+1...wi) > 0 β(wi−n+1...wi−1) × Pr(wi|wi−n+2...wi−1), de lo contrario (3) donde ˆPr(wi|wi−n+1...wi−1) = descuento #(wi−n+1...wi) #(wi−n+1...wi−1) (4) es la probabilidad descontada y β(wi−n+1...wi−1) es una constante de normalización β(wi−n+1...wi−1) = 1 − X x∈(wi−n+1...wi−1x) ˆPr(x|wi−n+1...wi−1) 1 − X x∈(wi−n+1...wi−1x) ˆPr(x|wi−n+2...wi−1) (5) La probabilidad descontada (4) se puede calcular con diferentes técnicas de suavizado, incluido el suavizado absoluto, el suavizado de Good-Turing, el suavizado lineal y el suavizado de Witten-Bell [5]. Utilizamos suavizado absoluto en nuestros experimentos. Dado que la probabilidad de una cadena, Pr(w1w2...wN), es un número muy pequeño y difícil de interpretar, utilizamos la entropía, tal como se define a continuación, para puntuar la cadena. Entropía = − 1 N log2 Pr(w1w2...wN ) (6) Ahora volviendo al ejemplo de la comparación de precios de hoteles, hay cuatro variantes de esta consulta, y la entropía de estos cuatro candidatos se muestra en la Tabla 3. Podemos ver que todas las alternativas son menos probables que la consulta de entrada. Por lo tanto, no es útil hacer una expansión para esta consulta. Por otro lado, si la consulta de entrada son comparaciones de precios de hoteles, que es la segunda alternativa en la tabla, entonces hay una mejor alternativa que la consulta de entrada, y por lo tanto debería ser ampliada. Para tolerar las variaciones en la estimación de probabilidad, relajamos el criterio de selección para esas alternativas de consulta si sus puntuaciones están dentro de una cierta distancia (10% en nuestros experimentos) de la mejor puntuación. Variaciones de la consulta Comparación de precios de hoteles 6.177 comparaciones de precios de hoteles 6.597 comparación de precios de hoteles 6.937 comparaciones de precios de hoteles 7.360 Tabla 3: Variaciones de la consulta comparación de precios de hoteles clasificadas por puntaje de entropía, con la consulta original en negrita. 3.5 Coincidencia de documentos sensibles al contexto Aun después de saber qué variantes de palabras son probablemente útiles, debemos ser conservadores en la coincidencia de documentos para las variantes ampliadas. Para la consulta de comparaciones de precios de hoteles, decidimos que la palabra \"comparaciones\" se amplía para incluir \"comparación\". Sin embargo, no todos los casos de comparación en el documento son de interés. Una página que trata sobre comparar el servicio al cliente puede contener todas las palabras comparaciones de precios de hoteles comparación. Esta página no es una buena página para la consulta. Si aceptamos coincidencias de cada ocurrencia de comparación, afectará la precisión de recuperación y esta es una de las principales razones por las que la mayoría de los enfoques de derivación no funcionan bien para la recuperación de información. Para abordar este problema, tenemos una restricción de proximidad que considera el contexto alrededor de la variante expandida en el documento. Una coincidencia de variante se considera válida solo si la variante ocurre en el mismo contexto que la palabra original lo hace. El contexto son los segmentos continuos de la izquierda o de la derecha de la palabra original. Tomando la misma consulta como ejemplo, el contexto de las comparaciones es el precio. La comparación de palabras ampliada solo es válida si está en el mismo contexto de comparaciones, que es después de la palabra precio. Por lo tanto, solo debemos emparejar aquellas ocurrencias de comparación en el documento si ocurren después de la palabra precio. Considerando el hecho de que las consultas y los documentos pueden no representar la intención de la misma manera exacta, relajamos esta restricción de proximidad para permitir ocurrencias variantes dentro de una ventana de un tamaño fijo. Si la comparación de palabras expandidas ocurre dentro del contexto de precio dentro de una ventana, se considera válida. Cuanto más pequeño sea el tamaño de la ventana, más restrictiva será la coincidencia. Utilizamos un tamaño de ventana de 4, que normalmente captura contextos que incluyen las frases nominales que contienen y las adyacentes. 4. EVALUACIÓN EXPERIMENTAL 4.1 Métricas de evaluación Mediremos tanto la mejora de relevancia como el costo de derivación necesario para lograr la relevancia. 1 un segmento de contexto no puede ser una sola palabra de parada. 4.1.1 Medición de relevancia Utilizamos una variante de la Ganancia Acumulada Descontada Promedio (DCG), un esquema recientemente popularizado para medir la relevancia de los motores de búsqueda [1, 11]. Dada una consulta y una lista clasificada de K documentos (K se establece en 5 en nuestros experimentos), el puntaje DCG(K) para esta consulta se calcula de la siguiente manera: DCG(K) = Σ k=1 a K gk log2(1 + k) . (7) donde gk es el peso para el documento en la posición k. Un mayor grado de relevancia corresponde a un peso mayor. Una página se califica en una de las cinco escalas: Perfecto, Excelente, Bueno, Regular, Malo, con pesos correspondientes. Utilizamos DCG para representar el DCG promedio(5) sobre un conjunto de consultas de prueba. 4.1.2 Costo de derivación Otro métrica es medir el costo adicional incurrido por la derivación. Dado el mismo nivel de mejora en la relevancia, preferimos un método de truncamiento que tenga un menor costo adicional. Medimos esto por el porcentaje de consultas que realmente se reducen, sobre todas las consultas que podrían ser reducidas. 4.2 Preparación de datos Muestreamos aleatoriamente 870 consultas de un registro de consultas de tres meses, con 290 de cada mes. Entre todas estas 870 consultas, eliminamos todas las consultas con errores ortográficos ya que las consultas con errores ortográficos no son de interés para el stemming. También eliminamos todas las consultas de una sola palabra, ya que reducir las consultas de una sola palabra sin contexto tiene un alto riesgo de cambiar la intención de la consulta, especialmente para palabras cortas. Al final, tenemos 529 consultas correctamente escritas con al menos 2 palabras. 4.3 Stemming ingenuo para la búsqueda en la Web Antes de explicar en detalle los experimentos y resultados, nos gustaría describir la forma tradicional de usar el stemming para la búsqueda en la Web, conocida como el modelo ingenuo. Esto es para tratar cada variante de palabra equivalente para todas las posibles palabras en la consulta. La consulta de la librería se transformará en (libro O libros)(tienda O tiendas) al limitar el truncamiento al manejo de pluralización solamente, donde O es un operador que denota la equivalencia de los argumentos izquierdo y derecho. 4.4 Configuración experimental El modelo base es el modelo sin truncamiento. Primero ejecutamos el modelo ingenuo para ver qué tan bien se desempeña en comparación con el punto de referencia. Luego mejoramos el modelo de derivación ingenua mediante la coincidencia sensible al documento, denominado modelo de coincidencia sensible al documento. Este modelo realiza el mismo stemming que el modelo ingenuo en el lado de la consulta, pero realiza un emparejamiento conservador en el lado del documento utilizando la estrategia descrita en la sección 3.5. El modelo ingenuo y el modelo de coincidencia sensible al documento son los que mejor responden a la mayoría de las consultas. De las 529 consultas, hay 408 consultas que se originan, lo que corresponde al 46.7% del tráfico de consultas (de un total de 870). Luego mejoramos aún más el modelo de coincidencia sensible de documentos desde el lado de la consulta con un proceso de derivación de palabras selectivo basado en modelado estadístico del lenguaje (sección 3.4), denominado modelo de derivación selectiva. Basado en la predicción del modelado del lenguaje, este modelo deriva solo un subconjunto de las 408 consultas derivadas por el modelo de coincidencia sensible al documento. Experimentamos con un <br>modelo de lenguaje</br> unigrama y un <br>modelo de lenguaje</br> bigrama. Dado que solo nos importa cuánto podemos mejorar el modelo ingenuo, solo utilizaremos estas 408 consultas (todas las consultas que se ven afectadas por el modelo de derivación ingenuo) en los experimentos. Para tener una idea de cómo se desempeñan estos modelos, también tenemos un modelo oráculo que proporciona el rendimiento máximo que un stemmer puede lograr en estos datos. El modelo del oráculo solo expande una palabra si el truncamiento dará mejores resultados. Para analizar la influencia del manejo de la pluralización en diferentes categorías de consultas, dividimos las consultas en consultas cortas y consultas largas. Entre las 408 consultas generadas por el modelo ingenuo, hay 272 consultas cortas con 2 o 3 palabras, y 136 consultas largas con al menos 4 palabras. Resumimos los resultados generales en la Tabla 4, y presentamos los resultados de las consultas cortas y largas por separado en la Tabla 5. Cada fila en la Tabla 4 es una estrategia de derivación descrita en la sección 4.4. La primera columna es el nombre de la estrategia. La segunda columna es el número de consultas afectadas por esta estrategia; esta columna mide el costo de derivación, y los números deberían ser bajos para el mismo nivel de dcg. La tercera columna es la puntuación DCG promedio sobre todas las consultas probadas en esta categoría (incluyendo aquellas que no fueron truncadas por la estrategia). La cuarta columna es la mejora relativa sobre la línea base, y la última columna es el valor p de la prueba de significancia de Wilcoxon. Hay varias observaciones sobre los resultados. Podemos ver que el truncado ingenuo solo logra una mejora estadísticamente insignificante del 1.5%. Mirando la Tabla 5, se observa una mejora del 2.7% en las consultas cortas. Sin embargo, también perjudica las consultas largas en un -2.4%. En general, la mejora se cancela. La razón por la que mejora las consultas cortas es que la mayoría de las consultas cortas solo tienen una palabra que se puede reducir a su raíz. Por lo tanto, pluralizar ciegamente consultas cortas es relativamente seguro. Sin embargo, para consultas largas, la mayoría de las consultas pueden tener varias palabras que pueden ser pluralizadas. Expandir todos ellos sin selección perjudicará significativamente la precisión. La aplicación de un stemming sensible al contexto del documento proporciona un aumento significativo en el rendimiento, desde un 2.7% hasta un 4.2% para consultas cortas y desde un -2.4% hasta un -1.6% para consultas largas, con un aumento general del 1.5% al 2.8%. La mejora proviene de la coincidencia de documentos sensible al contexto conservador. Una palabra expandida es válida solo si ocurre dentro del contexto de la consulta original en el documento. Esto reduce muchas coincidencias falsas. Sin embargo, aún observamos que para consultas largas, el truncamiento sensible al contexto no logra mejorar el rendimiento porque sigue seleccionando demasiados documentos y le presenta a la función de clasificación un problema difícil. Si bien el tamaño de ventana elegido de 4 es el que mejor funciona entre todas las opciones, aún permite coincidencias espurias. Es posible que el tamaño de la ventana deba elegirse según la consulta para garantizar restricciones de proximidad más estrictas para diferentes tipos de frases nominales. La pluralización selectiva de palabras ayuda aún más a resolver el problema enfrentado por el truncamiento sensible al contexto del documento. No se aplica el truncamiento a cada palabra que coloca toda la carga en el algoritmo de clasificación, sino que intenta eliminar el truncamiento innecesario en primer lugar. Al predecir qué variantes de palabras van a ser útiles, podemos reducir drásticamente el número de palabras derivadas, mejorando así tanto la recuperación como la precisión. Con el <br>modelo de lenguaje</br> unigrama, podemos reducir el costo de derivación en un 26.7% (de 408/408 a 300/408) y aumentar la mejora general de DCG del 2.8% al 3.4%. En particular, proporciona mejoras significativas en consultas largas. La ganancia de DCG se cambia de negativa a positiva, de -1.6% a 1.1%. Esto confirma nuestra hipótesis de que reducir la expansión innecesaria de palabras conduce a una mejora en la precisión. Para consultas cortas también observamos tanto la mejora de dcg como la reducción del costo de derivación con el <br>modelo de lenguaje</br> unigrama. Las ventajas de la expansión predictiva de palabras con un <br>modelo de lenguaje</br> se potencian aún más con un mejor <br>modelo de lenguaje</br> de bigrama. La ganancia total de DCG aumenta de 3.4% a 3.9%, y el costo de derivación se reduce drásticamente de 408/408 a 250/408, correspondiente a solo el 29% del tráfico de consultas (250 de 870) y una mejora total de DCG del 1.8% en todo el tráfico de consultas. Para consultas cortas, el <br>modelo de lenguaje</br> de bigrama mejora la ganancia de DCG del 4.4% al 4.7%, y reduce el costo de derivación de 272/272 a 150/272. ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        }
    }
}