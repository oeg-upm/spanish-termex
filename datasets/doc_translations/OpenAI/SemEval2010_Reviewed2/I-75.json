{
    "id": "I-75",
    "original_text": "Hypotheses Refinement under Topological Communication Constraints ∗ Gauvain Bourgne, Gael Hette, Nicolas Maudet, and Suzanne Pinson LAMSADE, Univ. Paris-Dauphine, France {bourgne,hette,maudet,pinson}@lamsade.dauphine.fr ABSTRACT We investigate the properties of a multiagent system where each (distributed) agent locally perceives its environment. Upon perception of an unexpected event, each agent locally computes its favoured hypothesis and tries to propagate it to other agents, by exchanging hypotheses and supporting arguments (observations). However, we further assume that communication opportunities are severely constrained and change dynamically. In this paper, we mostly investigate the convergence of such systems towards global consistency. We first show that (for a wide class of protocols that we shall define), the communication constraints induced by the topology will not prevent the convergence of the system, at the condition that the system dynamics guarantees that no agent will ever be isolated forever, and that agents have unlimited time for computation and arguments exchange. As this assumption cannot be made in most situations though, we then set up an experimental framework aiming at comparing the relative efficiency and effectiveness of different interaction protocols for hypotheses exchange. We study a critical situation involving a number of agents aiming at escaping from a burning building. The results reported here provide some insights regarding the design of optimal protocol for hypotheses refinement in this context. Categories and Subject Descriptors I.2.11 [Artificial Intelligence]: Distributed Artificial Intelligence-Multiagent systems General Terms Theory, Experimentation 1. INTRODUCTION We consider a multiagent system where each (distributed) agent locally perceives its environment, and we assume that some unexpected event occurs in that system. If each agent computes only locally its favoured hypothesis, it is only natural to assume that agents will seek to coordinate and refine their hypotheses by confronting their observations with other agents. If, in addition, the communication opportunities are severely constrained (for instance, agents can only communicate when they are close enough to some other agent), and dynamically changing (for instance, agents may change their locations), it becomes crucial to carefully design protocols that will allow agents to converge to some desired state of global consistency. In this paper we exhibit some sufficient conditions on the system dynamics and on the protocol/strategy structures that allow to guarantee that property, and we experimentally study some contexts where (some of) these assumptions are relaxed. While problems of diagnosis are among the venerable classics in the AI tradition, their multiagent counterparts have much more recently attracted some attention. Roos and colleagues [8, 9] in particular study a situation where a number of distributed entities try to come up with a satisfying global diagnosis of the whole system. They show in particular that the number of messages required to establish this global diagnosis is bound to be prohibitive, unless the communication is enhanced with some suitable protocol. However, they do not put any restrictions on agents communication options, and do not assume either that the system is dynamic. The benefits of enhancing communication with supporting information to make convergence to a desired global state of a system more efficient has often been put forward in the literature. This is for instance one of the main idea underlying the argumentation-based negotiation approach [7], where the desired state is a compromise between agents with conflicting preferences. Many of these works however make the assumption that this approach is beneficial to start with, and study the technical facets of the problem (or instead emphasize other advantages of using argumentation). Notable exceptions are the works of [3, 4, 2, 5], which studied in contexts different from ours the efficiency of argumentation. The rest of the paper is as follows. Section 2 specifies the basic elements of our model, and Section 3 goes on to presenting the different protocols and strategies used by the agents to exchange hypotheses and observations. We put special attention at clearly emphasizing the conditions on the system dynamics and protocols/strategies that will be exploited in the rest of the paper. Section 4 details one of 998 978-81-904262-7-5 (RPS) c 2007 IFAAMAS the main results of the paper, namely the fact that under the aforementioned conditions, the constraints that we put on the topology will not prevent the convergence of the system towards global consistency, at the condition that no agent ever gets completely lost forever in the system, and that unlimited time is allowed for computation and argument exchange. While the conditions on protocols and strategies are fairly mild, it is also clear that these system requirements look much more problematic, even frankly unrealistic in critical situations where distributed approaches are precisely advocated. To get a clearer picture of the situation induced when time is a critical factor, we have set up an experimental framework that we introduce and discuss in Section 5. The critical situation involves a number of agents aiming at escaping from a burning building. The results reported here show that the effectiveness of argument exchange crucially depends upon the nature of the building, and provide some insights regarding the design of optimal protocol for hypotheses refinement in this context. 2. BASIC NOTIONS We start by defining the basic elements of our system. Environment Let O be the (potentially infinite) set of possible observations. We assume the sensors of our agents to be perfect, hence the observations to be certain. Let H be the set of hypotheses, uncertain and revisable. Let Cons(h, O) be the consistency relation, a binary relation between a hypothesis h ∈ H and a set of observations O ⊆ O. In most cases, Cons will refer to classical consistency relation, however, we may overload its meaning and add some additional properties to that relation (in which case we will mention it). The environment may include some dynamics, and change over the course of time. We define below sequences of time points to deal with it: Definition 1 (Sequence of time points). A sequence of time points t1, t2, . . . , tn from t is an ordered set of time points t1, t2, . . . , tn such that t1 ≥ t and ∀i ∈ [1, n − 1], ti+1 ≥ ti. Agent We take a system populated by n agents a1, . . . , an. Each agent is defined as a tuple F, Oi, hi , where: • F, the set of facts, common knowledge to all agents. • Oi ∈ 2O , the set of observations made by the agent so far. We assume a perfect memory, hence this set grows monotonically. • hi ∈ H, the favourite hypothesis of the agent. A key notion governing the formation of hypotheses is that of consistency, defined below: Definition 2 (Consistency). We say that: • An agent is consistent (Cons(ai)) iff Cons(hi, Oi) (that is, its hypothesis is consistent with its observation set). • An agent ai consistent with a partner agent aj iff Cons(ai) and Cons(hi, Oj) (that is, this agent is consistent and its hypothesis can explain the observation set of the other agent). • Two agents ai and aj are mutually consistent (MCons(ai, aj)) iff Cons(ai, aj) and Cons(aj, ai). • A system is consistent iff ∀(i, j)∈[1, n]2 it is the case that MCons(ai, aj). To ensure its consistency, each agent is equipped with an abstract reasoning machinery that we shall call the explanation function Eh. This (deterministic) function takes a set of observation and returns a single prefered hypothesis (2O → H). We assume h = Eh(O) to be consistent with O by definition of Eh, so using this function on its observation set to determine its favourite hypothesis is a sure way for the agent to achieve consistency. Note however that an hypothesis does not need to be generated by Eh to be consistent with an observation set. As a concrete example of such a function, and one of the main inspiration of this work, one can cite the Theorist reasoning system [6] -as long as it is coupled with a filter selecting a single prefered theory among the ones initially selected by Theorist. Note also that hi may only be modified as a consequence of the application Eh. We refer to this as the autonomy of the agent: no other agent can directly impose a given hypothesis to an agent. As a consequence, only a new observation (being it a new perception, or an observation communicated by a fellow agent) can result in a modification of its prefered hypothesis hi (but not necessarily of course). We finally define a property of the system that we shall use in the rest of the paper: Definition 3 (Bounded Perceptions). A system involves a bounded perception for agents iff ∃n0 s.t. ∀t| ∪N i=1 Oi| ≤ n0. (That is, the number of observations to be made by the agents in the system is not infinite.) Agent Cycle Now we need to see how these agents will evolve and interact in their environment. In our context, agents evolve in a dynamic environment, and we classicaly assume the following system cycle: 1. Environment dynamics: the environment evolves according to the defined rules of the system dynamics. 2. Perception step : agents get perceptions from the environment. These perceptions are typically partial (e.g. the agent can only see a portion of a map). 3. Reasoning step: agents compare perception with predictions, seek explanations for (potential) difference(s), refine their hypothesis, draw new conclusions. 4. Communication step: agents can communicate hypotheses and observations with other agents through a defined protocol. Any agent can only be involved in one communication with another agent by step. 5. Action step: agents do some practical reasoning using the models obtained from the previous steps and select an action. They can then modify the environment by executing it. The communication of the agents will be further constrained by topological consideration. At a given time, an agent will only be able to communicate with a number of neighbours. Its connexions with these others agents may The Sixth Intl. Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 999 evolve with its situation in the environment. Typically, an agent can only communicate with agents that it can sense, but one could imagine evolving topological constraints on communication based on a network of communications between agents where the links are not always active. Communication In our system, agents will be able to communicate with each other. However, due to the aforementionned topological constraints, they will not be able to communicate with any agents at anytime. Who an agent can communicate with will be defined dynamically (for instance, this can be a consequence of the agents being close enough to get in touch). We will abstractly denote by C(ai, aj, t) the communication property, in other words, the fact that agents ai and aj can communicate at time t (note that this relation is assumed to be symetric, but of course not transitive). We are now in a position to define two essential properties of our system. Definition 4 (Temporal Path). There exists a temporal communication path at horizon tf (noted Ltf (aI , aJ )) between ai and aj iff there exists a sequence of time points t1, t2, . . . , tn from tf and a sequence of agents k1, k2, . . . , kn s.t. (i) C(aI , ak1 , t1), (ii) C(akn , aJ , tn+1), (iii) ∀i ∈ [1, n], C(aki , aki+1 , ti) Intuitively, what this property says is that it is possible to find a temporal path in the future that would allow to link agent ai and aj via a sequence of intermediary agents. Note that the time points are not necessarily successive, and that the sequence of agents may involve the same agents several times. Definition 5 (Temporal Connexity). A system is temporaly connex iff ∀t ∀(i, j)∈[1, n]2 Lt(ai, aj) In short, a temporaly connex system guarantees that any agent will be able to communicate with any other agents, no matter how long it might take to do so, at any time. To put it another way, it is never the case that an agent will be isolated for ever from another agent of the system. We will next discuss the detail of how communication concretely takes place in our system. Remember that in this paper, we only consider the case of bilateral exchanges (an agent can only speak to a single other agent), and that we also assume that any agent can only engage in a single exchange in a given round. 3. PROTOCOLS AND STRATEGIES In this section, we discuss the requirements of the interaction protocols that govern the exchange of messages between agents, and provide some example instantiation of such protocols. To clarify the presentation, we distinguish two levels: the local level, which is concerned with the regulation of bilateral exchanges; and the global level,which essentially regulates the way agents can actually engage into a conversation. At each level, we separate what is specified by the protocol, and what is left to agents strategies. Local Protocol and Strategies We start by inspecting local protocols and strategies that will regulate the communication between the agents of the system. As we limit ourselves to bilateral communication, these protocols will simply involve two agents. Such protocol will have to meet one basic requirement to be satisfying. • consistency (CONS)- a local protocol has to guarantee the mutual consistency of agents upon termination (which implies termination of course). Figure 1: A Hypotheses Exchange Protocol [1] One example such protocol is the protocol described in [1] that is pictured in Fig. 1. To further illustrate how such protocol can be used by agents, we give some details on a possible strategy: upon receiving a hypothesis h1 (propose(h1) or counterpropose(h1)) from a1, agent a2 is in state 2 and has the following possible replies: counterexample (if the agent knows an example contradicting the hypothesis, or not explained by this hypothesis), challenge (if the agents lacks evidence to accept this hypothesis), counterpropose (if the agent agrees with the hypothesis but prefers another one), or accept (if it is indeed as good as its favourite hypothesis). This strategy guarantees, among other properties, the eventual mutual logical consistency of the involved agents [1]. Global Protocol The global protocol regulates the way bilateral exchanges will be initiated between agents. At each turn, agents will concurrently send one weighted request to communicate to other agents. This weight is a value measuring the agents willingness to converse with the targeted agent (in practice, this can be based on different heuristics, but we shall make some assumptions on agents strategies, see below). Sending such a request is a kind of conditional commitment for the agent. An agent sending a weighted request commits to engage in conversation with the target if he does not receive and accept himself another request. Once all request have been received, each agent replies with either an acccept or a reject. By answering with an accept, an agent makes a full commitment to engage in conversation with the sender. Therefore, it can only send one accept in a given round, as an agent can only participate in one conversation per time step. When all response have been received, each agent receiving an accept can either initiate a conversation using the local protocol or send a cancel if it has accepted another request. At the end of all the bilateral exchanges, the agents engaged in conversation are discarded from the protocol. Then each of the remaining agents resends a request and the process iterates until no more requests are sent. Global Strategy We now define four requirements for the strategies used by agents, depending on their role in the protocol: two are concerned with the requestee role (how to decide who the 1000 The Sixth Intl. Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) agent wishes to communicate with?), the other two with the responder role (how to decide which communication request to accept or not?). • Willingness to solve inconsistancies (SOLVE)-agents want to communicate with any other agents unless they know they are mutually consistent. • Focus on solving inconsistencies (FOCUS)-agents do not request communication with an agent with whom they know they are mutually consistent. • Willingness to communicate (COMM)-agents cannot refuse a weighted communication request, unless they have just received or send a request with a greater weight. • Commitment to communication request (REQU)agents cannot accept a weighted communication request if they have themselves sent a communication request with a greater weight. Therefore, they will not cancel their request unless they have received a communicational request with greater weight. Now the protocol structure, together with the properties COMM+REQU, ensure that a request can only be rejected if its target agent engages in communication with another agent. Suppose indeed that agent ai wants to communicate with aj by sending a request with weight w. COMM guarantees that an agent receiving a weighted request will either accept this communication, accept a communication with a greater weight or wait for the answer to a request with a greater weight. This ensures that the request with maximal weight will be accepted and not cancelled (as REQU ensures that an agent sending a request can only cancel it if he accepts another request with greater weight). Therefore at least two agents will engage in conversation per round of the global protocol. As the protocol ensures that ai can resend its request while aj is not engaged in a conversation, there will be a turn in which aj must engage in a conversation, either with ai or another agent. These requirements concern request sending and acceptation, but agents also need some strategy of weight attribution. We describe below an altruist strategy, used in our experiments. Being cooperative, an agent may want to know more of the communication wishes of other agents in order to improve the overall allocation of exchanges to agents. A context request step is then added to the global protocol. Before sending their chosen weighted request, agents attribute a weight to all agents they are prepared to communicate with, according to some internal factors. In the simplest case, this weight will be 1 for all agent with whom the agent is not sure of being mutually consistent (ensuring SOLVE), other agent being not considered for communication (ensuring FOCUS). The agent then sends a context request to all agents with whom communication is considered. This request also provides information about the sender (list of considered communications along with their weight). After reception of all the context requests, agents will either reply with a deny, iff they are already engaged in a conversation (in which case, the requesting agent will not consider communication with them anymore in this turn), or an inform giving the requester information about the requests it has sent and received. When all replies have been received, each agent can calculate the weight of all requests concerning it. It does so by substracting from the weight of its request the weight of all requests concerning either it or its target (that is, the final weight of the request from ai to aj is Wi,j = wi,j +wj,i − ( P k∈R(i)−{j} wi,k + P k∈S(i)−{j} wk,i + P k∈R(j)−{i} wj,k + P k∈S(j)−{i} wk,j) where wi,j is the weight of the request of ai to aj, R(i) is the set of indice of agents having received a request from ai and S(i) is the set of indice of agents having send a request to ai). It then finally sends a weighted request to the agents who maximise this weight (or wait for a request) as described in the global protocol. 4. (CONDITIONAL) CONVERGENCE TO GLOBAL CONSISTENCY In this section we will show that the requirements regarding protocols and strategies just discussed will be sufficient to ensure that the system will eventually converge towards global consistency, under some conditions. We first show that, if two agents are not mutually consistent at some time, then there will be necessarily a time in the future such that an agent will learn a new observation, being it because it is new for the system, or by learning it from another agent. Lemma 1. Let S be a system populated by n agents a1, a2, ..., an, temporaly connex, and involving bounded perceptions for these agents. Let n1 be the sum of cardinalities of the intersection of pairwise observation sets. (n1 = P (i,j)∈[1,n]2 |Oi ∩ Oj|) Let n2 be the cardinality of the union of all agents observations sets. (n2 = | ∪N i=1 Oi|). If ¬MCons(ai, aj) at time t0, there is necessarily a time t > t0 s.t. either n1 or n2 will increase. Proof. Suppose that there exist a time t0 and indices (i, j) s.t. ¬MCons(ai, aj). We will use mt0 = P (k,l)∈[1,n]2 εComm(ak, al, t0) where εComm(ak, al, t0) = 1 if ak and al have communicated at least once since t0, and 0 otherwise. Temporal connexity guarantees that there exist t1, ..., tm+1 and k1, ..., km s.t. C(ai, ak1 , t1), C(akm , aj, tm+1), and ∀p ∈ [1, m], C(akp , akp+1 , tp). Clearly, if MCons(ai, ak1 ), MCons(akm , aj) and ∀p, MCons(akp , akp+1 ), we have MCons(ai, aj) which contradicts our hypothesis (MCons being transitive, MCons(ai, ak1 )∧MCons(ak1 , ak2 ) implies that MCons(ai, ak2 ) and so on till MCons(ai, akm )∧ MCons(akm , aj) which implies MCons(ai, aj) ). At least two agents are then necessarily inconsistent (¬MCons(ai, ak1 ), or ¬MCons(akm , aj), or ∃p0 t.q. ¬MCons(akp0 , akp0+1 )). Let ak and al be these two neighbours at a time t > t0 1 . The SOLVE property ensures that either ak or al will send a communication request to the other agent at time t . As shown before, this in turn ensures that at least one of these agents will be involved in a communication. Then there are two possibilities: (case i) ak and al communicate at time t . In this case, we know that ¬MCons(ak, al). This and the CONS property ensures that at least one of the agents must change its 1 Strictly speaking, the transitivity of MCons only ensure that ak and al are inconsistent at a time t ≥ t0 that can be different from the time t at which they can communicate. But if they become consistent between t and t (or inconsistent between t and t ), it means that at least one of them have changed its hypothesis between t and t , that is, after t0. We can then apply the reasoning of case iib. The Sixth Intl. Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 1001 hypothesis, which in turn, since agents are autonomous, implies at least one exchange of observation. But then |Ok ∩Ol| is bound to increase: n1(t ) > n1(t0). (case ii) ak communicates with ap at time t . We then have again two possibilities: (case iia) ak and ap did not communicate since t0. But then εComm(ak, ap, t0) had value 0 and takes value 1. Hence mt0 increases. (case iib) ak and ap did communicate at some time t0 > t0. The CONS property of the protocol ensures that MCons(ak, ap) at that time. Now the fact that they communicate and FOCUS implies that at least one of them did change its hypothesis in the meantime. The fact that agents are autonomous implies in turn that a new observation (perceived or received from another agent) necessarily provoked this change. The latter case would ensure the existence of a time t > t0 and an agent aq s.t. either |Op ∩Oq| or |Ok ∩Oq| increases of 1 at that time (implying n1(t ) > n1(t0)). The former case means that the agent gets a new perception o at time t . If that observation was unknown in the system before, then n2(t ) > n2(t0). If some agent aq already knew this observation before, then either Op ∩ Oq or Ok ∩ Oq increases of 1 at time t (which implies that n1(t ) > n1(t0)). Hence, ¬MCons(ai, aj) at time t0 guarantees that, either: −∃t > t0 t.q. n1(t ) > n1(t0); or −∃t > t0 t.q. n2(t ) > n2(t0); or −∃t > t0 t.q. mt0 increases of 1 at time t . By iterating the reasoning with t (but keeping t0 as the time reference for mt0 ), we can eliminate the third case (mt0 is integer and bounded by n2 , which means that after a maximum of n2 iterations, we necessarily will be in one of two other cases.) As a result, we have proven that if ¬MCons(ai, aj) at time t0, there is necessarily a time t s.t. either n1 or n2 will increase. Theorem 1 (Global consistency). Let S be a system populated by n agents a1, a2, ..., an, temporaly connex, and involving bounded perceptions for these agents. Let Cons(ai, aj) be a transitive consistency property. Then any protocol and strategies satisfying properties CONS, SOLVE, FOCUS, COMM and REQU guarantees that the system will converge towards global consistency. Proof. For the sake of contradiction, let us assume ∃I, J ∈ [1, N] s.t. ∀t, ∃t0 > t, t.q. ¬Cons(aI , aJ , t0). Using the lemma, this implies that ∃t > t0 s.t. either n1(t ) > n1(t0) or n2(t ) > n2(t0). But we can apply the same reasoning taking t = t , which would give us t1 > t > t0 s.t. ¬Cons(aI , aJ , t1), which gives us t > t1 s.t. either n1(t ) > n1(t1) or n2(t ) > n2(t1). By successive iterations we can then construct a sequence t0, t1, ..., tn, which can be divided in two sub-sequences t0, t1, ...tn and t0 , t1 , ..., tn s.t. n1(t0) < n1(t1) < ... < n1(tn) and n2(t0 ) < n2(t1 ) < ... < n2(tn). One of these sub-sequences has to be infinite. However, n1(ti) and n2(ti ) are strictly growing, integer, and bounded, which implies that both are finite. Contradiction. What the previous result essentially shows is that, in a system where no agent will be isolated from the rest of the agents for ever, only very mild assumptions on the protocols and strategies used by agents suffice to guarantee convergence towards system consistency in a finite amount of time (although it might take very long). Unfortunately, in many critical situations, it will not be possible to assume this temporal connexity. As distributed approaches as the one advocated in this paper are precisely often presented as a good way to tackle problems of reliability or problems of dependence to a center that are of utmost importance in these critical applications, it is certainly interesting to further explore how such a system would behave when we relax this assumption. 5. EXPERIMENTAL STUDY This experiment involves agents trying to escape from a burning building. The environment is described as a spatial grid with a set of walls and (thankfully) some exits. Time and space are considered discrete. Time is divided in rounds. Agents are localised by their position on the spatial grid. These agents can move and communicate with other agents. In a round, an agent can move of one cell in any of the four cardinal directions, provided it is not blocked by a wall. In this application, agents communicate with any other agent (but, recall, a single one) given that this agent is in view, and that they have not yet exchanged their current favoured hypothesis. Suddenly, a fire erupts in these premises. From this moment, the fire propagates. Each round, for each cases where there is fire, the fire propagates in the four directions. However, the fire cannot propagate through a wall. If the fire propagates in a case where an agent is positioned, that agent burns and is considered dead. It can of course no longer move nor communicate. If an agent gets to an exit, it is considered saved, and can no longer be burned. Agents know the environment and the rules governing the dynamics of this environment, that is, they know the map as well as the rules of fire propagation previously described. They also locally perceive this environment, but cannot see further than 3 cases away, in any direction. Walls also block the line of view, preventing agents from seeing behind them. Within their sight, they can see other agents and whether or not the cases they see are on fire. All these perceptions are memorised. We now show how this instantiates the abstract framework presented the paper. • O = {Fire(x, y, t), NoFire(x, y, t), Agent(ai, x, y, t)} Observations can then be positive (o ∈ P(O) iff ∃h ∈ H s.t. h |= o) or negative (o ∈ N(O) iff ∃h ∈ H s.t. h |= ¬o). • H={FireOrigin(x1, y1, t1)∧...∧FireOrigin(xl, yl, tl)} Hypotheses are conjunctions of FireOrigins. • Cons(h, O) consistency relation satisfies: - coherence : ∀o ∈ N(O), h |= ¬o. - completeness : ∀o ∈ P(O), h |= o. - minimality : For all h ∈ H, if h is coherent and complete for O, then h is prefered to h according to the preference relation (h ≤p h ).2 2 Selects first the minimal number of origins, then the most recent (least preemptive strategy [6]), then uses some arbitrary fixed ranking to discriminate ex-aequo. The resulting relation is a total order, hence minimality implies that there will be a single h s.t.Cons(O, h) for a given O. This in turn means that MCons(ai, aj) iff Cons(ai), Cons(aj), and hi = hj. This relation is then transitive and symmetric. 1002 The Sixth Intl. Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) • Eh takes O as argument and returns min≤p of the coherent and complete hypothesis for O 5.1 Experimental Evaluation We will classically (see e.g. [3, 4]) assess the effectiveness and efficiency of different interaction protocols. Effectiveness of a protocol The proportion of agents surviving the fire over the initial number of agents involved in the experiment will determine the effectiveness of a given protocol. If this value is high, the protocol has been effective to propagate the information and/or for the agents to refine their hypotheses and determine the best way to the exit. Efficiency of a protocol Typically, the use of supporting information will involve a communication overhead. We will assume here that the efficiency of a given protocol is characterised by the data flow induced by this protocol. In this paper we will only discuss this aspect wrt. local protocols. The main measure that we shall then use here is the mean total size of messages that are exchanged by agents per exchange (hence taking into account both the number of messages and the actual size of the messages, because it could be that messages happen to be very big, containing e.g. a large number of observations, which could counter-balance a low number of messages). 5.2 Experimental Settings The chosen experimental settings are the following: • Environmental topology- Performances of information propagation are highly constrained by the environment topology. The perception skills of the agents depend on the openness of the environment. With a large number of walls the perceptions of agents are limited, and also the number of possible inter-agent communications, whereas an open environment will provide optimal possibilities of perception and information propagation. Thus, we propose a topological index (see below) as a common basis to charaterize the environments (maps) used during experimentations. The topological index (TI) is the ratio of the number of cells that can be perceived by agents summed up from all possible positions, divided by the number of cells that would be perceived from the same positions but without any walls. (The closer to 1, the more open the environment). We shall also use two additional, more classical [10], measures: the characteristic path length3 (CPL) and the clustering coefficient4 (CC). • Number of agents- The propagation of information also depends on the initial number of agents involved during an experimentation. For instance, the more agents, the more potential communications there is. This means that there will be more potential for propagation, but also that the bilateral exchange restriction will be more crucial. 3 The CPL is the median of the means of the shortest path lengths connecting each node to all other nodes. 4 characterising the isolation degree of a region of an environment in terms of acessibility (number of roads still usable to reach this region). Map T.I. (%) C.P.L. C.C. 69-1 69,23 4,5 0,69 69-2 68,88 4,38 0,65 69-3 69,80 4,25 0,67 53-1 53,19 5,6 0,59 53-2 53,53 6,38 0,54 53-3 53,92 6,08 0,61 38-1 38,56 8,19 0,50 38-2 38,56 7,3 0,50 38-3 38,23 8,13 0,50 Table 1: Topological Characteristics of the Maps • Initial positions of the agents- Initial positions of the agents have a significant influence on the overall behavior of an instance of our system: being close from an exit will (in general) ease the escape. 5.3 Experimental environments We choose to realize experiments on three very different topological indexes (69% for open environments, 53% for mixed environments, and 38% for labyrinth-like environments). Figure 2: Two maps (left: TI=69%, right TI=38%) We designed three different maps for each index (Fig. 2 shows two of them), containing the same maximum number of agents (36 agents max.) with a maximum density of one agent per cell, the same number of exits and a similar fire origin (e.g. starting time and position). The three differents maps of a given index are designed as follows. The first map is a model of an existing building floor. The second map has the same enclosure, exits and fire origin as the first one, but the number and location of walls are different (wall locations are designed by an heuristic which randomly creates walls on the spatial grid such that no fully closed rooms are created and that no exit is closed). The third map is characterised by geometrical enclosure in wich walls location is also designed with the aforementioned heuristic. Table 1 summarizes the different topological measures characterizing these different maps. It is worth pointing out that the values confirm the relevance of TI (maps with a high TI have a low CPL and a high CC. However the CPL and CC allows to further refine the difference between the maps, e.g. between 53-1 and 53-2). 5.4 Experimental Results For each triple of maps defined as above we conduct the same experiments. In each experiment, the society differs in terms of its initial proportion of involved agents, from 1% to 100%. This initial proportion represents the percentage of involved agents with regards to the possible maximum number of agents. For each map and each initial proportion, The Sixth Intl. Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 1003 we select randomly 100 different initial agents locations. For each of those different locations we execute the system one time for each different interaction protocol. Effectiveness of Communication and Argumentation The first experiment that we set up aims at testing how effective is hypotheses exchange (HE), and in particular how the topological aspects will affect this effectiveness. In order to do so, we have computed the ratio of improvement offered by that protocol over a situation where agents could simply not communicate (no comm). To get further insights as to what extent the hypotheses exchange was really crucial, we also tested a much less elaborated protocol consisting of mere observation exchanges (OE). More precisely, this protocol requires that each agent stores any unexpected observation that it perceives, and agents simply exchange their respective lists of observations when they discuss. In this case, the local protocol is different (note in particular that it does not guarantee mutual consistency), but the global protocol remains the same (at the only exception that agents motivation to communicate is to synchronise their list of observations, not their hypothesis). If this protocol is at best as effective as HE, it has the advantage of being more efficient (this is obvious wrt the number of messages which will be limited to 2, less straightforward as far as the size of messages is concerned, but the rough observation that the exchange of observations can be viewed as a flat version of the challenge is helpful to see this). The results of these experiments are reported in Fig. 3. Figure 3: Comparative effectiveness ratio gain of protocols when the proportion of agents augments The first observation that needs to be made is that communication improves the effectiveness of the process, and this ratio increases as the number of agents grows in the system. The second lesson that we learn here is that closeness relatively makes communication more effective over non communication. Maps exhibiting a T.I. of 38% are constantly above the two others, and 53% are still slightly but significantly better than 69%. However, these curves also suggest, perhaps surprisingly, that HE outperforms OE in precisely those situations where the ratio gain is less important (the only noticeable difference occurs for rather open maps where T.I. is 69%). This may be explained as follows: when a map is open, agents have many potential explanation candidates, and argumentation becomes useful to discriminate between those. When a map is labyrinth-like, there are fewer possible explanations to an unexpected event. Importance of the Global Protocol The second set of experiments seeks to evaluate the importance of the design of the global protocol. We tested our protocol against a local broadcast (LB) protocol. Local broadcast means that all the neighbours agents perceived by an agent will be involved in a communication with that agent in a given round -we alleviate the constraint of a single communication by agent. This gives us a rough upper bound upon the possible ratio gain in the system (for a given local protocol). Again, we evaluated the ratio gain induced by that LB over our classical HE, for the three different classes of maps. The results are reported in Fig. 4. Figure 4: Ratio gain of local broadcast over hypotheses exchange Note to begin with that the ratio gain is 0 when the proportion of agents is 5%, which is easily explained by the fact that it corresponds to situations involving only two agents. We first observe that all classes of maps witness a ratio gain increasing when the proportion of agents augments: the gain reaches 10 to 20%, depending on the class of maps considered. If one compares this with the improvement reported in the previous experiment, it appears to be of the same magnitude. This illustrates that the design of the global protocol cannot be ignored, especially when the proportion of agents is high. However, we also note that the effectiveness ratio gain curves have very different shapes in both cases: the gain induced by the accuracy of the local protocol increases very quickly with the proportion of agents, while the curve is really smooth for the global one. Now let us observe more carefully the results reported here: the curve corresponding to a TI of 53% is above that corresponding to 38%. This is so because the more open a map, the more opportunities to communicate with more than one agent (and hence benefits from broadcast). However, we also observe that curve for 69% is below that for 53%. This is explained as follows: in the case of 69%, the potential gain to be made in terms of surviving agents is much lower, because our protocols already give rather efficient outcomes anyway (quickly reaching 90%, see Fig. 3). A simple rule of thumb could be that when the number of agents is small, special attention should be put on the local 1004 The Sixth Intl. Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) protocol, whereas when that number is large, one should carefully design the global one (unless the map is so open that the protocol is already almost optimally efficient). Efficiency of the Protocols The final experiment reported here is concerned with the analysis of the efficiency of the protocols. We analysis here the mean size of the totality of the messages that are exchanged by agents (mean size of exchanges, for short) using the following protocols: HE, OE, and two variant protocols. The first one is an intermediary restricted hypotheses exchange protocol (RHE). RHE is as follows: it does not involve any challenge nor counter-propose, which means that agents cannot switch their role during the protocol (this differs from RE in that respect). In short, RHE allows an agent to exhaust its partners criticism, and eventually this partner will come to adopt the agents hypothesis. Note that this means that the autonomy of the agent is not preserved here (as an agent will essentially accept any hypothesis it cannot undermine), with the hope that the gain in efficiency will be significant enough to compensate a loss in effectiveness. The second variant protocol is a complete observation exchange protocol (COE). COE uses the same principles as OE, but includes in addition all critical negative examples (nofire) in the exchange (thus giving all examples used as arguments by the hypotheses exchanges protocol), hence improving effectiveness. Results for map 69-1 are shown on Fig. 5. Figure 5: Mean size of exchanges First we can observe the fact that the ordering of the protocols, from the least efficient to the most efficient, is COE, HE, RHE and then OE. HE being more efficient than COE proves that the argumentation process gains efficiency by selecting when it is needed to provide negative example, which have less impact that positive ones in our specific testbed. However, by communicating hypotheses before eventually giving observation to support it (HE) instead of directly giving the most crucial observations (OE), the argumentation process doubles the size of data exchanges. It is the cost for ensuring consistency at the end of the exchange (a property that OE does not support). Also significant is the fact the the mean size of exchanges is slightly higher when the number of agents is small. This is explained by the fact that in these cases only a very few agents have relevant informations in their possession, and that they will need to communicate a lot in order to come up with a common view of the situation. When the number of agents increases, this knowledge is distributed over more agents which need shorter discussions to get to mutual consistency. As a consequence, the relative gain in efficiency of using RHE appears to be better when the number of agents is small: when it is high, they will hardly argue anyway. Finally, it is worth noticing that the standard deviation for these experiments is rather high, which means that the conversation do not converge to any stereotypic pattern. 6. CONCLUSION This paper has investigated the properties of a multiagent system where each (distributed) agent locally perceives its environment, and tries to reach consistency with other agents despite severe communication restrictions. In particular we have exhibited conditions allowing convergence, and experimentally investigated a typical situation where those conditions cannot hold. There are many possible extensions to this work, the first being to further investigate the properties of different global protocols belonging to the class we identified, and their influence on the outcome. There are in particular many heuristics, highly dependent on the context of the study, that could intuitively yield interesting results (in our study, selecting the recipient on the basis of what can be inferred from his observed actions could be such a heuristic). One obvious candidate for longer term issues concern the relaxation of the assumption of perfect sensing. 7. REFERENCES [1] G. Bourgne, N. Maudet, and S. Pinson. When agents communicate hypotheses in critical situations. In Proceedings of DALT-2006, May 2006. [2] P. Harvey, C. F. Chang, and A. Ghose. Support-based distributed search: a new approach for multiagent constraint processing. In Proceedings of AAMAS06, 2006. [3] H. Jung and M. Tambe. Argumentation as distributed constraint satisfaction: Applications and results. In Proceedings of AGENTS01, 2001. [4] N. C. Karunatillake and N. R. Jennings. Is it worth arguing? In Proceedings of ArgMAS 2004, 2004. [5] S. Onta˜n´on and E. Plaza. Arguments and counterexamples in case-based joint deliberation. In Proceedings of ArgMAS-2006, May 2006. [6] D. Poole. Explanation and prediction: An architecture for default and abductive reasoning. Computational Intelligence, 5(2):97-110, 1989. [7] I. Rahwan, S. D. Ramchurn, N. R. Jennings, P. McBurney, S. Parsons, and L. Sonenberg. Argumention-based negotiation. The Knowledge Engineering Review, 4(18):345-375, 2003. [8] N. Roos, A. ten Tije, and C. Witteveen. A protocol for multi-agent diagnosis with spatially distributed knowledge. In Proceedings of AAMAS03, 2003. [9] N. Roos, A. ten Tije, and C. Witteveen. Reaching diagnostic agreement in multiagent diagnosis. In Proceedings of AAMAS04, 2004. [10] T. Takahashi, Y. Kaneda, and N. Ito. Preliminary study - using robocuprescue simulations for disasters prevention. In Proceedings of SRMED2004, 2004. The Sixth Intl. Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 1005",
    "original_translation": "Refinamiento de hipótesis bajo restricciones de comunicación topológica ∗ Gauvain Bourgne, Gael Hette, Nicolas Maudet y Suzanne Pinson LAMSADE, Univ. Investigamos las propiedades de un sistema multiagente donde cada agente (distribuido) percibe localmente su entorno. Tras la percepción de un evento inesperado, cada agente calcula localmente su hipótesis favorita e intenta propagarla a otros agentes, intercambiando hipótesis y argumentos de apoyo (observaciones). Sin embargo, también asumimos que las oportunidades de comunicación están severamente limitadas y cambian dinámicamente. En este artículo, investigamos principalmente la convergencia de dichos sistemas hacia la consistencia global. Primero demostramos que (para una amplia clase de protocolos que definiremos), las restricciones de comunicación inducidas por la topología no impedirán la convergencia del sistema, bajo la condición de que la dinámica del sistema garantice que ningún agente quedará aislado para siempre, y que los agentes tengan tiempo ilimitado para la computación y el intercambio de argumentos. Dado que esta suposición no se puede hacer en la mayoría de las situaciones, establecimos un marco experimental con el objetivo de comparar la eficiencia y efectividad relativa de diferentes protocolos de interacción para el intercambio de hipótesis. Estudiamos una situación crítica que implica a varios agentes que intentan escapar de un edificio en llamas. Los resultados reportados aquí proporcionan algunas ideas sobre el diseño de un protocolo óptimo para el refinamiento de hipótesis en este contexto. Categorías y Descriptores de Asignaturas I.2.11 [Inteligencia Artificial]: Inteligencia Artificial Distribuida-Sistemas Multiagente Términos Generales Teoría, Experimentación 1. INTRODUCCIÓN Consideramos un sistema multiagente donde cada agente (distribuido) percibe localmente su entorno, y asumimos que ocurre un evento inesperado en ese sistema. Si cada agente calcula solo localmente su hipótesis preferida, es natural asumir que los agentes buscarán coordinar y refinar sus hipótesis confrontando sus observaciones con otros agentes. Si, además, las oportunidades de comunicación están severamente limitadas (por ejemplo, los agentes solo pueden comunicarse cuando están lo suficientemente cerca de otro agente) y cambian dinámicamente (por ejemplo, los agentes pueden cambiar sus ubicaciones), se vuelve crucial diseñar cuidadosamente protocolos que permitan a los agentes converger hacia algún estado deseado de consistencia global. En este documento presentamos algunas condiciones suficientes sobre la dinámica del sistema y sobre las estructuras de protocolo/estrategia que permiten garantizar esa propiedad, y estudiamos experimentalmente algunos contextos donde (algunas de) estas suposiciones se relajan. Si bien los problemas de diagnóstico son uno de los clásicos venerables en la tradición de la IA, sus contrapartes multiagentes han atraído atención mucho más recientemente. Roos y sus colegas [8, 9] en particular estudian una situación en la que un número de entidades distribuidas intentan llegar a un diagnóstico global satisfactorio de todo el sistema. Ellos muestran en particular que el número de mensajes necesarios para establecer este diagnóstico global está destinado a ser prohibitivo, a menos que la comunicación se mejore con algún protocolo adecuado. Sin embargo, no imponen restricciones a las opciones de comunicación de los agentes, ni asumen que el sistema es dinámico. Los beneficios de mejorar la comunicación con información de apoyo para hacer que la convergencia a un estado global deseado de un sistema sea más eficiente, a menudo se ha planteado en la literatura. Esta es, por ejemplo, una de las ideas principales que subyacen al enfoque de negociación basado en argumentos [7], donde el estado deseado es un compromiso entre agentes con preferencias conflictivas. Sin embargo, muchos de estos trabajos parten del supuesto de que este enfoque es beneficioso para comenzar y estudian los aspectos técnicos del problema (o en su lugar enfatizan otras ventajas de utilizar la argumentación). Excepciones notables son las obras de [3, 4, 2, 5], que estudiaron en contextos diferentes al nuestro la eficiencia de la argumentación. El resto del documento es el siguiente. La Sección 2 especifica los elementos básicos de nuestro modelo, y la Sección 3 continúa presentando los diferentes protocolos y estrategias utilizados por los agentes para intercambiar hipótesis y observaciones. Ponemos especial atención en enfatizar claramente las condiciones de la dinámica del sistema y los protocolos/estrategias que se explotarán en el resto del documento. La sección 4 detalla uno de los principales resultados del artículo, a saber, el hecho de que bajo las condiciones mencionadas, las restricciones que imponemos en la topología no impedirán la convergencia del sistema hacia la consistencia global, siempre y cuando ningún agente se pierda completamente para siempre en el sistema, y se permita un tiempo ilimitado para la computación y el intercambio de argumentos. Si bien las condiciones en los protocolos y estrategias son bastante suaves, también es claro que estos requisitos del sistema parecen mucho más problemáticos, incluso francamente poco realistas en situaciones críticas donde se abogan precisamente por enfoques distribuidos. Para obtener una imagen más clara de la situación inducida cuando el tiempo es un factor crítico, hemos establecido un marco experimental que presentamos y discutimos en la Sección 5. La situación crítica implica a varios agentes que intentan escapar de un edificio en llamas. Los resultados reportados aquí muestran que la efectividad del intercambio de argumentos depende crucialmente de la naturaleza del edificio, y proporcionan algunas ideas sobre el diseño de un protocolo óptimo para el refinamiento de hipótesis en este contexto. CONCEPTOS BÁSICOS Comenzamos definiendo los elementos básicos de nuestro sistema. Deje que O sea el conjunto (potencialmente infinito) de observaciones posibles. Suponemos que los sensores de nuestros agentes son perfectos, por lo tanto, las observaciones son seguras. Sea H el conjunto de hipótesis, incierto y revisable. Sea Cons(h, O) la relación de consistencia, una relación binaria entre una hipótesis h ∈ H y un conjunto de observaciones O ⊆ O. En la mayoría de los casos, Cons se referirá a la relación de consistencia clásica, sin embargo, podemos sobrecargar su significado y añadir algunas propiedades adicionales a esa relación (en cuyo caso lo mencionaremos). El entorno puede incluir cierta dinámica y cambiar con el transcurso del tiempo. Definimos a continuación secuencias de puntos temporales para tratar con ello: Definición 1 (Secuencia de puntos temporales). Una secuencia de puntos temporales t1, t2, . . . , tn de t es un conjunto ordenado de puntos temporales t1, t2, . . . , tn tal que t1 ≥ t y ∀i ∈ [1, n − 1], ti+1 ≥ ti. Tomamos un sistema poblado por n agentes a1, . . . , an. Cada agente se define como una tupla F, Oi, hi, donde: • F, el conjunto de hechos, conocimiento común a todos los agentes. • Oi ∈ 2O, el conjunto de observaciones realizadas por el agente hasta el momento. Suponemos una memoria perfecta, por lo tanto, este conjunto crece de forma monótona. • hi ∈ H, la hipótesis favorita del agente. Una noción clave que rige la formación de hipótesis es la de consistencia, definida a continuación: Definición 2 (Consistencia). Decimos que: • Un agente es consistente (Cons(ai)) si y solo si Cons(hi, Oi) (es decir, su hipótesis es consistente con su conjunto de observaciones). • Un agente ai es consistente con un agente compañero aj si y solo si Cons(ai) y Cons(hi, Oj) (es decir, este agente es consistente y su hipótesis puede explicar el conjunto de observaciones del otro agente). • Dos agentes ai y aj son mutuamente consistentes (MCons(ai, aj)) si y solo si Cons(ai, aj) y Cons(aj, ai). • Un sistema es consistente si y solo si para todo (i, j) ∈ [1, n]2 se cumple que MCons(ai, aj). Para garantizar su consistencia, cada agente está equipado con una maquinaria de razonamiento abstracto que llamaremos la función de explicación Eh. Esta función (determinística) toma un conjunto de observaciones y devuelve una única hipótesis preferida (2O → H). Suponemos que h = Eh(O) para ser consistente con O por definición de Eh, por lo que usar esta función en su conjunto de observaciones para determinar su hipótesis favorita es una forma segura para que el agente logre consistencia. Sin embargo, cabe destacar que una hipótesis no necesita ser generada por Eh para ser consistente con un conjunto de observaciones. Como ejemplo concreto de tal función, y una de las principales inspiraciones de este trabajo, se puede citar el sistema de razonamiento Theorist [6], siempre y cuando esté acoplado con un filtro que seleccione una teoría preferida entre las inicialmente seleccionadas por Theorist. También hay que tener en cuenta que hi solo puede ser modificado como consecuencia de la aplicación de Eh. Nos referimos a esto como la autonomía del agente: ningún otro agente puede imponer directamente una hipótesis dada a un agente. Como consecuencia, solo una nueva observación (ya sea una nueva percepción o una observación comunicada por otro agente) puede resultar en una modificación de su hipótesis preferida hi (pero no necesariamente, por supuesto). Finalmente definimos una propiedad del sistema que utilizaremos en el resto del artículo: Definición 3 (Percepciones Acotadas). Un sistema implica una percepción limitada para los agentes si y solo si existe un n0 tal que para todo t, la unión de N observaciones realizadas por los agentes es menor o igual a n0. (Es decir, el número de observaciones a realizar por los agentes en el sistema no es infinito.) Ahora necesitamos ver cómo evolucionarán e interactuarán estos agentes en su entorno. En nuestro contexto, los agentes evolucionan en un entorno dinámico, y asumimos clásicamente el siguiente ciclo del sistema: 1. Dinámica del entorno: el entorno evoluciona de acuerdo con las reglas definidas de la dinámica del sistema. 2. Paso de percepción: los agentes obtienen percepciones del entorno. Estas percepciones suelen ser parciales (por ejemplo, el agente solo puede ver una parte de un mapa). 3. Paso de razonamiento: los agentes comparan la percepción con las predicciones, buscan explicaciones para las diferencias (potenciales), refinan su hipótesis, y sacan nuevas conclusiones. 4. Paso de comunicación: los agentes pueden comunicar hipótesis y observaciones con otros agentes a través de un protocolo definido. Cualquier agente solo puede estar involucrado en una comunicación con otro agente en el paso 5. Paso de acción: los agentes realizan un razonamiento práctico utilizando los modelos obtenidos de los pasos anteriores y seleccionan una acción. Ellos pueden modificar el entorno ejecutándolo. La comunicación de los agentes estará aún más restringida por consideraciones topológicas. En un momento dado, un agente solo podrá comunicarse con un número de vecinos. Sus conexiones con estos otros agentes pueden The Sixth Intl. La Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) evoluciona con su situación en el entorno. Normalmente, un agente solo puede comunicarse con agentes que puede percibir, pero se podría imaginar la evolución de restricciones topológicas en la comunicación basadas en una red de comunicaciones entre agentes donde los enlaces no siempre están activos. En nuestro sistema, los agentes podrán comunicarse entre sí. Sin embargo, debido a las restricciones topológicas mencionadas anteriormente, no podrán comunicarse con ningún agente en ningún momento. Con quién puede comunicarse un agente se definirá dinámicamente (por ejemplo, esto puede ser consecuencia de que los agentes estén lo suficientemente cerca para ponerse en contacto). Denotaremos de forma abstracta por C(ai, aj, t) la propiedad de comunicación, es decir, el hecho de que los agentes ai y aj puedan comunicarse en el tiempo t (nota que se asume que esta relación es simétrica, pero por supuesto no transitiva). Ahora estamos en posición de definir dos propiedades esenciales de nuestro sistema. Definición 4 (Camino Temporal). Existe un camino de comunicación temporal en el horizonte tf (denotado Ltf (aI, aJ)) entre ai y aj si y solo si existe una secuencia de puntos temporales t1, t2, ..., tn desde tf y una secuencia de agentes k1, k2, ..., kn tal que (i) C(aI, ak1, t1), (ii) C(akn, aJ, tn+1), (iii) ∀i ∈ [1, n], C(aki, aki+1, ti). Intuitivamente, lo que esta propiedad dice es que es posible encontrar un camino temporal en el futuro que permitiría vincular al agente ai y aj a través de una secuencia de agentes intermedios. Ten en cuenta que los puntos temporales no necesariamente son sucesivos, y que la secuencia de agentes puede involucrar a los mismos agentes varias veces. Definición 5 (Conexidad Temporal). Un sistema es temporalmente conexo si y solo si ∀t ∀(i, j)∈[1, n]2 Lt(ai, aj). En resumen, un sistema temporalmente conexo garantiza que cualquier agente podrá comunicarse con cualquier otro agente, sin importar cuánto tiempo pueda llevar hacerlo, en cualquier momento. Dicho de otra manera, nunca sucede que un agente esté aislado para siempre de otro agente del sistema. A continuación discutiremos en detalle cómo la comunicación tiene lugar concretamente en nuestro sistema. Recuerda que en este documento, solo consideramos el caso de intercambios bilaterales (un agente solo puede hablar con otro agente) y también asumimos que cualquier agente solo puede participar en un intercambio en una ronda dada. 3. PROTOCOLOS Y ESTRATEGIAS En esta sección, discutimos los requisitos de los protocolos de interacción que rigen el intercambio de mensajes entre agentes, y proporcionamos algunos ejemplos de la implementación de dichos protocolos. Para aclarar la presentación, distinguimos dos niveles: el nivel local, que se ocupa de la regulación de los intercambios bilaterales; y el nivel global, que regula principalmente la forma en que los agentes pueden participar realmente en una conversación. En cada nivel, separamos lo que está especificado por el protocolo y lo que se deja a las estrategias de los agentes. Protocolos y estrategias locales Comenzamos inspeccionando los protocolos y estrategias locales que regularán la comunicación entre los agentes del sistema. Al limitarnos a la comunicación bilateral, estos protocolos simplemente implicarán a dos agentes. Dicho protocolo tendrá que cumplir con un requisito básico para ser satisfactorio: consistencia (CONS) - un protocolo local debe garantizar la consistencia mutua de los agentes al finalizar (lo que implica, por supuesto, la finalización). Figura 1: Un Protocolo de Intercambio de Hipótesis [1] Un ejemplo de dicho protocolo es el protocolo descrito en [1] que se muestra en la Fig. 1. Para ilustrar aún más cómo dicho protocolo puede ser utilizado por agentes, proporcionamos algunos detalles sobre una posible estrategia: al recibir una hipótesis h1 (proponer(h1) o contra-proponer(h1)) de a1, el agente a2 se encuentra en el estado 2 y tiene las siguientes respuestas posibles: contraejemplo (si el agente conoce un ejemplo que contradice la hipótesis, o no está explicado por esta hipótesis), desafío (si el agente carece de evidencia para aceptar esta hipótesis), contra-proponer (si el agente está de acuerdo con la hipótesis pero prefiere otra), o aceptar (si es tan buena como su hipótesis favorita). Esta estrategia garantiza, entre otras propiedades, la eventual consistencia lógica mutua de los agentes involucrados [1]. Protocolo global El protocolo global regula la forma en que se iniciarán los intercambios bilaterales entre agentes. En cada turno, los agentes enviarán simultáneamente una solicitud ponderada para comunicarse con otros agentes. Este peso es un valor que mide la disposición de los agentes para conversar con el agente objetivo (en la práctica, esto puede basarse en diferentes heurísticas, pero haremos algunas suposiciones sobre las estrategias de los agentes, ver más abajo). Enviar una solicitud de este tipo es una especie de compromiso condicional para el agente. Un agente que envía una solicitud ponderada se compromete a entablar una conversación con el objetivo si no recibe y acepta otra solicitud por sí mismo. Una vez que se hayan recibido todas las solicitudes, cada agente responde con un aceptar o un rechazar. Al responder con un aceptar, un agente se compromete plenamente a participar en la conversación con el remitente. Por lo tanto, solo puede enviar una aceptación en una ronda dada, ya que un agente solo puede participar en una conversación por paso de tiempo. Cuando se hayan recibido todas las respuestas, cada agente que reciba una aceptación puede iniciar una conversación utilizando el protocolo local o enviar una cancelación si ha aceptado otra solicitud. Al final de todos los intercambios bilaterales, los agentes involucrados en la conversación son descartados del protocolo. Entonces cada uno de los agentes restantes reenvía una solicitud y el proceso se repite hasta que no se envíen más solicitudes. Estrategia global Ahora definimos cuatro requisitos para las estrategias utilizadas por los agentes, dependiendo de su rol en el protocolo: dos se refieren al rol del solicitante (cómo decidir quién es el 1000 The Sixth Intl. La Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) ¿con qué agente desea comunicarse? Los otros dos con el rol de respondedor (¿cómo decidir qué solicitud de comunicación aceptar o no?). • Disposición para resolver inconsistencias (SOLVE): los agentes desean comunicarse con cualquier otro agente a menos que sepan que son mutuamente consistentes. • Enfoque en resolver inconsistencias (FOCUS): los agentes no solicitan comunicarse con un agente con el que saben que son mutuamente consistentes. • Disposición para comunicarse (COMM): los agentes no pueden rechazar una solicitud de comunicación ponderada, a menos que acaben de recibir o enviar una solicitud con un peso mayor. • Compromiso con la solicitud de comunicación (REQU): los agentes no pueden aceptar una solicitud de comunicación ponderada si ellos mismos han enviado una solicitud de comunicación con un peso mayor. Por lo tanto, no cancelarán su solicitud a menos que hayan recibido una solicitud comunicacional con mayor peso. Ahora la estructura del protocolo, junto con las propiedades COMM+REQU, garantizan que una solicitud solo puede ser rechazada si su agente objetivo se involucra en comunicación con otro agente. Supongamos de hecho que el agente ai quiere comunicarse con aj enviando una solicitud con peso w. COMM garantiza que un agente que reciba una solicitud ponderada aceptará esta comunicación, aceptará una comunicación con un peso mayor o esperará la respuesta a una solicitud con un peso mayor. Esto asegura que la solicitud con peso máximo será aceptada y no cancelada (ya que REQU asegura que un agente que envía una solicitud solo puede cancelarla si acepta otra solicitud con un peso mayor). Por lo tanto, al menos dos agentes participarán en una conversación por ronda del protocolo global. Como el protocolo asegura que ai puede reenviar su solicitud mientras aj no está ocupado en una conversación, llegará un momento en el que aj deberá participar en una conversación, ya sea con ai u otro agente. Estos requisitos se refieren al envío y aceptación de solicitudes, pero los agentes también necesitan alguna estrategia de atribución de peso. Describimos a continuación una estrategia altruista, utilizada en nuestros experimentos. Siendo cooperativo, un agente puede querer conocer más los deseos de comunicación de otros agentes para mejorar la asignación general de intercambios a los agentes. Se añade entonces un paso de solicitud de contexto al protocolo global. Antes de enviar su solicitud ponderada elegida, los agentes asignan un peso a todos los agentes con los que están dispuestos a comunicarse, de acuerdo con algunos factores internos. En el caso más simple, este peso será 1 para todos los agentes con los que el agente no esté seguro de ser mutuamente consistentes (garantizando SOLVE), sin considerar a otros agentes para la comunicación (garantizando FOCUS). El agente luego envía una solicitud de contexto a todos los agentes con los que se considera la comunicación. Esta solicitud también proporciona información sobre el remitente (lista de comunicaciones consideradas junto con su peso). Después de recibir todas las solicitudes de contexto, los agentes responderán con un rechazo si ya están ocupados en una conversación (en cuyo caso, el agente solicitante no considerará comunicarse con ellos en este turno), o con una información que brinde al solicitante información sobre las solicitudes que ha enviado y recibido. Cuando se hayan recibido todas las respuestas, cada agente puede calcular el peso de todas las solicitudes que le conciernen. Lo hace restando del peso de su solicitud el peso de todas las solicitudes relacionadas con él o su objetivo (es decir, el peso final de la solicitud de ai a aj es Wi,j = wi,j + wj,i - ( Σ k∈R(i)-{j} wi,k + Σ k∈S(i)-{j} wk,i + Σ k∈R(j)-{i} wj,k + Σ k∈S(j)-{i} wk,j) donde wi,j es el peso de la solicitud de ai a aj, R(i) es el conjunto de índices de agentes que han recibido una solicitud de ai y S(i) es el conjunto de índices de agentes que han enviado una solicitud a ai). Luego envía finalmente una solicitud ponderada a los agentes que maximizan este peso (o esperan una solicitud) según lo descrito en el protocolo global. 4. (CONDICIONAL) CONVERGENCIA HACIA LA COHERENCIA GLOBAL En esta sección mostraremos que los requisitos relacionados con los protocolos y estrategias recién discutidos serán suficientes para garantizar que el sistema eventualmente convergerá hacia la coherencia global, bajo ciertas condiciones. Primero demostramos que, si dos agentes no son mutuamente consistentes en algún momento, entonces necesariamente habrá un momento en el futuro en el que un agente aprenderá una nueva observación, ya sea porque es nueva para el sistema, o al aprenderla de otro agente. Lema 1. Sea S un sistema poblado por n agentes a1, a2, ..., an, temporalmente conectados e involucrando percepciones limitadas para estos agentes. Sea n1 la suma de las cardinalidades de la intersección de los conjuntos de observaciones emparejados. (n1 = P (i,j)∈[1,n]2 |Oi ∩ Oj|) Sea n2 la cardinalidad de la unión de todos los conjuntos de observaciones de los agentes. (n2 = | ∪N i=1 Oi|). Si ¬MCons(ai, aj) en el tiempo t0, necesariamente existe un tiempo t > t0 tal que ya sea n1 o n2 aumentarán. Prueba. Supongamos que exista un tiempo t0 y unos índices (i, j) tal que ¬MCons(ai, aj). Utilizaremos mt0 = P (k,l)∈[1,n]2 εComm(ak, al, t0) donde εComm(ak, al, t0) = 1 si ak y al han comunicado al menos una vez desde t0, y 0 en caso contrario. La conexidad temporal garantiza que existen t1, ..., tm+1 y k1, ..., km tal que. C(ai, ak1 , t1), C(akm , aj, tm+1), y ∀p ∈ [1, m], C(akp , akp+1 , tp). Claramente, si MCons(ai, ak1), MCons(akm, aj) y ∀p, MCons(akp, akp+1), tenemos MCons(ai, aj) lo cual contradice nuestra hipótesis (siendo MCons transitivo, MCons(ai, ak1)∧MCons(ak1, ak2) implica que MCons(ai, ak2) y así sucesivamente hasta MCons(ai, akm)∧MCons(akm, aj) lo cual implica MCons(ai, aj)). Al menos dos agentes son necesariamente inconsistentes (¬MCons(ai, ak1), o ¬MCons(akm, aj), o ∃p0 t.q. ¬MCons(akp0, akp0+1)). Que ak y al sean estos dos vecinos en un momento t > t0 1. La propiedad SOLVE asegura que ya sea ak o al enviará una solicitud de comunicación al otro agente en el tiempo t. Como se mostró anteriormente, esto a su vez garantiza que al menos uno de estos agentes estará involucrado en una comunicación. Entonces hay dos posibilidades: (caso i) ak y al se comunican en el tiempo t. En este caso, sabemos que ¬MCons(ak, al). Esto y la propiedad CONS aseguran que al menos uno de los agentes debe cambiar su 1. Estrictamente hablando, la transitividad de MCons solo asegura que ak y al son inconsistentes en un tiempo t ≥ t0 que puede ser diferente del tiempo t en el que pueden comunicarse. Pero si se vuelven consistentes entre t y t (o inconsistentes entre t y t), significa que al menos uno de ellos ha cambiado su hipótesis entre t y t, es decir, después de t0. Podemos entonces aplicar el razonamiento del caso iib. El Sexto Internacional. La Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 1001 hipótesis, lo cual a su vez, dado que los agentes son autónomos, implica al menos un intercambio de observación. Pero entonces |Ok ∩Ol| está destinado a aumentar: n1(t) > n1(t0). (caso ii) ak se comunica con ap en el tiempo t. Entonces tenemos de nuevo dos posibilidades: (caso iia) ak y ap no se comunicaron desde t0. Pero luego εComm(ak, ap, t0) tenía valor 0 y toma valor 1. Por lo tanto, mt0 aumenta. (caso iib) ak y ap se comunicaron en algún momento t0 > t0. La propiedad CONS del protocolo asegura que MCons(ak, ap) en ese momento. Ahora el hecho de que se comuniquen y se ENFOQUEN implica que al menos uno de ellos cambió su hipótesis en el ínterin. El hecho de que los agentes sean autónomos implica a su vez que una nueva observación (percibida o recibida de otro agente) necesariamente provocó este cambio. El último caso garantizaría la existencia de un tiempo t > t0 y un agente aq tal que |Op ∩ Oq| o |Ok ∩ Oq| aumenten en 1 en ese momento (lo que implica que n1(t) > n1(t0)). El caso anterior significa que el agente obtiene una nueva percepción en el tiempo t. Si esa observación era desconocida en el sistema antes, entonces n2(t) > n2(t0). Si algún agente aq ya conocía esta observación antes, entonces tanto Op ∩ Oq como Ok ∩ Oq aumentan en 1 en el tiempo t (lo que implica que n1(t) > n1(t0)). Por lo tanto, ¬MCons(ai, aj) en el tiempo t0 garantiza que, o bien: −∃t > t0 t.q. n1(t ) > n1(t0); o −∃t > t0 t.q. n2(t ) > n2(t0); o −∃t > t0 t.q. mt0 aumenta en 1 en el tiempo t. Al iterar el razonamiento con t (pero manteniendo t0 como la referencia de tiempo para mt0), podemos eliminar el tercer caso (mt0 es un entero y está limitado por n2, lo que significa que después de un máximo de n2 iteraciones, necesariamente estaremos en uno de los otros dos casos). Como resultado, hemos demostrado que si ¬MCons(ai, aj) en el tiempo t0, necesariamente habrá un tiempo t tal que ya sea n1 o n2 aumentarán. Teorema 1 (Consistencia global). Sea S un sistema poblado por n agentes a1, a2, ..., an, temporalmente conectados e involucrando percepciones limitadas para estos agentes. Sea Cons(ai, aj) una propiedad de consistencia transitiva. Entonces, cualquier protocolo y estrategias que cumplan con las propiedades CONS, SOLVE, FOCUS, COMM y REQU garantizan que el sistema convergerá hacia la consistencia global. Prueba. Por el bien de la contradicción, asumamos que ∃I, J ∈ [1, N] tal que ∀t, ∃t0 > t, tal que ¬Cons(aI , aJ , t0). Usando el lema, esto implica que ∃t > t0 tal que n1(t) > n1(t0) o n2(t) > n2(t0). Pero podemos aplicar el mismo razonamiento tomando t = t, lo que nos daría t1 > t > t0 tal que ¬Cons(aI , aJ , t1), lo que nos da t > t1 tal que n1(t) > n1(t1) o n2(t) > n2(t1). Mediante iteraciones sucesivas podemos construir una secuencia t0, t1, ..., tn, que puede dividirse en dos subsecuencias t0, t1, ...tn y t0, t1, ..., tn tal que n1(t0) < n1(t1) < ... < n1(tn) y n2(t0) < n2(t1) < ... < n2(tn). Una de estas subsecuencias tiene que ser infinita. Sin embargo, n1(ti) y n2(ti) son estrictamente crecientes, enteros y acotados, lo que implica que ambos son finitos. Contradicción. Lo que el resultado anterior muestra esencialmente es que, en un sistema donde ningún agente estará aislado del resto de los agentes para siempre, solo se necesitan suposiciones muy leves sobre los protocolos y estrategias utilizados por los agentes para garantizar la convergencia hacia la consistencia del sistema en una cantidad finita de tiempo (aunque podría llevar mucho tiempo). Desafortunadamente, en muchas situaciones críticas, no será posible asumir esta conexión temporal. Dado que enfoques distribuidos como el abogado en este documento suelen presentarse como una buena manera de abordar problemas de confiabilidad o problemas de dependencia de un centro que son de suma importancia en estas aplicaciones críticas, ciertamente resulta interesante explorar más a fondo cómo se comportaría un sistema de este tipo cuando relajamos esta suposición. ESTUDIO EXPERIMENTAL Este experimento implica agentes tratando de escapar de un edificio en llamas. El entorno se describe como una cuadrícula espacial con un conjunto de paredes y (afortunadamente) algunas salidas. El tiempo y el espacio se consideran discretos. El tiempo se divide en rondas. Los agentes se localizan por su posición en la cuadrícula espacial. Estos agentes pueden moverse y comunicarse con otros agentes. En una ronda, un agente puede moverse una celda en cualquiera de las cuatro direcciones cardinales, siempre y cuando no esté bloqueado por una pared. En esta aplicación, los agentes se comunican con cualquier otro agente (pero, recuerda, solo uno) siempre y cuando este agente esté a la vista y aún no hayan intercambiado su hipótesis actual favorita. De repente, se desata un incendio en estas instalaciones. A partir de este momento, el fuego se propaga. En cada ronda, en cada caso donde haya fuego, el fuego se propaga en las cuatro direcciones. Sin embargo, el fuego no puede propagarse a través de una pared. Si el fuego se propaga en un caso donde un agente está posicionado, ese agente se quema y se considera muerto. Por supuesto, ya no puede moverse ni comunicarse. Si un agente llega a una salida, se considera que está a salvo y ya no puede ser quemado. Los agentes conocen el entorno y las reglas que rigen la dinámica de este entorno, es decir, conocen el mapa así como las reglas de propagación del fuego previamente descritas. También perciben este entorno localmente, pero no pueden ver más allá de 3 casos en cualquier dirección. Las paredes también bloquean la línea de visión, impidiendo que los agentes vean detrás de ellas. Dentro de su campo de visión, pueden ver a otros agentes y si los casos que ven están en llamas. Todas estas percepciones están memorizadas. Mostramos ahora cómo se instancia el marco abstracto presentado en el documento. • O = {Fire(x, y, t), NoFire(x, y, t), Agent(ai, x, y, t)} Las observaciones pueden ser positivas (o ∈ P(O) si ∃h ∈ H tal que h |= o) o negativas (o ∈ N(O) si ∃h ∈ H tal que h |= ¬o). • H={FireOrigin(x1, y1, t1)∧...∧FireOrigin(xl, yl, tl)} Las hipótesis son conjunciones de Orígenes de Fuego. • La relación de consistencia Cons(h, O) satisface: - coherencia: ∀o ∈ N(O), h |= ¬o. - completitud: ∀o ∈ P(O), h |= o. - minimalidad: Para todo h ∈ H, si h es coherente y completo para O, entonces h es preferido a h de acuerdo con la relación de preferencia (h ≤p h). Selecciona primero el número mínimo de orígenes, luego el más reciente (estrategia menos preemptiva [6]), y luego utiliza un ranking fijo arbitrario para discriminar ex-aequo. La relación resultante es un orden total, por lo tanto, la minimalidad implica que habrá un único h tal que Cons(O, h) para un O dado. Esto a su vez significa que MCons(ai, aj) si y solo si Cons(ai), Cons(aj) y hi = hj. Esta relación es entonces transitiva y simétrica. 1002 El Sexto Internacional. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) • Eh toma O como argumento y devuelve min≤p de la hipótesis coherente y completa para O 5.1 Evaluación Experimental Clásicamente evaluaremos la efectividad y eficiencia de diferentes protocolos de interacción (ver, por ejemplo, [3, 4]). La efectividad de un protocolo se determinará por la proporción de agentes que sobreviven al incendio respecto al número inicial de agentes involucrados en el experimento. Si este valor es alto, el protocolo ha sido efectivo para propagar la información y/o para que los agentes refinen sus hipótesis y determinen la mejor manera de salir. Eficiencia de un protocolo. Por lo general, el uso de información de apoyo implicará una sobrecarga de comunicación. Aquí asumiremos que la eficiencia de un protocolo dado está caracterizada por el flujo de datos inducido por este protocolo. En este documento solo discutiremos este aspecto con respecto a los protocolos locales. La medida principal que utilizaremos aquí es el tamaño total promedio de los mensajes intercambiados por los agentes por intercambio (teniendo en cuenta tanto el número de mensajes como el tamaño real de los mensajes, ya que podría ser que los mensajes resulten ser muy grandes, conteniendo por ejemplo un gran número de observaciones, lo que podría contrarrestar un bajo número de mensajes). 5.2 Configuraciones Experimentales Las configuraciones experimentales elegidas son las siguientes: • Topología ambiental: El rendimiento de la propagación de la información está altamente condicionado por la topología del entorno. Las habilidades de percepción de los agentes dependen de la apertura del entorno. Con un gran número de paredes, las percepciones de los agentes están limitadas, al igual que el número de posibles comunicaciones entre agentes, mientras que un entorno abierto proporcionará posibilidades óptimas de percepción y propagación de información. Por lo tanto, proponemos un índice topológico (ver abajo) como base común para caracterizar los entornos (mapas) utilizados durante las experimentaciones. El índice topológico (TI) es la proporción entre el número de celdas que pueden ser percibidas por los agentes sumadas desde todas las posiciones posibles, dividido por el número de celdas que serían percibidas desde las mismas posiciones pero sin paredes. (Cuanto más cercano a 1, más abierto es el entorno). También utilizaremos dos medidas adicionales, más clásicas [10]: la longitud del camino característico (CPL) y el coeficiente de agrupamiento (CC). • Número de agentes: la propagación de la información también depende del número inicial de agentes involucrados durante una experimentación. Por ejemplo, cuantos más agentes haya, más potenciales comunicaciones existen. Esto significa que habrá más potencial de propagación, pero también que la restricción de intercambio bilateral será más crucial. 3 El CPL es la mediana de las medias de las longitudes de los caminos más cortos que conectan cada nodo con todos los demás nodos. 4 caracterizando el grado de aislamiento de una región de un entorno en términos de accesibilidad (número de caminos aún utilizables para llegar a esta región). Mapa T.I. (%) C.P.L. C.C. 69-1 69,23 4,5 0,69 69-2 68,88 4,38 0,65 69-3 69,80 4,25 0,67 53-1 53,19 5,6 0,59 53-2 53,53 6,38 0,54 53-3 53,92 6,08 0,61 38-1 38,56 8,19 0,50 38-2 38,56 7,3 0,50 38-3 38,23 8,13 0,50 Tabla 1: Características Topológicas de los Mapas • Posiciones iniciales de los agentes- Las posiciones iniciales de los agentes tienen una influencia significativa en el comportamiento general de una instancia de nuestro sistema: estar cerca de una salida facilitará (en general) la escapatoria. 5.3 Entornos experimentales Elegimos realizar experimentos en tres índices topológicos muy diferentes (69% para entornos abiertos, 53% para entornos mixtos y 38% para entornos tipo laberinto). Figura 2: Dos mapas (izquierda: IT=69%, derecha IT=38%) Diseñamos tres mapas diferentes para cada índice (la Fig. 2 muestra dos de ellos), conteniendo el mismo número máximo de agentes (máximo 36 agentes) con una densidad máxima de un agente por celda, el mismo número de salidas y un origen de incendio similar (por ejemplo, tiempo y posición de inicio). Los tres mapas diferentes de un índice dado están diseñados de la siguiente manera. El primer plano es un modelo de un piso de un edificio existente. El segundo mapa tiene el mismo perímetro, salidas y origen del fuego que el primero, pero la cantidad y ubicación de las paredes son diferentes (las ubicaciones de las paredes son diseñadas por una heurística que crea paredes de forma aleatoria en la cuadrícula espacial de manera que no se creen habitaciones completamente cerradas y que ninguna salida quede bloqueada). El tercer mapa se caracteriza por un recinto geométrico en el que la ubicación de las paredes también está diseñada con la heurística mencionada anteriormente. La Tabla 1 resume las diferentes medidas topológicas que caracterizan estos mapas diferentes. Vale la pena señalar que los valores confirman la relevancia de TI (los mapas con un alto TI tienen un bajo CPL y un alto CC). Sin embargo, el CPL y el CC permiten refinar aún más la diferencia entre los mapas, por ejemplo, entre 53-1 y 53-2). 5.4 Resultados Experimentales Para cada trío de mapas definidos como se mencionó anteriormente, llevamos a cabo los mismos experimentos. En cada experimento, la sociedad difiere en cuanto a su proporción inicial de agentes involucrados, desde el 1% hasta el 100%. Esta proporción inicial representa el porcentaje de agentes involucrados con respecto al número máximo posible de agentes. Para cada mapa y cada proporción inicial, la Sexta Internacional. En la Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) seleccionamos aleatoriamente 100 ubicaciones iniciales de agentes diferentes. Para cada una de esas ubicaciones diferentes ejecutamos el sistema una vez para cada protocolo de interacción diferente. La efectividad de la comunicación y argumentación El primer experimento que hemos establecido tiene como objetivo probar cuán efectivo es el intercambio de hipótesis (IH), y en particular cómo los aspectos topológicos afectarán esta efectividad. Para hacerlo, hemos calculado la proporción de mejora ofrecida por ese protocolo sobre una situación en la que los agentes simplemente no podían comunicarse (sin comunicación). Para obtener más información sobre en qué medida el intercambio de hipótesis fue realmente crucial, también probamos un protocolo mucho menos elaborado que consistía en intercambios de observaciones simples (OE). Más precisamente, este protocolo requiere que cada agente almacene cualquier observación inesperada que perciba, y los agentes simplemente intercambian sus respectivas listas de observaciones cuando discuten. En este caso, el protocolo local es diferente (nota en particular que no garantiza consistencia mutua), pero el protocolo global permanece igual (con la única excepción de que la motivación de los agentes para comunicarse es sincronizar su lista de observaciones, no sus hipótesis). Si este protocolo es como máximo tan efectivo como HE, tiene la ventaja de ser más eficiente (esto es obvio en cuanto al número de mensajes, que se limitará a 2, menos directo en lo que respecta al tamaño de los mensajes, pero la observación general de que el intercambio de observaciones se puede ver como una versión simplificada del desafío es útil para ver esto). Los resultados de estos experimentos se informan en la Figura 3. Figura 3: Ganancia de la proporción de efectividad comparativa de los protocolos cuando la proporción de agentes aumenta. La primera observación que debe hacerse es que la comunicación mejora la efectividad del proceso, y esta proporción aumenta a medida que el número de agentes crece en el sistema. La segunda lección que aprendemos aquí es que la cercanía relativamente hace que la comunicación sea más efectiva que la falta de comunicación. Los mapas que muestran un T.I. del 38% están constantemente por encima de los otros dos, y el 53% sigue siendo ligeramente pero significativamente mejor que el 69%. Sin embargo, estas curvas también sugieren, quizás sorprendentemente, que HE supera a OE precisamente en aquellas situaciones donde la ganancia de la relación es menos importante (la única diferencia notable ocurre en mapas bastante abiertos donde T.I. es del 69%). Esto se puede explicar de la siguiente manera: cuando un mapa está abierto, los agentes tienen muchos posibles candidatos de explicación, y la argumentación se vuelve útil para discriminar entre ellos. Cuando un mapa es laberíntico, hay menos posibles explicaciones para un evento inesperado. Importancia del Protocolo Global El segundo conjunto de experimentos busca evaluar la importancia del diseño del protocolo global. Probamos nuestro protocolo contra un protocolo de difusión local (LB). La difusión local significa que todos los agentes vecinos percibidos por un agente estarán involucrados en una comunicación con ese agente en una ronda dada, aliviando la restricción de una sola comunicación por agente. Esto nos proporciona un límite superior aproximado sobre la posible ganancia de ratio en el sistema (para un protocolo local dado). Nuevamente, evaluamos la ganancia de la relación inducida por ese LB sobre nuestro HE clásico, para las tres clases diferentes de mapas. Los resultados se informan en la Figura 4. Figura 4: Ganancia de la proporción de transmisión local sobre el intercambio de hipótesis. Tenga en cuenta que la ganancia de la proporción es 0 cuando la proporción de agentes es del 5%, lo cual se explica fácilmente por el hecho de que corresponde a situaciones que involucran solo a dos agentes. Primero observamos que todas las clases de mapas muestran un aumento en la ganancia de la proporción a medida que aumenta el número de agentes: la ganancia alcanza entre el 10 y el 20%, dependiendo de la clase de mapas considerada. Si se compara esto con la mejora reportada en el experimento anterior, parece ser de la misma magnitud. Esto ilustra que el diseño del protocolo global no puede ser ignorado, especialmente cuando la proporción de agentes es alta. Sin embargo, también observamos que las curvas de ganancia de la proporción de efectividad tienen formas muy diferentes en ambos casos: la ganancia inducida por la precisión del protocolo local aumenta muy rápidamente con la proporción de agentes, mientras que la curva es muy suave para el global. Ahora observemos con más cuidado los resultados reportados aquí: la curva correspondiente a una TI del 53% está por encima de la correspondiente al 38%. Esto se debe a que cuanto más abierta sea un mapa, más oportunidades hay de comunicarse con más de un agente (y por lo tanto beneficiarse de la difusión). Sin embargo, también observamos que la curva para el 69% está por debajo de la del 53%. Esto se explica de la siguiente manera: en el caso del 69%, la ganancia potencial en términos de agentes sobrevivientes es mucho menor, porque nuestros protocolos ya ofrecen resultados bastante eficientes de todos modos (alcanzando rápidamente el 90%, ver Fig. 3). Una regla general podría ser que cuando el número de agentes es pequeño, se debe prestar especial atención al local 1004 de la Sexta Internacional. En el caso de que el número de agentes sea pequeño, uno puede utilizar el protocolo de la Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07), mientras que cuando ese número es grande, se debe diseñar cuidadosamente uno global (a menos que el mapa sea tan abierto que el protocolo ya sea casi óptimamente eficiente). La eficiencia de los protocolos. El experimento final reportado aquí se centra en el análisis de la eficiencia de los protocolos. Aquí analizamos el tamaño medio de la totalidad de los mensajes que son intercambiados por agentes (tamaño medio de intercambios, en resumen) utilizando los siguientes protocolos: HE, OE y dos protocolos variantes. El primero es un protocolo de intercambio de hipótesis restringidas (RHE) intermediario. RHE es el siguiente: no implica ningún desafío ni contraoferta, lo que significa que los agentes no pueden cambiar su rol durante el protocolo (esto difiere de RE en ese aspecto). En resumen, RHE permite a un agente agotar las críticas de sus socios, y eventualmente este socio adoptará la hipótesis del agente. Ten en cuenta que esto significa que la autonomía del agente no se conserva aquí (ya que un agente esencialmente aceptará cualquier hipótesis que no pueda socavar), con la esperanza de que la ganancia en eficiencia sea lo suficientemente significativa como para compensar una pérdida en efectividad. El segundo protocolo de variante es un protocolo completo de intercambio de observaciones (COE). COE utiliza los mismos principios que OE, pero incluye además todos los ejemplos críticos negativos (nofire) en el intercambio (dando así todos los ejemplos utilizados como argumentos por el protocolo de intercambio de hipótesis), mejorando así la efectividad. Los resultados para el mapa 69-1 se muestran en la Figura 5. Figura 5: Tamaño medio de los intercambios. Primero podemos observar el hecho de que el orden de los protocolos, desde el menos eficiente hasta el más eficiente, es COE, HE, RHE y luego OE. ÉL siendo más eficiente que COE demuestra que el proceso de argumentación gana eficiencia al seleccionar cuándo es necesario proporcionar ejemplos negativos, los cuales tienen menos impacto que los positivos en nuestro entorno de prueba específico. Sin embargo, al comunicar hipótesis antes de proporcionar observaciones para respaldarla (HE) en lugar de dar directamente las observaciones más cruciales (OE), el proceso de argumentación duplica el tamaño de los intercambios de datos. Es el costo de garantizar la consistencia al final del intercambio (una propiedad que OE no admite). También es significativo el hecho de que el tamaño promedio de los intercambios es ligeramente mayor cuando el número de agentes es pequeño. Esto se explica por el hecho de que en estos casos solo unos pocos agentes tienen información relevante en su posesión, y que necesitarán comunicarse mucho para llegar a un punto de vista común de la situación. Cuando el número de agentes aumenta, este conocimiento se distribuye entre más agentes que necesitan discusiones más cortas para llegar a una consistencia mutua. Como consecuencia, la ganancia relativa en eficiencia de usar RHE parece ser mejor cuando el número de agentes es pequeño: cuando es alto, difícilmente discutirán de todos modos. Finalmente, vale la pena notar que la desviación estándar para estos experimentos es bastante alta, lo que significa que la conversación no converge hacia ningún patrón estereotípico. 6. CONCLUSIÓN Este documento ha investigado las propiedades de un sistema multiagente donde cada agente (distribuido) percibe localmente su entorno e intenta alcanzar consistencia con otros agentes a pesar de severas restricciones de comunicación. En particular, hemos expuesto condiciones que permiten la convergencia e investigado experimentalmente una situación típica donde esas condiciones no pueden cumplirse. Hay muchas posibles extensiones a este trabajo, la primera siendo investigar más a fondo las propiedades de diferentes protocolos globales pertenecientes a la clase que identificamos, y su influencia en el resultado. Existen en particular muchas heurísticas, altamente dependientes del contexto del estudio, que podrían intuitivamente arrojar resultados interesantes (en nuestro estudio, seleccionar al destinatario en función de lo que se pueda inferir de sus acciones observadas podría ser una de esas heurísticas). Un candidato obvio para problemas a largo plazo se refiere a la relajación de la suposición de un sensor perfecto. 7. REFERENCIAS [1] G. Bourgne, N. Maudet y S. Pinson. Cuando los agentes comunican hipótesis en situaciones críticas. En Actas de DALT-2006, mayo de 2006. [2] P. Harvey, C. F. Chang y A. Ghose. Búsqueda distribuida basada en soporte: un nuevo enfoque para el procesamiento de restricciones multiagente. En Actas de AAMAS06, 2006. [3] H. Jung y M. Tambe. Argumentación como satisfacción de restricciones distribuida: Aplicaciones y resultados. En Actas de AGENTS01, 2001. [4] N. C. Karunatillake y N. R. Jennings. ¿Vale la pena discutir? En Actas de ArgMAS 2004, 2004. [5] S. Onta˜n´on y E. Plaza. Argumentos y contraejemplos en la deliberación conjunta basada en casos. En Actas de ArgMAS-2006, mayo de 2006. [6] D. Poole. Explicación y predicción: Una arquitectura para el razonamiento por defecto y abductivo. Inteligencia Computacional, 5(2):97-110, 1989. [7] I. Rahwan, S. D. Ramchurn, N. R. Jennings, P. McBurney, S. Parsons y L. Sonenberg. Negociación basada en argumentos. La revisión de Ingeniería del Conocimiento, 4(18):345-375, 2003. [8] N. Roos, A. ten Tije y C. Witteveen. Un protocolo para el diagnóstico multiagente con conocimiento distribuido espacialmente. En Actas de AAMAS03, 2003. [9] N. Roos, A. ten Tije y C. Witteveen. Alcanzando acuerdo diagnóstico en el diagnóstico multiagente. En Actas de AAMAS04, 2004. [10] T. Takahashi, Y. Kaneda y N. Ito. Estudio preliminar: utilizando simulaciones de RoboCupRescue para la prevención de desastres. En Actas de SRMED2004, 2004. El Sexto Internacional. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 1005",
    "original_sentences": [
        "Hypotheses Refinement under Topological Communication Constraints ∗ Gauvain Bourgne, Gael Hette, Nicolas Maudet, and Suzanne Pinson LAMSADE, Univ.",
        "Paris-Dauphine, France {bourgne,hette,maudet,pinson}@lamsade.dauphine.fr ABSTRACT We investigate the properties of a multiagent system where each (distributed) agent locally perceives its environment.",
        "Upon perception of an unexpected event, each agent locally computes its favoured hypothesis and tries to propagate it to other agents, by exchanging hypotheses and supporting arguments (observations).",
        "However, we further assume that communication opportunities are severely constrained and change dynamically.",
        "In this paper, we mostly investigate the convergence of such systems towards global consistency.",
        "We first show that (for a wide class of protocols that we shall define), the communication constraints induced by the topology will not prevent the convergence of the system, at the condition that the system dynamics guarantees that no agent will ever be isolated forever, and that agents have unlimited time for computation and arguments exchange.",
        "As this assumption cannot be made in most situations though, we then set up an experimental framework aiming at comparing the relative efficiency and effectiveness of different interaction protocols for hypotheses exchange.",
        "We study a critical situation involving a number of agents aiming at escaping from a burning building.",
        "The results reported here provide some insights regarding the design of optimal protocol for hypotheses refinement in this context.",
        "Categories and Subject Descriptors I.2.11 [Artificial Intelligence]: Distributed Artificial Intelligence-Multiagent systems General Terms Theory, Experimentation 1.",
        "INTRODUCTION We consider a multiagent system where each (distributed) agent locally perceives its environment, and we assume that some unexpected event occurs in that system.",
        "If each agent computes only locally its favoured hypothesis, it is only natural to assume that agents will seek to coordinate and refine their hypotheses by confronting their observations with other agents.",
        "If, in addition, the communication opportunities are severely constrained (for instance, agents can only communicate when they are close enough to some other agent), and dynamically changing (for instance, agents may change their locations), it becomes crucial to carefully design protocols that will allow agents to converge to some desired state of global consistency.",
        "In this paper we exhibit some sufficient conditions on the system dynamics and on the protocol/strategy structures that allow to guarantee that property, and we experimentally study some contexts where (some of) these assumptions are relaxed.",
        "While problems of diagnosis are among the venerable classics in the AI tradition, their multiagent counterparts have much more recently attracted some attention.",
        "Roos and colleagues [8, 9] in particular study a situation where a number of distributed entities try to come up with a satisfying global diagnosis of the whole system.",
        "They show in particular that the number of messages required to establish this global diagnosis is bound to be prohibitive, unless the communication is enhanced with some suitable protocol.",
        "However, they do not put any restrictions on agents communication options, and do not assume either that the system is dynamic.",
        "The benefits of enhancing communication with supporting information to make convergence to a desired global state of a system more efficient has often been put forward in the literature.",
        "This is for instance one of the main idea underlying the argumentation-based negotiation approach [7], where the desired state is a compromise between agents with conflicting preferences.",
        "Many of these works however make the assumption that this approach is beneficial to start with, and study the technical facets of the problem (or instead emphasize other advantages of using argumentation).",
        "Notable exceptions are the works of [3, 4, 2, 5], which studied in contexts different from ours the efficiency of argumentation.",
        "The rest of the paper is as follows.",
        "Section 2 specifies the basic elements of our model, and Section 3 goes on to presenting the different protocols and strategies used by the agents to exchange hypotheses and observations.",
        "We put special attention at clearly emphasizing the conditions on the system dynamics and protocols/strategies that will be exploited in the rest of the paper.",
        "Section 4 details one of 998 978-81-904262-7-5 (RPS) c 2007 IFAAMAS the main results of the paper, namely the fact that under the aforementioned conditions, the constraints that we put on the topology will not prevent the convergence of the system towards global consistency, at the condition that no agent ever gets completely lost forever in the system, and that unlimited time is allowed for computation and argument exchange.",
        "While the conditions on protocols and strategies are fairly mild, it is also clear that these system requirements look much more problematic, even frankly unrealistic in critical situations where distributed approaches are precisely advocated.",
        "To get a clearer picture of the situation induced when time is a critical factor, we have set up an experimental framework that we introduce and discuss in Section 5.",
        "The critical situation involves a number of agents aiming at escaping from a burning building.",
        "The results reported here show that the effectiveness of argument exchange crucially depends upon the nature of the building, and provide some insights regarding the design of optimal protocol for hypotheses refinement in this context. 2.",
        "BASIC NOTIONS We start by defining the basic elements of our system.",
        "Environment Let O be the (potentially infinite) set of possible observations.",
        "We assume the sensors of our agents to be perfect, hence the observations to be certain.",
        "Let H be the set of hypotheses, uncertain and revisable.",
        "Let Cons(h, O) be the consistency relation, a binary relation between a hypothesis h ∈ H and a set of observations O ⊆ O.",
        "In most cases, Cons will refer to classical consistency relation, however, we may overload its meaning and add some additional properties to that relation (in which case we will mention it).",
        "The environment may include some dynamics, and change over the course of time.",
        "We define below sequences of time points to deal with it: Definition 1 (Sequence of time points).",
        "A sequence of time points t1, t2, . . . , tn from t is an ordered set of time points t1, t2, . . . , tn such that t1 ≥ t and ∀i ∈ [1, n − 1], ti+1 ≥ ti.",
        "Agent We take a system populated by n agents a1, . . . , an.",
        "Each agent is defined as a tuple F, Oi, hi , where: • F, the set of facts, common knowledge to all agents. • Oi ∈ 2O , the set of observations made by the agent so far.",
        "We assume a perfect memory, hence this set grows monotonically. • hi ∈ H, the favourite hypothesis of the agent.",
        "A key notion governing the formation of hypotheses is that of consistency, defined below: Definition 2 (Consistency).",
        "We say that: • An agent is consistent (Cons(ai)) iff Cons(hi, Oi) (that is, its hypothesis is consistent with its observation set). • An agent ai consistent with a partner agent aj iff Cons(ai) and Cons(hi, Oj) (that is, this agent is consistent and its hypothesis can explain the observation set of the other agent). • Two agents ai and aj are mutually consistent (MCons(ai, aj)) iff Cons(ai, aj) and Cons(aj, ai). • A system is consistent iff ∀(i, j)∈[1, n]2 it is the case that MCons(ai, aj).",
        "To ensure its consistency, each agent is equipped with an abstract reasoning machinery that we shall call the explanation function Eh.",
        "This (deterministic) function takes a set of observation and returns a single prefered hypothesis (2O → H).",
        "We assume h = Eh(O) to be consistent with O by definition of Eh, so using this function on its observation set to determine its favourite hypothesis is a sure way for the agent to achieve consistency.",
        "Note however that an hypothesis does not need to be generated by Eh to be consistent with an observation set.",
        "As a concrete example of such a function, and one of the main inspiration of this work, one can cite the Theorist reasoning system [6] -as long as it is coupled with a filter selecting a single prefered theory among the ones initially selected by Theorist.",
        "Note also that hi may only be modified as a consequence of the application Eh.",
        "We refer to this as the autonomy of the agent: no other agent can directly impose a given hypothesis to an agent.",
        "As a consequence, only a new observation (being it a new perception, or an observation communicated by a fellow agent) can result in a modification of its prefered hypothesis hi (but not necessarily of course).",
        "We finally define a property of the system that we shall use in the rest of the paper: Definition 3 (Bounded Perceptions).",
        "A system involves a bounded perception for agents iff ∃n0 s.t. ∀t| ∪N i=1 Oi| ≤ n0. (That is, the number of observations to be made by the agents in the system is not infinite.)",
        "Agent Cycle Now we need to see how these agents will evolve and interact in their environment.",
        "In our context, agents evolve in a dynamic environment, and we classicaly assume the following system cycle: 1.",
        "Environment dynamics: the environment evolves according to the defined rules of the system dynamics. 2.",
        "Perception step : agents get perceptions from the environment.",
        "These perceptions are typically partial (e.g. the agent can only see a portion of a map). 3.",
        "Reasoning step: agents compare perception with predictions, seek explanations for (potential) difference(s), refine their hypothesis, draw new conclusions. 4.",
        "Communication step: agents can communicate hypotheses and observations with other agents through a defined protocol.",
        "Any agent can only be involved in one communication with another agent by step. 5.",
        "Action step: agents do some practical reasoning using the models obtained from the previous steps and select an action.",
        "They can then modify the environment by executing it.",
        "The communication of the agents will be further constrained by topological consideration.",
        "At a given time, an agent will only be able to communicate with a number of neighbours.",
        "Its connexions with these others agents may The Sixth Intl.",
        "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 999 evolve with its situation in the environment.",
        "Typically, an agent can only communicate with agents that it can sense, but one could imagine evolving topological constraints on communication based on a network of communications between agents where the links are not always active.",
        "Communication In our system, agents will be able to communicate with each other.",
        "However, due to the aforementionned topological constraints, they will not be able to communicate with any agents at anytime.",
        "Who an agent can communicate with will be defined dynamically (for instance, this can be a consequence of the agents being close enough to get in touch).",
        "We will abstractly denote by C(ai, aj, t) the communication property, in other words, the fact that agents ai and aj can communicate at time t (note that this relation is assumed to be symetric, but of course not transitive).",
        "We are now in a position to define two essential properties of our system.",
        "Definition 4 (Temporal Path).",
        "There exists a temporal communication path at horizon tf (noted Ltf (aI , aJ )) between ai and aj iff there exists a sequence of time points t1, t2, . . . , tn from tf and a sequence of agents k1, k2, . . . , kn s.t. (i) C(aI , ak1 , t1), (ii) C(akn , aJ , tn+1), (iii) ∀i ∈ [1, n], C(aki , aki+1 , ti) Intuitively, what this property says is that it is possible to find a temporal path in the future that would allow to link agent ai and aj via a sequence of intermediary agents.",
        "Note that the time points are not necessarily successive, and that the sequence of agents may involve the same agents several times.",
        "Definition 5 (Temporal Connexity).",
        "A system is temporaly connex iff ∀t ∀(i, j)∈[1, n]2 Lt(ai, aj) In short, a temporaly connex system guarantees that any agent will be able to communicate with any other agents, no matter how long it might take to do so, at any time.",
        "To put it another way, it is never the case that an agent will be isolated for ever from another agent of the system.",
        "We will next discuss the detail of how communication concretely takes place in our system.",
        "Remember that in this paper, we only consider the case of bilateral exchanges (an agent can only speak to a single other agent), and that we also assume that any agent can only engage in a single exchange in a given round. 3.",
        "PROTOCOLS AND STRATEGIES In this section, we discuss the requirements of the interaction protocols that govern the exchange of messages between agents, and provide some example instantiation of such protocols.",
        "To clarify the presentation, we distinguish two levels: the local level, which is concerned with the regulation of bilateral exchanges; and the global level,which essentially regulates the way agents can actually engage into a conversation.",
        "At each level, we separate what is specified by the protocol, and what is left to agents strategies.",
        "Local Protocol and Strategies We start by inspecting local protocols and strategies that will regulate the communication between the agents of the system.",
        "As we limit ourselves to bilateral communication, these protocols will simply involve two agents.",
        "Such protocol will have to meet one basic requirement to be satisfying. • consistency (CONS)- a local protocol has to guarantee the mutual consistency of agents upon termination (which implies termination of course).",
        "Figure 1: A Hypotheses Exchange Protocol [1] One example such protocol is the protocol described in [1] that is pictured in Fig. 1.",
        "To further illustrate how such protocol can be used by agents, we give some details on a possible strategy: upon receiving a hypothesis h1 (propose(h1) or counterpropose(h1)) from a1, agent a2 is in state 2 and has the following possible replies: counterexample (if the agent knows an example contradicting the hypothesis, or not explained by this hypothesis), challenge (if the agents lacks evidence to accept this hypothesis), counterpropose (if the agent agrees with the hypothesis but prefers another one), or accept (if it is indeed as good as its favourite hypothesis).",
        "This strategy guarantees, among other properties, the eventual mutual logical consistency of the involved agents [1].",
        "Global Protocol The global protocol regulates the way bilateral exchanges will be initiated between agents.",
        "At each turn, agents will concurrently send one weighted request to communicate to other agents.",
        "This weight is a value measuring the agents willingness to converse with the targeted agent (in practice, this can be based on different heuristics, but we shall make some assumptions on agents strategies, see below).",
        "Sending such a request is a kind of conditional commitment for the agent.",
        "An agent sending a weighted request commits to engage in conversation with the target if he does not receive and accept himself another request.",
        "Once all request have been received, each agent replies with either an acccept or a reject.",
        "By answering with an accept, an agent makes a full commitment to engage in conversation with the sender.",
        "Therefore, it can only send one accept in a given round, as an agent can only participate in one conversation per time step.",
        "When all response have been received, each agent receiving an accept can either initiate a conversation using the local protocol or send a cancel if it has accepted another request.",
        "At the end of all the bilateral exchanges, the agents engaged in conversation are discarded from the protocol.",
        "Then each of the remaining agents resends a request and the process iterates until no more requests are sent.",
        "Global Strategy We now define four requirements for the strategies used by agents, depending on their role in the protocol: two are concerned with the requestee role (how to decide who the 1000 The Sixth Intl.",
        "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) agent wishes to communicate with? ), the other two with the responder role (how to decide which communication request to accept or not?). • Willingness to solve inconsistancies (SOLVE)-agents want to communicate with any other agents unless they know they are mutually consistent. • Focus on solving inconsistencies (FOCUS)-agents do not request communication with an agent with whom they know they are mutually consistent. • Willingness to communicate (COMM)-agents cannot refuse a weighted communication request, unless they have just received or send a request with a greater weight. • Commitment to communication request (REQU)agents cannot accept a weighted communication request if they have themselves sent a communication request with a greater weight.",
        "Therefore, they will not cancel their request unless they have received a communicational request with greater weight.",
        "Now the protocol structure, together with the properties COMM+REQU, ensure that a request can only be rejected if its target agent engages in communication with another agent.",
        "Suppose indeed that agent ai wants to communicate with aj by sending a request with weight w. COMM guarantees that an agent receiving a weighted request will either accept this communication, accept a communication with a greater weight or wait for the answer to a request with a greater weight.",
        "This ensures that the request with maximal weight will be accepted and not cancelled (as REQU ensures that an agent sending a request can only cancel it if he accepts another request with greater weight).",
        "Therefore at least two agents will engage in conversation per round of the global protocol.",
        "As the protocol ensures that ai can resend its request while aj is not engaged in a conversation, there will be a turn in which aj must engage in a conversation, either with ai or another agent.",
        "These requirements concern request sending and acceptation, but agents also need some strategy of weight attribution.",
        "We describe below an altruist strategy, used in our experiments.",
        "Being cooperative, an agent may want to know more of the communication wishes of other agents in order to improve the overall allocation of exchanges to agents.",
        "A context request step is then added to the global protocol.",
        "Before sending their chosen weighted request, agents attribute a weight to all agents they are prepared to communicate with, according to some internal factors.",
        "In the simplest case, this weight will be 1 for all agent with whom the agent is not sure of being mutually consistent (ensuring SOLVE), other agent being not considered for communication (ensuring FOCUS).",
        "The agent then sends a context request to all agents with whom communication is considered.",
        "This request also provides information about the sender (list of considered communications along with their weight).",
        "After reception of all the context requests, agents will either reply with a deny, iff they are already engaged in a conversation (in which case, the requesting agent will not consider communication with them anymore in this turn), or an inform giving the requester information about the requests it has sent and received.",
        "When all replies have been received, each agent can calculate the weight of all requests concerning it.",
        "It does so by substracting from the weight of its request the weight of all requests concerning either it or its target (that is, the final weight of the request from ai to aj is Wi,j = wi,j +wj,i − ( P k∈R(i)−{j} wi,k + P k∈S(i)−{j} wk,i + P k∈R(j)−{i} wj,k + P k∈S(j)−{i} wk,j) where wi,j is the weight of the request of ai to aj, R(i) is the set of indice of agents having received a request from ai and S(i) is the set of indice of agents having send a request to ai).",
        "It then finally sends a weighted request to the agents who maximise this weight (or wait for a request) as described in the global protocol. 4. (CONDITIONAL) CONVERGENCE TO GLOBAL CONSISTENCY In this section we will show that the requirements regarding protocols and strategies just discussed will be sufficient to ensure that the system will eventually converge towards global consistency, under some conditions.",
        "We first show that, if two agents are not mutually consistent at some time, then there will be necessarily a time in the future such that an agent will learn a new observation, being it because it is new for the system, or by learning it from another agent.",
        "Lemma 1.",
        "Let S be a system populated by n agents a1, a2, ..., an, temporaly connex, and involving bounded perceptions for these agents.",
        "Let n1 be the sum of cardinalities of the intersection of pairwise observation sets. (n1 = P (i,j)∈[1,n]2 |Oi ∩ Oj|) Let n2 be the cardinality of the union of all agents observations sets. (n2 = | ∪N i=1 Oi|).",
        "If ¬MCons(ai, aj) at time t0, there is necessarily a time t > t0 s.t. either n1 or n2 will increase.",
        "Proof.",
        "Suppose that there exist a time t0 and indices (i, j) s.t. ¬MCons(ai, aj).",
        "We will use mt0 = P (k,l)∈[1,n]2 εComm(ak, al, t0) where εComm(ak, al, t0) = 1 if ak and al have communicated at least once since t0, and 0 otherwise.",
        "Temporal connexity guarantees that there exist t1, ..., tm+1 and k1, ..., km s.t.",
        "C(ai, ak1 , t1), C(akm , aj, tm+1), and ∀p ∈ [1, m], C(akp , akp+1 , tp).",
        "Clearly, if MCons(ai, ak1 ), MCons(akm , aj) and ∀p, MCons(akp , akp+1 ), we have MCons(ai, aj) which contradicts our hypothesis (MCons being transitive, MCons(ai, ak1 )∧MCons(ak1 , ak2 ) implies that MCons(ai, ak2 ) and so on till MCons(ai, akm )∧ MCons(akm , aj) which implies MCons(ai, aj) ).",
        "At least two agents are then necessarily inconsistent (¬MCons(ai, ak1 ), or ¬MCons(akm , aj), or ∃p0 t.q. ¬MCons(akp0 , akp0+1 )).",
        "Let ak and al be these two neighbours at a time t > t0 1 .",
        "The SOLVE property ensures that either ak or al will send a communication request to the other agent at time t .",
        "As shown before, this in turn ensures that at least one of these agents will be involved in a communication.",
        "Then there are two possibilities: (case i) ak and al communicate at time t .",
        "In this case, we know that ¬MCons(ak, al).",
        "This and the CONS property ensures that at least one of the agents must change its 1 Strictly speaking, the transitivity of MCons only ensure that ak and al are inconsistent at a time t ≥ t0 that can be different from the time t at which they can communicate.",
        "But if they become consistent between t and t (or inconsistent between t and t ), it means that at least one of them have changed its hypothesis between t and t , that is, after t0.",
        "We can then apply the reasoning of case iib.",
        "The Sixth Intl.",
        "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 1001 hypothesis, which in turn, since agents are autonomous, implies at least one exchange of observation.",
        "But then |Ok ∩Ol| is bound to increase: n1(t ) > n1(t0). (case ii) ak communicates with ap at time t .",
        "We then have again two possibilities: (case iia) ak and ap did not communicate since t0.",
        "But then εComm(ak, ap, t0) had value 0 and takes value 1.",
        "Hence mt0 increases. (case iib) ak and ap did communicate at some time t0 > t0.",
        "The CONS property of the protocol ensures that MCons(ak, ap) at that time.",
        "Now the fact that they communicate and FOCUS implies that at least one of them did change its hypothesis in the meantime.",
        "The fact that agents are autonomous implies in turn that a new observation (perceived or received from another agent) necessarily provoked this change.",
        "The latter case would ensure the existence of a time t > t0 and an agent aq s.t. either |Op ∩Oq| or |Ok ∩Oq| increases of 1 at that time (implying n1(t ) > n1(t0)).",
        "The former case means that the agent gets a new perception o at time t .",
        "If that observation was unknown in the system before, then n2(t ) > n2(t0).",
        "If some agent aq already knew this observation before, then either Op ∩ Oq or Ok ∩ Oq increases of 1 at time t (which implies that n1(t ) > n1(t0)).",
        "Hence, ¬MCons(ai, aj) at time t0 guarantees that, either: −∃t > t0 t.q. n1(t ) > n1(t0); or −∃t > t0 t.q. n2(t ) > n2(t0); or −∃t > t0 t.q. mt0 increases of 1 at time t .",
        "By iterating the reasoning with t (but keeping t0 as the time reference for mt0 ), we can eliminate the third case (mt0 is integer and bounded by n2 , which means that after a maximum of n2 iterations, we necessarily will be in one of two other cases.)",
        "As a result, we have proven that if ¬MCons(ai, aj) at time t0, there is necessarily a time t s.t. either n1 or n2 will increase.",
        "Theorem 1 (Global consistency).",
        "Let S be a system populated by n agents a1, a2, ..., an, temporaly connex, and involving bounded perceptions for these agents.",
        "Let Cons(ai, aj) be a transitive consistency property.",
        "Then any protocol and strategies satisfying properties CONS, SOLVE, FOCUS, COMM and REQU guarantees that the system will converge towards global consistency.",
        "Proof.",
        "For the sake of contradiction, let us assume ∃I, J ∈ [1, N] s.t. ∀t, ∃t0 > t, t.q. ¬Cons(aI , aJ , t0).",
        "Using the lemma, this implies that ∃t > t0 s.t. either n1(t ) > n1(t0) or n2(t ) > n2(t0).",
        "But we can apply the same reasoning taking t = t , which would give us t1 > t > t0 s.t. ¬Cons(aI , aJ , t1), which gives us t > t1 s.t. either n1(t ) > n1(t1) or n2(t ) > n2(t1).",
        "By successive iterations we can then construct a sequence t0, t1, ..., tn, which can be divided in two sub-sequences t0, t1, ...tn and t0 , t1 , ..., tn s.t. n1(t0) < n1(t1) < ... < n1(tn) and n2(t0 ) < n2(t1 ) < ... < n2(tn).",
        "One of these sub-sequences has to be infinite.",
        "However, n1(ti) and n2(ti ) are strictly growing, integer, and bounded, which implies that both are finite.",
        "Contradiction.",
        "What the previous result essentially shows is that, in a system where no agent will be isolated from the rest of the agents for ever, only very mild assumptions on the protocols and strategies used by agents suffice to guarantee convergence towards system consistency in a finite amount of time (although it might take very long).",
        "Unfortunately, in many critical situations, it will not be possible to assume this temporal connexity.",
        "As distributed approaches as the one advocated in this paper are precisely often presented as a good way to tackle problems of reliability or problems of dependence to a center that are of utmost importance in these critical applications, it is certainly interesting to further explore how such a system would behave when we relax this assumption. 5.",
        "EXPERIMENTAL STUDY This experiment involves agents trying to escape from a burning building.",
        "The environment is described as a spatial grid with a set of walls and (thankfully) some exits.",
        "Time and space are considered discrete.",
        "Time is divided in rounds.",
        "Agents are localised by their position on the spatial grid.",
        "These agents can move and communicate with other agents.",
        "In a round, an agent can move of one cell in any of the four cardinal directions, provided it is not blocked by a wall.",
        "In this application, agents communicate with any other agent (but, recall, a single one) given that this agent is in view, and that they have not yet exchanged their current favoured hypothesis.",
        "Suddenly, a fire erupts in these premises.",
        "From this moment, the fire propagates.",
        "Each round, for each cases where there is fire, the fire propagates in the four directions.",
        "However, the fire cannot propagate through a wall.",
        "If the fire propagates in a case where an agent is positioned, that agent burns and is considered dead.",
        "It can of course no longer move nor communicate.",
        "If an agent gets to an exit, it is considered saved, and can no longer be burned.",
        "Agents know the environment and the rules governing the dynamics of this environment, that is, they know the map as well as the rules of fire propagation previously described.",
        "They also locally perceive this environment, but cannot see further than 3 cases away, in any direction.",
        "Walls also block the line of view, preventing agents from seeing behind them.",
        "Within their sight, they can see other agents and whether or not the cases they see are on fire.",
        "All these perceptions are memorised.",
        "We now show how this instantiates the abstract framework presented the paper. • O = {Fire(x, y, t), NoFire(x, y, t), Agent(ai, x, y, t)} Observations can then be positive (o ∈ P(O) iff ∃h ∈ H s.t. h |= o) or negative (o ∈ N(O) iff ∃h ∈ H s.t. h |= ¬o). • H={FireOrigin(x1, y1, t1)∧...∧FireOrigin(xl, yl, tl)} Hypotheses are conjunctions of FireOrigins. • Cons(h, O) consistency relation satisfies: - coherence : ∀o ∈ N(O), h |= ¬o. - completeness : ∀o ∈ P(O), h |= o. - minimality : For all h ∈ H, if h is coherent and complete for O, then h is prefered to h according to the preference relation (h ≤p h ).2 2 Selects first the minimal number of origins, then the most recent (least preemptive strategy [6]), then uses some arbitrary fixed ranking to discriminate ex-aequo.",
        "The resulting relation is a total order, hence minimality implies that there will be a single h s.t.Cons(O, h) for a given O.",
        "This in turn means that MCons(ai, aj) iff Cons(ai), Cons(aj), and hi = hj.",
        "This relation is then transitive and symmetric. 1002 The Sixth Intl.",
        "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) • Eh takes O as argument and returns min≤p of the coherent and complete hypothesis for O 5.1 Experimental Evaluation We will classically (see e.g. [3, 4]) assess the effectiveness and efficiency of different interaction protocols.",
        "Effectiveness of a protocol The proportion of agents surviving the fire over the initial number of agents involved in the experiment will determine the effectiveness of a given protocol.",
        "If this value is high, the protocol has been effective to propagate the information and/or for the agents to refine their hypotheses and determine the best way to the exit.",
        "Efficiency of a protocol Typically, the use of supporting information will involve a communication overhead.",
        "We will assume here that the efficiency of a given protocol is characterised by the data flow induced by this protocol.",
        "In this paper we will only discuss this aspect wrt. local protocols.",
        "The main measure that we shall then use here is the mean total size of messages that are exchanged by agents per exchange (hence taking into account both the number of messages and the actual size of the messages, because it could be that messages happen to be very big, containing e.g. a large number of observations, which could counter-balance a low number of messages). 5.2 Experimental Settings The chosen experimental settings are the following: • Environmental topology- Performances of information propagation are highly constrained by the environment topology.",
        "The perception skills of the agents depend on the openness of the environment.",
        "With a large number of walls the perceptions of agents are limited, and also the number of possible inter-agent communications, whereas an open environment will provide optimal possibilities of perception and information propagation.",
        "Thus, we propose a topological index (see below) as a common basis to charaterize the environments (maps) used during experimentations.",
        "The topological index (TI) is the ratio of the number of cells that can be perceived by agents summed up from all possible positions, divided by the number of cells that would be perceived from the same positions but without any walls. (The closer to 1, the more open the environment).",
        "We shall also use two additional, more classical [10], measures: the characteristic path length3 (CPL) and the clustering coefficient4 (CC). • Number of agents- The propagation of information also depends on the initial number of agents involved during an experimentation.",
        "For instance, the more agents, the more potential communications there is.",
        "This means that there will be more potential for propagation, but also that the bilateral exchange restriction will be more crucial. 3 The CPL is the median of the means of the shortest path lengths connecting each node to all other nodes. 4 characterising the isolation degree of a region of an environment in terms of acessibility (number of roads still usable to reach this region).",
        "Map T.I. (%) C.P.L.",
        "C.C. 69-1 69,23 4,5 0,69 69-2 68,88 4,38 0,65 69-3 69,80 4,25 0,67 53-1 53,19 5,6 0,59 53-2 53,53 6,38 0,54 53-3 53,92 6,08 0,61 38-1 38,56 8,19 0,50 38-2 38,56 7,3 0,50 38-3 38,23 8,13 0,50 Table 1: Topological Characteristics of the Maps • Initial positions of the agents- Initial positions of the agents have a significant influence on the overall behavior of an instance of our system: being close from an exit will (in general) ease the escape. 5.3 Experimental environments We choose to realize experiments on three very different topological indexes (69% for open environments, 53% for mixed environments, and 38% for labyrinth-like environments).",
        "Figure 2: Two maps (left: TI=69%, right TI=38%) We designed three different maps for each index (Fig. 2 shows two of them), containing the same maximum number of agents (36 agents max.) with a maximum density of one agent per cell, the same number of exits and a similar fire origin (e.g. starting time and position).",
        "The three differents maps of a given index are designed as follows.",
        "The first map is a model of an existing building floor.",
        "The second map has the same enclosure, exits and fire origin as the first one, but the number and location of walls are different (wall locations are designed by an heuristic which randomly creates walls on the spatial grid such that no fully closed rooms are created and that no exit is closed).",
        "The third map is characterised by geometrical enclosure in wich walls location is also designed with the aforementioned heuristic.",
        "Table 1 summarizes the different topological measures characterizing these different maps.",
        "It is worth pointing out that the values confirm the relevance of TI (maps with a high TI have a low CPL and a high CC.",
        "However the CPL and CC allows to further refine the difference between the maps, e.g. between 53-1 and 53-2). 5.4 Experimental Results For each triple of maps defined as above we conduct the same experiments.",
        "In each experiment, the society differs in terms of its initial proportion of involved agents, from 1% to 100%.",
        "This initial proportion represents the percentage of involved agents with regards to the possible maximum number of agents.",
        "For each map and each initial proportion, The Sixth Intl.",
        "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 1003 we select randomly 100 different initial agents locations.",
        "For each of those different locations we execute the system one time for each different interaction protocol.",
        "Effectiveness of Communication and Argumentation The first experiment that we set up aims at testing how effective is hypotheses exchange (HE), and in particular how the topological aspects will affect this effectiveness.",
        "In order to do so, we have computed the ratio of improvement offered by that protocol over a situation where agents could simply not communicate (no comm).",
        "To get further insights as to what extent the hypotheses exchange was really crucial, we also tested a much less elaborated protocol consisting of mere observation exchanges (OE).",
        "More precisely, this protocol requires that each agent stores any unexpected observation that it perceives, and agents simply exchange their respective lists of observations when they discuss.",
        "In this case, the local protocol is different (note in particular that it does not guarantee mutual consistency), but the global protocol remains the same (at the only exception that agents motivation to communicate is to synchronise their list of observations, not their hypothesis).",
        "If this protocol is at best as effective as HE, it has the advantage of being more efficient (this is obvious wrt the number of messages which will be limited to 2, less straightforward as far as the size of messages is concerned, but the rough observation that the exchange of observations can be viewed as a flat version of the challenge is helpful to see this).",
        "The results of these experiments are reported in Fig. 3.",
        "Figure 3: Comparative effectiveness ratio gain of protocols when the proportion of agents augments The first observation that needs to be made is that communication improves the effectiveness of the process, and this ratio increases as the number of agents grows in the system.",
        "The second lesson that we learn here is that closeness relatively makes communication more effective over non communication.",
        "Maps exhibiting a T.I. of 38% are constantly above the two others, and 53% are still slightly but significantly better than 69%.",
        "However, these curves also suggest, perhaps surprisingly, that HE outperforms OE in precisely those situations where the ratio gain is less important (the only noticeable difference occurs for rather open maps where T.I. is 69%).",
        "This may be explained as follows: when a map is open, agents have many potential explanation candidates, and argumentation becomes useful to discriminate between those.",
        "When a map is labyrinth-like, there are fewer possible explanations to an unexpected event.",
        "Importance of the Global Protocol The second set of experiments seeks to evaluate the importance of the design of the global protocol.",
        "We tested our protocol against a local broadcast (LB) protocol.",
        "Local broadcast means that all the neighbours agents perceived by an agent will be involved in a communication with that agent in a given round -we alleviate the constraint of a single communication by agent.",
        "This gives us a rough upper bound upon the possible ratio gain in the system (for a given local protocol).",
        "Again, we evaluated the ratio gain induced by that LB over our classical HE, for the three different classes of maps.",
        "The results are reported in Fig. 4.",
        "Figure 4: Ratio gain of local broadcast over hypotheses exchange Note to begin with that the ratio gain is 0 when the proportion of agents is 5%, which is easily explained by the fact that it corresponds to situations involving only two agents.",
        "We first observe that all classes of maps witness a ratio gain increasing when the proportion of agents augments: the gain reaches 10 to 20%, depending on the class of maps considered.",
        "If one compares this with the improvement reported in the previous experiment, it appears to be of the same magnitude.",
        "This illustrates that the design of the global protocol cannot be ignored, especially when the proportion of agents is high.",
        "However, we also note that the effectiveness ratio gain curves have very different shapes in both cases: the gain induced by the accuracy of the local protocol increases very quickly with the proportion of agents, while the curve is really smooth for the global one.",
        "Now let us observe more carefully the results reported here: the curve corresponding to a TI of 53% is above that corresponding to 38%.",
        "This is so because the more open a map, the more opportunities to communicate with more than one agent (and hence benefits from broadcast).",
        "However, we also observe that curve for 69% is below that for 53%.",
        "This is explained as follows: in the case of 69%, the potential gain to be made in terms of surviving agents is much lower, because our protocols already give rather efficient outcomes anyway (quickly reaching 90%, see Fig. 3).",
        "A simple rule of thumb could be that when the number of agents is small, special attention should be put on the local 1004 The Sixth Intl.",
        "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) protocol, whereas when that number is large, one should carefully design the global one (unless the map is so open that the protocol is already almost optimally efficient).",
        "Efficiency of the Protocols The final experiment reported here is concerned with the analysis of the efficiency of the protocols.",
        "We analysis here the mean size of the totality of the messages that are exchanged by agents (mean size of exchanges, for short) using the following protocols: HE, OE, and two variant protocols.",
        "The first one is an intermediary restricted hypotheses exchange protocol (RHE).",
        "RHE is as follows: it does not involve any challenge nor counter-propose, which means that agents cannot switch their role during the protocol (this differs from RE in that respect).",
        "In short, RHE allows an agent to exhaust its partners criticism, and eventually this partner will come to adopt the agents hypothesis.",
        "Note that this means that the autonomy of the agent is not preserved here (as an agent will essentially accept any hypothesis it cannot undermine), with the hope that the gain in efficiency will be significant enough to compensate a loss in effectiveness.",
        "The second variant protocol is a complete observation exchange protocol (COE).",
        "COE uses the same principles as OE, but includes in addition all critical negative examples (nofire) in the exchange (thus giving all examples used as arguments by the hypotheses exchanges protocol), hence improving effectiveness.",
        "Results for map 69-1 are shown on Fig. 5.",
        "Figure 5: Mean size of exchanges First we can observe the fact that the ordering of the protocols, from the least efficient to the most efficient, is COE, HE, RHE and then OE.",
        "HE being more efficient than COE proves that the argumentation process gains efficiency by selecting when it is needed to provide negative example, which have less impact that positive ones in our specific testbed.",
        "However, by communicating hypotheses before eventually giving observation to support it (HE) instead of directly giving the most crucial observations (OE), the argumentation process doubles the size of data exchanges.",
        "It is the cost for ensuring consistency at the end of the exchange (a property that OE does not support).",
        "Also significant is the fact the the mean size of exchanges is slightly higher when the number of agents is small.",
        "This is explained by the fact that in these cases only a very few agents have relevant informations in their possession, and that they will need to communicate a lot in order to come up with a common view of the situation.",
        "When the number of agents increases, this knowledge is distributed over more agents which need shorter discussions to get to mutual consistency.",
        "As a consequence, the relative gain in efficiency of using RHE appears to be better when the number of agents is small: when it is high, they will hardly argue anyway.",
        "Finally, it is worth noticing that the standard deviation for these experiments is rather high, which means that the conversation do not converge to any stereotypic pattern. 6.",
        "CONCLUSION This paper has investigated the properties of a multiagent system where each (distributed) agent locally perceives its environment, and tries to reach consistency with other agents despite severe communication restrictions.",
        "In particular we have exhibited conditions allowing convergence, and experimentally investigated a typical situation where those conditions cannot hold.",
        "There are many possible extensions to this work, the first being to further investigate the properties of different global protocols belonging to the class we identified, and their influence on the outcome.",
        "There are in particular many heuristics, highly dependent on the context of the study, that could intuitively yield interesting results (in our study, selecting the recipient on the basis of what can be inferred from his observed actions could be such a heuristic).",
        "One obvious candidate for longer term issues concern the relaxation of the assumption of perfect sensing. 7.",
        "REFERENCES [1] G. Bourgne, N. Maudet, and S. Pinson.",
        "When agents communicate hypotheses in critical situations.",
        "In Proceedings of DALT-2006, May 2006. [2] P. Harvey, C. F. Chang, and A. Ghose.",
        "Support-based distributed search: a new approach for multiagent constraint processing.",
        "In Proceedings of AAMAS06, 2006. [3] H. Jung and M. Tambe.",
        "Argumentation as distributed constraint satisfaction: Applications and results.",
        "In Proceedings of AGENTS01, 2001. [4] N. C. Karunatillake and N. R. Jennings.",
        "Is it worth arguing?",
        "In Proceedings of ArgMAS 2004, 2004. [5] S. Onta˜n´on and E. Plaza.",
        "Arguments and counterexamples in case-based joint deliberation.",
        "In Proceedings of ArgMAS-2006, May 2006. [6] D. Poole.",
        "Explanation and prediction: An architecture for default and abductive reasoning.",
        "Computational Intelligence, 5(2):97-110, 1989. [7] I. Rahwan, S. D. Ramchurn, N. R. Jennings, P. McBurney, S. Parsons, and L. Sonenberg.",
        "Argumention-based negotiation.",
        "The Knowledge Engineering Review, 4(18):345-375, 2003. [8] N. Roos, A. ten Tije, and C. Witteveen.",
        "A protocol for multi-agent diagnosis with spatially distributed knowledge.",
        "In Proceedings of AAMAS03, 2003. [9] N. Roos, A. ten Tije, and C. Witteveen.",
        "Reaching diagnostic agreement in multiagent diagnosis.",
        "In Proceedings of AAMAS04, 2004. [10] T. Takahashi, Y. Kaneda, and N. Ito.",
        "Preliminary study - using robocuprescue simulations for disasters prevention.",
        "In Proceedings of SRMED2004, 2004.",
        "The Sixth Intl.",
        "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 1005"
    ],
    "translated_text_sentences": [
        "Refinamiento de hipótesis bajo restricciones de comunicación topológica ∗ Gauvain Bourgne, Gael Hette, Nicolas Maudet y Suzanne Pinson LAMSADE, Univ.",
        "Investigamos las propiedades de un sistema multiagente donde cada agente (distribuido) percibe localmente su entorno.",
        "Tras la percepción de un evento inesperado, cada agente calcula localmente su hipótesis favorita e intenta propagarla a otros agentes, intercambiando hipótesis y argumentos de apoyo (observaciones).",
        "Sin embargo, también asumimos que las oportunidades de comunicación están severamente limitadas y cambian dinámicamente.",
        "En este artículo, investigamos principalmente la convergencia de dichos sistemas hacia la consistencia global.",
        "Primero demostramos que (para una amplia clase de protocolos que definiremos), las restricciones de comunicación inducidas por la topología no impedirán la convergencia del sistema, bajo la condición de que la dinámica del sistema garantice que ningún agente quedará aislado para siempre, y que los agentes tengan tiempo ilimitado para la computación y el intercambio de argumentos.",
        "Dado que esta suposición no se puede hacer en la mayoría de las situaciones, establecimos un marco experimental con el objetivo de comparar la eficiencia y efectividad relativa de diferentes protocolos de interacción para el intercambio de hipótesis.",
        "Estudiamos una situación crítica que implica a varios agentes que intentan escapar de un edificio en llamas.",
        "Los resultados reportados aquí proporcionan algunas ideas sobre el diseño de un protocolo óptimo para el refinamiento de hipótesis en este contexto.",
        "Categorías y Descriptores de Asignaturas I.2.11 [Inteligencia Artificial]: Inteligencia Artificial Distribuida-Sistemas Multiagente Términos Generales Teoría, Experimentación 1.",
        "INTRODUCCIÓN Consideramos un sistema multiagente donde cada agente (distribuido) percibe localmente su entorno, y asumimos que ocurre un evento inesperado en ese sistema.",
        "Si cada agente calcula solo localmente su hipótesis preferida, es natural asumir que los agentes buscarán coordinar y refinar sus hipótesis confrontando sus observaciones con otros agentes.",
        "Si, además, las oportunidades de comunicación están severamente limitadas (por ejemplo, los agentes solo pueden comunicarse cuando están lo suficientemente cerca de otro agente) y cambian dinámicamente (por ejemplo, los agentes pueden cambiar sus ubicaciones), se vuelve crucial diseñar cuidadosamente protocolos que permitan a los agentes converger hacia algún estado deseado de consistencia global.",
        "En este documento presentamos algunas condiciones suficientes sobre la dinámica del sistema y sobre las estructuras de protocolo/estrategia que permiten garantizar esa propiedad, y estudiamos experimentalmente algunos contextos donde (algunas de) estas suposiciones se relajan.",
        "Si bien los problemas de diagnóstico son uno de los clásicos venerables en la tradición de la IA, sus contrapartes multiagentes han atraído atención mucho más recientemente.",
        "Roos y sus colegas [8, 9] en particular estudian una situación en la que un número de entidades distribuidas intentan llegar a un diagnóstico global satisfactorio de todo el sistema.",
        "Ellos muestran en particular que el número de mensajes necesarios para establecer este diagnóstico global está destinado a ser prohibitivo, a menos que la comunicación se mejore con algún protocolo adecuado.",
        "Sin embargo, no imponen restricciones a las opciones de comunicación de los agentes, ni asumen que el sistema es dinámico.",
        "Los beneficios de mejorar la comunicación con información de apoyo para hacer que la convergencia a un estado global deseado de un sistema sea más eficiente, a menudo se ha planteado en la literatura.",
        "Esta es, por ejemplo, una de las ideas principales que subyacen al enfoque de negociación basado en argumentos [7], donde el estado deseado es un compromiso entre agentes con preferencias conflictivas.",
        "Sin embargo, muchos de estos trabajos parten del supuesto de que este enfoque es beneficioso para comenzar y estudian los aspectos técnicos del problema (o en su lugar enfatizan otras ventajas de utilizar la argumentación).",
        "Excepciones notables son las obras de [3, 4, 2, 5], que estudiaron en contextos diferentes al nuestro la eficiencia de la argumentación.",
        "El resto del documento es el siguiente.",
        "La Sección 2 especifica los elementos básicos de nuestro modelo, y la Sección 3 continúa presentando los diferentes protocolos y estrategias utilizados por los agentes para intercambiar hipótesis y observaciones.",
        "Ponemos especial atención en enfatizar claramente las condiciones de la dinámica del sistema y los protocolos/estrategias que se explotarán en el resto del documento.",
        "La sección 4 detalla uno de los principales resultados del artículo, a saber, el hecho de que bajo las condiciones mencionadas, las restricciones que imponemos en la topología no impedirán la convergencia del sistema hacia la consistencia global, siempre y cuando ningún agente se pierda completamente para siempre en el sistema, y se permita un tiempo ilimitado para la computación y el intercambio de argumentos.",
        "Si bien las condiciones en los protocolos y estrategias son bastante suaves, también es claro que estos requisitos del sistema parecen mucho más problemáticos, incluso francamente poco realistas en situaciones críticas donde se abogan precisamente por enfoques distribuidos.",
        "Para obtener una imagen más clara de la situación inducida cuando el tiempo es un factor crítico, hemos establecido un marco experimental que presentamos y discutimos en la Sección 5.",
        "La situación crítica implica a varios agentes que intentan escapar de un edificio en llamas.",
        "Los resultados reportados aquí muestran que la efectividad del intercambio de argumentos depende crucialmente de la naturaleza del edificio, y proporcionan algunas ideas sobre el diseño de un protocolo óptimo para el refinamiento de hipótesis en este contexto.",
        "CONCEPTOS BÁSICOS Comenzamos definiendo los elementos básicos de nuestro sistema.",
        "Deje que O sea el conjunto (potencialmente infinito) de observaciones posibles.",
        "Suponemos que los sensores de nuestros agentes son perfectos, por lo tanto, las observaciones son seguras.",
        "Sea H el conjunto de hipótesis, incierto y revisable.",
        "Sea Cons(h, O) la relación de consistencia, una relación binaria entre una hipótesis h ∈ H y un conjunto de observaciones O ⊆ O.",
        "En la mayoría de los casos, Cons se referirá a la relación de consistencia clásica, sin embargo, podemos sobrecargar su significado y añadir algunas propiedades adicionales a esa relación (en cuyo caso lo mencionaremos).",
        "El entorno puede incluir cierta dinámica y cambiar con el transcurso del tiempo.",
        "Definimos a continuación secuencias de puntos temporales para tratar con ello: Definición 1 (Secuencia de puntos temporales).",
        "Una secuencia de puntos temporales t1, t2, . . . , tn de t es un conjunto ordenado de puntos temporales t1, t2, . . . , tn tal que t1 ≥ t y ∀i ∈ [1, n − 1], ti+1 ≥ ti.",
        "Tomamos un sistema poblado por n agentes a1, . . . , an.",
        "Cada agente se define como una tupla F, Oi, hi, donde: • F, el conjunto de hechos, conocimiento común a todos los agentes. • Oi ∈ 2O, el conjunto de observaciones realizadas por el agente hasta el momento.",
        "Suponemos una memoria perfecta, por lo tanto, este conjunto crece de forma monótona. • hi ∈ H, la hipótesis favorita del agente.",
        "Una noción clave que rige la formación de hipótesis es la de consistencia, definida a continuación: Definición 2 (Consistencia).",
        "Decimos que: • Un agente es consistente (Cons(ai)) si y solo si Cons(hi, Oi) (es decir, su hipótesis es consistente con su conjunto de observaciones). • Un agente ai es consistente con un agente compañero aj si y solo si Cons(ai) y Cons(hi, Oj) (es decir, este agente es consistente y su hipótesis puede explicar el conjunto de observaciones del otro agente). • Dos agentes ai y aj son mutuamente consistentes (MCons(ai, aj)) si y solo si Cons(ai, aj) y Cons(aj, ai). • Un sistema es consistente si y solo si para todo (i, j) ∈ [1, n]2 se cumple que MCons(ai, aj).",
        "Para garantizar su consistencia, cada agente está equipado con una maquinaria de razonamiento abstracto que llamaremos la función de explicación Eh.",
        "Esta función (determinística) toma un conjunto de observaciones y devuelve una única hipótesis preferida (2O → H).",
        "Suponemos que h = Eh(O) para ser consistente con O por definición de Eh, por lo que usar esta función en su conjunto de observaciones para determinar su hipótesis favorita es una forma segura para que el agente logre consistencia.",
        "Sin embargo, cabe destacar que una hipótesis no necesita ser generada por Eh para ser consistente con un conjunto de observaciones.",
        "Como ejemplo concreto de tal función, y una de las principales inspiraciones de este trabajo, se puede citar el sistema de razonamiento Theorist [6], siempre y cuando esté acoplado con un filtro que seleccione una teoría preferida entre las inicialmente seleccionadas por Theorist.",
        "También hay que tener en cuenta que hi solo puede ser modificado como consecuencia de la aplicación de Eh.",
        "Nos referimos a esto como la autonomía del agente: ningún otro agente puede imponer directamente una hipótesis dada a un agente.",
        "Como consecuencia, solo una nueva observación (ya sea una nueva percepción o una observación comunicada por otro agente) puede resultar en una modificación de su hipótesis preferida hi (pero no necesariamente, por supuesto).",
        "Finalmente definimos una propiedad del sistema que utilizaremos en el resto del artículo: Definición 3 (Percepciones Acotadas).",
        "Un sistema implica una percepción limitada para los agentes si y solo si existe un n0 tal que para todo t, la unión de N observaciones realizadas por los agentes es menor o igual a n0. (Es decir, el número de observaciones a realizar por los agentes en el sistema no es infinito.)",
        "Ahora necesitamos ver cómo evolucionarán e interactuarán estos agentes en su entorno.",
        "En nuestro contexto, los agentes evolucionan en un entorno dinámico, y asumimos clásicamente el siguiente ciclo del sistema: 1.",
        "Dinámica del entorno: el entorno evoluciona de acuerdo con las reglas definidas de la dinámica del sistema. 2.",
        "Paso de percepción: los agentes obtienen percepciones del entorno.",
        "Estas percepciones suelen ser parciales (por ejemplo, el agente solo puede ver una parte de un mapa). 3.",
        "Paso de razonamiento: los agentes comparan la percepción con las predicciones, buscan explicaciones para las diferencias (potenciales), refinan su hipótesis, y sacan nuevas conclusiones. 4.",
        "Paso de comunicación: los agentes pueden comunicar hipótesis y observaciones con otros agentes a través de un protocolo definido.",
        "Cualquier agente solo puede estar involucrado en una comunicación con otro agente en el paso 5.",
        "Paso de acción: los agentes realizan un razonamiento práctico utilizando los modelos obtenidos de los pasos anteriores y seleccionan una acción.",
        "Ellos pueden modificar el entorno ejecutándolo.",
        "La comunicación de los agentes estará aún más restringida por consideraciones topológicas.",
        "En un momento dado, un agente solo podrá comunicarse con un número de vecinos.",
        "Sus conexiones con estos otros agentes pueden The Sixth Intl.",
        "La Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) evoluciona con su situación en el entorno.",
        "Normalmente, un agente solo puede comunicarse con agentes que puede percibir, pero se podría imaginar la evolución de restricciones topológicas en la comunicación basadas en una red de comunicaciones entre agentes donde los enlaces no siempre están activos.",
        "En nuestro sistema, los agentes podrán comunicarse entre sí.",
        "Sin embargo, debido a las restricciones topológicas mencionadas anteriormente, no podrán comunicarse con ningún agente en ningún momento.",
        "Con quién puede comunicarse un agente se definirá dinámicamente (por ejemplo, esto puede ser consecuencia de que los agentes estén lo suficientemente cerca para ponerse en contacto).",
        "Denotaremos de forma abstracta por C(ai, aj, t) la propiedad de comunicación, es decir, el hecho de que los agentes ai y aj puedan comunicarse en el tiempo t (nota que se asume que esta relación es simétrica, pero por supuesto no transitiva).",
        "Ahora estamos en posición de definir dos propiedades esenciales de nuestro sistema.",
        "Definición 4 (Camino Temporal).",
        "Existe un camino de comunicación temporal en el horizonte tf (denotado Ltf (aI, aJ)) entre ai y aj si y solo si existe una secuencia de puntos temporales t1, t2, ..., tn desde tf y una secuencia de agentes k1, k2, ..., kn tal que (i) C(aI, ak1, t1), (ii) C(akn, aJ, tn+1), (iii) ∀i ∈ [1, n], C(aki, aki+1, ti). Intuitivamente, lo que esta propiedad dice es que es posible encontrar un camino temporal en el futuro que permitiría vincular al agente ai y aj a través de una secuencia de agentes intermedios.",
        "Ten en cuenta que los puntos temporales no necesariamente son sucesivos, y que la secuencia de agentes puede involucrar a los mismos agentes varias veces.",
        "Definición 5 (Conexidad Temporal).",
        "Un sistema es temporalmente conexo si y solo si ∀t ∀(i, j)∈[1, n]2 Lt(ai, aj). En resumen, un sistema temporalmente conexo garantiza que cualquier agente podrá comunicarse con cualquier otro agente, sin importar cuánto tiempo pueda llevar hacerlo, en cualquier momento.",
        "Dicho de otra manera, nunca sucede que un agente esté aislado para siempre de otro agente del sistema.",
        "A continuación discutiremos en detalle cómo la comunicación tiene lugar concretamente en nuestro sistema.",
        "Recuerda que en este documento, solo consideramos el caso de intercambios bilaterales (un agente solo puede hablar con otro agente) y también asumimos que cualquier agente solo puede participar en un intercambio en una ronda dada. 3.",
        "PROTOCOLOS Y ESTRATEGIAS En esta sección, discutimos los requisitos de los protocolos de interacción que rigen el intercambio de mensajes entre agentes, y proporcionamos algunos ejemplos de la implementación de dichos protocolos.",
        "Para aclarar la presentación, distinguimos dos niveles: el nivel local, que se ocupa de la regulación de los intercambios bilaterales; y el nivel global, que regula principalmente la forma en que los agentes pueden participar realmente en una conversación.",
        "En cada nivel, separamos lo que está especificado por el protocolo y lo que se deja a las estrategias de los agentes.",
        "Protocolos y estrategias locales Comenzamos inspeccionando los protocolos y estrategias locales que regularán la comunicación entre los agentes del sistema.",
        "Al limitarnos a la comunicación bilateral, estos protocolos simplemente implicarán a dos agentes.",
        "Dicho protocolo tendrá que cumplir con un requisito básico para ser satisfactorio: consistencia (CONS) - un protocolo local debe garantizar la consistencia mutua de los agentes al finalizar (lo que implica, por supuesto, la finalización).",
        "Figura 1: Un Protocolo de Intercambio de Hipótesis [1] Un ejemplo de dicho protocolo es el protocolo descrito en [1] que se muestra en la Fig. 1.",
        "Para ilustrar aún más cómo dicho protocolo puede ser utilizado por agentes, proporcionamos algunos detalles sobre una posible estrategia: al recibir una hipótesis h1 (proponer(h1) o contra-proponer(h1)) de a1, el agente a2 se encuentra en el estado 2 y tiene las siguientes respuestas posibles: contraejemplo (si el agente conoce un ejemplo que contradice la hipótesis, o no está explicado por esta hipótesis), desafío (si el agente carece de evidencia para aceptar esta hipótesis), contra-proponer (si el agente está de acuerdo con la hipótesis pero prefiere otra), o aceptar (si es tan buena como su hipótesis favorita).",
        "Esta estrategia garantiza, entre otras propiedades, la eventual consistencia lógica mutua de los agentes involucrados [1].",
        "Protocolo global El protocolo global regula la forma en que se iniciarán los intercambios bilaterales entre agentes.",
        "En cada turno, los agentes enviarán simultáneamente una solicitud ponderada para comunicarse con otros agentes.",
        "Este peso es un valor que mide la disposición de los agentes para conversar con el agente objetivo (en la práctica, esto puede basarse en diferentes heurísticas, pero haremos algunas suposiciones sobre las estrategias de los agentes, ver más abajo).",
        "Enviar una solicitud de este tipo es una especie de compromiso condicional para el agente.",
        "Un agente que envía una solicitud ponderada se compromete a entablar una conversación con el objetivo si no recibe y acepta otra solicitud por sí mismo.",
        "Una vez que se hayan recibido todas las solicitudes, cada agente responde con un aceptar o un rechazar.",
        "Al responder con un aceptar, un agente se compromete plenamente a participar en la conversación con el remitente.",
        "Por lo tanto, solo puede enviar una aceptación en una ronda dada, ya que un agente solo puede participar en una conversación por paso de tiempo.",
        "Cuando se hayan recibido todas las respuestas, cada agente que reciba una aceptación puede iniciar una conversación utilizando el protocolo local o enviar una cancelación si ha aceptado otra solicitud.",
        "Al final de todos los intercambios bilaterales, los agentes involucrados en la conversación son descartados del protocolo.",
        "Entonces cada uno de los agentes restantes reenvía una solicitud y el proceso se repite hasta que no se envíen más solicitudes.",
        "Estrategia global Ahora definimos cuatro requisitos para las estrategias utilizadas por los agentes, dependiendo de su rol en el protocolo: dos se refieren al rol del solicitante (cómo decidir quién es el 1000 The Sixth Intl.",
        "La Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) ¿con qué agente desea comunicarse? Los otros dos con el rol de respondedor (¿cómo decidir qué solicitud de comunicación aceptar o no?). • Disposición para resolver inconsistencias (SOLVE): los agentes desean comunicarse con cualquier otro agente a menos que sepan que son mutuamente consistentes. • Enfoque en resolver inconsistencias (FOCUS): los agentes no solicitan comunicarse con un agente con el que saben que son mutuamente consistentes. • Disposición para comunicarse (COMM): los agentes no pueden rechazar una solicitud de comunicación ponderada, a menos que acaben de recibir o enviar una solicitud con un peso mayor. • Compromiso con la solicitud de comunicación (REQU): los agentes no pueden aceptar una solicitud de comunicación ponderada si ellos mismos han enviado una solicitud de comunicación con un peso mayor.",
        "Por lo tanto, no cancelarán su solicitud a menos que hayan recibido una solicitud comunicacional con mayor peso.",
        "Ahora la estructura del protocolo, junto con las propiedades COMM+REQU, garantizan que una solicitud solo puede ser rechazada si su agente objetivo se involucra en comunicación con otro agente.",
        "Supongamos de hecho que el agente ai quiere comunicarse con aj enviando una solicitud con peso w. COMM garantiza que un agente que reciba una solicitud ponderada aceptará esta comunicación, aceptará una comunicación con un peso mayor o esperará la respuesta a una solicitud con un peso mayor.",
        "Esto asegura que la solicitud con peso máximo será aceptada y no cancelada (ya que REQU asegura que un agente que envía una solicitud solo puede cancelarla si acepta otra solicitud con un peso mayor).",
        "Por lo tanto, al menos dos agentes participarán en una conversación por ronda del protocolo global.",
        "Como el protocolo asegura que ai puede reenviar su solicitud mientras aj no está ocupado en una conversación, llegará un momento en el que aj deberá participar en una conversación, ya sea con ai u otro agente.",
        "Estos requisitos se refieren al envío y aceptación de solicitudes, pero los agentes también necesitan alguna estrategia de atribución de peso.",
        "Describimos a continuación una estrategia altruista, utilizada en nuestros experimentos.",
        "Siendo cooperativo, un agente puede querer conocer más los deseos de comunicación de otros agentes para mejorar la asignación general de intercambios a los agentes.",
        "Se añade entonces un paso de solicitud de contexto al protocolo global.",
        "Antes de enviar su solicitud ponderada elegida, los agentes asignan un peso a todos los agentes con los que están dispuestos a comunicarse, de acuerdo con algunos factores internos.",
        "En el caso más simple, este peso será 1 para todos los agentes con los que el agente no esté seguro de ser mutuamente consistentes (garantizando SOLVE), sin considerar a otros agentes para la comunicación (garantizando FOCUS).",
        "El agente luego envía una solicitud de contexto a todos los agentes con los que se considera la comunicación.",
        "Esta solicitud también proporciona información sobre el remitente (lista de comunicaciones consideradas junto con su peso).",
        "Después de recibir todas las solicitudes de contexto, los agentes responderán con un rechazo si ya están ocupados en una conversación (en cuyo caso, el agente solicitante no considerará comunicarse con ellos en este turno), o con una información que brinde al solicitante información sobre las solicitudes que ha enviado y recibido.",
        "Cuando se hayan recibido todas las respuestas, cada agente puede calcular el peso de todas las solicitudes que le conciernen.",
        "Lo hace restando del peso de su solicitud el peso de todas las solicitudes relacionadas con él o su objetivo (es decir, el peso final de la solicitud de ai a aj es Wi,j = wi,j + wj,i - ( Σ k∈R(i)-{j} wi,k + Σ k∈S(i)-{j} wk,i + Σ k∈R(j)-{i} wj,k + Σ k∈S(j)-{i} wk,j) donde wi,j es el peso de la solicitud de ai a aj, R(i) es el conjunto de índices de agentes que han recibido una solicitud de ai y S(i) es el conjunto de índices de agentes que han enviado una solicitud a ai).",
        "Luego envía finalmente una solicitud ponderada a los agentes que maximizan este peso (o esperan una solicitud) según lo descrito en el protocolo global. 4. (CONDICIONAL) CONVERGENCIA HACIA LA COHERENCIA GLOBAL En esta sección mostraremos que los requisitos relacionados con los protocolos y estrategias recién discutidos serán suficientes para garantizar que el sistema eventualmente convergerá hacia la coherencia global, bajo ciertas condiciones.",
        "Primero demostramos que, si dos agentes no son mutuamente consistentes en algún momento, entonces necesariamente habrá un momento en el futuro en el que un agente aprenderá una nueva observación, ya sea porque es nueva para el sistema, o al aprenderla de otro agente.",
        "Lema 1.",
        "Sea S un sistema poblado por n agentes a1, a2, ..., an, temporalmente conectados e involucrando percepciones limitadas para estos agentes.",
        "Sea n1 la suma de las cardinalidades de la intersección de los conjuntos de observaciones emparejados. (n1 = P (i,j)∈[1,n]2 |Oi ∩ Oj|) Sea n2 la cardinalidad de la unión de todos los conjuntos de observaciones de los agentes. (n2 = | ∪N i=1 Oi|).",
        "Si ¬MCons(ai, aj) en el tiempo t0, necesariamente existe un tiempo t > t0 tal que ya sea n1 o n2 aumentarán.",
        "Prueba.",
        "Supongamos que exista un tiempo t0 y unos índices (i, j) tal que ¬MCons(ai, aj).",
        "Utilizaremos mt0 = P (k,l)∈[1,n]2 εComm(ak, al, t0) donde εComm(ak, al, t0) = 1 si ak y al han comunicado al menos una vez desde t0, y 0 en caso contrario.",
        "La conexidad temporal garantiza que existen t1, ..., tm+1 y k1, ..., km tal que.",
        "C(ai, ak1 , t1), C(akm , aj, tm+1), y ∀p ∈ [1, m], C(akp , akp+1 , tp).",
        "Claramente, si MCons(ai, ak1), MCons(akm, aj) y ∀p, MCons(akp, akp+1), tenemos MCons(ai, aj) lo cual contradice nuestra hipótesis (siendo MCons transitivo, MCons(ai, ak1)∧MCons(ak1, ak2) implica que MCons(ai, ak2) y así sucesivamente hasta MCons(ai, akm)∧MCons(akm, aj) lo cual implica MCons(ai, aj)).",
        "Al menos dos agentes son necesariamente inconsistentes (¬MCons(ai, ak1), o ¬MCons(akm, aj), o ∃p0 t.q. ¬MCons(akp0, akp0+1)).",
        "Que ak y al sean estos dos vecinos en un momento t > t0 1.",
        "La propiedad SOLVE asegura que ya sea ak o al enviará una solicitud de comunicación al otro agente en el tiempo t.",
        "Como se mostró anteriormente, esto a su vez garantiza que al menos uno de estos agentes estará involucrado en una comunicación.",
        "Entonces hay dos posibilidades: (caso i) ak y al se comunican en el tiempo t.",
        "En este caso, sabemos que ¬MCons(ak, al).",
        "Esto y la propiedad CONS aseguran que al menos uno de los agentes debe cambiar su 1. Estrictamente hablando, la transitividad de MCons solo asegura que ak y al son inconsistentes en un tiempo t ≥ t0 que puede ser diferente del tiempo t en el que pueden comunicarse.",
        "Pero si se vuelven consistentes entre t y t (o inconsistentes entre t y t), significa que al menos uno de ellos ha cambiado su hipótesis entre t y t, es decir, después de t0.",
        "Podemos entonces aplicar el razonamiento del caso iib.",
        "El Sexto Internacional.",
        "La Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 1001 hipótesis, lo cual a su vez, dado que los agentes son autónomos, implica al menos un intercambio de observación.",
        "Pero entonces |Ok ∩Ol| está destinado a aumentar: n1(t) > n1(t0). (caso ii) ak se comunica con ap en el tiempo t.",
        "Entonces tenemos de nuevo dos posibilidades: (caso iia) ak y ap no se comunicaron desde t0.",
        "Pero luego εComm(ak, ap, t0) tenía valor 0 y toma valor 1.",
        "Por lo tanto, mt0 aumenta. (caso iib) ak y ap se comunicaron en algún momento t0 > t0.",
        "La propiedad CONS del protocolo asegura que MCons(ak, ap) en ese momento.",
        "Ahora el hecho de que se comuniquen y se ENFOQUEN implica que al menos uno de ellos cambió su hipótesis en el ínterin.",
        "El hecho de que los agentes sean autónomos implica a su vez que una nueva observación (percibida o recibida de otro agente) necesariamente provocó este cambio.",
        "El último caso garantizaría la existencia de un tiempo t > t0 y un agente aq tal que |Op ∩ Oq| o |Ok ∩ Oq| aumenten en 1 en ese momento (lo que implica que n1(t) > n1(t0)).",
        "El caso anterior significa que el agente obtiene una nueva percepción en el tiempo t.",
        "Si esa observación era desconocida en el sistema antes, entonces n2(t) > n2(t0).",
        "Si algún agente aq ya conocía esta observación antes, entonces tanto Op ∩ Oq como Ok ∩ Oq aumentan en 1 en el tiempo t (lo que implica que n1(t) > n1(t0)).",
        "Por lo tanto, ¬MCons(ai, aj) en el tiempo t0 garantiza que, o bien: −∃t > t0 t.q. n1(t ) > n1(t0); o −∃t > t0 t.q. n2(t ) > n2(t0); o −∃t > t0 t.q. mt0 aumenta en 1 en el tiempo t.",
        "Al iterar el razonamiento con t (pero manteniendo t0 como la referencia de tiempo para mt0), podemos eliminar el tercer caso (mt0 es un entero y está limitado por n2, lo que significa que después de un máximo de n2 iteraciones, necesariamente estaremos en uno de los otros dos casos).",
        "Como resultado, hemos demostrado que si ¬MCons(ai, aj) en el tiempo t0, necesariamente habrá un tiempo t tal que ya sea n1 o n2 aumentarán.",
        "Teorema 1 (Consistencia global).",
        "Sea S un sistema poblado por n agentes a1, a2, ..., an, temporalmente conectados e involucrando percepciones limitadas para estos agentes.",
        "Sea Cons(ai, aj) una propiedad de consistencia transitiva.",
        "Entonces, cualquier protocolo y estrategias que cumplan con las propiedades CONS, SOLVE, FOCUS, COMM y REQU garantizan que el sistema convergerá hacia la consistencia global.",
        "Prueba.",
        "Por el bien de la contradicción, asumamos que ∃I, J ∈ [1, N] tal que ∀t, ∃t0 > t, tal que ¬Cons(aI , aJ , t0).",
        "Usando el lema, esto implica que ∃t > t0 tal que n1(t) > n1(t0) o n2(t) > n2(t0).",
        "Pero podemos aplicar el mismo razonamiento tomando t = t, lo que nos daría t1 > t > t0 tal que ¬Cons(aI , aJ , t1), lo que nos da t > t1 tal que n1(t) > n1(t1) o n2(t) > n2(t1).",
        "Mediante iteraciones sucesivas podemos construir una secuencia t0, t1, ..., tn, que puede dividirse en dos subsecuencias t0, t1, ...tn y t0, t1, ..., tn tal que n1(t0) < n1(t1) < ... < n1(tn) y n2(t0) < n2(t1) < ... < n2(tn).",
        "Una de estas subsecuencias tiene que ser infinita.",
        "Sin embargo, n1(ti) y n2(ti) son estrictamente crecientes, enteros y acotados, lo que implica que ambos son finitos.",
        "Contradicción.",
        "Lo que el resultado anterior muestra esencialmente es que, en un sistema donde ningún agente estará aislado del resto de los agentes para siempre, solo se necesitan suposiciones muy leves sobre los protocolos y estrategias utilizados por los agentes para garantizar la convergencia hacia la consistencia del sistema en una cantidad finita de tiempo (aunque podría llevar mucho tiempo).",
        "Desafortunadamente, en muchas situaciones críticas, no será posible asumir esta conexión temporal.",
        "Dado que enfoques distribuidos como el abogado en este documento suelen presentarse como una buena manera de abordar problemas de confiabilidad o problemas de dependencia de un centro que son de suma importancia en estas aplicaciones críticas, ciertamente resulta interesante explorar más a fondo cómo se comportaría un sistema de este tipo cuando relajamos esta suposición.",
        "ESTUDIO EXPERIMENTAL Este experimento implica agentes tratando de escapar de un edificio en llamas.",
        "El entorno se describe como una cuadrícula espacial con un conjunto de paredes y (afortunadamente) algunas salidas.",
        "El tiempo y el espacio se consideran discretos.",
        "El tiempo se divide en rondas.",
        "Los agentes se localizan por su posición en la cuadrícula espacial.",
        "Estos agentes pueden moverse y comunicarse con otros agentes.",
        "En una ronda, un agente puede moverse una celda en cualquiera de las cuatro direcciones cardinales, siempre y cuando no esté bloqueado por una pared.",
        "En esta aplicación, los agentes se comunican con cualquier otro agente (pero, recuerda, solo uno) siempre y cuando este agente esté a la vista y aún no hayan intercambiado su hipótesis actual favorita.",
        "De repente, se desata un incendio en estas instalaciones.",
        "A partir de este momento, el fuego se propaga.",
        "En cada ronda, en cada caso donde haya fuego, el fuego se propaga en las cuatro direcciones.",
        "Sin embargo, el fuego no puede propagarse a través de una pared.",
        "Si el fuego se propaga en un caso donde un agente está posicionado, ese agente se quema y se considera muerto.",
        "Por supuesto, ya no puede moverse ni comunicarse.",
        "Si un agente llega a una salida, se considera que está a salvo y ya no puede ser quemado.",
        "Los agentes conocen el entorno y las reglas que rigen la dinámica de este entorno, es decir, conocen el mapa así como las reglas de propagación del fuego previamente descritas.",
        "También perciben este entorno localmente, pero no pueden ver más allá de 3 casos en cualquier dirección.",
        "Las paredes también bloquean la línea de visión, impidiendo que los agentes vean detrás de ellas.",
        "Dentro de su campo de visión, pueden ver a otros agentes y si los casos que ven están en llamas.",
        "Todas estas percepciones están memorizadas.",
        "Mostramos ahora cómo se instancia el marco abstracto presentado en el documento. • O = {Fire(x, y, t), NoFire(x, y, t), Agent(ai, x, y, t)} Las observaciones pueden ser positivas (o ∈ P(O) si ∃h ∈ H tal que h |= o) o negativas (o ∈ N(O) si ∃h ∈ H tal que h |= ¬o). • H={FireOrigin(x1, y1, t1)∧...∧FireOrigin(xl, yl, tl)} Las hipótesis son conjunciones de Orígenes de Fuego. • La relación de consistencia Cons(h, O) satisface: - coherencia: ∀o ∈ N(O), h |= ¬o. - completitud: ∀o ∈ P(O), h |= o. - minimalidad: Para todo h ∈ H, si h es coherente y completo para O, entonces h es preferido a h de acuerdo con la relación de preferencia (h ≤p h). Selecciona primero el número mínimo de orígenes, luego el más reciente (estrategia menos preemptiva [6]), y luego utiliza un ranking fijo arbitrario para discriminar ex-aequo.",
        "La relación resultante es un orden total, por lo tanto, la minimalidad implica que habrá un único h tal que Cons(O, h) para un O dado.",
        "Esto a su vez significa que MCons(ai, aj) si y solo si Cons(ai), Cons(aj) y hi = hj.",
        "Esta relación es entonces transitiva y simétrica. 1002 El Sexto Internacional.",
        "Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) • Eh toma O como argumento y devuelve min≤p de la hipótesis coherente y completa para O 5.1 Evaluación Experimental Clásicamente evaluaremos la efectividad y eficiencia de diferentes protocolos de interacción (ver, por ejemplo, [3, 4]).",
        "La efectividad de un protocolo se determinará por la proporción de agentes que sobreviven al incendio respecto al número inicial de agentes involucrados en el experimento.",
        "Si este valor es alto, el protocolo ha sido efectivo para propagar la información y/o para que los agentes refinen sus hipótesis y determinen la mejor manera de salir.",
        "Eficiencia de un protocolo. Por lo general, el uso de información de apoyo implicará una sobrecarga de comunicación.",
        "Aquí asumiremos que la eficiencia de un protocolo dado está caracterizada por el flujo de datos inducido por este protocolo.",
        "En este documento solo discutiremos este aspecto con respecto a los protocolos locales.",
        "La medida principal que utilizaremos aquí es el tamaño total promedio de los mensajes intercambiados por los agentes por intercambio (teniendo en cuenta tanto el número de mensajes como el tamaño real de los mensajes, ya que podría ser que los mensajes resulten ser muy grandes, conteniendo por ejemplo un gran número de observaciones, lo que podría contrarrestar un bajo número de mensajes). 5.2 Configuraciones Experimentales Las configuraciones experimentales elegidas son las siguientes: • Topología ambiental: El rendimiento de la propagación de la información está altamente condicionado por la topología del entorno.",
        "Las habilidades de percepción de los agentes dependen de la apertura del entorno.",
        "Con un gran número de paredes, las percepciones de los agentes están limitadas, al igual que el número de posibles comunicaciones entre agentes, mientras que un entorno abierto proporcionará posibilidades óptimas de percepción y propagación de información.",
        "Por lo tanto, proponemos un índice topológico (ver abajo) como base común para caracterizar los entornos (mapas) utilizados durante las experimentaciones.",
        "El índice topológico (TI) es la proporción entre el número de celdas que pueden ser percibidas por los agentes sumadas desde todas las posiciones posibles, dividido por el número de celdas que serían percibidas desde las mismas posiciones pero sin paredes. (Cuanto más cercano a 1, más abierto es el entorno).",
        "También utilizaremos dos medidas adicionales, más clásicas [10]: la longitud del camino característico (CPL) y el coeficiente de agrupamiento (CC). • Número de agentes: la propagación de la información también depende del número inicial de agentes involucrados durante una experimentación.",
        "Por ejemplo, cuantos más agentes haya, más potenciales comunicaciones existen.",
        "Esto significa que habrá más potencial de propagación, pero también que la restricción de intercambio bilateral será más crucial. 3 El CPL es la mediana de las medias de las longitudes de los caminos más cortos que conectan cada nodo con todos los demás nodos. 4 caracterizando el grado de aislamiento de una región de un entorno en términos de accesibilidad (número de caminos aún utilizables para llegar a esta región).",
        "Mapa T.I. (%) C.P.L.",
        "C.C. 69-1 69,23 4,5 0,69 69-2 68,88 4,38 0,65 69-3 69,80 4,25 0,67 53-1 53,19 5,6 0,59 53-2 53,53 6,38 0,54 53-3 53,92 6,08 0,61 38-1 38,56 8,19 0,50 38-2 38,56 7,3 0,50 38-3 38,23 8,13 0,50 Tabla 1: Características Topológicas de los Mapas • Posiciones iniciales de los agentes- Las posiciones iniciales de los agentes tienen una influencia significativa en el comportamiento general de una instancia de nuestro sistema: estar cerca de una salida facilitará (en general) la escapatoria. 5.3 Entornos experimentales Elegimos realizar experimentos en tres índices topológicos muy diferentes (69% para entornos abiertos, 53% para entornos mixtos y 38% para entornos tipo laberinto).",
        "Figura 2: Dos mapas (izquierda: IT=69%, derecha IT=38%) Diseñamos tres mapas diferentes para cada índice (la Fig. 2 muestra dos de ellos), conteniendo el mismo número máximo de agentes (máximo 36 agentes) con una densidad máxima de un agente por celda, el mismo número de salidas y un origen de incendio similar (por ejemplo, tiempo y posición de inicio).",
        "Los tres mapas diferentes de un índice dado están diseñados de la siguiente manera.",
        "El primer plano es un modelo de un piso de un edificio existente.",
        "El segundo mapa tiene el mismo perímetro, salidas y origen del fuego que el primero, pero la cantidad y ubicación de las paredes son diferentes (las ubicaciones de las paredes son diseñadas por una heurística que crea paredes de forma aleatoria en la cuadrícula espacial de manera que no se creen habitaciones completamente cerradas y que ninguna salida quede bloqueada).",
        "El tercer mapa se caracteriza por un recinto geométrico en el que la ubicación de las paredes también está diseñada con la heurística mencionada anteriormente.",
        "La Tabla 1 resume las diferentes medidas topológicas que caracterizan estos mapas diferentes.",
        "Vale la pena señalar que los valores confirman la relevancia de TI (los mapas con un alto TI tienen un bajo CPL y un alto CC).",
        "Sin embargo, el CPL y el CC permiten refinar aún más la diferencia entre los mapas, por ejemplo, entre 53-1 y 53-2). 5.4 Resultados Experimentales Para cada trío de mapas definidos como se mencionó anteriormente, llevamos a cabo los mismos experimentos.",
        "En cada experimento, la sociedad difiere en cuanto a su proporción inicial de agentes involucrados, desde el 1% hasta el 100%.",
        "Esta proporción inicial representa el porcentaje de agentes involucrados con respecto al número máximo posible de agentes.",
        "Para cada mapa y cada proporción inicial, la Sexta Internacional.",
        "En la Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) seleccionamos aleatoriamente 100 ubicaciones iniciales de agentes diferentes.",
        "Para cada una de esas ubicaciones diferentes ejecutamos el sistema una vez para cada protocolo de interacción diferente.",
        "La efectividad de la comunicación y argumentación El primer experimento que hemos establecido tiene como objetivo probar cuán efectivo es el intercambio de hipótesis (IH), y en particular cómo los aspectos topológicos afectarán esta efectividad.",
        "Para hacerlo, hemos calculado la proporción de mejora ofrecida por ese protocolo sobre una situación en la que los agentes simplemente no podían comunicarse (sin comunicación).",
        "Para obtener más información sobre en qué medida el intercambio de hipótesis fue realmente crucial, también probamos un protocolo mucho menos elaborado que consistía en intercambios de observaciones simples (OE).",
        "Más precisamente, este protocolo requiere que cada agente almacene cualquier observación inesperada que perciba, y los agentes simplemente intercambian sus respectivas listas de observaciones cuando discuten.",
        "En este caso, el protocolo local es diferente (nota en particular que no garantiza consistencia mutua), pero el protocolo global permanece igual (con la única excepción de que la motivación de los agentes para comunicarse es sincronizar su lista de observaciones, no sus hipótesis).",
        "Si este protocolo es como máximo tan efectivo como HE, tiene la ventaja de ser más eficiente (esto es obvio en cuanto al número de mensajes, que se limitará a 2, menos directo en lo que respecta al tamaño de los mensajes, pero la observación general de que el intercambio de observaciones se puede ver como una versión simplificada del desafío es útil para ver esto).",
        "Los resultados de estos experimentos se informan en la Figura 3.",
        "Figura 3: Ganancia de la proporción de efectividad comparativa de los protocolos cuando la proporción de agentes aumenta. La primera observación que debe hacerse es que la comunicación mejora la efectividad del proceso, y esta proporción aumenta a medida que el número de agentes crece en el sistema.",
        "La segunda lección que aprendemos aquí es que la cercanía relativamente hace que la comunicación sea más efectiva que la falta de comunicación.",
        "Los mapas que muestran un T.I. del 38% están constantemente por encima de los otros dos, y el 53% sigue siendo ligeramente pero significativamente mejor que el 69%.",
        "Sin embargo, estas curvas también sugieren, quizás sorprendentemente, que HE supera a OE precisamente en aquellas situaciones donde la ganancia de la relación es menos importante (la única diferencia notable ocurre en mapas bastante abiertos donde T.I. es del 69%).",
        "Esto se puede explicar de la siguiente manera: cuando un mapa está abierto, los agentes tienen muchos posibles candidatos de explicación, y la argumentación se vuelve útil para discriminar entre ellos.",
        "Cuando un mapa es laberíntico, hay menos posibles explicaciones para un evento inesperado.",
        "Importancia del Protocolo Global El segundo conjunto de experimentos busca evaluar la importancia del diseño del protocolo global.",
        "Probamos nuestro protocolo contra un protocolo de difusión local (LB).",
        "La difusión local significa que todos los agentes vecinos percibidos por un agente estarán involucrados en una comunicación con ese agente en una ronda dada, aliviando la restricción de una sola comunicación por agente.",
        "Esto nos proporciona un límite superior aproximado sobre la posible ganancia de ratio en el sistema (para un protocolo local dado).",
        "Nuevamente, evaluamos la ganancia de la relación inducida por ese LB sobre nuestro HE clásico, para las tres clases diferentes de mapas.",
        "Los resultados se informan en la Figura 4.",
        "Figura 4: Ganancia de la proporción de transmisión local sobre el intercambio de hipótesis. Tenga en cuenta que la ganancia de la proporción es 0 cuando la proporción de agentes es del 5%, lo cual se explica fácilmente por el hecho de que corresponde a situaciones que involucran solo a dos agentes.",
        "Primero observamos que todas las clases de mapas muestran un aumento en la ganancia de la proporción a medida que aumenta el número de agentes: la ganancia alcanza entre el 10 y el 20%, dependiendo de la clase de mapas considerada.",
        "Si se compara esto con la mejora reportada en el experimento anterior, parece ser de la misma magnitud.",
        "Esto ilustra que el diseño del protocolo global no puede ser ignorado, especialmente cuando la proporción de agentes es alta.",
        "Sin embargo, también observamos que las curvas de ganancia de la proporción de efectividad tienen formas muy diferentes en ambos casos: la ganancia inducida por la precisión del protocolo local aumenta muy rápidamente con la proporción de agentes, mientras que la curva es muy suave para el global.",
        "Ahora observemos con más cuidado los resultados reportados aquí: la curva correspondiente a una TI del 53% está por encima de la correspondiente al 38%.",
        "Esto se debe a que cuanto más abierta sea un mapa, más oportunidades hay de comunicarse con más de un agente (y por lo tanto beneficiarse de la difusión).",
        "Sin embargo, también observamos que la curva para el 69% está por debajo de la del 53%.",
        "Esto se explica de la siguiente manera: en el caso del 69%, la ganancia potencial en términos de agentes sobrevivientes es mucho menor, porque nuestros protocolos ya ofrecen resultados bastante eficientes de todos modos (alcanzando rápidamente el 90%, ver Fig. 3).",
        "Una regla general podría ser que cuando el número de agentes es pequeño, se debe prestar especial atención al local 1004 de la Sexta Internacional.",
        "En el caso de que el número de agentes sea pequeño, uno puede utilizar el protocolo de la Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07), mientras que cuando ese número es grande, se debe diseñar cuidadosamente uno global (a menos que el mapa sea tan abierto que el protocolo ya sea casi óptimamente eficiente).",
        "La eficiencia de los protocolos. El experimento final reportado aquí se centra en el análisis de la eficiencia de los protocolos.",
        "Aquí analizamos el tamaño medio de la totalidad de los mensajes que son intercambiados por agentes (tamaño medio de intercambios, en resumen) utilizando los siguientes protocolos: HE, OE y dos protocolos variantes.",
        "El primero es un protocolo de intercambio de hipótesis restringidas (RHE) intermediario.",
        "RHE es el siguiente: no implica ningún desafío ni contraoferta, lo que significa que los agentes no pueden cambiar su rol durante el protocolo (esto difiere de RE en ese aspecto).",
        "En resumen, RHE permite a un agente agotar las críticas de sus socios, y eventualmente este socio adoptará la hipótesis del agente.",
        "Ten en cuenta que esto significa que la autonomía del agente no se conserva aquí (ya que un agente esencialmente aceptará cualquier hipótesis que no pueda socavar), con la esperanza de que la ganancia en eficiencia sea lo suficientemente significativa como para compensar una pérdida en efectividad.",
        "El segundo protocolo de variante es un protocolo completo de intercambio de observaciones (COE).",
        "COE utiliza los mismos principios que OE, pero incluye además todos los ejemplos críticos negativos (nofire) en el intercambio (dando así todos los ejemplos utilizados como argumentos por el protocolo de intercambio de hipótesis), mejorando así la efectividad.",
        "Los resultados para el mapa 69-1 se muestran en la Figura 5.",
        "Figura 5: Tamaño medio de los intercambios. Primero podemos observar el hecho de que el orden de los protocolos, desde el menos eficiente hasta el más eficiente, es COE, HE, RHE y luego OE.",
        "ÉL siendo más eficiente que COE demuestra que el proceso de argumentación gana eficiencia al seleccionar cuándo es necesario proporcionar ejemplos negativos, los cuales tienen menos impacto que los positivos en nuestro entorno de prueba específico.",
        "Sin embargo, al comunicar hipótesis antes de proporcionar observaciones para respaldarla (HE) en lugar de dar directamente las observaciones más cruciales (OE), el proceso de argumentación duplica el tamaño de los intercambios de datos.",
        "Es el costo de garantizar la consistencia al final del intercambio (una propiedad que OE no admite).",
        "También es significativo el hecho de que el tamaño promedio de los intercambios es ligeramente mayor cuando el número de agentes es pequeño.",
        "Esto se explica por el hecho de que en estos casos solo unos pocos agentes tienen información relevante en su posesión, y que necesitarán comunicarse mucho para llegar a un punto de vista común de la situación.",
        "Cuando el número de agentes aumenta, este conocimiento se distribuye entre más agentes que necesitan discusiones más cortas para llegar a una consistencia mutua.",
        "Como consecuencia, la ganancia relativa en eficiencia de usar RHE parece ser mejor cuando el número de agentes es pequeño: cuando es alto, difícilmente discutirán de todos modos.",
        "Finalmente, vale la pena notar que la desviación estándar para estos experimentos es bastante alta, lo que significa que la conversación no converge hacia ningún patrón estereotípico. 6.",
        "CONCLUSIÓN Este documento ha investigado las propiedades de un sistema multiagente donde cada agente (distribuido) percibe localmente su entorno e intenta alcanzar consistencia con otros agentes a pesar de severas restricciones de comunicación.",
        "En particular, hemos expuesto condiciones que permiten la convergencia e investigado experimentalmente una situación típica donde esas condiciones no pueden cumplirse.",
        "Hay muchas posibles extensiones a este trabajo, la primera siendo investigar más a fondo las propiedades de diferentes protocolos globales pertenecientes a la clase que identificamos, y su influencia en el resultado.",
        "Existen en particular muchas heurísticas, altamente dependientes del contexto del estudio, que podrían intuitivamente arrojar resultados interesantes (en nuestro estudio, seleccionar al destinatario en función de lo que se pueda inferir de sus acciones observadas podría ser una de esas heurísticas).",
        "Un candidato obvio para problemas a largo plazo se refiere a la relajación de la suposición de un sensor perfecto. 7.",
        "REFERENCIAS [1] G. Bourgne, N. Maudet y S. Pinson.",
        "Cuando los agentes comunican hipótesis en situaciones críticas.",
        "En Actas de DALT-2006, mayo de 2006. [2] P. Harvey, C. F. Chang y A. Ghose.",
        "Búsqueda distribuida basada en soporte: un nuevo enfoque para el procesamiento de restricciones multiagente.",
        "En Actas de AAMAS06, 2006. [3] H. Jung y M. Tambe.",
        "Argumentación como satisfacción de restricciones distribuida: Aplicaciones y resultados.",
        "En Actas de AGENTS01, 2001. [4] N. C. Karunatillake y N. R. Jennings.",
        "¿Vale la pena discutir?",
        "En Actas de ArgMAS 2004, 2004. [5] S. Onta˜n´on y E. Plaza.",
        "Argumentos y contraejemplos en la deliberación conjunta basada en casos.",
        "En Actas de ArgMAS-2006, mayo de 2006. [6] D. Poole.",
        "Explicación y predicción: Una arquitectura para el razonamiento por defecto y abductivo.",
        "Inteligencia Computacional, 5(2):97-110, 1989. [7] I. Rahwan, S. D. Ramchurn, N. R. Jennings, P. McBurney, S. Parsons y L. Sonenberg.",
        "Negociación basada en argumentos.",
        "La revisión de Ingeniería del Conocimiento, 4(18):345-375, 2003. [8] N. Roos, A. ten Tije y C. Witteveen.",
        "Un protocolo para el diagnóstico multiagente con conocimiento distribuido espacialmente.",
        "En Actas de AAMAS03, 2003. [9] N. Roos, A. ten Tije y C. Witteveen.",
        "Alcanzando acuerdo diagnóstico en el diagnóstico multiagente.",
        "En Actas de AAMAS04, 2004. [10] T. Takahashi, Y. Kaneda y N. Ito.",
        "Estudio preliminar: utilizando simulaciones de RoboCupRescue para la prevención de desastres.",
        "En Actas de SRMED2004, 2004.",
        "El Sexto Internacional.",
        "Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 1005"
    ],
    "error_count": 4,
    "keys": {
        "multiagent system": {
            "translated_key": "sistema multiagente",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Hypotheses Refinement under Topological Communication Constraints ∗ Gauvain Bourgne, Gael Hette, Nicolas Maudet, and Suzanne Pinson LAMSADE, Univ.",
                "Paris-Dauphine, France {bourgne,hette,maudet,pinson}@lamsade.dauphine.fr ABSTRACT We investigate the properties of a <br>multiagent system</br> where each (distributed) agent locally perceives its environment.",
                "Upon perception of an unexpected event, each agent locally computes its favoured hypothesis and tries to propagate it to other agents, by exchanging hypotheses and supporting arguments (observations).",
                "However, we further assume that communication opportunities are severely constrained and change dynamically.",
                "In this paper, we mostly investigate the convergence of such systems towards global consistency.",
                "We first show that (for a wide class of protocols that we shall define), the communication constraints induced by the topology will not prevent the convergence of the system, at the condition that the system dynamics guarantees that no agent will ever be isolated forever, and that agents have unlimited time for computation and arguments exchange.",
                "As this assumption cannot be made in most situations though, we then set up an experimental framework aiming at comparing the relative efficiency and effectiveness of different interaction protocols for hypotheses exchange.",
                "We study a critical situation involving a number of agents aiming at escaping from a burning building.",
                "The results reported here provide some insights regarding the design of optimal protocol for hypotheses refinement in this context.",
                "Categories and Subject Descriptors I.2.11 [Artificial Intelligence]: Distributed Artificial Intelligence-Multiagent systems General Terms Theory, Experimentation 1.",
                "INTRODUCTION We consider a <br>multiagent system</br> where each (distributed) agent locally perceives its environment, and we assume that some unexpected event occurs in that system.",
                "If each agent computes only locally its favoured hypothesis, it is only natural to assume that agents will seek to coordinate and refine their hypotheses by confronting their observations with other agents.",
                "If, in addition, the communication opportunities are severely constrained (for instance, agents can only communicate when they are close enough to some other agent), and dynamically changing (for instance, agents may change their locations), it becomes crucial to carefully design protocols that will allow agents to converge to some desired state of global consistency.",
                "In this paper we exhibit some sufficient conditions on the system dynamics and on the protocol/strategy structures that allow to guarantee that property, and we experimentally study some contexts where (some of) these assumptions are relaxed.",
                "While problems of diagnosis are among the venerable classics in the AI tradition, their multiagent counterparts have much more recently attracted some attention.",
                "Roos and colleagues [8, 9] in particular study a situation where a number of distributed entities try to come up with a satisfying global diagnosis of the whole system.",
                "They show in particular that the number of messages required to establish this global diagnosis is bound to be prohibitive, unless the communication is enhanced with some suitable protocol.",
                "However, they do not put any restrictions on agents communication options, and do not assume either that the system is dynamic.",
                "The benefits of enhancing communication with supporting information to make convergence to a desired global state of a system more efficient has often been put forward in the literature.",
                "This is for instance one of the main idea underlying the argumentation-based negotiation approach [7], where the desired state is a compromise between agents with conflicting preferences.",
                "Many of these works however make the assumption that this approach is beneficial to start with, and study the technical facets of the problem (or instead emphasize other advantages of using argumentation).",
                "Notable exceptions are the works of [3, 4, 2, 5], which studied in contexts different from ours the efficiency of argumentation.",
                "The rest of the paper is as follows.",
                "Section 2 specifies the basic elements of our model, and Section 3 goes on to presenting the different protocols and strategies used by the agents to exchange hypotheses and observations.",
                "We put special attention at clearly emphasizing the conditions on the system dynamics and protocols/strategies that will be exploited in the rest of the paper.",
                "Section 4 details one of 998 978-81-904262-7-5 (RPS) c 2007 IFAAMAS the main results of the paper, namely the fact that under the aforementioned conditions, the constraints that we put on the topology will not prevent the convergence of the system towards global consistency, at the condition that no agent ever gets completely lost forever in the system, and that unlimited time is allowed for computation and argument exchange.",
                "While the conditions on protocols and strategies are fairly mild, it is also clear that these system requirements look much more problematic, even frankly unrealistic in critical situations where distributed approaches are precisely advocated.",
                "To get a clearer picture of the situation induced when time is a critical factor, we have set up an experimental framework that we introduce and discuss in Section 5.",
                "The critical situation involves a number of agents aiming at escaping from a burning building.",
                "The results reported here show that the effectiveness of argument exchange crucially depends upon the nature of the building, and provide some insights regarding the design of optimal protocol for hypotheses refinement in this context. 2.",
                "BASIC NOTIONS We start by defining the basic elements of our system.",
                "Environment Let O be the (potentially infinite) set of possible observations.",
                "We assume the sensors of our agents to be perfect, hence the observations to be certain.",
                "Let H be the set of hypotheses, uncertain and revisable.",
                "Let Cons(h, O) be the consistency relation, a binary relation between a hypothesis h ∈ H and a set of observations O ⊆ O.",
                "In most cases, Cons will refer to classical consistency relation, however, we may overload its meaning and add some additional properties to that relation (in which case we will mention it).",
                "The environment may include some dynamics, and change over the course of time.",
                "We define below sequences of time points to deal with it: Definition 1 (Sequence of time points).",
                "A sequence of time points t1, t2, . . . , tn from t is an ordered set of time points t1, t2, . . . , tn such that t1 ≥ t and ∀i ∈ [1, n − 1], ti+1 ≥ ti.",
                "Agent We take a system populated by n agents a1, . . . , an.",
                "Each agent is defined as a tuple F, Oi, hi , where: • F, the set of facts, common knowledge to all agents. • Oi ∈ 2O , the set of observations made by the agent so far.",
                "We assume a perfect memory, hence this set grows monotonically. • hi ∈ H, the favourite hypothesis of the agent.",
                "A key notion governing the formation of hypotheses is that of consistency, defined below: Definition 2 (Consistency).",
                "We say that: • An agent is consistent (Cons(ai)) iff Cons(hi, Oi) (that is, its hypothesis is consistent with its observation set). • An agent ai consistent with a partner agent aj iff Cons(ai) and Cons(hi, Oj) (that is, this agent is consistent and its hypothesis can explain the observation set of the other agent). • Two agents ai and aj are mutually consistent (MCons(ai, aj)) iff Cons(ai, aj) and Cons(aj, ai). • A system is consistent iff ∀(i, j)∈[1, n]2 it is the case that MCons(ai, aj).",
                "To ensure its consistency, each agent is equipped with an abstract reasoning machinery that we shall call the explanation function Eh.",
                "This (deterministic) function takes a set of observation and returns a single prefered hypothesis (2O → H).",
                "We assume h = Eh(O) to be consistent with O by definition of Eh, so using this function on its observation set to determine its favourite hypothesis is a sure way for the agent to achieve consistency.",
                "Note however that an hypothesis does not need to be generated by Eh to be consistent with an observation set.",
                "As a concrete example of such a function, and one of the main inspiration of this work, one can cite the Theorist reasoning system [6] -as long as it is coupled with a filter selecting a single prefered theory among the ones initially selected by Theorist.",
                "Note also that hi may only be modified as a consequence of the application Eh.",
                "We refer to this as the autonomy of the agent: no other agent can directly impose a given hypothesis to an agent.",
                "As a consequence, only a new observation (being it a new perception, or an observation communicated by a fellow agent) can result in a modification of its prefered hypothesis hi (but not necessarily of course).",
                "We finally define a property of the system that we shall use in the rest of the paper: Definition 3 (Bounded Perceptions).",
                "A system involves a bounded perception for agents iff ∃n0 s.t. ∀t| ∪N i=1 Oi| ≤ n0. (That is, the number of observations to be made by the agents in the system is not infinite.)",
                "Agent Cycle Now we need to see how these agents will evolve and interact in their environment.",
                "In our context, agents evolve in a dynamic environment, and we classicaly assume the following system cycle: 1.",
                "Environment dynamics: the environment evolves according to the defined rules of the system dynamics. 2.",
                "Perception step : agents get perceptions from the environment.",
                "These perceptions are typically partial (e.g. the agent can only see a portion of a map). 3.",
                "Reasoning step: agents compare perception with predictions, seek explanations for (potential) difference(s), refine their hypothesis, draw new conclusions. 4.",
                "Communication step: agents can communicate hypotheses and observations with other agents through a defined protocol.",
                "Any agent can only be involved in one communication with another agent by step. 5.",
                "Action step: agents do some practical reasoning using the models obtained from the previous steps and select an action.",
                "They can then modify the environment by executing it.",
                "The communication of the agents will be further constrained by topological consideration.",
                "At a given time, an agent will only be able to communicate with a number of neighbours.",
                "Its connexions with these others agents may The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 999 evolve with its situation in the environment.",
                "Typically, an agent can only communicate with agents that it can sense, but one could imagine evolving topological constraints on communication based on a network of communications between agents where the links are not always active.",
                "Communication In our system, agents will be able to communicate with each other.",
                "However, due to the aforementionned topological constraints, they will not be able to communicate with any agents at anytime.",
                "Who an agent can communicate with will be defined dynamically (for instance, this can be a consequence of the agents being close enough to get in touch).",
                "We will abstractly denote by C(ai, aj, t) the communication property, in other words, the fact that agents ai and aj can communicate at time t (note that this relation is assumed to be symetric, but of course not transitive).",
                "We are now in a position to define two essential properties of our system.",
                "Definition 4 (Temporal Path).",
                "There exists a temporal communication path at horizon tf (noted Ltf (aI , aJ )) between ai and aj iff there exists a sequence of time points t1, t2, . . . , tn from tf and a sequence of agents k1, k2, . . . , kn s.t. (i) C(aI , ak1 , t1), (ii) C(akn , aJ , tn+1), (iii) ∀i ∈ [1, n], C(aki , aki+1 , ti) Intuitively, what this property says is that it is possible to find a temporal path in the future that would allow to link agent ai and aj via a sequence of intermediary agents.",
                "Note that the time points are not necessarily successive, and that the sequence of agents may involve the same agents several times.",
                "Definition 5 (Temporal Connexity).",
                "A system is temporaly connex iff ∀t ∀(i, j)∈[1, n]2 Lt(ai, aj) In short, a temporaly connex system guarantees that any agent will be able to communicate with any other agents, no matter how long it might take to do so, at any time.",
                "To put it another way, it is never the case that an agent will be isolated for ever from another agent of the system.",
                "We will next discuss the detail of how communication concretely takes place in our system.",
                "Remember that in this paper, we only consider the case of bilateral exchanges (an agent can only speak to a single other agent), and that we also assume that any agent can only engage in a single exchange in a given round. 3.",
                "PROTOCOLS AND STRATEGIES In this section, we discuss the requirements of the interaction protocols that govern the exchange of messages between agents, and provide some example instantiation of such protocols.",
                "To clarify the presentation, we distinguish two levels: the local level, which is concerned with the regulation of bilateral exchanges; and the global level,which essentially regulates the way agents can actually engage into a conversation.",
                "At each level, we separate what is specified by the protocol, and what is left to agents strategies.",
                "Local Protocol and Strategies We start by inspecting local protocols and strategies that will regulate the communication between the agents of the system.",
                "As we limit ourselves to bilateral communication, these protocols will simply involve two agents.",
                "Such protocol will have to meet one basic requirement to be satisfying. • consistency (CONS)- a local protocol has to guarantee the mutual consistency of agents upon termination (which implies termination of course).",
                "Figure 1: A Hypotheses Exchange Protocol [1] One example such protocol is the protocol described in [1] that is pictured in Fig. 1.",
                "To further illustrate how such protocol can be used by agents, we give some details on a possible strategy: upon receiving a hypothesis h1 (propose(h1) or counterpropose(h1)) from a1, agent a2 is in state 2 and has the following possible replies: counterexample (if the agent knows an example contradicting the hypothesis, or not explained by this hypothesis), challenge (if the agents lacks evidence to accept this hypothesis), counterpropose (if the agent agrees with the hypothesis but prefers another one), or accept (if it is indeed as good as its favourite hypothesis).",
                "This strategy guarantees, among other properties, the eventual mutual logical consistency of the involved agents [1].",
                "Global Protocol The global protocol regulates the way bilateral exchanges will be initiated between agents.",
                "At each turn, agents will concurrently send one weighted request to communicate to other agents.",
                "This weight is a value measuring the agents willingness to converse with the targeted agent (in practice, this can be based on different heuristics, but we shall make some assumptions on agents strategies, see below).",
                "Sending such a request is a kind of conditional commitment for the agent.",
                "An agent sending a weighted request commits to engage in conversation with the target if he does not receive and accept himself another request.",
                "Once all request have been received, each agent replies with either an acccept or a reject.",
                "By answering with an accept, an agent makes a full commitment to engage in conversation with the sender.",
                "Therefore, it can only send one accept in a given round, as an agent can only participate in one conversation per time step.",
                "When all response have been received, each agent receiving an accept can either initiate a conversation using the local protocol or send a cancel if it has accepted another request.",
                "At the end of all the bilateral exchanges, the agents engaged in conversation are discarded from the protocol.",
                "Then each of the remaining agents resends a request and the process iterates until no more requests are sent.",
                "Global Strategy We now define four requirements for the strategies used by agents, depending on their role in the protocol: two are concerned with the requestee role (how to decide who the 1000 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) agent wishes to communicate with? ), the other two with the responder role (how to decide which communication request to accept or not?). • Willingness to solve inconsistancies (SOLVE)-agents want to communicate with any other agents unless they know they are mutually consistent. • Focus on solving inconsistencies (FOCUS)-agents do not request communication with an agent with whom they know they are mutually consistent. • Willingness to communicate (COMM)-agents cannot refuse a weighted communication request, unless they have just received or send a request with a greater weight. • Commitment to communication request (REQU)agents cannot accept a weighted communication request if they have themselves sent a communication request with a greater weight.",
                "Therefore, they will not cancel their request unless they have received a communicational request with greater weight.",
                "Now the protocol structure, together with the properties COMM+REQU, ensure that a request can only be rejected if its target agent engages in communication with another agent.",
                "Suppose indeed that agent ai wants to communicate with aj by sending a request with weight w. COMM guarantees that an agent receiving a weighted request will either accept this communication, accept a communication with a greater weight or wait for the answer to a request with a greater weight.",
                "This ensures that the request with maximal weight will be accepted and not cancelled (as REQU ensures that an agent sending a request can only cancel it if he accepts another request with greater weight).",
                "Therefore at least two agents will engage in conversation per round of the global protocol.",
                "As the protocol ensures that ai can resend its request while aj is not engaged in a conversation, there will be a turn in which aj must engage in a conversation, either with ai or another agent.",
                "These requirements concern request sending and acceptation, but agents also need some strategy of weight attribution.",
                "We describe below an altruist strategy, used in our experiments.",
                "Being cooperative, an agent may want to know more of the communication wishes of other agents in order to improve the overall allocation of exchanges to agents.",
                "A context request step is then added to the global protocol.",
                "Before sending their chosen weighted request, agents attribute a weight to all agents they are prepared to communicate with, according to some internal factors.",
                "In the simplest case, this weight will be 1 for all agent with whom the agent is not sure of being mutually consistent (ensuring SOLVE), other agent being not considered for communication (ensuring FOCUS).",
                "The agent then sends a context request to all agents with whom communication is considered.",
                "This request also provides information about the sender (list of considered communications along with their weight).",
                "After reception of all the context requests, agents will either reply with a deny, iff they are already engaged in a conversation (in which case, the requesting agent will not consider communication with them anymore in this turn), or an inform giving the requester information about the requests it has sent and received.",
                "When all replies have been received, each agent can calculate the weight of all requests concerning it.",
                "It does so by substracting from the weight of its request the weight of all requests concerning either it or its target (that is, the final weight of the request from ai to aj is Wi,j = wi,j +wj,i − ( P k∈R(i)−{j} wi,k + P k∈S(i)−{j} wk,i + P k∈R(j)−{i} wj,k + P k∈S(j)−{i} wk,j) where wi,j is the weight of the request of ai to aj, R(i) is the set of indice of agents having received a request from ai and S(i) is the set of indice of agents having send a request to ai).",
                "It then finally sends a weighted request to the agents who maximise this weight (or wait for a request) as described in the global protocol. 4. (CONDITIONAL) CONVERGENCE TO GLOBAL CONSISTENCY In this section we will show that the requirements regarding protocols and strategies just discussed will be sufficient to ensure that the system will eventually converge towards global consistency, under some conditions.",
                "We first show that, if two agents are not mutually consistent at some time, then there will be necessarily a time in the future such that an agent will learn a new observation, being it because it is new for the system, or by learning it from another agent.",
                "Lemma 1.",
                "Let S be a system populated by n agents a1, a2, ..., an, temporaly connex, and involving bounded perceptions for these agents.",
                "Let n1 be the sum of cardinalities of the intersection of pairwise observation sets. (n1 = P (i,j)∈[1,n]2 |Oi ∩ Oj|) Let n2 be the cardinality of the union of all agents observations sets. (n2 = | ∪N i=1 Oi|).",
                "If ¬MCons(ai, aj) at time t0, there is necessarily a time t > t0 s.t. either n1 or n2 will increase.",
                "Proof.",
                "Suppose that there exist a time t0 and indices (i, j) s.t. ¬MCons(ai, aj).",
                "We will use mt0 = P (k,l)∈[1,n]2 εComm(ak, al, t0) where εComm(ak, al, t0) = 1 if ak and al have communicated at least once since t0, and 0 otherwise.",
                "Temporal connexity guarantees that there exist t1, ..., tm+1 and k1, ..., km s.t.",
                "C(ai, ak1 , t1), C(akm , aj, tm+1), and ∀p ∈ [1, m], C(akp , akp+1 , tp).",
                "Clearly, if MCons(ai, ak1 ), MCons(akm , aj) and ∀p, MCons(akp , akp+1 ), we have MCons(ai, aj) which contradicts our hypothesis (MCons being transitive, MCons(ai, ak1 )∧MCons(ak1 , ak2 ) implies that MCons(ai, ak2 ) and so on till MCons(ai, akm )∧ MCons(akm , aj) which implies MCons(ai, aj) ).",
                "At least two agents are then necessarily inconsistent (¬MCons(ai, ak1 ), or ¬MCons(akm , aj), or ∃p0 t.q. ¬MCons(akp0 , akp0+1 )).",
                "Let ak and al be these two neighbours at a time t > t0 1 .",
                "The SOLVE property ensures that either ak or al will send a communication request to the other agent at time t .",
                "As shown before, this in turn ensures that at least one of these agents will be involved in a communication.",
                "Then there are two possibilities: (case i) ak and al communicate at time t .",
                "In this case, we know that ¬MCons(ak, al).",
                "This and the CONS property ensures that at least one of the agents must change its 1 Strictly speaking, the transitivity of MCons only ensure that ak and al are inconsistent at a time t ≥ t0 that can be different from the time t at which they can communicate.",
                "But if they become consistent between t and t (or inconsistent between t and t ), it means that at least one of them have changed its hypothesis between t and t , that is, after t0.",
                "We can then apply the reasoning of case iib.",
                "The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 1001 hypothesis, which in turn, since agents are autonomous, implies at least one exchange of observation.",
                "But then |Ok ∩Ol| is bound to increase: n1(t ) > n1(t0). (case ii) ak communicates with ap at time t .",
                "We then have again two possibilities: (case iia) ak and ap did not communicate since t0.",
                "But then εComm(ak, ap, t0) had value 0 and takes value 1.",
                "Hence mt0 increases. (case iib) ak and ap did communicate at some time t0 > t0.",
                "The CONS property of the protocol ensures that MCons(ak, ap) at that time.",
                "Now the fact that they communicate and FOCUS implies that at least one of them did change its hypothesis in the meantime.",
                "The fact that agents are autonomous implies in turn that a new observation (perceived or received from another agent) necessarily provoked this change.",
                "The latter case would ensure the existence of a time t > t0 and an agent aq s.t. either |Op ∩Oq| or |Ok ∩Oq| increases of 1 at that time (implying n1(t ) > n1(t0)).",
                "The former case means that the agent gets a new perception o at time t .",
                "If that observation was unknown in the system before, then n2(t ) > n2(t0).",
                "If some agent aq already knew this observation before, then either Op ∩ Oq or Ok ∩ Oq increases of 1 at time t (which implies that n1(t ) > n1(t0)).",
                "Hence, ¬MCons(ai, aj) at time t0 guarantees that, either: −∃t > t0 t.q. n1(t ) > n1(t0); or −∃t > t0 t.q. n2(t ) > n2(t0); or −∃t > t0 t.q. mt0 increases of 1 at time t .",
                "By iterating the reasoning with t (but keeping t0 as the time reference for mt0 ), we can eliminate the third case (mt0 is integer and bounded by n2 , which means that after a maximum of n2 iterations, we necessarily will be in one of two other cases.)",
                "As a result, we have proven that if ¬MCons(ai, aj) at time t0, there is necessarily a time t s.t. either n1 or n2 will increase.",
                "Theorem 1 (Global consistency).",
                "Let S be a system populated by n agents a1, a2, ..., an, temporaly connex, and involving bounded perceptions for these agents.",
                "Let Cons(ai, aj) be a transitive consistency property.",
                "Then any protocol and strategies satisfying properties CONS, SOLVE, FOCUS, COMM and REQU guarantees that the system will converge towards global consistency.",
                "Proof.",
                "For the sake of contradiction, let us assume ∃I, J ∈ [1, N] s.t. ∀t, ∃t0 > t, t.q. ¬Cons(aI , aJ , t0).",
                "Using the lemma, this implies that ∃t > t0 s.t. either n1(t ) > n1(t0) or n2(t ) > n2(t0).",
                "But we can apply the same reasoning taking t = t , which would give us t1 > t > t0 s.t. ¬Cons(aI , aJ , t1), which gives us t > t1 s.t. either n1(t ) > n1(t1) or n2(t ) > n2(t1).",
                "By successive iterations we can then construct a sequence t0, t1, ..., tn, which can be divided in two sub-sequences t0, t1, ...tn and t0 , t1 , ..., tn s.t. n1(t0) < n1(t1) < ... < n1(tn) and n2(t0 ) < n2(t1 ) < ... < n2(tn).",
                "One of these sub-sequences has to be infinite.",
                "However, n1(ti) and n2(ti ) are strictly growing, integer, and bounded, which implies that both are finite.",
                "Contradiction.",
                "What the previous result essentially shows is that, in a system where no agent will be isolated from the rest of the agents for ever, only very mild assumptions on the protocols and strategies used by agents suffice to guarantee convergence towards system consistency in a finite amount of time (although it might take very long).",
                "Unfortunately, in many critical situations, it will not be possible to assume this temporal connexity.",
                "As distributed approaches as the one advocated in this paper are precisely often presented as a good way to tackle problems of reliability or problems of dependence to a center that are of utmost importance in these critical applications, it is certainly interesting to further explore how such a system would behave when we relax this assumption. 5.",
                "EXPERIMENTAL STUDY This experiment involves agents trying to escape from a burning building.",
                "The environment is described as a spatial grid with a set of walls and (thankfully) some exits.",
                "Time and space are considered discrete.",
                "Time is divided in rounds.",
                "Agents are localised by their position on the spatial grid.",
                "These agents can move and communicate with other agents.",
                "In a round, an agent can move of one cell in any of the four cardinal directions, provided it is not blocked by a wall.",
                "In this application, agents communicate with any other agent (but, recall, a single one) given that this agent is in view, and that they have not yet exchanged their current favoured hypothesis.",
                "Suddenly, a fire erupts in these premises.",
                "From this moment, the fire propagates.",
                "Each round, for each cases where there is fire, the fire propagates in the four directions.",
                "However, the fire cannot propagate through a wall.",
                "If the fire propagates in a case where an agent is positioned, that agent burns and is considered dead.",
                "It can of course no longer move nor communicate.",
                "If an agent gets to an exit, it is considered saved, and can no longer be burned.",
                "Agents know the environment and the rules governing the dynamics of this environment, that is, they know the map as well as the rules of fire propagation previously described.",
                "They also locally perceive this environment, but cannot see further than 3 cases away, in any direction.",
                "Walls also block the line of view, preventing agents from seeing behind them.",
                "Within their sight, they can see other agents and whether or not the cases they see are on fire.",
                "All these perceptions are memorised.",
                "We now show how this instantiates the abstract framework presented the paper. • O = {Fire(x, y, t), NoFire(x, y, t), Agent(ai, x, y, t)} Observations can then be positive (o ∈ P(O) iff ∃h ∈ H s.t. h |= o) or negative (o ∈ N(O) iff ∃h ∈ H s.t. h |= ¬o). • H={FireOrigin(x1, y1, t1)∧...∧FireOrigin(xl, yl, tl)} Hypotheses are conjunctions of FireOrigins. • Cons(h, O) consistency relation satisfies: - coherence : ∀o ∈ N(O), h |= ¬o. - completeness : ∀o ∈ P(O), h |= o. - minimality : For all h ∈ H, if h is coherent and complete for O, then h is prefered to h according to the preference relation (h ≤p h ).2 2 Selects first the minimal number of origins, then the most recent (least preemptive strategy [6]), then uses some arbitrary fixed ranking to discriminate ex-aequo.",
                "The resulting relation is a total order, hence minimality implies that there will be a single h s.t.Cons(O, h) for a given O.",
                "This in turn means that MCons(ai, aj) iff Cons(ai), Cons(aj), and hi = hj.",
                "This relation is then transitive and symmetric. 1002 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) • Eh takes O as argument and returns min≤p of the coherent and complete hypothesis for O 5.1 Experimental Evaluation We will classically (see e.g. [3, 4]) assess the effectiveness and efficiency of different interaction protocols.",
                "Effectiveness of a protocol The proportion of agents surviving the fire over the initial number of agents involved in the experiment will determine the effectiveness of a given protocol.",
                "If this value is high, the protocol has been effective to propagate the information and/or for the agents to refine their hypotheses and determine the best way to the exit.",
                "Efficiency of a protocol Typically, the use of supporting information will involve a communication overhead.",
                "We will assume here that the efficiency of a given protocol is characterised by the data flow induced by this protocol.",
                "In this paper we will only discuss this aspect wrt. local protocols.",
                "The main measure that we shall then use here is the mean total size of messages that are exchanged by agents per exchange (hence taking into account both the number of messages and the actual size of the messages, because it could be that messages happen to be very big, containing e.g. a large number of observations, which could counter-balance a low number of messages). 5.2 Experimental Settings The chosen experimental settings are the following: • Environmental topology- Performances of information propagation are highly constrained by the environment topology.",
                "The perception skills of the agents depend on the openness of the environment.",
                "With a large number of walls the perceptions of agents are limited, and also the number of possible inter-agent communications, whereas an open environment will provide optimal possibilities of perception and information propagation.",
                "Thus, we propose a topological index (see below) as a common basis to charaterize the environments (maps) used during experimentations.",
                "The topological index (TI) is the ratio of the number of cells that can be perceived by agents summed up from all possible positions, divided by the number of cells that would be perceived from the same positions but without any walls. (The closer to 1, the more open the environment).",
                "We shall also use two additional, more classical [10], measures: the characteristic path length3 (CPL) and the clustering coefficient4 (CC). • Number of agents- The propagation of information also depends on the initial number of agents involved during an experimentation.",
                "For instance, the more agents, the more potential communications there is.",
                "This means that there will be more potential for propagation, but also that the bilateral exchange restriction will be more crucial. 3 The CPL is the median of the means of the shortest path lengths connecting each node to all other nodes. 4 characterising the isolation degree of a region of an environment in terms of acessibility (number of roads still usable to reach this region).",
                "Map T.I. (%) C.P.L.",
                "C.C. 69-1 69,23 4,5 0,69 69-2 68,88 4,38 0,65 69-3 69,80 4,25 0,67 53-1 53,19 5,6 0,59 53-2 53,53 6,38 0,54 53-3 53,92 6,08 0,61 38-1 38,56 8,19 0,50 38-2 38,56 7,3 0,50 38-3 38,23 8,13 0,50 Table 1: Topological Characteristics of the Maps • Initial positions of the agents- Initial positions of the agents have a significant influence on the overall behavior of an instance of our system: being close from an exit will (in general) ease the escape. 5.3 Experimental environments We choose to realize experiments on three very different topological indexes (69% for open environments, 53% for mixed environments, and 38% for labyrinth-like environments).",
                "Figure 2: Two maps (left: TI=69%, right TI=38%) We designed three different maps for each index (Fig. 2 shows two of them), containing the same maximum number of agents (36 agents max.) with a maximum density of one agent per cell, the same number of exits and a similar fire origin (e.g. starting time and position).",
                "The three differents maps of a given index are designed as follows.",
                "The first map is a model of an existing building floor.",
                "The second map has the same enclosure, exits and fire origin as the first one, but the number and location of walls are different (wall locations are designed by an heuristic which randomly creates walls on the spatial grid such that no fully closed rooms are created and that no exit is closed).",
                "The third map is characterised by geometrical enclosure in wich walls location is also designed with the aforementioned heuristic.",
                "Table 1 summarizes the different topological measures characterizing these different maps.",
                "It is worth pointing out that the values confirm the relevance of TI (maps with a high TI have a low CPL and a high CC.",
                "However the CPL and CC allows to further refine the difference between the maps, e.g. between 53-1 and 53-2). 5.4 Experimental Results For each triple of maps defined as above we conduct the same experiments.",
                "In each experiment, the society differs in terms of its initial proportion of involved agents, from 1% to 100%.",
                "This initial proportion represents the percentage of involved agents with regards to the possible maximum number of agents.",
                "For each map and each initial proportion, The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 1003 we select randomly 100 different initial agents locations.",
                "For each of those different locations we execute the system one time for each different interaction protocol.",
                "Effectiveness of Communication and Argumentation The first experiment that we set up aims at testing how effective is hypotheses exchange (HE), and in particular how the topological aspects will affect this effectiveness.",
                "In order to do so, we have computed the ratio of improvement offered by that protocol over a situation where agents could simply not communicate (no comm).",
                "To get further insights as to what extent the hypotheses exchange was really crucial, we also tested a much less elaborated protocol consisting of mere observation exchanges (OE).",
                "More precisely, this protocol requires that each agent stores any unexpected observation that it perceives, and agents simply exchange their respective lists of observations when they discuss.",
                "In this case, the local protocol is different (note in particular that it does not guarantee mutual consistency), but the global protocol remains the same (at the only exception that agents motivation to communicate is to synchronise their list of observations, not their hypothesis).",
                "If this protocol is at best as effective as HE, it has the advantage of being more efficient (this is obvious wrt the number of messages which will be limited to 2, less straightforward as far as the size of messages is concerned, but the rough observation that the exchange of observations can be viewed as a flat version of the challenge is helpful to see this).",
                "The results of these experiments are reported in Fig. 3.",
                "Figure 3: Comparative effectiveness ratio gain of protocols when the proportion of agents augments The first observation that needs to be made is that communication improves the effectiveness of the process, and this ratio increases as the number of agents grows in the system.",
                "The second lesson that we learn here is that closeness relatively makes communication more effective over non communication.",
                "Maps exhibiting a T.I. of 38% are constantly above the two others, and 53% are still slightly but significantly better than 69%.",
                "However, these curves also suggest, perhaps surprisingly, that HE outperforms OE in precisely those situations where the ratio gain is less important (the only noticeable difference occurs for rather open maps where T.I. is 69%).",
                "This may be explained as follows: when a map is open, agents have many potential explanation candidates, and argumentation becomes useful to discriminate between those.",
                "When a map is labyrinth-like, there are fewer possible explanations to an unexpected event.",
                "Importance of the Global Protocol The second set of experiments seeks to evaluate the importance of the design of the global protocol.",
                "We tested our protocol against a local broadcast (LB) protocol.",
                "Local broadcast means that all the neighbours agents perceived by an agent will be involved in a communication with that agent in a given round -we alleviate the constraint of a single communication by agent.",
                "This gives us a rough upper bound upon the possible ratio gain in the system (for a given local protocol).",
                "Again, we evaluated the ratio gain induced by that LB over our classical HE, for the three different classes of maps.",
                "The results are reported in Fig. 4.",
                "Figure 4: Ratio gain of local broadcast over hypotheses exchange Note to begin with that the ratio gain is 0 when the proportion of agents is 5%, which is easily explained by the fact that it corresponds to situations involving only two agents.",
                "We first observe that all classes of maps witness a ratio gain increasing when the proportion of agents augments: the gain reaches 10 to 20%, depending on the class of maps considered.",
                "If one compares this with the improvement reported in the previous experiment, it appears to be of the same magnitude.",
                "This illustrates that the design of the global protocol cannot be ignored, especially when the proportion of agents is high.",
                "However, we also note that the effectiveness ratio gain curves have very different shapes in both cases: the gain induced by the accuracy of the local protocol increases very quickly with the proportion of agents, while the curve is really smooth for the global one.",
                "Now let us observe more carefully the results reported here: the curve corresponding to a TI of 53% is above that corresponding to 38%.",
                "This is so because the more open a map, the more opportunities to communicate with more than one agent (and hence benefits from broadcast).",
                "However, we also observe that curve for 69% is below that for 53%.",
                "This is explained as follows: in the case of 69%, the potential gain to be made in terms of surviving agents is much lower, because our protocols already give rather efficient outcomes anyway (quickly reaching 90%, see Fig. 3).",
                "A simple rule of thumb could be that when the number of agents is small, special attention should be put on the local 1004 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) protocol, whereas when that number is large, one should carefully design the global one (unless the map is so open that the protocol is already almost optimally efficient).",
                "Efficiency of the Protocols The final experiment reported here is concerned with the analysis of the efficiency of the protocols.",
                "We analysis here the mean size of the totality of the messages that are exchanged by agents (mean size of exchanges, for short) using the following protocols: HE, OE, and two variant protocols.",
                "The first one is an intermediary restricted hypotheses exchange protocol (RHE).",
                "RHE is as follows: it does not involve any challenge nor counter-propose, which means that agents cannot switch their role during the protocol (this differs from RE in that respect).",
                "In short, RHE allows an agent to exhaust its partners criticism, and eventually this partner will come to adopt the agents hypothesis.",
                "Note that this means that the autonomy of the agent is not preserved here (as an agent will essentially accept any hypothesis it cannot undermine), with the hope that the gain in efficiency will be significant enough to compensate a loss in effectiveness.",
                "The second variant protocol is a complete observation exchange protocol (COE).",
                "COE uses the same principles as OE, but includes in addition all critical negative examples (nofire) in the exchange (thus giving all examples used as arguments by the hypotheses exchanges protocol), hence improving effectiveness.",
                "Results for map 69-1 are shown on Fig. 5.",
                "Figure 5: Mean size of exchanges First we can observe the fact that the ordering of the protocols, from the least efficient to the most efficient, is COE, HE, RHE and then OE.",
                "HE being more efficient than COE proves that the argumentation process gains efficiency by selecting when it is needed to provide negative example, which have less impact that positive ones in our specific testbed.",
                "However, by communicating hypotheses before eventually giving observation to support it (HE) instead of directly giving the most crucial observations (OE), the argumentation process doubles the size of data exchanges.",
                "It is the cost for ensuring consistency at the end of the exchange (a property that OE does not support).",
                "Also significant is the fact the the mean size of exchanges is slightly higher when the number of agents is small.",
                "This is explained by the fact that in these cases only a very few agents have relevant informations in their possession, and that they will need to communicate a lot in order to come up with a common view of the situation.",
                "When the number of agents increases, this knowledge is distributed over more agents which need shorter discussions to get to mutual consistency.",
                "As a consequence, the relative gain in efficiency of using RHE appears to be better when the number of agents is small: when it is high, they will hardly argue anyway.",
                "Finally, it is worth noticing that the standard deviation for these experiments is rather high, which means that the conversation do not converge to any stereotypic pattern. 6.",
                "CONCLUSION This paper has investigated the properties of a <br>multiagent system</br> where each (distributed) agent locally perceives its environment, and tries to reach consistency with other agents despite severe communication restrictions.",
                "In particular we have exhibited conditions allowing convergence, and experimentally investigated a typical situation where those conditions cannot hold.",
                "There are many possible extensions to this work, the first being to further investigate the properties of different global protocols belonging to the class we identified, and their influence on the outcome.",
                "There are in particular many heuristics, highly dependent on the context of the study, that could intuitively yield interesting results (in our study, selecting the recipient on the basis of what can be inferred from his observed actions could be such a heuristic).",
                "One obvious candidate for longer term issues concern the relaxation of the assumption of perfect sensing. 7.",
                "REFERENCES [1] G. Bourgne, N. Maudet, and S. Pinson.",
                "When agents communicate hypotheses in critical situations.",
                "In Proceedings of DALT-2006, May 2006. [2] P. Harvey, C. F. Chang, and A. Ghose.",
                "Support-based distributed search: a new approach for multiagent constraint processing.",
                "In Proceedings of AAMAS06, 2006. [3] H. Jung and M. Tambe.",
                "Argumentation as distributed constraint satisfaction: Applications and results.",
                "In Proceedings of AGENTS01, 2001. [4] N. C. Karunatillake and N. R. Jennings.",
                "Is it worth arguing?",
                "In Proceedings of ArgMAS 2004, 2004. [5] S. Onta˜n´on and E. Plaza.",
                "Arguments and counterexamples in case-based joint deliberation.",
                "In Proceedings of ArgMAS-2006, May 2006. [6] D. Poole.",
                "Explanation and prediction: An architecture for default and abductive reasoning.",
                "Computational Intelligence, 5(2):97-110, 1989. [7] I. Rahwan, S. D. Ramchurn, N. R. Jennings, P. McBurney, S. Parsons, and L. Sonenberg.",
                "Argumention-based negotiation.",
                "The Knowledge Engineering Review, 4(18):345-375, 2003. [8] N. Roos, A. ten Tije, and C. Witteveen.",
                "A protocol for multi-agent diagnosis with spatially distributed knowledge.",
                "In Proceedings of AAMAS03, 2003. [9] N. Roos, A. ten Tije, and C. Witteveen.",
                "Reaching diagnostic agreement in multiagent diagnosis.",
                "In Proceedings of AAMAS04, 2004. [10] T. Takahashi, Y. Kaneda, and N. Ito.",
                "Preliminary study - using robocuprescue simulations for disasters prevention.",
                "In Proceedings of SRMED2004, 2004.",
                "The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 1005"
            ],
            "original_annotated_samples": [
                "Paris-Dauphine, France {bourgne,hette,maudet,pinson}@lamsade.dauphine.fr ABSTRACT We investigate the properties of a <br>multiagent system</br> where each (distributed) agent locally perceives its environment.",
                "INTRODUCTION We consider a <br>multiagent system</br> where each (distributed) agent locally perceives its environment, and we assume that some unexpected event occurs in that system.",
                "CONCLUSION This paper has investigated the properties of a <br>multiagent system</br> where each (distributed) agent locally perceives its environment, and tries to reach consistency with other agents despite severe communication restrictions."
            ],
            "translated_annotated_samples": [
                "Investigamos las propiedades de un <br>sistema multiagente</br> donde cada agente (distribuido) percibe localmente su entorno.",
                "INTRODUCCIÓN Consideramos un <br>sistema multiagente</br> donde cada agente (distribuido) percibe localmente su entorno, y asumimos que ocurre un evento inesperado en ese sistema.",
                "CONCLUSIÓN Este documento ha investigado las propiedades de un <br>sistema multiagente</br> donde cada agente (distribuido) percibe localmente su entorno e intenta alcanzar consistencia con otros agentes a pesar de severas restricciones de comunicación."
            ],
            "translated_text": "Refinamiento de hipótesis bajo restricciones de comunicación topológica ∗ Gauvain Bourgne, Gael Hette, Nicolas Maudet y Suzanne Pinson LAMSADE, Univ. Investigamos las propiedades de un <br>sistema multiagente</br> donde cada agente (distribuido) percibe localmente su entorno. Tras la percepción de un evento inesperado, cada agente calcula localmente su hipótesis favorita e intenta propagarla a otros agentes, intercambiando hipótesis y argumentos de apoyo (observaciones). Sin embargo, también asumimos que las oportunidades de comunicación están severamente limitadas y cambian dinámicamente. En este artículo, investigamos principalmente la convergencia de dichos sistemas hacia la consistencia global. Primero demostramos que (para una amplia clase de protocolos que definiremos), las restricciones de comunicación inducidas por la topología no impedirán la convergencia del sistema, bajo la condición de que la dinámica del sistema garantice que ningún agente quedará aislado para siempre, y que los agentes tengan tiempo ilimitado para la computación y el intercambio de argumentos. Dado que esta suposición no se puede hacer en la mayoría de las situaciones, establecimos un marco experimental con el objetivo de comparar la eficiencia y efectividad relativa de diferentes protocolos de interacción para el intercambio de hipótesis. Estudiamos una situación crítica que implica a varios agentes que intentan escapar de un edificio en llamas. Los resultados reportados aquí proporcionan algunas ideas sobre el diseño de un protocolo óptimo para el refinamiento de hipótesis en este contexto. Categorías y Descriptores de Asignaturas I.2.11 [Inteligencia Artificial]: Inteligencia Artificial Distribuida-Sistemas Multiagente Términos Generales Teoría, Experimentación 1. INTRODUCCIÓN Consideramos un <br>sistema multiagente</br> donde cada agente (distribuido) percibe localmente su entorno, y asumimos que ocurre un evento inesperado en ese sistema. Si cada agente calcula solo localmente su hipótesis preferida, es natural asumir que los agentes buscarán coordinar y refinar sus hipótesis confrontando sus observaciones con otros agentes. Si, además, las oportunidades de comunicación están severamente limitadas (por ejemplo, los agentes solo pueden comunicarse cuando están lo suficientemente cerca de otro agente) y cambian dinámicamente (por ejemplo, los agentes pueden cambiar sus ubicaciones), se vuelve crucial diseñar cuidadosamente protocolos que permitan a los agentes converger hacia algún estado deseado de consistencia global. En este documento presentamos algunas condiciones suficientes sobre la dinámica del sistema y sobre las estructuras de protocolo/estrategia que permiten garantizar esa propiedad, y estudiamos experimentalmente algunos contextos donde (algunas de) estas suposiciones se relajan. Si bien los problemas de diagnóstico son uno de los clásicos venerables en la tradición de la IA, sus contrapartes multiagentes han atraído atención mucho más recientemente. Roos y sus colegas [8, 9] en particular estudian una situación en la que un número de entidades distribuidas intentan llegar a un diagnóstico global satisfactorio de todo el sistema. Ellos muestran en particular que el número de mensajes necesarios para establecer este diagnóstico global está destinado a ser prohibitivo, a menos que la comunicación se mejore con algún protocolo adecuado. Sin embargo, no imponen restricciones a las opciones de comunicación de los agentes, ni asumen que el sistema es dinámico. Los beneficios de mejorar la comunicación con información de apoyo para hacer que la convergencia a un estado global deseado de un sistema sea más eficiente, a menudo se ha planteado en la literatura. Esta es, por ejemplo, una de las ideas principales que subyacen al enfoque de negociación basado en argumentos [7], donde el estado deseado es un compromiso entre agentes con preferencias conflictivas. Sin embargo, muchos de estos trabajos parten del supuesto de que este enfoque es beneficioso para comenzar y estudian los aspectos técnicos del problema (o en su lugar enfatizan otras ventajas de utilizar la argumentación). Excepciones notables son las obras de [3, 4, 2, 5], que estudiaron en contextos diferentes al nuestro la eficiencia de la argumentación. El resto del documento es el siguiente. La Sección 2 especifica los elementos básicos de nuestro modelo, y la Sección 3 continúa presentando los diferentes protocolos y estrategias utilizados por los agentes para intercambiar hipótesis y observaciones. Ponemos especial atención en enfatizar claramente las condiciones de la dinámica del sistema y los protocolos/estrategias que se explotarán en el resto del documento. La sección 4 detalla uno de los principales resultados del artículo, a saber, el hecho de que bajo las condiciones mencionadas, las restricciones que imponemos en la topología no impedirán la convergencia del sistema hacia la consistencia global, siempre y cuando ningún agente se pierda completamente para siempre en el sistema, y se permita un tiempo ilimitado para la computación y el intercambio de argumentos. Si bien las condiciones en los protocolos y estrategias son bastante suaves, también es claro que estos requisitos del sistema parecen mucho más problemáticos, incluso francamente poco realistas en situaciones críticas donde se abogan precisamente por enfoques distribuidos. Para obtener una imagen más clara de la situación inducida cuando el tiempo es un factor crítico, hemos establecido un marco experimental que presentamos y discutimos en la Sección 5. La situación crítica implica a varios agentes que intentan escapar de un edificio en llamas. Los resultados reportados aquí muestran que la efectividad del intercambio de argumentos depende crucialmente de la naturaleza del edificio, y proporcionan algunas ideas sobre el diseño de un protocolo óptimo para el refinamiento de hipótesis en este contexto. CONCEPTOS BÁSICOS Comenzamos definiendo los elementos básicos de nuestro sistema. Deje que O sea el conjunto (potencialmente infinito) de observaciones posibles. Suponemos que los sensores de nuestros agentes son perfectos, por lo tanto, las observaciones son seguras. Sea H el conjunto de hipótesis, incierto y revisable. Sea Cons(h, O) la relación de consistencia, una relación binaria entre una hipótesis h ∈ H y un conjunto de observaciones O ⊆ O. En la mayoría de los casos, Cons se referirá a la relación de consistencia clásica, sin embargo, podemos sobrecargar su significado y añadir algunas propiedades adicionales a esa relación (en cuyo caso lo mencionaremos). El entorno puede incluir cierta dinámica y cambiar con el transcurso del tiempo. Definimos a continuación secuencias de puntos temporales para tratar con ello: Definición 1 (Secuencia de puntos temporales). Una secuencia de puntos temporales t1, t2, . . . , tn de t es un conjunto ordenado de puntos temporales t1, t2, . . . , tn tal que t1 ≥ t y ∀i ∈ [1, n − 1], ti+1 ≥ ti. Tomamos un sistema poblado por n agentes a1, . . . , an. Cada agente se define como una tupla F, Oi, hi, donde: • F, el conjunto de hechos, conocimiento común a todos los agentes. • Oi ∈ 2O, el conjunto de observaciones realizadas por el agente hasta el momento. Suponemos una memoria perfecta, por lo tanto, este conjunto crece de forma monótona. • hi ∈ H, la hipótesis favorita del agente. Una noción clave que rige la formación de hipótesis es la de consistencia, definida a continuación: Definición 2 (Consistencia). Decimos que: • Un agente es consistente (Cons(ai)) si y solo si Cons(hi, Oi) (es decir, su hipótesis es consistente con su conjunto de observaciones). • Un agente ai es consistente con un agente compañero aj si y solo si Cons(ai) y Cons(hi, Oj) (es decir, este agente es consistente y su hipótesis puede explicar el conjunto de observaciones del otro agente). • Dos agentes ai y aj son mutuamente consistentes (MCons(ai, aj)) si y solo si Cons(ai, aj) y Cons(aj, ai). • Un sistema es consistente si y solo si para todo (i, j) ∈ [1, n]2 se cumple que MCons(ai, aj). Para garantizar su consistencia, cada agente está equipado con una maquinaria de razonamiento abstracto que llamaremos la función de explicación Eh. Esta función (determinística) toma un conjunto de observaciones y devuelve una única hipótesis preferida (2O → H). Suponemos que h = Eh(O) para ser consistente con O por definición de Eh, por lo que usar esta función en su conjunto de observaciones para determinar su hipótesis favorita es una forma segura para que el agente logre consistencia. Sin embargo, cabe destacar que una hipótesis no necesita ser generada por Eh para ser consistente con un conjunto de observaciones. Como ejemplo concreto de tal función, y una de las principales inspiraciones de este trabajo, se puede citar el sistema de razonamiento Theorist [6], siempre y cuando esté acoplado con un filtro que seleccione una teoría preferida entre las inicialmente seleccionadas por Theorist. También hay que tener en cuenta que hi solo puede ser modificado como consecuencia de la aplicación de Eh. Nos referimos a esto como la autonomía del agente: ningún otro agente puede imponer directamente una hipótesis dada a un agente. Como consecuencia, solo una nueva observación (ya sea una nueva percepción o una observación comunicada por otro agente) puede resultar en una modificación de su hipótesis preferida hi (pero no necesariamente, por supuesto). Finalmente definimos una propiedad del sistema que utilizaremos en el resto del artículo: Definición 3 (Percepciones Acotadas). Un sistema implica una percepción limitada para los agentes si y solo si existe un n0 tal que para todo t, la unión de N observaciones realizadas por los agentes es menor o igual a n0. (Es decir, el número de observaciones a realizar por los agentes en el sistema no es infinito.) Ahora necesitamos ver cómo evolucionarán e interactuarán estos agentes en su entorno. En nuestro contexto, los agentes evolucionan en un entorno dinámico, y asumimos clásicamente el siguiente ciclo del sistema: 1. Dinámica del entorno: el entorno evoluciona de acuerdo con las reglas definidas de la dinámica del sistema. 2. Paso de percepción: los agentes obtienen percepciones del entorno. Estas percepciones suelen ser parciales (por ejemplo, el agente solo puede ver una parte de un mapa). 3. Paso de razonamiento: los agentes comparan la percepción con las predicciones, buscan explicaciones para las diferencias (potenciales), refinan su hipótesis, y sacan nuevas conclusiones. 4. Paso de comunicación: los agentes pueden comunicar hipótesis y observaciones con otros agentes a través de un protocolo definido. Cualquier agente solo puede estar involucrado en una comunicación con otro agente en el paso 5. Paso de acción: los agentes realizan un razonamiento práctico utilizando los modelos obtenidos de los pasos anteriores y seleccionan una acción. Ellos pueden modificar el entorno ejecutándolo. La comunicación de los agentes estará aún más restringida por consideraciones topológicas. En un momento dado, un agente solo podrá comunicarse con un número de vecinos. Sus conexiones con estos otros agentes pueden The Sixth Intl. La Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) evoluciona con su situación en el entorno. Normalmente, un agente solo puede comunicarse con agentes que puede percibir, pero se podría imaginar la evolución de restricciones topológicas en la comunicación basadas en una red de comunicaciones entre agentes donde los enlaces no siempre están activos. En nuestro sistema, los agentes podrán comunicarse entre sí. Sin embargo, debido a las restricciones topológicas mencionadas anteriormente, no podrán comunicarse con ningún agente en ningún momento. Con quién puede comunicarse un agente se definirá dinámicamente (por ejemplo, esto puede ser consecuencia de que los agentes estén lo suficientemente cerca para ponerse en contacto). Denotaremos de forma abstracta por C(ai, aj, t) la propiedad de comunicación, es decir, el hecho de que los agentes ai y aj puedan comunicarse en el tiempo t (nota que se asume que esta relación es simétrica, pero por supuesto no transitiva). Ahora estamos en posición de definir dos propiedades esenciales de nuestro sistema. Definición 4 (Camino Temporal). Existe un camino de comunicación temporal en el horizonte tf (denotado Ltf (aI, aJ)) entre ai y aj si y solo si existe una secuencia de puntos temporales t1, t2, ..., tn desde tf y una secuencia de agentes k1, k2, ..., kn tal que (i) C(aI, ak1, t1), (ii) C(akn, aJ, tn+1), (iii) ∀i ∈ [1, n], C(aki, aki+1, ti). Intuitivamente, lo que esta propiedad dice es que es posible encontrar un camino temporal en el futuro que permitiría vincular al agente ai y aj a través de una secuencia de agentes intermedios. Ten en cuenta que los puntos temporales no necesariamente son sucesivos, y que la secuencia de agentes puede involucrar a los mismos agentes varias veces. Definición 5 (Conexidad Temporal). Un sistema es temporalmente conexo si y solo si ∀t ∀(i, j)∈[1, n]2 Lt(ai, aj). En resumen, un sistema temporalmente conexo garantiza que cualquier agente podrá comunicarse con cualquier otro agente, sin importar cuánto tiempo pueda llevar hacerlo, en cualquier momento. Dicho de otra manera, nunca sucede que un agente esté aislado para siempre de otro agente del sistema. A continuación discutiremos en detalle cómo la comunicación tiene lugar concretamente en nuestro sistema. Recuerda que en este documento, solo consideramos el caso de intercambios bilaterales (un agente solo puede hablar con otro agente) y también asumimos que cualquier agente solo puede participar en un intercambio en una ronda dada. 3. PROTOCOLOS Y ESTRATEGIAS En esta sección, discutimos los requisitos de los protocolos de interacción que rigen el intercambio de mensajes entre agentes, y proporcionamos algunos ejemplos de la implementación de dichos protocolos. Para aclarar la presentación, distinguimos dos niveles: el nivel local, que se ocupa de la regulación de los intercambios bilaterales; y el nivel global, que regula principalmente la forma en que los agentes pueden participar realmente en una conversación. En cada nivel, separamos lo que está especificado por el protocolo y lo que se deja a las estrategias de los agentes. Protocolos y estrategias locales Comenzamos inspeccionando los protocolos y estrategias locales que regularán la comunicación entre los agentes del sistema. Al limitarnos a la comunicación bilateral, estos protocolos simplemente implicarán a dos agentes. Dicho protocolo tendrá que cumplir con un requisito básico para ser satisfactorio: consistencia (CONS) - un protocolo local debe garantizar la consistencia mutua de los agentes al finalizar (lo que implica, por supuesto, la finalización). Figura 1: Un Protocolo de Intercambio de Hipótesis [1] Un ejemplo de dicho protocolo es el protocolo descrito en [1] que se muestra en la Fig. 1. Para ilustrar aún más cómo dicho protocolo puede ser utilizado por agentes, proporcionamos algunos detalles sobre una posible estrategia: al recibir una hipótesis h1 (proponer(h1) o contra-proponer(h1)) de a1, el agente a2 se encuentra en el estado 2 y tiene las siguientes respuestas posibles: contraejemplo (si el agente conoce un ejemplo que contradice la hipótesis, o no está explicado por esta hipótesis), desafío (si el agente carece de evidencia para aceptar esta hipótesis), contra-proponer (si el agente está de acuerdo con la hipótesis pero prefiere otra), o aceptar (si es tan buena como su hipótesis favorita). Esta estrategia garantiza, entre otras propiedades, la eventual consistencia lógica mutua de los agentes involucrados [1]. Protocolo global El protocolo global regula la forma en que se iniciarán los intercambios bilaterales entre agentes. En cada turno, los agentes enviarán simultáneamente una solicitud ponderada para comunicarse con otros agentes. Este peso es un valor que mide la disposición de los agentes para conversar con el agente objetivo (en la práctica, esto puede basarse en diferentes heurísticas, pero haremos algunas suposiciones sobre las estrategias de los agentes, ver más abajo). Enviar una solicitud de este tipo es una especie de compromiso condicional para el agente. Un agente que envía una solicitud ponderada se compromete a entablar una conversación con el objetivo si no recibe y acepta otra solicitud por sí mismo. Una vez que se hayan recibido todas las solicitudes, cada agente responde con un aceptar o un rechazar. Al responder con un aceptar, un agente se compromete plenamente a participar en la conversación con el remitente. Por lo tanto, solo puede enviar una aceptación en una ronda dada, ya que un agente solo puede participar en una conversación por paso de tiempo. Cuando se hayan recibido todas las respuestas, cada agente que reciba una aceptación puede iniciar una conversación utilizando el protocolo local o enviar una cancelación si ha aceptado otra solicitud. Al final de todos los intercambios bilaterales, los agentes involucrados en la conversación son descartados del protocolo. Entonces cada uno de los agentes restantes reenvía una solicitud y el proceso se repite hasta que no se envíen más solicitudes. Estrategia global Ahora definimos cuatro requisitos para las estrategias utilizadas por los agentes, dependiendo de su rol en el protocolo: dos se refieren al rol del solicitante (cómo decidir quién es el 1000 The Sixth Intl. La Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) ¿con qué agente desea comunicarse? Los otros dos con el rol de respondedor (¿cómo decidir qué solicitud de comunicación aceptar o no?). • Disposición para resolver inconsistencias (SOLVE): los agentes desean comunicarse con cualquier otro agente a menos que sepan que son mutuamente consistentes. • Enfoque en resolver inconsistencias (FOCUS): los agentes no solicitan comunicarse con un agente con el que saben que son mutuamente consistentes. • Disposición para comunicarse (COMM): los agentes no pueden rechazar una solicitud de comunicación ponderada, a menos que acaben de recibir o enviar una solicitud con un peso mayor. • Compromiso con la solicitud de comunicación (REQU): los agentes no pueden aceptar una solicitud de comunicación ponderada si ellos mismos han enviado una solicitud de comunicación con un peso mayor. Por lo tanto, no cancelarán su solicitud a menos que hayan recibido una solicitud comunicacional con mayor peso. Ahora la estructura del protocolo, junto con las propiedades COMM+REQU, garantizan que una solicitud solo puede ser rechazada si su agente objetivo se involucra en comunicación con otro agente. Supongamos de hecho que el agente ai quiere comunicarse con aj enviando una solicitud con peso w. COMM garantiza que un agente que reciba una solicitud ponderada aceptará esta comunicación, aceptará una comunicación con un peso mayor o esperará la respuesta a una solicitud con un peso mayor. Esto asegura que la solicitud con peso máximo será aceptada y no cancelada (ya que REQU asegura que un agente que envía una solicitud solo puede cancelarla si acepta otra solicitud con un peso mayor). Por lo tanto, al menos dos agentes participarán en una conversación por ronda del protocolo global. Como el protocolo asegura que ai puede reenviar su solicitud mientras aj no está ocupado en una conversación, llegará un momento en el que aj deberá participar en una conversación, ya sea con ai u otro agente. Estos requisitos se refieren al envío y aceptación de solicitudes, pero los agentes también necesitan alguna estrategia de atribución de peso. Describimos a continuación una estrategia altruista, utilizada en nuestros experimentos. Siendo cooperativo, un agente puede querer conocer más los deseos de comunicación de otros agentes para mejorar la asignación general de intercambios a los agentes. Se añade entonces un paso de solicitud de contexto al protocolo global. Antes de enviar su solicitud ponderada elegida, los agentes asignan un peso a todos los agentes con los que están dispuestos a comunicarse, de acuerdo con algunos factores internos. En el caso más simple, este peso será 1 para todos los agentes con los que el agente no esté seguro de ser mutuamente consistentes (garantizando SOLVE), sin considerar a otros agentes para la comunicación (garantizando FOCUS). El agente luego envía una solicitud de contexto a todos los agentes con los que se considera la comunicación. Esta solicitud también proporciona información sobre el remitente (lista de comunicaciones consideradas junto con su peso). Después de recibir todas las solicitudes de contexto, los agentes responderán con un rechazo si ya están ocupados en una conversación (en cuyo caso, el agente solicitante no considerará comunicarse con ellos en este turno), o con una información que brinde al solicitante información sobre las solicitudes que ha enviado y recibido. Cuando se hayan recibido todas las respuestas, cada agente puede calcular el peso de todas las solicitudes que le conciernen. Lo hace restando del peso de su solicitud el peso de todas las solicitudes relacionadas con él o su objetivo (es decir, el peso final de la solicitud de ai a aj es Wi,j = wi,j + wj,i - ( Σ k∈R(i)-{j} wi,k + Σ k∈S(i)-{j} wk,i + Σ k∈R(j)-{i} wj,k + Σ k∈S(j)-{i} wk,j) donde wi,j es el peso de la solicitud de ai a aj, R(i) es el conjunto de índices de agentes que han recibido una solicitud de ai y S(i) es el conjunto de índices de agentes que han enviado una solicitud a ai). Luego envía finalmente una solicitud ponderada a los agentes que maximizan este peso (o esperan una solicitud) según lo descrito en el protocolo global. 4. (CONDICIONAL) CONVERGENCIA HACIA LA COHERENCIA GLOBAL En esta sección mostraremos que los requisitos relacionados con los protocolos y estrategias recién discutidos serán suficientes para garantizar que el sistema eventualmente convergerá hacia la coherencia global, bajo ciertas condiciones. Primero demostramos que, si dos agentes no son mutuamente consistentes en algún momento, entonces necesariamente habrá un momento en el futuro en el que un agente aprenderá una nueva observación, ya sea porque es nueva para el sistema, o al aprenderla de otro agente. Lema 1. Sea S un sistema poblado por n agentes a1, a2, ..., an, temporalmente conectados e involucrando percepciones limitadas para estos agentes. Sea n1 la suma de las cardinalidades de la intersección de los conjuntos de observaciones emparejados. (n1 = P (i,j)∈[1,n]2 |Oi ∩ Oj|) Sea n2 la cardinalidad de la unión de todos los conjuntos de observaciones de los agentes. (n2 = | ∪N i=1 Oi|). Si ¬MCons(ai, aj) en el tiempo t0, necesariamente existe un tiempo t > t0 tal que ya sea n1 o n2 aumentarán. Prueba. Supongamos que exista un tiempo t0 y unos índices (i, j) tal que ¬MCons(ai, aj). Utilizaremos mt0 = P (k,l)∈[1,n]2 εComm(ak, al, t0) donde εComm(ak, al, t0) = 1 si ak y al han comunicado al menos una vez desde t0, y 0 en caso contrario. La conexidad temporal garantiza que existen t1, ..., tm+1 y k1, ..., km tal que. C(ai, ak1 , t1), C(akm , aj, tm+1), y ∀p ∈ [1, m], C(akp , akp+1 , tp). Claramente, si MCons(ai, ak1), MCons(akm, aj) y ∀p, MCons(akp, akp+1), tenemos MCons(ai, aj) lo cual contradice nuestra hipótesis (siendo MCons transitivo, MCons(ai, ak1)∧MCons(ak1, ak2) implica que MCons(ai, ak2) y así sucesivamente hasta MCons(ai, akm)∧MCons(akm, aj) lo cual implica MCons(ai, aj)). Al menos dos agentes son necesariamente inconsistentes (¬MCons(ai, ak1), o ¬MCons(akm, aj), o ∃p0 t.q. ¬MCons(akp0, akp0+1)). Que ak y al sean estos dos vecinos en un momento t > t0 1. La propiedad SOLVE asegura que ya sea ak o al enviará una solicitud de comunicación al otro agente en el tiempo t. Como se mostró anteriormente, esto a su vez garantiza que al menos uno de estos agentes estará involucrado en una comunicación. Entonces hay dos posibilidades: (caso i) ak y al se comunican en el tiempo t. En este caso, sabemos que ¬MCons(ak, al). Esto y la propiedad CONS aseguran que al menos uno de los agentes debe cambiar su 1. Estrictamente hablando, la transitividad de MCons solo asegura que ak y al son inconsistentes en un tiempo t ≥ t0 que puede ser diferente del tiempo t en el que pueden comunicarse. Pero si se vuelven consistentes entre t y t (o inconsistentes entre t y t), significa que al menos uno de ellos ha cambiado su hipótesis entre t y t, es decir, después de t0. Podemos entonces aplicar el razonamiento del caso iib. El Sexto Internacional. La Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 1001 hipótesis, lo cual a su vez, dado que los agentes son autónomos, implica al menos un intercambio de observación. Pero entonces |Ok ∩Ol| está destinado a aumentar: n1(t) > n1(t0). (caso ii) ak se comunica con ap en el tiempo t. Entonces tenemos de nuevo dos posibilidades: (caso iia) ak y ap no se comunicaron desde t0. Pero luego εComm(ak, ap, t0) tenía valor 0 y toma valor 1. Por lo tanto, mt0 aumenta. (caso iib) ak y ap se comunicaron en algún momento t0 > t0. La propiedad CONS del protocolo asegura que MCons(ak, ap) en ese momento. Ahora el hecho de que se comuniquen y se ENFOQUEN implica que al menos uno de ellos cambió su hipótesis en el ínterin. El hecho de que los agentes sean autónomos implica a su vez que una nueva observación (percibida o recibida de otro agente) necesariamente provocó este cambio. El último caso garantizaría la existencia de un tiempo t > t0 y un agente aq tal que |Op ∩ Oq| o |Ok ∩ Oq| aumenten en 1 en ese momento (lo que implica que n1(t) > n1(t0)). El caso anterior significa que el agente obtiene una nueva percepción en el tiempo t. Si esa observación era desconocida en el sistema antes, entonces n2(t) > n2(t0). Si algún agente aq ya conocía esta observación antes, entonces tanto Op ∩ Oq como Ok ∩ Oq aumentan en 1 en el tiempo t (lo que implica que n1(t) > n1(t0)). Por lo tanto, ¬MCons(ai, aj) en el tiempo t0 garantiza que, o bien: −∃t > t0 t.q. n1(t ) > n1(t0); o −∃t > t0 t.q. n2(t ) > n2(t0); o −∃t > t0 t.q. mt0 aumenta en 1 en el tiempo t. Al iterar el razonamiento con t (pero manteniendo t0 como la referencia de tiempo para mt0), podemos eliminar el tercer caso (mt0 es un entero y está limitado por n2, lo que significa que después de un máximo de n2 iteraciones, necesariamente estaremos en uno de los otros dos casos). Como resultado, hemos demostrado que si ¬MCons(ai, aj) en el tiempo t0, necesariamente habrá un tiempo t tal que ya sea n1 o n2 aumentarán. Teorema 1 (Consistencia global). Sea S un sistema poblado por n agentes a1, a2, ..., an, temporalmente conectados e involucrando percepciones limitadas para estos agentes. Sea Cons(ai, aj) una propiedad de consistencia transitiva. Entonces, cualquier protocolo y estrategias que cumplan con las propiedades CONS, SOLVE, FOCUS, COMM y REQU garantizan que el sistema convergerá hacia la consistencia global. Prueba. Por el bien de la contradicción, asumamos que ∃I, J ∈ [1, N] tal que ∀t, ∃t0 > t, tal que ¬Cons(aI , aJ , t0). Usando el lema, esto implica que ∃t > t0 tal que n1(t) > n1(t0) o n2(t) > n2(t0). Pero podemos aplicar el mismo razonamiento tomando t = t, lo que nos daría t1 > t > t0 tal que ¬Cons(aI , aJ , t1), lo que nos da t > t1 tal que n1(t) > n1(t1) o n2(t) > n2(t1). Mediante iteraciones sucesivas podemos construir una secuencia t0, t1, ..., tn, que puede dividirse en dos subsecuencias t0, t1, ...tn y t0, t1, ..., tn tal que n1(t0) < n1(t1) < ... < n1(tn) y n2(t0) < n2(t1) < ... < n2(tn). Una de estas subsecuencias tiene que ser infinita. Sin embargo, n1(ti) y n2(ti) son estrictamente crecientes, enteros y acotados, lo que implica que ambos son finitos. Contradicción. Lo que el resultado anterior muestra esencialmente es que, en un sistema donde ningún agente estará aislado del resto de los agentes para siempre, solo se necesitan suposiciones muy leves sobre los protocolos y estrategias utilizados por los agentes para garantizar la convergencia hacia la consistencia del sistema en una cantidad finita de tiempo (aunque podría llevar mucho tiempo). Desafortunadamente, en muchas situaciones críticas, no será posible asumir esta conexión temporal. Dado que enfoques distribuidos como el abogado en este documento suelen presentarse como una buena manera de abordar problemas de confiabilidad o problemas de dependencia de un centro que son de suma importancia en estas aplicaciones críticas, ciertamente resulta interesante explorar más a fondo cómo se comportaría un sistema de este tipo cuando relajamos esta suposición. ESTUDIO EXPERIMENTAL Este experimento implica agentes tratando de escapar de un edificio en llamas. El entorno se describe como una cuadrícula espacial con un conjunto de paredes y (afortunadamente) algunas salidas. El tiempo y el espacio se consideran discretos. El tiempo se divide en rondas. Los agentes se localizan por su posición en la cuadrícula espacial. Estos agentes pueden moverse y comunicarse con otros agentes. En una ronda, un agente puede moverse una celda en cualquiera de las cuatro direcciones cardinales, siempre y cuando no esté bloqueado por una pared. En esta aplicación, los agentes se comunican con cualquier otro agente (pero, recuerda, solo uno) siempre y cuando este agente esté a la vista y aún no hayan intercambiado su hipótesis actual favorita. De repente, se desata un incendio en estas instalaciones. A partir de este momento, el fuego se propaga. En cada ronda, en cada caso donde haya fuego, el fuego se propaga en las cuatro direcciones. Sin embargo, el fuego no puede propagarse a través de una pared. Si el fuego se propaga en un caso donde un agente está posicionado, ese agente se quema y se considera muerto. Por supuesto, ya no puede moverse ni comunicarse. Si un agente llega a una salida, se considera que está a salvo y ya no puede ser quemado. Los agentes conocen el entorno y las reglas que rigen la dinámica de este entorno, es decir, conocen el mapa así como las reglas de propagación del fuego previamente descritas. También perciben este entorno localmente, pero no pueden ver más allá de 3 casos en cualquier dirección. Las paredes también bloquean la línea de visión, impidiendo que los agentes vean detrás de ellas. Dentro de su campo de visión, pueden ver a otros agentes y si los casos que ven están en llamas. Todas estas percepciones están memorizadas. Mostramos ahora cómo se instancia el marco abstracto presentado en el documento. • O = {Fire(x, y, t), NoFire(x, y, t), Agent(ai, x, y, t)} Las observaciones pueden ser positivas (o ∈ P(O) si ∃h ∈ H tal que h |= o) o negativas (o ∈ N(O) si ∃h ∈ H tal que h |= ¬o). • H={FireOrigin(x1, y1, t1)∧...∧FireOrigin(xl, yl, tl)} Las hipótesis son conjunciones de Orígenes de Fuego. • La relación de consistencia Cons(h, O) satisface: - coherencia: ∀o ∈ N(O), h |= ¬o. - completitud: ∀o ∈ P(O), h |= o. - minimalidad: Para todo h ∈ H, si h es coherente y completo para O, entonces h es preferido a h de acuerdo con la relación de preferencia (h ≤p h). Selecciona primero el número mínimo de orígenes, luego el más reciente (estrategia menos preemptiva [6]), y luego utiliza un ranking fijo arbitrario para discriminar ex-aequo. La relación resultante es un orden total, por lo tanto, la minimalidad implica que habrá un único h tal que Cons(O, h) para un O dado. Esto a su vez significa que MCons(ai, aj) si y solo si Cons(ai), Cons(aj) y hi = hj. Esta relación es entonces transitiva y simétrica. 1002 El Sexto Internacional. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) • Eh toma O como argumento y devuelve min≤p de la hipótesis coherente y completa para O 5.1 Evaluación Experimental Clásicamente evaluaremos la efectividad y eficiencia de diferentes protocolos de interacción (ver, por ejemplo, [3, 4]). La efectividad de un protocolo se determinará por la proporción de agentes que sobreviven al incendio respecto al número inicial de agentes involucrados en el experimento. Si este valor es alto, el protocolo ha sido efectivo para propagar la información y/o para que los agentes refinen sus hipótesis y determinen la mejor manera de salir. Eficiencia de un protocolo. Por lo general, el uso de información de apoyo implicará una sobrecarga de comunicación. Aquí asumiremos que la eficiencia de un protocolo dado está caracterizada por el flujo de datos inducido por este protocolo. En este documento solo discutiremos este aspecto con respecto a los protocolos locales. La medida principal que utilizaremos aquí es el tamaño total promedio de los mensajes intercambiados por los agentes por intercambio (teniendo en cuenta tanto el número de mensajes como el tamaño real de los mensajes, ya que podría ser que los mensajes resulten ser muy grandes, conteniendo por ejemplo un gran número de observaciones, lo que podría contrarrestar un bajo número de mensajes). 5.2 Configuraciones Experimentales Las configuraciones experimentales elegidas son las siguientes: • Topología ambiental: El rendimiento de la propagación de la información está altamente condicionado por la topología del entorno. Las habilidades de percepción de los agentes dependen de la apertura del entorno. Con un gran número de paredes, las percepciones de los agentes están limitadas, al igual que el número de posibles comunicaciones entre agentes, mientras que un entorno abierto proporcionará posibilidades óptimas de percepción y propagación de información. Por lo tanto, proponemos un índice topológico (ver abajo) como base común para caracterizar los entornos (mapas) utilizados durante las experimentaciones. El índice topológico (TI) es la proporción entre el número de celdas que pueden ser percibidas por los agentes sumadas desde todas las posiciones posibles, dividido por el número de celdas que serían percibidas desde las mismas posiciones pero sin paredes. (Cuanto más cercano a 1, más abierto es el entorno). También utilizaremos dos medidas adicionales, más clásicas [10]: la longitud del camino característico (CPL) y el coeficiente de agrupamiento (CC). • Número de agentes: la propagación de la información también depende del número inicial de agentes involucrados durante una experimentación. Por ejemplo, cuantos más agentes haya, más potenciales comunicaciones existen. Esto significa que habrá más potencial de propagación, pero también que la restricción de intercambio bilateral será más crucial. 3 El CPL es la mediana de las medias de las longitudes de los caminos más cortos que conectan cada nodo con todos los demás nodos. 4 caracterizando el grado de aislamiento de una región de un entorno en términos de accesibilidad (número de caminos aún utilizables para llegar a esta región). Mapa T.I. (%) C.P.L. C.C. 69-1 69,23 4,5 0,69 69-2 68,88 4,38 0,65 69-3 69,80 4,25 0,67 53-1 53,19 5,6 0,59 53-2 53,53 6,38 0,54 53-3 53,92 6,08 0,61 38-1 38,56 8,19 0,50 38-2 38,56 7,3 0,50 38-3 38,23 8,13 0,50 Tabla 1: Características Topológicas de los Mapas • Posiciones iniciales de los agentes- Las posiciones iniciales de los agentes tienen una influencia significativa en el comportamiento general de una instancia de nuestro sistema: estar cerca de una salida facilitará (en general) la escapatoria. 5.3 Entornos experimentales Elegimos realizar experimentos en tres índices topológicos muy diferentes (69% para entornos abiertos, 53% para entornos mixtos y 38% para entornos tipo laberinto). Figura 2: Dos mapas (izquierda: IT=69%, derecha IT=38%) Diseñamos tres mapas diferentes para cada índice (la Fig. 2 muestra dos de ellos), conteniendo el mismo número máximo de agentes (máximo 36 agentes) con una densidad máxima de un agente por celda, el mismo número de salidas y un origen de incendio similar (por ejemplo, tiempo y posición de inicio). Los tres mapas diferentes de un índice dado están diseñados de la siguiente manera. El primer plano es un modelo de un piso de un edificio existente. El segundo mapa tiene el mismo perímetro, salidas y origen del fuego que el primero, pero la cantidad y ubicación de las paredes son diferentes (las ubicaciones de las paredes son diseñadas por una heurística que crea paredes de forma aleatoria en la cuadrícula espacial de manera que no se creen habitaciones completamente cerradas y que ninguna salida quede bloqueada). El tercer mapa se caracteriza por un recinto geométrico en el que la ubicación de las paredes también está diseñada con la heurística mencionada anteriormente. La Tabla 1 resume las diferentes medidas topológicas que caracterizan estos mapas diferentes. Vale la pena señalar que los valores confirman la relevancia de TI (los mapas con un alto TI tienen un bajo CPL y un alto CC). Sin embargo, el CPL y el CC permiten refinar aún más la diferencia entre los mapas, por ejemplo, entre 53-1 y 53-2). 5.4 Resultados Experimentales Para cada trío de mapas definidos como se mencionó anteriormente, llevamos a cabo los mismos experimentos. En cada experimento, la sociedad difiere en cuanto a su proporción inicial de agentes involucrados, desde el 1% hasta el 100%. Esta proporción inicial representa el porcentaje de agentes involucrados con respecto al número máximo posible de agentes. Para cada mapa y cada proporción inicial, la Sexta Internacional. En la Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) seleccionamos aleatoriamente 100 ubicaciones iniciales de agentes diferentes. Para cada una de esas ubicaciones diferentes ejecutamos el sistema una vez para cada protocolo de interacción diferente. La efectividad de la comunicación y argumentación El primer experimento que hemos establecido tiene como objetivo probar cuán efectivo es el intercambio de hipótesis (IH), y en particular cómo los aspectos topológicos afectarán esta efectividad. Para hacerlo, hemos calculado la proporción de mejora ofrecida por ese protocolo sobre una situación en la que los agentes simplemente no podían comunicarse (sin comunicación). Para obtener más información sobre en qué medida el intercambio de hipótesis fue realmente crucial, también probamos un protocolo mucho menos elaborado que consistía en intercambios de observaciones simples (OE). Más precisamente, este protocolo requiere que cada agente almacene cualquier observación inesperada que perciba, y los agentes simplemente intercambian sus respectivas listas de observaciones cuando discuten. En este caso, el protocolo local es diferente (nota en particular que no garantiza consistencia mutua), pero el protocolo global permanece igual (con la única excepción de que la motivación de los agentes para comunicarse es sincronizar su lista de observaciones, no sus hipótesis). Si este protocolo es como máximo tan efectivo como HE, tiene la ventaja de ser más eficiente (esto es obvio en cuanto al número de mensajes, que se limitará a 2, menos directo en lo que respecta al tamaño de los mensajes, pero la observación general de que el intercambio de observaciones se puede ver como una versión simplificada del desafío es útil para ver esto). Los resultados de estos experimentos se informan en la Figura 3. Figura 3: Ganancia de la proporción de efectividad comparativa de los protocolos cuando la proporción de agentes aumenta. La primera observación que debe hacerse es que la comunicación mejora la efectividad del proceso, y esta proporción aumenta a medida que el número de agentes crece en el sistema. La segunda lección que aprendemos aquí es que la cercanía relativamente hace que la comunicación sea más efectiva que la falta de comunicación. Los mapas que muestran un T.I. del 38% están constantemente por encima de los otros dos, y el 53% sigue siendo ligeramente pero significativamente mejor que el 69%. Sin embargo, estas curvas también sugieren, quizás sorprendentemente, que HE supera a OE precisamente en aquellas situaciones donde la ganancia de la relación es menos importante (la única diferencia notable ocurre en mapas bastante abiertos donde T.I. es del 69%). Esto se puede explicar de la siguiente manera: cuando un mapa está abierto, los agentes tienen muchos posibles candidatos de explicación, y la argumentación se vuelve útil para discriminar entre ellos. Cuando un mapa es laberíntico, hay menos posibles explicaciones para un evento inesperado. Importancia del Protocolo Global El segundo conjunto de experimentos busca evaluar la importancia del diseño del protocolo global. Probamos nuestro protocolo contra un protocolo de difusión local (LB). La difusión local significa que todos los agentes vecinos percibidos por un agente estarán involucrados en una comunicación con ese agente en una ronda dada, aliviando la restricción de una sola comunicación por agente. Esto nos proporciona un límite superior aproximado sobre la posible ganancia de ratio en el sistema (para un protocolo local dado). Nuevamente, evaluamos la ganancia de la relación inducida por ese LB sobre nuestro HE clásico, para las tres clases diferentes de mapas. Los resultados se informan en la Figura 4. Figura 4: Ganancia de la proporción de transmisión local sobre el intercambio de hipótesis. Tenga en cuenta que la ganancia de la proporción es 0 cuando la proporción de agentes es del 5%, lo cual se explica fácilmente por el hecho de que corresponde a situaciones que involucran solo a dos agentes. Primero observamos que todas las clases de mapas muestran un aumento en la ganancia de la proporción a medida que aumenta el número de agentes: la ganancia alcanza entre el 10 y el 20%, dependiendo de la clase de mapas considerada. Si se compara esto con la mejora reportada en el experimento anterior, parece ser de la misma magnitud. Esto ilustra que el diseño del protocolo global no puede ser ignorado, especialmente cuando la proporción de agentes es alta. Sin embargo, también observamos que las curvas de ganancia de la proporción de efectividad tienen formas muy diferentes en ambos casos: la ganancia inducida por la precisión del protocolo local aumenta muy rápidamente con la proporción de agentes, mientras que la curva es muy suave para el global. Ahora observemos con más cuidado los resultados reportados aquí: la curva correspondiente a una TI del 53% está por encima de la correspondiente al 38%. Esto se debe a que cuanto más abierta sea un mapa, más oportunidades hay de comunicarse con más de un agente (y por lo tanto beneficiarse de la difusión). Sin embargo, también observamos que la curva para el 69% está por debajo de la del 53%. Esto se explica de la siguiente manera: en el caso del 69%, la ganancia potencial en términos de agentes sobrevivientes es mucho menor, porque nuestros protocolos ya ofrecen resultados bastante eficientes de todos modos (alcanzando rápidamente el 90%, ver Fig. 3). Una regla general podría ser que cuando el número de agentes es pequeño, se debe prestar especial atención al local 1004 de la Sexta Internacional. En el caso de que el número de agentes sea pequeño, uno puede utilizar el protocolo de la Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07), mientras que cuando ese número es grande, se debe diseñar cuidadosamente uno global (a menos que el mapa sea tan abierto que el protocolo ya sea casi óptimamente eficiente). La eficiencia de los protocolos. El experimento final reportado aquí se centra en el análisis de la eficiencia de los protocolos. Aquí analizamos el tamaño medio de la totalidad de los mensajes que son intercambiados por agentes (tamaño medio de intercambios, en resumen) utilizando los siguientes protocolos: HE, OE y dos protocolos variantes. El primero es un protocolo de intercambio de hipótesis restringidas (RHE) intermediario. RHE es el siguiente: no implica ningún desafío ni contraoferta, lo que significa que los agentes no pueden cambiar su rol durante el protocolo (esto difiere de RE en ese aspecto). En resumen, RHE permite a un agente agotar las críticas de sus socios, y eventualmente este socio adoptará la hipótesis del agente. Ten en cuenta que esto significa que la autonomía del agente no se conserva aquí (ya que un agente esencialmente aceptará cualquier hipótesis que no pueda socavar), con la esperanza de que la ganancia en eficiencia sea lo suficientemente significativa como para compensar una pérdida en efectividad. El segundo protocolo de variante es un protocolo completo de intercambio de observaciones (COE). COE utiliza los mismos principios que OE, pero incluye además todos los ejemplos críticos negativos (nofire) en el intercambio (dando así todos los ejemplos utilizados como argumentos por el protocolo de intercambio de hipótesis), mejorando así la efectividad. Los resultados para el mapa 69-1 se muestran en la Figura 5. Figura 5: Tamaño medio de los intercambios. Primero podemos observar el hecho de que el orden de los protocolos, desde el menos eficiente hasta el más eficiente, es COE, HE, RHE y luego OE. ÉL siendo más eficiente que COE demuestra que el proceso de argumentación gana eficiencia al seleccionar cuándo es necesario proporcionar ejemplos negativos, los cuales tienen menos impacto que los positivos en nuestro entorno de prueba específico. Sin embargo, al comunicar hipótesis antes de proporcionar observaciones para respaldarla (HE) en lugar de dar directamente las observaciones más cruciales (OE), el proceso de argumentación duplica el tamaño de los intercambios de datos. Es el costo de garantizar la consistencia al final del intercambio (una propiedad que OE no admite). También es significativo el hecho de que el tamaño promedio de los intercambios es ligeramente mayor cuando el número de agentes es pequeño. Esto se explica por el hecho de que en estos casos solo unos pocos agentes tienen información relevante en su posesión, y que necesitarán comunicarse mucho para llegar a un punto de vista común de la situación. Cuando el número de agentes aumenta, este conocimiento se distribuye entre más agentes que necesitan discusiones más cortas para llegar a una consistencia mutua. Como consecuencia, la ganancia relativa en eficiencia de usar RHE parece ser mejor cuando el número de agentes es pequeño: cuando es alto, difícilmente discutirán de todos modos. Finalmente, vale la pena notar que la desviación estándar para estos experimentos es bastante alta, lo que significa que la conversación no converge hacia ningún patrón estereotípico. 6. CONCLUSIÓN Este documento ha investigado las propiedades de un <br>sistema multiagente</br> donde cada agente (distribuido) percibe localmente su entorno e intenta alcanzar consistencia con otros agentes a pesar de severas restricciones de comunicación. En particular, hemos expuesto condiciones que permiten la convergencia e investigado experimentalmente una situación típica donde esas condiciones no pueden cumplirse. Hay muchas posibles extensiones a este trabajo, la primera siendo investigar más a fondo las propiedades de diferentes protocolos globales pertenecientes a la clase que identificamos, y su influencia en el resultado. Existen en particular muchas heurísticas, altamente dependientes del contexto del estudio, que podrían intuitivamente arrojar resultados interesantes (en nuestro estudio, seleccionar al destinatario en función de lo que se pueda inferir de sus acciones observadas podría ser una de esas heurísticas). Un candidato obvio para problemas a largo plazo se refiere a la relajación de la suposición de un sensor perfecto. 7. REFERENCIAS [1] G. Bourgne, N. Maudet y S. Pinson. Cuando los agentes comunican hipótesis en situaciones críticas. En Actas de DALT-2006, mayo de 2006. [2] P. Harvey, C. F. Chang y A. Ghose. Búsqueda distribuida basada en soporte: un nuevo enfoque para el procesamiento de restricciones multiagente. En Actas de AAMAS06, 2006. [3] H. Jung y M. Tambe. Argumentación como satisfacción de restricciones distribuida: Aplicaciones y resultados. En Actas de AGENTS01, 2001. [4] N. C. Karunatillake y N. R. Jennings. ¿Vale la pena discutir? En Actas de ArgMAS 2004, 2004. [5] S. Onta˜n´on y E. Plaza. Argumentos y contraejemplos en la deliberación conjunta basada en casos. En Actas de ArgMAS-2006, mayo de 2006. [6] D. Poole. Explicación y predicción: Una arquitectura para el razonamiento por defecto y abductivo. Inteligencia Computacional, 5(2):97-110, 1989. [7] I. Rahwan, S. D. Ramchurn, N. R. Jennings, P. McBurney, S. Parsons y L. Sonenberg. Negociación basada en argumentos. La revisión de Ingeniería del Conocimiento, 4(18):345-375, 2003. [8] N. Roos, A. ten Tije y C. Witteveen. Un protocolo para el diagnóstico multiagente con conocimiento distribuido espacialmente. En Actas de AAMAS03, 2003. [9] N. Roos, A. ten Tije y C. Witteveen. Alcanzando acuerdo diagnóstico en el diagnóstico multiagente. En Actas de AAMAS04, 2004. [10] T. Takahashi, Y. Kaneda y N. Ito. Estudio preliminar: utilizando simulaciones de RoboCupRescue para la prevención de desastres. En Actas de SRMED2004, 2004. El Sexto Internacional. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 1005 ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "favoured hypothesis": {
            "translated_key": "hipótesis favorita",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Hypotheses Refinement under Topological Communication Constraints ∗ Gauvain Bourgne, Gael Hette, Nicolas Maudet, and Suzanne Pinson LAMSADE, Univ.",
                "Paris-Dauphine, France {bourgne,hette,maudet,pinson}@lamsade.dauphine.fr ABSTRACT We investigate the properties of a multiagent system where each (distributed) agent locally perceives its environment.",
                "Upon perception of an unexpected event, each agent locally computes its <br>favoured hypothesis</br> and tries to propagate it to other agents, by exchanging hypotheses and supporting arguments (observations).",
                "However, we further assume that communication opportunities are severely constrained and change dynamically.",
                "In this paper, we mostly investigate the convergence of such systems towards global consistency.",
                "We first show that (for a wide class of protocols that we shall define), the communication constraints induced by the topology will not prevent the convergence of the system, at the condition that the system dynamics guarantees that no agent will ever be isolated forever, and that agents have unlimited time for computation and arguments exchange.",
                "As this assumption cannot be made in most situations though, we then set up an experimental framework aiming at comparing the relative efficiency and effectiveness of different interaction protocols for hypotheses exchange.",
                "We study a critical situation involving a number of agents aiming at escaping from a burning building.",
                "The results reported here provide some insights regarding the design of optimal protocol for hypotheses refinement in this context.",
                "Categories and Subject Descriptors I.2.11 [Artificial Intelligence]: Distributed Artificial Intelligence-Multiagent systems General Terms Theory, Experimentation 1.",
                "INTRODUCTION We consider a multiagent system where each (distributed) agent locally perceives its environment, and we assume that some unexpected event occurs in that system.",
                "If each agent computes only locally its <br>favoured hypothesis</br>, it is only natural to assume that agents will seek to coordinate and refine their hypotheses by confronting their observations with other agents.",
                "If, in addition, the communication opportunities are severely constrained (for instance, agents can only communicate when they are close enough to some other agent), and dynamically changing (for instance, agents may change their locations), it becomes crucial to carefully design protocols that will allow agents to converge to some desired state of global consistency.",
                "In this paper we exhibit some sufficient conditions on the system dynamics and on the protocol/strategy structures that allow to guarantee that property, and we experimentally study some contexts where (some of) these assumptions are relaxed.",
                "While problems of diagnosis are among the venerable classics in the AI tradition, their multiagent counterparts have much more recently attracted some attention.",
                "Roos and colleagues [8, 9] in particular study a situation where a number of distributed entities try to come up with a satisfying global diagnosis of the whole system.",
                "They show in particular that the number of messages required to establish this global diagnosis is bound to be prohibitive, unless the communication is enhanced with some suitable protocol.",
                "However, they do not put any restrictions on agents communication options, and do not assume either that the system is dynamic.",
                "The benefits of enhancing communication with supporting information to make convergence to a desired global state of a system more efficient has often been put forward in the literature.",
                "This is for instance one of the main idea underlying the argumentation-based negotiation approach [7], where the desired state is a compromise between agents with conflicting preferences.",
                "Many of these works however make the assumption that this approach is beneficial to start with, and study the technical facets of the problem (or instead emphasize other advantages of using argumentation).",
                "Notable exceptions are the works of [3, 4, 2, 5], which studied in contexts different from ours the efficiency of argumentation.",
                "The rest of the paper is as follows.",
                "Section 2 specifies the basic elements of our model, and Section 3 goes on to presenting the different protocols and strategies used by the agents to exchange hypotheses and observations.",
                "We put special attention at clearly emphasizing the conditions on the system dynamics and protocols/strategies that will be exploited in the rest of the paper.",
                "Section 4 details one of 998 978-81-904262-7-5 (RPS) c 2007 IFAAMAS the main results of the paper, namely the fact that under the aforementioned conditions, the constraints that we put on the topology will not prevent the convergence of the system towards global consistency, at the condition that no agent ever gets completely lost forever in the system, and that unlimited time is allowed for computation and argument exchange.",
                "While the conditions on protocols and strategies are fairly mild, it is also clear that these system requirements look much more problematic, even frankly unrealistic in critical situations where distributed approaches are precisely advocated.",
                "To get a clearer picture of the situation induced when time is a critical factor, we have set up an experimental framework that we introduce and discuss in Section 5.",
                "The critical situation involves a number of agents aiming at escaping from a burning building.",
                "The results reported here show that the effectiveness of argument exchange crucially depends upon the nature of the building, and provide some insights regarding the design of optimal protocol for hypotheses refinement in this context. 2.",
                "BASIC NOTIONS We start by defining the basic elements of our system.",
                "Environment Let O be the (potentially infinite) set of possible observations.",
                "We assume the sensors of our agents to be perfect, hence the observations to be certain.",
                "Let H be the set of hypotheses, uncertain and revisable.",
                "Let Cons(h, O) be the consistency relation, a binary relation between a hypothesis h ∈ H and a set of observations O ⊆ O.",
                "In most cases, Cons will refer to classical consistency relation, however, we may overload its meaning and add some additional properties to that relation (in which case we will mention it).",
                "The environment may include some dynamics, and change over the course of time.",
                "We define below sequences of time points to deal with it: Definition 1 (Sequence of time points).",
                "A sequence of time points t1, t2, . . . , tn from t is an ordered set of time points t1, t2, . . . , tn such that t1 ≥ t and ∀i ∈ [1, n − 1], ti+1 ≥ ti.",
                "Agent We take a system populated by n agents a1, . . . , an.",
                "Each agent is defined as a tuple F, Oi, hi , where: • F, the set of facts, common knowledge to all agents. • Oi ∈ 2O , the set of observations made by the agent so far.",
                "We assume a perfect memory, hence this set grows monotonically. • hi ∈ H, the favourite hypothesis of the agent.",
                "A key notion governing the formation of hypotheses is that of consistency, defined below: Definition 2 (Consistency).",
                "We say that: • An agent is consistent (Cons(ai)) iff Cons(hi, Oi) (that is, its hypothesis is consistent with its observation set). • An agent ai consistent with a partner agent aj iff Cons(ai) and Cons(hi, Oj) (that is, this agent is consistent and its hypothesis can explain the observation set of the other agent). • Two agents ai and aj are mutually consistent (MCons(ai, aj)) iff Cons(ai, aj) and Cons(aj, ai). • A system is consistent iff ∀(i, j)∈[1, n]2 it is the case that MCons(ai, aj).",
                "To ensure its consistency, each agent is equipped with an abstract reasoning machinery that we shall call the explanation function Eh.",
                "This (deterministic) function takes a set of observation and returns a single prefered hypothesis (2O → H).",
                "We assume h = Eh(O) to be consistent with O by definition of Eh, so using this function on its observation set to determine its favourite hypothesis is a sure way for the agent to achieve consistency.",
                "Note however that an hypothesis does not need to be generated by Eh to be consistent with an observation set.",
                "As a concrete example of such a function, and one of the main inspiration of this work, one can cite the Theorist reasoning system [6] -as long as it is coupled with a filter selecting a single prefered theory among the ones initially selected by Theorist.",
                "Note also that hi may only be modified as a consequence of the application Eh.",
                "We refer to this as the autonomy of the agent: no other agent can directly impose a given hypothesis to an agent.",
                "As a consequence, only a new observation (being it a new perception, or an observation communicated by a fellow agent) can result in a modification of its prefered hypothesis hi (but not necessarily of course).",
                "We finally define a property of the system that we shall use in the rest of the paper: Definition 3 (Bounded Perceptions).",
                "A system involves a bounded perception for agents iff ∃n0 s.t. ∀t| ∪N i=1 Oi| ≤ n0. (That is, the number of observations to be made by the agents in the system is not infinite.)",
                "Agent Cycle Now we need to see how these agents will evolve and interact in their environment.",
                "In our context, agents evolve in a dynamic environment, and we classicaly assume the following system cycle: 1.",
                "Environment dynamics: the environment evolves according to the defined rules of the system dynamics. 2.",
                "Perception step : agents get perceptions from the environment.",
                "These perceptions are typically partial (e.g. the agent can only see a portion of a map). 3.",
                "Reasoning step: agents compare perception with predictions, seek explanations for (potential) difference(s), refine their hypothesis, draw new conclusions. 4.",
                "Communication step: agents can communicate hypotheses and observations with other agents through a defined protocol.",
                "Any agent can only be involved in one communication with another agent by step. 5.",
                "Action step: agents do some practical reasoning using the models obtained from the previous steps and select an action.",
                "They can then modify the environment by executing it.",
                "The communication of the agents will be further constrained by topological consideration.",
                "At a given time, an agent will only be able to communicate with a number of neighbours.",
                "Its connexions with these others agents may The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 999 evolve with its situation in the environment.",
                "Typically, an agent can only communicate with agents that it can sense, but one could imagine evolving topological constraints on communication based on a network of communications between agents where the links are not always active.",
                "Communication In our system, agents will be able to communicate with each other.",
                "However, due to the aforementionned topological constraints, they will not be able to communicate with any agents at anytime.",
                "Who an agent can communicate with will be defined dynamically (for instance, this can be a consequence of the agents being close enough to get in touch).",
                "We will abstractly denote by C(ai, aj, t) the communication property, in other words, the fact that agents ai and aj can communicate at time t (note that this relation is assumed to be symetric, but of course not transitive).",
                "We are now in a position to define two essential properties of our system.",
                "Definition 4 (Temporal Path).",
                "There exists a temporal communication path at horizon tf (noted Ltf (aI , aJ )) between ai and aj iff there exists a sequence of time points t1, t2, . . . , tn from tf and a sequence of agents k1, k2, . . . , kn s.t. (i) C(aI , ak1 , t1), (ii) C(akn , aJ , tn+1), (iii) ∀i ∈ [1, n], C(aki , aki+1 , ti) Intuitively, what this property says is that it is possible to find a temporal path in the future that would allow to link agent ai and aj via a sequence of intermediary agents.",
                "Note that the time points are not necessarily successive, and that the sequence of agents may involve the same agents several times.",
                "Definition 5 (Temporal Connexity).",
                "A system is temporaly connex iff ∀t ∀(i, j)∈[1, n]2 Lt(ai, aj) In short, a temporaly connex system guarantees that any agent will be able to communicate with any other agents, no matter how long it might take to do so, at any time.",
                "To put it another way, it is never the case that an agent will be isolated for ever from another agent of the system.",
                "We will next discuss the detail of how communication concretely takes place in our system.",
                "Remember that in this paper, we only consider the case of bilateral exchanges (an agent can only speak to a single other agent), and that we also assume that any agent can only engage in a single exchange in a given round. 3.",
                "PROTOCOLS AND STRATEGIES In this section, we discuss the requirements of the interaction protocols that govern the exchange of messages between agents, and provide some example instantiation of such protocols.",
                "To clarify the presentation, we distinguish two levels: the local level, which is concerned with the regulation of bilateral exchanges; and the global level,which essentially regulates the way agents can actually engage into a conversation.",
                "At each level, we separate what is specified by the protocol, and what is left to agents strategies.",
                "Local Protocol and Strategies We start by inspecting local protocols and strategies that will regulate the communication between the agents of the system.",
                "As we limit ourselves to bilateral communication, these protocols will simply involve two agents.",
                "Such protocol will have to meet one basic requirement to be satisfying. • consistency (CONS)- a local protocol has to guarantee the mutual consistency of agents upon termination (which implies termination of course).",
                "Figure 1: A Hypotheses Exchange Protocol [1] One example such protocol is the protocol described in [1] that is pictured in Fig. 1.",
                "To further illustrate how such protocol can be used by agents, we give some details on a possible strategy: upon receiving a hypothesis h1 (propose(h1) or counterpropose(h1)) from a1, agent a2 is in state 2 and has the following possible replies: counterexample (if the agent knows an example contradicting the hypothesis, or not explained by this hypothesis), challenge (if the agents lacks evidence to accept this hypothesis), counterpropose (if the agent agrees with the hypothesis but prefers another one), or accept (if it is indeed as good as its favourite hypothesis).",
                "This strategy guarantees, among other properties, the eventual mutual logical consistency of the involved agents [1].",
                "Global Protocol The global protocol regulates the way bilateral exchanges will be initiated between agents.",
                "At each turn, agents will concurrently send one weighted request to communicate to other agents.",
                "This weight is a value measuring the agents willingness to converse with the targeted agent (in practice, this can be based on different heuristics, but we shall make some assumptions on agents strategies, see below).",
                "Sending such a request is a kind of conditional commitment for the agent.",
                "An agent sending a weighted request commits to engage in conversation with the target if he does not receive and accept himself another request.",
                "Once all request have been received, each agent replies with either an acccept or a reject.",
                "By answering with an accept, an agent makes a full commitment to engage in conversation with the sender.",
                "Therefore, it can only send one accept in a given round, as an agent can only participate in one conversation per time step.",
                "When all response have been received, each agent receiving an accept can either initiate a conversation using the local protocol or send a cancel if it has accepted another request.",
                "At the end of all the bilateral exchanges, the agents engaged in conversation are discarded from the protocol.",
                "Then each of the remaining agents resends a request and the process iterates until no more requests are sent.",
                "Global Strategy We now define four requirements for the strategies used by agents, depending on their role in the protocol: two are concerned with the requestee role (how to decide who the 1000 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) agent wishes to communicate with? ), the other two with the responder role (how to decide which communication request to accept or not?). • Willingness to solve inconsistancies (SOLVE)-agents want to communicate with any other agents unless they know they are mutually consistent. • Focus on solving inconsistencies (FOCUS)-agents do not request communication with an agent with whom they know they are mutually consistent. • Willingness to communicate (COMM)-agents cannot refuse a weighted communication request, unless they have just received or send a request with a greater weight. • Commitment to communication request (REQU)agents cannot accept a weighted communication request if they have themselves sent a communication request with a greater weight.",
                "Therefore, they will not cancel their request unless they have received a communicational request with greater weight.",
                "Now the protocol structure, together with the properties COMM+REQU, ensure that a request can only be rejected if its target agent engages in communication with another agent.",
                "Suppose indeed that agent ai wants to communicate with aj by sending a request with weight w. COMM guarantees that an agent receiving a weighted request will either accept this communication, accept a communication with a greater weight or wait for the answer to a request with a greater weight.",
                "This ensures that the request with maximal weight will be accepted and not cancelled (as REQU ensures that an agent sending a request can only cancel it if he accepts another request with greater weight).",
                "Therefore at least two agents will engage in conversation per round of the global protocol.",
                "As the protocol ensures that ai can resend its request while aj is not engaged in a conversation, there will be a turn in which aj must engage in a conversation, either with ai or another agent.",
                "These requirements concern request sending and acceptation, but agents also need some strategy of weight attribution.",
                "We describe below an altruist strategy, used in our experiments.",
                "Being cooperative, an agent may want to know more of the communication wishes of other agents in order to improve the overall allocation of exchanges to agents.",
                "A context request step is then added to the global protocol.",
                "Before sending their chosen weighted request, agents attribute a weight to all agents they are prepared to communicate with, according to some internal factors.",
                "In the simplest case, this weight will be 1 for all agent with whom the agent is not sure of being mutually consistent (ensuring SOLVE), other agent being not considered for communication (ensuring FOCUS).",
                "The agent then sends a context request to all agents with whom communication is considered.",
                "This request also provides information about the sender (list of considered communications along with their weight).",
                "After reception of all the context requests, agents will either reply with a deny, iff they are already engaged in a conversation (in which case, the requesting agent will not consider communication with them anymore in this turn), or an inform giving the requester information about the requests it has sent and received.",
                "When all replies have been received, each agent can calculate the weight of all requests concerning it.",
                "It does so by substracting from the weight of its request the weight of all requests concerning either it or its target (that is, the final weight of the request from ai to aj is Wi,j = wi,j +wj,i − ( P k∈R(i)−{j} wi,k + P k∈S(i)−{j} wk,i + P k∈R(j)−{i} wj,k + P k∈S(j)−{i} wk,j) where wi,j is the weight of the request of ai to aj, R(i) is the set of indice of agents having received a request from ai and S(i) is the set of indice of agents having send a request to ai).",
                "It then finally sends a weighted request to the agents who maximise this weight (or wait for a request) as described in the global protocol. 4. (CONDITIONAL) CONVERGENCE TO GLOBAL CONSISTENCY In this section we will show that the requirements regarding protocols and strategies just discussed will be sufficient to ensure that the system will eventually converge towards global consistency, under some conditions.",
                "We first show that, if two agents are not mutually consistent at some time, then there will be necessarily a time in the future such that an agent will learn a new observation, being it because it is new for the system, or by learning it from another agent.",
                "Lemma 1.",
                "Let S be a system populated by n agents a1, a2, ..., an, temporaly connex, and involving bounded perceptions for these agents.",
                "Let n1 be the sum of cardinalities of the intersection of pairwise observation sets. (n1 = P (i,j)∈[1,n]2 |Oi ∩ Oj|) Let n2 be the cardinality of the union of all agents observations sets. (n2 = | ∪N i=1 Oi|).",
                "If ¬MCons(ai, aj) at time t0, there is necessarily a time t > t0 s.t. either n1 or n2 will increase.",
                "Proof.",
                "Suppose that there exist a time t0 and indices (i, j) s.t. ¬MCons(ai, aj).",
                "We will use mt0 = P (k,l)∈[1,n]2 εComm(ak, al, t0) where εComm(ak, al, t0) = 1 if ak and al have communicated at least once since t0, and 0 otherwise.",
                "Temporal connexity guarantees that there exist t1, ..., tm+1 and k1, ..., km s.t.",
                "C(ai, ak1 , t1), C(akm , aj, tm+1), and ∀p ∈ [1, m], C(akp , akp+1 , tp).",
                "Clearly, if MCons(ai, ak1 ), MCons(akm , aj) and ∀p, MCons(akp , akp+1 ), we have MCons(ai, aj) which contradicts our hypothesis (MCons being transitive, MCons(ai, ak1 )∧MCons(ak1 , ak2 ) implies that MCons(ai, ak2 ) and so on till MCons(ai, akm )∧ MCons(akm , aj) which implies MCons(ai, aj) ).",
                "At least two agents are then necessarily inconsistent (¬MCons(ai, ak1 ), or ¬MCons(akm , aj), or ∃p0 t.q. ¬MCons(akp0 , akp0+1 )).",
                "Let ak and al be these two neighbours at a time t > t0 1 .",
                "The SOLVE property ensures that either ak or al will send a communication request to the other agent at time t .",
                "As shown before, this in turn ensures that at least one of these agents will be involved in a communication.",
                "Then there are two possibilities: (case i) ak and al communicate at time t .",
                "In this case, we know that ¬MCons(ak, al).",
                "This and the CONS property ensures that at least one of the agents must change its 1 Strictly speaking, the transitivity of MCons only ensure that ak and al are inconsistent at a time t ≥ t0 that can be different from the time t at which they can communicate.",
                "But if they become consistent between t and t (or inconsistent between t and t ), it means that at least one of them have changed its hypothesis between t and t , that is, after t0.",
                "We can then apply the reasoning of case iib.",
                "The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 1001 hypothesis, which in turn, since agents are autonomous, implies at least one exchange of observation.",
                "But then |Ok ∩Ol| is bound to increase: n1(t ) > n1(t0). (case ii) ak communicates with ap at time t .",
                "We then have again two possibilities: (case iia) ak and ap did not communicate since t0.",
                "But then εComm(ak, ap, t0) had value 0 and takes value 1.",
                "Hence mt0 increases. (case iib) ak and ap did communicate at some time t0 > t0.",
                "The CONS property of the protocol ensures that MCons(ak, ap) at that time.",
                "Now the fact that they communicate and FOCUS implies that at least one of them did change its hypothesis in the meantime.",
                "The fact that agents are autonomous implies in turn that a new observation (perceived or received from another agent) necessarily provoked this change.",
                "The latter case would ensure the existence of a time t > t0 and an agent aq s.t. either |Op ∩Oq| or |Ok ∩Oq| increases of 1 at that time (implying n1(t ) > n1(t0)).",
                "The former case means that the agent gets a new perception o at time t .",
                "If that observation was unknown in the system before, then n2(t ) > n2(t0).",
                "If some agent aq already knew this observation before, then either Op ∩ Oq or Ok ∩ Oq increases of 1 at time t (which implies that n1(t ) > n1(t0)).",
                "Hence, ¬MCons(ai, aj) at time t0 guarantees that, either: −∃t > t0 t.q. n1(t ) > n1(t0); or −∃t > t0 t.q. n2(t ) > n2(t0); or −∃t > t0 t.q. mt0 increases of 1 at time t .",
                "By iterating the reasoning with t (but keeping t0 as the time reference for mt0 ), we can eliminate the third case (mt0 is integer and bounded by n2 , which means that after a maximum of n2 iterations, we necessarily will be in one of two other cases.)",
                "As a result, we have proven that if ¬MCons(ai, aj) at time t0, there is necessarily a time t s.t. either n1 or n2 will increase.",
                "Theorem 1 (Global consistency).",
                "Let S be a system populated by n agents a1, a2, ..., an, temporaly connex, and involving bounded perceptions for these agents.",
                "Let Cons(ai, aj) be a transitive consistency property.",
                "Then any protocol and strategies satisfying properties CONS, SOLVE, FOCUS, COMM and REQU guarantees that the system will converge towards global consistency.",
                "Proof.",
                "For the sake of contradiction, let us assume ∃I, J ∈ [1, N] s.t. ∀t, ∃t0 > t, t.q. ¬Cons(aI , aJ , t0).",
                "Using the lemma, this implies that ∃t > t0 s.t. either n1(t ) > n1(t0) or n2(t ) > n2(t0).",
                "But we can apply the same reasoning taking t = t , which would give us t1 > t > t0 s.t. ¬Cons(aI , aJ , t1), which gives us t > t1 s.t. either n1(t ) > n1(t1) or n2(t ) > n2(t1).",
                "By successive iterations we can then construct a sequence t0, t1, ..., tn, which can be divided in two sub-sequences t0, t1, ...tn and t0 , t1 , ..., tn s.t. n1(t0) < n1(t1) < ... < n1(tn) and n2(t0 ) < n2(t1 ) < ... < n2(tn).",
                "One of these sub-sequences has to be infinite.",
                "However, n1(ti) and n2(ti ) are strictly growing, integer, and bounded, which implies that both are finite.",
                "Contradiction.",
                "What the previous result essentially shows is that, in a system where no agent will be isolated from the rest of the agents for ever, only very mild assumptions on the protocols and strategies used by agents suffice to guarantee convergence towards system consistency in a finite amount of time (although it might take very long).",
                "Unfortunately, in many critical situations, it will not be possible to assume this temporal connexity.",
                "As distributed approaches as the one advocated in this paper are precisely often presented as a good way to tackle problems of reliability or problems of dependence to a center that are of utmost importance in these critical applications, it is certainly interesting to further explore how such a system would behave when we relax this assumption. 5.",
                "EXPERIMENTAL STUDY This experiment involves agents trying to escape from a burning building.",
                "The environment is described as a spatial grid with a set of walls and (thankfully) some exits.",
                "Time and space are considered discrete.",
                "Time is divided in rounds.",
                "Agents are localised by their position on the spatial grid.",
                "These agents can move and communicate with other agents.",
                "In a round, an agent can move of one cell in any of the four cardinal directions, provided it is not blocked by a wall.",
                "In this application, agents communicate with any other agent (but, recall, a single one) given that this agent is in view, and that they have not yet exchanged their current <br>favoured hypothesis</br>.",
                "Suddenly, a fire erupts in these premises.",
                "From this moment, the fire propagates.",
                "Each round, for each cases where there is fire, the fire propagates in the four directions.",
                "However, the fire cannot propagate through a wall.",
                "If the fire propagates in a case where an agent is positioned, that agent burns and is considered dead.",
                "It can of course no longer move nor communicate.",
                "If an agent gets to an exit, it is considered saved, and can no longer be burned.",
                "Agents know the environment and the rules governing the dynamics of this environment, that is, they know the map as well as the rules of fire propagation previously described.",
                "They also locally perceive this environment, but cannot see further than 3 cases away, in any direction.",
                "Walls also block the line of view, preventing agents from seeing behind them.",
                "Within their sight, they can see other agents and whether or not the cases they see are on fire.",
                "All these perceptions are memorised.",
                "We now show how this instantiates the abstract framework presented the paper. • O = {Fire(x, y, t), NoFire(x, y, t), Agent(ai, x, y, t)} Observations can then be positive (o ∈ P(O) iff ∃h ∈ H s.t. h |= o) or negative (o ∈ N(O) iff ∃h ∈ H s.t. h |= ¬o). • H={FireOrigin(x1, y1, t1)∧...∧FireOrigin(xl, yl, tl)} Hypotheses are conjunctions of FireOrigins. • Cons(h, O) consistency relation satisfies: - coherence : ∀o ∈ N(O), h |= ¬o. - completeness : ∀o ∈ P(O), h |= o. - minimality : For all h ∈ H, if h is coherent and complete for O, then h is prefered to h according to the preference relation (h ≤p h ).2 2 Selects first the minimal number of origins, then the most recent (least preemptive strategy [6]), then uses some arbitrary fixed ranking to discriminate ex-aequo.",
                "The resulting relation is a total order, hence minimality implies that there will be a single h s.t.Cons(O, h) for a given O.",
                "This in turn means that MCons(ai, aj) iff Cons(ai), Cons(aj), and hi = hj.",
                "This relation is then transitive and symmetric. 1002 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) • Eh takes O as argument and returns min≤p of the coherent and complete hypothesis for O 5.1 Experimental Evaluation We will classically (see e.g. [3, 4]) assess the effectiveness and efficiency of different interaction protocols.",
                "Effectiveness of a protocol The proportion of agents surviving the fire over the initial number of agents involved in the experiment will determine the effectiveness of a given protocol.",
                "If this value is high, the protocol has been effective to propagate the information and/or for the agents to refine their hypotheses and determine the best way to the exit.",
                "Efficiency of a protocol Typically, the use of supporting information will involve a communication overhead.",
                "We will assume here that the efficiency of a given protocol is characterised by the data flow induced by this protocol.",
                "In this paper we will only discuss this aspect wrt. local protocols.",
                "The main measure that we shall then use here is the mean total size of messages that are exchanged by agents per exchange (hence taking into account both the number of messages and the actual size of the messages, because it could be that messages happen to be very big, containing e.g. a large number of observations, which could counter-balance a low number of messages). 5.2 Experimental Settings The chosen experimental settings are the following: • Environmental topology- Performances of information propagation are highly constrained by the environment topology.",
                "The perception skills of the agents depend on the openness of the environment.",
                "With a large number of walls the perceptions of agents are limited, and also the number of possible inter-agent communications, whereas an open environment will provide optimal possibilities of perception and information propagation.",
                "Thus, we propose a topological index (see below) as a common basis to charaterize the environments (maps) used during experimentations.",
                "The topological index (TI) is the ratio of the number of cells that can be perceived by agents summed up from all possible positions, divided by the number of cells that would be perceived from the same positions but without any walls. (The closer to 1, the more open the environment).",
                "We shall also use two additional, more classical [10], measures: the characteristic path length3 (CPL) and the clustering coefficient4 (CC). • Number of agents- The propagation of information also depends on the initial number of agents involved during an experimentation.",
                "For instance, the more agents, the more potential communications there is.",
                "This means that there will be more potential for propagation, but also that the bilateral exchange restriction will be more crucial. 3 The CPL is the median of the means of the shortest path lengths connecting each node to all other nodes. 4 characterising the isolation degree of a region of an environment in terms of acessibility (number of roads still usable to reach this region).",
                "Map T.I. (%) C.P.L.",
                "C.C. 69-1 69,23 4,5 0,69 69-2 68,88 4,38 0,65 69-3 69,80 4,25 0,67 53-1 53,19 5,6 0,59 53-2 53,53 6,38 0,54 53-3 53,92 6,08 0,61 38-1 38,56 8,19 0,50 38-2 38,56 7,3 0,50 38-3 38,23 8,13 0,50 Table 1: Topological Characteristics of the Maps • Initial positions of the agents- Initial positions of the agents have a significant influence on the overall behavior of an instance of our system: being close from an exit will (in general) ease the escape. 5.3 Experimental environments We choose to realize experiments on three very different topological indexes (69% for open environments, 53% for mixed environments, and 38% for labyrinth-like environments).",
                "Figure 2: Two maps (left: TI=69%, right TI=38%) We designed three different maps for each index (Fig. 2 shows two of them), containing the same maximum number of agents (36 agents max.) with a maximum density of one agent per cell, the same number of exits and a similar fire origin (e.g. starting time and position).",
                "The three differents maps of a given index are designed as follows.",
                "The first map is a model of an existing building floor.",
                "The second map has the same enclosure, exits and fire origin as the first one, but the number and location of walls are different (wall locations are designed by an heuristic which randomly creates walls on the spatial grid such that no fully closed rooms are created and that no exit is closed).",
                "The third map is characterised by geometrical enclosure in wich walls location is also designed with the aforementioned heuristic.",
                "Table 1 summarizes the different topological measures characterizing these different maps.",
                "It is worth pointing out that the values confirm the relevance of TI (maps with a high TI have a low CPL and a high CC.",
                "However the CPL and CC allows to further refine the difference between the maps, e.g. between 53-1 and 53-2). 5.4 Experimental Results For each triple of maps defined as above we conduct the same experiments.",
                "In each experiment, the society differs in terms of its initial proportion of involved agents, from 1% to 100%.",
                "This initial proportion represents the percentage of involved agents with regards to the possible maximum number of agents.",
                "For each map and each initial proportion, The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 1003 we select randomly 100 different initial agents locations.",
                "For each of those different locations we execute the system one time for each different interaction protocol.",
                "Effectiveness of Communication and Argumentation The first experiment that we set up aims at testing how effective is hypotheses exchange (HE), and in particular how the topological aspects will affect this effectiveness.",
                "In order to do so, we have computed the ratio of improvement offered by that protocol over a situation where agents could simply not communicate (no comm).",
                "To get further insights as to what extent the hypotheses exchange was really crucial, we also tested a much less elaborated protocol consisting of mere observation exchanges (OE).",
                "More precisely, this protocol requires that each agent stores any unexpected observation that it perceives, and agents simply exchange their respective lists of observations when they discuss.",
                "In this case, the local protocol is different (note in particular that it does not guarantee mutual consistency), but the global protocol remains the same (at the only exception that agents motivation to communicate is to synchronise their list of observations, not their hypothesis).",
                "If this protocol is at best as effective as HE, it has the advantage of being more efficient (this is obvious wrt the number of messages which will be limited to 2, less straightforward as far as the size of messages is concerned, but the rough observation that the exchange of observations can be viewed as a flat version of the challenge is helpful to see this).",
                "The results of these experiments are reported in Fig. 3.",
                "Figure 3: Comparative effectiveness ratio gain of protocols when the proportion of agents augments The first observation that needs to be made is that communication improves the effectiveness of the process, and this ratio increases as the number of agents grows in the system.",
                "The second lesson that we learn here is that closeness relatively makes communication more effective over non communication.",
                "Maps exhibiting a T.I. of 38% are constantly above the two others, and 53% are still slightly but significantly better than 69%.",
                "However, these curves also suggest, perhaps surprisingly, that HE outperforms OE in precisely those situations where the ratio gain is less important (the only noticeable difference occurs for rather open maps where T.I. is 69%).",
                "This may be explained as follows: when a map is open, agents have many potential explanation candidates, and argumentation becomes useful to discriminate between those.",
                "When a map is labyrinth-like, there are fewer possible explanations to an unexpected event.",
                "Importance of the Global Protocol The second set of experiments seeks to evaluate the importance of the design of the global protocol.",
                "We tested our protocol against a local broadcast (LB) protocol.",
                "Local broadcast means that all the neighbours agents perceived by an agent will be involved in a communication with that agent in a given round -we alleviate the constraint of a single communication by agent.",
                "This gives us a rough upper bound upon the possible ratio gain in the system (for a given local protocol).",
                "Again, we evaluated the ratio gain induced by that LB over our classical HE, for the three different classes of maps.",
                "The results are reported in Fig. 4.",
                "Figure 4: Ratio gain of local broadcast over hypotheses exchange Note to begin with that the ratio gain is 0 when the proportion of agents is 5%, which is easily explained by the fact that it corresponds to situations involving only two agents.",
                "We first observe that all classes of maps witness a ratio gain increasing when the proportion of agents augments: the gain reaches 10 to 20%, depending on the class of maps considered.",
                "If one compares this with the improvement reported in the previous experiment, it appears to be of the same magnitude.",
                "This illustrates that the design of the global protocol cannot be ignored, especially when the proportion of agents is high.",
                "However, we also note that the effectiveness ratio gain curves have very different shapes in both cases: the gain induced by the accuracy of the local protocol increases very quickly with the proportion of agents, while the curve is really smooth for the global one.",
                "Now let us observe more carefully the results reported here: the curve corresponding to a TI of 53% is above that corresponding to 38%.",
                "This is so because the more open a map, the more opportunities to communicate with more than one agent (and hence benefits from broadcast).",
                "However, we also observe that curve for 69% is below that for 53%.",
                "This is explained as follows: in the case of 69%, the potential gain to be made in terms of surviving agents is much lower, because our protocols already give rather efficient outcomes anyway (quickly reaching 90%, see Fig. 3).",
                "A simple rule of thumb could be that when the number of agents is small, special attention should be put on the local 1004 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) protocol, whereas when that number is large, one should carefully design the global one (unless the map is so open that the protocol is already almost optimally efficient).",
                "Efficiency of the Protocols The final experiment reported here is concerned with the analysis of the efficiency of the protocols.",
                "We analysis here the mean size of the totality of the messages that are exchanged by agents (mean size of exchanges, for short) using the following protocols: HE, OE, and two variant protocols.",
                "The first one is an intermediary restricted hypotheses exchange protocol (RHE).",
                "RHE is as follows: it does not involve any challenge nor counter-propose, which means that agents cannot switch their role during the protocol (this differs from RE in that respect).",
                "In short, RHE allows an agent to exhaust its partners criticism, and eventually this partner will come to adopt the agents hypothesis.",
                "Note that this means that the autonomy of the agent is not preserved here (as an agent will essentially accept any hypothesis it cannot undermine), with the hope that the gain in efficiency will be significant enough to compensate a loss in effectiveness.",
                "The second variant protocol is a complete observation exchange protocol (COE).",
                "COE uses the same principles as OE, but includes in addition all critical negative examples (nofire) in the exchange (thus giving all examples used as arguments by the hypotheses exchanges protocol), hence improving effectiveness.",
                "Results for map 69-1 are shown on Fig. 5.",
                "Figure 5: Mean size of exchanges First we can observe the fact that the ordering of the protocols, from the least efficient to the most efficient, is COE, HE, RHE and then OE.",
                "HE being more efficient than COE proves that the argumentation process gains efficiency by selecting when it is needed to provide negative example, which have less impact that positive ones in our specific testbed.",
                "However, by communicating hypotheses before eventually giving observation to support it (HE) instead of directly giving the most crucial observations (OE), the argumentation process doubles the size of data exchanges.",
                "It is the cost for ensuring consistency at the end of the exchange (a property that OE does not support).",
                "Also significant is the fact the the mean size of exchanges is slightly higher when the number of agents is small.",
                "This is explained by the fact that in these cases only a very few agents have relevant informations in their possession, and that they will need to communicate a lot in order to come up with a common view of the situation.",
                "When the number of agents increases, this knowledge is distributed over more agents which need shorter discussions to get to mutual consistency.",
                "As a consequence, the relative gain in efficiency of using RHE appears to be better when the number of agents is small: when it is high, they will hardly argue anyway.",
                "Finally, it is worth noticing that the standard deviation for these experiments is rather high, which means that the conversation do not converge to any stereotypic pattern. 6.",
                "CONCLUSION This paper has investigated the properties of a multiagent system where each (distributed) agent locally perceives its environment, and tries to reach consistency with other agents despite severe communication restrictions.",
                "In particular we have exhibited conditions allowing convergence, and experimentally investigated a typical situation where those conditions cannot hold.",
                "There are many possible extensions to this work, the first being to further investigate the properties of different global protocols belonging to the class we identified, and their influence on the outcome.",
                "There are in particular many heuristics, highly dependent on the context of the study, that could intuitively yield interesting results (in our study, selecting the recipient on the basis of what can be inferred from his observed actions could be such a heuristic).",
                "One obvious candidate for longer term issues concern the relaxation of the assumption of perfect sensing. 7.",
                "REFERENCES [1] G. Bourgne, N. Maudet, and S. Pinson.",
                "When agents communicate hypotheses in critical situations.",
                "In Proceedings of DALT-2006, May 2006. [2] P. Harvey, C. F. Chang, and A. Ghose.",
                "Support-based distributed search: a new approach for multiagent constraint processing.",
                "In Proceedings of AAMAS06, 2006. [3] H. Jung and M. Tambe.",
                "Argumentation as distributed constraint satisfaction: Applications and results.",
                "In Proceedings of AGENTS01, 2001. [4] N. C. Karunatillake and N. R. Jennings.",
                "Is it worth arguing?",
                "In Proceedings of ArgMAS 2004, 2004. [5] S. Onta˜n´on and E. Plaza.",
                "Arguments and counterexamples in case-based joint deliberation.",
                "In Proceedings of ArgMAS-2006, May 2006. [6] D. Poole.",
                "Explanation and prediction: An architecture for default and abductive reasoning.",
                "Computational Intelligence, 5(2):97-110, 1989. [7] I. Rahwan, S. D. Ramchurn, N. R. Jennings, P. McBurney, S. Parsons, and L. Sonenberg.",
                "Argumention-based negotiation.",
                "The Knowledge Engineering Review, 4(18):345-375, 2003. [8] N. Roos, A. ten Tije, and C. Witteveen.",
                "A protocol for multi-agent diagnosis with spatially distributed knowledge.",
                "In Proceedings of AAMAS03, 2003. [9] N. Roos, A. ten Tije, and C. Witteveen.",
                "Reaching diagnostic agreement in multiagent diagnosis.",
                "In Proceedings of AAMAS04, 2004. [10] T. Takahashi, Y. Kaneda, and N. Ito.",
                "Preliminary study - using robocuprescue simulations for disasters prevention.",
                "In Proceedings of SRMED2004, 2004.",
                "The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 1005"
            ],
            "original_annotated_samples": [
                "Upon perception of an unexpected event, each agent locally computes its <br>favoured hypothesis</br> and tries to propagate it to other agents, by exchanging hypotheses and supporting arguments (observations).",
                "If each agent computes only locally its <br>favoured hypothesis</br>, it is only natural to assume that agents will seek to coordinate and refine their hypotheses by confronting their observations with other agents.",
                "In this application, agents communicate with any other agent (but, recall, a single one) given that this agent is in view, and that they have not yet exchanged their current <br>favoured hypothesis</br>."
            ],
            "translated_annotated_samples": [
                "Tras la percepción de un evento inesperado, cada agente calcula localmente su <br>hipótesis favorita</br> e intenta propagarla a otros agentes, intercambiando hipótesis y argumentos de apoyo (observaciones).",
                "Si cada agente calcula solo localmente su <br>hipótesis preferida</br>, es natural asumir que los agentes buscarán coordinar y refinar sus hipótesis confrontando sus observaciones con otros agentes.",
                "En esta aplicación, los agentes se comunican con cualquier otro agente (pero, recuerda, solo uno) siempre y cuando este agente esté a la vista y aún no hayan intercambiado su <br>hipótesis actual favorita</br>."
            ],
            "translated_text": "Refinamiento de hipótesis bajo restricciones de comunicación topológica ∗ Gauvain Bourgne, Gael Hette, Nicolas Maudet y Suzanne Pinson LAMSADE, Univ. Investigamos las propiedades de un sistema multiagente donde cada agente (distribuido) percibe localmente su entorno. Tras la percepción de un evento inesperado, cada agente calcula localmente su <br>hipótesis favorita</br> e intenta propagarla a otros agentes, intercambiando hipótesis y argumentos de apoyo (observaciones). Sin embargo, también asumimos que las oportunidades de comunicación están severamente limitadas y cambian dinámicamente. En este artículo, investigamos principalmente la convergencia de dichos sistemas hacia la consistencia global. Primero demostramos que (para una amplia clase de protocolos que definiremos), las restricciones de comunicación inducidas por la topología no impedirán la convergencia del sistema, bajo la condición de que la dinámica del sistema garantice que ningún agente quedará aislado para siempre, y que los agentes tengan tiempo ilimitado para la computación y el intercambio de argumentos. Dado que esta suposición no se puede hacer en la mayoría de las situaciones, establecimos un marco experimental con el objetivo de comparar la eficiencia y efectividad relativa de diferentes protocolos de interacción para el intercambio de hipótesis. Estudiamos una situación crítica que implica a varios agentes que intentan escapar de un edificio en llamas. Los resultados reportados aquí proporcionan algunas ideas sobre el diseño de un protocolo óptimo para el refinamiento de hipótesis en este contexto. Categorías y Descriptores de Asignaturas I.2.11 [Inteligencia Artificial]: Inteligencia Artificial Distribuida-Sistemas Multiagente Términos Generales Teoría, Experimentación 1. INTRODUCCIÓN Consideramos un sistema multiagente donde cada agente (distribuido) percibe localmente su entorno, y asumimos que ocurre un evento inesperado en ese sistema. Si cada agente calcula solo localmente su <br>hipótesis preferida</br>, es natural asumir que los agentes buscarán coordinar y refinar sus hipótesis confrontando sus observaciones con otros agentes. Si, además, las oportunidades de comunicación están severamente limitadas (por ejemplo, los agentes solo pueden comunicarse cuando están lo suficientemente cerca de otro agente) y cambian dinámicamente (por ejemplo, los agentes pueden cambiar sus ubicaciones), se vuelve crucial diseñar cuidadosamente protocolos que permitan a los agentes converger hacia algún estado deseado de consistencia global. En este documento presentamos algunas condiciones suficientes sobre la dinámica del sistema y sobre las estructuras de protocolo/estrategia que permiten garantizar esa propiedad, y estudiamos experimentalmente algunos contextos donde (algunas de) estas suposiciones se relajan. Si bien los problemas de diagnóstico son uno de los clásicos venerables en la tradición de la IA, sus contrapartes multiagentes han atraído atención mucho más recientemente. Roos y sus colegas [8, 9] en particular estudian una situación en la que un número de entidades distribuidas intentan llegar a un diagnóstico global satisfactorio de todo el sistema. Ellos muestran en particular que el número de mensajes necesarios para establecer este diagnóstico global está destinado a ser prohibitivo, a menos que la comunicación se mejore con algún protocolo adecuado. Sin embargo, no imponen restricciones a las opciones de comunicación de los agentes, ni asumen que el sistema es dinámico. Los beneficios de mejorar la comunicación con información de apoyo para hacer que la convergencia a un estado global deseado de un sistema sea más eficiente, a menudo se ha planteado en la literatura. Esta es, por ejemplo, una de las ideas principales que subyacen al enfoque de negociación basado en argumentos [7], donde el estado deseado es un compromiso entre agentes con preferencias conflictivas. Sin embargo, muchos de estos trabajos parten del supuesto de que este enfoque es beneficioso para comenzar y estudian los aspectos técnicos del problema (o en su lugar enfatizan otras ventajas de utilizar la argumentación). Excepciones notables son las obras de [3, 4, 2, 5], que estudiaron en contextos diferentes al nuestro la eficiencia de la argumentación. El resto del documento es el siguiente. La Sección 2 especifica los elementos básicos de nuestro modelo, y la Sección 3 continúa presentando los diferentes protocolos y estrategias utilizados por los agentes para intercambiar hipótesis y observaciones. Ponemos especial atención en enfatizar claramente las condiciones de la dinámica del sistema y los protocolos/estrategias que se explotarán en el resto del documento. La sección 4 detalla uno de los principales resultados del artículo, a saber, el hecho de que bajo las condiciones mencionadas, las restricciones que imponemos en la topología no impedirán la convergencia del sistema hacia la consistencia global, siempre y cuando ningún agente se pierda completamente para siempre en el sistema, y se permita un tiempo ilimitado para la computación y el intercambio de argumentos. Si bien las condiciones en los protocolos y estrategias son bastante suaves, también es claro que estos requisitos del sistema parecen mucho más problemáticos, incluso francamente poco realistas en situaciones críticas donde se abogan precisamente por enfoques distribuidos. Para obtener una imagen más clara de la situación inducida cuando el tiempo es un factor crítico, hemos establecido un marco experimental que presentamos y discutimos en la Sección 5. La situación crítica implica a varios agentes que intentan escapar de un edificio en llamas. Los resultados reportados aquí muestran que la efectividad del intercambio de argumentos depende crucialmente de la naturaleza del edificio, y proporcionan algunas ideas sobre el diseño de un protocolo óptimo para el refinamiento de hipótesis en este contexto. CONCEPTOS BÁSICOS Comenzamos definiendo los elementos básicos de nuestro sistema. Deje que O sea el conjunto (potencialmente infinito) de observaciones posibles. Suponemos que los sensores de nuestros agentes son perfectos, por lo tanto, las observaciones son seguras. Sea H el conjunto de hipótesis, incierto y revisable. Sea Cons(h, O) la relación de consistencia, una relación binaria entre una hipótesis h ∈ H y un conjunto de observaciones O ⊆ O. En la mayoría de los casos, Cons se referirá a la relación de consistencia clásica, sin embargo, podemos sobrecargar su significado y añadir algunas propiedades adicionales a esa relación (en cuyo caso lo mencionaremos). El entorno puede incluir cierta dinámica y cambiar con el transcurso del tiempo. Definimos a continuación secuencias de puntos temporales para tratar con ello: Definición 1 (Secuencia de puntos temporales). Una secuencia de puntos temporales t1, t2, . . . , tn de t es un conjunto ordenado de puntos temporales t1, t2, . . . , tn tal que t1 ≥ t y ∀i ∈ [1, n − 1], ti+1 ≥ ti. Tomamos un sistema poblado por n agentes a1, . . . , an. Cada agente se define como una tupla F, Oi, hi, donde: • F, el conjunto de hechos, conocimiento común a todos los agentes. • Oi ∈ 2O, el conjunto de observaciones realizadas por el agente hasta el momento. Suponemos una memoria perfecta, por lo tanto, este conjunto crece de forma monótona. • hi ∈ H, la hipótesis favorita del agente. Una noción clave que rige la formación de hipótesis es la de consistencia, definida a continuación: Definición 2 (Consistencia). Decimos que: • Un agente es consistente (Cons(ai)) si y solo si Cons(hi, Oi) (es decir, su hipótesis es consistente con su conjunto de observaciones). • Un agente ai es consistente con un agente compañero aj si y solo si Cons(ai) y Cons(hi, Oj) (es decir, este agente es consistente y su hipótesis puede explicar el conjunto de observaciones del otro agente). • Dos agentes ai y aj son mutuamente consistentes (MCons(ai, aj)) si y solo si Cons(ai, aj) y Cons(aj, ai). • Un sistema es consistente si y solo si para todo (i, j) ∈ [1, n]2 se cumple que MCons(ai, aj). Para garantizar su consistencia, cada agente está equipado con una maquinaria de razonamiento abstracto que llamaremos la función de explicación Eh. Esta función (determinística) toma un conjunto de observaciones y devuelve una única hipótesis preferida (2O → H). Suponemos que h = Eh(O) para ser consistente con O por definición de Eh, por lo que usar esta función en su conjunto de observaciones para determinar su hipótesis favorita es una forma segura para que el agente logre consistencia. Sin embargo, cabe destacar que una hipótesis no necesita ser generada por Eh para ser consistente con un conjunto de observaciones. Como ejemplo concreto de tal función, y una de las principales inspiraciones de este trabajo, se puede citar el sistema de razonamiento Theorist [6], siempre y cuando esté acoplado con un filtro que seleccione una teoría preferida entre las inicialmente seleccionadas por Theorist. También hay que tener en cuenta que hi solo puede ser modificado como consecuencia de la aplicación de Eh. Nos referimos a esto como la autonomía del agente: ningún otro agente puede imponer directamente una hipótesis dada a un agente. Como consecuencia, solo una nueva observación (ya sea una nueva percepción o una observación comunicada por otro agente) puede resultar en una modificación de su hipótesis preferida hi (pero no necesariamente, por supuesto). Finalmente definimos una propiedad del sistema que utilizaremos en el resto del artículo: Definición 3 (Percepciones Acotadas). Un sistema implica una percepción limitada para los agentes si y solo si existe un n0 tal que para todo t, la unión de N observaciones realizadas por los agentes es menor o igual a n0. (Es decir, el número de observaciones a realizar por los agentes en el sistema no es infinito.) Ahora necesitamos ver cómo evolucionarán e interactuarán estos agentes en su entorno. En nuestro contexto, los agentes evolucionan en un entorno dinámico, y asumimos clásicamente el siguiente ciclo del sistema: 1. Dinámica del entorno: el entorno evoluciona de acuerdo con las reglas definidas de la dinámica del sistema. 2. Paso de percepción: los agentes obtienen percepciones del entorno. Estas percepciones suelen ser parciales (por ejemplo, el agente solo puede ver una parte de un mapa). 3. Paso de razonamiento: los agentes comparan la percepción con las predicciones, buscan explicaciones para las diferencias (potenciales), refinan su hipótesis, y sacan nuevas conclusiones. 4. Paso de comunicación: los agentes pueden comunicar hipótesis y observaciones con otros agentes a través de un protocolo definido. Cualquier agente solo puede estar involucrado en una comunicación con otro agente en el paso 5. Paso de acción: los agentes realizan un razonamiento práctico utilizando los modelos obtenidos de los pasos anteriores y seleccionan una acción. Ellos pueden modificar el entorno ejecutándolo. La comunicación de los agentes estará aún más restringida por consideraciones topológicas. En un momento dado, un agente solo podrá comunicarse con un número de vecinos. Sus conexiones con estos otros agentes pueden The Sixth Intl. La Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) evoluciona con su situación en el entorno. Normalmente, un agente solo puede comunicarse con agentes que puede percibir, pero se podría imaginar la evolución de restricciones topológicas en la comunicación basadas en una red de comunicaciones entre agentes donde los enlaces no siempre están activos. En nuestro sistema, los agentes podrán comunicarse entre sí. Sin embargo, debido a las restricciones topológicas mencionadas anteriormente, no podrán comunicarse con ningún agente en ningún momento. Con quién puede comunicarse un agente se definirá dinámicamente (por ejemplo, esto puede ser consecuencia de que los agentes estén lo suficientemente cerca para ponerse en contacto). Denotaremos de forma abstracta por C(ai, aj, t) la propiedad de comunicación, es decir, el hecho de que los agentes ai y aj puedan comunicarse en el tiempo t (nota que se asume que esta relación es simétrica, pero por supuesto no transitiva). Ahora estamos en posición de definir dos propiedades esenciales de nuestro sistema. Definición 4 (Camino Temporal). Existe un camino de comunicación temporal en el horizonte tf (denotado Ltf (aI, aJ)) entre ai y aj si y solo si existe una secuencia de puntos temporales t1, t2, ..., tn desde tf y una secuencia de agentes k1, k2, ..., kn tal que (i) C(aI, ak1, t1), (ii) C(akn, aJ, tn+1), (iii) ∀i ∈ [1, n], C(aki, aki+1, ti). Intuitivamente, lo que esta propiedad dice es que es posible encontrar un camino temporal en el futuro que permitiría vincular al agente ai y aj a través de una secuencia de agentes intermedios. Ten en cuenta que los puntos temporales no necesariamente son sucesivos, y que la secuencia de agentes puede involucrar a los mismos agentes varias veces. Definición 5 (Conexidad Temporal). Un sistema es temporalmente conexo si y solo si ∀t ∀(i, j)∈[1, n]2 Lt(ai, aj). En resumen, un sistema temporalmente conexo garantiza que cualquier agente podrá comunicarse con cualquier otro agente, sin importar cuánto tiempo pueda llevar hacerlo, en cualquier momento. Dicho de otra manera, nunca sucede que un agente esté aislado para siempre de otro agente del sistema. A continuación discutiremos en detalle cómo la comunicación tiene lugar concretamente en nuestro sistema. Recuerda que en este documento, solo consideramos el caso de intercambios bilaterales (un agente solo puede hablar con otro agente) y también asumimos que cualquier agente solo puede participar en un intercambio en una ronda dada. 3. PROTOCOLOS Y ESTRATEGIAS En esta sección, discutimos los requisitos de los protocolos de interacción que rigen el intercambio de mensajes entre agentes, y proporcionamos algunos ejemplos de la implementación de dichos protocolos. Para aclarar la presentación, distinguimos dos niveles: el nivel local, que se ocupa de la regulación de los intercambios bilaterales; y el nivel global, que regula principalmente la forma en que los agentes pueden participar realmente en una conversación. En cada nivel, separamos lo que está especificado por el protocolo y lo que se deja a las estrategias de los agentes. Protocolos y estrategias locales Comenzamos inspeccionando los protocolos y estrategias locales que regularán la comunicación entre los agentes del sistema. Al limitarnos a la comunicación bilateral, estos protocolos simplemente implicarán a dos agentes. Dicho protocolo tendrá que cumplir con un requisito básico para ser satisfactorio: consistencia (CONS) - un protocolo local debe garantizar la consistencia mutua de los agentes al finalizar (lo que implica, por supuesto, la finalización). Figura 1: Un Protocolo de Intercambio de Hipótesis [1] Un ejemplo de dicho protocolo es el protocolo descrito en [1] que se muestra en la Fig. 1. Para ilustrar aún más cómo dicho protocolo puede ser utilizado por agentes, proporcionamos algunos detalles sobre una posible estrategia: al recibir una hipótesis h1 (proponer(h1) o contra-proponer(h1)) de a1, el agente a2 se encuentra en el estado 2 y tiene las siguientes respuestas posibles: contraejemplo (si el agente conoce un ejemplo que contradice la hipótesis, o no está explicado por esta hipótesis), desafío (si el agente carece de evidencia para aceptar esta hipótesis), contra-proponer (si el agente está de acuerdo con la hipótesis pero prefiere otra), o aceptar (si es tan buena como su hipótesis favorita). Esta estrategia garantiza, entre otras propiedades, la eventual consistencia lógica mutua de los agentes involucrados [1]. Protocolo global El protocolo global regula la forma en que se iniciarán los intercambios bilaterales entre agentes. En cada turno, los agentes enviarán simultáneamente una solicitud ponderada para comunicarse con otros agentes. Este peso es un valor que mide la disposición de los agentes para conversar con el agente objetivo (en la práctica, esto puede basarse en diferentes heurísticas, pero haremos algunas suposiciones sobre las estrategias de los agentes, ver más abajo). Enviar una solicitud de este tipo es una especie de compromiso condicional para el agente. Un agente que envía una solicitud ponderada se compromete a entablar una conversación con el objetivo si no recibe y acepta otra solicitud por sí mismo. Una vez que se hayan recibido todas las solicitudes, cada agente responde con un aceptar o un rechazar. Al responder con un aceptar, un agente se compromete plenamente a participar en la conversación con el remitente. Por lo tanto, solo puede enviar una aceptación en una ronda dada, ya que un agente solo puede participar en una conversación por paso de tiempo. Cuando se hayan recibido todas las respuestas, cada agente que reciba una aceptación puede iniciar una conversación utilizando el protocolo local o enviar una cancelación si ha aceptado otra solicitud. Al final de todos los intercambios bilaterales, los agentes involucrados en la conversación son descartados del protocolo. Entonces cada uno de los agentes restantes reenvía una solicitud y el proceso se repite hasta que no se envíen más solicitudes. Estrategia global Ahora definimos cuatro requisitos para las estrategias utilizadas por los agentes, dependiendo de su rol en el protocolo: dos se refieren al rol del solicitante (cómo decidir quién es el 1000 The Sixth Intl. La Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) ¿con qué agente desea comunicarse? Los otros dos con el rol de respondedor (¿cómo decidir qué solicitud de comunicación aceptar o no?). • Disposición para resolver inconsistencias (SOLVE): los agentes desean comunicarse con cualquier otro agente a menos que sepan que son mutuamente consistentes. • Enfoque en resolver inconsistencias (FOCUS): los agentes no solicitan comunicarse con un agente con el que saben que son mutuamente consistentes. • Disposición para comunicarse (COMM): los agentes no pueden rechazar una solicitud de comunicación ponderada, a menos que acaben de recibir o enviar una solicitud con un peso mayor. • Compromiso con la solicitud de comunicación (REQU): los agentes no pueden aceptar una solicitud de comunicación ponderada si ellos mismos han enviado una solicitud de comunicación con un peso mayor. Por lo tanto, no cancelarán su solicitud a menos que hayan recibido una solicitud comunicacional con mayor peso. Ahora la estructura del protocolo, junto con las propiedades COMM+REQU, garantizan que una solicitud solo puede ser rechazada si su agente objetivo se involucra en comunicación con otro agente. Supongamos de hecho que el agente ai quiere comunicarse con aj enviando una solicitud con peso w. COMM garantiza que un agente que reciba una solicitud ponderada aceptará esta comunicación, aceptará una comunicación con un peso mayor o esperará la respuesta a una solicitud con un peso mayor. Esto asegura que la solicitud con peso máximo será aceptada y no cancelada (ya que REQU asegura que un agente que envía una solicitud solo puede cancelarla si acepta otra solicitud con un peso mayor). Por lo tanto, al menos dos agentes participarán en una conversación por ronda del protocolo global. Como el protocolo asegura que ai puede reenviar su solicitud mientras aj no está ocupado en una conversación, llegará un momento en el que aj deberá participar en una conversación, ya sea con ai u otro agente. Estos requisitos se refieren al envío y aceptación de solicitudes, pero los agentes también necesitan alguna estrategia de atribución de peso. Describimos a continuación una estrategia altruista, utilizada en nuestros experimentos. Siendo cooperativo, un agente puede querer conocer más los deseos de comunicación de otros agentes para mejorar la asignación general de intercambios a los agentes. Se añade entonces un paso de solicitud de contexto al protocolo global. Antes de enviar su solicitud ponderada elegida, los agentes asignan un peso a todos los agentes con los que están dispuestos a comunicarse, de acuerdo con algunos factores internos. En el caso más simple, este peso será 1 para todos los agentes con los que el agente no esté seguro de ser mutuamente consistentes (garantizando SOLVE), sin considerar a otros agentes para la comunicación (garantizando FOCUS). El agente luego envía una solicitud de contexto a todos los agentes con los que se considera la comunicación. Esta solicitud también proporciona información sobre el remitente (lista de comunicaciones consideradas junto con su peso). Después de recibir todas las solicitudes de contexto, los agentes responderán con un rechazo si ya están ocupados en una conversación (en cuyo caso, el agente solicitante no considerará comunicarse con ellos en este turno), o con una información que brinde al solicitante información sobre las solicitudes que ha enviado y recibido. Cuando se hayan recibido todas las respuestas, cada agente puede calcular el peso de todas las solicitudes que le conciernen. Lo hace restando del peso de su solicitud el peso de todas las solicitudes relacionadas con él o su objetivo (es decir, el peso final de la solicitud de ai a aj es Wi,j = wi,j + wj,i - ( Σ k∈R(i)-{j} wi,k + Σ k∈S(i)-{j} wk,i + Σ k∈R(j)-{i} wj,k + Σ k∈S(j)-{i} wk,j) donde wi,j es el peso de la solicitud de ai a aj, R(i) es el conjunto de índices de agentes que han recibido una solicitud de ai y S(i) es el conjunto de índices de agentes que han enviado una solicitud a ai). Luego envía finalmente una solicitud ponderada a los agentes que maximizan este peso (o esperan una solicitud) según lo descrito en el protocolo global. 4. (CONDICIONAL) CONVERGENCIA HACIA LA COHERENCIA GLOBAL En esta sección mostraremos que los requisitos relacionados con los protocolos y estrategias recién discutidos serán suficientes para garantizar que el sistema eventualmente convergerá hacia la coherencia global, bajo ciertas condiciones. Primero demostramos que, si dos agentes no son mutuamente consistentes en algún momento, entonces necesariamente habrá un momento en el futuro en el que un agente aprenderá una nueva observación, ya sea porque es nueva para el sistema, o al aprenderla de otro agente. Lema 1. Sea S un sistema poblado por n agentes a1, a2, ..., an, temporalmente conectados e involucrando percepciones limitadas para estos agentes. Sea n1 la suma de las cardinalidades de la intersección de los conjuntos de observaciones emparejados. (n1 = P (i,j)∈[1,n]2 |Oi ∩ Oj|) Sea n2 la cardinalidad de la unión de todos los conjuntos de observaciones de los agentes. (n2 = | ∪N i=1 Oi|). Si ¬MCons(ai, aj) en el tiempo t0, necesariamente existe un tiempo t > t0 tal que ya sea n1 o n2 aumentarán. Prueba. Supongamos que exista un tiempo t0 y unos índices (i, j) tal que ¬MCons(ai, aj). Utilizaremos mt0 = P (k,l)∈[1,n]2 εComm(ak, al, t0) donde εComm(ak, al, t0) = 1 si ak y al han comunicado al menos una vez desde t0, y 0 en caso contrario. La conexidad temporal garantiza que existen t1, ..., tm+1 y k1, ..., km tal que. C(ai, ak1 , t1), C(akm , aj, tm+1), y ∀p ∈ [1, m], C(akp , akp+1 , tp). Claramente, si MCons(ai, ak1), MCons(akm, aj) y ∀p, MCons(akp, akp+1), tenemos MCons(ai, aj) lo cual contradice nuestra hipótesis (siendo MCons transitivo, MCons(ai, ak1)∧MCons(ak1, ak2) implica que MCons(ai, ak2) y así sucesivamente hasta MCons(ai, akm)∧MCons(akm, aj) lo cual implica MCons(ai, aj)). Al menos dos agentes son necesariamente inconsistentes (¬MCons(ai, ak1), o ¬MCons(akm, aj), o ∃p0 t.q. ¬MCons(akp0, akp0+1)). Que ak y al sean estos dos vecinos en un momento t > t0 1. La propiedad SOLVE asegura que ya sea ak o al enviará una solicitud de comunicación al otro agente en el tiempo t. Como se mostró anteriormente, esto a su vez garantiza que al menos uno de estos agentes estará involucrado en una comunicación. Entonces hay dos posibilidades: (caso i) ak y al se comunican en el tiempo t. En este caso, sabemos que ¬MCons(ak, al). Esto y la propiedad CONS aseguran que al menos uno de los agentes debe cambiar su 1. Estrictamente hablando, la transitividad de MCons solo asegura que ak y al son inconsistentes en un tiempo t ≥ t0 que puede ser diferente del tiempo t en el que pueden comunicarse. Pero si se vuelven consistentes entre t y t (o inconsistentes entre t y t), significa que al menos uno de ellos ha cambiado su hipótesis entre t y t, es decir, después de t0. Podemos entonces aplicar el razonamiento del caso iib. El Sexto Internacional. La Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 1001 hipótesis, lo cual a su vez, dado que los agentes son autónomos, implica al menos un intercambio de observación. Pero entonces |Ok ∩Ol| está destinado a aumentar: n1(t) > n1(t0). (caso ii) ak se comunica con ap en el tiempo t. Entonces tenemos de nuevo dos posibilidades: (caso iia) ak y ap no se comunicaron desde t0. Pero luego εComm(ak, ap, t0) tenía valor 0 y toma valor 1. Por lo tanto, mt0 aumenta. (caso iib) ak y ap se comunicaron en algún momento t0 > t0. La propiedad CONS del protocolo asegura que MCons(ak, ap) en ese momento. Ahora el hecho de que se comuniquen y se ENFOQUEN implica que al menos uno de ellos cambió su hipótesis en el ínterin. El hecho de que los agentes sean autónomos implica a su vez que una nueva observación (percibida o recibida de otro agente) necesariamente provocó este cambio. El último caso garantizaría la existencia de un tiempo t > t0 y un agente aq tal que |Op ∩ Oq| o |Ok ∩ Oq| aumenten en 1 en ese momento (lo que implica que n1(t) > n1(t0)). El caso anterior significa que el agente obtiene una nueva percepción en el tiempo t. Si esa observación era desconocida en el sistema antes, entonces n2(t) > n2(t0). Si algún agente aq ya conocía esta observación antes, entonces tanto Op ∩ Oq como Ok ∩ Oq aumentan en 1 en el tiempo t (lo que implica que n1(t) > n1(t0)). Por lo tanto, ¬MCons(ai, aj) en el tiempo t0 garantiza que, o bien: −∃t > t0 t.q. n1(t ) > n1(t0); o −∃t > t0 t.q. n2(t ) > n2(t0); o −∃t > t0 t.q. mt0 aumenta en 1 en el tiempo t. Al iterar el razonamiento con t (pero manteniendo t0 como la referencia de tiempo para mt0), podemos eliminar el tercer caso (mt0 es un entero y está limitado por n2, lo que significa que después de un máximo de n2 iteraciones, necesariamente estaremos en uno de los otros dos casos). Como resultado, hemos demostrado que si ¬MCons(ai, aj) en el tiempo t0, necesariamente habrá un tiempo t tal que ya sea n1 o n2 aumentarán. Teorema 1 (Consistencia global). Sea S un sistema poblado por n agentes a1, a2, ..., an, temporalmente conectados e involucrando percepciones limitadas para estos agentes. Sea Cons(ai, aj) una propiedad de consistencia transitiva. Entonces, cualquier protocolo y estrategias que cumplan con las propiedades CONS, SOLVE, FOCUS, COMM y REQU garantizan que el sistema convergerá hacia la consistencia global. Prueba. Por el bien de la contradicción, asumamos que ∃I, J ∈ [1, N] tal que ∀t, ∃t0 > t, tal que ¬Cons(aI , aJ , t0). Usando el lema, esto implica que ∃t > t0 tal que n1(t) > n1(t0) o n2(t) > n2(t0). Pero podemos aplicar el mismo razonamiento tomando t = t, lo que nos daría t1 > t > t0 tal que ¬Cons(aI , aJ , t1), lo que nos da t > t1 tal que n1(t) > n1(t1) o n2(t) > n2(t1). Mediante iteraciones sucesivas podemos construir una secuencia t0, t1, ..., tn, que puede dividirse en dos subsecuencias t0, t1, ...tn y t0, t1, ..., tn tal que n1(t0) < n1(t1) < ... < n1(tn) y n2(t0) < n2(t1) < ... < n2(tn). Una de estas subsecuencias tiene que ser infinita. Sin embargo, n1(ti) y n2(ti) son estrictamente crecientes, enteros y acotados, lo que implica que ambos son finitos. Contradicción. Lo que el resultado anterior muestra esencialmente es que, en un sistema donde ningún agente estará aislado del resto de los agentes para siempre, solo se necesitan suposiciones muy leves sobre los protocolos y estrategias utilizados por los agentes para garantizar la convergencia hacia la consistencia del sistema en una cantidad finita de tiempo (aunque podría llevar mucho tiempo). Desafortunadamente, en muchas situaciones críticas, no será posible asumir esta conexión temporal. Dado que enfoques distribuidos como el abogado en este documento suelen presentarse como una buena manera de abordar problemas de confiabilidad o problemas de dependencia de un centro que son de suma importancia en estas aplicaciones críticas, ciertamente resulta interesante explorar más a fondo cómo se comportaría un sistema de este tipo cuando relajamos esta suposición. ESTUDIO EXPERIMENTAL Este experimento implica agentes tratando de escapar de un edificio en llamas. El entorno se describe como una cuadrícula espacial con un conjunto de paredes y (afortunadamente) algunas salidas. El tiempo y el espacio se consideran discretos. El tiempo se divide en rondas. Los agentes se localizan por su posición en la cuadrícula espacial. Estos agentes pueden moverse y comunicarse con otros agentes. En una ronda, un agente puede moverse una celda en cualquiera de las cuatro direcciones cardinales, siempre y cuando no esté bloqueado por una pared. En esta aplicación, los agentes se comunican con cualquier otro agente (pero, recuerda, solo uno) siempre y cuando este agente esté a la vista y aún no hayan intercambiado su <br>hipótesis actual favorita</br>. De repente, se desata un incendio en estas instalaciones. A partir de este momento, el fuego se propaga. En cada ronda, en cada caso donde haya fuego, el fuego se propaga en las cuatro direcciones. Sin embargo, el fuego no puede propagarse a través de una pared. Si el fuego se propaga en un caso donde un agente está posicionado, ese agente se quema y se considera muerto. Por supuesto, ya no puede moverse ni comunicarse. Si un agente llega a una salida, se considera que está a salvo y ya no puede ser quemado. Los agentes conocen el entorno y las reglas que rigen la dinámica de este entorno, es decir, conocen el mapa así como las reglas de propagación del fuego previamente descritas. También perciben este entorno localmente, pero no pueden ver más allá de 3 casos en cualquier dirección. Las paredes también bloquean la línea de visión, impidiendo que los agentes vean detrás de ellas. Dentro de su campo de visión, pueden ver a otros agentes y si los casos que ven están en llamas. Todas estas percepciones están memorizadas. Mostramos ahora cómo se instancia el marco abstracto presentado en el documento. • O = {Fire(x, y, t), NoFire(x, y, t), Agent(ai, x, y, t)} Las observaciones pueden ser positivas (o ∈ P(O) si ∃h ∈ H tal que h |= o) o negativas (o ∈ N(O) si ∃h ∈ H tal que h |= ¬o). • H={FireOrigin(x1, y1, t1)∧...∧FireOrigin(xl, yl, tl)} Las hipótesis son conjunciones de Orígenes de Fuego. • La relación de consistencia Cons(h, O) satisface: - coherencia: ∀o ∈ N(O), h |= ¬o. - completitud: ∀o ∈ P(O), h |= o. - minimalidad: Para todo h ∈ H, si h es coherente y completo para O, entonces h es preferido a h de acuerdo con la relación de preferencia (h ≤p h). Selecciona primero el número mínimo de orígenes, luego el más reciente (estrategia menos preemptiva [6]), y luego utiliza un ranking fijo arbitrario para discriminar ex-aequo. La relación resultante es un orden total, por lo tanto, la minimalidad implica que habrá un único h tal que Cons(O, h) para un O dado. Esto a su vez significa que MCons(ai, aj) si y solo si Cons(ai), Cons(aj) y hi = hj. Esta relación es entonces transitiva y simétrica. 1002 El Sexto Internacional. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) • Eh toma O como argumento y devuelve min≤p de la hipótesis coherente y completa para O 5.1 Evaluación Experimental Clásicamente evaluaremos la efectividad y eficiencia de diferentes protocolos de interacción (ver, por ejemplo, [3, 4]). La efectividad de un protocolo se determinará por la proporción de agentes que sobreviven al incendio respecto al número inicial de agentes involucrados en el experimento. Si este valor es alto, el protocolo ha sido efectivo para propagar la información y/o para que los agentes refinen sus hipótesis y determinen la mejor manera de salir. Eficiencia de un protocolo. Por lo general, el uso de información de apoyo implicará una sobrecarga de comunicación. Aquí asumiremos que la eficiencia de un protocolo dado está caracterizada por el flujo de datos inducido por este protocolo. En este documento solo discutiremos este aspecto con respecto a los protocolos locales. La medida principal que utilizaremos aquí es el tamaño total promedio de los mensajes intercambiados por los agentes por intercambio (teniendo en cuenta tanto el número de mensajes como el tamaño real de los mensajes, ya que podría ser que los mensajes resulten ser muy grandes, conteniendo por ejemplo un gran número de observaciones, lo que podría contrarrestar un bajo número de mensajes). 5.2 Configuraciones Experimentales Las configuraciones experimentales elegidas son las siguientes: • Topología ambiental: El rendimiento de la propagación de la información está altamente condicionado por la topología del entorno. Las habilidades de percepción de los agentes dependen de la apertura del entorno. Con un gran número de paredes, las percepciones de los agentes están limitadas, al igual que el número de posibles comunicaciones entre agentes, mientras que un entorno abierto proporcionará posibilidades óptimas de percepción y propagación de información. Por lo tanto, proponemos un índice topológico (ver abajo) como base común para caracterizar los entornos (mapas) utilizados durante las experimentaciones. El índice topológico (TI) es la proporción entre el número de celdas que pueden ser percibidas por los agentes sumadas desde todas las posiciones posibles, dividido por el número de celdas que serían percibidas desde las mismas posiciones pero sin paredes. (Cuanto más cercano a 1, más abierto es el entorno). También utilizaremos dos medidas adicionales, más clásicas [10]: la longitud del camino característico (CPL) y el coeficiente de agrupamiento (CC). • Número de agentes: la propagación de la información también depende del número inicial de agentes involucrados durante una experimentación. Por ejemplo, cuantos más agentes haya, más potenciales comunicaciones existen. Esto significa que habrá más potencial de propagación, pero también que la restricción de intercambio bilateral será más crucial. 3 El CPL es la mediana de las medias de las longitudes de los caminos más cortos que conectan cada nodo con todos los demás nodos. 4 caracterizando el grado de aislamiento de una región de un entorno en términos de accesibilidad (número de caminos aún utilizables para llegar a esta región). Mapa T.I. (%) C.P.L. C.C. 69-1 69,23 4,5 0,69 69-2 68,88 4,38 0,65 69-3 69,80 4,25 0,67 53-1 53,19 5,6 0,59 53-2 53,53 6,38 0,54 53-3 53,92 6,08 0,61 38-1 38,56 8,19 0,50 38-2 38,56 7,3 0,50 38-3 38,23 8,13 0,50 Tabla 1: Características Topológicas de los Mapas • Posiciones iniciales de los agentes- Las posiciones iniciales de los agentes tienen una influencia significativa en el comportamiento general de una instancia de nuestro sistema: estar cerca de una salida facilitará (en general) la escapatoria. 5.3 Entornos experimentales Elegimos realizar experimentos en tres índices topológicos muy diferentes (69% para entornos abiertos, 53% para entornos mixtos y 38% para entornos tipo laberinto). Figura 2: Dos mapas (izquierda: IT=69%, derecha IT=38%) Diseñamos tres mapas diferentes para cada índice (la Fig. 2 muestra dos de ellos), conteniendo el mismo número máximo de agentes (máximo 36 agentes) con una densidad máxima de un agente por celda, el mismo número de salidas y un origen de incendio similar (por ejemplo, tiempo y posición de inicio). Los tres mapas diferentes de un índice dado están diseñados de la siguiente manera. El primer plano es un modelo de un piso de un edificio existente. El segundo mapa tiene el mismo perímetro, salidas y origen del fuego que el primero, pero la cantidad y ubicación de las paredes son diferentes (las ubicaciones de las paredes son diseñadas por una heurística que crea paredes de forma aleatoria en la cuadrícula espacial de manera que no se creen habitaciones completamente cerradas y que ninguna salida quede bloqueada). El tercer mapa se caracteriza por un recinto geométrico en el que la ubicación de las paredes también está diseñada con la heurística mencionada anteriormente. La Tabla 1 resume las diferentes medidas topológicas que caracterizan estos mapas diferentes. Vale la pena señalar que los valores confirman la relevancia de TI (los mapas con un alto TI tienen un bajo CPL y un alto CC). Sin embargo, el CPL y el CC permiten refinar aún más la diferencia entre los mapas, por ejemplo, entre 53-1 y 53-2). 5.4 Resultados Experimentales Para cada trío de mapas definidos como se mencionó anteriormente, llevamos a cabo los mismos experimentos. En cada experimento, la sociedad difiere en cuanto a su proporción inicial de agentes involucrados, desde el 1% hasta el 100%. Esta proporción inicial representa el porcentaje de agentes involucrados con respecto al número máximo posible de agentes. Para cada mapa y cada proporción inicial, la Sexta Internacional. En la Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) seleccionamos aleatoriamente 100 ubicaciones iniciales de agentes diferentes. Para cada una de esas ubicaciones diferentes ejecutamos el sistema una vez para cada protocolo de interacción diferente. La efectividad de la comunicación y argumentación El primer experimento que hemos establecido tiene como objetivo probar cuán efectivo es el intercambio de hipótesis (IH), y en particular cómo los aspectos topológicos afectarán esta efectividad. Para hacerlo, hemos calculado la proporción de mejora ofrecida por ese protocolo sobre una situación en la que los agentes simplemente no podían comunicarse (sin comunicación). Para obtener más información sobre en qué medida el intercambio de hipótesis fue realmente crucial, también probamos un protocolo mucho menos elaborado que consistía en intercambios de observaciones simples (OE). Más precisamente, este protocolo requiere que cada agente almacene cualquier observación inesperada que perciba, y los agentes simplemente intercambian sus respectivas listas de observaciones cuando discuten. En este caso, el protocolo local es diferente (nota en particular que no garantiza consistencia mutua), pero el protocolo global permanece igual (con la única excepción de que la motivación de los agentes para comunicarse es sincronizar su lista de observaciones, no sus hipótesis). Si este protocolo es como máximo tan efectivo como HE, tiene la ventaja de ser más eficiente (esto es obvio en cuanto al número de mensajes, que se limitará a 2, menos directo en lo que respecta al tamaño de los mensajes, pero la observación general de que el intercambio de observaciones se puede ver como una versión simplificada del desafío es útil para ver esto). Los resultados de estos experimentos se informan en la Figura 3. Figura 3: Ganancia de la proporción de efectividad comparativa de los protocolos cuando la proporción de agentes aumenta. La primera observación que debe hacerse es que la comunicación mejora la efectividad del proceso, y esta proporción aumenta a medida que el número de agentes crece en el sistema. La segunda lección que aprendemos aquí es que la cercanía relativamente hace que la comunicación sea más efectiva que la falta de comunicación. Los mapas que muestran un T.I. del 38% están constantemente por encima de los otros dos, y el 53% sigue siendo ligeramente pero significativamente mejor que el 69%. Sin embargo, estas curvas también sugieren, quizás sorprendentemente, que HE supera a OE precisamente en aquellas situaciones donde la ganancia de la relación es menos importante (la única diferencia notable ocurre en mapas bastante abiertos donde T.I. es del 69%). Esto se puede explicar de la siguiente manera: cuando un mapa está abierto, los agentes tienen muchos posibles candidatos de explicación, y la argumentación se vuelve útil para discriminar entre ellos. Cuando un mapa es laberíntico, hay menos posibles explicaciones para un evento inesperado. Importancia del Protocolo Global El segundo conjunto de experimentos busca evaluar la importancia del diseño del protocolo global. Probamos nuestro protocolo contra un protocolo de difusión local (LB). La difusión local significa que todos los agentes vecinos percibidos por un agente estarán involucrados en una comunicación con ese agente en una ronda dada, aliviando la restricción de una sola comunicación por agente. Esto nos proporciona un límite superior aproximado sobre la posible ganancia de ratio en el sistema (para un protocolo local dado). Nuevamente, evaluamos la ganancia de la relación inducida por ese LB sobre nuestro HE clásico, para las tres clases diferentes de mapas. Los resultados se informan en la Figura 4. Figura 4: Ganancia de la proporción de transmisión local sobre el intercambio de hipótesis. Tenga en cuenta que la ganancia de la proporción es 0 cuando la proporción de agentes es del 5%, lo cual se explica fácilmente por el hecho de que corresponde a situaciones que involucran solo a dos agentes. Primero observamos que todas las clases de mapas muestran un aumento en la ganancia de la proporción a medida que aumenta el número de agentes: la ganancia alcanza entre el 10 y el 20%, dependiendo de la clase de mapas considerada. Si se compara esto con la mejora reportada en el experimento anterior, parece ser de la misma magnitud. Esto ilustra que el diseño del protocolo global no puede ser ignorado, especialmente cuando la proporción de agentes es alta. Sin embargo, también observamos que las curvas de ganancia de la proporción de efectividad tienen formas muy diferentes en ambos casos: la ganancia inducida por la precisión del protocolo local aumenta muy rápidamente con la proporción de agentes, mientras que la curva es muy suave para el global. Ahora observemos con más cuidado los resultados reportados aquí: la curva correspondiente a una TI del 53% está por encima de la correspondiente al 38%. Esto se debe a que cuanto más abierta sea un mapa, más oportunidades hay de comunicarse con más de un agente (y por lo tanto beneficiarse de la difusión). Sin embargo, también observamos que la curva para el 69% está por debajo de la del 53%. Esto se explica de la siguiente manera: en el caso del 69%, la ganancia potencial en términos de agentes sobrevivientes es mucho menor, porque nuestros protocolos ya ofrecen resultados bastante eficientes de todos modos (alcanzando rápidamente el 90%, ver Fig. 3). Una regla general podría ser que cuando el número de agentes es pequeño, se debe prestar especial atención al local 1004 de la Sexta Internacional. En el caso de que el número de agentes sea pequeño, uno puede utilizar el protocolo de la Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07), mientras que cuando ese número es grande, se debe diseñar cuidadosamente uno global (a menos que el mapa sea tan abierto que el protocolo ya sea casi óptimamente eficiente). La eficiencia de los protocolos. El experimento final reportado aquí se centra en el análisis de la eficiencia de los protocolos. Aquí analizamos el tamaño medio de la totalidad de los mensajes que son intercambiados por agentes (tamaño medio de intercambios, en resumen) utilizando los siguientes protocolos: HE, OE y dos protocolos variantes. El primero es un protocolo de intercambio de hipótesis restringidas (RHE) intermediario. RHE es el siguiente: no implica ningún desafío ni contraoferta, lo que significa que los agentes no pueden cambiar su rol durante el protocolo (esto difiere de RE en ese aspecto). En resumen, RHE permite a un agente agotar las críticas de sus socios, y eventualmente este socio adoptará la hipótesis del agente. Ten en cuenta que esto significa que la autonomía del agente no se conserva aquí (ya que un agente esencialmente aceptará cualquier hipótesis que no pueda socavar), con la esperanza de que la ganancia en eficiencia sea lo suficientemente significativa como para compensar una pérdida en efectividad. El segundo protocolo de variante es un protocolo completo de intercambio de observaciones (COE). COE utiliza los mismos principios que OE, pero incluye además todos los ejemplos críticos negativos (nofire) en el intercambio (dando así todos los ejemplos utilizados como argumentos por el protocolo de intercambio de hipótesis), mejorando así la efectividad. Los resultados para el mapa 69-1 se muestran en la Figura 5. Figura 5: Tamaño medio de los intercambios. Primero podemos observar el hecho de que el orden de los protocolos, desde el menos eficiente hasta el más eficiente, es COE, HE, RHE y luego OE. ÉL siendo más eficiente que COE demuestra que el proceso de argumentación gana eficiencia al seleccionar cuándo es necesario proporcionar ejemplos negativos, los cuales tienen menos impacto que los positivos en nuestro entorno de prueba específico. Sin embargo, al comunicar hipótesis antes de proporcionar observaciones para respaldarla (HE) en lugar de dar directamente las observaciones más cruciales (OE), el proceso de argumentación duplica el tamaño de los intercambios de datos. Es el costo de garantizar la consistencia al final del intercambio (una propiedad que OE no admite). También es significativo el hecho de que el tamaño promedio de los intercambios es ligeramente mayor cuando el número de agentes es pequeño. Esto se explica por el hecho de que en estos casos solo unos pocos agentes tienen información relevante en su posesión, y que necesitarán comunicarse mucho para llegar a un punto de vista común de la situación. Cuando el número de agentes aumenta, este conocimiento se distribuye entre más agentes que necesitan discusiones más cortas para llegar a una consistencia mutua. Como consecuencia, la ganancia relativa en eficiencia de usar RHE parece ser mejor cuando el número de agentes es pequeño: cuando es alto, difícilmente discutirán de todos modos. Finalmente, vale la pena notar que la desviación estándar para estos experimentos es bastante alta, lo que significa que la conversación no converge hacia ningún patrón estereotípico. 6. CONCLUSIÓN Este documento ha investigado las propiedades de un sistema multiagente donde cada agente (distribuido) percibe localmente su entorno e intenta alcanzar consistencia con otros agentes a pesar de severas restricciones de comunicación. En particular, hemos expuesto condiciones que permiten la convergencia e investigado experimentalmente una situación típica donde esas condiciones no pueden cumplirse. Hay muchas posibles extensiones a este trabajo, la primera siendo investigar más a fondo las propiedades de diferentes protocolos globales pertenecientes a la clase que identificamos, y su influencia en el resultado. Existen en particular muchas heurísticas, altamente dependientes del contexto del estudio, que podrían intuitivamente arrojar resultados interesantes (en nuestro estudio, seleccionar al destinatario en función de lo que se pueda inferir de sus acciones observadas podría ser una de esas heurísticas). Un candidato obvio para problemas a largo plazo se refiere a la relajación de la suposición de un sensor perfecto. 7. REFERENCIAS [1] G. Bourgne, N. Maudet y S. Pinson. Cuando los agentes comunican hipótesis en situaciones críticas. En Actas de DALT-2006, mayo de 2006. [2] P. Harvey, C. F. Chang y A. Ghose. Búsqueda distribuida basada en soporte: un nuevo enfoque para el procesamiento de restricciones multiagente. En Actas de AAMAS06, 2006. [3] H. Jung y M. Tambe. Argumentación como satisfacción de restricciones distribuida: Aplicaciones y resultados. En Actas de AGENTS01, 2001. [4] N. C. Karunatillake y N. R. Jennings. ¿Vale la pena discutir? En Actas de ArgMAS 2004, 2004. [5] S. Onta˜n´on y E. Plaza. Argumentos y contraejemplos en la deliberación conjunta basada en casos. En Actas de ArgMAS-2006, mayo de 2006. [6] D. Poole. Explicación y predicción: Una arquitectura para el razonamiento por defecto y abductivo. Inteligencia Computacional, 5(2):97-110, 1989. [7] I. Rahwan, S. D. Ramchurn, N. R. Jennings, P. McBurney, S. Parsons y L. Sonenberg. Negociación basada en argumentos. La revisión de Ingeniería del Conocimiento, 4(18):345-375, 2003. [8] N. Roos, A. ten Tije y C. Witteveen. Un protocolo para el diagnóstico multiagente con conocimiento distribuido espacialmente. En Actas de AAMAS03, 2003. [9] N. Roos, A. ten Tije y C. Witteveen. Alcanzando acuerdo diagnóstico en el diagnóstico multiagente. En Actas de AAMAS04, 2004. [10] T. Takahashi, Y. Kaneda y N. Ito. Estudio preliminar: utilizando simulaciones de RoboCupRescue para la prevención de desastres. En Actas de SRMED2004, 2004. El Sexto Internacional. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 1005 ",
            "candidates": [],
            "error": [
                [
                    "hipótesis favorita",
                    "hipótesis preferida",
                    "hipótesis actual favorita"
                ]
            ]
        },
        "global consistency": {
            "translated_key": "consistencia global",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Hypotheses Refinement under Topological Communication Constraints ∗ Gauvain Bourgne, Gael Hette, Nicolas Maudet, and Suzanne Pinson LAMSADE, Univ.",
                "Paris-Dauphine, France {bourgne,hette,maudet,pinson}@lamsade.dauphine.fr ABSTRACT We investigate the properties of a multiagent system where each (distributed) agent locally perceives its environment.",
                "Upon perception of an unexpected event, each agent locally computes its favoured hypothesis and tries to propagate it to other agents, by exchanging hypotheses and supporting arguments (observations).",
                "However, we further assume that communication opportunities are severely constrained and change dynamically.",
                "In this paper, we mostly investigate the convergence of such systems towards <br>global consistency</br>.",
                "We first show that (for a wide class of protocols that we shall define), the communication constraints induced by the topology will not prevent the convergence of the system, at the condition that the system dynamics guarantees that no agent will ever be isolated forever, and that agents have unlimited time for computation and arguments exchange.",
                "As this assumption cannot be made in most situations though, we then set up an experimental framework aiming at comparing the relative efficiency and effectiveness of different interaction protocols for hypotheses exchange.",
                "We study a critical situation involving a number of agents aiming at escaping from a burning building.",
                "The results reported here provide some insights regarding the design of optimal protocol for hypotheses refinement in this context.",
                "Categories and Subject Descriptors I.2.11 [Artificial Intelligence]: Distributed Artificial Intelligence-Multiagent systems General Terms Theory, Experimentation 1.",
                "INTRODUCTION We consider a multiagent system where each (distributed) agent locally perceives its environment, and we assume that some unexpected event occurs in that system.",
                "If each agent computes only locally its favoured hypothesis, it is only natural to assume that agents will seek to coordinate and refine their hypotheses by confronting their observations with other agents.",
                "If, in addition, the communication opportunities are severely constrained (for instance, agents can only communicate when they are close enough to some other agent), and dynamically changing (for instance, agents may change their locations), it becomes crucial to carefully design protocols that will allow agents to converge to some desired state of <br>global consistency</br>.",
                "In this paper we exhibit some sufficient conditions on the system dynamics and on the protocol/strategy structures that allow to guarantee that property, and we experimentally study some contexts where (some of) these assumptions are relaxed.",
                "While problems of diagnosis are among the venerable classics in the AI tradition, their multiagent counterparts have much more recently attracted some attention.",
                "Roos and colleagues [8, 9] in particular study a situation where a number of distributed entities try to come up with a satisfying global diagnosis of the whole system.",
                "They show in particular that the number of messages required to establish this global diagnosis is bound to be prohibitive, unless the communication is enhanced with some suitable protocol.",
                "However, they do not put any restrictions on agents communication options, and do not assume either that the system is dynamic.",
                "The benefits of enhancing communication with supporting information to make convergence to a desired global state of a system more efficient has often been put forward in the literature.",
                "This is for instance one of the main idea underlying the argumentation-based negotiation approach [7], where the desired state is a compromise between agents with conflicting preferences.",
                "Many of these works however make the assumption that this approach is beneficial to start with, and study the technical facets of the problem (or instead emphasize other advantages of using argumentation).",
                "Notable exceptions are the works of [3, 4, 2, 5], which studied in contexts different from ours the efficiency of argumentation.",
                "The rest of the paper is as follows.",
                "Section 2 specifies the basic elements of our model, and Section 3 goes on to presenting the different protocols and strategies used by the agents to exchange hypotheses and observations.",
                "We put special attention at clearly emphasizing the conditions on the system dynamics and protocols/strategies that will be exploited in the rest of the paper.",
                "Section 4 details one of 998 978-81-904262-7-5 (RPS) c 2007 IFAAMAS the main results of the paper, namely the fact that under the aforementioned conditions, the constraints that we put on the topology will not prevent the convergence of the system towards <br>global consistency</br>, at the condition that no agent ever gets completely lost forever in the system, and that unlimited time is allowed for computation and argument exchange.",
                "While the conditions on protocols and strategies are fairly mild, it is also clear that these system requirements look much more problematic, even frankly unrealistic in critical situations where distributed approaches are precisely advocated.",
                "To get a clearer picture of the situation induced when time is a critical factor, we have set up an experimental framework that we introduce and discuss in Section 5.",
                "The critical situation involves a number of agents aiming at escaping from a burning building.",
                "The results reported here show that the effectiveness of argument exchange crucially depends upon the nature of the building, and provide some insights regarding the design of optimal protocol for hypotheses refinement in this context. 2.",
                "BASIC NOTIONS We start by defining the basic elements of our system.",
                "Environment Let O be the (potentially infinite) set of possible observations.",
                "We assume the sensors of our agents to be perfect, hence the observations to be certain.",
                "Let H be the set of hypotheses, uncertain and revisable.",
                "Let Cons(h, O) be the consistency relation, a binary relation between a hypothesis h ∈ H and a set of observations O ⊆ O.",
                "In most cases, Cons will refer to classical consistency relation, however, we may overload its meaning and add some additional properties to that relation (in which case we will mention it).",
                "The environment may include some dynamics, and change over the course of time.",
                "We define below sequences of time points to deal with it: Definition 1 (Sequence of time points).",
                "A sequence of time points t1, t2, . . . , tn from t is an ordered set of time points t1, t2, . . . , tn such that t1 ≥ t and ∀i ∈ [1, n − 1], ti+1 ≥ ti.",
                "Agent We take a system populated by n agents a1, . . . , an.",
                "Each agent is defined as a tuple F, Oi, hi , where: • F, the set of facts, common knowledge to all agents. • Oi ∈ 2O , the set of observations made by the agent so far.",
                "We assume a perfect memory, hence this set grows monotonically. • hi ∈ H, the favourite hypothesis of the agent.",
                "A key notion governing the formation of hypotheses is that of consistency, defined below: Definition 2 (Consistency).",
                "We say that: • An agent is consistent (Cons(ai)) iff Cons(hi, Oi) (that is, its hypothesis is consistent with its observation set). • An agent ai consistent with a partner agent aj iff Cons(ai) and Cons(hi, Oj) (that is, this agent is consistent and its hypothesis can explain the observation set of the other agent). • Two agents ai and aj are mutually consistent (MCons(ai, aj)) iff Cons(ai, aj) and Cons(aj, ai). • A system is consistent iff ∀(i, j)∈[1, n]2 it is the case that MCons(ai, aj).",
                "To ensure its consistency, each agent is equipped with an abstract reasoning machinery that we shall call the explanation function Eh.",
                "This (deterministic) function takes a set of observation and returns a single prefered hypothesis (2O → H).",
                "We assume h = Eh(O) to be consistent with O by definition of Eh, so using this function on its observation set to determine its favourite hypothesis is a sure way for the agent to achieve consistency.",
                "Note however that an hypothesis does not need to be generated by Eh to be consistent with an observation set.",
                "As a concrete example of such a function, and one of the main inspiration of this work, one can cite the Theorist reasoning system [6] -as long as it is coupled with a filter selecting a single prefered theory among the ones initially selected by Theorist.",
                "Note also that hi may only be modified as a consequence of the application Eh.",
                "We refer to this as the autonomy of the agent: no other agent can directly impose a given hypothesis to an agent.",
                "As a consequence, only a new observation (being it a new perception, or an observation communicated by a fellow agent) can result in a modification of its prefered hypothesis hi (but not necessarily of course).",
                "We finally define a property of the system that we shall use in the rest of the paper: Definition 3 (Bounded Perceptions).",
                "A system involves a bounded perception for agents iff ∃n0 s.t. ∀t| ∪N i=1 Oi| ≤ n0. (That is, the number of observations to be made by the agents in the system is not infinite.)",
                "Agent Cycle Now we need to see how these agents will evolve and interact in their environment.",
                "In our context, agents evolve in a dynamic environment, and we classicaly assume the following system cycle: 1.",
                "Environment dynamics: the environment evolves according to the defined rules of the system dynamics. 2.",
                "Perception step : agents get perceptions from the environment.",
                "These perceptions are typically partial (e.g. the agent can only see a portion of a map). 3.",
                "Reasoning step: agents compare perception with predictions, seek explanations for (potential) difference(s), refine their hypothesis, draw new conclusions. 4.",
                "Communication step: agents can communicate hypotheses and observations with other agents through a defined protocol.",
                "Any agent can only be involved in one communication with another agent by step. 5.",
                "Action step: agents do some practical reasoning using the models obtained from the previous steps and select an action.",
                "They can then modify the environment by executing it.",
                "The communication of the agents will be further constrained by topological consideration.",
                "At a given time, an agent will only be able to communicate with a number of neighbours.",
                "Its connexions with these others agents may The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 999 evolve with its situation in the environment.",
                "Typically, an agent can only communicate with agents that it can sense, but one could imagine evolving topological constraints on communication based on a network of communications between agents where the links are not always active.",
                "Communication In our system, agents will be able to communicate with each other.",
                "However, due to the aforementionned topological constraints, they will not be able to communicate with any agents at anytime.",
                "Who an agent can communicate with will be defined dynamically (for instance, this can be a consequence of the agents being close enough to get in touch).",
                "We will abstractly denote by C(ai, aj, t) the communication property, in other words, the fact that agents ai and aj can communicate at time t (note that this relation is assumed to be symetric, but of course not transitive).",
                "We are now in a position to define two essential properties of our system.",
                "Definition 4 (Temporal Path).",
                "There exists a temporal communication path at horizon tf (noted Ltf (aI , aJ )) between ai and aj iff there exists a sequence of time points t1, t2, . . . , tn from tf and a sequence of agents k1, k2, . . . , kn s.t. (i) C(aI , ak1 , t1), (ii) C(akn , aJ , tn+1), (iii) ∀i ∈ [1, n], C(aki , aki+1 , ti) Intuitively, what this property says is that it is possible to find a temporal path in the future that would allow to link agent ai and aj via a sequence of intermediary agents.",
                "Note that the time points are not necessarily successive, and that the sequence of agents may involve the same agents several times.",
                "Definition 5 (Temporal Connexity).",
                "A system is temporaly connex iff ∀t ∀(i, j)∈[1, n]2 Lt(ai, aj) In short, a temporaly connex system guarantees that any agent will be able to communicate with any other agents, no matter how long it might take to do so, at any time.",
                "To put it another way, it is never the case that an agent will be isolated for ever from another agent of the system.",
                "We will next discuss the detail of how communication concretely takes place in our system.",
                "Remember that in this paper, we only consider the case of bilateral exchanges (an agent can only speak to a single other agent), and that we also assume that any agent can only engage in a single exchange in a given round. 3.",
                "PROTOCOLS AND STRATEGIES In this section, we discuss the requirements of the interaction protocols that govern the exchange of messages between agents, and provide some example instantiation of such protocols.",
                "To clarify the presentation, we distinguish two levels: the local level, which is concerned with the regulation of bilateral exchanges; and the global level,which essentially regulates the way agents can actually engage into a conversation.",
                "At each level, we separate what is specified by the protocol, and what is left to agents strategies.",
                "Local Protocol and Strategies We start by inspecting local protocols and strategies that will regulate the communication between the agents of the system.",
                "As we limit ourselves to bilateral communication, these protocols will simply involve two agents.",
                "Such protocol will have to meet one basic requirement to be satisfying. • consistency (CONS)- a local protocol has to guarantee the mutual consistency of agents upon termination (which implies termination of course).",
                "Figure 1: A Hypotheses Exchange Protocol [1] One example such protocol is the protocol described in [1] that is pictured in Fig. 1.",
                "To further illustrate how such protocol can be used by agents, we give some details on a possible strategy: upon receiving a hypothesis h1 (propose(h1) or counterpropose(h1)) from a1, agent a2 is in state 2 and has the following possible replies: counterexample (if the agent knows an example contradicting the hypothesis, or not explained by this hypothesis), challenge (if the agents lacks evidence to accept this hypothesis), counterpropose (if the agent agrees with the hypothesis but prefers another one), or accept (if it is indeed as good as its favourite hypothesis).",
                "This strategy guarantees, among other properties, the eventual mutual logical consistency of the involved agents [1].",
                "Global Protocol The global protocol regulates the way bilateral exchanges will be initiated between agents.",
                "At each turn, agents will concurrently send one weighted request to communicate to other agents.",
                "This weight is a value measuring the agents willingness to converse with the targeted agent (in practice, this can be based on different heuristics, but we shall make some assumptions on agents strategies, see below).",
                "Sending such a request is a kind of conditional commitment for the agent.",
                "An agent sending a weighted request commits to engage in conversation with the target if he does not receive and accept himself another request.",
                "Once all request have been received, each agent replies with either an acccept or a reject.",
                "By answering with an accept, an agent makes a full commitment to engage in conversation with the sender.",
                "Therefore, it can only send one accept in a given round, as an agent can only participate in one conversation per time step.",
                "When all response have been received, each agent receiving an accept can either initiate a conversation using the local protocol or send a cancel if it has accepted another request.",
                "At the end of all the bilateral exchanges, the agents engaged in conversation are discarded from the protocol.",
                "Then each of the remaining agents resends a request and the process iterates until no more requests are sent.",
                "Global Strategy We now define four requirements for the strategies used by agents, depending on their role in the protocol: two are concerned with the requestee role (how to decide who the 1000 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) agent wishes to communicate with? ), the other two with the responder role (how to decide which communication request to accept or not?). • Willingness to solve inconsistancies (SOLVE)-agents want to communicate with any other agents unless they know they are mutually consistent. • Focus on solving inconsistencies (FOCUS)-agents do not request communication with an agent with whom they know they are mutually consistent. • Willingness to communicate (COMM)-agents cannot refuse a weighted communication request, unless they have just received or send a request with a greater weight. • Commitment to communication request (REQU)agents cannot accept a weighted communication request if they have themselves sent a communication request with a greater weight.",
                "Therefore, they will not cancel their request unless they have received a communicational request with greater weight.",
                "Now the protocol structure, together with the properties COMM+REQU, ensure that a request can only be rejected if its target agent engages in communication with another agent.",
                "Suppose indeed that agent ai wants to communicate with aj by sending a request with weight w. COMM guarantees that an agent receiving a weighted request will either accept this communication, accept a communication with a greater weight or wait for the answer to a request with a greater weight.",
                "This ensures that the request with maximal weight will be accepted and not cancelled (as REQU ensures that an agent sending a request can only cancel it if he accepts another request with greater weight).",
                "Therefore at least two agents will engage in conversation per round of the global protocol.",
                "As the protocol ensures that ai can resend its request while aj is not engaged in a conversation, there will be a turn in which aj must engage in a conversation, either with ai or another agent.",
                "These requirements concern request sending and acceptation, but agents also need some strategy of weight attribution.",
                "We describe below an altruist strategy, used in our experiments.",
                "Being cooperative, an agent may want to know more of the communication wishes of other agents in order to improve the overall allocation of exchanges to agents.",
                "A context request step is then added to the global protocol.",
                "Before sending their chosen weighted request, agents attribute a weight to all agents they are prepared to communicate with, according to some internal factors.",
                "In the simplest case, this weight will be 1 for all agent with whom the agent is not sure of being mutually consistent (ensuring SOLVE), other agent being not considered for communication (ensuring FOCUS).",
                "The agent then sends a context request to all agents with whom communication is considered.",
                "This request also provides information about the sender (list of considered communications along with their weight).",
                "After reception of all the context requests, agents will either reply with a deny, iff they are already engaged in a conversation (in which case, the requesting agent will not consider communication with them anymore in this turn), or an inform giving the requester information about the requests it has sent and received.",
                "When all replies have been received, each agent can calculate the weight of all requests concerning it.",
                "It does so by substracting from the weight of its request the weight of all requests concerning either it or its target (that is, the final weight of the request from ai to aj is Wi,j = wi,j +wj,i − ( P k∈R(i)−{j} wi,k + P k∈S(i)−{j} wk,i + P k∈R(j)−{i} wj,k + P k∈S(j)−{i} wk,j) where wi,j is the weight of the request of ai to aj, R(i) is the set of indice of agents having received a request from ai and S(i) is the set of indice of agents having send a request to ai).",
                "It then finally sends a weighted request to the agents who maximise this weight (or wait for a request) as described in the global protocol. 4. (CONDITIONAL) CONVERGENCE TO <br>global consistency</br> In this section we will show that the requirements regarding protocols and strategies just discussed will be sufficient to ensure that the system will eventually converge towards <br>global consistency</br>, under some conditions.",
                "We first show that, if two agents are not mutually consistent at some time, then there will be necessarily a time in the future such that an agent will learn a new observation, being it because it is new for the system, or by learning it from another agent.",
                "Lemma 1.",
                "Let S be a system populated by n agents a1, a2, ..., an, temporaly connex, and involving bounded perceptions for these agents.",
                "Let n1 be the sum of cardinalities of the intersection of pairwise observation sets. (n1 = P (i,j)∈[1,n]2 |Oi ∩ Oj|) Let n2 be the cardinality of the union of all agents observations sets. (n2 = | ∪N i=1 Oi|).",
                "If ¬MCons(ai, aj) at time t0, there is necessarily a time t > t0 s.t. either n1 or n2 will increase.",
                "Proof.",
                "Suppose that there exist a time t0 and indices (i, j) s.t. ¬MCons(ai, aj).",
                "We will use mt0 = P (k,l)∈[1,n]2 εComm(ak, al, t0) where εComm(ak, al, t0) = 1 if ak and al have communicated at least once since t0, and 0 otherwise.",
                "Temporal connexity guarantees that there exist t1, ..., tm+1 and k1, ..., km s.t.",
                "C(ai, ak1 , t1), C(akm , aj, tm+1), and ∀p ∈ [1, m], C(akp , akp+1 , tp).",
                "Clearly, if MCons(ai, ak1 ), MCons(akm , aj) and ∀p, MCons(akp , akp+1 ), we have MCons(ai, aj) which contradicts our hypothesis (MCons being transitive, MCons(ai, ak1 )∧MCons(ak1 , ak2 ) implies that MCons(ai, ak2 ) and so on till MCons(ai, akm )∧ MCons(akm , aj) which implies MCons(ai, aj) ).",
                "At least two agents are then necessarily inconsistent (¬MCons(ai, ak1 ), or ¬MCons(akm , aj), or ∃p0 t.q. ¬MCons(akp0 , akp0+1 )).",
                "Let ak and al be these two neighbours at a time t > t0 1 .",
                "The SOLVE property ensures that either ak or al will send a communication request to the other agent at time t .",
                "As shown before, this in turn ensures that at least one of these agents will be involved in a communication.",
                "Then there are two possibilities: (case i) ak and al communicate at time t .",
                "In this case, we know that ¬MCons(ak, al).",
                "This and the CONS property ensures that at least one of the agents must change its 1 Strictly speaking, the transitivity of MCons only ensure that ak and al are inconsistent at a time t ≥ t0 that can be different from the time t at which they can communicate.",
                "But if they become consistent between t and t (or inconsistent between t and t ), it means that at least one of them have changed its hypothesis between t and t , that is, after t0.",
                "We can then apply the reasoning of case iib.",
                "The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 1001 hypothesis, which in turn, since agents are autonomous, implies at least one exchange of observation.",
                "But then |Ok ∩Ol| is bound to increase: n1(t ) > n1(t0). (case ii) ak communicates with ap at time t .",
                "We then have again two possibilities: (case iia) ak and ap did not communicate since t0.",
                "But then εComm(ak, ap, t0) had value 0 and takes value 1.",
                "Hence mt0 increases. (case iib) ak and ap did communicate at some time t0 > t0.",
                "The CONS property of the protocol ensures that MCons(ak, ap) at that time.",
                "Now the fact that they communicate and FOCUS implies that at least one of them did change its hypothesis in the meantime.",
                "The fact that agents are autonomous implies in turn that a new observation (perceived or received from another agent) necessarily provoked this change.",
                "The latter case would ensure the existence of a time t > t0 and an agent aq s.t. either |Op ∩Oq| or |Ok ∩Oq| increases of 1 at that time (implying n1(t ) > n1(t0)).",
                "The former case means that the agent gets a new perception o at time t .",
                "If that observation was unknown in the system before, then n2(t ) > n2(t0).",
                "If some agent aq already knew this observation before, then either Op ∩ Oq or Ok ∩ Oq increases of 1 at time t (which implies that n1(t ) > n1(t0)).",
                "Hence, ¬MCons(ai, aj) at time t0 guarantees that, either: −∃t > t0 t.q. n1(t ) > n1(t0); or −∃t > t0 t.q. n2(t ) > n2(t0); or −∃t > t0 t.q. mt0 increases of 1 at time t .",
                "By iterating the reasoning with t (but keeping t0 as the time reference for mt0 ), we can eliminate the third case (mt0 is integer and bounded by n2 , which means that after a maximum of n2 iterations, we necessarily will be in one of two other cases.)",
                "As a result, we have proven that if ¬MCons(ai, aj) at time t0, there is necessarily a time t s.t. either n1 or n2 will increase.",
                "Theorem 1 (<br>global consistency</br>).",
                "Let S be a system populated by n agents a1, a2, ..., an, temporaly connex, and involving bounded perceptions for these agents.",
                "Let Cons(ai, aj) be a transitive consistency property.",
                "Then any protocol and strategies satisfying properties CONS, SOLVE, FOCUS, COMM and REQU guarantees that the system will converge towards <br>global consistency</br>.",
                "Proof.",
                "For the sake of contradiction, let us assume ∃I, J ∈ [1, N] s.t. ∀t, ∃t0 > t, t.q. ¬Cons(aI , aJ , t0).",
                "Using the lemma, this implies that ∃t > t0 s.t. either n1(t ) > n1(t0) or n2(t ) > n2(t0).",
                "But we can apply the same reasoning taking t = t , which would give us t1 > t > t0 s.t. ¬Cons(aI , aJ , t1), which gives us t > t1 s.t. either n1(t ) > n1(t1) or n2(t ) > n2(t1).",
                "By successive iterations we can then construct a sequence t0, t1, ..., tn, which can be divided in two sub-sequences t0, t1, ...tn and t0 , t1 , ..., tn s.t. n1(t0) < n1(t1) < ... < n1(tn) and n2(t0 ) < n2(t1 ) < ... < n2(tn).",
                "One of these sub-sequences has to be infinite.",
                "However, n1(ti) and n2(ti ) are strictly growing, integer, and bounded, which implies that both are finite.",
                "Contradiction.",
                "What the previous result essentially shows is that, in a system where no agent will be isolated from the rest of the agents for ever, only very mild assumptions on the protocols and strategies used by agents suffice to guarantee convergence towards system consistency in a finite amount of time (although it might take very long).",
                "Unfortunately, in many critical situations, it will not be possible to assume this temporal connexity.",
                "As distributed approaches as the one advocated in this paper are precisely often presented as a good way to tackle problems of reliability or problems of dependence to a center that are of utmost importance in these critical applications, it is certainly interesting to further explore how such a system would behave when we relax this assumption. 5.",
                "EXPERIMENTAL STUDY This experiment involves agents trying to escape from a burning building.",
                "The environment is described as a spatial grid with a set of walls and (thankfully) some exits.",
                "Time and space are considered discrete.",
                "Time is divided in rounds.",
                "Agents are localised by their position on the spatial grid.",
                "These agents can move and communicate with other agents.",
                "In a round, an agent can move of one cell in any of the four cardinal directions, provided it is not blocked by a wall.",
                "In this application, agents communicate with any other agent (but, recall, a single one) given that this agent is in view, and that they have not yet exchanged their current favoured hypothesis.",
                "Suddenly, a fire erupts in these premises.",
                "From this moment, the fire propagates.",
                "Each round, for each cases where there is fire, the fire propagates in the four directions.",
                "However, the fire cannot propagate through a wall.",
                "If the fire propagates in a case where an agent is positioned, that agent burns and is considered dead.",
                "It can of course no longer move nor communicate.",
                "If an agent gets to an exit, it is considered saved, and can no longer be burned.",
                "Agents know the environment and the rules governing the dynamics of this environment, that is, they know the map as well as the rules of fire propagation previously described.",
                "They also locally perceive this environment, but cannot see further than 3 cases away, in any direction.",
                "Walls also block the line of view, preventing agents from seeing behind them.",
                "Within their sight, they can see other agents and whether or not the cases they see are on fire.",
                "All these perceptions are memorised.",
                "We now show how this instantiates the abstract framework presented the paper. • O = {Fire(x, y, t), NoFire(x, y, t), Agent(ai, x, y, t)} Observations can then be positive (o ∈ P(O) iff ∃h ∈ H s.t. h |= o) or negative (o ∈ N(O) iff ∃h ∈ H s.t. h |= ¬o). • H={FireOrigin(x1, y1, t1)∧...∧FireOrigin(xl, yl, tl)} Hypotheses are conjunctions of FireOrigins. • Cons(h, O) consistency relation satisfies: - coherence : ∀o ∈ N(O), h |= ¬o. - completeness : ∀o ∈ P(O), h |= o. - minimality : For all h ∈ H, if h is coherent and complete for O, then h is prefered to h according to the preference relation (h ≤p h ).2 2 Selects first the minimal number of origins, then the most recent (least preemptive strategy [6]), then uses some arbitrary fixed ranking to discriminate ex-aequo.",
                "The resulting relation is a total order, hence minimality implies that there will be a single h s.t.Cons(O, h) for a given O.",
                "This in turn means that MCons(ai, aj) iff Cons(ai), Cons(aj), and hi = hj.",
                "This relation is then transitive and symmetric. 1002 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) • Eh takes O as argument and returns min≤p of the coherent and complete hypothesis for O 5.1 Experimental Evaluation We will classically (see e.g. [3, 4]) assess the effectiveness and efficiency of different interaction protocols.",
                "Effectiveness of a protocol The proportion of agents surviving the fire over the initial number of agents involved in the experiment will determine the effectiveness of a given protocol.",
                "If this value is high, the protocol has been effective to propagate the information and/or for the agents to refine their hypotheses and determine the best way to the exit.",
                "Efficiency of a protocol Typically, the use of supporting information will involve a communication overhead.",
                "We will assume here that the efficiency of a given protocol is characterised by the data flow induced by this protocol.",
                "In this paper we will only discuss this aspect wrt. local protocols.",
                "The main measure that we shall then use here is the mean total size of messages that are exchanged by agents per exchange (hence taking into account both the number of messages and the actual size of the messages, because it could be that messages happen to be very big, containing e.g. a large number of observations, which could counter-balance a low number of messages). 5.2 Experimental Settings The chosen experimental settings are the following: • Environmental topology- Performances of information propagation are highly constrained by the environment topology.",
                "The perception skills of the agents depend on the openness of the environment.",
                "With a large number of walls the perceptions of agents are limited, and also the number of possible inter-agent communications, whereas an open environment will provide optimal possibilities of perception and information propagation.",
                "Thus, we propose a topological index (see below) as a common basis to charaterize the environments (maps) used during experimentations.",
                "The topological index (TI) is the ratio of the number of cells that can be perceived by agents summed up from all possible positions, divided by the number of cells that would be perceived from the same positions but without any walls. (The closer to 1, the more open the environment).",
                "We shall also use two additional, more classical [10], measures: the characteristic path length3 (CPL) and the clustering coefficient4 (CC). • Number of agents- The propagation of information also depends on the initial number of agents involved during an experimentation.",
                "For instance, the more agents, the more potential communications there is.",
                "This means that there will be more potential for propagation, but also that the bilateral exchange restriction will be more crucial. 3 The CPL is the median of the means of the shortest path lengths connecting each node to all other nodes. 4 characterising the isolation degree of a region of an environment in terms of acessibility (number of roads still usable to reach this region).",
                "Map T.I. (%) C.P.L.",
                "C.C. 69-1 69,23 4,5 0,69 69-2 68,88 4,38 0,65 69-3 69,80 4,25 0,67 53-1 53,19 5,6 0,59 53-2 53,53 6,38 0,54 53-3 53,92 6,08 0,61 38-1 38,56 8,19 0,50 38-2 38,56 7,3 0,50 38-3 38,23 8,13 0,50 Table 1: Topological Characteristics of the Maps • Initial positions of the agents- Initial positions of the agents have a significant influence on the overall behavior of an instance of our system: being close from an exit will (in general) ease the escape. 5.3 Experimental environments We choose to realize experiments on three very different topological indexes (69% for open environments, 53% for mixed environments, and 38% for labyrinth-like environments).",
                "Figure 2: Two maps (left: TI=69%, right TI=38%) We designed three different maps for each index (Fig. 2 shows two of them), containing the same maximum number of agents (36 agents max.) with a maximum density of one agent per cell, the same number of exits and a similar fire origin (e.g. starting time and position).",
                "The three differents maps of a given index are designed as follows.",
                "The first map is a model of an existing building floor.",
                "The second map has the same enclosure, exits and fire origin as the first one, but the number and location of walls are different (wall locations are designed by an heuristic which randomly creates walls on the spatial grid such that no fully closed rooms are created and that no exit is closed).",
                "The third map is characterised by geometrical enclosure in wich walls location is also designed with the aforementioned heuristic.",
                "Table 1 summarizes the different topological measures characterizing these different maps.",
                "It is worth pointing out that the values confirm the relevance of TI (maps with a high TI have a low CPL and a high CC.",
                "However the CPL and CC allows to further refine the difference between the maps, e.g. between 53-1 and 53-2). 5.4 Experimental Results For each triple of maps defined as above we conduct the same experiments.",
                "In each experiment, the society differs in terms of its initial proportion of involved agents, from 1% to 100%.",
                "This initial proportion represents the percentage of involved agents with regards to the possible maximum number of agents.",
                "For each map and each initial proportion, The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 1003 we select randomly 100 different initial agents locations.",
                "For each of those different locations we execute the system one time for each different interaction protocol.",
                "Effectiveness of Communication and Argumentation The first experiment that we set up aims at testing how effective is hypotheses exchange (HE), and in particular how the topological aspects will affect this effectiveness.",
                "In order to do so, we have computed the ratio of improvement offered by that protocol over a situation where agents could simply not communicate (no comm).",
                "To get further insights as to what extent the hypotheses exchange was really crucial, we also tested a much less elaborated protocol consisting of mere observation exchanges (OE).",
                "More precisely, this protocol requires that each agent stores any unexpected observation that it perceives, and agents simply exchange their respective lists of observations when they discuss.",
                "In this case, the local protocol is different (note in particular that it does not guarantee mutual consistency), but the global protocol remains the same (at the only exception that agents motivation to communicate is to synchronise their list of observations, not their hypothesis).",
                "If this protocol is at best as effective as HE, it has the advantage of being more efficient (this is obvious wrt the number of messages which will be limited to 2, less straightforward as far as the size of messages is concerned, but the rough observation that the exchange of observations can be viewed as a flat version of the challenge is helpful to see this).",
                "The results of these experiments are reported in Fig. 3.",
                "Figure 3: Comparative effectiveness ratio gain of protocols when the proportion of agents augments The first observation that needs to be made is that communication improves the effectiveness of the process, and this ratio increases as the number of agents grows in the system.",
                "The second lesson that we learn here is that closeness relatively makes communication more effective over non communication.",
                "Maps exhibiting a T.I. of 38% are constantly above the two others, and 53% are still slightly but significantly better than 69%.",
                "However, these curves also suggest, perhaps surprisingly, that HE outperforms OE in precisely those situations where the ratio gain is less important (the only noticeable difference occurs for rather open maps where T.I. is 69%).",
                "This may be explained as follows: when a map is open, agents have many potential explanation candidates, and argumentation becomes useful to discriminate between those.",
                "When a map is labyrinth-like, there are fewer possible explanations to an unexpected event.",
                "Importance of the Global Protocol The second set of experiments seeks to evaluate the importance of the design of the global protocol.",
                "We tested our protocol against a local broadcast (LB) protocol.",
                "Local broadcast means that all the neighbours agents perceived by an agent will be involved in a communication with that agent in a given round -we alleviate the constraint of a single communication by agent.",
                "This gives us a rough upper bound upon the possible ratio gain in the system (for a given local protocol).",
                "Again, we evaluated the ratio gain induced by that LB over our classical HE, for the three different classes of maps.",
                "The results are reported in Fig. 4.",
                "Figure 4: Ratio gain of local broadcast over hypotheses exchange Note to begin with that the ratio gain is 0 when the proportion of agents is 5%, which is easily explained by the fact that it corresponds to situations involving only two agents.",
                "We first observe that all classes of maps witness a ratio gain increasing when the proportion of agents augments: the gain reaches 10 to 20%, depending on the class of maps considered.",
                "If one compares this with the improvement reported in the previous experiment, it appears to be of the same magnitude.",
                "This illustrates that the design of the global protocol cannot be ignored, especially when the proportion of agents is high.",
                "However, we also note that the effectiveness ratio gain curves have very different shapes in both cases: the gain induced by the accuracy of the local protocol increases very quickly with the proportion of agents, while the curve is really smooth for the global one.",
                "Now let us observe more carefully the results reported here: the curve corresponding to a TI of 53% is above that corresponding to 38%.",
                "This is so because the more open a map, the more opportunities to communicate with more than one agent (and hence benefits from broadcast).",
                "However, we also observe that curve for 69% is below that for 53%.",
                "This is explained as follows: in the case of 69%, the potential gain to be made in terms of surviving agents is much lower, because our protocols already give rather efficient outcomes anyway (quickly reaching 90%, see Fig. 3).",
                "A simple rule of thumb could be that when the number of agents is small, special attention should be put on the local 1004 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) protocol, whereas when that number is large, one should carefully design the global one (unless the map is so open that the protocol is already almost optimally efficient).",
                "Efficiency of the Protocols The final experiment reported here is concerned with the analysis of the efficiency of the protocols.",
                "We analysis here the mean size of the totality of the messages that are exchanged by agents (mean size of exchanges, for short) using the following protocols: HE, OE, and two variant protocols.",
                "The first one is an intermediary restricted hypotheses exchange protocol (RHE).",
                "RHE is as follows: it does not involve any challenge nor counter-propose, which means that agents cannot switch their role during the protocol (this differs from RE in that respect).",
                "In short, RHE allows an agent to exhaust its partners criticism, and eventually this partner will come to adopt the agents hypothesis.",
                "Note that this means that the autonomy of the agent is not preserved here (as an agent will essentially accept any hypothesis it cannot undermine), with the hope that the gain in efficiency will be significant enough to compensate a loss in effectiveness.",
                "The second variant protocol is a complete observation exchange protocol (COE).",
                "COE uses the same principles as OE, but includes in addition all critical negative examples (nofire) in the exchange (thus giving all examples used as arguments by the hypotheses exchanges protocol), hence improving effectiveness.",
                "Results for map 69-1 are shown on Fig. 5.",
                "Figure 5: Mean size of exchanges First we can observe the fact that the ordering of the protocols, from the least efficient to the most efficient, is COE, HE, RHE and then OE.",
                "HE being more efficient than COE proves that the argumentation process gains efficiency by selecting when it is needed to provide negative example, which have less impact that positive ones in our specific testbed.",
                "However, by communicating hypotheses before eventually giving observation to support it (HE) instead of directly giving the most crucial observations (OE), the argumentation process doubles the size of data exchanges.",
                "It is the cost for ensuring consistency at the end of the exchange (a property that OE does not support).",
                "Also significant is the fact the the mean size of exchanges is slightly higher when the number of agents is small.",
                "This is explained by the fact that in these cases only a very few agents have relevant informations in their possession, and that they will need to communicate a lot in order to come up with a common view of the situation.",
                "When the number of agents increases, this knowledge is distributed over more agents which need shorter discussions to get to mutual consistency.",
                "As a consequence, the relative gain in efficiency of using RHE appears to be better when the number of agents is small: when it is high, they will hardly argue anyway.",
                "Finally, it is worth noticing that the standard deviation for these experiments is rather high, which means that the conversation do not converge to any stereotypic pattern. 6.",
                "CONCLUSION This paper has investigated the properties of a multiagent system where each (distributed) agent locally perceives its environment, and tries to reach consistency with other agents despite severe communication restrictions.",
                "In particular we have exhibited conditions allowing convergence, and experimentally investigated a typical situation where those conditions cannot hold.",
                "There are many possible extensions to this work, the first being to further investigate the properties of different global protocols belonging to the class we identified, and their influence on the outcome.",
                "There are in particular many heuristics, highly dependent on the context of the study, that could intuitively yield interesting results (in our study, selecting the recipient on the basis of what can be inferred from his observed actions could be such a heuristic).",
                "One obvious candidate for longer term issues concern the relaxation of the assumption of perfect sensing. 7.",
                "REFERENCES [1] G. Bourgne, N. Maudet, and S. Pinson.",
                "When agents communicate hypotheses in critical situations.",
                "In Proceedings of DALT-2006, May 2006. [2] P. Harvey, C. F. Chang, and A. Ghose.",
                "Support-based distributed search: a new approach for multiagent constraint processing.",
                "In Proceedings of AAMAS06, 2006. [3] H. Jung and M. Tambe.",
                "Argumentation as distributed constraint satisfaction: Applications and results.",
                "In Proceedings of AGENTS01, 2001. [4] N. C. Karunatillake and N. R. Jennings.",
                "Is it worth arguing?",
                "In Proceedings of ArgMAS 2004, 2004. [5] S. Onta˜n´on and E. Plaza.",
                "Arguments and counterexamples in case-based joint deliberation.",
                "In Proceedings of ArgMAS-2006, May 2006. [6] D. Poole.",
                "Explanation and prediction: An architecture for default and abductive reasoning.",
                "Computational Intelligence, 5(2):97-110, 1989. [7] I. Rahwan, S. D. Ramchurn, N. R. Jennings, P. McBurney, S. Parsons, and L. Sonenberg.",
                "Argumention-based negotiation.",
                "The Knowledge Engineering Review, 4(18):345-375, 2003. [8] N. Roos, A. ten Tije, and C. Witteveen.",
                "A protocol for multi-agent diagnosis with spatially distributed knowledge.",
                "In Proceedings of AAMAS03, 2003. [9] N. Roos, A. ten Tije, and C. Witteveen.",
                "Reaching diagnostic agreement in multiagent diagnosis.",
                "In Proceedings of AAMAS04, 2004. [10] T. Takahashi, Y. Kaneda, and N. Ito.",
                "Preliminary study - using robocuprescue simulations for disasters prevention.",
                "In Proceedings of SRMED2004, 2004.",
                "The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 1005"
            ],
            "original_annotated_samples": [
                "In this paper, we mostly investigate the convergence of such systems towards <br>global consistency</br>.",
                "If, in addition, the communication opportunities are severely constrained (for instance, agents can only communicate when they are close enough to some other agent), and dynamically changing (for instance, agents may change their locations), it becomes crucial to carefully design protocols that will allow agents to converge to some desired state of <br>global consistency</br>.",
                "Section 4 details one of 998 978-81-904262-7-5 (RPS) c 2007 IFAAMAS the main results of the paper, namely the fact that under the aforementioned conditions, the constraints that we put on the topology will not prevent the convergence of the system towards <br>global consistency</br>, at the condition that no agent ever gets completely lost forever in the system, and that unlimited time is allowed for computation and argument exchange.",
                "It then finally sends a weighted request to the agents who maximise this weight (or wait for a request) as described in the global protocol. 4. (CONDITIONAL) CONVERGENCE TO <br>global consistency</br> In this section we will show that the requirements regarding protocols and strategies just discussed will be sufficient to ensure that the system will eventually converge towards <br>global consistency</br>, under some conditions.",
                "Theorem 1 (<br>global consistency</br>)."
            ],
            "translated_annotated_samples": [
                "En este artículo, investigamos principalmente la convergencia de dichos sistemas hacia la <br>consistencia global</br>.",
                "Si, además, las oportunidades de comunicación están severamente limitadas (por ejemplo, los agentes solo pueden comunicarse cuando están lo suficientemente cerca de otro agente) y cambian dinámicamente (por ejemplo, los agentes pueden cambiar sus ubicaciones), se vuelve crucial diseñar cuidadosamente protocolos que permitan a los agentes converger hacia algún estado deseado de <br>consistencia global</br>.",
                "La sección 4 detalla uno de los principales resultados del artículo, a saber, el hecho de que bajo las condiciones mencionadas, las restricciones que imponemos en la topología no impedirán la convergencia del sistema hacia la <br>consistencia global</br>, siempre y cuando ningún agente se pierda completamente para siempre en el sistema, y se permita un tiempo ilimitado para la computación y el intercambio de argumentos.",
                "Luego envía finalmente una solicitud ponderada a los agentes que maximizan este peso (o esperan una solicitud) según lo descrito en el protocolo global. 4. (CONDICIONAL) CONVERGENCIA HACIA LA COHERENCIA GLOBAL En esta sección mostraremos que los requisitos relacionados con los protocolos y estrategias recién discutidos serán suficientes para garantizar que el sistema eventualmente convergerá hacia la <br>coherencia global</br>, bajo ciertas condiciones.",
                "Teorema 1 (Consistencia global)."
            ],
            "translated_text": "Refinamiento de hipótesis bajo restricciones de comunicación topológica ∗ Gauvain Bourgne, Gael Hette, Nicolas Maudet y Suzanne Pinson LAMSADE, Univ. Investigamos las propiedades de un sistema multiagente donde cada agente (distribuido) percibe localmente su entorno. Tras la percepción de un evento inesperado, cada agente calcula localmente su hipótesis favorita e intenta propagarla a otros agentes, intercambiando hipótesis y argumentos de apoyo (observaciones). Sin embargo, también asumimos que las oportunidades de comunicación están severamente limitadas y cambian dinámicamente. En este artículo, investigamos principalmente la convergencia de dichos sistemas hacia la <br>consistencia global</br>. Primero demostramos que (para una amplia clase de protocolos que definiremos), las restricciones de comunicación inducidas por la topología no impedirán la convergencia del sistema, bajo la condición de que la dinámica del sistema garantice que ningún agente quedará aislado para siempre, y que los agentes tengan tiempo ilimitado para la computación y el intercambio de argumentos. Dado que esta suposición no se puede hacer en la mayoría de las situaciones, establecimos un marco experimental con el objetivo de comparar la eficiencia y efectividad relativa de diferentes protocolos de interacción para el intercambio de hipótesis. Estudiamos una situación crítica que implica a varios agentes que intentan escapar de un edificio en llamas. Los resultados reportados aquí proporcionan algunas ideas sobre el diseño de un protocolo óptimo para el refinamiento de hipótesis en este contexto. Categorías y Descriptores de Asignaturas I.2.11 [Inteligencia Artificial]: Inteligencia Artificial Distribuida-Sistemas Multiagente Términos Generales Teoría, Experimentación 1. INTRODUCCIÓN Consideramos un sistema multiagente donde cada agente (distribuido) percibe localmente su entorno, y asumimos que ocurre un evento inesperado en ese sistema. Si cada agente calcula solo localmente su hipótesis preferida, es natural asumir que los agentes buscarán coordinar y refinar sus hipótesis confrontando sus observaciones con otros agentes. Si, además, las oportunidades de comunicación están severamente limitadas (por ejemplo, los agentes solo pueden comunicarse cuando están lo suficientemente cerca de otro agente) y cambian dinámicamente (por ejemplo, los agentes pueden cambiar sus ubicaciones), se vuelve crucial diseñar cuidadosamente protocolos que permitan a los agentes converger hacia algún estado deseado de <br>consistencia global</br>. En este documento presentamos algunas condiciones suficientes sobre la dinámica del sistema y sobre las estructuras de protocolo/estrategia que permiten garantizar esa propiedad, y estudiamos experimentalmente algunos contextos donde (algunas de) estas suposiciones se relajan. Si bien los problemas de diagnóstico son uno de los clásicos venerables en la tradición de la IA, sus contrapartes multiagentes han atraído atención mucho más recientemente. Roos y sus colegas [8, 9] en particular estudian una situación en la que un número de entidades distribuidas intentan llegar a un diagnóstico global satisfactorio de todo el sistema. Ellos muestran en particular que el número de mensajes necesarios para establecer este diagnóstico global está destinado a ser prohibitivo, a menos que la comunicación se mejore con algún protocolo adecuado. Sin embargo, no imponen restricciones a las opciones de comunicación de los agentes, ni asumen que el sistema es dinámico. Los beneficios de mejorar la comunicación con información de apoyo para hacer que la convergencia a un estado global deseado de un sistema sea más eficiente, a menudo se ha planteado en la literatura. Esta es, por ejemplo, una de las ideas principales que subyacen al enfoque de negociación basado en argumentos [7], donde el estado deseado es un compromiso entre agentes con preferencias conflictivas. Sin embargo, muchos de estos trabajos parten del supuesto de que este enfoque es beneficioso para comenzar y estudian los aspectos técnicos del problema (o en su lugar enfatizan otras ventajas de utilizar la argumentación). Excepciones notables son las obras de [3, 4, 2, 5], que estudiaron en contextos diferentes al nuestro la eficiencia de la argumentación. El resto del documento es el siguiente. La Sección 2 especifica los elementos básicos de nuestro modelo, y la Sección 3 continúa presentando los diferentes protocolos y estrategias utilizados por los agentes para intercambiar hipótesis y observaciones. Ponemos especial atención en enfatizar claramente las condiciones de la dinámica del sistema y los protocolos/estrategias que se explotarán en el resto del documento. La sección 4 detalla uno de los principales resultados del artículo, a saber, el hecho de que bajo las condiciones mencionadas, las restricciones que imponemos en la topología no impedirán la convergencia del sistema hacia la <br>consistencia global</br>, siempre y cuando ningún agente se pierda completamente para siempre en el sistema, y se permita un tiempo ilimitado para la computación y el intercambio de argumentos. Si bien las condiciones en los protocolos y estrategias son bastante suaves, también es claro que estos requisitos del sistema parecen mucho más problemáticos, incluso francamente poco realistas en situaciones críticas donde se abogan precisamente por enfoques distribuidos. Para obtener una imagen más clara de la situación inducida cuando el tiempo es un factor crítico, hemos establecido un marco experimental que presentamos y discutimos en la Sección 5. La situación crítica implica a varios agentes que intentan escapar de un edificio en llamas. Los resultados reportados aquí muestran que la efectividad del intercambio de argumentos depende crucialmente de la naturaleza del edificio, y proporcionan algunas ideas sobre el diseño de un protocolo óptimo para el refinamiento de hipótesis en este contexto. CONCEPTOS BÁSICOS Comenzamos definiendo los elementos básicos de nuestro sistema. Deje que O sea el conjunto (potencialmente infinito) de observaciones posibles. Suponemos que los sensores de nuestros agentes son perfectos, por lo tanto, las observaciones son seguras. Sea H el conjunto de hipótesis, incierto y revisable. Sea Cons(h, O) la relación de consistencia, una relación binaria entre una hipótesis h ∈ H y un conjunto de observaciones O ⊆ O. En la mayoría de los casos, Cons se referirá a la relación de consistencia clásica, sin embargo, podemos sobrecargar su significado y añadir algunas propiedades adicionales a esa relación (en cuyo caso lo mencionaremos). El entorno puede incluir cierta dinámica y cambiar con el transcurso del tiempo. Definimos a continuación secuencias de puntos temporales para tratar con ello: Definición 1 (Secuencia de puntos temporales). Una secuencia de puntos temporales t1, t2, . . . , tn de t es un conjunto ordenado de puntos temporales t1, t2, . . . , tn tal que t1 ≥ t y ∀i ∈ [1, n − 1], ti+1 ≥ ti. Tomamos un sistema poblado por n agentes a1, . . . , an. Cada agente se define como una tupla F, Oi, hi, donde: • F, el conjunto de hechos, conocimiento común a todos los agentes. • Oi ∈ 2O, el conjunto de observaciones realizadas por el agente hasta el momento. Suponemos una memoria perfecta, por lo tanto, este conjunto crece de forma monótona. • hi ∈ H, la hipótesis favorita del agente. Una noción clave que rige la formación de hipótesis es la de consistencia, definida a continuación: Definición 2 (Consistencia). Decimos que: • Un agente es consistente (Cons(ai)) si y solo si Cons(hi, Oi) (es decir, su hipótesis es consistente con su conjunto de observaciones). • Un agente ai es consistente con un agente compañero aj si y solo si Cons(ai) y Cons(hi, Oj) (es decir, este agente es consistente y su hipótesis puede explicar el conjunto de observaciones del otro agente). • Dos agentes ai y aj son mutuamente consistentes (MCons(ai, aj)) si y solo si Cons(ai, aj) y Cons(aj, ai). • Un sistema es consistente si y solo si para todo (i, j) ∈ [1, n]2 se cumple que MCons(ai, aj). Para garantizar su consistencia, cada agente está equipado con una maquinaria de razonamiento abstracto que llamaremos la función de explicación Eh. Esta función (determinística) toma un conjunto de observaciones y devuelve una única hipótesis preferida (2O → H). Suponemos que h = Eh(O) para ser consistente con O por definición de Eh, por lo que usar esta función en su conjunto de observaciones para determinar su hipótesis favorita es una forma segura para que el agente logre consistencia. Sin embargo, cabe destacar que una hipótesis no necesita ser generada por Eh para ser consistente con un conjunto de observaciones. Como ejemplo concreto de tal función, y una de las principales inspiraciones de este trabajo, se puede citar el sistema de razonamiento Theorist [6], siempre y cuando esté acoplado con un filtro que seleccione una teoría preferida entre las inicialmente seleccionadas por Theorist. También hay que tener en cuenta que hi solo puede ser modificado como consecuencia de la aplicación de Eh. Nos referimos a esto como la autonomía del agente: ningún otro agente puede imponer directamente una hipótesis dada a un agente. Como consecuencia, solo una nueva observación (ya sea una nueva percepción o una observación comunicada por otro agente) puede resultar en una modificación de su hipótesis preferida hi (pero no necesariamente, por supuesto). Finalmente definimos una propiedad del sistema que utilizaremos en el resto del artículo: Definición 3 (Percepciones Acotadas). Un sistema implica una percepción limitada para los agentes si y solo si existe un n0 tal que para todo t, la unión de N observaciones realizadas por los agentes es menor o igual a n0. (Es decir, el número de observaciones a realizar por los agentes en el sistema no es infinito.) Ahora necesitamos ver cómo evolucionarán e interactuarán estos agentes en su entorno. En nuestro contexto, los agentes evolucionan en un entorno dinámico, y asumimos clásicamente el siguiente ciclo del sistema: 1. Dinámica del entorno: el entorno evoluciona de acuerdo con las reglas definidas de la dinámica del sistema. 2. Paso de percepción: los agentes obtienen percepciones del entorno. Estas percepciones suelen ser parciales (por ejemplo, el agente solo puede ver una parte de un mapa). 3. Paso de razonamiento: los agentes comparan la percepción con las predicciones, buscan explicaciones para las diferencias (potenciales), refinan su hipótesis, y sacan nuevas conclusiones. 4. Paso de comunicación: los agentes pueden comunicar hipótesis y observaciones con otros agentes a través de un protocolo definido. Cualquier agente solo puede estar involucrado en una comunicación con otro agente en el paso 5. Paso de acción: los agentes realizan un razonamiento práctico utilizando los modelos obtenidos de los pasos anteriores y seleccionan una acción. Ellos pueden modificar el entorno ejecutándolo. La comunicación de los agentes estará aún más restringida por consideraciones topológicas. En un momento dado, un agente solo podrá comunicarse con un número de vecinos. Sus conexiones con estos otros agentes pueden The Sixth Intl. La Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) evoluciona con su situación en el entorno. Normalmente, un agente solo puede comunicarse con agentes que puede percibir, pero se podría imaginar la evolución de restricciones topológicas en la comunicación basadas en una red de comunicaciones entre agentes donde los enlaces no siempre están activos. En nuestro sistema, los agentes podrán comunicarse entre sí. Sin embargo, debido a las restricciones topológicas mencionadas anteriormente, no podrán comunicarse con ningún agente en ningún momento. Con quién puede comunicarse un agente se definirá dinámicamente (por ejemplo, esto puede ser consecuencia de que los agentes estén lo suficientemente cerca para ponerse en contacto). Denotaremos de forma abstracta por C(ai, aj, t) la propiedad de comunicación, es decir, el hecho de que los agentes ai y aj puedan comunicarse en el tiempo t (nota que se asume que esta relación es simétrica, pero por supuesto no transitiva). Ahora estamos en posición de definir dos propiedades esenciales de nuestro sistema. Definición 4 (Camino Temporal). Existe un camino de comunicación temporal en el horizonte tf (denotado Ltf (aI, aJ)) entre ai y aj si y solo si existe una secuencia de puntos temporales t1, t2, ..., tn desde tf y una secuencia de agentes k1, k2, ..., kn tal que (i) C(aI, ak1, t1), (ii) C(akn, aJ, tn+1), (iii) ∀i ∈ [1, n], C(aki, aki+1, ti). Intuitivamente, lo que esta propiedad dice es que es posible encontrar un camino temporal en el futuro que permitiría vincular al agente ai y aj a través de una secuencia de agentes intermedios. Ten en cuenta que los puntos temporales no necesariamente son sucesivos, y que la secuencia de agentes puede involucrar a los mismos agentes varias veces. Definición 5 (Conexidad Temporal). Un sistema es temporalmente conexo si y solo si ∀t ∀(i, j)∈[1, n]2 Lt(ai, aj). En resumen, un sistema temporalmente conexo garantiza que cualquier agente podrá comunicarse con cualquier otro agente, sin importar cuánto tiempo pueda llevar hacerlo, en cualquier momento. Dicho de otra manera, nunca sucede que un agente esté aislado para siempre de otro agente del sistema. A continuación discutiremos en detalle cómo la comunicación tiene lugar concretamente en nuestro sistema. Recuerda que en este documento, solo consideramos el caso de intercambios bilaterales (un agente solo puede hablar con otro agente) y también asumimos que cualquier agente solo puede participar en un intercambio en una ronda dada. 3. PROTOCOLOS Y ESTRATEGIAS En esta sección, discutimos los requisitos de los protocolos de interacción que rigen el intercambio de mensajes entre agentes, y proporcionamos algunos ejemplos de la implementación de dichos protocolos. Para aclarar la presentación, distinguimos dos niveles: el nivel local, que se ocupa de la regulación de los intercambios bilaterales; y el nivel global, que regula principalmente la forma en que los agentes pueden participar realmente en una conversación. En cada nivel, separamos lo que está especificado por el protocolo y lo que se deja a las estrategias de los agentes. Protocolos y estrategias locales Comenzamos inspeccionando los protocolos y estrategias locales que regularán la comunicación entre los agentes del sistema. Al limitarnos a la comunicación bilateral, estos protocolos simplemente implicarán a dos agentes. Dicho protocolo tendrá que cumplir con un requisito básico para ser satisfactorio: consistencia (CONS) - un protocolo local debe garantizar la consistencia mutua de los agentes al finalizar (lo que implica, por supuesto, la finalización). Figura 1: Un Protocolo de Intercambio de Hipótesis [1] Un ejemplo de dicho protocolo es el protocolo descrito en [1] que se muestra en la Fig. 1. Para ilustrar aún más cómo dicho protocolo puede ser utilizado por agentes, proporcionamos algunos detalles sobre una posible estrategia: al recibir una hipótesis h1 (proponer(h1) o contra-proponer(h1)) de a1, el agente a2 se encuentra en el estado 2 y tiene las siguientes respuestas posibles: contraejemplo (si el agente conoce un ejemplo que contradice la hipótesis, o no está explicado por esta hipótesis), desafío (si el agente carece de evidencia para aceptar esta hipótesis), contra-proponer (si el agente está de acuerdo con la hipótesis pero prefiere otra), o aceptar (si es tan buena como su hipótesis favorita). Esta estrategia garantiza, entre otras propiedades, la eventual consistencia lógica mutua de los agentes involucrados [1]. Protocolo global El protocolo global regula la forma en que se iniciarán los intercambios bilaterales entre agentes. En cada turno, los agentes enviarán simultáneamente una solicitud ponderada para comunicarse con otros agentes. Este peso es un valor que mide la disposición de los agentes para conversar con el agente objetivo (en la práctica, esto puede basarse en diferentes heurísticas, pero haremos algunas suposiciones sobre las estrategias de los agentes, ver más abajo). Enviar una solicitud de este tipo es una especie de compromiso condicional para el agente. Un agente que envía una solicitud ponderada se compromete a entablar una conversación con el objetivo si no recibe y acepta otra solicitud por sí mismo. Una vez que se hayan recibido todas las solicitudes, cada agente responde con un aceptar o un rechazar. Al responder con un aceptar, un agente se compromete plenamente a participar en la conversación con el remitente. Por lo tanto, solo puede enviar una aceptación en una ronda dada, ya que un agente solo puede participar en una conversación por paso de tiempo. Cuando se hayan recibido todas las respuestas, cada agente que reciba una aceptación puede iniciar una conversación utilizando el protocolo local o enviar una cancelación si ha aceptado otra solicitud. Al final de todos los intercambios bilaterales, los agentes involucrados en la conversación son descartados del protocolo. Entonces cada uno de los agentes restantes reenvía una solicitud y el proceso se repite hasta que no se envíen más solicitudes. Estrategia global Ahora definimos cuatro requisitos para las estrategias utilizadas por los agentes, dependiendo de su rol en el protocolo: dos se refieren al rol del solicitante (cómo decidir quién es el 1000 The Sixth Intl. La Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) ¿con qué agente desea comunicarse? Los otros dos con el rol de respondedor (¿cómo decidir qué solicitud de comunicación aceptar o no?). • Disposición para resolver inconsistencias (SOLVE): los agentes desean comunicarse con cualquier otro agente a menos que sepan que son mutuamente consistentes. • Enfoque en resolver inconsistencias (FOCUS): los agentes no solicitan comunicarse con un agente con el que saben que son mutuamente consistentes. • Disposición para comunicarse (COMM): los agentes no pueden rechazar una solicitud de comunicación ponderada, a menos que acaben de recibir o enviar una solicitud con un peso mayor. • Compromiso con la solicitud de comunicación (REQU): los agentes no pueden aceptar una solicitud de comunicación ponderada si ellos mismos han enviado una solicitud de comunicación con un peso mayor. Por lo tanto, no cancelarán su solicitud a menos que hayan recibido una solicitud comunicacional con mayor peso. Ahora la estructura del protocolo, junto con las propiedades COMM+REQU, garantizan que una solicitud solo puede ser rechazada si su agente objetivo se involucra en comunicación con otro agente. Supongamos de hecho que el agente ai quiere comunicarse con aj enviando una solicitud con peso w. COMM garantiza que un agente que reciba una solicitud ponderada aceptará esta comunicación, aceptará una comunicación con un peso mayor o esperará la respuesta a una solicitud con un peso mayor. Esto asegura que la solicitud con peso máximo será aceptada y no cancelada (ya que REQU asegura que un agente que envía una solicitud solo puede cancelarla si acepta otra solicitud con un peso mayor). Por lo tanto, al menos dos agentes participarán en una conversación por ronda del protocolo global. Como el protocolo asegura que ai puede reenviar su solicitud mientras aj no está ocupado en una conversación, llegará un momento en el que aj deberá participar en una conversación, ya sea con ai u otro agente. Estos requisitos se refieren al envío y aceptación de solicitudes, pero los agentes también necesitan alguna estrategia de atribución de peso. Describimos a continuación una estrategia altruista, utilizada en nuestros experimentos. Siendo cooperativo, un agente puede querer conocer más los deseos de comunicación de otros agentes para mejorar la asignación general de intercambios a los agentes. Se añade entonces un paso de solicitud de contexto al protocolo global. Antes de enviar su solicitud ponderada elegida, los agentes asignan un peso a todos los agentes con los que están dispuestos a comunicarse, de acuerdo con algunos factores internos. En el caso más simple, este peso será 1 para todos los agentes con los que el agente no esté seguro de ser mutuamente consistentes (garantizando SOLVE), sin considerar a otros agentes para la comunicación (garantizando FOCUS). El agente luego envía una solicitud de contexto a todos los agentes con los que se considera la comunicación. Esta solicitud también proporciona información sobre el remitente (lista de comunicaciones consideradas junto con su peso). Después de recibir todas las solicitudes de contexto, los agentes responderán con un rechazo si ya están ocupados en una conversación (en cuyo caso, el agente solicitante no considerará comunicarse con ellos en este turno), o con una información que brinde al solicitante información sobre las solicitudes que ha enviado y recibido. Cuando se hayan recibido todas las respuestas, cada agente puede calcular el peso de todas las solicitudes que le conciernen. Lo hace restando del peso de su solicitud el peso de todas las solicitudes relacionadas con él o su objetivo (es decir, el peso final de la solicitud de ai a aj es Wi,j = wi,j + wj,i - ( Σ k∈R(i)-{j} wi,k + Σ k∈S(i)-{j} wk,i + Σ k∈R(j)-{i} wj,k + Σ k∈S(j)-{i} wk,j) donde wi,j es el peso de la solicitud de ai a aj, R(i) es el conjunto de índices de agentes que han recibido una solicitud de ai y S(i) es el conjunto de índices de agentes que han enviado una solicitud a ai). Luego envía finalmente una solicitud ponderada a los agentes que maximizan este peso (o esperan una solicitud) según lo descrito en el protocolo global. 4. (CONDICIONAL) CONVERGENCIA HACIA LA COHERENCIA GLOBAL En esta sección mostraremos que los requisitos relacionados con los protocolos y estrategias recién discutidos serán suficientes para garantizar que el sistema eventualmente convergerá hacia la <br>coherencia global</br>, bajo ciertas condiciones. Primero demostramos que, si dos agentes no son mutuamente consistentes en algún momento, entonces necesariamente habrá un momento en el futuro en el que un agente aprenderá una nueva observación, ya sea porque es nueva para el sistema, o al aprenderla de otro agente. Lema 1. Sea S un sistema poblado por n agentes a1, a2, ..., an, temporalmente conectados e involucrando percepciones limitadas para estos agentes. Sea n1 la suma de las cardinalidades de la intersección de los conjuntos de observaciones emparejados. (n1 = P (i,j)∈[1,n]2 |Oi ∩ Oj|) Sea n2 la cardinalidad de la unión de todos los conjuntos de observaciones de los agentes. (n2 = | ∪N i=1 Oi|). Si ¬MCons(ai, aj) en el tiempo t0, necesariamente existe un tiempo t > t0 tal que ya sea n1 o n2 aumentarán. Prueba. Supongamos que exista un tiempo t0 y unos índices (i, j) tal que ¬MCons(ai, aj). Utilizaremos mt0 = P (k,l)∈[1,n]2 εComm(ak, al, t0) donde εComm(ak, al, t0) = 1 si ak y al han comunicado al menos una vez desde t0, y 0 en caso contrario. La conexidad temporal garantiza que existen t1, ..., tm+1 y k1, ..., km tal que. C(ai, ak1 , t1), C(akm , aj, tm+1), y ∀p ∈ [1, m], C(akp , akp+1 , tp). Claramente, si MCons(ai, ak1), MCons(akm, aj) y ∀p, MCons(akp, akp+1), tenemos MCons(ai, aj) lo cual contradice nuestra hipótesis (siendo MCons transitivo, MCons(ai, ak1)∧MCons(ak1, ak2) implica que MCons(ai, ak2) y así sucesivamente hasta MCons(ai, akm)∧MCons(akm, aj) lo cual implica MCons(ai, aj)). Al menos dos agentes son necesariamente inconsistentes (¬MCons(ai, ak1), o ¬MCons(akm, aj), o ∃p0 t.q. ¬MCons(akp0, akp0+1)). Que ak y al sean estos dos vecinos en un momento t > t0 1. La propiedad SOLVE asegura que ya sea ak o al enviará una solicitud de comunicación al otro agente en el tiempo t. Como se mostró anteriormente, esto a su vez garantiza que al menos uno de estos agentes estará involucrado en una comunicación. Entonces hay dos posibilidades: (caso i) ak y al se comunican en el tiempo t. En este caso, sabemos que ¬MCons(ak, al). Esto y la propiedad CONS aseguran que al menos uno de los agentes debe cambiar su 1. Estrictamente hablando, la transitividad de MCons solo asegura que ak y al son inconsistentes en un tiempo t ≥ t0 que puede ser diferente del tiempo t en el que pueden comunicarse. Pero si se vuelven consistentes entre t y t (o inconsistentes entre t y t), significa que al menos uno de ellos ha cambiado su hipótesis entre t y t, es decir, después de t0. Podemos entonces aplicar el razonamiento del caso iib. El Sexto Internacional. La Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 1001 hipótesis, lo cual a su vez, dado que los agentes son autónomos, implica al menos un intercambio de observación. Pero entonces |Ok ∩Ol| está destinado a aumentar: n1(t) > n1(t0). (caso ii) ak se comunica con ap en el tiempo t. Entonces tenemos de nuevo dos posibilidades: (caso iia) ak y ap no se comunicaron desde t0. Pero luego εComm(ak, ap, t0) tenía valor 0 y toma valor 1. Por lo tanto, mt0 aumenta. (caso iib) ak y ap se comunicaron en algún momento t0 > t0. La propiedad CONS del protocolo asegura que MCons(ak, ap) en ese momento. Ahora el hecho de que se comuniquen y se ENFOQUEN implica que al menos uno de ellos cambió su hipótesis en el ínterin. El hecho de que los agentes sean autónomos implica a su vez que una nueva observación (percibida o recibida de otro agente) necesariamente provocó este cambio. El último caso garantizaría la existencia de un tiempo t > t0 y un agente aq tal que |Op ∩ Oq| o |Ok ∩ Oq| aumenten en 1 en ese momento (lo que implica que n1(t) > n1(t0)). El caso anterior significa que el agente obtiene una nueva percepción en el tiempo t. Si esa observación era desconocida en el sistema antes, entonces n2(t) > n2(t0). Si algún agente aq ya conocía esta observación antes, entonces tanto Op ∩ Oq como Ok ∩ Oq aumentan en 1 en el tiempo t (lo que implica que n1(t) > n1(t0)). Por lo tanto, ¬MCons(ai, aj) en el tiempo t0 garantiza que, o bien: −∃t > t0 t.q. n1(t ) > n1(t0); o −∃t > t0 t.q. n2(t ) > n2(t0); o −∃t > t0 t.q. mt0 aumenta en 1 en el tiempo t. Al iterar el razonamiento con t (pero manteniendo t0 como la referencia de tiempo para mt0), podemos eliminar el tercer caso (mt0 es un entero y está limitado por n2, lo que significa que después de un máximo de n2 iteraciones, necesariamente estaremos en uno de los otros dos casos). Como resultado, hemos demostrado que si ¬MCons(ai, aj) en el tiempo t0, necesariamente habrá un tiempo t tal que ya sea n1 o n2 aumentarán. Teorema 1 (Consistencia global). ",
            "candidates": [],
            "error": [
                [
                    "consistencia global",
                    "consistencia global",
                    "consistencia global",
                    "coherencia global"
                ]
            ]
        },
        "consistency": {
            "translated_key": "consistencia",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Hypotheses Refinement under Topological Communication Constraints ∗ Gauvain Bourgne, Gael Hette, Nicolas Maudet, and Suzanne Pinson LAMSADE, Univ.",
                "Paris-Dauphine, France {bourgne,hette,maudet,pinson}@lamsade.dauphine.fr ABSTRACT We investigate the properties of a multiagent system where each (distributed) agent locally perceives its environment.",
                "Upon perception of an unexpected event, each agent locally computes its favoured hypothesis and tries to propagate it to other agents, by exchanging hypotheses and supporting arguments (observations).",
                "However, we further assume that communication opportunities are severely constrained and change dynamically.",
                "In this paper, we mostly investigate the convergence of such systems towards global <br>consistency</br>.",
                "We first show that (for a wide class of protocols that we shall define), the communication constraints induced by the topology will not prevent the convergence of the system, at the condition that the system dynamics guarantees that no agent will ever be isolated forever, and that agents have unlimited time for computation and arguments exchange.",
                "As this assumption cannot be made in most situations though, we then set up an experimental framework aiming at comparing the relative efficiency and effectiveness of different interaction protocols for hypotheses exchange.",
                "We study a critical situation involving a number of agents aiming at escaping from a burning building.",
                "The results reported here provide some insights regarding the design of optimal protocol for hypotheses refinement in this context.",
                "Categories and Subject Descriptors I.2.11 [Artificial Intelligence]: Distributed Artificial Intelligence-Multiagent systems General Terms Theory, Experimentation 1.",
                "INTRODUCTION We consider a multiagent system where each (distributed) agent locally perceives its environment, and we assume that some unexpected event occurs in that system.",
                "If each agent computes only locally its favoured hypothesis, it is only natural to assume that agents will seek to coordinate and refine their hypotheses by confronting their observations with other agents.",
                "If, in addition, the communication opportunities are severely constrained (for instance, agents can only communicate when they are close enough to some other agent), and dynamically changing (for instance, agents may change their locations), it becomes crucial to carefully design protocols that will allow agents to converge to some desired state of global <br>consistency</br>.",
                "In this paper we exhibit some sufficient conditions on the system dynamics and on the protocol/strategy structures that allow to guarantee that property, and we experimentally study some contexts where (some of) these assumptions are relaxed.",
                "While problems of diagnosis are among the venerable classics in the AI tradition, their multiagent counterparts have much more recently attracted some attention.",
                "Roos and colleagues [8, 9] in particular study a situation where a number of distributed entities try to come up with a satisfying global diagnosis of the whole system.",
                "They show in particular that the number of messages required to establish this global diagnosis is bound to be prohibitive, unless the communication is enhanced with some suitable protocol.",
                "However, they do not put any restrictions on agents communication options, and do not assume either that the system is dynamic.",
                "The benefits of enhancing communication with supporting information to make convergence to a desired global state of a system more efficient has often been put forward in the literature.",
                "This is for instance one of the main idea underlying the argumentation-based negotiation approach [7], where the desired state is a compromise between agents with conflicting preferences.",
                "Many of these works however make the assumption that this approach is beneficial to start with, and study the technical facets of the problem (or instead emphasize other advantages of using argumentation).",
                "Notable exceptions are the works of [3, 4, 2, 5], which studied in contexts different from ours the efficiency of argumentation.",
                "The rest of the paper is as follows.",
                "Section 2 specifies the basic elements of our model, and Section 3 goes on to presenting the different protocols and strategies used by the agents to exchange hypotheses and observations.",
                "We put special attention at clearly emphasizing the conditions on the system dynamics and protocols/strategies that will be exploited in the rest of the paper.",
                "Section 4 details one of 998 978-81-904262-7-5 (RPS) c 2007 IFAAMAS the main results of the paper, namely the fact that under the aforementioned conditions, the constraints that we put on the topology will not prevent the convergence of the system towards global <br>consistency</br>, at the condition that no agent ever gets completely lost forever in the system, and that unlimited time is allowed for computation and argument exchange.",
                "While the conditions on protocols and strategies are fairly mild, it is also clear that these system requirements look much more problematic, even frankly unrealistic in critical situations where distributed approaches are precisely advocated.",
                "To get a clearer picture of the situation induced when time is a critical factor, we have set up an experimental framework that we introduce and discuss in Section 5.",
                "The critical situation involves a number of agents aiming at escaping from a burning building.",
                "The results reported here show that the effectiveness of argument exchange crucially depends upon the nature of the building, and provide some insights regarding the design of optimal protocol for hypotheses refinement in this context. 2.",
                "BASIC NOTIONS We start by defining the basic elements of our system.",
                "Environment Let O be the (potentially infinite) set of possible observations.",
                "We assume the sensors of our agents to be perfect, hence the observations to be certain.",
                "Let H be the set of hypotheses, uncertain and revisable.",
                "Let Cons(h, O) be the <br>consistency</br> relation, a binary relation between a hypothesis h ∈ H and a set of observations O ⊆ O.",
                "In most cases, Cons will refer to classical <br>consistency</br> relation, however, we may overload its meaning and add some additional properties to that relation (in which case we will mention it).",
                "The environment may include some dynamics, and change over the course of time.",
                "We define below sequences of time points to deal with it: Definition 1 (Sequence of time points).",
                "A sequence of time points t1, t2, . . . , tn from t is an ordered set of time points t1, t2, . . . , tn such that t1 ≥ t and ∀i ∈ [1, n − 1], ti+1 ≥ ti.",
                "Agent We take a system populated by n agents a1, . . . , an.",
                "Each agent is defined as a tuple F, Oi, hi , where: • F, the set of facts, common knowledge to all agents. • Oi ∈ 2O , the set of observations made by the agent so far.",
                "We assume a perfect memory, hence this set grows monotonically. • hi ∈ H, the favourite hypothesis of the agent.",
                "A key notion governing the formation of hypotheses is that of <br>consistency</br>, defined below: Definition 2 (<br>consistency</br>).",
                "We say that: • An agent is consistent (Cons(ai)) iff Cons(hi, Oi) (that is, its hypothesis is consistent with its observation set). • An agent ai consistent with a partner agent aj iff Cons(ai) and Cons(hi, Oj) (that is, this agent is consistent and its hypothesis can explain the observation set of the other agent). • Two agents ai and aj are mutually consistent (MCons(ai, aj)) iff Cons(ai, aj) and Cons(aj, ai). • A system is consistent iff ∀(i, j)∈[1, n]2 it is the case that MCons(ai, aj).",
                "To ensure its <br>consistency</br>, each agent is equipped with an abstract reasoning machinery that we shall call the explanation function Eh.",
                "This (deterministic) function takes a set of observation and returns a single prefered hypothesis (2O → H).",
                "We assume h = Eh(O) to be consistent with O by definition of Eh, so using this function on its observation set to determine its favourite hypothesis is a sure way for the agent to achieve <br>consistency</br>.",
                "Note however that an hypothesis does not need to be generated by Eh to be consistent with an observation set.",
                "As a concrete example of such a function, and one of the main inspiration of this work, one can cite the Theorist reasoning system [6] -as long as it is coupled with a filter selecting a single prefered theory among the ones initially selected by Theorist.",
                "Note also that hi may only be modified as a consequence of the application Eh.",
                "We refer to this as the autonomy of the agent: no other agent can directly impose a given hypothesis to an agent.",
                "As a consequence, only a new observation (being it a new perception, or an observation communicated by a fellow agent) can result in a modification of its prefered hypothesis hi (but not necessarily of course).",
                "We finally define a property of the system that we shall use in the rest of the paper: Definition 3 (Bounded Perceptions).",
                "A system involves a bounded perception for agents iff ∃n0 s.t. ∀t| ∪N i=1 Oi| ≤ n0. (That is, the number of observations to be made by the agents in the system is not infinite.)",
                "Agent Cycle Now we need to see how these agents will evolve and interact in their environment.",
                "In our context, agents evolve in a dynamic environment, and we classicaly assume the following system cycle: 1.",
                "Environment dynamics: the environment evolves according to the defined rules of the system dynamics. 2.",
                "Perception step : agents get perceptions from the environment.",
                "These perceptions are typically partial (e.g. the agent can only see a portion of a map). 3.",
                "Reasoning step: agents compare perception with predictions, seek explanations for (potential) difference(s), refine their hypothesis, draw new conclusions. 4.",
                "Communication step: agents can communicate hypotheses and observations with other agents through a defined protocol.",
                "Any agent can only be involved in one communication with another agent by step. 5.",
                "Action step: agents do some practical reasoning using the models obtained from the previous steps and select an action.",
                "They can then modify the environment by executing it.",
                "The communication of the agents will be further constrained by topological consideration.",
                "At a given time, an agent will only be able to communicate with a number of neighbours.",
                "Its connexions with these others agents may The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 999 evolve with its situation in the environment.",
                "Typically, an agent can only communicate with agents that it can sense, but one could imagine evolving topological constraints on communication based on a network of communications between agents where the links are not always active.",
                "Communication In our system, agents will be able to communicate with each other.",
                "However, due to the aforementionned topological constraints, they will not be able to communicate with any agents at anytime.",
                "Who an agent can communicate with will be defined dynamically (for instance, this can be a consequence of the agents being close enough to get in touch).",
                "We will abstractly denote by C(ai, aj, t) the communication property, in other words, the fact that agents ai and aj can communicate at time t (note that this relation is assumed to be symetric, but of course not transitive).",
                "We are now in a position to define two essential properties of our system.",
                "Definition 4 (Temporal Path).",
                "There exists a temporal communication path at horizon tf (noted Ltf (aI , aJ )) between ai and aj iff there exists a sequence of time points t1, t2, . . . , tn from tf and a sequence of agents k1, k2, . . . , kn s.t. (i) C(aI , ak1 , t1), (ii) C(akn , aJ , tn+1), (iii) ∀i ∈ [1, n], C(aki , aki+1 , ti) Intuitively, what this property says is that it is possible to find a temporal path in the future that would allow to link agent ai and aj via a sequence of intermediary agents.",
                "Note that the time points are not necessarily successive, and that the sequence of agents may involve the same agents several times.",
                "Definition 5 (Temporal Connexity).",
                "A system is temporaly connex iff ∀t ∀(i, j)∈[1, n]2 Lt(ai, aj) In short, a temporaly connex system guarantees that any agent will be able to communicate with any other agents, no matter how long it might take to do so, at any time.",
                "To put it another way, it is never the case that an agent will be isolated for ever from another agent of the system.",
                "We will next discuss the detail of how communication concretely takes place in our system.",
                "Remember that in this paper, we only consider the case of bilateral exchanges (an agent can only speak to a single other agent), and that we also assume that any agent can only engage in a single exchange in a given round. 3.",
                "PROTOCOLS AND STRATEGIES In this section, we discuss the requirements of the interaction protocols that govern the exchange of messages between agents, and provide some example instantiation of such protocols.",
                "To clarify the presentation, we distinguish two levels: the local level, which is concerned with the regulation of bilateral exchanges; and the global level,which essentially regulates the way agents can actually engage into a conversation.",
                "At each level, we separate what is specified by the protocol, and what is left to agents strategies.",
                "Local Protocol and Strategies We start by inspecting local protocols and strategies that will regulate the communication between the agents of the system.",
                "As we limit ourselves to bilateral communication, these protocols will simply involve two agents.",
                "Such protocol will have to meet one basic requirement to be satisfying. • <br>consistency</br> (CONS)- a local protocol has to guarantee the mutual <br>consistency</br> of agents upon termination (which implies termination of course).",
                "Figure 1: A Hypotheses Exchange Protocol [1] One example such protocol is the protocol described in [1] that is pictured in Fig. 1.",
                "To further illustrate how such protocol can be used by agents, we give some details on a possible strategy: upon receiving a hypothesis h1 (propose(h1) or counterpropose(h1)) from a1, agent a2 is in state 2 and has the following possible replies: counterexample (if the agent knows an example contradicting the hypothesis, or not explained by this hypothesis), challenge (if the agents lacks evidence to accept this hypothesis), counterpropose (if the agent agrees with the hypothesis but prefers another one), or accept (if it is indeed as good as its favourite hypothesis).",
                "This strategy guarantees, among other properties, the eventual mutual logical <br>consistency</br> of the involved agents [1].",
                "Global Protocol The global protocol regulates the way bilateral exchanges will be initiated between agents.",
                "At each turn, agents will concurrently send one weighted request to communicate to other agents.",
                "This weight is a value measuring the agents willingness to converse with the targeted agent (in practice, this can be based on different heuristics, but we shall make some assumptions on agents strategies, see below).",
                "Sending such a request is a kind of conditional commitment for the agent.",
                "An agent sending a weighted request commits to engage in conversation with the target if he does not receive and accept himself another request.",
                "Once all request have been received, each agent replies with either an acccept or a reject.",
                "By answering with an accept, an agent makes a full commitment to engage in conversation with the sender.",
                "Therefore, it can only send one accept in a given round, as an agent can only participate in one conversation per time step.",
                "When all response have been received, each agent receiving an accept can either initiate a conversation using the local protocol or send a cancel if it has accepted another request.",
                "At the end of all the bilateral exchanges, the agents engaged in conversation are discarded from the protocol.",
                "Then each of the remaining agents resends a request and the process iterates until no more requests are sent.",
                "Global Strategy We now define four requirements for the strategies used by agents, depending on their role in the protocol: two are concerned with the requestee role (how to decide who the 1000 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) agent wishes to communicate with? ), the other two with the responder role (how to decide which communication request to accept or not?). • Willingness to solve inconsistancies (SOLVE)-agents want to communicate with any other agents unless they know they are mutually consistent. • Focus on solving inconsistencies (FOCUS)-agents do not request communication with an agent with whom they know they are mutually consistent. • Willingness to communicate (COMM)-agents cannot refuse a weighted communication request, unless they have just received or send a request with a greater weight. • Commitment to communication request (REQU)agents cannot accept a weighted communication request if they have themselves sent a communication request with a greater weight.",
                "Therefore, they will not cancel their request unless they have received a communicational request with greater weight.",
                "Now the protocol structure, together with the properties COMM+REQU, ensure that a request can only be rejected if its target agent engages in communication with another agent.",
                "Suppose indeed that agent ai wants to communicate with aj by sending a request with weight w. COMM guarantees that an agent receiving a weighted request will either accept this communication, accept a communication with a greater weight or wait for the answer to a request with a greater weight.",
                "This ensures that the request with maximal weight will be accepted and not cancelled (as REQU ensures that an agent sending a request can only cancel it if he accepts another request with greater weight).",
                "Therefore at least two agents will engage in conversation per round of the global protocol.",
                "As the protocol ensures that ai can resend its request while aj is not engaged in a conversation, there will be a turn in which aj must engage in a conversation, either with ai or another agent.",
                "These requirements concern request sending and acceptation, but agents also need some strategy of weight attribution.",
                "We describe below an altruist strategy, used in our experiments.",
                "Being cooperative, an agent may want to know more of the communication wishes of other agents in order to improve the overall allocation of exchanges to agents.",
                "A context request step is then added to the global protocol.",
                "Before sending their chosen weighted request, agents attribute a weight to all agents they are prepared to communicate with, according to some internal factors.",
                "In the simplest case, this weight will be 1 for all agent with whom the agent is not sure of being mutually consistent (ensuring SOLVE), other agent being not considered for communication (ensuring FOCUS).",
                "The agent then sends a context request to all agents with whom communication is considered.",
                "This request also provides information about the sender (list of considered communications along with their weight).",
                "After reception of all the context requests, agents will either reply with a deny, iff they are already engaged in a conversation (in which case, the requesting agent will not consider communication with them anymore in this turn), or an inform giving the requester information about the requests it has sent and received.",
                "When all replies have been received, each agent can calculate the weight of all requests concerning it.",
                "It does so by substracting from the weight of its request the weight of all requests concerning either it or its target (that is, the final weight of the request from ai to aj is Wi,j = wi,j +wj,i − ( P k∈R(i)−{j} wi,k + P k∈S(i)−{j} wk,i + P k∈R(j)−{i} wj,k + P k∈S(j)−{i} wk,j) where wi,j is the weight of the request of ai to aj, R(i) is the set of indice of agents having received a request from ai and S(i) is the set of indice of agents having send a request to ai).",
                "It then finally sends a weighted request to the agents who maximise this weight (or wait for a request) as described in the global protocol. 4. (CONDITIONAL) CONVERGENCE TO GLOBAL <br>consistency</br> In this section we will show that the requirements regarding protocols and strategies just discussed will be sufficient to ensure that the system will eventually converge towards global <br>consistency</br>, under some conditions.",
                "We first show that, if two agents are not mutually consistent at some time, then there will be necessarily a time in the future such that an agent will learn a new observation, being it because it is new for the system, or by learning it from another agent.",
                "Lemma 1.",
                "Let S be a system populated by n agents a1, a2, ..., an, temporaly connex, and involving bounded perceptions for these agents.",
                "Let n1 be the sum of cardinalities of the intersection of pairwise observation sets. (n1 = P (i,j)∈[1,n]2 |Oi ∩ Oj|) Let n2 be the cardinality of the union of all agents observations sets. (n2 = | ∪N i=1 Oi|).",
                "If ¬MCons(ai, aj) at time t0, there is necessarily a time t > t0 s.t. either n1 or n2 will increase.",
                "Proof.",
                "Suppose that there exist a time t0 and indices (i, j) s.t. ¬MCons(ai, aj).",
                "We will use mt0 = P (k,l)∈[1,n]2 εComm(ak, al, t0) where εComm(ak, al, t0) = 1 if ak and al have communicated at least once since t0, and 0 otherwise.",
                "Temporal connexity guarantees that there exist t1, ..., tm+1 and k1, ..., km s.t.",
                "C(ai, ak1 , t1), C(akm , aj, tm+1), and ∀p ∈ [1, m], C(akp , akp+1 , tp).",
                "Clearly, if MCons(ai, ak1 ), MCons(akm , aj) and ∀p, MCons(akp , akp+1 ), we have MCons(ai, aj) which contradicts our hypothesis (MCons being transitive, MCons(ai, ak1 )∧MCons(ak1 , ak2 ) implies that MCons(ai, ak2 ) and so on till MCons(ai, akm )∧ MCons(akm , aj) which implies MCons(ai, aj) ).",
                "At least two agents are then necessarily inconsistent (¬MCons(ai, ak1 ), or ¬MCons(akm , aj), or ∃p0 t.q. ¬MCons(akp0 , akp0+1 )).",
                "Let ak and al be these two neighbours at a time t > t0 1 .",
                "The SOLVE property ensures that either ak or al will send a communication request to the other agent at time t .",
                "As shown before, this in turn ensures that at least one of these agents will be involved in a communication.",
                "Then there are two possibilities: (case i) ak and al communicate at time t .",
                "In this case, we know that ¬MCons(ak, al).",
                "This and the CONS property ensures that at least one of the agents must change its 1 Strictly speaking, the transitivity of MCons only ensure that ak and al are inconsistent at a time t ≥ t0 that can be different from the time t at which they can communicate.",
                "But if they become consistent between t and t (or inconsistent between t and t ), it means that at least one of them have changed its hypothesis between t and t , that is, after t0.",
                "We can then apply the reasoning of case iib.",
                "The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 1001 hypothesis, which in turn, since agents are autonomous, implies at least one exchange of observation.",
                "But then |Ok ∩Ol| is bound to increase: n1(t ) > n1(t0). (case ii) ak communicates with ap at time t .",
                "We then have again two possibilities: (case iia) ak and ap did not communicate since t0.",
                "But then εComm(ak, ap, t0) had value 0 and takes value 1.",
                "Hence mt0 increases. (case iib) ak and ap did communicate at some time t0 > t0.",
                "The CONS property of the protocol ensures that MCons(ak, ap) at that time.",
                "Now the fact that they communicate and FOCUS implies that at least one of them did change its hypothesis in the meantime.",
                "The fact that agents are autonomous implies in turn that a new observation (perceived or received from another agent) necessarily provoked this change.",
                "The latter case would ensure the existence of a time t > t0 and an agent aq s.t. either |Op ∩Oq| or |Ok ∩Oq| increases of 1 at that time (implying n1(t ) > n1(t0)).",
                "The former case means that the agent gets a new perception o at time t .",
                "If that observation was unknown in the system before, then n2(t ) > n2(t0).",
                "If some agent aq already knew this observation before, then either Op ∩ Oq or Ok ∩ Oq increases of 1 at time t (which implies that n1(t ) > n1(t0)).",
                "Hence, ¬MCons(ai, aj) at time t0 guarantees that, either: −∃t > t0 t.q. n1(t ) > n1(t0); or −∃t > t0 t.q. n2(t ) > n2(t0); or −∃t > t0 t.q. mt0 increases of 1 at time t .",
                "By iterating the reasoning with t (but keeping t0 as the time reference for mt0 ), we can eliminate the third case (mt0 is integer and bounded by n2 , which means that after a maximum of n2 iterations, we necessarily will be in one of two other cases.)",
                "As a result, we have proven that if ¬MCons(ai, aj) at time t0, there is necessarily a time t s.t. either n1 or n2 will increase.",
                "Theorem 1 (Global <br>consistency</br>).",
                "Let S be a system populated by n agents a1, a2, ..., an, temporaly connex, and involving bounded perceptions for these agents.",
                "Let Cons(ai, aj) be a transitive <br>consistency</br> property.",
                "Then any protocol and strategies satisfying properties CONS, SOLVE, FOCUS, COMM and REQU guarantees that the system will converge towards global <br>consistency</br>.",
                "Proof.",
                "For the sake of contradiction, let us assume ∃I, J ∈ [1, N] s.t. ∀t, ∃t0 > t, t.q. ¬Cons(aI , aJ , t0).",
                "Using the lemma, this implies that ∃t > t0 s.t. either n1(t ) > n1(t0) or n2(t ) > n2(t0).",
                "But we can apply the same reasoning taking t = t , which would give us t1 > t > t0 s.t. ¬Cons(aI , aJ , t1), which gives us t > t1 s.t. either n1(t ) > n1(t1) or n2(t ) > n2(t1).",
                "By successive iterations we can then construct a sequence t0, t1, ..., tn, which can be divided in two sub-sequences t0, t1, ...tn and t0 , t1 , ..., tn s.t. n1(t0) < n1(t1) < ... < n1(tn) and n2(t0 ) < n2(t1 ) < ... < n2(tn).",
                "One of these sub-sequences has to be infinite.",
                "However, n1(ti) and n2(ti ) are strictly growing, integer, and bounded, which implies that both are finite.",
                "Contradiction.",
                "What the previous result essentially shows is that, in a system where no agent will be isolated from the rest of the agents for ever, only very mild assumptions on the protocols and strategies used by agents suffice to guarantee convergence towards system <br>consistency</br> in a finite amount of time (although it might take very long).",
                "Unfortunately, in many critical situations, it will not be possible to assume this temporal connexity.",
                "As distributed approaches as the one advocated in this paper are precisely often presented as a good way to tackle problems of reliability or problems of dependence to a center that are of utmost importance in these critical applications, it is certainly interesting to further explore how such a system would behave when we relax this assumption. 5.",
                "EXPERIMENTAL STUDY This experiment involves agents trying to escape from a burning building.",
                "The environment is described as a spatial grid with a set of walls and (thankfully) some exits.",
                "Time and space are considered discrete.",
                "Time is divided in rounds.",
                "Agents are localised by their position on the spatial grid.",
                "These agents can move and communicate with other agents.",
                "In a round, an agent can move of one cell in any of the four cardinal directions, provided it is not blocked by a wall.",
                "In this application, agents communicate with any other agent (but, recall, a single one) given that this agent is in view, and that they have not yet exchanged their current favoured hypothesis.",
                "Suddenly, a fire erupts in these premises.",
                "From this moment, the fire propagates.",
                "Each round, for each cases where there is fire, the fire propagates in the four directions.",
                "However, the fire cannot propagate through a wall.",
                "If the fire propagates in a case where an agent is positioned, that agent burns and is considered dead.",
                "It can of course no longer move nor communicate.",
                "If an agent gets to an exit, it is considered saved, and can no longer be burned.",
                "Agents know the environment and the rules governing the dynamics of this environment, that is, they know the map as well as the rules of fire propagation previously described.",
                "They also locally perceive this environment, but cannot see further than 3 cases away, in any direction.",
                "Walls also block the line of view, preventing agents from seeing behind them.",
                "Within their sight, they can see other agents and whether or not the cases they see are on fire.",
                "All these perceptions are memorised.",
                "We now show how this instantiates the abstract framework presented the paper. • O = {Fire(x, y, t), NoFire(x, y, t), Agent(ai, x, y, t)} Observations can then be positive (o ∈ P(O) iff ∃h ∈ H s.t. h |= o) or negative (o ∈ N(O) iff ∃h ∈ H s.t. h |= ¬o). • H={FireOrigin(x1, y1, t1)∧...∧FireOrigin(xl, yl, tl)} Hypotheses are conjunctions of FireOrigins. • Cons(h, O) <br>consistency</br> relation satisfies: - coherence : ∀o ∈ N(O), h |= ¬o. - completeness : ∀o ∈ P(O), h |= o. - minimality : For all h ∈ H, if h is coherent and complete for O, then h is prefered to h according to the preference relation (h ≤p h ).2 2 Selects first the minimal number of origins, then the most recent (least preemptive strategy [6]), then uses some arbitrary fixed ranking to discriminate ex-aequo.",
                "The resulting relation is a total order, hence minimality implies that there will be a single h s.t.Cons(O, h) for a given O.",
                "This in turn means that MCons(ai, aj) iff Cons(ai), Cons(aj), and hi = hj.",
                "This relation is then transitive and symmetric. 1002 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) • Eh takes O as argument and returns min≤p of the coherent and complete hypothesis for O 5.1 Experimental Evaluation We will classically (see e.g. [3, 4]) assess the effectiveness and efficiency of different interaction protocols.",
                "Effectiveness of a protocol The proportion of agents surviving the fire over the initial number of agents involved in the experiment will determine the effectiveness of a given protocol.",
                "If this value is high, the protocol has been effective to propagate the information and/or for the agents to refine their hypotheses and determine the best way to the exit.",
                "Efficiency of a protocol Typically, the use of supporting information will involve a communication overhead.",
                "We will assume here that the efficiency of a given protocol is characterised by the data flow induced by this protocol.",
                "In this paper we will only discuss this aspect wrt. local protocols.",
                "The main measure that we shall then use here is the mean total size of messages that are exchanged by agents per exchange (hence taking into account both the number of messages and the actual size of the messages, because it could be that messages happen to be very big, containing e.g. a large number of observations, which could counter-balance a low number of messages). 5.2 Experimental Settings The chosen experimental settings are the following: • Environmental topology- Performances of information propagation are highly constrained by the environment topology.",
                "The perception skills of the agents depend on the openness of the environment.",
                "With a large number of walls the perceptions of agents are limited, and also the number of possible inter-agent communications, whereas an open environment will provide optimal possibilities of perception and information propagation.",
                "Thus, we propose a topological index (see below) as a common basis to charaterize the environments (maps) used during experimentations.",
                "The topological index (TI) is the ratio of the number of cells that can be perceived by agents summed up from all possible positions, divided by the number of cells that would be perceived from the same positions but without any walls. (The closer to 1, the more open the environment).",
                "We shall also use two additional, more classical [10], measures: the characteristic path length3 (CPL) and the clustering coefficient4 (CC). • Number of agents- The propagation of information also depends on the initial number of agents involved during an experimentation.",
                "For instance, the more agents, the more potential communications there is.",
                "This means that there will be more potential for propagation, but also that the bilateral exchange restriction will be more crucial. 3 The CPL is the median of the means of the shortest path lengths connecting each node to all other nodes. 4 characterising the isolation degree of a region of an environment in terms of acessibility (number of roads still usable to reach this region).",
                "Map T.I. (%) C.P.L.",
                "C.C. 69-1 69,23 4,5 0,69 69-2 68,88 4,38 0,65 69-3 69,80 4,25 0,67 53-1 53,19 5,6 0,59 53-2 53,53 6,38 0,54 53-3 53,92 6,08 0,61 38-1 38,56 8,19 0,50 38-2 38,56 7,3 0,50 38-3 38,23 8,13 0,50 Table 1: Topological Characteristics of the Maps • Initial positions of the agents- Initial positions of the agents have a significant influence on the overall behavior of an instance of our system: being close from an exit will (in general) ease the escape. 5.3 Experimental environments We choose to realize experiments on three very different topological indexes (69% for open environments, 53% for mixed environments, and 38% for labyrinth-like environments).",
                "Figure 2: Two maps (left: TI=69%, right TI=38%) We designed three different maps for each index (Fig. 2 shows two of them), containing the same maximum number of agents (36 agents max.) with a maximum density of one agent per cell, the same number of exits and a similar fire origin (e.g. starting time and position).",
                "The three differents maps of a given index are designed as follows.",
                "The first map is a model of an existing building floor.",
                "The second map has the same enclosure, exits and fire origin as the first one, but the number and location of walls are different (wall locations are designed by an heuristic which randomly creates walls on the spatial grid such that no fully closed rooms are created and that no exit is closed).",
                "The third map is characterised by geometrical enclosure in wich walls location is also designed with the aforementioned heuristic.",
                "Table 1 summarizes the different topological measures characterizing these different maps.",
                "It is worth pointing out that the values confirm the relevance of TI (maps with a high TI have a low CPL and a high CC.",
                "However the CPL and CC allows to further refine the difference between the maps, e.g. between 53-1 and 53-2). 5.4 Experimental Results For each triple of maps defined as above we conduct the same experiments.",
                "In each experiment, the society differs in terms of its initial proportion of involved agents, from 1% to 100%.",
                "This initial proportion represents the percentage of involved agents with regards to the possible maximum number of agents.",
                "For each map and each initial proportion, The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 1003 we select randomly 100 different initial agents locations.",
                "For each of those different locations we execute the system one time for each different interaction protocol.",
                "Effectiveness of Communication and Argumentation The first experiment that we set up aims at testing how effective is hypotheses exchange (HE), and in particular how the topological aspects will affect this effectiveness.",
                "In order to do so, we have computed the ratio of improvement offered by that protocol over a situation where agents could simply not communicate (no comm).",
                "To get further insights as to what extent the hypotheses exchange was really crucial, we also tested a much less elaborated protocol consisting of mere observation exchanges (OE).",
                "More precisely, this protocol requires that each agent stores any unexpected observation that it perceives, and agents simply exchange their respective lists of observations when they discuss.",
                "In this case, the local protocol is different (note in particular that it does not guarantee mutual <br>consistency</br>), but the global protocol remains the same (at the only exception that agents motivation to communicate is to synchronise their list of observations, not their hypothesis).",
                "If this protocol is at best as effective as HE, it has the advantage of being more efficient (this is obvious wrt the number of messages which will be limited to 2, less straightforward as far as the size of messages is concerned, but the rough observation that the exchange of observations can be viewed as a flat version of the challenge is helpful to see this).",
                "The results of these experiments are reported in Fig. 3.",
                "Figure 3: Comparative effectiveness ratio gain of protocols when the proportion of agents augments The first observation that needs to be made is that communication improves the effectiveness of the process, and this ratio increases as the number of agents grows in the system.",
                "The second lesson that we learn here is that closeness relatively makes communication more effective over non communication.",
                "Maps exhibiting a T.I. of 38% are constantly above the two others, and 53% are still slightly but significantly better than 69%.",
                "However, these curves also suggest, perhaps surprisingly, that HE outperforms OE in precisely those situations where the ratio gain is less important (the only noticeable difference occurs for rather open maps where T.I. is 69%).",
                "This may be explained as follows: when a map is open, agents have many potential explanation candidates, and argumentation becomes useful to discriminate between those.",
                "When a map is labyrinth-like, there are fewer possible explanations to an unexpected event.",
                "Importance of the Global Protocol The second set of experiments seeks to evaluate the importance of the design of the global protocol.",
                "We tested our protocol against a local broadcast (LB) protocol.",
                "Local broadcast means that all the neighbours agents perceived by an agent will be involved in a communication with that agent in a given round -we alleviate the constraint of a single communication by agent.",
                "This gives us a rough upper bound upon the possible ratio gain in the system (for a given local protocol).",
                "Again, we evaluated the ratio gain induced by that LB over our classical HE, for the three different classes of maps.",
                "The results are reported in Fig. 4.",
                "Figure 4: Ratio gain of local broadcast over hypotheses exchange Note to begin with that the ratio gain is 0 when the proportion of agents is 5%, which is easily explained by the fact that it corresponds to situations involving only two agents.",
                "We first observe that all classes of maps witness a ratio gain increasing when the proportion of agents augments: the gain reaches 10 to 20%, depending on the class of maps considered.",
                "If one compares this with the improvement reported in the previous experiment, it appears to be of the same magnitude.",
                "This illustrates that the design of the global protocol cannot be ignored, especially when the proportion of agents is high.",
                "However, we also note that the effectiveness ratio gain curves have very different shapes in both cases: the gain induced by the accuracy of the local protocol increases very quickly with the proportion of agents, while the curve is really smooth for the global one.",
                "Now let us observe more carefully the results reported here: the curve corresponding to a TI of 53% is above that corresponding to 38%.",
                "This is so because the more open a map, the more opportunities to communicate with more than one agent (and hence benefits from broadcast).",
                "However, we also observe that curve for 69% is below that for 53%.",
                "This is explained as follows: in the case of 69%, the potential gain to be made in terms of surviving agents is much lower, because our protocols already give rather efficient outcomes anyway (quickly reaching 90%, see Fig. 3).",
                "A simple rule of thumb could be that when the number of agents is small, special attention should be put on the local 1004 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) protocol, whereas when that number is large, one should carefully design the global one (unless the map is so open that the protocol is already almost optimally efficient).",
                "Efficiency of the Protocols The final experiment reported here is concerned with the analysis of the efficiency of the protocols.",
                "We analysis here the mean size of the totality of the messages that are exchanged by agents (mean size of exchanges, for short) using the following protocols: HE, OE, and two variant protocols.",
                "The first one is an intermediary restricted hypotheses exchange protocol (RHE).",
                "RHE is as follows: it does not involve any challenge nor counter-propose, which means that agents cannot switch their role during the protocol (this differs from RE in that respect).",
                "In short, RHE allows an agent to exhaust its partners criticism, and eventually this partner will come to adopt the agents hypothesis.",
                "Note that this means that the autonomy of the agent is not preserved here (as an agent will essentially accept any hypothesis it cannot undermine), with the hope that the gain in efficiency will be significant enough to compensate a loss in effectiveness.",
                "The second variant protocol is a complete observation exchange protocol (COE).",
                "COE uses the same principles as OE, but includes in addition all critical negative examples (nofire) in the exchange (thus giving all examples used as arguments by the hypotheses exchanges protocol), hence improving effectiveness.",
                "Results for map 69-1 are shown on Fig. 5.",
                "Figure 5: Mean size of exchanges First we can observe the fact that the ordering of the protocols, from the least efficient to the most efficient, is COE, HE, RHE and then OE.",
                "HE being more efficient than COE proves that the argumentation process gains efficiency by selecting when it is needed to provide negative example, which have less impact that positive ones in our specific testbed.",
                "However, by communicating hypotheses before eventually giving observation to support it (HE) instead of directly giving the most crucial observations (OE), the argumentation process doubles the size of data exchanges.",
                "It is the cost for ensuring <br>consistency</br> at the end of the exchange (a property that OE does not support).",
                "Also significant is the fact the the mean size of exchanges is slightly higher when the number of agents is small.",
                "This is explained by the fact that in these cases only a very few agents have relevant informations in their possession, and that they will need to communicate a lot in order to come up with a common view of the situation.",
                "When the number of agents increases, this knowledge is distributed over more agents which need shorter discussions to get to mutual <br>consistency</br>.",
                "As a consequence, the relative gain in efficiency of using RHE appears to be better when the number of agents is small: when it is high, they will hardly argue anyway.",
                "Finally, it is worth noticing that the standard deviation for these experiments is rather high, which means that the conversation do not converge to any stereotypic pattern. 6.",
                "CONCLUSION This paper has investigated the properties of a multiagent system where each (distributed) agent locally perceives its environment, and tries to reach <br>consistency</br> with other agents despite severe communication restrictions.",
                "In particular we have exhibited conditions allowing convergence, and experimentally investigated a typical situation where those conditions cannot hold.",
                "There are many possible extensions to this work, the first being to further investigate the properties of different global protocols belonging to the class we identified, and their influence on the outcome.",
                "There are in particular many heuristics, highly dependent on the context of the study, that could intuitively yield interesting results (in our study, selecting the recipient on the basis of what can be inferred from his observed actions could be such a heuristic).",
                "One obvious candidate for longer term issues concern the relaxation of the assumption of perfect sensing. 7.",
                "REFERENCES [1] G. Bourgne, N. Maudet, and S. Pinson.",
                "When agents communicate hypotheses in critical situations.",
                "In Proceedings of DALT-2006, May 2006. [2] P. Harvey, C. F. Chang, and A. Ghose.",
                "Support-based distributed search: a new approach for multiagent constraint processing.",
                "In Proceedings of AAMAS06, 2006. [3] H. Jung and M. Tambe.",
                "Argumentation as distributed constraint satisfaction: Applications and results.",
                "In Proceedings of AGENTS01, 2001. [4] N. C. Karunatillake and N. R. Jennings.",
                "Is it worth arguing?",
                "In Proceedings of ArgMAS 2004, 2004. [5] S. Onta˜n´on and E. Plaza.",
                "Arguments and counterexamples in case-based joint deliberation.",
                "In Proceedings of ArgMAS-2006, May 2006. [6] D. Poole.",
                "Explanation and prediction: An architecture for default and abductive reasoning.",
                "Computational Intelligence, 5(2):97-110, 1989. [7] I. Rahwan, S. D. Ramchurn, N. R. Jennings, P. McBurney, S. Parsons, and L. Sonenberg.",
                "Argumention-based negotiation.",
                "The Knowledge Engineering Review, 4(18):345-375, 2003. [8] N. Roos, A. ten Tije, and C. Witteveen.",
                "A protocol for multi-agent diagnosis with spatially distributed knowledge.",
                "In Proceedings of AAMAS03, 2003. [9] N. Roos, A. ten Tije, and C. Witteveen.",
                "Reaching diagnostic agreement in multiagent diagnosis.",
                "In Proceedings of AAMAS04, 2004. [10] T. Takahashi, Y. Kaneda, and N. Ito.",
                "Preliminary study - using robocuprescue simulations for disasters prevention.",
                "In Proceedings of SRMED2004, 2004.",
                "The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 1005"
            ],
            "original_annotated_samples": [
                "In this paper, we mostly investigate the convergence of such systems towards global <br>consistency</br>.",
                "If, in addition, the communication opportunities are severely constrained (for instance, agents can only communicate when they are close enough to some other agent), and dynamically changing (for instance, agents may change their locations), it becomes crucial to carefully design protocols that will allow agents to converge to some desired state of global <br>consistency</br>.",
                "Section 4 details one of 998 978-81-904262-7-5 (RPS) c 2007 IFAAMAS the main results of the paper, namely the fact that under the aforementioned conditions, the constraints that we put on the topology will not prevent the convergence of the system towards global <br>consistency</br>, at the condition that no agent ever gets completely lost forever in the system, and that unlimited time is allowed for computation and argument exchange.",
                "Let Cons(h, O) be the <br>consistency</br> relation, a binary relation between a hypothesis h ∈ H and a set of observations O ⊆ O.",
                "In most cases, Cons will refer to classical <br>consistency</br> relation, however, we may overload its meaning and add some additional properties to that relation (in which case we will mention it)."
            ],
            "translated_annotated_samples": [
                "En este artículo, investigamos principalmente la convergencia de dichos sistemas hacia la <br>consistencia</br> global.",
                "Si, además, las oportunidades de comunicación están severamente limitadas (por ejemplo, los agentes solo pueden comunicarse cuando están lo suficientemente cerca de otro agente) y cambian dinámicamente (por ejemplo, los agentes pueden cambiar sus ubicaciones), se vuelve crucial diseñar cuidadosamente protocolos que permitan a los agentes converger hacia algún estado deseado de <br>consistencia</br> global.",
                "La sección 4 detalla uno de los principales resultados del artículo, a saber, el hecho de que bajo las condiciones mencionadas, las restricciones que imponemos en la topología no impedirán la convergencia del sistema hacia la <br>consistencia</br> global, siempre y cuando ningún agente se pierda completamente para siempre en el sistema, y se permita un tiempo ilimitado para la computación y el intercambio de argumentos.",
                "Sea Cons(h, O) la <br>relación de consistencia</br>, una relación binaria entre una hipótesis h ∈ H y un conjunto de observaciones O ⊆ O.",
                "En la mayoría de los casos, Cons se referirá a la relación de <br>consistencia</br> clásica, sin embargo, podemos sobrecargar su significado y añadir algunas propiedades adicionales a esa relación (en cuyo caso lo mencionaremos)."
            ],
            "translated_text": "Refinamiento de hipótesis bajo restricciones de comunicación topológica ∗ Gauvain Bourgne, Gael Hette, Nicolas Maudet y Suzanne Pinson LAMSADE, Univ. Investigamos las propiedades de un sistema multiagente donde cada agente (distribuido) percibe localmente su entorno. Tras la percepción de un evento inesperado, cada agente calcula localmente su hipótesis favorita e intenta propagarla a otros agentes, intercambiando hipótesis y argumentos de apoyo (observaciones). Sin embargo, también asumimos que las oportunidades de comunicación están severamente limitadas y cambian dinámicamente. En este artículo, investigamos principalmente la convergencia de dichos sistemas hacia la <br>consistencia</br> global. Primero demostramos que (para una amplia clase de protocolos que definiremos), las restricciones de comunicación inducidas por la topología no impedirán la convergencia del sistema, bajo la condición de que la dinámica del sistema garantice que ningún agente quedará aislado para siempre, y que los agentes tengan tiempo ilimitado para la computación y el intercambio de argumentos. Dado que esta suposición no se puede hacer en la mayoría de las situaciones, establecimos un marco experimental con el objetivo de comparar la eficiencia y efectividad relativa de diferentes protocolos de interacción para el intercambio de hipótesis. Estudiamos una situación crítica que implica a varios agentes que intentan escapar de un edificio en llamas. Los resultados reportados aquí proporcionan algunas ideas sobre el diseño de un protocolo óptimo para el refinamiento de hipótesis en este contexto. Categorías y Descriptores de Asignaturas I.2.11 [Inteligencia Artificial]: Inteligencia Artificial Distribuida-Sistemas Multiagente Términos Generales Teoría, Experimentación 1. INTRODUCCIÓN Consideramos un sistema multiagente donde cada agente (distribuido) percibe localmente su entorno, y asumimos que ocurre un evento inesperado en ese sistema. Si cada agente calcula solo localmente su hipótesis preferida, es natural asumir que los agentes buscarán coordinar y refinar sus hipótesis confrontando sus observaciones con otros agentes. Si, además, las oportunidades de comunicación están severamente limitadas (por ejemplo, los agentes solo pueden comunicarse cuando están lo suficientemente cerca de otro agente) y cambian dinámicamente (por ejemplo, los agentes pueden cambiar sus ubicaciones), se vuelve crucial diseñar cuidadosamente protocolos que permitan a los agentes converger hacia algún estado deseado de <br>consistencia</br> global. En este documento presentamos algunas condiciones suficientes sobre la dinámica del sistema y sobre las estructuras de protocolo/estrategia que permiten garantizar esa propiedad, y estudiamos experimentalmente algunos contextos donde (algunas de) estas suposiciones se relajan. Si bien los problemas de diagnóstico son uno de los clásicos venerables en la tradición de la IA, sus contrapartes multiagentes han atraído atención mucho más recientemente. Roos y sus colegas [8, 9] en particular estudian una situación en la que un número de entidades distribuidas intentan llegar a un diagnóstico global satisfactorio de todo el sistema. Ellos muestran en particular que el número de mensajes necesarios para establecer este diagnóstico global está destinado a ser prohibitivo, a menos que la comunicación se mejore con algún protocolo adecuado. Sin embargo, no imponen restricciones a las opciones de comunicación de los agentes, ni asumen que el sistema es dinámico. Los beneficios de mejorar la comunicación con información de apoyo para hacer que la convergencia a un estado global deseado de un sistema sea más eficiente, a menudo se ha planteado en la literatura. Esta es, por ejemplo, una de las ideas principales que subyacen al enfoque de negociación basado en argumentos [7], donde el estado deseado es un compromiso entre agentes con preferencias conflictivas. Sin embargo, muchos de estos trabajos parten del supuesto de que este enfoque es beneficioso para comenzar y estudian los aspectos técnicos del problema (o en su lugar enfatizan otras ventajas de utilizar la argumentación). Excepciones notables son las obras de [3, 4, 2, 5], que estudiaron en contextos diferentes al nuestro la eficiencia de la argumentación. El resto del documento es el siguiente. La Sección 2 especifica los elementos básicos de nuestro modelo, y la Sección 3 continúa presentando los diferentes protocolos y estrategias utilizados por los agentes para intercambiar hipótesis y observaciones. Ponemos especial atención en enfatizar claramente las condiciones de la dinámica del sistema y los protocolos/estrategias que se explotarán en el resto del documento. La sección 4 detalla uno de los principales resultados del artículo, a saber, el hecho de que bajo las condiciones mencionadas, las restricciones que imponemos en la topología no impedirán la convergencia del sistema hacia la <br>consistencia</br> global, siempre y cuando ningún agente se pierda completamente para siempre en el sistema, y se permita un tiempo ilimitado para la computación y el intercambio de argumentos. Si bien las condiciones en los protocolos y estrategias son bastante suaves, también es claro que estos requisitos del sistema parecen mucho más problemáticos, incluso francamente poco realistas en situaciones críticas donde se abogan precisamente por enfoques distribuidos. Para obtener una imagen más clara de la situación inducida cuando el tiempo es un factor crítico, hemos establecido un marco experimental que presentamos y discutimos en la Sección 5. La situación crítica implica a varios agentes que intentan escapar de un edificio en llamas. Los resultados reportados aquí muestran que la efectividad del intercambio de argumentos depende crucialmente de la naturaleza del edificio, y proporcionan algunas ideas sobre el diseño de un protocolo óptimo para el refinamiento de hipótesis en este contexto. CONCEPTOS BÁSICOS Comenzamos definiendo los elementos básicos de nuestro sistema. Deje que O sea el conjunto (potencialmente infinito) de observaciones posibles. Suponemos que los sensores de nuestros agentes son perfectos, por lo tanto, las observaciones son seguras. Sea H el conjunto de hipótesis, incierto y revisable. Sea Cons(h, O) la <br>relación de consistencia</br>, una relación binaria entre una hipótesis h ∈ H y un conjunto de observaciones O ⊆ O. En la mayoría de los casos, Cons se referirá a la relación de <br>consistencia</br> clásica, sin embargo, podemos sobrecargar su significado y añadir algunas propiedades adicionales a esa relación (en cuyo caso lo mencionaremos). ",
            "candidates": [],
            "error": [
                [
                    "consistencia",
                    "consistencia",
                    "consistencia",
                    "relación de consistencia",
                    "consistencia"
                ]
            ]
        },
        "observation set": {
            "translated_key": "conjunto de observaciones",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Hypotheses Refinement under Topological Communication Constraints ∗ Gauvain Bourgne, Gael Hette, Nicolas Maudet, and Suzanne Pinson LAMSADE, Univ.",
                "Paris-Dauphine, France {bourgne,hette,maudet,pinson}@lamsade.dauphine.fr ABSTRACT We investigate the properties of a multiagent system where each (distributed) agent locally perceives its environment.",
                "Upon perception of an unexpected event, each agent locally computes its favoured hypothesis and tries to propagate it to other agents, by exchanging hypotheses and supporting arguments (observations).",
                "However, we further assume that communication opportunities are severely constrained and change dynamically.",
                "In this paper, we mostly investigate the convergence of such systems towards global consistency.",
                "We first show that (for a wide class of protocols that we shall define), the communication constraints induced by the topology will not prevent the convergence of the system, at the condition that the system dynamics guarantees that no agent will ever be isolated forever, and that agents have unlimited time for computation and arguments exchange.",
                "As this assumption cannot be made in most situations though, we then set up an experimental framework aiming at comparing the relative efficiency and effectiveness of different interaction protocols for hypotheses exchange.",
                "We study a critical situation involving a number of agents aiming at escaping from a burning building.",
                "The results reported here provide some insights regarding the design of optimal protocol for hypotheses refinement in this context.",
                "Categories and Subject Descriptors I.2.11 [Artificial Intelligence]: Distributed Artificial Intelligence-Multiagent systems General Terms Theory, Experimentation 1.",
                "INTRODUCTION We consider a multiagent system where each (distributed) agent locally perceives its environment, and we assume that some unexpected event occurs in that system.",
                "If each agent computes only locally its favoured hypothesis, it is only natural to assume that agents will seek to coordinate and refine their hypotheses by confronting their observations with other agents.",
                "If, in addition, the communication opportunities are severely constrained (for instance, agents can only communicate when they are close enough to some other agent), and dynamically changing (for instance, agents may change their locations), it becomes crucial to carefully design protocols that will allow agents to converge to some desired state of global consistency.",
                "In this paper we exhibit some sufficient conditions on the system dynamics and on the protocol/strategy structures that allow to guarantee that property, and we experimentally study some contexts where (some of) these assumptions are relaxed.",
                "While problems of diagnosis are among the venerable classics in the AI tradition, their multiagent counterparts have much more recently attracted some attention.",
                "Roos and colleagues [8, 9] in particular study a situation where a number of distributed entities try to come up with a satisfying global diagnosis of the whole system.",
                "They show in particular that the number of messages required to establish this global diagnosis is bound to be prohibitive, unless the communication is enhanced with some suitable protocol.",
                "However, they do not put any restrictions on agents communication options, and do not assume either that the system is dynamic.",
                "The benefits of enhancing communication with supporting information to make convergence to a desired global state of a system more efficient has often been put forward in the literature.",
                "This is for instance one of the main idea underlying the argumentation-based negotiation approach [7], where the desired state is a compromise between agents with conflicting preferences.",
                "Many of these works however make the assumption that this approach is beneficial to start with, and study the technical facets of the problem (or instead emphasize other advantages of using argumentation).",
                "Notable exceptions are the works of [3, 4, 2, 5], which studied in contexts different from ours the efficiency of argumentation.",
                "The rest of the paper is as follows.",
                "Section 2 specifies the basic elements of our model, and Section 3 goes on to presenting the different protocols and strategies used by the agents to exchange hypotheses and observations.",
                "We put special attention at clearly emphasizing the conditions on the system dynamics and protocols/strategies that will be exploited in the rest of the paper.",
                "Section 4 details one of 998 978-81-904262-7-5 (RPS) c 2007 IFAAMAS the main results of the paper, namely the fact that under the aforementioned conditions, the constraints that we put on the topology will not prevent the convergence of the system towards global consistency, at the condition that no agent ever gets completely lost forever in the system, and that unlimited time is allowed for computation and argument exchange.",
                "While the conditions on protocols and strategies are fairly mild, it is also clear that these system requirements look much more problematic, even frankly unrealistic in critical situations where distributed approaches are precisely advocated.",
                "To get a clearer picture of the situation induced when time is a critical factor, we have set up an experimental framework that we introduce and discuss in Section 5.",
                "The critical situation involves a number of agents aiming at escaping from a burning building.",
                "The results reported here show that the effectiveness of argument exchange crucially depends upon the nature of the building, and provide some insights regarding the design of optimal protocol for hypotheses refinement in this context. 2.",
                "BASIC NOTIONS We start by defining the basic elements of our system.",
                "Environment Let O be the (potentially infinite) set of possible observations.",
                "We assume the sensors of our agents to be perfect, hence the observations to be certain.",
                "Let H be the set of hypotheses, uncertain and revisable.",
                "Let Cons(h, O) be the consistency relation, a binary relation between a hypothesis h ∈ H and a set of observations O ⊆ O.",
                "In most cases, Cons will refer to classical consistency relation, however, we may overload its meaning and add some additional properties to that relation (in which case we will mention it).",
                "The environment may include some dynamics, and change over the course of time.",
                "We define below sequences of time points to deal with it: Definition 1 (Sequence of time points).",
                "A sequence of time points t1, t2, . . . , tn from t is an ordered set of time points t1, t2, . . . , tn such that t1 ≥ t and ∀i ∈ [1, n − 1], ti+1 ≥ ti.",
                "Agent We take a system populated by n agents a1, . . . , an.",
                "Each agent is defined as a tuple F, Oi, hi , where: • F, the set of facts, common knowledge to all agents. • Oi ∈ 2O , the set of observations made by the agent so far.",
                "We assume a perfect memory, hence this set grows monotonically. • hi ∈ H, the favourite hypothesis of the agent.",
                "A key notion governing the formation of hypotheses is that of consistency, defined below: Definition 2 (Consistency).",
                "We say that: • An agent is consistent (Cons(ai)) iff Cons(hi, Oi) (that is, its hypothesis is consistent with its <br>observation set</br>). • An agent ai consistent with a partner agent aj iff Cons(ai) and Cons(hi, Oj) (that is, this agent is consistent and its hypothesis can explain the <br>observation set</br> of the other agent). • Two agents ai and aj are mutually consistent (MCons(ai, aj)) iff Cons(ai, aj) and Cons(aj, ai). • A system is consistent iff ∀(i, j)∈[1, n]2 it is the case that MCons(ai, aj).",
                "To ensure its consistency, each agent is equipped with an abstract reasoning machinery that we shall call the explanation function Eh.",
                "This (deterministic) function takes a set of observation and returns a single prefered hypothesis (2O → H).",
                "We assume h = Eh(O) to be consistent with O by definition of Eh, so using this function on its <br>observation set</br> to determine its favourite hypothesis is a sure way for the agent to achieve consistency.",
                "Note however that an hypothesis does not need to be generated by Eh to be consistent with an <br>observation set</br>.",
                "As a concrete example of such a function, and one of the main inspiration of this work, one can cite the Theorist reasoning system [6] -as long as it is coupled with a filter selecting a single prefered theory among the ones initially selected by Theorist.",
                "Note also that hi may only be modified as a consequence of the application Eh.",
                "We refer to this as the autonomy of the agent: no other agent can directly impose a given hypothesis to an agent.",
                "As a consequence, only a new observation (being it a new perception, or an observation communicated by a fellow agent) can result in a modification of its prefered hypothesis hi (but not necessarily of course).",
                "We finally define a property of the system that we shall use in the rest of the paper: Definition 3 (Bounded Perceptions).",
                "A system involves a bounded perception for agents iff ∃n0 s.t. ∀t| ∪N i=1 Oi| ≤ n0. (That is, the number of observations to be made by the agents in the system is not infinite.)",
                "Agent Cycle Now we need to see how these agents will evolve and interact in their environment.",
                "In our context, agents evolve in a dynamic environment, and we classicaly assume the following system cycle: 1.",
                "Environment dynamics: the environment evolves according to the defined rules of the system dynamics. 2.",
                "Perception step : agents get perceptions from the environment.",
                "These perceptions are typically partial (e.g. the agent can only see a portion of a map). 3.",
                "Reasoning step: agents compare perception with predictions, seek explanations for (potential) difference(s), refine their hypothesis, draw new conclusions. 4.",
                "Communication step: agents can communicate hypotheses and observations with other agents through a defined protocol.",
                "Any agent can only be involved in one communication with another agent by step. 5.",
                "Action step: agents do some practical reasoning using the models obtained from the previous steps and select an action.",
                "They can then modify the environment by executing it.",
                "The communication of the agents will be further constrained by topological consideration.",
                "At a given time, an agent will only be able to communicate with a number of neighbours.",
                "Its connexions with these others agents may The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 999 evolve with its situation in the environment.",
                "Typically, an agent can only communicate with agents that it can sense, but one could imagine evolving topological constraints on communication based on a network of communications between agents where the links are not always active.",
                "Communication In our system, agents will be able to communicate with each other.",
                "However, due to the aforementionned topological constraints, they will not be able to communicate with any agents at anytime.",
                "Who an agent can communicate with will be defined dynamically (for instance, this can be a consequence of the agents being close enough to get in touch).",
                "We will abstractly denote by C(ai, aj, t) the communication property, in other words, the fact that agents ai and aj can communicate at time t (note that this relation is assumed to be symetric, but of course not transitive).",
                "We are now in a position to define two essential properties of our system.",
                "Definition 4 (Temporal Path).",
                "There exists a temporal communication path at horizon tf (noted Ltf (aI , aJ )) between ai and aj iff there exists a sequence of time points t1, t2, . . . , tn from tf and a sequence of agents k1, k2, . . . , kn s.t. (i) C(aI , ak1 , t1), (ii) C(akn , aJ , tn+1), (iii) ∀i ∈ [1, n], C(aki , aki+1 , ti) Intuitively, what this property says is that it is possible to find a temporal path in the future that would allow to link agent ai and aj via a sequence of intermediary agents.",
                "Note that the time points are not necessarily successive, and that the sequence of agents may involve the same agents several times.",
                "Definition 5 (Temporal Connexity).",
                "A system is temporaly connex iff ∀t ∀(i, j)∈[1, n]2 Lt(ai, aj) In short, a temporaly connex system guarantees that any agent will be able to communicate with any other agents, no matter how long it might take to do so, at any time.",
                "To put it another way, it is never the case that an agent will be isolated for ever from another agent of the system.",
                "We will next discuss the detail of how communication concretely takes place in our system.",
                "Remember that in this paper, we only consider the case of bilateral exchanges (an agent can only speak to a single other agent), and that we also assume that any agent can only engage in a single exchange in a given round. 3.",
                "PROTOCOLS AND STRATEGIES In this section, we discuss the requirements of the interaction protocols that govern the exchange of messages between agents, and provide some example instantiation of such protocols.",
                "To clarify the presentation, we distinguish two levels: the local level, which is concerned with the regulation of bilateral exchanges; and the global level,which essentially regulates the way agents can actually engage into a conversation.",
                "At each level, we separate what is specified by the protocol, and what is left to agents strategies.",
                "Local Protocol and Strategies We start by inspecting local protocols and strategies that will regulate the communication between the agents of the system.",
                "As we limit ourselves to bilateral communication, these protocols will simply involve two agents.",
                "Such protocol will have to meet one basic requirement to be satisfying. • consistency (CONS)- a local protocol has to guarantee the mutual consistency of agents upon termination (which implies termination of course).",
                "Figure 1: A Hypotheses Exchange Protocol [1] One example such protocol is the protocol described in [1] that is pictured in Fig. 1.",
                "To further illustrate how such protocol can be used by agents, we give some details on a possible strategy: upon receiving a hypothesis h1 (propose(h1) or counterpropose(h1)) from a1, agent a2 is in state 2 and has the following possible replies: counterexample (if the agent knows an example contradicting the hypothesis, or not explained by this hypothesis), challenge (if the agents lacks evidence to accept this hypothesis), counterpropose (if the agent agrees with the hypothesis but prefers another one), or accept (if it is indeed as good as its favourite hypothesis).",
                "This strategy guarantees, among other properties, the eventual mutual logical consistency of the involved agents [1].",
                "Global Protocol The global protocol regulates the way bilateral exchanges will be initiated between agents.",
                "At each turn, agents will concurrently send one weighted request to communicate to other agents.",
                "This weight is a value measuring the agents willingness to converse with the targeted agent (in practice, this can be based on different heuristics, but we shall make some assumptions on agents strategies, see below).",
                "Sending such a request is a kind of conditional commitment for the agent.",
                "An agent sending a weighted request commits to engage in conversation with the target if he does not receive and accept himself another request.",
                "Once all request have been received, each agent replies with either an acccept or a reject.",
                "By answering with an accept, an agent makes a full commitment to engage in conversation with the sender.",
                "Therefore, it can only send one accept in a given round, as an agent can only participate in one conversation per time step.",
                "When all response have been received, each agent receiving an accept can either initiate a conversation using the local protocol or send a cancel if it has accepted another request.",
                "At the end of all the bilateral exchanges, the agents engaged in conversation are discarded from the protocol.",
                "Then each of the remaining agents resends a request and the process iterates until no more requests are sent.",
                "Global Strategy We now define four requirements for the strategies used by agents, depending on their role in the protocol: two are concerned with the requestee role (how to decide who the 1000 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) agent wishes to communicate with? ), the other two with the responder role (how to decide which communication request to accept or not?). • Willingness to solve inconsistancies (SOLVE)-agents want to communicate with any other agents unless they know they are mutually consistent. • Focus on solving inconsistencies (FOCUS)-agents do not request communication with an agent with whom they know they are mutually consistent. • Willingness to communicate (COMM)-agents cannot refuse a weighted communication request, unless they have just received or send a request with a greater weight. • Commitment to communication request (REQU)agents cannot accept a weighted communication request if they have themselves sent a communication request with a greater weight.",
                "Therefore, they will not cancel their request unless they have received a communicational request with greater weight.",
                "Now the protocol structure, together with the properties COMM+REQU, ensure that a request can only be rejected if its target agent engages in communication with another agent.",
                "Suppose indeed that agent ai wants to communicate with aj by sending a request with weight w. COMM guarantees that an agent receiving a weighted request will either accept this communication, accept a communication with a greater weight or wait for the answer to a request with a greater weight.",
                "This ensures that the request with maximal weight will be accepted and not cancelled (as REQU ensures that an agent sending a request can only cancel it if he accepts another request with greater weight).",
                "Therefore at least two agents will engage in conversation per round of the global protocol.",
                "As the protocol ensures that ai can resend its request while aj is not engaged in a conversation, there will be a turn in which aj must engage in a conversation, either with ai or another agent.",
                "These requirements concern request sending and acceptation, but agents also need some strategy of weight attribution.",
                "We describe below an altruist strategy, used in our experiments.",
                "Being cooperative, an agent may want to know more of the communication wishes of other agents in order to improve the overall allocation of exchanges to agents.",
                "A context request step is then added to the global protocol.",
                "Before sending their chosen weighted request, agents attribute a weight to all agents they are prepared to communicate with, according to some internal factors.",
                "In the simplest case, this weight will be 1 for all agent with whom the agent is not sure of being mutually consistent (ensuring SOLVE), other agent being not considered for communication (ensuring FOCUS).",
                "The agent then sends a context request to all agents with whom communication is considered.",
                "This request also provides information about the sender (list of considered communications along with their weight).",
                "After reception of all the context requests, agents will either reply with a deny, iff they are already engaged in a conversation (in which case, the requesting agent will not consider communication with them anymore in this turn), or an inform giving the requester information about the requests it has sent and received.",
                "When all replies have been received, each agent can calculate the weight of all requests concerning it.",
                "It does so by substracting from the weight of its request the weight of all requests concerning either it or its target (that is, the final weight of the request from ai to aj is Wi,j = wi,j +wj,i − ( P k∈R(i)−{j} wi,k + P k∈S(i)−{j} wk,i + P k∈R(j)−{i} wj,k + P k∈S(j)−{i} wk,j) where wi,j is the weight of the request of ai to aj, R(i) is the set of indice of agents having received a request from ai and S(i) is the set of indice of agents having send a request to ai).",
                "It then finally sends a weighted request to the agents who maximise this weight (or wait for a request) as described in the global protocol. 4. (CONDITIONAL) CONVERGENCE TO GLOBAL CONSISTENCY In this section we will show that the requirements regarding protocols and strategies just discussed will be sufficient to ensure that the system will eventually converge towards global consistency, under some conditions.",
                "We first show that, if two agents are not mutually consistent at some time, then there will be necessarily a time in the future such that an agent will learn a new observation, being it because it is new for the system, or by learning it from another agent.",
                "Lemma 1.",
                "Let S be a system populated by n agents a1, a2, ..., an, temporaly connex, and involving bounded perceptions for these agents.",
                "Let n1 be the sum of cardinalities of the intersection of pairwise observation sets. (n1 = P (i,j)∈[1,n]2 |Oi ∩ Oj|) Let n2 be the cardinality of the union of all agents observations sets. (n2 = | ∪N i=1 Oi|).",
                "If ¬MCons(ai, aj) at time t0, there is necessarily a time t > t0 s.t. either n1 or n2 will increase.",
                "Proof.",
                "Suppose that there exist a time t0 and indices (i, j) s.t. ¬MCons(ai, aj).",
                "We will use mt0 = P (k,l)∈[1,n]2 εComm(ak, al, t0) where εComm(ak, al, t0) = 1 if ak and al have communicated at least once since t0, and 0 otherwise.",
                "Temporal connexity guarantees that there exist t1, ..., tm+1 and k1, ..., km s.t.",
                "C(ai, ak1 , t1), C(akm , aj, tm+1), and ∀p ∈ [1, m], C(akp , akp+1 , tp).",
                "Clearly, if MCons(ai, ak1 ), MCons(akm , aj) and ∀p, MCons(akp , akp+1 ), we have MCons(ai, aj) which contradicts our hypothesis (MCons being transitive, MCons(ai, ak1 )∧MCons(ak1 , ak2 ) implies that MCons(ai, ak2 ) and so on till MCons(ai, akm )∧ MCons(akm , aj) which implies MCons(ai, aj) ).",
                "At least two agents are then necessarily inconsistent (¬MCons(ai, ak1 ), or ¬MCons(akm , aj), or ∃p0 t.q. ¬MCons(akp0 , akp0+1 )).",
                "Let ak and al be these two neighbours at a time t > t0 1 .",
                "The SOLVE property ensures that either ak or al will send a communication request to the other agent at time t .",
                "As shown before, this in turn ensures that at least one of these agents will be involved in a communication.",
                "Then there are two possibilities: (case i) ak and al communicate at time t .",
                "In this case, we know that ¬MCons(ak, al).",
                "This and the CONS property ensures that at least one of the agents must change its 1 Strictly speaking, the transitivity of MCons only ensure that ak and al are inconsistent at a time t ≥ t0 that can be different from the time t at which they can communicate.",
                "But if they become consistent between t and t (or inconsistent between t and t ), it means that at least one of them have changed its hypothesis between t and t , that is, after t0.",
                "We can then apply the reasoning of case iib.",
                "The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 1001 hypothesis, which in turn, since agents are autonomous, implies at least one exchange of observation.",
                "But then |Ok ∩Ol| is bound to increase: n1(t ) > n1(t0). (case ii) ak communicates with ap at time t .",
                "We then have again two possibilities: (case iia) ak and ap did not communicate since t0.",
                "But then εComm(ak, ap, t0) had value 0 and takes value 1.",
                "Hence mt0 increases. (case iib) ak and ap did communicate at some time t0 > t0.",
                "The CONS property of the protocol ensures that MCons(ak, ap) at that time.",
                "Now the fact that they communicate and FOCUS implies that at least one of them did change its hypothesis in the meantime.",
                "The fact that agents are autonomous implies in turn that a new observation (perceived or received from another agent) necessarily provoked this change.",
                "The latter case would ensure the existence of a time t > t0 and an agent aq s.t. either |Op ∩Oq| or |Ok ∩Oq| increases of 1 at that time (implying n1(t ) > n1(t0)).",
                "The former case means that the agent gets a new perception o at time t .",
                "If that observation was unknown in the system before, then n2(t ) > n2(t0).",
                "If some agent aq already knew this observation before, then either Op ∩ Oq or Ok ∩ Oq increases of 1 at time t (which implies that n1(t ) > n1(t0)).",
                "Hence, ¬MCons(ai, aj) at time t0 guarantees that, either: −∃t > t0 t.q. n1(t ) > n1(t0); or −∃t > t0 t.q. n2(t ) > n2(t0); or −∃t > t0 t.q. mt0 increases of 1 at time t .",
                "By iterating the reasoning with t (but keeping t0 as the time reference for mt0 ), we can eliminate the third case (mt0 is integer and bounded by n2 , which means that after a maximum of n2 iterations, we necessarily will be in one of two other cases.)",
                "As a result, we have proven that if ¬MCons(ai, aj) at time t0, there is necessarily a time t s.t. either n1 or n2 will increase.",
                "Theorem 1 (Global consistency).",
                "Let S be a system populated by n agents a1, a2, ..., an, temporaly connex, and involving bounded perceptions for these agents.",
                "Let Cons(ai, aj) be a transitive consistency property.",
                "Then any protocol and strategies satisfying properties CONS, SOLVE, FOCUS, COMM and REQU guarantees that the system will converge towards global consistency.",
                "Proof.",
                "For the sake of contradiction, let us assume ∃I, J ∈ [1, N] s.t. ∀t, ∃t0 > t, t.q. ¬Cons(aI , aJ , t0).",
                "Using the lemma, this implies that ∃t > t0 s.t. either n1(t ) > n1(t0) or n2(t ) > n2(t0).",
                "But we can apply the same reasoning taking t = t , which would give us t1 > t > t0 s.t. ¬Cons(aI , aJ , t1), which gives us t > t1 s.t. either n1(t ) > n1(t1) or n2(t ) > n2(t1).",
                "By successive iterations we can then construct a sequence t0, t1, ..., tn, which can be divided in two sub-sequences t0, t1, ...tn and t0 , t1 , ..., tn s.t. n1(t0) < n1(t1) < ... < n1(tn) and n2(t0 ) < n2(t1 ) < ... < n2(tn).",
                "One of these sub-sequences has to be infinite.",
                "However, n1(ti) and n2(ti ) are strictly growing, integer, and bounded, which implies that both are finite.",
                "Contradiction.",
                "What the previous result essentially shows is that, in a system where no agent will be isolated from the rest of the agents for ever, only very mild assumptions on the protocols and strategies used by agents suffice to guarantee convergence towards system consistency in a finite amount of time (although it might take very long).",
                "Unfortunately, in many critical situations, it will not be possible to assume this temporal connexity.",
                "As distributed approaches as the one advocated in this paper are precisely often presented as a good way to tackle problems of reliability or problems of dependence to a center that are of utmost importance in these critical applications, it is certainly interesting to further explore how such a system would behave when we relax this assumption. 5.",
                "EXPERIMENTAL STUDY This experiment involves agents trying to escape from a burning building.",
                "The environment is described as a spatial grid with a set of walls and (thankfully) some exits.",
                "Time and space are considered discrete.",
                "Time is divided in rounds.",
                "Agents are localised by their position on the spatial grid.",
                "These agents can move and communicate with other agents.",
                "In a round, an agent can move of one cell in any of the four cardinal directions, provided it is not blocked by a wall.",
                "In this application, agents communicate with any other agent (but, recall, a single one) given that this agent is in view, and that they have not yet exchanged their current favoured hypothesis.",
                "Suddenly, a fire erupts in these premises.",
                "From this moment, the fire propagates.",
                "Each round, for each cases where there is fire, the fire propagates in the four directions.",
                "However, the fire cannot propagate through a wall.",
                "If the fire propagates in a case where an agent is positioned, that agent burns and is considered dead.",
                "It can of course no longer move nor communicate.",
                "If an agent gets to an exit, it is considered saved, and can no longer be burned.",
                "Agents know the environment and the rules governing the dynamics of this environment, that is, they know the map as well as the rules of fire propagation previously described.",
                "They also locally perceive this environment, but cannot see further than 3 cases away, in any direction.",
                "Walls also block the line of view, preventing agents from seeing behind them.",
                "Within their sight, they can see other agents and whether or not the cases they see are on fire.",
                "All these perceptions are memorised.",
                "We now show how this instantiates the abstract framework presented the paper. • O = {Fire(x, y, t), NoFire(x, y, t), Agent(ai, x, y, t)} Observations can then be positive (o ∈ P(O) iff ∃h ∈ H s.t. h |= o) or negative (o ∈ N(O) iff ∃h ∈ H s.t. h |= ¬o). • H={FireOrigin(x1, y1, t1)∧...∧FireOrigin(xl, yl, tl)} Hypotheses are conjunctions of FireOrigins. • Cons(h, O) consistency relation satisfies: - coherence : ∀o ∈ N(O), h |= ¬o. - completeness : ∀o ∈ P(O), h |= o. - minimality : For all h ∈ H, if h is coherent and complete for O, then h is prefered to h according to the preference relation (h ≤p h ).2 2 Selects first the minimal number of origins, then the most recent (least preemptive strategy [6]), then uses some arbitrary fixed ranking to discriminate ex-aequo.",
                "The resulting relation is a total order, hence minimality implies that there will be a single h s.t.Cons(O, h) for a given O.",
                "This in turn means that MCons(ai, aj) iff Cons(ai), Cons(aj), and hi = hj.",
                "This relation is then transitive and symmetric. 1002 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) • Eh takes O as argument and returns min≤p of the coherent and complete hypothesis for O 5.1 Experimental Evaluation We will classically (see e.g. [3, 4]) assess the effectiveness and efficiency of different interaction protocols.",
                "Effectiveness of a protocol The proportion of agents surviving the fire over the initial number of agents involved in the experiment will determine the effectiveness of a given protocol.",
                "If this value is high, the protocol has been effective to propagate the information and/or for the agents to refine their hypotheses and determine the best way to the exit.",
                "Efficiency of a protocol Typically, the use of supporting information will involve a communication overhead.",
                "We will assume here that the efficiency of a given protocol is characterised by the data flow induced by this protocol.",
                "In this paper we will only discuss this aspect wrt. local protocols.",
                "The main measure that we shall then use here is the mean total size of messages that are exchanged by agents per exchange (hence taking into account both the number of messages and the actual size of the messages, because it could be that messages happen to be very big, containing e.g. a large number of observations, which could counter-balance a low number of messages). 5.2 Experimental Settings The chosen experimental settings are the following: • Environmental topology- Performances of information propagation are highly constrained by the environment topology.",
                "The perception skills of the agents depend on the openness of the environment.",
                "With a large number of walls the perceptions of agents are limited, and also the number of possible inter-agent communications, whereas an open environment will provide optimal possibilities of perception and information propagation.",
                "Thus, we propose a topological index (see below) as a common basis to charaterize the environments (maps) used during experimentations.",
                "The topological index (TI) is the ratio of the number of cells that can be perceived by agents summed up from all possible positions, divided by the number of cells that would be perceived from the same positions but without any walls. (The closer to 1, the more open the environment).",
                "We shall also use two additional, more classical [10], measures: the characteristic path length3 (CPL) and the clustering coefficient4 (CC). • Number of agents- The propagation of information also depends on the initial number of agents involved during an experimentation.",
                "For instance, the more agents, the more potential communications there is.",
                "This means that there will be more potential for propagation, but also that the bilateral exchange restriction will be more crucial. 3 The CPL is the median of the means of the shortest path lengths connecting each node to all other nodes. 4 characterising the isolation degree of a region of an environment in terms of acessibility (number of roads still usable to reach this region).",
                "Map T.I. (%) C.P.L.",
                "C.C. 69-1 69,23 4,5 0,69 69-2 68,88 4,38 0,65 69-3 69,80 4,25 0,67 53-1 53,19 5,6 0,59 53-2 53,53 6,38 0,54 53-3 53,92 6,08 0,61 38-1 38,56 8,19 0,50 38-2 38,56 7,3 0,50 38-3 38,23 8,13 0,50 Table 1: Topological Characteristics of the Maps • Initial positions of the agents- Initial positions of the agents have a significant influence on the overall behavior of an instance of our system: being close from an exit will (in general) ease the escape. 5.3 Experimental environments We choose to realize experiments on three very different topological indexes (69% for open environments, 53% for mixed environments, and 38% for labyrinth-like environments).",
                "Figure 2: Two maps (left: TI=69%, right TI=38%) We designed three different maps for each index (Fig. 2 shows two of them), containing the same maximum number of agents (36 agents max.) with a maximum density of one agent per cell, the same number of exits and a similar fire origin (e.g. starting time and position).",
                "The three differents maps of a given index are designed as follows.",
                "The first map is a model of an existing building floor.",
                "The second map has the same enclosure, exits and fire origin as the first one, but the number and location of walls are different (wall locations are designed by an heuristic which randomly creates walls on the spatial grid such that no fully closed rooms are created and that no exit is closed).",
                "The third map is characterised by geometrical enclosure in wich walls location is also designed with the aforementioned heuristic.",
                "Table 1 summarizes the different topological measures characterizing these different maps.",
                "It is worth pointing out that the values confirm the relevance of TI (maps with a high TI have a low CPL and a high CC.",
                "However the CPL and CC allows to further refine the difference between the maps, e.g. between 53-1 and 53-2). 5.4 Experimental Results For each triple of maps defined as above we conduct the same experiments.",
                "In each experiment, the society differs in terms of its initial proportion of involved agents, from 1% to 100%.",
                "This initial proportion represents the percentage of involved agents with regards to the possible maximum number of agents.",
                "For each map and each initial proportion, The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 1003 we select randomly 100 different initial agents locations.",
                "For each of those different locations we execute the system one time for each different interaction protocol.",
                "Effectiveness of Communication and Argumentation The first experiment that we set up aims at testing how effective is hypotheses exchange (HE), and in particular how the topological aspects will affect this effectiveness.",
                "In order to do so, we have computed the ratio of improvement offered by that protocol over a situation where agents could simply not communicate (no comm).",
                "To get further insights as to what extent the hypotheses exchange was really crucial, we also tested a much less elaborated protocol consisting of mere observation exchanges (OE).",
                "More precisely, this protocol requires that each agent stores any unexpected observation that it perceives, and agents simply exchange their respective lists of observations when they discuss.",
                "In this case, the local protocol is different (note in particular that it does not guarantee mutual consistency), but the global protocol remains the same (at the only exception that agents motivation to communicate is to synchronise their list of observations, not their hypothesis).",
                "If this protocol is at best as effective as HE, it has the advantage of being more efficient (this is obvious wrt the number of messages which will be limited to 2, less straightforward as far as the size of messages is concerned, but the rough observation that the exchange of observations can be viewed as a flat version of the challenge is helpful to see this).",
                "The results of these experiments are reported in Fig. 3.",
                "Figure 3: Comparative effectiveness ratio gain of protocols when the proportion of agents augments The first observation that needs to be made is that communication improves the effectiveness of the process, and this ratio increases as the number of agents grows in the system.",
                "The second lesson that we learn here is that closeness relatively makes communication more effective over non communication.",
                "Maps exhibiting a T.I. of 38% are constantly above the two others, and 53% are still slightly but significantly better than 69%.",
                "However, these curves also suggest, perhaps surprisingly, that HE outperforms OE in precisely those situations where the ratio gain is less important (the only noticeable difference occurs for rather open maps where T.I. is 69%).",
                "This may be explained as follows: when a map is open, agents have many potential explanation candidates, and argumentation becomes useful to discriminate between those.",
                "When a map is labyrinth-like, there are fewer possible explanations to an unexpected event.",
                "Importance of the Global Protocol The second set of experiments seeks to evaluate the importance of the design of the global protocol.",
                "We tested our protocol against a local broadcast (LB) protocol.",
                "Local broadcast means that all the neighbours agents perceived by an agent will be involved in a communication with that agent in a given round -we alleviate the constraint of a single communication by agent.",
                "This gives us a rough upper bound upon the possible ratio gain in the system (for a given local protocol).",
                "Again, we evaluated the ratio gain induced by that LB over our classical HE, for the three different classes of maps.",
                "The results are reported in Fig. 4.",
                "Figure 4: Ratio gain of local broadcast over hypotheses exchange Note to begin with that the ratio gain is 0 when the proportion of agents is 5%, which is easily explained by the fact that it corresponds to situations involving only two agents.",
                "We first observe that all classes of maps witness a ratio gain increasing when the proportion of agents augments: the gain reaches 10 to 20%, depending on the class of maps considered.",
                "If one compares this with the improvement reported in the previous experiment, it appears to be of the same magnitude.",
                "This illustrates that the design of the global protocol cannot be ignored, especially when the proportion of agents is high.",
                "However, we also note that the effectiveness ratio gain curves have very different shapes in both cases: the gain induced by the accuracy of the local protocol increases very quickly with the proportion of agents, while the curve is really smooth for the global one.",
                "Now let us observe more carefully the results reported here: the curve corresponding to a TI of 53% is above that corresponding to 38%.",
                "This is so because the more open a map, the more opportunities to communicate with more than one agent (and hence benefits from broadcast).",
                "However, we also observe that curve for 69% is below that for 53%.",
                "This is explained as follows: in the case of 69%, the potential gain to be made in terms of surviving agents is much lower, because our protocols already give rather efficient outcomes anyway (quickly reaching 90%, see Fig. 3).",
                "A simple rule of thumb could be that when the number of agents is small, special attention should be put on the local 1004 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) protocol, whereas when that number is large, one should carefully design the global one (unless the map is so open that the protocol is already almost optimally efficient).",
                "Efficiency of the Protocols The final experiment reported here is concerned with the analysis of the efficiency of the protocols.",
                "We analysis here the mean size of the totality of the messages that are exchanged by agents (mean size of exchanges, for short) using the following protocols: HE, OE, and two variant protocols.",
                "The first one is an intermediary restricted hypotheses exchange protocol (RHE).",
                "RHE is as follows: it does not involve any challenge nor counter-propose, which means that agents cannot switch their role during the protocol (this differs from RE in that respect).",
                "In short, RHE allows an agent to exhaust its partners criticism, and eventually this partner will come to adopt the agents hypothesis.",
                "Note that this means that the autonomy of the agent is not preserved here (as an agent will essentially accept any hypothesis it cannot undermine), with the hope that the gain in efficiency will be significant enough to compensate a loss in effectiveness.",
                "The second variant protocol is a complete observation exchange protocol (COE).",
                "COE uses the same principles as OE, but includes in addition all critical negative examples (nofire) in the exchange (thus giving all examples used as arguments by the hypotheses exchanges protocol), hence improving effectiveness.",
                "Results for map 69-1 are shown on Fig. 5.",
                "Figure 5: Mean size of exchanges First we can observe the fact that the ordering of the protocols, from the least efficient to the most efficient, is COE, HE, RHE and then OE.",
                "HE being more efficient than COE proves that the argumentation process gains efficiency by selecting when it is needed to provide negative example, which have less impact that positive ones in our specific testbed.",
                "However, by communicating hypotheses before eventually giving observation to support it (HE) instead of directly giving the most crucial observations (OE), the argumentation process doubles the size of data exchanges.",
                "It is the cost for ensuring consistency at the end of the exchange (a property that OE does not support).",
                "Also significant is the fact the the mean size of exchanges is slightly higher when the number of agents is small.",
                "This is explained by the fact that in these cases only a very few agents have relevant informations in their possession, and that they will need to communicate a lot in order to come up with a common view of the situation.",
                "When the number of agents increases, this knowledge is distributed over more agents which need shorter discussions to get to mutual consistency.",
                "As a consequence, the relative gain in efficiency of using RHE appears to be better when the number of agents is small: when it is high, they will hardly argue anyway.",
                "Finally, it is worth noticing that the standard deviation for these experiments is rather high, which means that the conversation do not converge to any stereotypic pattern. 6.",
                "CONCLUSION This paper has investigated the properties of a multiagent system where each (distributed) agent locally perceives its environment, and tries to reach consistency with other agents despite severe communication restrictions.",
                "In particular we have exhibited conditions allowing convergence, and experimentally investigated a typical situation where those conditions cannot hold.",
                "There are many possible extensions to this work, the first being to further investigate the properties of different global protocols belonging to the class we identified, and their influence on the outcome.",
                "There are in particular many heuristics, highly dependent on the context of the study, that could intuitively yield interesting results (in our study, selecting the recipient on the basis of what can be inferred from his observed actions could be such a heuristic).",
                "One obvious candidate for longer term issues concern the relaxation of the assumption of perfect sensing. 7.",
                "REFERENCES [1] G. Bourgne, N. Maudet, and S. Pinson.",
                "When agents communicate hypotheses in critical situations.",
                "In Proceedings of DALT-2006, May 2006. [2] P. Harvey, C. F. Chang, and A. Ghose.",
                "Support-based distributed search: a new approach for multiagent constraint processing.",
                "In Proceedings of AAMAS06, 2006. [3] H. Jung and M. Tambe.",
                "Argumentation as distributed constraint satisfaction: Applications and results.",
                "In Proceedings of AGENTS01, 2001. [4] N. C. Karunatillake and N. R. Jennings.",
                "Is it worth arguing?",
                "In Proceedings of ArgMAS 2004, 2004. [5] S. Onta˜n´on and E. Plaza.",
                "Arguments and counterexamples in case-based joint deliberation.",
                "In Proceedings of ArgMAS-2006, May 2006. [6] D. Poole.",
                "Explanation and prediction: An architecture for default and abductive reasoning.",
                "Computational Intelligence, 5(2):97-110, 1989. [7] I. Rahwan, S. D. Ramchurn, N. R. Jennings, P. McBurney, S. Parsons, and L. Sonenberg.",
                "Argumention-based negotiation.",
                "The Knowledge Engineering Review, 4(18):345-375, 2003. [8] N. Roos, A. ten Tije, and C. Witteveen.",
                "A protocol for multi-agent diagnosis with spatially distributed knowledge.",
                "In Proceedings of AAMAS03, 2003. [9] N. Roos, A. ten Tije, and C. Witteveen.",
                "Reaching diagnostic agreement in multiagent diagnosis.",
                "In Proceedings of AAMAS04, 2004. [10] T. Takahashi, Y. Kaneda, and N. Ito.",
                "Preliminary study - using robocuprescue simulations for disasters prevention.",
                "In Proceedings of SRMED2004, 2004.",
                "The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 1005"
            ],
            "original_annotated_samples": [
                "We say that: • An agent is consistent (Cons(ai)) iff Cons(hi, Oi) (that is, its hypothesis is consistent with its <br>observation set</br>). • An agent ai consistent with a partner agent aj iff Cons(ai) and Cons(hi, Oj) (that is, this agent is consistent and its hypothesis can explain the <br>observation set</br> of the other agent). • Two agents ai and aj are mutually consistent (MCons(ai, aj)) iff Cons(ai, aj) and Cons(aj, ai). • A system is consistent iff ∀(i, j)∈[1, n]2 it is the case that MCons(ai, aj).",
                "We assume h = Eh(O) to be consistent with O by definition of Eh, so using this function on its <br>observation set</br> to determine its favourite hypothesis is a sure way for the agent to achieve consistency.",
                "Note however that an hypothesis does not need to be generated by Eh to be consistent with an <br>observation set</br>."
            ],
            "translated_annotated_samples": [
                "Decimos que: • Un agente es consistente (Cons(ai)) si y solo si Cons(hi, Oi) (es decir, su hipótesis es consistente con su <br>conjunto de observaciones</br>). • Un agente ai es consistente con un agente compañero aj si y solo si Cons(ai) y Cons(hi, Oj) (es decir, este agente es consistente y su hipótesis puede explicar el <br>conjunto de observaciones</br> del otro agente). • Dos agentes ai y aj son mutuamente consistentes (MCons(ai, aj)) si y solo si Cons(ai, aj) y Cons(aj, ai). • Un sistema es consistente si y solo si para todo (i, j) ∈ [1, n]2 se cumple que MCons(ai, aj).",
                "Suponemos que h = Eh(O) para ser consistente con O por definición de Eh, por lo que usar esta función en su <br>conjunto de observaciones</br> para determinar su hipótesis favorita es una forma segura para que el agente logre consistencia.",
                "Sin embargo, cabe destacar que una hipótesis no necesita ser generada por Eh para ser consistente con un <br>conjunto de observaciones</br>."
            ],
            "translated_text": "Refinamiento de hipótesis bajo restricciones de comunicación topológica ∗ Gauvain Bourgne, Gael Hette, Nicolas Maudet y Suzanne Pinson LAMSADE, Univ. Investigamos las propiedades de un sistema multiagente donde cada agente (distribuido) percibe localmente su entorno. Tras la percepción de un evento inesperado, cada agente calcula localmente su hipótesis favorita e intenta propagarla a otros agentes, intercambiando hipótesis y argumentos de apoyo (observaciones). Sin embargo, también asumimos que las oportunidades de comunicación están severamente limitadas y cambian dinámicamente. En este artículo, investigamos principalmente la convergencia de dichos sistemas hacia la consistencia global. Primero demostramos que (para una amplia clase de protocolos que definiremos), las restricciones de comunicación inducidas por la topología no impedirán la convergencia del sistema, bajo la condición de que la dinámica del sistema garantice que ningún agente quedará aislado para siempre, y que los agentes tengan tiempo ilimitado para la computación y el intercambio de argumentos. Dado que esta suposición no se puede hacer en la mayoría de las situaciones, establecimos un marco experimental con el objetivo de comparar la eficiencia y efectividad relativa de diferentes protocolos de interacción para el intercambio de hipótesis. Estudiamos una situación crítica que implica a varios agentes que intentan escapar de un edificio en llamas. Los resultados reportados aquí proporcionan algunas ideas sobre el diseño de un protocolo óptimo para el refinamiento de hipótesis en este contexto. Categorías y Descriptores de Asignaturas I.2.11 [Inteligencia Artificial]: Inteligencia Artificial Distribuida-Sistemas Multiagente Términos Generales Teoría, Experimentación 1. INTRODUCCIÓN Consideramos un sistema multiagente donde cada agente (distribuido) percibe localmente su entorno, y asumimos que ocurre un evento inesperado en ese sistema. Si cada agente calcula solo localmente su hipótesis preferida, es natural asumir que los agentes buscarán coordinar y refinar sus hipótesis confrontando sus observaciones con otros agentes. Si, además, las oportunidades de comunicación están severamente limitadas (por ejemplo, los agentes solo pueden comunicarse cuando están lo suficientemente cerca de otro agente) y cambian dinámicamente (por ejemplo, los agentes pueden cambiar sus ubicaciones), se vuelve crucial diseñar cuidadosamente protocolos que permitan a los agentes converger hacia algún estado deseado de consistencia global. En este documento presentamos algunas condiciones suficientes sobre la dinámica del sistema y sobre las estructuras de protocolo/estrategia que permiten garantizar esa propiedad, y estudiamos experimentalmente algunos contextos donde (algunas de) estas suposiciones se relajan. Si bien los problemas de diagnóstico son uno de los clásicos venerables en la tradición de la IA, sus contrapartes multiagentes han atraído atención mucho más recientemente. Roos y sus colegas [8, 9] en particular estudian una situación en la que un número de entidades distribuidas intentan llegar a un diagnóstico global satisfactorio de todo el sistema. Ellos muestran en particular que el número de mensajes necesarios para establecer este diagnóstico global está destinado a ser prohibitivo, a menos que la comunicación se mejore con algún protocolo adecuado. Sin embargo, no imponen restricciones a las opciones de comunicación de los agentes, ni asumen que el sistema es dinámico. Los beneficios de mejorar la comunicación con información de apoyo para hacer que la convergencia a un estado global deseado de un sistema sea más eficiente, a menudo se ha planteado en la literatura. Esta es, por ejemplo, una de las ideas principales que subyacen al enfoque de negociación basado en argumentos [7], donde el estado deseado es un compromiso entre agentes con preferencias conflictivas. Sin embargo, muchos de estos trabajos parten del supuesto de que este enfoque es beneficioso para comenzar y estudian los aspectos técnicos del problema (o en su lugar enfatizan otras ventajas de utilizar la argumentación). Excepciones notables son las obras de [3, 4, 2, 5], que estudiaron en contextos diferentes al nuestro la eficiencia de la argumentación. El resto del documento es el siguiente. La Sección 2 especifica los elementos básicos de nuestro modelo, y la Sección 3 continúa presentando los diferentes protocolos y estrategias utilizados por los agentes para intercambiar hipótesis y observaciones. Ponemos especial atención en enfatizar claramente las condiciones de la dinámica del sistema y los protocolos/estrategias que se explotarán en el resto del documento. La sección 4 detalla uno de los principales resultados del artículo, a saber, el hecho de que bajo las condiciones mencionadas, las restricciones que imponemos en la topología no impedirán la convergencia del sistema hacia la consistencia global, siempre y cuando ningún agente se pierda completamente para siempre en el sistema, y se permita un tiempo ilimitado para la computación y el intercambio de argumentos. Si bien las condiciones en los protocolos y estrategias son bastante suaves, también es claro que estos requisitos del sistema parecen mucho más problemáticos, incluso francamente poco realistas en situaciones críticas donde se abogan precisamente por enfoques distribuidos. Para obtener una imagen más clara de la situación inducida cuando el tiempo es un factor crítico, hemos establecido un marco experimental que presentamos y discutimos en la Sección 5. La situación crítica implica a varios agentes que intentan escapar de un edificio en llamas. Los resultados reportados aquí muestran que la efectividad del intercambio de argumentos depende crucialmente de la naturaleza del edificio, y proporcionan algunas ideas sobre el diseño de un protocolo óptimo para el refinamiento de hipótesis en este contexto. CONCEPTOS BÁSICOS Comenzamos definiendo los elementos básicos de nuestro sistema. Deje que O sea el conjunto (potencialmente infinito) de observaciones posibles. Suponemos que los sensores de nuestros agentes son perfectos, por lo tanto, las observaciones son seguras. Sea H el conjunto de hipótesis, incierto y revisable. Sea Cons(h, O) la relación de consistencia, una relación binaria entre una hipótesis h ∈ H y un conjunto de observaciones O ⊆ O. En la mayoría de los casos, Cons se referirá a la relación de consistencia clásica, sin embargo, podemos sobrecargar su significado y añadir algunas propiedades adicionales a esa relación (en cuyo caso lo mencionaremos). El entorno puede incluir cierta dinámica y cambiar con el transcurso del tiempo. Definimos a continuación secuencias de puntos temporales para tratar con ello: Definición 1 (Secuencia de puntos temporales). Una secuencia de puntos temporales t1, t2, . . . , tn de t es un conjunto ordenado de puntos temporales t1, t2, . . . , tn tal que t1 ≥ t y ∀i ∈ [1, n − 1], ti+1 ≥ ti. Tomamos un sistema poblado por n agentes a1, . . . , an. Cada agente se define como una tupla F, Oi, hi, donde: • F, el conjunto de hechos, conocimiento común a todos los agentes. • Oi ∈ 2O, el conjunto de observaciones realizadas por el agente hasta el momento. Suponemos una memoria perfecta, por lo tanto, este conjunto crece de forma monótona. • hi ∈ H, la hipótesis favorita del agente. Una noción clave que rige la formación de hipótesis es la de consistencia, definida a continuación: Definición 2 (Consistencia). Decimos que: • Un agente es consistente (Cons(ai)) si y solo si Cons(hi, Oi) (es decir, su hipótesis es consistente con su <br>conjunto de observaciones</br>). • Un agente ai es consistente con un agente compañero aj si y solo si Cons(ai) y Cons(hi, Oj) (es decir, este agente es consistente y su hipótesis puede explicar el <br>conjunto de observaciones</br> del otro agente). • Dos agentes ai y aj son mutuamente consistentes (MCons(ai, aj)) si y solo si Cons(ai, aj) y Cons(aj, ai). • Un sistema es consistente si y solo si para todo (i, j) ∈ [1, n]2 se cumple que MCons(ai, aj). Para garantizar su consistencia, cada agente está equipado con una maquinaria de razonamiento abstracto que llamaremos la función de explicación Eh. Esta función (determinística) toma un conjunto de observaciones y devuelve una única hipótesis preferida (2O → H). Suponemos que h = Eh(O) para ser consistente con O por definición de Eh, por lo que usar esta función en su <br>conjunto de observaciones</br> para determinar su hipótesis favorita es una forma segura para que el agente logre consistencia. Sin embargo, cabe destacar que una hipótesis no necesita ser generada por Eh para ser consistente con un <br>conjunto de observaciones</br>. Como ejemplo concreto de tal función, y una de las principales inspiraciones de este trabajo, se puede citar el sistema de razonamiento Theorist [6], siempre y cuando esté acoplado con un filtro que seleccione una teoría preferida entre las inicialmente seleccionadas por Theorist. También hay que tener en cuenta que hi solo puede ser modificado como consecuencia de la aplicación de Eh. Nos referimos a esto como la autonomía del agente: ningún otro agente puede imponer directamente una hipótesis dada a un agente. Como consecuencia, solo una nueva observación (ya sea una nueva percepción o una observación comunicada por otro agente) puede resultar en una modificación de su hipótesis preferida hi (pero no necesariamente, por supuesto). Finalmente definimos una propiedad del sistema que utilizaremos en el resto del artículo: Definición 3 (Percepciones Acotadas). Un sistema implica una percepción limitada para los agentes si y solo si existe un n0 tal que para todo t, la unión de N observaciones realizadas por los agentes es menor o igual a n0. (Es decir, el número de observaciones a realizar por los agentes en el sistema no es infinito.) Ahora necesitamos ver cómo evolucionarán e interactuarán estos agentes en su entorno. En nuestro contexto, los agentes evolucionan en un entorno dinámico, y asumimos clásicamente el siguiente ciclo del sistema: 1. Dinámica del entorno: el entorno evoluciona de acuerdo con las reglas definidas de la dinámica del sistema. 2. Paso de percepción: los agentes obtienen percepciones del entorno. Estas percepciones suelen ser parciales (por ejemplo, el agente solo puede ver una parte de un mapa). 3. Paso de razonamiento: los agentes comparan la percepción con las predicciones, buscan explicaciones para las diferencias (potenciales), refinan su hipótesis, y sacan nuevas conclusiones. 4. Paso de comunicación: los agentes pueden comunicar hipótesis y observaciones con otros agentes a través de un protocolo definido. Cualquier agente solo puede estar involucrado en una comunicación con otro agente en el paso 5. Paso de acción: los agentes realizan un razonamiento práctico utilizando los modelos obtenidos de los pasos anteriores y seleccionan una acción. Ellos pueden modificar el entorno ejecutándolo. La comunicación de los agentes estará aún más restringida por consideraciones topológicas. En un momento dado, un agente solo podrá comunicarse con un número de vecinos. Sus conexiones con estos otros agentes pueden The Sixth Intl. La Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) evoluciona con su situación en el entorno. Normalmente, un agente solo puede comunicarse con agentes que puede percibir, pero se podría imaginar la evolución de restricciones topológicas en la comunicación basadas en una red de comunicaciones entre agentes donde los enlaces no siempre están activos. En nuestro sistema, los agentes podrán comunicarse entre sí. Sin embargo, debido a las restricciones topológicas mencionadas anteriormente, no podrán comunicarse con ningún agente en ningún momento. Con quién puede comunicarse un agente se definirá dinámicamente (por ejemplo, esto puede ser consecuencia de que los agentes estén lo suficientemente cerca para ponerse en contacto). Denotaremos de forma abstracta por C(ai, aj, t) la propiedad de comunicación, es decir, el hecho de que los agentes ai y aj puedan comunicarse en el tiempo t (nota que se asume que esta relación es simétrica, pero por supuesto no transitiva). Ahora estamos en posición de definir dos propiedades esenciales de nuestro sistema. Definición 4 (Camino Temporal). Existe un camino de comunicación temporal en el horizonte tf (denotado Ltf (aI, aJ)) entre ai y aj si y solo si existe una secuencia de puntos temporales t1, t2, ..., tn desde tf y una secuencia de agentes k1, k2, ..., kn tal que (i) C(aI, ak1, t1), (ii) C(akn, aJ, tn+1), (iii) ∀i ∈ [1, n], C(aki, aki+1, ti). Intuitivamente, lo que esta propiedad dice es que es posible encontrar un camino temporal en el futuro que permitiría vincular al agente ai y aj a través de una secuencia de agentes intermedios. Ten en cuenta que los puntos temporales no necesariamente son sucesivos, y que la secuencia de agentes puede involucrar a los mismos agentes varias veces. Definición 5 (Conexidad Temporal). Un sistema es temporalmente conexo si y solo si ∀t ∀(i, j)∈[1, n]2 Lt(ai, aj). En resumen, un sistema temporalmente conexo garantiza que cualquier agente podrá comunicarse con cualquier otro agente, sin importar cuánto tiempo pueda llevar hacerlo, en cualquier momento. Dicho de otra manera, nunca sucede que un agente esté aislado para siempre de otro agente del sistema. A continuación discutiremos en detalle cómo la comunicación tiene lugar concretamente en nuestro sistema. Recuerda que en este documento, solo consideramos el caso de intercambios bilaterales (un agente solo puede hablar con otro agente) y también asumimos que cualquier agente solo puede participar en un intercambio en una ronda dada. 3. PROTOCOLOS Y ESTRATEGIAS En esta sección, discutimos los requisitos de los protocolos de interacción que rigen el intercambio de mensajes entre agentes, y proporcionamos algunos ejemplos de la implementación de dichos protocolos. Para aclarar la presentación, distinguimos dos niveles: el nivel local, que se ocupa de la regulación de los intercambios bilaterales; y el nivel global, que regula principalmente la forma en que los agentes pueden participar realmente en una conversación. En cada nivel, separamos lo que está especificado por el protocolo y lo que se deja a las estrategias de los agentes. Protocolos y estrategias locales Comenzamos inspeccionando los protocolos y estrategias locales que regularán la comunicación entre los agentes del sistema. Al limitarnos a la comunicación bilateral, estos protocolos simplemente implicarán a dos agentes. Dicho protocolo tendrá que cumplir con un requisito básico para ser satisfactorio: consistencia (CONS) - un protocolo local debe garantizar la consistencia mutua de los agentes al finalizar (lo que implica, por supuesto, la finalización). Figura 1: Un Protocolo de Intercambio de Hipótesis [1] Un ejemplo de dicho protocolo es el protocolo descrito en [1] que se muestra en la Fig. 1. Para ilustrar aún más cómo dicho protocolo puede ser utilizado por agentes, proporcionamos algunos detalles sobre una posible estrategia: al recibir una hipótesis h1 (proponer(h1) o contra-proponer(h1)) de a1, el agente a2 se encuentra en el estado 2 y tiene las siguientes respuestas posibles: contraejemplo (si el agente conoce un ejemplo que contradice la hipótesis, o no está explicado por esta hipótesis), desafío (si el agente carece de evidencia para aceptar esta hipótesis), contra-proponer (si el agente está de acuerdo con la hipótesis pero prefiere otra), o aceptar (si es tan buena como su hipótesis favorita). Esta estrategia garantiza, entre otras propiedades, la eventual consistencia lógica mutua de los agentes involucrados [1]. Protocolo global El protocolo global regula la forma en que se iniciarán los intercambios bilaterales entre agentes. En cada turno, los agentes enviarán simultáneamente una solicitud ponderada para comunicarse con otros agentes. Este peso es un valor que mide la disposición de los agentes para conversar con el agente objetivo (en la práctica, esto puede basarse en diferentes heurísticas, pero haremos algunas suposiciones sobre las estrategias de los agentes, ver más abajo). Enviar una solicitud de este tipo es una especie de compromiso condicional para el agente. Un agente que envía una solicitud ponderada se compromete a entablar una conversación con el objetivo si no recibe y acepta otra solicitud por sí mismo. Una vez que se hayan recibido todas las solicitudes, cada agente responde con un aceptar o un rechazar. Al responder con un aceptar, un agente se compromete plenamente a participar en la conversación con el remitente. Por lo tanto, solo puede enviar una aceptación en una ronda dada, ya que un agente solo puede participar en una conversación por paso de tiempo. Cuando se hayan recibido todas las respuestas, cada agente que reciba una aceptación puede iniciar una conversación utilizando el protocolo local o enviar una cancelación si ha aceptado otra solicitud. Al final de todos los intercambios bilaterales, los agentes involucrados en la conversación son descartados del protocolo. Entonces cada uno de los agentes restantes reenvía una solicitud y el proceso se repite hasta que no se envíen más solicitudes. Estrategia global Ahora definimos cuatro requisitos para las estrategias utilizadas por los agentes, dependiendo de su rol en el protocolo: dos se refieren al rol del solicitante (cómo decidir quién es el 1000 The Sixth Intl. La Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) ¿con qué agente desea comunicarse? Los otros dos con el rol de respondedor (¿cómo decidir qué solicitud de comunicación aceptar o no?). • Disposición para resolver inconsistencias (SOLVE): los agentes desean comunicarse con cualquier otro agente a menos que sepan que son mutuamente consistentes. • Enfoque en resolver inconsistencias (FOCUS): los agentes no solicitan comunicarse con un agente con el que saben que son mutuamente consistentes. • Disposición para comunicarse (COMM): los agentes no pueden rechazar una solicitud de comunicación ponderada, a menos que acaben de recibir o enviar una solicitud con un peso mayor. • Compromiso con la solicitud de comunicación (REQU): los agentes no pueden aceptar una solicitud de comunicación ponderada si ellos mismos han enviado una solicitud de comunicación con un peso mayor. Por lo tanto, no cancelarán su solicitud a menos que hayan recibido una solicitud comunicacional con mayor peso. Ahora la estructura del protocolo, junto con las propiedades COMM+REQU, garantizan que una solicitud solo puede ser rechazada si su agente objetivo se involucra en comunicación con otro agente. Supongamos de hecho que el agente ai quiere comunicarse con aj enviando una solicitud con peso w. COMM garantiza que un agente que reciba una solicitud ponderada aceptará esta comunicación, aceptará una comunicación con un peso mayor o esperará la respuesta a una solicitud con un peso mayor. Esto asegura que la solicitud con peso máximo será aceptada y no cancelada (ya que REQU asegura que un agente que envía una solicitud solo puede cancelarla si acepta otra solicitud con un peso mayor). Por lo tanto, al menos dos agentes participarán en una conversación por ronda del protocolo global. Como el protocolo asegura que ai puede reenviar su solicitud mientras aj no está ocupado en una conversación, llegará un momento en el que aj deberá participar en una conversación, ya sea con ai u otro agente. Estos requisitos se refieren al envío y aceptación de solicitudes, pero los agentes también necesitan alguna estrategia de atribución de peso. Describimos a continuación una estrategia altruista, utilizada en nuestros experimentos. Siendo cooperativo, un agente puede querer conocer más los deseos de comunicación de otros agentes para mejorar la asignación general de intercambios a los agentes. Se añade entonces un paso de solicitud de contexto al protocolo global. Antes de enviar su solicitud ponderada elegida, los agentes asignan un peso a todos los agentes con los que están dispuestos a comunicarse, de acuerdo con algunos factores internos. En el caso más simple, este peso será 1 para todos los agentes con los que el agente no esté seguro de ser mutuamente consistentes (garantizando SOLVE), sin considerar a otros agentes para la comunicación (garantizando FOCUS). El agente luego envía una solicitud de contexto a todos los agentes con los que se considera la comunicación. Esta solicitud también proporciona información sobre el remitente (lista de comunicaciones consideradas junto con su peso). Después de recibir todas las solicitudes de contexto, los agentes responderán con un rechazo si ya están ocupados en una conversación (en cuyo caso, el agente solicitante no considerará comunicarse con ellos en este turno), o con una información que brinde al solicitante información sobre las solicitudes que ha enviado y recibido. Cuando se hayan recibido todas las respuestas, cada agente puede calcular el peso de todas las solicitudes que le conciernen. Lo hace restando del peso de su solicitud el peso de todas las solicitudes relacionadas con él o su objetivo (es decir, el peso final de la solicitud de ai a aj es Wi,j = wi,j + wj,i - ( Σ k∈R(i)-{j} wi,k + Σ k∈S(i)-{j} wk,i + Σ k∈R(j)-{i} wj,k + Σ k∈S(j)-{i} wk,j) donde wi,j es el peso de la solicitud de ai a aj, R(i) es el conjunto de índices de agentes que han recibido una solicitud de ai y S(i) es el conjunto de índices de agentes que han enviado una solicitud a ai). Luego envía finalmente una solicitud ponderada a los agentes que maximizan este peso (o esperan una solicitud) según lo descrito en el protocolo global. 4. (CONDICIONAL) CONVERGENCIA HACIA LA COHERENCIA GLOBAL En esta sección mostraremos que los requisitos relacionados con los protocolos y estrategias recién discutidos serán suficientes para garantizar que el sistema eventualmente convergerá hacia la coherencia global, bajo ciertas condiciones. Primero demostramos que, si dos agentes no son mutuamente consistentes en algún momento, entonces necesariamente habrá un momento en el futuro en el que un agente aprenderá una nueva observación, ya sea porque es nueva para el sistema, o al aprenderla de otro agente. Lema 1. Sea S un sistema poblado por n agentes a1, a2, ..., an, temporalmente conectados e involucrando percepciones limitadas para estos agentes. Sea n1 la suma de las cardinalidades de la intersección de los conjuntos de observaciones emparejados. (n1 = P (i,j)∈[1,n]2 |Oi ∩ Oj|) Sea n2 la cardinalidad de la unión de todos los conjuntos de observaciones de los agentes. (n2 = | ∪N i=1 Oi|). Si ¬MCons(ai, aj) en el tiempo t0, necesariamente existe un tiempo t > t0 tal que ya sea n1 o n2 aumentarán. Prueba. Supongamos que exista un tiempo t0 y unos índices (i, j) tal que ¬MCons(ai, aj). Utilizaremos mt0 = P (k,l)∈[1,n]2 εComm(ak, al, t0) donde εComm(ak, al, t0) = 1 si ak y al han comunicado al menos una vez desde t0, y 0 en caso contrario. La conexidad temporal garantiza que existen t1, ..., tm+1 y k1, ..., km tal que. C(ai, ak1 , t1), C(akm , aj, tm+1), y ∀p ∈ [1, m], C(akp , akp+1 , tp). Claramente, si MCons(ai, ak1), MCons(akm, aj) y ∀p, MCons(akp, akp+1), tenemos MCons(ai, aj) lo cual contradice nuestra hipótesis (siendo MCons transitivo, MCons(ai, ak1)∧MCons(ak1, ak2) implica que MCons(ai, ak2) y así sucesivamente hasta MCons(ai, akm)∧MCons(akm, aj) lo cual implica MCons(ai, aj)). Al menos dos agentes son necesariamente inconsistentes (¬MCons(ai, ak1), o ¬MCons(akm, aj), o ∃p0 t.q. ¬MCons(akp0, akp0+1)). Que ak y al sean estos dos vecinos en un momento t > t0 1. La propiedad SOLVE asegura que ya sea ak o al enviará una solicitud de comunicación al otro agente en el tiempo t. Como se mostró anteriormente, esto a su vez garantiza que al menos uno de estos agentes estará involucrado en una comunicación. Entonces hay dos posibilidades: (caso i) ak y al se comunican en el tiempo t. En este caso, sabemos que ¬MCons(ak, al). Esto y la propiedad CONS aseguran que al menos uno de los agentes debe cambiar su 1. Estrictamente hablando, la transitividad de MCons solo asegura que ak y al son inconsistentes en un tiempo t ≥ t0 que puede ser diferente del tiempo t en el que pueden comunicarse. Pero si se vuelven consistentes entre t y t (o inconsistentes entre t y t), significa que al menos uno de ellos ha cambiado su hipótesis entre t y t, es decir, después de t0. Podemos entonces aplicar el razonamiento del caso iib. El Sexto Internacional. La Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 1001 hipótesis, lo cual a su vez, dado que los agentes son autónomos, implica al menos un intercambio de observación. Pero entonces |Ok ∩Ol| está destinado a aumentar: n1(t) > n1(t0). (caso ii) ak se comunica con ap en el tiempo t. Entonces tenemos de nuevo dos posibilidades: (caso iia) ak y ap no se comunicaron desde t0. Pero luego εComm(ak, ap, t0) tenía valor 0 y toma valor 1. Por lo tanto, mt0 aumenta. (caso iib) ak y ap se comunicaron en algún momento t0 > t0. La propiedad CONS del protocolo asegura que MCons(ak, ap) en ese momento. Ahora el hecho de que se comuniquen y se ENFOQUEN implica que al menos uno de ellos cambió su hipótesis en el ínterin. El hecho de que los agentes sean autónomos implica a su vez que una nueva observación (percibida o recibida de otro agente) necesariamente provocó este cambio. El último caso garantizaría la existencia de un tiempo t > t0 y un agente aq tal que |Op ∩ Oq| o |Ok ∩ Oq| aumenten en 1 en ese momento (lo que implica que n1(t) > n1(t0)). El caso anterior significa que el agente obtiene una nueva percepción en el tiempo t. Si esa observación era desconocida en el sistema antes, entonces n2(t) > n2(t0). Si algún agente aq ya conocía esta observación antes, entonces tanto Op ∩ Oq como Ok ∩ Oq aumentan en 1 en el tiempo t (lo que implica que n1(t) > n1(t0)). Por lo tanto, ¬MCons(ai, aj) en el tiempo t0 garantiza que, o bien: −∃t > t0 t.q. n1(t ) > n1(t0); o −∃t > t0 t.q. n2(t ) > n2(t0); o −∃t > t0 t.q. mt0 aumenta en 1 en el tiempo t. Al iterar el razonamiento con t (pero manteniendo t0 como la referencia de tiempo para mt0), podemos eliminar el tercer caso (mt0 es un entero y está limitado por n2, lo que significa que después de un máximo de n2 iteraciones, necesariamente estaremos en uno de los otros dos casos). Como resultado, hemos demostrado que si ¬MCons(ai, aj) en el tiempo t0, necesariamente habrá un tiempo t tal que ya sea n1 o n2 aumentarán. Teorema 1 (Consistencia global). Sea S un sistema poblado por n agentes a1, a2, ..., an, temporalmente conectados e involucrando percepciones limitadas para estos agentes. Sea Cons(ai, aj) una propiedad de consistencia transitiva. Entonces, cualquier protocolo y estrategias que cumplan con las propiedades CONS, SOLVE, FOCUS, COMM y REQU garantizan que el sistema convergerá hacia la consistencia global. Prueba. Por el bien de la contradicción, asumamos que ∃I, J ∈ [1, N] tal que ∀t, ∃t0 > t, tal que ¬Cons(aI , aJ , t0). Usando el lema, esto implica que ∃t > t0 tal que n1(t) > n1(t0) o n2(t) > n2(t0). Pero podemos aplicar el mismo razonamiento tomando t = t, lo que nos daría t1 > t > t0 tal que ¬Cons(aI , aJ , t1), lo que nos da t > t1 tal que n1(t) > n1(t1) o n2(t) > n2(t1). Mediante iteraciones sucesivas podemos construir una secuencia t0, t1, ..., tn, que puede dividirse en dos subsecuencias t0, t1, ...tn y t0, t1, ..., tn tal que n1(t0) < n1(t1) < ... < n1(tn) y n2(t0) < n2(t1) < ... < n2(tn). Una de estas subsecuencias tiene que ser infinita. Sin embargo, n1(ti) y n2(ti) son estrictamente crecientes, enteros y acotados, lo que implica que ambos son finitos. Contradicción. Lo que el resultado anterior muestra esencialmente es que, en un sistema donde ningún agente estará aislado del resto de los agentes para siempre, solo se necesitan suposiciones muy leves sobre los protocolos y estrategias utilizados por los agentes para garantizar la convergencia hacia la consistencia del sistema en una cantidad finita de tiempo (aunque podría llevar mucho tiempo). Desafortunadamente, en muchas situaciones críticas, no será posible asumir esta conexión temporal. Dado que enfoques distribuidos como el abogado en este documento suelen presentarse como una buena manera de abordar problemas de confiabilidad o problemas de dependencia de un centro que son de suma importancia en estas aplicaciones críticas, ciertamente resulta interesante explorar más a fondo cómo se comportaría un sistema de este tipo cuando relajamos esta suposición. ESTUDIO EXPERIMENTAL Este experimento implica agentes tratando de escapar de un edificio en llamas. El entorno se describe como una cuadrícula espacial con un conjunto de paredes y (afortunadamente) algunas salidas. El tiempo y el espacio se consideran discretos. El tiempo se divide en rondas. Los agentes se localizan por su posición en la cuadrícula espacial. Estos agentes pueden moverse y comunicarse con otros agentes. En una ronda, un agente puede moverse una celda en cualquiera de las cuatro direcciones cardinales, siempre y cuando no esté bloqueado por una pared. En esta aplicación, los agentes se comunican con cualquier otro agente (pero, recuerda, solo uno) siempre y cuando este agente esté a la vista y aún no hayan intercambiado su hipótesis actual favorita. De repente, se desata un incendio en estas instalaciones. A partir de este momento, el fuego se propaga. En cada ronda, en cada caso donde haya fuego, el fuego se propaga en las cuatro direcciones. Sin embargo, el fuego no puede propagarse a través de una pared. Si el fuego se propaga en un caso donde un agente está posicionado, ese agente se quema y se considera muerto. Por supuesto, ya no puede moverse ni comunicarse. Si un agente llega a una salida, se considera que está a salvo y ya no puede ser quemado. Los agentes conocen el entorno y las reglas que rigen la dinámica de este entorno, es decir, conocen el mapa así como las reglas de propagación del fuego previamente descritas. También perciben este entorno localmente, pero no pueden ver más allá de 3 casos en cualquier dirección. Las paredes también bloquean la línea de visión, impidiendo que los agentes vean detrás de ellas. Dentro de su campo de visión, pueden ver a otros agentes y si los casos que ven están en llamas. Todas estas percepciones están memorizadas. Mostramos ahora cómo se instancia el marco abstracto presentado en el documento. • O = {Fire(x, y, t), NoFire(x, y, t), Agent(ai, x, y, t)} Las observaciones pueden ser positivas (o ∈ P(O) si ∃h ∈ H tal que h |= o) o negativas (o ∈ N(O) si ∃h ∈ H tal que h |= ¬o). • H={FireOrigin(x1, y1, t1)∧...∧FireOrigin(xl, yl, tl)} Las hipótesis son conjunciones de Orígenes de Fuego. • La relación de consistencia Cons(h, O) satisface: - coherencia: ∀o ∈ N(O), h |= ¬o. - completitud: ∀o ∈ P(O), h |= o. - minimalidad: Para todo h ∈ H, si h es coherente y completo para O, entonces h es preferido a h de acuerdo con la relación de preferencia (h ≤p h). Selecciona primero el número mínimo de orígenes, luego el más reciente (estrategia menos preemptiva [6]), y luego utiliza un ranking fijo arbitrario para discriminar ex-aequo. La relación resultante es un orden total, por lo tanto, la minimalidad implica que habrá un único h tal que Cons(O, h) para un O dado. Esto a su vez significa que MCons(ai, aj) si y solo si Cons(ai), Cons(aj) y hi = hj. Esta relación es entonces transitiva y simétrica. 1002 El Sexto Internacional. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) • Eh toma O como argumento y devuelve min≤p de la hipótesis coherente y completa para O 5.1 Evaluación Experimental Clásicamente evaluaremos la efectividad y eficiencia de diferentes protocolos de interacción (ver, por ejemplo, [3, 4]). La efectividad de un protocolo se determinará por la proporción de agentes que sobreviven al incendio respecto al número inicial de agentes involucrados en el experimento. Si este valor es alto, el protocolo ha sido efectivo para propagar la información y/o para que los agentes refinen sus hipótesis y determinen la mejor manera de salir. Eficiencia de un protocolo. Por lo general, el uso de información de apoyo implicará una sobrecarga de comunicación. Aquí asumiremos que la eficiencia de un protocolo dado está caracterizada por el flujo de datos inducido por este protocolo. En este documento solo discutiremos este aspecto con respecto a los protocolos locales. La medida principal que utilizaremos aquí es el tamaño total promedio de los mensajes intercambiados por los agentes por intercambio (teniendo en cuenta tanto el número de mensajes como el tamaño real de los mensajes, ya que podría ser que los mensajes resulten ser muy grandes, conteniendo por ejemplo un gran número de observaciones, lo que podría contrarrestar un bajo número de mensajes). 5.2 Configuraciones Experimentales Las configuraciones experimentales elegidas son las siguientes: • Topología ambiental: El rendimiento de la propagación de la información está altamente condicionado por la topología del entorno. Las habilidades de percepción de los agentes dependen de la apertura del entorno. Con un gran número de paredes, las percepciones de los agentes están limitadas, al igual que el número de posibles comunicaciones entre agentes, mientras que un entorno abierto proporcionará posibilidades óptimas de percepción y propagación de información. Por lo tanto, proponemos un índice topológico (ver abajo) como base común para caracterizar los entornos (mapas) utilizados durante las experimentaciones. El índice topológico (TI) es la proporción entre el número de celdas que pueden ser percibidas por los agentes sumadas desde todas las posiciones posibles, dividido por el número de celdas que serían percibidas desde las mismas posiciones pero sin paredes. (Cuanto más cercano a 1, más abierto es el entorno). También utilizaremos dos medidas adicionales, más clásicas [10]: la longitud del camino característico (CPL) y el coeficiente de agrupamiento (CC). • Número de agentes: la propagación de la información también depende del número inicial de agentes involucrados durante una experimentación. Por ejemplo, cuantos más agentes haya, más potenciales comunicaciones existen. Esto significa que habrá más potencial de propagación, pero también que la restricción de intercambio bilateral será más crucial. 3 El CPL es la mediana de las medias de las longitudes de los caminos más cortos que conectan cada nodo con todos los demás nodos. 4 caracterizando el grado de aislamiento de una región de un entorno en términos de accesibilidad (número de caminos aún utilizables para llegar a esta región). Mapa T.I. (%) C.P.L. C.C. 69-1 69,23 4,5 0,69 69-2 68,88 4,38 0,65 69-3 69,80 4,25 0,67 53-1 53,19 5,6 0,59 53-2 53,53 6,38 0,54 53-3 53,92 6,08 0,61 38-1 38,56 8,19 0,50 38-2 38,56 7,3 0,50 38-3 38,23 8,13 0,50 Tabla 1: Características Topológicas de los Mapas • Posiciones iniciales de los agentes- Las posiciones iniciales de los agentes tienen una influencia significativa en el comportamiento general de una instancia de nuestro sistema: estar cerca de una salida facilitará (en general) la escapatoria. 5.3 Entornos experimentales Elegimos realizar experimentos en tres índices topológicos muy diferentes (69% para entornos abiertos, 53% para entornos mixtos y 38% para entornos tipo laberinto). Figura 2: Dos mapas (izquierda: IT=69%, derecha IT=38%) Diseñamos tres mapas diferentes para cada índice (la Fig. 2 muestra dos de ellos), conteniendo el mismo número máximo de agentes (máximo 36 agentes) con una densidad máxima de un agente por celda, el mismo número de salidas y un origen de incendio similar (por ejemplo, tiempo y posición de inicio). Los tres mapas diferentes de un índice dado están diseñados de la siguiente manera. El primer plano es un modelo de un piso de un edificio existente. El segundo mapa tiene el mismo perímetro, salidas y origen del fuego que el primero, pero la cantidad y ubicación de las paredes son diferentes (las ubicaciones de las paredes son diseñadas por una heurística que crea paredes de forma aleatoria en la cuadrícula espacial de manera que no se creen habitaciones completamente cerradas y que ninguna salida quede bloqueada). El tercer mapa se caracteriza por un recinto geométrico en el que la ubicación de las paredes también está diseñada con la heurística mencionada anteriormente. La Tabla 1 resume las diferentes medidas topológicas que caracterizan estos mapas diferentes. Vale la pena señalar que los valores confirman la relevancia de TI (los mapas con un alto TI tienen un bajo CPL y un alto CC). Sin embargo, el CPL y el CC permiten refinar aún más la diferencia entre los mapas, por ejemplo, entre 53-1 y 53-2). 5.4 Resultados Experimentales Para cada trío de mapas definidos como se mencionó anteriormente, llevamos a cabo los mismos experimentos. En cada experimento, la sociedad difiere en cuanto a su proporción inicial de agentes involucrados, desde el 1% hasta el 100%. Esta proporción inicial representa el porcentaje de agentes involucrados con respecto al número máximo posible de agentes. Para cada mapa y cada proporción inicial, la Sexta Internacional. En la Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) seleccionamos aleatoriamente 100 ubicaciones iniciales de agentes diferentes. Para cada una de esas ubicaciones diferentes ejecutamos el sistema una vez para cada protocolo de interacción diferente. La efectividad de la comunicación y argumentación El primer experimento que hemos establecido tiene como objetivo probar cuán efectivo es el intercambio de hipótesis (IH), y en particular cómo los aspectos topológicos afectarán esta efectividad. Para hacerlo, hemos calculado la proporción de mejora ofrecida por ese protocolo sobre una situación en la que los agentes simplemente no podían comunicarse (sin comunicación). Para obtener más información sobre en qué medida el intercambio de hipótesis fue realmente crucial, también probamos un protocolo mucho menos elaborado que consistía en intercambios de observaciones simples (OE). Más precisamente, este protocolo requiere que cada agente almacene cualquier observación inesperada que perciba, y los agentes simplemente intercambian sus respectivas listas de observaciones cuando discuten. En este caso, el protocolo local es diferente (nota en particular que no garantiza consistencia mutua), pero el protocolo global permanece igual (con la única excepción de que la motivación de los agentes para comunicarse es sincronizar su lista de observaciones, no sus hipótesis). Si este protocolo es como máximo tan efectivo como HE, tiene la ventaja de ser más eficiente (esto es obvio en cuanto al número de mensajes, que se limitará a 2, menos directo en lo que respecta al tamaño de los mensajes, pero la observación general de que el intercambio de observaciones se puede ver como una versión simplificada del desafío es útil para ver esto). Los resultados de estos experimentos se informan en la Figura 3. Figura 3: Ganancia de la proporción de efectividad comparativa de los protocolos cuando la proporción de agentes aumenta. La primera observación que debe hacerse es que la comunicación mejora la efectividad del proceso, y esta proporción aumenta a medida que el número de agentes crece en el sistema. La segunda lección que aprendemos aquí es que la cercanía relativamente hace que la comunicación sea más efectiva que la falta de comunicación. Los mapas que muestran un T.I. del 38% están constantemente por encima de los otros dos, y el 53% sigue siendo ligeramente pero significativamente mejor que el 69%. Sin embargo, estas curvas también sugieren, quizás sorprendentemente, que HE supera a OE precisamente en aquellas situaciones donde la ganancia de la relación es menos importante (la única diferencia notable ocurre en mapas bastante abiertos donde T.I. es del 69%). Esto se puede explicar de la siguiente manera: cuando un mapa está abierto, los agentes tienen muchos posibles candidatos de explicación, y la argumentación se vuelve útil para discriminar entre ellos. Cuando un mapa es laberíntico, hay menos posibles explicaciones para un evento inesperado. Importancia del Protocolo Global El segundo conjunto de experimentos busca evaluar la importancia del diseño del protocolo global. Probamos nuestro protocolo contra un protocolo de difusión local (LB). La difusión local significa que todos los agentes vecinos percibidos por un agente estarán involucrados en una comunicación con ese agente en una ronda dada, aliviando la restricción de una sola comunicación por agente. Esto nos proporciona un límite superior aproximado sobre la posible ganancia de ratio en el sistema (para un protocolo local dado). Nuevamente, evaluamos la ganancia de la relación inducida por ese LB sobre nuestro HE clásico, para las tres clases diferentes de mapas. Los resultados se informan en la Figura 4. Figura 4: Ganancia de la proporción de transmisión local sobre el intercambio de hipótesis. Tenga en cuenta que la ganancia de la proporción es 0 cuando la proporción de agentes es del 5%, lo cual se explica fácilmente por el hecho de que corresponde a situaciones que involucran solo a dos agentes. Primero observamos que todas las clases de mapas muestran un aumento en la ganancia de la proporción a medida que aumenta el número de agentes: la ganancia alcanza entre el 10 y el 20%, dependiendo de la clase de mapas considerada. Si se compara esto con la mejora reportada en el experimento anterior, parece ser de la misma magnitud. Esto ilustra que el diseño del protocolo global no puede ser ignorado, especialmente cuando la proporción de agentes es alta. Sin embargo, también observamos que las curvas de ganancia de la proporción de efectividad tienen formas muy diferentes en ambos casos: la ganancia inducida por la precisión del protocolo local aumenta muy rápidamente con la proporción de agentes, mientras que la curva es muy suave para el global. Ahora observemos con más cuidado los resultados reportados aquí: la curva correspondiente a una TI del 53% está por encima de la correspondiente al 38%. Esto se debe a que cuanto más abierta sea un mapa, más oportunidades hay de comunicarse con más de un agente (y por lo tanto beneficiarse de la difusión). Sin embargo, también observamos que la curva para el 69% está por debajo de la del 53%. Esto se explica de la siguiente manera: en el caso del 69%, la ganancia potencial en términos de agentes sobrevivientes es mucho menor, porque nuestros protocolos ya ofrecen resultados bastante eficientes de todos modos (alcanzando rápidamente el 90%, ver Fig. 3). Una regla general podría ser que cuando el número de agentes es pequeño, se debe prestar especial atención al local 1004 de la Sexta Internacional. En el caso de que el número de agentes sea pequeño, uno puede utilizar el protocolo de la Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07), mientras que cuando ese número es grande, se debe diseñar cuidadosamente uno global (a menos que el mapa sea tan abierto que el protocolo ya sea casi óptimamente eficiente). La eficiencia de los protocolos. El experimento final reportado aquí se centra en el análisis de la eficiencia de los protocolos. Aquí analizamos el tamaño medio de la totalidad de los mensajes que son intercambiados por agentes (tamaño medio de intercambios, en resumen) utilizando los siguientes protocolos: HE, OE y dos protocolos variantes. El primero es un protocolo de intercambio de hipótesis restringidas (RHE) intermediario. RHE es el siguiente: no implica ningún desafío ni contraoferta, lo que significa que los agentes no pueden cambiar su rol durante el protocolo (esto difiere de RE en ese aspecto). En resumen, RHE permite a un agente agotar las críticas de sus socios, y eventualmente este socio adoptará la hipótesis del agente. Ten en cuenta que esto significa que la autonomía del agente no se conserva aquí (ya que un agente esencialmente aceptará cualquier hipótesis que no pueda socavar), con la esperanza de que la ganancia en eficiencia sea lo suficientemente significativa como para compensar una pérdida en efectividad. El segundo protocolo de variante es un protocolo completo de intercambio de observaciones (COE). COE utiliza los mismos principios que OE, pero incluye además todos los ejemplos críticos negativos (nofire) en el intercambio (dando así todos los ejemplos utilizados como argumentos por el protocolo de intercambio de hipótesis), mejorando así la efectividad. Los resultados para el mapa 69-1 se muestran en la Figura 5. Figura 5: Tamaño medio de los intercambios. Primero podemos observar el hecho de que el orden de los protocolos, desde el menos eficiente hasta el más eficiente, es COE, HE, RHE y luego OE. ÉL siendo más eficiente que COE demuestra que el proceso de argumentación gana eficiencia al seleccionar cuándo es necesario proporcionar ejemplos negativos, los cuales tienen menos impacto que los positivos en nuestro entorno de prueba específico. Sin embargo, al comunicar hipótesis antes de proporcionar observaciones para respaldarla (HE) en lugar de dar directamente las observaciones más cruciales (OE), el proceso de argumentación duplica el tamaño de los intercambios de datos. Es el costo de garantizar la consistencia al final del intercambio (una propiedad que OE no admite). También es significativo el hecho de que el tamaño promedio de los intercambios es ligeramente mayor cuando el número de agentes es pequeño. Esto se explica por el hecho de que en estos casos solo unos pocos agentes tienen información relevante en su posesión, y que necesitarán comunicarse mucho para llegar a un punto de vista común de la situación. Cuando el número de agentes aumenta, este conocimiento se distribuye entre más agentes que necesitan discusiones más cortas para llegar a una consistencia mutua. Como consecuencia, la ganancia relativa en eficiencia de usar RHE parece ser mejor cuando el número de agentes es pequeño: cuando es alto, difícilmente discutirán de todos modos. Finalmente, vale la pena notar que la desviación estándar para estos experimentos es bastante alta, lo que significa que la conversación no converge hacia ningún patrón estereotípico. 6. CONCLUSIÓN Este documento ha investigado las propiedades de un sistema multiagente donde cada agente (distribuido) percibe localmente su entorno e intenta alcanzar consistencia con otros agentes a pesar de severas restricciones de comunicación. En particular, hemos expuesto condiciones que permiten la convergencia e investigado experimentalmente una situación típica donde esas condiciones no pueden cumplirse. Hay muchas posibles extensiones a este trabajo, la primera siendo investigar más a fondo las propiedades de diferentes protocolos globales pertenecientes a la clase que identificamos, y su influencia en el resultado. Existen en particular muchas heurísticas, altamente dependientes del contexto del estudio, que podrían intuitivamente arrojar resultados interesantes (en nuestro estudio, seleccionar al destinatario en función de lo que se pueda inferir de sus acciones observadas podría ser una de esas heurísticas). Un candidato obvio para problemas a largo plazo se refiere a la relajación de la suposición de un sensor perfecto. 7. REFERENCIAS [1] G. Bourgne, N. Maudet y S. Pinson. Cuando los agentes comunican hipótesis en situaciones críticas. En Actas de DALT-2006, mayo de 2006. [2] P. Harvey, C. F. Chang y A. Ghose. Búsqueda distribuida basada en soporte: un nuevo enfoque para el procesamiento de restricciones multiagente. En Actas de AAMAS06, 2006. [3] H. Jung y M. Tambe. Argumentación como satisfacción de restricciones distribuida: Aplicaciones y resultados. En Actas de AGENTS01, 2001. [4] N. C. Karunatillake y N. R. Jennings. ¿Vale la pena discutir? En Actas de ArgMAS 2004, 2004. [5] S. Onta˜n´on y E. Plaza. Argumentos y contraejemplos en la deliberación conjunta basada en casos. En Actas de ArgMAS-2006, mayo de 2006. [6] D. Poole. Explicación y predicción: Una arquitectura para el razonamiento por defecto y abductivo. Inteligencia Computacional, 5(2):97-110, 1989. [7] I. Rahwan, S. D. Ramchurn, N. R. Jennings, P. McBurney, S. Parsons y L. Sonenberg. Negociación basada en argumentos. La revisión de Ingeniería del Conocimiento, 4(18):345-375, 2003. [8] N. Roos, A. ten Tije y C. Witteveen. Un protocolo para el diagnóstico multiagente con conocimiento distribuido espacialmente. En Actas de AAMAS03, 2003. [9] N. Roos, A. ten Tije y C. Witteveen. Alcanzando acuerdo diagnóstico en el diagnóstico multiagente. En Actas de AAMAS04, 2004. [10] T. Takahashi, Y. Kaneda y N. Ito. Estudio preliminar: utilizando simulaciones de RoboCupRescue para la prevención de desastres. En Actas de SRMED2004, 2004. El Sexto Internacional. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 1005 ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "sequence of time point": {
            "translated_key": "puntos temporales",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Hypotheses Refinement under Topological Communication Constraints ∗ Gauvain Bourgne, Gael Hette, Nicolas Maudet, and Suzanne Pinson LAMSADE, Univ.",
                "Paris-Dauphine, France {bourgne,hette,maudet,pinson}@lamsade.dauphine.fr ABSTRACT We investigate the properties of a multiagent system where each (distributed) agent locally perceives its environment.",
                "Upon perception of an unexpected event, each agent locally computes its favoured hypothesis and tries to propagate it to other agents, by exchanging hypotheses and supporting arguments (observations).",
                "However, we further assume that communication opportunities are severely constrained and change dynamically.",
                "In this paper, we mostly investigate the convergence of such systems towards global consistency.",
                "We first show that (for a wide class of protocols that we shall define), the communication constraints induced by the topology will not prevent the convergence of the system, at the condition that the system dynamics guarantees that no agent will ever be isolated forever, and that agents have unlimited time for computation and arguments exchange.",
                "As this assumption cannot be made in most situations though, we then set up an experimental framework aiming at comparing the relative efficiency and effectiveness of different interaction protocols for hypotheses exchange.",
                "We study a critical situation involving a number of agents aiming at escaping from a burning building.",
                "The results reported here provide some insights regarding the design of optimal protocol for hypotheses refinement in this context.",
                "Categories and Subject Descriptors I.2.11 [Artificial Intelligence]: Distributed Artificial Intelligence-Multiagent systems General Terms Theory, Experimentation 1.",
                "INTRODUCTION We consider a multiagent system where each (distributed) agent locally perceives its environment, and we assume that some unexpected event occurs in that system.",
                "If each agent computes only locally its favoured hypothesis, it is only natural to assume that agents will seek to coordinate and refine their hypotheses by confronting their observations with other agents.",
                "If, in addition, the communication opportunities are severely constrained (for instance, agents can only communicate when they are close enough to some other agent), and dynamically changing (for instance, agents may change their locations), it becomes crucial to carefully design protocols that will allow agents to converge to some desired state of global consistency.",
                "In this paper we exhibit some sufficient conditions on the system dynamics and on the protocol/strategy structures that allow to guarantee that property, and we experimentally study some contexts where (some of) these assumptions are relaxed.",
                "While problems of diagnosis are among the venerable classics in the AI tradition, their multiagent counterparts have much more recently attracted some attention.",
                "Roos and colleagues [8, 9] in particular study a situation where a number of distributed entities try to come up with a satisfying global diagnosis of the whole system.",
                "They show in particular that the number of messages required to establish this global diagnosis is bound to be prohibitive, unless the communication is enhanced with some suitable protocol.",
                "However, they do not put any restrictions on agents communication options, and do not assume either that the system is dynamic.",
                "The benefits of enhancing communication with supporting information to make convergence to a desired global state of a system more efficient has often been put forward in the literature.",
                "This is for instance one of the main idea underlying the argumentation-based negotiation approach [7], where the desired state is a compromise between agents with conflicting preferences.",
                "Many of these works however make the assumption that this approach is beneficial to start with, and study the technical facets of the problem (or instead emphasize other advantages of using argumentation).",
                "Notable exceptions are the works of [3, 4, 2, 5], which studied in contexts different from ours the efficiency of argumentation.",
                "The rest of the paper is as follows.",
                "Section 2 specifies the basic elements of our model, and Section 3 goes on to presenting the different protocols and strategies used by the agents to exchange hypotheses and observations.",
                "We put special attention at clearly emphasizing the conditions on the system dynamics and protocols/strategies that will be exploited in the rest of the paper.",
                "Section 4 details one of 998 978-81-904262-7-5 (RPS) c 2007 IFAAMAS the main results of the paper, namely the fact that under the aforementioned conditions, the constraints that we put on the topology will not prevent the convergence of the system towards global consistency, at the condition that no agent ever gets completely lost forever in the system, and that unlimited time is allowed for computation and argument exchange.",
                "While the conditions on protocols and strategies are fairly mild, it is also clear that these system requirements look much more problematic, even frankly unrealistic in critical situations where distributed approaches are precisely advocated.",
                "To get a clearer picture of the situation induced when time is a critical factor, we have set up an experimental framework that we introduce and discuss in Section 5.",
                "The critical situation involves a number of agents aiming at escaping from a burning building.",
                "The results reported here show that the effectiveness of argument exchange crucially depends upon the nature of the building, and provide some insights regarding the design of optimal protocol for hypotheses refinement in this context. 2.",
                "BASIC NOTIONS We start by defining the basic elements of our system.",
                "Environment Let O be the (potentially infinite) set of possible observations.",
                "We assume the sensors of our agents to be perfect, hence the observations to be certain.",
                "Let H be the set of hypotheses, uncertain and revisable.",
                "Let Cons(h, O) be the consistency relation, a binary relation between a hypothesis h ∈ H and a set of observations O ⊆ O.",
                "In most cases, Cons will refer to classical consistency relation, however, we may overload its meaning and add some additional properties to that relation (in which case we will mention it).",
                "The environment may include some dynamics, and change over the course of time.",
                "We define below sequences of time points to deal with it: Definition 1 (Sequence of time points).",
                "A <br>sequence of time point</br>s t1, t2, . . . , tn from t is an ordered set of time points t1, t2, . . . , tn such that t1 ≥ t and ∀i ∈ [1, n − 1], ti+1 ≥ ti.",
                "Agent We take a system populated by n agents a1, . . . , an.",
                "Each agent is defined as a tuple F, Oi, hi , where: • F, the set of facts, common knowledge to all agents. • Oi ∈ 2O , the set of observations made by the agent so far.",
                "We assume a perfect memory, hence this set grows monotonically. • hi ∈ H, the favourite hypothesis of the agent.",
                "A key notion governing the formation of hypotheses is that of consistency, defined below: Definition 2 (Consistency).",
                "We say that: • An agent is consistent (Cons(ai)) iff Cons(hi, Oi) (that is, its hypothesis is consistent with its observation set). • An agent ai consistent with a partner agent aj iff Cons(ai) and Cons(hi, Oj) (that is, this agent is consistent and its hypothesis can explain the observation set of the other agent). • Two agents ai and aj are mutually consistent (MCons(ai, aj)) iff Cons(ai, aj) and Cons(aj, ai). • A system is consistent iff ∀(i, j)∈[1, n]2 it is the case that MCons(ai, aj).",
                "To ensure its consistency, each agent is equipped with an abstract reasoning machinery that we shall call the explanation function Eh.",
                "This (deterministic) function takes a set of observation and returns a single prefered hypothesis (2O → H).",
                "We assume h = Eh(O) to be consistent with O by definition of Eh, so using this function on its observation set to determine its favourite hypothesis is a sure way for the agent to achieve consistency.",
                "Note however that an hypothesis does not need to be generated by Eh to be consistent with an observation set.",
                "As a concrete example of such a function, and one of the main inspiration of this work, one can cite the Theorist reasoning system [6] -as long as it is coupled with a filter selecting a single prefered theory among the ones initially selected by Theorist.",
                "Note also that hi may only be modified as a consequence of the application Eh.",
                "We refer to this as the autonomy of the agent: no other agent can directly impose a given hypothesis to an agent.",
                "As a consequence, only a new observation (being it a new perception, or an observation communicated by a fellow agent) can result in a modification of its prefered hypothesis hi (but not necessarily of course).",
                "We finally define a property of the system that we shall use in the rest of the paper: Definition 3 (Bounded Perceptions).",
                "A system involves a bounded perception for agents iff ∃n0 s.t. ∀t| ∪N i=1 Oi| ≤ n0. (That is, the number of observations to be made by the agents in the system is not infinite.)",
                "Agent Cycle Now we need to see how these agents will evolve and interact in their environment.",
                "In our context, agents evolve in a dynamic environment, and we classicaly assume the following system cycle: 1.",
                "Environment dynamics: the environment evolves according to the defined rules of the system dynamics. 2.",
                "Perception step : agents get perceptions from the environment.",
                "These perceptions are typically partial (e.g. the agent can only see a portion of a map). 3.",
                "Reasoning step: agents compare perception with predictions, seek explanations for (potential) difference(s), refine their hypothesis, draw new conclusions. 4.",
                "Communication step: agents can communicate hypotheses and observations with other agents through a defined protocol.",
                "Any agent can only be involved in one communication with another agent by step. 5.",
                "Action step: agents do some practical reasoning using the models obtained from the previous steps and select an action.",
                "They can then modify the environment by executing it.",
                "The communication of the agents will be further constrained by topological consideration.",
                "At a given time, an agent will only be able to communicate with a number of neighbours.",
                "Its connexions with these others agents may The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 999 evolve with its situation in the environment.",
                "Typically, an agent can only communicate with agents that it can sense, but one could imagine evolving topological constraints on communication based on a network of communications between agents where the links are not always active.",
                "Communication In our system, agents will be able to communicate with each other.",
                "However, due to the aforementionned topological constraints, they will not be able to communicate with any agents at anytime.",
                "Who an agent can communicate with will be defined dynamically (for instance, this can be a consequence of the agents being close enough to get in touch).",
                "We will abstractly denote by C(ai, aj, t) the communication property, in other words, the fact that agents ai and aj can communicate at time t (note that this relation is assumed to be symetric, but of course not transitive).",
                "We are now in a position to define two essential properties of our system.",
                "Definition 4 (Temporal Path).",
                "There exists a temporal communication path at horizon tf (noted Ltf (aI , aJ )) between ai and aj iff there exists a <br>sequence of time point</br>s t1, t2, . . . , tn from tf and a sequence of agents k1, k2, . . . , kn s.t. (i) C(aI , ak1 , t1), (ii) C(akn , aJ , tn+1), (iii) ∀i ∈ [1, n], C(aki , aki+1 , ti) Intuitively, what this property says is that it is possible to find a temporal path in the future that would allow to link agent ai and aj via a sequence of intermediary agents.",
                "Note that the time points are not necessarily successive, and that the sequence of agents may involve the same agents several times.",
                "Definition 5 (Temporal Connexity).",
                "A system is temporaly connex iff ∀t ∀(i, j)∈[1, n]2 Lt(ai, aj) In short, a temporaly connex system guarantees that any agent will be able to communicate with any other agents, no matter how long it might take to do so, at any time.",
                "To put it another way, it is never the case that an agent will be isolated for ever from another agent of the system.",
                "We will next discuss the detail of how communication concretely takes place in our system.",
                "Remember that in this paper, we only consider the case of bilateral exchanges (an agent can only speak to a single other agent), and that we also assume that any agent can only engage in a single exchange in a given round. 3.",
                "PROTOCOLS AND STRATEGIES In this section, we discuss the requirements of the interaction protocols that govern the exchange of messages between agents, and provide some example instantiation of such protocols.",
                "To clarify the presentation, we distinguish two levels: the local level, which is concerned with the regulation of bilateral exchanges; and the global level,which essentially regulates the way agents can actually engage into a conversation.",
                "At each level, we separate what is specified by the protocol, and what is left to agents strategies.",
                "Local Protocol and Strategies We start by inspecting local protocols and strategies that will regulate the communication between the agents of the system.",
                "As we limit ourselves to bilateral communication, these protocols will simply involve two agents.",
                "Such protocol will have to meet one basic requirement to be satisfying. • consistency (CONS)- a local protocol has to guarantee the mutual consistency of agents upon termination (which implies termination of course).",
                "Figure 1: A Hypotheses Exchange Protocol [1] One example such protocol is the protocol described in [1] that is pictured in Fig. 1.",
                "To further illustrate how such protocol can be used by agents, we give some details on a possible strategy: upon receiving a hypothesis h1 (propose(h1) or counterpropose(h1)) from a1, agent a2 is in state 2 and has the following possible replies: counterexample (if the agent knows an example contradicting the hypothesis, or not explained by this hypothesis), challenge (if the agents lacks evidence to accept this hypothesis), counterpropose (if the agent agrees with the hypothesis but prefers another one), or accept (if it is indeed as good as its favourite hypothesis).",
                "This strategy guarantees, among other properties, the eventual mutual logical consistency of the involved agents [1].",
                "Global Protocol The global protocol regulates the way bilateral exchanges will be initiated between agents.",
                "At each turn, agents will concurrently send one weighted request to communicate to other agents.",
                "This weight is a value measuring the agents willingness to converse with the targeted agent (in practice, this can be based on different heuristics, but we shall make some assumptions on agents strategies, see below).",
                "Sending such a request is a kind of conditional commitment for the agent.",
                "An agent sending a weighted request commits to engage in conversation with the target if he does not receive and accept himself another request.",
                "Once all request have been received, each agent replies with either an acccept or a reject.",
                "By answering with an accept, an agent makes a full commitment to engage in conversation with the sender.",
                "Therefore, it can only send one accept in a given round, as an agent can only participate in one conversation per time step.",
                "When all response have been received, each agent receiving an accept can either initiate a conversation using the local protocol or send a cancel if it has accepted another request.",
                "At the end of all the bilateral exchanges, the agents engaged in conversation are discarded from the protocol.",
                "Then each of the remaining agents resends a request and the process iterates until no more requests are sent.",
                "Global Strategy We now define four requirements for the strategies used by agents, depending on their role in the protocol: two are concerned with the requestee role (how to decide who the 1000 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) agent wishes to communicate with? ), the other two with the responder role (how to decide which communication request to accept or not?). • Willingness to solve inconsistancies (SOLVE)-agents want to communicate with any other agents unless they know they are mutually consistent. • Focus on solving inconsistencies (FOCUS)-agents do not request communication with an agent with whom they know they are mutually consistent. • Willingness to communicate (COMM)-agents cannot refuse a weighted communication request, unless they have just received or send a request with a greater weight. • Commitment to communication request (REQU)agents cannot accept a weighted communication request if they have themselves sent a communication request with a greater weight.",
                "Therefore, they will not cancel their request unless they have received a communicational request with greater weight.",
                "Now the protocol structure, together with the properties COMM+REQU, ensure that a request can only be rejected if its target agent engages in communication with another agent.",
                "Suppose indeed that agent ai wants to communicate with aj by sending a request with weight w. COMM guarantees that an agent receiving a weighted request will either accept this communication, accept a communication with a greater weight or wait for the answer to a request with a greater weight.",
                "This ensures that the request with maximal weight will be accepted and not cancelled (as REQU ensures that an agent sending a request can only cancel it if he accepts another request with greater weight).",
                "Therefore at least two agents will engage in conversation per round of the global protocol.",
                "As the protocol ensures that ai can resend its request while aj is not engaged in a conversation, there will be a turn in which aj must engage in a conversation, either with ai or another agent.",
                "These requirements concern request sending and acceptation, but agents also need some strategy of weight attribution.",
                "We describe below an altruist strategy, used in our experiments.",
                "Being cooperative, an agent may want to know more of the communication wishes of other agents in order to improve the overall allocation of exchanges to agents.",
                "A context request step is then added to the global protocol.",
                "Before sending their chosen weighted request, agents attribute a weight to all agents they are prepared to communicate with, according to some internal factors.",
                "In the simplest case, this weight will be 1 for all agent with whom the agent is not sure of being mutually consistent (ensuring SOLVE), other agent being not considered for communication (ensuring FOCUS).",
                "The agent then sends a context request to all agents with whom communication is considered.",
                "This request also provides information about the sender (list of considered communications along with their weight).",
                "After reception of all the context requests, agents will either reply with a deny, iff they are already engaged in a conversation (in which case, the requesting agent will not consider communication with them anymore in this turn), or an inform giving the requester information about the requests it has sent and received.",
                "When all replies have been received, each agent can calculate the weight of all requests concerning it.",
                "It does so by substracting from the weight of its request the weight of all requests concerning either it or its target (that is, the final weight of the request from ai to aj is Wi,j = wi,j +wj,i − ( P k∈R(i)−{j} wi,k + P k∈S(i)−{j} wk,i + P k∈R(j)−{i} wj,k + P k∈S(j)−{i} wk,j) where wi,j is the weight of the request of ai to aj, R(i) is the set of indice of agents having received a request from ai and S(i) is the set of indice of agents having send a request to ai).",
                "It then finally sends a weighted request to the agents who maximise this weight (or wait for a request) as described in the global protocol. 4. (CONDITIONAL) CONVERGENCE TO GLOBAL CONSISTENCY In this section we will show that the requirements regarding protocols and strategies just discussed will be sufficient to ensure that the system will eventually converge towards global consistency, under some conditions.",
                "We first show that, if two agents are not mutually consistent at some time, then there will be necessarily a time in the future such that an agent will learn a new observation, being it because it is new for the system, or by learning it from another agent.",
                "Lemma 1.",
                "Let S be a system populated by n agents a1, a2, ..., an, temporaly connex, and involving bounded perceptions for these agents.",
                "Let n1 be the sum of cardinalities of the intersection of pairwise observation sets. (n1 = P (i,j)∈[1,n]2 |Oi ∩ Oj|) Let n2 be the cardinality of the union of all agents observations sets. (n2 = | ∪N i=1 Oi|).",
                "If ¬MCons(ai, aj) at time t0, there is necessarily a time t > t0 s.t. either n1 or n2 will increase.",
                "Proof.",
                "Suppose that there exist a time t0 and indices (i, j) s.t. ¬MCons(ai, aj).",
                "We will use mt0 = P (k,l)∈[1,n]2 εComm(ak, al, t0) where εComm(ak, al, t0) = 1 if ak and al have communicated at least once since t0, and 0 otherwise.",
                "Temporal connexity guarantees that there exist t1, ..., tm+1 and k1, ..., km s.t.",
                "C(ai, ak1 , t1), C(akm , aj, tm+1), and ∀p ∈ [1, m], C(akp , akp+1 , tp).",
                "Clearly, if MCons(ai, ak1 ), MCons(akm , aj) and ∀p, MCons(akp , akp+1 ), we have MCons(ai, aj) which contradicts our hypothesis (MCons being transitive, MCons(ai, ak1 )∧MCons(ak1 , ak2 ) implies that MCons(ai, ak2 ) and so on till MCons(ai, akm )∧ MCons(akm , aj) which implies MCons(ai, aj) ).",
                "At least two agents are then necessarily inconsistent (¬MCons(ai, ak1 ), or ¬MCons(akm , aj), or ∃p0 t.q. ¬MCons(akp0 , akp0+1 )).",
                "Let ak and al be these two neighbours at a time t > t0 1 .",
                "The SOLVE property ensures that either ak or al will send a communication request to the other agent at time t .",
                "As shown before, this in turn ensures that at least one of these agents will be involved in a communication.",
                "Then there are two possibilities: (case i) ak and al communicate at time t .",
                "In this case, we know that ¬MCons(ak, al).",
                "This and the CONS property ensures that at least one of the agents must change its 1 Strictly speaking, the transitivity of MCons only ensure that ak and al are inconsistent at a time t ≥ t0 that can be different from the time t at which they can communicate.",
                "But if they become consistent between t and t (or inconsistent between t and t ), it means that at least one of them have changed its hypothesis between t and t , that is, after t0.",
                "We can then apply the reasoning of case iib.",
                "The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 1001 hypothesis, which in turn, since agents are autonomous, implies at least one exchange of observation.",
                "But then |Ok ∩Ol| is bound to increase: n1(t ) > n1(t0). (case ii) ak communicates with ap at time t .",
                "We then have again two possibilities: (case iia) ak and ap did not communicate since t0.",
                "But then εComm(ak, ap, t0) had value 0 and takes value 1.",
                "Hence mt0 increases. (case iib) ak and ap did communicate at some time t0 > t0.",
                "The CONS property of the protocol ensures that MCons(ak, ap) at that time.",
                "Now the fact that they communicate and FOCUS implies that at least one of them did change its hypothesis in the meantime.",
                "The fact that agents are autonomous implies in turn that a new observation (perceived or received from another agent) necessarily provoked this change.",
                "The latter case would ensure the existence of a time t > t0 and an agent aq s.t. either |Op ∩Oq| or |Ok ∩Oq| increases of 1 at that time (implying n1(t ) > n1(t0)).",
                "The former case means that the agent gets a new perception o at time t .",
                "If that observation was unknown in the system before, then n2(t ) > n2(t0).",
                "If some agent aq already knew this observation before, then either Op ∩ Oq or Ok ∩ Oq increases of 1 at time t (which implies that n1(t ) > n1(t0)).",
                "Hence, ¬MCons(ai, aj) at time t0 guarantees that, either: −∃t > t0 t.q. n1(t ) > n1(t0); or −∃t > t0 t.q. n2(t ) > n2(t0); or −∃t > t0 t.q. mt0 increases of 1 at time t .",
                "By iterating the reasoning with t (but keeping t0 as the time reference for mt0 ), we can eliminate the third case (mt0 is integer and bounded by n2 , which means that after a maximum of n2 iterations, we necessarily will be in one of two other cases.)",
                "As a result, we have proven that if ¬MCons(ai, aj) at time t0, there is necessarily a time t s.t. either n1 or n2 will increase.",
                "Theorem 1 (Global consistency).",
                "Let S be a system populated by n agents a1, a2, ..., an, temporaly connex, and involving bounded perceptions for these agents.",
                "Let Cons(ai, aj) be a transitive consistency property.",
                "Then any protocol and strategies satisfying properties CONS, SOLVE, FOCUS, COMM and REQU guarantees that the system will converge towards global consistency.",
                "Proof.",
                "For the sake of contradiction, let us assume ∃I, J ∈ [1, N] s.t. ∀t, ∃t0 > t, t.q. ¬Cons(aI , aJ , t0).",
                "Using the lemma, this implies that ∃t > t0 s.t. either n1(t ) > n1(t0) or n2(t ) > n2(t0).",
                "But we can apply the same reasoning taking t = t , which would give us t1 > t > t0 s.t. ¬Cons(aI , aJ , t1), which gives us t > t1 s.t. either n1(t ) > n1(t1) or n2(t ) > n2(t1).",
                "By successive iterations we can then construct a sequence t0, t1, ..., tn, which can be divided in two sub-sequences t0, t1, ...tn and t0 , t1 , ..., tn s.t. n1(t0) < n1(t1) < ... < n1(tn) and n2(t0 ) < n2(t1 ) < ... < n2(tn).",
                "One of these sub-sequences has to be infinite.",
                "However, n1(ti) and n2(ti ) are strictly growing, integer, and bounded, which implies that both are finite.",
                "Contradiction.",
                "What the previous result essentially shows is that, in a system where no agent will be isolated from the rest of the agents for ever, only very mild assumptions on the protocols and strategies used by agents suffice to guarantee convergence towards system consistency in a finite amount of time (although it might take very long).",
                "Unfortunately, in many critical situations, it will not be possible to assume this temporal connexity.",
                "As distributed approaches as the one advocated in this paper are precisely often presented as a good way to tackle problems of reliability or problems of dependence to a center that are of utmost importance in these critical applications, it is certainly interesting to further explore how such a system would behave when we relax this assumption. 5.",
                "EXPERIMENTAL STUDY This experiment involves agents trying to escape from a burning building.",
                "The environment is described as a spatial grid with a set of walls and (thankfully) some exits.",
                "Time and space are considered discrete.",
                "Time is divided in rounds.",
                "Agents are localised by their position on the spatial grid.",
                "These agents can move and communicate with other agents.",
                "In a round, an agent can move of one cell in any of the four cardinal directions, provided it is not blocked by a wall.",
                "In this application, agents communicate with any other agent (but, recall, a single one) given that this agent is in view, and that they have not yet exchanged their current favoured hypothesis.",
                "Suddenly, a fire erupts in these premises.",
                "From this moment, the fire propagates.",
                "Each round, for each cases where there is fire, the fire propagates in the four directions.",
                "However, the fire cannot propagate through a wall.",
                "If the fire propagates in a case where an agent is positioned, that agent burns and is considered dead.",
                "It can of course no longer move nor communicate.",
                "If an agent gets to an exit, it is considered saved, and can no longer be burned.",
                "Agents know the environment and the rules governing the dynamics of this environment, that is, they know the map as well as the rules of fire propagation previously described.",
                "They also locally perceive this environment, but cannot see further than 3 cases away, in any direction.",
                "Walls also block the line of view, preventing agents from seeing behind them.",
                "Within their sight, they can see other agents and whether or not the cases they see are on fire.",
                "All these perceptions are memorised.",
                "We now show how this instantiates the abstract framework presented the paper. • O = {Fire(x, y, t), NoFire(x, y, t), Agent(ai, x, y, t)} Observations can then be positive (o ∈ P(O) iff ∃h ∈ H s.t. h |= o) or negative (o ∈ N(O) iff ∃h ∈ H s.t. h |= ¬o). • H={FireOrigin(x1, y1, t1)∧...∧FireOrigin(xl, yl, tl)} Hypotheses are conjunctions of FireOrigins. • Cons(h, O) consistency relation satisfies: - coherence : ∀o ∈ N(O), h |= ¬o. - completeness : ∀o ∈ P(O), h |= o. - minimality : For all h ∈ H, if h is coherent and complete for O, then h is prefered to h according to the preference relation (h ≤p h ).2 2 Selects first the minimal number of origins, then the most recent (least preemptive strategy [6]), then uses some arbitrary fixed ranking to discriminate ex-aequo.",
                "The resulting relation is a total order, hence minimality implies that there will be a single h s.t.Cons(O, h) for a given O.",
                "This in turn means that MCons(ai, aj) iff Cons(ai), Cons(aj), and hi = hj.",
                "This relation is then transitive and symmetric. 1002 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) • Eh takes O as argument and returns min≤p of the coherent and complete hypothesis for O 5.1 Experimental Evaluation We will classically (see e.g. [3, 4]) assess the effectiveness and efficiency of different interaction protocols.",
                "Effectiveness of a protocol The proportion of agents surviving the fire over the initial number of agents involved in the experiment will determine the effectiveness of a given protocol.",
                "If this value is high, the protocol has been effective to propagate the information and/or for the agents to refine their hypotheses and determine the best way to the exit.",
                "Efficiency of a protocol Typically, the use of supporting information will involve a communication overhead.",
                "We will assume here that the efficiency of a given protocol is characterised by the data flow induced by this protocol.",
                "In this paper we will only discuss this aspect wrt. local protocols.",
                "The main measure that we shall then use here is the mean total size of messages that are exchanged by agents per exchange (hence taking into account both the number of messages and the actual size of the messages, because it could be that messages happen to be very big, containing e.g. a large number of observations, which could counter-balance a low number of messages). 5.2 Experimental Settings The chosen experimental settings are the following: • Environmental topology- Performances of information propagation are highly constrained by the environment topology.",
                "The perception skills of the agents depend on the openness of the environment.",
                "With a large number of walls the perceptions of agents are limited, and also the number of possible inter-agent communications, whereas an open environment will provide optimal possibilities of perception and information propagation.",
                "Thus, we propose a topological index (see below) as a common basis to charaterize the environments (maps) used during experimentations.",
                "The topological index (TI) is the ratio of the number of cells that can be perceived by agents summed up from all possible positions, divided by the number of cells that would be perceived from the same positions but without any walls. (The closer to 1, the more open the environment).",
                "We shall also use two additional, more classical [10], measures: the characteristic path length3 (CPL) and the clustering coefficient4 (CC). • Number of agents- The propagation of information also depends on the initial number of agents involved during an experimentation.",
                "For instance, the more agents, the more potential communications there is.",
                "This means that there will be more potential for propagation, but also that the bilateral exchange restriction will be more crucial. 3 The CPL is the median of the means of the shortest path lengths connecting each node to all other nodes. 4 characterising the isolation degree of a region of an environment in terms of acessibility (number of roads still usable to reach this region).",
                "Map T.I. (%) C.P.L.",
                "C.C. 69-1 69,23 4,5 0,69 69-2 68,88 4,38 0,65 69-3 69,80 4,25 0,67 53-1 53,19 5,6 0,59 53-2 53,53 6,38 0,54 53-3 53,92 6,08 0,61 38-1 38,56 8,19 0,50 38-2 38,56 7,3 0,50 38-3 38,23 8,13 0,50 Table 1: Topological Characteristics of the Maps • Initial positions of the agents- Initial positions of the agents have a significant influence on the overall behavior of an instance of our system: being close from an exit will (in general) ease the escape. 5.3 Experimental environments We choose to realize experiments on three very different topological indexes (69% for open environments, 53% for mixed environments, and 38% for labyrinth-like environments).",
                "Figure 2: Two maps (left: TI=69%, right TI=38%) We designed three different maps for each index (Fig. 2 shows two of them), containing the same maximum number of agents (36 agents max.) with a maximum density of one agent per cell, the same number of exits and a similar fire origin (e.g. starting time and position).",
                "The three differents maps of a given index are designed as follows.",
                "The first map is a model of an existing building floor.",
                "The second map has the same enclosure, exits and fire origin as the first one, but the number and location of walls are different (wall locations are designed by an heuristic which randomly creates walls on the spatial grid such that no fully closed rooms are created and that no exit is closed).",
                "The third map is characterised by geometrical enclosure in wich walls location is also designed with the aforementioned heuristic.",
                "Table 1 summarizes the different topological measures characterizing these different maps.",
                "It is worth pointing out that the values confirm the relevance of TI (maps with a high TI have a low CPL and a high CC.",
                "However the CPL and CC allows to further refine the difference between the maps, e.g. between 53-1 and 53-2). 5.4 Experimental Results For each triple of maps defined as above we conduct the same experiments.",
                "In each experiment, the society differs in terms of its initial proportion of involved agents, from 1% to 100%.",
                "This initial proportion represents the percentage of involved agents with regards to the possible maximum number of agents.",
                "For each map and each initial proportion, The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 1003 we select randomly 100 different initial agents locations.",
                "For each of those different locations we execute the system one time for each different interaction protocol.",
                "Effectiveness of Communication and Argumentation The first experiment that we set up aims at testing how effective is hypotheses exchange (HE), and in particular how the topological aspects will affect this effectiveness.",
                "In order to do so, we have computed the ratio of improvement offered by that protocol over a situation where agents could simply not communicate (no comm).",
                "To get further insights as to what extent the hypotheses exchange was really crucial, we also tested a much less elaborated protocol consisting of mere observation exchanges (OE).",
                "More precisely, this protocol requires that each agent stores any unexpected observation that it perceives, and agents simply exchange their respective lists of observations when they discuss.",
                "In this case, the local protocol is different (note in particular that it does not guarantee mutual consistency), but the global protocol remains the same (at the only exception that agents motivation to communicate is to synchronise their list of observations, not their hypothesis).",
                "If this protocol is at best as effective as HE, it has the advantage of being more efficient (this is obvious wrt the number of messages which will be limited to 2, less straightforward as far as the size of messages is concerned, but the rough observation that the exchange of observations can be viewed as a flat version of the challenge is helpful to see this).",
                "The results of these experiments are reported in Fig. 3.",
                "Figure 3: Comparative effectiveness ratio gain of protocols when the proportion of agents augments The first observation that needs to be made is that communication improves the effectiveness of the process, and this ratio increases as the number of agents grows in the system.",
                "The second lesson that we learn here is that closeness relatively makes communication more effective over non communication.",
                "Maps exhibiting a T.I. of 38% are constantly above the two others, and 53% are still slightly but significantly better than 69%.",
                "However, these curves also suggest, perhaps surprisingly, that HE outperforms OE in precisely those situations where the ratio gain is less important (the only noticeable difference occurs for rather open maps where T.I. is 69%).",
                "This may be explained as follows: when a map is open, agents have many potential explanation candidates, and argumentation becomes useful to discriminate between those.",
                "When a map is labyrinth-like, there are fewer possible explanations to an unexpected event.",
                "Importance of the Global Protocol The second set of experiments seeks to evaluate the importance of the design of the global protocol.",
                "We tested our protocol against a local broadcast (LB) protocol.",
                "Local broadcast means that all the neighbours agents perceived by an agent will be involved in a communication with that agent in a given round -we alleviate the constraint of a single communication by agent.",
                "This gives us a rough upper bound upon the possible ratio gain in the system (for a given local protocol).",
                "Again, we evaluated the ratio gain induced by that LB over our classical HE, for the three different classes of maps.",
                "The results are reported in Fig. 4.",
                "Figure 4: Ratio gain of local broadcast over hypotheses exchange Note to begin with that the ratio gain is 0 when the proportion of agents is 5%, which is easily explained by the fact that it corresponds to situations involving only two agents.",
                "We first observe that all classes of maps witness a ratio gain increasing when the proportion of agents augments: the gain reaches 10 to 20%, depending on the class of maps considered.",
                "If one compares this with the improvement reported in the previous experiment, it appears to be of the same magnitude.",
                "This illustrates that the design of the global protocol cannot be ignored, especially when the proportion of agents is high.",
                "However, we also note that the effectiveness ratio gain curves have very different shapes in both cases: the gain induced by the accuracy of the local protocol increases very quickly with the proportion of agents, while the curve is really smooth for the global one.",
                "Now let us observe more carefully the results reported here: the curve corresponding to a TI of 53% is above that corresponding to 38%.",
                "This is so because the more open a map, the more opportunities to communicate with more than one agent (and hence benefits from broadcast).",
                "However, we also observe that curve for 69% is below that for 53%.",
                "This is explained as follows: in the case of 69%, the potential gain to be made in terms of surviving agents is much lower, because our protocols already give rather efficient outcomes anyway (quickly reaching 90%, see Fig. 3).",
                "A simple rule of thumb could be that when the number of agents is small, special attention should be put on the local 1004 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) protocol, whereas when that number is large, one should carefully design the global one (unless the map is so open that the protocol is already almost optimally efficient).",
                "Efficiency of the Protocols The final experiment reported here is concerned with the analysis of the efficiency of the protocols.",
                "We analysis here the mean size of the totality of the messages that are exchanged by agents (mean size of exchanges, for short) using the following protocols: HE, OE, and two variant protocols.",
                "The first one is an intermediary restricted hypotheses exchange protocol (RHE).",
                "RHE is as follows: it does not involve any challenge nor counter-propose, which means that agents cannot switch their role during the protocol (this differs from RE in that respect).",
                "In short, RHE allows an agent to exhaust its partners criticism, and eventually this partner will come to adopt the agents hypothesis.",
                "Note that this means that the autonomy of the agent is not preserved here (as an agent will essentially accept any hypothesis it cannot undermine), with the hope that the gain in efficiency will be significant enough to compensate a loss in effectiveness.",
                "The second variant protocol is a complete observation exchange protocol (COE).",
                "COE uses the same principles as OE, but includes in addition all critical negative examples (nofire) in the exchange (thus giving all examples used as arguments by the hypotheses exchanges protocol), hence improving effectiveness.",
                "Results for map 69-1 are shown on Fig. 5.",
                "Figure 5: Mean size of exchanges First we can observe the fact that the ordering of the protocols, from the least efficient to the most efficient, is COE, HE, RHE and then OE.",
                "HE being more efficient than COE proves that the argumentation process gains efficiency by selecting when it is needed to provide negative example, which have less impact that positive ones in our specific testbed.",
                "However, by communicating hypotheses before eventually giving observation to support it (HE) instead of directly giving the most crucial observations (OE), the argumentation process doubles the size of data exchanges.",
                "It is the cost for ensuring consistency at the end of the exchange (a property that OE does not support).",
                "Also significant is the fact the the mean size of exchanges is slightly higher when the number of agents is small.",
                "This is explained by the fact that in these cases only a very few agents have relevant informations in their possession, and that they will need to communicate a lot in order to come up with a common view of the situation.",
                "When the number of agents increases, this knowledge is distributed over more agents which need shorter discussions to get to mutual consistency.",
                "As a consequence, the relative gain in efficiency of using RHE appears to be better when the number of agents is small: when it is high, they will hardly argue anyway.",
                "Finally, it is worth noticing that the standard deviation for these experiments is rather high, which means that the conversation do not converge to any stereotypic pattern. 6.",
                "CONCLUSION This paper has investigated the properties of a multiagent system where each (distributed) agent locally perceives its environment, and tries to reach consistency with other agents despite severe communication restrictions.",
                "In particular we have exhibited conditions allowing convergence, and experimentally investigated a typical situation where those conditions cannot hold.",
                "There are many possible extensions to this work, the first being to further investigate the properties of different global protocols belonging to the class we identified, and their influence on the outcome.",
                "There are in particular many heuristics, highly dependent on the context of the study, that could intuitively yield interesting results (in our study, selecting the recipient on the basis of what can be inferred from his observed actions could be such a heuristic).",
                "One obvious candidate for longer term issues concern the relaxation of the assumption of perfect sensing. 7.",
                "REFERENCES [1] G. Bourgne, N. Maudet, and S. Pinson.",
                "When agents communicate hypotheses in critical situations.",
                "In Proceedings of DALT-2006, May 2006. [2] P. Harvey, C. F. Chang, and A. Ghose.",
                "Support-based distributed search: a new approach for multiagent constraint processing.",
                "In Proceedings of AAMAS06, 2006. [3] H. Jung and M. Tambe.",
                "Argumentation as distributed constraint satisfaction: Applications and results.",
                "In Proceedings of AGENTS01, 2001. [4] N. C. Karunatillake and N. R. Jennings.",
                "Is it worth arguing?",
                "In Proceedings of ArgMAS 2004, 2004. [5] S. Onta˜n´on and E. Plaza.",
                "Arguments and counterexamples in case-based joint deliberation.",
                "In Proceedings of ArgMAS-2006, May 2006. [6] D. Poole.",
                "Explanation and prediction: An architecture for default and abductive reasoning.",
                "Computational Intelligence, 5(2):97-110, 1989. [7] I. Rahwan, S. D. Ramchurn, N. R. Jennings, P. McBurney, S. Parsons, and L. Sonenberg.",
                "Argumention-based negotiation.",
                "The Knowledge Engineering Review, 4(18):345-375, 2003. [8] N. Roos, A. ten Tije, and C. Witteveen.",
                "A protocol for multi-agent diagnosis with spatially distributed knowledge.",
                "In Proceedings of AAMAS03, 2003. [9] N. Roos, A. ten Tije, and C. Witteveen.",
                "Reaching diagnostic agreement in multiagent diagnosis.",
                "In Proceedings of AAMAS04, 2004. [10] T. Takahashi, Y. Kaneda, and N. Ito.",
                "Preliminary study - using robocuprescue simulations for disasters prevention.",
                "In Proceedings of SRMED2004, 2004.",
                "The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 1005"
            ],
            "original_annotated_samples": [
                "A <br>sequence of time point</br>s t1, t2, . . . , tn from t is an ordered set of time points t1, t2, . . . , tn such that t1 ≥ t and ∀i ∈ [1, n − 1], ti+1 ≥ ti.",
                "There exists a temporal communication path at horizon tf (noted Ltf (aI , aJ )) between ai and aj iff there exists a <br>sequence of time point</br>s t1, t2, . . . , tn from tf and a sequence of agents k1, k2, . . . , kn s.t. (i) C(aI , ak1 , t1), (ii) C(akn , aJ , tn+1), (iii) ∀i ∈ [1, n], C(aki , aki+1 , ti) Intuitively, what this property says is that it is possible to find a temporal path in the future that would allow to link agent ai and aj via a sequence of intermediary agents."
            ],
            "translated_annotated_samples": [
                "Una secuencia de <br>puntos temporales</br> t1, t2, . . . , tn de t es un conjunto ordenado de <br>puntos temporales</br> t1, t2, . . . , tn tal que t1 ≥ t y ∀i ∈ [1, n − 1], ti+1 ≥ ti.",
                "Existe un camino de comunicación temporal en el horizonte tf (denotado Ltf (aI, aJ)) entre ai y aj si y solo si existe una <br>secuencia de puntos temporales</br> t1, t2, ..., tn desde tf y una secuencia de agentes k1, k2, ..., kn tal que (i) C(aI, ak1, t1), (ii) C(akn, aJ, tn+1), (iii) ∀i ∈ [1, n], C(aki, aki+1, ti). Intuitivamente, lo que esta propiedad dice es que es posible encontrar un camino temporal en el futuro que permitiría vincular al agente ai y aj a través de una secuencia de agentes intermedios."
            ],
            "translated_text": "Refinamiento de hipótesis bajo restricciones de comunicación topológica ∗ Gauvain Bourgne, Gael Hette, Nicolas Maudet y Suzanne Pinson LAMSADE, Univ. Investigamos las propiedades de un sistema multiagente donde cada agente (distribuido) percibe localmente su entorno. Tras la percepción de un evento inesperado, cada agente calcula localmente su hipótesis favorita e intenta propagarla a otros agentes, intercambiando hipótesis y argumentos de apoyo (observaciones). Sin embargo, también asumimos que las oportunidades de comunicación están severamente limitadas y cambian dinámicamente. En este artículo, investigamos principalmente la convergencia de dichos sistemas hacia la consistencia global. Primero demostramos que (para una amplia clase de protocolos que definiremos), las restricciones de comunicación inducidas por la topología no impedirán la convergencia del sistema, bajo la condición de que la dinámica del sistema garantice que ningún agente quedará aislado para siempre, y que los agentes tengan tiempo ilimitado para la computación y el intercambio de argumentos. Dado que esta suposición no se puede hacer en la mayoría de las situaciones, establecimos un marco experimental con el objetivo de comparar la eficiencia y efectividad relativa de diferentes protocolos de interacción para el intercambio de hipótesis. Estudiamos una situación crítica que implica a varios agentes que intentan escapar de un edificio en llamas. Los resultados reportados aquí proporcionan algunas ideas sobre el diseño de un protocolo óptimo para el refinamiento de hipótesis en este contexto. Categorías y Descriptores de Asignaturas I.2.11 [Inteligencia Artificial]: Inteligencia Artificial Distribuida-Sistemas Multiagente Términos Generales Teoría, Experimentación 1. INTRODUCCIÓN Consideramos un sistema multiagente donde cada agente (distribuido) percibe localmente su entorno, y asumimos que ocurre un evento inesperado en ese sistema. Si cada agente calcula solo localmente su hipótesis preferida, es natural asumir que los agentes buscarán coordinar y refinar sus hipótesis confrontando sus observaciones con otros agentes. Si, además, las oportunidades de comunicación están severamente limitadas (por ejemplo, los agentes solo pueden comunicarse cuando están lo suficientemente cerca de otro agente) y cambian dinámicamente (por ejemplo, los agentes pueden cambiar sus ubicaciones), se vuelve crucial diseñar cuidadosamente protocolos que permitan a los agentes converger hacia algún estado deseado de consistencia global. En este documento presentamos algunas condiciones suficientes sobre la dinámica del sistema y sobre las estructuras de protocolo/estrategia que permiten garantizar esa propiedad, y estudiamos experimentalmente algunos contextos donde (algunas de) estas suposiciones se relajan. Si bien los problemas de diagnóstico son uno de los clásicos venerables en la tradición de la IA, sus contrapartes multiagentes han atraído atención mucho más recientemente. Roos y sus colegas [8, 9] en particular estudian una situación en la que un número de entidades distribuidas intentan llegar a un diagnóstico global satisfactorio de todo el sistema. Ellos muestran en particular que el número de mensajes necesarios para establecer este diagnóstico global está destinado a ser prohibitivo, a menos que la comunicación se mejore con algún protocolo adecuado. Sin embargo, no imponen restricciones a las opciones de comunicación de los agentes, ni asumen que el sistema es dinámico. Los beneficios de mejorar la comunicación con información de apoyo para hacer que la convergencia a un estado global deseado de un sistema sea más eficiente, a menudo se ha planteado en la literatura. Esta es, por ejemplo, una de las ideas principales que subyacen al enfoque de negociación basado en argumentos [7], donde el estado deseado es un compromiso entre agentes con preferencias conflictivas. Sin embargo, muchos de estos trabajos parten del supuesto de que este enfoque es beneficioso para comenzar y estudian los aspectos técnicos del problema (o en su lugar enfatizan otras ventajas de utilizar la argumentación). Excepciones notables son las obras de [3, 4, 2, 5], que estudiaron en contextos diferentes al nuestro la eficiencia de la argumentación. El resto del documento es el siguiente. La Sección 2 especifica los elementos básicos de nuestro modelo, y la Sección 3 continúa presentando los diferentes protocolos y estrategias utilizados por los agentes para intercambiar hipótesis y observaciones. Ponemos especial atención en enfatizar claramente las condiciones de la dinámica del sistema y los protocolos/estrategias que se explotarán en el resto del documento. La sección 4 detalla uno de los principales resultados del artículo, a saber, el hecho de que bajo las condiciones mencionadas, las restricciones que imponemos en la topología no impedirán la convergencia del sistema hacia la consistencia global, siempre y cuando ningún agente se pierda completamente para siempre en el sistema, y se permita un tiempo ilimitado para la computación y el intercambio de argumentos. Si bien las condiciones en los protocolos y estrategias son bastante suaves, también es claro que estos requisitos del sistema parecen mucho más problemáticos, incluso francamente poco realistas en situaciones críticas donde se abogan precisamente por enfoques distribuidos. Para obtener una imagen más clara de la situación inducida cuando el tiempo es un factor crítico, hemos establecido un marco experimental que presentamos y discutimos en la Sección 5. La situación crítica implica a varios agentes que intentan escapar de un edificio en llamas. Los resultados reportados aquí muestran que la efectividad del intercambio de argumentos depende crucialmente de la naturaleza del edificio, y proporcionan algunas ideas sobre el diseño de un protocolo óptimo para el refinamiento de hipótesis en este contexto. CONCEPTOS BÁSICOS Comenzamos definiendo los elementos básicos de nuestro sistema. Deje que O sea el conjunto (potencialmente infinito) de observaciones posibles. Suponemos que los sensores de nuestros agentes son perfectos, por lo tanto, las observaciones son seguras. Sea H el conjunto de hipótesis, incierto y revisable. Sea Cons(h, O) la relación de consistencia, una relación binaria entre una hipótesis h ∈ H y un conjunto de observaciones O ⊆ O. En la mayoría de los casos, Cons se referirá a la relación de consistencia clásica, sin embargo, podemos sobrecargar su significado y añadir algunas propiedades adicionales a esa relación (en cuyo caso lo mencionaremos). El entorno puede incluir cierta dinámica y cambiar con el transcurso del tiempo. Definimos a continuación secuencias de puntos temporales para tratar con ello: Definición 1 (Secuencia de puntos temporales). Una secuencia de <br>puntos temporales</br> t1, t2, . . . , tn de t es un conjunto ordenado de <br>puntos temporales</br> t1, t2, . . . , tn tal que t1 ≥ t y ∀i ∈ [1, n − 1], ti+1 ≥ ti. Tomamos un sistema poblado por n agentes a1, . . . , an. Cada agente se define como una tupla F, Oi, hi, donde: • F, el conjunto de hechos, conocimiento común a todos los agentes. • Oi ∈ 2O, el conjunto de observaciones realizadas por el agente hasta el momento. Suponemos una memoria perfecta, por lo tanto, este conjunto crece de forma monótona. • hi ∈ H, la hipótesis favorita del agente. Una noción clave que rige la formación de hipótesis es la de consistencia, definida a continuación: Definición 2 (Consistencia). Decimos que: • Un agente es consistente (Cons(ai)) si y solo si Cons(hi, Oi) (es decir, su hipótesis es consistente con su conjunto de observaciones). • Un agente ai es consistente con un agente compañero aj si y solo si Cons(ai) y Cons(hi, Oj) (es decir, este agente es consistente y su hipótesis puede explicar el conjunto de observaciones del otro agente). • Dos agentes ai y aj son mutuamente consistentes (MCons(ai, aj)) si y solo si Cons(ai, aj) y Cons(aj, ai). • Un sistema es consistente si y solo si para todo (i, j) ∈ [1, n]2 se cumple que MCons(ai, aj). Para garantizar su consistencia, cada agente está equipado con una maquinaria de razonamiento abstracto que llamaremos la función de explicación Eh. Esta función (determinística) toma un conjunto de observaciones y devuelve una única hipótesis preferida (2O → H). Suponemos que h = Eh(O) para ser consistente con O por definición de Eh, por lo que usar esta función en su conjunto de observaciones para determinar su hipótesis favorita es una forma segura para que el agente logre consistencia. Sin embargo, cabe destacar que una hipótesis no necesita ser generada por Eh para ser consistente con un conjunto de observaciones. Como ejemplo concreto de tal función, y una de las principales inspiraciones de este trabajo, se puede citar el sistema de razonamiento Theorist [6], siempre y cuando esté acoplado con un filtro que seleccione una teoría preferida entre las inicialmente seleccionadas por Theorist. También hay que tener en cuenta que hi solo puede ser modificado como consecuencia de la aplicación de Eh. Nos referimos a esto como la autonomía del agente: ningún otro agente puede imponer directamente una hipótesis dada a un agente. Como consecuencia, solo una nueva observación (ya sea una nueva percepción o una observación comunicada por otro agente) puede resultar en una modificación de su hipótesis preferida hi (pero no necesariamente, por supuesto). Finalmente definimos una propiedad del sistema que utilizaremos en el resto del artículo: Definición 3 (Percepciones Acotadas). Un sistema implica una percepción limitada para los agentes si y solo si existe un n0 tal que para todo t, la unión de N observaciones realizadas por los agentes es menor o igual a n0. (Es decir, el número de observaciones a realizar por los agentes en el sistema no es infinito.) Ahora necesitamos ver cómo evolucionarán e interactuarán estos agentes en su entorno. En nuestro contexto, los agentes evolucionan en un entorno dinámico, y asumimos clásicamente el siguiente ciclo del sistema: 1. Dinámica del entorno: el entorno evoluciona de acuerdo con las reglas definidas de la dinámica del sistema. 2. Paso de percepción: los agentes obtienen percepciones del entorno. Estas percepciones suelen ser parciales (por ejemplo, el agente solo puede ver una parte de un mapa). 3. Paso de razonamiento: los agentes comparan la percepción con las predicciones, buscan explicaciones para las diferencias (potenciales), refinan su hipótesis, y sacan nuevas conclusiones. 4. Paso de comunicación: los agentes pueden comunicar hipótesis y observaciones con otros agentes a través de un protocolo definido. Cualquier agente solo puede estar involucrado en una comunicación con otro agente en el paso 5. Paso de acción: los agentes realizan un razonamiento práctico utilizando los modelos obtenidos de los pasos anteriores y seleccionan una acción. Ellos pueden modificar el entorno ejecutándolo. La comunicación de los agentes estará aún más restringida por consideraciones topológicas. En un momento dado, un agente solo podrá comunicarse con un número de vecinos. Sus conexiones con estos otros agentes pueden The Sixth Intl. La Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) evoluciona con su situación en el entorno. Normalmente, un agente solo puede comunicarse con agentes que puede percibir, pero se podría imaginar la evolución de restricciones topológicas en la comunicación basadas en una red de comunicaciones entre agentes donde los enlaces no siempre están activos. En nuestro sistema, los agentes podrán comunicarse entre sí. Sin embargo, debido a las restricciones topológicas mencionadas anteriormente, no podrán comunicarse con ningún agente en ningún momento. Con quién puede comunicarse un agente se definirá dinámicamente (por ejemplo, esto puede ser consecuencia de que los agentes estén lo suficientemente cerca para ponerse en contacto). Denotaremos de forma abstracta por C(ai, aj, t) la propiedad de comunicación, es decir, el hecho de que los agentes ai y aj puedan comunicarse en el tiempo t (nota que se asume que esta relación es simétrica, pero por supuesto no transitiva). Ahora estamos en posición de definir dos propiedades esenciales de nuestro sistema. Definición 4 (Camino Temporal). Existe un camino de comunicación temporal en el horizonte tf (denotado Ltf (aI, aJ)) entre ai y aj si y solo si existe una <br>secuencia de puntos temporales</br> t1, t2, ..., tn desde tf y una secuencia de agentes k1, k2, ..., kn tal que (i) C(aI, ak1, t1), (ii) C(akn, aJ, tn+1), (iii) ∀i ∈ [1, n], C(aki, aki+1, ti). Intuitivamente, lo que esta propiedad dice es que es posible encontrar un camino temporal en el futuro que permitiría vincular al agente ai y aj a través de una secuencia de agentes intermedios. Ten en cuenta que los puntos temporales no necesariamente son sucesivos, y que la secuencia de agentes puede involucrar a los mismos agentes varias veces. Definición 5 (Conexidad Temporal). Un sistema es temporalmente conexo si y solo si ∀t ∀(i, j)∈[1, n]2 Lt(ai, aj). En resumen, un sistema temporalmente conexo garantiza que cualquier agente podrá comunicarse con cualquier otro agente, sin importar cuánto tiempo pueda llevar hacerlo, en cualquier momento. Dicho de otra manera, nunca sucede que un agente esté aislado para siempre de otro agente del sistema. A continuación discutiremos en detalle cómo la comunicación tiene lugar concretamente en nuestro sistema. Recuerda que en este documento, solo consideramos el caso de intercambios bilaterales (un agente solo puede hablar con otro agente) y también asumimos que cualquier agente solo puede participar en un intercambio en una ronda dada. 3. PROTOCOLOS Y ESTRATEGIAS En esta sección, discutimos los requisitos de los protocolos de interacción que rigen el intercambio de mensajes entre agentes, y proporcionamos algunos ejemplos de la implementación de dichos protocolos. Para aclarar la presentación, distinguimos dos niveles: el nivel local, que se ocupa de la regulación de los intercambios bilaterales; y el nivel global, que regula principalmente la forma en que los agentes pueden participar realmente en una conversación. En cada nivel, separamos lo que está especificado por el protocolo y lo que se deja a las estrategias de los agentes. Protocolos y estrategias locales Comenzamos inspeccionando los protocolos y estrategias locales que regularán la comunicación entre los agentes del sistema. Al limitarnos a la comunicación bilateral, estos protocolos simplemente implicarán a dos agentes. Dicho protocolo tendrá que cumplir con un requisito básico para ser satisfactorio: consistencia (CONS) - un protocolo local debe garantizar la consistencia mutua de los agentes al finalizar (lo que implica, por supuesto, la finalización). Figura 1: Un Protocolo de Intercambio de Hipótesis [1] Un ejemplo de dicho protocolo es el protocolo descrito en [1] que se muestra en la Fig. 1. Para ilustrar aún más cómo dicho protocolo puede ser utilizado por agentes, proporcionamos algunos detalles sobre una posible estrategia: al recibir una hipótesis h1 (proponer(h1) o contra-proponer(h1)) de a1, el agente a2 se encuentra en el estado 2 y tiene las siguientes respuestas posibles: contraejemplo (si el agente conoce un ejemplo que contradice la hipótesis, o no está explicado por esta hipótesis), desafío (si el agente carece de evidencia para aceptar esta hipótesis), contra-proponer (si el agente está de acuerdo con la hipótesis pero prefiere otra), o aceptar (si es tan buena como su hipótesis favorita). Esta estrategia garantiza, entre otras propiedades, la eventual consistencia lógica mutua de los agentes involucrados [1]. Protocolo global El protocolo global regula la forma en que se iniciarán los intercambios bilaterales entre agentes. En cada turno, los agentes enviarán simultáneamente una solicitud ponderada para comunicarse con otros agentes. Este peso es un valor que mide la disposición de los agentes para conversar con el agente objetivo (en la práctica, esto puede basarse en diferentes heurísticas, pero haremos algunas suposiciones sobre las estrategias de los agentes, ver más abajo). Enviar una solicitud de este tipo es una especie de compromiso condicional para el agente. Un agente que envía una solicitud ponderada se compromete a entablar una conversación con el objetivo si no recibe y acepta otra solicitud por sí mismo. Una vez que se hayan recibido todas las solicitudes, cada agente responde con un aceptar o un rechazar. Al responder con un aceptar, un agente se compromete plenamente a participar en la conversación con el remitente. Por lo tanto, solo puede enviar una aceptación en una ronda dada, ya que un agente solo puede participar en una conversación por paso de tiempo. Cuando se hayan recibido todas las respuestas, cada agente que reciba una aceptación puede iniciar una conversación utilizando el protocolo local o enviar una cancelación si ha aceptado otra solicitud. Al final de todos los intercambios bilaterales, los agentes involucrados en la conversación son descartados del protocolo. Entonces cada uno de los agentes restantes reenvía una solicitud y el proceso se repite hasta que no se envíen más solicitudes. Estrategia global Ahora definimos cuatro requisitos para las estrategias utilizadas por los agentes, dependiendo de su rol en el protocolo: dos se refieren al rol del solicitante (cómo decidir quién es el 1000 The Sixth Intl. La Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) ¿con qué agente desea comunicarse? Los otros dos con el rol de respondedor (¿cómo decidir qué solicitud de comunicación aceptar o no?). • Disposición para resolver inconsistencias (SOLVE): los agentes desean comunicarse con cualquier otro agente a menos que sepan que son mutuamente consistentes. • Enfoque en resolver inconsistencias (FOCUS): los agentes no solicitan comunicarse con un agente con el que saben que son mutuamente consistentes. • Disposición para comunicarse (COMM): los agentes no pueden rechazar una solicitud de comunicación ponderada, a menos que acaben de recibir o enviar una solicitud con un peso mayor. • Compromiso con la solicitud de comunicación (REQU): los agentes no pueden aceptar una solicitud de comunicación ponderada si ellos mismos han enviado una solicitud de comunicación con un peso mayor. Por lo tanto, no cancelarán su solicitud a menos que hayan recibido una solicitud comunicacional con mayor peso. Ahora la estructura del protocolo, junto con las propiedades COMM+REQU, garantizan que una solicitud solo puede ser rechazada si su agente objetivo se involucra en comunicación con otro agente. Supongamos de hecho que el agente ai quiere comunicarse con aj enviando una solicitud con peso w. COMM garantiza que un agente que reciba una solicitud ponderada aceptará esta comunicación, aceptará una comunicación con un peso mayor o esperará la respuesta a una solicitud con un peso mayor. Esto asegura que la solicitud con peso máximo será aceptada y no cancelada (ya que REQU asegura que un agente que envía una solicitud solo puede cancelarla si acepta otra solicitud con un peso mayor). Por lo tanto, al menos dos agentes participarán en una conversación por ronda del protocolo global. Como el protocolo asegura que ai puede reenviar su solicitud mientras aj no está ocupado en una conversación, llegará un momento en el que aj deberá participar en una conversación, ya sea con ai u otro agente. Estos requisitos se refieren al envío y aceptación de solicitudes, pero los agentes también necesitan alguna estrategia de atribución de peso. Describimos a continuación una estrategia altruista, utilizada en nuestros experimentos. Siendo cooperativo, un agente puede querer conocer más los deseos de comunicación de otros agentes para mejorar la asignación general de intercambios a los agentes. Se añade entonces un paso de solicitud de contexto al protocolo global. Antes de enviar su solicitud ponderada elegida, los agentes asignan un peso a todos los agentes con los que están dispuestos a comunicarse, de acuerdo con algunos factores internos. En el caso más simple, este peso será 1 para todos los agentes con los que el agente no esté seguro de ser mutuamente consistentes (garantizando SOLVE), sin considerar a otros agentes para la comunicación (garantizando FOCUS). El agente luego envía una solicitud de contexto a todos los agentes con los que se considera la comunicación. Esta solicitud también proporciona información sobre el remitente (lista de comunicaciones consideradas junto con su peso). Después de recibir todas las solicitudes de contexto, los agentes responderán con un rechazo si ya están ocupados en una conversación (en cuyo caso, el agente solicitante no considerará comunicarse con ellos en este turno), o con una información que brinde al solicitante información sobre las solicitudes que ha enviado y recibido. Cuando se hayan recibido todas las respuestas, cada agente puede calcular el peso de todas las solicitudes que le conciernen. Lo hace restando del peso de su solicitud el peso de todas las solicitudes relacionadas con él o su objetivo (es decir, el peso final de la solicitud de ai a aj es Wi,j = wi,j + wj,i - ( Σ k∈R(i)-{j} wi,k + Σ k∈S(i)-{j} wk,i + Σ k∈R(j)-{i} wj,k + Σ k∈S(j)-{i} wk,j) donde wi,j es el peso de la solicitud de ai a aj, R(i) es el conjunto de índices de agentes que han recibido una solicitud de ai y S(i) es el conjunto de índices de agentes que han enviado una solicitud a ai). Luego envía finalmente una solicitud ponderada a los agentes que maximizan este peso (o esperan una solicitud) según lo descrito en el protocolo global. 4. (CONDICIONAL) CONVERGENCIA HACIA LA COHERENCIA GLOBAL En esta sección mostraremos que los requisitos relacionados con los protocolos y estrategias recién discutidos serán suficientes para garantizar que el sistema eventualmente convergerá hacia la coherencia global, bajo ciertas condiciones. Primero demostramos que, si dos agentes no son mutuamente consistentes en algún momento, entonces necesariamente habrá un momento en el futuro en el que un agente aprenderá una nueva observación, ya sea porque es nueva para el sistema, o al aprenderla de otro agente. Lema 1. Sea S un sistema poblado por n agentes a1, a2, ..., an, temporalmente conectados e involucrando percepciones limitadas para estos agentes. Sea n1 la suma de las cardinalidades de la intersección de los conjuntos de observaciones emparejados. (n1 = P (i,j)∈[1,n]2 |Oi ∩ Oj|) Sea n2 la cardinalidad de la unión de todos los conjuntos de observaciones de los agentes. (n2 = | ∪N i=1 Oi|). Si ¬MCons(ai, aj) en el tiempo t0, necesariamente existe un tiempo t > t0 tal que ya sea n1 o n2 aumentarán. Prueba. Supongamos que exista un tiempo t0 y unos índices (i, j) tal que ¬MCons(ai, aj). Utilizaremos mt0 = P (k,l)∈[1,n]2 εComm(ak, al, t0) donde εComm(ak, al, t0) = 1 si ak y al han comunicado al menos una vez desde t0, y 0 en caso contrario. La conexidad temporal garantiza que existen t1, ..., tm+1 y k1, ..., km tal que. C(ai, ak1 , t1), C(akm , aj, tm+1), y ∀p ∈ [1, m], C(akp , akp+1 , tp). Claramente, si MCons(ai, ak1), MCons(akm, aj) y ∀p, MCons(akp, akp+1), tenemos MCons(ai, aj) lo cual contradice nuestra hipótesis (siendo MCons transitivo, MCons(ai, ak1)∧MCons(ak1, ak2) implica que MCons(ai, ak2) y así sucesivamente hasta MCons(ai, akm)∧MCons(akm, aj) lo cual implica MCons(ai, aj)). Al menos dos agentes son necesariamente inconsistentes (¬MCons(ai, ak1), o ¬MCons(akm, aj), o ∃p0 t.q. ¬MCons(akp0, akp0+1)). Que ak y al sean estos dos vecinos en un momento t > t0 1. La propiedad SOLVE asegura que ya sea ak o al enviará una solicitud de comunicación al otro agente en el tiempo t. Como se mostró anteriormente, esto a su vez garantiza que al menos uno de estos agentes estará involucrado en una comunicación. Entonces hay dos posibilidades: (caso i) ak y al se comunican en el tiempo t. En este caso, sabemos que ¬MCons(ak, al). Esto y la propiedad CONS aseguran que al menos uno de los agentes debe cambiar su 1. Estrictamente hablando, la transitividad de MCons solo asegura que ak y al son inconsistentes en un tiempo t ≥ t0 que puede ser diferente del tiempo t en el que pueden comunicarse. Pero si se vuelven consistentes entre t y t (o inconsistentes entre t y t), significa que al menos uno de ellos ha cambiado su hipótesis entre t y t, es decir, después de t0. Podemos entonces aplicar el razonamiento del caso iib. El Sexto Internacional. La Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 1001 hipótesis, lo cual a su vez, dado que los agentes son autónomos, implica al menos un intercambio de observación. Pero entonces |Ok ∩Ol| está destinado a aumentar: n1(t) > n1(t0). (caso ii) ak se comunica con ap en el tiempo t. Entonces tenemos de nuevo dos posibilidades: (caso iia) ak y ap no se comunicaron desde t0. Pero luego εComm(ak, ap, t0) tenía valor 0 y toma valor 1. Por lo tanto, mt0 aumenta. (caso iib) ak y ap se comunicaron en algún momento t0 > t0. La propiedad CONS del protocolo asegura que MCons(ak, ap) en ese momento. Ahora el hecho de que se comuniquen y se ENFOQUEN implica que al menos uno de ellos cambió su hipótesis en el ínterin. El hecho de que los agentes sean autónomos implica a su vez que una nueva observación (percibida o recibida de otro agente) necesariamente provocó este cambio. El último caso garantizaría la existencia de un tiempo t > t0 y un agente aq tal que |Op ∩ Oq| o |Ok ∩ Oq| aumenten en 1 en ese momento (lo que implica que n1(t) > n1(t0)). El caso anterior significa que el agente obtiene una nueva percepción en el tiempo t. Si esa observación era desconocida en el sistema antes, entonces n2(t) > n2(t0). Si algún agente aq ya conocía esta observación antes, entonces tanto Op ∩ Oq como Ok ∩ Oq aumentan en 1 en el tiempo t (lo que implica que n1(t) > n1(t0)). Por lo tanto, ¬MCons(ai, aj) en el tiempo t0 garantiza que, o bien: −∃t > t0 t.q. n1(t ) > n1(t0); o −∃t > t0 t.q. n2(t ) > n2(t0); o −∃t > t0 t.q. mt0 aumenta en 1 en el tiempo t. Al iterar el razonamiento con t (pero manteniendo t0 como la referencia de tiempo para mt0), podemos eliminar el tercer caso (mt0 es un entero y está limitado por n2, lo que significa que después de un máximo de n2 iteraciones, necesariamente estaremos en uno de los otros dos casos). Como resultado, hemos demostrado que si ¬MCons(ai, aj) en el tiempo t0, necesariamente habrá un tiempo t tal que ya sea n1 o n2 aumentarán. Teorema 1 (Consistencia global). Sea S un sistema poblado por n agentes a1, a2, ..., an, temporalmente conectados e involucrando percepciones limitadas para estos agentes. Sea Cons(ai, aj) una propiedad de consistencia transitiva. Entonces, cualquier protocolo y estrategias que cumplan con las propiedades CONS, SOLVE, FOCUS, COMM y REQU garantizan que el sistema convergerá hacia la consistencia global. Prueba. Por el bien de la contradicción, asumamos que ∃I, J ∈ [1, N] tal que ∀t, ∃t0 > t, tal que ¬Cons(aI , aJ , t0). Usando el lema, esto implica que ∃t > t0 tal que n1(t) > n1(t0) o n2(t) > n2(t0). Pero podemos aplicar el mismo razonamiento tomando t = t, lo que nos daría t1 > t > t0 tal que ¬Cons(aI , aJ , t1), lo que nos da t > t1 tal que n1(t) > n1(t1) o n2(t) > n2(t1). Mediante iteraciones sucesivas podemos construir una secuencia t0, t1, ..., tn, que puede dividirse en dos subsecuencias t0, t1, ...tn y t0, t1, ..., tn tal que n1(t0) < n1(t1) < ... < n1(tn) y n2(t0) < n2(t1) < ... < n2(tn). Una de estas subsecuencias tiene que ser infinita. Sin embargo, n1(ti) y n2(ti) son estrictamente crecientes, enteros y acotados, lo que implica que ambos son finitos. Contradicción. Lo que el resultado anterior muestra esencialmente es que, en un sistema donde ningún agente estará aislado del resto de los agentes para siempre, solo se necesitan suposiciones muy leves sobre los protocolos y estrategias utilizados por los agentes para garantizar la convergencia hacia la consistencia del sistema en una cantidad finita de tiempo (aunque podría llevar mucho tiempo). Desafortunadamente, en muchas situaciones críticas, no será posible asumir esta conexión temporal. Dado que enfoques distribuidos como el abogado en este documento suelen presentarse como una buena manera de abordar problemas de confiabilidad o problemas de dependencia de un centro que son de suma importancia en estas aplicaciones críticas, ciertamente resulta interesante explorar más a fondo cómo se comportaría un sistema de este tipo cuando relajamos esta suposición. ESTUDIO EXPERIMENTAL Este experimento implica agentes tratando de escapar de un edificio en llamas. El entorno se describe como una cuadrícula espacial con un conjunto de paredes y (afortunadamente) algunas salidas. El tiempo y el espacio se consideran discretos. El tiempo se divide en rondas. Los agentes se localizan por su posición en la cuadrícula espacial. Estos agentes pueden moverse y comunicarse con otros agentes. En una ronda, un agente puede moverse una celda en cualquiera de las cuatro direcciones cardinales, siempre y cuando no esté bloqueado por una pared. En esta aplicación, los agentes se comunican con cualquier otro agente (pero, recuerda, solo uno) siempre y cuando este agente esté a la vista y aún no hayan intercambiado su hipótesis actual favorita. De repente, se desata un incendio en estas instalaciones. A partir de este momento, el fuego se propaga. En cada ronda, en cada caso donde haya fuego, el fuego se propaga en las cuatro direcciones. Sin embargo, el fuego no puede propagarse a través de una pared. Si el fuego se propaga en un caso donde un agente está posicionado, ese agente se quema y se considera muerto. Por supuesto, ya no puede moverse ni comunicarse. Si un agente llega a una salida, se considera que está a salvo y ya no puede ser quemado. Los agentes conocen el entorno y las reglas que rigen la dinámica de este entorno, es decir, conocen el mapa así como las reglas de propagación del fuego previamente descritas. También perciben este entorno localmente, pero no pueden ver más allá de 3 casos en cualquier dirección. Las paredes también bloquean la línea de visión, impidiendo que los agentes vean detrás de ellas. Dentro de su campo de visión, pueden ver a otros agentes y si los casos que ven están en llamas. Todas estas percepciones están memorizadas. Mostramos ahora cómo se instancia el marco abstracto presentado en el documento. • O = {Fire(x, y, t), NoFire(x, y, t), Agent(ai, x, y, t)} Las observaciones pueden ser positivas (o ∈ P(O) si ∃h ∈ H tal que h |= o) o negativas (o ∈ N(O) si ∃h ∈ H tal que h |= ¬o). • H={FireOrigin(x1, y1, t1)∧...∧FireOrigin(xl, yl, tl)} Las hipótesis son conjunciones de Orígenes de Fuego. • La relación de consistencia Cons(h, O) satisface: - coherencia: ∀o ∈ N(O), h |= ¬o. - completitud: ∀o ∈ P(O), h |= o. - minimalidad: Para todo h ∈ H, si h es coherente y completo para O, entonces h es preferido a h de acuerdo con la relación de preferencia (h ≤p h). Selecciona primero el número mínimo de orígenes, luego el más reciente (estrategia menos preemptiva [6]), y luego utiliza un ranking fijo arbitrario para discriminar ex-aequo. La relación resultante es un orden total, por lo tanto, la minimalidad implica que habrá un único h tal que Cons(O, h) para un O dado. Esto a su vez significa que MCons(ai, aj) si y solo si Cons(ai), Cons(aj) y hi = hj. Esta relación es entonces transitiva y simétrica. 1002 El Sexto Internacional. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) • Eh toma O como argumento y devuelve min≤p de la hipótesis coherente y completa para O 5.1 Evaluación Experimental Clásicamente evaluaremos la efectividad y eficiencia de diferentes protocolos de interacción (ver, por ejemplo, [3, 4]). La efectividad de un protocolo se determinará por la proporción de agentes que sobreviven al incendio respecto al número inicial de agentes involucrados en el experimento. Si este valor es alto, el protocolo ha sido efectivo para propagar la información y/o para que los agentes refinen sus hipótesis y determinen la mejor manera de salir. Eficiencia de un protocolo. Por lo general, el uso de información de apoyo implicará una sobrecarga de comunicación. Aquí asumiremos que la eficiencia de un protocolo dado está caracterizada por el flujo de datos inducido por este protocolo. En este documento solo discutiremos este aspecto con respecto a los protocolos locales. La medida principal que utilizaremos aquí es el tamaño total promedio de los mensajes intercambiados por los agentes por intercambio (teniendo en cuenta tanto el número de mensajes como el tamaño real de los mensajes, ya que podría ser que los mensajes resulten ser muy grandes, conteniendo por ejemplo un gran número de observaciones, lo que podría contrarrestar un bajo número de mensajes). 5.2 Configuraciones Experimentales Las configuraciones experimentales elegidas son las siguientes: • Topología ambiental: El rendimiento de la propagación de la información está altamente condicionado por la topología del entorno. Las habilidades de percepción de los agentes dependen de la apertura del entorno. Con un gran número de paredes, las percepciones de los agentes están limitadas, al igual que el número de posibles comunicaciones entre agentes, mientras que un entorno abierto proporcionará posibilidades óptimas de percepción y propagación de información. Por lo tanto, proponemos un índice topológico (ver abajo) como base común para caracterizar los entornos (mapas) utilizados durante las experimentaciones. El índice topológico (TI) es la proporción entre el número de celdas que pueden ser percibidas por los agentes sumadas desde todas las posiciones posibles, dividido por el número de celdas que serían percibidas desde las mismas posiciones pero sin paredes. (Cuanto más cercano a 1, más abierto es el entorno). También utilizaremos dos medidas adicionales, más clásicas [10]: la longitud del camino característico (CPL) y el coeficiente de agrupamiento (CC). • Número de agentes: la propagación de la información también depende del número inicial de agentes involucrados durante una experimentación. Por ejemplo, cuantos más agentes haya, más potenciales comunicaciones existen. Esto significa que habrá más potencial de propagación, pero también que la restricción de intercambio bilateral será más crucial. 3 El CPL es la mediana de las medias de las longitudes de los caminos más cortos que conectan cada nodo con todos los demás nodos. 4 caracterizando el grado de aislamiento de una región de un entorno en términos de accesibilidad (número de caminos aún utilizables para llegar a esta región). Mapa T.I. (%) C.P.L. C.C. 69-1 69,23 4,5 0,69 69-2 68,88 4,38 0,65 69-3 69,80 4,25 0,67 53-1 53,19 5,6 0,59 53-2 53,53 6,38 0,54 53-3 53,92 6,08 0,61 38-1 38,56 8,19 0,50 38-2 38,56 7,3 0,50 38-3 38,23 8,13 0,50 Tabla 1: Características Topológicas de los Mapas • Posiciones iniciales de los agentes- Las posiciones iniciales de los agentes tienen una influencia significativa en el comportamiento general de una instancia de nuestro sistema: estar cerca de una salida facilitará (en general) la escapatoria. 5.3 Entornos experimentales Elegimos realizar experimentos en tres índices topológicos muy diferentes (69% para entornos abiertos, 53% para entornos mixtos y 38% para entornos tipo laberinto). Figura 2: Dos mapas (izquierda: IT=69%, derecha IT=38%) Diseñamos tres mapas diferentes para cada índice (la Fig. 2 muestra dos de ellos), conteniendo el mismo número máximo de agentes (máximo 36 agentes) con una densidad máxima de un agente por celda, el mismo número de salidas y un origen de incendio similar (por ejemplo, tiempo y posición de inicio). Los tres mapas diferentes de un índice dado están diseñados de la siguiente manera. El primer plano es un modelo de un piso de un edificio existente. El segundo mapa tiene el mismo perímetro, salidas y origen del fuego que el primero, pero la cantidad y ubicación de las paredes son diferentes (las ubicaciones de las paredes son diseñadas por una heurística que crea paredes de forma aleatoria en la cuadrícula espacial de manera que no se creen habitaciones completamente cerradas y que ninguna salida quede bloqueada). El tercer mapa se caracteriza por un recinto geométrico en el que la ubicación de las paredes también está diseñada con la heurística mencionada anteriormente. La Tabla 1 resume las diferentes medidas topológicas que caracterizan estos mapas diferentes. Vale la pena señalar que los valores confirman la relevancia de TI (los mapas con un alto TI tienen un bajo CPL y un alto CC). Sin embargo, el CPL y el CC permiten refinar aún más la diferencia entre los mapas, por ejemplo, entre 53-1 y 53-2). 5.4 Resultados Experimentales Para cada trío de mapas definidos como se mencionó anteriormente, llevamos a cabo los mismos experimentos. En cada experimento, la sociedad difiere en cuanto a su proporción inicial de agentes involucrados, desde el 1% hasta el 100%. Esta proporción inicial representa el porcentaje de agentes involucrados con respecto al número máximo posible de agentes. Para cada mapa y cada proporción inicial, la Sexta Internacional. En la Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) seleccionamos aleatoriamente 100 ubicaciones iniciales de agentes diferentes. Para cada una de esas ubicaciones diferentes ejecutamos el sistema una vez para cada protocolo de interacción diferente. La efectividad de la comunicación y argumentación El primer experimento que hemos establecido tiene como objetivo probar cuán efectivo es el intercambio de hipótesis (IH), y en particular cómo los aspectos topológicos afectarán esta efectividad. Para hacerlo, hemos calculado la proporción de mejora ofrecida por ese protocolo sobre una situación en la que los agentes simplemente no podían comunicarse (sin comunicación). Para obtener más información sobre en qué medida el intercambio de hipótesis fue realmente crucial, también probamos un protocolo mucho menos elaborado que consistía en intercambios de observaciones simples (OE). Más precisamente, este protocolo requiere que cada agente almacene cualquier observación inesperada que perciba, y los agentes simplemente intercambian sus respectivas listas de observaciones cuando discuten. En este caso, el protocolo local es diferente (nota en particular que no garantiza consistencia mutua), pero el protocolo global permanece igual (con la única excepción de que la motivación de los agentes para comunicarse es sincronizar su lista de observaciones, no sus hipótesis). Si este protocolo es como máximo tan efectivo como HE, tiene la ventaja de ser más eficiente (esto es obvio en cuanto al número de mensajes, que se limitará a 2, menos directo en lo que respecta al tamaño de los mensajes, pero la observación general de que el intercambio de observaciones se puede ver como una versión simplificada del desafío es útil para ver esto). Los resultados de estos experimentos se informan en la Figura 3. Figura 3: Ganancia de la proporción de efectividad comparativa de los protocolos cuando la proporción de agentes aumenta. La primera observación que debe hacerse es que la comunicación mejora la efectividad del proceso, y esta proporción aumenta a medida que el número de agentes crece en el sistema. La segunda lección que aprendemos aquí es que la cercanía relativamente hace que la comunicación sea más efectiva que la falta de comunicación. Los mapas que muestran un T.I. del 38% están constantemente por encima de los otros dos, y el 53% sigue siendo ligeramente pero significativamente mejor que el 69%. Sin embargo, estas curvas también sugieren, quizás sorprendentemente, que HE supera a OE precisamente en aquellas situaciones donde la ganancia de la relación es menos importante (la única diferencia notable ocurre en mapas bastante abiertos donde T.I. es del 69%). Esto se puede explicar de la siguiente manera: cuando un mapa está abierto, los agentes tienen muchos posibles candidatos de explicación, y la argumentación se vuelve útil para discriminar entre ellos. Cuando un mapa es laberíntico, hay menos posibles explicaciones para un evento inesperado. Importancia del Protocolo Global El segundo conjunto de experimentos busca evaluar la importancia del diseño del protocolo global. Probamos nuestro protocolo contra un protocolo de difusión local (LB). La difusión local significa que todos los agentes vecinos percibidos por un agente estarán involucrados en una comunicación con ese agente en una ronda dada, aliviando la restricción de una sola comunicación por agente. Esto nos proporciona un límite superior aproximado sobre la posible ganancia de ratio en el sistema (para un protocolo local dado). Nuevamente, evaluamos la ganancia de la relación inducida por ese LB sobre nuestro HE clásico, para las tres clases diferentes de mapas. Los resultados se informan en la Figura 4. Figura 4: Ganancia de la proporción de transmisión local sobre el intercambio de hipótesis. Tenga en cuenta que la ganancia de la proporción es 0 cuando la proporción de agentes es del 5%, lo cual se explica fácilmente por el hecho de que corresponde a situaciones que involucran solo a dos agentes. Primero observamos que todas las clases de mapas muestran un aumento en la ganancia de la proporción a medida que aumenta el número de agentes: la ganancia alcanza entre el 10 y el 20%, dependiendo de la clase de mapas considerada. Si se compara esto con la mejora reportada en el experimento anterior, parece ser de la misma magnitud. Esto ilustra que el diseño del protocolo global no puede ser ignorado, especialmente cuando la proporción de agentes es alta. Sin embargo, también observamos que las curvas de ganancia de la proporción de efectividad tienen formas muy diferentes en ambos casos: la ganancia inducida por la precisión del protocolo local aumenta muy rápidamente con la proporción de agentes, mientras que la curva es muy suave para el global. Ahora observemos con más cuidado los resultados reportados aquí: la curva correspondiente a una TI del 53% está por encima de la correspondiente al 38%. Esto se debe a que cuanto más abierta sea un mapa, más oportunidades hay de comunicarse con más de un agente (y por lo tanto beneficiarse de la difusión). Sin embargo, también observamos que la curva para el 69% está por debajo de la del 53%. Esto se explica de la siguiente manera: en el caso del 69%, la ganancia potencial en términos de agentes sobrevivientes es mucho menor, porque nuestros protocolos ya ofrecen resultados bastante eficientes de todos modos (alcanzando rápidamente el 90%, ver Fig. 3). Una regla general podría ser que cuando el número de agentes es pequeño, se debe prestar especial atención al local 1004 de la Sexta Internacional. En el caso de que el número de agentes sea pequeño, uno puede utilizar el protocolo de la Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07), mientras que cuando ese número es grande, se debe diseñar cuidadosamente uno global (a menos que el mapa sea tan abierto que el protocolo ya sea casi óptimamente eficiente). La eficiencia de los protocolos. El experimento final reportado aquí se centra en el análisis de la eficiencia de los protocolos. Aquí analizamos el tamaño medio de la totalidad de los mensajes que son intercambiados por agentes (tamaño medio de intercambios, en resumen) utilizando los siguientes protocolos: HE, OE y dos protocolos variantes. El primero es un protocolo de intercambio de hipótesis restringidas (RHE) intermediario. RHE es el siguiente: no implica ningún desafío ni contraoferta, lo que significa que los agentes no pueden cambiar su rol durante el protocolo (esto difiere de RE en ese aspecto). En resumen, RHE permite a un agente agotar las críticas de sus socios, y eventualmente este socio adoptará la hipótesis del agente. Ten en cuenta que esto significa que la autonomía del agente no se conserva aquí (ya que un agente esencialmente aceptará cualquier hipótesis que no pueda socavar), con la esperanza de que la ganancia en eficiencia sea lo suficientemente significativa como para compensar una pérdida en efectividad. El segundo protocolo de variante es un protocolo completo de intercambio de observaciones (COE). COE utiliza los mismos principios que OE, pero incluye además todos los ejemplos críticos negativos (nofire) en el intercambio (dando así todos los ejemplos utilizados como argumentos por el protocolo de intercambio de hipótesis), mejorando así la efectividad. Los resultados para el mapa 69-1 se muestran en la Figura 5. Figura 5: Tamaño medio de los intercambios. Primero podemos observar el hecho de que el orden de los protocolos, desde el menos eficiente hasta el más eficiente, es COE, HE, RHE y luego OE. ÉL siendo más eficiente que COE demuestra que el proceso de argumentación gana eficiencia al seleccionar cuándo es necesario proporcionar ejemplos negativos, los cuales tienen menos impacto que los positivos en nuestro entorno de prueba específico. Sin embargo, al comunicar hipótesis antes de proporcionar observaciones para respaldarla (HE) en lugar de dar directamente las observaciones más cruciales (OE), el proceso de argumentación duplica el tamaño de los intercambios de datos. Es el costo de garantizar la consistencia al final del intercambio (una propiedad que OE no admite). También es significativo el hecho de que el tamaño promedio de los intercambios es ligeramente mayor cuando el número de agentes es pequeño. Esto se explica por el hecho de que en estos casos solo unos pocos agentes tienen información relevante en su posesión, y que necesitarán comunicarse mucho para llegar a un punto de vista común de la situación. Cuando el número de agentes aumenta, este conocimiento se distribuye entre más agentes que necesitan discusiones más cortas para llegar a una consistencia mutua. Como consecuencia, la ganancia relativa en eficiencia de usar RHE parece ser mejor cuando el número de agentes es pequeño: cuando es alto, difícilmente discutirán de todos modos. Finalmente, vale la pena notar que la desviación estándar para estos experimentos es bastante alta, lo que significa que la conversación no converge hacia ningún patrón estereotípico. 6. CONCLUSIÓN Este documento ha investigado las propiedades de un sistema multiagente donde cada agente (distribuido) percibe localmente su entorno e intenta alcanzar consistencia con otros agentes a pesar de severas restricciones de comunicación. En particular, hemos expuesto condiciones que permiten la convergencia e investigado experimentalmente una situación típica donde esas condiciones no pueden cumplirse. Hay muchas posibles extensiones a este trabajo, la primera siendo investigar más a fondo las propiedades de diferentes protocolos globales pertenecientes a la clase que identificamos, y su influencia en el resultado. Existen en particular muchas heurísticas, altamente dependientes del contexto del estudio, que podrían intuitivamente arrojar resultados interesantes (en nuestro estudio, seleccionar al destinatario en función de lo que se pueda inferir de sus acciones observadas podría ser una de esas heurísticas). Un candidato obvio para problemas a largo plazo se refiere a la relajación de la suposición de un sensor perfecto. 7. REFERENCIAS [1] G. Bourgne, N. Maudet y S. Pinson. Cuando los agentes comunican hipótesis en situaciones críticas. En Actas de DALT-2006, mayo de 2006. [2] P. Harvey, C. F. Chang y A. Ghose. Búsqueda distribuida basada en soporte: un nuevo enfoque para el procesamiento de restricciones multiagente. En Actas de AAMAS06, 2006. [3] H. Jung y M. Tambe. Argumentación como satisfacción de restricciones distribuida: Aplicaciones y resultados. En Actas de AGENTS01, 2001. [4] N. C. Karunatillake y N. R. Jennings. ¿Vale la pena discutir? En Actas de ArgMAS 2004, 2004. [5] S. Onta˜n´on y E. Plaza. Argumentos y contraejemplos en la deliberación conjunta basada en casos. En Actas de ArgMAS-2006, mayo de 2006. [6] D. Poole. Explicación y predicción: Una arquitectura para el razonamiento por defecto y abductivo. Inteligencia Computacional, 5(2):97-110, 1989. [7] I. Rahwan, S. D. Ramchurn, N. R. Jennings, P. McBurney, S. Parsons y L. Sonenberg. Negociación basada en argumentos. La revisión de Ingeniería del Conocimiento, 4(18):345-375, 2003. [8] N. Roos, A. ten Tije y C. Witteveen. Un protocolo para el diagnóstico multiagente con conocimiento distribuido espacialmente. En Actas de AAMAS03, 2003. [9] N. Roos, A. ten Tije y C. Witteveen. Alcanzando acuerdo diagnóstico en el diagnóstico multiagente. En Actas de AAMAS04, 2004. [10] T. Takahashi, Y. Kaneda y N. Ito. Estudio preliminar: utilizando simulaciones de RoboCupRescue para la prevención de desastres. En Actas de SRMED2004, 2004. El Sexto Internacional. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 1005 ",
            "candidates": [],
            "error": [
                [
                    "puntos temporales",
                    "puntos temporales",
                    "secuencia de puntos temporales"
                ]
            ]
        },
        "time point sequence": {
            "translated_key": "secuencia de puntos temporales",
            "is_in_text": false,
            "original_annotated_sentences": [
                "Hypotheses Refinement under Topological Communication Constraints ∗ Gauvain Bourgne, Gael Hette, Nicolas Maudet, and Suzanne Pinson LAMSADE, Univ.",
                "Paris-Dauphine, France {bourgne,hette,maudet,pinson}@lamsade.dauphine.fr ABSTRACT We investigate the properties of a multiagent system where each (distributed) agent locally perceives its environment.",
                "Upon perception of an unexpected event, each agent locally computes its favoured hypothesis and tries to propagate it to other agents, by exchanging hypotheses and supporting arguments (observations).",
                "However, we further assume that communication opportunities are severely constrained and change dynamically.",
                "In this paper, we mostly investigate the convergence of such systems towards global consistency.",
                "We first show that (for a wide class of protocols that we shall define), the communication constraints induced by the topology will not prevent the convergence of the system, at the condition that the system dynamics guarantees that no agent will ever be isolated forever, and that agents have unlimited time for computation and arguments exchange.",
                "As this assumption cannot be made in most situations though, we then set up an experimental framework aiming at comparing the relative efficiency and effectiveness of different interaction protocols for hypotheses exchange.",
                "We study a critical situation involving a number of agents aiming at escaping from a burning building.",
                "The results reported here provide some insights regarding the design of optimal protocol for hypotheses refinement in this context.",
                "Categories and Subject Descriptors I.2.11 [Artificial Intelligence]: Distributed Artificial Intelligence-Multiagent systems General Terms Theory, Experimentation 1.",
                "INTRODUCTION We consider a multiagent system where each (distributed) agent locally perceives its environment, and we assume that some unexpected event occurs in that system.",
                "If each agent computes only locally its favoured hypothesis, it is only natural to assume that agents will seek to coordinate and refine their hypotheses by confronting their observations with other agents.",
                "If, in addition, the communication opportunities are severely constrained (for instance, agents can only communicate when they are close enough to some other agent), and dynamically changing (for instance, agents may change their locations), it becomes crucial to carefully design protocols that will allow agents to converge to some desired state of global consistency.",
                "In this paper we exhibit some sufficient conditions on the system dynamics and on the protocol/strategy structures that allow to guarantee that property, and we experimentally study some contexts where (some of) these assumptions are relaxed.",
                "While problems of diagnosis are among the venerable classics in the AI tradition, their multiagent counterparts have much more recently attracted some attention.",
                "Roos and colleagues [8, 9] in particular study a situation where a number of distributed entities try to come up with a satisfying global diagnosis of the whole system.",
                "They show in particular that the number of messages required to establish this global diagnosis is bound to be prohibitive, unless the communication is enhanced with some suitable protocol.",
                "However, they do not put any restrictions on agents communication options, and do not assume either that the system is dynamic.",
                "The benefits of enhancing communication with supporting information to make convergence to a desired global state of a system more efficient has often been put forward in the literature.",
                "This is for instance one of the main idea underlying the argumentation-based negotiation approach [7], where the desired state is a compromise between agents with conflicting preferences.",
                "Many of these works however make the assumption that this approach is beneficial to start with, and study the technical facets of the problem (or instead emphasize other advantages of using argumentation).",
                "Notable exceptions are the works of [3, 4, 2, 5], which studied in contexts different from ours the efficiency of argumentation.",
                "The rest of the paper is as follows.",
                "Section 2 specifies the basic elements of our model, and Section 3 goes on to presenting the different protocols and strategies used by the agents to exchange hypotheses and observations.",
                "We put special attention at clearly emphasizing the conditions on the system dynamics and protocols/strategies that will be exploited in the rest of the paper.",
                "Section 4 details one of 998 978-81-904262-7-5 (RPS) c 2007 IFAAMAS the main results of the paper, namely the fact that under the aforementioned conditions, the constraints that we put on the topology will not prevent the convergence of the system towards global consistency, at the condition that no agent ever gets completely lost forever in the system, and that unlimited time is allowed for computation and argument exchange.",
                "While the conditions on protocols and strategies are fairly mild, it is also clear that these system requirements look much more problematic, even frankly unrealistic in critical situations where distributed approaches are precisely advocated.",
                "To get a clearer picture of the situation induced when time is a critical factor, we have set up an experimental framework that we introduce and discuss in Section 5.",
                "The critical situation involves a number of agents aiming at escaping from a burning building.",
                "The results reported here show that the effectiveness of argument exchange crucially depends upon the nature of the building, and provide some insights regarding the design of optimal protocol for hypotheses refinement in this context. 2.",
                "BASIC NOTIONS We start by defining the basic elements of our system.",
                "Environment Let O be the (potentially infinite) set of possible observations.",
                "We assume the sensors of our agents to be perfect, hence the observations to be certain.",
                "Let H be the set of hypotheses, uncertain and revisable.",
                "Let Cons(h, O) be the consistency relation, a binary relation between a hypothesis h ∈ H and a set of observations O ⊆ O.",
                "In most cases, Cons will refer to classical consistency relation, however, we may overload its meaning and add some additional properties to that relation (in which case we will mention it).",
                "The environment may include some dynamics, and change over the course of time.",
                "We define below sequences of time points to deal with it: Definition 1 (Sequence of time points).",
                "A sequence of time points t1, t2, . . . , tn from t is an ordered set of time points t1, t2, . . . , tn such that t1 ≥ t and ∀i ∈ [1, n − 1], ti+1 ≥ ti.",
                "Agent We take a system populated by n agents a1, . . . , an.",
                "Each agent is defined as a tuple F, Oi, hi , where: • F, the set of facts, common knowledge to all agents. • Oi ∈ 2O , the set of observations made by the agent so far.",
                "We assume a perfect memory, hence this set grows monotonically. • hi ∈ H, the favourite hypothesis of the agent.",
                "A key notion governing the formation of hypotheses is that of consistency, defined below: Definition 2 (Consistency).",
                "We say that: • An agent is consistent (Cons(ai)) iff Cons(hi, Oi) (that is, its hypothesis is consistent with its observation set). • An agent ai consistent with a partner agent aj iff Cons(ai) and Cons(hi, Oj) (that is, this agent is consistent and its hypothesis can explain the observation set of the other agent). • Two agents ai and aj are mutually consistent (MCons(ai, aj)) iff Cons(ai, aj) and Cons(aj, ai). • A system is consistent iff ∀(i, j)∈[1, n]2 it is the case that MCons(ai, aj).",
                "To ensure its consistency, each agent is equipped with an abstract reasoning machinery that we shall call the explanation function Eh.",
                "This (deterministic) function takes a set of observation and returns a single prefered hypothesis (2O → H).",
                "We assume h = Eh(O) to be consistent with O by definition of Eh, so using this function on its observation set to determine its favourite hypothesis is a sure way for the agent to achieve consistency.",
                "Note however that an hypothesis does not need to be generated by Eh to be consistent with an observation set.",
                "As a concrete example of such a function, and one of the main inspiration of this work, one can cite the Theorist reasoning system [6] -as long as it is coupled with a filter selecting a single prefered theory among the ones initially selected by Theorist.",
                "Note also that hi may only be modified as a consequence of the application Eh.",
                "We refer to this as the autonomy of the agent: no other agent can directly impose a given hypothesis to an agent.",
                "As a consequence, only a new observation (being it a new perception, or an observation communicated by a fellow agent) can result in a modification of its prefered hypothesis hi (but not necessarily of course).",
                "We finally define a property of the system that we shall use in the rest of the paper: Definition 3 (Bounded Perceptions).",
                "A system involves a bounded perception for agents iff ∃n0 s.t. ∀t| ∪N i=1 Oi| ≤ n0. (That is, the number of observations to be made by the agents in the system is not infinite.)",
                "Agent Cycle Now we need to see how these agents will evolve and interact in their environment.",
                "In our context, agents evolve in a dynamic environment, and we classicaly assume the following system cycle: 1.",
                "Environment dynamics: the environment evolves according to the defined rules of the system dynamics. 2.",
                "Perception step : agents get perceptions from the environment.",
                "These perceptions are typically partial (e.g. the agent can only see a portion of a map). 3.",
                "Reasoning step: agents compare perception with predictions, seek explanations for (potential) difference(s), refine their hypothesis, draw new conclusions. 4.",
                "Communication step: agents can communicate hypotheses and observations with other agents through a defined protocol.",
                "Any agent can only be involved in one communication with another agent by step. 5.",
                "Action step: agents do some practical reasoning using the models obtained from the previous steps and select an action.",
                "They can then modify the environment by executing it.",
                "The communication of the agents will be further constrained by topological consideration.",
                "At a given time, an agent will only be able to communicate with a number of neighbours.",
                "Its connexions with these others agents may The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 999 evolve with its situation in the environment.",
                "Typically, an agent can only communicate with agents that it can sense, but one could imagine evolving topological constraints on communication based on a network of communications between agents where the links are not always active.",
                "Communication In our system, agents will be able to communicate with each other.",
                "However, due to the aforementionned topological constraints, they will not be able to communicate with any agents at anytime.",
                "Who an agent can communicate with will be defined dynamically (for instance, this can be a consequence of the agents being close enough to get in touch).",
                "We will abstractly denote by C(ai, aj, t) the communication property, in other words, the fact that agents ai and aj can communicate at time t (note that this relation is assumed to be symetric, but of course not transitive).",
                "We are now in a position to define two essential properties of our system.",
                "Definition 4 (Temporal Path).",
                "There exists a temporal communication path at horizon tf (noted Ltf (aI , aJ )) between ai and aj iff there exists a sequence of time points t1, t2, . . . , tn from tf and a sequence of agents k1, k2, . . . , kn s.t. (i) C(aI , ak1 , t1), (ii) C(akn , aJ , tn+1), (iii) ∀i ∈ [1, n], C(aki , aki+1 , ti) Intuitively, what this property says is that it is possible to find a temporal path in the future that would allow to link agent ai and aj via a sequence of intermediary agents.",
                "Note that the time points are not necessarily successive, and that the sequence of agents may involve the same agents several times.",
                "Definition 5 (Temporal Connexity).",
                "A system is temporaly connex iff ∀t ∀(i, j)∈[1, n]2 Lt(ai, aj) In short, a temporaly connex system guarantees that any agent will be able to communicate with any other agents, no matter how long it might take to do so, at any time.",
                "To put it another way, it is never the case that an agent will be isolated for ever from another agent of the system.",
                "We will next discuss the detail of how communication concretely takes place in our system.",
                "Remember that in this paper, we only consider the case of bilateral exchanges (an agent can only speak to a single other agent), and that we also assume that any agent can only engage in a single exchange in a given round. 3.",
                "PROTOCOLS AND STRATEGIES In this section, we discuss the requirements of the interaction protocols that govern the exchange of messages between agents, and provide some example instantiation of such protocols.",
                "To clarify the presentation, we distinguish two levels: the local level, which is concerned with the regulation of bilateral exchanges; and the global level,which essentially regulates the way agents can actually engage into a conversation.",
                "At each level, we separate what is specified by the protocol, and what is left to agents strategies.",
                "Local Protocol and Strategies We start by inspecting local protocols and strategies that will regulate the communication between the agents of the system.",
                "As we limit ourselves to bilateral communication, these protocols will simply involve two agents.",
                "Such protocol will have to meet one basic requirement to be satisfying. • consistency (CONS)- a local protocol has to guarantee the mutual consistency of agents upon termination (which implies termination of course).",
                "Figure 1: A Hypotheses Exchange Protocol [1] One example such protocol is the protocol described in [1] that is pictured in Fig. 1.",
                "To further illustrate how such protocol can be used by agents, we give some details on a possible strategy: upon receiving a hypothesis h1 (propose(h1) or counterpropose(h1)) from a1, agent a2 is in state 2 and has the following possible replies: counterexample (if the agent knows an example contradicting the hypothesis, or not explained by this hypothesis), challenge (if the agents lacks evidence to accept this hypothesis), counterpropose (if the agent agrees with the hypothesis but prefers another one), or accept (if it is indeed as good as its favourite hypothesis).",
                "This strategy guarantees, among other properties, the eventual mutual logical consistency of the involved agents [1].",
                "Global Protocol The global protocol regulates the way bilateral exchanges will be initiated between agents.",
                "At each turn, agents will concurrently send one weighted request to communicate to other agents.",
                "This weight is a value measuring the agents willingness to converse with the targeted agent (in practice, this can be based on different heuristics, but we shall make some assumptions on agents strategies, see below).",
                "Sending such a request is a kind of conditional commitment for the agent.",
                "An agent sending a weighted request commits to engage in conversation with the target if he does not receive and accept himself another request.",
                "Once all request have been received, each agent replies with either an acccept or a reject.",
                "By answering with an accept, an agent makes a full commitment to engage in conversation with the sender.",
                "Therefore, it can only send one accept in a given round, as an agent can only participate in one conversation per time step.",
                "When all response have been received, each agent receiving an accept can either initiate a conversation using the local protocol or send a cancel if it has accepted another request.",
                "At the end of all the bilateral exchanges, the agents engaged in conversation are discarded from the protocol.",
                "Then each of the remaining agents resends a request and the process iterates until no more requests are sent.",
                "Global Strategy We now define four requirements for the strategies used by agents, depending on their role in the protocol: two are concerned with the requestee role (how to decide who the 1000 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) agent wishes to communicate with? ), the other two with the responder role (how to decide which communication request to accept or not?). • Willingness to solve inconsistancies (SOLVE)-agents want to communicate with any other agents unless they know they are mutually consistent. • Focus on solving inconsistencies (FOCUS)-agents do not request communication with an agent with whom they know they are mutually consistent. • Willingness to communicate (COMM)-agents cannot refuse a weighted communication request, unless they have just received or send a request with a greater weight. • Commitment to communication request (REQU)agents cannot accept a weighted communication request if they have themselves sent a communication request with a greater weight.",
                "Therefore, they will not cancel their request unless they have received a communicational request with greater weight.",
                "Now the protocol structure, together with the properties COMM+REQU, ensure that a request can only be rejected if its target agent engages in communication with another agent.",
                "Suppose indeed that agent ai wants to communicate with aj by sending a request with weight w. COMM guarantees that an agent receiving a weighted request will either accept this communication, accept a communication with a greater weight or wait for the answer to a request with a greater weight.",
                "This ensures that the request with maximal weight will be accepted and not cancelled (as REQU ensures that an agent sending a request can only cancel it if he accepts another request with greater weight).",
                "Therefore at least two agents will engage in conversation per round of the global protocol.",
                "As the protocol ensures that ai can resend its request while aj is not engaged in a conversation, there will be a turn in which aj must engage in a conversation, either with ai or another agent.",
                "These requirements concern request sending and acceptation, but agents also need some strategy of weight attribution.",
                "We describe below an altruist strategy, used in our experiments.",
                "Being cooperative, an agent may want to know more of the communication wishes of other agents in order to improve the overall allocation of exchanges to agents.",
                "A context request step is then added to the global protocol.",
                "Before sending their chosen weighted request, agents attribute a weight to all agents they are prepared to communicate with, according to some internal factors.",
                "In the simplest case, this weight will be 1 for all agent with whom the agent is not sure of being mutually consistent (ensuring SOLVE), other agent being not considered for communication (ensuring FOCUS).",
                "The agent then sends a context request to all agents with whom communication is considered.",
                "This request also provides information about the sender (list of considered communications along with their weight).",
                "After reception of all the context requests, agents will either reply with a deny, iff they are already engaged in a conversation (in which case, the requesting agent will not consider communication with them anymore in this turn), or an inform giving the requester information about the requests it has sent and received.",
                "When all replies have been received, each agent can calculate the weight of all requests concerning it.",
                "It does so by substracting from the weight of its request the weight of all requests concerning either it or its target (that is, the final weight of the request from ai to aj is Wi,j = wi,j +wj,i − ( P k∈R(i)−{j} wi,k + P k∈S(i)−{j} wk,i + P k∈R(j)−{i} wj,k + P k∈S(j)−{i} wk,j) where wi,j is the weight of the request of ai to aj, R(i) is the set of indice of agents having received a request from ai and S(i) is the set of indice of agents having send a request to ai).",
                "It then finally sends a weighted request to the agents who maximise this weight (or wait for a request) as described in the global protocol. 4. (CONDITIONAL) CONVERGENCE TO GLOBAL CONSISTENCY In this section we will show that the requirements regarding protocols and strategies just discussed will be sufficient to ensure that the system will eventually converge towards global consistency, under some conditions.",
                "We first show that, if two agents are not mutually consistent at some time, then there will be necessarily a time in the future such that an agent will learn a new observation, being it because it is new for the system, or by learning it from another agent.",
                "Lemma 1.",
                "Let S be a system populated by n agents a1, a2, ..., an, temporaly connex, and involving bounded perceptions for these agents.",
                "Let n1 be the sum of cardinalities of the intersection of pairwise observation sets. (n1 = P (i,j)∈[1,n]2 |Oi ∩ Oj|) Let n2 be the cardinality of the union of all agents observations sets. (n2 = | ∪N i=1 Oi|).",
                "If ¬MCons(ai, aj) at time t0, there is necessarily a time t > t0 s.t. either n1 or n2 will increase.",
                "Proof.",
                "Suppose that there exist a time t0 and indices (i, j) s.t. ¬MCons(ai, aj).",
                "We will use mt0 = P (k,l)∈[1,n]2 εComm(ak, al, t0) where εComm(ak, al, t0) = 1 if ak and al have communicated at least once since t0, and 0 otherwise.",
                "Temporal connexity guarantees that there exist t1, ..., tm+1 and k1, ..., km s.t.",
                "C(ai, ak1 , t1), C(akm , aj, tm+1), and ∀p ∈ [1, m], C(akp , akp+1 , tp).",
                "Clearly, if MCons(ai, ak1 ), MCons(akm , aj) and ∀p, MCons(akp , akp+1 ), we have MCons(ai, aj) which contradicts our hypothesis (MCons being transitive, MCons(ai, ak1 )∧MCons(ak1 , ak2 ) implies that MCons(ai, ak2 ) and so on till MCons(ai, akm )∧ MCons(akm , aj) which implies MCons(ai, aj) ).",
                "At least two agents are then necessarily inconsistent (¬MCons(ai, ak1 ), or ¬MCons(akm , aj), or ∃p0 t.q. ¬MCons(akp0 , akp0+1 )).",
                "Let ak and al be these two neighbours at a time t > t0 1 .",
                "The SOLVE property ensures that either ak or al will send a communication request to the other agent at time t .",
                "As shown before, this in turn ensures that at least one of these agents will be involved in a communication.",
                "Then there are two possibilities: (case i) ak and al communicate at time t .",
                "In this case, we know that ¬MCons(ak, al).",
                "This and the CONS property ensures that at least one of the agents must change its 1 Strictly speaking, the transitivity of MCons only ensure that ak and al are inconsistent at a time t ≥ t0 that can be different from the time t at which they can communicate.",
                "But if they become consistent between t and t (or inconsistent between t and t ), it means that at least one of them have changed its hypothesis between t and t , that is, after t0.",
                "We can then apply the reasoning of case iib.",
                "The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 1001 hypothesis, which in turn, since agents are autonomous, implies at least one exchange of observation.",
                "But then |Ok ∩Ol| is bound to increase: n1(t ) > n1(t0). (case ii) ak communicates with ap at time t .",
                "We then have again two possibilities: (case iia) ak and ap did not communicate since t0.",
                "But then εComm(ak, ap, t0) had value 0 and takes value 1.",
                "Hence mt0 increases. (case iib) ak and ap did communicate at some time t0 > t0.",
                "The CONS property of the protocol ensures that MCons(ak, ap) at that time.",
                "Now the fact that they communicate and FOCUS implies that at least one of them did change its hypothesis in the meantime.",
                "The fact that agents are autonomous implies in turn that a new observation (perceived or received from another agent) necessarily provoked this change.",
                "The latter case would ensure the existence of a time t > t0 and an agent aq s.t. either |Op ∩Oq| or |Ok ∩Oq| increases of 1 at that time (implying n1(t ) > n1(t0)).",
                "The former case means that the agent gets a new perception o at time t .",
                "If that observation was unknown in the system before, then n2(t ) > n2(t0).",
                "If some agent aq already knew this observation before, then either Op ∩ Oq or Ok ∩ Oq increases of 1 at time t (which implies that n1(t ) > n1(t0)).",
                "Hence, ¬MCons(ai, aj) at time t0 guarantees that, either: −∃t > t0 t.q. n1(t ) > n1(t0); or −∃t > t0 t.q. n2(t ) > n2(t0); or −∃t > t0 t.q. mt0 increases of 1 at time t .",
                "By iterating the reasoning with t (but keeping t0 as the time reference for mt0 ), we can eliminate the third case (mt0 is integer and bounded by n2 , which means that after a maximum of n2 iterations, we necessarily will be in one of two other cases.)",
                "As a result, we have proven that if ¬MCons(ai, aj) at time t0, there is necessarily a time t s.t. either n1 or n2 will increase.",
                "Theorem 1 (Global consistency).",
                "Let S be a system populated by n agents a1, a2, ..., an, temporaly connex, and involving bounded perceptions for these agents.",
                "Let Cons(ai, aj) be a transitive consistency property.",
                "Then any protocol and strategies satisfying properties CONS, SOLVE, FOCUS, COMM and REQU guarantees that the system will converge towards global consistency.",
                "Proof.",
                "For the sake of contradiction, let us assume ∃I, J ∈ [1, N] s.t. ∀t, ∃t0 > t, t.q. ¬Cons(aI , aJ , t0).",
                "Using the lemma, this implies that ∃t > t0 s.t. either n1(t ) > n1(t0) or n2(t ) > n2(t0).",
                "But we can apply the same reasoning taking t = t , which would give us t1 > t > t0 s.t. ¬Cons(aI , aJ , t1), which gives us t > t1 s.t. either n1(t ) > n1(t1) or n2(t ) > n2(t1).",
                "By successive iterations we can then construct a sequence t0, t1, ..., tn, which can be divided in two sub-sequences t0, t1, ...tn and t0 , t1 , ..., tn s.t. n1(t0) < n1(t1) < ... < n1(tn) and n2(t0 ) < n2(t1 ) < ... < n2(tn).",
                "One of these sub-sequences has to be infinite.",
                "However, n1(ti) and n2(ti ) are strictly growing, integer, and bounded, which implies that both are finite.",
                "Contradiction.",
                "What the previous result essentially shows is that, in a system where no agent will be isolated from the rest of the agents for ever, only very mild assumptions on the protocols and strategies used by agents suffice to guarantee convergence towards system consistency in a finite amount of time (although it might take very long).",
                "Unfortunately, in many critical situations, it will not be possible to assume this temporal connexity.",
                "As distributed approaches as the one advocated in this paper are precisely often presented as a good way to tackle problems of reliability or problems of dependence to a center that are of utmost importance in these critical applications, it is certainly interesting to further explore how such a system would behave when we relax this assumption. 5.",
                "EXPERIMENTAL STUDY This experiment involves agents trying to escape from a burning building.",
                "The environment is described as a spatial grid with a set of walls and (thankfully) some exits.",
                "Time and space are considered discrete.",
                "Time is divided in rounds.",
                "Agents are localised by their position on the spatial grid.",
                "These agents can move and communicate with other agents.",
                "In a round, an agent can move of one cell in any of the four cardinal directions, provided it is not blocked by a wall.",
                "In this application, agents communicate with any other agent (but, recall, a single one) given that this agent is in view, and that they have not yet exchanged their current favoured hypothesis.",
                "Suddenly, a fire erupts in these premises.",
                "From this moment, the fire propagates.",
                "Each round, for each cases where there is fire, the fire propagates in the four directions.",
                "However, the fire cannot propagate through a wall.",
                "If the fire propagates in a case where an agent is positioned, that agent burns and is considered dead.",
                "It can of course no longer move nor communicate.",
                "If an agent gets to an exit, it is considered saved, and can no longer be burned.",
                "Agents know the environment and the rules governing the dynamics of this environment, that is, they know the map as well as the rules of fire propagation previously described.",
                "They also locally perceive this environment, but cannot see further than 3 cases away, in any direction.",
                "Walls also block the line of view, preventing agents from seeing behind them.",
                "Within their sight, they can see other agents and whether or not the cases they see are on fire.",
                "All these perceptions are memorised.",
                "We now show how this instantiates the abstract framework presented the paper. • O = {Fire(x, y, t), NoFire(x, y, t), Agent(ai, x, y, t)} Observations can then be positive (o ∈ P(O) iff ∃h ∈ H s.t. h |= o) or negative (o ∈ N(O) iff ∃h ∈ H s.t. h |= ¬o). • H={FireOrigin(x1, y1, t1)∧...∧FireOrigin(xl, yl, tl)} Hypotheses are conjunctions of FireOrigins. • Cons(h, O) consistency relation satisfies: - coherence : ∀o ∈ N(O), h |= ¬o. - completeness : ∀o ∈ P(O), h |= o. - minimality : For all h ∈ H, if h is coherent and complete for O, then h is prefered to h according to the preference relation (h ≤p h ).2 2 Selects first the minimal number of origins, then the most recent (least preemptive strategy [6]), then uses some arbitrary fixed ranking to discriminate ex-aequo.",
                "The resulting relation is a total order, hence minimality implies that there will be a single h s.t.Cons(O, h) for a given O.",
                "This in turn means that MCons(ai, aj) iff Cons(ai), Cons(aj), and hi = hj.",
                "This relation is then transitive and symmetric. 1002 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) • Eh takes O as argument and returns min≤p of the coherent and complete hypothesis for O 5.1 Experimental Evaluation We will classically (see e.g. [3, 4]) assess the effectiveness and efficiency of different interaction protocols.",
                "Effectiveness of a protocol The proportion of agents surviving the fire over the initial number of agents involved in the experiment will determine the effectiveness of a given protocol.",
                "If this value is high, the protocol has been effective to propagate the information and/or for the agents to refine their hypotheses and determine the best way to the exit.",
                "Efficiency of a protocol Typically, the use of supporting information will involve a communication overhead.",
                "We will assume here that the efficiency of a given protocol is characterised by the data flow induced by this protocol.",
                "In this paper we will only discuss this aspect wrt. local protocols.",
                "The main measure that we shall then use here is the mean total size of messages that are exchanged by agents per exchange (hence taking into account both the number of messages and the actual size of the messages, because it could be that messages happen to be very big, containing e.g. a large number of observations, which could counter-balance a low number of messages). 5.2 Experimental Settings The chosen experimental settings are the following: • Environmental topology- Performances of information propagation are highly constrained by the environment topology.",
                "The perception skills of the agents depend on the openness of the environment.",
                "With a large number of walls the perceptions of agents are limited, and also the number of possible inter-agent communications, whereas an open environment will provide optimal possibilities of perception and information propagation.",
                "Thus, we propose a topological index (see below) as a common basis to charaterize the environments (maps) used during experimentations.",
                "The topological index (TI) is the ratio of the number of cells that can be perceived by agents summed up from all possible positions, divided by the number of cells that would be perceived from the same positions but without any walls. (The closer to 1, the more open the environment).",
                "We shall also use two additional, more classical [10], measures: the characteristic path length3 (CPL) and the clustering coefficient4 (CC). • Number of agents- The propagation of information also depends on the initial number of agents involved during an experimentation.",
                "For instance, the more agents, the more potential communications there is.",
                "This means that there will be more potential for propagation, but also that the bilateral exchange restriction will be more crucial. 3 The CPL is the median of the means of the shortest path lengths connecting each node to all other nodes. 4 characterising the isolation degree of a region of an environment in terms of acessibility (number of roads still usable to reach this region).",
                "Map T.I. (%) C.P.L.",
                "C.C. 69-1 69,23 4,5 0,69 69-2 68,88 4,38 0,65 69-3 69,80 4,25 0,67 53-1 53,19 5,6 0,59 53-2 53,53 6,38 0,54 53-3 53,92 6,08 0,61 38-1 38,56 8,19 0,50 38-2 38,56 7,3 0,50 38-3 38,23 8,13 0,50 Table 1: Topological Characteristics of the Maps • Initial positions of the agents- Initial positions of the agents have a significant influence on the overall behavior of an instance of our system: being close from an exit will (in general) ease the escape. 5.3 Experimental environments We choose to realize experiments on three very different topological indexes (69% for open environments, 53% for mixed environments, and 38% for labyrinth-like environments).",
                "Figure 2: Two maps (left: TI=69%, right TI=38%) We designed three different maps for each index (Fig. 2 shows two of them), containing the same maximum number of agents (36 agents max.) with a maximum density of one agent per cell, the same number of exits and a similar fire origin (e.g. starting time and position).",
                "The three differents maps of a given index are designed as follows.",
                "The first map is a model of an existing building floor.",
                "The second map has the same enclosure, exits and fire origin as the first one, but the number and location of walls are different (wall locations are designed by an heuristic which randomly creates walls on the spatial grid such that no fully closed rooms are created and that no exit is closed).",
                "The third map is characterised by geometrical enclosure in wich walls location is also designed with the aforementioned heuristic.",
                "Table 1 summarizes the different topological measures characterizing these different maps.",
                "It is worth pointing out that the values confirm the relevance of TI (maps with a high TI have a low CPL and a high CC.",
                "However the CPL and CC allows to further refine the difference between the maps, e.g. between 53-1 and 53-2). 5.4 Experimental Results For each triple of maps defined as above we conduct the same experiments.",
                "In each experiment, the society differs in terms of its initial proportion of involved agents, from 1% to 100%.",
                "This initial proportion represents the percentage of involved agents with regards to the possible maximum number of agents.",
                "For each map and each initial proportion, The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 1003 we select randomly 100 different initial agents locations.",
                "For each of those different locations we execute the system one time for each different interaction protocol.",
                "Effectiveness of Communication and Argumentation The first experiment that we set up aims at testing how effective is hypotheses exchange (HE), and in particular how the topological aspects will affect this effectiveness.",
                "In order to do so, we have computed the ratio of improvement offered by that protocol over a situation where agents could simply not communicate (no comm).",
                "To get further insights as to what extent the hypotheses exchange was really crucial, we also tested a much less elaborated protocol consisting of mere observation exchanges (OE).",
                "More precisely, this protocol requires that each agent stores any unexpected observation that it perceives, and agents simply exchange their respective lists of observations when they discuss.",
                "In this case, the local protocol is different (note in particular that it does not guarantee mutual consistency), but the global protocol remains the same (at the only exception that agents motivation to communicate is to synchronise their list of observations, not their hypothesis).",
                "If this protocol is at best as effective as HE, it has the advantage of being more efficient (this is obvious wrt the number of messages which will be limited to 2, less straightforward as far as the size of messages is concerned, but the rough observation that the exchange of observations can be viewed as a flat version of the challenge is helpful to see this).",
                "The results of these experiments are reported in Fig. 3.",
                "Figure 3: Comparative effectiveness ratio gain of protocols when the proportion of agents augments The first observation that needs to be made is that communication improves the effectiveness of the process, and this ratio increases as the number of agents grows in the system.",
                "The second lesson that we learn here is that closeness relatively makes communication more effective over non communication.",
                "Maps exhibiting a T.I. of 38% are constantly above the two others, and 53% are still slightly but significantly better than 69%.",
                "However, these curves also suggest, perhaps surprisingly, that HE outperforms OE in precisely those situations where the ratio gain is less important (the only noticeable difference occurs for rather open maps where T.I. is 69%).",
                "This may be explained as follows: when a map is open, agents have many potential explanation candidates, and argumentation becomes useful to discriminate between those.",
                "When a map is labyrinth-like, there are fewer possible explanations to an unexpected event.",
                "Importance of the Global Protocol The second set of experiments seeks to evaluate the importance of the design of the global protocol.",
                "We tested our protocol against a local broadcast (LB) protocol.",
                "Local broadcast means that all the neighbours agents perceived by an agent will be involved in a communication with that agent in a given round -we alleviate the constraint of a single communication by agent.",
                "This gives us a rough upper bound upon the possible ratio gain in the system (for a given local protocol).",
                "Again, we evaluated the ratio gain induced by that LB over our classical HE, for the three different classes of maps.",
                "The results are reported in Fig. 4.",
                "Figure 4: Ratio gain of local broadcast over hypotheses exchange Note to begin with that the ratio gain is 0 when the proportion of agents is 5%, which is easily explained by the fact that it corresponds to situations involving only two agents.",
                "We first observe that all classes of maps witness a ratio gain increasing when the proportion of agents augments: the gain reaches 10 to 20%, depending on the class of maps considered.",
                "If one compares this with the improvement reported in the previous experiment, it appears to be of the same magnitude.",
                "This illustrates that the design of the global protocol cannot be ignored, especially when the proportion of agents is high.",
                "However, we also note that the effectiveness ratio gain curves have very different shapes in both cases: the gain induced by the accuracy of the local protocol increases very quickly with the proportion of agents, while the curve is really smooth for the global one.",
                "Now let us observe more carefully the results reported here: the curve corresponding to a TI of 53% is above that corresponding to 38%.",
                "This is so because the more open a map, the more opportunities to communicate with more than one agent (and hence benefits from broadcast).",
                "However, we also observe that curve for 69% is below that for 53%.",
                "This is explained as follows: in the case of 69%, the potential gain to be made in terms of surviving agents is much lower, because our protocols already give rather efficient outcomes anyway (quickly reaching 90%, see Fig. 3).",
                "A simple rule of thumb could be that when the number of agents is small, special attention should be put on the local 1004 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) protocol, whereas when that number is large, one should carefully design the global one (unless the map is so open that the protocol is already almost optimally efficient).",
                "Efficiency of the Protocols The final experiment reported here is concerned with the analysis of the efficiency of the protocols.",
                "We analysis here the mean size of the totality of the messages that are exchanged by agents (mean size of exchanges, for short) using the following protocols: HE, OE, and two variant protocols.",
                "The first one is an intermediary restricted hypotheses exchange protocol (RHE).",
                "RHE is as follows: it does not involve any challenge nor counter-propose, which means that agents cannot switch their role during the protocol (this differs from RE in that respect).",
                "In short, RHE allows an agent to exhaust its partners criticism, and eventually this partner will come to adopt the agents hypothesis.",
                "Note that this means that the autonomy of the agent is not preserved here (as an agent will essentially accept any hypothesis it cannot undermine), with the hope that the gain in efficiency will be significant enough to compensate a loss in effectiveness.",
                "The second variant protocol is a complete observation exchange protocol (COE).",
                "COE uses the same principles as OE, but includes in addition all critical negative examples (nofire) in the exchange (thus giving all examples used as arguments by the hypotheses exchanges protocol), hence improving effectiveness.",
                "Results for map 69-1 are shown on Fig. 5.",
                "Figure 5: Mean size of exchanges First we can observe the fact that the ordering of the protocols, from the least efficient to the most efficient, is COE, HE, RHE and then OE.",
                "HE being more efficient than COE proves that the argumentation process gains efficiency by selecting when it is needed to provide negative example, which have less impact that positive ones in our specific testbed.",
                "However, by communicating hypotheses before eventually giving observation to support it (HE) instead of directly giving the most crucial observations (OE), the argumentation process doubles the size of data exchanges.",
                "It is the cost for ensuring consistency at the end of the exchange (a property that OE does not support).",
                "Also significant is the fact the the mean size of exchanges is slightly higher when the number of agents is small.",
                "This is explained by the fact that in these cases only a very few agents have relevant informations in their possession, and that they will need to communicate a lot in order to come up with a common view of the situation.",
                "When the number of agents increases, this knowledge is distributed over more agents which need shorter discussions to get to mutual consistency.",
                "As a consequence, the relative gain in efficiency of using RHE appears to be better when the number of agents is small: when it is high, they will hardly argue anyway.",
                "Finally, it is worth noticing that the standard deviation for these experiments is rather high, which means that the conversation do not converge to any stereotypic pattern. 6.",
                "CONCLUSION This paper has investigated the properties of a multiagent system where each (distributed) agent locally perceives its environment, and tries to reach consistency with other agents despite severe communication restrictions.",
                "In particular we have exhibited conditions allowing convergence, and experimentally investigated a typical situation where those conditions cannot hold.",
                "There are many possible extensions to this work, the first being to further investigate the properties of different global protocols belonging to the class we identified, and their influence on the outcome.",
                "There are in particular many heuristics, highly dependent on the context of the study, that could intuitively yield interesting results (in our study, selecting the recipient on the basis of what can be inferred from his observed actions could be such a heuristic).",
                "One obvious candidate for longer term issues concern the relaxation of the assumption of perfect sensing. 7.",
                "REFERENCES [1] G. Bourgne, N. Maudet, and S. Pinson.",
                "When agents communicate hypotheses in critical situations.",
                "In Proceedings of DALT-2006, May 2006. [2] P. Harvey, C. F. Chang, and A. Ghose.",
                "Support-based distributed search: a new approach for multiagent constraint processing.",
                "In Proceedings of AAMAS06, 2006. [3] H. Jung and M. Tambe.",
                "Argumentation as distributed constraint satisfaction: Applications and results.",
                "In Proceedings of AGENTS01, 2001. [4] N. C. Karunatillake and N. R. Jennings.",
                "Is it worth arguing?",
                "In Proceedings of ArgMAS 2004, 2004. [5] S. Onta˜n´on and E. Plaza.",
                "Arguments and counterexamples in case-based joint deliberation.",
                "In Proceedings of ArgMAS-2006, May 2006. [6] D. Poole.",
                "Explanation and prediction: An architecture for default and abductive reasoning.",
                "Computational Intelligence, 5(2):97-110, 1989. [7] I. Rahwan, S. D. Ramchurn, N. R. Jennings, P. McBurney, S. Parsons, and L. Sonenberg.",
                "Argumention-based negotiation.",
                "The Knowledge Engineering Review, 4(18):345-375, 2003. [8] N. Roos, A. ten Tije, and C. Witteveen.",
                "A protocol for multi-agent diagnosis with spatially distributed knowledge.",
                "In Proceedings of AAMAS03, 2003. [9] N. Roos, A. ten Tije, and C. Witteveen.",
                "Reaching diagnostic agreement in multiagent diagnosis.",
                "In Proceedings of AAMAS04, 2004. [10] T. Takahashi, Y. Kaneda, and N. Ito.",
                "Preliminary study - using robocuprescue simulations for disasters prevention.",
                "In Proceedings of SRMED2004, 2004.",
                "The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 1005"
            ],
            "original_annotated_samples": [],
            "translated_annotated_samples": [],
            "translated_text": "",
            "candidates": [],
            "error": [
                []
            ]
        },
        "bounded perception": {
            "translated_key": "percepción limitada",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Hypotheses Refinement under Topological Communication Constraints ∗ Gauvain Bourgne, Gael Hette, Nicolas Maudet, and Suzanne Pinson LAMSADE, Univ.",
                "Paris-Dauphine, France {bourgne,hette,maudet,pinson}@lamsade.dauphine.fr ABSTRACT We investigate the properties of a multiagent system where each (distributed) agent locally perceives its environment.",
                "Upon perception of an unexpected event, each agent locally computes its favoured hypothesis and tries to propagate it to other agents, by exchanging hypotheses and supporting arguments (observations).",
                "However, we further assume that communication opportunities are severely constrained and change dynamically.",
                "In this paper, we mostly investigate the convergence of such systems towards global consistency.",
                "We first show that (for a wide class of protocols that we shall define), the communication constraints induced by the topology will not prevent the convergence of the system, at the condition that the system dynamics guarantees that no agent will ever be isolated forever, and that agents have unlimited time for computation and arguments exchange.",
                "As this assumption cannot be made in most situations though, we then set up an experimental framework aiming at comparing the relative efficiency and effectiveness of different interaction protocols for hypotheses exchange.",
                "We study a critical situation involving a number of agents aiming at escaping from a burning building.",
                "The results reported here provide some insights regarding the design of optimal protocol for hypotheses refinement in this context.",
                "Categories and Subject Descriptors I.2.11 [Artificial Intelligence]: Distributed Artificial Intelligence-Multiagent systems General Terms Theory, Experimentation 1.",
                "INTRODUCTION We consider a multiagent system where each (distributed) agent locally perceives its environment, and we assume that some unexpected event occurs in that system.",
                "If each agent computes only locally its favoured hypothesis, it is only natural to assume that agents will seek to coordinate and refine their hypotheses by confronting their observations with other agents.",
                "If, in addition, the communication opportunities are severely constrained (for instance, agents can only communicate when they are close enough to some other agent), and dynamically changing (for instance, agents may change their locations), it becomes crucial to carefully design protocols that will allow agents to converge to some desired state of global consistency.",
                "In this paper we exhibit some sufficient conditions on the system dynamics and on the protocol/strategy structures that allow to guarantee that property, and we experimentally study some contexts where (some of) these assumptions are relaxed.",
                "While problems of diagnosis are among the venerable classics in the AI tradition, their multiagent counterparts have much more recently attracted some attention.",
                "Roos and colleagues [8, 9] in particular study a situation where a number of distributed entities try to come up with a satisfying global diagnosis of the whole system.",
                "They show in particular that the number of messages required to establish this global diagnosis is bound to be prohibitive, unless the communication is enhanced with some suitable protocol.",
                "However, they do not put any restrictions on agents communication options, and do not assume either that the system is dynamic.",
                "The benefits of enhancing communication with supporting information to make convergence to a desired global state of a system more efficient has often been put forward in the literature.",
                "This is for instance one of the main idea underlying the argumentation-based negotiation approach [7], where the desired state is a compromise between agents with conflicting preferences.",
                "Many of these works however make the assumption that this approach is beneficial to start with, and study the technical facets of the problem (or instead emphasize other advantages of using argumentation).",
                "Notable exceptions are the works of [3, 4, 2, 5], which studied in contexts different from ours the efficiency of argumentation.",
                "The rest of the paper is as follows.",
                "Section 2 specifies the basic elements of our model, and Section 3 goes on to presenting the different protocols and strategies used by the agents to exchange hypotheses and observations.",
                "We put special attention at clearly emphasizing the conditions on the system dynamics and protocols/strategies that will be exploited in the rest of the paper.",
                "Section 4 details one of 998 978-81-904262-7-5 (RPS) c 2007 IFAAMAS the main results of the paper, namely the fact that under the aforementioned conditions, the constraints that we put on the topology will not prevent the convergence of the system towards global consistency, at the condition that no agent ever gets completely lost forever in the system, and that unlimited time is allowed for computation and argument exchange.",
                "While the conditions on protocols and strategies are fairly mild, it is also clear that these system requirements look much more problematic, even frankly unrealistic in critical situations where distributed approaches are precisely advocated.",
                "To get a clearer picture of the situation induced when time is a critical factor, we have set up an experimental framework that we introduce and discuss in Section 5.",
                "The critical situation involves a number of agents aiming at escaping from a burning building.",
                "The results reported here show that the effectiveness of argument exchange crucially depends upon the nature of the building, and provide some insights regarding the design of optimal protocol for hypotheses refinement in this context. 2.",
                "BASIC NOTIONS We start by defining the basic elements of our system.",
                "Environment Let O be the (potentially infinite) set of possible observations.",
                "We assume the sensors of our agents to be perfect, hence the observations to be certain.",
                "Let H be the set of hypotheses, uncertain and revisable.",
                "Let Cons(h, O) be the consistency relation, a binary relation between a hypothesis h ∈ H and a set of observations O ⊆ O.",
                "In most cases, Cons will refer to classical consistency relation, however, we may overload its meaning and add some additional properties to that relation (in which case we will mention it).",
                "The environment may include some dynamics, and change over the course of time.",
                "We define below sequences of time points to deal with it: Definition 1 (Sequence of time points).",
                "A sequence of time points t1, t2, . . . , tn from t is an ordered set of time points t1, t2, . . . , tn such that t1 ≥ t and ∀i ∈ [1, n − 1], ti+1 ≥ ti.",
                "Agent We take a system populated by n agents a1, . . . , an.",
                "Each agent is defined as a tuple F, Oi, hi , where: • F, the set of facts, common knowledge to all agents. • Oi ∈ 2O , the set of observations made by the agent so far.",
                "We assume a perfect memory, hence this set grows monotonically. • hi ∈ H, the favourite hypothesis of the agent.",
                "A key notion governing the formation of hypotheses is that of consistency, defined below: Definition 2 (Consistency).",
                "We say that: • An agent is consistent (Cons(ai)) iff Cons(hi, Oi) (that is, its hypothesis is consistent with its observation set). • An agent ai consistent with a partner agent aj iff Cons(ai) and Cons(hi, Oj) (that is, this agent is consistent and its hypothesis can explain the observation set of the other agent). • Two agents ai and aj are mutually consistent (MCons(ai, aj)) iff Cons(ai, aj) and Cons(aj, ai). • A system is consistent iff ∀(i, j)∈[1, n]2 it is the case that MCons(ai, aj).",
                "To ensure its consistency, each agent is equipped with an abstract reasoning machinery that we shall call the explanation function Eh.",
                "This (deterministic) function takes a set of observation and returns a single prefered hypothesis (2O → H).",
                "We assume h = Eh(O) to be consistent with O by definition of Eh, so using this function on its observation set to determine its favourite hypothesis is a sure way for the agent to achieve consistency.",
                "Note however that an hypothesis does not need to be generated by Eh to be consistent with an observation set.",
                "As a concrete example of such a function, and one of the main inspiration of this work, one can cite the Theorist reasoning system [6] -as long as it is coupled with a filter selecting a single prefered theory among the ones initially selected by Theorist.",
                "Note also that hi may only be modified as a consequence of the application Eh.",
                "We refer to this as the autonomy of the agent: no other agent can directly impose a given hypothesis to an agent.",
                "As a consequence, only a new observation (being it a new perception, or an observation communicated by a fellow agent) can result in a modification of its prefered hypothesis hi (but not necessarily of course).",
                "We finally define a property of the system that we shall use in the rest of the paper: Definition 3 (Bounded Perceptions).",
                "A system involves a <br>bounded perception</br> for agents iff ∃n0 s.t. ∀t| ∪N i=1 Oi| ≤ n0. (That is, the number of observations to be made by the agents in the system is not infinite.)",
                "Agent Cycle Now we need to see how these agents will evolve and interact in their environment.",
                "In our context, agents evolve in a dynamic environment, and we classicaly assume the following system cycle: 1.",
                "Environment dynamics: the environment evolves according to the defined rules of the system dynamics. 2.",
                "Perception step : agents get perceptions from the environment.",
                "These perceptions are typically partial (e.g. the agent can only see a portion of a map). 3.",
                "Reasoning step: agents compare perception with predictions, seek explanations for (potential) difference(s), refine their hypothesis, draw new conclusions. 4.",
                "Communication step: agents can communicate hypotheses and observations with other agents through a defined protocol.",
                "Any agent can only be involved in one communication with another agent by step. 5.",
                "Action step: agents do some practical reasoning using the models obtained from the previous steps and select an action.",
                "They can then modify the environment by executing it.",
                "The communication of the agents will be further constrained by topological consideration.",
                "At a given time, an agent will only be able to communicate with a number of neighbours.",
                "Its connexions with these others agents may The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 999 evolve with its situation in the environment.",
                "Typically, an agent can only communicate with agents that it can sense, but one could imagine evolving topological constraints on communication based on a network of communications between agents where the links are not always active.",
                "Communication In our system, agents will be able to communicate with each other.",
                "However, due to the aforementionned topological constraints, they will not be able to communicate with any agents at anytime.",
                "Who an agent can communicate with will be defined dynamically (for instance, this can be a consequence of the agents being close enough to get in touch).",
                "We will abstractly denote by C(ai, aj, t) the communication property, in other words, the fact that agents ai and aj can communicate at time t (note that this relation is assumed to be symetric, but of course not transitive).",
                "We are now in a position to define two essential properties of our system.",
                "Definition 4 (Temporal Path).",
                "There exists a temporal communication path at horizon tf (noted Ltf (aI , aJ )) between ai and aj iff there exists a sequence of time points t1, t2, . . . , tn from tf and a sequence of agents k1, k2, . . . , kn s.t. (i) C(aI , ak1 , t1), (ii) C(akn , aJ , tn+1), (iii) ∀i ∈ [1, n], C(aki , aki+1 , ti) Intuitively, what this property says is that it is possible to find a temporal path in the future that would allow to link agent ai and aj via a sequence of intermediary agents.",
                "Note that the time points are not necessarily successive, and that the sequence of agents may involve the same agents several times.",
                "Definition 5 (Temporal Connexity).",
                "A system is temporaly connex iff ∀t ∀(i, j)∈[1, n]2 Lt(ai, aj) In short, a temporaly connex system guarantees that any agent will be able to communicate with any other agents, no matter how long it might take to do so, at any time.",
                "To put it another way, it is never the case that an agent will be isolated for ever from another agent of the system.",
                "We will next discuss the detail of how communication concretely takes place in our system.",
                "Remember that in this paper, we only consider the case of bilateral exchanges (an agent can only speak to a single other agent), and that we also assume that any agent can only engage in a single exchange in a given round. 3.",
                "PROTOCOLS AND STRATEGIES In this section, we discuss the requirements of the interaction protocols that govern the exchange of messages between agents, and provide some example instantiation of such protocols.",
                "To clarify the presentation, we distinguish two levels: the local level, which is concerned with the regulation of bilateral exchanges; and the global level,which essentially regulates the way agents can actually engage into a conversation.",
                "At each level, we separate what is specified by the protocol, and what is left to agents strategies.",
                "Local Protocol and Strategies We start by inspecting local protocols and strategies that will regulate the communication between the agents of the system.",
                "As we limit ourselves to bilateral communication, these protocols will simply involve two agents.",
                "Such protocol will have to meet one basic requirement to be satisfying. • consistency (CONS)- a local protocol has to guarantee the mutual consistency of agents upon termination (which implies termination of course).",
                "Figure 1: A Hypotheses Exchange Protocol [1] One example such protocol is the protocol described in [1] that is pictured in Fig. 1.",
                "To further illustrate how such protocol can be used by agents, we give some details on a possible strategy: upon receiving a hypothesis h1 (propose(h1) or counterpropose(h1)) from a1, agent a2 is in state 2 and has the following possible replies: counterexample (if the agent knows an example contradicting the hypothesis, or not explained by this hypothesis), challenge (if the agents lacks evidence to accept this hypothesis), counterpropose (if the agent agrees with the hypothesis but prefers another one), or accept (if it is indeed as good as its favourite hypothesis).",
                "This strategy guarantees, among other properties, the eventual mutual logical consistency of the involved agents [1].",
                "Global Protocol The global protocol regulates the way bilateral exchanges will be initiated between agents.",
                "At each turn, agents will concurrently send one weighted request to communicate to other agents.",
                "This weight is a value measuring the agents willingness to converse with the targeted agent (in practice, this can be based on different heuristics, but we shall make some assumptions on agents strategies, see below).",
                "Sending such a request is a kind of conditional commitment for the agent.",
                "An agent sending a weighted request commits to engage in conversation with the target if he does not receive and accept himself another request.",
                "Once all request have been received, each agent replies with either an acccept or a reject.",
                "By answering with an accept, an agent makes a full commitment to engage in conversation with the sender.",
                "Therefore, it can only send one accept in a given round, as an agent can only participate in one conversation per time step.",
                "When all response have been received, each agent receiving an accept can either initiate a conversation using the local protocol or send a cancel if it has accepted another request.",
                "At the end of all the bilateral exchanges, the agents engaged in conversation are discarded from the protocol.",
                "Then each of the remaining agents resends a request and the process iterates until no more requests are sent.",
                "Global Strategy We now define four requirements for the strategies used by agents, depending on their role in the protocol: two are concerned with the requestee role (how to decide who the 1000 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) agent wishes to communicate with? ), the other two with the responder role (how to decide which communication request to accept or not?). • Willingness to solve inconsistancies (SOLVE)-agents want to communicate with any other agents unless they know they are mutually consistent. • Focus on solving inconsistencies (FOCUS)-agents do not request communication with an agent with whom they know they are mutually consistent. • Willingness to communicate (COMM)-agents cannot refuse a weighted communication request, unless they have just received or send a request with a greater weight. • Commitment to communication request (REQU)agents cannot accept a weighted communication request if they have themselves sent a communication request with a greater weight.",
                "Therefore, they will not cancel their request unless they have received a communicational request with greater weight.",
                "Now the protocol structure, together with the properties COMM+REQU, ensure that a request can only be rejected if its target agent engages in communication with another agent.",
                "Suppose indeed that agent ai wants to communicate with aj by sending a request with weight w. COMM guarantees that an agent receiving a weighted request will either accept this communication, accept a communication with a greater weight or wait for the answer to a request with a greater weight.",
                "This ensures that the request with maximal weight will be accepted and not cancelled (as REQU ensures that an agent sending a request can only cancel it if he accepts another request with greater weight).",
                "Therefore at least two agents will engage in conversation per round of the global protocol.",
                "As the protocol ensures that ai can resend its request while aj is not engaged in a conversation, there will be a turn in which aj must engage in a conversation, either with ai or another agent.",
                "These requirements concern request sending and acceptation, but agents also need some strategy of weight attribution.",
                "We describe below an altruist strategy, used in our experiments.",
                "Being cooperative, an agent may want to know more of the communication wishes of other agents in order to improve the overall allocation of exchanges to agents.",
                "A context request step is then added to the global protocol.",
                "Before sending their chosen weighted request, agents attribute a weight to all agents they are prepared to communicate with, according to some internal factors.",
                "In the simplest case, this weight will be 1 for all agent with whom the agent is not sure of being mutually consistent (ensuring SOLVE), other agent being not considered for communication (ensuring FOCUS).",
                "The agent then sends a context request to all agents with whom communication is considered.",
                "This request also provides information about the sender (list of considered communications along with their weight).",
                "After reception of all the context requests, agents will either reply with a deny, iff they are already engaged in a conversation (in which case, the requesting agent will not consider communication with them anymore in this turn), or an inform giving the requester information about the requests it has sent and received.",
                "When all replies have been received, each agent can calculate the weight of all requests concerning it.",
                "It does so by substracting from the weight of its request the weight of all requests concerning either it or its target (that is, the final weight of the request from ai to aj is Wi,j = wi,j +wj,i − ( P k∈R(i)−{j} wi,k + P k∈S(i)−{j} wk,i + P k∈R(j)−{i} wj,k + P k∈S(j)−{i} wk,j) where wi,j is the weight of the request of ai to aj, R(i) is the set of indice of agents having received a request from ai and S(i) is the set of indice of agents having send a request to ai).",
                "It then finally sends a weighted request to the agents who maximise this weight (or wait for a request) as described in the global protocol. 4. (CONDITIONAL) CONVERGENCE TO GLOBAL CONSISTENCY In this section we will show that the requirements regarding protocols and strategies just discussed will be sufficient to ensure that the system will eventually converge towards global consistency, under some conditions.",
                "We first show that, if two agents are not mutually consistent at some time, then there will be necessarily a time in the future such that an agent will learn a new observation, being it because it is new for the system, or by learning it from another agent.",
                "Lemma 1.",
                "Let S be a system populated by n agents a1, a2, ..., an, temporaly connex, and involving bounded perceptions for these agents.",
                "Let n1 be the sum of cardinalities of the intersection of pairwise observation sets. (n1 = P (i,j)∈[1,n]2 |Oi ∩ Oj|) Let n2 be the cardinality of the union of all agents observations sets. (n2 = | ∪N i=1 Oi|).",
                "If ¬MCons(ai, aj) at time t0, there is necessarily a time t > t0 s.t. either n1 or n2 will increase.",
                "Proof.",
                "Suppose that there exist a time t0 and indices (i, j) s.t. ¬MCons(ai, aj).",
                "We will use mt0 = P (k,l)∈[1,n]2 εComm(ak, al, t0) where εComm(ak, al, t0) = 1 if ak and al have communicated at least once since t0, and 0 otherwise.",
                "Temporal connexity guarantees that there exist t1, ..., tm+1 and k1, ..., km s.t.",
                "C(ai, ak1 , t1), C(akm , aj, tm+1), and ∀p ∈ [1, m], C(akp , akp+1 , tp).",
                "Clearly, if MCons(ai, ak1 ), MCons(akm , aj) and ∀p, MCons(akp , akp+1 ), we have MCons(ai, aj) which contradicts our hypothesis (MCons being transitive, MCons(ai, ak1 )∧MCons(ak1 , ak2 ) implies that MCons(ai, ak2 ) and so on till MCons(ai, akm )∧ MCons(akm , aj) which implies MCons(ai, aj) ).",
                "At least two agents are then necessarily inconsistent (¬MCons(ai, ak1 ), or ¬MCons(akm , aj), or ∃p0 t.q. ¬MCons(akp0 , akp0+1 )).",
                "Let ak and al be these two neighbours at a time t > t0 1 .",
                "The SOLVE property ensures that either ak or al will send a communication request to the other agent at time t .",
                "As shown before, this in turn ensures that at least one of these agents will be involved in a communication.",
                "Then there are two possibilities: (case i) ak and al communicate at time t .",
                "In this case, we know that ¬MCons(ak, al).",
                "This and the CONS property ensures that at least one of the agents must change its 1 Strictly speaking, the transitivity of MCons only ensure that ak and al are inconsistent at a time t ≥ t0 that can be different from the time t at which they can communicate.",
                "But if they become consistent between t and t (or inconsistent between t and t ), it means that at least one of them have changed its hypothesis between t and t , that is, after t0.",
                "We can then apply the reasoning of case iib.",
                "The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 1001 hypothesis, which in turn, since agents are autonomous, implies at least one exchange of observation.",
                "But then |Ok ∩Ol| is bound to increase: n1(t ) > n1(t0). (case ii) ak communicates with ap at time t .",
                "We then have again two possibilities: (case iia) ak and ap did not communicate since t0.",
                "But then εComm(ak, ap, t0) had value 0 and takes value 1.",
                "Hence mt0 increases. (case iib) ak and ap did communicate at some time t0 > t0.",
                "The CONS property of the protocol ensures that MCons(ak, ap) at that time.",
                "Now the fact that they communicate and FOCUS implies that at least one of them did change its hypothesis in the meantime.",
                "The fact that agents are autonomous implies in turn that a new observation (perceived or received from another agent) necessarily provoked this change.",
                "The latter case would ensure the existence of a time t > t0 and an agent aq s.t. either |Op ∩Oq| or |Ok ∩Oq| increases of 1 at that time (implying n1(t ) > n1(t0)).",
                "The former case means that the agent gets a new perception o at time t .",
                "If that observation was unknown in the system before, then n2(t ) > n2(t0).",
                "If some agent aq already knew this observation before, then either Op ∩ Oq or Ok ∩ Oq increases of 1 at time t (which implies that n1(t ) > n1(t0)).",
                "Hence, ¬MCons(ai, aj) at time t0 guarantees that, either: −∃t > t0 t.q. n1(t ) > n1(t0); or −∃t > t0 t.q. n2(t ) > n2(t0); or −∃t > t0 t.q. mt0 increases of 1 at time t .",
                "By iterating the reasoning with t (but keeping t0 as the time reference for mt0 ), we can eliminate the third case (mt0 is integer and bounded by n2 , which means that after a maximum of n2 iterations, we necessarily will be in one of two other cases.)",
                "As a result, we have proven that if ¬MCons(ai, aj) at time t0, there is necessarily a time t s.t. either n1 or n2 will increase.",
                "Theorem 1 (Global consistency).",
                "Let S be a system populated by n agents a1, a2, ..., an, temporaly connex, and involving bounded perceptions for these agents.",
                "Let Cons(ai, aj) be a transitive consistency property.",
                "Then any protocol and strategies satisfying properties CONS, SOLVE, FOCUS, COMM and REQU guarantees that the system will converge towards global consistency.",
                "Proof.",
                "For the sake of contradiction, let us assume ∃I, J ∈ [1, N] s.t. ∀t, ∃t0 > t, t.q. ¬Cons(aI , aJ , t0).",
                "Using the lemma, this implies that ∃t > t0 s.t. either n1(t ) > n1(t0) or n2(t ) > n2(t0).",
                "But we can apply the same reasoning taking t = t , which would give us t1 > t > t0 s.t. ¬Cons(aI , aJ , t1), which gives us t > t1 s.t. either n1(t ) > n1(t1) or n2(t ) > n2(t1).",
                "By successive iterations we can then construct a sequence t0, t1, ..., tn, which can be divided in two sub-sequences t0, t1, ...tn and t0 , t1 , ..., tn s.t. n1(t0) < n1(t1) < ... < n1(tn) and n2(t0 ) < n2(t1 ) < ... < n2(tn).",
                "One of these sub-sequences has to be infinite.",
                "However, n1(ti) and n2(ti ) are strictly growing, integer, and bounded, which implies that both are finite.",
                "Contradiction.",
                "What the previous result essentially shows is that, in a system where no agent will be isolated from the rest of the agents for ever, only very mild assumptions on the protocols and strategies used by agents suffice to guarantee convergence towards system consistency in a finite amount of time (although it might take very long).",
                "Unfortunately, in many critical situations, it will not be possible to assume this temporal connexity.",
                "As distributed approaches as the one advocated in this paper are precisely often presented as a good way to tackle problems of reliability or problems of dependence to a center that are of utmost importance in these critical applications, it is certainly interesting to further explore how such a system would behave when we relax this assumption. 5.",
                "EXPERIMENTAL STUDY This experiment involves agents trying to escape from a burning building.",
                "The environment is described as a spatial grid with a set of walls and (thankfully) some exits.",
                "Time and space are considered discrete.",
                "Time is divided in rounds.",
                "Agents are localised by their position on the spatial grid.",
                "These agents can move and communicate with other agents.",
                "In a round, an agent can move of one cell in any of the four cardinal directions, provided it is not blocked by a wall.",
                "In this application, agents communicate with any other agent (but, recall, a single one) given that this agent is in view, and that they have not yet exchanged their current favoured hypothesis.",
                "Suddenly, a fire erupts in these premises.",
                "From this moment, the fire propagates.",
                "Each round, for each cases where there is fire, the fire propagates in the four directions.",
                "However, the fire cannot propagate through a wall.",
                "If the fire propagates in a case where an agent is positioned, that agent burns and is considered dead.",
                "It can of course no longer move nor communicate.",
                "If an agent gets to an exit, it is considered saved, and can no longer be burned.",
                "Agents know the environment and the rules governing the dynamics of this environment, that is, they know the map as well as the rules of fire propagation previously described.",
                "They also locally perceive this environment, but cannot see further than 3 cases away, in any direction.",
                "Walls also block the line of view, preventing agents from seeing behind them.",
                "Within their sight, they can see other agents and whether or not the cases they see are on fire.",
                "All these perceptions are memorised.",
                "We now show how this instantiates the abstract framework presented the paper. • O = {Fire(x, y, t), NoFire(x, y, t), Agent(ai, x, y, t)} Observations can then be positive (o ∈ P(O) iff ∃h ∈ H s.t. h |= o) or negative (o ∈ N(O) iff ∃h ∈ H s.t. h |= ¬o). • H={FireOrigin(x1, y1, t1)∧...∧FireOrigin(xl, yl, tl)} Hypotheses are conjunctions of FireOrigins. • Cons(h, O) consistency relation satisfies: - coherence : ∀o ∈ N(O), h |= ¬o. - completeness : ∀o ∈ P(O), h |= o. - minimality : For all h ∈ H, if h is coherent and complete for O, then h is prefered to h according to the preference relation (h ≤p h ).2 2 Selects first the minimal number of origins, then the most recent (least preemptive strategy [6]), then uses some arbitrary fixed ranking to discriminate ex-aequo.",
                "The resulting relation is a total order, hence minimality implies that there will be a single h s.t.Cons(O, h) for a given O.",
                "This in turn means that MCons(ai, aj) iff Cons(ai), Cons(aj), and hi = hj.",
                "This relation is then transitive and symmetric. 1002 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) • Eh takes O as argument and returns min≤p of the coherent and complete hypothesis for O 5.1 Experimental Evaluation We will classically (see e.g. [3, 4]) assess the effectiveness and efficiency of different interaction protocols.",
                "Effectiveness of a protocol The proportion of agents surviving the fire over the initial number of agents involved in the experiment will determine the effectiveness of a given protocol.",
                "If this value is high, the protocol has been effective to propagate the information and/or for the agents to refine their hypotheses and determine the best way to the exit.",
                "Efficiency of a protocol Typically, the use of supporting information will involve a communication overhead.",
                "We will assume here that the efficiency of a given protocol is characterised by the data flow induced by this protocol.",
                "In this paper we will only discuss this aspect wrt. local protocols.",
                "The main measure that we shall then use here is the mean total size of messages that are exchanged by agents per exchange (hence taking into account both the number of messages and the actual size of the messages, because it could be that messages happen to be very big, containing e.g. a large number of observations, which could counter-balance a low number of messages). 5.2 Experimental Settings The chosen experimental settings are the following: • Environmental topology- Performances of information propagation are highly constrained by the environment topology.",
                "The perception skills of the agents depend on the openness of the environment.",
                "With a large number of walls the perceptions of agents are limited, and also the number of possible inter-agent communications, whereas an open environment will provide optimal possibilities of perception and information propagation.",
                "Thus, we propose a topological index (see below) as a common basis to charaterize the environments (maps) used during experimentations.",
                "The topological index (TI) is the ratio of the number of cells that can be perceived by agents summed up from all possible positions, divided by the number of cells that would be perceived from the same positions but without any walls. (The closer to 1, the more open the environment).",
                "We shall also use two additional, more classical [10], measures: the characteristic path length3 (CPL) and the clustering coefficient4 (CC). • Number of agents- The propagation of information also depends on the initial number of agents involved during an experimentation.",
                "For instance, the more agents, the more potential communications there is.",
                "This means that there will be more potential for propagation, but also that the bilateral exchange restriction will be more crucial. 3 The CPL is the median of the means of the shortest path lengths connecting each node to all other nodes. 4 characterising the isolation degree of a region of an environment in terms of acessibility (number of roads still usable to reach this region).",
                "Map T.I. (%) C.P.L.",
                "C.C. 69-1 69,23 4,5 0,69 69-2 68,88 4,38 0,65 69-3 69,80 4,25 0,67 53-1 53,19 5,6 0,59 53-2 53,53 6,38 0,54 53-3 53,92 6,08 0,61 38-1 38,56 8,19 0,50 38-2 38,56 7,3 0,50 38-3 38,23 8,13 0,50 Table 1: Topological Characteristics of the Maps • Initial positions of the agents- Initial positions of the agents have a significant influence on the overall behavior of an instance of our system: being close from an exit will (in general) ease the escape. 5.3 Experimental environments We choose to realize experiments on three very different topological indexes (69% for open environments, 53% for mixed environments, and 38% for labyrinth-like environments).",
                "Figure 2: Two maps (left: TI=69%, right TI=38%) We designed three different maps for each index (Fig. 2 shows two of them), containing the same maximum number of agents (36 agents max.) with a maximum density of one agent per cell, the same number of exits and a similar fire origin (e.g. starting time and position).",
                "The three differents maps of a given index are designed as follows.",
                "The first map is a model of an existing building floor.",
                "The second map has the same enclosure, exits and fire origin as the first one, but the number and location of walls are different (wall locations are designed by an heuristic which randomly creates walls on the spatial grid such that no fully closed rooms are created and that no exit is closed).",
                "The third map is characterised by geometrical enclosure in wich walls location is also designed with the aforementioned heuristic.",
                "Table 1 summarizes the different topological measures characterizing these different maps.",
                "It is worth pointing out that the values confirm the relevance of TI (maps with a high TI have a low CPL and a high CC.",
                "However the CPL and CC allows to further refine the difference between the maps, e.g. between 53-1 and 53-2). 5.4 Experimental Results For each triple of maps defined as above we conduct the same experiments.",
                "In each experiment, the society differs in terms of its initial proportion of involved agents, from 1% to 100%.",
                "This initial proportion represents the percentage of involved agents with regards to the possible maximum number of agents.",
                "For each map and each initial proportion, The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 1003 we select randomly 100 different initial agents locations.",
                "For each of those different locations we execute the system one time for each different interaction protocol.",
                "Effectiveness of Communication and Argumentation The first experiment that we set up aims at testing how effective is hypotheses exchange (HE), and in particular how the topological aspects will affect this effectiveness.",
                "In order to do so, we have computed the ratio of improvement offered by that protocol over a situation where agents could simply not communicate (no comm).",
                "To get further insights as to what extent the hypotheses exchange was really crucial, we also tested a much less elaborated protocol consisting of mere observation exchanges (OE).",
                "More precisely, this protocol requires that each agent stores any unexpected observation that it perceives, and agents simply exchange their respective lists of observations when they discuss.",
                "In this case, the local protocol is different (note in particular that it does not guarantee mutual consistency), but the global protocol remains the same (at the only exception that agents motivation to communicate is to synchronise their list of observations, not their hypothesis).",
                "If this protocol is at best as effective as HE, it has the advantage of being more efficient (this is obvious wrt the number of messages which will be limited to 2, less straightforward as far as the size of messages is concerned, but the rough observation that the exchange of observations can be viewed as a flat version of the challenge is helpful to see this).",
                "The results of these experiments are reported in Fig. 3.",
                "Figure 3: Comparative effectiveness ratio gain of protocols when the proportion of agents augments The first observation that needs to be made is that communication improves the effectiveness of the process, and this ratio increases as the number of agents grows in the system.",
                "The second lesson that we learn here is that closeness relatively makes communication more effective over non communication.",
                "Maps exhibiting a T.I. of 38% are constantly above the two others, and 53% are still slightly but significantly better than 69%.",
                "However, these curves also suggest, perhaps surprisingly, that HE outperforms OE in precisely those situations where the ratio gain is less important (the only noticeable difference occurs for rather open maps where T.I. is 69%).",
                "This may be explained as follows: when a map is open, agents have many potential explanation candidates, and argumentation becomes useful to discriminate between those.",
                "When a map is labyrinth-like, there are fewer possible explanations to an unexpected event.",
                "Importance of the Global Protocol The second set of experiments seeks to evaluate the importance of the design of the global protocol.",
                "We tested our protocol against a local broadcast (LB) protocol.",
                "Local broadcast means that all the neighbours agents perceived by an agent will be involved in a communication with that agent in a given round -we alleviate the constraint of a single communication by agent.",
                "This gives us a rough upper bound upon the possible ratio gain in the system (for a given local protocol).",
                "Again, we evaluated the ratio gain induced by that LB over our classical HE, for the three different classes of maps.",
                "The results are reported in Fig. 4.",
                "Figure 4: Ratio gain of local broadcast over hypotheses exchange Note to begin with that the ratio gain is 0 when the proportion of agents is 5%, which is easily explained by the fact that it corresponds to situations involving only two agents.",
                "We first observe that all classes of maps witness a ratio gain increasing when the proportion of agents augments: the gain reaches 10 to 20%, depending on the class of maps considered.",
                "If one compares this with the improvement reported in the previous experiment, it appears to be of the same magnitude.",
                "This illustrates that the design of the global protocol cannot be ignored, especially when the proportion of agents is high.",
                "However, we also note that the effectiveness ratio gain curves have very different shapes in both cases: the gain induced by the accuracy of the local protocol increases very quickly with the proportion of agents, while the curve is really smooth for the global one.",
                "Now let us observe more carefully the results reported here: the curve corresponding to a TI of 53% is above that corresponding to 38%.",
                "This is so because the more open a map, the more opportunities to communicate with more than one agent (and hence benefits from broadcast).",
                "However, we also observe that curve for 69% is below that for 53%.",
                "This is explained as follows: in the case of 69%, the potential gain to be made in terms of surviving agents is much lower, because our protocols already give rather efficient outcomes anyway (quickly reaching 90%, see Fig. 3).",
                "A simple rule of thumb could be that when the number of agents is small, special attention should be put on the local 1004 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) protocol, whereas when that number is large, one should carefully design the global one (unless the map is so open that the protocol is already almost optimally efficient).",
                "Efficiency of the Protocols The final experiment reported here is concerned with the analysis of the efficiency of the protocols.",
                "We analysis here the mean size of the totality of the messages that are exchanged by agents (mean size of exchanges, for short) using the following protocols: HE, OE, and two variant protocols.",
                "The first one is an intermediary restricted hypotheses exchange protocol (RHE).",
                "RHE is as follows: it does not involve any challenge nor counter-propose, which means that agents cannot switch their role during the protocol (this differs from RE in that respect).",
                "In short, RHE allows an agent to exhaust its partners criticism, and eventually this partner will come to adopt the agents hypothesis.",
                "Note that this means that the autonomy of the agent is not preserved here (as an agent will essentially accept any hypothesis it cannot undermine), with the hope that the gain in efficiency will be significant enough to compensate a loss in effectiveness.",
                "The second variant protocol is a complete observation exchange protocol (COE).",
                "COE uses the same principles as OE, but includes in addition all critical negative examples (nofire) in the exchange (thus giving all examples used as arguments by the hypotheses exchanges protocol), hence improving effectiveness.",
                "Results for map 69-1 are shown on Fig. 5.",
                "Figure 5: Mean size of exchanges First we can observe the fact that the ordering of the protocols, from the least efficient to the most efficient, is COE, HE, RHE and then OE.",
                "HE being more efficient than COE proves that the argumentation process gains efficiency by selecting when it is needed to provide negative example, which have less impact that positive ones in our specific testbed.",
                "However, by communicating hypotheses before eventually giving observation to support it (HE) instead of directly giving the most crucial observations (OE), the argumentation process doubles the size of data exchanges.",
                "It is the cost for ensuring consistency at the end of the exchange (a property that OE does not support).",
                "Also significant is the fact the the mean size of exchanges is slightly higher when the number of agents is small.",
                "This is explained by the fact that in these cases only a very few agents have relevant informations in their possession, and that they will need to communicate a lot in order to come up with a common view of the situation.",
                "When the number of agents increases, this knowledge is distributed over more agents which need shorter discussions to get to mutual consistency.",
                "As a consequence, the relative gain in efficiency of using RHE appears to be better when the number of agents is small: when it is high, they will hardly argue anyway.",
                "Finally, it is worth noticing that the standard deviation for these experiments is rather high, which means that the conversation do not converge to any stereotypic pattern. 6.",
                "CONCLUSION This paper has investigated the properties of a multiagent system where each (distributed) agent locally perceives its environment, and tries to reach consistency with other agents despite severe communication restrictions.",
                "In particular we have exhibited conditions allowing convergence, and experimentally investigated a typical situation where those conditions cannot hold.",
                "There are many possible extensions to this work, the first being to further investigate the properties of different global protocols belonging to the class we identified, and their influence on the outcome.",
                "There are in particular many heuristics, highly dependent on the context of the study, that could intuitively yield interesting results (in our study, selecting the recipient on the basis of what can be inferred from his observed actions could be such a heuristic).",
                "One obvious candidate for longer term issues concern the relaxation of the assumption of perfect sensing. 7.",
                "REFERENCES [1] G. Bourgne, N. Maudet, and S. Pinson.",
                "When agents communicate hypotheses in critical situations.",
                "In Proceedings of DALT-2006, May 2006. [2] P. Harvey, C. F. Chang, and A. Ghose.",
                "Support-based distributed search: a new approach for multiagent constraint processing.",
                "In Proceedings of AAMAS06, 2006. [3] H. Jung and M. Tambe.",
                "Argumentation as distributed constraint satisfaction: Applications and results.",
                "In Proceedings of AGENTS01, 2001. [4] N. C. Karunatillake and N. R. Jennings.",
                "Is it worth arguing?",
                "In Proceedings of ArgMAS 2004, 2004. [5] S. Onta˜n´on and E. Plaza.",
                "Arguments and counterexamples in case-based joint deliberation.",
                "In Proceedings of ArgMAS-2006, May 2006. [6] D. Poole.",
                "Explanation and prediction: An architecture for default and abductive reasoning.",
                "Computational Intelligence, 5(2):97-110, 1989. [7] I. Rahwan, S. D. Ramchurn, N. R. Jennings, P. McBurney, S. Parsons, and L. Sonenberg.",
                "Argumention-based negotiation.",
                "The Knowledge Engineering Review, 4(18):345-375, 2003. [8] N. Roos, A. ten Tije, and C. Witteveen.",
                "A protocol for multi-agent diagnosis with spatially distributed knowledge.",
                "In Proceedings of AAMAS03, 2003. [9] N. Roos, A. ten Tije, and C. Witteveen.",
                "Reaching diagnostic agreement in multiagent diagnosis.",
                "In Proceedings of AAMAS04, 2004. [10] T. Takahashi, Y. Kaneda, and N. Ito.",
                "Preliminary study - using robocuprescue simulations for disasters prevention.",
                "In Proceedings of SRMED2004, 2004.",
                "The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 1005"
            ],
            "original_annotated_samples": [
                "A system involves a <br>bounded perception</br> for agents iff ∃n0 s.t. ∀t| ∪N i=1 Oi| ≤ n0. (That is, the number of observations to be made by the agents in the system is not infinite.)"
            ],
            "translated_annotated_samples": [
                "Un sistema implica una <br>percepción limitada</br> para los agentes si y solo si existe un n0 tal que para todo t, la unión de N observaciones realizadas por los agentes es menor o igual a n0. (Es decir, el número de observaciones a realizar por los agentes en el sistema no es infinito.)"
            ],
            "translated_text": "Refinamiento de hipótesis bajo restricciones de comunicación topológica ∗ Gauvain Bourgne, Gael Hette, Nicolas Maudet y Suzanne Pinson LAMSADE, Univ. Investigamos las propiedades de un sistema multiagente donde cada agente (distribuido) percibe localmente su entorno. Tras la percepción de un evento inesperado, cada agente calcula localmente su hipótesis favorita e intenta propagarla a otros agentes, intercambiando hipótesis y argumentos de apoyo (observaciones). Sin embargo, también asumimos que las oportunidades de comunicación están severamente limitadas y cambian dinámicamente. En este artículo, investigamos principalmente la convergencia de dichos sistemas hacia la consistencia global. Primero demostramos que (para una amplia clase de protocolos que definiremos), las restricciones de comunicación inducidas por la topología no impedirán la convergencia del sistema, bajo la condición de que la dinámica del sistema garantice que ningún agente quedará aislado para siempre, y que los agentes tengan tiempo ilimitado para la computación y el intercambio de argumentos. Dado que esta suposición no se puede hacer en la mayoría de las situaciones, establecimos un marco experimental con el objetivo de comparar la eficiencia y efectividad relativa de diferentes protocolos de interacción para el intercambio de hipótesis. Estudiamos una situación crítica que implica a varios agentes que intentan escapar de un edificio en llamas. Los resultados reportados aquí proporcionan algunas ideas sobre el diseño de un protocolo óptimo para el refinamiento de hipótesis en este contexto. Categorías y Descriptores de Asignaturas I.2.11 [Inteligencia Artificial]: Inteligencia Artificial Distribuida-Sistemas Multiagente Términos Generales Teoría, Experimentación 1. INTRODUCCIÓN Consideramos un sistema multiagente donde cada agente (distribuido) percibe localmente su entorno, y asumimos que ocurre un evento inesperado en ese sistema. Si cada agente calcula solo localmente su hipótesis preferida, es natural asumir que los agentes buscarán coordinar y refinar sus hipótesis confrontando sus observaciones con otros agentes. Si, además, las oportunidades de comunicación están severamente limitadas (por ejemplo, los agentes solo pueden comunicarse cuando están lo suficientemente cerca de otro agente) y cambian dinámicamente (por ejemplo, los agentes pueden cambiar sus ubicaciones), se vuelve crucial diseñar cuidadosamente protocolos que permitan a los agentes converger hacia algún estado deseado de consistencia global. En este documento presentamos algunas condiciones suficientes sobre la dinámica del sistema y sobre las estructuras de protocolo/estrategia que permiten garantizar esa propiedad, y estudiamos experimentalmente algunos contextos donde (algunas de) estas suposiciones se relajan. Si bien los problemas de diagnóstico son uno de los clásicos venerables en la tradición de la IA, sus contrapartes multiagentes han atraído atención mucho más recientemente. Roos y sus colegas [8, 9] en particular estudian una situación en la que un número de entidades distribuidas intentan llegar a un diagnóstico global satisfactorio de todo el sistema. Ellos muestran en particular que el número de mensajes necesarios para establecer este diagnóstico global está destinado a ser prohibitivo, a menos que la comunicación se mejore con algún protocolo adecuado. Sin embargo, no imponen restricciones a las opciones de comunicación de los agentes, ni asumen que el sistema es dinámico. Los beneficios de mejorar la comunicación con información de apoyo para hacer que la convergencia a un estado global deseado de un sistema sea más eficiente, a menudo se ha planteado en la literatura. Esta es, por ejemplo, una de las ideas principales que subyacen al enfoque de negociación basado en argumentos [7], donde el estado deseado es un compromiso entre agentes con preferencias conflictivas. Sin embargo, muchos de estos trabajos parten del supuesto de que este enfoque es beneficioso para comenzar y estudian los aspectos técnicos del problema (o en su lugar enfatizan otras ventajas de utilizar la argumentación). Excepciones notables son las obras de [3, 4, 2, 5], que estudiaron en contextos diferentes al nuestro la eficiencia de la argumentación. El resto del documento es el siguiente. La Sección 2 especifica los elementos básicos de nuestro modelo, y la Sección 3 continúa presentando los diferentes protocolos y estrategias utilizados por los agentes para intercambiar hipótesis y observaciones. Ponemos especial atención en enfatizar claramente las condiciones de la dinámica del sistema y los protocolos/estrategias que se explotarán en el resto del documento. La sección 4 detalla uno de los principales resultados del artículo, a saber, el hecho de que bajo las condiciones mencionadas, las restricciones que imponemos en la topología no impedirán la convergencia del sistema hacia la consistencia global, siempre y cuando ningún agente se pierda completamente para siempre en el sistema, y se permita un tiempo ilimitado para la computación y el intercambio de argumentos. Si bien las condiciones en los protocolos y estrategias son bastante suaves, también es claro que estos requisitos del sistema parecen mucho más problemáticos, incluso francamente poco realistas en situaciones críticas donde se abogan precisamente por enfoques distribuidos. Para obtener una imagen más clara de la situación inducida cuando el tiempo es un factor crítico, hemos establecido un marco experimental que presentamos y discutimos en la Sección 5. La situación crítica implica a varios agentes que intentan escapar de un edificio en llamas. Los resultados reportados aquí muestran que la efectividad del intercambio de argumentos depende crucialmente de la naturaleza del edificio, y proporcionan algunas ideas sobre el diseño de un protocolo óptimo para el refinamiento de hipótesis en este contexto. CONCEPTOS BÁSICOS Comenzamos definiendo los elementos básicos de nuestro sistema. Deje que O sea el conjunto (potencialmente infinito) de observaciones posibles. Suponemos que los sensores de nuestros agentes son perfectos, por lo tanto, las observaciones son seguras. Sea H el conjunto de hipótesis, incierto y revisable. Sea Cons(h, O) la relación de consistencia, una relación binaria entre una hipótesis h ∈ H y un conjunto de observaciones O ⊆ O. En la mayoría de los casos, Cons se referirá a la relación de consistencia clásica, sin embargo, podemos sobrecargar su significado y añadir algunas propiedades adicionales a esa relación (en cuyo caso lo mencionaremos). El entorno puede incluir cierta dinámica y cambiar con el transcurso del tiempo. Definimos a continuación secuencias de puntos temporales para tratar con ello: Definición 1 (Secuencia de puntos temporales). Una secuencia de puntos temporales t1, t2, . . . , tn de t es un conjunto ordenado de puntos temporales t1, t2, . . . , tn tal que t1 ≥ t y ∀i ∈ [1, n − 1], ti+1 ≥ ti. Tomamos un sistema poblado por n agentes a1, . . . , an. Cada agente se define como una tupla F, Oi, hi, donde: • F, el conjunto de hechos, conocimiento común a todos los agentes. • Oi ∈ 2O, el conjunto de observaciones realizadas por el agente hasta el momento. Suponemos una memoria perfecta, por lo tanto, este conjunto crece de forma monótona. • hi ∈ H, la hipótesis favorita del agente. Una noción clave que rige la formación de hipótesis es la de consistencia, definida a continuación: Definición 2 (Consistencia). Decimos que: • Un agente es consistente (Cons(ai)) si y solo si Cons(hi, Oi) (es decir, su hipótesis es consistente con su conjunto de observaciones). • Un agente ai es consistente con un agente compañero aj si y solo si Cons(ai) y Cons(hi, Oj) (es decir, este agente es consistente y su hipótesis puede explicar el conjunto de observaciones del otro agente). • Dos agentes ai y aj son mutuamente consistentes (MCons(ai, aj)) si y solo si Cons(ai, aj) y Cons(aj, ai). • Un sistema es consistente si y solo si para todo (i, j) ∈ [1, n]2 se cumple que MCons(ai, aj). Para garantizar su consistencia, cada agente está equipado con una maquinaria de razonamiento abstracto que llamaremos la función de explicación Eh. Esta función (determinística) toma un conjunto de observaciones y devuelve una única hipótesis preferida (2O → H). Suponemos que h = Eh(O) para ser consistente con O por definición de Eh, por lo que usar esta función en su conjunto de observaciones para determinar su hipótesis favorita es una forma segura para que el agente logre consistencia. Sin embargo, cabe destacar que una hipótesis no necesita ser generada por Eh para ser consistente con un conjunto de observaciones. Como ejemplo concreto de tal función, y una de las principales inspiraciones de este trabajo, se puede citar el sistema de razonamiento Theorist [6], siempre y cuando esté acoplado con un filtro que seleccione una teoría preferida entre las inicialmente seleccionadas por Theorist. También hay que tener en cuenta que hi solo puede ser modificado como consecuencia de la aplicación de Eh. Nos referimos a esto como la autonomía del agente: ningún otro agente puede imponer directamente una hipótesis dada a un agente. Como consecuencia, solo una nueva observación (ya sea una nueva percepción o una observación comunicada por otro agente) puede resultar en una modificación de su hipótesis preferida hi (pero no necesariamente, por supuesto). Finalmente definimos una propiedad del sistema que utilizaremos en el resto del artículo: Definición 3 (Percepciones Acotadas). Un sistema implica una <br>percepción limitada</br> para los agentes si y solo si existe un n0 tal que para todo t, la unión de N observaciones realizadas por los agentes es menor o igual a n0. (Es decir, el número de observaciones a realizar por los agentes en el sistema no es infinito.) Ahora necesitamos ver cómo evolucionarán e interactuarán estos agentes en su entorno. En nuestro contexto, los agentes evolucionan en un entorno dinámico, y asumimos clásicamente el siguiente ciclo del sistema: 1. Dinámica del entorno: el entorno evoluciona de acuerdo con las reglas definidas de la dinámica del sistema. 2. Paso de percepción: los agentes obtienen percepciones del entorno. Estas percepciones suelen ser parciales (por ejemplo, el agente solo puede ver una parte de un mapa). 3. Paso de razonamiento: los agentes comparan la percepción con las predicciones, buscan explicaciones para las diferencias (potenciales), refinan su hipótesis, y sacan nuevas conclusiones. 4. Paso de comunicación: los agentes pueden comunicar hipótesis y observaciones con otros agentes a través de un protocolo definido. Cualquier agente solo puede estar involucrado en una comunicación con otro agente en el paso 5. Paso de acción: los agentes realizan un razonamiento práctico utilizando los modelos obtenidos de los pasos anteriores y seleccionan una acción. Ellos pueden modificar el entorno ejecutándolo. La comunicación de los agentes estará aún más restringida por consideraciones topológicas. En un momento dado, un agente solo podrá comunicarse con un número de vecinos. Sus conexiones con estos otros agentes pueden The Sixth Intl. La Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) evoluciona con su situación en el entorno. Normalmente, un agente solo puede comunicarse con agentes que puede percibir, pero se podría imaginar la evolución de restricciones topológicas en la comunicación basadas en una red de comunicaciones entre agentes donde los enlaces no siempre están activos. En nuestro sistema, los agentes podrán comunicarse entre sí. Sin embargo, debido a las restricciones topológicas mencionadas anteriormente, no podrán comunicarse con ningún agente en ningún momento. Con quién puede comunicarse un agente se definirá dinámicamente (por ejemplo, esto puede ser consecuencia de que los agentes estén lo suficientemente cerca para ponerse en contacto). Denotaremos de forma abstracta por C(ai, aj, t) la propiedad de comunicación, es decir, el hecho de que los agentes ai y aj puedan comunicarse en el tiempo t (nota que se asume que esta relación es simétrica, pero por supuesto no transitiva). Ahora estamos en posición de definir dos propiedades esenciales de nuestro sistema. Definición 4 (Camino Temporal). Existe un camino de comunicación temporal en el horizonte tf (denotado Ltf (aI, aJ)) entre ai y aj si y solo si existe una secuencia de puntos temporales t1, t2, ..., tn desde tf y una secuencia de agentes k1, k2, ..., kn tal que (i) C(aI, ak1, t1), (ii) C(akn, aJ, tn+1), (iii) ∀i ∈ [1, n], C(aki, aki+1, ti). Intuitivamente, lo que esta propiedad dice es que es posible encontrar un camino temporal en el futuro que permitiría vincular al agente ai y aj a través de una secuencia de agentes intermedios. Ten en cuenta que los puntos temporales no necesariamente son sucesivos, y que la secuencia de agentes puede involucrar a los mismos agentes varias veces. Definición 5 (Conexidad Temporal). Un sistema es temporalmente conexo si y solo si ∀t ∀(i, j)∈[1, n]2 Lt(ai, aj). En resumen, un sistema temporalmente conexo garantiza que cualquier agente podrá comunicarse con cualquier otro agente, sin importar cuánto tiempo pueda llevar hacerlo, en cualquier momento. Dicho de otra manera, nunca sucede que un agente esté aislado para siempre de otro agente del sistema. A continuación discutiremos en detalle cómo la comunicación tiene lugar concretamente en nuestro sistema. Recuerda que en este documento, solo consideramos el caso de intercambios bilaterales (un agente solo puede hablar con otro agente) y también asumimos que cualquier agente solo puede participar en un intercambio en una ronda dada. 3. PROTOCOLOS Y ESTRATEGIAS En esta sección, discutimos los requisitos de los protocolos de interacción que rigen el intercambio de mensajes entre agentes, y proporcionamos algunos ejemplos de la implementación de dichos protocolos. Para aclarar la presentación, distinguimos dos niveles: el nivel local, que se ocupa de la regulación de los intercambios bilaterales; y el nivel global, que regula principalmente la forma en que los agentes pueden participar realmente en una conversación. En cada nivel, separamos lo que está especificado por el protocolo y lo que se deja a las estrategias de los agentes. Protocolos y estrategias locales Comenzamos inspeccionando los protocolos y estrategias locales que regularán la comunicación entre los agentes del sistema. Al limitarnos a la comunicación bilateral, estos protocolos simplemente implicarán a dos agentes. Dicho protocolo tendrá que cumplir con un requisito básico para ser satisfactorio: consistencia (CONS) - un protocolo local debe garantizar la consistencia mutua de los agentes al finalizar (lo que implica, por supuesto, la finalización). Figura 1: Un Protocolo de Intercambio de Hipótesis [1] Un ejemplo de dicho protocolo es el protocolo descrito en [1] que se muestra en la Fig. 1. Para ilustrar aún más cómo dicho protocolo puede ser utilizado por agentes, proporcionamos algunos detalles sobre una posible estrategia: al recibir una hipótesis h1 (proponer(h1) o contra-proponer(h1)) de a1, el agente a2 se encuentra en el estado 2 y tiene las siguientes respuestas posibles: contraejemplo (si el agente conoce un ejemplo que contradice la hipótesis, o no está explicado por esta hipótesis), desafío (si el agente carece de evidencia para aceptar esta hipótesis), contra-proponer (si el agente está de acuerdo con la hipótesis pero prefiere otra), o aceptar (si es tan buena como su hipótesis favorita). Esta estrategia garantiza, entre otras propiedades, la eventual consistencia lógica mutua de los agentes involucrados [1]. Protocolo global El protocolo global regula la forma en que se iniciarán los intercambios bilaterales entre agentes. En cada turno, los agentes enviarán simultáneamente una solicitud ponderada para comunicarse con otros agentes. Este peso es un valor que mide la disposición de los agentes para conversar con el agente objetivo (en la práctica, esto puede basarse en diferentes heurísticas, pero haremos algunas suposiciones sobre las estrategias de los agentes, ver más abajo). Enviar una solicitud de este tipo es una especie de compromiso condicional para el agente. Un agente que envía una solicitud ponderada se compromete a entablar una conversación con el objetivo si no recibe y acepta otra solicitud por sí mismo. Una vez que se hayan recibido todas las solicitudes, cada agente responde con un aceptar o un rechazar. Al responder con un aceptar, un agente se compromete plenamente a participar en la conversación con el remitente. Por lo tanto, solo puede enviar una aceptación en una ronda dada, ya que un agente solo puede participar en una conversación por paso de tiempo. Cuando se hayan recibido todas las respuestas, cada agente que reciba una aceptación puede iniciar una conversación utilizando el protocolo local o enviar una cancelación si ha aceptado otra solicitud. Al final de todos los intercambios bilaterales, los agentes involucrados en la conversación son descartados del protocolo. Entonces cada uno de los agentes restantes reenvía una solicitud y el proceso se repite hasta que no se envíen más solicitudes. Estrategia global Ahora definimos cuatro requisitos para las estrategias utilizadas por los agentes, dependiendo de su rol en el protocolo: dos se refieren al rol del solicitante (cómo decidir quién es el 1000 The Sixth Intl. La Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) ¿con qué agente desea comunicarse? Los otros dos con el rol de respondedor (¿cómo decidir qué solicitud de comunicación aceptar o no?). • Disposición para resolver inconsistencias (SOLVE): los agentes desean comunicarse con cualquier otro agente a menos que sepan que son mutuamente consistentes. • Enfoque en resolver inconsistencias (FOCUS): los agentes no solicitan comunicarse con un agente con el que saben que son mutuamente consistentes. • Disposición para comunicarse (COMM): los agentes no pueden rechazar una solicitud de comunicación ponderada, a menos que acaben de recibir o enviar una solicitud con un peso mayor. • Compromiso con la solicitud de comunicación (REQU): los agentes no pueden aceptar una solicitud de comunicación ponderada si ellos mismos han enviado una solicitud de comunicación con un peso mayor. Por lo tanto, no cancelarán su solicitud a menos que hayan recibido una solicitud comunicacional con mayor peso. Ahora la estructura del protocolo, junto con las propiedades COMM+REQU, garantizan que una solicitud solo puede ser rechazada si su agente objetivo se involucra en comunicación con otro agente. Supongamos de hecho que el agente ai quiere comunicarse con aj enviando una solicitud con peso w. COMM garantiza que un agente que reciba una solicitud ponderada aceptará esta comunicación, aceptará una comunicación con un peso mayor o esperará la respuesta a una solicitud con un peso mayor. Esto asegura que la solicitud con peso máximo será aceptada y no cancelada (ya que REQU asegura que un agente que envía una solicitud solo puede cancelarla si acepta otra solicitud con un peso mayor). Por lo tanto, al menos dos agentes participarán en una conversación por ronda del protocolo global. Como el protocolo asegura que ai puede reenviar su solicitud mientras aj no está ocupado en una conversación, llegará un momento en el que aj deberá participar en una conversación, ya sea con ai u otro agente. Estos requisitos se refieren al envío y aceptación de solicitudes, pero los agentes también necesitan alguna estrategia de atribución de peso. Describimos a continuación una estrategia altruista, utilizada en nuestros experimentos. Siendo cooperativo, un agente puede querer conocer más los deseos de comunicación de otros agentes para mejorar la asignación general de intercambios a los agentes. Se añade entonces un paso de solicitud de contexto al protocolo global. Antes de enviar su solicitud ponderada elegida, los agentes asignan un peso a todos los agentes con los que están dispuestos a comunicarse, de acuerdo con algunos factores internos. En el caso más simple, este peso será 1 para todos los agentes con los que el agente no esté seguro de ser mutuamente consistentes (garantizando SOLVE), sin considerar a otros agentes para la comunicación (garantizando FOCUS). El agente luego envía una solicitud de contexto a todos los agentes con los que se considera la comunicación. Esta solicitud también proporciona información sobre el remitente (lista de comunicaciones consideradas junto con su peso). Después de recibir todas las solicitudes de contexto, los agentes responderán con un rechazo si ya están ocupados en una conversación (en cuyo caso, el agente solicitante no considerará comunicarse con ellos en este turno), o con una información que brinde al solicitante información sobre las solicitudes que ha enviado y recibido. Cuando se hayan recibido todas las respuestas, cada agente puede calcular el peso de todas las solicitudes que le conciernen. Lo hace restando del peso de su solicitud el peso de todas las solicitudes relacionadas con él o su objetivo (es decir, el peso final de la solicitud de ai a aj es Wi,j = wi,j + wj,i - ( Σ k∈R(i)-{j} wi,k + Σ k∈S(i)-{j} wk,i + Σ k∈R(j)-{i} wj,k + Σ k∈S(j)-{i} wk,j) donde wi,j es el peso de la solicitud de ai a aj, R(i) es el conjunto de índices de agentes que han recibido una solicitud de ai y S(i) es el conjunto de índices de agentes que han enviado una solicitud a ai). Luego envía finalmente una solicitud ponderada a los agentes que maximizan este peso (o esperan una solicitud) según lo descrito en el protocolo global. 4. (CONDICIONAL) CONVERGENCIA HACIA LA COHERENCIA GLOBAL En esta sección mostraremos que los requisitos relacionados con los protocolos y estrategias recién discutidos serán suficientes para garantizar que el sistema eventualmente convergerá hacia la coherencia global, bajo ciertas condiciones. Primero demostramos que, si dos agentes no son mutuamente consistentes en algún momento, entonces necesariamente habrá un momento en el futuro en el que un agente aprenderá una nueva observación, ya sea porque es nueva para el sistema, o al aprenderla de otro agente. Lema 1. Sea S un sistema poblado por n agentes a1, a2, ..., an, temporalmente conectados e involucrando percepciones limitadas para estos agentes. Sea n1 la suma de las cardinalidades de la intersección de los conjuntos de observaciones emparejados. (n1 = P (i,j)∈[1,n]2 |Oi ∩ Oj|) Sea n2 la cardinalidad de la unión de todos los conjuntos de observaciones de los agentes. (n2 = | ∪N i=1 Oi|). Si ¬MCons(ai, aj) en el tiempo t0, necesariamente existe un tiempo t > t0 tal que ya sea n1 o n2 aumentarán. Prueba. Supongamos que exista un tiempo t0 y unos índices (i, j) tal que ¬MCons(ai, aj). Utilizaremos mt0 = P (k,l)∈[1,n]2 εComm(ak, al, t0) donde εComm(ak, al, t0) = 1 si ak y al han comunicado al menos una vez desde t0, y 0 en caso contrario. La conexidad temporal garantiza que existen t1, ..., tm+1 y k1, ..., km tal que. C(ai, ak1 , t1), C(akm , aj, tm+1), y ∀p ∈ [1, m], C(akp , akp+1 , tp). Claramente, si MCons(ai, ak1), MCons(akm, aj) y ∀p, MCons(akp, akp+1), tenemos MCons(ai, aj) lo cual contradice nuestra hipótesis (siendo MCons transitivo, MCons(ai, ak1)∧MCons(ak1, ak2) implica que MCons(ai, ak2) y así sucesivamente hasta MCons(ai, akm)∧MCons(akm, aj) lo cual implica MCons(ai, aj)). Al menos dos agentes son necesariamente inconsistentes (¬MCons(ai, ak1), o ¬MCons(akm, aj), o ∃p0 t.q. ¬MCons(akp0, akp0+1)). Que ak y al sean estos dos vecinos en un momento t > t0 1. La propiedad SOLVE asegura que ya sea ak o al enviará una solicitud de comunicación al otro agente en el tiempo t. Como se mostró anteriormente, esto a su vez garantiza que al menos uno de estos agentes estará involucrado en una comunicación. Entonces hay dos posibilidades: (caso i) ak y al se comunican en el tiempo t. En este caso, sabemos que ¬MCons(ak, al). Esto y la propiedad CONS aseguran que al menos uno de los agentes debe cambiar su 1. Estrictamente hablando, la transitividad de MCons solo asegura que ak y al son inconsistentes en un tiempo t ≥ t0 que puede ser diferente del tiempo t en el que pueden comunicarse. Pero si se vuelven consistentes entre t y t (o inconsistentes entre t y t), significa que al menos uno de ellos ha cambiado su hipótesis entre t y t, es decir, después de t0. Podemos entonces aplicar el razonamiento del caso iib. El Sexto Internacional. La Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 1001 hipótesis, lo cual a su vez, dado que los agentes son autónomos, implica al menos un intercambio de observación. Pero entonces |Ok ∩Ol| está destinado a aumentar: n1(t) > n1(t0). (caso ii) ak se comunica con ap en el tiempo t. Entonces tenemos de nuevo dos posibilidades: (caso iia) ak y ap no se comunicaron desde t0. Pero luego εComm(ak, ap, t0) tenía valor 0 y toma valor 1. Por lo tanto, mt0 aumenta. (caso iib) ak y ap se comunicaron en algún momento t0 > t0. La propiedad CONS del protocolo asegura que MCons(ak, ap) en ese momento. Ahora el hecho de que se comuniquen y se ENFOQUEN implica que al menos uno de ellos cambió su hipótesis en el ínterin. El hecho de que los agentes sean autónomos implica a su vez que una nueva observación (percibida o recibida de otro agente) necesariamente provocó este cambio. El último caso garantizaría la existencia de un tiempo t > t0 y un agente aq tal que |Op ∩ Oq| o |Ok ∩ Oq| aumenten en 1 en ese momento (lo que implica que n1(t) > n1(t0)). El caso anterior significa que el agente obtiene una nueva percepción en el tiempo t. Si esa observación era desconocida en el sistema antes, entonces n2(t) > n2(t0). Si algún agente aq ya conocía esta observación antes, entonces tanto Op ∩ Oq como Ok ∩ Oq aumentan en 1 en el tiempo t (lo que implica que n1(t) > n1(t0)). Por lo tanto, ¬MCons(ai, aj) en el tiempo t0 garantiza que, o bien: −∃t > t0 t.q. n1(t ) > n1(t0); o −∃t > t0 t.q. n2(t ) > n2(t0); o −∃t > t0 t.q. mt0 aumenta en 1 en el tiempo t. Al iterar el razonamiento con t (pero manteniendo t0 como la referencia de tiempo para mt0), podemos eliminar el tercer caso (mt0 es un entero y está limitado por n2, lo que significa que después de un máximo de n2 iteraciones, necesariamente estaremos en uno de los otros dos casos). Como resultado, hemos demostrado que si ¬MCons(ai, aj) en el tiempo t0, necesariamente habrá un tiempo t tal que ya sea n1 o n2 aumentarán. Teorema 1 (Consistencia global). Sea S un sistema poblado por n agentes a1, a2, ..., an, temporalmente conectados e involucrando percepciones limitadas para estos agentes. Sea Cons(ai, aj) una propiedad de consistencia transitiva. Entonces, cualquier protocolo y estrategias que cumplan con las propiedades CONS, SOLVE, FOCUS, COMM y REQU garantizan que el sistema convergerá hacia la consistencia global. Prueba. Por el bien de la contradicción, asumamos que ∃I, J ∈ [1, N] tal que ∀t, ∃t0 > t, tal que ¬Cons(aI , aJ , t0). Usando el lema, esto implica que ∃t > t0 tal que n1(t) > n1(t0) o n2(t) > n2(t0). Pero podemos aplicar el mismo razonamiento tomando t = t, lo que nos daría t1 > t > t0 tal que ¬Cons(aI , aJ , t1), lo que nos da t > t1 tal que n1(t) > n1(t1) o n2(t) > n2(t1). Mediante iteraciones sucesivas podemos construir una secuencia t0, t1, ..., tn, que puede dividirse en dos subsecuencias t0, t1, ...tn y t0, t1, ..., tn tal que n1(t0) < n1(t1) < ... < n1(tn) y n2(t0) < n2(t1) < ... < n2(tn). Una de estas subsecuencias tiene que ser infinita. Sin embargo, n1(ti) y n2(ti) son estrictamente crecientes, enteros y acotados, lo que implica que ambos son finitos. Contradicción. Lo que el resultado anterior muestra esencialmente es que, en un sistema donde ningún agente estará aislado del resto de los agentes para siempre, solo se necesitan suposiciones muy leves sobre los protocolos y estrategias utilizados por los agentes para garantizar la convergencia hacia la consistencia del sistema en una cantidad finita de tiempo (aunque podría llevar mucho tiempo). Desafortunadamente, en muchas situaciones críticas, no será posible asumir esta conexión temporal. Dado que enfoques distribuidos como el abogado en este documento suelen presentarse como una buena manera de abordar problemas de confiabilidad o problemas de dependencia de un centro que son de suma importancia en estas aplicaciones críticas, ciertamente resulta interesante explorar más a fondo cómo se comportaría un sistema de este tipo cuando relajamos esta suposición. ESTUDIO EXPERIMENTAL Este experimento implica agentes tratando de escapar de un edificio en llamas. El entorno se describe como una cuadrícula espacial con un conjunto de paredes y (afortunadamente) algunas salidas. El tiempo y el espacio se consideran discretos. El tiempo se divide en rondas. Los agentes se localizan por su posición en la cuadrícula espacial. Estos agentes pueden moverse y comunicarse con otros agentes. En una ronda, un agente puede moverse una celda en cualquiera de las cuatro direcciones cardinales, siempre y cuando no esté bloqueado por una pared. En esta aplicación, los agentes se comunican con cualquier otro agente (pero, recuerda, solo uno) siempre y cuando este agente esté a la vista y aún no hayan intercambiado su hipótesis actual favorita. De repente, se desata un incendio en estas instalaciones. A partir de este momento, el fuego se propaga. En cada ronda, en cada caso donde haya fuego, el fuego se propaga en las cuatro direcciones. Sin embargo, el fuego no puede propagarse a través de una pared. Si el fuego se propaga en un caso donde un agente está posicionado, ese agente se quema y se considera muerto. Por supuesto, ya no puede moverse ni comunicarse. Si un agente llega a una salida, se considera que está a salvo y ya no puede ser quemado. Los agentes conocen el entorno y las reglas que rigen la dinámica de este entorno, es decir, conocen el mapa así como las reglas de propagación del fuego previamente descritas. También perciben este entorno localmente, pero no pueden ver más allá de 3 casos en cualquier dirección. Las paredes también bloquean la línea de visión, impidiendo que los agentes vean detrás de ellas. Dentro de su campo de visión, pueden ver a otros agentes y si los casos que ven están en llamas. Todas estas percepciones están memorizadas. Mostramos ahora cómo se instancia el marco abstracto presentado en el documento. • O = {Fire(x, y, t), NoFire(x, y, t), Agent(ai, x, y, t)} Las observaciones pueden ser positivas (o ∈ P(O) si ∃h ∈ H tal que h |= o) o negativas (o ∈ N(O) si ∃h ∈ H tal que h |= ¬o). • H={FireOrigin(x1, y1, t1)∧...∧FireOrigin(xl, yl, tl)} Las hipótesis son conjunciones de Orígenes de Fuego. • La relación de consistencia Cons(h, O) satisface: - coherencia: ∀o ∈ N(O), h |= ¬o. - completitud: ∀o ∈ P(O), h |= o. - minimalidad: Para todo h ∈ H, si h es coherente y completo para O, entonces h es preferido a h de acuerdo con la relación de preferencia (h ≤p h). Selecciona primero el número mínimo de orígenes, luego el más reciente (estrategia menos preemptiva [6]), y luego utiliza un ranking fijo arbitrario para discriminar ex-aequo. La relación resultante es un orden total, por lo tanto, la minimalidad implica que habrá un único h tal que Cons(O, h) para un O dado. Esto a su vez significa que MCons(ai, aj) si y solo si Cons(ai), Cons(aj) y hi = hj. Esta relación es entonces transitiva y simétrica. 1002 El Sexto Internacional. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) • Eh toma O como argumento y devuelve min≤p de la hipótesis coherente y completa para O 5.1 Evaluación Experimental Clásicamente evaluaremos la efectividad y eficiencia de diferentes protocolos de interacción (ver, por ejemplo, [3, 4]). La efectividad de un protocolo se determinará por la proporción de agentes que sobreviven al incendio respecto al número inicial de agentes involucrados en el experimento. Si este valor es alto, el protocolo ha sido efectivo para propagar la información y/o para que los agentes refinen sus hipótesis y determinen la mejor manera de salir. Eficiencia de un protocolo. Por lo general, el uso de información de apoyo implicará una sobrecarga de comunicación. Aquí asumiremos que la eficiencia de un protocolo dado está caracterizada por el flujo de datos inducido por este protocolo. En este documento solo discutiremos este aspecto con respecto a los protocolos locales. La medida principal que utilizaremos aquí es el tamaño total promedio de los mensajes intercambiados por los agentes por intercambio (teniendo en cuenta tanto el número de mensajes como el tamaño real de los mensajes, ya que podría ser que los mensajes resulten ser muy grandes, conteniendo por ejemplo un gran número de observaciones, lo que podría contrarrestar un bajo número de mensajes). 5.2 Configuraciones Experimentales Las configuraciones experimentales elegidas son las siguientes: • Topología ambiental: El rendimiento de la propagación de la información está altamente condicionado por la topología del entorno. Las habilidades de percepción de los agentes dependen de la apertura del entorno. Con un gran número de paredes, las percepciones de los agentes están limitadas, al igual que el número de posibles comunicaciones entre agentes, mientras que un entorno abierto proporcionará posibilidades óptimas de percepción y propagación de información. Por lo tanto, proponemos un índice topológico (ver abajo) como base común para caracterizar los entornos (mapas) utilizados durante las experimentaciones. El índice topológico (TI) es la proporción entre el número de celdas que pueden ser percibidas por los agentes sumadas desde todas las posiciones posibles, dividido por el número de celdas que serían percibidas desde las mismas posiciones pero sin paredes. (Cuanto más cercano a 1, más abierto es el entorno). También utilizaremos dos medidas adicionales, más clásicas [10]: la longitud del camino característico (CPL) y el coeficiente de agrupamiento (CC). • Número de agentes: la propagación de la información también depende del número inicial de agentes involucrados durante una experimentación. Por ejemplo, cuantos más agentes haya, más potenciales comunicaciones existen. Esto significa que habrá más potencial de propagación, pero también que la restricción de intercambio bilateral será más crucial. 3 El CPL es la mediana de las medias de las longitudes de los caminos más cortos que conectan cada nodo con todos los demás nodos. 4 caracterizando el grado de aislamiento de una región de un entorno en términos de accesibilidad (número de caminos aún utilizables para llegar a esta región). Mapa T.I. (%) C.P.L. C.C. 69-1 69,23 4,5 0,69 69-2 68,88 4,38 0,65 69-3 69,80 4,25 0,67 53-1 53,19 5,6 0,59 53-2 53,53 6,38 0,54 53-3 53,92 6,08 0,61 38-1 38,56 8,19 0,50 38-2 38,56 7,3 0,50 38-3 38,23 8,13 0,50 Tabla 1: Características Topológicas de los Mapas • Posiciones iniciales de los agentes- Las posiciones iniciales de los agentes tienen una influencia significativa en el comportamiento general de una instancia de nuestro sistema: estar cerca de una salida facilitará (en general) la escapatoria. 5.3 Entornos experimentales Elegimos realizar experimentos en tres índices topológicos muy diferentes (69% para entornos abiertos, 53% para entornos mixtos y 38% para entornos tipo laberinto). Figura 2: Dos mapas (izquierda: IT=69%, derecha IT=38%) Diseñamos tres mapas diferentes para cada índice (la Fig. 2 muestra dos de ellos), conteniendo el mismo número máximo de agentes (máximo 36 agentes) con una densidad máxima de un agente por celda, el mismo número de salidas y un origen de incendio similar (por ejemplo, tiempo y posición de inicio). Los tres mapas diferentes de un índice dado están diseñados de la siguiente manera. El primer plano es un modelo de un piso de un edificio existente. El segundo mapa tiene el mismo perímetro, salidas y origen del fuego que el primero, pero la cantidad y ubicación de las paredes son diferentes (las ubicaciones de las paredes son diseñadas por una heurística que crea paredes de forma aleatoria en la cuadrícula espacial de manera que no se creen habitaciones completamente cerradas y que ninguna salida quede bloqueada). El tercer mapa se caracteriza por un recinto geométrico en el que la ubicación de las paredes también está diseñada con la heurística mencionada anteriormente. La Tabla 1 resume las diferentes medidas topológicas que caracterizan estos mapas diferentes. Vale la pena señalar que los valores confirman la relevancia de TI (los mapas con un alto TI tienen un bajo CPL y un alto CC). Sin embargo, el CPL y el CC permiten refinar aún más la diferencia entre los mapas, por ejemplo, entre 53-1 y 53-2). 5.4 Resultados Experimentales Para cada trío de mapas definidos como se mencionó anteriormente, llevamos a cabo los mismos experimentos. En cada experimento, la sociedad difiere en cuanto a su proporción inicial de agentes involucrados, desde el 1% hasta el 100%. Esta proporción inicial representa el porcentaje de agentes involucrados con respecto al número máximo posible de agentes. Para cada mapa y cada proporción inicial, la Sexta Internacional. En la Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) seleccionamos aleatoriamente 100 ubicaciones iniciales de agentes diferentes. Para cada una de esas ubicaciones diferentes ejecutamos el sistema una vez para cada protocolo de interacción diferente. La efectividad de la comunicación y argumentación El primer experimento que hemos establecido tiene como objetivo probar cuán efectivo es el intercambio de hipótesis (IH), y en particular cómo los aspectos topológicos afectarán esta efectividad. Para hacerlo, hemos calculado la proporción de mejora ofrecida por ese protocolo sobre una situación en la que los agentes simplemente no podían comunicarse (sin comunicación). Para obtener más información sobre en qué medida el intercambio de hipótesis fue realmente crucial, también probamos un protocolo mucho menos elaborado que consistía en intercambios de observaciones simples (OE). Más precisamente, este protocolo requiere que cada agente almacene cualquier observación inesperada que perciba, y los agentes simplemente intercambian sus respectivas listas de observaciones cuando discuten. En este caso, el protocolo local es diferente (nota en particular que no garantiza consistencia mutua), pero el protocolo global permanece igual (con la única excepción de que la motivación de los agentes para comunicarse es sincronizar su lista de observaciones, no sus hipótesis). Si este protocolo es como máximo tan efectivo como HE, tiene la ventaja de ser más eficiente (esto es obvio en cuanto al número de mensajes, que se limitará a 2, menos directo en lo que respecta al tamaño de los mensajes, pero la observación general de que el intercambio de observaciones se puede ver como una versión simplificada del desafío es útil para ver esto). Los resultados de estos experimentos se informan en la Figura 3. Figura 3: Ganancia de la proporción de efectividad comparativa de los protocolos cuando la proporción de agentes aumenta. La primera observación que debe hacerse es que la comunicación mejora la efectividad del proceso, y esta proporción aumenta a medida que el número de agentes crece en el sistema. La segunda lección que aprendemos aquí es que la cercanía relativamente hace que la comunicación sea más efectiva que la falta de comunicación. Los mapas que muestran un T.I. del 38% están constantemente por encima de los otros dos, y el 53% sigue siendo ligeramente pero significativamente mejor que el 69%. Sin embargo, estas curvas también sugieren, quizás sorprendentemente, que HE supera a OE precisamente en aquellas situaciones donde la ganancia de la relación es menos importante (la única diferencia notable ocurre en mapas bastante abiertos donde T.I. es del 69%). Esto se puede explicar de la siguiente manera: cuando un mapa está abierto, los agentes tienen muchos posibles candidatos de explicación, y la argumentación se vuelve útil para discriminar entre ellos. Cuando un mapa es laberíntico, hay menos posibles explicaciones para un evento inesperado. Importancia del Protocolo Global El segundo conjunto de experimentos busca evaluar la importancia del diseño del protocolo global. Probamos nuestro protocolo contra un protocolo de difusión local (LB). La difusión local significa que todos los agentes vecinos percibidos por un agente estarán involucrados en una comunicación con ese agente en una ronda dada, aliviando la restricción de una sola comunicación por agente. Esto nos proporciona un límite superior aproximado sobre la posible ganancia de ratio en el sistema (para un protocolo local dado). Nuevamente, evaluamos la ganancia de la relación inducida por ese LB sobre nuestro HE clásico, para las tres clases diferentes de mapas. Los resultados se informan en la Figura 4. Figura 4: Ganancia de la proporción de transmisión local sobre el intercambio de hipótesis. Tenga en cuenta que la ganancia de la proporción es 0 cuando la proporción de agentes es del 5%, lo cual se explica fácilmente por el hecho de que corresponde a situaciones que involucran solo a dos agentes. Primero observamos que todas las clases de mapas muestran un aumento en la ganancia de la proporción a medida que aumenta el número de agentes: la ganancia alcanza entre el 10 y el 20%, dependiendo de la clase de mapas considerada. Si se compara esto con la mejora reportada en el experimento anterior, parece ser de la misma magnitud. Esto ilustra que el diseño del protocolo global no puede ser ignorado, especialmente cuando la proporción de agentes es alta. Sin embargo, también observamos que las curvas de ganancia de la proporción de efectividad tienen formas muy diferentes en ambos casos: la ganancia inducida por la precisión del protocolo local aumenta muy rápidamente con la proporción de agentes, mientras que la curva es muy suave para el global. Ahora observemos con más cuidado los resultados reportados aquí: la curva correspondiente a una TI del 53% está por encima de la correspondiente al 38%. Esto se debe a que cuanto más abierta sea un mapa, más oportunidades hay de comunicarse con más de un agente (y por lo tanto beneficiarse de la difusión). Sin embargo, también observamos que la curva para el 69% está por debajo de la del 53%. Esto se explica de la siguiente manera: en el caso del 69%, la ganancia potencial en términos de agentes sobrevivientes es mucho menor, porque nuestros protocolos ya ofrecen resultados bastante eficientes de todos modos (alcanzando rápidamente el 90%, ver Fig. 3). Una regla general podría ser que cuando el número de agentes es pequeño, se debe prestar especial atención al local 1004 de la Sexta Internacional. En el caso de que el número de agentes sea pequeño, uno puede utilizar el protocolo de la Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07), mientras que cuando ese número es grande, se debe diseñar cuidadosamente uno global (a menos que el mapa sea tan abierto que el protocolo ya sea casi óptimamente eficiente). La eficiencia de los protocolos. El experimento final reportado aquí se centra en el análisis de la eficiencia de los protocolos. Aquí analizamos el tamaño medio de la totalidad de los mensajes que son intercambiados por agentes (tamaño medio de intercambios, en resumen) utilizando los siguientes protocolos: HE, OE y dos protocolos variantes. El primero es un protocolo de intercambio de hipótesis restringidas (RHE) intermediario. RHE es el siguiente: no implica ningún desafío ni contraoferta, lo que significa que los agentes no pueden cambiar su rol durante el protocolo (esto difiere de RE en ese aspecto). En resumen, RHE permite a un agente agotar las críticas de sus socios, y eventualmente este socio adoptará la hipótesis del agente. Ten en cuenta que esto significa que la autonomía del agente no se conserva aquí (ya que un agente esencialmente aceptará cualquier hipótesis que no pueda socavar), con la esperanza de que la ganancia en eficiencia sea lo suficientemente significativa como para compensar una pérdida en efectividad. El segundo protocolo de variante es un protocolo completo de intercambio de observaciones (COE). COE utiliza los mismos principios que OE, pero incluye además todos los ejemplos críticos negativos (nofire) en el intercambio (dando así todos los ejemplos utilizados como argumentos por el protocolo de intercambio de hipótesis), mejorando así la efectividad. Los resultados para el mapa 69-1 se muestran en la Figura 5. Figura 5: Tamaño medio de los intercambios. Primero podemos observar el hecho de que el orden de los protocolos, desde el menos eficiente hasta el más eficiente, es COE, HE, RHE y luego OE. ÉL siendo más eficiente que COE demuestra que el proceso de argumentación gana eficiencia al seleccionar cuándo es necesario proporcionar ejemplos negativos, los cuales tienen menos impacto que los positivos en nuestro entorno de prueba específico. Sin embargo, al comunicar hipótesis antes de proporcionar observaciones para respaldarla (HE) en lugar de dar directamente las observaciones más cruciales (OE), el proceso de argumentación duplica el tamaño de los intercambios de datos. Es el costo de garantizar la consistencia al final del intercambio (una propiedad que OE no admite). También es significativo el hecho de que el tamaño promedio de los intercambios es ligeramente mayor cuando el número de agentes es pequeño. Esto se explica por el hecho de que en estos casos solo unos pocos agentes tienen información relevante en su posesión, y que necesitarán comunicarse mucho para llegar a un punto de vista común de la situación. Cuando el número de agentes aumenta, este conocimiento se distribuye entre más agentes que necesitan discusiones más cortas para llegar a una consistencia mutua. Como consecuencia, la ganancia relativa en eficiencia de usar RHE parece ser mejor cuando el número de agentes es pequeño: cuando es alto, difícilmente discutirán de todos modos. Finalmente, vale la pena notar que la desviación estándar para estos experimentos es bastante alta, lo que significa que la conversación no converge hacia ningún patrón estereotípico. 6. CONCLUSIÓN Este documento ha investigado las propiedades de un sistema multiagente donde cada agente (distribuido) percibe localmente su entorno e intenta alcanzar consistencia con otros agentes a pesar de severas restricciones de comunicación. En particular, hemos expuesto condiciones que permiten la convergencia e investigado experimentalmente una situación típica donde esas condiciones no pueden cumplirse. Hay muchas posibles extensiones a este trabajo, la primera siendo investigar más a fondo las propiedades de diferentes protocolos globales pertenecientes a la clase que identificamos, y su influencia en el resultado. Existen en particular muchas heurísticas, altamente dependientes del contexto del estudio, que podrían intuitivamente arrojar resultados interesantes (en nuestro estudio, seleccionar al destinatario en función de lo que se pueda inferir de sus acciones observadas podría ser una de esas heurísticas). Un candidato obvio para problemas a largo plazo se refiere a la relajación de la suposición de un sensor perfecto. 7. REFERENCIAS [1] G. Bourgne, N. Maudet y S. Pinson. Cuando los agentes comunican hipótesis en situaciones críticas. En Actas de DALT-2006, mayo de 2006. [2] P. Harvey, C. F. Chang y A. Ghose. Búsqueda distribuida basada en soporte: un nuevo enfoque para el procesamiento de restricciones multiagente. En Actas de AAMAS06, 2006. [3] H. Jung y M. Tambe. Argumentación como satisfacción de restricciones distribuida: Aplicaciones y resultados. En Actas de AGENTS01, 2001. [4] N. C. Karunatillake y N. R. Jennings. ¿Vale la pena discutir? En Actas de ArgMAS 2004, 2004. [5] S. Onta˜n´on y E. Plaza. Argumentos y contraejemplos en la deliberación conjunta basada en casos. En Actas de ArgMAS-2006, mayo de 2006. [6] D. Poole. Explicación y predicción: Una arquitectura para el razonamiento por defecto y abductivo. Inteligencia Computacional, 5(2):97-110, 1989. [7] I. Rahwan, S. D. Ramchurn, N. R. Jennings, P. McBurney, S. Parsons y L. Sonenberg. Negociación basada en argumentos. La revisión de Ingeniería del Conocimiento, 4(18):345-375, 2003. [8] N. Roos, A. ten Tije y C. Witteveen. Un protocolo para el diagnóstico multiagente con conocimiento distribuido espacialmente. En Actas de AAMAS03, 2003. [9] N. Roos, A. ten Tije y C. Witteveen. Alcanzando acuerdo diagnóstico en el diagnóstico multiagente. En Actas de AAMAS04, 2004. [10] T. Takahashi, Y. Kaneda y N. Ito. Estudio preliminar: utilizando simulaciones de RoboCupRescue para la prevención de desastres. En Actas de SRMED2004, 2004. El Sexto Internacional. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 1005 ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "temporal path": {
            "translated_key": "camino temporal",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Hypotheses Refinement under Topological Communication Constraints ∗ Gauvain Bourgne, Gael Hette, Nicolas Maudet, and Suzanne Pinson LAMSADE, Univ.",
                "Paris-Dauphine, France {bourgne,hette,maudet,pinson}@lamsade.dauphine.fr ABSTRACT We investigate the properties of a multiagent system where each (distributed) agent locally perceives its environment.",
                "Upon perception of an unexpected event, each agent locally computes its favoured hypothesis and tries to propagate it to other agents, by exchanging hypotheses and supporting arguments (observations).",
                "However, we further assume that communication opportunities are severely constrained and change dynamically.",
                "In this paper, we mostly investigate the convergence of such systems towards global consistency.",
                "We first show that (for a wide class of protocols that we shall define), the communication constraints induced by the topology will not prevent the convergence of the system, at the condition that the system dynamics guarantees that no agent will ever be isolated forever, and that agents have unlimited time for computation and arguments exchange.",
                "As this assumption cannot be made in most situations though, we then set up an experimental framework aiming at comparing the relative efficiency and effectiveness of different interaction protocols for hypotheses exchange.",
                "We study a critical situation involving a number of agents aiming at escaping from a burning building.",
                "The results reported here provide some insights regarding the design of optimal protocol for hypotheses refinement in this context.",
                "Categories and Subject Descriptors I.2.11 [Artificial Intelligence]: Distributed Artificial Intelligence-Multiagent systems General Terms Theory, Experimentation 1.",
                "INTRODUCTION We consider a multiagent system where each (distributed) agent locally perceives its environment, and we assume that some unexpected event occurs in that system.",
                "If each agent computes only locally its favoured hypothesis, it is only natural to assume that agents will seek to coordinate and refine their hypotheses by confronting their observations with other agents.",
                "If, in addition, the communication opportunities are severely constrained (for instance, agents can only communicate when they are close enough to some other agent), and dynamically changing (for instance, agents may change their locations), it becomes crucial to carefully design protocols that will allow agents to converge to some desired state of global consistency.",
                "In this paper we exhibit some sufficient conditions on the system dynamics and on the protocol/strategy structures that allow to guarantee that property, and we experimentally study some contexts where (some of) these assumptions are relaxed.",
                "While problems of diagnosis are among the venerable classics in the AI tradition, their multiagent counterparts have much more recently attracted some attention.",
                "Roos and colleagues [8, 9] in particular study a situation where a number of distributed entities try to come up with a satisfying global diagnosis of the whole system.",
                "They show in particular that the number of messages required to establish this global diagnosis is bound to be prohibitive, unless the communication is enhanced with some suitable protocol.",
                "However, they do not put any restrictions on agents communication options, and do not assume either that the system is dynamic.",
                "The benefits of enhancing communication with supporting information to make convergence to a desired global state of a system more efficient has often been put forward in the literature.",
                "This is for instance one of the main idea underlying the argumentation-based negotiation approach [7], where the desired state is a compromise between agents with conflicting preferences.",
                "Many of these works however make the assumption that this approach is beneficial to start with, and study the technical facets of the problem (or instead emphasize other advantages of using argumentation).",
                "Notable exceptions are the works of [3, 4, 2, 5], which studied in contexts different from ours the efficiency of argumentation.",
                "The rest of the paper is as follows.",
                "Section 2 specifies the basic elements of our model, and Section 3 goes on to presenting the different protocols and strategies used by the agents to exchange hypotheses and observations.",
                "We put special attention at clearly emphasizing the conditions on the system dynamics and protocols/strategies that will be exploited in the rest of the paper.",
                "Section 4 details one of 998 978-81-904262-7-5 (RPS) c 2007 IFAAMAS the main results of the paper, namely the fact that under the aforementioned conditions, the constraints that we put on the topology will not prevent the convergence of the system towards global consistency, at the condition that no agent ever gets completely lost forever in the system, and that unlimited time is allowed for computation and argument exchange.",
                "While the conditions on protocols and strategies are fairly mild, it is also clear that these system requirements look much more problematic, even frankly unrealistic in critical situations where distributed approaches are precisely advocated.",
                "To get a clearer picture of the situation induced when time is a critical factor, we have set up an experimental framework that we introduce and discuss in Section 5.",
                "The critical situation involves a number of agents aiming at escaping from a burning building.",
                "The results reported here show that the effectiveness of argument exchange crucially depends upon the nature of the building, and provide some insights regarding the design of optimal protocol for hypotheses refinement in this context. 2.",
                "BASIC NOTIONS We start by defining the basic elements of our system.",
                "Environment Let O be the (potentially infinite) set of possible observations.",
                "We assume the sensors of our agents to be perfect, hence the observations to be certain.",
                "Let H be the set of hypotheses, uncertain and revisable.",
                "Let Cons(h, O) be the consistency relation, a binary relation between a hypothesis h ∈ H and a set of observations O ⊆ O.",
                "In most cases, Cons will refer to classical consistency relation, however, we may overload its meaning and add some additional properties to that relation (in which case we will mention it).",
                "The environment may include some dynamics, and change over the course of time.",
                "We define below sequences of time points to deal with it: Definition 1 (Sequence of time points).",
                "A sequence of time points t1, t2, . . . , tn from t is an ordered set of time points t1, t2, . . . , tn such that t1 ≥ t and ∀i ∈ [1, n − 1], ti+1 ≥ ti.",
                "Agent We take a system populated by n agents a1, . . . , an.",
                "Each agent is defined as a tuple F, Oi, hi , where: • F, the set of facts, common knowledge to all agents. • Oi ∈ 2O , the set of observations made by the agent so far.",
                "We assume a perfect memory, hence this set grows monotonically. • hi ∈ H, the favourite hypothesis of the agent.",
                "A key notion governing the formation of hypotheses is that of consistency, defined below: Definition 2 (Consistency).",
                "We say that: • An agent is consistent (Cons(ai)) iff Cons(hi, Oi) (that is, its hypothesis is consistent with its observation set). • An agent ai consistent with a partner agent aj iff Cons(ai) and Cons(hi, Oj) (that is, this agent is consistent and its hypothesis can explain the observation set of the other agent). • Two agents ai and aj are mutually consistent (MCons(ai, aj)) iff Cons(ai, aj) and Cons(aj, ai). • A system is consistent iff ∀(i, j)∈[1, n]2 it is the case that MCons(ai, aj).",
                "To ensure its consistency, each agent is equipped with an abstract reasoning machinery that we shall call the explanation function Eh.",
                "This (deterministic) function takes a set of observation and returns a single prefered hypothesis (2O → H).",
                "We assume h = Eh(O) to be consistent with O by definition of Eh, so using this function on its observation set to determine its favourite hypothesis is a sure way for the agent to achieve consistency.",
                "Note however that an hypothesis does not need to be generated by Eh to be consistent with an observation set.",
                "As a concrete example of such a function, and one of the main inspiration of this work, one can cite the Theorist reasoning system [6] -as long as it is coupled with a filter selecting a single prefered theory among the ones initially selected by Theorist.",
                "Note also that hi may only be modified as a consequence of the application Eh.",
                "We refer to this as the autonomy of the agent: no other agent can directly impose a given hypothesis to an agent.",
                "As a consequence, only a new observation (being it a new perception, or an observation communicated by a fellow agent) can result in a modification of its prefered hypothesis hi (but not necessarily of course).",
                "We finally define a property of the system that we shall use in the rest of the paper: Definition 3 (Bounded Perceptions).",
                "A system involves a bounded perception for agents iff ∃n0 s.t. ∀t| ∪N i=1 Oi| ≤ n0. (That is, the number of observations to be made by the agents in the system is not infinite.)",
                "Agent Cycle Now we need to see how these agents will evolve and interact in their environment.",
                "In our context, agents evolve in a dynamic environment, and we classicaly assume the following system cycle: 1.",
                "Environment dynamics: the environment evolves according to the defined rules of the system dynamics. 2.",
                "Perception step : agents get perceptions from the environment.",
                "These perceptions are typically partial (e.g. the agent can only see a portion of a map). 3.",
                "Reasoning step: agents compare perception with predictions, seek explanations for (potential) difference(s), refine their hypothesis, draw new conclusions. 4.",
                "Communication step: agents can communicate hypotheses and observations with other agents through a defined protocol.",
                "Any agent can only be involved in one communication with another agent by step. 5.",
                "Action step: agents do some practical reasoning using the models obtained from the previous steps and select an action.",
                "They can then modify the environment by executing it.",
                "The communication of the agents will be further constrained by topological consideration.",
                "At a given time, an agent will only be able to communicate with a number of neighbours.",
                "Its connexions with these others agents may The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 999 evolve with its situation in the environment.",
                "Typically, an agent can only communicate with agents that it can sense, but one could imagine evolving topological constraints on communication based on a network of communications between agents where the links are not always active.",
                "Communication In our system, agents will be able to communicate with each other.",
                "However, due to the aforementionned topological constraints, they will not be able to communicate with any agents at anytime.",
                "Who an agent can communicate with will be defined dynamically (for instance, this can be a consequence of the agents being close enough to get in touch).",
                "We will abstractly denote by C(ai, aj, t) the communication property, in other words, the fact that agents ai and aj can communicate at time t (note that this relation is assumed to be symetric, but of course not transitive).",
                "We are now in a position to define two essential properties of our system.",
                "Definition 4 (<br>temporal path</br>).",
                "There exists a temporal communication path at horizon tf (noted Ltf (aI , aJ )) between ai and aj iff there exists a sequence of time points t1, t2, . . . , tn from tf and a sequence of agents k1, k2, . . . , kn s.t. (i) C(aI , ak1 , t1), (ii) C(akn , aJ , tn+1), (iii) ∀i ∈ [1, n], C(aki , aki+1 , ti) Intuitively, what this property says is that it is possible to find a <br>temporal path</br> in the future that would allow to link agent ai and aj via a sequence of intermediary agents.",
                "Note that the time points are not necessarily successive, and that the sequence of agents may involve the same agents several times.",
                "Definition 5 (Temporal Connexity).",
                "A system is temporaly connex iff ∀t ∀(i, j)∈[1, n]2 Lt(ai, aj) In short, a temporaly connex system guarantees that any agent will be able to communicate with any other agents, no matter how long it might take to do so, at any time.",
                "To put it another way, it is never the case that an agent will be isolated for ever from another agent of the system.",
                "We will next discuss the detail of how communication concretely takes place in our system.",
                "Remember that in this paper, we only consider the case of bilateral exchanges (an agent can only speak to a single other agent), and that we also assume that any agent can only engage in a single exchange in a given round. 3.",
                "PROTOCOLS AND STRATEGIES In this section, we discuss the requirements of the interaction protocols that govern the exchange of messages between agents, and provide some example instantiation of such protocols.",
                "To clarify the presentation, we distinguish two levels: the local level, which is concerned with the regulation of bilateral exchanges; and the global level,which essentially regulates the way agents can actually engage into a conversation.",
                "At each level, we separate what is specified by the protocol, and what is left to agents strategies.",
                "Local Protocol and Strategies We start by inspecting local protocols and strategies that will regulate the communication between the agents of the system.",
                "As we limit ourselves to bilateral communication, these protocols will simply involve two agents.",
                "Such protocol will have to meet one basic requirement to be satisfying. • consistency (CONS)- a local protocol has to guarantee the mutual consistency of agents upon termination (which implies termination of course).",
                "Figure 1: A Hypotheses Exchange Protocol [1] One example such protocol is the protocol described in [1] that is pictured in Fig. 1.",
                "To further illustrate how such protocol can be used by agents, we give some details on a possible strategy: upon receiving a hypothesis h1 (propose(h1) or counterpropose(h1)) from a1, agent a2 is in state 2 and has the following possible replies: counterexample (if the agent knows an example contradicting the hypothesis, or not explained by this hypothesis), challenge (if the agents lacks evidence to accept this hypothesis), counterpropose (if the agent agrees with the hypothesis but prefers another one), or accept (if it is indeed as good as its favourite hypothesis).",
                "This strategy guarantees, among other properties, the eventual mutual logical consistency of the involved agents [1].",
                "Global Protocol The global protocol regulates the way bilateral exchanges will be initiated between agents.",
                "At each turn, agents will concurrently send one weighted request to communicate to other agents.",
                "This weight is a value measuring the agents willingness to converse with the targeted agent (in practice, this can be based on different heuristics, but we shall make some assumptions on agents strategies, see below).",
                "Sending such a request is a kind of conditional commitment for the agent.",
                "An agent sending a weighted request commits to engage in conversation with the target if he does not receive and accept himself another request.",
                "Once all request have been received, each agent replies with either an acccept or a reject.",
                "By answering with an accept, an agent makes a full commitment to engage in conversation with the sender.",
                "Therefore, it can only send one accept in a given round, as an agent can only participate in one conversation per time step.",
                "When all response have been received, each agent receiving an accept can either initiate a conversation using the local protocol or send a cancel if it has accepted another request.",
                "At the end of all the bilateral exchanges, the agents engaged in conversation are discarded from the protocol.",
                "Then each of the remaining agents resends a request and the process iterates until no more requests are sent.",
                "Global Strategy We now define four requirements for the strategies used by agents, depending on their role in the protocol: two are concerned with the requestee role (how to decide who the 1000 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) agent wishes to communicate with? ), the other two with the responder role (how to decide which communication request to accept or not?). • Willingness to solve inconsistancies (SOLVE)-agents want to communicate with any other agents unless they know they are mutually consistent. • Focus on solving inconsistencies (FOCUS)-agents do not request communication with an agent with whom they know they are mutually consistent. • Willingness to communicate (COMM)-agents cannot refuse a weighted communication request, unless they have just received or send a request with a greater weight. • Commitment to communication request (REQU)agents cannot accept a weighted communication request if they have themselves sent a communication request with a greater weight.",
                "Therefore, they will not cancel their request unless they have received a communicational request with greater weight.",
                "Now the protocol structure, together with the properties COMM+REQU, ensure that a request can only be rejected if its target agent engages in communication with another agent.",
                "Suppose indeed that agent ai wants to communicate with aj by sending a request with weight w. COMM guarantees that an agent receiving a weighted request will either accept this communication, accept a communication with a greater weight or wait for the answer to a request with a greater weight.",
                "This ensures that the request with maximal weight will be accepted and not cancelled (as REQU ensures that an agent sending a request can only cancel it if he accepts another request with greater weight).",
                "Therefore at least two agents will engage in conversation per round of the global protocol.",
                "As the protocol ensures that ai can resend its request while aj is not engaged in a conversation, there will be a turn in which aj must engage in a conversation, either with ai or another agent.",
                "These requirements concern request sending and acceptation, but agents also need some strategy of weight attribution.",
                "We describe below an altruist strategy, used in our experiments.",
                "Being cooperative, an agent may want to know more of the communication wishes of other agents in order to improve the overall allocation of exchanges to agents.",
                "A context request step is then added to the global protocol.",
                "Before sending their chosen weighted request, agents attribute a weight to all agents they are prepared to communicate with, according to some internal factors.",
                "In the simplest case, this weight will be 1 for all agent with whom the agent is not sure of being mutually consistent (ensuring SOLVE), other agent being not considered for communication (ensuring FOCUS).",
                "The agent then sends a context request to all agents with whom communication is considered.",
                "This request also provides information about the sender (list of considered communications along with their weight).",
                "After reception of all the context requests, agents will either reply with a deny, iff they are already engaged in a conversation (in which case, the requesting agent will not consider communication with them anymore in this turn), or an inform giving the requester information about the requests it has sent and received.",
                "When all replies have been received, each agent can calculate the weight of all requests concerning it.",
                "It does so by substracting from the weight of its request the weight of all requests concerning either it or its target (that is, the final weight of the request from ai to aj is Wi,j = wi,j +wj,i − ( P k∈R(i)−{j} wi,k + P k∈S(i)−{j} wk,i + P k∈R(j)−{i} wj,k + P k∈S(j)−{i} wk,j) where wi,j is the weight of the request of ai to aj, R(i) is the set of indice of agents having received a request from ai and S(i) is the set of indice of agents having send a request to ai).",
                "It then finally sends a weighted request to the agents who maximise this weight (or wait for a request) as described in the global protocol. 4. (CONDITIONAL) CONVERGENCE TO GLOBAL CONSISTENCY In this section we will show that the requirements regarding protocols and strategies just discussed will be sufficient to ensure that the system will eventually converge towards global consistency, under some conditions.",
                "We first show that, if two agents are not mutually consistent at some time, then there will be necessarily a time in the future such that an agent will learn a new observation, being it because it is new for the system, or by learning it from another agent.",
                "Lemma 1.",
                "Let S be a system populated by n agents a1, a2, ..., an, temporaly connex, and involving bounded perceptions for these agents.",
                "Let n1 be the sum of cardinalities of the intersection of pairwise observation sets. (n1 = P (i,j)∈[1,n]2 |Oi ∩ Oj|) Let n2 be the cardinality of the union of all agents observations sets. (n2 = | ∪N i=1 Oi|).",
                "If ¬MCons(ai, aj) at time t0, there is necessarily a time t > t0 s.t. either n1 or n2 will increase.",
                "Proof.",
                "Suppose that there exist a time t0 and indices (i, j) s.t. ¬MCons(ai, aj).",
                "We will use mt0 = P (k,l)∈[1,n]2 εComm(ak, al, t0) where εComm(ak, al, t0) = 1 if ak and al have communicated at least once since t0, and 0 otherwise.",
                "Temporal connexity guarantees that there exist t1, ..., tm+1 and k1, ..., km s.t.",
                "C(ai, ak1 , t1), C(akm , aj, tm+1), and ∀p ∈ [1, m], C(akp , akp+1 , tp).",
                "Clearly, if MCons(ai, ak1 ), MCons(akm , aj) and ∀p, MCons(akp , akp+1 ), we have MCons(ai, aj) which contradicts our hypothesis (MCons being transitive, MCons(ai, ak1 )∧MCons(ak1 , ak2 ) implies that MCons(ai, ak2 ) and so on till MCons(ai, akm )∧ MCons(akm , aj) which implies MCons(ai, aj) ).",
                "At least two agents are then necessarily inconsistent (¬MCons(ai, ak1 ), or ¬MCons(akm , aj), or ∃p0 t.q. ¬MCons(akp0 , akp0+1 )).",
                "Let ak and al be these two neighbours at a time t > t0 1 .",
                "The SOLVE property ensures that either ak or al will send a communication request to the other agent at time t .",
                "As shown before, this in turn ensures that at least one of these agents will be involved in a communication.",
                "Then there are two possibilities: (case i) ak and al communicate at time t .",
                "In this case, we know that ¬MCons(ak, al).",
                "This and the CONS property ensures that at least one of the agents must change its 1 Strictly speaking, the transitivity of MCons only ensure that ak and al are inconsistent at a time t ≥ t0 that can be different from the time t at which they can communicate.",
                "But if they become consistent between t and t (or inconsistent between t and t ), it means that at least one of them have changed its hypothesis between t and t , that is, after t0.",
                "We can then apply the reasoning of case iib.",
                "The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 1001 hypothesis, which in turn, since agents are autonomous, implies at least one exchange of observation.",
                "But then |Ok ∩Ol| is bound to increase: n1(t ) > n1(t0). (case ii) ak communicates with ap at time t .",
                "We then have again two possibilities: (case iia) ak and ap did not communicate since t0.",
                "But then εComm(ak, ap, t0) had value 0 and takes value 1.",
                "Hence mt0 increases. (case iib) ak and ap did communicate at some time t0 > t0.",
                "The CONS property of the protocol ensures that MCons(ak, ap) at that time.",
                "Now the fact that they communicate and FOCUS implies that at least one of them did change its hypothesis in the meantime.",
                "The fact that agents are autonomous implies in turn that a new observation (perceived or received from another agent) necessarily provoked this change.",
                "The latter case would ensure the existence of a time t > t0 and an agent aq s.t. either |Op ∩Oq| or |Ok ∩Oq| increases of 1 at that time (implying n1(t ) > n1(t0)).",
                "The former case means that the agent gets a new perception o at time t .",
                "If that observation was unknown in the system before, then n2(t ) > n2(t0).",
                "If some agent aq already knew this observation before, then either Op ∩ Oq or Ok ∩ Oq increases of 1 at time t (which implies that n1(t ) > n1(t0)).",
                "Hence, ¬MCons(ai, aj) at time t0 guarantees that, either: −∃t > t0 t.q. n1(t ) > n1(t0); or −∃t > t0 t.q. n2(t ) > n2(t0); or −∃t > t0 t.q. mt0 increases of 1 at time t .",
                "By iterating the reasoning with t (but keeping t0 as the time reference for mt0 ), we can eliminate the third case (mt0 is integer and bounded by n2 , which means that after a maximum of n2 iterations, we necessarily will be in one of two other cases.)",
                "As a result, we have proven that if ¬MCons(ai, aj) at time t0, there is necessarily a time t s.t. either n1 or n2 will increase.",
                "Theorem 1 (Global consistency).",
                "Let S be a system populated by n agents a1, a2, ..., an, temporaly connex, and involving bounded perceptions for these agents.",
                "Let Cons(ai, aj) be a transitive consistency property.",
                "Then any protocol and strategies satisfying properties CONS, SOLVE, FOCUS, COMM and REQU guarantees that the system will converge towards global consistency.",
                "Proof.",
                "For the sake of contradiction, let us assume ∃I, J ∈ [1, N] s.t. ∀t, ∃t0 > t, t.q. ¬Cons(aI , aJ , t0).",
                "Using the lemma, this implies that ∃t > t0 s.t. either n1(t ) > n1(t0) or n2(t ) > n2(t0).",
                "But we can apply the same reasoning taking t = t , which would give us t1 > t > t0 s.t. ¬Cons(aI , aJ , t1), which gives us t > t1 s.t. either n1(t ) > n1(t1) or n2(t ) > n2(t1).",
                "By successive iterations we can then construct a sequence t0, t1, ..., tn, which can be divided in two sub-sequences t0, t1, ...tn and t0 , t1 , ..., tn s.t. n1(t0) < n1(t1) < ... < n1(tn) and n2(t0 ) < n2(t1 ) < ... < n2(tn).",
                "One of these sub-sequences has to be infinite.",
                "However, n1(ti) and n2(ti ) are strictly growing, integer, and bounded, which implies that both are finite.",
                "Contradiction.",
                "What the previous result essentially shows is that, in a system where no agent will be isolated from the rest of the agents for ever, only very mild assumptions on the protocols and strategies used by agents suffice to guarantee convergence towards system consistency in a finite amount of time (although it might take very long).",
                "Unfortunately, in many critical situations, it will not be possible to assume this temporal connexity.",
                "As distributed approaches as the one advocated in this paper are precisely often presented as a good way to tackle problems of reliability or problems of dependence to a center that are of utmost importance in these critical applications, it is certainly interesting to further explore how such a system would behave when we relax this assumption. 5.",
                "EXPERIMENTAL STUDY This experiment involves agents trying to escape from a burning building.",
                "The environment is described as a spatial grid with a set of walls and (thankfully) some exits.",
                "Time and space are considered discrete.",
                "Time is divided in rounds.",
                "Agents are localised by their position on the spatial grid.",
                "These agents can move and communicate with other agents.",
                "In a round, an agent can move of one cell in any of the four cardinal directions, provided it is not blocked by a wall.",
                "In this application, agents communicate with any other agent (but, recall, a single one) given that this agent is in view, and that they have not yet exchanged their current favoured hypothesis.",
                "Suddenly, a fire erupts in these premises.",
                "From this moment, the fire propagates.",
                "Each round, for each cases where there is fire, the fire propagates in the four directions.",
                "However, the fire cannot propagate through a wall.",
                "If the fire propagates in a case where an agent is positioned, that agent burns and is considered dead.",
                "It can of course no longer move nor communicate.",
                "If an agent gets to an exit, it is considered saved, and can no longer be burned.",
                "Agents know the environment and the rules governing the dynamics of this environment, that is, they know the map as well as the rules of fire propagation previously described.",
                "They also locally perceive this environment, but cannot see further than 3 cases away, in any direction.",
                "Walls also block the line of view, preventing agents from seeing behind them.",
                "Within their sight, they can see other agents and whether or not the cases they see are on fire.",
                "All these perceptions are memorised.",
                "We now show how this instantiates the abstract framework presented the paper. • O = {Fire(x, y, t), NoFire(x, y, t), Agent(ai, x, y, t)} Observations can then be positive (o ∈ P(O) iff ∃h ∈ H s.t. h |= o) or negative (o ∈ N(O) iff ∃h ∈ H s.t. h |= ¬o). • H={FireOrigin(x1, y1, t1)∧...∧FireOrigin(xl, yl, tl)} Hypotheses are conjunctions of FireOrigins. • Cons(h, O) consistency relation satisfies: - coherence : ∀o ∈ N(O), h |= ¬o. - completeness : ∀o ∈ P(O), h |= o. - minimality : For all h ∈ H, if h is coherent and complete for O, then h is prefered to h according to the preference relation (h ≤p h ).2 2 Selects first the minimal number of origins, then the most recent (least preemptive strategy [6]), then uses some arbitrary fixed ranking to discriminate ex-aequo.",
                "The resulting relation is a total order, hence minimality implies that there will be a single h s.t.Cons(O, h) for a given O.",
                "This in turn means that MCons(ai, aj) iff Cons(ai), Cons(aj), and hi = hj.",
                "This relation is then transitive and symmetric. 1002 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) • Eh takes O as argument and returns min≤p of the coherent and complete hypothesis for O 5.1 Experimental Evaluation We will classically (see e.g. [3, 4]) assess the effectiveness and efficiency of different interaction protocols.",
                "Effectiveness of a protocol The proportion of agents surviving the fire over the initial number of agents involved in the experiment will determine the effectiveness of a given protocol.",
                "If this value is high, the protocol has been effective to propagate the information and/or for the agents to refine their hypotheses and determine the best way to the exit.",
                "Efficiency of a protocol Typically, the use of supporting information will involve a communication overhead.",
                "We will assume here that the efficiency of a given protocol is characterised by the data flow induced by this protocol.",
                "In this paper we will only discuss this aspect wrt. local protocols.",
                "The main measure that we shall then use here is the mean total size of messages that are exchanged by agents per exchange (hence taking into account both the number of messages and the actual size of the messages, because it could be that messages happen to be very big, containing e.g. a large number of observations, which could counter-balance a low number of messages). 5.2 Experimental Settings The chosen experimental settings are the following: • Environmental topology- Performances of information propagation are highly constrained by the environment topology.",
                "The perception skills of the agents depend on the openness of the environment.",
                "With a large number of walls the perceptions of agents are limited, and also the number of possible inter-agent communications, whereas an open environment will provide optimal possibilities of perception and information propagation.",
                "Thus, we propose a topological index (see below) as a common basis to charaterize the environments (maps) used during experimentations.",
                "The topological index (TI) is the ratio of the number of cells that can be perceived by agents summed up from all possible positions, divided by the number of cells that would be perceived from the same positions but without any walls. (The closer to 1, the more open the environment).",
                "We shall also use two additional, more classical [10], measures: the characteristic path length3 (CPL) and the clustering coefficient4 (CC). • Number of agents- The propagation of information also depends on the initial number of agents involved during an experimentation.",
                "For instance, the more agents, the more potential communications there is.",
                "This means that there will be more potential for propagation, but also that the bilateral exchange restriction will be more crucial. 3 The CPL is the median of the means of the shortest path lengths connecting each node to all other nodes. 4 characterising the isolation degree of a region of an environment in terms of acessibility (number of roads still usable to reach this region).",
                "Map T.I. (%) C.P.L.",
                "C.C. 69-1 69,23 4,5 0,69 69-2 68,88 4,38 0,65 69-3 69,80 4,25 0,67 53-1 53,19 5,6 0,59 53-2 53,53 6,38 0,54 53-3 53,92 6,08 0,61 38-1 38,56 8,19 0,50 38-2 38,56 7,3 0,50 38-3 38,23 8,13 0,50 Table 1: Topological Characteristics of the Maps • Initial positions of the agents- Initial positions of the agents have a significant influence on the overall behavior of an instance of our system: being close from an exit will (in general) ease the escape. 5.3 Experimental environments We choose to realize experiments on three very different topological indexes (69% for open environments, 53% for mixed environments, and 38% for labyrinth-like environments).",
                "Figure 2: Two maps (left: TI=69%, right TI=38%) We designed three different maps for each index (Fig. 2 shows two of them), containing the same maximum number of agents (36 agents max.) with a maximum density of one agent per cell, the same number of exits and a similar fire origin (e.g. starting time and position).",
                "The three differents maps of a given index are designed as follows.",
                "The first map is a model of an existing building floor.",
                "The second map has the same enclosure, exits and fire origin as the first one, but the number and location of walls are different (wall locations are designed by an heuristic which randomly creates walls on the spatial grid such that no fully closed rooms are created and that no exit is closed).",
                "The third map is characterised by geometrical enclosure in wich walls location is also designed with the aforementioned heuristic.",
                "Table 1 summarizes the different topological measures characterizing these different maps.",
                "It is worth pointing out that the values confirm the relevance of TI (maps with a high TI have a low CPL and a high CC.",
                "However the CPL and CC allows to further refine the difference between the maps, e.g. between 53-1 and 53-2). 5.4 Experimental Results For each triple of maps defined as above we conduct the same experiments.",
                "In each experiment, the society differs in terms of its initial proportion of involved agents, from 1% to 100%.",
                "This initial proportion represents the percentage of involved agents with regards to the possible maximum number of agents.",
                "For each map and each initial proportion, The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 1003 we select randomly 100 different initial agents locations.",
                "For each of those different locations we execute the system one time for each different interaction protocol.",
                "Effectiveness of Communication and Argumentation The first experiment that we set up aims at testing how effective is hypotheses exchange (HE), and in particular how the topological aspects will affect this effectiveness.",
                "In order to do so, we have computed the ratio of improvement offered by that protocol over a situation where agents could simply not communicate (no comm).",
                "To get further insights as to what extent the hypotheses exchange was really crucial, we also tested a much less elaborated protocol consisting of mere observation exchanges (OE).",
                "More precisely, this protocol requires that each agent stores any unexpected observation that it perceives, and agents simply exchange their respective lists of observations when they discuss.",
                "In this case, the local protocol is different (note in particular that it does not guarantee mutual consistency), but the global protocol remains the same (at the only exception that agents motivation to communicate is to synchronise their list of observations, not their hypothesis).",
                "If this protocol is at best as effective as HE, it has the advantage of being more efficient (this is obvious wrt the number of messages which will be limited to 2, less straightforward as far as the size of messages is concerned, but the rough observation that the exchange of observations can be viewed as a flat version of the challenge is helpful to see this).",
                "The results of these experiments are reported in Fig. 3.",
                "Figure 3: Comparative effectiveness ratio gain of protocols when the proportion of agents augments The first observation that needs to be made is that communication improves the effectiveness of the process, and this ratio increases as the number of agents grows in the system.",
                "The second lesson that we learn here is that closeness relatively makes communication more effective over non communication.",
                "Maps exhibiting a T.I. of 38% are constantly above the two others, and 53% are still slightly but significantly better than 69%.",
                "However, these curves also suggest, perhaps surprisingly, that HE outperforms OE in precisely those situations where the ratio gain is less important (the only noticeable difference occurs for rather open maps where T.I. is 69%).",
                "This may be explained as follows: when a map is open, agents have many potential explanation candidates, and argumentation becomes useful to discriminate between those.",
                "When a map is labyrinth-like, there are fewer possible explanations to an unexpected event.",
                "Importance of the Global Protocol The second set of experiments seeks to evaluate the importance of the design of the global protocol.",
                "We tested our protocol against a local broadcast (LB) protocol.",
                "Local broadcast means that all the neighbours agents perceived by an agent will be involved in a communication with that agent in a given round -we alleviate the constraint of a single communication by agent.",
                "This gives us a rough upper bound upon the possible ratio gain in the system (for a given local protocol).",
                "Again, we evaluated the ratio gain induced by that LB over our classical HE, for the three different classes of maps.",
                "The results are reported in Fig. 4.",
                "Figure 4: Ratio gain of local broadcast over hypotheses exchange Note to begin with that the ratio gain is 0 when the proportion of agents is 5%, which is easily explained by the fact that it corresponds to situations involving only two agents.",
                "We first observe that all classes of maps witness a ratio gain increasing when the proportion of agents augments: the gain reaches 10 to 20%, depending on the class of maps considered.",
                "If one compares this with the improvement reported in the previous experiment, it appears to be of the same magnitude.",
                "This illustrates that the design of the global protocol cannot be ignored, especially when the proportion of agents is high.",
                "However, we also note that the effectiveness ratio gain curves have very different shapes in both cases: the gain induced by the accuracy of the local protocol increases very quickly with the proportion of agents, while the curve is really smooth for the global one.",
                "Now let us observe more carefully the results reported here: the curve corresponding to a TI of 53% is above that corresponding to 38%.",
                "This is so because the more open a map, the more opportunities to communicate with more than one agent (and hence benefits from broadcast).",
                "However, we also observe that curve for 69% is below that for 53%.",
                "This is explained as follows: in the case of 69%, the potential gain to be made in terms of surviving agents is much lower, because our protocols already give rather efficient outcomes anyway (quickly reaching 90%, see Fig. 3).",
                "A simple rule of thumb could be that when the number of agents is small, special attention should be put on the local 1004 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) protocol, whereas when that number is large, one should carefully design the global one (unless the map is so open that the protocol is already almost optimally efficient).",
                "Efficiency of the Protocols The final experiment reported here is concerned with the analysis of the efficiency of the protocols.",
                "We analysis here the mean size of the totality of the messages that are exchanged by agents (mean size of exchanges, for short) using the following protocols: HE, OE, and two variant protocols.",
                "The first one is an intermediary restricted hypotheses exchange protocol (RHE).",
                "RHE is as follows: it does not involve any challenge nor counter-propose, which means that agents cannot switch their role during the protocol (this differs from RE in that respect).",
                "In short, RHE allows an agent to exhaust its partners criticism, and eventually this partner will come to adopt the agents hypothesis.",
                "Note that this means that the autonomy of the agent is not preserved here (as an agent will essentially accept any hypothesis it cannot undermine), with the hope that the gain in efficiency will be significant enough to compensate a loss in effectiveness.",
                "The second variant protocol is a complete observation exchange protocol (COE).",
                "COE uses the same principles as OE, but includes in addition all critical negative examples (nofire) in the exchange (thus giving all examples used as arguments by the hypotheses exchanges protocol), hence improving effectiveness.",
                "Results for map 69-1 are shown on Fig. 5.",
                "Figure 5: Mean size of exchanges First we can observe the fact that the ordering of the protocols, from the least efficient to the most efficient, is COE, HE, RHE and then OE.",
                "HE being more efficient than COE proves that the argumentation process gains efficiency by selecting when it is needed to provide negative example, which have less impact that positive ones in our specific testbed.",
                "However, by communicating hypotheses before eventually giving observation to support it (HE) instead of directly giving the most crucial observations (OE), the argumentation process doubles the size of data exchanges.",
                "It is the cost for ensuring consistency at the end of the exchange (a property that OE does not support).",
                "Also significant is the fact the the mean size of exchanges is slightly higher when the number of agents is small.",
                "This is explained by the fact that in these cases only a very few agents have relevant informations in their possession, and that they will need to communicate a lot in order to come up with a common view of the situation.",
                "When the number of agents increases, this knowledge is distributed over more agents which need shorter discussions to get to mutual consistency.",
                "As a consequence, the relative gain in efficiency of using RHE appears to be better when the number of agents is small: when it is high, they will hardly argue anyway.",
                "Finally, it is worth noticing that the standard deviation for these experiments is rather high, which means that the conversation do not converge to any stereotypic pattern. 6.",
                "CONCLUSION This paper has investigated the properties of a multiagent system where each (distributed) agent locally perceives its environment, and tries to reach consistency with other agents despite severe communication restrictions.",
                "In particular we have exhibited conditions allowing convergence, and experimentally investigated a typical situation where those conditions cannot hold.",
                "There are many possible extensions to this work, the first being to further investigate the properties of different global protocols belonging to the class we identified, and their influence on the outcome.",
                "There are in particular many heuristics, highly dependent on the context of the study, that could intuitively yield interesting results (in our study, selecting the recipient on the basis of what can be inferred from his observed actions could be such a heuristic).",
                "One obvious candidate for longer term issues concern the relaxation of the assumption of perfect sensing. 7.",
                "REFERENCES [1] G. Bourgne, N. Maudet, and S. Pinson.",
                "When agents communicate hypotheses in critical situations.",
                "In Proceedings of DALT-2006, May 2006. [2] P. Harvey, C. F. Chang, and A. Ghose.",
                "Support-based distributed search: a new approach for multiagent constraint processing.",
                "In Proceedings of AAMAS06, 2006. [3] H. Jung and M. Tambe.",
                "Argumentation as distributed constraint satisfaction: Applications and results.",
                "In Proceedings of AGENTS01, 2001. [4] N. C. Karunatillake and N. R. Jennings.",
                "Is it worth arguing?",
                "In Proceedings of ArgMAS 2004, 2004. [5] S. Onta˜n´on and E. Plaza.",
                "Arguments and counterexamples in case-based joint deliberation.",
                "In Proceedings of ArgMAS-2006, May 2006. [6] D. Poole.",
                "Explanation and prediction: An architecture for default and abductive reasoning.",
                "Computational Intelligence, 5(2):97-110, 1989. [7] I. Rahwan, S. D. Ramchurn, N. R. Jennings, P. McBurney, S. Parsons, and L. Sonenberg.",
                "Argumention-based negotiation.",
                "The Knowledge Engineering Review, 4(18):345-375, 2003. [8] N. Roos, A. ten Tije, and C. Witteveen.",
                "A protocol for multi-agent diagnosis with spatially distributed knowledge.",
                "In Proceedings of AAMAS03, 2003. [9] N. Roos, A. ten Tije, and C. Witteveen.",
                "Reaching diagnostic agreement in multiagent diagnosis.",
                "In Proceedings of AAMAS04, 2004. [10] T. Takahashi, Y. Kaneda, and N. Ito.",
                "Preliminary study - using robocuprescue simulations for disasters prevention.",
                "In Proceedings of SRMED2004, 2004.",
                "The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 1005"
            ],
            "original_annotated_samples": [
                "Definition 4 (<br>temporal path</br>).",
                "There exists a temporal communication path at horizon tf (noted Ltf (aI , aJ )) between ai and aj iff there exists a sequence of time points t1, t2, . . . , tn from tf and a sequence of agents k1, k2, . . . , kn s.t. (i) C(aI , ak1 , t1), (ii) C(akn , aJ , tn+1), (iii) ∀i ∈ [1, n], C(aki , aki+1 , ti) Intuitively, what this property says is that it is possible to find a <br>temporal path</br> in the future that would allow to link agent ai and aj via a sequence of intermediary agents."
            ],
            "translated_annotated_samples": [
                "Definición 4 (Camino Temporal).",
                "Existe un camino de comunicación temporal en el horizonte tf (denotado Ltf (aI, aJ)) entre ai y aj si y solo si existe una secuencia de puntos temporales t1, t2, ..., tn desde tf y una secuencia de agentes k1, k2, ..., kn tal que (i) C(aI, ak1, t1), (ii) C(akn, aJ, tn+1), (iii) ∀i ∈ [1, n], C(aki, aki+1, ti). Intuitivamente, lo que esta propiedad dice es que es posible encontrar un <br>camino temporal</br> en el futuro que permitiría vincular al agente ai y aj a través de una secuencia de agentes intermedios."
            ],
            "translated_text": "Refinamiento de hipótesis bajo restricciones de comunicación topológica ∗ Gauvain Bourgne, Gael Hette, Nicolas Maudet y Suzanne Pinson LAMSADE, Univ. Investigamos las propiedades de un sistema multiagente donde cada agente (distribuido) percibe localmente su entorno. Tras la percepción de un evento inesperado, cada agente calcula localmente su hipótesis favorita e intenta propagarla a otros agentes, intercambiando hipótesis y argumentos de apoyo (observaciones). Sin embargo, también asumimos que las oportunidades de comunicación están severamente limitadas y cambian dinámicamente. En este artículo, investigamos principalmente la convergencia de dichos sistemas hacia la consistencia global. Primero demostramos que (para una amplia clase de protocolos que definiremos), las restricciones de comunicación inducidas por la topología no impedirán la convergencia del sistema, bajo la condición de que la dinámica del sistema garantice que ningún agente quedará aislado para siempre, y que los agentes tengan tiempo ilimitado para la computación y el intercambio de argumentos. Dado que esta suposición no se puede hacer en la mayoría de las situaciones, establecimos un marco experimental con el objetivo de comparar la eficiencia y efectividad relativa de diferentes protocolos de interacción para el intercambio de hipótesis. Estudiamos una situación crítica que implica a varios agentes que intentan escapar de un edificio en llamas. Los resultados reportados aquí proporcionan algunas ideas sobre el diseño de un protocolo óptimo para el refinamiento de hipótesis en este contexto. Categorías y Descriptores de Asignaturas I.2.11 [Inteligencia Artificial]: Inteligencia Artificial Distribuida-Sistemas Multiagente Términos Generales Teoría, Experimentación 1. INTRODUCCIÓN Consideramos un sistema multiagente donde cada agente (distribuido) percibe localmente su entorno, y asumimos que ocurre un evento inesperado en ese sistema. Si cada agente calcula solo localmente su hipótesis preferida, es natural asumir que los agentes buscarán coordinar y refinar sus hipótesis confrontando sus observaciones con otros agentes. Si, además, las oportunidades de comunicación están severamente limitadas (por ejemplo, los agentes solo pueden comunicarse cuando están lo suficientemente cerca de otro agente) y cambian dinámicamente (por ejemplo, los agentes pueden cambiar sus ubicaciones), se vuelve crucial diseñar cuidadosamente protocolos que permitan a los agentes converger hacia algún estado deseado de consistencia global. En este documento presentamos algunas condiciones suficientes sobre la dinámica del sistema y sobre las estructuras de protocolo/estrategia que permiten garantizar esa propiedad, y estudiamos experimentalmente algunos contextos donde (algunas de) estas suposiciones se relajan. Si bien los problemas de diagnóstico son uno de los clásicos venerables en la tradición de la IA, sus contrapartes multiagentes han atraído atención mucho más recientemente. Roos y sus colegas [8, 9] en particular estudian una situación en la que un número de entidades distribuidas intentan llegar a un diagnóstico global satisfactorio de todo el sistema. Ellos muestran en particular que el número de mensajes necesarios para establecer este diagnóstico global está destinado a ser prohibitivo, a menos que la comunicación se mejore con algún protocolo adecuado. Sin embargo, no imponen restricciones a las opciones de comunicación de los agentes, ni asumen que el sistema es dinámico. Los beneficios de mejorar la comunicación con información de apoyo para hacer que la convergencia a un estado global deseado de un sistema sea más eficiente, a menudo se ha planteado en la literatura. Esta es, por ejemplo, una de las ideas principales que subyacen al enfoque de negociación basado en argumentos [7], donde el estado deseado es un compromiso entre agentes con preferencias conflictivas. Sin embargo, muchos de estos trabajos parten del supuesto de que este enfoque es beneficioso para comenzar y estudian los aspectos técnicos del problema (o en su lugar enfatizan otras ventajas de utilizar la argumentación). Excepciones notables son las obras de [3, 4, 2, 5], que estudiaron en contextos diferentes al nuestro la eficiencia de la argumentación. El resto del documento es el siguiente. La Sección 2 especifica los elementos básicos de nuestro modelo, y la Sección 3 continúa presentando los diferentes protocolos y estrategias utilizados por los agentes para intercambiar hipótesis y observaciones. Ponemos especial atención en enfatizar claramente las condiciones de la dinámica del sistema y los protocolos/estrategias que se explotarán en el resto del documento. La sección 4 detalla uno de los principales resultados del artículo, a saber, el hecho de que bajo las condiciones mencionadas, las restricciones que imponemos en la topología no impedirán la convergencia del sistema hacia la consistencia global, siempre y cuando ningún agente se pierda completamente para siempre en el sistema, y se permita un tiempo ilimitado para la computación y el intercambio de argumentos. Si bien las condiciones en los protocolos y estrategias son bastante suaves, también es claro que estos requisitos del sistema parecen mucho más problemáticos, incluso francamente poco realistas en situaciones críticas donde se abogan precisamente por enfoques distribuidos. Para obtener una imagen más clara de la situación inducida cuando el tiempo es un factor crítico, hemos establecido un marco experimental que presentamos y discutimos en la Sección 5. La situación crítica implica a varios agentes que intentan escapar de un edificio en llamas. Los resultados reportados aquí muestran que la efectividad del intercambio de argumentos depende crucialmente de la naturaleza del edificio, y proporcionan algunas ideas sobre el diseño de un protocolo óptimo para el refinamiento de hipótesis en este contexto. CONCEPTOS BÁSICOS Comenzamos definiendo los elementos básicos de nuestro sistema. Deje que O sea el conjunto (potencialmente infinito) de observaciones posibles. Suponemos que los sensores de nuestros agentes son perfectos, por lo tanto, las observaciones son seguras. Sea H el conjunto de hipótesis, incierto y revisable. Sea Cons(h, O) la relación de consistencia, una relación binaria entre una hipótesis h ∈ H y un conjunto de observaciones O ⊆ O. En la mayoría de los casos, Cons se referirá a la relación de consistencia clásica, sin embargo, podemos sobrecargar su significado y añadir algunas propiedades adicionales a esa relación (en cuyo caso lo mencionaremos). El entorno puede incluir cierta dinámica y cambiar con el transcurso del tiempo. Definimos a continuación secuencias de puntos temporales para tratar con ello: Definición 1 (Secuencia de puntos temporales). Una secuencia de puntos temporales t1, t2, . . . , tn de t es un conjunto ordenado de puntos temporales t1, t2, . . . , tn tal que t1 ≥ t y ∀i ∈ [1, n − 1], ti+1 ≥ ti. Tomamos un sistema poblado por n agentes a1, . . . , an. Cada agente se define como una tupla F, Oi, hi, donde: • F, el conjunto de hechos, conocimiento común a todos los agentes. • Oi ∈ 2O, el conjunto de observaciones realizadas por el agente hasta el momento. Suponemos una memoria perfecta, por lo tanto, este conjunto crece de forma monótona. • hi ∈ H, la hipótesis favorita del agente. Una noción clave que rige la formación de hipótesis es la de consistencia, definida a continuación: Definición 2 (Consistencia). Decimos que: • Un agente es consistente (Cons(ai)) si y solo si Cons(hi, Oi) (es decir, su hipótesis es consistente con su conjunto de observaciones). • Un agente ai es consistente con un agente compañero aj si y solo si Cons(ai) y Cons(hi, Oj) (es decir, este agente es consistente y su hipótesis puede explicar el conjunto de observaciones del otro agente). • Dos agentes ai y aj son mutuamente consistentes (MCons(ai, aj)) si y solo si Cons(ai, aj) y Cons(aj, ai). • Un sistema es consistente si y solo si para todo (i, j) ∈ [1, n]2 se cumple que MCons(ai, aj). Para garantizar su consistencia, cada agente está equipado con una maquinaria de razonamiento abstracto que llamaremos la función de explicación Eh. Esta función (determinística) toma un conjunto de observaciones y devuelve una única hipótesis preferida (2O → H). Suponemos que h = Eh(O) para ser consistente con O por definición de Eh, por lo que usar esta función en su conjunto de observaciones para determinar su hipótesis favorita es una forma segura para que el agente logre consistencia. Sin embargo, cabe destacar que una hipótesis no necesita ser generada por Eh para ser consistente con un conjunto de observaciones. Como ejemplo concreto de tal función, y una de las principales inspiraciones de este trabajo, se puede citar el sistema de razonamiento Theorist [6], siempre y cuando esté acoplado con un filtro que seleccione una teoría preferida entre las inicialmente seleccionadas por Theorist. También hay que tener en cuenta que hi solo puede ser modificado como consecuencia de la aplicación de Eh. Nos referimos a esto como la autonomía del agente: ningún otro agente puede imponer directamente una hipótesis dada a un agente. Como consecuencia, solo una nueva observación (ya sea una nueva percepción o una observación comunicada por otro agente) puede resultar en una modificación de su hipótesis preferida hi (pero no necesariamente, por supuesto). Finalmente definimos una propiedad del sistema que utilizaremos en el resto del artículo: Definición 3 (Percepciones Acotadas). Un sistema implica una percepción limitada para los agentes si y solo si existe un n0 tal que para todo t, la unión de N observaciones realizadas por los agentes es menor o igual a n0. (Es decir, el número de observaciones a realizar por los agentes en el sistema no es infinito.) Ahora necesitamos ver cómo evolucionarán e interactuarán estos agentes en su entorno. En nuestro contexto, los agentes evolucionan en un entorno dinámico, y asumimos clásicamente el siguiente ciclo del sistema: 1. Dinámica del entorno: el entorno evoluciona de acuerdo con las reglas definidas de la dinámica del sistema. 2. Paso de percepción: los agentes obtienen percepciones del entorno. Estas percepciones suelen ser parciales (por ejemplo, el agente solo puede ver una parte de un mapa). 3. Paso de razonamiento: los agentes comparan la percepción con las predicciones, buscan explicaciones para las diferencias (potenciales), refinan su hipótesis, y sacan nuevas conclusiones. 4. Paso de comunicación: los agentes pueden comunicar hipótesis y observaciones con otros agentes a través de un protocolo definido. Cualquier agente solo puede estar involucrado en una comunicación con otro agente en el paso 5. Paso de acción: los agentes realizan un razonamiento práctico utilizando los modelos obtenidos de los pasos anteriores y seleccionan una acción. Ellos pueden modificar el entorno ejecutándolo. La comunicación de los agentes estará aún más restringida por consideraciones topológicas. En un momento dado, un agente solo podrá comunicarse con un número de vecinos. Sus conexiones con estos otros agentes pueden The Sixth Intl. La Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) evoluciona con su situación en el entorno. Normalmente, un agente solo puede comunicarse con agentes que puede percibir, pero se podría imaginar la evolución de restricciones topológicas en la comunicación basadas en una red de comunicaciones entre agentes donde los enlaces no siempre están activos. En nuestro sistema, los agentes podrán comunicarse entre sí. Sin embargo, debido a las restricciones topológicas mencionadas anteriormente, no podrán comunicarse con ningún agente en ningún momento. Con quién puede comunicarse un agente se definirá dinámicamente (por ejemplo, esto puede ser consecuencia de que los agentes estén lo suficientemente cerca para ponerse en contacto). Denotaremos de forma abstracta por C(ai, aj, t) la propiedad de comunicación, es decir, el hecho de que los agentes ai y aj puedan comunicarse en el tiempo t (nota que se asume que esta relación es simétrica, pero por supuesto no transitiva). Ahora estamos en posición de definir dos propiedades esenciales de nuestro sistema. Definición 4 (Camino Temporal). Existe un camino de comunicación temporal en el horizonte tf (denotado Ltf (aI, aJ)) entre ai y aj si y solo si existe una secuencia de puntos temporales t1, t2, ..., tn desde tf y una secuencia de agentes k1, k2, ..., kn tal que (i) C(aI, ak1, t1), (ii) C(akn, aJ, tn+1), (iii) ∀i ∈ [1, n], C(aki, aki+1, ti). Intuitivamente, lo que esta propiedad dice es que es posible encontrar un <br>camino temporal</br> en el futuro que permitiría vincular al agente ai y aj a través de una secuencia de agentes intermedios. Ten en cuenta que los puntos temporales no necesariamente son sucesivos, y que la secuencia de agentes puede involucrar a los mismos agentes varias veces. Definición 5 (Conexidad Temporal). Un sistema es temporalmente conexo si y solo si ∀t ∀(i, j)∈[1, n]2 Lt(ai, aj). En resumen, un sistema temporalmente conexo garantiza que cualquier agente podrá comunicarse con cualquier otro agente, sin importar cuánto tiempo pueda llevar hacerlo, en cualquier momento. Dicho de otra manera, nunca sucede que un agente esté aislado para siempre de otro agente del sistema. A continuación discutiremos en detalle cómo la comunicación tiene lugar concretamente en nuestro sistema. Recuerda que en este documento, solo consideramos el caso de intercambios bilaterales (un agente solo puede hablar con otro agente) y también asumimos que cualquier agente solo puede participar en un intercambio en una ronda dada. 3. PROTOCOLOS Y ESTRATEGIAS En esta sección, discutimos los requisitos de los protocolos de interacción que rigen el intercambio de mensajes entre agentes, y proporcionamos algunos ejemplos de la implementación de dichos protocolos. Para aclarar la presentación, distinguimos dos niveles: el nivel local, que se ocupa de la regulación de los intercambios bilaterales; y el nivel global, que regula principalmente la forma en que los agentes pueden participar realmente en una conversación. En cada nivel, separamos lo que está especificado por el protocolo y lo que se deja a las estrategias de los agentes. Protocolos y estrategias locales Comenzamos inspeccionando los protocolos y estrategias locales que regularán la comunicación entre los agentes del sistema. Al limitarnos a la comunicación bilateral, estos protocolos simplemente implicarán a dos agentes. Dicho protocolo tendrá que cumplir con un requisito básico para ser satisfactorio: consistencia (CONS) - un protocolo local debe garantizar la consistencia mutua de los agentes al finalizar (lo que implica, por supuesto, la finalización). Figura 1: Un Protocolo de Intercambio de Hipótesis [1] Un ejemplo de dicho protocolo es el protocolo descrito en [1] que se muestra en la Fig. 1. Para ilustrar aún más cómo dicho protocolo puede ser utilizado por agentes, proporcionamos algunos detalles sobre una posible estrategia: al recibir una hipótesis h1 (proponer(h1) o contra-proponer(h1)) de a1, el agente a2 se encuentra en el estado 2 y tiene las siguientes respuestas posibles: contraejemplo (si el agente conoce un ejemplo que contradice la hipótesis, o no está explicado por esta hipótesis), desafío (si el agente carece de evidencia para aceptar esta hipótesis), contra-proponer (si el agente está de acuerdo con la hipótesis pero prefiere otra), o aceptar (si es tan buena como su hipótesis favorita). Esta estrategia garantiza, entre otras propiedades, la eventual consistencia lógica mutua de los agentes involucrados [1]. Protocolo global El protocolo global regula la forma en que se iniciarán los intercambios bilaterales entre agentes. En cada turno, los agentes enviarán simultáneamente una solicitud ponderada para comunicarse con otros agentes. Este peso es un valor que mide la disposición de los agentes para conversar con el agente objetivo (en la práctica, esto puede basarse en diferentes heurísticas, pero haremos algunas suposiciones sobre las estrategias de los agentes, ver más abajo). Enviar una solicitud de este tipo es una especie de compromiso condicional para el agente. Un agente que envía una solicitud ponderada se compromete a entablar una conversación con el objetivo si no recibe y acepta otra solicitud por sí mismo. Una vez que se hayan recibido todas las solicitudes, cada agente responde con un aceptar o un rechazar. Al responder con un aceptar, un agente se compromete plenamente a participar en la conversación con el remitente. Por lo tanto, solo puede enviar una aceptación en una ronda dada, ya que un agente solo puede participar en una conversación por paso de tiempo. Cuando se hayan recibido todas las respuestas, cada agente que reciba una aceptación puede iniciar una conversación utilizando el protocolo local o enviar una cancelación si ha aceptado otra solicitud. Al final de todos los intercambios bilaterales, los agentes involucrados en la conversación son descartados del protocolo. Entonces cada uno de los agentes restantes reenvía una solicitud y el proceso se repite hasta que no se envíen más solicitudes. Estrategia global Ahora definimos cuatro requisitos para las estrategias utilizadas por los agentes, dependiendo de su rol en el protocolo: dos se refieren al rol del solicitante (cómo decidir quién es el 1000 The Sixth Intl. La Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) ¿con qué agente desea comunicarse? Los otros dos con el rol de respondedor (¿cómo decidir qué solicitud de comunicación aceptar o no?). • Disposición para resolver inconsistencias (SOLVE): los agentes desean comunicarse con cualquier otro agente a menos que sepan que son mutuamente consistentes. • Enfoque en resolver inconsistencias (FOCUS): los agentes no solicitan comunicarse con un agente con el que saben que son mutuamente consistentes. • Disposición para comunicarse (COMM): los agentes no pueden rechazar una solicitud de comunicación ponderada, a menos que acaben de recibir o enviar una solicitud con un peso mayor. • Compromiso con la solicitud de comunicación (REQU): los agentes no pueden aceptar una solicitud de comunicación ponderada si ellos mismos han enviado una solicitud de comunicación con un peso mayor. Por lo tanto, no cancelarán su solicitud a menos que hayan recibido una solicitud comunicacional con mayor peso. Ahora la estructura del protocolo, junto con las propiedades COMM+REQU, garantizan que una solicitud solo puede ser rechazada si su agente objetivo se involucra en comunicación con otro agente. Supongamos de hecho que el agente ai quiere comunicarse con aj enviando una solicitud con peso w. COMM garantiza que un agente que reciba una solicitud ponderada aceptará esta comunicación, aceptará una comunicación con un peso mayor o esperará la respuesta a una solicitud con un peso mayor. Esto asegura que la solicitud con peso máximo será aceptada y no cancelada (ya que REQU asegura que un agente que envía una solicitud solo puede cancelarla si acepta otra solicitud con un peso mayor). Por lo tanto, al menos dos agentes participarán en una conversación por ronda del protocolo global. Como el protocolo asegura que ai puede reenviar su solicitud mientras aj no está ocupado en una conversación, llegará un momento en el que aj deberá participar en una conversación, ya sea con ai u otro agente. Estos requisitos se refieren al envío y aceptación de solicitudes, pero los agentes también necesitan alguna estrategia de atribución de peso. Describimos a continuación una estrategia altruista, utilizada en nuestros experimentos. Siendo cooperativo, un agente puede querer conocer más los deseos de comunicación de otros agentes para mejorar la asignación general de intercambios a los agentes. Se añade entonces un paso de solicitud de contexto al protocolo global. Antes de enviar su solicitud ponderada elegida, los agentes asignan un peso a todos los agentes con los que están dispuestos a comunicarse, de acuerdo con algunos factores internos. En el caso más simple, este peso será 1 para todos los agentes con los que el agente no esté seguro de ser mutuamente consistentes (garantizando SOLVE), sin considerar a otros agentes para la comunicación (garantizando FOCUS). El agente luego envía una solicitud de contexto a todos los agentes con los que se considera la comunicación. Esta solicitud también proporciona información sobre el remitente (lista de comunicaciones consideradas junto con su peso). Después de recibir todas las solicitudes de contexto, los agentes responderán con un rechazo si ya están ocupados en una conversación (en cuyo caso, el agente solicitante no considerará comunicarse con ellos en este turno), o con una información que brinde al solicitante información sobre las solicitudes que ha enviado y recibido. Cuando se hayan recibido todas las respuestas, cada agente puede calcular el peso de todas las solicitudes que le conciernen. Lo hace restando del peso de su solicitud el peso de todas las solicitudes relacionadas con él o su objetivo (es decir, el peso final de la solicitud de ai a aj es Wi,j = wi,j + wj,i - ( Σ k∈R(i)-{j} wi,k + Σ k∈S(i)-{j} wk,i + Σ k∈R(j)-{i} wj,k + Σ k∈S(j)-{i} wk,j) donde wi,j es el peso de la solicitud de ai a aj, R(i) es el conjunto de índices de agentes que han recibido una solicitud de ai y S(i) es el conjunto de índices de agentes que han enviado una solicitud a ai). Luego envía finalmente una solicitud ponderada a los agentes que maximizan este peso (o esperan una solicitud) según lo descrito en el protocolo global. 4. (CONDICIONAL) CONVERGENCIA HACIA LA COHERENCIA GLOBAL En esta sección mostraremos que los requisitos relacionados con los protocolos y estrategias recién discutidos serán suficientes para garantizar que el sistema eventualmente convergerá hacia la coherencia global, bajo ciertas condiciones. Primero demostramos que, si dos agentes no son mutuamente consistentes en algún momento, entonces necesariamente habrá un momento en el futuro en el que un agente aprenderá una nueva observación, ya sea porque es nueva para el sistema, o al aprenderla de otro agente. Lema 1. Sea S un sistema poblado por n agentes a1, a2, ..., an, temporalmente conectados e involucrando percepciones limitadas para estos agentes. Sea n1 la suma de las cardinalidades de la intersección de los conjuntos de observaciones emparejados. (n1 = P (i,j)∈[1,n]2 |Oi ∩ Oj|) Sea n2 la cardinalidad de la unión de todos los conjuntos de observaciones de los agentes. (n2 = | ∪N i=1 Oi|). Si ¬MCons(ai, aj) en el tiempo t0, necesariamente existe un tiempo t > t0 tal que ya sea n1 o n2 aumentarán. Prueba. Supongamos que exista un tiempo t0 y unos índices (i, j) tal que ¬MCons(ai, aj). Utilizaremos mt0 = P (k,l)∈[1,n]2 εComm(ak, al, t0) donde εComm(ak, al, t0) = 1 si ak y al han comunicado al menos una vez desde t0, y 0 en caso contrario. La conexidad temporal garantiza que existen t1, ..., tm+1 y k1, ..., km tal que. C(ai, ak1 , t1), C(akm , aj, tm+1), y ∀p ∈ [1, m], C(akp , akp+1 , tp). Claramente, si MCons(ai, ak1), MCons(akm, aj) y ∀p, MCons(akp, akp+1), tenemos MCons(ai, aj) lo cual contradice nuestra hipótesis (siendo MCons transitivo, MCons(ai, ak1)∧MCons(ak1, ak2) implica que MCons(ai, ak2) y así sucesivamente hasta MCons(ai, akm)∧MCons(akm, aj) lo cual implica MCons(ai, aj)). Al menos dos agentes son necesariamente inconsistentes (¬MCons(ai, ak1), o ¬MCons(akm, aj), o ∃p0 t.q. ¬MCons(akp0, akp0+1)). Que ak y al sean estos dos vecinos en un momento t > t0 1. La propiedad SOLVE asegura que ya sea ak o al enviará una solicitud de comunicación al otro agente en el tiempo t. Como se mostró anteriormente, esto a su vez garantiza que al menos uno de estos agentes estará involucrado en una comunicación. Entonces hay dos posibilidades: (caso i) ak y al se comunican en el tiempo t. En este caso, sabemos que ¬MCons(ak, al). Esto y la propiedad CONS aseguran que al menos uno de los agentes debe cambiar su 1. Estrictamente hablando, la transitividad de MCons solo asegura que ak y al son inconsistentes en un tiempo t ≥ t0 que puede ser diferente del tiempo t en el que pueden comunicarse. Pero si se vuelven consistentes entre t y t (o inconsistentes entre t y t), significa que al menos uno de ellos ha cambiado su hipótesis entre t y t, es decir, después de t0. Podemos entonces aplicar el razonamiento del caso iib. El Sexto Internacional. La Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 1001 hipótesis, lo cual a su vez, dado que los agentes son autónomos, implica al menos un intercambio de observación. Pero entonces |Ok ∩Ol| está destinado a aumentar: n1(t) > n1(t0). (caso ii) ak se comunica con ap en el tiempo t. Entonces tenemos de nuevo dos posibilidades: (caso iia) ak y ap no se comunicaron desde t0. Pero luego εComm(ak, ap, t0) tenía valor 0 y toma valor 1. Por lo tanto, mt0 aumenta. (caso iib) ak y ap se comunicaron en algún momento t0 > t0. La propiedad CONS del protocolo asegura que MCons(ak, ap) en ese momento. Ahora el hecho de que se comuniquen y se ENFOQUEN implica que al menos uno de ellos cambió su hipótesis en el ínterin. El hecho de que los agentes sean autónomos implica a su vez que una nueva observación (percibida o recibida de otro agente) necesariamente provocó este cambio. El último caso garantizaría la existencia de un tiempo t > t0 y un agente aq tal que |Op ∩ Oq| o |Ok ∩ Oq| aumenten en 1 en ese momento (lo que implica que n1(t) > n1(t0)). El caso anterior significa que el agente obtiene una nueva percepción en el tiempo t. Si esa observación era desconocida en el sistema antes, entonces n2(t) > n2(t0). Si algún agente aq ya conocía esta observación antes, entonces tanto Op ∩ Oq como Ok ∩ Oq aumentan en 1 en el tiempo t (lo que implica que n1(t) > n1(t0)). Por lo tanto, ¬MCons(ai, aj) en el tiempo t0 garantiza que, o bien: −∃t > t0 t.q. n1(t ) > n1(t0); o −∃t > t0 t.q. n2(t ) > n2(t0); o −∃t > t0 t.q. mt0 aumenta en 1 en el tiempo t. Al iterar el razonamiento con t (pero manteniendo t0 como la referencia de tiempo para mt0), podemos eliminar el tercer caso (mt0 es un entero y está limitado por n2, lo que significa que después de un máximo de n2 iteraciones, necesariamente estaremos en uno de los otros dos casos). Como resultado, hemos demostrado que si ¬MCons(ai, aj) en el tiempo t0, necesariamente habrá un tiempo t tal que ya sea n1 o n2 aumentarán. Teorema 1 (Consistencia global). Sea S un sistema poblado por n agentes a1, a2, ..., an, temporalmente conectados e involucrando percepciones limitadas para estos agentes. Sea Cons(ai, aj) una propiedad de consistencia transitiva. Entonces, cualquier protocolo y estrategias que cumplan con las propiedades CONS, SOLVE, FOCUS, COMM y REQU garantizan que el sistema convergerá hacia la consistencia global. Prueba. Por el bien de la contradicción, asumamos que ∃I, J ∈ [1, N] tal que ∀t, ∃t0 > t, tal que ¬Cons(aI , aJ , t0). Usando el lema, esto implica que ∃t > t0 tal que n1(t) > n1(t0) o n2(t) > n2(t0). Pero podemos aplicar el mismo razonamiento tomando t = t, lo que nos daría t1 > t > t0 tal que ¬Cons(aI , aJ , t1), lo que nos da t > t1 tal que n1(t) > n1(t1) o n2(t) > n2(t1). Mediante iteraciones sucesivas podemos construir una secuencia t0, t1, ..., tn, que puede dividirse en dos subsecuencias t0, t1, ...tn y t0, t1, ..., tn tal que n1(t0) < n1(t1) < ... < n1(tn) y n2(t0) < n2(t1) < ... < n2(tn). Una de estas subsecuencias tiene que ser infinita. Sin embargo, n1(ti) y n2(ti) son estrictamente crecientes, enteros y acotados, lo que implica que ambos son finitos. Contradicción. Lo que el resultado anterior muestra esencialmente es que, en un sistema donde ningún agente estará aislado del resto de los agentes para siempre, solo se necesitan suposiciones muy leves sobre los protocolos y estrategias utilizados por los agentes para garantizar la convergencia hacia la consistencia del sistema en una cantidad finita de tiempo (aunque podría llevar mucho tiempo). Desafortunadamente, en muchas situaciones críticas, no será posible asumir esta conexión temporal. Dado que enfoques distribuidos como el abogado en este documento suelen presentarse como una buena manera de abordar problemas de confiabilidad o problemas de dependencia de un centro que son de suma importancia en estas aplicaciones críticas, ciertamente resulta interesante explorar más a fondo cómo se comportaría un sistema de este tipo cuando relajamos esta suposición. ESTUDIO EXPERIMENTAL Este experimento implica agentes tratando de escapar de un edificio en llamas. El entorno se describe como una cuadrícula espacial con un conjunto de paredes y (afortunadamente) algunas salidas. El tiempo y el espacio se consideran discretos. El tiempo se divide en rondas. Los agentes se localizan por su posición en la cuadrícula espacial. Estos agentes pueden moverse y comunicarse con otros agentes. En una ronda, un agente puede moverse una celda en cualquiera de las cuatro direcciones cardinales, siempre y cuando no esté bloqueado por una pared. En esta aplicación, los agentes se comunican con cualquier otro agente (pero, recuerda, solo uno) siempre y cuando este agente esté a la vista y aún no hayan intercambiado su hipótesis actual favorita. De repente, se desata un incendio en estas instalaciones. A partir de este momento, el fuego se propaga. En cada ronda, en cada caso donde haya fuego, el fuego se propaga en las cuatro direcciones. Sin embargo, el fuego no puede propagarse a través de una pared. Si el fuego se propaga en un caso donde un agente está posicionado, ese agente se quema y se considera muerto. Por supuesto, ya no puede moverse ni comunicarse. Si un agente llega a una salida, se considera que está a salvo y ya no puede ser quemado. Los agentes conocen el entorno y las reglas que rigen la dinámica de este entorno, es decir, conocen el mapa así como las reglas de propagación del fuego previamente descritas. También perciben este entorno localmente, pero no pueden ver más allá de 3 casos en cualquier dirección. Las paredes también bloquean la línea de visión, impidiendo que los agentes vean detrás de ellas. Dentro de su campo de visión, pueden ver a otros agentes y si los casos que ven están en llamas. Todas estas percepciones están memorizadas. Mostramos ahora cómo se instancia el marco abstracto presentado en el documento. • O = {Fire(x, y, t), NoFire(x, y, t), Agent(ai, x, y, t)} Las observaciones pueden ser positivas (o ∈ P(O) si ∃h ∈ H tal que h |= o) o negativas (o ∈ N(O) si ∃h ∈ H tal que h |= ¬o). • H={FireOrigin(x1, y1, t1)∧...∧FireOrigin(xl, yl, tl)} Las hipótesis son conjunciones de Orígenes de Fuego. • La relación de consistencia Cons(h, O) satisface: - coherencia: ∀o ∈ N(O), h |= ¬o. - completitud: ∀o ∈ P(O), h |= o. - minimalidad: Para todo h ∈ H, si h es coherente y completo para O, entonces h es preferido a h de acuerdo con la relación de preferencia (h ≤p h). Selecciona primero el número mínimo de orígenes, luego el más reciente (estrategia menos preemptiva [6]), y luego utiliza un ranking fijo arbitrario para discriminar ex-aequo. La relación resultante es un orden total, por lo tanto, la minimalidad implica que habrá un único h tal que Cons(O, h) para un O dado. Esto a su vez significa que MCons(ai, aj) si y solo si Cons(ai), Cons(aj) y hi = hj. Esta relación es entonces transitiva y simétrica. 1002 El Sexto Internacional. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) • Eh toma O como argumento y devuelve min≤p de la hipótesis coherente y completa para O 5.1 Evaluación Experimental Clásicamente evaluaremos la efectividad y eficiencia de diferentes protocolos de interacción (ver, por ejemplo, [3, 4]). La efectividad de un protocolo se determinará por la proporción de agentes que sobreviven al incendio respecto al número inicial de agentes involucrados en el experimento. Si este valor es alto, el protocolo ha sido efectivo para propagar la información y/o para que los agentes refinen sus hipótesis y determinen la mejor manera de salir. Eficiencia de un protocolo. Por lo general, el uso de información de apoyo implicará una sobrecarga de comunicación. Aquí asumiremos que la eficiencia de un protocolo dado está caracterizada por el flujo de datos inducido por este protocolo. En este documento solo discutiremos este aspecto con respecto a los protocolos locales. La medida principal que utilizaremos aquí es el tamaño total promedio de los mensajes intercambiados por los agentes por intercambio (teniendo en cuenta tanto el número de mensajes como el tamaño real de los mensajes, ya que podría ser que los mensajes resulten ser muy grandes, conteniendo por ejemplo un gran número de observaciones, lo que podría contrarrestar un bajo número de mensajes). 5.2 Configuraciones Experimentales Las configuraciones experimentales elegidas son las siguientes: • Topología ambiental: El rendimiento de la propagación de la información está altamente condicionado por la topología del entorno. Las habilidades de percepción de los agentes dependen de la apertura del entorno. Con un gran número de paredes, las percepciones de los agentes están limitadas, al igual que el número de posibles comunicaciones entre agentes, mientras que un entorno abierto proporcionará posibilidades óptimas de percepción y propagación de información. Por lo tanto, proponemos un índice topológico (ver abajo) como base común para caracterizar los entornos (mapas) utilizados durante las experimentaciones. El índice topológico (TI) es la proporción entre el número de celdas que pueden ser percibidas por los agentes sumadas desde todas las posiciones posibles, dividido por el número de celdas que serían percibidas desde las mismas posiciones pero sin paredes. (Cuanto más cercano a 1, más abierto es el entorno). También utilizaremos dos medidas adicionales, más clásicas [10]: la longitud del camino característico (CPL) y el coeficiente de agrupamiento (CC). • Número de agentes: la propagación de la información también depende del número inicial de agentes involucrados durante una experimentación. Por ejemplo, cuantos más agentes haya, más potenciales comunicaciones existen. Esto significa que habrá más potencial de propagación, pero también que la restricción de intercambio bilateral será más crucial. 3 El CPL es la mediana de las medias de las longitudes de los caminos más cortos que conectan cada nodo con todos los demás nodos. 4 caracterizando el grado de aislamiento de una región de un entorno en términos de accesibilidad (número de caminos aún utilizables para llegar a esta región). Mapa T.I. (%) C.P.L. C.C. 69-1 69,23 4,5 0,69 69-2 68,88 4,38 0,65 69-3 69,80 4,25 0,67 53-1 53,19 5,6 0,59 53-2 53,53 6,38 0,54 53-3 53,92 6,08 0,61 38-1 38,56 8,19 0,50 38-2 38,56 7,3 0,50 38-3 38,23 8,13 0,50 Tabla 1: Características Topológicas de los Mapas • Posiciones iniciales de los agentes- Las posiciones iniciales de los agentes tienen una influencia significativa en el comportamiento general de una instancia de nuestro sistema: estar cerca de una salida facilitará (en general) la escapatoria. 5.3 Entornos experimentales Elegimos realizar experimentos en tres índices topológicos muy diferentes (69% para entornos abiertos, 53% para entornos mixtos y 38% para entornos tipo laberinto). Figura 2: Dos mapas (izquierda: IT=69%, derecha IT=38%) Diseñamos tres mapas diferentes para cada índice (la Fig. 2 muestra dos de ellos), conteniendo el mismo número máximo de agentes (máximo 36 agentes) con una densidad máxima de un agente por celda, el mismo número de salidas y un origen de incendio similar (por ejemplo, tiempo y posición de inicio). Los tres mapas diferentes de un índice dado están diseñados de la siguiente manera. El primer plano es un modelo de un piso de un edificio existente. El segundo mapa tiene el mismo perímetro, salidas y origen del fuego que el primero, pero la cantidad y ubicación de las paredes son diferentes (las ubicaciones de las paredes son diseñadas por una heurística que crea paredes de forma aleatoria en la cuadrícula espacial de manera que no se creen habitaciones completamente cerradas y que ninguna salida quede bloqueada). El tercer mapa se caracteriza por un recinto geométrico en el que la ubicación de las paredes también está diseñada con la heurística mencionada anteriormente. La Tabla 1 resume las diferentes medidas topológicas que caracterizan estos mapas diferentes. Vale la pena señalar que los valores confirman la relevancia de TI (los mapas con un alto TI tienen un bajo CPL y un alto CC). Sin embargo, el CPL y el CC permiten refinar aún más la diferencia entre los mapas, por ejemplo, entre 53-1 y 53-2). 5.4 Resultados Experimentales Para cada trío de mapas definidos como se mencionó anteriormente, llevamos a cabo los mismos experimentos. En cada experimento, la sociedad difiere en cuanto a su proporción inicial de agentes involucrados, desde el 1% hasta el 100%. Esta proporción inicial representa el porcentaje de agentes involucrados con respecto al número máximo posible de agentes. Para cada mapa y cada proporción inicial, la Sexta Internacional. En la Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) seleccionamos aleatoriamente 100 ubicaciones iniciales de agentes diferentes. Para cada una de esas ubicaciones diferentes ejecutamos el sistema una vez para cada protocolo de interacción diferente. La efectividad de la comunicación y argumentación El primer experimento que hemos establecido tiene como objetivo probar cuán efectivo es el intercambio de hipótesis (IH), y en particular cómo los aspectos topológicos afectarán esta efectividad. Para hacerlo, hemos calculado la proporción de mejora ofrecida por ese protocolo sobre una situación en la que los agentes simplemente no podían comunicarse (sin comunicación). Para obtener más información sobre en qué medida el intercambio de hipótesis fue realmente crucial, también probamos un protocolo mucho menos elaborado que consistía en intercambios de observaciones simples (OE). Más precisamente, este protocolo requiere que cada agente almacene cualquier observación inesperada que perciba, y los agentes simplemente intercambian sus respectivas listas de observaciones cuando discuten. En este caso, el protocolo local es diferente (nota en particular que no garantiza consistencia mutua), pero el protocolo global permanece igual (con la única excepción de que la motivación de los agentes para comunicarse es sincronizar su lista de observaciones, no sus hipótesis). Si este protocolo es como máximo tan efectivo como HE, tiene la ventaja de ser más eficiente (esto es obvio en cuanto al número de mensajes, que se limitará a 2, menos directo en lo que respecta al tamaño de los mensajes, pero la observación general de que el intercambio de observaciones se puede ver como una versión simplificada del desafío es útil para ver esto). Los resultados de estos experimentos se informan en la Figura 3. Figura 3: Ganancia de la proporción de efectividad comparativa de los protocolos cuando la proporción de agentes aumenta. La primera observación que debe hacerse es que la comunicación mejora la efectividad del proceso, y esta proporción aumenta a medida que el número de agentes crece en el sistema. La segunda lección que aprendemos aquí es que la cercanía relativamente hace que la comunicación sea más efectiva que la falta de comunicación. Los mapas que muestran un T.I. del 38% están constantemente por encima de los otros dos, y el 53% sigue siendo ligeramente pero significativamente mejor que el 69%. Sin embargo, estas curvas también sugieren, quizás sorprendentemente, que HE supera a OE precisamente en aquellas situaciones donde la ganancia de la relación es menos importante (la única diferencia notable ocurre en mapas bastante abiertos donde T.I. es del 69%). Esto se puede explicar de la siguiente manera: cuando un mapa está abierto, los agentes tienen muchos posibles candidatos de explicación, y la argumentación se vuelve útil para discriminar entre ellos. Cuando un mapa es laberíntico, hay menos posibles explicaciones para un evento inesperado. Importancia del Protocolo Global El segundo conjunto de experimentos busca evaluar la importancia del diseño del protocolo global. Probamos nuestro protocolo contra un protocolo de difusión local (LB). La difusión local significa que todos los agentes vecinos percibidos por un agente estarán involucrados en una comunicación con ese agente en una ronda dada, aliviando la restricción de una sola comunicación por agente. Esto nos proporciona un límite superior aproximado sobre la posible ganancia de ratio en el sistema (para un protocolo local dado). Nuevamente, evaluamos la ganancia de la relación inducida por ese LB sobre nuestro HE clásico, para las tres clases diferentes de mapas. Los resultados se informan en la Figura 4. Figura 4: Ganancia de la proporción de transmisión local sobre el intercambio de hipótesis. Tenga en cuenta que la ganancia de la proporción es 0 cuando la proporción de agentes es del 5%, lo cual se explica fácilmente por el hecho de que corresponde a situaciones que involucran solo a dos agentes. Primero observamos que todas las clases de mapas muestran un aumento en la ganancia de la proporción a medida que aumenta el número de agentes: la ganancia alcanza entre el 10 y el 20%, dependiendo de la clase de mapas considerada. Si se compara esto con la mejora reportada en el experimento anterior, parece ser de la misma magnitud. Esto ilustra que el diseño del protocolo global no puede ser ignorado, especialmente cuando la proporción de agentes es alta. Sin embargo, también observamos que las curvas de ganancia de la proporción de efectividad tienen formas muy diferentes en ambos casos: la ganancia inducida por la precisión del protocolo local aumenta muy rápidamente con la proporción de agentes, mientras que la curva es muy suave para el global. Ahora observemos con más cuidado los resultados reportados aquí: la curva correspondiente a una TI del 53% está por encima de la correspondiente al 38%. Esto se debe a que cuanto más abierta sea un mapa, más oportunidades hay de comunicarse con más de un agente (y por lo tanto beneficiarse de la difusión). Sin embargo, también observamos que la curva para el 69% está por debajo de la del 53%. Esto se explica de la siguiente manera: en el caso del 69%, la ganancia potencial en términos de agentes sobrevivientes es mucho menor, porque nuestros protocolos ya ofrecen resultados bastante eficientes de todos modos (alcanzando rápidamente el 90%, ver Fig. 3). Una regla general podría ser que cuando el número de agentes es pequeño, se debe prestar especial atención al local 1004 de la Sexta Internacional. En el caso de que el número de agentes sea pequeño, uno puede utilizar el protocolo de la Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07), mientras que cuando ese número es grande, se debe diseñar cuidadosamente uno global (a menos que el mapa sea tan abierto que el protocolo ya sea casi óptimamente eficiente). La eficiencia de los protocolos. El experimento final reportado aquí se centra en el análisis de la eficiencia de los protocolos. Aquí analizamos el tamaño medio de la totalidad de los mensajes que son intercambiados por agentes (tamaño medio de intercambios, en resumen) utilizando los siguientes protocolos: HE, OE y dos protocolos variantes. El primero es un protocolo de intercambio de hipótesis restringidas (RHE) intermediario. RHE es el siguiente: no implica ningún desafío ni contraoferta, lo que significa que los agentes no pueden cambiar su rol durante el protocolo (esto difiere de RE en ese aspecto). En resumen, RHE permite a un agente agotar las críticas de sus socios, y eventualmente este socio adoptará la hipótesis del agente. Ten en cuenta que esto significa que la autonomía del agente no se conserva aquí (ya que un agente esencialmente aceptará cualquier hipótesis que no pueda socavar), con la esperanza de que la ganancia en eficiencia sea lo suficientemente significativa como para compensar una pérdida en efectividad. El segundo protocolo de variante es un protocolo completo de intercambio de observaciones (COE). COE utiliza los mismos principios que OE, pero incluye además todos los ejemplos críticos negativos (nofire) en el intercambio (dando así todos los ejemplos utilizados como argumentos por el protocolo de intercambio de hipótesis), mejorando así la efectividad. Los resultados para el mapa 69-1 se muestran en la Figura 5. Figura 5: Tamaño medio de los intercambios. Primero podemos observar el hecho de que el orden de los protocolos, desde el menos eficiente hasta el más eficiente, es COE, HE, RHE y luego OE. ÉL siendo más eficiente que COE demuestra que el proceso de argumentación gana eficiencia al seleccionar cuándo es necesario proporcionar ejemplos negativos, los cuales tienen menos impacto que los positivos en nuestro entorno de prueba específico. Sin embargo, al comunicar hipótesis antes de proporcionar observaciones para respaldarla (HE) en lugar de dar directamente las observaciones más cruciales (OE), el proceso de argumentación duplica el tamaño de los intercambios de datos. Es el costo de garantizar la consistencia al final del intercambio (una propiedad que OE no admite). También es significativo el hecho de que el tamaño promedio de los intercambios es ligeramente mayor cuando el número de agentes es pequeño. Esto se explica por el hecho de que en estos casos solo unos pocos agentes tienen información relevante en su posesión, y que necesitarán comunicarse mucho para llegar a un punto de vista común de la situación. Cuando el número de agentes aumenta, este conocimiento se distribuye entre más agentes que necesitan discusiones más cortas para llegar a una consistencia mutua. Como consecuencia, la ganancia relativa en eficiencia de usar RHE parece ser mejor cuando el número de agentes es pequeño: cuando es alto, difícilmente discutirán de todos modos. Finalmente, vale la pena notar que la desviación estándar para estos experimentos es bastante alta, lo que significa que la conversación no converge hacia ningún patrón estereotípico. 6. CONCLUSIÓN Este documento ha investigado las propiedades de un sistema multiagente donde cada agente (distribuido) percibe localmente su entorno e intenta alcanzar consistencia con otros agentes a pesar de severas restricciones de comunicación. En particular, hemos expuesto condiciones que permiten la convergencia e investigado experimentalmente una situación típica donde esas condiciones no pueden cumplirse. Hay muchas posibles extensiones a este trabajo, la primera siendo investigar más a fondo las propiedades de diferentes protocolos globales pertenecientes a la clase que identificamos, y su influencia en el resultado. Existen en particular muchas heurísticas, altamente dependientes del contexto del estudio, que podrían intuitivamente arrojar resultados interesantes (en nuestro estudio, seleccionar al destinatario en función de lo que se pueda inferir de sus acciones observadas podría ser una de esas heurísticas). Un candidato obvio para problemas a largo plazo se refiere a la relajación de la suposición de un sensor perfecto. 7. REFERENCIAS [1] G. Bourgne, N. Maudet y S. Pinson. Cuando los agentes comunican hipótesis en situaciones críticas. En Actas de DALT-2006, mayo de 2006. [2] P. Harvey, C. F. Chang y A. Ghose. Búsqueda distribuida basada en soporte: un nuevo enfoque para el procesamiento de restricciones multiagente. En Actas de AAMAS06, 2006. [3] H. Jung y M. Tambe. Argumentación como satisfacción de restricciones distribuida: Aplicaciones y resultados. En Actas de AGENTS01, 2001. [4] N. C. Karunatillake y N. R. Jennings. ¿Vale la pena discutir? En Actas de ArgMAS 2004, 2004. [5] S. Onta˜n´on y E. Plaza. Argumentos y contraejemplos en la deliberación conjunta basada en casos. En Actas de ArgMAS-2006, mayo de 2006. [6] D. Poole. Explicación y predicción: Una arquitectura para el razonamiento por defecto y abductivo. Inteligencia Computacional, 5(2):97-110, 1989. [7] I. Rahwan, S. D. Ramchurn, N. R. Jennings, P. McBurney, S. Parsons y L. Sonenberg. Negociación basada en argumentos. La revisión de Ingeniería del Conocimiento, 4(18):345-375, 2003. [8] N. Roos, A. ten Tije y C. Witteveen. Un protocolo para el diagnóstico multiagente con conocimiento distribuido espacialmente. En Actas de AAMAS03, 2003. [9] N. Roos, A. ten Tije y C. Witteveen. Alcanzando acuerdo diagnóstico en el diagnóstico multiagente. En Actas de AAMAS04, 2004. [10] T. Takahashi, Y. Kaneda y N. Ito. Estudio preliminar: utilizando simulaciones de RoboCupRescue para la prevención de desastres. En Actas de SRMED2004, 2004. El Sexto Internacional. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 1005 ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "topological constraint": {
            "translated_key": "restricciones topológicas",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Hypotheses Refinement under Topological Communication Constraints ∗ Gauvain Bourgne, Gael Hette, Nicolas Maudet, and Suzanne Pinson LAMSADE, Univ.",
                "Paris-Dauphine, France {bourgne,hette,maudet,pinson}@lamsade.dauphine.fr ABSTRACT We investigate the properties of a multiagent system where each (distributed) agent locally perceives its environment.",
                "Upon perception of an unexpected event, each agent locally computes its favoured hypothesis and tries to propagate it to other agents, by exchanging hypotheses and supporting arguments (observations).",
                "However, we further assume that communication opportunities are severely constrained and change dynamically.",
                "In this paper, we mostly investigate the convergence of such systems towards global consistency.",
                "We first show that (for a wide class of protocols that we shall define), the communication constraints induced by the topology will not prevent the convergence of the system, at the condition that the system dynamics guarantees that no agent will ever be isolated forever, and that agents have unlimited time for computation and arguments exchange.",
                "As this assumption cannot be made in most situations though, we then set up an experimental framework aiming at comparing the relative efficiency and effectiveness of different interaction protocols for hypotheses exchange.",
                "We study a critical situation involving a number of agents aiming at escaping from a burning building.",
                "The results reported here provide some insights regarding the design of optimal protocol for hypotheses refinement in this context.",
                "Categories and Subject Descriptors I.2.11 [Artificial Intelligence]: Distributed Artificial Intelligence-Multiagent systems General Terms Theory, Experimentation 1.",
                "INTRODUCTION We consider a multiagent system where each (distributed) agent locally perceives its environment, and we assume that some unexpected event occurs in that system.",
                "If each agent computes only locally its favoured hypothesis, it is only natural to assume that agents will seek to coordinate and refine their hypotheses by confronting their observations with other agents.",
                "If, in addition, the communication opportunities are severely constrained (for instance, agents can only communicate when they are close enough to some other agent), and dynamically changing (for instance, agents may change their locations), it becomes crucial to carefully design protocols that will allow agents to converge to some desired state of global consistency.",
                "In this paper we exhibit some sufficient conditions on the system dynamics and on the protocol/strategy structures that allow to guarantee that property, and we experimentally study some contexts where (some of) these assumptions are relaxed.",
                "While problems of diagnosis are among the venerable classics in the AI tradition, their multiagent counterparts have much more recently attracted some attention.",
                "Roos and colleagues [8, 9] in particular study a situation where a number of distributed entities try to come up with a satisfying global diagnosis of the whole system.",
                "They show in particular that the number of messages required to establish this global diagnosis is bound to be prohibitive, unless the communication is enhanced with some suitable protocol.",
                "However, they do not put any restrictions on agents communication options, and do not assume either that the system is dynamic.",
                "The benefits of enhancing communication with supporting information to make convergence to a desired global state of a system more efficient has often been put forward in the literature.",
                "This is for instance one of the main idea underlying the argumentation-based negotiation approach [7], where the desired state is a compromise between agents with conflicting preferences.",
                "Many of these works however make the assumption that this approach is beneficial to start with, and study the technical facets of the problem (or instead emphasize other advantages of using argumentation).",
                "Notable exceptions are the works of [3, 4, 2, 5], which studied in contexts different from ours the efficiency of argumentation.",
                "The rest of the paper is as follows.",
                "Section 2 specifies the basic elements of our model, and Section 3 goes on to presenting the different protocols and strategies used by the agents to exchange hypotheses and observations.",
                "We put special attention at clearly emphasizing the conditions on the system dynamics and protocols/strategies that will be exploited in the rest of the paper.",
                "Section 4 details one of 998 978-81-904262-7-5 (RPS) c 2007 IFAAMAS the main results of the paper, namely the fact that under the aforementioned conditions, the constraints that we put on the topology will not prevent the convergence of the system towards global consistency, at the condition that no agent ever gets completely lost forever in the system, and that unlimited time is allowed for computation and argument exchange.",
                "While the conditions on protocols and strategies are fairly mild, it is also clear that these system requirements look much more problematic, even frankly unrealistic in critical situations where distributed approaches are precisely advocated.",
                "To get a clearer picture of the situation induced when time is a critical factor, we have set up an experimental framework that we introduce and discuss in Section 5.",
                "The critical situation involves a number of agents aiming at escaping from a burning building.",
                "The results reported here show that the effectiveness of argument exchange crucially depends upon the nature of the building, and provide some insights regarding the design of optimal protocol for hypotheses refinement in this context. 2.",
                "BASIC NOTIONS We start by defining the basic elements of our system.",
                "Environment Let O be the (potentially infinite) set of possible observations.",
                "We assume the sensors of our agents to be perfect, hence the observations to be certain.",
                "Let H be the set of hypotheses, uncertain and revisable.",
                "Let Cons(h, O) be the consistency relation, a binary relation between a hypothesis h ∈ H and a set of observations O ⊆ O.",
                "In most cases, Cons will refer to classical consistency relation, however, we may overload its meaning and add some additional properties to that relation (in which case we will mention it).",
                "The environment may include some dynamics, and change over the course of time.",
                "We define below sequences of time points to deal with it: Definition 1 (Sequence of time points).",
                "A sequence of time points t1, t2, . . . , tn from t is an ordered set of time points t1, t2, . . . , tn such that t1 ≥ t and ∀i ∈ [1, n − 1], ti+1 ≥ ti.",
                "Agent We take a system populated by n agents a1, . . . , an.",
                "Each agent is defined as a tuple F, Oi, hi , where: • F, the set of facts, common knowledge to all agents. • Oi ∈ 2O , the set of observations made by the agent so far.",
                "We assume a perfect memory, hence this set grows monotonically. • hi ∈ H, the favourite hypothesis of the agent.",
                "A key notion governing the formation of hypotheses is that of consistency, defined below: Definition 2 (Consistency).",
                "We say that: • An agent is consistent (Cons(ai)) iff Cons(hi, Oi) (that is, its hypothesis is consistent with its observation set). • An agent ai consistent with a partner agent aj iff Cons(ai) and Cons(hi, Oj) (that is, this agent is consistent and its hypothesis can explain the observation set of the other agent). • Two agents ai and aj are mutually consistent (MCons(ai, aj)) iff Cons(ai, aj) and Cons(aj, ai). • A system is consistent iff ∀(i, j)∈[1, n]2 it is the case that MCons(ai, aj).",
                "To ensure its consistency, each agent is equipped with an abstract reasoning machinery that we shall call the explanation function Eh.",
                "This (deterministic) function takes a set of observation and returns a single prefered hypothesis (2O → H).",
                "We assume h = Eh(O) to be consistent with O by definition of Eh, so using this function on its observation set to determine its favourite hypothesis is a sure way for the agent to achieve consistency.",
                "Note however that an hypothesis does not need to be generated by Eh to be consistent with an observation set.",
                "As a concrete example of such a function, and one of the main inspiration of this work, one can cite the Theorist reasoning system [6] -as long as it is coupled with a filter selecting a single prefered theory among the ones initially selected by Theorist.",
                "Note also that hi may only be modified as a consequence of the application Eh.",
                "We refer to this as the autonomy of the agent: no other agent can directly impose a given hypothesis to an agent.",
                "As a consequence, only a new observation (being it a new perception, or an observation communicated by a fellow agent) can result in a modification of its prefered hypothesis hi (but not necessarily of course).",
                "We finally define a property of the system that we shall use in the rest of the paper: Definition 3 (Bounded Perceptions).",
                "A system involves a bounded perception for agents iff ∃n0 s.t. ∀t| ∪N i=1 Oi| ≤ n0. (That is, the number of observations to be made by the agents in the system is not infinite.)",
                "Agent Cycle Now we need to see how these agents will evolve and interact in their environment.",
                "In our context, agents evolve in a dynamic environment, and we classicaly assume the following system cycle: 1.",
                "Environment dynamics: the environment evolves according to the defined rules of the system dynamics. 2.",
                "Perception step : agents get perceptions from the environment.",
                "These perceptions are typically partial (e.g. the agent can only see a portion of a map). 3.",
                "Reasoning step: agents compare perception with predictions, seek explanations for (potential) difference(s), refine their hypothesis, draw new conclusions. 4.",
                "Communication step: agents can communicate hypotheses and observations with other agents through a defined protocol.",
                "Any agent can only be involved in one communication with another agent by step. 5.",
                "Action step: agents do some practical reasoning using the models obtained from the previous steps and select an action.",
                "They can then modify the environment by executing it.",
                "The communication of the agents will be further constrained by topological consideration.",
                "At a given time, an agent will only be able to communicate with a number of neighbours.",
                "Its connexions with these others agents may The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 999 evolve with its situation in the environment.",
                "Typically, an agent can only communicate with agents that it can sense, but one could imagine evolving <br>topological constraint</br>s on communication based on a network of communications between agents where the links are not always active.",
                "Communication In our system, agents will be able to communicate with each other.",
                "However, due to the aforementionned <br>topological constraint</br>s, they will not be able to communicate with any agents at anytime.",
                "Who an agent can communicate with will be defined dynamically (for instance, this can be a consequence of the agents being close enough to get in touch).",
                "We will abstractly denote by C(ai, aj, t) the communication property, in other words, the fact that agents ai and aj can communicate at time t (note that this relation is assumed to be symetric, but of course not transitive).",
                "We are now in a position to define two essential properties of our system.",
                "Definition 4 (Temporal Path).",
                "There exists a temporal communication path at horizon tf (noted Ltf (aI , aJ )) between ai and aj iff there exists a sequence of time points t1, t2, . . . , tn from tf and a sequence of agents k1, k2, . . . , kn s.t. (i) C(aI , ak1 , t1), (ii) C(akn , aJ , tn+1), (iii) ∀i ∈ [1, n], C(aki , aki+1 , ti) Intuitively, what this property says is that it is possible to find a temporal path in the future that would allow to link agent ai and aj via a sequence of intermediary agents.",
                "Note that the time points are not necessarily successive, and that the sequence of agents may involve the same agents several times.",
                "Definition 5 (Temporal Connexity).",
                "A system is temporaly connex iff ∀t ∀(i, j)∈[1, n]2 Lt(ai, aj) In short, a temporaly connex system guarantees that any agent will be able to communicate with any other agents, no matter how long it might take to do so, at any time.",
                "To put it another way, it is never the case that an agent will be isolated for ever from another agent of the system.",
                "We will next discuss the detail of how communication concretely takes place in our system.",
                "Remember that in this paper, we only consider the case of bilateral exchanges (an agent can only speak to a single other agent), and that we also assume that any agent can only engage in a single exchange in a given round. 3.",
                "PROTOCOLS AND STRATEGIES In this section, we discuss the requirements of the interaction protocols that govern the exchange of messages between agents, and provide some example instantiation of such protocols.",
                "To clarify the presentation, we distinguish two levels: the local level, which is concerned with the regulation of bilateral exchanges; and the global level,which essentially regulates the way agents can actually engage into a conversation.",
                "At each level, we separate what is specified by the protocol, and what is left to agents strategies.",
                "Local Protocol and Strategies We start by inspecting local protocols and strategies that will regulate the communication between the agents of the system.",
                "As we limit ourselves to bilateral communication, these protocols will simply involve two agents.",
                "Such protocol will have to meet one basic requirement to be satisfying. • consistency (CONS)- a local protocol has to guarantee the mutual consistency of agents upon termination (which implies termination of course).",
                "Figure 1: A Hypotheses Exchange Protocol [1] One example such protocol is the protocol described in [1] that is pictured in Fig. 1.",
                "To further illustrate how such protocol can be used by agents, we give some details on a possible strategy: upon receiving a hypothesis h1 (propose(h1) or counterpropose(h1)) from a1, agent a2 is in state 2 and has the following possible replies: counterexample (if the agent knows an example contradicting the hypothesis, or not explained by this hypothesis), challenge (if the agents lacks evidence to accept this hypothesis), counterpropose (if the agent agrees with the hypothesis but prefers another one), or accept (if it is indeed as good as its favourite hypothesis).",
                "This strategy guarantees, among other properties, the eventual mutual logical consistency of the involved agents [1].",
                "Global Protocol The global protocol regulates the way bilateral exchanges will be initiated between agents.",
                "At each turn, agents will concurrently send one weighted request to communicate to other agents.",
                "This weight is a value measuring the agents willingness to converse with the targeted agent (in practice, this can be based on different heuristics, but we shall make some assumptions on agents strategies, see below).",
                "Sending such a request is a kind of conditional commitment for the agent.",
                "An agent sending a weighted request commits to engage in conversation with the target if he does not receive and accept himself another request.",
                "Once all request have been received, each agent replies with either an acccept or a reject.",
                "By answering with an accept, an agent makes a full commitment to engage in conversation with the sender.",
                "Therefore, it can only send one accept in a given round, as an agent can only participate in one conversation per time step.",
                "When all response have been received, each agent receiving an accept can either initiate a conversation using the local protocol or send a cancel if it has accepted another request.",
                "At the end of all the bilateral exchanges, the agents engaged in conversation are discarded from the protocol.",
                "Then each of the remaining agents resends a request and the process iterates until no more requests are sent.",
                "Global Strategy We now define four requirements for the strategies used by agents, depending on their role in the protocol: two are concerned with the requestee role (how to decide who the 1000 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) agent wishes to communicate with? ), the other two with the responder role (how to decide which communication request to accept or not?). • Willingness to solve inconsistancies (SOLVE)-agents want to communicate with any other agents unless they know they are mutually consistent. • Focus on solving inconsistencies (FOCUS)-agents do not request communication with an agent with whom they know they are mutually consistent. • Willingness to communicate (COMM)-agents cannot refuse a weighted communication request, unless they have just received or send a request with a greater weight. • Commitment to communication request (REQU)agents cannot accept a weighted communication request if they have themselves sent a communication request with a greater weight.",
                "Therefore, they will not cancel their request unless they have received a communicational request with greater weight.",
                "Now the protocol structure, together with the properties COMM+REQU, ensure that a request can only be rejected if its target agent engages in communication with another agent.",
                "Suppose indeed that agent ai wants to communicate with aj by sending a request with weight w. COMM guarantees that an agent receiving a weighted request will either accept this communication, accept a communication with a greater weight or wait for the answer to a request with a greater weight.",
                "This ensures that the request with maximal weight will be accepted and not cancelled (as REQU ensures that an agent sending a request can only cancel it if he accepts another request with greater weight).",
                "Therefore at least two agents will engage in conversation per round of the global protocol.",
                "As the protocol ensures that ai can resend its request while aj is not engaged in a conversation, there will be a turn in which aj must engage in a conversation, either with ai or another agent.",
                "These requirements concern request sending and acceptation, but agents also need some strategy of weight attribution.",
                "We describe below an altruist strategy, used in our experiments.",
                "Being cooperative, an agent may want to know more of the communication wishes of other agents in order to improve the overall allocation of exchanges to agents.",
                "A context request step is then added to the global protocol.",
                "Before sending their chosen weighted request, agents attribute a weight to all agents they are prepared to communicate with, according to some internal factors.",
                "In the simplest case, this weight will be 1 for all agent with whom the agent is not sure of being mutually consistent (ensuring SOLVE), other agent being not considered for communication (ensuring FOCUS).",
                "The agent then sends a context request to all agents with whom communication is considered.",
                "This request also provides information about the sender (list of considered communications along with their weight).",
                "After reception of all the context requests, agents will either reply with a deny, iff they are already engaged in a conversation (in which case, the requesting agent will not consider communication with them anymore in this turn), or an inform giving the requester information about the requests it has sent and received.",
                "When all replies have been received, each agent can calculate the weight of all requests concerning it.",
                "It does so by substracting from the weight of its request the weight of all requests concerning either it or its target (that is, the final weight of the request from ai to aj is Wi,j = wi,j +wj,i − ( P k∈R(i)−{j} wi,k + P k∈S(i)−{j} wk,i + P k∈R(j)−{i} wj,k + P k∈S(j)−{i} wk,j) where wi,j is the weight of the request of ai to aj, R(i) is the set of indice of agents having received a request from ai and S(i) is the set of indice of agents having send a request to ai).",
                "It then finally sends a weighted request to the agents who maximise this weight (or wait for a request) as described in the global protocol. 4. (CONDITIONAL) CONVERGENCE TO GLOBAL CONSISTENCY In this section we will show that the requirements regarding protocols and strategies just discussed will be sufficient to ensure that the system will eventually converge towards global consistency, under some conditions.",
                "We first show that, if two agents are not mutually consistent at some time, then there will be necessarily a time in the future such that an agent will learn a new observation, being it because it is new for the system, or by learning it from another agent.",
                "Lemma 1.",
                "Let S be a system populated by n agents a1, a2, ..., an, temporaly connex, and involving bounded perceptions for these agents.",
                "Let n1 be the sum of cardinalities of the intersection of pairwise observation sets. (n1 = P (i,j)∈[1,n]2 |Oi ∩ Oj|) Let n2 be the cardinality of the union of all agents observations sets. (n2 = | ∪N i=1 Oi|).",
                "If ¬MCons(ai, aj) at time t0, there is necessarily a time t > t0 s.t. either n1 or n2 will increase.",
                "Proof.",
                "Suppose that there exist a time t0 and indices (i, j) s.t. ¬MCons(ai, aj).",
                "We will use mt0 = P (k,l)∈[1,n]2 εComm(ak, al, t0) where εComm(ak, al, t0) = 1 if ak and al have communicated at least once since t0, and 0 otherwise.",
                "Temporal connexity guarantees that there exist t1, ..., tm+1 and k1, ..., km s.t.",
                "C(ai, ak1 , t1), C(akm , aj, tm+1), and ∀p ∈ [1, m], C(akp , akp+1 , tp).",
                "Clearly, if MCons(ai, ak1 ), MCons(akm , aj) and ∀p, MCons(akp , akp+1 ), we have MCons(ai, aj) which contradicts our hypothesis (MCons being transitive, MCons(ai, ak1 )∧MCons(ak1 , ak2 ) implies that MCons(ai, ak2 ) and so on till MCons(ai, akm )∧ MCons(akm , aj) which implies MCons(ai, aj) ).",
                "At least two agents are then necessarily inconsistent (¬MCons(ai, ak1 ), or ¬MCons(akm , aj), or ∃p0 t.q. ¬MCons(akp0 , akp0+1 )).",
                "Let ak and al be these two neighbours at a time t > t0 1 .",
                "The SOLVE property ensures that either ak or al will send a communication request to the other agent at time t .",
                "As shown before, this in turn ensures that at least one of these agents will be involved in a communication.",
                "Then there are two possibilities: (case i) ak and al communicate at time t .",
                "In this case, we know that ¬MCons(ak, al).",
                "This and the CONS property ensures that at least one of the agents must change its 1 Strictly speaking, the transitivity of MCons only ensure that ak and al are inconsistent at a time t ≥ t0 that can be different from the time t at which they can communicate.",
                "But if they become consistent between t and t (or inconsistent between t and t ), it means that at least one of them have changed its hypothesis between t and t , that is, after t0.",
                "We can then apply the reasoning of case iib.",
                "The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 1001 hypothesis, which in turn, since agents are autonomous, implies at least one exchange of observation.",
                "But then |Ok ∩Ol| is bound to increase: n1(t ) > n1(t0). (case ii) ak communicates with ap at time t .",
                "We then have again two possibilities: (case iia) ak and ap did not communicate since t0.",
                "But then εComm(ak, ap, t0) had value 0 and takes value 1.",
                "Hence mt0 increases. (case iib) ak and ap did communicate at some time t0 > t0.",
                "The CONS property of the protocol ensures that MCons(ak, ap) at that time.",
                "Now the fact that they communicate and FOCUS implies that at least one of them did change its hypothesis in the meantime.",
                "The fact that agents are autonomous implies in turn that a new observation (perceived or received from another agent) necessarily provoked this change.",
                "The latter case would ensure the existence of a time t > t0 and an agent aq s.t. either |Op ∩Oq| or |Ok ∩Oq| increases of 1 at that time (implying n1(t ) > n1(t0)).",
                "The former case means that the agent gets a new perception o at time t .",
                "If that observation was unknown in the system before, then n2(t ) > n2(t0).",
                "If some agent aq already knew this observation before, then either Op ∩ Oq or Ok ∩ Oq increases of 1 at time t (which implies that n1(t ) > n1(t0)).",
                "Hence, ¬MCons(ai, aj) at time t0 guarantees that, either: −∃t > t0 t.q. n1(t ) > n1(t0); or −∃t > t0 t.q. n2(t ) > n2(t0); or −∃t > t0 t.q. mt0 increases of 1 at time t .",
                "By iterating the reasoning with t (but keeping t0 as the time reference for mt0 ), we can eliminate the third case (mt0 is integer and bounded by n2 , which means that after a maximum of n2 iterations, we necessarily will be in one of two other cases.)",
                "As a result, we have proven that if ¬MCons(ai, aj) at time t0, there is necessarily a time t s.t. either n1 or n2 will increase.",
                "Theorem 1 (Global consistency).",
                "Let S be a system populated by n agents a1, a2, ..., an, temporaly connex, and involving bounded perceptions for these agents.",
                "Let Cons(ai, aj) be a transitive consistency property.",
                "Then any protocol and strategies satisfying properties CONS, SOLVE, FOCUS, COMM and REQU guarantees that the system will converge towards global consistency.",
                "Proof.",
                "For the sake of contradiction, let us assume ∃I, J ∈ [1, N] s.t. ∀t, ∃t0 > t, t.q. ¬Cons(aI , aJ , t0).",
                "Using the lemma, this implies that ∃t > t0 s.t. either n1(t ) > n1(t0) or n2(t ) > n2(t0).",
                "But we can apply the same reasoning taking t = t , which would give us t1 > t > t0 s.t. ¬Cons(aI , aJ , t1), which gives us t > t1 s.t. either n1(t ) > n1(t1) or n2(t ) > n2(t1).",
                "By successive iterations we can then construct a sequence t0, t1, ..., tn, which can be divided in two sub-sequences t0, t1, ...tn and t0 , t1 , ..., tn s.t. n1(t0) < n1(t1) < ... < n1(tn) and n2(t0 ) < n2(t1 ) < ... < n2(tn).",
                "One of these sub-sequences has to be infinite.",
                "However, n1(ti) and n2(ti ) are strictly growing, integer, and bounded, which implies that both are finite.",
                "Contradiction.",
                "What the previous result essentially shows is that, in a system where no agent will be isolated from the rest of the agents for ever, only very mild assumptions on the protocols and strategies used by agents suffice to guarantee convergence towards system consistency in a finite amount of time (although it might take very long).",
                "Unfortunately, in many critical situations, it will not be possible to assume this temporal connexity.",
                "As distributed approaches as the one advocated in this paper are precisely often presented as a good way to tackle problems of reliability or problems of dependence to a center that are of utmost importance in these critical applications, it is certainly interesting to further explore how such a system would behave when we relax this assumption. 5.",
                "EXPERIMENTAL STUDY This experiment involves agents trying to escape from a burning building.",
                "The environment is described as a spatial grid with a set of walls and (thankfully) some exits.",
                "Time and space are considered discrete.",
                "Time is divided in rounds.",
                "Agents are localised by their position on the spatial grid.",
                "These agents can move and communicate with other agents.",
                "In a round, an agent can move of one cell in any of the four cardinal directions, provided it is not blocked by a wall.",
                "In this application, agents communicate with any other agent (but, recall, a single one) given that this agent is in view, and that they have not yet exchanged their current favoured hypothesis.",
                "Suddenly, a fire erupts in these premises.",
                "From this moment, the fire propagates.",
                "Each round, for each cases where there is fire, the fire propagates in the four directions.",
                "However, the fire cannot propagate through a wall.",
                "If the fire propagates in a case where an agent is positioned, that agent burns and is considered dead.",
                "It can of course no longer move nor communicate.",
                "If an agent gets to an exit, it is considered saved, and can no longer be burned.",
                "Agents know the environment and the rules governing the dynamics of this environment, that is, they know the map as well as the rules of fire propagation previously described.",
                "They also locally perceive this environment, but cannot see further than 3 cases away, in any direction.",
                "Walls also block the line of view, preventing agents from seeing behind them.",
                "Within their sight, they can see other agents and whether or not the cases they see are on fire.",
                "All these perceptions are memorised.",
                "We now show how this instantiates the abstract framework presented the paper. • O = {Fire(x, y, t), NoFire(x, y, t), Agent(ai, x, y, t)} Observations can then be positive (o ∈ P(O) iff ∃h ∈ H s.t. h |= o) or negative (o ∈ N(O) iff ∃h ∈ H s.t. h |= ¬o). • H={FireOrigin(x1, y1, t1)∧...∧FireOrigin(xl, yl, tl)} Hypotheses are conjunctions of FireOrigins. • Cons(h, O) consistency relation satisfies: - coherence : ∀o ∈ N(O), h |= ¬o. - completeness : ∀o ∈ P(O), h |= o. - minimality : For all h ∈ H, if h is coherent and complete for O, then h is prefered to h according to the preference relation (h ≤p h ).2 2 Selects first the minimal number of origins, then the most recent (least preemptive strategy [6]), then uses some arbitrary fixed ranking to discriminate ex-aequo.",
                "The resulting relation is a total order, hence minimality implies that there will be a single h s.t.Cons(O, h) for a given O.",
                "This in turn means that MCons(ai, aj) iff Cons(ai), Cons(aj), and hi = hj.",
                "This relation is then transitive and symmetric. 1002 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) • Eh takes O as argument and returns min≤p of the coherent and complete hypothesis for O 5.1 Experimental Evaluation We will classically (see e.g. [3, 4]) assess the effectiveness and efficiency of different interaction protocols.",
                "Effectiveness of a protocol The proportion of agents surviving the fire over the initial number of agents involved in the experiment will determine the effectiveness of a given protocol.",
                "If this value is high, the protocol has been effective to propagate the information and/or for the agents to refine their hypotheses and determine the best way to the exit.",
                "Efficiency of a protocol Typically, the use of supporting information will involve a communication overhead.",
                "We will assume here that the efficiency of a given protocol is characterised by the data flow induced by this protocol.",
                "In this paper we will only discuss this aspect wrt. local protocols.",
                "The main measure that we shall then use here is the mean total size of messages that are exchanged by agents per exchange (hence taking into account both the number of messages and the actual size of the messages, because it could be that messages happen to be very big, containing e.g. a large number of observations, which could counter-balance a low number of messages). 5.2 Experimental Settings The chosen experimental settings are the following: • Environmental topology- Performances of information propagation are highly constrained by the environment topology.",
                "The perception skills of the agents depend on the openness of the environment.",
                "With a large number of walls the perceptions of agents are limited, and also the number of possible inter-agent communications, whereas an open environment will provide optimal possibilities of perception and information propagation.",
                "Thus, we propose a topological index (see below) as a common basis to charaterize the environments (maps) used during experimentations.",
                "The topological index (TI) is the ratio of the number of cells that can be perceived by agents summed up from all possible positions, divided by the number of cells that would be perceived from the same positions but without any walls. (The closer to 1, the more open the environment).",
                "We shall also use two additional, more classical [10], measures: the characteristic path length3 (CPL) and the clustering coefficient4 (CC). • Number of agents- The propagation of information also depends on the initial number of agents involved during an experimentation.",
                "For instance, the more agents, the more potential communications there is.",
                "This means that there will be more potential for propagation, but also that the bilateral exchange restriction will be more crucial. 3 The CPL is the median of the means of the shortest path lengths connecting each node to all other nodes. 4 characterising the isolation degree of a region of an environment in terms of acessibility (number of roads still usable to reach this region).",
                "Map T.I. (%) C.P.L.",
                "C.C. 69-1 69,23 4,5 0,69 69-2 68,88 4,38 0,65 69-3 69,80 4,25 0,67 53-1 53,19 5,6 0,59 53-2 53,53 6,38 0,54 53-3 53,92 6,08 0,61 38-1 38,56 8,19 0,50 38-2 38,56 7,3 0,50 38-3 38,23 8,13 0,50 Table 1: Topological Characteristics of the Maps • Initial positions of the agents- Initial positions of the agents have a significant influence on the overall behavior of an instance of our system: being close from an exit will (in general) ease the escape. 5.3 Experimental environments We choose to realize experiments on three very different topological indexes (69% for open environments, 53% for mixed environments, and 38% for labyrinth-like environments).",
                "Figure 2: Two maps (left: TI=69%, right TI=38%) We designed three different maps for each index (Fig. 2 shows two of them), containing the same maximum number of agents (36 agents max.) with a maximum density of one agent per cell, the same number of exits and a similar fire origin (e.g. starting time and position).",
                "The three differents maps of a given index are designed as follows.",
                "The first map is a model of an existing building floor.",
                "The second map has the same enclosure, exits and fire origin as the first one, but the number and location of walls are different (wall locations are designed by an heuristic which randomly creates walls on the spatial grid such that no fully closed rooms are created and that no exit is closed).",
                "The third map is characterised by geometrical enclosure in wich walls location is also designed with the aforementioned heuristic.",
                "Table 1 summarizes the different topological measures characterizing these different maps.",
                "It is worth pointing out that the values confirm the relevance of TI (maps with a high TI have a low CPL and a high CC.",
                "However the CPL and CC allows to further refine the difference between the maps, e.g. between 53-1 and 53-2). 5.4 Experimental Results For each triple of maps defined as above we conduct the same experiments.",
                "In each experiment, the society differs in terms of its initial proportion of involved agents, from 1% to 100%.",
                "This initial proportion represents the percentage of involved agents with regards to the possible maximum number of agents.",
                "For each map and each initial proportion, The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 1003 we select randomly 100 different initial agents locations.",
                "For each of those different locations we execute the system one time for each different interaction protocol.",
                "Effectiveness of Communication and Argumentation The first experiment that we set up aims at testing how effective is hypotheses exchange (HE), and in particular how the topological aspects will affect this effectiveness.",
                "In order to do so, we have computed the ratio of improvement offered by that protocol over a situation where agents could simply not communicate (no comm).",
                "To get further insights as to what extent the hypotheses exchange was really crucial, we also tested a much less elaborated protocol consisting of mere observation exchanges (OE).",
                "More precisely, this protocol requires that each agent stores any unexpected observation that it perceives, and agents simply exchange their respective lists of observations when they discuss.",
                "In this case, the local protocol is different (note in particular that it does not guarantee mutual consistency), but the global protocol remains the same (at the only exception that agents motivation to communicate is to synchronise their list of observations, not their hypothesis).",
                "If this protocol is at best as effective as HE, it has the advantage of being more efficient (this is obvious wrt the number of messages which will be limited to 2, less straightforward as far as the size of messages is concerned, but the rough observation that the exchange of observations can be viewed as a flat version of the challenge is helpful to see this).",
                "The results of these experiments are reported in Fig. 3.",
                "Figure 3: Comparative effectiveness ratio gain of protocols when the proportion of agents augments The first observation that needs to be made is that communication improves the effectiveness of the process, and this ratio increases as the number of agents grows in the system.",
                "The second lesson that we learn here is that closeness relatively makes communication more effective over non communication.",
                "Maps exhibiting a T.I. of 38% are constantly above the two others, and 53% are still slightly but significantly better than 69%.",
                "However, these curves also suggest, perhaps surprisingly, that HE outperforms OE in precisely those situations where the ratio gain is less important (the only noticeable difference occurs for rather open maps where T.I. is 69%).",
                "This may be explained as follows: when a map is open, agents have many potential explanation candidates, and argumentation becomes useful to discriminate between those.",
                "When a map is labyrinth-like, there are fewer possible explanations to an unexpected event.",
                "Importance of the Global Protocol The second set of experiments seeks to evaluate the importance of the design of the global protocol.",
                "We tested our protocol against a local broadcast (LB) protocol.",
                "Local broadcast means that all the neighbours agents perceived by an agent will be involved in a communication with that agent in a given round -we alleviate the constraint of a single communication by agent.",
                "This gives us a rough upper bound upon the possible ratio gain in the system (for a given local protocol).",
                "Again, we evaluated the ratio gain induced by that LB over our classical HE, for the three different classes of maps.",
                "The results are reported in Fig. 4.",
                "Figure 4: Ratio gain of local broadcast over hypotheses exchange Note to begin with that the ratio gain is 0 when the proportion of agents is 5%, which is easily explained by the fact that it corresponds to situations involving only two agents.",
                "We first observe that all classes of maps witness a ratio gain increasing when the proportion of agents augments: the gain reaches 10 to 20%, depending on the class of maps considered.",
                "If one compares this with the improvement reported in the previous experiment, it appears to be of the same magnitude.",
                "This illustrates that the design of the global protocol cannot be ignored, especially when the proportion of agents is high.",
                "However, we also note that the effectiveness ratio gain curves have very different shapes in both cases: the gain induced by the accuracy of the local protocol increases very quickly with the proportion of agents, while the curve is really smooth for the global one.",
                "Now let us observe more carefully the results reported here: the curve corresponding to a TI of 53% is above that corresponding to 38%.",
                "This is so because the more open a map, the more opportunities to communicate with more than one agent (and hence benefits from broadcast).",
                "However, we also observe that curve for 69% is below that for 53%.",
                "This is explained as follows: in the case of 69%, the potential gain to be made in terms of surviving agents is much lower, because our protocols already give rather efficient outcomes anyway (quickly reaching 90%, see Fig. 3).",
                "A simple rule of thumb could be that when the number of agents is small, special attention should be put on the local 1004 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) protocol, whereas when that number is large, one should carefully design the global one (unless the map is so open that the protocol is already almost optimally efficient).",
                "Efficiency of the Protocols The final experiment reported here is concerned with the analysis of the efficiency of the protocols.",
                "We analysis here the mean size of the totality of the messages that are exchanged by agents (mean size of exchanges, for short) using the following protocols: HE, OE, and two variant protocols.",
                "The first one is an intermediary restricted hypotheses exchange protocol (RHE).",
                "RHE is as follows: it does not involve any challenge nor counter-propose, which means that agents cannot switch their role during the protocol (this differs from RE in that respect).",
                "In short, RHE allows an agent to exhaust its partners criticism, and eventually this partner will come to adopt the agents hypothesis.",
                "Note that this means that the autonomy of the agent is not preserved here (as an agent will essentially accept any hypothesis it cannot undermine), with the hope that the gain in efficiency will be significant enough to compensate a loss in effectiveness.",
                "The second variant protocol is a complete observation exchange protocol (COE).",
                "COE uses the same principles as OE, but includes in addition all critical negative examples (nofire) in the exchange (thus giving all examples used as arguments by the hypotheses exchanges protocol), hence improving effectiveness.",
                "Results for map 69-1 are shown on Fig. 5.",
                "Figure 5: Mean size of exchanges First we can observe the fact that the ordering of the protocols, from the least efficient to the most efficient, is COE, HE, RHE and then OE.",
                "HE being more efficient than COE proves that the argumentation process gains efficiency by selecting when it is needed to provide negative example, which have less impact that positive ones in our specific testbed.",
                "However, by communicating hypotheses before eventually giving observation to support it (HE) instead of directly giving the most crucial observations (OE), the argumentation process doubles the size of data exchanges.",
                "It is the cost for ensuring consistency at the end of the exchange (a property that OE does not support).",
                "Also significant is the fact the the mean size of exchanges is slightly higher when the number of agents is small.",
                "This is explained by the fact that in these cases only a very few agents have relevant informations in their possession, and that they will need to communicate a lot in order to come up with a common view of the situation.",
                "When the number of agents increases, this knowledge is distributed over more agents which need shorter discussions to get to mutual consistency.",
                "As a consequence, the relative gain in efficiency of using RHE appears to be better when the number of agents is small: when it is high, they will hardly argue anyway.",
                "Finally, it is worth noticing that the standard deviation for these experiments is rather high, which means that the conversation do not converge to any stereotypic pattern. 6.",
                "CONCLUSION This paper has investigated the properties of a multiagent system where each (distributed) agent locally perceives its environment, and tries to reach consistency with other agents despite severe communication restrictions.",
                "In particular we have exhibited conditions allowing convergence, and experimentally investigated a typical situation where those conditions cannot hold.",
                "There are many possible extensions to this work, the first being to further investigate the properties of different global protocols belonging to the class we identified, and their influence on the outcome.",
                "There are in particular many heuristics, highly dependent on the context of the study, that could intuitively yield interesting results (in our study, selecting the recipient on the basis of what can be inferred from his observed actions could be such a heuristic).",
                "One obvious candidate for longer term issues concern the relaxation of the assumption of perfect sensing. 7.",
                "REFERENCES [1] G. Bourgne, N. Maudet, and S. Pinson.",
                "When agents communicate hypotheses in critical situations.",
                "In Proceedings of DALT-2006, May 2006. [2] P. Harvey, C. F. Chang, and A. Ghose.",
                "Support-based distributed search: a new approach for multiagent constraint processing.",
                "In Proceedings of AAMAS06, 2006. [3] H. Jung and M. Tambe.",
                "Argumentation as distributed constraint satisfaction: Applications and results.",
                "In Proceedings of AGENTS01, 2001. [4] N. C. Karunatillake and N. R. Jennings.",
                "Is it worth arguing?",
                "In Proceedings of ArgMAS 2004, 2004. [5] S. Onta˜n´on and E. Plaza.",
                "Arguments and counterexamples in case-based joint deliberation.",
                "In Proceedings of ArgMAS-2006, May 2006. [6] D. Poole.",
                "Explanation and prediction: An architecture for default and abductive reasoning.",
                "Computational Intelligence, 5(2):97-110, 1989. [7] I. Rahwan, S. D. Ramchurn, N. R. Jennings, P. McBurney, S. Parsons, and L. Sonenberg.",
                "Argumention-based negotiation.",
                "The Knowledge Engineering Review, 4(18):345-375, 2003. [8] N. Roos, A. ten Tije, and C. Witteveen.",
                "A protocol for multi-agent diagnosis with spatially distributed knowledge.",
                "In Proceedings of AAMAS03, 2003. [9] N. Roos, A. ten Tije, and C. Witteveen.",
                "Reaching diagnostic agreement in multiagent diagnosis.",
                "In Proceedings of AAMAS04, 2004. [10] T. Takahashi, Y. Kaneda, and N. Ito.",
                "Preliminary study - using robocuprescue simulations for disasters prevention.",
                "In Proceedings of SRMED2004, 2004.",
                "The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 1005"
            ],
            "original_annotated_samples": [
                "Typically, an agent can only communicate with agents that it can sense, but one could imagine evolving <br>topological constraint</br>s on communication based on a network of communications between agents where the links are not always active.",
                "However, due to the aforementionned <br>topological constraint</br>s, they will not be able to communicate with any agents at anytime."
            ],
            "translated_annotated_samples": [
                "Normalmente, un agente solo puede comunicarse con agentes que puede percibir, pero se podría imaginar la evolución de <br>restricciones topológicas</br> en la comunicación basadas en una red de comunicaciones entre agentes donde los enlaces no siempre están activos.",
                "Sin embargo, debido a las <br>restricciones topológicas</br> mencionadas anteriormente, no podrán comunicarse con ningún agente en ningún momento."
            ],
            "translated_text": "Refinamiento de hipótesis bajo restricciones de comunicación topológica ∗ Gauvain Bourgne, Gael Hette, Nicolas Maudet y Suzanne Pinson LAMSADE, Univ. Investigamos las propiedades de un sistema multiagente donde cada agente (distribuido) percibe localmente su entorno. Tras la percepción de un evento inesperado, cada agente calcula localmente su hipótesis favorita e intenta propagarla a otros agentes, intercambiando hipótesis y argumentos de apoyo (observaciones). Sin embargo, también asumimos que las oportunidades de comunicación están severamente limitadas y cambian dinámicamente. En este artículo, investigamos principalmente la convergencia de dichos sistemas hacia la consistencia global. Primero demostramos que (para una amplia clase de protocolos que definiremos), las restricciones de comunicación inducidas por la topología no impedirán la convergencia del sistema, bajo la condición de que la dinámica del sistema garantice que ningún agente quedará aislado para siempre, y que los agentes tengan tiempo ilimitado para la computación y el intercambio de argumentos. Dado que esta suposición no se puede hacer en la mayoría de las situaciones, establecimos un marco experimental con el objetivo de comparar la eficiencia y efectividad relativa de diferentes protocolos de interacción para el intercambio de hipótesis. Estudiamos una situación crítica que implica a varios agentes que intentan escapar de un edificio en llamas. Los resultados reportados aquí proporcionan algunas ideas sobre el diseño de un protocolo óptimo para el refinamiento de hipótesis en este contexto. Categorías y Descriptores de Asignaturas I.2.11 [Inteligencia Artificial]: Inteligencia Artificial Distribuida-Sistemas Multiagente Términos Generales Teoría, Experimentación 1. INTRODUCCIÓN Consideramos un sistema multiagente donde cada agente (distribuido) percibe localmente su entorno, y asumimos que ocurre un evento inesperado en ese sistema. Si cada agente calcula solo localmente su hipótesis preferida, es natural asumir que los agentes buscarán coordinar y refinar sus hipótesis confrontando sus observaciones con otros agentes. Si, además, las oportunidades de comunicación están severamente limitadas (por ejemplo, los agentes solo pueden comunicarse cuando están lo suficientemente cerca de otro agente) y cambian dinámicamente (por ejemplo, los agentes pueden cambiar sus ubicaciones), se vuelve crucial diseñar cuidadosamente protocolos que permitan a los agentes converger hacia algún estado deseado de consistencia global. En este documento presentamos algunas condiciones suficientes sobre la dinámica del sistema y sobre las estructuras de protocolo/estrategia que permiten garantizar esa propiedad, y estudiamos experimentalmente algunos contextos donde (algunas de) estas suposiciones se relajan. Si bien los problemas de diagnóstico son uno de los clásicos venerables en la tradición de la IA, sus contrapartes multiagentes han atraído atención mucho más recientemente. Roos y sus colegas [8, 9] en particular estudian una situación en la que un número de entidades distribuidas intentan llegar a un diagnóstico global satisfactorio de todo el sistema. Ellos muestran en particular que el número de mensajes necesarios para establecer este diagnóstico global está destinado a ser prohibitivo, a menos que la comunicación se mejore con algún protocolo adecuado. Sin embargo, no imponen restricciones a las opciones de comunicación de los agentes, ni asumen que el sistema es dinámico. Los beneficios de mejorar la comunicación con información de apoyo para hacer que la convergencia a un estado global deseado de un sistema sea más eficiente, a menudo se ha planteado en la literatura. Esta es, por ejemplo, una de las ideas principales que subyacen al enfoque de negociación basado en argumentos [7], donde el estado deseado es un compromiso entre agentes con preferencias conflictivas. Sin embargo, muchos de estos trabajos parten del supuesto de que este enfoque es beneficioso para comenzar y estudian los aspectos técnicos del problema (o en su lugar enfatizan otras ventajas de utilizar la argumentación). Excepciones notables son las obras de [3, 4, 2, 5], que estudiaron en contextos diferentes al nuestro la eficiencia de la argumentación. El resto del documento es el siguiente. La Sección 2 especifica los elementos básicos de nuestro modelo, y la Sección 3 continúa presentando los diferentes protocolos y estrategias utilizados por los agentes para intercambiar hipótesis y observaciones. Ponemos especial atención en enfatizar claramente las condiciones de la dinámica del sistema y los protocolos/estrategias que se explotarán en el resto del documento. La sección 4 detalla uno de los principales resultados del artículo, a saber, el hecho de que bajo las condiciones mencionadas, las restricciones que imponemos en la topología no impedirán la convergencia del sistema hacia la consistencia global, siempre y cuando ningún agente se pierda completamente para siempre en el sistema, y se permita un tiempo ilimitado para la computación y el intercambio de argumentos. Si bien las condiciones en los protocolos y estrategias son bastante suaves, también es claro que estos requisitos del sistema parecen mucho más problemáticos, incluso francamente poco realistas en situaciones críticas donde se abogan precisamente por enfoques distribuidos. Para obtener una imagen más clara de la situación inducida cuando el tiempo es un factor crítico, hemos establecido un marco experimental que presentamos y discutimos en la Sección 5. La situación crítica implica a varios agentes que intentan escapar de un edificio en llamas. Los resultados reportados aquí muestran que la efectividad del intercambio de argumentos depende crucialmente de la naturaleza del edificio, y proporcionan algunas ideas sobre el diseño de un protocolo óptimo para el refinamiento de hipótesis en este contexto. CONCEPTOS BÁSICOS Comenzamos definiendo los elementos básicos de nuestro sistema. Deje que O sea el conjunto (potencialmente infinito) de observaciones posibles. Suponemos que los sensores de nuestros agentes son perfectos, por lo tanto, las observaciones son seguras. Sea H el conjunto de hipótesis, incierto y revisable. Sea Cons(h, O) la relación de consistencia, una relación binaria entre una hipótesis h ∈ H y un conjunto de observaciones O ⊆ O. En la mayoría de los casos, Cons se referirá a la relación de consistencia clásica, sin embargo, podemos sobrecargar su significado y añadir algunas propiedades adicionales a esa relación (en cuyo caso lo mencionaremos). El entorno puede incluir cierta dinámica y cambiar con el transcurso del tiempo. Definimos a continuación secuencias de puntos temporales para tratar con ello: Definición 1 (Secuencia de puntos temporales). Una secuencia de puntos temporales t1, t2, . . . , tn de t es un conjunto ordenado de puntos temporales t1, t2, . . . , tn tal que t1 ≥ t y ∀i ∈ [1, n − 1], ti+1 ≥ ti. Tomamos un sistema poblado por n agentes a1, . . . , an. Cada agente se define como una tupla F, Oi, hi, donde: • F, el conjunto de hechos, conocimiento común a todos los agentes. • Oi ∈ 2O, el conjunto de observaciones realizadas por el agente hasta el momento. Suponemos una memoria perfecta, por lo tanto, este conjunto crece de forma monótona. • hi ∈ H, la hipótesis favorita del agente. Una noción clave que rige la formación de hipótesis es la de consistencia, definida a continuación: Definición 2 (Consistencia). Decimos que: • Un agente es consistente (Cons(ai)) si y solo si Cons(hi, Oi) (es decir, su hipótesis es consistente con su conjunto de observaciones). • Un agente ai es consistente con un agente compañero aj si y solo si Cons(ai) y Cons(hi, Oj) (es decir, este agente es consistente y su hipótesis puede explicar el conjunto de observaciones del otro agente). • Dos agentes ai y aj son mutuamente consistentes (MCons(ai, aj)) si y solo si Cons(ai, aj) y Cons(aj, ai). • Un sistema es consistente si y solo si para todo (i, j) ∈ [1, n]2 se cumple que MCons(ai, aj). Para garantizar su consistencia, cada agente está equipado con una maquinaria de razonamiento abstracto que llamaremos la función de explicación Eh. Esta función (determinística) toma un conjunto de observaciones y devuelve una única hipótesis preferida (2O → H). Suponemos que h = Eh(O) para ser consistente con O por definición de Eh, por lo que usar esta función en su conjunto de observaciones para determinar su hipótesis favorita es una forma segura para que el agente logre consistencia. Sin embargo, cabe destacar que una hipótesis no necesita ser generada por Eh para ser consistente con un conjunto de observaciones. Como ejemplo concreto de tal función, y una de las principales inspiraciones de este trabajo, se puede citar el sistema de razonamiento Theorist [6], siempre y cuando esté acoplado con un filtro que seleccione una teoría preferida entre las inicialmente seleccionadas por Theorist. También hay que tener en cuenta que hi solo puede ser modificado como consecuencia de la aplicación de Eh. Nos referimos a esto como la autonomía del agente: ningún otro agente puede imponer directamente una hipótesis dada a un agente. Como consecuencia, solo una nueva observación (ya sea una nueva percepción o una observación comunicada por otro agente) puede resultar en una modificación de su hipótesis preferida hi (pero no necesariamente, por supuesto). Finalmente definimos una propiedad del sistema que utilizaremos en el resto del artículo: Definición 3 (Percepciones Acotadas). Un sistema implica una percepción limitada para los agentes si y solo si existe un n0 tal que para todo t, la unión de N observaciones realizadas por los agentes es menor o igual a n0. (Es decir, el número de observaciones a realizar por los agentes en el sistema no es infinito.) Ahora necesitamos ver cómo evolucionarán e interactuarán estos agentes en su entorno. En nuestro contexto, los agentes evolucionan en un entorno dinámico, y asumimos clásicamente el siguiente ciclo del sistema: 1. Dinámica del entorno: el entorno evoluciona de acuerdo con las reglas definidas de la dinámica del sistema. 2. Paso de percepción: los agentes obtienen percepciones del entorno. Estas percepciones suelen ser parciales (por ejemplo, el agente solo puede ver una parte de un mapa). 3. Paso de razonamiento: los agentes comparan la percepción con las predicciones, buscan explicaciones para las diferencias (potenciales), refinan su hipótesis, y sacan nuevas conclusiones. 4. Paso de comunicación: los agentes pueden comunicar hipótesis y observaciones con otros agentes a través de un protocolo definido. Cualquier agente solo puede estar involucrado en una comunicación con otro agente en el paso 5. Paso de acción: los agentes realizan un razonamiento práctico utilizando los modelos obtenidos de los pasos anteriores y seleccionan una acción. Ellos pueden modificar el entorno ejecutándolo. La comunicación de los agentes estará aún más restringida por consideraciones topológicas. En un momento dado, un agente solo podrá comunicarse con un número de vecinos. Sus conexiones con estos otros agentes pueden The Sixth Intl. La Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) evoluciona con su situación en el entorno. Normalmente, un agente solo puede comunicarse con agentes que puede percibir, pero se podría imaginar la evolución de <br>restricciones topológicas</br> en la comunicación basadas en una red de comunicaciones entre agentes donde los enlaces no siempre están activos. En nuestro sistema, los agentes podrán comunicarse entre sí. Sin embargo, debido a las <br>restricciones topológicas</br> mencionadas anteriormente, no podrán comunicarse con ningún agente en ningún momento. Con quién puede comunicarse un agente se definirá dinámicamente (por ejemplo, esto puede ser consecuencia de que los agentes estén lo suficientemente cerca para ponerse en contacto). Denotaremos de forma abstracta por C(ai, aj, t) la propiedad de comunicación, es decir, el hecho de que los agentes ai y aj puedan comunicarse en el tiempo t (nota que se asume que esta relación es simétrica, pero por supuesto no transitiva). Ahora estamos en posición de definir dos propiedades esenciales de nuestro sistema. Definición 4 (Camino Temporal). Existe un camino de comunicación temporal en el horizonte tf (denotado Ltf (aI, aJ)) entre ai y aj si y solo si existe una secuencia de puntos temporales t1, t2, ..., tn desde tf y una secuencia de agentes k1, k2, ..., kn tal que (i) C(aI, ak1, t1), (ii) C(akn, aJ, tn+1), (iii) ∀i ∈ [1, n], C(aki, aki+1, ti). Intuitivamente, lo que esta propiedad dice es que es posible encontrar un camino temporal en el futuro que permitiría vincular al agente ai y aj a través de una secuencia de agentes intermedios. Ten en cuenta que los puntos temporales no necesariamente son sucesivos, y que la secuencia de agentes puede involucrar a los mismos agentes varias veces. Definición 5 (Conexidad Temporal). Un sistema es temporalmente conexo si y solo si ∀t ∀(i, j)∈[1, n]2 Lt(ai, aj). En resumen, un sistema temporalmente conexo garantiza que cualquier agente podrá comunicarse con cualquier otro agente, sin importar cuánto tiempo pueda llevar hacerlo, en cualquier momento. Dicho de otra manera, nunca sucede que un agente esté aislado para siempre de otro agente del sistema. A continuación discutiremos en detalle cómo la comunicación tiene lugar concretamente en nuestro sistema. Recuerda que en este documento, solo consideramos el caso de intercambios bilaterales (un agente solo puede hablar con otro agente) y también asumimos que cualquier agente solo puede participar en un intercambio en una ronda dada. 3. PROTOCOLOS Y ESTRATEGIAS En esta sección, discutimos los requisitos de los protocolos de interacción que rigen el intercambio de mensajes entre agentes, y proporcionamos algunos ejemplos de la implementación de dichos protocolos. Para aclarar la presentación, distinguimos dos niveles: el nivel local, que se ocupa de la regulación de los intercambios bilaterales; y el nivel global, que regula principalmente la forma en que los agentes pueden participar realmente en una conversación. En cada nivel, separamos lo que está especificado por el protocolo y lo que se deja a las estrategias de los agentes. Protocolos y estrategias locales Comenzamos inspeccionando los protocolos y estrategias locales que regularán la comunicación entre los agentes del sistema. Al limitarnos a la comunicación bilateral, estos protocolos simplemente implicarán a dos agentes. Dicho protocolo tendrá que cumplir con un requisito básico para ser satisfactorio: consistencia (CONS) - un protocolo local debe garantizar la consistencia mutua de los agentes al finalizar (lo que implica, por supuesto, la finalización). Figura 1: Un Protocolo de Intercambio de Hipótesis [1] Un ejemplo de dicho protocolo es el protocolo descrito en [1] que se muestra en la Fig. 1. Para ilustrar aún más cómo dicho protocolo puede ser utilizado por agentes, proporcionamos algunos detalles sobre una posible estrategia: al recibir una hipótesis h1 (proponer(h1) o contra-proponer(h1)) de a1, el agente a2 se encuentra en el estado 2 y tiene las siguientes respuestas posibles: contraejemplo (si el agente conoce un ejemplo que contradice la hipótesis, o no está explicado por esta hipótesis), desafío (si el agente carece de evidencia para aceptar esta hipótesis), contra-proponer (si el agente está de acuerdo con la hipótesis pero prefiere otra), o aceptar (si es tan buena como su hipótesis favorita). Esta estrategia garantiza, entre otras propiedades, la eventual consistencia lógica mutua de los agentes involucrados [1]. Protocolo global El protocolo global regula la forma en que se iniciarán los intercambios bilaterales entre agentes. En cada turno, los agentes enviarán simultáneamente una solicitud ponderada para comunicarse con otros agentes. Este peso es un valor que mide la disposición de los agentes para conversar con el agente objetivo (en la práctica, esto puede basarse en diferentes heurísticas, pero haremos algunas suposiciones sobre las estrategias de los agentes, ver más abajo). Enviar una solicitud de este tipo es una especie de compromiso condicional para el agente. Un agente que envía una solicitud ponderada se compromete a entablar una conversación con el objetivo si no recibe y acepta otra solicitud por sí mismo. Una vez que se hayan recibido todas las solicitudes, cada agente responde con un aceptar o un rechazar. Al responder con un aceptar, un agente se compromete plenamente a participar en la conversación con el remitente. Por lo tanto, solo puede enviar una aceptación en una ronda dada, ya que un agente solo puede participar en una conversación por paso de tiempo. Cuando se hayan recibido todas las respuestas, cada agente que reciba una aceptación puede iniciar una conversación utilizando el protocolo local o enviar una cancelación si ha aceptado otra solicitud. Al final de todos los intercambios bilaterales, los agentes involucrados en la conversación son descartados del protocolo. Entonces cada uno de los agentes restantes reenvía una solicitud y el proceso se repite hasta que no se envíen más solicitudes. Estrategia global Ahora definimos cuatro requisitos para las estrategias utilizadas por los agentes, dependiendo de su rol en el protocolo: dos se refieren al rol del solicitante (cómo decidir quién es el 1000 The Sixth Intl. La Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) ¿con qué agente desea comunicarse? Los otros dos con el rol de respondedor (¿cómo decidir qué solicitud de comunicación aceptar o no?). • Disposición para resolver inconsistencias (SOLVE): los agentes desean comunicarse con cualquier otro agente a menos que sepan que son mutuamente consistentes. • Enfoque en resolver inconsistencias (FOCUS): los agentes no solicitan comunicarse con un agente con el que saben que son mutuamente consistentes. • Disposición para comunicarse (COMM): los agentes no pueden rechazar una solicitud de comunicación ponderada, a menos que acaben de recibir o enviar una solicitud con un peso mayor. • Compromiso con la solicitud de comunicación (REQU): los agentes no pueden aceptar una solicitud de comunicación ponderada si ellos mismos han enviado una solicitud de comunicación con un peso mayor. Por lo tanto, no cancelarán su solicitud a menos que hayan recibido una solicitud comunicacional con mayor peso. Ahora la estructura del protocolo, junto con las propiedades COMM+REQU, garantizan que una solicitud solo puede ser rechazada si su agente objetivo se involucra en comunicación con otro agente. Supongamos de hecho que el agente ai quiere comunicarse con aj enviando una solicitud con peso w. COMM garantiza que un agente que reciba una solicitud ponderada aceptará esta comunicación, aceptará una comunicación con un peso mayor o esperará la respuesta a una solicitud con un peso mayor. Esto asegura que la solicitud con peso máximo será aceptada y no cancelada (ya que REQU asegura que un agente que envía una solicitud solo puede cancelarla si acepta otra solicitud con un peso mayor). Por lo tanto, al menos dos agentes participarán en una conversación por ronda del protocolo global. Como el protocolo asegura que ai puede reenviar su solicitud mientras aj no está ocupado en una conversación, llegará un momento en el que aj deberá participar en una conversación, ya sea con ai u otro agente. Estos requisitos se refieren al envío y aceptación de solicitudes, pero los agentes también necesitan alguna estrategia de atribución de peso. Describimos a continuación una estrategia altruista, utilizada en nuestros experimentos. Siendo cooperativo, un agente puede querer conocer más los deseos de comunicación de otros agentes para mejorar la asignación general de intercambios a los agentes. Se añade entonces un paso de solicitud de contexto al protocolo global. Antes de enviar su solicitud ponderada elegida, los agentes asignan un peso a todos los agentes con los que están dispuestos a comunicarse, de acuerdo con algunos factores internos. En el caso más simple, este peso será 1 para todos los agentes con los que el agente no esté seguro de ser mutuamente consistentes (garantizando SOLVE), sin considerar a otros agentes para la comunicación (garantizando FOCUS). El agente luego envía una solicitud de contexto a todos los agentes con los que se considera la comunicación. Esta solicitud también proporciona información sobre el remitente (lista de comunicaciones consideradas junto con su peso). Después de recibir todas las solicitudes de contexto, los agentes responderán con un rechazo si ya están ocupados en una conversación (en cuyo caso, el agente solicitante no considerará comunicarse con ellos en este turno), o con una información que brinde al solicitante información sobre las solicitudes que ha enviado y recibido. Cuando se hayan recibido todas las respuestas, cada agente puede calcular el peso de todas las solicitudes que le conciernen. Lo hace restando del peso de su solicitud el peso de todas las solicitudes relacionadas con él o su objetivo (es decir, el peso final de la solicitud de ai a aj es Wi,j = wi,j + wj,i - ( Σ k∈R(i)-{j} wi,k + Σ k∈S(i)-{j} wk,i + Σ k∈R(j)-{i} wj,k + Σ k∈S(j)-{i} wk,j) donde wi,j es el peso de la solicitud de ai a aj, R(i) es el conjunto de índices de agentes que han recibido una solicitud de ai y S(i) es el conjunto de índices de agentes que han enviado una solicitud a ai). Luego envía finalmente una solicitud ponderada a los agentes que maximizan este peso (o esperan una solicitud) según lo descrito en el protocolo global. 4. (CONDICIONAL) CONVERGENCIA HACIA LA COHERENCIA GLOBAL En esta sección mostraremos que los requisitos relacionados con los protocolos y estrategias recién discutidos serán suficientes para garantizar que el sistema eventualmente convergerá hacia la coherencia global, bajo ciertas condiciones. Primero demostramos que, si dos agentes no son mutuamente consistentes en algún momento, entonces necesariamente habrá un momento en el futuro en el que un agente aprenderá una nueva observación, ya sea porque es nueva para el sistema, o al aprenderla de otro agente. Lema 1. Sea S un sistema poblado por n agentes a1, a2, ..., an, temporalmente conectados e involucrando percepciones limitadas para estos agentes. Sea n1 la suma de las cardinalidades de la intersección de los conjuntos de observaciones emparejados. (n1 = P (i,j)∈[1,n]2 |Oi ∩ Oj|) Sea n2 la cardinalidad de la unión de todos los conjuntos de observaciones de los agentes. (n2 = | ∪N i=1 Oi|). Si ¬MCons(ai, aj) en el tiempo t0, necesariamente existe un tiempo t > t0 tal que ya sea n1 o n2 aumentarán. Prueba. Supongamos que exista un tiempo t0 y unos índices (i, j) tal que ¬MCons(ai, aj). Utilizaremos mt0 = P (k,l)∈[1,n]2 εComm(ak, al, t0) donde εComm(ak, al, t0) = 1 si ak y al han comunicado al menos una vez desde t0, y 0 en caso contrario. La conexidad temporal garantiza que existen t1, ..., tm+1 y k1, ..., km tal que. C(ai, ak1 , t1), C(akm , aj, tm+1), y ∀p ∈ [1, m], C(akp , akp+1 , tp). Claramente, si MCons(ai, ak1), MCons(akm, aj) y ∀p, MCons(akp, akp+1), tenemos MCons(ai, aj) lo cual contradice nuestra hipótesis (siendo MCons transitivo, MCons(ai, ak1)∧MCons(ak1, ak2) implica que MCons(ai, ak2) y así sucesivamente hasta MCons(ai, akm)∧MCons(akm, aj) lo cual implica MCons(ai, aj)). Al menos dos agentes son necesariamente inconsistentes (¬MCons(ai, ak1), o ¬MCons(akm, aj), o ∃p0 t.q. ¬MCons(akp0, akp0+1)). Que ak y al sean estos dos vecinos en un momento t > t0 1. La propiedad SOLVE asegura que ya sea ak o al enviará una solicitud de comunicación al otro agente en el tiempo t. Como se mostró anteriormente, esto a su vez garantiza que al menos uno de estos agentes estará involucrado en una comunicación. Entonces hay dos posibilidades: (caso i) ak y al se comunican en el tiempo t. En este caso, sabemos que ¬MCons(ak, al). Esto y la propiedad CONS aseguran que al menos uno de los agentes debe cambiar su 1. Estrictamente hablando, la transitividad de MCons solo asegura que ak y al son inconsistentes en un tiempo t ≥ t0 que puede ser diferente del tiempo t en el que pueden comunicarse. Pero si se vuelven consistentes entre t y t (o inconsistentes entre t y t), significa que al menos uno de ellos ha cambiado su hipótesis entre t y t, es decir, después de t0. Podemos entonces aplicar el razonamiento del caso iib. El Sexto Internacional. La Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 1001 hipótesis, lo cual a su vez, dado que los agentes son autónomos, implica al menos un intercambio de observación. Pero entonces |Ok ∩Ol| está destinado a aumentar: n1(t) > n1(t0). (caso ii) ak se comunica con ap en el tiempo t. Entonces tenemos de nuevo dos posibilidades: (caso iia) ak y ap no se comunicaron desde t0. Pero luego εComm(ak, ap, t0) tenía valor 0 y toma valor 1. Por lo tanto, mt0 aumenta. (caso iib) ak y ap se comunicaron en algún momento t0 > t0. La propiedad CONS del protocolo asegura que MCons(ak, ap) en ese momento. Ahora el hecho de que se comuniquen y se ENFOQUEN implica que al menos uno de ellos cambió su hipótesis en el ínterin. El hecho de que los agentes sean autónomos implica a su vez que una nueva observación (percibida o recibida de otro agente) necesariamente provocó este cambio. El último caso garantizaría la existencia de un tiempo t > t0 y un agente aq tal que |Op ∩ Oq| o |Ok ∩ Oq| aumenten en 1 en ese momento (lo que implica que n1(t) > n1(t0)). El caso anterior significa que el agente obtiene una nueva percepción en el tiempo t. Si esa observación era desconocida en el sistema antes, entonces n2(t) > n2(t0). Si algún agente aq ya conocía esta observación antes, entonces tanto Op ∩ Oq como Ok ∩ Oq aumentan en 1 en el tiempo t (lo que implica que n1(t) > n1(t0)). Por lo tanto, ¬MCons(ai, aj) en el tiempo t0 garantiza que, o bien: −∃t > t0 t.q. n1(t ) > n1(t0); o −∃t > t0 t.q. n2(t ) > n2(t0); o −∃t > t0 t.q. mt0 aumenta en 1 en el tiempo t. Al iterar el razonamiento con t (pero manteniendo t0 como la referencia de tiempo para mt0), podemos eliminar el tercer caso (mt0 es un entero y está limitado por n2, lo que significa que después de un máximo de n2 iteraciones, necesariamente estaremos en uno de los otros dos casos). Como resultado, hemos demostrado que si ¬MCons(ai, aj) en el tiempo t0, necesariamente habrá un tiempo t tal que ya sea n1 o n2 aumentarán. Teorema 1 (Consistencia global). Sea S un sistema poblado por n agentes a1, a2, ..., an, temporalmente conectados e involucrando percepciones limitadas para estos agentes. Sea Cons(ai, aj) una propiedad de consistencia transitiva. Entonces, cualquier protocolo y estrategias que cumplan con las propiedades CONS, SOLVE, FOCUS, COMM y REQU garantizan que el sistema convergerá hacia la consistencia global. Prueba. Por el bien de la contradicción, asumamos que ∃I, J ∈ [1, N] tal que ∀t, ∃t0 > t, tal que ¬Cons(aI , aJ , t0). Usando el lema, esto implica que ∃t > t0 tal que n1(t) > n1(t0) o n2(t) > n2(t0). Pero podemos aplicar el mismo razonamiento tomando t = t, lo que nos daría t1 > t > t0 tal que ¬Cons(aI , aJ , t1), lo que nos da t > t1 tal que n1(t) > n1(t1) o n2(t) > n2(t1). Mediante iteraciones sucesivas podemos construir una secuencia t0, t1, ..., tn, que puede dividirse en dos subsecuencias t0, t1, ...tn y t0, t1, ..., tn tal que n1(t0) < n1(t1) < ... < n1(tn) y n2(t0) < n2(t1) < ... < n2(tn). Una de estas subsecuencias tiene que ser infinita. Sin embargo, n1(ti) y n2(ti) son estrictamente crecientes, enteros y acotados, lo que implica que ambos son finitos. Contradicción. Lo que el resultado anterior muestra esencialmente es que, en un sistema donde ningún agente estará aislado del resto de los agentes para siempre, solo se necesitan suposiciones muy leves sobre los protocolos y estrategias utilizados por los agentes para garantizar la convergencia hacia la consistencia del sistema en una cantidad finita de tiempo (aunque podría llevar mucho tiempo). Desafortunadamente, en muchas situaciones críticas, no será posible asumir esta conexión temporal. Dado que enfoques distribuidos como el abogado en este documento suelen presentarse como una buena manera de abordar problemas de confiabilidad o problemas de dependencia de un centro que son de suma importancia en estas aplicaciones críticas, ciertamente resulta interesante explorar más a fondo cómo se comportaría un sistema de este tipo cuando relajamos esta suposición. ESTUDIO EXPERIMENTAL Este experimento implica agentes tratando de escapar de un edificio en llamas. El entorno se describe como una cuadrícula espacial con un conjunto de paredes y (afortunadamente) algunas salidas. El tiempo y el espacio se consideran discretos. El tiempo se divide en rondas. Los agentes se localizan por su posición en la cuadrícula espacial. Estos agentes pueden moverse y comunicarse con otros agentes. En una ronda, un agente puede moverse una celda en cualquiera de las cuatro direcciones cardinales, siempre y cuando no esté bloqueado por una pared. En esta aplicación, los agentes se comunican con cualquier otro agente (pero, recuerda, solo uno) siempre y cuando este agente esté a la vista y aún no hayan intercambiado su hipótesis actual favorita. De repente, se desata un incendio en estas instalaciones. A partir de este momento, el fuego se propaga. En cada ronda, en cada caso donde haya fuego, el fuego se propaga en las cuatro direcciones. Sin embargo, el fuego no puede propagarse a través de una pared. Si el fuego se propaga en un caso donde un agente está posicionado, ese agente se quema y se considera muerto. Por supuesto, ya no puede moverse ni comunicarse. Si un agente llega a una salida, se considera que está a salvo y ya no puede ser quemado. Los agentes conocen el entorno y las reglas que rigen la dinámica de este entorno, es decir, conocen el mapa así como las reglas de propagación del fuego previamente descritas. También perciben este entorno localmente, pero no pueden ver más allá de 3 casos en cualquier dirección. Las paredes también bloquean la línea de visión, impidiendo que los agentes vean detrás de ellas. Dentro de su campo de visión, pueden ver a otros agentes y si los casos que ven están en llamas. Todas estas percepciones están memorizadas. Mostramos ahora cómo se instancia el marco abstracto presentado en el documento. • O = {Fire(x, y, t), NoFire(x, y, t), Agent(ai, x, y, t)} Las observaciones pueden ser positivas (o ∈ P(O) si ∃h ∈ H tal que h |= o) o negativas (o ∈ N(O) si ∃h ∈ H tal que h |= ¬o). • H={FireOrigin(x1, y1, t1)∧...∧FireOrigin(xl, yl, tl)} Las hipótesis son conjunciones de Orígenes de Fuego. • La relación de consistencia Cons(h, O) satisface: - coherencia: ∀o ∈ N(O), h |= ¬o. - completitud: ∀o ∈ P(O), h |= o. - minimalidad: Para todo h ∈ H, si h es coherente y completo para O, entonces h es preferido a h de acuerdo con la relación de preferencia (h ≤p h). Selecciona primero el número mínimo de orígenes, luego el más reciente (estrategia menos preemptiva [6]), y luego utiliza un ranking fijo arbitrario para discriminar ex-aequo. La relación resultante es un orden total, por lo tanto, la minimalidad implica que habrá un único h tal que Cons(O, h) para un O dado. Esto a su vez significa que MCons(ai, aj) si y solo si Cons(ai), Cons(aj) y hi = hj. Esta relación es entonces transitiva y simétrica. 1002 El Sexto Internacional. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) • Eh toma O como argumento y devuelve min≤p de la hipótesis coherente y completa para O 5.1 Evaluación Experimental Clásicamente evaluaremos la efectividad y eficiencia de diferentes protocolos de interacción (ver, por ejemplo, [3, 4]). La efectividad de un protocolo se determinará por la proporción de agentes que sobreviven al incendio respecto al número inicial de agentes involucrados en el experimento. Si este valor es alto, el protocolo ha sido efectivo para propagar la información y/o para que los agentes refinen sus hipótesis y determinen la mejor manera de salir. Eficiencia de un protocolo. Por lo general, el uso de información de apoyo implicará una sobrecarga de comunicación. Aquí asumiremos que la eficiencia de un protocolo dado está caracterizada por el flujo de datos inducido por este protocolo. En este documento solo discutiremos este aspecto con respecto a los protocolos locales. La medida principal que utilizaremos aquí es el tamaño total promedio de los mensajes intercambiados por los agentes por intercambio (teniendo en cuenta tanto el número de mensajes como el tamaño real de los mensajes, ya que podría ser que los mensajes resulten ser muy grandes, conteniendo por ejemplo un gran número de observaciones, lo que podría contrarrestar un bajo número de mensajes). 5.2 Configuraciones Experimentales Las configuraciones experimentales elegidas son las siguientes: • Topología ambiental: El rendimiento de la propagación de la información está altamente condicionado por la topología del entorno. Las habilidades de percepción de los agentes dependen de la apertura del entorno. Con un gran número de paredes, las percepciones de los agentes están limitadas, al igual que el número de posibles comunicaciones entre agentes, mientras que un entorno abierto proporcionará posibilidades óptimas de percepción y propagación de información. Por lo tanto, proponemos un índice topológico (ver abajo) como base común para caracterizar los entornos (mapas) utilizados durante las experimentaciones. El índice topológico (TI) es la proporción entre el número de celdas que pueden ser percibidas por los agentes sumadas desde todas las posiciones posibles, dividido por el número de celdas que serían percibidas desde las mismas posiciones pero sin paredes. (Cuanto más cercano a 1, más abierto es el entorno). También utilizaremos dos medidas adicionales, más clásicas [10]: la longitud del camino característico (CPL) y el coeficiente de agrupamiento (CC). • Número de agentes: la propagación de la información también depende del número inicial de agentes involucrados durante una experimentación. Por ejemplo, cuantos más agentes haya, más potenciales comunicaciones existen. Esto significa que habrá más potencial de propagación, pero también que la restricción de intercambio bilateral será más crucial. 3 El CPL es la mediana de las medias de las longitudes de los caminos más cortos que conectan cada nodo con todos los demás nodos. 4 caracterizando el grado de aislamiento de una región de un entorno en términos de accesibilidad (número de caminos aún utilizables para llegar a esta región). Mapa T.I. (%) C.P.L. C.C. 69-1 69,23 4,5 0,69 69-2 68,88 4,38 0,65 69-3 69,80 4,25 0,67 53-1 53,19 5,6 0,59 53-2 53,53 6,38 0,54 53-3 53,92 6,08 0,61 38-1 38,56 8,19 0,50 38-2 38,56 7,3 0,50 38-3 38,23 8,13 0,50 Tabla 1: Características Topológicas de los Mapas • Posiciones iniciales de los agentes- Las posiciones iniciales de los agentes tienen una influencia significativa en el comportamiento general de una instancia de nuestro sistema: estar cerca de una salida facilitará (en general) la escapatoria. 5.3 Entornos experimentales Elegimos realizar experimentos en tres índices topológicos muy diferentes (69% para entornos abiertos, 53% para entornos mixtos y 38% para entornos tipo laberinto). Figura 2: Dos mapas (izquierda: IT=69%, derecha IT=38%) Diseñamos tres mapas diferentes para cada índice (la Fig. 2 muestra dos de ellos), conteniendo el mismo número máximo de agentes (máximo 36 agentes) con una densidad máxima de un agente por celda, el mismo número de salidas y un origen de incendio similar (por ejemplo, tiempo y posición de inicio). Los tres mapas diferentes de un índice dado están diseñados de la siguiente manera. El primer plano es un modelo de un piso de un edificio existente. El segundo mapa tiene el mismo perímetro, salidas y origen del fuego que el primero, pero la cantidad y ubicación de las paredes son diferentes (las ubicaciones de las paredes son diseñadas por una heurística que crea paredes de forma aleatoria en la cuadrícula espacial de manera que no se creen habitaciones completamente cerradas y que ninguna salida quede bloqueada). El tercer mapa se caracteriza por un recinto geométrico en el que la ubicación de las paredes también está diseñada con la heurística mencionada anteriormente. La Tabla 1 resume las diferentes medidas topológicas que caracterizan estos mapas diferentes. Vale la pena señalar que los valores confirman la relevancia de TI (los mapas con un alto TI tienen un bajo CPL y un alto CC). Sin embargo, el CPL y el CC permiten refinar aún más la diferencia entre los mapas, por ejemplo, entre 53-1 y 53-2). 5.4 Resultados Experimentales Para cada trío de mapas definidos como se mencionó anteriormente, llevamos a cabo los mismos experimentos. En cada experimento, la sociedad difiere en cuanto a su proporción inicial de agentes involucrados, desde el 1% hasta el 100%. Esta proporción inicial representa el porcentaje de agentes involucrados con respecto al número máximo posible de agentes. Para cada mapa y cada proporción inicial, la Sexta Internacional. En la Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) seleccionamos aleatoriamente 100 ubicaciones iniciales de agentes diferentes. Para cada una de esas ubicaciones diferentes ejecutamos el sistema una vez para cada protocolo de interacción diferente. La efectividad de la comunicación y argumentación El primer experimento que hemos establecido tiene como objetivo probar cuán efectivo es el intercambio de hipótesis (IH), y en particular cómo los aspectos topológicos afectarán esta efectividad. Para hacerlo, hemos calculado la proporción de mejora ofrecida por ese protocolo sobre una situación en la que los agentes simplemente no podían comunicarse (sin comunicación). Para obtener más información sobre en qué medida el intercambio de hipótesis fue realmente crucial, también probamos un protocolo mucho menos elaborado que consistía en intercambios de observaciones simples (OE). Más precisamente, este protocolo requiere que cada agente almacene cualquier observación inesperada que perciba, y los agentes simplemente intercambian sus respectivas listas de observaciones cuando discuten. En este caso, el protocolo local es diferente (nota en particular que no garantiza consistencia mutua), pero el protocolo global permanece igual (con la única excepción de que la motivación de los agentes para comunicarse es sincronizar su lista de observaciones, no sus hipótesis). Si este protocolo es como máximo tan efectivo como HE, tiene la ventaja de ser más eficiente (esto es obvio en cuanto al número de mensajes, que se limitará a 2, menos directo en lo que respecta al tamaño de los mensajes, pero la observación general de que el intercambio de observaciones se puede ver como una versión simplificada del desafío es útil para ver esto). Los resultados de estos experimentos se informan en la Figura 3. Figura 3: Ganancia de la proporción de efectividad comparativa de los protocolos cuando la proporción de agentes aumenta. La primera observación que debe hacerse es que la comunicación mejora la efectividad del proceso, y esta proporción aumenta a medida que el número de agentes crece en el sistema. La segunda lección que aprendemos aquí es que la cercanía relativamente hace que la comunicación sea más efectiva que la falta de comunicación. Los mapas que muestran un T.I. del 38% están constantemente por encima de los otros dos, y el 53% sigue siendo ligeramente pero significativamente mejor que el 69%. Sin embargo, estas curvas también sugieren, quizás sorprendentemente, que HE supera a OE precisamente en aquellas situaciones donde la ganancia de la relación es menos importante (la única diferencia notable ocurre en mapas bastante abiertos donde T.I. es del 69%). Esto se puede explicar de la siguiente manera: cuando un mapa está abierto, los agentes tienen muchos posibles candidatos de explicación, y la argumentación se vuelve útil para discriminar entre ellos. Cuando un mapa es laberíntico, hay menos posibles explicaciones para un evento inesperado. Importancia del Protocolo Global El segundo conjunto de experimentos busca evaluar la importancia del diseño del protocolo global. Probamos nuestro protocolo contra un protocolo de difusión local (LB). La difusión local significa que todos los agentes vecinos percibidos por un agente estarán involucrados en una comunicación con ese agente en una ronda dada, aliviando la restricción de una sola comunicación por agente. Esto nos proporciona un límite superior aproximado sobre la posible ganancia de ratio en el sistema (para un protocolo local dado). Nuevamente, evaluamos la ganancia de la relación inducida por ese LB sobre nuestro HE clásico, para las tres clases diferentes de mapas. Los resultados se informan en la Figura 4. Figura 4: Ganancia de la proporción de transmisión local sobre el intercambio de hipótesis. Tenga en cuenta que la ganancia de la proporción es 0 cuando la proporción de agentes es del 5%, lo cual se explica fácilmente por el hecho de que corresponde a situaciones que involucran solo a dos agentes. Primero observamos que todas las clases de mapas muestran un aumento en la ganancia de la proporción a medida que aumenta el número de agentes: la ganancia alcanza entre el 10 y el 20%, dependiendo de la clase de mapas considerada. Si se compara esto con la mejora reportada en el experimento anterior, parece ser de la misma magnitud. Esto ilustra que el diseño del protocolo global no puede ser ignorado, especialmente cuando la proporción de agentes es alta. Sin embargo, también observamos que las curvas de ganancia de la proporción de efectividad tienen formas muy diferentes en ambos casos: la ganancia inducida por la precisión del protocolo local aumenta muy rápidamente con la proporción de agentes, mientras que la curva es muy suave para el global. Ahora observemos con más cuidado los resultados reportados aquí: la curva correspondiente a una TI del 53% está por encima de la correspondiente al 38%. Esto se debe a que cuanto más abierta sea un mapa, más oportunidades hay de comunicarse con más de un agente (y por lo tanto beneficiarse de la difusión). Sin embargo, también observamos que la curva para el 69% está por debajo de la del 53%. Esto se explica de la siguiente manera: en el caso del 69%, la ganancia potencial en términos de agentes sobrevivientes es mucho menor, porque nuestros protocolos ya ofrecen resultados bastante eficientes de todos modos (alcanzando rápidamente el 90%, ver Fig. 3). Una regla general podría ser que cuando el número de agentes es pequeño, se debe prestar especial atención al local 1004 de la Sexta Internacional. En el caso de que el número de agentes sea pequeño, uno puede utilizar el protocolo de la Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07), mientras que cuando ese número es grande, se debe diseñar cuidadosamente uno global (a menos que el mapa sea tan abierto que el protocolo ya sea casi óptimamente eficiente). La eficiencia de los protocolos. El experimento final reportado aquí se centra en el análisis de la eficiencia de los protocolos. Aquí analizamos el tamaño medio de la totalidad de los mensajes que son intercambiados por agentes (tamaño medio de intercambios, en resumen) utilizando los siguientes protocolos: HE, OE y dos protocolos variantes. El primero es un protocolo de intercambio de hipótesis restringidas (RHE) intermediario. RHE es el siguiente: no implica ningún desafío ni contraoferta, lo que significa que los agentes no pueden cambiar su rol durante el protocolo (esto difiere de RE en ese aspecto). En resumen, RHE permite a un agente agotar las críticas de sus socios, y eventualmente este socio adoptará la hipótesis del agente. Ten en cuenta que esto significa que la autonomía del agente no se conserva aquí (ya que un agente esencialmente aceptará cualquier hipótesis que no pueda socavar), con la esperanza de que la ganancia en eficiencia sea lo suficientemente significativa como para compensar una pérdida en efectividad. El segundo protocolo de variante es un protocolo completo de intercambio de observaciones (COE). COE utiliza los mismos principios que OE, pero incluye además todos los ejemplos críticos negativos (nofire) en el intercambio (dando así todos los ejemplos utilizados como argumentos por el protocolo de intercambio de hipótesis), mejorando así la efectividad. Los resultados para el mapa 69-1 se muestran en la Figura 5. Figura 5: Tamaño medio de los intercambios. Primero podemos observar el hecho de que el orden de los protocolos, desde el menos eficiente hasta el más eficiente, es COE, HE, RHE y luego OE. ÉL siendo más eficiente que COE demuestra que el proceso de argumentación gana eficiencia al seleccionar cuándo es necesario proporcionar ejemplos negativos, los cuales tienen menos impacto que los positivos en nuestro entorno de prueba específico. Sin embargo, al comunicar hipótesis antes de proporcionar observaciones para respaldarla (HE) en lugar de dar directamente las observaciones más cruciales (OE), el proceso de argumentación duplica el tamaño de los intercambios de datos. Es el costo de garantizar la consistencia al final del intercambio (una propiedad que OE no admite). También es significativo el hecho de que el tamaño promedio de los intercambios es ligeramente mayor cuando el número de agentes es pequeño. Esto se explica por el hecho de que en estos casos solo unos pocos agentes tienen información relevante en su posesión, y que necesitarán comunicarse mucho para llegar a un punto de vista común de la situación. Cuando el número de agentes aumenta, este conocimiento se distribuye entre más agentes que necesitan discusiones más cortas para llegar a una consistencia mutua. Como consecuencia, la ganancia relativa en eficiencia de usar RHE parece ser mejor cuando el número de agentes es pequeño: cuando es alto, difícilmente discutirán de todos modos. Finalmente, vale la pena notar que la desviación estándar para estos experimentos es bastante alta, lo que significa que la conversación no converge hacia ningún patrón estereotípico. 6. CONCLUSIÓN Este documento ha investigado las propiedades de un sistema multiagente donde cada agente (distribuido) percibe localmente su entorno e intenta alcanzar consistencia con otros agentes a pesar de severas restricciones de comunicación. En particular, hemos expuesto condiciones que permiten la convergencia e investigado experimentalmente una situación típica donde esas condiciones no pueden cumplirse. Hay muchas posibles extensiones a este trabajo, la primera siendo investigar más a fondo las propiedades de diferentes protocolos globales pertenecientes a la clase que identificamos, y su influencia en el resultado. Existen en particular muchas heurísticas, altamente dependientes del contexto del estudio, que podrían intuitivamente arrojar resultados interesantes (en nuestro estudio, seleccionar al destinatario en función de lo que se pueda inferir de sus acciones observadas podría ser una de esas heurísticas). Un candidato obvio para problemas a largo plazo se refiere a la relajación de la suposición de un sensor perfecto. 7. REFERENCIAS [1] G. Bourgne, N. Maudet y S. Pinson. Cuando los agentes comunican hipótesis en situaciones críticas. En Actas de DALT-2006, mayo de 2006. [2] P. Harvey, C. F. Chang y A. Ghose. Búsqueda distribuida basada en soporte: un nuevo enfoque para el procesamiento de restricciones multiagente. En Actas de AAMAS06, 2006. [3] H. Jung y M. Tambe. Argumentación como satisfacción de restricciones distribuida: Aplicaciones y resultados. En Actas de AGENTS01, 2001. [4] N. C. Karunatillake y N. R. Jennings. ¿Vale la pena discutir? En Actas de ArgMAS 2004, 2004. [5] S. Onta˜n´on y E. Plaza. Argumentos y contraejemplos en la deliberación conjunta basada en casos. En Actas de ArgMAS-2006, mayo de 2006. [6] D. Poole. Explicación y predicción: Una arquitectura para el razonamiento por defecto y abductivo. Inteligencia Computacional, 5(2):97-110, 1989. [7] I. Rahwan, S. D. Ramchurn, N. R. Jennings, P. McBurney, S. Parsons y L. Sonenberg. Negociación basada en argumentos. La revisión de Ingeniería del Conocimiento, 4(18):345-375, 2003. [8] N. Roos, A. ten Tije y C. Witteveen. Un protocolo para el diagnóstico multiagente con conocimiento distribuido espacialmente. En Actas de AAMAS03, 2003. [9] N. Roos, A. ten Tije y C. Witteveen. Alcanzando acuerdo diagnóstico en el diagnóstico multiagente. En Actas de AAMAS04, 2004. [10] T. Takahashi, Y. Kaneda y N. Ito. Estudio preliminar: utilizando simulaciones de RoboCupRescue para la prevención de desastres. En Actas de SRMED2004, 2004. El Sexto Internacional. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 1005 ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "hypothesis exchange protocol": {
            "translated_key": "protocolo de intercambio de hipótesis",
            "is_in_text": false,
            "original_annotated_sentences": [
                "Hypotheses Refinement under Topological Communication Constraints ∗ Gauvain Bourgne, Gael Hette, Nicolas Maudet, and Suzanne Pinson LAMSADE, Univ.",
                "Paris-Dauphine, France {bourgne,hette,maudet,pinson}@lamsade.dauphine.fr ABSTRACT We investigate the properties of a multiagent system where each (distributed) agent locally perceives its environment.",
                "Upon perception of an unexpected event, each agent locally computes its favoured hypothesis and tries to propagate it to other agents, by exchanging hypotheses and supporting arguments (observations).",
                "However, we further assume that communication opportunities are severely constrained and change dynamically.",
                "In this paper, we mostly investigate the convergence of such systems towards global consistency.",
                "We first show that (for a wide class of protocols that we shall define), the communication constraints induced by the topology will not prevent the convergence of the system, at the condition that the system dynamics guarantees that no agent will ever be isolated forever, and that agents have unlimited time for computation and arguments exchange.",
                "As this assumption cannot be made in most situations though, we then set up an experimental framework aiming at comparing the relative efficiency and effectiveness of different interaction protocols for hypotheses exchange.",
                "We study a critical situation involving a number of agents aiming at escaping from a burning building.",
                "The results reported here provide some insights regarding the design of optimal protocol for hypotheses refinement in this context.",
                "Categories and Subject Descriptors I.2.11 [Artificial Intelligence]: Distributed Artificial Intelligence-Multiagent systems General Terms Theory, Experimentation 1.",
                "INTRODUCTION We consider a multiagent system where each (distributed) agent locally perceives its environment, and we assume that some unexpected event occurs in that system.",
                "If each agent computes only locally its favoured hypothesis, it is only natural to assume that agents will seek to coordinate and refine their hypotheses by confronting their observations with other agents.",
                "If, in addition, the communication opportunities are severely constrained (for instance, agents can only communicate when they are close enough to some other agent), and dynamically changing (for instance, agents may change their locations), it becomes crucial to carefully design protocols that will allow agents to converge to some desired state of global consistency.",
                "In this paper we exhibit some sufficient conditions on the system dynamics and on the protocol/strategy structures that allow to guarantee that property, and we experimentally study some contexts where (some of) these assumptions are relaxed.",
                "While problems of diagnosis are among the venerable classics in the AI tradition, their multiagent counterparts have much more recently attracted some attention.",
                "Roos and colleagues [8, 9] in particular study a situation where a number of distributed entities try to come up with a satisfying global diagnosis of the whole system.",
                "They show in particular that the number of messages required to establish this global diagnosis is bound to be prohibitive, unless the communication is enhanced with some suitable protocol.",
                "However, they do not put any restrictions on agents communication options, and do not assume either that the system is dynamic.",
                "The benefits of enhancing communication with supporting information to make convergence to a desired global state of a system more efficient has often been put forward in the literature.",
                "This is for instance one of the main idea underlying the argumentation-based negotiation approach [7], where the desired state is a compromise between agents with conflicting preferences.",
                "Many of these works however make the assumption that this approach is beneficial to start with, and study the technical facets of the problem (or instead emphasize other advantages of using argumentation).",
                "Notable exceptions are the works of [3, 4, 2, 5], which studied in contexts different from ours the efficiency of argumentation.",
                "The rest of the paper is as follows.",
                "Section 2 specifies the basic elements of our model, and Section 3 goes on to presenting the different protocols and strategies used by the agents to exchange hypotheses and observations.",
                "We put special attention at clearly emphasizing the conditions on the system dynamics and protocols/strategies that will be exploited in the rest of the paper.",
                "Section 4 details one of 998 978-81-904262-7-5 (RPS) c 2007 IFAAMAS the main results of the paper, namely the fact that under the aforementioned conditions, the constraints that we put on the topology will not prevent the convergence of the system towards global consistency, at the condition that no agent ever gets completely lost forever in the system, and that unlimited time is allowed for computation and argument exchange.",
                "While the conditions on protocols and strategies are fairly mild, it is also clear that these system requirements look much more problematic, even frankly unrealistic in critical situations where distributed approaches are precisely advocated.",
                "To get a clearer picture of the situation induced when time is a critical factor, we have set up an experimental framework that we introduce and discuss in Section 5.",
                "The critical situation involves a number of agents aiming at escaping from a burning building.",
                "The results reported here show that the effectiveness of argument exchange crucially depends upon the nature of the building, and provide some insights regarding the design of optimal protocol for hypotheses refinement in this context. 2.",
                "BASIC NOTIONS We start by defining the basic elements of our system.",
                "Environment Let O be the (potentially infinite) set of possible observations.",
                "We assume the sensors of our agents to be perfect, hence the observations to be certain.",
                "Let H be the set of hypotheses, uncertain and revisable.",
                "Let Cons(h, O) be the consistency relation, a binary relation between a hypothesis h ∈ H and a set of observations O ⊆ O.",
                "In most cases, Cons will refer to classical consistency relation, however, we may overload its meaning and add some additional properties to that relation (in which case we will mention it).",
                "The environment may include some dynamics, and change over the course of time.",
                "We define below sequences of time points to deal with it: Definition 1 (Sequence of time points).",
                "A sequence of time points t1, t2, . . . , tn from t is an ordered set of time points t1, t2, . . . , tn such that t1 ≥ t and ∀i ∈ [1, n − 1], ti+1 ≥ ti.",
                "Agent We take a system populated by n agents a1, . . . , an.",
                "Each agent is defined as a tuple F, Oi, hi , where: • F, the set of facts, common knowledge to all agents. • Oi ∈ 2O , the set of observations made by the agent so far.",
                "We assume a perfect memory, hence this set grows monotonically. • hi ∈ H, the favourite hypothesis of the agent.",
                "A key notion governing the formation of hypotheses is that of consistency, defined below: Definition 2 (Consistency).",
                "We say that: • An agent is consistent (Cons(ai)) iff Cons(hi, Oi) (that is, its hypothesis is consistent with its observation set). • An agent ai consistent with a partner agent aj iff Cons(ai) and Cons(hi, Oj) (that is, this agent is consistent and its hypothesis can explain the observation set of the other agent). • Two agents ai and aj are mutually consistent (MCons(ai, aj)) iff Cons(ai, aj) and Cons(aj, ai). • A system is consistent iff ∀(i, j)∈[1, n]2 it is the case that MCons(ai, aj).",
                "To ensure its consistency, each agent is equipped with an abstract reasoning machinery that we shall call the explanation function Eh.",
                "This (deterministic) function takes a set of observation and returns a single prefered hypothesis (2O → H).",
                "We assume h = Eh(O) to be consistent with O by definition of Eh, so using this function on its observation set to determine its favourite hypothesis is a sure way for the agent to achieve consistency.",
                "Note however that an hypothesis does not need to be generated by Eh to be consistent with an observation set.",
                "As a concrete example of such a function, and one of the main inspiration of this work, one can cite the Theorist reasoning system [6] -as long as it is coupled with a filter selecting a single prefered theory among the ones initially selected by Theorist.",
                "Note also that hi may only be modified as a consequence of the application Eh.",
                "We refer to this as the autonomy of the agent: no other agent can directly impose a given hypothesis to an agent.",
                "As a consequence, only a new observation (being it a new perception, or an observation communicated by a fellow agent) can result in a modification of its prefered hypothesis hi (but not necessarily of course).",
                "We finally define a property of the system that we shall use in the rest of the paper: Definition 3 (Bounded Perceptions).",
                "A system involves a bounded perception for agents iff ∃n0 s.t. ∀t| ∪N i=1 Oi| ≤ n0. (That is, the number of observations to be made by the agents in the system is not infinite.)",
                "Agent Cycle Now we need to see how these agents will evolve and interact in their environment.",
                "In our context, agents evolve in a dynamic environment, and we classicaly assume the following system cycle: 1.",
                "Environment dynamics: the environment evolves according to the defined rules of the system dynamics. 2.",
                "Perception step : agents get perceptions from the environment.",
                "These perceptions are typically partial (e.g. the agent can only see a portion of a map). 3.",
                "Reasoning step: agents compare perception with predictions, seek explanations for (potential) difference(s), refine their hypothesis, draw new conclusions. 4.",
                "Communication step: agents can communicate hypotheses and observations with other agents through a defined protocol.",
                "Any agent can only be involved in one communication with another agent by step. 5.",
                "Action step: agents do some practical reasoning using the models obtained from the previous steps and select an action.",
                "They can then modify the environment by executing it.",
                "The communication of the agents will be further constrained by topological consideration.",
                "At a given time, an agent will only be able to communicate with a number of neighbours.",
                "Its connexions with these others agents may The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 999 evolve with its situation in the environment.",
                "Typically, an agent can only communicate with agents that it can sense, but one could imagine evolving topological constraints on communication based on a network of communications between agents where the links are not always active.",
                "Communication In our system, agents will be able to communicate with each other.",
                "However, due to the aforementionned topological constraints, they will not be able to communicate with any agents at anytime.",
                "Who an agent can communicate with will be defined dynamically (for instance, this can be a consequence of the agents being close enough to get in touch).",
                "We will abstractly denote by C(ai, aj, t) the communication property, in other words, the fact that agents ai and aj can communicate at time t (note that this relation is assumed to be symetric, but of course not transitive).",
                "We are now in a position to define two essential properties of our system.",
                "Definition 4 (Temporal Path).",
                "There exists a temporal communication path at horizon tf (noted Ltf (aI , aJ )) between ai and aj iff there exists a sequence of time points t1, t2, . . . , tn from tf and a sequence of agents k1, k2, . . . , kn s.t. (i) C(aI , ak1 , t1), (ii) C(akn , aJ , tn+1), (iii) ∀i ∈ [1, n], C(aki , aki+1 , ti) Intuitively, what this property says is that it is possible to find a temporal path in the future that would allow to link agent ai and aj via a sequence of intermediary agents.",
                "Note that the time points are not necessarily successive, and that the sequence of agents may involve the same agents several times.",
                "Definition 5 (Temporal Connexity).",
                "A system is temporaly connex iff ∀t ∀(i, j)∈[1, n]2 Lt(ai, aj) In short, a temporaly connex system guarantees that any agent will be able to communicate with any other agents, no matter how long it might take to do so, at any time.",
                "To put it another way, it is never the case that an agent will be isolated for ever from another agent of the system.",
                "We will next discuss the detail of how communication concretely takes place in our system.",
                "Remember that in this paper, we only consider the case of bilateral exchanges (an agent can only speak to a single other agent), and that we also assume that any agent can only engage in a single exchange in a given round. 3.",
                "PROTOCOLS AND STRATEGIES In this section, we discuss the requirements of the interaction protocols that govern the exchange of messages between agents, and provide some example instantiation of such protocols.",
                "To clarify the presentation, we distinguish two levels: the local level, which is concerned with the regulation of bilateral exchanges; and the global level,which essentially regulates the way agents can actually engage into a conversation.",
                "At each level, we separate what is specified by the protocol, and what is left to agents strategies.",
                "Local Protocol and Strategies We start by inspecting local protocols and strategies that will regulate the communication between the agents of the system.",
                "As we limit ourselves to bilateral communication, these protocols will simply involve two agents.",
                "Such protocol will have to meet one basic requirement to be satisfying. • consistency (CONS)- a local protocol has to guarantee the mutual consistency of agents upon termination (which implies termination of course).",
                "Figure 1: A Hypotheses Exchange Protocol [1] One example such protocol is the protocol described in [1] that is pictured in Fig. 1.",
                "To further illustrate how such protocol can be used by agents, we give some details on a possible strategy: upon receiving a hypothesis h1 (propose(h1) or counterpropose(h1)) from a1, agent a2 is in state 2 and has the following possible replies: counterexample (if the agent knows an example contradicting the hypothesis, or not explained by this hypothesis), challenge (if the agents lacks evidence to accept this hypothesis), counterpropose (if the agent agrees with the hypothesis but prefers another one), or accept (if it is indeed as good as its favourite hypothesis).",
                "This strategy guarantees, among other properties, the eventual mutual logical consistency of the involved agents [1].",
                "Global Protocol The global protocol regulates the way bilateral exchanges will be initiated between agents.",
                "At each turn, agents will concurrently send one weighted request to communicate to other agents.",
                "This weight is a value measuring the agents willingness to converse with the targeted agent (in practice, this can be based on different heuristics, but we shall make some assumptions on agents strategies, see below).",
                "Sending such a request is a kind of conditional commitment for the agent.",
                "An agent sending a weighted request commits to engage in conversation with the target if he does not receive and accept himself another request.",
                "Once all request have been received, each agent replies with either an acccept or a reject.",
                "By answering with an accept, an agent makes a full commitment to engage in conversation with the sender.",
                "Therefore, it can only send one accept in a given round, as an agent can only participate in one conversation per time step.",
                "When all response have been received, each agent receiving an accept can either initiate a conversation using the local protocol or send a cancel if it has accepted another request.",
                "At the end of all the bilateral exchanges, the agents engaged in conversation are discarded from the protocol.",
                "Then each of the remaining agents resends a request and the process iterates until no more requests are sent.",
                "Global Strategy We now define four requirements for the strategies used by agents, depending on their role in the protocol: two are concerned with the requestee role (how to decide who the 1000 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) agent wishes to communicate with? ), the other two with the responder role (how to decide which communication request to accept or not?). • Willingness to solve inconsistancies (SOLVE)-agents want to communicate with any other agents unless they know they are mutually consistent. • Focus on solving inconsistencies (FOCUS)-agents do not request communication with an agent with whom they know they are mutually consistent. • Willingness to communicate (COMM)-agents cannot refuse a weighted communication request, unless they have just received or send a request with a greater weight. • Commitment to communication request (REQU)agents cannot accept a weighted communication request if they have themselves sent a communication request with a greater weight.",
                "Therefore, they will not cancel their request unless they have received a communicational request with greater weight.",
                "Now the protocol structure, together with the properties COMM+REQU, ensure that a request can only be rejected if its target agent engages in communication with another agent.",
                "Suppose indeed that agent ai wants to communicate with aj by sending a request with weight w. COMM guarantees that an agent receiving a weighted request will either accept this communication, accept a communication with a greater weight or wait for the answer to a request with a greater weight.",
                "This ensures that the request with maximal weight will be accepted and not cancelled (as REQU ensures that an agent sending a request can only cancel it if he accepts another request with greater weight).",
                "Therefore at least two agents will engage in conversation per round of the global protocol.",
                "As the protocol ensures that ai can resend its request while aj is not engaged in a conversation, there will be a turn in which aj must engage in a conversation, either with ai or another agent.",
                "These requirements concern request sending and acceptation, but agents also need some strategy of weight attribution.",
                "We describe below an altruist strategy, used in our experiments.",
                "Being cooperative, an agent may want to know more of the communication wishes of other agents in order to improve the overall allocation of exchanges to agents.",
                "A context request step is then added to the global protocol.",
                "Before sending their chosen weighted request, agents attribute a weight to all agents they are prepared to communicate with, according to some internal factors.",
                "In the simplest case, this weight will be 1 for all agent with whom the agent is not sure of being mutually consistent (ensuring SOLVE), other agent being not considered for communication (ensuring FOCUS).",
                "The agent then sends a context request to all agents with whom communication is considered.",
                "This request also provides information about the sender (list of considered communications along with their weight).",
                "After reception of all the context requests, agents will either reply with a deny, iff they are already engaged in a conversation (in which case, the requesting agent will not consider communication with them anymore in this turn), or an inform giving the requester information about the requests it has sent and received.",
                "When all replies have been received, each agent can calculate the weight of all requests concerning it.",
                "It does so by substracting from the weight of its request the weight of all requests concerning either it or its target (that is, the final weight of the request from ai to aj is Wi,j = wi,j +wj,i − ( P k∈R(i)−{j} wi,k + P k∈S(i)−{j} wk,i + P k∈R(j)−{i} wj,k + P k∈S(j)−{i} wk,j) where wi,j is the weight of the request of ai to aj, R(i) is the set of indice of agents having received a request from ai and S(i) is the set of indice of agents having send a request to ai).",
                "It then finally sends a weighted request to the agents who maximise this weight (or wait for a request) as described in the global protocol. 4. (CONDITIONAL) CONVERGENCE TO GLOBAL CONSISTENCY In this section we will show that the requirements regarding protocols and strategies just discussed will be sufficient to ensure that the system will eventually converge towards global consistency, under some conditions.",
                "We first show that, if two agents are not mutually consistent at some time, then there will be necessarily a time in the future such that an agent will learn a new observation, being it because it is new for the system, or by learning it from another agent.",
                "Lemma 1.",
                "Let S be a system populated by n agents a1, a2, ..., an, temporaly connex, and involving bounded perceptions for these agents.",
                "Let n1 be the sum of cardinalities of the intersection of pairwise observation sets. (n1 = P (i,j)∈[1,n]2 |Oi ∩ Oj|) Let n2 be the cardinality of the union of all agents observations sets. (n2 = | ∪N i=1 Oi|).",
                "If ¬MCons(ai, aj) at time t0, there is necessarily a time t > t0 s.t. either n1 or n2 will increase.",
                "Proof.",
                "Suppose that there exist a time t0 and indices (i, j) s.t. ¬MCons(ai, aj).",
                "We will use mt0 = P (k,l)∈[1,n]2 εComm(ak, al, t0) where εComm(ak, al, t0) = 1 if ak and al have communicated at least once since t0, and 0 otherwise.",
                "Temporal connexity guarantees that there exist t1, ..., tm+1 and k1, ..., km s.t.",
                "C(ai, ak1 , t1), C(akm , aj, tm+1), and ∀p ∈ [1, m], C(akp , akp+1 , tp).",
                "Clearly, if MCons(ai, ak1 ), MCons(akm , aj) and ∀p, MCons(akp , akp+1 ), we have MCons(ai, aj) which contradicts our hypothesis (MCons being transitive, MCons(ai, ak1 )∧MCons(ak1 , ak2 ) implies that MCons(ai, ak2 ) and so on till MCons(ai, akm )∧ MCons(akm , aj) which implies MCons(ai, aj) ).",
                "At least two agents are then necessarily inconsistent (¬MCons(ai, ak1 ), or ¬MCons(akm , aj), or ∃p0 t.q. ¬MCons(akp0 , akp0+1 )).",
                "Let ak and al be these two neighbours at a time t > t0 1 .",
                "The SOLVE property ensures that either ak or al will send a communication request to the other agent at time t .",
                "As shown before, this in turn ensures that at least one of these agents will be involved in a communication.",
                "Then there are two possibilities: (case i) ak and al communicate at time t .",
                "In this case, we know that ¬MCons(ak, al).",
                "This and the CONS property ensures that at least one of the agents must change its 1 Strictly speaking, the transitivity of MCons only ensure that ak and al are inconsistent at a time t ≥ t0 that can be different from the time t at which they can communicate.",
                "But if they become consistent between t and t (or inconsistent between t and t ), it means that at least one of them have changed its hypothesis between t and t , that is, after t0.",
                "We can then apply the reasoning of case iib.",
                "The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 1001 hypothesis, which in turn, since agents are autonomous, implies at least one exchange of observation.",
                "But then |Ok ∩Ol| is bound to increase: n1(t ) > n1(t0). (case ii) ak communicates with ap at time t .",
                "We then have again two possibilities: (case iia) ak and ap did not communicate since t0.",
                "But then εComm(ak, ap, t0) had value 0 and takes value 1.",
                "Hence mt0 increases. (case iib) ak and ap did communicate at some time t0 > t0.",
                "The CONS property of the protocol ensures that MCons(ak, ap) at that time.",
                "Now the fact that they communicate and FOCUS implies that at least one of them did change its hypothesis in the meantime.",
                "The fact that agents are autonomous implies in turn that a new observation (perceived or received from another agent) necessarily provoked this change.",
                "The latter case would ensure the existence of a time t > t0 and an agent aq s.t. either |Op ∩Oq| or |Ok ∩Oq| increases of 1 at that time (implying n1(t ) > n1(t0)).",
                "The former case means that the agent gets a new perception o at time t .",
                "If that observation was unknown in the system before, then n2(t ) > n2(t0).",
                "If some agent aq already knew this observation before, then either Op ∩ Oq or Ok ∩ Oq increases of 1 at time t (which implies that n1(t ) > n1(t0)).",
                "Hence, ¬MCons(ai, aj) at time t0 guarantees that, either: −∃t > t0 t.q. n1(t ) > n1(t0); or −∃t > t0 t.q. n2(t ) > n2(t0); or −∃t > t0 t.q. mt0 increases of 1 at time t .",
                "By iterating the reasoning with t (but keeping t0 as the time reference for mt0 ), we can eliminate the third case (mt0 is integer and bounded by n2 , which means that after a maximum of n2 iterations, we necessarily will be in one of two other cases.)",
                "As a result, we have proven that if ¬MCons(ai, aj) at time t0, there is necessarily a time t s.t. either n1 or n2 will increase.",
                "Theorem 1 (Global consistency).",
                "Let S be a system populated by n agents a1, a2, ..., an, temporaly connex, and involving bounded perceptions for these agents.",
                "Let Cons(ai, aj) be a transitive consistency property.",
                "Then any protocol and strategies satisfying properties CONS, SOLVE, FOCUS, COMM and REQU guarantees that the system will converge towards global consistency.",
                "Proof.",
                "For the sake of contradiction, let us assume ∃I, J ∈ [1, N] s.t. ∀t, ∃t0 > t, t.q. ¬Cons(aI , aJ , t0).",
                "Using the lemma, this implies that ∃t > t0 s.t. either n1(t ) > n1(t0) or n2(t ) > n2(t0).",
                "But we can apply the same reasoning taking t = t , which would give us t1 > t > t0 s.t. ¬Cons(aI , aJ , t1), which gives us t > t1 s.t. either n1(t ) > n1(t1) or n2(t ) > n2(t1).",
                "By successive iterations we can then construct a sequence t0, t1, ..., tn, which can be divided in two sub-sequences t0, t1, ...tn and t0 , t1 , ..., tn s.t. n1(t0) < n1(t1) < ... < n1(tn) and n2(t0 ) < n2(t1 ) < ... < n2(tn).",
                "One of these sub-sequences has to be infinite.",
                "However, n1(ti) and n2(ti ) are strictly growing, integer, and bounded, which implies that both are finite.",
                "Contradiction.",
                "What the previous result essentially shows is that, in a system where no agent will be isolated from the rest of the agents for ever, only very mild assumptions on the protocols and strategies used by agents suffice to guarantee convergence towards system consistency in a finite amount of time (although it might take very long).",
                "Unfortunately, in many critical situations, it will not be possible to assume this temporal connexity.",
                "As distributed approaches as the one advocated in this paper are precisely often presented as a good way to tackle problems of reliability or problems of dependence to a center that are of utmost importance in these critical applications, it is certainly interesting to further explore how such a system would behave when we relax this assumption. 5.",
                "EXPERIMENTAL STUDY This experiment involves agents trying to escape from a burning building.",
                "The environment is described as a spatial grid with a set of walls and (thankfully) some exits.",
                "Time and space are considered discrete.",
                "Time is divided in rounds.",
                "Agents are localised by their position on the spatial grid.",
                "These agents can move and communicate with other agents.",
                "In a round, an agent can move of one cell in any of the four cardinal directions, provided it is not blocked by a wall.",
                "In this application, agents communicate with any other agent (but, recall, a single one) given that this agent is in view, and that they have not yet exchanged their current favoured hypothesis.",
                "Suddenly, a fire erupts in these premises.",
                "From this moment, the fire propagates.",
                "Each round, for each cases where there is fire, the fire propagates in the four directions.",
                "However, the fire cannot propagate through a wall.",
                "If the fire propagates in a case where an agent is positioned, that agent burns and is considered dead.",
                "It can of course no longer move nor communicate.",
                "If an agent gets to an exit, it is considered saved, and can no longer be burned.",
                "Agents know the environment and the rules governing the dynamics of this environment, that is, they know the map as well as the rules of fire propagation previously described.",
                "They also locally perceive this environment, but cannot see further than 3 cases away, in any direction.",
                "Walls also block the line of view, preventing agents from seeing behind them.",
                "Within their sight, they can see other agents and whether or not the cases they see are on fire.",
                "All these perceptions are memorised.",
                "We now show how this instantiates the abstract framework presented the paper. • O = {Fire(x, y, t), NoFire(x, y, t), Agent(ai, x, y, t)} Observations can then be positive (o ∈ P(O) iff ∃h ∈ H s.t. h |= o) or negative (o ∈ N(O) iff ∃h ∈ H s.t. h |= ¬o). • H={FireOrigin(x1, y1, t1)∧...∧FireOrigin(xl, yl, tl)} Hypotheses are conjunctions of FireOrigins. • Cons(h, O) consistency relation satisfies: - coherence : ∀o ∈ N(O), h |= ¬o. - completeness : ∀o ∈ P(O), h |= o. - minimality : For all h ∈ H, if h is coherent and complete for O, then h is prefered to h according to the preference relation (h ≤p h ).2 2 Selects first the minimal number of origins, then the most recent (least preemptive strategy [6]), then uses some arbitrary fixed ranking to discriminate ex-aequo.",
                "The resulting relation is a total order, hence minimality implies that there will be a single h s.t.Cons(O, h) for a given O.",
                "This in turn means that MCons(ai, aj) iff Cons(ai), Cons(aj), and hi = hj.",
                "This relation is then transitive and symmetric. 1002 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) • Eh takes O as argument and returns min≤p of the coherent and complete hypothesis for O 5.1 Experimental Evaluation We will classically (see e.g. [3, 4]) assess the effectiveness and efficiency of different interaction protocols.",
                "Effectiveness of a protocol The proportion of agents surviving the fire over the initial number of agents involved in the experiment will determine the effectiveness of a given protocol.",
                "If this value is high, the protocol has been effective to propagate the information and/or for the agents to refine their hypotheses and determine the best way to the exit.",
                "Efficiency of a protocol Typically, the use of supporting information will involve a communication overhead.",
                "We will assume here that the efficiency of a given protocol is characterised by the data flow induced by this protocol.",
                "In this paper we will only discuss this aspect wrt. local protocols.",
                "The main measure that we shall then use here is the mean total size of messages that are exchanged by agents per exchange (hence taking into account both the number of messages and the actual size of the messages, because it could be that messages happen to be very big, containing e.g. a large number of observations, which could counter-balance a low number of messages). 5.2 Experimental Settings The chosen experimental settings are the following: • Environmental topology- Performances of information propagation are highly constrained by the environment topology.",
                "The perception skills of the agents depend on the openness of the environment.",
                "With a large number of walls the perceptions of agents are limited, and also the number of possible inter-agent communications, whereas an open environment will provide optimal possibilities of perception and information propagation.",
                "Thus, we propose a topological index (see below) as a common basis to charaterize the environments (maps) used during experimentations.",
                "The topological index (TI) is the ratio of the number of cells that can be perceived by agents summed up from all possible positions, divided by the number of cells that would be perceived from the same positions but without any walls. (The closer to 1, the more open the environment).",
                "We shall also use two additional, more classical [10], measures: the characteristic path length3 (CPL) and the clustering coefficient4 (CC). • Number of agents- The propagation of information also depends on the initial number of agents involved during an experimentation.",
                "For instance, the more agents, the more potential communications there is.",
                "This means that there will be more potential for propagation, but also that the bilateral exchange restriction will be more crucial. 3 The CPL is the median of the means of the shortest path lengths connecting each node to all other nodes. 4 characterising the isolation degree of a region of an environment in terms of acessibility (number of roads still usable to reach this region).",
                "Map T.I. (%) C.P.L.",
                "C.C. 69-1 69,23 4,5 0,69 69-2 68,88 4,38 0,65 69-3 69,80 4,25 0,67 53-1 53,19 5,6 0,59 53-2 53,53 6,38 0,54 53-3 53,92 6,08 0,61 38-1 38,56 8,19 0,50 38-2 38,56 7,3 0,50 38-3 38,23 8,13 0,50 Table 1: Topological Characteristics of the Maps • Initial positions of the agents- Initial positions of the agents have a significant influence on the overall behavior of an instance of our system: being close from an exit will (in general) ease the escape. 5.3 Experimental environments We choose to realize experiments on three very different topological indexes (69% for open environments, 53% for mixed environments, and 38% for labyrinth-like environments).",
                "Figure 2: Two maps (left: TI=69%, right TI=38%) We designed three different maps for each index (Fig. 2 shows two of them), containing the same maximum number of agents (36 agents max.) with a maximum density of one agent per cell, the same number of exits and a similar fire origin (e.g. starting time and position).",
                "The three differents maps of a given index are designed as follows.",
                "The first map is a model of an existing building floor.",
                "The second map has the same enclosure, exits and fire origin as the first one, but the number and location of walls are different (wall locations are designed by an heuristic which randomly creates walls on the spatial grid such that no fully closed rooms are created and that no exit is closed).",
                "The third map is characterised by geometrical enclosure in wich walls location is also designed with the aforementioned heuristic.",
                "Table 1 summarizes the different topological measures characterizing these different maps.",
                "It is worth pointing out that the values confirm the relevance of TI (maps with a high TI have a low CPL and a high CC.",
                "However the CPL and CC allows to further refine the difference between the maps, e.g. between 53-1 and 53-2). 5.4 Experimental Results For each triple of maps defined as above we conduct the same experiments.",
                "In each experiment, the society differs in terms of its initial proportion of involved agents, from 1% to 100%.",
                "This initial proportion represents the percentage of involved agents with regards to the possible maximum number of agents.",
                "For each map and each initial proportion, The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 1003 we select randomly 100 different initial agents locations.",
                "For each of those different locations we execute the system one time for each different interaction protocol.",
                "Effectiveness of Communication and Argumentation The first experiment that we set up aims at testing how effective is hypotheses exchange (HE), and in particular how the topological aspects will affect this effectiveness.",
                "In order to do so, we have computed the ratio of improvement offered by that protocol over a situation where agents could simply not communicate (no comm).",
                "To get further insights as to what extent the hypotheses exchange was really crucial, we also tested a much less elaborated protocol consisting of mere observation exchanges (OE).",
                "More precisely, this protocol requires that each agent stores any unexpected observation that it perceives, and agents simply exchange their respective lists of observations when they discuss.",
                "In this case, the local protocol is different (note in particular that it does not guarantee mutual consistency), but the global protocol remains the same (at the only exception that agents motivation to communicate is to synchronise their list of observations, not their hypothesis).",
                "If this protocol is at best as effective as HE, it has the advantage of being more efficient (this is obvious wrt the number of messages which will be limited to 2, less straightforward as far as the size of messages is concerned, but the rough observation that the exchange of observations can be viewed as a flat version of the challenge is helpful to see this).",
                "The results of these experiments are reported in Fig. 3.",
                "Figure 3: Comparative effectiveness ratio gain of protocols when the proportion of agents augments The first observation that needs to be made is that communication improves the effectiveness of the process, and this ratio increases as the number of agents grows in the system.",
                "The second lesson that we learn here is that closeness relatively makes communication more effective over non communication.",
                "Maps exhibiting a T.I. of 38% are constantly above the two others, and 53% are still slightly but significantly better than 69%.",
                "However, these curves also suggest, perhaps surprisingly, that HE outperforms OE in precisely those situations where the ratio gain is less important (the only noticeable difference occurs for rather open maps where T.I. is 69%).",
                "This may be explained as follows: when a map is open, agents have many potential explanation candidates, and argumentation becomes useful to discriminate between those.",
                "When a map is labyrinth-like, there are fewer possible explanations to an unexpected event.",
                "Importance of the Global Protocol The second set of experiments seeks to evaluate the importance of the design of the global protocol.",
                "We tested our protocol against a local broadcast (LB) protocol.",
                "Local broadcast means that all the neighbours agents perceived by an agent will be involved in a communication with that agent in a given round -we alleviate the constraint of a single communication by agent.",
                "This gives us a rough upper bound upon the possible ratio gain in the system (for a given local protocol).",
                "Again, we evaluated the ratio gain induced by that LB over our classical HE, for the three different classes of maps.",
                "The results are reported in Fig. 4.",
                "Figure 4: Ratio gain of local broadcast over hypotheses exchange Note to begin with that the ratio gain is 0 when the proportion of agents is 5%, which is easily explained by the fact that it corresponds to situations involving only two agents.",
                "We first observe that all classes of maps witness a ratio gain increasing when the proportion of agents augments: the gain reaches 10 to 20%, depending on the class of maps considered.",
                "If one compares this with the improvement reported in the previous experiment, it appears to be of the same magnitude.",
                "This illustrates that the design of the global protocol cannot be ignored, especially when the proportion of agents is high.",
                "However, we also note that the effectiveness ratio gain curves have very different shapes in both cases: the gain induced by the accuracy of the local protocol increases very quickly with the proportion of agents, while the curve is really smooth for the global one.",
                "Now let us observe more carefully the results reported here: the curve corresponding to a TI of 53% is above that corresponding to 38%.",
                "This is so because the more open a map, the more opportunities to communicate with more than one agent (and hence benefits from broadcast).",
                "However, we also observe that curve for 69% is below that for 53%.",
                "This is explained as follows: in the case of 69%, the potential gain to be made in terms of surviving agents is much lower, because our protocols already give rather efficient outcomes anyway (quickly reaching 90%, see Fig. 3).",
                "A simple rule of thumb could be that when the number of agents is small, special attention should be put on the local 1004 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) protocol, whereas when that number is large, one should carefully design the global one (unless the map is so open that the protocol is already almost optimally efficient).",
                "Efficiency of the Protocols The final experiment reported here is concerned with the analysis of the efficiency of the protocols.",
                "We analysis here the mean size of the totality of the messages that are exchanged by agents (mean size of exchanges, for short) using the following protocols: HE, OE, and two variant protocols.",
                "The first one is an intermediary restricted hypotheses exchange protocol (RHE).",
                "RHE is as follows: it does not involve any challenge nor counter-propose, which means that agents cannot switch their role during the protocol (this differs from RE in that respect).",
                "In short, RHE allows an agent to exhaust its partners criticism, and eventually this partner will come to adopt the agents hypothesis.",
                "Note that this means that the autonomy of the agent is not preserved here (as an agent will essentially accept any hypothesis it cannot undermine), with the hope that the gain in efficiency will be significant enough to compensate a loss in effectiveness.",
                "The second variant protocol is a complete observation exchange protocol (COE).",
                "COE uses the same principles as OE, but includes in addition all critical negative examples (nofire) in the exchange (thus giving all examples used as arguments by the hypotheses exchanges protocol), hence improving effectiveness.",
                "Results for map 69-1 are shown on Fig. 5.",
                "Figure 5: Mean size of exchanges First we can observe the fact that the ordering of the protocols, from the least efficient to the most efficient, is COE, HE, RHE and then OE.",
                "HE being more efficient than COE proves that the argumentation process gains efficiency by selecting when it is needed to provide negative example, which have less impact that positive ones in our specific testbed.",
                "However, by communicating hypotheses before eventually giving observation to support it (HE) instead of directly giving the most crucial observations (OE), the argumentation process doubles the size of data exchanges.",
                "It is the cost for ensuring consistency at the end of the exchange (a property that OE does not support).",
                "Also significant is the fact the the mean size of exchanges is slightly higher when the number of agents is small.",
                "This is explained by the fact that in these cases only a very few agents have relevant informations in their possession, and that they will need to communicate a lot in order to come up with a common view of the situation.",
                "When the number of agents increases, this knowledge is distributed over more agents which need shorter discussions to get to mutual consistency.",
                "As a consequence, the relative gain in efficiency of using RHE appears to be better when the number of agents is small: when it is high, they will hardly argue anyway.",
                "Finally, it is worth noticing that the standard deviation for these experiments is rather high, which means that the conversation do not converge to any stereotypic pattern. 6.",
                "CONCLUSION This paper has investigated the properties of a multiagent system where each (distributed) agent locally perceives its environment, and tries to reach consistency with other agents despite severe communication restrictions.",
                "In particular we have exhibited conditions allowing convergence, and experimentally investigated a typical situation where those conditions cannot hold.",
                "There are many possible extensions to this work, the first being to further investigate the properties of different global protocols belonging to the class we identified, and their influence on the outcome.",
                "There are in particular many heuristics, highly dependent on the context of the study, that could intuitively yield interesting results (in our study, selecting the recipient on the basis of what can be inferred from his observed actions could be such a heuristic).",
                "One obvious candidate for longer term issues concern the relaxation of the assumption of perfect sensing. 7.",
                "REFERENCES [1] G. Bourgne, N. Maudet, and S. Pinson.",
                "When agents communicate hypotheses in critical situations.",
                "In Proceedings of DALT-2006, May 2006. [2] P. Harvey, C. F. Chang, and A. Ghose.",
                "Support-based distributed search: a new approach for multiagent constraint processing.",
                "In Proceedings of AAMAS06, 2006. [3] H. Jung and M. Tambe.",
                "Argumentation as distributed constraint satisfaction: Applications and results.",
                "In Proceedings of AGENTS01, 2001. [4] N. C. Karunatillake and N. R. Jennings.",
                "Is it worth arguing?",
                "In Proceedings of ArgMAS 2004, 2004. [5] S. Onta˜n´on and E. Plaza.",
                "Arguments and counterexamples in case-based joint deliberation.",
                "In Proceedings of ArgMAS-2006, May 2006. [6] D. Poole.",
                "Explanation and prediction: An architecture for default and abductive reasoning.",
                "Computational Intelligence, 5(2):97-110, 1989. [7] I. Rahwan, S. D. Ramchurn, N. R. Jennings, P. McBurney, S. Parsons, and L. Sonenberg.",
                "Argumention-based negotiation.",
                "The Knowledge Engineering Review, 4(18):345-375, 2003. [8] N. Roos, A. ten Tije, and C. Witteveen.",
                "A protocol for multi-agent diagnosis with spatially distributed knowledge.",
                "In Proceedings of AAMAS03, 2003. [9] N. Roos, A. ten Tije, and C. Witteveen.",
                "Reaching diagnostic agreement in multiagent diagnosis.",
                "In Proceedings of AAMAS04, 2004. [10] T. Takahashi, Y. Kaneda, and N. Ito.",
                "Preliminary study - using robocuprescue simulations for disasters prevention.",
                "In Proceedings of SRMED2004, 2004.",
                "The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 1005"
            ],
            "original_annotated_samples": [],
            "translated_annotated_samples": [],
            "translated_text": "",
            "candidates": [],
            "error": [
                []
            ]
        },
        "bilateral exchange": {
            "translated_key": "intercambio bilateral",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Hypotheses Refinement under Topological Communication Constraints ∗ Gauvain Bourgne, Gael Hette, Nicolas Maudet, and Suzanne Pinson LAMSADE, Univ.",
                "Paris-Dauphine, France {bourgne,hette,maudet,pinson}@lamsade.dauphine.fr ABSTRACT We investigate the properties of a multiagent system where each (distributed) agent locally perceives its environment.",
                "Upon perception of an unexpected event, each agent locally computes its favoured hypothesis and tries to propagate it to other agents, by exchanging hypotheses and supporting arguments (observations).",
                "However, we further assume that communication opportunities are severely constrained and change dynamically.",
                "In this paper, we mostly investigate the convergence of such systems towards global consistency.",
                "We first show that (for a wide class of protocols that we shall define), the communication constraints induced by the topology will not prevent the convergence of the system, at the condition that the system dynamics guarantees that no agent will ever be isolated forever, and that agents have unlimited time for computation and arguments exchange.",
                "As this assumption cannot be made in most situations though, we then set up an experimental framework aiming at comparing the relative efficiency and effectiveness of different interaction protocols for hypotheses exchange.",
                "We study a critical situation involving a number of agents aiming at escaping from a burning building.",
                "The results reported here provide some insights regarding the design of optimal protocol for hypotheses refinement in this context.",
                "Categories and Subject Descriptors I.2.11 [Artificial Intelligence]: Distributed Artificial Intelligence-Multiagent systems General Terms Theory, Experimentation 1.",
                "INTRODUCTION We consider a multiagent system where each (distributed) agent locally perceives its environment, and we assume that some unexpected event occurs in that system.",
                "If each agent computes only locally its favoured hypothesis, it is only natural to assume that agents will seek to coordinate and refine their hypotheses by confronting their observations with other agents.",
                "If, in addition, the communication opportunities are severely constrained (for instance, agents can only communicate when they are close enough to some other agent), and dynamically changing (for instance, agents may change their locations), it becomes crucial to carefully design protocols that will allow agents to converge to some desired state of global consistency.",
                "In this paper we exhibit some sufficient conditions on the system dynamics and on the protocol/strategy structures that allow to guarantee that property, and we experimentally study some contexts where (some of) these assumptions are relaxed.",
                "While problems of diagnosis are among the venerable classics in the AI tradition, their multiagent counterparts have much more recently attracted some attention.",
                "Roos and colleagues [8, 9] in particular study a situation where a number of distributed entities try to come up with a satisfying global diagnosis of the whole system.",
                "They show in particular that the number of messages required to establish this global diagnosis is bound to be prohibitive, unless the communication is enhanced with some suitable protocol.",
                "However, they do not put any restrictions on agents communication options, and do not assume either that the system is dynamic.",
                "The benefits of enhancing communication with supporting information to make convergence to a desired global state of a system more efficient has often been put forward in the literature.",
                "This is for instance one of the main idea underlying the argumentation-based negotiation approach [7], where the desired state is a compromise between agents with conflicting preferences.",
                "Many of these works however make the assumption that this approach is beneficial to start with, and study the technical facets of the problem (or instead emphasize other advantages of using argumentation).",
                "Notable exceptions are the works of [3, 4, 2, 5], which studied in contexts different from ours the efficiency of argumentation.",
                "The rest of the paper is as follows.",
                "Section 2 specifies the basic elements of our model, and Section 3 goes on to presenting the different protocols and strategies used by the agents to exchange hypotheses and observations.",
                "We put special attention at clearly emphasizing the conditions on the system dynamics and protocols/strategies that will be exploited in the rest of the paper.",
                "Section 4 details one of 998 978-81-904262-7-5 (RPS) c 2007 IFAAMAS the main results of the paper, namely the fact that under the aforementioned conditions, the constraints that we put on the topology will not prevent the convergence of the system towards global consistency, at the condition that no agent ever gets completely lost forever in the system, and that unlimited time is allowed for computation and argument exchange.",
                "While the conditions on protocols and strategies are fairly mild, it is also clear that these system requirements look much more problematic, even frankly unrealistic in critical situations where distributed approaches are precisely advocated.",
                "To get a clearer picture of the situation induced when time is a critical factor, we have set up an experimental framework that we introduce and discuss in Section 5.",
                "The critical situation involves a number of agents aiming at escaping from a burning building.",
                "The results reported here show that the effectiveness of argument exchange crucially depends upon the nature of the building, and provide some insights regarding the design of optimal protocol for hypotheses refinement in this context. 2.",
                "BASIC NOTIONS We start by defining the basic elements of our system.",
                "Environment Let O be the (potentially infinite) set of possible observations.",
                "We assume the sensors of our agents to be perfect, hence the observations to be certain.",
                "Let H be the set of hypotheses, uncertain and revisable.",
                "Let Cons(h, O) be the consistency relation, a binary relation between a hypothesis h ∈ H and a set of observations O ⊆ O.",
                "In most cases, Cons will refer to classical consistency relation, however, we may overload its meaning and add some additional properties to that relation (in which case we will mention it).",
                "The environment may include some dynamics, and change over the course of time.",
                "We define below sequences of time points to deal with it: Definition 1 (Sequence of time points).",
                "A sequence of time points t1, t2, . . . , tn from t is an ordered set of time points t1, t2, . . . , tn such that t1 ≥ t and ∀i ∈ [1, n − 1], ti+1 ≥ ti.",
                "Agent We take a system populated by n agents a1, . . . , an.",
                "Each agent is defined as a tuple F, Oi, hi , where: • F, the set of facts, common knowledge to all agents. • Oi ∈ 2O , the set of observations made by the agent so far.",
                "We assume a perfect memory, hence this set grows monotonically. • hi ∈ H, the favourite hypothesis of the agent.",
                "A key notion governing the formation of hypotheses is that of consistency, defined below: Definition 2 (Consistency).",
                "We say that: • An agent is consistent (Cons(ai)) iff Cons(hi, Oi) (that is, its hypothesis is consistent with its observation set). • An agent ai consistent with a partner agent aj iff Cons(ai) and Cons(hi, Oj) (that is, this agent is consistent and its hypothesis can explain the observation set of the other agent). • Two agents ai and aj are mutually consistent (MCons(ai, aj)) iff Cons(ai, aj) and Cons(aj, ai). • A system is consistent iff ∀(i, j)∈[1, n]2 it is the case that MCons(ai, aj).",
                "To ensure its consistency, each agent is equipped with an abstract reasoning machinery that we shall call the explanation function Eh.",
                "This (deterministic) function takes a set of observation and returns a single prefered hypothesis (2O → H).",
                "We assume h = Eh(O) to be consistent with O by definition of Eh, so using this function on its observation set to determine its favourite hypothesis is a sure way for the agent to achieve consistency.",
                "Note however that an hypothesis does not need to be generated by Eh to be consistent with an observation set.",
                "As a concrete example of such a function, and one of the main inspiration of this work, one can cite the Theorist reasoning system [6] -as long as it is coupled with a filter selecting a single prefered theory among the ones initially selected by Theorist.",
                "Note also that hi may only be modified as a consequence of the application Eh.",
                "We refer to this as the autonomy of the agent: no other agent can directly impose a given hypothesis to an agent.",
                "As a consequence, only a new observation (being it a new perception, or an observation communicated by a fellow agent) can result in a modification of its prefered hypothesis hi (but not necessarily of course).",
                "We finally define a property of the system that we shall use in the rest of the paper: Definition 3 (Bounded Perceptions).",
                "A system involves a bounded perception for agents iff ∃n0 s.t. ∀t| ∪N i=1 Oi| ≤ n0. (That is, the number of observations to be made by the agents in the system is not infinite.)",
                "Agent Cycle Now we need to see how these agents will evolve and interact in their environment.",
                "In our context, agents evolve in a dynamic environment, and we classicaly assume the following system cycle: 1.",
                "Environment dynamics: the environment evolves according to the defined rules of the system dynamics. 2.",
                "Perception step : agents get perceptions from the environment.",
                "These perceptions are typically partial (e.g. the agent can only see a portion of a map). 3.",
                "Reasoning step: agents compare perception with predictions, seek explanations for (potential) difference(s), refine their hypothesis, draw new conclusions. 4.",
                "Communication step: agents can communicate hypotheses and observations with other agents through a defined protocol.",
                "Any agent can only be involved in one communication with another agent by step. 5.",
                "Action step: agents do some practical reasoning using the models obtained from the previous steps and select an action.",
                "They can then modify the environment by executing it.",
                "The communication of the agents will be further constrained by topological consideration.",
                "At a given time, an agent will only be able to communicate with a number of neighbours.",
                "Its connexions with these others agents may The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 999 evolve with its situation in the environment.",
                "Typically, an agent can only communicate with agents that it can sense, but one could imagine evolving topological constraints on communication based on a network of communications between agents where the links are not always active.",
                "Communication In our system, agents will be able to communicate with each other.",
                "However, due to the aforementionned topological constraints, they will not be able to communicate with any agents at anytime.",
                "Who an agent can communicate with will be defined dynamically (for instance, this can be a consequence of the agents being close enough to get in touch).",
                "We will abstractly denote by C(ai, aj, t) the communication property, in other words, the fact that agents ai and aj can communicate at time t (note that this relation is assumed to be symetric, but of course not transitive).",
                "We are now in a position to define two essential properties of our system.",
                "Definition 4 (Temporal Path).",
                "There exists a temporal communication path at horizon tf (noted Ltf (aI , aJ )) between ai and aj iff there exists a sequence of time points t1, t2, . . . , tn from tf and a sequence of agents k1, k2, . . . , kn s.t. (i) C(aI , ak1 , t1), (ii) C(akn , aJ , tn+1), (iii) ∀i ∈ [1, n], C(aki , aki+1 , ti) Intuitively, what this property says is that it is possible to find a temporal path in the future that would allow to link agent ai and aj via a sequence of intermediary agents.",
                "Note that the time points are not necessarily successive, and that the sequence of agents may involve the same agents several times.",
                "Definition 5 (Temporal Connexity).",
                "A system is temporaly connex iff ∀t ∀(i, j)∈[1, n]2 Lt(ai, aj) In short, a temporaly connex system guarantees that any agent will be able to communicate with any other agents, no matter how long it might take to do so, at any time.",
                "To put it another way, it is never the case that an agent will be isolated for ever from another agent of the system.",
                "We will next discuss the detail of how communication concretely takes place in our system.",
                "Remember that in this paper, we only consider the case of bilateral exchanges (an agent can only speak to a single other agent), and that we also assume that any agent can only engage in a single exchange in a given round. 3.",
                "PROTOCOLS AND STRATEGIES In this section, we discuss the requirements of the interaction protocols that govern the exchange of messages between agents, and provide some example instantiation of such protocols.",
                "To clarify the presentation, we distinguish two levels: the local level, which is concerned with the regulation of bilateral exchanges; and the global level,which essentially regulates the way agents can actually engage into a conversation.",
                "At each level, we separate what is specified by the protocol, and what is left to agents strategies.",
                "Local Protocol and Strategies We start by inspecting local protocols and strategies that will regulate the communication between the agents of the system.",
                "As we limit ourselves to bilateral communication, these protocols will simply involve two agents.",
                "Such protocol will have to meet one basic requirement to be satisfying. • consistency (CONS)- a local protocol has to guarantee the mutual consistency of agents upon termination (which implies termination of course).",
                "Figure 1: A Hypotheses Exchange Protocol [1] One example such protocol is the protocol described in [1] that is pictured in Fig. 1.",
                "To further illustrate how such protocol can be used by agents, we give some details on a possible strategy: upon receiving a hypothesis h1 (propose(h1) or counterpropose(h1)) from a1, agent a2 is in state 2 and has the following possible replies: counterexample (if the agent knows an example contradicting the hypothesis, or not explained by this hypothesis), challenge (if the agents lacks evidence to accept this hypothesis), counterpropose (if the agent agrees with the hypothesis but prefers another one), or accept (if it is indeed as good as its favourite hypothesis).",
                "This strategy guarantees, among other properties, the eventual mutual logical consistency of the involved agents [1].",
                "Global Protocol The global protocol regulates the way bilateral exchanges will be initiated between agents.",
                "At each turn, agents will concurrently send one weighted request to communicate to other agents.",
                "This weight is a value measuring the agents willingness to converse with the targeted agent (in practice, this can be based on different heuristics, but we shall make some assumptions on agents strategies, see below).",
                "Sending such a request is a kind of conditional commitment for the agent.",
                "An agent sending a weighted request commits to engage in conversation with the target if he does not receive and accept himself another request.",
                "Once all request have been received, each agent replies with either an acccept or a reject.",
                "By answering with an accept, an agent makes a full commitment to engage in conversation with the sender.",
                "Therefore, it can only send one accept in a given round, as an agent can only participate in one conversation per time step.",
                "When all response have been received, each agent receiving an accept can either initiate a conversation using the local protocol or send a cancel if it has accepted another request.",
                "At the end of all the bilateral exchanges, the agents engaged in conversation are discarded from the protocol.",
                "Then each of the remaining agents resends a request and the process iterates until no more requests are sent.",
                "Global Strategy We now define four requirements for the strategies used by agents, depending on their role in the protocol: two are concerned with the requestee role (how to decide who the 1000 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) agent wishes to communicate with? ), the other two with the responder role (how to decide which communication request to accept or not?). • Willingness to solve inconsistancies (SOLVE)-agents want to communicate with any other agents unless they know they are mutually consistent. • Focus on solving inconsistencies (FOCUS)-agents do not request communication with an agent with whom they know they are mutually consistent. • Willingness to communicate (COMM)-agents cannot refuse a weighted communication request, unless they have just received or send a request with a greater weight. • Commitment to communication request (REQU)agents cannot accept a weighted communication request if they have themselves sent a communication request with a greater weight.",
                "Therefore, they will not cancel their request unless they have received a communicational request with greater weight.",
                "Now the protocol structure, together with the properties COMM+REQU, ensure that a request can only be rejected if its target agent engages in communication with another agent.",
                "Suppose indeed that agent ai wants to communicate with aj by sending a request with weight w. COMM guarantees that an agent receiving a weighted request will either accept this communication, accept a communication with a greater weight or wait for the answer to a request with a greater weight.",
                "This ensures that the request with maximal weight will be accepted and not cancelled (as REQU ensures that an agent sending a request can only cancel it if he accepts another request with greater weight).",
                "Therefore at least two agents will engage in conversation per round of the global protocol.",
                "As the protocol ensures that ai can resend its request while aj is not engaged in a conversation, there will be a turn in which aj must engage in a conversation, either with ai or another agent.",
                "These requirements concern request sending and acceptation, but agents also need some strategy of weight attribution.",
                "We describe below an altruist strategy, used in our experiments.",
                "Being cooperative, an agent may want to know more of the communication wishes of other agents in order to improve the overall allocation of exchanges to agents.",
                "A context request step is then added to the global protocol.",
                "Before sending their chosen weighted request, agents attribute a weight to all agents they are prepared to communicate with, according to some internal factors.",
                "In the simplest case, this weight will be 1 for all agent with whom the agent is not sure of being mutually consistent (ensuring SOLVE), other agent being not considered for communication (ensuring FOCUS).",
                "The agent then sends a context request to all agents with whom communication is considered.",
                "This request also provides information about the sender (list of considered communications along with their weight).",
                "After reception of all the context requests, agents will either reply with a deny, iff they are already engaged in a conversation (in which case, the requesting agent will not consider communication with them anymore in this turn), or an inform giving the requester information about the requests it has sent and received.",
                "When all replies have been received, each agent can calculate the weight of all requests concerning it.",
                "It does so by substracting from the weight of its request the weight of all requests concerning either it or its target (that is, the final weight of the request from ai to aj is Wi,j = wi,j +wj,i − ( P k∈R(i)−{j} wi,k + P k∈S(i)−{j} wk,i + P k∈R(j)−{i} wj,k + P k∈S(j)−{i} wk,j) where wi,j is the weight of the request of ai to aj, R(i) is the set of indice of agents having received a request from ai and S(i) is the set of indice of agents having send a request to ai).",
                "It then finally sends a weighted request to the agents who maximise this weight (or wait for a request) as described in the global protocol. 4. (CONDITIONAL) CONVERGENCE TO GLOBAL CONSISTENCY In this section we will show that the requirements regarding protocols and strategies just discussed will be sufficient to ensure that the system will eventually converge towards global consistency, under some conditions.",
                "We first show that, if two agents are not mutually consistent at some time, then there will be necessarily a time in the future such that an agent will learn a new observation, being it because it is new for the system, or by learning it from another agent.",
                "Lemma 1.",
                "Let S be a system populated by n agents a1, a2, ..., an, temporaly connex, and involving bounded perceptions for these agents.",
                "Let n1 be the sum of cardinalities of the intersection of pairwise observation sets. (n1 = P (i,j)∈[1,n]2 |Oi ∩ Oj|) Let n2 be the cardinality of the union of all agents observations sets. (n2 = | ∪N i=1 Oi|).",
                "If ¬MCons(ai, aj) at time t0, there is necessarily a time t > t0 s.t. either n1 or n2 will increase.",
                "Proof.",
                "Suppose that there exist a time t0 and indices (i, j) s.t. ¬MCons(ai, aj).",
                "We will use mt0 = P (k,l)∈[1,n]2 εComm(ak, al, t0) where εComm(ak, al, t0) = 1 if ak and al have communicated at least once since t0, and 0 otherwise.",
                "Temporal connexity guarantees that there exist t1, ..., tm+1 and k1, ..., km s.t.",
                "C(ai, ak1 , t1), C(akm , aj, tm+1), and ∀p ∈ [1, m], C(akp , akp+1 , tp).",
                "Clearly, if MCons(ai, ak1 ), MCons(akm , aj) and ∀p, MCons(akp , akp+1 ), we have MCons(ai, aj) which contradicts our hypothesis (MCons being transitive, MCons(ai, ak1 )∧MCons(ak1 , ak2 ) implies that MCons(ai, ak2 ) and so on till MCons(ai, akm )∧ MCons(akm , aj) which implies MCons(ai, aj) ).",
                "At least two agents are then necessarily inconsistent (¬MCons(ai, ak1 ), or ¬MCons(akm , aj), or ∃p0 t.q. ¬MCons(akp0 , akp0+1 )).",
                "Let ak and al be these two neighbours at a time t > t0 1 .",
                "The SOLVE property ensures that either ak or al will send a communication request to the other agent at time t .",
                "As shown before, this in turn ensures that at least one of these agents will be involved in a communication.",
                "Then there are two possibilities: (case i) ak and al communicate at time t .",
                "In this case, we know that ¬MCons(ak, al).",
                "This and the CONS property ensures that at least one of the agents must change its 1 Strictly speaking, the transitivity of MCons only ensure that ak and al are inconsistent at a time t ≥ t0 that can be different from the time t at which they can communicate.",
                "But if they become consistent between t and t (or inconsistent between t and t ), it means that at least one of them have changed its hypothesis between t and t , that is, after t0.",
                "We can then apply the reasoning of case iib.",
                "The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 1001 hypothesis, which in turn, since agents are autonomous, implies at least one exchange of observation.",
                "But then |Ok ∩Ol| is bound to increase: n1(t ) > n1(t0). (case ii) ak communicates with ap at time t .",
                "We then have again two possibilities: (case iia) ak and ap did not communicate since t0.",
                "But then εComm(ak, ap, t0) had value 0 and takes value 1.",
                "Hence mt0 increases. (case iib) ak and ap did communicate at some time t0 > t0.",
                "The CONS property of the protocol ensures that MCons(ak, ap) at that time.",
                "Now the fact that they communicate and FOCUS implies that at least one of them did change its hypothesis in the meantime.",
                "The fact that agents are autonomous implies in turn that a new observation (perceived or received from another agent) necessarily provoked this change.",
                "The latter case would ensure the existence of a time t > t0 and an agent aq s.t. either |Op ∩Oq| or |Ok ∩Oq| increases of 1 at that time (implying n1(t ) > n1(t0)).",
                "The former case means that the agent gets a new perception o at time t .",
                "If that observation was unknown in the system before, then n2(t ) > n2(t0).",
                "If some agent aq already knew this observation before, then either Op ∩ Oq or Ok ∩ Oq increases of 1 at time t (which implies that n1(t ) > n1(t0)).",
                "Hence, ¬MCons(ai, aj) at time t0 guarantees that, either: −∃t > t0 t.q. n1(t ) > n1(t0); or −∃t > t0 t.q. n2(t ) > n2(t0); or −∃t > t0 t.q. mt0 increases of 1 at time t .",
                "By iterating the reasoning with t (but keeping t0 as the time reference for mt0 ), we can eliminate the third case (mt0 is integer and bounded by n2 , which means that after a maximum of n2 iterations, we necessarily will be in one of two other cases.)",
                "As a result, we have proven that if ¬MCons(ai, aj) at time t0, there is necessarily a time t s.t. either n1 or n2 will increase.",
                "Theorem 1 (Global consistency).",
                "Let S be a system populated by n agents a1, a2, ..., an, temporaly connex, and involving bounded perceptions for these agents.",
                "Let Cons(ai, aj) be a transitive consistency property.",
                "Then any protocol and strategies satisfying properties CONS, SOLVE, FOCUS, COMM and REQU guarantees that the system will converge towards global consistency.",
                "Proof.",
                "For the sake of contradiction, let us assume ∃I, J ∈ [1, N] s.t. ∀t, ∃t0 > t, t.q. ¬Cons(aI , aJ , t0).",
                "Using the lemma, this implies that ∃t > t0 s.t. either n1(t ) > n1(t0) or n2(t ) > n2(t0).",
                "But we can apply the same reasoning taking t = t , which would give us t1 > t > t0 s.t. ¬Cons(aI , aJ , t1), which gives us t > t1 s.t. either n1(t ) > n1(t1) or n2(t ) > n2(t1).",
                "By successive iterations we can then construct a sequence t0, t1, ..., tn, which can be divided in two sub-sequences t0, t1, ...tn and t0 , t1 , ..., tn s.t. n1(t0) < n1(t1) < ... < n1(tn) and n2(t0 ) < n2(t1 ) < ... < n2(tn).",
                "One of these sub-sequences has to be infinite.",
                "However, n1(ti) and n2(ti ) are strictly growing, integer, and bounded, which implies that both are finite.",
                "Contradiction.",
                "What the previous result essentially shows is that, in a system where no agent will be isolated from the rest of the agents for ever, only very mild assumptions on the protocols and strategies used by agents suffice to guarantee convergence towards system consistency in a finite amount of time (although it might take very long).",
                "Unfortunately, in many critical situations, it will not be possible to assume this temporal connexity.",
                "As distributed approaches as the one advocated in this paper are precisely often presented as a good way to tackle problems of reliability or problems of dependence to a center that are of utmost importance in these critical applications, it is certainly interesting to further explore how such a system would behave when we relax this assumption. 5.",
                "EXPERIMENTAL STUDY This experiment involves agents trying to escape from a burning building.",
                "The environment is described as a spatial grid with a set of walls and (thankfully) some exits.",
                "Time and space are considered discrete.",
                "Time is divided in rounds.",
                "Agents are localised by their position on the spatial grid.",
                "These agents can move and communicate with other agents.",
                "In a round, an agent can move of one cell in any of the four cardinal directions, provided it is not blocked by a wall.",
                "In this application, agents communicate with any other agent (but, recall, a single one) given that this agent is in view, and that they have not yet exchanged their current favoured hypothesis.",
                "Suddenly, a fire erupts in these premises.",
                "From this moment, the fire propagates.",
                "Each round, for each cases where there is fire, the fire propagates in the four directions.",
                "However, the fire cannot propagate through a wall.",
                "If the fire propagates in a case where an agent is positioned, that agent burns and is considered dead.",
                "It can of course no longer move nor communicate.",
                "If an agent gets to an exit, it is considered saved, and can no longer be burned.",
                "Agents know the environment and the rules governing the dynamics of this environment, that is, they know the map as well as the rules of fire propagation previously described.",
                "They also locally perceive this environment, but cannot see further than 3 cases away, in any direction.",
                "Walls also block the line of view, preventing agents from seeing behind them.",
                "Within their sight, they can see other agents and whether or not the cases they see are on fire.",
                "All these perceptions are memorised.",
                "We now show how this instantiates the abstract framework presented the paper. • O = {Fire(x, y, t), NoFire(x, y, t), Agent(ai, x, y, t)} Observations can then be positive (o ∈ P(O) iff ∃h ∈ H s.t. h |= o) or negative (o ∈ N(O) iff ∃h ∈ H s.t. h |= ¬o). • H={FireOrigin(x1, y1, t1)∧...∧FireOrigin(xl, yl, tl)} Hypotheses are conjunctions of FireOrigins. • Cons(h, O) consistency relation satisfies: - coherence : ∀o ∈ N(O), h |= ¬o. - completeness : ∀o ∈ P(O), h |= o. - minimality : For all h ∈ H, if h is coherent and complete for O, then h is prefered to h according to the preference relation (h ≤p h ).2 2 Selects first the minimal number of origins, then the most recent (least preemptive strategy [6]), then uses some arbitrary fixed ranking to discriminate ex-aequo.",
                "The resulting relation is a total order, hence minimality implies that there will be a single h s.t.Cons(O, h) for a given O.",
                "This in turn means that MCons(ai, aj) iff Cons(ai), Cons(aj), and hi = hj.",
                "This relation is then transitive and symmetric. 1002 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) • Eh takes O as argument and returns min≤p of the coherent and complete hypothesis for O 5.1 Experimental Evaluation We will classically (see e.g. [3, 4]) assess the effectiveness and efficiency of different interaction protocols.",
                "Effectiveness of a protocol The proportion of agents surviving the fire over the initial number of agents involved in the experiment will determine the effectiveness of a given protocol.",
                "If this value is high, the protocol has been effective to propagate the information and/or for the agents to refine their hypotheses and determine the best way to the exit.",
                "Efficiency of a protocol Typically, the use of supporting information will involve a communication overhead.",
                "We will assume here that the efficiency of a given protocol is characterised by the data flow induced by this protocol.",
                "In this paper we will only discuss this aspect wrt. local protocols.",
                "The main measure that we shall then use here is the mean total size of messages that are exchanged by agents per exchange (hence taking into account both the number of messages and the actual size of the messages, because it could be that messages happen to be very big, containing e.g. a large number of observations, which could counter-balance a low number of messages). 5.2 Experimental Settings The chosen experimental settings are the following: • Environmental topology- Performances of information propagation are highly constrained by the environment topology.",
                "The perception skills of the agents depend on the openness of the environment.",
                "With a large number of walls the perceptions of agents are limited, and also the number of possible inter-agent communications, whereas an open environment will provide optimal possibilities of perception and information propagation.",
                "Thus, we propose a topological index (see below) as a common basis to charaterize the environments (maps) used during experimentations.",
                "The topological index (TI) is the ratio of the number of cells that can be perceived by agents summed up from all possible positions, divided by the number of cells that would be perceived from the same positions but without any walls. (The closer to 1, the more open the environment).",
                "We shall also use two additional, more classical [10], measures: the characteristic path length3 (CPL) and the clustering coefficient4 (CC). • Number of agents- The propagation of information also depends on the initial number of agents involved during an experimentation.",
                "For instance, the more agents, the more potential communications there is.",
                "This means that there will be more potential for propagation, but also that the <br>bilateral exchange</br> restriction will be more crucial. 3 The CPL is the median of the means of the shortest path lengths connecting each node to all other nodes. 4 characterising the isolation degree of a region of an environment in terms of acessibility (number of roads still usable to reach this region).",
                "Map T.I. (%) C.P.L.",
                "C.C. 69-1 69,23 4,5 0,69 69-2 68,88 4,38 0,65 69-3 69,80 4,25 0,67 53-1 53,19 5,6 0,59 53-2 53,53 6,38 0,54 53-3 53,92 6,08 0,61 38-1 38,56 8,19 0,50 38-2 38,56 7,3 0,50 38-3 38,23 8,13 0,50 Table 1: Topological Characteristics of the Maps • Initial positions of the agents- Initial positions of the agents have a significant influence on the overall behavior of an instance of our system: being close from an exit will (in general) ease the escape. 5.3 Experimental environments We choose to realize experiments on three very different topological indexes (69% for open environments, 53% for mixed environments, and 38% for labyrinth-like environments).",
                "Figure 2: Two maps (left: TI=69%, right TI=38%) We designed three different maps for each index (Fig. 2 shows two of them), containing the same maximum number of agents (36 agents max.) with a maximum density of one agent per cell, the same number of exits and a similar fire origin (e.g. starting time and position).",
                "The three differents maps of a given index are designed as follows.",
                "The first map is a model of an existing building floor.",
                "The second map has the same enclosure, exits and fire origin as the first one, but the number and location of walls are different (wall locations are designed by an heuristic which randomly creates walls on the spatial grid such that no fully closed rooms are created and that no exit is closed).",
                "The third map is characterised by geometrical enclosure in wich walls location is also designed with the aforementioned heuristic.",
                "Table 1 summarizes the different topological measures characterizing these different maps.",
                "It is worth pointing out that the values confirm the relevance of TI (maps with a high TI have a low CPL and a high CC.",
                "However the CPL and CC allows to further refine the difference between the maps, e.g. between 53-1 and 53-2). 5.4 Experimental Results For each triple of maps defined as above we conduct the same experiments.",
                "In each experiment, the society differs in terms of its initial proportion of involved agents, from 1% to 100%.",
                "This initial proportion represents the percentage of involved agents with regards to the possible maximum number of agents.",
                "For each map and each initial proportion, The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 1003 we select randomly 100 different initial agents locations.",
                "For each of those different locations we execute the system one time for each different interaction protocol.",
                "Effectiveness of Communication and Argumentation The first experiment that we set up aims at testing how effective is hypotheses exchange (HE), and in particular how the topological aspects will affect this effectiveness.",
                "In order to do so, we have computed the ratio of improvement offered by that protocol over a situation where agents could simply not communicate (no comm).",
                "To get further insights as to what extent the hypotheses exchange was really crucial, we also tested a much less elaborated protocol consisting of mere observation exchanges (OE).",
                "More precisely, this protocol requires that each agent stores any unexpected observation that it perceives, and agents simply exchange their respective lists of observations when they discuss.",
                "In this case, the local protocol is different (note in particular that it does not guarantee mutual consistency), but the global protocol remains the same (at the only exception that agents motivation to communicate is to synchronise their list of observations, not their hypothesis).",
                "If this protocol is at best as effective as HE, it has the advantage of being more efficient (this is obvious wrt the number of messages which will be limited to 2, less straightforward as far as the size of messages is concerned, but the rough observation that the exchange of observations can be viewed as a flat version of the challenge is helpful to see this).",
                "The results of these experiments are reported in Fig. 3.",
                "Figure 3: Comparative effectiveness ratio gain of protocols when the proportion of agents augments The first observation that needs to be made is that communication improves the effectiveness of the process, and this ratio increases as the number of agents grows in the system.",
                "The second lesson that we learn here is that closeness relatively makes communication more effective over non communication.",
                "Maps exhibiting a T.I. of 38% are constantly above the two others, and 53% are still slightly but significantly better than 69%.",
                "However, these curves also suggest, perhaps surprisingly, that HE outperforms OE in precisely those situations where the ratio gain is less important (the only noticeable difference occurs for rather open maps where T.I. is 69%).",
                "This may be explained as follows: when a map is open, agents have many potential explanation candidates, and argumentation becomes useful to discriminate between those.",
                "When a map is labyrinth-like, there are fewer possible explanations to an unexpected event.",
                "Importance of the Global Protocol The second set of experiments seeks to evaluate the importance of the design of the global protocol.",
                "We tested our protocol against a local broadcast (LB) protocol.",
                "Local broadcast means that all the neighbours agents perceived by an agent will be involved in a communication with that agent in a given round -we alleviate the constraint of a single communication by agent.",
                "This gives us a rough upper bound upon the possible ratio gain in the system (for a given local protocol).",
                "Again, we evaluated the ratio gain induced by that LB over our classical HE, for the three different classes of maps.",
                "The results are reported in Fig. 4.",
                "Figure 4: Ratio gain of local broadcast over hypotheses exchange Note to begin with that the ratio gain is 0 when the proportion of agents is 5%, which is easily explained by the fact that it corresponds to situations involving only two agents.",
                "We first observe that all classes of maps witness a ratio gain increasing when the proportion of agents augments: the gain reaches 10 to 20%, depending on the class of maps considered.",
                "If one compares this with the improvement reported in the previous experiment, it appears to be of the same magnitude.",
                "This illustrates that the design of the global protocol cannot be ignored, especially when the proportion of agents is high.",
                "However, we also note that the effectiveness ratio gain curves have very different shapes in both cases: the gain induced by the accuracy of the local protocol increases very quickly with the proportion of agents, while the curve is really smooth for the global one.",
                "Now let us observe more carefully the results reported here: the curve corresponding to a TI of 53% is above that corresponding to 38%.",
                "This is so because the more open a map, the more opportunities to communicate with more than one agent (and hence benefits from broadcast).",
                "However, we also observe that curve for 69% is below that for 53%.",
                "This is explained as follows: in the case of 69%, the potential gain to be made in terms of surviving agents is much lower, because our protocols already give rather efficient outcomes anyway (quickly reaching 90%, see Fig. 3).",
                "A simple rule of thumb could be that when the number of agents is small, special attention should be put on the local 1004 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) protocol, whereas when that number is large, one should carefully design the global one (unless the map is so open that the protocol is already almost optimally efficient).",
                "Efficiency of the Protocols The final experiment reported here is concerned with the analysis of the efficiency of the protocols.",
                "We analysis here the mean size of the totality of the messages that are exchanged by agents (mean size of exchanges, for short) using the following protocols: HE, OE, and two variant protocols.",
                "The first one is an intermediary restricted hypotheses exchange protocol (RHE).",
                "RHE is as follows: it does not involve any challenge nor counter-propose, which means that agents cannot switch their role during the protocol (this differs from RE in that respect).",
                "In short, RHE allows an agent to exhaust its partners criticism, and eventually this partner will come to adopt the agents hypothesis.",
                "Note that this means that the autonomy of the agent is not preserved here (as an agent will essentially accept any hypothesis it cannot undermine), with the hope that the gain in efficiency will be significant enough to compensate a loss in effectiveness.",
                "The second variant protocol is a complete observation exchange protocol (COE).",
                "COE uses the same principles as OE, but includes in addition all critical negative examples (nofire) in the exchange (thus giving all examples used as arguments by the hypotheses exchanges protocol), hence improving effectiveness.",
                "Results for map 69-1 are shown on Fig. 5.",
                "Figure 5: Mean size of exchanges First we can observe the fact that the ordering of the protocols, from the least efficient to the most efficient, is COE, HE, RHE and then OE.",
                "HE being more efficient than COE proves that the argumentation process gains efficiency by selecting when it is needed to provide negative example, which have less impact that positive ones in our specific testbed.",
                "However, by communicating hypotheses before eventually giving observation to support it (HE) instead of directly giving the most crucial observations (OE), the argumentation process doubles the size of data exchanges.",
                "It is the cost for ensuring consistency at the end of the exchange (a property that OE does not support).",
                "Also significant is the fact the the mean size of exchanges is slightly higher when the number of agents is small.",
                "This is explained by the fact that in these cases only a very few agents have relevant informations in their possession, and that they will need to communicate a lot in order to come up with a common view of the situation.",
                "When the number of agents increases, this knowledge is distributed over more agents which need shorter discussions to get to mutual consistency.",
                "As a consequence, the relative gain in efficiency of using RHE appears to be better when the number of agents is small: when it is high, they will hardly argue anyway.",
                "Finally, it is worth noticing that the standard deviation for these experiments is rather high, which means that the conversation do not converge to any stereotypic pattern. 6.",
                "CONCLUSION This paper has investigated the properties of a multiagent system where each (distributed) agent locally perceives its environment, and tries to reach consistency with other agents despite severe communication restrictions.",
                "In particular we have exhibited conditions allowing convergence, and experimentally investigated a typical situation where those conditions cannot hold.",
                "There are many possible extensions to this work, the first being to further investigate the properties of different global protocols belonging to the class we identified, and their influence on the outcome.",
                "There are in particular many heuristics, highly dependent on the context of the study, that could intuitively yield interesting results (in our study, selecting the recipient on the basis of what can be inferred from his observed actions could be such a heuristic).",
                "One obvious candidate for longer term issues concern the relaxation of the assumption of perfect sensing. 7.",
                "REFERENCES [1] G. Bourgne, N. Maudet, and S. Pinson.",
                "When agents communicate hypotheses in critical situations.",
                "In Proceedings of DALT-2006, May 2006. [2] P. Harvey, C. F. Chang, and A. Ghose.",
                "Support-based distributed search: a new approach for multiagent constraint processing.",
                "In Proceedings of AAMAS06, 2006. [3] H. Jung and M. Tambe.",
                "Argumentation as distributed constraint satisfaction: Applications and results.",
                "In Proceedings of AGENTS01, 2001. [4] N. C. Karunatillake and N. R. Jennings.",
                "Is it worth arguing?",
                "In Proceedings of ArgMAS 2004, 2004. [5] S. Onta˜n´on and E. Plaza.",
                "Arguments and counterexamples in case-based joint deliberation.",
                "In Proceedings of ArgMAS-2006, May 2006. [6] D. Poole.",
                "Explanation and prediction: An architecture for default and abductive reasoning.",
                "Computational Intelligence, 5(2):97-110, 1989. [7] I. Rahwan, S. D. Ramchurn, N. R. Jennings, P. McBurney, S. Parsons, and L. Sonenberg.",
                "Argumention-based negotiation.",
                "The Knowledge Engineering Review, 4(18):345-375, 2003. [8] N. Roos, A. ten Tije, and C. Witteveen.",
                "A protocol for multi-agent diagnosis with spatially distributed knowledge.",
                "In Proceedings of AAMAS03, 2003. [9] N. Roos, A. ten Tije, and C. Witteveen.",
                "Reaching diagnostic agreement in multiagent diagnosis.",
                "In Proceedings of AAMAS04, 2004. [10] T. Takahashi, Y. Kaneda, and N. Ito.",
                "Preliminary study - using robocuprescue simulations for disasters prevention.",
                "In Proceedings of SRMED2004, 2004.",
                "The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 1005"
            ],
            "original_annotated_samples": [
                "This means that there will be more potential for propagation, but also that the <br>bilateral exchange</br> restriction will be more crucial. 3 The CPL is the median of the means of the shortest path lengths connecting each node to all other nodes. 4 characterising the isolation degree of a region of an environment in terms of acessibility (number of roads still usable to reach this region)."
            ],
            "translated_annotated_samples": [
                "Esto significa que habrá más potencial de propagación, pero también que la restricción de <br>intercambio bilateral</br> será más crucial. 3 El CPL es la mediana de las medias de las longitudes de los caminos más cortos que conectan cada nodo con todos los demás nodos. 4 caracterizando el grado de aislamiento de una región de un entorno en términos de accesibilidad (número de caminos aún utilizables para llegar a esta región)."
            ],
            "translated_text": "Refinamiento de hipótesis bajo restricciones de comunicación topológica ∗ Gauvain Bourgne, Gael Hette, Nicolas Maudet y Suzanne Pinson LAMSADE, Univ. Investigamos las propiedades de un sistema multiagente donde cada agente (distribuido) percibe localmente su entorno. Tras la percepción de un evento inesperado, cada agente calcula localmente su hipótesis favorita e intenta propagarla a otros agentes, intercambiando hipótesis y argumentos de apoyo (observaciones). Sin embargo, también asumimos que las oportunidades de comunicación están severamente limitadas y cambian dinámicamente. En este artículo, investigamos principalmente la convergencia de dichos sistemas hacia la consistencia global. Primero demostramos que (para una amplia clase de protocolos que definiremos), las restricciones de comunicación inducidas por la topología no impedirán la convergencia del sistema, bajo la condición de que la dinámica del sistema garantice que ningún agente quedará aislado para siempre, y que los agentes tengan tiempo ilimitado para la computación y el intercambio de argumentos. Dado que esta suposición no se puede hacer en la mayoría de las situaciones, establecimos un marco experimental con el objetivo de comparar la eficiencia y efectividad relativa de diferentes protocolos de interacción para el intercambio de hipótesis. Estudiamos una situación crítica que implica a varios agentes que intentan escapar de un edificio en llamas. Los resultados reportados aquí proporcionan algunas ideas sobre el diseño de un protocolo óptimo para el refinamiento de hipótesis en este contexto. Categorías y Descriptores de Asignaturas I.2.11 [Inteligencia Artificial]: Inteligencia Artificial Distribuida-Sistemas Multiagente Términos Generales Teoría, Experimentación 1. INTRODUCCIÓN Consideramos un sistema multiagente donde cada agente (distribuido) percibe localmente su entorno, y asumimos que ocurre un evento inesperado en ese sistema. Si cada agente calcula solo localmente su hipótesis preferida, es natural asumir que los agentes buscarán coordinar y refinar sus hipótesis confrontando sus observaciones con otros agentes. Si, además, las oportunidades de comunicación están severamente limitadas (por ejemplo, los agentes solo pueden comunicarse cuando están lo suficientemente cerca de otro agente) y cambian dinámicamente (por ejemplo, los agentes pueden cambiar sus ubicaciones), se vuelve crucial diseñar cuidadosamente protocolos que permitan a los agentes converger hacia algún estado deseado de consistencia global. En este documento presentamos algunas condiciones suficientes sobre la dinámica del sistema y sobre las estructuras de protocolo/estrategia que permiten garantizar esa propiedad, y estudiamos experimentalmente algunos contextos donde (algunas de) estas suposiciones se relajan. Si bien los problemas de diagnóstico son uno de los clásicos venerables en la tradición de la IA, sus contrapartes multiagentes han atraído atención mucho más recientemente. Roos y sus colegas [8, 9] en particular estudian una situación en la que un número de entidades distribuidas intentan llegar a un diagnóstico global satisfactorio de todo el sistema. Ellos muestran en particular que el número de mensajes necesarios para establecer este diagnóstico global está destinado a ser prohibitivo, a menos que la comunicación se mejore con algún protocolo adecuado. Sin embargo, no imponen restricciones a las opciones de comunicación de los agentes, ni asumen que el sistema es dinámico. Los beneficios de mejorar la comunicación con información de apoyo para hacer que la convergencia a un estado global deseado de un sistema sea más eficiente, a menudo se ha planteado en la literatura. Esta es, por ejemplo, una de las ideas principales que subyacen al enfoque de negociación basado en argumentos [7], donde el estado deseado es un compromiso entre agentes con preferencias conflictivas. Sin embargo, muchos de estos trabajos parten del supuesto de que este enfoque es beneficioso para comenzar y estudian los aspectos técnicos del problema (o en su lugar enfatizan otras ventajas de utilizar la argumentación). Excepciones notables son las obras de [3, 4, 2, 5], que estudiaron en contextos diferentes al nuestro la eficiencia de la argumentación. El resto del documento es el siguiente. La Sección 2 especifica los elementos básicos de nuestro modelo, y la Sección 3 continúa presentando los diferentes protocolos y estrategias utilizados por los agentes para intercambiar hipótesis y observaciones. Ponemos especial atención en enfatizar claramente las condiciones de la dinámica del sistema y los protocolos/estrategias que se explotarán en el resto del documento. La sección 4 detalla uno de los principales resultados del artículo, a saber, el hecho de que bajo las condiciones mencionadas, las restricciones que imponemos en la topología no impedirán la convergencia del sistema hacia la consistencia global, siempre y cuando ningún agente se pierda completamente para siempre en el sistema, y se permita un tiempo ilimitado para la computación y el intercambio de argumentos. Si bien las condiciones en los protocolos y estrategias son bastante suaves, también es claro que estos requisitos del sistema parecen mucho más problemáticos, incluso francamente poco realistas en situaciones críticas donde se abogan precisamente por enfoques distribuidos. Para obtener una imagen más clara de la situación inducida cuando el tiempo es un factor crítico, hemos establecido un marco experimental que presentamos y discutimos en la Sección 5. La situación crítica implica a varios agentes que intentan escapar de un edificio en llamas. Los resultados reportados aquí muestran que la efectividad del intercambio de argumentos depende crucialmente de la naturaleza del edificio, y proporcionan algunas ideas sobre el diseño de un protocolo óptimo para el refinamiento de hipótesis en este contexto. CONCEPTOS BÁSICOS Comenzamos definiendo los elementos básicos de nuestro sistema. Deje que O sea el conjunto (potencialmente infinito) de observaciones posibles. Suponemos que los sensores de nuestros agentes son perfectos, por lo tanto, las observaciones son seguras. Sea H el conjunto de hipótesis, incierto y revisable. Sea Cons(h, O) la relación de consistencia, una relación binaria entre una hipótesis h ∈ H y un conjunto de observaciones O ⊆ O. En la mayoría de los casos, Cons se referirá a la relación de consistencia clásica, sin embargo, podemos sobrecargar su significado y añadir algunas propiedades adicionales a esa relación (en cuyo caso lo mencionaremos). El entorno puede incluir cierta dinámica y cambiar con el transcurso del tiempo. Definimos a continuación secuencias de puntos temporales para tratar con ello: Definición 1 (Secuencia de puntos temporales). Una secuencia de puntos temporales t1, t2, . . . , tn de t es un conjunto ordenado de puntos temporales t1, t2, . . . , tn tal que t1 ≥ t y ∀i ∈ [1, n − 1], ti+1 ≥ ti. Tomamos un sistema poblado por n agentes a1, . . . , an. Cada agente se define como una tupla F, Oi, hi, donde: • F, el conjunto de hechos, conocimiento común a todos los agentes. • Oi ∈ 2O, el conjunto de observaciones realizadas por el agente hasta el momento. Suponemos una memoria perfecta, por lo tanto, este conjunto crece de forma monótona. • hi ∈ H, la hipótesis favorita del agente. Una noción clave que rige la formación de hipótesis es la de consistencia, definida a continuación: Definición 2 (Consistencia). Decimos que: • Un agente es consistente (Cons(ai)) si y solo si Cons(hi, Oi) (es decir, su hipótesis es consistente con su conjunto de observaciones). • Un agente ai es consistente con un agente compañero aj si y solo si Cons(ai) y Cons(hi, Oj) (es decir, este agente es consistente y su hipótesis puede explicar el conjunto de observaciones del otro agente). • Dos agentes ai y aj son mutuamente consistentes (MCons(ai, aj)) si y solo si Cons(ai, aj) y Cons(aj, ai). • Un sistema es consistente si y solo si para todo (i, j) ∈ [1, n]2 se cumple que MCons(ai, aj). Para garantizar su consistencia, cada agente está equipado con una maquinaria de razonamiento abstracto que llamaremos la función de explicación Eh. Esta función (determinística) toma un conjunto de observaciones y devuelve una única hipótesis preferida (2O → H). Suponemos que h = Eh(O) para ser consistente con O por definición de Eh, por lo que usar esta función en su conjunto de observaciones para determinar su hipótesis favorita es una forma segura para que el agente logre consistencia. Sin embargo, cabe destacar que una hipótesis no necesita ser generada por Eh para ser consistente con un conjunto de observaciones. Como ejemplo concreto de tal función, y una de las principales inspiraciones de este trabajo, se puede citar el sistema de razonamiento Theorist [6], siempre y cuando esté acoplado con un filtro que seleccione una teoría preferida entre las inicialmente seleccionadas por Theorist. También hay que tener en cuenta que hi solo puede ser modificado como consecuencia de la aplicación de Eh. Nos referimos a esto como la autonomía del agente: ningún otro agente puede imponer directamente una hipótesis dada a un agente. Como consecuencia, solo una nueva observación (ya sea una nueva percepción o una observación comunicada por otro agente) puede resultar en una modificación de su hipótesis preferida hi (pero no necesariamente, por supuesto). Finalmente definimos una propiedad del sistema que utilizaremos en el resto del artículo: Definición 3 (Percepciones Acotadas). Un sistema implica una percepción limitada para los agentes si y solo si existe un n0 tal que para todo t, la unión de N observaciones realizadas por los agentes es menor o igual a n0. (Es decir, el número de observaciones a realizar por los agentes en el sistema no es infinito.) Ahora necesitamos ver cómo evolucionarán e interactuarán estos agentes en su entorno. En nuestro contexto, los agentes evolucionan en un entorno dinámico, y asumimos clásicamente el siguiente ciclo del sistema: 1. Dinámica del entorno: el entorno evoluciona de acuerdo con las reglas definidas de la dinámica del sistema. 2. Paso de percepción: los agentes obtienen percepciones del entorno. Estas percepciones suelen ser parciales (por ejemplo, el agente solo puede ver una parte de un mapa). 3. Paso de razonamiento: los agentes comparan la percepción con las predicciones, buscan explicaciones para las diferencias (potenciales), refinan su hipótesis, y sacan nuevas conclusiones. 4. Paso de comunicación: los agentes pueden comunicar hipótesis y observaciones con otros agentes a través de un protocolo definido. Cualquier agente solo puede estar involucrado en una comunicación con otro agente en el paso 5. Paso de acción: los agentes realizan un razonamiento práctico utilizando los modelos obtenidos de los pasos anteriores y seleccionan una acción. Ellos pueden modificar el entorno ejecutándolo. La comunicación de los agentes estará aún más restringida por consideraciones topológicas. En un momento dado, un agente solo podrá comunicarse con un número de vecinos. Sus conexiones con estos otros agentes pueden The Sixth Intl. La Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) evoluciona con su situación en el entorno. Normalmente, un agente solo puede comunicarse con agentes que puede percibir, pero se podría imaginar la evolución de restricciones topológicas en la comunicación basadas en una red de comunicaciones entre agentes donde los enlaces no siempre están activos. En nuestro sistema, los agentes podrán comunicarse entre sí. Sin embargo, debido a las restricciones topológicas mencionadas anteriormente, no podrán comunicarse con ningún agente en ningún momento. Con quién puede comunicarse un agente se definirá dinámicamente (por ejemplo, esto puede ser consecuencia de que los agentes estén lo suficientemente cerca para ponerse en contacto). Denotaremos de forma abstracta por C(ai, aj, t) la propiedad de comunicación, es decir, el hecho de que los agentes ai y aj puedan comunicarse en el tiempo t (nota que se asume que esta relación es simétrica, pero por supuesto no transitiva). Ahora estamos en posición de definir dos propiedades esenciales de nuestro sistema. Definición 4 (Camino Temporal). Existe un camino de comunicación temporal en el horizonte tf (denotado Ltf (aI, aJ)) entre ai y aj si y solo si existe una secuencia de puntos temporales t1, t2, ..., tn desde tf y una secuencia de agentes k1, k2, ..., kn tal que (i) C(aI, ak1, t1), (ii) C(akn, aJ, tn+1), (iii) ∀i ∈ [1, n], C(aki, aki+1, ti). Intuitivamente, lo que esta propiedad dice es que es posible encontrar un camino temporal en el futuro que permitiría vincular al agente ai y aj a través de una secuencia de agentes intermedios. Ten en cuenta que los puntos temporales no necesariamente son sucesivos, y que la secuencia de agentes puede involucrar a los mismos agentes varias veces. Definición 5 (Conexidad Temporal). Un sistema es temporalmente conexo si y solo si ∀t ∀(i, j)∈[1, n]2 Lt(ai, aj). En resumen, un sistema temporalmente conexo garantiza que cualquier agente podrá comunicarse con cualquier otro agente, sin importar cuánto tiempo pueda llevar hacerlo, en cualquier momento. Dicho de otra manera, nunca sucede que un agente esté aislado para siempre de otro agente del sistema. A continuación discutiremos en detalle cómo la comunicación tiene lugar concretamente en nuestro sistema. Recuerda que en este documento, solo consideramos el caso de intercambios bilaterales (un agente solo puede hablar con otro agente) y también asumimos que cualquier agente solo puede participar en un intercambio en una ronda dada. 3. PROTOCOLOS Y ESTRATEGIAS En esta sección, discutimos los requisitos de los protocolos de interacción que rigen el intercambio de mensajes entre agentes, y proporcionamos algunos ejemplos de la implementación de dichos protocolos. Para aclarar la presentación, distinguimos dos niveles: el nivel local, que se ocupa de la regulación de los intercambios bilaterales; y el nivel global, que regula principalmente la forma en que los agentes pueden participar realmente en una conversación. En cada nivel, separamos lo que está especificado por el protocolo y lo que se deja a las estrategias de los agentes. Protocolos y estrategias locales Comenzamos inspeccionando los protocolos y estrategias locales que regularán la comunicación entre los agentes del sistema. Al limitarnos a la comunicación bilateral, estos protocolos simplemente implicarán a dos agentes. Dicho protocolo tendrá que cumplir con un requisito básico para ser satisfactorio: consistencia (CONS) - un protocolo local debe garantizar la consistencia mutua de los agentes al finalizar (lo que implica, por supuesto, la finalización). Figura 1: Un Protocolo de Intercambio de Hipótesis [1] Un ejemplo de dicho protocolo es el protocolo descrito en [1] que se muestra en la Fig. 1. Para ilustrar aún más cómo dicho protocolo puede ser utilizado por agentes, proporcionamos algunos detalles sobre una posible estrategia: al recibir una hipótesis h1 (proponer(h1) o contra-proponer(h1)) de a1, el agente a2 se encuentra en el estado 2 y tiene las siguientes respuestas posibles: contraejemplo (si el agente conoce un ejemplo que contradice la hipótesis, o no está explicado por esta hipótesis), desafío (si el agente carece de evidencia para aceptar esta hipótesis), contra-proponer (si el agente está de acuerdo con la hipótesis pero prefiere otra), o aceptar (si es tan buena como su hipótesis favorita). Esta estrategia garantiza, entre otras propiedades, la eventual consistencia lógica mutua de los agentes involucrados [1]. Protocolo global El protocolo global regula la forma en que se iniciarán los intercambios bilaterales entre agentes. En cada turno, los agentes enviarán simultáneamente una solicitud ponderada para comunicarse con otros agentes. Este peso es un valor que mide la disposición de los agentes para conversar con el agente objetivo (en la práctica, esto puede basarse en diferentes heurísticas, pero haremos algunas suposiciones sobre las estrategias de los agentes, ver más abajo). Enviar una solicitud de este tipo es una especie de compromiso condicional para el agente. Un agente que envía una solicitud ponderada se compromete a entablar una conversación con el objetivo si no recibe y acepta otra solicitud por sí mismo. Una vez que se hayan recibido todas las solicitudes, cada agente responde con un aceptar o un rechazar. Al responder con un aceptar, un agente se compromete plenamente a participar en la conversación con el remitente. Por lo tanto, solo puede enviar una aceptación en una ronda dada, ya que un agente solo puede participar en una conversación por paso de tiempo. Cuando se hayan recibido todas las respuestas, cada agente que reciba una aceptación puede iniciar una conversación utilizando el protocolo local o enviar una cancelación si ha aceptado otra solicitud. Al final de todos los intercambios bilaterales, los agentes involucrados en la conversación son descartados del protocolo. Entonces cada uno de los agentes restantes reenvía una solicitud y el proceso se repite hasta que no se envíen más solicitudes. Estrategia global Ahora definimos cuatro requisitos para las estrategias utilizadas por los agentes, dependiendo de su rol en el protocolo: dos se refieren al rol del solicitante (cómo decidir quién es el 1000 The Sixth Intl. La Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) ¿con qué agente desea comunicarse? Los otros dos con el rol de respondedor (¿cómo decidir qué solicitud de comunicación aceptar o no?). • Disposición para resolver inconsistencias (SOLVE): los agentes desean comunicarse con cualquier otro agente a menos que sepan que son mutuamente consistentes. • Enfoque en resolver inconsistencias (FOCUS): los agentes no solicitan comunicarse con un agente con el que saben que son mutuamente consistentes. • Disposición para comunicarse (COMM): los agentes no pueden rechazar una solicitud de comunicación ponderada, a menos que acaben de recibir o enviar una solicitud con un peso mayor. • Compromiso con la solicitud de comunicación (REQU): los agentes no pueden aceptar una solicitud de comunicación ponderada si ellos mismos han enviado una solicitud de comunicación con un peso mayor. Por lo tanto, no cancelarán su solicitud a menos que hayan recibido una solicitud comunicacional con mayor peso. Ahora la estructura del protocolo, junto con las propiedades COMM+REQU, garantizan que una solicitud solo puede ser rechazada si su agente objetivo se involucra en comunicación con otro agente. Supongamos de hecho que el agente ai quiere comunicarse con aj enviando una solicitud con peso w. COMM garantiza que un agente que reciba una solicitud ponderada aceptará esta comunicación, aceptará una comunicación con un peso mayor o esperará la respuesta a una solicitud con un peso mayor. Esto asegura que la solicitud con peso máximo será aceptada y no cancelada (ya que REQU asegura que un agente que envía una solicitud solo puede cancelarla si acepta otra solicitud con un peso mayor). Por lo tanto, al menos dos agentes participarán en una conversación por ronda del protocolo global. Como el protocolo asegura que ai puede reenviar su solicitud mientras aj no está ocupado en una conversación, llegará un momento en el que aj deberá participar en una conversación, ya sea con ai u otro agente. Estos requisitos se refieren al envío y aceptación de solicitudes, pero los agentes también necesitan alguna estrategia de atribución de peso. Describimos a continuación una estrategia altruista, utilizada en nuestros experimentos. Siendo cooperativo, un agente puede querer conocer más los deseos de comunicación de otros agentes para mejorar la asignación general de intercambios a los agentes. Se añade entonces un paso de solicitud de contexto al protocolo global. Antes de enviar su solicitud ponderada elegida, los agentes asignan un peso a todos los agentes con los que están dispuestos a comunicarse, de acuerdo con algunos factores internos. En el caso más simple, este peso será 1 para todos los agentes con los que el agente no esté seguro de ser mutuamente consistentes (garantizando SOLVE), sin considerar a otros agentes para la comunicación (garantizando FOCUS). El agente luego envía una solicitud de contexto a todos los agentes con los que se considera la comunicación. Esta solicitud también proporciona información sobre el remitente (lista de comunicaciones consideradas junto con su peso). Después de recibir todas las solicitudes de contexto, los agentes responderán con un rechazo si ya están ocupados en una conversación (en cuyo caso, el agente solicitante no considerará comunicarse con ellos en este turno), o con una información que brinde al solicitante información sobre las solicitudes que ha enviado y recibido. Cuando se hayan recibido todas las respuestas, cada agente puede calcular el peso de todas las solicitudes que le conciernen. Lo hace restando del peso de su solicitud el peso de todas las solicitudes relacionadas con él o su objetivo (es decir, el peso final de la solicitud de ai a aj es Wi,j = wi,j + wj,i - ( Σ k∈R(i)-{j} wi,k + Σ k∈S(i)-{j} wk,i + Σ k∈R(j)-{i} wj,k + Σ k∈S(j)-{i} wk,j) donde wi,j es el peso de la solicitud de ai a aj, R(i) es el conjunto de índices de agentes que han recibido una solicitud de ai y S(i) es el conjunto de índices de agentes que han enviado una solicitud a ai). Luego envía finalmente una solicitud ponderada a los agentes que maximizan este peso (o esperan una solicitud) según lo descrito en el protocolo global. 4. (CONDICIONAL) CONVERGENCIA HACIA LA COHERENCIA GLOBAL En esta sección mostraremos que los requisitos relacionados con los protocolos y estrategias recién discutidos serán suficientes para garantizar que el sistema eventualmente convergerá hacia la coherencia global, bajo ciertas condiciones. Primero demostramos que, si dos agentes no son mutuamente consistentes en algún momento, entonces necesariamente habrá un momento en el futuro en el que un agente aprenderá una nueva observación, ya sea porque es nueva para el sistema, o al aprenderla de otro agente. Lema 1. Sea S un sistema poblado por n agentes a1, a2, ..., an, temporalmente conectados e involucrando percepciones limitadas para estos agentes. Sea n1 la suma de las cardinalidades de la intersección de los conjuntos de observaciones emparejados. (n1 = P (i,j)∈[1,n]2 |Oi ∩ Oj|) Sea n2 la cardinalidad de la unión de todos los conjuntos de observaciones de los agentes. (n2 = | ∪N i=1 Oi|). Si ¬MCons(ai, aj) en el tiempo t0, necesariamente existe un tiempo t > t0 tal que ya sea n1 o n2 aumentarán. Prueba. Supongamos que exista un tiempo t0 y unos índices (i, j) tal que ¬MCons(ai, aj). Utilizaremos mt0 = P (k,l)∈[1,n]2 εComm(ak, al, t0) donde εComm(ak, al, t0) = 1 si ak y al han comunicado al menos una vez desde t0, y 0 en caso contrario. La conexidad temporal garantiza que existen t1, ..., tm+1 y k1, ..., km tal que. C(ai, ak1 , t1), C(akm , aj, tm+1), y ∀p ∈ [1, m], C(akp , akp+1 , tp). Claramente, si MCons(ai, ak1), MCons(akm, aj) y ∀p, MCons(akp, akp+1), tenemos MCons(ai, aj) lo cual contradice nuestra hipótesis (siendo MCons transitivo, MCons(ai, ak1)∧MCons(ak1, ak2) implica que MCons(ai, ak2) y así sucesivamente hasta MCons(ai, akm)∧MCons(akm, aj) lo cual implica MCons(ai, aj)). Al menos dos agentes son necesariamente inconsistentes (¬MCons(ai, ak1), o ¬MCons(akm, aj), o ∃p0 t.q. ¬MCons(akp0, akp0+1)). Que ak y al sean estos dos vecinos en un momento t > t0 1. La propiedad SOLVE asegura que ya sea ak o al enviará una solicitud de comunicación al otro agente en el tiempo t. Como se mostró anteriormente, esto a su vez garantiza que al menos uno de estos agentes estará involucrado en una comunicación. Entonces hay dos posibilidades: (caso i) ak y al se comunican en el tiempo t. En este caso, sabemos que ¬MCons(ak, al). Esto y la propiedad CONS aseguran que al menos uno de los agentes debe cambiar su 1. Estrictamente hablando, la transitividad de MCons solo asegura que ak y al son inconsistentes en un tiempo t ≥ t0 que puede ser diferente del tiempo t en el que pueden comunicarse. Pero si se vuelven consistentes entre t y t (o inconsistentes entre t y t), significa que al menos uno de ellos ha cambiado su hipótesis entre t y t, es decir, después de t0. Podemos entonces aplicar el razonamiento del caso iib. El Sexto Internacional. La Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 1001 hipótesis, lo cual a su vez, dado que los agentes son autónomos, implica al menos un intercambio de observación. Pero entonces |Ok ∩Ol| está destinado a aumentar: n1(t) > n1(t0). (caso ii) ak se comunica con ap en el tiempo t. Entonces tenemos de nuevo dos posibilidades: (caso iia) ak y ap no se comunicaron desde t0. Pero luego εComm(ak, ap, t0) tenía valor 0 y toma valor 1. Por lo tanto, mt0 aumenta. (caso iib) ak y ap se comunicaron en algún momento t0 > t0. La propiedad CONS del protocolo asegura que MCons(ak, ap) en ese momento. Ahora el hecho de que se comuniquen y se ENFOQUEN implica que al menos uno de ellos cambió su hipótesis en el ínterin. El hecho de que los agentes sean autónomos implica a su vez que una nueva observación (percibida o recibida de otro agente) necesariamente provocó este cambio. El último caso garantizaría la existencia de un tiempo t > t0 y un agente aq tal que |Op ∩ Oq| o |Ok ∩ Oq| aumenten en 1 en ese momento (lo que implica que n1(t) > n1(t0)). El caso anterior significa que el agente obtiene una nueva percepción en el tiempo t. Si esa observación era desconocida en el sistema antes, entonces n2(t) > n2(t0). Si algún agente aq ya conocía esta observación antes, entonces tanto Op ∩ Oq como Ok ∩ Oq aumentan en 1 en el tiempo t (lo que implica que n1(t) > n1(t0)). Por lo tanto, ¬MCons(ai, aj) en el tiempo t0 garantiza que, o bien: −∃t > t0 t.q. n1(t ) > n1(t0); o −∃t > t0 t.q. n2(t ) > n2(t0); o −∃t > t0 t.q. mt0 aumenta en 1 en el tiempo t. Al iterar el razonamiento con t (pero manteniendo t0 como la referencia de tiempo para mt0), podemos eliminar el tercer caso (mt0 es un entero y está limitado por n2, lo que significa que después de un máximo de n2 iteraciones, necesariamente estaremos en uno de los otros dos casos). Como resultado, hemos demostrado que si ¬MCons(ai, aj) en el tiempo t0, necesariamente habrá un tiempo t tal que ya sea n1 o n2 aumentarán. Teorema 1 (Consistencia global). Sea S un sistema poblado por n agentes a1, a2, ..., an, temporalmente conectados e involucrando percepciones limitadas para estos agentes. Sea Cons(ai, aj) una propiedad de consistencia transitiva. Entonces, cualquier protocolo y estrategias que cumplan con las propiedades CONS, SOLVE, FOCUS, COMM y REQU garantizan que el sistema convergerá hacia la consistencia global. Prueba. Por el bien de la contradicción, asumamos que ∃I, J ∈ [1, N] tal que ∀t, ∃t0 > t, tal que ¬Cons(aI , aJ , t0). Usando el lema, esto implica que ∃t > t0 tal que n1(t) > n1(t0) o n2(t) > n2(t0). Pero podemos aplicar el mismo razonamiento tomando t = t, lo que nos daría t1 > t > t0 tal que ¬Cons(aI , aJ , t1), lo que nos da t > t1 tal que n1(t) > n1(t1) o n2(t) > n2(t1). Mediante iteraciones sucesivas podemos construir una secuencia t0, t1, ..., tn, que puede dividirse en dos subsecuencias t0, t1, ...tn y t0, t1, ..., tn tal que n1(t0) < n1(t1) < ... < n1(tn) y n2(t0) < n2(t1) < ... < n2(tn). Una de estas subsecuencias tiene que ser infinita. Sin embargo, n1(ti) y n2(ti) son estrictamente crecientes, enteros y acotados, lo que implica que ambos son finitos. Contradicción. Lo que el resultado anterior muestra esencialmente es que, en un sistema donde ningún agente estará aislado del resto de los agentes para siempre, solo se necesitan suposiciones muy leves sobre los protocolos y estrategias utilizados por los agentes para garantizar la convergencia hacia la consistencia del sistema en una cantidad finita de tiempo (aunque podría llevar mucho tiempo). Desafortunadamente, en muchas situaciones críticas, no será posible asumir esta conexión temporal. Dado que enfoques distribuidos como el abogado en este documento suelen presentarse como una buena manera de abordar problemas de confiabilidad o problemas de dependencia de un centro que son de suma importancia en estas aplicaciones críticas, ciertamente resulta interesante explorar más a fondo cómo se comportaría un sistema de este tipo cuando relajamos esta suposición. ESTUDIO EXPERIMENTAL Este experimento implica agentes tratando de escapar de un edificio en llamas. El entorno se describe como una cuadrícula espacial con un conjunto de paredes y (afortunadamente) algunas salidas. El tiempo y el espacio se consideran discretos. El tiempo se divide en rondas. Los agentes se localizan por su posición en la cuadrícula espacial. Estos agentes pueden moverse y comunicarse con otros agentes. En una ronda, un agente puede moverse una celda en cualquiera de las cuatro direcciones cardinales, siempre y cuando no esté bloqueado por una pared. En esta aplicación, los agentes se comunican con cualquier otro agente (pero, recuerda, solo uno) siempre y cuando este agente esté a la vista y aún no hayan intercambiado su hipótesis actual favorita. De repente, se desata un incendio en estas instalaciones. A partir de este momento, el fuego se propaga. En cada ronda, en cada caso donde haya fuego, el fuego se propaga en las cuatro direcciones. Sin embargo, el fuego no puede propagarse a través de una pared. Si el fuego se propaga en un caso donde un agente está posicionado, ese agente se quema y se considera muerto. Por supuesto, ya no puede moverse ni comunicarse. Si un agente llega a una salida, se considera que está a salvo y ya no puede ser quemado. Los agentes conocen el entorno y las reglas que rigen la dinámica de este entorno, es decir, conocen el mapa así como las reglas de propagación del fuego previamente descritas. También perciben este entorno localmente, pero no pueden ver más allá de 3 casos en cualquier dirección. Las paredes también bloquean la línea de visión, impidiendo que los agentes vean detrás de ellas. Dentro de su campo de visión, pueden ver a otros agentes y si los casos que ven están en llamas. Todas estas percepciones están memorizadas. Mostramos ahora cómo se instancia el marco abstracto presentado en el documento. • O = {Fire(x, y, t), NoFire(x, y, t), Agent(ai, x, y, t)} Las observaciones pueden ser positivas (o ∈ P(O) si ∃h ∈ H tal que h |= o) o negativas (o ∈ N(O) si ∃h ∈ H tal que h |= ¬o). • H={FireOrigin(x1, y1, t1)∧...∧FireOrigin(xl, yl, tl)} Las hipótesis son conjunciones de Orígenes de Fuego. • La relación de consistencia Cons(h, O) satisface: - coherencia: ∀o ∈ N(O), h |= ¬o. - completitud: ∀o ∈ P(O), h |= o. - minimalidad: Para todo h ∈ H, si h es coherente y completo para O, entonces h es preferido a h de acuerdo con la relación de preferencia (h ≤p h). Selecciona primero el número mínimo de orígenes, luego el más reciente (estrategia menos preemptiva [6]), y luego utiliza un ranking fijo arbitrario para discriminar ex-aequo. La relación resultante es un orden total, por lo tanto, la minimalidad implica que habrá un único h tal que Cons(O, h) para un O dado. Esto a su vez significa que MCons(ai, aj) si y solo si Cons(ai), Cons(aj) y hi = hj. Esta relación es entonces transitiva y simétrica. 1002 El Sexto Internacional. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) • Eh toma O como argumento y devuelve min≤p de la hipótesis coherente y completa para O 5.1 Evaluación Experimental Clásicamente evaluaremos la efectividad y eficiencia de diferentes protocolos de interacción (ver, por ejemplo, [3, 4]). La efectividad de un protocolo se determinará por la proporción de agentes que sobreviven al incendio respecto al número inicial de agentes involucrados en el experimento. Si este valor es alto, el protocolo ha sido efectivo para propagar la información y/o para que los agentes refinen sus hipótesis y determinen la mejor manera de salir. Eficiencia de un protocolo. Por lo general, el uso de información de apoyo implicará una sobrecarga de comunicación. Aquí asumiremos que la eficiencia de un protocolo dado está caracterizada por el flujo de datos inducido por este protocolo. En este documento solo discutiremos este aspecto con respecto a los protocolos locales. La medida principal que utilizaremos aquí es el tamaño total promedio de los mensajes intercambiados por los agentes por intercambio (teniendo en cuenta tanto el número de mensajes como el tamaño real de los mensajes, ya que podría ser que los mensajes resulten ser muy grandes, conteniendo por ejemplo un gran número de observaciones, lo que podría contrarrestar un bajo número de mensajes). 5.2 Configuraciones Experimentales Las configuraciones experimentales elegidas son las siguientes: • Topología ambiental: El rendimiento de la propagación de la información está altamente condicionado por la topología del entorno. Las habilidades de percepción de los agentes dependen de la apertura del entorno. Con un gran número de paredes, las percepciones de los agentes están limitadas, al igual que el número de posibles comunicaciones entre agentes, mientras que un entorno abierto proporcionará posibilidades óptimas de percepción y propagación de información. Por lo tanto, proponemos un índice topológico (ver abajo) como base común para caracterizar los entornos (mapas) utilizados durante las experimentaciones. El índice topológico (TI) es la proporción entre el número de celdas que pueden ser percibidas por los agentes sumadas desde todas las posiciones posibles, dividido por el número de celdas que serían percibidas desde las mismas posiciones pero sin paredes. (Cuanto más cercano a 1, más abierto es el entorno). También utilizaremos dos medidas adicionales, más clásicas [10]: la longitud del camino característico (CPL) y el coeficiente de agrupamiento (CC). • Número de agentes: la propagación de la información también depende del número inicial de agentes involucrados durante una experimentación. Por ejemplo, cuantos más agentes haya, más potenciales comunicaciones existen. Esto significa que habrá más potencial de propagación, pero también que la restricción de <br>intercambio bilateral</br> será más crucial. 3 El CPL es la mediana de las medias de las longitudes de los caminos más cortos que conectan cada nodo con todos los demás nodos. 4 caracterizando el grado de aislamiento de una región de un entorno en términos de accesibilidad (número de caminos aún utilizables para llegar a esta región). Mapa T.I. (%) C.P.L. C.C. 69-1 69,23 4,5 0,69 69-2 68,88 4,38 0,65 69-3 69,80 4,25 0,67 53-1 53,19 5,6 0,59 53-2 53,53 6,38 0,54 53-3 53,92 6,08 0,61 38-1 38,56 8,19 0,50 38-2 38,56 7,3 0,50 38-3 38,23 8,13 0,50 Tabla 1: Características Topológicas de los Mapas • Posiciones iniciales de los agentes- Las posiciones iniciales de los agentes tienen una influencia significativa en el comportamiento general de una instancia de nuestro sistema: estar cerca de una salida facilitará (en general) la escapatoria. 5.3 Entornos experimentales Elegimos realizar experimentos en tres índices topológicos muy diferentes (69% para entornos abiertos, 53% para entornos mixtos y 38% para entornos tipo laberinto). Figura 2: Dos mapas (izquierda: IT=69%, derecha IT=38%) Diseñamos tres mapas diferentes para cada índice (la Fig. 2 muestra dos de ellos), conteniendo el mismo número máximo de agentes (máximo 36 agentes) con una densidad máxima de un agente por celda, el mismo número de salidas y un origen de incendio similar (por ejemplo, tiempo y posición de inicio). Los tres mapas diferentes de un índice dado están diseñados de la siguiente manera. El primer plano es un modelo de un piso de un edificio existente. El segundo mapa tiene el mismo perímetro, salidas y origen del fuego que el primero, pero la cantidad y ubicación de las paredes son diferentes (las ubicaciones de las paredes son diseñadas por una heurística que crea paredes de forma aleatoria en la cuadrícula espacial de manera que no se creen habitaciones completamente cerradas y que ninguna salida quede bloqueada). El tercer mapa se caracteriza por un recinto geométrico en el que la ubicación de las paredes también está diseñada con la heurística mencionada anteriormente. La Tabla 1 resume las diferentes medidas topológicas que caracterizan estos mapas diferentes. Vale la pena señalar que los valores confirman la relevancia de TI (los mapas con un alto TI tienen un bajo CPL y un alto CC). Sin embargo, el CPL y el CC permiten refinar aún más la diferencia entre los mapas, por ejemplo, entre 53-1 y 53-2). 5.4 Resultados Experimentales Para cada trío de mapas definidos como se mencionó anteriormente, llevamos a cabo los mismos experimentos. En cada experimento, la sociedad difiere en cuanto a su proporción inicial de agentes involucrados, desde el 1% hasta el 100%. Esta proporción inicial representa el porcentaje de agentes involucrados con respecto al número máximo posible de agentes. Para cada mapa y cada proporción inicial, la Sexta Internacional. En la Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) seleccionamos aleatoriamente 100 ubicaciones iniciales de agentes diferentes. Para cada una de esas ubicaciones diferentes ejecutamos el sistema una vez para cada protocolo de interacción diferente. La efectividad de la comunicación y argumentación El primer experimento que hemos establecido tiene como objetivo probar cuán efectivo es el intercambio de hipótesis (IH), y en particular cómo los aspectos topológicos afectarán esta efectividad. Para hacerlo, hemos calculado la proporción de mejora ofrecida por ese protocolo sobre una situación en la que los agentes simplemente no podían comunicarse (sin comunicación). Para obtener más información sobre en qué medida el intercambio de hipótesis fue realmente crucial, también probamos un protocolo mucho menos elaborado que consistía en intercambios de observaciones simples (OE). Más precisamente, este protocolo requiere que cada agente almacene cualquier observación inesperada que perciba, y los agentes simplemente intercambian sus respectivas listas de observaciones cuando discuten. En este caso, el protocolo local es diferente (nota en particular que no garantiza consistencia mutua), pero el protocolo global permanece igual (con la única excepción de que la motivación de los agentes para comunicarse es sincronizar su lista de observaciones, no sus hipótesis). Si este protocolo es como máximo tan efectivo como HE, tiene la ventaja de ser más eficiente (esto es obvio en cuanto al número de mensajes, que se limitará a 2, menos directo en lo que respecta al tamaño de los mensajes, pero la observación general de que el intercambio de observaciones se puede ver como una versión simplificada del desafío es útil para ver esto). Los resultados de estos experimentos se informan en la Figura 3. Figura 3: Ganancia de la proporción de efectividad comparativa de los protocolos cuando la proporción de agentes aumenta. La primera observación que debe hacerse es que la comunicación mejora la efectividad del proceso, y esta proporción aumenta a medida que el número de agentes crece en el sistema. La segunda lección que aprendemos aquí es que la cercanía relativamente hace que la comunicación sea más efectiva que la falta de comunicación. Los mapas que muestran un T.I. del 38% están constantemente por encima de los otros dos, y el 53% sigue siendo ligeramente pero significativamente mejor que el 69%. Sin embargo, estas curvas también sugieren, quizás sorprendentemente, que HE supera a OE precisamente en aquellas situaciones donde la ganancia de la relación es menos importante (la única diferencia notable ocurre en mapas bastante abiertos donde T.I. es del 69%). Esto se puede explicar de la siguiente manera: cuando un mapa está abierto, los agentes tienen muchos posibles candidatos de explicación, y la argumentación se vuelve útil para discriminar entre ellos. Cuando un mapa es laberíntico, hay menos posibles explicaciones para un evento inesperado. Importancia del Protocolo Global El segundo conjunto de experimentos busca evaluar la importancia del diseño del protocolo global. Probamos nuestro protocolo contra un protocolo de difusión local (LB). La difusión local significa que todos los agentes vecinos percibidos por un agente estarán involucrados en una comunicación con ese agente en una ronda dada, aliviando la restricción de una sola comunicación por agente. Esto nos proporciona un límite superior aproximado sobre la posible ganancia de ratio en el sistema (para un protocolo local dado). Nuevamente, evaluamos la ganancia de la relación inducida por ese LB sobre nuestro HE clásico, para las tres clases diferentes de mapas. Los resultados se informan en la Figura 4. Figura 4: Ganancia de la proporción de transmisión local sobre el intercambio de hipótesis. Tenga en cuenta que la ganancia de la proporción es 0 cuando la proporción de agentes es del 5%, lo cual se explica fácilmente por el hecho de que corresponde a situaciones que involucran solo a dos agentes. Primero observamos que todas las clases de mapas muestran un aumento en la ganancia de la proporción a medida que aumenta el número de agentes: la ganancia alcanza entre el 10 y el 20%, dependiendo de la clase de mapas considerada. Si se compara esto con la mejora reportada en el experimento anterior, parece ser de la misma magnitud. Esto ilustra que el diseño del protocolo global no puede ser ignorado, especialmente cuando la proporción de agentes es alta. Sin embargo, también observamos que las curvas de ganancia de la proporción de efectividad tienen formas muy diferentes en ambos casos: la ganancia inducida por la precisión del protocolo local aumenta muy rápidamente con la proporción de agentes, mientras que la curva es muy suave para el global. Ahora observemos con más cuidado los resultados reportados aquí: la curva correspondiente a una TI del 53% está por encima de la correspondiente al 38%. Esto se debe a que cuanto más abierta sea un mapa, más oportunidades hay de comunicarse con más de un agente (y por lo tanto beneficiarse de la difusión). Sin embargo, también observamos que la curva para el 69% está por debajo de la del 53%. Esto se explica de la siguiente manera: en el caso del 69%, la ganancia potencial en términos de agentes sobrevivientes es mucho menor, porque nuestros protocolos ya ofrecen resultados bastante eficientes de todos modos (alcanzando rápidamente el 90%, ver Fig. 3). Una regla general podría ser que cuando el número de agentes es pequeño, se debe prestar especial atención al local 1004 de la Sexta Internacional. En el caso de que el número de agentes sea pequeño, uno puede utilizar el protocolo de la Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07), mientras que cuando ese número es grande, se debe diseñar cuidadosamente uno global (a menos que el mapa sea tan abierto que el protocolo ya sea casi óptimamente eficiente). La eficiencia de los protocolos. El experimento final reportado aquí se centra en el análisis de la eficiencia de los protocolos. Aquí analizamos el tamaño medio de la totalidad de los mensajes que son intercambiados por agentes (tamaño medio de intercambios, en resumen) utilizando los siguientes protocolos: HE, OE y dos protocolos variantes. El primero es un protocolo de intercambio de hipótesis restringidas (RHE) intermediario. RHE es el siguiente: no implica ningún desafío ni contraoferta, lo que significa que los agentes no pueden cambiar su rol durante el protocolo (esto difiere de RE en ese aspecto). En resumen, RHE permite a un agente agotar las críticas de sus socios, y eventualmente este socio adoptará la hipótesis del agente. Ten en cuenta que esto significa que la autonomía del agente no se conserva aquí (ya que un agente esencialmente aceptará cualquier hipótesis que no pueda socavar), con la esperanza de que la ganancia en eficiencia sea lo suficientemente significativa como para compensar una pérdida en efectividad. El segundo protocolo de variante es un protocolo completo de intercambio de observaciones (COE). COE utiliza los mismos principios que OE, pero incluye además todos los ejemplos críticos negativos (nofire) en el intercambio (dando así todos los ejemplos utilizados como argumentos por el protocolo de intercambio de hipótesis), mejorando así la efectividad. Los resultados para el mapa 69-1 se muestran en la Figura 5. Figura 5: Tamaño medio de los intercambios. Primero podemos observar el hecho de que el orden de los protocolos, desde el menos eficiente hasta el más eficiente, es COE, HE, RHE y luego OE. ÉL siendo más eficiente que COE demuestra que el proceso de argumentación gana eficiencia al seleccionar cuándo es necesario proporcionar ejemplos negativos, los cuales tienen menos impacto que los positivos en nuestro entorno de prueba específico. Sin embargo, al comunicar hipótesis antes de proporcionar observaciones para respaldarla (HE) en lugar de dar directamente las observaciones más cruciales (OE), el proceso de argumentación duplica el tamaño de los intercambios de datos. Es el costo de garantizar la consistencia al final del intercambio (una propiedad que OE no admite). También es significativo el hecho de que el tamaño promedio de los intercambios es ligeramente mayor cuando el número de agentes es pequeño. Esto se explica por el hecho de que en estos casos solo unos pocos agentes tienen información relevante en su posesión, y que necesitarán comunicarse mucho para llegar a un punto de vista común de la situación. Cuando el número de agentes aumenta, este conocimiento se distribuye entre más agentes que necesitan discusiones más cortas para llegar a una consistencia mutua. Como consecuencia, la ganancia relativa en eficiencia de usar RHE parece ser mejor cuando el número de agentes es pequeño: cuando es alto, difícilmente discutirán de todos modos. Finalmente, vale la pena notar que la desviación estándar para estos experimentos es bastante alta, lo que significa que la conversación no converge hacia ningún patrón estereotípico. 6. CONCLUSIÓN Este documento ha investigado las propiedades de un sistema multiagente donde cada agente (distribuido) percibe localmente su entorno e intenta alcanzar consistencia con otros agentes a pesar de severas restricciones de comunicación. En particular, hemos expuesto condiciones que permiten la convergencia e investigado experimentalmente una situación típica donde esas condiciones no pueden cumplirse. Hay muchas posibles extensiones a este trabajo, la primera siendo investigar más a fondo las propiedades de diferentes protocolos globales pertenecientes a la clase que identificamos, y su influencia en el resultado. Existen en particular muchas heurísticas, altamente dependientes del contexto del estudio, que podrían intuitivamente arrojar resultados interesantes (en nuestro estudio, seleccionar al destinatario en función de lo que se pueda inferir de sus acciones observadas podría ser una de esas heurísticas). Un candidato obvio para problemas a largo plazo se refiere a la relajación de la suposición de un sensor perfecto. 7. REFERENCIAS [1] G. Bourgne, N. Maudet y S. Pinson. Cuando los agentes comunican hipótesis en situaciones críticas. En Actas de DALT-2006, mayo de 2006. [2] P. Harvey, C. F. Chang y A. Ghose. Búsqueda distribuida basada en soporte: un nuevo enfoque para el procesamiento de restricciones multiagente. En Actas de AAMAS06, 2006. [3] H. Jung y M. Tambe. Argumentación como satisfacción de restricciones distribuida: Aplicaciones y resultados. En Actas de AGENTS01, 2001. [4] N. C. Karunatillake y N. R. Jennings. ¿Vale la pena discutir? En Actas de ArgMAS 2004, 2004. [5] S. Onta˜n´on y E. Plaza. Argumentos y contraejemplos en la deliberación conjunta basada en casos. En Actas de ArgMAS-2006, mayo de 2006. [6] D. Poole. Explicación y predicción: Una arquitectura para el razonamiento por defecto y abductivo. Inteligencia Computacional, 5(2):97-110, 1989. [7] I. Rahwan, S. D. Ramchurn, N. R. Jennings, P. McBurney, S. Parsons y L. Sonenberg. Negociación basada en argumentos. La revisión de Ingeniería del Conocimiento, 4(18):345-375, 2003. [8] N. Roos, A. ten Tije y C. Witteveen. Un protocolo para el diagnóstico multiagente con conocimiento distribuido espacialmente. En Actas de AAMAS03, 2003. [9] N. Roos, A. ten Tije y C. Witteveen. Alcanzando acuerdo diagnóstico en el diagnóstico multiagente. En Actas de AAMAS04, 2004. [10] T. Takahashi, Y. Kaneda y N. Ito. Estudio preliminar: utilizando simulaciones de RoboCupRescue para la prevención de desastres. En Actas de SRMED2004, 2004. El Sexto Internacional. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 1005 ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "mutual consistency": {
            "translated_key": "consistencia mutua",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Hypotheses Refinement under Topological Communication Constraints ∗ Gauvain Bourgne, Gael Hette, Nicolas Maudet, and Suzanne Pinson LAMSADE, Univ.",
                "Paris-Dauphine, France {bourgne,hette,maudet,pinson}@lamsade.dauphine.fr ABSTRACT We investigate the properties of a multiagent system where each (distributed) agent locally perceives its environment.",
                "Upon perception of an unexpected event, each agent locally computes its favoured hypothesis and tries to propagate it to other agents, by exchanging hypotheses and supporting arguments (observations).",
                "However, we further assume that communication opportunities are severely constrained and change dynamically.",
                "In this paper, we mostly investigate the convergence of such systems towards global consistency.",
                "We first show that (for a wide class of protocols that we shall define), the communication constraints induced by the topology will not prevent the convergence of the system, at the condition that the system dynamics guarantees that no agent will ever be isolated forever, and that agents have unlimited time for computation and arguments exchange.",
                "As this assumption cannot be made in most situations though, we then set up an experimental framework aiming at comparing the relative efficiency and effectiveness of different interaction protocols for hypotheses exchange.",
                "We study a critical situation involving a number of agents aiming at escaping from a burning building.",
                "The results reported here provide some insights regarding the design of optimal protocol for hypotheses refinement in this context.",
                "Categories and Subject Descriptors I.2.11 [Artificial Intelligence]: Distributed Artificial Intelligence-Multiagent systems General Terms Theory, Experimentation 1.",
                "INTRODUCTION We consider a multiagent system where each (distributed) agent locally perceives its environment, and we assume that some unexpected event occurs in that system.",
                "If each agent computes only locally its favoured hypothesis, it is only natural to assume that agents will seek to coordinate and refine their hypotheses by confronting their observations with other agents.",
                "If, in addition, the communication opportunities are severely constrained (for instance, agents can only communicate when they are close enough to some other agent), and dynamically changing (for instance, agents may change their locations), it becomes crucial to carefully design protocols that will allow agents to converge to some desired state of global consistency.",
                "In this paper we exhibit some sufficient conditions on the system dynamics and on the protocol/strategy structures that allow to guarantee that property, and we experimentally study some contexts where (some of) these assumptions are relaxed.",
                "While problems of diagnosis are among the venerable classics in the AI tradition, their multiagent counterparts have much more recently attracted some attention.",
                "Roos and colleagues [8, 9] in particular study a situation where a number of distributed entities try to come up with a satisfying global diagnosis of the whole system.",
                "They show in particular that the number of messages required to establish this global diagnosis is bound to be prohibitive, unless the communication is enhanced with some suitable protocol.",
                "However, they do not put any restrictions on agents communication options, and do not assume either that the system is dynamic.",
                "The benefits of enhancing communication with supporting information to make convergence to a desired global state of a system more efficient has often been put forward in the literature.",
                "This is for instance one of the main idea underlying the argumentation-based negotiation approach [7], where the desired state is a compromise between agents with conflicting preferences.",
                "Many of these works however make the assumption that this approach is beneficial to start with, and study the technical facets of the problem (or instead emphasize other advantages of using argumentation).",
                "Notable exceptions are the works of [3, 4, 2, 5], which studied in contexts different from ours the efficiency of argumentation.",
                "The rest of the paper is as follows.",
                "Section 2 specifies the basic elements of our model, and Section 3 goes on to presenting the different protocols and strategies used by the agents to exchange hypotheses and observations.",
                "We put special attention at clearly emphasizing the conditions on the system dynamics and protocols/strategies that will be exploited in the rest of the paper.",
                "Section 4 details one of 998 978-81-904262-7-5 (RPS) c 2007 IFAAMAS the main results of the paper, namely the fact that under the aforementioned conditions, the constraints that we put on the topology will not prevent the convergence of the system towards global consistency, at the condition that no agent ever gets completely lost forever in the system, and that unlimited time is allowed for computation and argument exchange.",
                "While the conditions on protocols and strategies are fairly mild, it is also clear that these system requirements look much more problematic, even frankly unrealistic in critical situations where distributed approaches are precisely advocated.",
                "To get a clearer picture of the situation induced when time is a critical factor, we have set up an experimental framework that we introduce and discuss in Section 5.",
                "The critical situation involves a number of agents aiming at escaping from a burning building.",
                "The results reported here show that the effectiveness of argument exchange crucially depends upon the nature of the building, and provide some insights regarding the design of optimal protocol for hypotheses refinement in this context. 2.",
                "BASIC NOTIONS We start by defining the basic elements of our system.",
                "Environment Let O be the (potentially infinite) set of possible observations.",
                "We assume the sensors of our agents to be perfect, hence the observations to be certain.",
                "Let H be the set of hypotheses, uncertain and revisable.",
                "Let Cons(h, O) be the consistency relation, a binary relation between a hypothesis h ∈ H and a set of observations O ⊆ O.",
                "In most cases, Cons will refer to classical consistency relation, however, we may overload its meaning and add some additional properties to that relation (in which case we will mention it).",
                "The environment may include some dynamics, and change over the course of time.",
                "We define below sequences of time points to deal with it: Definition 1 (Sequence of time points).",
                "A sequence of time points t1, t2, . . . , tn from t is an ordered set of time points t1, t2, . . . , tn such that t1 ≥ t and ∀i ∈ [1, n − 1], ti+1 ≥ ti.",
                "Agent We take a system populated by n agents a1, . . . , an.",
                "Each agent is defined as a tuple F, Oi, hi , where: • F, the set of facts, common knowledge to all agents. • Oi ∈ 2O , the set of observations made by the agent so far.",
                "We assume a perfect memory, hence this set grows monotonically. • hi ∈ H, the favourite hypothesis of the agent.",
                "A key notion governing the formation of hypotheses is that of consistency, defined below: Definition 2 (Consistency).",
                "We say that: • An agent is consistent (Cons(ai)) iff Cons(hi, Oi) (that is, its hypothesis is consistent with its observation set). • An agent ai consistent with a partner agent aj iff Cons(ai) and Cons(hi, Oj) (that is, this agent is consistent and its hypothesis can explain the observation set of the other agent). • Two agents ai and aj are mutually consistent (MCons(ai, aj)) iff Cons(ai, aj) and Cons(aj, ai). • A system is consistent iff ∀(i, j)∈[1, n]2 it is the case that MCons(ai, aj).",
                "To ensure its consistency, each agent is equipped with an abstract reasoning machinery that we shall call the explanation function Eh.",
                "This (deterministic) function takes a set of observation and returns a single prefered hypothesis (2O → H).",
                "We assume h = Eh(O) to be consistent with O by definition of Eh, so using this function on its observation set to determine its favourite hypothesis is a sure way for the agent to achieve consistency.",
                "Note however that an hypothesis does not need to be generated by Eh to be consistent with an observation set.",
                "As a concrete example of such a function, and one of the main inspiration of this work, one can cite the Theorist reasoning system [6] -as long as it is coupled with a filter selecting a single prefered theory among the ones initially selected by Theorist.",
                "Note also that hi may only be modified as a consequence of the application Eh.",
                "We refer to this as the autonomy of the agent: no other agent can directly impose a given hypothesis to an agent.",
                "As a consequence, only a new observation (being it a new perception, or an observation communicated by a fellow agent) can result in a modification of its prefered hypothesis hi (but not necessarily of course).",
                "We finally define a property of the system that we shall use in the rest of the paper: Definition 3 (Bounded Perceptions).",
                "A system involves a bounded perception for agents iff ∃n0 s.t. ∀t| ∪N i=1 Oi| ≤ n0. (That is, the number of observations to be made by the agents in the system is not infinite.)",
                "Agent Cycle Now we need to see how these agents will evolve and interact in their environment.",
                "In our context, agents evolve in a dynamic environment, and we classicaly assume the following system cycle: 1.",
                "Environment dynamics: the environment evolves according to the defined rules of the system dynamics. 2.",
                "Perception step : agents get perceptions from the environment.",
                "These perceptions are typically partial (e.g. the agent can only see a portion of a map). 3.",
                "Reasoning step: agents compare perception with predictions, seek explanations for (potential) difference(s), refine their hypothesis, draw new conclusions. 4.",
                "Communication step: agents can communicate hypotheses and observations with other agents through a defined protocol.",
                "Any agent can only be involved in one communication with another agent by step. 5.",
                "Action step: agents do some practical reasoning using the models obtained from the previous steps and select an action.",
                "They can then modify the environment by executing it.",
                "The communication of the agents will be further constrained by topological consideration.",
                "At a given time, an agent will only be able to communicate with a number of neighbours.",
                "Its connexions with these others agents may The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 999 evolve with its situation in the environment.",
                "Typically, an agent can only communicate with agents that it can sense, but one could imagine evolving topological constraints on communication based on a network of communications between agents where the links are not always active.",
                "Communication In our system, agents will be able to communicate with each other.",
                "However, due to the aforementionned topological constraints, they will not be able to communicate with any agents at anytime.",
                "Who an agent can communicate with will be defined dynamically (for instance, this can be a consequence of the agents being close enough to get in touch).",
                "We will abstractly denote by C(ai, aj, t) the communication property, in other words, the fact that agents ai and aj can communicate at time t (note that this relation is assumed to be symetric, but of course not transitive).",
                "We are now in a position to define two essential properties of our system.",
                "Definition 4 (Temporal Path).",
                "There exists a temporal communication path at horizon tf (noted Ltf (aI , aJ )) between ai and aj iff there exists a sequence of time points t1, t2, . . . , tn from tf and a sequence of agents k1, k2, . . . , kn s.t. (i) C(aI , ak1 , t1), (ii) C(akn , aJ , tn+1), (iii) ∀i ∈ [1, n], C(aki , aki+1 , ti) Intuitively, what this property says is that it is possible to find a temporal path in the future that would allow to link agent ai and aj via a sequence of intermediary agents.",
                "Note that the time points are not necessarily successive, and that the sequence of agents may involve the same agents several times.",
                "Definition 5 (Temporal Connexity).",
                "A system is temporaly connex iff ∀t ∀(i, j)∈[1, n]2 Lt(ai, aj) In short, a temporaly connex system guarantees that any agent will be able to communicate with any other agents, no matter how long it might take to do so, at any time.",
                "To put it another way, it is never the case that an agent will be isolated for ever from another agent of the system.",
                "We will next discuss the detail of how communication concretely takes place in our system.",
                "Remember that in this paper, we only consider the case of bilateral exchanges (an agent can only speak to a single other agent), and that we also assume that any agent can only engage in a single exchange in a given round. 3.",
                "PROTOCOLS AND STRATEGIES In this section, we discuss the requirements of the interaction protocols that govern the exchange of messages between agents, and provide some example instantiation of such protocols.",
                "To clarify the presentation, we distinguish two levels: the local level, which is concerned with the regulation of bilateral exchanges; and the global level,which essentially regulates the way agents can actually engage into a conversation.",
                "At each level, we separate what is specified by the protocol, and what is left to agents strategies.",
                "Local Protocol and Strategies We start by inspecting local protocols and strategies that will regulate the communication between the agents of the system.",
                "As we limit ourselves to bilateral communication, these protocols will simply involve two agents.",
                "Such protocol will have to meet one basic requirement to be satisfying. • consistency (CONS)- a local protocol has to guarantee the <br>mutual consistency</br> of agents upon termination (which implies termination of course).",
                "Figure 1: A Hypotheses Exchange Protocol [1] One example such protocol is the protocol described in [1] that is pictured in Fig. 1.",
                "To further illustrate how such protocol can be used by agents, we give some details on a possible strategy: upon receiving a hypothesis h1 (propose(h1) or counterpropose(h1)) from a1, agent a2 is in state 2 and has the following possible replies: counterexample (if the agent knows an example contradicting the hypothesis, or not explained by this hypothesis), challenge (if the agents lacks evidence to accept this hypothesis), counterpropose (if the agent agrees with the hypothesis but prefers another one), or accept (if it is indeed as good as its favourite hypothesis).",
                "This strategy guarantees, among other properties, the eventual mutual logical consistency of the involved agents [1].",
                "Global Protocol The global protocol regulates the way bilateral exchanges will be initiated between agents.",
                "At each turn, agents will concurrently send one weighted request to communicate to other agents.",
                "This weight is a value measuring the agents willingness to converse with the targeted agent (in practice, this can be based on different heuristics, but we shall make some assumptions on agents strategies, see below).",
                "Sending such a request is a kind of conditional commitment for the agent.",
                "An agent sending a weighted request commits to engage in conversation with the target if he does not receive and accept himself another request.",
                "Once all request have been received, each agent replies with either an acccept or a reject.",
                "By answering with an accept, an agent makes a full commitment to engage in conversation with the sender.",
                "Therefore, it can only send one accept in a given round, as an agent can only participate in one conversation per time step.",
                "When all response have been received, each agent receiving an accept can either initiate a conversation using the local protocol or send a cancel if it has accepted another request.",
                "At the end of all the bilateral exchanges, the agents engaged in conversation are discarded from the protocol.",
                "Then each of the remaining agents resends a request and the process iterates until no more requests are sent.",
                "Global Strategy We now define four requirements for the strategies used by agents, depending on their role in the protocol: two are concerned with the requestee role (how to decide who the 1000 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) agent wishes to communicate with? ), the other two with the responder role (how to decide which communication request to accept or not?). • Willingness to solve inconsistancies (SOLVE)-agents want to communicate with any other agents unless they know they are mutually consistent. • Focus on solving inconsistencies (FOCUS)-agents do not request communication with an agent with whom they know they are mutually consistent. • Willingness to communicate (COMM)-agents cannot refuse a weighted communication request, unless they have just received or send a request with a greater weight. • Commitment to communication request (REQU)agents cannot accept a weighted communication request if they have themselves sent a communication request with a greater weight.",
                "Therefore, they will not cancel their request unless they have received a communicational request with greater weight.",
                "Now the protocol structure, together with the properties COMM+REQU, ensure that a request can only be rejected if its target agent engages in communication with another agent.",
                "Suppose indeed that agent ai wants to communicate with aj by sending a request with weight w. COMM guarantees that an agent receiving a weighted request will either accept this communication, accept a communication with a greater weight or wait for the answer to a request with a greater weight.",
                "This ensures that the request with maximal weight will be accepted and not cancelled (as REQU ensures that an agent sending a request can only cancel it if he accepts another request with greater weight).",
                "Therefore at least two agents will engage in conversation per round of the global protocol.",
                "As the protocol ensures that ai can resend its request while aj is not engaged in a conversation, there will be a turn in which aj must engage in a conversation, either with ai or another agent.",
                "These requirements concern request sending and acceptation, but agents also need some strategy of weight attribution.",
                "We describe below an altruist strategy, used in our experiments.",
                "Being cooperative, an agent may want to know more of the communication wishes of other agents in order to improve the overall allocation of exchanges to agents.",
                "A context request step is then added to the global protocol.",
                "Before sending their chosen weighted request, agents attribute a weight to all agents they are prepared to communicate with, according to some internal factors.",
                "In the simplest case, this weight will be 1 for all agent with whom the agent is not sure of being mutually consistent (ensuring SOLVE), other agent being not considered for communication (ensuring FOCUS).",
                "The agent then sends a context request to all agents with whom communication is considered.",
                "This request also provides information about the sender (list of considered communications along with their weight).",
                "After reception of all the context requests, agents will either reply with a deny, iff they are already engaged in a conversation (in which case, the requesting agent will not consider communication with them anymore in this turn), or an inform giving the requester information about the requests it has sent and received.",
                "When all replies have been received, each agent can calculate the weight of all requests concerning it.",
                "It does so by substracting from the weight of its request the weight of all requests concerning either it or its target (that is, the final weight of the request from ai to aj is Wi,j = wi,j +wj,i − ( P k∈R(i)−{j} wi,k + P k∈S(i)−{j} wk,i + P k∈R(j)−{i} wj,k + P k∈S(j)−{i} wk,j) where wi,j is the weight of the request of ai to aj, R(i) is the set of indice of agents having received a request from ai and S(i) is the set of indice of agents having send a request to ai).",
                "It then finally sends a weighted request to the agents who maximise this weight (or wait for a request) as described in the global protocol. 4. (CONDITIONAL) CONVERGENCE TO GLOBAL CONSISTENCY In this section we will show that the requirements regarding protocols and strategies just discussed will be sufficient to ensure that the system will eventually converge towards global consistency, under some conditions.",
                "We first show that, if two agents are not mutually consistent at some time, then there will be necessarily a time in the future such that an agent will learn a new observation, being it because it is new for the system, or by learning it from another agent.",
                "Lemma 1.",
                "Let S be a system populated by n agents a1, a2, ..., an, temporaly connex, and involving bounded perceptions for these agents.",
                "Let n1 be the sum of cardinalities of the intersection of pairwise observation sets. (n1 = P (i,j)∈[1,n]2 |Oi ∩ Oj|) Let n2 be the cardinality of the union of all agents observations sets. (n2 = | ∪N i=1 Oi|).",
                "If ¬MCons(ai, aj) at time t0, there is necessarily a time t > t0 s.t. either n1 or n2 will increase.",
                "Proof.",
                "Suppose that there exist a time t0 and indices (i, j) s.t. ¬MCons(ai, aj).",
                "We will use mt0 = P (k,l)∈[1,n]2 εComm(ak, al, t0) where εComm(ak, al, t0) = 1 if ak and al have communicated at least once since t0, and 0 otherwise.",
                "Temporal connexity guarantees that there exist t1, ..., tm+1 and k1, ..., km s.t.",
                "C(ai, ak1 , t1), C(akm , aj, tm+1), and ∀p ∈ [1, m], C(akp , akp+1 , tp).",
                "Clearly, if MCons(ai, ak1 ), MCons(akm , aj) and ∀p, MCons(akp , akp+1 ), we have MCons(ai, aj) which contradicts our hypothesis (MCons being transitive, MCons(ai, ak1 )∧MCons(ak1 , ak2 ) implies that MCons(ai, ak2 ) and so on till MCons(ai, akm )∧ MCons(akm , aj) which implies MCons(ai, aj) ).",
                "At least two agents are then necessarily inconsistent (¬MCons(ai, ak1 ), or ¬MCons(akm , aj), or ∃p0 t.q. ¬MCons(akp0 , akp0+1 )).",
                "Let ak and al be these two neighbours at a time t > t0 1 .",
                "The SOLVE property ensures that either ak or al will send a communication request to the other agent at time t .",
                "As shown before, this in turn ensures that at least one of these agents will be involved in a communication.",
                "Then there are two possibilities: (case i) ak and al communicate at time t .",
                "In this case, we know that ¬MCons(ak, al).",
                "This and the CONS property ensures that at least one of the agents must change its 1 Strictly speaking, the transitivity of MCons only ensure that ak and al are inconsistent at a time t ≥ t0 that can be different from the time t at which they can communicate.",
                "But if they become consistent between t and t (or inconsistent between t and t ), it means that at least one of them have changed its hypothesis between t and t , that is, after t0.",
                "We can then apply the reasoning of case iib.",
                "The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 1001 hypothesis, which in turn, since agents are autonomous, implies at least one exchange of observation.",
                "But then |Ok ∩Ol| is bound to increase: n1(t ) > n1(t0). (case ii) ak communicates with ap at time t .",
                "We then have again two possibilities: (case iia) ak and ap did not communicate since t0.",
                "But then εComm(ak, ap, t0) had value 0 and takes value 1.",
                "Hence mt0 increases. (case iib) ak and ap did communicate at some time t0 > t0.",
                "The CONS property of the protocol ensures that MCons(ak, ap) at that time.",
                "Now the fact that they communicate and FOCUS implies that at least one of them did change its hypothesis in the meantime.",
                "The fact that agents are autonomous implies in turn that a new observation (perceived or received from another agent) necessarily provoked this change.",
                "The latter case would ensure the existence of a time t > t0 and an agent aq s.t. either |Op ∩Oq| or |Ok ∩Oq| increases of 1 at that time (implying n1(t ) > n1(t0)).",
                "The former case means that the agent gets a new perception o at time t .",
                "If that observation was unknown in the system before, then n2(t ) > n2(t0).",
                "If some agent aq already knew this observation before, then either Op ∩ Oq or Ok ∩ Oq increases of 1 at time t (which implies that n1(t ) > n1(t0)).",
                "Hence, ¬MCons(ai, aj) at time t0 guarantees that, either: −∃t > t0 t.q. n1(t ) > n1(t0); or −∃t > t0 t.q. n2(t ) > n2(t0); or −∃t > t0 t.q. mt0 increases of 1 at time t .",
                "By iterating the reasoning with t (but keeping t0 as the time reference for mt0 ), we can eliminate the third case (mt0 is integer and bounded by n2 , which means that after a maximum of n2 iterations, we necessarily will be in one of two other cases.)",
                "As a result, we have proven that if ¬MCons(ai, aj) at time t0, there is necessarily a time t s.t. either n1 or n2 will increase.",
                "Theorem 1 (Global consistency).",
                "Let S be a system populated by n agents a1, a2, ..., an, temporaly connex, and involving bounded perceptions for these agents.",
                "Let Cons(ai, aj) be a transitive consistency property.",
                "Then any protocol and strategies satisfying properties CONS, SOLVE, FOCUS, COMM and REQU guarantees that the system will converge towards global consistency.",
                "Proof.",
                "For the sake of contradiction, let us assume ∃I, J ∈ [1, N] s.t. ∀t, ∃t0 > t, t.q. ¬Cons(aI , aJ , t0).",
                "Using the lemma, this implies that ∃t > t0 s.t. either n1(t ) > n1(t0) or n2(t ) > n2(t0).",
                "But we can apply the same reasoning taking t = t , which would give us t1 > t > t0 s.t. ¬Cons(aI , aJ , t1), which gives us t > t1 s.t. either n1(t ) > n1(t1) or n2(t ) > n2(t1).",
                "By successive iterations we can then construct a sequence t0, t1, ..., tn, which can be divided in two sub-sequences t0, t1, ...tn and t0 , t1 , ..., tn s.t. n1(t0) < n1(t1) < ... < n1(tn) and n2(t0 ) < n2(t1 ) < ... < n2(tn).",
                "One of these sub-sequences has to be infinite.",
                "However, n1(ti) and n2(ti ) are strictly growing, integer, and bounded, which implies that both are finite.",
                "Contradiction.",
                "What the previous result essentially shows is that, in a system where no agent will be isolated from the rest of the agents for ever, only very mild assumptions on the protocols and strategies used by agents suffice to guarantee convergence towards system consistency in a finite amount of time (although it might take very long).",
                "Unfortunately, in many critical situations, it will not be possible to assume this temporal connexity.",
                "As distributed approaches as the one advocated in this paper are precisely often presented as a good way to tackle problems of reliability or problems of dependence to a center that are of utmost importance in these critical applications, it is certainly interesting to further explore how such a system would behave when we relax this assumption. 5.",
                "EXPERIMENTAL STUDY This experiment involves agents trying to escape from a burning building.",
                "The environment is described as a spatial grid with a set of walls and (thankfully) some exits.",
                "Time and space are considered discrete.",
                "Time is divided in rounds.",
                "Agents are localised by their position on the spatial grid.",
                "These agents can move and communicate with other agents.",
                "In a round, an agent can move of one cell in any of the four cardinal directions, provided it is not blocked by a wall.",
                "In this application, agents communicate with any other agent (but, recall, a single one) given that this agent is in view, and that they have not yet exchanged their current favoured hypothesis.",
                "Suddenly, a fire erupts in these premises.",
                "From this moment, the fire propagates.",
                "Each round, for each cases where there is fire, the fire propagates in the four directions.",
                "However, the fire cannot propagate through a wall.",
                "If the fire propagates in a case where an agent is positioned, that agent burns and is considered dead.",
                "It can of course no longer move nor communicate.",
                "If an agent gets to an exit, it is considered saved, and can no longer be burned.",
                "Agents know the environment and the rules governing the dynamics of this environment, that is, they know the map as well as the rules of fire propagation previously described.",
                "They also locally perceive this environment, but cannot see further than 3 cases away, in any direction.",
                "Walls also block the line of view, preventing agents from seeing behind them.",
                "Within their sight, they can see other agents and whether or not the cases they see are on fire.",
                "All these perceptions are memorised.",
                "We now show how this instantiates the abstract framework presented the paper. • O = {Fire(x, y, t), NoFire(x, y, t), Agent(ai, x, y, t)} Observations can then be positive (o ∈ P(O) iff ∃h ∈ H s.t. h |= o) or negative (o ∈ N(O) iff ∃h ∈ H s.t. h |= ¬o). • H={FireOrigin(x1, y1, t1)∧...∧FireOrigin(xl, yl, tl)} Hypotheses are conjunctions of FireOrigins. • Cons(h, O) consistency relation satisfies: - coherence : ∀o ∈ N(O), h |= ¬o. - completeness : ∀o ∈ P(O), h |= o. - minimality : For all h ∈ H, if h is coherent and complete for O, then h is prefered to h according to the preference relation (h ≤p h ).2 2 Selects first the minimal number of origins, then the most recent (least preemptive strategy [6]), then uses some arbitrary fixed ranking to discriminate ex-aequo.",
                "The resulting relation is a total order, hence minimality implies that there will be a single h s.t.Cons(O, h) for a given O.",
                "This in turn means that MCons(ai, aj) iff Cons(ai), Cons(aj), and hi = hj.",
                "This relation is then transitive and symmetric. 1002 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) • Eh takes O as argument and returns min≤p of the coherent and complete hypothesis for O 5.1 Experimental Evaluation We will classically (see e.g. [3, 4]) assess the effectiveness and efficiency of different interaction protocols.",
                "Effectiveness of a protocol The proportion of agents surviving the fire over the initial number of agents involved in the experiment will determine the effectiveness of a given protocol.",
                "If this value is high, the protocol has been effective to propagate the information and/or for the agents to refine their hypotheses and determine the best way to the exit.",
                "Efficiency of a protocol Typically, the use of supporting information will involve a communication overhead.",
                "We will assume here that the efficiency of a given protocol is characterised by the data flow induced by this protocol.",
                "In this paper we will only discuss this aspect wrt. local protocols.",
                "The main measure that we shall then use here is the mean total size of messages that are exchanged by agents per exchange (hence taking into account both the number of messages and the actual size of the messages, because it could be that messages happen to be very big, containing e.g. a large number of observations, which could counter-balance a low number of messages). 5.2 Experimental Settings The chosen experimental settings are the following: • Environmental topology- Performances of information propagation are highly constrained by the environment topology.",
                "The perception skills of the agents depend on the openness of the environment.",
                "With a large number of walls the perceptions of agents are limited, and also the number of possible inter-agent communications, whereas an open environment will provide optimal possibilities of perception and information propagation.",
                "Thus, we propose a topological index (see below) as a common basis to charaterize the environments (maps) used during experimentations.",
                "The topological index (TI) is the ratio of the number of cells that can be perceived by agents summed up from all possible positions, divided by the number of cells that would be perceived from the same positions but without any walls. (The closer to 1, the more open the environment).",
                "We shall also use two additional, more classical [10], measures: the characteristic path length3 (CPL) and the clustering coefficient4 (CC). • Number of agents- The propagation of information also depends on the initial number of agents involved during an experimentation.",
                "For instance, the more agents, the more potential communications there is.",
                "This means that there will be more potential for propagation, but also that the bilateral exchange restriction will be more crucial. 3 The CPL is the median of the means of the shortest path lengths connecting each node to all other nodes. 4 characterising the isolation degree of a region of an environment in terms of acessibility (number of roads still usable to reach this region).",
                "Map T.I. (%) C.P.L.",
                "C.C. 69-1 69,23 4,5 0,69 69-2 68,88 4,38 0,65 69-3 69,80 4,25 0,67 53-1 53,19 5,6 0,59 53-2 53,53 6,38 0,54 53-3 53,92 6,08 0,61 38-1 38,56 8,19 0,50 38-2 38,56 7,3 0,50 38-3 38,23 8,13 0,50 Table 1: Topological Characteristics of the Maps • Initial positions of the agents- Initial positions of the agents have a significant influence on the overall behavior of an instance of our system: being close from an exit will (in general) ease the escape. 5.3 Experimental environments We choose to realize experiments on three very different topological indexes (69% for open environments, 53% for mixed environments, and 38% for labyrinth-like environments).",
                "Figure 2: Two maps (left: TI=69%, right TI=38%) We designed three different maps for each index (Fig. 2 shows two of them), containing the same maximum number of agents (36 agents max.) with a maximum density of one agent per cell, the same number of exits and a similar fire origin (e.g. starting time and position).",
                "The three differents maps of a given index are designed as follows.",
                "The first map is a model of an existing building floor.",
                "The second map has the same enclosure, exits and fire origin as the first one, but the number and location of walls are different (wall locations are designed by an heuristic which randomly creates walls on the spatial grid such that no fully closed rooms are created and that no exit is closed).",
                "The third map is characterised by geometrical enclosure in wich walls location is also designed with the aforementioned heuristic.",
                "Table 1 summarizes the different topological measures characterizing these different maps.",
                "It is worth pointing out that the values confirm the relevance of TI (maps with a high TI have a low CPL and a high CC.",
                "However the CPL and CC allows to further refine the difference between the maps, e.g. between 53-1 and 53-2). 5.4 Experimental Results For each triple of maps defined as above we conduct the same experiments.",
                "In each experiment, the society differs in terms of its initial proportion of involved agents, from 1% to 100%.",
                "This initial proportion represents the percentage of involved agents with regards to the possible maximum number of agents.",
                "For each map and each initial proportion, The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 1003 we select randomly 100 different initial agents locations.",
                "For each of those different locations we execute the system one time for each different interaction protocol.",
                "Effectiveness of Communication and Argumentation The first experiment that we set up aims at testing how effective is hypotheses exchange (HE), and in particular how the topological aspects will affect this effectiveness.",
                "In order to do so, we have computed the ratio of improvement offered by that protocol over a situation where agents could simply not communicate (no comm).",
                "To get further insights as to what extent the hypotheses exchange was really crucial, we also tested a much less elaborated protocol consisting of mere observation exchanges (OE).",
                "More precisely, this protocol requires that each agent stores any unexpected observation that it perceives, and agents simply exchange their respective lists of observations when they discuss.",
                "In this case, the local protocol is different (note in particular that it does not guarantee <br>mutual consistency</br>), but the global protocol remains the same (at the only exception that agents motivation to communicate is to synchronise their list of observations, not their hypothesis).",
                "If this protocol is at best as effective as HE, it has the advantage of being more efficient (this is obvious wrt the number of messages which will be limited to 2, less straightforward as far as the size of messages is concerned, but the rough observation that the exchange of observations can be viewed as a flat version of the challenge is helpful to see this).",
                "The results of these experiments are reported in Fig. 3.",
                "Figure 3: Comparative effectiveness ratio gain of protocols when the proportion of agents augments The first observation that needs to be made is that communication improves the effectiveness of the process, and this ratio increases as the number of agents grows in the system.",
                "The second lesson that we learn here is that closeness relatively makes communication more effective over non communication.",
                "Maps exhibiting a T.I. of 38% are constantly above the two others, and 53% are still slightly but significantly better than 69%.",
                "However, these curves also suggest, perhaps surprisingly, that HE outperforms OE in precisely those situations where the ratio gain is less important (the only noticeable difference occurs for rather open maps where T.I. is 69%).",
                "This may be explained as follows: when a map is open, agents have many potential explanation candidates, and argumentation becomes useful to discriminate between those.",
                "When a map is labyrinth-like, there are fewer possible explanations to an unexpected event.",
                "Importance of the Global Protocol The second set of experiments seeks to evaluate the importance of the design of the global protocol.",
                "We tested our protocol against a local broadcast (LB) protocol.",
                "Local broadcast means that all the neighbours agents perceived by an agent will be involved in a communication with that agent in a given round -we alleviate the constraint of a single communication by agent.",
                "This gives us a rough upper bound upon the possible ratio gain in the system (for a given local protocol).",
                "Again, we evaluated the ratio gain induced by that LB over our classical HE, for the three different classes of maps.",
                "The results are reported in Fig. 4.",
                "Figure 4: Ratio gain of local broadcast over hypotheses exchange Note to begin with that the ratio gain is 0 when the proportion of agents is 5%, which is easily explained by the fact that it corresponds to situations involving only two agents.",
                "We first observe that all classes of maps witness a ratio gain increasing when the proportion of agents augments: the gain reaches 10 to 20%, depending on the class of maps considered.",
                "If one compares this with the improvement reported in the previous experiment, it appears to be of the same magnitude.",
                "This illustrates that the design of the global protocol cannot be ignored, especially when the proportion of agents is high.",
                "However, we also note that the effectiveness ratio gain curves have very different shapes in both cases: the gain induced by the accuracy of the local protocol increases very quickly with the proportion of agents, while the curve is really smooth for the global one.",
                "Now let us observe more carefully the results reported here: the curve corresponding to a TI of 53% is above that corresponding to 38%.",
                "This is so because the more open a map, the more opportunities to communicate with more than one agent (and hence benefits from broadcast).",
                "However, we also observe that curve for 69% is below that for 53%.",
                "This is explained as follows: in the case of 69%, the potential gain to be made in terms of surviving agents is much lower, because our protocols already give rather efficient outcomes anyway (quickly reaching 90%, see Fig. 3).",
                "A simple rule of thumb could be that when the number of agents is small, special attention should be put on the local 1004 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) protocol, whereas when that number is large, one should carefully design the global one (unless the map is so open that the protocol is already almost optimally efficient).",
                "Efficiency of the Protocols The final experiment reported here is concerned with the analysis of the efficiency of the protocols.",
                "We analysis here the mean size of the totality of the messages that are exchanged by agents (mean size of exchanges, for short) using the following protocols: HE, OE, and two variant protocols.",
                "The first one is an intermediary restricted hypotheses exchange protocol (RHE).",
                "RHE is as follows: it does not involve any challenge nor counter-propose, which means that agents cannot switch their role during the protocol (this differs from RE in that respect).",
                "In short, RHE allows an agent to exhaust its partners criticism, and eventually this partner will come to adopt the agents hypothesis.",
                "Note that this means that the autonomy of the agent is not preserved here (as an agent will essentially accept any hypothesis it cannot undermine), with the hope that the gain in efficiency will be significant enough to compensate a loss in effectiveness.",
                "The second variant protocol is a complete observation exchange protocol (COE).",
                "COE uses the same principles as OE, but includes in addition all critical negative examples (nofire) in the exchange (thus giving all examples used as arguments by the hypotheses exchanges protocol), hence improving effectiveness.",
                "Results for map 69-1 are shown on Fig. 5.",
                "Figure 5: Mean size of exchanges First we can observe the fact that the ordering of the protocols, from the least efficient to the most efficient, is COE, HE, RHE and then OE.",
                "HE being more efficient than COE proves that the argumentation process gains efficiency by selecting when it is needed to provide negative example, which have less impact that positive ones in our specific testbed.",
                "However, by communicating hypotheses before eventually giving observation to support it (HE) instead of directly giving the most crucial observations (OE), the argumentation process doubles the size of data exchanges.",
                "It is the cost for ensuring consistency at the end of the exchange (a property that OE does not support).",
                "Also significant is the fact the the mean size of exchanges is slightly higher when the number of agents is small.",
                "This is explained by the fact that in these cases only a very few agents have relevant informations in their possession, and that they will need to communicate a lot in order to come up with a common view of the situation.",
                "When the number of agents increases, this knowledge is distributed over more agents which need shorter discussions to get to <br>mutual consistency</br>.",
                "As a consequence, the relative gain in efficiency of using RHE appears to be better when the number of agents is small: when it is high, they will hardly argue anyway.",
                "Finally, it is worth noticing that the standard deviation for these experiments is rather high, which means that the conversation do not converge to any stereotypic pattern. 6.",
                "CONCLUSION This paper has investigated the properties of a multiagent system where each (distributed) agent locally perceives its environment, and tries to reach consistency with other agents despite severe communication restrictions.",
                "In particular we have exhibited conditions allowing convergence, and experimentally investigated a typical situation where those conditions cannot hold.",
                "There are many possible extensions to this work, the first being to further investigate the properties of different global protocols belonging to the class we identified, and their influence on the outcome.",
                "There are in particular many heuristics, highly dependent on the context of the study, that could intuitively yield interesting results (in our study, selecting the recipient on the basis of what can be inferred from his observed actions could be such a heuristic).",
                "One obvious candidate for longer term issues concern the relaxation of the assumption of perfect sensing. 7.",
                "REFERENCES [1] G. Bourgne, N. Maudet, and S. Pinson.",
                "When agents communicate hypotheses in critical situations.",
                "In Proceedings of DALT-2006, May 2006. [2] P. Harvey, C. F. Chang, and A. Ghose.",
                "Support-based distributed search: a new approach for multiagent constraint processing.",
                "In Proceedings of AAMAS06, 2006. [3] H. Jung and M. Tambe.",
                "Argumentation as distributed constraint satisfaction: Applications and results.",
                "In Proceedings of AGENTS01, 2001. [4] N. C. Karunatillake and N. R. Jennings.",
                "Is it worth arguing?",
                "In Proceedings of ArgMAS 2004, 2004. [5] S. Onta˜n´on and E. Plaza.",
                "Arguments and counterexamples in case-based joint deliberation.",
                "In Proceedings of ArgMAS-2006, May 2006. [6] D. Poole.",
                "Explanation and prediction: An architecture for default and abductive reasoning.",
                "Computational Intelligence, 5(2):97-110, 1989. [7] I. Rahwan, S. D. Ramchurn, N. R. Jennings, P. McBurney, S. Parsons, and L. Sonenberg.",
                "Argumention-based negotiation.",
                "The Knowledge Engineering Review, 4(18):345-375, 2003. [8] N. Roos, A. ten Tije, and C. Witteveen.",
                "A protocol for multi-agent diagnosis with spatially distributed knowledge.",
                "In Proceedings of AAMAS03, 2003. [9] N. Roos, A. ten Tije, and C. Witteveen.",
                "Reaching diagnostic agreement in multiagent diagnosis.",
                "In Proceedings of AAMAS04, 2004. [10] T. Takahashi, Y. Kaneda, and N. Ito.",
                "Preliminary study - using robocuprescue simulations for disasters prevention.",
                "In Proceedings of SRMED2004, 2004.",
                "The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 1005"
            ],
            "original_annotated_samples": [
                "Such protocol will have to meet one basic requirement to be satisfying. • consistency (CONS)- a local protocol has to guarantee the <br>mutual consistency</br> of agents upon termination (which implies termination of course).",
                "In this case, the local protocol is different (note in particular that it does not guarantee <br>mutual consistency</br>), but the global protocol remains the same (at the only exception that agents motivation to communicate is to synchronise their list of observations, not their hypothesis).",
                "When the number of agents increases, this knowledge is distributed over more agents which need shorter discussions to get to <br>mutual consistency</br>."
            ],
            "translated_annotated_samples": [
                "Dicho protocolo tendrá que cumplir con un requisito básico para ser satisfactorio: consistencia (CONS) - un protocolo local debe garantizar la <br>consistencia mutua</br> de los agentes al finalizar (lo que implica, por supuesto, la finalización).",
                "En este caso, el protocolo local es diferente (nota en particular que no garantiza <br>consistencia mutua</br>), pero el protocolo global permanece igual (con la única excepción de que la motivación de los agentes para comunicarse es sincronizar su lista de observaciones, no sus hipótesis).",
                "Cuando el número de agentes aumenta, este conocimiento se distribuye entre más agentes que necesitan discusiones más cortas para llegar a una <br>consistencia mutua</br>."
            ],
            "translated_text": "Refinamiento de hipótesis bajo restricciones de comunicación topológica ∗ Gauvain Bourgne, Gael Hette, Nicolas Maudet y Suzanne Pinson LAMSADE, Univ. Investigamos las propiedades de un sistema multiagente donde cada agente (distribuido) percibe localmente su entorno. Tras la percepción de un evento inesperado, cada agente calcula localmente su hipótesis favorita e intenta propagarla a otros agentes, intercambiando hipótesis y argumentos de apoyo (observaciones). Sin embargo, también asumimos que las oportunidades de comunicación están severamente limitadas y cambian dinámicamente. En este artículo, investigamos principalmente la convergencia de dichos sistemas hacia la consistencia global. Primero demostramos que (para una amplia clase de protocolos que definiremos), las restricciones de comunicación inducidas por la topología no impedirán la convergencia del sistema, bajo la condición de que la dinámica del sistema garantice que ningún agente quedará aislado para siempre, y que los agentes tengan tiempo ilimitado para la computación y el intercambio de argumentos. Dado que esta suposición no se puede hacer en la mayoría de las situaciones, establecimos un marco experimental con el objetivo de comparar la eficiencia y efectividad relativa de diferentes protocolos de interacción para el intercambio de hipótesis. Estudiamos una situación crítica que implica a varios agentes que intentan escapar de un edificio en llamas. Los resultados reportados aquí proporcionan algunas ideas sobre el diseño de un protocolo óptimo para el refinamiento de hipótesis en este contexto. Categorías y Descriptores de Asignaturas I.2.11 [Inteligencia Artificial]: Inteligencia Artificial Distribuida-Sistemas Multiagente Términos Generales Teoría, Experimentación 1. INTRODUCCIÓN Consideramos un sistema multiagente donde cada agente (distribuido) percibe localmente su entorno, y asumimos que ocurre un evento inesperado en ese sistema. Si cada agente calcula solo localmente su hipótesis preferida, es natural asumir que los agentes buscarán coordinar y refinar sus hipótesis confrontando sus observaciones con otros agentes. Si, además, las oportunidades de comunicación están severamente limitadas (por ejemplo, los agentes solo pueden comunicarse cuando están lo suficientemente cerca de otro agente) y cambian dinámicamente (por ejemplo, los agentes pueden cambiar sus ubicaciones), se vuelve crucial diseñar cuidadosamente protocolos que permitan a los agentes converger hacia algún estado deseado de consistencia global. En este documento presentamos algunas condiciones suficientes sobre la dinámica del sistema y sobre las estructuras de protocolo/estrategia que permiten garantizar esa propiedad, y estudiamos experimentalmente algunos contextos donde (algunas de) estas suposiciones se relajan. Si bien los problemas de diagnóstico son uno de los clásicos venerables en la tradición de la IA, sus contrapartes multiagentes han atraído atención mucho más recientemente. Roos y sus colegas [8, 9] en particular estudian una situación en la que un número de entidades distribuidas intentan llegar a un diagnóstico global satisfactorio de todo el sistema. Ellos muestran en particular que el número de mensajes necesarios para establecer este diagnóstico global está destinado a ser prohibitivo, a menos que la comunicación se mejore con algún protocolo adecuado. Sin embargo, no imponen restricciones a las opciones de comunicación de los agentes, ni asumen que el sistema es dinámico. Los beneficios de mejorar la comunicación con información de apoyo para hacer que la convergencia a un estado global deseado de un sistema sea más eficiente, a menudo se ha planteado en la literatura. Esta es, por ejemplo, una de las ideas principales que subyacen al enfoque de negociación basado en argumentos [7], donde el estado deseado es un compromiso entre agentes con preferencias conflictivas. Sin embargo, muchos de estos trabajos parten del supuesto de que este enfoque es beneficioso para comenzar y estudian los aspectos técnicos del problema (o en su lugar enfatizan otras ventajas de utilizar la argumentación). Excepciones notables son las obras de [3, 4, 2, 5], que estudiaron en contextos diferentes al nuestro la eficiencia de la argumentación. El resto del documento es el siguiente. La Sección 2 especifica los elementos básicos de nuestro modelo, y la Sección 3 continúa presentando los diferentes protocolos y estrategias utilizados por los agentes para intercambiar hipótesis y observaciones. Ponemos especial atención en enfatizar claramente las condiciones de la dinámica del sistema y los protocolos/estrategias que se explotarán en el resto del documento. La sección 4 detalla uno de los principales resultados del artículo, a saber, el hecho de que bajo las condiciones mencionadas, las restricciones que imponemos en la topología no impedirán la convergencia del sistema hacia la consistencia global, siempre y cuando ningún agente se pierda completamente para siempre en el sistema, y se permita un tiempo ilimitado para la computación y el intercambio de argumentos. Si bien las condiciones en los protocolos y estrategias son bastante suaves, también es claro que estos requisitos del sistema parecen mucho más problemáticos, incluso francamente poco realistas en situaciones críticas donde se abogan precisamente por enfoques distribuidos. Para obtener una imagen más clara de la situación inducida cuando el tiempo es un factor crítico, hemos establecido un marco experimental que presentamos y discutimos en la Sección 5. La situación crítica implica a varios agentes que intentan escapar de un edificio en llamas. Los resultados reportados aquí muestran que la efectividad del intercambio de argumentos depende crucialmente de la naturaleza del edificio, y proporcionan algunas ideas sobre el diseño de un protocolo óptimo para el refinamiento de hipótesis en este contexto. CONCEPTOS BÁSICOS Comenzamos definiendo los elementos básicos de nuestro sistema. Deje que O sea el conjunto (potencialmente infinito) de observaciones posibles. Suponemos que los sensores de nuestros agentes son perfectos, por lo tanto, las observaciones son seguras. Sea H el conjunto de hipótesis, incierto y revisable. Sea Cons(h, O) la relación de consistencia, una relación binaria entre una hipótesis h ∈ H y un conjunto de observaciones O ⊆ O. En la mayoría de los casos, Cons se referirá a la relación de consistencia clásica, sin embargo, podemos sobrecargar su significado y añadir algunas propiedades adicionales a esa relación (en cuyo caso lo mencionaremos). El entorno puede incluir cierta dinámica y cambiar con el transcurso del tiempo. Definimos a continuación secuencias de puntos temporales para tratar con ello: Definición 1 (Secuencia de puntos temporales). Una secuencia de puntos temporales t1, t2, . . . , tn de t es un conjunto ordenado de puntos temporales t1, t2, . . . , tn tal que t1 ≥ t y ∀i ∈ [1, n − 1], ti+1 ≥ ti. Tomamos un sistema poblado por n agentes a1, . . . , an. Cada agente se define como una tupla F, Oi, hi, donde: • F, el conjunto de hechos, conocimiento común a todos los agentes. • Oi ∈ 2O, el conjunto de observaciones realizadas por el agente hasta el momento. Suponemos una memoria perfecta, por lo tanto, este conjunto crece de forma monótona. • hi ∈ H, la hipótesis favorita del agente. Una noción clave que rige la formación de hipótesis es la de consistencia, definida a continuación: Definición 2 (Consistencia). Decimos que: • Un agente es consistente (Cons(ai)) si y solo si Cons(hi, Oi) (es decir, su hipótesis es consistente con su conjunto de observaciones). • Un agente ai es consistente con un agente compañero aj si y solo si Cons(ai) y Cons(hi, Oj) (es decir, este agente es consistente y su hipótesis puede explicar el conjunto de observaciones del otro agente). • Dos agentes ai y aj son mutuamente consistentes (MCons(ai, aj)) si y solo si Cons(ai, aj) y Cons(aj, ai). • Un sistema es consistente si y solo si para todo (i, j) ∈ [1, n]2 se cumple que MCons(ai, aj). Para garantizar su consistencia, cada agente está equipado con una maquinaria de razonamiento abstracto que llamaremos la función de explicación Eh. Esta función (determinística) toma un conjunto de observaciones y devuelve una única hipótesis preferida (2O → H). Suponemos que h = Eh(O) para ser consistente con O por definición de Eh, por lo que usar esta función en su conjunto de observaciones para determinar su hipótesis favorita es una forma segura para que el agente logre consistencia. Sin embargo, cabe destacar que una hipótesis no necesita ser generada por Eh para ser consistente con un conjunto de observaciones. Como ejemplo concreto de tal función, y una de las principales inspiraciones de este trabajo, se puede citar el sistema de razonamiento Theorist [6], siempre y cuando esté acoplado con un filtro que seleccione una teoría preferida entre las inicialmente seleccionadas por Theorist. También hay que tener en cuenta que hi solo puede ser modificado como consecuencia de la aplicación de Eh. Nos referimos a esto como la autonomía del agente: ningún otro agente puede imponer directamente una hipótesis dada a un agente. Como consecuencia, solo una nueva observación (ya sea una nueva percepción o una observación comunicada por otro agente) puede resultar en una modificación de su hipótesis preferida hi (pero no necesariamente, por supuesto). Finalmente definimos una propiedad del sistema que utilizaremos en el resto del artículo: Definición 3 (Percepciones Acotadas). Un sistema implica una percepción limitada para los agentes si y solo si existe un n0 tal que para todo t, la unión de N observaciones realizadas por los agentes es menor o igual a n0. (Es decir, el número de observaciones a realizar por los agentes en el sistema no es infinito.) Ahora necesitamos ver cómo evolucionarán e interactuarán estos agentes en su entorno. En nuestro contexto, los agentes evolucionan en un entorno dinámico, y asumimos clásicamente el siguiente ciclo del sistema: 1. Dinámica del entorno: el entorno evoluciona de acuerdo con las reglas definidas de la dinámica del sistema. 2. Paso de percepción: los agentes obtienen percepciones del entorno. Estas percepciones suelen ser parciales (por ejemplo, el agente solo puede ver una parte de un mapa). 3. Paso de razonamiento: los agentes comparan la percepción con las predicciones, buscan explicaciones para las diferencias (potenciales), refinan su hipótesis, y sacan nuevas conclusiones. 4. Paso de comunicación: los agentes pueden comunicar hipótesis y observaciones con otros agentes a través de un protocolo definido. Cualquier agente solo puede estar involucrado en una comunicación con otro agente en el paso 5. Paso de acción: los agentes realizan un razonamiento práctico utilizando los modelos obtenidos de los pasos anteriores y seleccionan una acción. Ellos pueden modificar el entorno ejecutándolo. La comunicación de los agentes estará aún más restringida por consideraciones topológicas. En un momento dado, un agente solo podrá comunicarse con un número de vecinos. Sus conexiones con estos otros agentes pueden The Sixth Intl. La Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) evoluciona con su situación en el entorno. Normalmente, un agente solo puede comunicarse con agentes que puede percibir, pero se podría imaginar la evolución de restricciones topológicas en la comunicación basadas en una red de comunicaciones entre agentes donde los enlaces no siempre están activos. En nuestro sistema, los agentes podrán comunicarse entre sí. Sin embargo, debido a las restricciones topológicas mencionadas anteriormente, no podrán comunicarse con ningún agente en ningún momento. Con quién puede comunicarse un agente se definirá dinámicamente (por ejemplo, esto puede ser consecuencia de que los agentes estén lo suficientemente cerca para ponerse en contacto). Denotaremos de forma abstracta por C(ai, aj, t) la propiedad de comunicación, es decir, el hecho de que los agentes ai y aj puedan comunicarse en el tiempo t (nota que se asume que esta relación es simétrica, pero por supuesto no transitiva). Ahora estamos en posición de definir dos propiedades esenciales de nuestro sistema. Definición 4 (Camino Temporal). Existe un camino de comunicación temporal en el horizonte tf (denotado Ltf (aI, aJ)) entre ai y aj si y solo si existe una secuencia de puntos temporales t1, t2, ..., tn desde tf y una secuencia de agentes k1, k2, ..., kn tal que (i) C(aI, ak1, t1), (ii) C(akn, aJ, tn+1), (iii) ∀i ∈ [1, n], C(aki, aki+1, ti). Intuitivamente, lo que esta propiedad dice es que es posible encontrar un camino temporal en el futuro que permitiría vincular al agente ai y aj a través de una secuencia de agentes intermedios. Ten en cuenta que los puntos temporales no necesariamente son sucesivos, y que la secuencia de agentes puede involucrar a los mismos agentes varias veces. Definición 5 (Conexidad Temporal). Un sistema es temporalmente conexo si y solo si ∀t ∀(i, j)∈[1, n]2 Lt(ai, aj). En resumen, un sistema temporalmente conexo garantiza que cualquier agente podrá comunicarse con cualquier otro agente, sin importar cuánto tiempo pueda llevar hacerlo, en cualquier momento. Dicho de otra manera, nunca sucede que un agente esté aislado para siempre de otro agente del sistema. A continuación discutiremos en detalle cómo la comunicación tiene lugar concretamente en nuestro sistema. Recuerda que en este documento, solo consideramos el caso de intercambios bilaterales (un agente solo puede hablar con otro agente) y también asumimos que cualquier agente solo puede participar en un intercambio en una ronda dada. 3. PROTOCOLOS Y ESTRATEGIAS En esta sección, discutimos los requisitos de los protocolos de interacción que rigen el intercambio de mensajes entre agentes, y proporcionamos algunos ejemplos de la implementación de dichos protocolos. Para aclarar la presentación, distinguimos dos niveles: el nivel local, que se ocupa de la regulación de los intercambios bilaterales; y el nivel global, que regula principalmente la forma en que los agentes pueden participar realmente en una conversación. En cada nivel, separamos lo que está especificado por el protocolo y lo que se deja a las estrategias de los agentes. Protocolos y estrategias locales Comenzamos inspeccionando los protocolos y estrategias locales que regularán la comunicación entre los agentes del sistema. Al limitarnos a la comunicación bilateral, estos protocolos simplemente implicarán a dos agentes. Dicho protocolo tendrá que cumplir con un requisito básico para ser satisfactorio: consistencia (CONS) - un protocolo local debe garantizar la <br>consistencia mutua</br> de los agentes al finalizar (lo que implica, por supuesto, la finalización). Figura 1: Un Protocolo de Intercambio de Hipótesis [1] Un ejemplo de dicho protocolo es el protocolo descrito en [1] que se muestra en la Fig. 1. Para ilustrar aún más cómo dicho protocolo puede ser utilizado por agentes, proporcionamos algunos detalles sobre una posible estrategia: al recibir una hipótesis h1 (proponer(h1) o contra-proponer(h1)) de a1, el agente a2 se encuentra en el estado 2 y tiene las siguientes respuestas posibles: contraejemplo (si el agente conoce un ejemplo que contradice la hipótesis, o no está explicado por esta hipótesis), desafío (si el agente carece de evidencia para aceptar esta hipótesis), contra-proponer (si el agente está de acuerdo con la hipótesis pero prefiere otra), o aceptar (si es tan buena como su hipótesis favorita). Esta estrategia garantiza, entre otras propiedades, la eventual consistencia lógica mutua de los agentes involucrados [1]. Protocolo global El protocolo global regula la forma en que se iniciarán los intercambios bilaterales entre agentes. En cada turno, los agentes enviarán simultáneamente una solicitud ponderada para comunicarse con otros agentes. Este peso es un valor que mide la disposición de los agentes para conversar con el agente objetivo (en la práctica, esto puede basarse en diferentes heurísticas, pero haremos algunas suposiciones sobre las estrategias de los agentes, ver más abajo). Enviar una solicitud de este tipo es una especie de compromiso condicional para el agente. Un agente que envía una solicitud ponderada se compromete a entablar una conversación con el objetivo si no recibe y acepta otra solicitud por sí mismo. Una vez que se hayan recibido todas las solicitudes, cada agente responde con un aceptar o un rechazar. Al responder con un aceptar, un agente se compromete plenamente a participar en la conversación con el remitente. Por lo tanto, solo puede enviar una aceptación en una ronda dada, ya que un agente solo puede participar en una conversación por paso de tiempo. Cuando se hayan recibido todas las respuestas, cada agente que reciba una aceptación puede iniciar una conversación utilizando el protocolo local o enviar una cancelación si ha aceptado otra solicitud. Al final de todos los intercambios bilaterales, los agentes involucrados en la conversación son descartados del protocolo. Entonces cada uno de los agentes restantes reenvía una solicitud y el proceso se repite hasta que no se envíen más solicitudes. Estrategia global Ahora definimos cuatro requisitos para las estrategias utilizadas por los agentes, dependiendo de su rol en el protocolo: dos se refieren al rol del solicitante (cómo decidir quién es el 1000 The Sixth Intl. La Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) ¿con qué agente desea comunicarse? Los otros dos con el rol de respondedor (¿cómo decidir qué solicitud de comunicación aceptar o no?). • Disposición para resolver inconsistencias (SOLVE): los agentes desean comunicarse con cualquier otro agente a menos que sepan que son mutuamente consistentes. • Enfoque en resolver inconsistencias (FOCUS): los agentes no solicitan comunicarse con un agente con el que saben que son mutuamente consistentes. • Disposición para comunicarse (COMM): los agentes no pueden rechazar una solicitud de comunicación ponderada, a menos que acaben de recibir o enviar una solicitud con un peso mayor. • Compromiso con la solicitud de comunicación (REQU): los agentes no pueden aceptar una solicitud de comunicación ponderada si ellos mismos han enviado una solicitud de comunicación con un peso mayor. Por lo tanto, no cancelarán su solicitud a menos que hayan recibido una solicitud comunicacional con mayor peso. Ahora la estructura del protocolo, junto con las propiedades COMM+REQU, garantizan que una solicitud solo puede ser rechazada si su agente objetivo se involucra en comunicación con otro agente. Supongamos de hecho que el agente ai quiere comunicarse con aj enviando una solicitud con peso w. COMM garantiza que un agente que reciba una solicitud ponderada aceptará esta comunicación, aceptará una comunicación con un peso mayor o esperará la respuesta a una solicitud con un peso mayor. Esto asegura que la solicitud con peso máximo será aceptada y no cancelada (ya que REQU asegura que un agente que envía una solicitud solo puede cancelarla si acepta otra solicitud con un peso mayor). Por lo tanto, al menos dos agentes participarán en una conversación por ronda del protocolo global. Como el protocolo asegura que ai puede reenviar su solicitud mientras aj no está ocupado en una conversación, llegará un momento en el que aj deberá participar en una conversación, ya sea con ai u otro agente. Estos requisitos se refieren al envío y aceptación de solicitudes, pero los agentes también necesitan alguna estrategia de atribución de peso. Describimos a continuación una estrategia altruista, utilizada en nuestros experimentos. Siendo cooperativo, un agente puede querer conocer más los deseos de comunicación de otros agentes para mejorar la asignación general de intercambios a los agentes. Se añade entonces un paso de solicitud de contexto al protocolo global. Antes de enviar su solicitud ponderada elegida, los agentes asignan un peso a todos los agentes con los que están dispuestos a comunicarse, de acuerdo con algunos factores internos. En el caso más simple, este peso será 1 para todos los agentes con los que el agente no esté seguro de ser mutuamente consistentes (garantizando SOLVE), sin considerar a otros agentes para la comunicación (garantizando FOCUS). El agente luego envía una solicitud de contexto a todos los agentes con los que se considera la comunicación. Esta solicitud también proporciona información sobre el remitente (lista de comunicaciones consideradas junto con su peso). Después de recibir todas las solicitudes de contexto, los agentes responderán con un rechazo si ya están ocupados en una conversación (en cuyo caso, el agente solicitante no considerará comunicarse con ellos en este turno), o con una información que brinde al solicitante información sobre las solicitudes que ha enviado y recibido. Cuando se hayan recibido todas las respuestas, cada agente puede calcular el peso de todas las solicitudes que le conciernen. Lo hace restando del peso de su solicitud el peso de todas las solicitudes relacionadas con él o su objetivo (es decir, el peso final de la solicitud de ai a aj es Wi,j = wi,j + wj,i - ( Σ k∈R(i)-{j} wi,k + Σ k∈S(i)-{j} wk,i + Σ k∈R(j)-{i} wj,k + Σ k∈S(j)-{i} wk,j) donde wi,j es el peso de la solicitud de ai a aj, R(i) es el conjunto de índices de agentes que han recibido una solicitud de ai y S(i) es el conjunto de índices de agentes que han enviado una solicitud a ai). Luego envía finalmente una solicitud ponderada a los agentes que maximizan este peso (o esperan una solicitud) según lo descrito en el protocolo global. 4. (CONDICIONAL) CONVERGENCIA HACIA LA COHERENCIA GLOBAL En esta sección mostraremos que los requisitos relacionados con los protocolos y estrategias recién discutidos serán suficientes para garantizar que el sistema eventualmente convergerá hacia la coherencia global, bajo ciertas condiciones. Primero demostramos que, si dos agentes no son mutuamente consistentes en algún momento, entonces necesariamente habrá un momento en el futuro en el que un agente aprenderá una nueva observación, ya sea porque es nueva para el sistema, o al aprenderla de otro agente. Lema 1. Sea S un sistema poblado por n agentes a1, a2, ..., an, temporalmente conectados e involucrando percepciones limitadas para estos agentes. Sea n1 la suma de las cardinalidades de la intersección de los conjuntos de observaciones emparejados. (n1 = P (i,j)∈[1,n]2 |Oi ∩ Oj|) Sea n2 la cardinalidad de la unión de todos los conjuntos de observaciones de los agentes. (n2 = | ∪N i=1 Oi|). Si ¬MCons(ai, aj) en el tiempo t0, necesariamente existe un tiempo t > t0 tal que ya sea n1 o n2 aumentarán. Prueba. Supongamos que exista un tiempo t0 y unos índices (i, j) tal que ¬MCons(ai, aj). Utilizaremos mt0 = P (k,l)∈[1,n]2 εComm(ak, al, t0) donde εComm(ak, al, t0) = 1 si ak y al han comunicado al menos una vez desde t0, y 0 en caso contrario. La conexidad temporal garantiza que existen t1, ..., tm+1 y k1, ..., km tal que. C(ai, ak1 , t1), C(akm , aj, tm+1), y ∀p ∈ [1, m], C(akp , akp+1 , tp). Claramente, si MCons(ai, ak1), MCons(akm, aj) y ∀p, MCons(akp, akp+1), tenemos MCons(ai, aj) lo cual contradice nuestra hipótesis (siendo MCons transitivo, MCons(ai, ak1)∧MCons(ak1, ak2) implica que MCons(ai, ak2) y así sucesivamente hasta MCons(ai, akm)∧MCons(akm, aj) lo cual implica MCons(ai, aj)). Al menos dos agentes son necesariamente inconsistentes (¬MCons(ai, ak1), o ¬MCons(akm, aj), o ∃p0 t.q. ¬MCons(akp0, akp0+1)). Que ak y al sean estos dos vecinos en un momento t > t0 1. La propiedad SOLVE asegura que ya sea ak o al enviará una solicitud de comunicación al otro agente en el tiempo t. Como se mostró anteriormente, esto a su vez garantiza que al menos uno de estos agentes estará involucrado en una comunicación. Entonces hay dos posibilidades: (caso i) ak y al se comunican en el tiempo t. En este caso, sabemos que ¬MCons(ak, al). Esto y la propiedad CONS aseguran que al menos uno de los agentes debe cambiar su 1. Estrictamente hablando, la transitividad de MCons solo asegura que ak y al son inconsistentes en un tiempo t ≥ t0 que puede ser diferente del tiempo t en el que pueden comunicarse. Pero si se vuelven consistentes entre t y t (o inconsistentes entre t y t), significa que al menos uno de ellos ha cambiado su hipótesis entre t y t, es decir, después de t0. Podemos entonces aplicar el razonamiento del caso iib. El Sexto Internacional. La Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 1001 hipótesis, lo cual a su vez, dado que los agentes son autónomos, implica al menos un intercambio de observación. Pero entonces |Ok ∩Ol| está destinado a aumentar: n1(t) > n1(t0). (caso ii) ak se comunica con ap en el tiempo t. Entonces tenemos de nuevo dos posibilidades: (caso iia) ak y ap no se comunicaron desde t0. Pero luego εComm(ak, ap, t0) tenía valor 0 y toma valor 1. Por lo tanto, mt0 aumenta. (caso iib) ak y ap se comunicaron en algún momento t0 > t0. La propiedad CONS del protocolo asegura que MCons(ak, ap) en ese momento. Ahora el hecho de que se comuniquen y se ENFOQUEN implica que al menos uno de ellos cambió su hipótesis en el ínterin. El hecho de que los agentes sean autónomos implica a su vez que una nueva observación (percibida o recibida de otro agente) necesariamente provocó este cambio. El último caso garantizaría la existencia de un tiempo t > t0 y un agente aq tal que |Op ∩ Oq| o |Ok ∩ Oq| aumenten en 1 en ese momento (lo que implica que n1(t) > n1(t0)). El caso anterior significa que el agente obtiene una nueva percepción en el tiempo t. Si esa observación era desconocida en el sistema antes, entonces n2(t) > n2(t0). Si algún agente aq ya conocía esta observación antes, entonces tanto Op ∩ Oq como Ok ∩ Oq aumentan en 1 en el tiempo t (lo que implica que n1(t) > n1(t0)). Por lo tanto, ¬MCons(ai, aj) en el tiempo t0 garantiza que, o bien: −∃t > t0 t.q. n1(t ) > n1(t0); o −∃t > t0 t.q. n2(t ) > n2(t0); o −∃t > t0 t.q. mt0 aumenta en 1 en el tiempo t. Al iterar el razonamiento con t (pero manteniendo t0 como la referencia de tiempo para mt0), podemos eliminar el tercer caso (mt0 es un entero y está limitado por n2, lo que significa que después de un máximo de n2 iteraciones, necesariamente estaremos en uno de los otros dos casos). Como resultado, hemos demostrado que si ¬MCons(ai, aj) en el tiempo t0, necesariamente habrá un tiempo t tal que ya sea n1 o n2 aumentarán. Teorema 1 (Consistencia global). Sea S un sistema poblado por n agentes a1, a2, ..., an, temporalmente conectados e involucrando percepciones limitadas para estos agentes. Sea Cons(ai, aj) una propiedad de consistencia transitiva. Entonces, cualquier protocolo y estrategias que cumplan con las propiedades CONS, SOLVE, FOCUS, COMM y REQU garantizan que el sistema convergerá hacia la consistencia global. Prueba. Por el bien de la contradicción, asumamos que ∃I, J ∈ [1, N] tal que ∀t, ∃t0 > t, tal que ¬Cons(aI , aJ , t0). Usando el lema, esto implica que ∃t > t0 tal que n1(t) > n1(t0) o n2(t) > n2(t0). Pero podemos aplicar el mismo razonamiento tomando t = t, lo que nos daría t1 > t > t0 tal que ¬Cons(aI , aJ , t1), lo que nos da t > t1 tal que n1(t) > n1(t1) o n2(t) > n2(t1). Mediante iteraciones sucesivas podemos construir una secuencia t0, t1, ..., tn, que puede dividirse en dos subsecuencias t0, t1, ...tn y t0, t1, ..., tn tal que n1(t0) < n1(t1) < ... < n1(tn) y n2(t0) < n2(t1) < ... < n2(tn). Una de estas subsecuencias tiene que ser infinita. Sin embargo, n1(ti) y n2(ti) son estrictamente crecientes, enteros y acotados, lo que implica que ambos son finitos. Contradicción. Lo que el resultado anterior muestra esencialmente es que, en un sistema donde ningún agente estará aislado del resto de los agentes para siempre, solo se necesitan suposiciones muy leves sobre los protocolos y estrategias utilizados por los agentes para garantizar la convergencia hacia la consistencia del sistema en una cantidad finita de tiempo (aunque podría llevar mucho tiempo). Desafortunadamente, en muchas situaciones críticas, no será posible asumir esta conexión temporal. Dado que enfoques distribuidos como el abogado en este documento suelen presentarse como una buena manera de abordar problemas de confiabilidad o problemas de dependencia de un centro que son de suma importancia en estas aplicaciones críticas, ciertamente resulta interesante explorar más a fondo cómo se comportaría un sistema de este tipo cuando relajamos esta suposición. ESTUDIO EXPERIMENTAL Este experimento implica agentes tratando de escapar de un edificio en llamas. El entorno se describe como una cuadrícula espacial con un conjunto de paredes y (afortunadamente) algunas salidas. El tiempo y el espacio se consideran discretos. El tiempo se divide en rondas. Los agentes se localizan por su posición en la cuadrícula espacial. Estos agentes pueden moverse y comunicarse con otros agentes. En una ronda, un agente puede moverse una celda en cualquiera de las cuatro direcciones cardinales, siempre y cuando no esté bloqueado por una pared. En esta aplicación, los agentes se comunican con cualquier otro agente (pero, recuerda, solo uno) siempre y cuando este agente esté a la vista y aún no hayan intercambiado su hipótesis actual favorita. De repente, se desata un incendio en estas instalaciones. A partir de este momento, el fuego se propaga. En cada ronda, en cada caso donde haya fuego, el fuego se propaga en las cuatro direcciones. Sin embargo, el fuego no puede propagarse a través de una pared. Si el fuego se propaga en un caso donde un agente está posicionado, ese agente se quema y se considera muerto. Por supuesto, ya no puede moverse ni comunicarse. Si un agente llega a una salida, se considera que está a salvo y ya no puede ser quemado. Los agentes conocen el entorno y las reglas que rigen la dinámica de este entorno, es decir, conocen el mapa así como las reglas de propagación del fuego previamente descritas. También perciben este entorno localmente, pero no pueden ver más allá de 3 casos en cualquier dirección. Las paredes también bloquean la línea de visión, impidiendo que los agentes vean detrás de ellas. Dentro de su campo de visión, pueden ver a otros agentes y si los casos que ven están en llamas. Todas estas percepciones están memorizadas. Mostramos ahora cómo se instancia el marco abstracto presentado en el documento. • O = {Fire(x, y, t), NoFire(x, y, t), Agent(ai, x, y, t)} Las observaciones pueden ser positivas (o ∈ P(O) si ∃h ∈ H tal que h |= o) o negativas (o ∈ N(O) si ∃h ∈ H tal que h |= ¬o). • H={FireOrigin(x1, y1, t1)∧...∧FireOrigin(xl, yl, tl)} Las hipótesis son conjunciones de Orígenes de Fuego. • La relación de consistencia Cons(h, O) satisface: - coherencia: ∀o ∈ N(O), h |= ¬o. - completitud: ∀o ∈ P(O), h |= o. - minimalidad: Para todo h ∈ H, si h es coherente y completo para O, entonces h es preferido a h de acuerdo con la relación de preferencia (h ≤p h). Selecciona primero el número mínimo de orígenes, luego el más reciente (estrategia menos preemptiva [6]), y luego utiliza un ranking fijo arbitrario para discriminar ex-aequo. La relación resultante es un orden total, por lo tanto, la minimalidad implica que habrá un único h tal que Cons(O, h) para un O dado. Esto a su vez significa que MCons(ai, aj) si y solo si Cons(ai), Cons(aj) y hi = hj. Esta relación es entonces transitiva y simétrica. 1002 El Sexto Internacional. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) • Eh toma O como argumento y devuelve min≤p de la hipótesis coherente y completa para O 5.1 Evaluación Experimental Clásicamente evaluaremos la efectividad y eficiencia de diferentes protocolos de interacción (ver, por ejemplo, [3, 4]). La efectividad de un protocolo se determinará por la proporción de agentes que sobreviven al incendio respecto al número inicial de agentes involucrados en el experimento. Si este valor es alto, el protocolo ha sido efectivo para propagar la información y/o para que los agentes refinen sus hipótesis y determinen la mejor manera de salir. Eficiencia de un protocolo. Por lo general, el uso de información de apoyo implicará una sobrecarga de comunicación. Aquí asumiremos que la eficiencia de un protocolo dado está caracterizada por el flujo de datos inducido por este protocolo. En este documento solo discutiremos este aspecto con respecto a los protocolos locales. La medida principal que utilizaremos aquí es el tamaño total promedio de los mensajes intercambiados por los agentes por intercambio (teniendo en cuenta tanto el número de mensajes como el tamaño real de los mensajes, ya que podría ser que los mensajes resulten ser muy grandes, conteniendo por ejemplo un gran número de observaciones, lo que podría contrarrestar un bajo número de mensajes). 5.2 Configuraciones Experimentales Las configuraciones experimentales elegidas son las siguientes: • Topología ambiental: El rendimiento de la propagación de la información está altamente condicionado por la topología del entorno. Las habilidades de percepción de los agentes dependen de la apertura del entorno. Con un gran número de paredes, las percepciones de los agentes están limitadas, al igual que el número de posibles comunicaciones entre agentes, mientras que un entorno abierto proporcionará posibilidades óptimas de percepción y propagación de información. Por lo tanto, proponemos un índice topológico (ver abajo) como base común para caracterizar los entornos (mapas) utilizados durante las experimentaciones. El índice topológico (TI) es la proporción entre el número de celdas que pueden ser percibidas por los agentes sumadas desde todas las posiciones posibles, dividido por el número de celdas que serían percibidas desde las mismas posiciones pero sin paredes. (Cuanto más cercano a 1, más abierto es el entorno). También utilizaremos dos medidas adicionales, más clásicas [10]: la longitud del camino característico (CPL) y el coeficiente de agrupamiento (CC). • Número de agentes: la propagación de la información también depende del número inicial de agentes involucrados durante una experimentación. Por ejemplo, cuantos más agentes haya, más potenciales comunicaciones existen. Esto significa que habrá más potencial de propagación, pero también que la restricción de intercambio bilateral será más crucial. 3 El CPL es la mediana de las medias de las longitudes de los caminos más cortos que conectan cada nodo con todos los demás nodos. 4 caracterizando el grado de aislamiento de una región de un entorno en términos de accesibilidad (número de caminos aún utilizables para llegar a esta región). Mapa T.I. (%) C.P.L. C.C. 69-1 69,23 4,5 0,69 69-2 68,88 4,38 0,65 69-3 69,80 4,25 0,67 53-1 53,19 5,6 0,59 53-2 53,53 6,38 0,54 53-3 53,92 6,08 0,61 38-1 38,56 8,19 0,50 38-2 38,56 7,3 0,50 38-3 38,23 8,13 0,50 Tabla 1: Características Topológicas de los Mapas • Posiciones iniciales de los agentes- Las posiciones iniciales de los agentes tienen una influencia significativa en el comportamiento general de una instancia de nuestro sistema: estar cerca de una salida facilitará (en general) la escapatoria. 5.3 Entornos experimentales Elegimos realizar experimentos en tres índices topológicos muy diferentes (69% para entornos abiertos, 53% para entornos mixtos y 38% para entornos tipo laberinto). Figura 2: Dos mapas (izquierda: IT=69%, derecha IT=38%) Diseñamos tres mapas diferentes para cada índice (la Fig. 2 muestra dos de ellos), conteniendo el mismo número máximo de agentes (máximo 36 agentes) con una densidad máxima de un agente por celda, el mismo número de salidas y un origen de incendio similar (por ejemplo, tiempo y posición de inicio). Los tres mapas diferentes de un índice dado están diseñados de la siguiente manera. El primer plano es un modelo de un piso de un edificio existente. El segundo mapa tiene el mismo perímetro, salidas y origen del fuego que el primero, pero la cantidad y ubicación de las paredes son diferentes (las ubicaciones de las paredes son diseñadas por una heurística que crea paredes de forma aleatoria en la cuadrícula espacial de manera que no se creen habitaciones completamente cerradas y que ninguna salida quede bloqueada). El tercer mapa se caracteriza por un recinto geométrico en el que la ubicación de las paredes también está diseñada con la heurística mencionada anteriormente. La Tabla 1 resume las diferentes medidas topológicas que caracterizan estos mapas diferentes. Vale la pena señalar que los valores confirman la relevancia de TI (los mapas con un alto TI tienen un bajo CPL y un alto CC). Sin embargo, el CPL y el CC permiten refinar aún más la diferencia entre los mapas, por ejemplo, entre 53-1 y 53-2). 5.4 Resultados Experimentales Para cada trío de mapas definidos como se mencionó anteriormente, llevamos a cabo los mismos experimentos. En cada experimento, la sociedad difiere en cuanto a su proporción inicial de agentes involucrados, desde el 1% hasta el 100%. Esta proporción inicial representa el porcentaje de agentes involucrados con respecto al número máximo posible de agentes. Para cada mapa y cada proporción inicial, la Sexta Internacional. En la Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) seleccionamos aleatoriamente 100 ubicaciones iniciales de agentes diferentes. Para cada una de esas ubicaciones diferentes ejecutamos el sistema una vez para cada protocolo de interacción diferente. La efectividad de la comunicación y argumentación El primer experimento que hemos establecido tiene como objetivo probar cuán efectivo es el intercambio de hipótesis (IH), y en particular cómo los aspectos topológicos afectarán esta efectividad. Para hacerlo, hemos calculado la proporción de mejora ofrecida por ese protocolo sobre una situación en la que los agentes simplemente no podían comunicarse (sin comunicación). Para obtener más información sobre en qué medida el intercambio de hipótesis fue realmente crucial, también probamos un protocolo mucho menos elaborado que consistía en intercambios de observaciones simples (OE). Más precisamente, este protocolo requiere que cada agente almacene cualquier observación inesperada que perciba, y los agentes simplemente intercambian sus respectivas listas de observaciones cuando discuten. En este caso, el protocolo local es diferente (nota en particular que no garantiza <br>consistencia mutua</br>), pero el protocolo global permanece igual (con la única excepción de que la motivación de los agentes para comunicarse es sincronizar su lista de observaciones, no sus hipótesis). Si este protocolo es como máximo tan efectivo como HE, tiene la ventaja de ser más eficiente (esto es obvio en cuanto al número de mensajes, que se limitará a 2, menos directo en lo que respecta al tamaño de los mensajes, pero la observación general de que el intercambio de observaciones se puede ver como una versión simplificada del desafío es útil para ver esto). Los resultados de estos experimentos se informan en la Figura 3. Figura 3: Ganancia de la proporción de efectividad comparativa de los protocolos cuando la proporción de agentes aumenta. La primera observación que debe hacerse es que la comunicación mejora la efectividad del proceso, y esta proporción aumenta a medida que el número de agentes crece en el sistema. La segunda lección que aprendemos aquí es que la cercanía relativamente hace que la comunicación sea más efectiva que la falta de comunicación. Los mapas que muestran un T.I. del 38% están constantemente por encima de los otros dos, y el 53% sigue siendo ligeramente pero significativamente mejor que el 69%. Sin embargo, estas curvas también sugieren, quizás sorprendentemente, que HE supera a OE precisamente en aquellas situaciones donde la ganancia de la relación es menos importante (la única diferencia notable ocurre en mapas bastante abiertos donde T.I. es del 69%). Esto se puede explicar de la siguiente manera: cuando un mapa está abierto, los agentes tienen muchos posibles candidatos de explicación, y la argumentación se vuelve útil para discriminar entre ellos. Cuando un mapa es laberíntico, hay menos posibles explicaciones para un evento inesperado. Importancia del Protocolo Global El segundo conjunto de experimentos busca evaluar la importancia del diseño del protocolo global. Probamos nuestro protocolo contra un protocolo de difusión local (LB). La difusión local significa que todos los agentes vecinos percibidos por un agente estarán involucrados en una comunicación con ese agente en una ronda dada, aliviando la restricción de una sola comunicación por agente. Esto nos proporciona un límite superior aproximado sobre la posible ganancia de ratio en el sistema (para un protocolo local dado). Nuevamente, evaluamos la ganancia de la relación inducida por ese LB sobre nuestro HE clásico, para las tres clases diferentes de mapas. Los resultados se informan en la Figura 4. Figura 4: Ganancia de la proporción de transmisión local sobre el intercambio de hipótesis. Tenga en cuenta que la ganancia de la proporción es 0 cuando la proporción de agentes es del 5%, lo cual se explica fácilmente por el hecho de que corresponde a situaciones que involucran solo a dos agentes. Primero observamos que todas las clases de mapas muestran un aumento en la ganancia de la proporción a medida que aumenta el número de agentes: la ganancia alcanza entre el 10 y el 20%, dependiendo de la clase de mapas considerada. Si se compara esto con la mejora reportada en el experimento anterior, parece ser de la misma magnitud. Esto ilustra que el diseño del protocolo global no puede ser ignorado, especialmente cuando la proporción de agentes es alta. Sin embargo, también observamos que las curvas de ganancia de la proporción de efectividad tienen formas muy diferentes en ambos casos: la ganancia inducida por la precisión del protocolo local aumenta muy rápidamente con la proporción de agentes, mientras que la curva es muy suave para el global. Ahora observemos con más cuidado los resultados reportados aquí: la curva correspondiente a una TI del 53% está por encima de la correspondiente al 38%. Esto se debe a que cuanto más abierta sea un mapa, más oportunidades hay de comunicarse con más de un agente (y por lo tanto beneficiarse de la difusión). Sin embargo, también observamos que la curva para el 69% está por debajo de la del 53%. Esto se explica de la siguiente manera: en el caso del 69%, la ganancia potencial en términos de agentes sobrevivientes es mucho menor, porque nuestros protocolos ya ofrecen resultados bastante eficientes de todos modos (alcanzando rápidamente el 90%, ver Fig. 3). Una regla general podría ser que cuando el número de agentes es pequeño, se debe prestar especial atención al local 1004 de la Sexta Internacional. En el caso de que el número de agentes sea pequeño, uno puede utilizar el protocolo de la Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07), mientras que cuando ese número es grande, se debe diseñar cuidadosamente uno global (a menos que el mapa sea tan abierto que el protocolo ya sea casi óptimamente eficiente). La eficiencia de los protocolos. El experimento final reportado aquí se centra en el análisis de la eficiencia de los protocolos. Aquí analizamos el tamaño medio de la totalidad de los mensajes que son intercambiados por agentes (tamaño medio de intercambios, en resumen) utilizando los siguientes protocolos: HE, OE y dos protocolos variantes. El primero es un protocolo de intercambio de hipótesis restringidas (RHE) intermediario. RHE es el siguiente: no implica ningún desafío ni contraoferta, lo que significa que los agentes no pueden cambiar su rol durante el protocolo (esto difiere de RE en ese aspecto). En resumen, RHE permite a un agente agotar las críticas de sus socios, y eventualmente este socio adoptará la hipótesis del agente. Ten en cuenta que esto significa que la autonomía del agente no se conserva aquí (ya que un agente esencialmente aceptará cualquier hipótesis que no pueda socavar), con la esperanza de que la ganancia en eficiencia sea lo suficientemente significativa como para compensar una pérdida en efectividad. El segundo protocolo de variante es un protocolo completo de intercambio de observaciones (COE). COE utiliza los mismos principios que OE, pero incluye además todos los ejemplos críticos negativos (nofire) en el intercambio (dando así todos los ejemplos utilizados como argumentos por el protocolo de intercambio de hipótesis), mejorando así la efectividad. Los resultados para el mapa 69-1 se muestran en la Figura 5. Figura 5: Tamaño medio de los intercambios. Primero podemos observar el hecho de que el orden de los protocolos, desde el menos eficiente hasta el más eficiente, es COE, HE, RHE y luego OE. ÉL siendo más eficiente que COE demuestra que el proceso de argumentación gana eficiencia al seleccionar cuándo es necesario proporcionar ejemplos negativos, los cuales tienen menos impacto que los positivos en nuestro entorno de prueba específico. Sin embargo, al comunicar hipótesis antes de proporcionar observaciones para respaldarla (HE) en lugar de dar directamente las observaciones más cruciales (OE), el proceso de argumentación duplica el tamaño de los intercambios de datos. Es el costo de garantizar la consistencia al final del intercambio (una propiedad que OE no admite). También es significativo el hecho de que el tamaño promedio de los intercambios es ligeramente mayor cuando el número de agentes es pequeño. Esto se explica por el hecho de que en estos casos solo unos pocos agentes tienen información relevante en su posesión, y que necesitarán comunicarse mucho para llegar a un punto de vista común de la situación. Cuando el número de agentes aumenta, este conocimiento se distribuye entre más agentes que necesitan discusiones más cortas para llegar a una <br>consistencia mutua</br>. Como consecuencia, la ganancia relativa en eficiencia de usar RHE parece ser mejor cuando el número de agentes es pequeño: cuando es alto, difícilmente discutirán de todos modos. Finalmente, vale la pena notar que la desviación estándar para estos experimentos es bastante alta, lo que significa que la conversación no converge hacia ningún patrón estereotípico. 6. CONCLUSIÓN Este documento ha investigado las propiedades de un sistema multiagente donde cada agente (distribuido) percibe localmente su entorno e intenta alcanzar consistencia con otros agentes a pesar de severas restricciones de comunicación. En particular, hemos expuesto condiciones que permiten la convergencia e investigado experimentalmente una situación típica donde esas condiciones no pueden cumplirse. Hay muchas posibles extensiones a este trabajo, la primera siendo investigar más a fondo las propiedades de diferentes protocolos globales pertenecientes a la clase que identificamos, y su influencia en el resultado. Existen en particular muchas heurísticas, altamente dependientes del contexto del estudio, que podrían intuitivamente arrojar resultados interesantes (en nuestro estudio, seleccionar al destinatario en función de lo que se pueda inferir de sus acciones observadas podría ser una de esas heurísticas). Un candidato obvio para problemas a largo plazo se refiere a la relajación de la suposición de un sensor perfecto. 7. REFERENCIAS [1] G. Bourgne, N. Maudet y S. Pinson. Cuando los agentes comunican hipótesis en situaciones críticas. En Actas de DALT-2006, mayo de 2006. [2] P. Harvey, C. F. Chang y A. Ghose. Búsqueda distribuida basada en soporte: un nuevo enfoque para el procesamiento de restricciones multiagente. En Actas de AAMAS06, 2006. [3] H. Jung y M. Tambe. Argumentación como satisfacción de restricciones distribuida: Aplicaciones y resultados. En Actas de AGENTS01, 2001. [4] N. C. Karunatillake y N. R. Jennings. ¿Vale la pena discutir? En Actas de ArgMAS 2004, 2004. [5] S. Onta˜n´on y E. Plaza. Argumentos y contraejemplos en la deliberación conjunta basada en casos. En Actas de ArgMAS-2006, mayo de 2006. [6] D. Poole. Explicación y predicción: Una arquitectura para el razonamiento por defecto y abductivo. Inteligencia Computacional, 5(2):97-110, 1989. [7] I. Rahwan, S. D. Ramchurn, N. R. Jennings, P. McBurney, S. Parsons y L. Sonenberg. Negociación basada en argumentos. La revisión de Ingeniería del Conocimiento, 4(18):345-375, 2003. [8] N. Roos, A. ten Tije y C. Witteveen. Un protocolo para el diagnóstico multiagente con conocimiento distribuido espacialmente. En Actas de AAMAS03, 2003. [9] N. Roos, A. ten Tije y C. Witteveen. Alcanzando acuerdo diagnóstico en el diagnóstico multiagente. En Actas de AAMAS04, 2004. [10] T. Takahashi, Y. Kaneda y N. Ito. Estudio preliminar: utilizando simulaciones de RoboCupRescue para la prevención de desastres. En Actas de SRMED2004, 2004. El Sexto Internacional. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 1005 ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "context request step": {
            "translated_key": "paso de solicitud de contexto",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Hypotheses Refinement under Topological Communication Constraints ∗ Gauvain Bourgne, Gael Hette, Nicolas Maudet, and Suzanne Pinson LAMSADE, Univ.",
                "Paris-Dauphine, France {bourgne,hette,maudet,pinson}@lamsade.dauphine.fr ABSTRACT We investigate the properties of a multiagent system where each (distributed) agent locally perceives its environment.",
                "Upon perception of an unexpected event, each agent locally computes its favoured hypothesis and tries to propagate it to other agents, by exchanging hypotheses and supporting arguments (observations).",
                "However, we further assume that communication opportunities are severely constrained and change dynamically.",
                "In this paper, we mostly investigate the convergence of such systems towards global consistency.",
                "We first show that (for a wide class of protocols that we shall define), the communication constraints induced by the topology will not prevent the convergence of the system, at the condition that the system dynamics guarantees that no agent will ever be isolated forever, and that agents have unlimited time for computation and arguments exchange.",
                "As this assumption cannot be made in most situations though, we then set up an experimental framework aiming at comparing the relative efficiency and effectiveness of different interaction protocols for hypotheses exchange.",
                "We study a critical situation involving a number of agents aiming at escaping from a burning building.",
                "The results reported here provide some insights regarding the design of optimal protocol for hypotheses refinement in this context.",
                "Categories and Subject Descriptors I.2.11 [Artificial Intelligence]: Distributed Artificial Intelligence-Multiagent systems General Terms Theory, Experimentation 1.",
                "INTRODUCTION We consider a multiagent system where each (distributed) agent locally perceives its environment, and we assume that some unexpected event occurs in that system.",
                "If each agent computes only locally its favoured hypothesis, it is only natural to assume that agents will seek to coordinate and refine their hypotheses by confronting their observations with other agents.",
                "If, in addition, the communication opportunities are severely constrained (for instance, agents can only communicate when they are close enough to some other agent), and dynamically changing (for instance, agents may change their locations), it becomes crucial to carefully design protocols that will allow agents to converge to some desired state of global consistency.",
                "In this paper we exhibit some sufficient conditions on the system dynamics and on the protocol/strategy structures that allow to guarantee that property, and we experimentally study some contexts where (some of) these assumptions are relaxed.",
                "While problems of diagnosis are among the venerable classics in the AI tradition, their multiagent counterparts have much more recently attracted some attention.",
                "Roos and colleagues [8, 9] in particular study a situation where a number of distributed entities try to come up with a satisfying global diagnosis of the whole system.",
                "They show in particular that the number of messages required to establish this global diagnosis is bound to be prohibitive, unless the communication is enhanced with some suitable protocol.",
                "However, they do not put any restrictions on agents communication options, and do not assume either that the system is dynamic.",
                "The benefits of enhancing communication with supporting information to make convergence to a desired global state of a system more efficient has often been put forward in the literature.",
                "This is for instance one of the main idea underlying the argumentation-based negotiation approach [7], where the desired state is a compromise between agents with conflicting preferences.",
                "Many of these works however make the assumption that this approach is beneficial to start with, and study the technical facets of the problem (or instead emphasize other advantages of using argumentation).",
                "Notable exceptions are the works of [3, 4, 2, 5], which studied in contexts different from ours the efficiency of argumentation.",
                "The rest of the paper is as follows.",
                "Section 2 specifies the basic elements of our model, and Section 3 goes on to presenting the different protocols and strategies used by the agents to exchange hypotheses and observations.",
                "We put special attention at clearly emphasizing the conditions on the system dynamics and protocols/strategies that will be exploited in the rest of the paper.",
                "Section 4 details one of 998 978-81-904262-7-5 (RPS) c 2007 IFAAMAS the main results of the paper, namely the fact that under the aforementioned conditions, the constraints that we put on the topology will not prevent the convergence of the system towards global consistency, at the condition that no agent ever gets completely lost forever in the system, and that unlimited time is allowed for computation and argument exchange.",
                "While the conditions on protocols and strategies are fairly mild, it is also clear that these system requirements look much more problematic, even frankly unrealistic in critical situations where distributed approaches are precisely advocated.",
                "To get a clearer picture of the situation induced when time is a critical factor, we have set up an experimental framework that we introduce and discuss in Section 5.",
                "The critical situation involves a number of agents aiming at escaping from a burning building.",
                "The results reported here show that the effectiveness of argument exchange crucially depends upon the nature of the building, and provide some insights regarding the design of optimal protocol for hypotheses refinement in this context. 2.",
                "BASIC NOTIONS We start by defining the basic elements of our system.",
                "Environment Let O be the (potentially infinite) set of possible observations.",
                "We assume the sensors of our agents to be perfect, hence the observations to be certain.",
                "Let H be the set of hypotheses, uncertain and revisable.",
                "Let Cons(h, O) be the consistency relation, a binary relation between a hypothesis h ∈ H and a set of observations O ⊆ O.",
                "In most cases, Cons will refer to classical consistency relation, however, we may overload its meaning and add some additional properties to that relation (in which case we will mention it).",
                "The environment may include some dynamics, and change over the course of time.",
                "We define below sequences of time points to deal with it: Definition 1 (Sequence of time points).",
                "A sequence of time points t1, t2, . . . , tn from t is an ordered set of time points t1, t2, . . . , tn such that t1 ≥ t and ∀i ∈ [1, n − 1], ti+1 ≥ ti.",
                "Agent We take a system populated by n agents a1, . . . , an.",
                "Each agent is defined as a tuple F, Oi, hi , where: • F, the set of facts, common knowledge to all agents. • Oi ∈ 2O , the set of observations made by the agent so far.",
                "We assume a perfect memory, hence this set grows monotonically. • hi ∈ H, the favourite hypothesis of the agent.",
                "A key notion governing the formation of hypotheses is that of consistency, defined below: Definition 2 (Consistency).",
                "We say that: • An agent is consistent (Cons(ai)) iff Cons(hi, Oi) (that is, its hypothesis is consistent with its observation set). • An agent ai consistent with a partner agent aj iff Cons(ai) and Cons(hi, Oj) (that is, this agent is consistent and its hypothesis can explain the observation set of the other agent). • Two agents ai and aj are mutually consistent (MCons(ai, aj)) iff Cons(ai, aj) and Cons(aj, ai). • A system is consistent iff ∀(i, j)∈[1, n]2 it is the case that MCons(ai, aj).",
                "To ensure its consistency, each agent is equipped with an abstract reasoning machinery that we shall call the explanation function Eh.",
                "This (deterministic) function takes a set of observation and returns a single prefered hypothesis (2O → H).",
                "We assume h = Eh(O) to be consistent with O by definition of Eh, so using this function on its observation set to determine its favourite hypothesis is a sure way for the agent to achieve consistency.",
                "Note however that an hypothesis does not need to be generated by Eh to be consistent with an observation set.",
                "As a concrete example of such a function, and one of the main inspiration of this work, one can cite the Theorist reasoning system [6] -as long as it is coupled with a filter selecting a single prefered theory among the ones initially selected by Theorist.",
                "Note also that hi may only be modified as a consequence of the application Eh.",
                "We refer to this as the autonomy of the agent: no other agent can directly impose a given hypothesis to an agent.",
                "As a consequence, only a new observation (being it a new perception, or an observation communicated by a fellow agent) can result in a modification of its prefered hypothesis hi (but not necessarily of course).",
                "We finally define a property of the system that we shall use in the rest of the paper: Definition 3 (Bounded Perceptions).",
                "A system involves a bounded perception for agents iff ∃n0 s.t. ∀t| ∪N i=1 Oi| ≤ n0. (That is, the number of observations to be made by the agents in the system is not infinite.)",
                "Agent Cycle Now we need to see how these agents will evolve and interact in their environment.",
                "In our context, agents evolve in a dynamic environment, and we classicaly assume the following system cycle: 1.",
                "Environment dynamics: the environment evolves according to the defined rules of the system dynamics. 2.",
                "Perception step : agents get perceptions from the environment.",
                "These perceptions are typically partial (e.g. the agent can only see a portion of a map). 3.",
                "Reasoning step: agents compare perception with predictions, seek explanations for (potential) difference(s), refine their hypothesis, draw new conclusions. 4.",
                "Communication step: agents can communicate hypotheses and observations with other agents through a defined protocol.",
                "Any agent can only be involved in one communication with another agent by step. 5.",
                "Action step: agents do some practical reasoning using the models obtained from the previous steps and select an action.",
                "They can then modify the environment by executing it.",
                "The communication of the agents will be further constrained by topological consideration.",
                "At a given time, an agent will only be able to communicate with a number of neighbours.",
                "Its connexions with these others agents may The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 999 evolve with its situation in the environment.",
                "Typically, an agent can only communicate with agents that it can sense, but one could imagine evolving topological constraints on communication based on a network of communications between agents where the links are not always active.",
                "Communication In our system, agents will be able to communicate with each other.",
                "However, due to the aforementionned topological constraints, they will not be able to communicate with any agents at anytime.",
                "Who an agent can communicate with will be defined dynamically (for instance, this can be a consequence of the agents being close enough to get in touch).",
                "We will abstractly denote by C(ai, aj, t) the communication property, in other words, the fact that agents ai and aj can communicate at time t (note that this relation is assumed to be symetric, but of course not transitive).",
                "We are now in a position to define two essential properties of our system.",
                "Definition 4 (Temporal Path).",
                "There exists a temporal communication path at horizon tf (noted Ltf (aI , aJ )) between ai and aj iff there exists a sequence of time points t1, t2, . . . , tn from tf and a sequence of agents k1, k2, . . . , kn s.t. (i) C(aI , ak1 , t1), (ii) C(akn , aJ , tn+1), (iii) ∀i ∈ [1, n], C(aki , aki+1 , ti) Intuitively, what this property says is that it is possible to find a temporal path in the future that would allow to link agent ai and aj via a sequence of intermediary agents.",
                "Note that the time points are not necessarily successive, and that the sequence of agents may involve the same agents several times.",
                "Definition 5 (Temporal Connexity).",
                "A system is temporaly connex iff ∀t ∀(i, j)∈[1, n]2 Lt(ai, aj) In short, a temporaly connex system guarantees that any agent will be able to communicate with any other agents, no matter how long it might take to do so, at any time.",
                "To put it another way, it is never the case that an agent will be isolated for ever from another agent of the system.",
                "We will next discuss the detail of how communication concretely takes place in our system.",
                "Remember that in this paper, we only consider the case of bilateral exchanges (an agent can only speak to a single other agent), and that we also assume that any agent can only engage in a single exchange in a given round. 3.",
                "PROTOCOLS AND STRATEGIES In this section, we discuss the requirements of the interaction protocols that govern the exchange of messages between agents, and provide some example instantiation of such protocols.",
                "To clarify the presentation, we distinguish two levels: the local level, which is concerned with the regulation of bilateral exchanges; and the global level,which essentially regulates the way agents can actually engage into a conversation.",
                "At each level, we separate what is specified by the protocol, and what is left to agents strategies.",
                "Local Protocol and Strategies We start by inspecting local protocols and strategies that will regulate the communication between the agents of the system.",
                "As we limit ourselves to bilateral communication, these protocols will simply involve two agents.",
                "Such protocol will have to meet one basic requirement to be satisfying. • consistency (CONS)- a local protocol has to guarantee the mutual consistency of agents upon termination (which implies termination of course).",
                "Figure 1: A Hypotheses Exchange Protocol [1] One example such protocol is the protocol described in [1] that is pictured in Fig. 1.",
                "To further illustrate how such protocol can be used by agents, we give some details on a possible strategy: upon receiving a hypothesis h1 (propose(h1) or counterpropose(h1)) from a1, agent a2 is in state 2 and has the following possible replies: counterexample (if the agent knows an example contradicting the hypothesis, or not explained by this hypothesis), challenge (if the agents lacks evidence to accept this hypothesis), counterpropose (if the agent agrees with the hypothesis but prefers another one), or accept (if it is indeed as good as its favourite hypothesis).",
                "This strategy guarantees, among other properties, the eventual mutual logical consistency of the involved agents [1].",
                "Global Protocol The global protocol regulates the way bilateral exchanges will be initiated between agents.",
                "At each turn, agents will concurrently send one weighted request to communicate to other agents.",
                "This weight is a value measuring the agents willingness to converse with the targeted agent (in practice, this can be based on different heuristics, but we shall make some assumptions on agents strategies, see below).",
                "Sending such a request is a kind of conditional commitment for the agent.",
                "An agent sending a weighted request commits to engage in conversation with the target if he does not receive and accept himself another request.",
                "Once all request have been received, each agent replies with either an acccept or a reject.",
                "By answering with an accept, an agent makes a full commitment to engage in conversation with the sender.",
                "Therefore, it can only send one accept in a given round, as an agent can only participate in one conversation per time step.",
                "When all response have been received, each agent receiving an accept can either initiate a conversation using the local protocol or send a cancel if it has accepted another request.",
                "At the end of all the bilateral exchanges, the agents engaged in conversation are discarded from the protocol.",
                "Then each of the remaining agents resends a request and the process iterates until no more requests are sent.",
                "Global Strategy We now define four requirements for the strategies used by agents, depending on their role in the protocol: two are concerned with the requestee role (how to decide who the 1000 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) agent wishes to communicate with? ), the other two with the responder role (how to decide which communication request to accept or not?). • Willingness to solve inconsistancies (SOLVE)-agents want to communicate with any other agents unless they know they are mutually consistent. • Focus on solving inconsistencies (FOCUS)-agents do not request communication with an agent with whom they know they are mutually consistent. • Willingness to communicate (COMM)-agents cannot refuse a weighted communication request, unless they have just received or send a request with a greater weight. • Commitment to communication request (REQU)agents cannot accept a weighted communication request if they have themselves sent a communication request with a greater weight.",
                "Therefore, they will not cancel their request unless they have received a communicational request with greater weight.",
                "Now the protocol structure, together with the properties COMM+REQU, ensure that a request can only be rejected if its target agent engages in communication with another agent.",
                "Suppose indeed that agent ai wants to communicate with aj by sending a request with weight w. COMM guarantees that an agent receiving a weighted request will either accept this communication, accept a communication with a greater weight or wait for the answer to a request with a greater weight.",
                "This ensures that the request with maximal weight will be accepted and not cancelled (as REQU ensures that an agent sending a request can only cancel it if he accepts another request with greater weight).",
                "Therefore at least two agents will engage in conversation per round of the global protocol.",
                "As the protocol ensures that ai can resend its request while aj is not engaged in a conversation, there will be a turn in which aj must engage in a conversation, either with ai or another agent.",
                "These requirements concern request sending and acceptation, but agents also need some strategy of weight attribution.",
                "We describe below an altruist strategy, used in our experiments.",
                "Being cooperative, an agent may want to know more of the communication wishes of other agents in order to improve the overall allocation of exchanges to agents.",
                "A <br>context request step</br> is then added to the global protocol.",
                "Before sending their chosen weighted request, agents attribute a weight to all agents they are prepared to communicate with, according to some internal factors.",
                "In the simplest case, this weight will be 1 for all agent with whom the agent is not sure of being mutually consistent (ensuring SOLVE), other agent being not considered for communication (ensuring FOCUS).",
                "The agent then sends a context request to all agents with whom communication is considered.",
                "This request also provides information about the sender (list of considered communications along with their weight).",
                "After reception of all the context requests, agents will either reply with a deny, iff they are already engaged in a conversation (in which case, the requesting agent will not consider communication with them anymore in this turn), or an inform giving the requester information about the requests it has sent and received.",
                "When all replies have been received, each agent can calculate the weight of all requests concerning it.",
                "It does so by substracting from the weight of its request the weight of all requests concerning either it or its target (that is, the final weight of the request from ai to aj is Wi,j = wi,j +wj,i − ( P k∈R(i)−{j} wi,k + P k∈S(i)−{j} wk,i + P k∈R(j)−{i} wj,k + P k∈S(j)−{i} wk,j) where wi,j is the weight of the request of ai to aj, R(i) is the set of indice of agents having received a request from ai and S(i) is the set of indice of agents having send a request to ai).",
                "It then finally sends a weighted request to the agents who maximise this weight (or wait for a request) as described in the global protocol. 4. (CONDITIONAL) CONVERGENCE TO GLOBAL CONSISTENCY In this section we will show that the requirements regarding protocols and strategies just discussed will be sufficient to ensure that the system will eventually converge towards global consistency, under some conditions.",
                "We first show that, if two agents are not mutually consistent at some time, then there will be necessarily a time in the future such that an agent will learn a new observation, being it because it is new for the system, or by learning it from another agent.",
                "Lemma 1.",
                "Let S be a system populated by n agents a1, a2, ..., an, temporaly connex, and involving bounded perceptions for these agents.",
                "Let n1 be the sum of cardinalities of the intersection of pairwise observation sets. (n1 = P (i,j)∈[1,n]2 |Oi ∩ Oj|) Let n2 be the cardinality of the union of all agents observations sets. (n2 = | ∪N i=1 Oi|).",
                "If ¬MCons(ai, aj) at time t0, there is necessarily a time t > t0 s.t. either n1 or n2 will increase.",
                "Proof.",
                "Suppose that there exist a time t0 and indices (i, j) s.t. ¬MCons(ai, aj).",
                "We will use mt0 = P (k,l)∈[1,n]2 εComm(ak, al, t0) where εComm(ak, al, t0) = 1 if ak and al have communicated at least once since t0, and 0 otherwise.",
                "Temporal connexity guarantees that there exist t1, ..., tm+1 and k1, ..., km s.t.",
                "C(ai, ak1 , t1), C(akm , aj, tm+1), and ∀p ∈ [1, m], C(akp , akp+1 , tp).",
                "Clearly, if MCons(ai, ak1 ), MCons(akm , aj) and ∀p, MCons(akp , akp+1 ), we have MCons(ai, aj) which contradicts our hypothesis (MCons being transitive, MCons(ai, ak1 )∧MCons(ak1 , ak2 ) implies that MCons(ai, ak2 ) and so on till MCons(ai, akm )∧ MCons(akm , aj) which implies MCons(ai, aj) ).",
                "At least two agents are then necessarily inconsistent (¬MCons(ai, ak1 ), or ¬MCons(akm , aj), or ∃p0 t.q. ¬MCons(akp0 , akp0+1 )).",
                "Let ak and al be these two neighbours at a time t > t0 1 .",
                "The SOLVE property ensures that either ak or al will send a communication request to the other agent at time t .",
                "As shown before, this in turn ensures that at least one of these agents will be involved in a communication.",
                "Then there are two possibilities: (case i) ak and al communicate at time t .",
                "In this case, we know that ¬MCons(ak, al).",
                "This and the CONS property ensures that at least one of the agents must change its 1 Strictly speaking, the transitivity of MCons only ensure that ak and al are inconsistent at a time t ≥ t0 that can be different from the time t at which they can communicate.",
                "But if they become consistent between t and t (or inconsistent between t and t ), it means that at least one of them have changed its hypothesis between t and t , that is, after t0.",
                "We can then apply the reasoning of case iib.",
                "The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 1001 hypothesis, which in turn, since agents are autonomous, implies at least one exchange of observation.",
                "But then |Ok ∩Ol| is bound to increase: n1(t ) > n1(t0). (case ii) ak communicates with ap at time t .",
                "We then have again two possibilities: (case iia) ak and ap did not communicate since t0.",
                "But then εComm(ak, ap, t0) had value 0 and takes value 1.",
                "Hence mt0 increases. (case iib) ak and ap did communicate at some time t0 > t0.",
                "The CONS property of the protocol ensures that MCons(ak, ap) at that time.",
                "Now the fact that they communicate and FOCUS implies that at least one of them did change its hypothesis in the meantime.",
                "The fact that agents are autonomous implies in turn that a new observation (perceived or received from another agent) necessarily provoked this change.",
                "The latter case would ensure the existence of a time t > t0 and an agent aq s.t. either |Op ∩Oq| or |Ok ∩Oq| increases of 1 at that time (implying n1(t ) > n1(t0)).",
                "The former case means that the agent gets a new perception o at time t .",
                "If that observation was unknown in the system before, then n2(t ) > n2(t0).",
                "If some agent aq already knew this observation before, then either Op ∩ Oq or Ok ∩ Oq increases of 1 at time t (which implies that n1(t ) > n1(t0)).",
                "Hence, ¬MCons(ai, aj) at time t0 guarantees that, either: −∃t > t0 t.q. n1(t ) > n1(t0); or −∃t > t0 t.q. n2(t ) > n2(t0); or −∃t > t0 t.q. mt0 increases of 1 at time t .",
                "By iterating the reasoning with t (but keeping t0 as the time reference for mt0 ), we can eliminate the third case (mt0 is integer and bounded by n2 , which means that after a maximum of n2 iterations, we necessarily will be in one of two other cases.)",
                "As a result, we have proven that if ¬MCons(ai, aj) at time t0, there is necessarily a time t s.t. either n1 or n2 will increase.",
                "Theorem 1 (Global consistency).",
                "Let S be a system populated by n agents a1, a2, ..., an, temporaly connex, and involving bounded perceptions for these agents.",
                "Let Cons(ai, aj) be a transitive consistency property.",
                "Then any protocol and strategies satisfying properties CONS, SOLVE, FOCUS, COMM and REQU guarantees that the system will converge towards global consistency.",
                "Proof.",
                "For the sake of contradiction, let us assume ∃I, J ∈ [1, N] s.t. ∀t, ∃t0 > t, t.q. ¬Cons(aI , aJ , t0).",
                "Using the lemma, this implies that ∃t > t0 s.t. either n1(t ) > n1(t0) or n2(t ) > n2(t0).",
                "But we can apply the same reasoning taking t = t , which would give us t1 > t > t0 s.t. ¬Cons(aI , aJ , t1), which gives us t > t1 s.t. either n1(t ) > n1(t1) or n2(t ) > n2(t1).",
                "By successive iterations we can then construct a sequence t0, t1, ..., tn, which can be divided in two sub-sequences t0, t1, ...tn and t0 , t1 , ..., tn s.t. n1(t0) < n1(t1) < ... < n1(tn) and n2(t0 ) < n2(t1 ) < ... < n2(tn).",
                "One of these sub-sequences has to be infinite.",
                "However, n1(ti) and n2(ti ) are strictly growing, integer, and bounded, which implies that both are finite.",
                "Contradiction.",
                "What the previous result essentially shows is that, in a system where no agent will be isolated from the rest of the agents for ever, only very mild assumptions on the protocols and strategies used by agents suffice to guarantee convergence towards system consistency in a finite amount of time (although it might take very long).",
                "Unfortunately, in many critical situations, it will not be possible to assume this temporal connexity.",
                "As distributed approaches as the one advocated in this paper are precisely often presented as a good way to tackle problems of reliability or problems of dependence to a center that are of utmost importance in these critical applications, it is certainly interesting to further explore how such a system would behave when we relax this assumption. 5.",
                "EXPERIMENTAL STUDY This experiment involves agents trying to escape from a burning building.",
                "The environment is described as a spatial grid with a set of walls and (thankfully) some exits.",
                "Time and space are considered discrete.",
                "Time is divided in rounds.",
                "Agents are localised by their position on the spatial grid.",
                "These agents can move and communicate with other agents.",
                "In a round, an agent can move of one cell in any of the four cardinal directions, provided it is not blocked by a wall.",
                "In this application, agents communicate with any other agent (but, recall, a single one) given that this agent is in view, and that they have not yet exchanged their current favoured hypothesis.",
                "Suddenly, a fire erupts in these premises.",
                "From this moment, the fire propagates.",
                "Each round, for each cases where there is fire, the fire propagates in the four directions.",
                "However, the fire cannot propagate through a wall.",
                "If the fire propagates in a case where an agent is positioned, that agent burns and is considered dead.",
                "It can of course no longer move nor communicate.",
                "If an agent gets to an exit, it is considered saved, and can no longer be burned.",
                "Agents know the environment and the rules governing the dynamics of this environment, that is, they know the map as well as the rules of fire propagation previously described.",
                "They also locally perceive this environment, but cannot see further than 3 cases away, in any direction.",
                "Walls also block the line of view, preventing agents from seeing behind them.",
                "Within their sight, they can see other agents and whether or not the cases they see are on fire.",
                "All these perceptions are memorised.",
                "We now show how this instantiates the abstract framework presented the paper. • O = {Fire(x, y, t), NoFire(x, y, t), Agent(ai, x, y, t)} Observations can then be positive (o ∈ P(O) iff ∃h ∈ H s.t. h |= o) or negative (o ∈ N(O) iff ∃h ∈ H s.t. h |= ¬o). • H={FireOrigin(x1, y1, t1)∧...∧FireOrigin(xl, yl, tl)} Hypotheses are conjunctions of FireOrigins. • Cons(h, O) consistency relation satisfies: - coherence : ∀o ∈ N(O), h |= ¬o. - completeness : ∀o ∈ P(O), h |= o. - minimality : For all h ∈ H, if h is coherent and complete for O, then h is prefered to h according to the preference relation (h ≤p h ).2 2 Selects first the minimal number of origins, then the most recent (least preemptive strategy [6]), then uses some arbitrary fixed ranking to discriminate ex-aequo.",
                "The resulting relation is a total order, hence minimality implies that there will be a single h s.t.Cons(O, h) for a given O.",
                "This in turn means that MCons(ai, aj) iff Cons(ai), Cons(aj), and hi = hj.",
                "This relation is then transitive and symmetric. 1002 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) • Eh takes O as argument and returns min≤p of the coherent and complete hypothesis for O 5.1 Experimental Evaluation We will classically (see e.g. [3, 4]) assess the effectiveness and efficiency of different interaction protocols.",
                "Effectiveness of a protocol The proportion of agents surviving the fire over the initial number of agents involved in the experiment will determine the effectiveness of a given protocol.",
                "If this value is high, the protocol has been effective to propagate the information and/or for the agents to refine their hypotheses and determine the best way to the exit.",
                "Efficiency of a protocol Typically, the use of supporting information will involve a communication overhead.",
                "We will assume here that the efficiency of a given protocol is characterised by the data flow induced by this protocol.",
                "In this paper we will only discuss this aspect wrt. local protocols.",
                "The main measure that we shall then use here is the mean total size of messages that are exchanged by agents per exchange (hence taking into account both the number of messages and the actual size of the messages, because it could be that messages happen to be very big, containing e.g. a large number of observations, which could counter-balance a low number of messages). 5.2 Experimental Settings The chosen experimental settings are the following: • Environmental topology- Performances of information propagation are highly constrained by the environment topology.",
                "The perception skills of the agents depend on the openness of the environment.",
                "With a large number of walls the perceptions of agents are limited, and also the number of possible inter-agent communications, whereas an open environment will provide optimal possibilities of perception and information propagation.",
                "Thus, we propose a topological index (see below) as a common basis to charaterize the environments (maps) used during experimentations.",
                "The topological index (TI) is the ratio of the number of cells that can be perceived by agents summed up from all possible positions, divided by the number of cells that would be perceived from the same positions but without any walls. (The closer to 1, the more open the environment).",
                "We shall also use two additional, more classical [10], measures: the characteristic path length3 (CPL) and the clustering coefficient4 (CC). • Number of agents- The propagation of information also depends on the initial number of agents involved during an experimentation.",
                "For instance, the more agents, the more potential communications there is.",
                "This means that there will be more potential for propagation, but also that the bilateral exchange restriction will be more crucial. 3 The CPL is the median of the means of the shortest path lengths connecting each node to all other nodes. 4 characterising the isolation degree of a region of an environment in terms of acessibility (number of roads still usable to reach this region).",
                "Map T.I. (%) C.P.L.",
                "C.C. 69-1 69,23 4,5 0,69 69-2 68,88 4,38 0,65 69-3 69,80 4,25 0,67 53-1 53,19 5,6 0,59 53-2 53,53 6,38 0,54 53-3 53,92 6,08 0,61 38-1 38,56 8,19 0,50 38-2 38,56 7,3 0,50 38-3 38,23 8,13 0,50 Table 1: Topological Characteristics of the Maps • Initial positions of the agents- Initial positions of the agents have a significant influence on the overall behavior of an instance of our system: being close from an exit will (in general) ease the escape. 5.3 Experimental environments We choose to realize experiments on three very different topological indexes (69% for open environments, 53% for mixed environments, and 38% for labyrinth-like environments).",
                "Figure 2: Two maps (left: TI=69%, right TI=38%) We designed three different maps for each index (Fig. 2 shows two of them), containing the same maximum number of agents (36 agents max.) with a maximum density of one agent per cell, the same number of exits and a similar fire origin (e.g. starting time and position).",
                "The three differents maps of a given index are designed as follows.",
                "The first map is a model of an existing building floor.",
                "The second map has the same enclosure, exits and fire origin as the first one, but the number and location of walls are different (wall locations are designed by an heuristic which randomly creates walls on the spatial grid such that no fully closed rooms are created and that no exit is closed).",
                "The third map is characterised by geometrical enclosure in wich walls location is also designed with the aforementioned heuristic.",
                "Table 1 summarizes the different topological measures characterizing these different maps.",
                "It is worth pointing out that the values confirm the relevance of TI (maps with a high TI have a low CPL and a high CC.",
                "However the CPL and CC allows to further refine the difference between the maps, e.g. between 53-1 and 53-2). 5.4 Experimental Results For each triple of maps defined as above we conduct the same experiments.",
                "In each experiment, the society differs in terms of its initial proportion of involved agents, from 1% to 100%.",
                "This initial proportion represents the percentage of involved agents with regards to the possible maximum number of agents.",
                "For each map and each initial proportion, The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 1003 we select randomly 100 different initial agents locations.",
                "For each of those different locations we execute the system one time for each different interaction protocol.",
                "Effectiveness of Communication and Argumentation The first experiment that we set up aims at testing how effective is hypotheses exchange (HE), and in particular how the topological aspects will affect this effectiveness.",
                "In order to do so, we have computed the ratio of improvement offered by that protocol over a situation where agents could simply not communicate (no comm).",
                "To get further insights as to what extent the hypotheses exchange was really crucial, we also tested a much less elaborated protocol consisting of mere observation exchanges (OE).",
                "More precisely, this protocol requires that each agent stores any unexpected observation that it perceives, and agents simply exchange their respective lists of observations when they discuss.",
                "In this case, the local protocol is different (note in particular that it does not guarantee mutual consistency), but the global protocol remains the same (at the only exception that agents motivation to communicate is to synchronise their list of observations, not their hypothesis).",
                "If this protocol is at best as effective as HE, it has the advantage of being more efficient (this is obvious wrt the number of messages which will be limited to 2, less straightforward as far as the size of messages is concerned, but the rough observation that the exchange of observations can be viewed as a flat version of the challenge is helpful to see this).",
                "The results of these experiments are reported in Fig. 3.",
                "Figure 3: Comparative effectiveness ratio gain of protocols when the proportion of agents augments The first observation that needs to be made is that communication improves the effectiveness of the process, and this ratio increases as the number of agents grows in the system.",
                "The second lesson that we learn here is that closeness relatively makes communication more effective over non communication.",
                "Maps exhibiting a T.I. of 38% are constantly above the two others, and 53% are still slightly but significantly better than 69%.",
                "However, these curves also suggest, perhaps surprisingly, that HE outperforms OE in precisely those situations where the ratio gain is less important (the only noticeable difference occurs for rather open maps where T.I. is 69%).",
                "This may be explained as follows: when a map is open, agents have many potential explanation candidates, and argumentation becomes useful to discriminate between those.",
                "When a map is labyrinth-like, there are fewer possible explanations to an unexpected event.",
                "Importance of the Global Protocol The second set of experiments seeks to evaluate the importance of the design of the global protocol.",
                "We tested our protocol against a local broadcast (LB) protocol.",
                "Local broadcast means that all the neighbours agents perceived by an agent will be involved in a communication with that agent in a given round -we alleviate the constraint of a single communication by agent.",
                "This gives us a rough upper bound upon the possible ratio gain in the system (for a given local protocol).",
                "Again, we evaluated the ratio gain induced by that LB over our classical HE, for the three different classes of maps.",
                "The results are reported in Fig. 4.",
                "Figure 4: Ratio gain of local broadcast over hypotheses exchange Note to begin with that the ratio gain is 0 when the proportion of agents is 5%, which is easily explained by the fact that it corresponds to situations involving only two agents.",
                "We first observe that all classes of maps witness a ratio gain increasing when the proportion of agents augments: the gain reaches 10 to 20%, depending on the class of maps considered.",
                "If one compares this with the improvement reported in the previous experiment, it appears to be of the same magnitude.",
                "This illustrates that the design of the global protocol cannot be ignored, especially when the proportion of agents is high.",
                "However, we also note that the effectiveness ratio gain curves have very different shapes in both cases: the gain induced by the accuracy of the local protocol increases very quickly with the proportion of agents, while the curve is really smooth for the global one.",
                "Now let us observe more carefully the results reported here: the curve corresponding to a TI of 53% is above that corresponding to 38%.",
                "This is so because the more open a map, the more opportunities to communicate with more than one agent (and hence benefits from broadcast).",
                "However, we also observe that curve for 69% is below that for 53%.",
                "This is explained as follows: in the case of 69%, the potential gain to be made in terms of surviving agents is much lower, because our protocols already give rather efficient outcomes anyway (quickly reaching 90%, see Fig. 3).",
                "A simple rule of thumb could be that when the number of agents is small, special attention should be put on the local 1004 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) protocol, whereas when that number is large, one should carefully design the global one (unless the map is so open that the protocol is already almost optimally efficient).",
                "Efficiency of the Protocols The final experiment reported here is concerned with the analysis of the efficiency of the protocols.",
                "We analysis here the mean size of the totality of the messages that are exchanged by agents (mean size of exchanges, for short) using the following protocols: HE, OE, and two variant protocols.",
                "The first one is an intermediary restricted hypotheses exchange protocol (RHE).",
                "RHE is as follows: it does not involve any challenge nor counter-propose, which means that agents cannot switch their role during the protocol (this differs from RE in that respect).",
                "In short, RHE allows an agent to exhaust its partners criticism, and eventually this partner will come to adopt the agents hypothesis.",
                "Note that this means that the autonomy of the agent is not preserved here (as an agent will essentially accept any hypothesis it cannot undermine), with the hope that the gain in efficiency will be significant enough to compensate a loss in effectiveness.",
                "The second variant protocol is a complete observation exchange protocol (COE).",
                "COE uses the same principles as OE, but includes in addition all critical negative examples (nofire) in the exchange (thus giving all examples used as arguments by the hypotheses exchanges protocol), hence improving effectiveness.",
                "Results for map 69-1 are shown on Fig. 5.",
                "Figure 5: Mean size of exchanges First we can observe the fact that the ordering of the protocols, from the least efficient to the most efficient, is COE, HE, RHE and then OE.",
                "HE being more efficient than COE proves that the argumentation process gains efficiency by selecting when it is needed to provide negative example, which have less impact that positive ones in our specific testbed.",
                "However, by communicating hypotheses before eventually giving observation to support it (HE) instead of directly giving the most crucial observations (OE), the argumentation process doubles the size of data exchanges.",
                "It is the cost for ensuring consistency at the end of the exchange (a property that OE does not support).",
                "Also significant is the fact the the mean size of exchanges is slightly higher when the number of agents is small.",
                "This is explained by the fact that in these cases only a very few agents have relevant informations in their possession, and that they will need to communicate a lot in order to come up with a common view of the situation.",
                "When the number of agents increases, this knowledge is distributed over more agents which need shorter discussions to get to mutual consistency.",
                "As a consequence, the relative gain in efficiency of using RHE appears to be better when the number of agents is small: when it is high, they will hardly argue anyway.",
                "Finally, it is worth noticing that the standard deviation for these experiments is rather high, which means that the conversation do not converge to any stereotypic pattern. 6.",
                "CONCLUSION This paper has investigated the properties of a multiagent system where each (distributed) agent locally perceives its environment, and tries to reach consistency with other agents despite severe communication restrictions.",
                "In particular we have exhibited conditions allowing convergence, and experimentally investigated a typical situation where those conditions cannot hold.",
                "There are many possible extensions to this work, the first being to further investigate the properties of different global protocols belonging to the class we identified, and their influence on the outcome.",
                "There are in particular many heuristics, highly dependent on the context of the study, that could intuitively yield interesting results (in our study, selecting the recipient on the basis of what can be inferred from his observed actions could be such a heuristic).",
                "One obvious candidate for longer term issues concern the relaxation of the assumption of perfect sensing. 7.",
                "REFERENCES [1] G. Bourgne, N. Maudet, and S. Pinson.",
                "When agents communicate hypotheses in critical situations.",
                "In Proceedings of DALT-2006, May 2006. [2] P. Harvey, C. F. Chang, and A. Ghose.",
                "Support-based distributed search: a new approach for multiagent constraint processing.",
                "In Proceedings of AAMAS06, 2006. [3] H. Jung and M. Tambe.",
                "Argumentation as distributed constraint satisfaction: Applications and results.",
                "In Proceedings of AGENTS01, 2001. [4] N. C. Karunatillake and N. R. Jennings.",
                "Is it worth arguing?",
                "In Proceedings of ArgMAS 2004, 2004. [5] S. Onta˜n´on and E. Plaza.",
                "Arguments and counterexamples in case-based joint deliberation.",
                "In Proceedings of ArgMAS-2006, May 2006. [6] D. Poole.",
                "Explanation and prediction: An architecture for default and abductive reasoning.",
                "Computational Intelligence, 5(2):97-110, 1989. [7] I. Rahwan, S. D. Ramchurn, N. R. Jennings, P. McBurney, S. Parsons, and L. Sonenberg.",
                "Argumention-based negotiation.",
                "The Knowledge Engineering Review, 4(18):345-375, 2003. [8] N. Roos, A. ten Tije, and C. Witteveen.",
                "A protocol for multi-agent diagnosis with spatially distributed knowledge.",
                "In Proceedings of AAMAS03, 2003. [9] N. Roos, A. ten Tije, and C. Witteveen.",
                "Reaching diagnostic agreement in multiagent diagnosis.",
                "In Proceedings of AAMAS04, 2004. [10] T. Takahashi, Y. Kaneda, and N. Ito.",
                "Preliminary study - using robocuprescue simulations for disasters prevention.",
                "In Proceedings of SRMED2004, 2004.",
                "The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 1005"
            ],
            "original_annotated_samples": [
                "A <br>context request step</br> is then added to the global protocol."
            ],
            "translated_annotated_samples": [
                "Se añade entonces un <br>paso de solicitud de contexto</br> al protocolo global."
            ],
            "translated_text": "Refinamiento de hipótesis bajo restricciones de comunicación topológica ∗ Gauvain Bourgne, Gael Hette, Nicolas Maudet y Suzanne Pinson LAMSADE, Univ. Investigamos las propiedades de un sistema multiagente donde cada agente (distribuido) percibe localmente su entorno. Tras la percepción de un evento inesperado, cada agente calcula localmente su hipótesis favorita e intenta propagarla a otros agentes, intercambiando hipótesis y argumentos de apoyo (observaciones). Sin embargo, también asumimos que las oportunidades de comunicación están severamente limitadas y cambian dinámicamente. En este artículo, investigamos principalmente la convergencia de dichos sistemas hacia la consistencia global. Primero demostramos que (para una amplia clase de protocolos que definiremos), las restricciones de comunicación inducidas por la topología no impedirán la convergencia del sistema, bajo la condición de que la dinámica del sistema garantice que ningún agente quedará aislado para siempre, y que los agentes tengan tiempo ilimitado para la computación y el intercambio de argumentos. Dado que esta suposición no se puede hacer en la mayoría de las situaciones, establecimos un marco experimental con el objetivo de comparar la eficiencia y efectividad relativa de diferentes protocolos de interacción para el intercambio de hipótesis. Estudiamos una situación crítica que implica a varios agentes que intentan escapar de un edificio en llamas. Los resultados reportados aquí proporcionan algunas ideas sobre el diseño de un protocolo óptimo para el refinamiento de hipótesis en este contexto. Categorías y Descriptores de Asignaturas I.2.11 [Inteligencia Artificial]: Inteligencia Artificial Distribuida-Sistemas Multiagente Términos Generales Teoría, Experimentación 1. INTRODUCCIÓN Consideramos un sistema multiagente donde cada agente (distribuido) percibe localmente su entorno, y asumimos que ocurre un evento inesperado en ese sistema. Si cada agente calcula solo localmente su hipótesis preferida, es natural asumir que los agentes buscarán coordinar y refinar sus hipótesis confrontando sus observaciones con otros agentes. Si, además, las oportunidades de comunicación están severamente limitadas (por ejemplo, los agentes solo pueden comunicarse cuando están lo suficientemente cerca de otro agente) y cambian dinámicamente (por ejemplo, los agentes pueden cambiar sus ubicaciones), se vuelve crucial diseñar cuidadosamente protocolos que permitan a los agentes converger hacia algún estado deseado de consistencia global. En este documento presentamos algunas condiciones suficientes sobre la dinámica del sistema y sobre las estructuras de protocolo/estrategia que permiten garantizar esa propiedad, y estudiamos experimentalmente algunos contextos donde (algunas de) estas suposiciones se relajan. Si bien los problemas de diagnóstico son uno de los clásicos venerables en la tradición de la IA, sus contrapartes multiagentes han atraído atención mucho más recientemente. Roos y sus colegas [8, 9] en particular estudian una situación en la que un número de entidades distribuidas intentan llegar a un diagnóstico global satisfactorio de todo el sistema. Ellos muestran en particular que el número de mensajes necesarios para establecer este diagnóstico global está destinado a ser prohibitivo, a menos que la comunicación se mejore con algún protocolo adecuado. Sin embargo, no imponen restricciones a las opciones de comunicación de los agentes, ni asumen que el sistema es dinámico. Los beneficios de mejorar la comunicación con información de apoyo para hacer que la convergencia a un estado global deseado de un sistema sea más eficiente, a menudo se ha planteado en la literatura. Esta es, por ejemplo, una de las ideas principales que subyacen al enfoque de negociación basado en argumentos [7], donde el estado deseado es un compromiso entre agentes con preferencias conflictivas. Sin embargo, muchos de estos trabajos parten del supuesto de que este enfoque es beneficioso para comenzar y estudian los aspectos técnicos del problema (o en su lugar enfatizan otras ventajas de utilizar la argumentación). Excepciones notables son las obras de [3, 4, 2, 5], que estudiaron en contextos diferentes al nuestro la eficiencia de la argumentación. El resto del documento es el siguiente. La Sección 2 especifica los elementos básicos de nuestro modelo, y la Sección 3 continúa presentando los diferentes protocolos y estrategias utilizados por los agentes para intercambiar hipótesis y observaciones. Ponemos especial atención en enfatizar claramente las condiciones de la dinámica del sistema y los protocolos/estrategias que se explotarán en el resto del documento. La sección 4 detalla uno de los principales resultados del artículo, a saber, el hecho de que bajo las condiciones mencionadas, las restricciones que imponemos en la topología no impedirán la convergencia del sistema hacia la consistencia global, siempre y cuando ningún agente se pierda completamente para siempre en el sistema, y se permita un tiempo ilimitado para la computación y el intercambio de argumentos. Si bien las condiciones en los protocolos y estrategias son bastante suaves, también es claro que estos requisitos del sistema parecen mucho más problemáticos, incluso francamente poco realistas en situaciones críticas donde se abogan precisamente por enfoques distribuidos. Para obtener una imagen más clara de la situación inducida cuando el tiempo es un factor crítico, hemos establecido un marco experimental que presentamos y discutimos en la Sección 5. La situación crítica implica a varios agentes que intentan escapar de un edificio en llamas. Los resultados reportados aquí muestran que la efectividad del intercambio de argumentos depende crucialmente de la naturaleza del edificio, y proporcionan algunas ideas sobre el diseño de un protocolo óptimo para el refinamiento de hipótesis en este contexto. CONCEPTOS BÁSICOS Comenzamos definiendo los elementos básicos de nuestro sistema. Deje que O sea el conjunto (potencialmente infinito) de observaciones posibles. Suponemos que los sensores de nuestros agentes son perfectos, por lo tanto, las observaciones son seguras. Sea H el conjunto de hipótesis, incierto y revisable. Sea Cons(h, O) la relación de consistencia, una relación binaria entre una hipótesis h ∈ H y un conjunto de observaciones O ⊆ O. En la mayoría de los casos, Cons se referirá a la relación de consistencia clásica, sin embargo, podemos sobrecargar su significado y añadir algunas propiedades adicionales a esa relación (en cuyo caso lo mencionaremos). El entorno puede incluir cierta dinámica y cambiar con el transcurso del tiempo. Definimos a continuación secuencias de puntos temporales para tratar con ello: Definición 1 (Secuencia de puntos temporales). Una secuencia de puntos temporales t1, t2, . . . , tn de t es un conjunto ordenado de puntos temporales t1, t2, . . . , tn tal que t1 ≥ t y ∀i ∈ [1, n − 1], ti+1 ≥ ti. Tomamos un sistema poblado por n agentes a1, . . . , an. Cada agente se define como una tupla F, Oi, hi, donde: • F, el conjunto de hechos, conocimiento común a todos los agentes. • Oi ∈ 2O, el conjunto de observaciones realizadas por el agente hasta el momento. Suponemos una memoria perfecta, por lo tanto, este conjunto crece de forma monótona. • hi ∈ H, la hipótesis favorita del agente. Una noción clave que rige la formación de hipótesis es la de consistencia, definida a continuación: Definición 2 (Consistencia). Decimos que: • Un agente es consistente (Cons(ai)) si y solo si Cons(hi, Oi) (es decir, su hipótesis es consistente con su conjunto de observaciones). • Un agente ai es consistente con un agente compañero aj si y solo si Cons(ai) y Cons(hi, Oj) (es decir, este agente es consistente y su hipótesis puede explicar el conjunto de observaciones del otro agente). • Dos agentes ai y aj son mutuamente consistentes (MCons(ai, aj)) si y solo si Cons(ai, aj) y Cons(aj, ai). • Un sistema es consistente si y solo si para todo (i, j) ∈ [1, n]2 se cumple que MCons(ai, aj). Para garantizar su consistencia, cada agente está equipado con una maquinaria de razonamiento abstracto que llamaremos la función de explicación Eh. Esta función (determinística) toma un conjunto de observaciones y devuelve una única hipótesis preferida (2O → H). Suponemos que h = Eh(O) para ser consistente con O por definición de Eh, por lo que usar esta función en su conjunto de observaciones para determinar su hipótesis favorita es una forma segura para que el agente logre consistencia. Sin embargo, cabe destacar que una hipótesis no necesita ser generada por Eh para ser consistente con un conjunto de observaciones. Como ejemplo concreto de tal función, y una de las principales inspiraciones de este trabajo, se puede citar el sistema de razonamiento Theorist [6], siempre y cuando esté acoplado con un filtro que seleccione una teoría preferida entre las inicialmente seleccionadas por Theorist. También hay que tener en cuenta que hi solo puede ser modificado como consecuencia de la aplicación de Eh. Nos referimos a esto como la autonomía del agente: ningún otro agente puede imponer directamente una hipótesis dada a un agente. Como consecuencia, solo una nueva observación (ya sea una nueva percepción o una observación comunicada por otro agente) puede resultar en una modificación de su hipótesis preferida hi (pero no necesariamente, por supuesto). Finalmente definimos una propiedad del sistema que utilizaremos en el resto del artículo: Definición 3 (Percepciones Acotadas). Un sistema implica una percepción limitada para los agentes si y solo si existe un n0 tal que para todo t, la unión de N observaciones realizadas por los agentes es menor o igual a n0. (Es decir, el número de observaciones a realizar por los agentes en el sistema no es infinito.) Ahora necesitamos ver cómo evolucionarán e interactuarán estos agentes en su entorno. En nuestro contexto, los agentes evolucionan en un entorno dinámico, y asumimos clásicamente el siguiente ciclo del sistema: 1. Dinámica del entorno: el entorno evoluciona de acuerdo con las reglas definidas de la dinámica del sistema. 2. Paso de percepción: los agentes obtienen percepciones del entorno. Estas percepciones suelen ser parciales (por ejemplo, el agente solo puede ver una parte de un mapa). 3. Paso de razonamiento: los agentes comparan la percepción con las predicciones, buscan explicaciones para las diferencias (potenciales), refinan su hipótesis, y sacan nuevas conclusiones. 4. Paso de comunicación: los agentes pueden comunicar hipótesis y observaciones con otros agentes a través de un protocolo definido. Cualquier agente solo puede estar involucrado en una comunicación con otro agente en el paso 5. Paso de acción: los agentes realizan un razonamiento práctico utilizando los modelos obtenidos de los pasos anteriores y seleccionan una acción. Ellos pueden modificar el entorno ejecutándolo. La comunicación de los agentes estará aún más restringida por consideraciones topológicas. En un momento dado, un agente solo podrá comunicarse con un número de vecinos. Sus conexiones con estos otros agentes pueden The Sixth Intl. La Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) evoluciona con su situación en el entorno. Normalmente, un agente solo puede comunicarse con agentes que puede percibir, pero se podría imaginar la evolución de restricciones topológicas en la comunicación basadas en una red de comunicaciones entre agentes donde los enlaces no siempre están activos. En nuestro sistema, los agentes podrán comunicarse entre sí. Sin embargo, debido a las restricciones topológicas mencionadas anteriormente, no podrán comunicarse con ningún agente en ningún momento. Con quién puede comunicarse un agente se definirá dinámicamente (por ejemplo, esto puede ser consecuencia de que los agentes estén lo suficientemente cerca para ponerse en contacto). Denotaremos de forma abstracta por C(ai, aj, t) la propiedad de comunicación, es decir, el hecho de que los agentes ai y aj puedan comunicarse en el tiempo t (nota que se asume que esta relación es simétrica, pero por supuesto no transitiva). Ahora estamos en posición de definir dos propiedades esenciales de nuestro sistema. Definición 4 (Camino Temporal). Existe un camino de comunicación temporal en el horizonte tf (denotado Ltf (aI, aJ)) entre ai y aj si y solo si existe una secuencia de puntos temporales t1, t2, ..., tn desde tf y una secuencia de agentes k1, k2, ..., kn tal que (i) C(aI, ak1, t1), (ii) C(akn, aJ, tn+1), (iii) ∀i ∈ [1, n], C(aki, aki+1, ti). Intuitivamente, lo que esta propiedad dice es que es posible encontrar un camino temporal en el futuro que permitiría vincular al agente ai y aj a través de una secuencia de agentes intermedios. Ten en cuenta que los puntos temporales no necesariamente son sucesivos, y que la secuencia de agentes puede involucrar a los mismos agentes varias veces. Definición 5 (Conexidad Temporal). Un sistema es temporalmente conexo si y solo si ∀t ∀(i, j)∈[1, n]2 Lt(ai, aj). En resumen, un sistema temporalmente conexo garantiza que cualquier agente podrá comunicarse con cualquier otro agente, sin importar cuánto tiempo pueda llevar hacerlo, en cualquier momento. Dicho de otra manera, nunca sucede que un agente esté aislado para siempre de otro agente del sistema. A continuación discutiremos en detalle cómo la comunicación tiene lugar concretamente en nuestro sistema. Recuerda que en este documento, solo consideramos el caso de intercambios bilaterales (un agente solo puede hablar con otro agente) y también asumimos que cualquier agente solo puede participar en un intercambio en una ronda dada. 3. PROTOCOLOS Y ESTRATEGIAS En esta sección, discutimos los requisitos de los protocolos de interacción que rigen el intercambio de mensajes entre agentes, y proporcionamos algunos ejemplos de la implementación de dichos protocolos. Para aclarar la presentación, distinguimos dos niveles: el nivel local, que se ocupa de la regulación de los intercambios bilaterales; y el nivel global, que regula principalmente la forma en que los agentes pueden participar realmente en una conversación. En cada nivel, separamos lo que está especificado por el protocolo y lo que se deja a las estrategias de los agentes. Protocolos y estrategias locales Comenzamos inspeccionando los protocolos y estrategias locales que regularán la comunicación entre los agentes del sistema. Al limitarnos a la comunicación bilateral, estos protocolos simplemente implicarán a dos agentes. Dicho protocolo tendrá que cumplir con un requisito básico para ser satisfactorio: consistencia (CONS) - un protocolo local debe garantizar la consistencia mutua de los agentes al finalizar (lo que implica, por supuesto, la finalización). Figura 1: Un Protocolo de Intercambio de Hipótesis [1] Un ejemplo de dicho protocolo es el protocolo descrito en [1] que se muestra en la Fig. 1. Para ilustrar aún más cómo dicho protocolo puede ser utilizado por agentes, proporcionamos algunos detalles sobre una posible estrategia: al recibir una hipótesis h1 (proponer(h1) o contra-proponer(h1)) de a1, el agente a2 se encuentra en el estado 2 y tiene las siguientes respuestas posibles: contraejemplo (si el agente conoce un ejemplo que contradice la hipótesis, o no está explicado por esta hipótesis), desafío (si el agente carece de evidencia para aceptar esta hipótesis), contra-proponer (si el agente está de acuerdo con la hipótesis pero prefiere otra), o aceptar (si es tan buena como su hipótesis favorita). Esta estrategia garantiza, entre otras propiedades, la eventual consistencia lógica mutua de los agentes involucrados [1]. Protocolo global El protocolo global regula la forma en que se iniciarán los intercambios bilaterales entre agentes. En cada turno, los agentes enviarán simultáneamente una solicitud ponderada para comunicarse con otros agentes. Este peso es un valor que mide la disposición de los agentes para conversar con el agente objetivo (en la práctica, esto puede basarse en diferentes heurísticas, pero haremos algunas suposiciones sobre las estrategias de los agentes, ver más abajo). Enviar una solicitud de este tipo es una especie de compromiso condicional para el agente. Un agente que envía una solicitud ponderada se compromete a entablar una conversación con el objetivo si no recibe y acepta otra solicitud por sí mismo. Una vez que se hayan recibido todas las solicitudes, cada agente responde con un aceptar o un rechazar. Al responder con un aceptar, un agente se compromete plenamente a participar en la conversación con el remitente. Por lo tanto, solo puede enviar una aceptación en una ronda dada, ya que un agente solo puede participar en una conversación por paso de tiempo. Cuando se hayan recibido todas las respuestas, cada agente que reciba una aceptación puede iniciar una conversación utilizando el protocolo local o enviar una cancelación si ha aceptado otra solicitud. Al final de todos los intercambios bilaterales, los agentes involucrados en la conversación son descartados del protocolo. Entonces cada uno de los agentes restantes reenvía una solicitud y el proceso se repite hasta que no se envíen más solicitudes. Estrategia global Ahora definimos cuatro requisitos para las estrategias utilizadas por los agentes, dependiendo de su rol en el protocolo: dos se refieren al rol del solicitante (cómo decidir quién es el 1000 The Sixth Intl. La Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) ¿con qué agente desea comunicarse? Los otros dos con el rol de respondedor (¿cómo decidir qué solicitud de comunicación aceptar o no?). • Disposición para resolver inconsistencias (SOLVE): los agentes desean comunicarse con cualquier otro agente a menos que sepan que son mutuamente consistentes. • Enfoque en resolver inconsistencias (FOCUS): los agentes no solicitan comunicarse con un agente con el que saben que son mutuamente consistentes. • Disposición para comunicarse (COMM): los agentes no pueden rechazar una solicitud de comunicación ponderada, a menos que acaben de recibir o enviar una solicitud con un peso mayor. • Compromiso con la solicitud de comunicación (REQU): los agentes no pueden aceptar una solicitud de comunicación ponderada si ellos mismos han enviado una solicitud de comunicación con un peso mayor. Por lo tanto, no cancelarán su solicitud a menos que hayan recibido una solicitud comunicacional con mayor peso. Ahora la estructura del protocolo, junto con las propiedades COMM+REQU, garantizan que una solicitud solo puede ser rechazada si su agente objetivo se involucra en comunicación con otro agente. Supongamos de hecho que el agente ai quiere comunicarse con aj enviando una solicitud con peso w. COMM garantiza que un agente que reciba una solicitud ponderada aceptará esta comunicación, aceptará una comunicación con un peso mayor o esperará la respuesta a una solicitud con un peso mayor. Esto asegura que la solicitud con peso máximo será aceptada y no cancelada (ya que REQU asegura que un agente que envía una solicitud solo puede cancelarla si acepta otra solicitud con un peso mayor). Por lo tanto, al menos dos agentes participarán en una conversación por ronda del protocolo global. Como el protocolo asegura que ai puede reenviar su solicitud mientras aj no está ocupado en una conversación, llegará un momento en el que aj deberá participar en una conversación, ya sea con ai u otro agente. Estos requisitos se refieren al envío y aceptación de solicitudes, pero los agentes también necesitan alguna estrategia de atribución de peso. Describimos a continuación una estrategia altruista, utilizada en nuestros experimentos. Siendo cooperativo, un agente puede querer conocer más los deseos de comunicación de otros agentes para mejorar la asignación general de intercambios a los agentes. Se añade entonces un <br>paso de solicitud de contexto</br> al protocolo global. Antes de enviar su solicitud ponderada elegida, los agentes asignan un peso a todos los agentes con los que están dispuestos a comunicarse, de acuerdo con algunos factores internos. En el caso más simple, este peso será 1 para todos los agentes con los que el agente no esté seguro de ser mutuamente consistentes (garantizando SOLVE), sin considerar a otros agentes para la comunicación (garantizando FOCUS). El agente luego envía una solicitud de contexto a todos los agentes con los que se considera la comunicación. Esta solicitud también proporciona información sobre el remitente (lista de comunicaciones consideradas junto con su peso). Después de recibir todas las solicitudes de contexto, los agentes responderán con un rechazo si ya están ocupados en una conversación (en cuyo caso, el agente solicitante no considerará comunicarse con ellos en este turno), o con una información que brinde al solicitante información sobre las solicitudes que ha enviado y recibido. Cuando se hayan recibido todas las respuestas, cada agente puede calcular el peso de todas las solicitudes que le conciernen. Lo hace restando del peso de su solicitud el peso de todas las solicitudes relacionadas con él o su objetivo (es decir, el peso final de la solicitud de ai a aj es Wi,j = wi,j + wj,i - ( Σ k∈R(i)-{j} wi,k + Σ k∈S(i)-{j} wk,i + Σ k∈R(j)-{i} wj,k + Σ k∈S(j)-{i} wk,j) donde wi,j es el peso de la solicitud de ai a aj, R(i) es el conjunto de índices de agentes que han recibido una solicitud de ai y S(i) es el conjunto de índices de agentes que han enviado una solicitud a ai). Luego envía finalmente una solicitud ponderada a los agentes que maximizan este peso (o esperan una solicitud) según lo descrito en el protocolo global. 4. (CONDICIONAL) CONVERGENCIA HACIA LA COHERENCIA GLOBAL En esta sección mostraremos que los requisitos relacionados con los protocolos y estrategias recién discutidos serán suficientes para garantizar que el sistema eventualmente convergerá hacia la coherencia global, bajo ciertas condiciones. Primero demostramos que, si dos agentes no son mutuamente consistentes en algún momento, entonces necesariamente habrá un momento en el futuro en el que un agente aprenderá una nueva observación, ya sea porque es nueva para el sistema, o al aprenderla de otro agente. Lema 1. Sea S un sistema poblado por n agentes a1, a2, ..., an, temporalmente conectados e involucrando percepciones limitadas para estos agentes. Sea n1 la suma de las cardinalidades de la intersección de los conjuntos de observaciones emparejados. (n1 = P (i,j)∈[1,n]2 |Oi ∩ Oj|) Sea n2 la cardinalidad de la unión de todos los conjuntos de observaciones de los agentes. (n2 = | ∪N i=1 Oi|). Si ¬MCons(ai, aj) en el tiempo t0, necesariamente existe un tiempo t > t0 tal que ya sea n1 o n2 aumentarán. Prueba. Supongamos que exista un tiempo t0 y unos índices (i, j) tal que ¬MCons(ai, aj). Utilizaremos mt0 = P (k,l)∈[1,n]2 εComm(ak, al, t0) donde εComm(ak, al, t0) = 1 si ak y al han comunicado al menos una vez desde t0, y 0 en caso contrario. La conexidad temporal garantiza que existen t1, ..., tm+1 y k1, ..., km tal que. C(ai, ak1 , t1), C(akm , aj, tm+1), y ∀p ∈ [1, m], C(akp , akp+1 , tp). Claramente, si MCons(ai, ak1), MCons(akm, aj) y ∀p, MCons(akp, akp+1), tenemos MCons(ai, aj) lo cual contradice nuestra hipótesis (siendo MCons transitivo, MCons(ai, ak1)∧MCons(ak1, ak2) implica que MCons(ai, ak2) y así sucesivamente hasta MCons(ai, akm)∧MCons(akm, aj) lo cual implica MCons(ai, aj)). Al menos dos agentes son necesariamente inconsistentes (¬MCons(ai, ak1), o ¬MCons(akm, aj), o ∃p0 t.q. ¬MCons(akp0, akp0+1)). Que ak y al sean estos dos vecinos en un momento t > t0 1. La propiedad SOLVE asegura que ya sea ak o al enviará una solicitud de comunicación al otro agente en el tiempo t. Como se mostró anteriormente, esto a su vez garantiza que al menos uno de estos agentes estará involucrado en una comunicación. Entonces hay dos posibilidades: (caso i) ak y al se comunican en el tiempo t. En este caso, sabemos que ¬MCons(ak, al). Esto y la propiedad CONS aseguran que al menos uno de los agentes debe cambiar su 1. Estrictamente hablando, la transitividad de MCons solo asegura que ak y al son inconsistentes en un tiempo t ≥ t0 que puede ser diferente del tiempo t en el que pueden comunicarse. Pero si se vuelven consistentes entre t y t (o inconsistentes entre t y t), significa que al menos uno de ellos ha cambiado su hipótesis entre t y t, es decir, después de t0. Podemos entonces aplicar el razonamiento del caso iib. El Sexto Internacional. La Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 1001 hipótesis, lo cual a su vez, dado que los agentes son autónomos, implica al menos un intercambio de observación. Pero entonces |Ok ∩Ol| está destinado a aumentar: n1(t) > n1(t0). (caso ii) ak se comunica con ap en el tiempo t. Entonces tenemos de nuevo dos posibilidades: (caso iia) ak y ap no se comunicaron desde t0. Pero luego εComm(ak, ap, t0) tenía valor 0 y toma valor 1. Por lo tanto, mt0 aumenta. (caso iib) ak y ap se comunicaron en algún momento t0 > t0. La propiedad CONS del protocolo asegura que MCons(ak, ap) en ese momento. Ahora el hecho de que se comuniquen y se ENFOQUEN implica que al menos uno de ellos cambió su hipótesis en el ínterin. El hecho de que los agentes sean autónomos implica a su vez que una nueva observación (percibida o recibida de otro agente) necesariamente provocó este cambio. El último caso garantizaría la existencia de un tiempo t > t0 y un agente aq tal que |Op ∩ Oq| o |Ok ∩ Oq| aumenten en 1 en ese momento (lo que implica que n1(t) > n1(t0)). El caso anterior significa que el agente obtiene una nueva percepción en el tiempo t. Si esa observación era desconocida en el sistema antes, entonces n2(t) > n2(t0). Si algún agente aq ya conocía esta observación antes, entonces tanto Op ∩ Oq como Ok ∩ Oq aumentan en 1 en el tiempo t (lo que implica que n1(t) > n1(t0)). Por lo tanto, ¬MCons(ai, aj) en el tiempo t0 garantiza que, o bien: −∃t > t0 t.q. n1(t ) > n1(t0); o −∃t > t0 t.q. n2(t ) > n2(t0); o −∃t > t0 t.q. mt0 aumenta en 1 en el tiempo t. Al iterar el razonamiento con t (pero manteniendo t0 como la referencia de tiempo para mt0), podemos eliminar el tercer caso (mt0 es un entero y está limitado por n2, lo que significa que después de un máximo de n2 iteraciones, necesariamente estaremos en uno de los otros dos casos). Como resultado, hemos demostrado que si ¬MCons(ai, aj) en el tiempo t0, necesariamente habrá un tiempo t tal que ya sea n1 o n2 aumentarán. Teorema 1 (Consistencia global). Sea S un sistema poblado por n agentes a1, a2, ..., an, temporalmente conectados e involucrando percepciones limitadas para estos agentes. Sea Cons(ai, aj) una propiedad de consistencia transitiva. Entonces, cualquier protocolo y estrategias que cumplan con las propiedades CONS, SOLVE, FOCUS, COMM y REQU garantizan que el sistema convergerá hacia la consistencia global. Prueba. Por el bien de la contradicción, asumamos que ∃I, J ∈ [1, N] tal que ∀t, ∃t0 > t, tal que ¬Cons(aI , aJ , t0). Usando el lema, esto implica que ∃t > t0 tal que n1(t) > n1(t0) o n2(t) > n2(t0). Pero podemos aplicar el mismo razonamiento tomando t = t, lo que nos daría t1 > t > t0 tal que ¬Cons(aI , aJ , t1), lo que nos da t > t1 tal que n1(t) > n1(t1) o n2(t) > n2(t1). Mediante iteraciones sucesivas podemos construir una secuencia t0, t1, ..., tn, que puede dividirse en dos subsecuencias t0, t1, ...tn y t0, t1, ..., tn tal que n1(t0) < n1(t1) < ... < n1(tn) y n2(t0) < n2(t1) < ... < n2(tn). Una de estas subsecuencias tiene que ser infinita. Sin embargo, n1(ti) y n2(ti) son estrictamente crecientes, enteros y acotados, lo que implica que ambos son finitos. Contradicción. Lo que el resultado anterior muestra esencialmente es que, en un sistema donde ningún agente estará aislado del resto de los agentes para siempre, solo se necesitan suposiciones muy leves sobre los protocolos y estrategias utilizados por los agentes para garantizar la convergencia hacia la consistencia del sistema en una cantidad finita de tiempo (aunque podría llevar mucho tiempo). Desafortunadamente, en muchas situaciones críticas, no será posible asumir esta conexión temporal. Dado que enfoques distribuidos como el abogado en este documento suelen presentarse como una buena manera de abordar problemas de confiabilidad o problemas de dependencia de un centro que son de suma importancia en estas aplicaciones críticas, ciertamente resulta interesante explorar más a fondo cómo se comportaría un sistema de este tipo cuando relajamos esta suposición. ESTUDIO EXPERIMENTAL Este experimento implica agentes tratando de escapar de un edificio en llamas. El entorno se describe como una cuadrícula espacial con un conjunto de paredes y (afortunadamente) algunas salidas. El tiempo y el espacio se consideran discretos. El tiempo se divide en rondas. Los agentes se localizan por su posición en la cuadrícula espacial. Estos agentes pueden moverse y comunicarse con otros agentes. En una ronda, un agente puede moverse una celda en cualquiera de las cuatro direcciones cardinales, siempre y cuando no esté bloqueado por una pared. En esta aplicación, los agentes se comunican con cualquier otro agente (pero, recuerda, solo uno) siempre y cuando este agente esté a la vista y aún no hayan intercambiado su hipótesis actual favorita. De repente, se desata un incendio en estas instalaciones. A partir de este momento, el fuego se propaga. En cada ronda, en cada caso donde haya fuego, el fuego se propaga en las cuatro direcciones. Sin embargo, el fuego no puede propagarse a través de una pared. Si el fuego se propaga en un caso donde un agente está posicionado, ese agente se quema y se considera muerto. Por supuesto, ya no puede moverse ni comunicarse. Si un agente llega a una salida, se considera que está a salvo y ya no puede ser quemado. Los agentes conocen el entorno y las reglas que rigen la dinámica de este entorno, es decir, conocen el mapa así como las reglas de propagación del fuego previamente descritas. También perciben este entorno localmente, pero no pueden ver más allá de 3 casos en cualquier dirección. Las paredes también bloquean la línea de visión, impidiendo que los agentes vean detrás de ellas. Dentro de su campo de visión, pueden ver a otros agentes y si los casos que ven están en llamas. Todas estas percepciones están memorizadas. Mostramos ahora cómo se instancia el marco abstracto presentado en el documento. • O = {Fire(x, y, t), NoFire(x, y, t), Agent(ai, x, y, t)} Las observaciones pueden ser positivas (o ∈ P(O) si ∃h ∈ H tal que h |= o) o negativas (o ∈ N(O) si ∃h ∈ H tal que h |= ¬o). • H={FireOrigin(x1, y1, t1)∧...∧FireOrigin(xl, yl, tl)} Las hipótesis son conjunciones de Orígenes de Fuego. • La relación de consistencia Cons(h, O) satisface: - coherencia: ∀o ∈ N(O), h |= ¬o. - completitud: ∀o ∈ P(O), h |= o. - minimalidad: Para todo h ∈ H, si h es coherente y completo para O, entonces h es preferido a h de acuerdo con la relación de preferencia (h ≤p h). Selecciona primero el número mínimo de orígenes, luego el más reciente (estrategia menos preemptiva [6]), y luego utiliza un ranking fijo arbitrario para discriminar ex-aequo. La relación resultante es un orden total, por lo tanto, la minimalidad implica que habrá un único h tal que Cons(O, h) para un O dado. Esto a su vez significa que MCons(ai, aj) si y solo si Cons(ai), Cons(aj) y hi = hj. Esta relación es entonces transitiva y simétrica. 1002 El Sexto Internacional. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) • Eh toma O como argumento y devuelve min≤p de la hipótesis coherente y completa para O 5.1 Evaluación Experimental Clásicamente evaluaremos la efectividad y eficiencia de diferentes protocolos de interacción (ver, por ejemplo, [3, 4]). La efectividad de un protocolo se determinará por la proporción de agentes que sobreviven al incendio respecto al número inicial de agentes involucrados en el experimento. Si este valor es alto, el protocolo ha sido efectivo para propagar la información y/o para que los agentes refinen sus hipótesis y determinen la mejor manera de salir. Eficiencia de un protocolo. Por lo general, el uso de información de apoyo implicará una sobrecarga de comunicación. Aquí asumiremos que la eficiencia de un protocolo dado está caracterizada por el flujo de datos inducido por este protocolo. En este documento solo discutiremos este aspecto con respecto a los protocolos locales. La medida principal que utilizaremos aquí es el tamaño total promedio de los mensajes intercambiados por los agentes por intercambio (teniendo en cuenta tanto el número de mensajes como el tamaño real de los mensajes, ya que podría ser que los mensajes resulten ser muy grandes, conteniendo por ejemplo un gran número de observaciones, lo que podría contrarrestar un bajo número de mensajes). 5.2 Configuraciones Experimentales Las configuraciones experimentales elegidas son las siguientes: • Topología ambiental: El rendimiento de la propagación de la información está altamente condicionado por la topología del entorno. Las habilidades de percepción de los agentes dependen de la apertura del entorno. Con un gran número de paredes, las percepciones de los agentes están limitadas, al igual que el número de posibles comunicaciones entre agentes, mientras que un entorno abierto proporcionará posibilidades óptimas de percepción y propagación de información. Por lo tanto, proponemos un índice topológico (ver abajo) como base común para caracterizar los entornos (mapas) utilizados durante las experimentaciones. El índice topológico (TI) es la proporción entre el número de celdas que pueden ser percibidas por los agentes sumadas desde todas las posiciones posibles, dividido por el número de celdas que serían percibidas desde las mismas posiciones pero sin paredes. (Cuanto más cercano a 1, más abierto es el entorno). También utilizaremos dos medidas adicionales, más clásicas [10]: la longitud del camino característico (CPL) y el coeficiente de agrupamiento (CC). • Número de agentes: la propagación de la información también depende del número inicial de agentes involucrados durante una experimentación. Por ejemplo, cuantos más agentes haya, más potenciales comunicaciones existen. Esto significa que habrá más potencial de propagación, pero también que la restricción de intercambio bilateral será más crucial. 3 El CPL es la mediana de las medias de las longitudes de los caminos más cortos que conectan cada nodo con todos los demás nodos. 4 caracterizando el grado de aislamiento de una región de un entorno en términos de accesibilidad (número de caminos aún utilizables para llegar a esta región). Mapa T.I. (%) C.P.L. C.C. 69-1 69,23 4,5 0,69 69-2 68,88 4,38 0,65 69-3 69,80 4,25 0,67 53-1 53,19 5,6 0,59 53-2 53,53 6,38 0,54 53-3 53,92 6,08 0,61 38-1 38,56 8,19 0,50 38-2 38,56 7,3 0,50 38-3 38,23 8,13 0,50 Tabla 1: Características Topológicas de los Mapas • Posiciones iniciales de los agentes- Las posiciones iniciales de los agentes tienen una influencia significativa en el comportamiento general de una instancia de nuestro sistema: estar cerca de una salida facilitará (en general) la escapatoria. 5.3 Entornos experimentales Elegimos realizar experimentos en tres índices topológicos muy diferentes (69% para entornos abiertos, 53% para entornos mixtos y 38% para entornos tipo laberinto). Figura 2: Dos mapas (izquierda: IT=69%, derecha IT=38%) Diseñamos tres mapas diferentes para cada índice (la Fig. 2 muestra dos de ellos), conteniendo el mismo número máximo de agentes (máximo 36 agentes) con una densidad máxima de un agente por celda, el mismo número de salidas y un origen de incendio similar (por ejemplo, tiempo y posición de inicio). Los tres mapas diferentes de un índice dado están diseñados de la siguiente manera. El primer plano es un modelo de un piso de un edificio existente. El segundo mapa tiene el mismo perímetro, salidas y origen del fuego que el primero, pero la cantidad y ubicación de las paredes son diferentes (las ubicaciones de las paredes son diseñadas por una heurística que crea paredes de forma aleatoria en la cuadrícula espacial de manera que no se creen habitaciones completamente cerradas y que ninguna salida quede bloqueada). El tercer mapa se caracteriza por un recinto geométrico en el que la ubicación de las paredes también está diseñada con la heurística mencionada anteriormente. La Tabla 1 resume las diferentes medidas topológicas que caracterizan estos mapas diferentes. Vale la pena señalar que los valores confirman la relevancia de TI (los mapas con un alto TI tienen un bajo CPL y un alto CC). Sin embargo, el CPL y el CC permiten refinar aún más la diferencia entre los mapas, por ejemplo, entre 53-1 y 53-2). 5.4 Resultados Experimentales Para cada trío de mapas definidos como se mencionó anteriormente, llevamos a cabo los mismos experimentos. En cada experimento, la sociedad difiere en cuanto a su proporción inicial de agentes involucrados, desde el 1% hasta el 100%. Esta proporción inicial representa el porcentaje de agentes involucrados con respecto al número máximo posible de agentes. Para cada mapa y cada proporción inicial, la Sexta Internacional. En la Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) seleccionamos aleatoriamente 100 ubicaciones iniciales de agentes diferentes. Para cada una de esas ubicaciones diferentes ejecutamos el sistema una vez para cada protocolo de interacción diferente. La efectividad de la comunicación y argumentación El primer experimento que hemos establecido tiene como objetivo probar cuán efectivo es el intercambio de hipótesis (IH), y en particular cómo los aspectos topológicos afectarán esta efectividad. Para hacerlo, hemos calculado la proporción de mejora ofrecida por ese protocolo sobre una situación en la que los agentes simplemente no podían comunicarse (sin comunicación). Para obtener más información sobre en qué medida el intercambio de hipótesis fue realmente crucial, también probamos un protocolo mucho menos elaborado que consistía en intercambios de observaciones simples (OE). Más precisamente, este protocolo requiere que cada agente almacene cualquier observación inesperada que perciba, y los agentes simplemente intercambian sus respectivas listas de observaciones cuando discuten. En este caso, el protocolo local es diferente (nota en particular que no garantiza consistencia mutua), pero el protocolo global permanece igual (con la única excepción de que la motivación de los agentes para comunicarse es sincronizar su lista de observaciones, no sus hipótesis). Si este protocolo es como máximo tan efectivo como HE, tiene la ventaja de ser más eficiente (esto es obvio en cuanto al número de mensajes, que se limitará a 2, menos directo en lo que respecta al tamaño de los mensajes, pero la observación general de que el intercambio de observaciones se puede ver como una versión simplificada del desafío es útil para ver esto). Los resultados de estos experimentos se informan en la Figura 3. Figura 3: Ganancia de la proporción de efectividad comparativa de los protocolos cuando la proporción de agentes aumenta. La primera observación que debe hacerse es que la comunicación mejora la efectividad del proceso, y esta proporción aumenta a medida que el número de agentes crece en el sistema. La segunda lección que aprendemos aquí es que la cercanía relativamente hace que la comunicación sea más efectiva que la falta de comunicación. Los mapas que muestran un T.I. del 38% están constantemente por encima de los otros dos, y el 53% sigue siendo ligeramente pero significativamente mejor que el 69%. Sin embargo, estas curvas también sugieren, quizás sorprendentemente, que HE supera a OE precisamente en aquellas situaciones donde la ganancia de la relación es menos importante (la única diferencia notable ocurre en mapas bastante abiertos donde T.I. es del 69%). Esto se puede explicar de la siguiente manera: cuando un mapa está abierto, los agentes tienen muchos posibles candidatos de explicación, y la argumentación se vuelve útil para discriminar entre ellos. Cuando un mapa es laberíntico, hay menos posibles explicaciones para un evento inesperado. Importancia del Protocolo Global El segundo conjunto de experimentos busca evaluar la importancia del diseño del protocolo global. Probamos nuestro protocolo contra un protocolo de difusión local (LB). La difusión local significa que todos los agentes vecinos percibidos por un agente estarán involucrados en una comunicación con ese agente en una ronda dada, aliviando la restricción de una sola comunicación por agente. Esto nos proporciona un límite superior aproximado sobre la posible ganancia de ratio en el sistema (para un protocolo local dado). Nuevamente, evaluamos la ganancia de la relación inducida por ese LB sobre nuestro HE clásico, para las tres clases diferentes de mapas. Los resultados se informan en la Figura 4. Figura 4: Ganancia de la proporción de transmisión local sobre el intercambio de hipótesis. Tenga en cuenta que la ganancia de la proporción es 0 cuando la proporción de agentes es del 5%, lo cual se explica fácilmente por el hecho de que corresponde a situaciones que involucran solo a dos agentes. Primero observamos que todas las clases de mapas muestran un aumento en la ganancia de la proporción a medida que aumenta el número de agentes: la ganancia alcanza entre el 10 y el 20%, dependiendo de la clase de mapas considerada. Si se compara esto con la mejora reportada en el experimento anterior, parece ser de la misma magnitud. Esto ilustra que el diseño del protocolo global no puede ser ignorado, especialmente cuando la proporción de agentes es alta. Sin embargo, también observamos que las curvas de ganancia de la proporción de efectividad tienen formas muy diferentes en ambos casos: la ganancia inducida por la precisión del protocolo local aumenta muy rápidamente con la proporción de agentes, mientras que la curva es muy suave para el global. Ahora observemos con más cuidado los resultados reportados aquí: la curva correspondiente a una TI del 53% está por encima de la correspondiente al 38%. Esto se debe a que cuanto más abierta sea un mapa, más oportunidades hay de comunicarse con más de un agente (y por lo tanto beneficiarse de la difusión). Sin embargo, también observamos que la curva para el 69% está por debajo de la del 53%. Esto se explica de la siguiente manera: en el caso del 69%, la ganancia potencial en términos de agentes sobrevivientes es mucho menor, porque nuestros protocolos ya ofrecen resultados bastante eficientes de todos modos (alcanzando rápidamente el 90%, ver Fig. 3). Una regla general podría ser que cuando el número de agentes es pequeño, se debe prestar especial atención al local 1004 de la Sexta Internacional. En el caso de que el número de agentes sea pequeño, uno puede utilizar el protocolo de la Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07), mientras que cuando ese número es grande, se debe diseñar cuidadosamente uno global (a menos que el mapa sea tan abierto que el protocolo ya sea casi óptimamente eficiente). La eficiencia de los protocolos. El experimento final reportado aquí se centra en el análisis de la eficiencia de los protocolos. Aquí analizamos el tamaño medio de la totalidad de los mensajes que son intercambiados por agentes (tamaño medio de intercambios, en resumen) utilizando los siguientes protocolos: HE, OE y dos protocolos variantes. El primero es un protocolo de intercambio de hipótesis restringidas (RHE) intermediario. RHE es el siguiente: no implica ningún desafío ni contraoferta, lo que significa que los agentes no pueden cambiar su rol durante el protocolo (esto difiere de RE en ese aspecto). En resumen, RHE permite a un agente agotar las críticas de sus socios, y eventualmente este socio adoptará la hipótesis del agente. Ten en cuenta que esto significa que la autonomía del agente no se conserva aquí (ya que un agente esencialmente aceptará cualquier hipótesis que no pueda socavar), con la esperanza de que la ganancia en eficiencia sea lo suficientemente significativa como para compensar una pérdida en efectividad. El segundo protocolo de variante es un protocolo completo de intercambio de observaciones (COE). COE utiliza los mismos principios que OE, pero incluye además todos los ejemplos críticos negativos (nofire) en el intercambio (dando así todos los ejemplos utilizados como argumentos por el protocolo de intercambio de hipótesis), mejorando así la efectividad. Los resultados para el mapa 69-1 se muestran en la Figura 5. Figura 5: Tamaño medio de los intercambios. Primero podemos observar el hecho de que el orden de los protocolos, desde el menos eficiente hasta el más eficiente, es COE, HE, RHE y luego OE. ÉL siendo más eficiente que COE demuestra que el proceso de argumentación gana eficiencia al seleccionar cuándo es necesario proporcionar ejemplos negativos, los cuales tienen menos impacto que los positivos en nuestro entorno de prueba específico. Sin embargo, al comunicar hipótesis antes de proporcionar observaciones para respaldarla (HE) en lugar de dar directamente las observaciones más cruciales (OE), el proceso de argumentación duplica el tamaño de los intercambios de datos. Es el costo de garantizar la consistencia al final del intercambio (una propiedad que OE no admite). También es significativo el hecho de que el tamaño promedio de los intercambios es ligeramente mayor cuando el número de agentes es pequeño. Esto se explica por el hecho de que en estos casos solo unos pocos agentes tienen información relevante en su posesión, y que necesitarán comunicarse mucho para llegar a un punto de vista común de la situación. Cuando el número de agentes aumenta, este conocimiento se distribuye entre más agentes que necesitan discusiones más cortas para llegar a una consistencia mutua. Como consecuencia, la ganancia relativa en eficiencia de usar RHE parece ser mejor cuando el número de agentes es pequeño: cuando es alto, difícilmente discutirán de todos modos. Finalmente, vale la pena notar que la desviación estándar para estos experimentos es bastante alta, lo que significa que la conversación no converge hacia ningún patrón estereotípico. 6. CONCLUSIÓN Este documento ha investigado las propiedades de un sistema multiagente donde cada agente (distribuido) percibe localmente su entorno e intenta alcanzar consistencia con otros agentes a pesar de severas restricciones de comunicación. En particular, hemos expuesto condiciones que permiten la convergencia e investigado experimentalmente una situación típica donde esas condiciones no pueden cumplirse. Hay muchas posibles extensiones a este trabajo, la primera siendo investigar más a fondo las propiedades de diferentes protocolos globales pertenecientes a la clase que identificamos, y su influencia en el resultado. Existen en particular muchas heurísticas, altamente dependientes del contexto del estudio, que podrían intuitivamente arrojar resultados interesantes (en nuestro estudio, seleccionar al destinatario en función de lo que se pueda inferir de sus acciones observadas podría ser una de esas heurísticas). Un candidato obvio para problemas a largo plazo se refiere a la relajación de la suposición de un sensor perfecto. 7. REFERENCIAS [1] G. Bourgne, N. Maudet y S. Pinson. Cuando los agentes comunican hipótesis en situaciones críticas. En Actas de DALT-2006, mayo de 2006. [2] P. Harvey, C. F. Chang y A. Ghose. Búsqueda distribuida basada en soporte: un nuevo enfoque para el procesamiento de restricciones multiagente. En Actas de AAMAS06, 2006. [3] H. Jung y M. Tambe. Argumentación como satisfacción de restricciones distribuida: Aplicaciones y resultados. En Actas de AGENTS01, 2001. [4] N. C. Karunatillake y N. R. Jennings. ¿Vale la pena discutir? En Actas de ArgMAS 2004, 2004. [5] S. Onta˜n´on y E. Plaza. Argumentos y contraejemplos en la deliberación conjunta basada en casos. En Actas de ArgMAS-2006, mayo de 2006. [6] D. Poole. Explicación y predicción: Una arquitectura para el razonamiento por defecto y abductivo. Inteligencia Computacional, 5(2):97-110, 1989. [7] I. Rahwan, S. D. Ramchurn, N. R. Jennings, P. McBurney, S. Parsons y L. Sonenberg. Negociación basada en argumentos. La revisión de Ingeniería del Conocimiento, 4(18):345-375, 2003. [8] N. Roos, A. ten Tije y C. Witteveen. Un protocolo para el diagnóstico multiagente con conocimiento distribuido espacialmente. En Actas de AAMAS03, 2003. [9] N. Roos, A. ten Tije y C. Witteveen. Alcanzando acuerdo diagnóstico en el diagnóstico multiagente. En Actas de AAMAS04, 2004. [10] T. Takahashi, Y. Kaneda y N. Ito. Estudio preliminar: utilizando simulaciones de RoboCupRescue para la prevención de desastres. En Actas de SRMED2004, 2004. El Sexto Internacional. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 1005 ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "inter-agent communication": {
            "translated_key": "comunicaciones entre agentes",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Hypotheses Refinement under Topological Communication Constraints ∗ Gauvain Bourgne, Gael Hette, Nicolas Maudet, and Suzanne Pinson LAMSADE, Univ.",
                "Paris-Dauphine, France {bourgne,hette,maudet,pinson}@lamsade.dauphine.fr ABSTRACT We investigate the properties of a multiagent system where each (distributed) agent locally perceives its environment.",
                "Upon perception of an unexpected event, each agent locally computes its favoured hypothesis and tries to propagate it to other agents, by exchanging hypotheses and supporting arguments (observations).",
                "However, we further assume that communication opportunities are severely constrained and change dynamically.",
                "In this paper, we mostly investigate the convergence of such systems towards global consistency.",
                "We first show that (for a wide class of protocols that we shall define), the communication constraints induced by the topology will not prevent the convergence of the system, at the condition that the system dynamics guarantees that no agent will ever be isolated forever, and that agents have unlimited time for computation and arguments exchange.",
                "As this assumption cannot be made in most situations though, we then set up an experimental framework aiming at comparing the relative efficiency and effectiveness of different interaction protocols for hypotheses exchange.",
                "We study a critical situation involving a number of agents aiming at escaping from a burning building.",
                "The results reported here provide some insights regarding the design of optimal protocol for hypotheses refinement in this context.",
                "Categories and Subject Descriptors I.2.11 [Artificial Intelligence]: Distributed Artificial Intelligence-Multiagent systems General Terms Theory, Experimentation 1.",
                "INTRODUCTION We consider a multiagent system where each (distributed) agent locally perceives its environment, and we assume that some unexpected event occurs in that system.",
                "If each agent computes only locally its favoured hypothesis, it is only natural to assume that agents will seek to coordinate and refine their hypotheses by confronting their observations with other agents.",
                "If, in addition, the communication opportunities are severely constrained (for instance, agents can only communicate when they are close enough to some other agent), and dynamically changing (for instance, agents may change their locations), it becomes crucial to carefully design protocols that will allow agents to converge to some desired state of global consistency.",
                "In this paper we exhibit some sufficient conditions on the system dynamics and on the protocol/strategy structures that allow to guarantee that property, and we experimentally study some contexts where (some of) these assumptions are relaxed.",
                "While problems of diagnosis are among the venerable classics in the AI tradition, their multiagent counterparts have much more recently attracted some attention.",
                "Roos and colleagues [8, 9] in particular study a situation where a number of distributed entities try to come up with a satisfying global diagnosis of the whole system.",
                "They show in particular that the number of messages required to establish this global diagnosis is bound to be prohibitive, unless the communication is enhanced with some suitable protocol.",
                "However, they do not put any restrictions on agents communication options, and do not assume either that the system is dynamic.",
                "The benefits of enhancing communication with supporting information to make convergence to a desired global state of a system more efficient has often been put forward in the literature.",
                "This is for instance one of the main idea underlying the argumentation-based negotiation approach [7], where the desired state is a compromise between agents with conflicting preferences.",
                "Many of these works however make the assumption that this approach is beneficial to start with, and study the technical facets of the problem (or instead emphasize other advantages of using argumentation).",
                "Notable exceptions are the works of [3, 4, 2, 5], which studied in contexts different from ours the efficiency of argumentation.",
                "The rest of the paper is as follows.",
                "Section 2 specifies the basic elements of our model, and Section 3 goes on to presenting the different protocols and strategies used by the agents to exchange hypotheses and observations.",
                "We put special attention at clearly emphasizing the conditions on the system dynamics and protocols/strategies that will be exploited in the rest of the paper.",
                "Section 4 details one of 998 978-81-904262-7-5 (RPS) c 2007 IFAAMAS the main results of the paper, namely the fact that under the aforementioned conditions, the constraints that we put on the topology will not prevent the convergence of the system towards global consistency, at the condition that no agent ever gets completely lost forever in the system, and that unlimited time is allowed for computation and argument exchange.",
                "While the conditions on protocols and strategies are fairly mild, it is also clear that these system requirements look much more problematic, even frankly unrealistic in critical situations where distributed approaches are precisely advocated.",
                "To get a clearer picture of the situation induced when time is a critical factor, we have set up an experimental framework that we introduce and discuss in Section 5.",
                "The critical situation involves a number of agents aiming at escaping from a burning building.",
                "The results reported here show that the effectiveness of argument exchange crucially depends upon the nature of the building, and provide some insights regarding the design of optimal protocol for hypotheses refinement in this context. 2.",
                "BASIC NOTIONS We start by defining the basic elements of our system.",
                "Environment Let O be the (potentially infinite) set of possible observations.",
                "We assume the sensors of our agents to be perfect, hence the observations to be certain.",
                "Let H be the set of hypotheses, uncertain and revisable.",
                "Let Cons(h, O) be the consistency relation, a binary relation between a hypothesis h ∈ H and a set of observations O ⊆ O.",
                "In most cases, Cons will refer to classical consistency relation, however, we may overload its meaning and add some additional properties to that relation (in which case we will mention it).",
                "The environment may include some dynamics, and change over the course of time.",
                "We define below sequences of time points to deal with it: Definition 1 (Sequence of time points).",
                "A sequence of time points t1, t2, . . . , tn from t is an ordered set of time points t1, t2, . . . , tn such that t1 ≥ t and ∀i ∈ [1, n − 1], ti+1 ≥ ti.",
                "Agent We take a system populated by n agents a1, . . . , an.",
                "Each agent is defined as a tuple F, Oi, hi , where: • F, the set of facts, common knowledge to all agents. • Oi ∈ 2O , the set of observations made by the agent so far.",
                "We assume a perfect memory, hence this set grows monotonically. • hi ∈ H, the favourite hypothesis of the agent.",
                "A key notion governing the formation of hypotheses is that of consistency, defined below: Definition 2 (Consistency).",
                "We say that: • An agent is consistent (Cons(ai)) iff Cons(hi, Oi) (that is, its hypothesis is consistent with its observation set). • An agent ai consistent with a partner agent aj iff Cons(ai) and Cons(hi, Oj) (that is, this agent is consistent and its hypothesis can explain the observation set of the other agent). • Two agents ai and aj are mutually consistent (MCons(ai, aj)) iff Cons(ai, aj) and Cons(aj, ai). • A system is consistent iff ∀(i, j)∈[1, n]2 it is the case that MCons(ai, aj).",
                "To ensure its consistency, each agent is equipped with an abstract reasoning machinery that we shall call the explanation function Eh.",
                "This (deterministic) function takes a set of observation and returns a single prefered hypothesis (2O → H).",
                "We assume h = Eh(O) to be consistent with O by definition of Eh, so using this function on its observation set to determine its favourite hypothesis is a sure way for the agent to achieve consistency.",
                "Note however that an hypothesis does not need to be generated by Eh to be consistent with an observation set.",
                "As a concrete example of such a function, and one of the main inspiration of this work, one can cite the Theorist reasoning system [6] -as long as it is coupled with a filter selecting a single prefered theory among the ones initially selected by Theorist.",
                "Note also that hi may only be modified as a consequence of the application Eh.",
                "We refer to this as the autonomy of the agent: no other agent can directly impose a given hypothesis to an agent.",
                "As a consequence, only a new observation (being it a new perception, or an observation communicated by a fellow agent) can result in a modification of its prefered hypothesis hi (but not necessarily of course).",
                "We finally define a property of the system that we shall use in the rest of the paper: Definition 3 (Bounded Perceptions).",
                "A system involves a bounded perception for agents iff ∃n0 s.t. ∀t| ∪N i=1 Oi| ≤ n0. (That is, the number of observations to be made by the agents in the system is not infinite.)",
                "Agent Cycle Now we need to see how these agents will evolve and interact in their environment.",
                "In our context, agents evolve in a dynamic environment, and we classicaly assume the following system cycle: 1.",
                "Environment dynamics: the environment evolves according to the defined rules of the system dynamics. 2.",
                "Perception step : agents get perceptions from the environment.",
                "These perceptions are typically partial (e.g. the agent can only see a portion of a map). 3.",
                "Reasoning step: agents compare perception with predictions, seek explanations for (potential) difference(s), refine their hypothesis, draw new conclusions. 4.",
                "Communication step: agents can communicate hypotheses and observations with other agents through a defined protocol.",
                "Any agent can only be involved in one communication with another agent by step. 5.",
                "Action step: agents do some practical reasoning using the models obtained from the previous steps and select an action.",
                "They can then modify the environment by executing it.",
                "The communication of the agents will be further constrained by topological consideration.",
                "At a given time, an agent will only be able to communicate with a number of neighbours.",
                "Its connexions with these others agents may The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 999 evolve with its situation in the environment.",
                "Typically, an agent can only communicate with agents that it can sense, but one could imagine evolving topological constraints on communication based on a network of communications between agents where the links are not always active.",
                "Communication In our system, agents will be able to communicate with each other.",
                "However, due to the aforementionned topological constraints, they will not be able to communicate with any agents at anytime.",
                "Who an agent can communicate with will be defined dynamically (for instance, this can be a consequence of the agents being close enough to get in touch).",
                "We will abstractly denote by C(ai, aj, t) the communication property, in other words, the fact that agents ai and aj can communicate at time t (note that this relation is assumed to be symetric, but of course not transitive).",
                "We are now in a position to define two essential properties of our system.",
                "Definition 4 (Temporal Path).",
                "There exists a temporal communication path at horizon tf (noted Ltf (aI , aJ )) between ai and aj iff there exists a sequence of time points t1, t2, . . . , tn from tf and a sequence of agents k1, k2, . . . , kn s.t. (i) C(aI , ak1 , t1), (ii) C(akn , aJ , tn+1), (iii) ∀i ∈ [1, n], C(aki , aki+1 , ti) Intuitively, what this property says is that it is possible to find a temporal path in the future that would allow to link agent ai and aj via a sequence of intermediary agents.",
                "Note that the time points are not necessarily successive, and that the sequence of agents may involve the same agents several times.",
                "Definition 5 (Temporal Connexity).",
                "A system is temporaly connex iff ∀t ∀(i, j)∈[1, n]2 Lt(ai, aj) In short, a temporaly connex system guarantees that any agent will be able to communicate with any other agents, no matter how long it might take to do so, at any time.",
                "To put it another way, it is never the case that an agent will be isolated for ever from another agent of the system.",
                "We will next discuss the detail of how communication concretely takes place in our system.",
                "Remember that in this paper, we only consider the case of bilateral exchanges (an agent can only speak to a single other agent), and that we also assume that any agent can only engage in a single exchange in a given round. 3.",
                "PROTOCOLS AND STRATEGIES In this section, we discuss the requirements of the interaction protocols that govern the exchange of messages between agents, and provide some example instantiation of such protocols.",
                "To clarify the presentation, we distinguish two levels: the local level, which is concerned with the regulation of bilateral exchanges; and the global level,which essentially regulates the way agents can actually engage into a conversation.",
                "At each level, we separate what is specified by the protocol, and what is left to agents strategies.",
                "Local Protocol and Strategies We start by inspecting local protocols and strategies that will regulate the communication between the agents of the system.",
                "As we limit ourselves to bilateral communication, these protocols will simply involve two agents.",
                "Such protocol will have to meet one basic requirement to be satisfying. • consistency (CONS)- a local protocol has to guarantee the mutual consistency of agents upon termination (which implies termination of course).",
                "Figure 1: A Hypotheses Exchange Protocol [1] One example such protocol is the protocol described in [1] that is pictured in Fig. 1.",
                "To further illustrate how such protocol can be used by agents, we give some details on a possible strategy: upon receiving a hypothesis h1 (propose(h1) or counterpropose(h1)) from a1, agent a2 is in state 2 and has the following possible replies: counterexample (if the agent knows an example contradicting the hypothesis, or not explained by this hypothesis), challenge (if the agents lacks evidence to accept this hypothesis), counterpropose (if the agent agrees with the hypothesis but prefers another one), or accept (if it is indeed as good as its favourite hypothesis).",
                "This strategy guarantees, among other properties, the eventual mutual logical consistency of the involved agents [1].",
                "Global Protocol The global protocol regulates the way bilateral exchanges will be initiated between agents.",
                "At each turn, agents will concurrently send one weighted request to communicate to other agents.",
                "This weight is a value measuring the agents willingness to converse with the targeted agent (in practice, this can be based on different heuristics, but we shall make some assumptions on agents strategies, see below).",
                "Sending such a request is a kind of conditional commitment for the agent.",
                "An agent sending a weighted request commits to engage in conversation with the target if he does not receive and accept himself another request.",
                "Once all request have been received, each agent replies with either an acccept or a reject.",
                "By answering with an accept, an agent makes a full commitment to engage in conversation with the sender.",
                "Therefore, it can only send one accept in a given round, as an agent can only participate in one conversation per time step.",
                "When all response have been received, each agent receiving an accept can either initiate a conversation using the local protocol or send a cancel if it has accepted another request.",
                "At the end of all the bilateral exchanges, the agents engaged in conversation are discarded from the protocol.",
                "Then each of the remaining agents resends a request and the process iterates until no more requests are sent.",
                "Global Strategy We now define four requirements for the strategies used by agents, depending on their role in the protocol: two are concerned with the requestee role (how to decide who the 1000 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) agent wishes to communicate with? ), the other two with the responder role (how to decide which communication request to accept or not?). • Willingness to solve inconsistancies (SOLVE)-agents want to communicate with any other agents unless they know they are mutually consistent. • Focus on solving inconsistencies (FOCUS)-agents do not request communication with an agent with whom they know they are mutually consistent. • Willingness to communicate (COMM)-agents cannot refuse a weighted communication request, unless they have just received or send a request with a greater weight. • Commitment to communication request (REQU)agents cannot accept a weighted communication request if they have themselves sent a communication request with a greater weight.",
                "Therefore, they will not cancel their request unless they have received a communicational request with greater weight.",
                "Now the protocol structure, together with the properties COMM+REQU, ensure that a request can only be rejected if its target agent engages in communication with another agent.",
                "Suppose indeed that agent ai wants to communicate with aj by sending a request with weight w. COMM guarantees that an agent receiving a weighted request will either accept this communication, accept a communication with a greater weight or wait for the answer to a request with a greater weight.",
                "This ensures that the request with maximal weight will be accepted and not cancelled (as REQU ensures that an agent sending a request can only cancel it if he accepts another request with greater weight).",
                "Therefore at least two agents will engage in conversation per round of the global protocol.",
                "As the protocol ensures that ai can resend its request while aj is not engaged in a conversation, there will be a turn in which aj must engage in a conversation, either with ai or another agent.",
                "These requirements concern request sending and acceptation, but agents also need some strategy of weight attribution.",
                "We describe below an altruist strategy, used in our experiments.",
                "Being cooperative, an agent may want to know more of the communication wishes of other agents in order to improve the overall allocation of exchanges to agents.",
                "A context request step is then added to the global protocol.",
                "Before sending their chosen weighted request, agents attribute a weight to all agents they are prepared to communicate with, according to some internal factors.",
                "In the simplest case, this weight will be 1 for all agent with whom the agent is not sure of being mutually consistent (ensuring SOLVE), other agent being not considered for communication (ensuring FOCUS).",
                "The agent then sends a context request to all agents with whom communication is considered.",
                "This request also provides information about the sender (list of considered communications along with their weight).",
                "After reception of all the context requests, agents will either reply with a deny, iff they are already engaged in a conversation (in which case, the requesting agent will not consider communication with them anymore in this turn), or an inform giving the requester information about the requests it has sent and received.",
                "When all replies have been received, each agent can calculate the weight of all requests concerning it.",
                "It does so by substracting from the weight of its request the weight of all requests concerning either it or its target (that is, the final weight of the request from ai to aj is Wi,j = wi,j +wj,i − ( P k∈R(i)−{j} wi,k + P k∈S(i)−{j} wk,i + P k∈R(j)−{i} wj,k + P k∈S(j)−{i} wk,j) where wi,j is the weight of the request of ai to aj, R(i) is the set of indice of agents having received a request from ai and S(i) is the set of indice of agents having send a request to ai).",
                "It then finally sends a weighted request to the agents who maximise this weight (or wait for a request) as described in the global protocol. 4. (CONDITIONAL) CONVERGENCE TO GLOBAL CONSISTENCY In this section we will show that the requirements regarding protocols and strategies just discussed will be sufficient to ensure that the system will eventually converge towards global consistency, under some conditions.",
                "We first show that, if two agents are not mutually consistent at some time, then there will be necessarily a time in the future such that an agent will learn a new observation, being it because it is new for the system, or by learning it from another agent.",
                "Lemma 1.",
                "Let S be a system populated by n agents a1, a2, ..., an, temporaly connex, and involving bounded perceptions for these agents.",
                "Let n1 be the sum of cardinalities of the intersection of pairwise observation sets. (n1 = P (i,j)∈[1,n]2 |Oi ∩ Oj|) Let n2 be the cardinality of the union of all agents observations sets. (n2 = | ∪N i=1 Oi|).",
                "If ¬MCons(ai, aj) at time t0, there is necessarily a time t > t0 s.t. either n1 or n2 will increase.",
                "Proof.",
                "Suppose that there exist a time t0 and indices (i, j) s.t. ¬MCons(ai, aj).",
                "We will use mt0 = P (k,l)∈[1,n]2 εComm(ak, al, t0) where εComm(ak, al, t0) = 1 if ak and al have communicated at least once since t0, and 0 otherwise.",
                "Temporal connexity guarantees that there exist t1, ..., tm+1 and k1, ..., km s.t.",
                "C(ai, ak1 , t1), C(akm , aj, tm+1), and ∀p ∈ [1, m], C(akp , akp+1 , tp).",
                "Clearly, if MCons(ai, ak1 ), MCons(akm , aj) and ∀p, MCons(akp , akp+1 ), we have MCons(ai, aj) which contradicts our hypothesis (MCons being transitive, MCons(ai, ak1 )∧MCons(ak1 , ak2 ) implies that MCons(ai, ak2 ) and so on till MCons(ai, akm )∧ MCons(akm , aj) which implies MCons(ai, aj) ).",
                "At least two agents are then necessarily inconsistent (¬MCons(ai, ak1 ), or ¬MCons(akm , aj), or ∃p0 t.q. ¬MCons(akp0 , akp0+1 )).",
                "Let ak and al be these two neighbours at a time t > t0 1 .",
                "The SOLVE property ensures that either ak or al will send a communication request to the other agent at time t .",
                "As shown before, this in turn ensures that at least one of these agents will be involved in a communication.",
                "Then there are two possibilities: (case i) ak and al communicate at time t .",
                "In this case, we know that ¬MCons(ak, al).",
                "This and the CONS property ensures that at least one of the agents must change its 1 Strictly speaking, the transitivity of MCons only ensure that ak and al are inconsistent at a time t ≥ t0 that can be different from the time t at which they can communicate.",
                "But if they become consistent between t and t (or inconsistent between t and t ), it means that at least one of them have changed its hypothesis between t and t , that is, after t0.",
                "We can then apply the reasoning of case iib.",
                "The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 1001 hypothesis, which in turn, since agents are autonomous, implies at least one exchange of observation.",
                "But then |Ok ∩Ol| is bound to increase: n1(t ) > n1(t0). (case ii) ak communicates with ap at time t .",
                "We then have again two possibilities: (case iia) ak and ap did not communicate since t0.",
                "But then εComm(ak, ap, t0) had value 0 and takes value 1.",
                "Hence mt0 increases. (case iib) ak and ap did communicate at some time t0 > t0.",
                "The CONS property of the protocol ensures that MCons(ak, ap) at that time.",
                "Now the fact that they communicate and FOCUS implies that at least one of them did change its hypothesis in the meantime.",
                "The fact that agents are autonomous implies in turn that a new observation (perceived or received from another agent) necessarily provoked this change.",
                "The latter case would ensure the existence of a time t > t0 and an agent aq s.t. either |Op ∩Oq| or |Ok ∩Oq| increases of 1 at that time (implying n1(t ) > n1(t0)).",
                "The former case means that the agent gets a new perception o at time t .",
                "If that observation was unknown in the system before, then n2(t ) > n2(t0).",
                "If some agent aq already knew this observation before, then either Op ∩ Oq or Ok ∩ Oq increases of 1 at time t (which implies that n1(t ) > n1(t0)).",
                "Hence, ¬MCons(ai, aj) at time t0 guarantees that, either: −∃t > t0 t.q. n1(t ) > n1(t0); or −∃t > t0 t.q. n2(t ) > n2(t0); or −∃t > t0 t.q. mt0 increases of 1 at time t .",
                "By iterating the reasoning with t (but keeping t0 as the time reference for mt0 ), we can eliminate the third case (mt0 is integer and bounded by n2 , which means that after a maximum of n2 iterations, we necessarily will be in one of two other cases.)",
                "As a result, we have proven that if ¬MCons(ai, aj) at time t0, there is necessarily a time t s.t. either n1 or n2 will increase.",
                "Theorem 1 (Global consistency).",
                "Let S be a system populated by n agents a1, a2, ..., an, temporaly connex, and involving bounded perceptions for these agents.",
                "Let Cons(ai, aj) be a transitive consistency property.",
                "Then any protocol and strategies satisfying properties CONS, SOLVE, FOCUS, COMM and REQU guarantees that the system will converge towards global consistency.",
                "Proof.",
                "For the sake of contradiction, let us assume ∃I, J ∈ [1, N] s.t. ∀t, ∃t0 > t, t.q. ¬Cons(aI , aJ , t0).",
                "Using the lemma, this implies that ∃t > t0 s.t. either n1(t ) > n1(t0) or n2(t ) > n2(t0).",
                "But we can apply the same reasoning taking t = t , which would give us t1 > t > t0 s.t. ¬Cons(aI , aJ , t1), which gives us t > t1 s.t. either n1(t ) > n1(t1) or n2(t ) > n2(t1).",
                "By successive iterations we can then construct a sequence t0, t1, ..., tn, which can be divided in two sub-sequences t0, t1, ...tn and t0 , t1 , ..., tn s.t. n1(t0) < n1(t1) < ... < n1(tn) and n2(t0 ) < n2(t1 ) < ... < n2(tn).",
                "One of these sub-sequences has to be infinite.",
                "However, n1(ti) and n2(ti ) are strictly growing, integer, and bounded, which implies that both are finite.",
                "Contradiction.",
                "What the previous result essentially shows is that, in a system where no agent will be isolated from the rest of the agents for ever, only very mild assumptions on the protocols and strategies used by agents suffice to guarantee convergence towards system consistency in a finite amount of time (although it might take very long).",
                "Unfortunately, in many critical situations, it will not be possible to assume this temporal connexity.",
                "As distributed approaches as the one advocated in this paper are precisely often presented as a good way to tackle problems of reliability or problems of dependence to a center that are of utmost importance in these critical applications, it is certainly interesting to further explore how such a system would behave when we relax this assumption. 5.",
                "EXPERIMENTAL STUDY This experiment involves agents trying to escape from a burning building.",
                "The environment is described as a spatial grid with a set of walls and (thankfully) some exits.",
                "Time and space are considered discrete.",
                "Time is divided in rounds.",
                "Agents are localised by their position on the spatial grid.",
                "These agents can move and communicate with other agents.",
                "In a round, an agent can move of one cell in any of the four cardinal directions, provided it is not blocked by a wall.",
                "In this application, agents communicate with any other agent (but, recall, a single one) given that this agent is in view, and that they have not yet exchanged their current favoured hypothesis.",
                "Suddenly, a fire erupts in these premises.",
                "From this moment, the fire propagates.",
                "Each round, for each cases where there is fire, the fire propagates in the four directions.",
                "However, the fire cannot propagate through a wall.",
                "If the fire propagates in a case where an agent is positioned, that agent burns and is considered dead.",
                "It can of course no longer move nor communicate.",
                "If an agent gets to an exit, it is considered saved, and can no longer be burned.",
                "Agents know the environment and the rules governing the dynamics of this environment, that is, they know the map as well as the rules of fire propagation previously described.",
                "They also locally perceive this environment, but cannot see further than 3 cases away, in any direction.",
                "Walls also block the line of view, preventing agents from seeing behind them.",
                "Within their sight, they can see other agents and whether or not the cases they see are on fire.",
                "All these perceptions are memorised.",
                "We now show how this instantiates the abstract framework presented the paper. • O = {Fire(x, y, t), NoFire(x, y, t), Agent(ai, x, y, t)} Observations can then be positive (o ∈ P(O) iff ∃h ∈ H s.t. h |= o) or negative (o ∈ N(O) iff ∃h ∈ H s.t. h |= ¬o). • H={FireOrigin(x1, y1, t1)∧...∧FireOrigin(xl, yl, tl)} Hypotheses are conjunctions of FireOrigins. • Cons(h, O) consistency relation satisfies: - coherence : ∀o ∈ N(O), h |= ¬o. - completeness : ∀o ∈ P(O), h |= o. - minimality : For all h ∈ H, if h is coherent and complete for O, then h is prefered to h according to the preference relation (h ≤p h ).2 2 Selects first the minimal number of origins, then the most recent (least preemptive strategy [6]), then uses some arbitrary fixed ranking to discriminate ex-aequo.",
                "The resulting relation is a total order, hence minimality implies that there will be a single h s.t.Cons(O, h) for a given O.",
                "This in turn means that MCons(ai, aj) iff Cons(ai), Cons(aj), and hi = hj.",
                "This relation is then transitive and symmetric. 1002 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) • Eh takes O as argument and returns min≤p of the coherent and complete hypothesis for O 5.1 Experimental Evaluation We will classically (see e.g. [3, 4]) assess the effectiveness and efficiency of different interaction protocols.",
                "Effectiveness of a protocol The proportion of agents surviving the fire over the initial number of agents involved in the experiment will determine the effectiveness of a given protocol.",
                "If this value is high, the protocol has been effective to propagate the information and/or for the agents to refine their hypotheses and determine the best way to the exit.",
                "Efficiency of a protocol Typically, the use of supporting information will involve a communication overhead.",
                "We will assume here that the efficiency of a given protocol is characterised by the data flow induced by this protocol.",
                "In this paper we will only discuss this aspect wrt. local protocols.",
                "The main measure that we shall then use here is the mean total size of messages that are exchanged by agents per exchange (hence taking into account both the number of messages and the actual size of the messages, because it could be that messages happen to be very big, containing e.g. a large number of observations, which could counter-balance a low number of messages). 5.2 Experimental Settings The chosen experimental settings are the following: • Environmental topology- Performances of information propagation are highly constrained by the environment topology.",
                "The perception skills of the agents depend on the openness of the environment.",
                "With a large number of walls the perceptions of agents are limited, and also the number of possible <br>inter-agent communication</br>s, whereas an open environment will provide optimal possibilities of perception and information propagation.",
                "Thus, we propose a topological index (see below) as a common basis to charaterize the environments (maps) used during experimentations.",
                "The topological index (TI) is the ratio of the number of cells that can be perceived by agents summed up from all possible positions, divided by the number of cells that would be perceived from the same positions but without any walls. (The closer to 1, the more open the environment).",
                "We shall also use two additional, more classical [10], measures: the characteristic path length3 (CPL) and the clustering coefficient4 (CC). • Number of agents- The propagation of information also depends on the initial number of agents involved during an experimentation.",
                "For instance, the more agents, the more potential communications there is.",
                "This means that there will be more potential for propagation, but also that the bilateral exchange restriction will be more crucial. 3 The CPL is the median of the means of the shortest path lengths connecting each node to all other nodes. 4 characterising the isolation degree of a region of an environment in terms of acessibility (number of roads still usable to reach this region).",
                "Map T.I. (%) C.P.L.",
                "C.C. 69-1 69,23 4,5 0,69 69-2 68,88 4,38 0,65 69-3 69,80 4,25 0,67 53-1 53,19 5,6 0,59 53-2 53,53 6,38 0,54 53-3 53,92 6,08 0,61 38-1 38,56 8,19 0,50 38-2 38,56 7,3 0,50 38-3 38,23 8,13 0,50 Table 1: Topological Characteristics of the Maps • Initial positions of the agents- Initial positions of the agents have a significant influence on the overall behavior of an instance of our system: being close from an exit will (in general) ease the escape. 5.3 Experimental environments We choose to realize experiments on three very different topological indexes (69% for open environments, 53% for mixed environments, and 38% for labyrinth-like environments).",
                "Figure 2: Two maps (left: TI=69%, right TI=38%) We designed three different maps for each index (Fig. 2 shows two of them), containing the same maximum number of agents (36 agents max.) with a maximum density of one agent per cell, the same number of exits and a similar fire origin (e.g. starting time and position).",
                "The three differents maps of a given index are designed as follows.",
                "The first map is a model of an existing building floor.",
                "The second map has the same enclosure, exits and fire origin as the first one, but the number and location of walls are different (wall locations are designed by an heuristic which randomly creates walls on the spatial grid such that no fully closed rooms are created and that no exit is closed).",
                "The third map is characterised by geometrical enclosure in wich walls location is also designed with the aforementioned heuristic.",
                "Table 1 summarizes the different topological measures characterizing these different maps.",
                "It is worth pointing out that the values confirm the relevance of TI (maps with a high TI have a low CPL and a high CC.",
                "However the CPL and CC allows to further refine the difference between the maps, e.g. between 53-1 and 53-2). 5.4 Experimental Results For each triple of maps defined as above we conduct the same experiments.",
                "In each experiment, the society differs in terms of its initial proportion of involved agents, from 1% to 100%.",
                "This initial proportion represents the percentage of involved agents with regards to the possible maximum number of agents.",
                "For each map and each initial proportion, The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 1003 we select randomly 100 different initial agents locations.",
                "For each of those different locations we execute the system one time for each different interaction protocol.",
                "Effectiveness of Communication and Argumentation The first experiment that we set up aims at testing how effective is hypotheses exchange (HE), and in particular how the topological aspects will affect this effectiveness.",
                "In order to do so, we have computed the ratio of improvement offered by that protocol over a situation where agents could simply not communicate (no comm).",
                "To get further insights as to what extent the hypotheses exchange was really crucial, we also tested a much less elaborated protocol consisting of mere observation exchanges (OE).",
                "More precisely, this protocol requires that each agent stores any unexpected observation that it perceives, and agents simply exchange their respective lists of observations when they discuss.",
                "In this case, the local protocol is different (note in particular that it does not guarantee mutual consistency), but the global protocol remains the same (at the only exception that agents motivation to communicate is to synchronise their list of observations, not their hypothesis).",
                "If this protocol is at best as effective as HE, it has the advantage of being more efficient (this is obvious wrt the number of messages which will be limited to 2, less straightforward as far as the size of messages is concerned, but the rough observation that the exchange of observations can be viewed as a flat version of the challenge is helpful to see this).",
                "The results of these experiments are reported in Fig. 3.",
                "Figure 3: Comparative effectiveness ratio gain of protocols when the proportion of agents augments The first observation that needs to be made is that communication improves the effectiveness of the process, and this ratio increases as the number of agents grows in the system.",
                "The second lesson that we learn here is that closeness relatively makes communication more effective over non communication.",
                "Maps exhibiting a T.I. of 38% are constantly above the two others, and 53% are still slightly but significantly better than 69%.",
                "However, these curves also suggest, perhaps surprisingly, that HE outperforms OE in precisely those situations where the ratio gain is less important (the only noticeable difference occurs for rather open maps where T.I. is 69%).",
                "This may be explained as follows: when a map is open, agents have many potential explanation candidates, and argumentation becomes useful to discriminate between those.",
                "When a map is labyrinth-like, there are fewer possible explanations to an unexpected event.",
                "Importance of the Global Protocol The second set of experiments seeks to evaluate the importance of the design of the global protocol.",
                "We tested our protocol against a local broadcast (LB) protocol.",
                "Local broadcast means that all the neighbours agents perceived by an agent will be involved in a communication with that agent in a given round -we alleviate the constraint of a single communication by agent.",
                "This gives us a rough upper bound upon the possible ratio gain in the system (for a given local protocol).",
                "Again, we evaluated the ratio gain induced by that LB over our classical HE, for the three different classes of maps.",
                "The results are reported in Fig. 4.",
                "Figure 4: Ratio gain of local broadcast over hypotheses exchange Note to begin with that the ratio gain is 0 when the proportion of agents is 5%, which is easily explained by the fact that it corresponds to situations involving only two agents.",
                "We first observe that all classes of maps witness a ratio gain increasing when the proportion of agents augments: the gain reaches 10 to 20%, depending on the class of maps considered.",
                "If one compares this with the improvement reported in the previous experiment, it appears to be of the same magnitude.",
                "This illustrates that the design of the global protocol cannot be ignored, especially when the proportion of agents is high.",
                "However, we also note that the effectiveness ratio gain curves have very different shapes in both cases: the gain induced by the accuracy of the local protocol increases very quickly with the proportion of agents, while the curve is really smooth for the global one.",
                "Now let us observe more carefully the results reported here: the curve corresponding to a TI of 53% is above that corresponding to 38%.",
                "This is so because the more open a map, the more opportunities to communicate with more than one agent (and hence benefits from broadcast).",
                "However, we also observe that curve for 69% is below that for 53%.",
                "This is explained as follows: in the case of 69%, the potential gain to be made in terms of surviving agents is much lower, because our protocols already give rather efficient outcomes anyway (quickly reaching 90%, see Fig. 3).",
                "A simple rule of thumb could be that when the number of agents is small, special attention should be put on the local 1004 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) protocol, whereas when that number is large, one should carefully design the global one (unless the map is so open that the protocol is already almost optimally efficient).",
                "Efficiency of the Protocols The final experiment reported here is concerned with the analysis of the efficiency of the protocols.",
                "We analysis here the mean size of the totality of the messages that are exchanged by agents (mean size of exchanges, for short) using the following protocols: HE, OE, and two variant protocols.",
                "The first one is an intermediary restricted hypotheses exchange protocol (RHE).",
                "RHE is as follows: it does not involve any challenge nor counter-propose, which means that agents cannot switch their role during the protocol (this differs from RE in that respect).",
                "In short, RHE allows an agent to exhaust its partners criticism, and eventually this partner will come to adopt the agents hypothesis.",
                "Note that this means that the autonomy of the agent is not preserved here (as an agent will essentially accept any hypothesis it cannot undermine), with the hope that the gain in efficiency will be significant enough to compensate a loss in effectiveness.",
                "The second variant protocol is a complete observation exchange protocol (COE).",
                "COE uses the same principles as OE, but includes in addition all critical negative examples (nofire) in the exchange (thus giving all examples used as arguments by the hypotheses exchanges protocol), hence improving effectiveness.",
                "Results for map 69-1 are shown on Fig. 5.",
                "Figure 5: Mean size of exchanges First we can observe the fact that the ordering of the protocols, from the least efficient to the most efficient, is COE, HE, RHE and then OE.",
                "HE being more efficient than COE proves that the argumentation process gains efficiency by selecting when it is needed to provide negative example, which have less impact that positive ones in our specific testbed.",
                "However, by communicating hypotheses before eventually giving observation to support it (HE) instead of directly giving the most crucial observations (OE), the argumentation process doubles the size of data exchanges.",
                "It is the cost for ensuring consistency at the end of the exchange (a property that OE does not support).",
                "Also significant is the fact the the mean size of exchanges is slightly higher when the number of agents is small.",
                "This is explained by the fact that in these cases only a very few agents have relevant informations in their possession, and that they will need to communicate a lot in order to come up with a common view of the situation.",
                "When the number of agents increases, this knowledge is distributed over more agents which need shorter discussions to get to mutual consistency.",
                "As a consequence, the relative gain in efficiency of using RHE appears to be better when the number of agents is small: when it is high, they will hardly argue anyway.",
                "Finally, it is worth noticing that the standard deviation for these experiments is rather high, which means that the conversation do not converge to any stereotypic pattern. 6.",
                "CONCLUSION This paper has investigated the properties of a multiagent system where each (distributed) agent locally perceives its environment, and tries to reach consistency with other agents despite severe communication restrictions.",
                "In particular we have exhibited conditions allowing convergence, and experimentally investigated a typical situation where those conditions cannot hold.",
                "There are many possible extensions to this work, the first being to further investigate the properties of different global protocols belonging to the class we identified, and their influence on the outcome.",
                "There are in particular many heuristics, highly dependent on the context of the study, that could intuitively yield interesting results (in our study, selecting the recipient on the basis of what can be inferred from his observed actions could be such a heuristic).",
                "One obvious candidate for longer term issues concern the relaxation of the assumption of perfect sensing. 7.",
                "REFERENCES [1] G. Bourgne, N. Maudet, and S. Pinson.",
                "When agents communicate hypotheses in critical situations.",
                "In Proceedings of DALT-2006, May 2006. [2] P. Harvey, C. F. Chang, and A. Ghose.",
                "Support-based distributed search: a new approach for multiagent constraint processing.",
                "In Proceedings of AAMAS06, 2006. [3] H. Jung and M. Tambe.",
                "Argumentation as distributed constraint satisfaction: Applications and results.",
                "In Proceedings of AGENTS01, 2001. [4] N. C. Karunatillake and N. R. Jennings.",
                "Is it worth arguing?",
                "In Proceedings of ArgMAS 2004, 2004. [5] S. Onta˜n´on and E. Plaza.",
                "Arguments and counterexamples in case-based joint deliberation.",
                "In Proceedings of ArgMAS-2006, May 2006. [6] D. Poole.",
                "Explanation and prediction: An architecture for default and abductive reasoning.",
                "Computational Intelligence, 5(2):97-110, 1989. [7] I. Rahwan, S. D. Ramchurn, N. R. Jennings, P. McBurney, S. Parsons, and L. Sonenberg.",
                "Argumention-based negotiation.",
                "The Knowledge Engineering Review, 4(18):345-375, 2003. [8] N. Roos, A. ten Tije, and C. Witteveen.",
                "A protocol for multi-agent diagnosis with spatially distributed knowledge.",
                "In Proceedings of AAMAS03, 2003. [9] N. Roos, A. ten Tije, and C. Witteveen.",
                "Reaching diagnostic agreement in multiagent diagnosis.",
                "In Proceedings of AAMAS04, 2004. [10] T. Takahashi, Y. Kaneda, and N. Ito.",
                "Preliminary study - using robocuprescue simulations for disasters prevention.",
                "In Proceedings of SRMED2004, 2004.",
                "The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 1005"
            ],
            "original_annotated_samples": [
                "With a large number of walls the perceptions of agents are limited, and also the number of possible <br>inter-agent communication</br>s, whereas an open environment will provide optimal possibilities of perception and information propagation."
            ],
            "translated_annotated_samples": [
                "Con un gran número de paredes, las percepciones de los agentes están limitadas, al igual que el número de posibles <br>comunicaciones entre agentes</br>, mientras que un entorno abierto proporcionará posibilidades óptimas de percepción y propagación de información."
            ],
            "translated_text": "Refinamiento de hipótesis bajo restricciones de comunicación topológica ∗ Gauvain Bourgne, Gael Hette, Nicolas Maudet y Suzanne Pinson LAMSADE, Univ. Investigamos las propiedades de un sistema multiagente donde cada agente (distribuido) percibe localmente su entorno. Tras la percepción de un evento inesperado, cada agente calcula localmente su hipótesis favorita e intenta propagarla a otros agentes, intercambiando hipótesis y argumentos de apoyo (observaciones). Sin embargo, también asumimos que las oportunidades de comunicación están severamente limitadas y cambian dinámicamente. En este artículo, investigamos principalmente la convergencia de dichos sistemas hacia la consistencia global. Primero demostramos que (para una amplia clase de protocolos que definiremos), las restricciones de comunicación inducidas por la topología no impedirán la convergencia del sistema, bajo la condición de que la dinámica del sistema garantice que ningún agente quedará aislado para siempre, y que los agentes tengan tiempo ilimitado para la computación y el intercambio de argumentos. Dado que esta suposición no se puede hacer en la mayoría de las situaciones, establecimos un marco experimental con el objetivo de comparar la eficiencia y efectividad relativa de diferentes protocolos de interacción para el intercambio de hipótesis. Estudiamos una situación crítica que implica a varios agentes que intentan escapar de un edificio en llamas. Los resultados reportados aquí proporcionan algunas ideas sobre el diseño de un protocolo óptimo para el refinamiento de hipótesis en este contexto. Categorías y Descriptores de Asignaturas I.2.11 [Inteligencia Artificial]: Inteligencia Artificial Distribuida-Sistemas Multiagente Términos Generales Teoría, Experimentación 1. INTRODUCCIÓN Consideramos un sistema multiagente donde cada agente (distribuido) percibe localmente su entorno, y asumimos que ocurre un evento inesperado en ese sistema. Si cada agente calcula solo localmente su hipótesis preferida, es natural asumir que los agentes buscarán coordinar y refinar sus hipótesis confrontando sus observaciones con otros agentes. Si, además, las oportunidades de comunicación están severamente limitadas (por ejemplo, los agentes solo pueden comunicarse cuando están lo suficientemente cerca de otro agente) y cambian dinámicamente (por ejemplo, los agentes pueden cambiar sus ubicaciones), se vuelve crucial diseñar cuidadosamente protocolos que permitan a los agentes converger hacia algún estado deseado de consistencia global. En este documento presentamos algunas condiciones suficientes sobre la dinámica del sistema y sobre las estructuras de protocolo/estrategia que permiten garantizar esa propiedad, y estudiamos experimentalmente algunos contextos donde (algunas de) estas suposiciones se relajan. Si bien los problemas de diagnóstico son uno de los clásicos venerables en la tradición de la IA, sus contrapartes multiagentes han atraído atención mucho más recientemente. Roos y sus colegas [8, 9] en particular estudian una situación en la que un número de entidades distribuidas intentan llegar a un diagnóstico global satisfactorio de todo el sistema. Ellos muestran en particular que el número de mensajes necesarios para establecer este diagnóstico global está destinado a ser prohibitivo, a menos que la comunicación se mejore con algún protocolo adecuado. Sin embargo, no imponen restricciones a las opciones de comunicación de los agentes, ni asumen que el sistema es dinámico. Los beneficios de mejorar la comunicación con información de apoyo para hacer que la convergencia a un estado global deseado de un sistema sea más eficiente, a menudo se ha planteado en la literatura. Esta es, por ejemplo, una de las ideas principales que subyacen al enfoque de negociación basado en argumentos [7], donde el estado deseado es un compromiso entre agentes con preferencias conflictivas. Sin embargo, muchos de estos trabajos parten del supuesto de que este enfoque es beneficioso para comenzar y estudian los aspectos técnicos del problema (o en su lugar enfatizan otras ventajas de utilizar la argumentación). Excepciones notables son las obras de [3, 4, 2, 5], que estudiaron en contextos diferentes al nuestro la eficiencia de la argumentación. El resto del documento es el siguiente. La Sección 2 especifica los elementos básicos de nuestro modelo, y la Sección 3 continúa presentando los diferentes protocolos y estrategias utilizados por los agentes para intercambiar hipótesis y observaciones. Ponemos especial atención en enfatizar claramente las condiciones de la dinámica del sistema y los protocolos/estrategias que se explotarán en el resto del documento. La sección 4 detalla uno de los principales resultados del artículo, a saber, el hecho de que bajo las condiciones mencionadas, las restricciones que imponemos en la topología no impedirán la convergencia del sistema hacia la consistencia global, siempre y cuando ningún agente se pierda completamente para siempre en el sistema, y se permita un tiempo ilimitado para la computación y el intercambio de argumentos. Si bien las condiciones en los protocolos y estrategias son bastante suaves, también es claro que estos requisitos del sistema parecen mucho más problemáticos, incluso francamente poco realistas en situaciones críticas donde se abogan precisamente por enfoques distribuidos. Para obtener una imagen más clara de la situación inducida cuando el tiempo es un factor crítico, hemos establecido un marco experimental que presentamos y discutimos en la Sección 5. La situación crítica implica a varios agentes que intentan escapar de un edificio en llamas. Los resultados reportados aquí muestran que la efectividad del intercambio de argumentos depende crucialmente de la naturaleza del edificio, y proporcionan algunas ideas sobre el diseño de un protocolo óptimo para el refinamiento de hipótesis en este contexto. CONCEPTOS BÁSICOS Comenzamos definiendo los elementos básicos de nuestro sistema. Deje que O sea el conjunto (potencialmente infinito) de observaciones posibles. Suponemos que los sensores de nuestros agentes son perfectos, por lo tanto, las observaciones son seguras. Sea H el conjunto de hipótesis, incierto y revisable. Sea Cons(h, O) la relación de consistencia, una relación binaria entre una hipótesis h ∈ H y un conjunto de observaciones O ⊆ O. En la mayoría de los casos, Cons se referirá a la relación de consistencia clásica, sin embargo, podemos sobrecargar su significado y añadir algunas propiedades adicionales a esa relación (en cuyo caso lo mencionaremos). El entorno puede incluir cierta dinámica y cambiar con el transcurso del tiempo. Definimos a continuación secuencias de puntos temporales para tratar con ello: Definición 1 (Secuencia de puntos temporales). Una secuencia de puntos temporales t1, t2, . . . , tn de t es un conjunto ordenado de puntos temporales t1, t2, . . . , tn tal que t1 ≥ t y ∀i ∈ [1, n − 1], ti+1 ≥ ti. Tomamos un sistema poblado por n agentes a1, . . . , an. Cada agente se define como una tupla F, Oi, hi, donde: • F, el conjunto de hechos, conocimiento común a todos los agentes. • Oi ∈ 2O, el conjunto de observaciones realizadas por el agente hasta el momento. Suponemos una memoria perfecta, por lo tanto, este conjunto crece de forma monótona. • hi ∈ H, la hipótesis favorita del agente. Una noción clave que rige la formación de hipótesis es la de consistencia, definida a continuación: Definición 2 (Consistencia). Decimos que: • Un agente es consistente (Cons(ai)) si y solo si Cons(hi, Oi) (es decir, su hipótesis es consistente con su conjunto de observaciones). • Un agente ai es consistente con un agente compañero aj si y solo si Cons(ai) y Cons(hi, Oj) (es decir, este agente es consistente y su hipótesis puede explicar el conjunto de observaciones del otro agente). • Dos agentes ai y aj son mutuamente consistentes (MCons(ai, aj)) si y solo si Cons(ai, aj) y Cons(aj, ai). • Un sistema es consistente si y solo si para todo (i, j) ∈ [1, n]2 se cumple que MCons(ai, aj). Para garantizar su consistencia, cada agente está equipado con una maquinaria de razonamiento abstracto que llamaremos la función de explicación Eh. Esta función (determinística) toma un conjunto de observaciones y devuelve una única hipótesis preferida (2O → H). Suponemos que h = Eh(O) para ser consistente con O por definición de Eh, por lo que usar esta función en su conjunto de observaciones para determinar su hipótesis favorita es una forma segura para que el agente logre consistencia. Sin embargo, cabe destacar que una hipótesis no necesita ser generada por Eh para ser consistente con un conjunto de observaciones. Como ejemplo concreto de tal función, y una de las principales inspiraciones de este trabajo, se puede citar el sistema de razonamiento Theorist [6], siempre y cuando esté acoplado con un filtro que seleccione una teoría preferida entre las inicialmente seleccionadas por Theorist. También hay que tener en cuenta que hi solo puede ser modificado como consecuencia de la aplicación de Eh. Nos referimos a esto como la autonomía del agente: ningún otro agente puede imponer directamente una hipótesis dada a un agente. Como consecuencia, solo una nueva observación (ya sea una nueva percepción o una observación comunicada por otro agente) puede resultar en una modificación de su hipótesis preferida hi (pero no necesariamente, por supuesto). Finalmente definimos una propiedad del sistema que utilizaremos en el resto del artículo: Definición 3 (Percepciones Acotadas). Un sistema implica una percepción limitada para los agentes si y solo si existe un n0 tal que para todo t, la unión de N observaciones realizadas por los agentes es menor o igual a n0. (Es decir, el número de observaciones a realizar por los agentes en el sistema no es infinito.) Ahora necesitamos ver cómo evolucionarán e interactuarán estos agentes en su entorno. En nuestro contexto, los agentes evolucionan en un entorno dinámico, y asumimos clásicamente el siguiente ciclo del sistema: 1. Dinámica del entorno: el entorno evoluciona de acuerdo con las reglas definidas de la dinámica del sistema. 2. Paso de percepción: los agentes obtienen percepciones del entorno. Estas percepciones suelen ser parciales (por ejemplo, el agente solo puede ver una parte de un mapa). 3. Paso de razonamiento: los agentes comparan la percepción con las predicciones, buscan explicaciones para las diferencias (potenciales), refinan su hipótesis, y sacan nuevas conclusiones. 4. Paso de comunicación: los agentes pueden comunicar hipótesis y observaciones con otros agentes a través de un protocolo definido. Cualquier agente solo puede estar involucrado en una comunicación con otro agente en el paso 5. Paso de acción: los agentes realizan un razonamiento práctico utilizando los modelos obtenidos de los pasos anteriores y seleccionan una acción. Ellos pueden modificar el entorno ejecutándolo. La comunicación de los agentes estará aún más restringida por consideraciones topológicas. En un momento dado, un agente solo podrá comunicarse con un número de vecinos. Sus conexiones con estos otros agentes pueden The Sixth Intl. La Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) evoluciona con su situación en el entorno. Normalmente, un agente solo puede comunicarse con agentes que puede percibir, pero se podría imaginar la evolución de restricciones topológicas en la comunicación basadas en una red de comunicaciones entre agentes donde los enlaces no siempre están activos. En nuestro sistema, los agentes podrán comunicarse entre sí. Sin embargo, debido a las restricciones topológicas mencionadas anteriormente, no podrán comunicarse con ningún agente en ningún momento. Con quién puede comunicarse un agente se definirá dinámicamente (por ejemplo, esto puede ser consecuencia de que los agentes estén lo suficientemente cerca para ponerse en contacto). Denotaremos de forma abstracta por C(ai, aj, t) la propiedad de comunicación, es decir, el hecho de que los agentes ai y aj puedan comunicarse en el tiempo t (nota que se asume que esta relación es simétrica, pero por supuesto no transitiva). Ahora estamos en posición de definir dos propiedades esenciales de nuestro sistema. Definición 4 (Camino Temporal). Existe un camino de comunicación temporal en el horizonte tf (denotado Ltf (aI, aJ)) entre ai y aj si y solo si existe una secuencia de puntos temporales t1, t2, ..., tn desde tf y una secuencia de agentes k1, k2, ..., kn tal que (i) C(aI, ak1, t1), (ii) C(akn, aJ, tn+1), (iii) ∀i ∈ [1, n], C(aki, aki+1, ti). Intuitivamente, lo que esta propiedad dice es que es posible encontrar un camino temporal en el futuro que permitiría vincular al agente ai y aj a través de una secuencia de agentes intermedios. Ten en cuenta que los puntos temporales no necesariamente son sucesivos, y que la secuencia de agentes puede involucrar a los mismos agentes varias veces. Definición 5 (Conexidad Temporal). Un sistema es temporalmente conexo si y solo si ∀t ∀(i, j)∈[1, n]2 Lt(ai, aj). En resumen, un sistema temporalmente conexo garantiza que cualquier agente podrá comunicarse con cualquier otro agente, sin importar cuánto tiempo pueda llevar hacerlo, en cualquier momento. Dicho de otra manera, nunca sucede que un agente esté aislado para siempre de otro agente del sistema. A continuación discutiremos en detalle cómo la comunicación tiene lugar concretamente en nuestro sistema. Recuerda que en este documento, solo consideramos el caso de intercambios bilaterales (un agente solo puede hablar con otro agente) y también asumimos que cualquier agente solo puede participar en un intercambio en una ronda dada. 3. PROTOCOLOS Y ESTRATEGIAS En esta sección, discutimos los requisitos de los protocolos de interacción que rigen el intercambio de mensajes entre agentes, y proporcionamos algunos ejemplos de la implementación de dichos protocolos. Para aclarar la presentación, distinguimos dos niveles: el nivel local, que se ocupa de la regulación de los intercambios bilaterales; y el nivel global, que regula principalmente la forma en que los agentes pueden participar realmente en una conversación. En cada nivel, separamos lo que está especificado por el protocolo y lo que se deja a las estrategias de los agentes. Protocolos y estrategias locales Comenzamos inspeccionando los protocolos y estrategias locales que regularán la comunicación entre los agentes del sistema. Al limitarnos a la comunicación bilateral, estos protocolos simplemente implicarán a dos agentes. Dicho protocolo tendrá que cumplir con un requisito básico para ser satisfactorio: consistencia (CONS) - un protocolo local debe garantizar la consistencia mutua de los agentes al finalizar (lo que implica, por supuesto, la finalización). Figura 1: Un Protocolo de Intercambio de Hipótesis [1] Un ejemplo de dicho protocolo es el protocolo descrito en [1] que se muestra en la Fig. 1. Para ilustrar aún más cómo dicho protocolo puede ser utilizado por agentes, proporcionamos algunos detalles sobre una posible estrategia: al recibir una hipótesis h1 (proponer(h1) o contra-proponer(h1)) de a1, el agente a2 se encuentra en el estado 2 y tiene las siguientes respuestas posibles: contraejemplo (si el agente conoce un ejemplo que contradice la hipótesis, o no está explicado por esta hipótesis), desafío (si el agente carece de evidencia para aceptar esta hipótesis), contra-proponer (si el agente está de acuerdo con la hipótesis pero prefiere otra), o aceptar (si es tan buena como su hipótesis favorita). Esta estrategia garantiza, entre otras propiedades, la eventual consistencia lógica mutua de los agentes involucrados [1]. Protocolo global El protocolo global regula la forma en que se iniciarán los intercambios bilaterales entre agentes. En cada turno, los agentes enviarán simultáneamente una solicitud ponderada para comunicarse con otros agentes. Este peso es un valor que mide la disposición de los agentes para conversar con el agente objetivo (en la práctica, esto puede basarse en diferentes heurísticas, pero haremos algunas suposiciones sobre las estrategias de los agentes, ver más abajo). Enviar una solicitud de este tipo es una especie de compromiso condicional para el agente. Un agente que envía una solicitud ponderada se compromete a entablar una conversación con el objetivo si no recibe y acepta otra solicitud por sí mismo. Una vez que se hayan recibido todas las solicitudes, cada agente responde con un aceptar o un rechazar. Al responder con un aceptar, un agente se compromete plenamente a participar en la conversación con el remitente. Por lo tanto, solo puede enviar una aceptación en una ronda dada, ya que un agente solo puede participar en una conversación por paso de tiempo. Cuando se hayan recibido todas las respuestas, cada agente que reciba una aceptación puede iniciar una conversación utilizando el protocolo local o enviar una cancelación si ha aceptado otra solicitud. Al final de todos los intercambios bilaterales, los agentes involucrados en la conversación son descartados del protocolo. Entonces cada uno de los agentes restantes reenvía una solicitud y el proceso se repite hasta que no se envíen más solicitudes. Estrategia global Ahora definimos cuatro requisitos para las estrategias utilizadas por los agentes, dependiendo de su rol en el protocolo: dos se refieren al rol del solicitante (cómo decidir quién es el 1000 The Sixth Intl. La Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) ¿con qué agente desea comunicarse? Los otros dos con el rol de respondedor (¿cómo decidir qué solicitud de comunicación aceptar o no?). • Disposición para resolver inconsistencias (SOLVE): los agentes desean comunicarse con cualquier otro agente a menos que sepan que son mutuamente consistentes. • Enfoque en resolver inconsistencias (FOCUS): los agentes no solicitan comunicarse con un agente con el que saben que son mutuamente consistentes. • Disposición para comunicarse (COMM): los agentes no pueden rechazar una solicitud de comunicación ponderada, a menos que acaben de recibir o enviar una solicitud con un peso mayor. • Compromiso con la solicitud de comunicación (REQU): los agentes no pueden aceptar una solicitud de comunicación ponderada si ellos mismos han enviado una solicitud de comunicación con un peso mayor. Por lo tanto, no cancelarán su solicitud a menos que hayan recibido una solicitud comunicacional con mayor peso. Ahora la estructura del protocolo, junto con las propiedades COMM+REQU, garantizan que una solicitud solo puede ser rechazada si su agente objetivo se involucra en comunicación con otro agente. Supongamos de hecho que el agente ai quiere comunicarse con aj enviando una solicitud con peso w. COMM garantiza que un agente que reciba una solicitud ponderada aceptará esta comunicación, aceptará una comunicación con un peso mayor o esperará la respuesta a una solicitud con un peso mayor. Esto asegura que la solicitud con peso máximo será aceptada y no cancelada (ya que REQU asegura que un agente que envía una solicitud solo puede cancelarla si acepta otra solicitud con un peso mayor). Por lo tanto, al menos dos agentes participarán en una conversación por ronda del protocolo global. Como el protocolo asegura que ai puede reenviar su solicitud mientras aj no está ocupado en una conversación, llegará un momento en el que aj deberá participar en una conversación, ya sea con ai u otro agente. Estos requisitos se refieren al envío y aceptación de solicitudes, pero los agentes también necesitan alguna estrategia de atribución de peso. Describimos a continuación una estrategia altruista, utilizada en nuestros experimentos. Siendo cooperativo, un agente puede querer conocer más los deseos de comunicación de otros agentes para mejorar la asignación general de intercambios a los agentes. Se añade entonces un paso de solicitud de contexto al protocolo global. Antes de enviar su solicitud ponderada elegida, los agentes asignan un peso a todos los agentes con los que están dispuestos a comunicarse, de acuerdo con algunos factores internos. En el caso más simple, este peso será 1 para todos los agentes con los que el agente no esté seguro de ser mutuamente consistentes (garantizando SOLVE), sin considerar a otros agentes para la comunicación (garantizando FOCUS). El agente luego envía una solicitud de contexto a todos los agentes con los que se considera la comunicación. Esta solicitud también proporciona información sobre el remitente (lista de comunicaciones consideradas junto con su peso). Después de recibir todas las solicitudes de contexto, los agentes responderán con un rechazo si ya están ocupados en una conversación (en cuyo caso, el agente solicitante no considerará comunicarse con ellos en este turno), o con una información que brinde al solicitante información sobre las solicitudes que ha enviado y recibido. Cuando se hayan recibido todas las respuestas, cada agente puede calcular el peso de todas las solicitudes que le conciernen. Lo hace restando del peso de su solicitud el peso de todas las solicitudes relacionadas con él o su objetivo (es decir, el peso final de la solicitud de ai a aj es Wi,j = wi,j + wj,i - ( Σ k∈R(i)-{j} wi,k + Σ k∈S(i)-{j} wk,i + Σ k∈R(j)-{i} wj,k + Σ k∈S(j)-{i} wk,j) donde wi,j es el peso de la solicitud de ai a aj, R(i) es el conjunto de índices de agentes que han recibido una solicitud de ai y S(i) es el conjunto de índices de agentes que han enviado una solicitud a ai). Luego envía finalmente una solicitud ponderada a los agentes que maximizan este peso (o esperan una solicitud) según lo descrito en el protocolo global. 4. (CONDICIONAL) CONVERGENCIA HACIA LA COHERENCIA GLOBAL En esta sección mostraremos que los requisitos relacionados con los protocolos y estrategias recién discutidos serán suficientes para garantizar que el sistema eventualmente convergerá hacia la coherencia global, bajo ciertas condiciones. Primero demostramos que, si dos agentes no son mutuamente consistentes en algún momento, entonces necesariamente habrá un momento en el futuro en el que un agente aprenderá una nueva observación, ya sea porque es nueva para el sistema, o al aprenderla de otro agente. Lema 1. Sea S un sistema poblado por n agentes a1, a2, ..., an, temporalmente conectados e involucrando percepciones limitadas para estos agentes. Sea n1 la suma de las cardinalidades de la intersección de los conjuntos de observaciones emparejados. (n1 = P (i,j)∈[1,n]2 |Oi ∩ Oj|) Sea n2 la cardinalidad de la unión de todos los conjuntos de observaciones de los agentes. (n2 = | ∪N i=1 Oi|). Si ¬MCons(ai, aj) en el tiempo t0, necesariamente existe un tiempo t > t0 tal que ya sea n1 o n2 aumentarán. Prueba. Supongamos que exista un tiempo t0 y unos índices (i, j) tal que ¬MCons(ai, aj). Utilizaremos mt0 = P (k,l)∈[1,n]2 εComm(ak, al, t0) donde εComm(ak, al, t0) = 1 si ak y al han comunicado al menos una vez desde t0, y 0 en caso contrario. La conexidad temporal garantiza que existen t1, ..., tm+1 y k1, ..., km tal que. C(ai, ak1 , t1), C(akm , aj, tm+1), y ∀p ∈ [1, m], C(akp , akp+1 , tp). Claramente, si MCons(ai, ak1), MCons(akm, aj) y ∀p, MCons(akp, akp+1), tenemos MCons(ai, aj) lo cual contradice nuestra hipótesis (siendo MCons transitivo, MCons(ai, ak1)∧MCons(ak1, ak2) implica que MCons(ai, ak2) y así sucesivamente hasta MCons(ai, akm)∧MCons(akm, aj) lo cual implica MCons(ai, aj)). Al menos dos agentes son necesariamente inconsistentes (¬MCons(ai, ak1), o ¬MCons(akm, aj), o ∃p0 t.q. ¬MCons(akp0, akp0+1)). Que ak y al sean estos dos vecinos en un momento t > t0 1. La propiedad SOLVE asegura que ya sea ak o al enviará una solicitud de comunicación al otro agente en el tiempo t. Como se mostró anteriormente, esto a su vez garantiza que al menos uno de estos agentes estará involucrado en una comunicación. Entonces hay dos posibilidades: (caso i) ak y al se comunican en el tiempo t. En este caso, sabemos que ¬MCons(ak, al). Esto y la propiedad CONS aseguran que al menos uno de los agentes debe cambiar su 1. Estrictamente hablando, la transitividad de MCons solo asegura que ak y al son inconsistentes en un tiempo t ≥ t0 que puede ser diferente del tiempo t en el que pueden comunicarse. Pero si se vuelven consistentes entre t y t (o inconsistentes entre t y t), significa que al menos uno de ellos ha cambiado su hipótesis entre t y t, es decir, después de t0. Podemos entonces aplicar el razonamiento del caso iib. El Sexto Internacional. La Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 1001 hipótesis, lo cual a su vez, dado que los agentes son autónomos, implica al menos un intercambio de observación. Pero entonces |Ok ∩Ol| está destinado a aumentar: n1(t) > n1(t0). (caso ii) ak se comunica con ap en el tiempo t. Entonces tenemos de nuevo dos posibilidades: (caso iia) ak y ap no se comunicaron desde t0. Pero luego εComm(ak, ap, t0) tenía valor 0 y toma valor 1. Por lo tanto, mt0 aumenta. (caso iib) ak y ap se comunicaron en algún momento t0 > t0. La propiedad CONS del protocolo asegura que MCons(ak, ap) en ese momento. Ahora el hecho de que se comuniquen y se ENFOQUEN implica que al menos uno de ellos cambió su hipótesis en el ínterin. El hecho de que los agentes sean autónomos implica a su vez que una nueva observación (percibida o recibida de otro agente) necesariamente provocó este cambio. El último caso garantizaría la existencia de un tiempo t > t0 y un agente aq tal que |Op ∩ Oq| o |Ok ∩ Oq| aumenten en 1 en ese momento (lo que implica que n1(t) > n1(t0)). El caso anterior significa que el agente obtiene una nueva percepción en el tiempo t. Si esa observación era desconocida en el sistema antes, entonces n2(t) > n2(t0). Si algún agente aq ya conocía esta observación antes, entonces tanto Op ∩ Oq como Ok ∩ Oq aumentan en 1 en el tiempo t (lo que implica que n1(t) > n1(t0)). Por lo tanto, ¬MCons(ai, aj) en el tiempo t0 garantiza que, o bien: −∃t > t0 t.q. n1(t ) > n1(t0); o −∃t > t0 t.q. n2(t ) > n2(t0); o −∃t > t0 t.q. mt0 aumenta en 1 en el tiempo t. Al iterar el razonamiento con t (pero manteniendo t0 como la referencia de tiempo para mt0), podemos eliminar el tercer caso (mt0 es un entero y está limitado por n2, lo que significa que después de un máximo de n2 iteraciones, necesariamente estaremos en uno de los otros dos casos). Como resultado, hemos demostrado que si ¬MCons(ai, aj) en el tiempo t0, necesariamente habrá un tiempo t tal que ya sea n1 o n2 aumentarán. Teorema 1 (Consistencia global). Sea S un sistema poblado por n agentes a1, a2, ..., an, temporalmente conectados e involucrando percepciones limitadas para estos agentes. Sea Cons(ai, aj) una propiedad de consistencia transitiva. Entonces, cualquier protocolo y estrategias que cumplan con las propiedades CONS, SOLVE, FOCUS, COMM y REQU garantizan que el sistema convergerá hacia la consistencia global. Prueba. Por el bien de la contradicción, asumamos que ∃I, J ∈ [1, N] tal que ∀t, ∃t0 > t, tal que ¬Cons(aI , aJ , t0). Usando el lema, esto implica que ∃t > t0 tal que n1(t) > n1(t0) o n2(t) > n2(t0). Pero podemos aplicar el mismo razonamiento tomando t = t, lo que nos daría t1 > t > t0 tal que ¬Cons(aI , aJ , t1), lo que nos da t > t1 tal que n1(t) > n1(t1) o n2(t) > n2(t1). Mediante iteraciones sucesivas podemos construir una secuencia t0, t1, ..., tn, que puede dividirse en dos subsecuencias t0, t1, ...tn y t0, t1, ..., tn tal que n1(t0) < n1(t1) < ... < n1(tn) y n2(t0) < n2(t1) < ... < n2(tn). Una de estas subsecuencias tiene que ser infinita. Sin embargo, n1(ti) y n2(ti) son estrictamente crecientes, enteros y acotados, lo que implica que ambos son finitos. Contradicción. Lo que el resultado anterior muestra esencialmente es que, en un sistema donde ningún agente estará aislado del resto de los agentes para siempre, solo se necesitan suposiciones muy leves sobre los protocolos y estrategias utilizados por los agentes para garantizar la convergencia hacia la consistencia del sistema en una cantidad finita de tiempo (aunque podría llevar mucho tiempo). Desafortunadamente, en muchas situaciones críticas, no será posible asumir esta conexión temporal. Dado que enfoques distribuidos como el abogado en este documento suelen presentarse como una buena manera de abordar problemas de confiabilidad o problemas de dependencia de un centro que son de suma importancia en estas aplicaciones críticas, ciertamente resulta interesante explorar más a fondo cómo se comportaría un sistema de este tipo cuando relajamos esta suposición. ESTUDIO EXPERIMENTAL Este experimento implica agentes tratando de escapar de un edificio en llamas. El entorno se describe como una cuadrícula espacial con un conjunto de paredes y (afortunadamente) algunas salidas. El tiempo y el espacio se consideran discretos. El tiempo se divide en rondas. Los agentes se localizan por su posición en la cuadrícula espacial. Estos agentes pueden moverse y comunicarse con otros agentes. En una ronda, un agente puede moverse una celda en cualquiera de las cuatro direcciones cardinales, siempre y cuando no esté bloqueado por una pared. En esta aplicación, los agentes se comunican con cualquier otro agente (pero, recuerda, solo uno) siempre y cuando este agente esté a la vista y aún no hayan intercambiado su hipótesis actual favorita. De repente, se desata un incendio en estas instalaciones. A partir de este momento, el fuego se propaga. En cada ronda, en cada caso donde haya fuego, el fuego se propaga en las cuatro direcciones. Sin embargo, el fuego no puede propagarse a través de una pared. Si el fuego se propaga en un caso donde un agente está posicionado, ese agente se quema y se considera muerto. Por supuesto, ya no puede moverse ni comunicarse. Si un agente llega a una salida, se considera que está a salvo y ya no puede ser quemado. Los agentes conocen el entorno y las reglas que rigen la dinámica de este entorno, es decir, conocen el mapa así como las reglas de propagación del fuego previamente descritas. También perciben este entorno localmente, pero no pueden ver más allá de 3 casos en cualquier dirección. Las paredes también bloquean la línea de visión, impidiendo que los agentes vean detrás de ellas. Dentro de su campo de visión, pueden ver a otros agentes y si los casos que ven están en llamas. Todas estas percepciones están memorizadas. Mostramos ahora cómo se instancia el marco abstracto presentado en el documento. • O = {Fire(x, y, t), NoFire(x, y, t), Agent(ai, x, y, t)} Las observaciones pueden ser positivas (o ∈ P(O) si ∃h ∈ H tal que h |= o) o negativas (o ∈ N(O) si ∃h ∈ H tal que h |= ¬o). • H={FireOrigin(x1, y1, t1)∧...∧FireOrigin(xl, yl, tl)} Las hipótesis son conjunciones de Orígenes de Fuego. • La relación de consistencia Cons(h, O) satisface: - coherencia: ∀o ∈ N(O), h |= ¬o. - completitud: ∀o ∈ P(O), h |= o. - minimalidad: Para todo h ∈ H, si h es coherente y completo para O, entonces h es preferido a h de acuerdo con la relación de preferencia (h ≤p h). Selecciona primero el número mínimo de orígenes, luego el más reciente (estrategia menos preemptiva [6]), y luego utiliza un ranking fijo arbitrario para discriminar ex-aequo. La relación resultante es un orden total, por lo tanto, la minimalidad implica que habrá un único h tal que Cons(O, h) para un O dado. Esto a su vez significa que MCons(ai, aj) si y solo si Cons(ai), Cons(aj) y hi = hj. Esta relación es entonces transitiva y simétrica. 1002 El Sexto Internacional. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) • Eh toma O como argumento y devuelve min≤p de la hipótesis coherente y completa para O 5.1 Evaluación Experimental Clásicamente evaluaremos la efectividad y eficiencia de diferentes protocolos de interacción (ver, por ejemplo, [3, 4]). La efectividad de un protocolo se determinará por la proporción de agentes que sobreviven al incendio respecto al número inicial de agentes involucrados en el experimento. Si este valor es alto, el protocolo ha sido efectivo para propagar la información y/o para que los agentes refinen sus hipótesis y determinen la mejor manera de salir. Eficiencia de un protocolo. Por lo general, el uso de información de apoyo implicará una sobrecarga de comunicación. Aquí asumiremos que la eficiencia de un protocolo dado está caracterizada por el flujo de datos inducido por este protocolo. En este documento solo discutiremos este aspecto con respecto a los protocolos locales. La medida principal que utilizaremos aquí es el tamaño total promedio de los mensajes intercambiados por los agentes por intercambio (teniendo en cuenta tanto el número de mensajes como el tamaño real de los mensajes, ya que podría ser que los mensajes resulten ser muy grandes, conteniendo por ejemplo un gran número de observaciones, lo que podría contrarrestar un bajo número de mensajes). 5.2 Configuraciones Experimentales Las configuraciones experimentales elegidas son las siguientes: • Topología ambiental: El rendimiento de la propagación de la información está altamente condicionado por la topología del entorno. Las habilidades de percepción de los agentes dependen de la apertura del entorno. Con un gran número de paredes, las percepciones de los agentes están limitadas, al igual que el número de posibles <br>comunicaciones entre agentes</br>, mientras que un entorno abierto proporcionará posibilidades óptimas de percepción y propagación de información. Por lo tanto, proponemos un índice topológico (ver abajo) como base común para caracterizar los entornos (mapas) utilizados durante las experimentaciones. El índice topológico (TI) es la proporción entre el número de celdas que pueden ser percibidas por los agentes sumadas desde todas las posiciones posibles, dividido por el número de celdas que serían percibidas desde las mismas posiciones pero sin paredes. (Cuanto más cercano a 1, más abierto es el entorno). También utilizaremos dos medidas adicionales, más clásicas [10]: la longitud del camino característico (CPL) y el coeficiente de agrupamiento (CC). • Número de agentes: la propagación de la información también depende del número inicial de agentes involucrados durante una experimentación. Por ejemplo, cuantos más agentes haya, más potenciales comunicaciones existen. Esto significa que habrá más potencial de propagación, pero también que la restricción de intercambio bilateral será más crucial. 3 El CPL es la mediana de las medias de las longitudes de los caminos más cortos que conectan cada nodo con todos los demás nodos. 4 caracterizando el grado de aislamiento de una región de un entorno en términos de accesibilidad (número de caminos aún utilizables para llegar a esta región). Mapa T.I. (%) C.P.L. C.C. 69-1 69,23 4,5 0,69 69-2 68,88 4,38 0,65 69-3 69,80 4,25 0,67 53-1 53,19 5,6 0,59 53-2 53,53 6,38 0,54 53-3 53,92 6,08 0,61 38-1 38,56 8,19 0,50 38-2 38,56 7,3 0,50 38-3 38,23 8,13 0,50 Tabla 1: Características Topológicas de los Mapas • Posiciones iniciales de los agentes- Las posiciones iniciales de los agentes tienen una influencia significativa en el comportamiento general de una instancia de nuestro sistema: estar cerca de una salida facilitará (en general) la escapatoria. 5.3 Entornos experimentales Elegimos realizar experimentos en tres índices topológicos muy diferentes (69% para entornos abiertos, 53% para entornos mixtos y 38% para entornos tipo laberinto). Figura 2: Dos mapas (izquierda: IT=69%, derecha IT=38%) Diseñamos tres mapas diferentes para cada índice (la Fig. 2 muestra dos de ellos), conteniendo el mismo número máximo de agentes (máximo 36 agentes) con una densidad máxima de un agente por celda, el mismo número de salidas y un origen de incendio similar (por ejemplo, tiempo y posición de inicio). Los tres mapas diferentes de un índice dado están diseñados de la siguiente manera. El primer plano es un modelo de un piso de un edificio existente. El segundo mapa tiene el mismo perímetro, salidas y origen del fuego que el primero, pero la cantidad y ubicación de las paredes son diferentes (las ubicaciones de las paredes son diseñadas por una heurística que crea paredes de forma aleatoria en la cuadrícula espacial de manera que no se creen habitaciones completamente cerradas y que ninguna salida quede bloqueada). El tercer mapa se caracteriza por un recinto geométrico en el que la ubicación de las paredes también está diseñada con la heurística mencionada anteriormente. La Tabla 1 resume las diferentes medidas topológicas que caracterizan estos mapas diferentes. Vale la pena señalar que los valores confirman la relevancia de TI (los mapas con un alto TI tienen un bajo CPL y un alto CC). Sin embargo, el CPL y el CC permiten refinar aún más la diferencia entre los mapas, por ejemplo, entre 53-1 y 53-2). 5.4 Resultados Experimentales Para cada trío de mapas definidos como se mencionó anteriormente, llevamos a cabo los mismos experimentos. En cada experimento, la sociedad difiere en cuanto a su proporción inicial de agentes involucrados, desde el 1% hasta el 100%. Esta proporción inicial representa el porcentaje de agentes involucrados con respecto al número máximo posible de agentes. Para cada mapa y cada proporción inicial, la Sexta Internacional. En la Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) seleccionamos aleatoriamente 100 ubicaciones iniciales de agentes diferentes. Para cada una de esas ubicaciones diferentes ejecutamos el sistema una vez para cada protocolo de interacción diferente. La efectividad de la comunicación y argumentación El primer experimento que hemos establecido tiene como objetivo probar cuán efectivo es el intercambio de hipótesis (IH), y en particular cómo los aspectos topológicos afectarán esta efectividad. Para hacerlo, hemos calculado la proporción de mejora ofrecida por ese protocolo sobre una situación en la que los agentes simplemente no podían comunicarse (sin comunicación). Para obtener más información sobre en qué medida el intercambio de hipótesis fue realmente crucial, también probamos un protocolo mucho menos elaborado que consistía en intercambios de observaciones simples (OE). Más precisamente, este protocolo requiere que cada agente almacene cualquier observación inesperada que perciba, y los agentes simplemente intercambian sus respectivas listas de observaciones cuando discuten. En este caso, el protocolo local es diferente (nota en particular que no garantiza consistencia mutua), pero el protocolo global permanece igual (con la única excepción de que la motivación de los agentes para comunicarse es sincronizar su lista de observaciones, no sus hipótesis). Si este protocolo es como máximo tan efectivo como HE, tiene la ventaja de ser más eficiente (esto es obvio en cuanto al número de mensajes, que se limitará a 2, menos directo en lo que respecta al tamaño de los mensajes, pero la observación general de que el intercambio de observaciones se puede ver como una versión simplificada del desafío es útil para ver esto). Los resultados de estos experimentos se informan en la Figura 3. Figura 3: Ganancia de la proporción de efectividad comparativa de los protocolos cuando la proporción de agentes aumenta. La primera observación que debe hacerse es que la comunicación mejora la efectividad del proceso, y esta proporción aumenta a medida que el número de agentes crece en el sistema. La segunda lección que aprendemos aquí es que la cercanía relativamente hace que la comunicación sea más efectiva que la falta de comunicación. Los mapas que muestran un T.I. del 38% están constantemente por encima de los otros dos, y el 53% sigue siendo ligeramente pero significativamente mejor que el 69%. Sin embargo, estas curvas también sugieren, quizás sorprendentemente, que HE supera a OE precisamente en aquellas situaciones donde la ganancia de la relación es menos importante (la única diferencia notable ocurre en mapas bastante abiertos donde T.I. es del 69%). Esto se puede explicar de la siguiente manera: cuando un mapa está abierto, los agentes tienen muchos posibles candidatos de explicación, y la argumentación se vuelve útil para discriminar entre ellos. Cuando un mapa es laberíntico, hay menos posibles explicaciones para un evento inesperado. Importancia del Protocolo Global El segundo conjunto de experimentos busca evaluar la importancia del diseño del protocolo global. Probamos nuestro protocolo contra un protocolo de difusión local (LB). La difusión local significa que todos los agentes vecinos percibidos por un agente estarán involucrados en una comunicación con ese agente en una ronda dada, aliviando la restricción de una sola comunicación por agente. Esto nos proporciona un límite superior aproximado sobre la posible ganancia de ratio en el sistema (para un protocolo local dado). Nuevamente, evaluamos la ganancia de la relación inducida por ese LB sobre nuestro HE clásico, para las tres clases diferentes de mapas. Los resultados se informan en la Figura 4. Figura 4: Ganancia de la proporción de transmisión local sobre el intercambio de hipótesis. Tenga en cuenta que la ganancia de la proporción es 0 cuando la proporción de agentes es del 5%, lo cual se explica fácilmente por el hecho de que corresponde a situaciones que involucran solo a dos agentes. Primero observamos que todas las clases de mapas muestran un aumento en la ganancia de la proporción a medida que aumenta el número de agentes: la ganancia alcanza entre el 10 y el 20%, dependiendo de la clase de mapas considerada. Si se compara esto con la mejora reportada en el experimento anterior, parece ser de la misma magnitud. Esto ilustra que el diseño del protocolo global no puede ser ignorado, especialmente cuando la proporción de agentes es alta. Sin embargo, también observamos que las curvas de ganancia de la proporción de efectividad tienen formas muy diferentes en ambos casos: la ganancia inducida por la precisión del protocolo local aumenta muy rápidamente con la proporción de agentes, mientras que la curva es muy suave para el global. Ahora observemos con más cuidado los resultados reportados aquí: la curva correspondiente a una TI del 53% está por encima de la correspondiente al 38%. Esto se debe a que cuanto más abierta sea un mapa, más oportunidades hay de comunicarse con más de un agente (y por lo tanto beneficiarse de la difusión). Sin embargo, también observamos que la curva para el 69% está por debajo de la del 53%. Esto se explica de la siguiente manera: en el caso del 69%, la ganancia potencial en términos de agentes sobrevivientes es mucho menor, porque nuestros protocolos ya ofrecen resultados bastante eficientes de todos modos (alcanzando rápidamente el 90%, ver Fig. 3). Una regla general podría ser que cuando el número de agentes es pequeño, se debe prestar especial atención al local 1004 de la Sexta Internacional. En el caso de que el número de agentes sea pequeño, uno puede utilizar el protocolo de la Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07), mientras que cuando ese número es grande, se debe diseñar cuidadosamente uno global (a menos que el mapa sea tan abierto que el protocolo ya sea casi óptimamente eficiente). La eficiencia de los protocolos. El experimento final reportado aquí se centra en el análisis de la eficiencia de los protocolos. Aquí analizamos el tamaño medio de la totalidad de los mensajes que son intercambiados por agentes (tamaño medio de intercambios, en resumen) utilizando los siguientes protocolos: HE, OE y dos protocolos variantes. El primero es un protocolo de intercambio de hipótesis restringidas (RHE) intermediario. RHE es el siguiente: no implica ningún desafío ni contraoferta, lo que significa que los agentes no pueden cambiar su rol durante el protocolo (esto difiere de RE en ese aspecto). En resumen, RHE permite a un agente agotar las críticas de sus socios, y eventualmente este socio adoptará la hipótesis del agente. Ten en cuenta que esto significa que la autonomía del agente no se conserva aquí (ya que un agente esencialmente aceptará cualquier hipótesis que no pueda socavar), con la esperanza de que la ganancia en eficiencia sea lo suficientemente significativa como para compensar una pérdida en efectividad. El segundo protocolo de variante es un protocolo completo de intercambio de observaciones (COE). COE utiliza los mismos principios que OE, pero incluye además todos los ejemplos críticos negativos (nofire) en el intercambio (dando así todos los ejemplos utilizados como argumentos por el protocolo de intercambio de hipótesis), mejorando así la efectividad. Los resultados para el mapa 69-1 se muestran en la Figura 5. Figura 5: Tamaño medio de los intercambios. Primero podemos observar el hecho de que el orden de los protocolos, desde el menos eficiente hasta el más eficiente, es COE, HE, RHE y luego OE. ÉL siendo más eficiente que COE demuestra que el proceso de argumentación gana eficiencia al seleccionar cuándo es necesario proporcionar ejemplos negativos, los cuales tienen menos impacto que los positivos en nuestro entorno de prueba específico. Sin embargo, al comunicar hipótesis antes de proporcionar observaciones para respaldarla (HE) en lugar de dar directamente las observaciones más cruciales (OE), el proceso de argumentación duplica el tamaño de los intercambios de datos. Es el costo de garantizar la consistencia al final del intercambio (una propiedad que OE no admite). También es significativo el hecho de que el tamaño promedio de los intercambios es ligeramente mayor cuando el número de agentes es pequeño. Esto se explica por el hecho de que en estos casos solo unos pocos agentes tienen información relevante en su posesión, y que necesitarán comunicarse mucho para llegar a un punto de vista común de la situación. Cuando el número de agentes aumenta, este conocimiento se distribuye entre más agentes que necesitan discusiones más cortas para llegar a una consistencia mutua. Como consecuencia, la ganancia relativa en eficiencia de usar RHE parece ser mejor cuando el número de agentes es pequeño: cuando es alto, difícilmente discutirán de todos modos. Finalmente, vale la pena notar que la desviación estándar para estos experimentos es bastante alta, lo que significa que la conversación no converge hacia ningún patrón estereotípico. 6. CONCLUSIÓN Este documento ha investigado las propiedades de un sistema multiagente donde cada agente (distribuido) percibe localmente su entorno e intenta alcanzar consistencia con otros agentes a pesar de severas restricciones de comunicación. En particular, hemos expuesto condiciones que permiten la convergencia e investigado experimentalmente una situación típica donde esas condiciones no pueden cumplirse. Hay muchas posibles extensiones a este trabajo, la primera siendo investigar más a fondo las propiedades de diferentes protocolos globales pertenecientes a la clase que identificamos, y su influencia en el resultado. Existen en particular muchas heurísticas, altamente dependientes del contexto del estudio, que podrían intuitivamente arrojar resultados interesantes (en nuestro estudio, seleccionar al destinatario en función de lo que se pueda inferir de sus acciones observadas podría ser una de esas heurísticas). Un candidato obvio para problemas a largo plazo se refiere a la relajación de la suposición de un sensor perfecto. 7. REFERENCIAS [1] G. Bourgne, N. Maudet y S. Pinson. Cuando los agentes comunican hipótesis en situaciones críticas. En Actas de DALT-2006, mayo de 2006. [2] P. Harvey, C. F. Chang y A. Ghose. Búsqueda distribuida basada en soporte: un nuevo enfoque para el procesamiento de restricciones multiagente. En Actas de AAMAS06, 2006. [3] H. Jung y M. Tambe. Argumentación como satisfacción de restricciones distribuida: Aplicaciones y resultados. En Actas de AGENTS01, 2001. [4] N. C. Karunatillake y N. R. Jennings. ¿Vale la pena discutir? En Actas de ArgMAS 2004, 2004. [5] S. Onta˜n´on y E. Plaza. Argumentos y contraejemplos en la deliberación conjunta basada en casos. En Actas de ArgMAS-2006, mayo de 2006. [6] D. Poole. Explicación y predicción: Una arquitectura para el razonamiento por defecto y abductivo. Inteligencia Computacional, 5(2):97-110, 1989. [7] I. Rahwan, S. D. Ramchurn, N. R. Jennings, P. McBurney, S. Parsons y L. Sonenberg. Negociación basada en argumentos. La revisión de Ingeniería del Conocimiento, 4(18):345-375, 2003. [8] N. Roos, A. ten Tije y C. Witteveen. Un protocolo para el diagnóstico multiagente con conocimiento distribuido espacialmente. En Actas de AAMAS03, 2003. [9] N. Roos, A. ten Tije y C. Witteveen. Alcanzando acuerdo diagnóstico en el diagnóstico multiagente. En Actas de AAMAS04, 2004. [10] T. Takahashi, Y. Kaneda y N. Ito. Estudio preliminar: utilizando simulaciones de RoboCupRescue para la prevención de desastres. En Actas de SRMED2004, 2004. El Sexto Internacional. Conferencia Conjunta sobre Agentes Autónomos y Sistemas Multiagente (AAMAS 07) 1005 ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "negotiation and argumentation": {
            "translated_key": "negociación y argumentación",
            "is_in_text": false,
            "original_annotated_sentences": [
                "Hypotheses Refinement under Topological Communication Constraints ∗ Gauvain Bourgne, Gael Hette, Nicolas Maudet, and Suzanne Pinson LAMSADE, Univ.",
                "Paris-Dauphine, France {bourgne,hette,maudet,pinson}@lamsade.dauphine.fr ABSTRACT We investigate the properties of a multiagent system where each (distributed) agent locally perceives its environment.",
                "Upon perception of an unexpected event, each agent locally computes its favoured hypothesis and tries to propagate it to other agents, by exchanging hypotheses and supporting arguments (observations).",
                "However, we further assume that communication opportunities are severely constrained and change dynamically.",
                "In this paper, we mostly investigate the convergence of such systems towards global consistency.",
                "We first show that (for a wide class of protocols that we shall define), the communication constraints induced by the topology will not prevent the convergence of the system, at the condition that the system dynamics guarantees that no agent will ever be isolated forever, and that agents have unlimited time for computation and arguments exchange.",
                "As this assumption cannot be made in most situations though, we then set up an experimental framework aiming at comparing the relative efficiency and effectiveness of different interaction protocols for hypotheses exchange.",
                "We study a critical situation involving a number of agents aiming at escaping from a burning building.",
                "The results reported here provide some insights regarding the design of optimal protocol for hypotheses refinement in this context.",
                "Categories and Subject Descriptors I.2.11 [Artificial Intelligence]: Distributed Artificial Intelligence-Multiagent systems General Terms Theory, Experimentation 1.",
                "INTRODUCTION We consider a multiagent system where each (distributed) agent locally perceives its environment, and we assume that some unexpected event occurs in that system.",
                "If each agent computes only locally its favoured hypothesis, it is only natural to assume that agents will seek to coordinate and refine their hypotheses by confronting their observations with other agents.",
                "If, in addition, the communication opportunities are severely constrained (for instance, agents can only communicate when they are close enough to some other agent), and dynamically changing (for instance, agents may change their locations), it becomes crucial to carefully design protocols that will allow agents to converge to some desired state of global consistency.",
                "In this paper we exhibit some sufficient conditions on the system dynamics and on the protocol/strategy structures that allow to guarantee that property, and we experimentally study some contexts where (some of) these assumptions are relaxed.",
                "While problems of diagnosis are among the venerable classics in the AI tradition, their multiagent counterparts have much more recently attracted some attention.",
                "Roos and colleagues [8, 9] in particular study a situation where a number of distributed entities try to come up with a satisfying global diagnosis of the whole system.",
                "They show in particular that the number of messages required to establish this global diagnosis is bound to be prohibitive, unless the communication is enhanced with some suitable protocol.",
                "However, they do not put any restrictions on agents communication options, and do not assume either that the system is dynamic.",
                "The benefits of enhancing communication with supporting information to make convergence to a desired global state of a system more efficient has often been put forward in the literature.",
                "This is for instance one of the main idea underlying the argumentation-based negotiation approach [7], where the desired state is a compromise between agents with conflicting preferences.",
                "Many of these works however make the assumption that this approach is beneficial to start with, and study the technical facets of the problem (or instead emphasize other advantages of using argumentation).",
                "Notable exceptions are the works of [3, 4, 2, 5], which studied in contexts different from ours the efficiency of argumentation.",
                "The rest of the paper is as follows.",
                "Section 2 specifies the basic elements of our model, and Section 3 goes on to presenting the different protocols and strategies used by the agents to exchange hypotheses and observations.",
                "We put special attention at clearly emphasizing the conditions on the system dynamics and protocols/strategies that will be exploited in the rest of the paper.",
                "Section 4 details one of 998 978-81-904262-7-5 (RPS) c 2007 IFAAMAS the main results of the paper, namely the fact that under the aforementioned conditions, the constraints that we put on the topology will not prevent the convergence of the system towards global consistency, at the condition that no agent ever gets completely lost forever in the system, and that unlimited time is allowed for computation and argument exchange.",
                "While the conditions on protocols and strategies are fairly mild, it is also clear that these system requirements look much more problematic, even frankly unrealistic in critical situations where distributed approaches are precisely advocated.",
                "To get a clearer picture of the situation induced when time is a critical factor, we have set up an experimental framework that we introduce and discuss in Section 5.",
                "The critical situation involves a number of agents aiming at escaping from a burning building.",
                "The results reported here show that the effectiveness of argument exchange crucially depends upon the nature of the building, and provide some insights regarding the design of optimal protocol for hypotheses refinement in this context. 2.",
                "BASIC NOTIONS We start by defining the basic elements of our system.",
                "Environment Let O be the (potentially infinite) set of possible observations.",
                "We assume the sensors of our agents to be perfect, hence the observations to be certain.",
                "Let H be the set of hypotheses, uncertain and revisable.",
                "Let Cons(h, O) be the consistency relation, a binary relation between a hypothesis h ∈ H and a set of observations O ⊆ O.",
                "In most cases, Cons will refer to classical consistency relation, however, we may overload its meaning and add some additional properties to that relation (in which case we will mention it).",
                "The environment may include some dynamics, and change over the course of time.",
                "We define below sequences of time points to deal with it: Definition 1 (Sequence of time points).",
                "A sequence of time points t1, t2, . . . , tn from t is an ordered set of time points t1, t2, . . . , tn such that t1 ≥ t and ∀i ∈ [1, n − 1], ti+1 ≥ ti.",
                "Agent We take a system populated by n agents a1, . . . , an.",
                "Each agent is defined as a tuple F, Oi, hi , where: • F, the set of facts, common knowledge to all agents. • Oi ∈ 2O , the set of observations made by the agent so far.",
                "We assume a perfect memory, hence this set grows monotonically. • hi ∈ H, the favourite hypothesis of the agent.",
                "A key notion governing the formation of hypotheses is that of consistency, defined below: Definition 2 (Consistency).",
                "We say that: • An agent is consistent (Cons(ai)) iff Cons(hi, Oi) (that is, its hypothesis is consistent with its observation set). • An agent ai consistent with a partner agent aj iff Cons(ai) and Cons(hi, Oj) (that is, this agent is consistent and its hypothesis can explain the observation set of the other agent). • Two agents ai and aj are mutually consistent (MCons(ai, aj)) iff Cons(ai, aj) and Cons(aj, ai). • A system is consistent iff ∀(i, j)∈[1, n]2 it is the case that MCons(ai, aj).",
                "To ensure its consistency, each agent is equipped with an abstract reasoning machinery that we shall call the explanation function Eh.",
                "This (deterministic) function takes a set of observation and returns a single prefered hypothesis (2O → H).",
                "We assume h = Eh(O) to be consistent with O by definition of Eh, so using this function on its observation set to determine its favourite hypothesis is a sure way for the agent to achieve consistency.",
                "Note however that an hypothesis does not need to be generated by Eh to be consistent with an observation set.",
                "As a concrete example of such a function, and one of the main inspiration of this work, one can cite the Theorist reasoning system [6] -as long as it is coupled with a filter selecting a single prefered theory among the ones initially selected by Theorist.",
                "Note also that hi may only be modified as a consequence of the application Eh.",
                "We refer to this as the autonomy of the agent: no other agent can directly impose a given hypothesis to an agent.",
                "As a consequence, only a new observation (being it a new perception, or an observation communicated by a fellow agent) can result in a modification of its prefered hypothesis hi (but not necessarily of course).",
                "We finally define a property of the system that we shall use in the rest of the paper: Definition 3 (Bounded Perceptions).",
                "A system involves a bounded perception for agents iff ∃n0 s.t. ∀t| ∪N i=1 Oi| ≤ n0. (That is, the number of observations to be made by the agents in the system is not infinite.)",
                "Agent Cycle Now we need to see how these agents will evolve and interact in their environment.",
                "In our context, agents evolve in a dynamic environment, and we classicaly assume the following system cycle: 1.",
                "Environment dynamics: the environment evolves according to the defined rules of the system dynamics. 2.",
                "Perception step : agents get perceptions from the environment.",
                "These perceptions are typically partial (e.g. the agent can only see a portion of a map). 3.",
                "Reasoning step: agents compare perception with predictions, seek explanations for (potential) difference(s), refine their hypothesis, draw new conclusions. 4.",
                "Communication step: agents can communicate hypotheses and observations with other agents through a defined protocol.",
                "Any agent can only be involved in one communication with another agent by step. 5.",
                "Action step: agents do some practical reasoning using the models obtained from the previous steps and select an action.",
                "They can then modify the environment by executing it.",
                "The communication of the agents will be further constrained by topological consideration.",
                "At a given time, an agent will only be able to communicate with a number of neighbours.",
                "Its connexions with these others agents may The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 999 evolve with its situation in the environment.",
                "Typically, an agent can only communicate with agents that it can sense, but one could imagine evolving topological constraints on communication based on a network of communications between agents where the links are not always active.",
                "Communication In our system, agents will be able to communicate with each other.",
                "However, due to the aforementionned topological constraints, they will not be able to communicate with any agents at anytime.",
                "Who an agent can communicate with will be defined dynamically (for instance, this can be a consequence of the agents being close enough to get in touch).",
                "We will abstractly denote by C(ai, aj, t) the communication property, in other words, the fact that agents ai and aj can communicate at time t (note that this relation is assumed to be symetric, but of course not transitive).",
                "We are now in a position to define two essential properties of our system.",
                "Definition 4 (Temporal Path).",
                "There exists a temporal communication path at horizon tf (noted Ltf (aI , aJ )) between ai and aj iff there exists a sequence of time points t1, t2, . . . , tn from tf and a sequence of agents k1, k2, . . . , kn s.t. (i) C(aI , ak1 , t1), (ii) C(akn , aJ , tn+1), (iii) ∀i ∈ [1, n], C(aki , aki+1 , ti) Intuitively, what this property says is that it is possible to find a temporal path in the future that would allow to link agent ai and aj via a sequence of intermediary agents.",
                "Note that the time points are not necessarily successive, and that the sequence of agents may involve the same agents several times.",
                "Definition 5 (Temporal Connexity).",
                "A system is temporaly connex iff ∀t ∀(i, j)∈[1, n]2 Lt(ai, aj) In short, a temporaly connex system guarantees that any agent will be able to communicate with any other agents, no matter how long it might take to do so, at any time.",
                "To put it another way, it is never the case that an agent will be isolated for ever from another agent of the system.",
                "We will next discuss the detail of how communication concretely takes place in our system.",
                "Remember that in this paper, we only consider the case of bilateral exchanges (an agent can only speak to a single other agent), and that we also assume that any agent can only engage in a single exchange in a given round. 3.",
                "PROTOCOLS AND STRATEGIES In this section, we discuss the requirements of the interaction protocols that govern the exchange of messages between agents, and provide some example instantiation of such protocols.",
                "To clarify the presentation, we distinguish two levels: the local level, which is concerned with the regulation of bilateral exchanges; and the global level,which essentially regulates the way agents can actually engage into a conversation.",
                "At each level, we separate what is specified by the protocol, and what is left to agents strategies.",
                "Local Protocol and Strategies We start by inspecting local protocols and strategies that will regulate the communication between the agents of the system.",
                "As we limit ourselves to bilateral communication, these protocols will simply involve two agents.",
                "Such protocol will have to meet one basic requirement to be satisfying. • consistency (CONS)- a local protocol has to guarantee the mutual consistency of agents upon termination (which implies termination of course).",
                "Figure 1: A Hypotheses Exchange Protocol [1] One example such protocol is the protocol described in [1] that is pictured in Fig. 1.",
                "To further illustrate how such protocol can be used by agents, we give some details on a possible strategy: upon receiving a hypothesis h1 (propose(h1) or counterpropose(h1)) from a1, agent a2 is in state 2 and has the following possible replies: counterexample (if the agent knows an example contradicting the hypothesis, or not explained by this hypothesis), challenge (if the agents lacks evidence to accept this hypothesis), counterpropose (if the agent agrees with the hypothesis but prefers another one), or accept (if it is indeed as good as its favourite hypothesis).",
                "This strategy guarantees, among other properties, the eventual mutual logical consistency of the involved agents [1].",
                "Global Protocol The global protocol regulates the way bilateral exchanges will be initiated between agents.",
                "At each turn, agents will concurrently send one weighted request to communicate to other agents.",
                "This weight is a value measuring the agents willingness to converse with the targeted agent (in practice, this can be based on different heuristics, but we shall make some assumptions on agents strategies, see below).",
                "Sending such a request is a kind of conditional commitment for the agent.",
                "An agent sending a weighted request commits to engage in conversation with the target if he does not receive and accept himself another request.",
                "Once all request have been received, each agent replies with either an acccept or a reject.",
                "By answering with an accept, an agent makes a full commitment to engage in conversation with the sender.",
                "Therefore, it can only send one accept in a given round, as an agent can only participate in one conversation per time step.",
                "When all response have been received, each agent receiving an accept can either initiate a conversation using the local protocol or send a cancel if it has accepted another request.",
                "At the end of all the bilateral exchanges, the agents engaged in conversation are discarded from the protocol.",
                "Then each of the remaining agents resends a request and the process iterates until no more requests are sent.",
                "Global Strategy We now define four requirements for the strategies used by agents, depending on their role in the protocol: two are concerned with the requestee role (how to decide who the 1000 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) agent wishes to communicate with? ), the other two with the responder role (how to decide which communication request to accept or not?). • Willingness to solve inconsistancies (SOLVE)-agents want to communicate with any other agents unless they know they are mutually consistent. • Focus on solving inconsistencies (FOCUS)-agents do not request communication with an agent with whom they know they are mutually consistent. • Willingness to communicate (COMM)-agents cannot refuse a weighted communication request, unless they have just received or send a request with a greater weight. • Commitment to communication request (REQU)agents cannot accept a weighted communication request if they have themselves sent a communication request with a greater weight.",
                "Therefore, they will not cancel their request unless they have received a communicational request with greater weight.",
                "Now the protocol structure, together with the properties COMM+REQU, ensure that a request can only be rejected if its target agent engages in communication with another agent.",
                "Suppose indeed that agent ai wants to communicate with aj by sending a request with weight w. COMM guarantees that an agent receiving a weighted request will either accept this communication, accept a communication with a greater weight or wait for the answer to a request with a greater weight.",
                "This ensures that the request with maximal weight will be accepted and not cancelled (as REQU ensures that an agent sending a request can only cancel it if he accepts another request with greater weight).",
                "Therefore at least two agents will engage in conversation per round of the global protocol.",
                "As the protocol ensures that ai can resend its request while aj is not engaged in a conversation, there will be a turn in which aj must engage in a conversation, either with ai or another agent.",
                "These requirements concern request sending and acceptation, but agents also need some strategy of weight attribution.",
                "We describe below an altruist strategy, used in our experiments.",
                "Being cooperative, an agent may want to know more of the communication wishes of other agents in order to improve the overall allocation of exchanges to agents.",
                "A context request step is then added to the global protocol.",
                "Before sending their chosen weighted request, agents attribute a weight to all agents they are prepared to communicate with, according to some internal factors.",
                "In the simplest case, this weight will be 1 for all agent with whom the agent is not sure of being mutually consistent (ensuring SOLVE), other agent being not considered for communication (ensuring FOCUS).",
                "The agent then sends a context request to all agents with whom communication is considered.",
                "This request also provides information about the sender (list of considered communications along with their weight).",
                "After reception of all the context requests, agents will either reply with a deny, iff they are already engaged in a conversation (in which case, the requesting agent will not consider communication with them anymore in this turn), or an inform giving the requester information about the requests it has sent and received.",
                "When all replies have been received, each agent can calculate the weight of all requests concerning it.",
                "It does so by substracting from the weight of its request the weight of all requests concerning either it or its target (that is, the final weight of the request from ai to aj is Wi,j = wi,j +wj,i − ( P k∈R(i)−{j} wi,k + P k∈S(i)−{j} wk,i + P k∈R(j)−{i} wj,k + P k∈S(j)−{i} wk,j) where wi,j is the weight of the request of ai to aj, R(i) is the set of indice of agents having received a request from ai and S(i) is the set of indice of agents having send a request to ai).",
                "It then finally sends a weighted request to the agents who maximise this weight (or wait for a request) as described in the global protocol. 4. (CONDITIONAL) CONVERGENCE TO GLOBAL CONSISTENCY In this section we will show that the requirements regarding protocols and strategies just discussed will be sufficient to ensure that the system will eventually converge towards global consistency, under some conditions.",
                "We first show that, if two agents are not mutually consistent at some time, then there will be necessarily a time in the future such that an agent will learn a new observation, being it because it is new for the system, or by learning it from another agent.",
                "Lemma 1.",
                "Let S be a system populated by n agents a1, a2, ..., an, temporaly connex, and involving bounded perceptions for these agents.",
                "Let n1 be the sum of cardinalities of the intersection of pairwise observation sets. (n1 = P (i,j)∈[1,n]2 |Oi ∩ Oj|) Let n2 be the cardinality of the union of all agents observations sets. (n2 = | ∪N i=1 Oi|).",
                "If ¬MCons(ai, aj) at time t0, there is necessarily a time t > t0 s.t. either n1 or n2 will increase.",
                "Proof.",
                "Suppose that there exist a time t0 and indices (i, j) s.t. ¬MCons(ai, aj).",
                "We will use mt0 = P (k,l)∈[1,n]2 εComm(ak, al, t0) where εComm(ak, al, t0) = 1 if ak and al have communicated at least once since t0, and 0 otherwise.",
                "Temporal connexity guarantees that there exist t1, ..., tm+1 and k1, ..., km s.t.",
                "C(ai, ak1 , t1), C(akm , aj, tm+1), and ∀p ∈ [1, m], C(akp , akp+1 , tp).",
                "Clearly, if MCons(ai, ak1 ), MCons(akm , aj) and ∀p, MCons(akp , akp+1 ), we have MCons(ai, aj) which contradicts our hypothesis (MCons being transitive, MCons(ai, ak1 )∧MCons(ak1 , ak2 ) implies that MCons(ai, ak2 ) and so on till MCons(ai, akm )∧ MCons(akm , aj) which implies MCons(ai, aj) ).",
                "At least two agents are then necessarily inconsistent (¬MCons(ai, ak1 ), or ¬MCons(akm , aj), or ∃p0 t.q. ¬MCons(akp0 , akp0+1 )).",
                "Let ak and al be these two neighbours at a time t > t0 1 .",
                "The SOLVE property ensures that either ak or al will send a communication request to the other agent at time t .",
                "As shown before, this in turn ensures that at least one of these agents will be involved in a communication.",
                "Then there are two possibilities: (case i) ak and al communicate at time t .",
                "In this case, we know that ¬MCons(ak, al).",
                "This and the CONS property ensures that at least one of the agents must change its 1 Strictly speaking, the transitivity of MCons only ensure that ak and al are inconsistent at a time t ≥ t0 that can be different from the time t at which they can communicate.",
                "But if they become consistent between t and t (or inconsistent between t and t ), it means that at least one of them have changed its hypothesis between t and t , that is, after t0.",
                "We can then apply the reasoning of case iib.",
                "The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 1001 hypothesis, which in turn, since agents are autonomous, implies at least one exchange of observation.",
                "But then |Ok ∩Ol| is bound to increase: n1(t ) > n1(t0). (case ii) ak communicates with ap at time t .",
                "We then have again two possibilities: (case iia) ak and ap did not communicate since t0.",
                "But then εComm(ak, ap, t0) had value 0 and takes value 1.",
                "Hence mt0 increases. (case iib) ak and ap did communicate at some time t0 > t0.",
                "The CONS property of the protocol ensures that MCons(ak, ap) at that time.",
                "Now the fact that they communicate and FOCUS implies that at least one of them did change its hypothesis in the meantime.",
                "The fact that agents are autonomous implies in turn that a new observation (perceived or received from another agent) necessarily provoked this change.",
                "The latter case would ensure the existence of a time t > t0 and an agent aq s.t. either |Op ∩Oq| or |Ok ∩Oq| increases of 1 at that time (implying n1(t ) > n1(t0)).",
                "The former case means that the agent gets a new perception o at time t .",
                "If that observation was unknown in the system before, then n2(t ) > n2(t0).",
                "If some agent aq already knew this observation before, then either Op ∩ Oq or Ok ∩ Oq increases of 1 at time t (which implies that n1(t ) > n1(t0)).",
                "Hence, ¬MCons(ai, aj) at time t0 guarantees that, either: −∃t > t0 t.q. n1(t ) > n1(t0); or −∃t > t0 t.q. n2(t ) > n2(t0); or −∃t > t0 t.q. mt0 increases of 1 at time t .",
                "By iterating the reasoning with t (but keeping t0 as the time reference for mt0 ), we can eliminate the third case (mt0 is integer and bounded by n2 , which means that after a maximum of n2 iterations, we necessarily will be in one of two other cases.)",
                "As a result, we have proven that if ¬MCons(ai, aj) at time t0, there is necessarily a time t s.t. either n1 or n2 will increase.",
                "Theorem 1 (Global consistency).",
                "Let S be a system populated by n agents a1, a2, ..., an, temporaly connex, and involving bounded perceptions for these agents.",
                "Let Cons(ai, aj) be a transitive consistency property.",
                "Then any protocol and strategies satisfying properties CONS, SOLVE, FOCUS, COMM and REQU guarantees that the system will converge towards global consistency.",
                "Proof.",
                "For the sake of contradiction, let us assume ∃I, J ∈ [1, N] s.t. ∀t, ∃t0 > t, t.q. ¬Cons(aI , aJ , t0).",
                "Using the lemma, this implies that ∃t > t0 s.t. either n1(t ) > n1(t0) or n2(t ) > n2(t0).",
                "But we can apply the same reasoning taking t = t , which would give us t1 > t > t0 s.t. ¬Cons(aI , aJ , t1), which gives us t > t1 s.t. either n1(t ) > n1(t1) or n2(t ) > n2(t1).",
                "By successive iterations we can then construct a sequence t0, t1, ..., tn, which can be divided in two sub-sequences t0, t1, ...tn and t0 , t1 , ..., tn s.t. n1(t0) < n1(t1) < ... < n1(tn) and n2(t0 ) < n2(t1 ) < ... < n2(tn).",
                "One of these sub-sequences has to be infinite.",
                "However, n1(ti) and n2(ti ) are strictly growing, integer, and bounded, which implies that both are finite.",
                "Contradiction.",
                "What the previous result essentially shows is that, in a system where no agent will be isolated from the rest of the agents for ever, only very mild assumptions on the protocols and strategies used by agents suffice to guarantee convergence towards system consistency in a finite amount of time (although it might take very long).",
                "Unfortunately, in many critical situations, it will not be possible to assume this temporal connexity.",
                "As distributed approaches as the one advocated in this paper are precisely often presented as a good way to tackle problems of reliability or problems of dependence to a center that are of utmost importance in these critical applications, it is certainly interesting to further explore how such a system would behave when we relax this assumption. 5.",
                "EXPERIMENTAL STUDY This experiment involves agents trying to escape from a burning building.",
                "The environment is described as a spatial grid with a set of walls and (thankfully) some exits.",
                "Time and space are considered discrete.",
                "Time is divided in rounds.",
                "Agents are localised by their position on the spatial grid.",
                "These agents can move and communicate with other agents.",
                "In a round, an agent can move of one cell in any of the four cardinal directions, provided it is not blocked by a wall.",
                "In this application, agents communicate with any other agent (but, recall, a single one) given that this agent is in view, and that they have not yet exchanged their current favoured hypothesis.",
                "Suddenly, a fire erupts in these premises.",
                "From this moment, the fire propagates.",
                "Each round, for each cases where there is fire, the fire propagates in the four directions.",
                "However, the fire cannot propagate through a wall.",
                "If the fire propagates in a case where an agent is positioned, that agent burns and is considered dead.",
                "It can of course no longer move nor communicate.",
                "If an agent gets to an exit, it is considered saved, and can no longer be burned.",
                "Agents know the environment and the rules governing the dynamics of this environment, that is, they know the map as well as the rules of fire propagation previously described.",
                "They also locally perceive this environment, but cannot see further than 3 cases away, in any direction.",
                "Walls also block the line of view, preventing agents from seeing behind them.",
                "Within their sight, they can see other agents and whether or not the cases they see are on fire.",
                "All these perceptions are memorised.",
                "We now show how this instantiates the abstract framework presented the paper. • O = {Fire(x, y, t), NoFire(x, y, t), Agent(ai, x, y, t)} Observations can then be positive (o ∈ P(O) iff ∃h ∈ H s.t. h |= o) or negative (o ∈ N(O) iff ∃h ∈ H s.t. h |= ¬o). • H={FireOrigin(x1, y1, t1)∧...∧FireOrigin(xl, yl, tl)} Hypotheses are conjunctions of FireOrigins. • Cons(h, O) consistency relation satisfies: - coherence : ∀o ∈ N(O), h |= ¬o. - completeness : ∀o ∈ P(O), h |= o. - minimality : For all h ∈ H, if h is coherent and complete for O, then h is prefered to h according to the preference relation (h ≤p h ).2 2 Selects first the minimal number of origins, then the most recent (least preemptive strategy [6]), then uses some arbitrary fixed ranking to discriminate ex-aequo.",
                "The resulting relation is a total order, hence minimality implies that there will be a single h s.t.Cons(O, h) for a given O.",
                "This in turn means that MCons(ai, aj) iff Cons(ai), Cons(aj), and hi = hj.",
                "This relation is then transitive and symmetric. 1002 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) • Eh takes O as argument and returns min≤p of the coherent and complete hypothesis for O 5.1 Experimental Evaluation We will classically (see e.g. [3, 4]) assess the effectiveness and efficiency of different interaction protocols.",
                "Effectiveness of a protocol The proportion of agents surviving the fire over the initial number of agents involved in the experiment will determine the effectiveness of a given protocol.",
                "If this value is high, the protocol has been effective to propagate the information and/or for the agents to refine their hypotheses and determine the best way to the exit.",
                "Efficiency of a protocol Typically, the use of supporting information will involve a communication overhead.",
                "We will assume here that the efficiency of a given protocol is characterised by the data flow induced by this protocol.",
                "In this paper we will only discuss this aspect wrt. local protocols.",
                "The main measure that we shall then use here is the mean total size of messages that are exchanged by agents per exchange (hence taking into account both the number of messages and the actual size of the messages, because it could be that messages happen to be very big, containing e.g. a large number of observations, which could counter-balance a low number of messages). 5.2 Experimental Settings The chosen experimental settings are the following: • Environmental topology- Performances of information propagation are highly constrained by the environment topology.",
                "The perception skills of the agents depend on the openness of the environment.",
                "With a large number of walls the perceptions of agents are limited, and also the number of possible inter-agent communications, whereas an open environment will provide optimal possibilities of perception and information propagation.",
                "Thus, we propose a topological index (see below) as a common basis to charaterize the environments (maps) used during experimentations.",
                "The topological index (TI) is the ratio of the number of cells that can be perceived by agents summed up from all possible positions, divided by the number of cells that would be perceived from the same positions but without any walls. (The closer to 1, the more open the environment).",
                "We shall also use two additional, more classical [10], measures: the characteristic path length3 (CPL) and the clustering coefficient4 (CC). • Number of agents- The propagation of information also depends on the initial number of agents involved during an experimentation.",
                "For instance, the more agents, the more potential communications there is.",
                "This means that there will be more potential for propagation, but also that the bilateral exchange restriction will be more crucial. 3 The CPL is the median of the means of the shortest path lengths connecting each node to all other nodes. 4 characterising the isolation degree of a region of an environment in terms of acessibility (number of roads still usable to reach this region).",
                "Map T.I. (%) C.P.L.",
                "C.C. 69-1 69,23 4,5 0,69 69-2 68,88 4,38 0,65 69-3 69,80 4,25 0,67 53-1 53,19 5,6 0,59 53-2 53,53 6,38 0,54 53-3 53,92 6,08 0,61 38-1 38,56 8,19 0,50 38-2 38,56 7,3 0,50 38-3 38,23 8,13 0,50 Table 1: Topological Characteristics of the Maps • Initial positions of the agents- Initial positions of the agents have a significant influence on the overall behavior of an instance of our system: being close from an exit will (in general) ease the escape. 5.3 Experimental environments We choose to realize experiments on three very different topological indexes (69% for open environments, 53% for mixed environments, and 38% for labyrinth-like environments).",
                "Figure 2: Two maps (left: TI=69%, right TI=38%) We designed three different maps for each index (Fig. 2 shows two of them), containing the same maximum number of agents (36 agents max.) with a maximum density of one agent per cell, the same number of exits and a similar fire origin (e.g. starting time and position).",
                "The three differents maps of a given index are designed as follows.",
                "The first map is a model of an existing building floor.",
                "The second map has the same enclosure, exits and fire origin as the first one, but the number and location of walls are different (wall locations are designed by an heuristic which randomly creates walls on the spatial grid such that no fully closed rooms are created and that no exit is closed).",
                "The third map is characterised by geometrical enclosure in wich walls location is also designed with the aforementioned heuristic.",
                "Table 1 summarizes the different topological measures characterizing these different maps.",
                "It is worth pointing out that the values confirm the relevance of TI (maps with a high TI have a low CPL and a high CC.",
                "However the CPL and CC allows to further refine the difference between the maps, e.g. between 53-1 and 53-2). 5.4 Experimental Results For each triple of maps defined as above we conduct the same experiments.",
                "In each experiment, the society differs in terms of its initial proportion of involved agents, from 1% to 100%.",
                "This initial proportion represents the percentage of involved agents with regards to the possible maximum number of agents.",
                "For each map and each initial proportion, The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 1003 we select randomly 100 different initial agents locations.",
                "For each of those different locations we execute the system one time for each different interaction protocol.",
                "Effectiveness of Communication and Argumentation The first experiment that we set up aims at testing how effective is hypotheses exchange (HE), and in particular how the topological aspects will affect this effectiveness.",
                "In order to do so, we have computed the ratio of improvement offered by that protocol over a situation where agents could simply not communicate (no comm).",
                "To get further insights as to what extent the hypotheses exchange was really crucial, we also tested a much less elaborated protocol consisting of mere observation exchanges (OE).",
                "More precisely, this protocol requires that each agent stores any unexpected observation that it perceives, and agents simply exchange their respective lists of observations when they discuss.",
                "In this case, the local protocol is different (note in particular that it does not guarantee mutual consistency), but the global protocol remains the same (at the only exception that agents motivation to communicate is to synchronise their list of observations, not their hypothesis).",
                "If this protocol is at best as effective as HE, it has the advantage of being more efficient (this is obvious wrt the number of messages which will be limited to 2, less straightforward as far as the size of messages is concerned, but the rough observation that the exchange of observations can be viewed as a flat version of the challenge is helpful to see this).",
                "The results of these experiments are reported in Fig. 3.",
                "Figure 3: Comparative effectiveness ratio gain of protocols when the proportion of agents augments The first observation that needs to be made is that communication improves the effectiveness of the process, and this ratio increases as the number of agents grows in the system.",
                "The second lesson that we learn here is that closeness relatively makes communication more effective over non communication.",
                "Maps exhibiting a T.I. of 38% are constantly above the two others, and 53% are still slightly but significantly better than 69%.",
                "However, these curves also suggest, perhaps surprisingly, that HE outperforms OE in precisely those situations where the ratio gain is less important (the only noticeable difference occurs for rather open maps where T.I. is 69%).",
                "This may be explained as follows: when a map is open, agents have many potential explanation candidates, and argumentation becomes useful to discriminate between those.",
                "When a map is labyrinth-like, there are fewer possible explanations to an unexpected event.",
                "Importance of the Global Protocol The second set of experiments seeks to evaluate the importance of the design of the global protocol.",
                "We tested our protocol against a local broadcast (LB) protocol.",
                "Local broadcast means that all the neighbours agents perceived by an agent will be involved in a communication with that agent in a given round -we alleviate the constraint of a single communication by agent.",
                "This gives us a rough upper bound upon the possible ratio gain in the system (for a given local protocol).",
                "Again, we evaluated the ratio gain induced by that LB over our classical HE, for the three different classes of maps.",
                "The results are reported in Fig. 4.",
                "Figure 4: Ratio gain of local broadcast over hypotheses exchange Note to begin with that the ratio gain is 0 when the proportion of agents is 5%, which is easily explained by the fact that it corresponds to situations involving only two agents.",
                "We first observe that all classes of maps witness a ratio gain increasing when the proportion of agents augments: the gain reaches 10 to 20%, depending on the class of maps considered.",
                "If one compares this with the improvement reported in the previous experiment, it appears to be of the same magnitude.",
                "This illustrates that the design of the global protocol cannot be ignored, especially when the proportion of agents is high.",
                "However, we also note that the effectiveness ratio gain curves have very different shapes in both cases: the gain induced by the accuracy of the local protocol increases very quickly with the proportion of agents, while the curve is really smooth for the global one.",
                "Now let us observe more carefully the results reported here: the curve corresponding to a TI of 53% is above that corresponding to 38%.",
                "This is so because the more open a map, the more opportunities to communicate with more than one agent (and hence benefits from broadcast).",
                "However, we also observe that curve for 69% is below that for 53%.",
                "This is explained as follows: in the case of 69%, the potential gain to be made in terms of surviving agents is much lower, because our protocols already give rather efficient outcomes anyway (quickly reaching 90%, see Fig. 3).",
                "A simple rule of thumb could be that when the number of agents is small, special attention should be put on the local 1004 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) protocol, whereas when that number is large, one should carefully design the global one (unless the map is so open that the protocol is already almost optimally efficient).",
                "Efficiency of the Protocols The final experiment reported here is concerned with the analysis of the efficiency of the protocols.",
                "We analysis here the mean size of the totality of the messages that are exchanged by agents (mean size of exchanges, for short) using the following protocols: HE, OE, and two variant protocols.",
                "The first one is an intermediary restricted hypotheses exchange protocol (RHE).",
                "RHE is as follows: it does not involve any challenge nor counter-propose, which means that agents cannot switch their role during the protocol (this differs from RE in that respect).",
                "In short, RHE allows an agent to exhaust its partners criticism, and eventually this partner will come to adopt the agents hypothesis.",
                "Note that this means that the autonomy of the agent is not preserved here (as an agent will essentially accept any hypothesis it cannot undermine), with the hope that the gain in efficiency will be significant enough to compensate a loss in effectiveness.",
                "The second variant protocol is a complete observation exchange protocol (COE).",
                "COE uses the same principles as OE, but includes in addition all critical negative examples (nofire) in the exchange (thus giving all examples used as arguments by the hypotheses exchanges protocol), hence improving effectiveness.",
                "Results for map 69-1 are shown on Fig. 5.",
                "Figure 5: Mean size of exchanges First we can observe the fact that the ordering of the protocols, from the least efficient to the most efficient, is COE, HE, RHE and then OE.",
                "HE being more efficient than COE proves that the argumentation process gains efficiency by selecting when it is needed to provide negative example, which have less impact that positive ones in our specific testbed.",
                "However, by communicating hypotheses before eventually giving observation to support it (HE) instead of directly giving the most crucial observations (OE), the argumentation process doubles the size of data exchanges.",
                "It is the cost for ensuring consistency at the end of the exchange (a property that OE does not support).",
                "Also significant is the fact the the mean size of exchanges is slightly higher when the number of agents is small.",
                "This is explained by the fact that in these cases only a very few agents have relevant informations in their possession, and that they will need to communicate a lot in order to come up with a common view of the situation.",
                "When the number of agents increases, this knowledge is distributed over more agents which need shorter discussions to get to mutual consistency.",
                "As a consequence, the relative gain in efficiency of using RHE appears to be better when the number of agents is small: when it is high, they will hardly argue anyway.",
                "Finally, it is worth noticing that the standard deviation for these experiments is rather high, which means that the conversation do not converge to any stereotypic pattern. 6.",
                "CONCLUSION This paper has investigated the properties of a multiagent system where each (distributed) agent locally perceives its environment, and tries to reach consistency with other agents despite severe communication restrictions.",
                "In particular we have exhibited conditions allowing convergence, and experimentally investigated a typical situation where those conditions cannot hold.",
                "There are many possible extensions to this work, the first being to further investigate the properties of different global protocols belonging to the class we identified, and their influence on the outcome.",
                "There are in particular many heuristics, highly dependent on the context of the study, that could intuitively yield interesting results (in our study, selecting the recipient on the basis of what can be inferred from his observed actions could be such a heuristic).",
                "One obvious candidate for longer term issues concern the relaxation of the assumption of perfect sensing. 7.",
                "REFERENCES [1] G. Bourgne, N. Maudet, and S. Pinson.",
                "When agents communicate hypotheses in critical situations.",
                "In Proceedings of DALT-2006, May 2006. [2] P. Harvey, C. F. Chang, and A. Ghose.",
                "Support-based distributed search: a new approach for multiagent constraint processing.",
                "In Proceedings of AAMAS06, 2006. [3] H. Jung and M. Tambe.",
                "Argumentation as distributed constraint satisfaction: Applications and results.",
                "In Proceedings of AGENTS01, 2001. [4] N. C. Karunatillake and N. R. Jennings.",
                "Is it worth arguing?",
                "In Proceedings of ArgMAS 2004, 2004. [5] S. Onta˜n´on and E. Plaza.",
                "Arguments and counterexamples in case-based joint deliberation.",
                "In Proceedings of ArgMAS-2006, May 2006. [6] D. Poole.",
                "Explanation and prediction: An architecture for default and abductive reasoning.",
                "Computational Intelligence, 5(2):97-110, 1989. [7] I. Rahwan, S. D. Ramchurn, N. R. Jennings, P. McBurney, S. Parsons, and L. Sonenberg.",
                "Argumention-based negotiation.",
                "The Knowledge Engineering Review, 4(18):345-375, 2003. [8] N. Roos, A. ten Tije, and C. Witteveen.",
                "A protocol for multi-agent diagnosis with spatially distributed knowledge.",
                "In Proceedings of AAMAS03, 2003. [9] N. Roos, A. ten Tije, and C. Witteveen.",
                "Reaching diagnostic agreement in multiagent diagnosis.",
                "In Proceedings of AAMAS04, 2004. [10] T. Takahashi, Y. Kaneda, and N. Ito.",
                "Preliminary study - using robocuprescue simulations for disasters prevention.",
                "In Proceedings of SRMED2004, 2004.",
                "The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 1005"
            ],
            "original_annotated_samples": [],
            "translated_annotated_samples": [],
            "translated_text": "",
            "candidates": [],
            "error": [
                []
            ]
        },
        "agent communication language and protocol": {
            "translated_key": "lenguaje y protocolo de comunicación del agente",
            "is_in_text": false,
            "original_annotated_sentences": [
                "Hypotheses Refinement under Topological Communication Constraints ∗ Gauvain Bourgne, Gael Hette, Nicolas Maudet, and Suzanne Pinson LAMSADE, Univ.",
                "Paris-Dauphine, France {bourgne,hette,maudet,pinson}@lamsade.dauphine.fr ABSTRACT We investigate the properties of a multiagent system where each (distributed) agent locally perceives its environment.",
                "Upon perception of an unexpected event, each agent locally computes its favoured hypothesis and tries to propagate it to other agents, by exchanging hypotheses and supporting arguments (observations).",
                "However, we further assume that communication opportunities are severely constrained and change dynamically.",
                "In this paper, we mostly investigate the convergence of such systems towards global consistency.",
                "We first show that (for a wide class of protocols that we shall define), the communication constraints induced by the topology will not prevent the convergence of the system, at the condition that the system dynamics guarantees that no agent will ever be isolated forever, and that agents have unlimited time for computation and arguments exchange.",
                "As this assumption cannot be made in most situations though, we then set up an experimental framework aiming at comparing the relative efficiency and effectiveness of different interaction protocols for hypotheses exchange.",
                "We study a critical situation involving a number of agents aiming at escaping from a burning building.",
                "The results reported here provide some insights regarding the design of optimal protocol for hypotheses refinement in this context.",
                "Categories and Subject Descriptors I.2.11 [Artificial Intelligence]: Distributed Artificial Intelligence-Multiagent systems General Terms Theory, Experimentation 1.",
                "INTRODUCTION We consider a multiagent system where each (distributed) agent locally perceives its environment, and we assume that some unexpected event occurs in that system.",
                "If each agent computes only locally its favoured hypothesis, it is only natural to assume that agents will seek to coordinate and refine their hypotheses by confronting their observations with other agents.",
                "If, in addition, the communication opportunities are severely constrained (for instance, agents can only communicate when they are close enough to some other agent), and dynamically changing (for instance, agents may change their locations), it becomes crucial to carefully design protocols that will allow agents to converge to some desired state of global consistency.",
                "In this paper we exhibit some sufficient conditions on the system dynamics and on the protocol/strategy structures that allow to guarantee that property, and we experimentally study some contexts where (some of) these assumptions are relaxed.",
                "While problems of diagnosis are among the venerable classics in the AI tradition, their multiagent counterparts have much more recently attracted some attention.",
                "Roos and colleagues [8, 9] in particular study a situation where a number of distributed entities try to come up with a satisfying global diagnosis of the whole system.",
                "They show in particular that the number of messages required to establish this global diagnosis is bound to be prohibitive, unless the communication is enhanced with some suitable protocol.",
                "However, they do not put any restrictions on agents communication options, and do not assume either that the system is dynamic.",
                "The benefits of enhancing communication with supporting information to make convergence to a desired global state of a system more efficient has often been put forward in the literature.",
                "This is for instance one of the main idea underlying the argumentation-based negotiation approach [7], where the desired state is a compromise between agents with conflicting preferences.",
                "Many of these works however make the assumption that this approach is beneficial to start with, and study the technical facets of the problem (or instead emphasize other advantages of using argumentation).",
                "Notable exceptions are the works of [3, 4, 2, 5], which studied in contexts different from ours the efficiency of argumentation.",
                "The rest of the paper is as follows.",
                "Section 2 specifies the basic elements of our model, and Section 3 goes on to presenting the different protocols and strategies used by the agents to exchange hypotheses and observations.",
                "We put special attention at clearly emphasizing the conditions on the system dynamics and protocols/strategies that will be exploited in the rest of the paper.",
                "Section 4 details one of 998 978-81-904262-7-5 (RPS) c 2007 IFAAMAS the main results of the paper, namely the fact that under the aforementioned conditions, the constraints that we put on the topology will not prevent the convergence of the system towards global consistency, at the condition that no agent ever gets completely lost forever in the system, and that unlimited time is allowed for computation and argument exchange.",
                "While the conditions on protocols and strategies are fairly mild, it is also clear that these system requirements look much more problematic, even frankly unrealistic in critical situations where distributed approaches are precisely advocated.",
                "To get a clearer picture of the situation induced when time is a critical factor, we have set up an experimental framework that we introduce and discuss in Section 5.",
                "The critical situation involves a number of agents aiming at escaping from a burning building.",
                "The results reported here show that the effectiveness of argument exchange crucially depends upon the nature of the building, and provide some insights regarding the design of optimal protocol for hypotheses refinement in this context. 2.",
                "BASIC NOTIONS We start by defining the basic elements of our system.",
                "Environment Let O be the (potentially infinite) set of possible observations.",
                "We assume the sensors of our agents to be perfect, hence the observations to be certain.",
                "Let H be the set of hypotheses, uncertain and revisable.",
                "Let Cons(h, O) be the consistency relation, a binary relation between a hypothesis h ∈ H and a set of observations O ⊆ O.",
                "In most cases, Cons will refer to classical consistency relation, however, we may overload its meaning and add some additional properties to that relation (in which case we will mention it).",
                "The environment may include some dynamics, and change over the course of time.",
                "We define below sequences of time points to deal with it: Definition 1 (Sequence of time points).",
                "A sequence of time points t1, t2, . . . , tn from t is an ordered set of time points t1, t2, . . . , tn such that t1 ≥ t and ∀i ∈ [1, n − 1], ti+1 ≥ ti.",
                "Agent We take a system populated by n agents a1, . . . , an.",
                "Each agent is defined as a tuple F, Oi, hi , where: • F, the set of facts, common knowledge to all agents. • Oi ∈ 2O , the set of observations made by the agent so far.",
                "We assume a perfect memory, hence this set grows monotonically. • hi ∈ H, the favourite hypothesis of the agent.",
                "A key notion governing the formation of hypotheses is that of consistency, defined below: Definition 2 (Consistency).",
                "We say that: • An agent is consistent (Cons(ai)) iff Cons(hi, Oi) (that is, its hypothesis is consistent with its observation set). • An agent ai consistent with a partner agent aj iff Cons(ai) and Cons(hi, Oj) (that is, this agent is consistent and its hypothesis can explain the observation set of the other agent). • Two agents ai and aj are mutually consistent (MCons(ai, aj)) iff Cons(ai, aj) and Cons(aj, ai). • A system is consistent iff ∀(i, j)∈[1, n]2 it is the case that MCons(ai, aj).",
                "To ensure its consistency, each agent is equipped with an abstract reasoning machinery that we shall call the explanation function Eh.",
                "This (deterministic) function takes a set of observation and returns a single prefered hypothesis (2O → H).",
                "We assume h = Eh(O) to be consistent with O by definition of Eh, so using this function on its observation set to determine its favourite hypothesis is a sure way for the agent to achieve consistency.",
                "Note however that an hypothesis does not need to be generated by Eh to be consistent with an observation set.",
                "As a concrete example of such a function, and one of the main inspiration of this work, one can cite the Theorist reasoning system [6] -as long as it is coupled with a filter selecting a single prefered theory among the ones initially selected by Theorist.",
                "Note also that hi may only be modified as a consequence of the application Eh.",
                "We refer to this as the autonomy of the agent: no other agent can directly impose a given hypothesis to an agent.",
                "As a consequence, only a new observation (being it a new perception, or an observation communicated by a fellow agent) can result in a modification of its prefered hypothesis hi (but not necessarily of course).",
                "We finally define a property of the system that we shall use in the rest of the paper: Definition 3 (Bounded Perceptions).",
                "A system involves a bounded perception for agents iff ∃n0 s.t. ∀t| ∪N i=1 Oi| ≤ n0. (That is, the number of observations to be made by the agents in the system is not infinite.)",
                "Agent Cycle Now we need to see how these agents will evolve and interact in their environment.",
                "In our context, agents evolve in a dynamic environment, and we classicaly assume the following system cycle: 1.",
                "Environment dynamics: the environment evolves according to the defined rules of the system dynamics. 2.",
                "Perception step : agents get perceptions from the environment.",
                "These perceptions are typically partial (e.g. the agent can only see a portion of a map). 3.",
                "Reasoning step: agents compare perception with predictions, seek explanations for (potential) difference(s), refine their hypothesis, draw new conclusions. 4.",
                "Communication step: agents can communicate hypotheses and observations with other agents through a defined protocol.",
                "Any agent can only be involved in one communication with another agent by step. 5.",
                "Action step: agents do some practical reasoning using the models obtained from the previous steps and select an action.",
                "They can then modify the environment by executing it.",
                "The communication of the agents will be further constrained by topological consideration.",
                "At a given time, an agent will only be able to communicate with a number of neighbours.",
                "Its connexions with these others agents may The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 999 evolve with its situation in the environment.",
                "Typically, an agent can only communicate with agents that it can sense, but one could imagine evolving topological constraints on communication based on a network of communications between agents where the links are not always active.",
                "Communication In our system, agents will be able to communicate with each other.",
                "However, due to the aforementionned topological constraints, they will not be able to communicate with any agents at anytime.",
                "Who an agent can communicate with will be defined dynamically (for instance, this can be a consequence of the agents being close enough to get in touch).",
                "We will abstractly denote by C(ai, aj, t) the communication property, in other words, the fact that agents ai and aj can communicate at time t (note that this relation is assumed to be symetric, but of course not transitive).",
                "We are now in a position to define two essential properties of our system.",
                "Definition 4 (Temporal Path).",
                "There exists a temporal communication path at horizon tf (noted Ltf (aI , aJ )) between ai and aj iff there exists a sequence of time points t1, t2, . . . , tn from tf and a sequence of agents k1, k2, . . . , kn s.t. (i) C(aI , ak1 , t1), (ii) C(akn , aJ , tn+1), (iii) ∀i ∈ [1, n], C(aki , aki+1 , ti) Intuitively, what this property says is that it is possible to find a temporal path in the future that would allow to link agent ai and aj via a sequence of intermediary agents.",
                "Note that the time points are not necessarily successive, and that the sequence of agents may involve the same agents several times.",
                "Definition 5 (Temporal Connexity).",
                "A system is temporaly connex iff ∀t ∀(i, j)∈[1, n]2 Lt(ai, aj) In short, a temporaly connex system guarantees that any agent will be able to communicate with any other agents, no matter how long it might take to do so, at any time.",
                "To put it another way, it is never the case that an agent will be isolated for ever from another agent of the system.",
                "We will next discuss the detail of how communication concretely takes place in our system.",
                "Remember that in this paper, we only consider the case of bilateral exchanges (an agent can only speak to a single other agent), and that we also assume that any agent can only engage in a single exchange in a given round. 3.",
                "PROTOCOLS AND STRATEGIES In this section, we discuss the requirements of the interaction protocols that govern the exchange of messages between agents, and provide some example instantiation of such protocols.",
                "To clarify the presentation, we distinguish two levels: the local level, which is concerned with the regulation of bilateral exchanges; and the global level,which essentially regulates the way agents can actually engage into a conversation.",
                "At each level, we separate what is specified by the protocol, and what is left to agents strategies.",
                "Local Protocol and Strategies We start by inspecting local protocols and strategies that will regulate the communication between the agents of the system.",
                "As we limit ourselves to bilateral communication, these protocols will simply involve two agents.",
                "Such protocol will have to meet one basic requirement to be satisfying. • consistency (CONS)- a local protocol has to guarantee the mutual consistency of agents upon termination (which implies termination of course).",
                "Figure 1: A Hypotheses Exchange Protocol [1] One example such protocol is the protocol described in [1] that is pictured in Fig. 1.",
                "To further illustrate how such protocol can be used by agents, we give some details on a possible strategy: upon receiving a hypothesis h1 (propose(h1) or counterpropose(h1)) from a1, agent a2 is in state 2 and has the following possible replies: counterexample (if the agent knows an example contradicting the hypothesis, or not explained by this hypothesis), challenge (if the agents lacks evidence to accept this hypothesis), counterpropose (if the agent agrees with the hypothesis but prefers another one), or accept (if it is indeed as good as its favourite hypothesis).",
                "This strategy guarantees, among other properties, the eventual mutual logical consistency of the involved agents [1].",
                "Global Protocol The global protocol regulates the way bilateral exchanges will be initiated between agents.",
                "At each turn, agents will concurrently send one weighted request to communicate to other agents.",
                "This weight is a value measuring the agents willingness to converse with the targeted agent (in practice, this can be based on different heuristics, but we shall make some assumptions on agents strategies, see below).",
                "Sending such a request is a kind of conditional commitment for the agent.",
                "An agent sending a weighted request commits to engage in conversation with the target if he does not receive and accept himself another request.",
                "Once all request have been received, each agent replies with either an acccept or a reject.",
                "By answering with an accept, an agent makes a full commitment to engage in conversation with the sender.",
                "Therefore, it can only send one accept in a given round, as an agent can only participate in one conversation per time step.",
                "When all response have been received, each agent receiving an accept can either initiate a conversation using the local protocol or send a cancel if it has accepted another request.",
                "At the end of all the bilateral exchanges, the agents engaged in conversation are discarded from the protocol.",
                "Then each of the remaining agents resends a request and the process iterates until no more requests are sent.",
                "Global Strategy We now define four requirements for the strategies used by agents, depending on their role in the protocol: two are concerned with the requestee role (how to decide who the 1000 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) agent wishes to communicate with? ), the other two with the responder role (how to decide which communication request to accept or not?). • Willingness to solve inconsistancies (SOLVE)-agents want to communicate with any other agents unless they know they are mutually consistent. • Focus on solving inconsistencies (FOCUS)-agents do not request communication with an agent with whom they know they are mutually consistent. • Willingness to communicate (COMM)-agents cannot refuse a weighted communication request, unless they have just received or send a request with a greater weight. • Commitment to communication request (REQU)agents cannot accept a weighted communication request if they have themselves sent a communication request with a greater weight.",
                "Therefore, they will not cancel their request unless they have received a communicational request with greater weight.",
                "Now the protocol structure, together with the properties COMM+REQU, ensure that a request can only be rejected if its target agent engages in communication with another agent.",
                "Suppose indeed that agent ai wants to communicate with aj by sending a request with weight w. COMM guarantees that an agent receiving a weighted request will either accept this communication, accept a communication with a greater weight or wait for the answer to a request with a greater weight.",
                "This ensures that the request with maximal weight will be accepted and not cancelled (as REQU ensures that an agent sending a request can only cancel it if he accepts another request with greater weight).",
                "Therefore at least two agents will engage in conversation per round of the global protocol.",
                "As the protocol ensures that ai can resend its request while aj is not engaged in a conversation, there will be a turn in which aj must engage in a conversation, either with ai or another agent.",
                "These requirements concern request sending and acceptation, but agents also need some strategy of weight attribution.",
                "We describe below an altruist strategy, used in our experiments.",
                "Being cooperative, an agent may want to know more of the communication wishes of other agents in order to improve the overall allocation of exchanges to agents.",
                "A context request step is then added to the global protocol.",
                "Before sending their chosen weighted request, agents attribute a weight to all agents they are prepared to communicate with, according to some internal factors.",
                "In the simplest case, this weight will be 1 for all agent with whom the agent is not sure of being mutually consistent (ensuring SOLVE), other agent being not considered for communication (ensuring FOCUS).",
                "The agent then sends a context request to all agents with whom communication is considered.",
                "This request also provides information about the sender (list of considered communications along with their weight).",
                "After reception of all the context requests, agents will either reply with a deny, iff they are already engaged in a conversation (in which case, the requesting agent will not consider communication with them anymore in this turn), or an inform giving the requester information about the requests it has sent and received.",
                "When all replies have been received, each agent can calculate the weight of all requests concerning it.",
                "It does so by substracting from the weight of its request the weight of all requests concerning either it or its target (that is, the final weight of the request from ai to aj is Wi,j = wi,j +wj,i − ( P k∈R(i)−{j} wi,k + P k∈S(i)−{j} wk,i + P k∈R(j)−{i} wj,k + P k∈S(j)−{i} wk,j) where wi,j is the weight of the request of ai to aj, R(i) is the set of indice of agents having received a request from ai and S(i) is the set of indice of agents having send a request to ai).",
                "It then finally sends a weighted request to the agents who maximise this weight (or wait for a request) as described in the global protocol. 4. (CONDITIONAL) CONVERGENCE TO GLOBAL CONSISTENCY In this section we will show that the requirements regarding protocols and strategies just discussed will be sufficient to ensure that the system will eventually converge towards global consistency, under some conditions.",
                "We first show that, if two agents are not mutually consistent at some time, then there will be necessarily a time in the future such that an agent will learn a new observation, being it because it is new for the system, or by learning it from another agent.",
                "Lemma 1.",
                "Let S be a system populated by n agents a1, a2, ..., an, temporaly connex, and involving bounded perceptions for these agents.",
                "Let n1 be the sum of cardinalities of the intersection of pairwise observation sets. (n1 = P (i,j)∈[1,n]2 |Oi ∩ Oj|) Let n2 be the cardinality of the union of all agents observations sets. (n2 = | ∪N i=1 Oi|).",
                "If ¬MCons(ai, aj) at time t0, there is necessarily a time t > t0 s.t. either n1 or n2 will increase.",
                "Proof.",
                "Suppose that there exist a time t0 and indices (i, j) s.t. ¬MCons(ai, aj).",
                "We will use mt0 = P (k,l)∈[1,n]2 εComm(ak, al, t0) where εComm(ak, al, t0) = 1 if ak and al have communicated at least once since t0, and 0 otherwise.",
                "Temporal connexity guarantees that there exist t1, ..., tm+1 and k1, ..., km s.t.",
                "C(ai, ak1 , t1), C(akm , aj, tm+1), and ∀p ∈ [1, m], C(akp , akp+1 , tp).",
                "Clearly, if MCons(ai, ak1 ), MCons(akm , aj) and ∀p, MCons(akp , akp+1 ), we have MCons(ai, aj) which contradicts our hypothesis (MCons being transitive, MCons(ai, ak1 )∧MCons(ak1 , ak2 ) implies that MCons(ai, ak2 ) and so on till MCons(ai, akm )∧ MCons(akm , aj) which implies MCons(ai, aj) ).",
                "At least two agents are then necessarily inconsistent (¬MCons(ai, ak1 ), or ¬MCons(akm , aj), or ∃p0 t.q. ¬MCons(akp0 , akp0+1 )).",
                "Let ak and al be these two neighbours at a time t > t0 1 .",
                "The SOLVE property ensures that either ak or al will send a communication request to the other agent at time t .",
                "As shown before, this in turn ensures that at least one of these agents will be involved in a communication.",
                "Then there are two possibilities: (case i) ak and al communicate at time t .",
                "In this case, we know that ¬MCons(ak, al).",
                "This and the CONS property ensures that at least one of the agents must change its 1 Strictly speaking, the transitivity of MCons only ensure that ak and al are inconsistent at a time t ≥ t0 that can be different from the time t at which they can communicate.",
                "But if they become consistent between t and t (or inconsistent between t and t ), it means that at least one of them have changed its hypothesis between t and t , that is, after t0.",
                "We can then apply the reasoning of case iib.",
                "The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 1001 hypothesis, which in turn, since agents are autonomous, implies at least one exchange of observation.",
                "But then |Ok ∩Ol| is bound to increase: n1(t ) > n1(t0). (case ii) ak communicates with ap at time t .",
                "We then have again two possibilities: (case iia) ak and ap did not communicate since t0.",
                "But then εComm(ak, ap, t0) had value 0 and takes value 1.",
                "Hence mt0 increases. (case iib) ak and ap did communicate at some time t0 > t0.",
                "The CONS property of the protocol ensures that MCons(ak, ap) at that time.",
                "Now the fact that they communicate and FOCUS implies that at least one of them did change its hypothesis in the meantime.",
                "The fact that agents are autonomous implies in turn that a new observation (perceived or received from another agent) necessarily provoked this change.",
                "The latter case would ensure the existence of a time t > t0 and an agent aq s.t. either |Op ∩Oq| or |Ok ∩Oq| increases of 1 at that time (implying n1(t ) > n1(t0)).",
                "The former case means that the agent gets a new perception o at time t .",
                "If that observation was unknown in the system before, then n2(t ) > n2(t0).",
                "If some agent aq already knew this observation before, then either Op ∩ Oq or Ok ∩ Oq increases of 1 at time t (which implies that n1(t ) > n1(t0)).",
                "Hence, ¬MCons(ai, aj) at time t0 guarantees that, either: −∃t > t0 t.q. n1(t ) > n1(t0); or −∃t > t0 t.q. n2(t ) > n2(t0); or −∃t > t0 t.q. mt0 increases of 1 at time t .",
                "By iterating the reasoning with t (but keeping t0 as the time reference for mt0 ), we can eliminate the third case (mt0 is integer and bounded by n2 , which means that after a maximum of n2 iterations, we necessarily will be in one of two other cases.)",
                "As a result, we have proven that if ¬MCons(ai, aj) at time t0, there is necessarily a time t s.t. either n1 or n2 will increase.",
                "Theorem 1 (Global consistency).",
                "Let S be a system populated by n agents a1, a2, ..., an, temporaly connex, and involving bounded perceptions for these agents.",
                "Let Cons(ai, aj) be a transitive consistency property.",
                "Then any protocol and strategies satisfying properties CONS, SOLVE, FOCUS, COMM and REQU guarantees that the system will converge towards global consistency.",
                "Proof.",
                "For the sake of contradiction, let us assume ∃I, J ∈ [1, N] s.t. ∀t, ∃t0 > t, t.q. ¬Cons(aI , aJ , t0).",
                "Using the lemma, this implies that ∃t > t0 s.t. either n1(t ) > n1(t0) or n2(t ) > n2(t0).",
                "But we can apply the same reasoning taking t = t , which would give us t1 > t > t0 s.t. ¬Cons(aI , aJ , t1), which gives us t > t1 s.t. either n1(t ) > n1(t1) or n2(t ) > n2(t1).",
                "By successive iterations we can then construct a sequence t0, t1, ..., tn, which can be divided in two sub-sequences t0, t1, ...tn and t0 , t1 , ..., tn s.t. n1(t0) < n1(t1) < ... < n1(tn) and n2(t0 ) < n2(t1 ) < ... < n2(tn).",
                "One of these sub-sequences has to be infinite.",
                "However, n1(ti) and n2(ti ) are strictly growing, integer, and bounded, which implies that both are finite.",
                "Contradiction.",
                "What the previous result essentially shows is that, in a system where no agent will be isolated from the rest of the agents for ever, only very mild assumptions on the protocols and strategies used by agents suffice to guarantee convergence towards system consistency in a finite amount of time (although it might take very long).",
                "Unfortunately, in many critical situations, it will not be possible to assume this temporal connexity.",
                "As distributed approaches as the one advocated in this paper are precisely often presented as a good way to tackle problems of reliability or problems of dependence to a center that are of utmost importance in these critical applications, it is certainly interesting to further explore how such a system would behave when we relax this assumption. 5.",
                "EXPERIMENTAL STUDY This experiment involves agents trying to escape from a burning building.",
                "The environment is described as a spatial grid with a set of walls and (thankfully) some exits.",
                "Time and space are considered discrete.",
                "Time is divided in rounds.",
                "Agents are localised by their position on the spatial grid.",
                "These agents can move and communicate with other agents.",
                "In a round, an agent can move of one cell in any of the four cardinal directions, provided it is not blocked by a wall.",
                "In this application, agents communicate with any other agent (but, recall, a single one) given that this agent is in view, and that they have not yet exchanged their current favoured hypothesis.",
                "Suddenly, a fire erupts in these premises.",
                "From this moment, the fire propagates.",
                "Each round, for each cases where there is fire, the fire propagates in the four directions.",
                "However, the fire cannot propagate through a wall.",
                "If the fire propagates in a case where an agent is positioned, that agent burns and is considered dead.",
                "It can of course no longer move nor communicate.",
                "If an agent gets to an exit, it is considered saved, and can no longer be burned.",
                "Agents know the environment and the rules governing the dynamics of this environment, that is, they know the map as well as the rules of fire propagation previously described.",
                "They also locally perceive this environment, but cannot see further than 3 cases away, in any direction.",
                "Walls also block the line of view, preventing agents from seeing behind them.",
                "Within their sight, they can see other agents and whether or not the cases they see are on fire.",
                "All these perceptions are memorised.",
                "We now show how this instantiates the abstract framework presented the paper. • O = {Fire(x, y, t), NoFire(x, y, t), Agent(ai, x, y, t)} Observations can then be positive (o ∈ P(O) iff ∃h ∈ H s.t. h |= o) or negative (o ∈ N(O) iff ∃h ∈ H s.t. h |= ¬o). • H={FireOrigin(x1, y1, t1)∧...∧FireOrigin(xl, yl, tl)} Hypotheses are conjunctions of FireOrigins. • Cons(h, O) consistency relation satisfies: - coherence : ∀o ∈ N(O), h |= ¬o. - completeness : ∀o ∈ P(O), h |= o. - minimality : For all h ∈ H, if h is coherent and complete for O, then h is prefered to h according to the preference relation (h ≤p h ).2 2 Selects first the minimal number of origins, then the most recent (least preemptive strategy [6]), then uses some arbitrary fixed ranking to discriminate ex-aequo.",
                "The resulting relation is a total order, hence minimality implies that there will be a single h s.t.Cons(O, h) for a given O.",
                "This in turn means that MCons(ai, aj) iff Cons(ai), Cons(aj), and hi = hj.",
                "This relation is then transitive and symmetric. 1002 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) • Eh takes O as argument and returns min≤p of the coherent and complete hypothesis for O 5.1 Experimental Evaluation We will classically (see e.g. [3, 4]) assess the effectiveness and efficiency of different interaction protocols.",
                "Effectiveness of a protocol The proportion of agents surviving the fire over the initial number of agents involved in the experiment will determine the effectiveness of a given protocol.",
                "If this value is high, the protocol has been effective to propagate the information and/or for the agents to refine their hypotheses and determine the best way to the exit.",
                "Efficiency of a protocol Typically, the use of supporting information will involve a communication overhead.",
                "We will assume here that the efficiency of a given protocol is characterised by the data flow induced by this protocol.",
                "In this paper we will only discuss this aspect wrt. local protocols.",
                "The main measure that we shall then use here is the mean total size of messages that are exchanged by agents per exchange (hence taking into account both the number of messages and the actual size of the messages, because it could be that messages happen to be very big, containing e.g. a large number of observations, which could counter-balance a low number of messages). 5.2 Experimental Settings The chosen experimental settings are the following: • Environmental topology- Performances of information propagation are highly constrained by the environment topology.",
                "The perception skills of the agents depend on the openness of the environment.",
                "With a large number of walls the perceptions of agents are limited, and also the number of possible inter-agent communications, whereas an open environment will provide optimal possibilities of perception and information propagation.",
                "Thus, we propose a topological index (see below) as a common basis to charaterize the environments (maps) used during experimentations.",
                "The topological index (TI) is the ratio of the number of cells that can be perceived by agents summed up from all possible positions, divided by the number of cells that would be perceived from the same positions but without any walls. (The closer to 1, the more open the environment).",
                "We shall also use two additional, more classical [10], measures: the characteristic path length3 (CPL) and the clustering coefficient4 (CC). • Number of agents- The propagation of information also depends on the initial number of agents involved during an experimentation.",
                "For instance, the more agents, the more potential communications there is.",
                "This means that there will be more potential for propagation, but also that the bilateral exchange restriction will be more crucial. 3 The CPL is the median of the means of the shortest path lengths connecting each node to all other nodes. 4 characterising the isolation degree of a region of an environment in terms of acessibility (number of roads still usable to reach this region).",
                "Map T.I. (%) C.P.L.",
                "C.C. 69-1 69,23 4,5 0,69 69-2 68,88 4,38 0,65 69-3 69,80 4,25 0,67 53-1 53,19 5,6 0,59 53-2 53,53 6,38 0,54 53-3 53,92 6,08 0,61 38-1 38,56 8,19 0,50 38-2 38,56 7,3 0,50 38-3 38,23 8,13 0,50 Table 1: Topological Characteristics of the Maps • Initial positions of the agents- Initial positions of the agents have a significant influence on the overall behavior of an instance of our system: being close from an exit will (in general) ease the escape. 5.3 Experimental environments We choose to realize experiments on three very different topological indexes (69% for open environments, 53% for mixed environments, and 38% for labyrinth-like environments).",
                "Figure 2: Two maps (left: TI=69%, right TI=38%) We designed three different maps for each index (Fig. 2 shows two of them), containing the same maximum number of agents (36 agents max.) with a maximum density of one agent per cell, the same number of exits and a similar fire origin (e.g. starting time and position).",
                "The three differents maps of a given index are designed as follows.",
                "The first map is a model of an existing building floor.",
                "The second map has the same enclosure, exits and fire origin as the first one, but the number and location of walls are different (wall locations are designed by an heuristic which randomly creates walls on the spatial grid such that no fully closed rooms are created and that no exit is closed).",
                "The third map is characterised by geometrical enclosure in wich walls location is also designed with the aforementioned heuristic.",
                "Table 1 summarizes the different topological measures characterizing these different maps.",
                "It is worth pointing out that the values confirm the relevance of TI (maps with a high TI have a low CPL and a high CC.",
                "However the CPL and CC allows to further refine the difference between the maps, e.g. between 53-1 and 53-2). 5.4 Experimental Results For each triple of maps defined as above we conduct the same experiments.",
                "In each experiment, the society differs in terms of its initial proportion of involved agents, from 1% to 100%.",
                "This initial proportion represents the percentage of involved agents with regards to the possible maximum number of agents.",
                "For each map and each initial proportion, The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 1003 we select randomly 100 different initial agents locations.",
                "For each of those different locations we execute the system one time for each different interaction protocol.",
                "Effectiveness of Communication and Argumentation The first experiment that we set up aims at testing how effective is hypotheses exchange (HE), and in particular how the topological aspects will affect this effectiveness.",
                "In order to do so, we have computed the ratio of improvement offered by that protocol over a situation where agents could simply not communicate (no comm).",
                "To get further insights as to what extent the hypotheses exchange was really crucial, we also tested a much less elaborated protocol consisting of mere observation exchanges (OE).",
                "More precisely, this protocol requires that each agent stores any unexpected observation that it perceives, and agents simply exchange their respective lists of observations when they discuss.",
                "In this case, the local protocol is different (note in particular that it does not guarantee mutual consistency), but the global protocol remains the same (at the only exception that agents motivation to communicate is to synchronise their list of observations, not their hypothesis).",
                "If this protocol is at best as effective as HE, it has the advantage of being more efficient (this is obvious wrt the number of messages which will be limited to 2, less straightforward as far as the size of messages is concerned, but the rough observation that the exchange of observations can be viewed as a flat version of the challenge is helpful to see this).",
                "The results of these experiments are reported in Fig. 3.",
                "Figure 3: Comparative effectiveness ratio gain of protocols when the proportion of agents augments The first observation that needs to be made is that communication improves the effectiveness of the process, and this ratio increases as the number of agents grows in the system.",
                "The second lesson that we learn here is that closeness relatively makes communication more effective over non communication.",
                "Maps exhibiting a T.I. of 38% are constantly above the two others, and 53% are still slightly but significantly better than 69%.",
                "However, these curves also suggest, perhaps surprisingly, that HE outperforms OE in precisely those situations where the ratio gain is less important (the only noticeable difference occurs for rather open maps where T.I. is 69%).",
                "This may be explained as follows: when a map is open, agents have many potential explanation candidates, and argumentation becomes useful to discriminate between those.",
                "When a map is labyrinth-like, there are fewer possible explanations to an unexpected event.",
                "Importance of the Global Protocol The second set of experiments seeks to evaluate the importance of the design of the global protocol.",
                "We tested our protocol against a local broadcast (LB) protocol.",
                "Local broadcast means that all the neighbours agents perceived by an agent will be involved in a communication with that agent in a given round -we alleviate the constraint of a single communication by agent.",
                "This gives us a rough upper bound upon the possible ratio gain in the system (for a given local protocol).",
                "Again, we evaluated the ratio gain induced by that LB over our classical HE, for the three different classes of maps.",
                "The results are reported in Fig. 4.",
                "Figure 4: Ratio gain of local broadcast over hypotheses exchange Note to begin with that the ratio gain is 0 when the proportion of agents is 5%, which is easily explained by the fact that it corresponds to situations involving only two agents.",
                "We first observe that all classes of maps witness a ratio gain increasing when the proportion of agents augments: the gain reaches 10 to 20%, depending on the class of maps considered.",
                "If one compares this with the improvement reported in the previous experiment, it appears to be of the same magnitude.",
                "This illustrates that the design of the global protocol cannot be ignored, especially when the proportion of agents is high.",
                "However, we also note that the effectiveness ratio gain curves have very different shapes in both cases: the gain induced by the accuracy of the local protocol increases very quickly with the proportion of agents, while the curve is really smooth for the global one.",
                "Now let us observe more carefully the results reported here: the curve corresponding to a TI of 53% is above that corresponding to 38%.",
                "This is so because the more open a map, the more opportunities to communicate with more than one agent (and hence benefits from broadcast).",
                "However, we also observe that curve for 69% is below that for 53%.",
                "This is explained as follows: in the case of 69%, the potential gain to be made in terms of surviving agents is much lower, because our protocols already give rather efficient outcomes anyway (quickly reaching 90%, see Fig. 3).",
                "A simple rule of thumb could be that when the number of agents is small, special attention should be put on the local 1004 The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) protocol, whereas when that number is large, one should carefully design the global one (unless the map is so open that the protocol is already almost optimally efficient).",
                "Efficiency of the Protocols The final experiment reported here is concerned with the analysis of the efficiency of the protocols.",
                "We analysis here the mean size of the totality of the messages that are exchanged by agents (mean size of exchanges, for short) using the following protocols: HE, OE, and two variant protocols.",
                "The first one is an intermediary restricted hypotheses exchange protocol (RHE).",
                "RHE is as follows: it does not involve any challenge nor counter-propose, which means that agents cannot switch their role during the protocol (this differs from RE in that respect).",
                "In short, RHE allows an agent to exhaust its partners criticism, and eventually this partner will come to adopt the agents hypothesis.",
                "Note that this means that the autonomy of the agent is not preserved here (as an agent will essentially accept any hypothesis it cannot undermine), with the hope that the gain in efficiency will be significant enough to compensate a loss in effectiveness.",
                "The second variant protocol is a complete observation exchange protocol (COE).",
                "COE uses the same principles as OE, but includes in addition all critical negative examples (nofire) in the exchange (thus giving all examples used as arguments by the hypotheses exchanges protocol), hence improving effectiveness.",
                "Results for map 69-1 are shown on Fig. 5.",
                "Figure 5: Mean size of exchanges First we can observe the fact that the ordering of the protocols, from the least efficient to the most efficient, is COE, HE, RHE and then OE.",
                "HE being more efficient than COE proves that the argumentation process gains efficiency by selecting when it is needed to provide negative example, which have less impact that positive ones in our specific testbed.",
                "However, by communicating hypotheses before eventually giving observation to support it (HE) instead of directly giving the most crucial observations (OE), the argumentation process doubles the size of data exchanges.",
                "It is the cost for ensuring consistency at the end of the exchange (a property that OE does not support).",
                "Also significant is the fact the the mean size of exchanges is slightly higher when the number of agents is small.",
                "This is explained by the fact that in these cases only a very few agents have relevant informations in their possession, and that they will need to communicate a lot in order to come up with a common view of the situation.",
                "When the number of agents increases, this knowledge is distributed over more agents which need shorter discussions to get to mutual consistency.",
                "As a consequence, the relative gain in efficiency of using RHE appears to be better when the number of agents is small: when it is high, they will hardly argue anyway.",
                "Finally, it is worth noticing that the standard deviation for these experiments is rather high, which means that the conversation do not converge to any stereotypic pattern. 6.",
                "CONCLUSION This paper has investigated the properties of a multiagent system where each (distributed) agent locally perceives its environment, and tries to reach consistency with other agents despite severe communication restrictions.",
                "In particular we have exhibited conditions allowing convergence, and experimentally investigated a typical situation where those conditions cannot hold.",
                "There are many possible extensions to this work, the first being to further investigate the properties of different global protocols belonging to the class we identified, and their influence on the outcome.",
                "There are in particular many heuristics, highly dependent on the context of the study, that could intuitively yield interesting results (in our study, selecting the recipient on the basis of what can be inferred from his observed actions could be such a heuristic).",
                "One obvious candidate for longer term issues concern the relaxation of the assumption of perfect sensing. 7.",
                "REFERENCES [1] G. Bourgne, N. Maudet, and S. Pinson.",
                "When agents communicate hypotheses in critical situations.",
                "In Proceedings of DALT-2006, May 2006. [2] P. Harvey, C. F. Chang, and A. Ghose.",
                "Support-based distributed search: a new approach for multiagent constraint processing.",
                "In Proceedings of AAMAS06, 2006. [3] H. Jung and M. Tambe.",
                "Argumentation as distributed constraint satisfaction: Applications and results.",
                "In Proceedings of AGENTS01, 2001. [4] N. C. Karunatillake and N. R. Jennings.",
                "Is it worth arguing?",
                "In Proceedings of ArgMAS 2004, 2004. [5] S. Onta˜n´on and E. Plaza.",
                "Arguments and counterexamples in case-based joint deliberation.",
                "In Proceedings of ArgMAS-2006, May 2006. [6] D. Poole.",
                "Explanation and prediction: An architecture for default and abductive reasoning.",
                "Computational Intelligence, 5(2):97-110, 1989. [7] I. Rahwan, S. D. Ramchurn, N. R. Jennings, P. McBurney, S. Parsons, and L. Sonenberg.",
                "Argumention-based negotiation.",
                "The Knowledge Engineering Review, 4(18):345-375, 2003. [8] N. Roos, A. ten Tije, and C. Witteveen.",
                "A protocol for multi-agent diagnosis with spatially distributed knowledge.",
                "In Proceedings of AAMAS03, 2003. [9] N. Roos, A. ten Tije, and C. Witteveen.",
                "Reaching diagnostic agreement in multiagent diagnosis.",
                "In Proceedings of AAMAS04, 2004. [10] T. Takahashi, Y. Kaneda, and N. Ito.",
                "Preliminary study - using robocuprescue simulations for disasters prevention.",
                "In Proceedings of SRMED2004, 2004.",
                "The Sixth Intl.",
                "Joint Conf. on Autonomous Agents and Multi-Agent Systems (AAMAS 07) 1005"
            ],
            "original_annotated_samples": [],
            "translated_annotated_samples": [],
            "translated_text": "",
            "candidates": [],
            "error": [
                []
            ]
        }
    }
}