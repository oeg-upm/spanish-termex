{
    "id": "H-11",
    "original_text": "Laplacian Optimal Design for Image Retrieval Xiaofei He Yahoo! Burbank, CA 91504 hex@yahoo-inc.com Wanli Min IBM Yorktown Heights, NY 10598 wanlimin@us.ibm.com Deng Cai CS Dept., UIUC Urbana, IL 61801 dengcai2@cs.uiuc.edu Kun Zhou Microsoft Research Asia Beijing, China kunzhou@microsoft.com ABSTRACT Relevance feedback is a powerful technique to enhance ContentBased Image Retrieval (CBIR) performance. It solicits the users relevance judgments on the retrieved images returned by the CBIR systems. The users labeling is then used to learn a classifier to distinguish between relevant and irrelevant images. However, the top returned images may not be the most informative ones. The challenge is thus to determine which unlabeled images would be the most informative (i.e., improve the classifier the most) if they were labeled and used as training samples. In this paper, we propose a novel active learning algorithm, called Laplacian Optimal Design (LOD), for relevance feedback image retrieval. Our algorithm is based on a regression model which minimizes the least square error on the measured (or, labeled) images and simultaneously preserves the local geometrical structure of the image space. Specifically, we assume that if two images are sufficiently close to each other, then their measurements (or, labels) are close as well. By constructing a nearest neighbor graph, the geometrical structure of the image space can be described by the graph Laplacian. We discuss how results from the field of optimal experimental design may be used to guide our selection of a subset of images, which gives us the most amount of information. Experimental results on Corel database suggest that the proposed approach achieves higher precision in relevance feedback image retrieval. Categories and Subject Descriptors H.3.3 [Information storage and retrieval]: Information search and retrieval-Relevance feedback; G.3 [Mathematics of Computing]: Probability and Statistics-Experimental design General Terms Algorithms, Performance, Theory 1. INTRODUCTION In many machine learning and information retrieval tasks, there is no shortage of unlabeled data but labels are expensive. The challenge is thus to determine which unlabeled samples would be the most informative (i.e., improve the classifier the most) if they were labeled and used as training samples. This problem is typically called active learning [4]. Here the task is to minimize an overall cost, which depends both on the classifier accuracy and the cost of data collection. Many real world applications can be casted into active learning framework. Particularly, we consider the problem of relevance feedback driven Content-Based Image Retrieval (CBIR) [13]. Content-Based Image Retrieval has attracted substantial interests in the last decade [13]. It is motivated by the fast growth of digital image databases which, in turn, require efficient search schemes. Rather than describe an image using text, in these systems an image query is described using one or more example images. The low level visual features (color, texture, shape, etc.) are automatically extracted to represent the images. However, the low level features may not accurately characterize the high level semantic concepts. To narrow down the semantic gap, relevance feedback is introduced into CBIR [12]. In many of the current relevance feedback driven CBIR systems, the user is required to provide his/her relevance judgments on the top images returned by the system. The labeled images are then used to train a classifier to separate images that match the query concept from those that do not. However, in general the top returned images may not be the most informative ones. In the worst case, all the top images labeled by the user may be positive and thus the standard classification techniques can not be applied due to the lack of negative examples. Unlike the standard classification problems where the labeled samples are pregiven, in relevance feedback image retrieval the system can actively select the images to label. Thus active learning can be naturally introduced into image retrieval. Despite many existing active learning techniques, Support Vector Machine (SVM) active learning [14] and regression based active learning [1] have received the most interests. Based on the observation that the closer to the SVM boundary an image is, the less reliable its classification is, SVM active learning selects those unlabeled images closest to the boundary to solicit user feedback so as to achieve maximal refinement on the hyperplane between the two classes. The major disadvantage of SVM active learning is that the estimated boundary may not be accurate enough. Moreover, it may not be applied at the beginning of the retrieval when there is no labeled images. Some other SVM based active learning algorithms can be found in [7], [9]. In statistics, the problem of selecting samples to label is typically referred to as experimental design. The sample x is referred to as experiment, and its label y is referred to as measurement. The study of optimal experimental design (OED) [1] is concerned with the design of experiments that are expected to minimize variances of a parameterized model. The intent of optimal experimental design is usually to maximize confidence in a given model, minimize parameter variances for system identification, or minimize the models output variance. Classical experimental design approaches include A-Optimal Design, D-Optimal Design, and E-Optimal Design. All of these approaches are based on a least squares regression model. Comparing to SVM based active learning algorithms, experimental design approaches are much more efficient in computation. However, this kind of approaches takes only measured (or, labeled) data into account in their objective function, while the unmeasured (or, unlabeled) data is ignored. Benefit from recent progresses on optimal experimental design and semi-supervised learning, in this paper we propose a novel active learning algorithm for image retrieval, called Laplacian Optimal Design (LOD). Unlike traditional experimental design methods whose loss functions are only defined on the measured points, the loss function of our proposed LOD algorithm is defined on both measured and unmeasured points. Specifically, we introduce a locality preserving regularizer into the standard least-square-error based loss function. The new loss function aims to find a classifier which is locally as smooth as possible. In other words, if two points are sufficiently close to each other in the input space, then they are expected to share the same label. Once the loss function is defined, we can select the most informative data points which are presented to the user for labeling. It would be important to note that the most informative images may not be the top returned images. The rest of the paper is organized as follows. In Section 2, we provide a brief description of the related work. Our proposed Laplacian Optimal Design algorithm is introduced in Section 3. In Section 4, we compare our algorithm with the state-or-the-art algorithms and present the experimental results on image retrieval. Finally, we provide some concluding remarks and suggestions for future work in Section 5. 2. RELATED WORK Since our proposed algorithm is based on regression framework. The most related work is optimal experimental design [1], including A-Optimal Design, D-Optimal Design, and EOptimal Design. In this Section, we give a brief description of these approaches. 2.1 The Active Learning Problem The generic problem of active learning is the following. Given a set of points A = {x1, x2, · · · , xm} in Rd , find a subset B = {z1, z2, · · · , zk} ⊂ A which contains the most informative points. In other words, the points zi(i = 1, · · · , k) can improve the classifier the most if they are labeled and used as training points. 2.2 Optimal Experimental Design We consider a linear regression model y = wT x + (1) where y is the observation, x is the independent variable, w is the weight vector and is an unknown error with zero mean. Different observations have errors that are independent, but with equal variances σ2 . We define f(x) = wT x to be the learners output given input x and the weight vector w. Suppose we have a set of labeled sample points (z1, y1), · · · , (zk, yk), where yi is the label of zi. Thus, the maximum likelihood estimate for the weight vector, ˆw, is that which minimizes the sum squared error Jsse(w) = k i=1 wT zi − yi 2 (2) The estimate ˆw gives us an estimate of the output at a novel input: ˆy = ˆwT x. By Gauss-Markov theorem, we know that ˆw − w has a zero mean and a covariance matrix given by σ2 H−1 sse, where Hsse is the Hessian of Jsse(w) Hsse = ∂2 Jsse ∂w2 = k i=1 zizT i = ZZT where Z = (z1, z2, · · · , zk). The three most common scalar measures of the size of the parameter covariance matrix in optimal experimental design are: • D-optimal design: determinant of Hsse. • A-optimal design: trace of Hsse. • E-optimal design: maximum eigenvalue of Hsse. Since the computation of the determinant and eigenvalues of a matrix is much more expensive than the computation of matrix trace, A-optimal design is more efficient than the other two. Some recent work on experimental design can be found in [6], [16]. 3. LAPLACIAN OPTIMAL DESIGN Since the covariance matrix Hsse used in traditional approaches is only dependent on the measured samples, i.e. zis, these approaches fail to evaluate the expected errors on the unmeasured samples. In this Section, we introduce a novel active learning algorithm called Laplacian Optimal Design (LOD) which makes efficient use of both measured (labeled) and unmeasured (unlabeled) samples. 3.1 The Objective Function In many machine learning problems, it is natural to assume that if two points xi, xj are sufficiently close to each other, then their measurements (f(xi), f(xj)) are close as well. Let S be a similarity matrix. Thus, a new loss function which respects the geometrical structure of the data space can be defined as follows: J0(w) = k i=1 f(zi)−yi 2 + λ 2 m i,j=1 f(xi)−f(xj) 2 Sij (3) where yi is the measurement (or, label) of zi. Note that, the loss function (3) is essentially the same as the one used in Laplacian Regularized Regression (LRR, [2]). However, LRR is a passive learning algorithm where the training data is given. In this paper, we are focused on how to select the most informative data for training. The loss function with our choice of symmetric weights Sij (Sij = Sji) incurs a heavy penalty if neighboring points xi and xj are mapped far apart. Therefore, minimizing J0(w) is an attempt to ensure that if xi and xj are close then f(xi) and f(xj) are close as well. There are many choices of the similarity matrix S. A simple definition is as follows: Sij = ⎧ ⎨ ⎩ 1, if xi is among the p nearest neighbors of xj, or xj is among the p nearest neighbors of xi; 0, otherwise. (4) Let D be a diagonal matrix, Dii = j Sij, and L = D−S. The matrix L is called graph Laplacian in spectral graph theory [3]. Let y = (y1, · · · , yk)T and X = (x1, · · · , xm). Following some simple algebraic steps, we see that: J0(w) = k i=1 wT zi − yi 2 + λ 2 m i,j=1 wT xi − wT xj 2 Sij = y − ZT w T y − ZT w + λwT m i=1 DiixixT i − m i,j=1 SijxixT j w = yT y − 2wT Zy + wT ZZT w +λwT XDXT − XSXT w = yT y − 2wT Zy + wT ZZT + λXLXT w The Hessian of J0(w) can be computed as follows: H0 = ∂2 J0 ∂w2 = ZZT + λXLXT In some cases, the matrix ZZT +λXLXT is singular (e.g. if m < d). Thus, there is no stable solution to the optimization problem Eq. (3). A common way to deal with this ill-posed problem is to introduce a Tikhonov regularizer into our loss function: J(w) = k i=1 wT zi − yi 2 + λ1 2 m i,j=1 wT xi − wT xj 2 Sij +λ2 w 2 (5) The Hessian of the new loss function is given by: H = ∂2 J ∂w2 = ZZT + λ1XLXT + λ2I := ZZT + Λ where I is an identity matrix and Λ = λ1XLXT + λ2I. Clearly, H is of full rank. Requiring that the gradient of J(w) with respect to w vanish gives the optimal estimate ˆw: ˆw = H−1 Zy The following proposition states the bias and variance properties of the estimator for the coefficient vector w. Proposition 3.1. E( ˆw − w) = −H−1 Λw, Cov( ˆw) = σ2 (H−1 − H−1 ΛH−1 ) Proof. Since y = ZT w + and E( ) = 0, it follows that E( ˆw − w) (6) = H−1 ZZT w − w = H−1 (ZZT + Λ − Λ)w − w = (I − H−1 Λ)w − w = −H−1 Λw (7) Notice Cov(y) = σ2 I, the covariance matrix of ˆw has the expression: Cov( ˆw) = H−1 ZCov(y)ZT H−1 = σ2 H−1 ZZT H−1 = σ2 H−1 (H − Λ)H−1 = σ2 (H−1 − H−1 ΛH−1 ) (8) Therefore mean squared error matrix for the coefficients w is E(w − ˆw)(w − ˆw)T (9) = H−1 ΛwwT ΛH−1 + σ2 (H−1 − H−1 ΛH−1 ) (10) For any x, let ˆy = ˆwT x be its predicted observation. The expected squared prediction error is E(y − ˆy)2 = E( + wT x − ˆwT x)2 = σ2 + xT [E(w − ˆw)(w − ˆw)T ]x = σ2 + xT [H−1 ΛwwT ΛH−1 + σ2 H−1 − σ2 H−1 ΛH−1 ]x Clearly the expected square prediction error depends on the explanatory variable x, therefore average expected square predictive error over the complete data set A is 1 m m i=1 E(yi − ˆwT xi)2 = 1 m m i=1 xT i [H−1 ΛwwT ΛH−1 + σ2 H−1 − σ2 H−1 ΛH−1 ]xi +σ2 = 1 m Tr(XT [σ2 H−1 + H−1 ΛwwT ΛH−1 − σ2 H−1 ΛH−1 ]X) +σ2 Since Tr(XT [H−1 ΛwwT ΛH−1 − σ2 H−1 ΛH−1 ]X) Tr(σ2 XT H−1 X), Our Laplacian optimality criterion is thus formulated by minimizing the trace of XT H−1 X. Definition 1. Laplacian Optimal Design min Z=(z1,··· ,zk) Tr XT ZZT + λ1XLXT + λ2I −1 X (11) where z1, · · · , zk are selected from {x1, · · · , xm}. 4. KERNEL LAPLACIAN OPTIMAL DESIGN Canonical experimental design approaches (e.g. A-Optimal Design, D-Optimal Design, and E-Optimal) only consider linear functions. They fail to discover the intrinsic geometry in the data when the data space is highly nonlinear. In this section, we describe how to perform Laplacian Experimental Design in Reproducing Kernel Hilbert Space (RKHS) which gives rise to Kernel Laplacian Experimental Design (KLOD). For given data points x1, · · · , xm ∈ X with a positive definite mercer kernel K : X ×X → R, there exists a unique RKHS HK of real valued functions on X. Let Kt(s) be the function of s obtained by fixing t and letting Kt(s) . = K(s, t). HK consists of all finite linear combinations of the form l i=1 αiKti with ti ∈ X and limits of such functions as the ti become dense in X. We have Ks, Kt HK = K(s, t). 4.1 Derivation of LOD in Reproducing Kernel Hilbert Space Consider the optimization problem (5) in RKHS. Thus, we seek a function f ∈ HK such that the following objective function is minimized: min f∈HK k i=1 f(zi)−yi 2 + λ1 2 m i,j=1 f(xi)−f(xj) 2 Sij+λ2 f 2 HK (12) We have the following proposition. Proposition 4.1. Let H = { m i=1 αiK(·, xi)|αi ∈ R} be a subspace of HK , the solution to the problem (12) is in H. Proof. Let H⊥ be the orthogonal complement of H, i.e. HK = H ⊕ H⊥ . Thus, for any function f ∈ HK , it has orthogonal decomposition as follows: f = fH + fH⊥ Now, lets evaluate f at xi: f(xi) = f, Kxi HK = fH + fH⊥ , Kxi HK = fH, Kxi HK + fH⊥ , Kxi HK Notice that Kxi ∈ H while fH⊥ ∈ H⊥ . This implies that fH⊥ , Kxi HK = 0. Therefore, f(xi) = fH, Kxi HK = fH(xi) This completes the proof. Proposition 4.1 tells us the minimizer of problem (12) admits a representation f∗ = m i=1 αiK(·, xi). Please see [2] for the details. Let φ : Rd → H be a feature map from the input space Rd to H, and K(xi, xj) =< φ(xi), φ(xj) >. Let X denote the data matrix in RKHS, X = (φ(x1), φ(x2), · · · , φ(xm)). Similarly, we define Z = (φ(z1), φ(z2), · · · , φ(zk)). Thus, the optimization problem in RKHS can be written as follows: min Z Tr XT ZZT + λ1XLXT + λ2I −1 X (13) Since the mapping function φ is generally unknown, there is no direct way to solve problem (13). In the following, we apply kernel tricks to solve this optimization problem. Let X−1 be the Moore-Penrose inverse (also known as pseudo inverse) of X. Thus, we have: XT ZZT + λ1XLXT + λ2I −1 X = XT XX−1 ZZT + λ1XLXT + λ2I −1 (XT )−1 XT X = XT X ZZT X + λ1XLXT X + λ2X −1 (XT )−1 XT X = XT X XT ZZT X + λ1XT XLXT X + λ2XT X −1 XT X = KXX KXZKZX + λ1KXXLKXX + λ2KXX −1 KXX where KXX is a m × m matrix (KXX,ij = K(xi, xj)), KXZ is a m×k matrix (KXZ,ij = K(xi, zj)), and KZX is a k×m matrix (KZX,ij = K(zi, xj)). Thus, the Kernel Laplacian Optimal Design can be defined as follows: Definition 2. Kernel Laplacian Optimal Design minZ=(z1,··· ,zk) Tr KXX KXZKZX + λ1KXXLKXX λ2KXX −1 KXX (14) 4.2 Optimization Scheme In this subsection, we discuss how to solve the optimization problems (11) and (14). Particularly, if we select a linear kernel for KLOD, then it reduces to LOD. Therefore, we will focus on problem (14) in the following. It can be shown that the optimization problem (14) is NP-hard. In this subsection, we develop a simple sequential greedy approach to solve (14). Suppose n points have been selected, denoted by a matrix Zn = (z1, · · · , zn). The (n + 1)-th point zn+1 can be selected by solving the following optimization problem: max Zn+1=(Zn,zn+1) Tr KXX KXZn+1 KZn+1X + λ1KXXLKXX + λ2KXX −1 KXX (15) The kernel matrices KXZn+1 and KZn+1X can be rewritten as follows: KXZn+1 = KXZn , KXzn+1 , KZn+1X = KZnX Kzn+1X Thus, we have: KXZn+1 KZn+1X = KXZn KZnX + KXzn+1 Kzn+1X We define: A = KXZn KZnX + λ1KXXLKXX + λ2KXX A is only dependent on X and Zn . Thus, the (n + 1)-th point zn+1 is given by: zn+1 = arg min zn+1 Tr KXX A + KXzn+1 Kzn+1X −1 KXX (16) Each time we select a new point zn+1, the matrix A is updated by: A ← A + KXzn+1 Kzn+1X If the kernel function is chosen as inner product K(x, y) = x, y , then HK is a linear functional space and the algorithm reduces to LOD. 5. CONTENT-BASED IMAGE RETRIEVAL USING LAPLACIAN OPTIMAL DESIGN In this section, we describe how to apply Laplacian Optimal Design to CBIR. We begin with a brief description of image representation using low level visual features. 5.1 Low-Level Image Representation Low-level image representation is a crucial problem in CBIR. General visual features includes color, texture, shape, etc. Color and texture features are the most extensively used visual features in CBIR. Compared with color and texture features, shape features are usually described after images have been segmented into regions or objects. Since robust and accurate image segmentation is difficult to achieve, the use of shape features for image retrieval has been limited to special applications where objects or regions are readily available. In this work, We combine 64-dimensional color histogram and 64-dimensional Color Texture Moment (CTM, [15]) to represent the images. The color histogram is calculated using 4 × 4 × 4 bins in HSV space. The Color Texture Moment is proposed by Yu et al. [15], which integrates the color and texture characteristics of the image in a compact form. CTM adopts local Fourier transform as a texture representation scheme and derives eight characteristic maps to describe different aspects of co-occurrence relations of image pixels in each channel of the (SVcosH, SVsinH, V) color space. Then CTM calculates the first and second moment of these maps as a representation of the natural color image pixel distribution. Please see [15] for details. 5.2 Relevance Feedback Image Retrieval Relevance feedback is one of the most important techniques to narrow down the gap between low level visual features and high level semantic concepts [12]. Traditionally, the users relevance feedbacks are used to update the query vector or adjust the weighting of different dimensions. This process can be viewed as an on-line learning process in which the image retrieval system acts as a learner and the user acts as a teacher. They typical retrieval process is outlined as follows: 1. The user submits a query image example to the system. The system ranks the images in database according to some pre-defined distance metric and presents to the user the top ranked images. 2. The system selects some images from the database and request the user to label them as relevant or irrelevant. 3. The system uses the users provided information to rerank the images in database and returns to the user the top images. Go to step 2 until the user is satisfied. Our Laplacian Optimal Design algorithm is applied in the second step for selecting the most informative images. Once we get the labels for the images selected by LOD, we apply Laplacian Regularized Regression (LRR, [2]) to solve the optimization problem (3) and build the classifier. The classifier is then used to re-rank the images in database. Note that, in order to reduce the computational complexity, we do not use all the unlabeled images in the database but only those within top 500 returns of previous iteration. 6. EXPERIMENTAL RESULTS In this section, we evaluate the performance of our proposed algorithm on a large image database. To demonstrate the effectiveness of our proposed LOD algorithm, we compare it with Laplacian Regularized Regression (LRR, [2]), Support Vector Machine (SVM), Support Vector Machine Active Learning (SVMactive) [14], and A-Optimal Design (AOD). Both SVMactive, AOD, and LOD are active learning algorithms, while LRR and SVM are standard classification algorithms. SVM only makes use of the labeled images, while LRR is a semi-supervised learning algorithm which makes use of both labeled and unlabeled images. For SVMactive, AOD, and LOD, 10 training images are selected by the algorithms themselves at each iteration. While for LRR and SVM, we use the top 10 images as training data. It would be important to note that SVMactive is based on the ordinary SVM, LOD is based on LRR, and AOD is based on the ordinary regression. The parameters λ1 and λ2 in our LOD algorithm are empirically set to be 0.001 and 0.00001. For both LRR and LOD algorithms, we use the same graph structure (see Eq. 4) and set the value of p (number of nearest neighbors) to be 5. We begin with a simple synthetic example to give some intuition about how LOD works. 6.1 Simple Synthetic Example A simple synthetic example is given in Figure 1. The data set contains two circles. Eight points are selected by AOD and LOD. As can be seen, all the points selected by AOD are from the big circle, while LOD selects four points from the big circle and four from the small circle. The numbers beside the selected points denote their orders to be selected. Clearly, the points selected by our LOD algorithm can better represent the original data set. We did not compare our algorithm with SVMactive because SVMactive can not be applied in this case due to the lack of the labeled points. 6.2 Image Retrieval Experimental Design The image database we used consists of 7,900 images of 79 semantic categories, from COREL data set. It is a large and heterogeneous image set. Each image is represented as a 128-dimensional vector as described in Section 5.1. Figure 2 shows some sample images. To exhibit the advantages of using our algorithm, we need a reliable way of evaluating the retrieval performance and the comparisons with other algorithms. We list different aspects of the experimental design below. 6.2.1 Evaluation Metrics We use precision-scope curve and precision rate [10] to evaluate the effectiveness of the image retrieval algorithms. The scope is specified by the number (N) of top-ranked images presented to the user. The precision is the ratio of the number of relevant images presented to the user to the (a) Data set 1 2 3 4 5 6 7 8 (b) AOD 1 2 3 4 5 6 7 8 (c) LOD Figure 1: Data selection by active learning algorithms. The numbers beside the selected points denote their orders to be selected. Clearly, the points selected by our LOD algorithm can better represent the original data set. Note that, the SVMactive algorithm can not be applied in this case due to the lack of labeled points. (a) (b) (c) Figure 2: Sample images from category bead, elephant, and ship. scope N. The precision-scope curve describes the precision with various scopes and thus gives an overall performance evaluation of the algorithms. On the other hand, the precision rate emphasizes the precision at a particular value of scope. In general, it is appropriate to present 20 images on a screen. Putting more images on a screen may affect the quality of the presented images. Therefore, the precision at top 20 (N = 20) is especially important. In real world image retrieval systems, the query image is usually not in the image database. To simulate such environment, we use five-fold cross validation to evaluate the algorithms. More precisely, we divide the whole image database into five subsets with equal size. Thus, there are 20 images per category in each subset. At each run of cross validation, one subset is selected as the query set, and the other four subsets are used as the database for retrieval. The precisionscope curve and precision rate are computed by averaging the results from the five-fold cross validation. 6.2.2 Automatic Relevance Feedback Scheme We designed an automatic feedback scheme to model the retrieval process. For each submitted query, our system retrieves and ranks the images in the database. 10 images were selected from the database for user labeling and the label information is used by the system for re-ranking. Note that, the images which have been selected at previous iterations are excluded from later selections. For each query, the automatic relevance feedback mechanism is performed for four iterations. It is important to note that the automatic relevance feedback scheme used here is different from the ones described in [8], [11]. In [8], [11], the top four relevant and irrelevant images were selected as the feedback images. However, this may not be practical. In real world image retrieval systems, it is possible that most of the top-ranked images are relevant (or, irrelevant). Thus, it is difficult for the user to find both four relevant and irrelevant images. It is more reasonable for the users to provide feedback information only on the 10 images selected by the system. 6.3 Image Retrieval Performance In real world, it is not practical to require the user to provide many rounds of feedbacks. The retrieval performance after the first two rounds of feedbacks (especially the first round) is more important. Figure 3 shows the average precision-scope curves of the different algorithms for the first two feedback iterations. At the beginning of retrieval, the Euclidean distances in the original 128-dimensional space are used to rank the images in database. After the user provides relevance feedbacks, the LRR, SVM, SVMactive, AOD, and LOD algorithms are then applied to re-rank the images. In order to reduce the time complexity of active learning algorithms, we didnt select the most informative images from the whole database but from the top 500 images. For LRR and SVM, the user is required to label the top 10 images. For SVMactive, AOD, and LOD, the user is required to label 10 most informative images selected by these algorithms. Note that, SVMactive can only be ap(a) Feedback Iteration 1 (b) Feedback Iteration 2 Figure 3: The average precision-scope curves of different algorithms for the first two feedback iterations. The LOD algorithm performs the best on the entire scope. Note that, at the first round of feedback, the SVMactive algorithm can not be applied. It applies the ordinary SVM to build the initial classifier. (a) Precision at Top 10 (b) Precision at Top 20 (c) Precision at Top 30 Figure 4: Performance evaluation of the five learning algorithms for relevance feedback image retrieval. (a) Precision at top 10, (b) Precision at top 20, and (c) Precision at top 30. As can be seen, our LOD algorithm consistently outperforms the other four algorithms. plied when the classifier is already built. Therefore, it can not be applied at the first round and we use the standard SVM to build the initial classifier. As can be seen, our LOD algorithm outperforms the other four algorithms on the entire scope. Also, the LRR algorithm performs better than SVM. This is because that the LRR algorithm makes efficient use of the unlabeled images by incorporating a locality preserving regularizer into the ordinary regression objective function. The AOD algorithm performs the worst. As the scope gets larger, the performance difference between these algorithms gets smaller. By iteratively adding the users feedbacks, the corresponding precision results (at top 10, top 20, and top 30) of the five algorithms are respectively shown in Figure 4. As can be seen, our LOD algorithm performs the best in all the cases and the LRR algorithm performs the second best. Both of these two algorithms make use of the unlabeled images. This shows that the unlabeled images are helpful for discovering the intrinsic geometrical structure of the image space and therefore enhance the retrieval performance. In real world, the user may not be willing to provide too many relevance feedbacks. Therefore, the retrieval performance at the first two rounds are especially important. As can be seen, our LOD algorithm achieves 6.8% performance improvement for top 10 results, 5.2% for top 20 results, and 4.1% for top 30 results, comparing to the second best algorithm (LRR) after the first two rounds of relevance feedbacks. 6.4 Discussion Several experiments on Corel database have been systematically performed. We would like to highlight several interesting points: 1. It is clear that the use of active learning is beneficial in the image retrieval domain. There is a significant increase in performance from using the active learning methods. Especially, out of the three active learning methods (SVMactive, AOD, LOD), our proposed LOD algorithm performs the best. 2. In many real world applications like relevance feedback image retrieval, there are generally two ways of reducing labor-intensive manual labeling task. One is active learning which selects the most informative samples to label, and the other is semi-supervised learning which makes use of the unlabeled samples to enhance the learning performance. Both of these two strategies have been studied extensively in the past [14], [7], [5], [8]. The work presented in this paper is focused on active learning, but it also takes advantage of the recent progresses on semi-supervised learning [2]. Specifically, we incorporate a locality preserving regularizer into the standard regression framework and find the most informative samples with respect to the new objective function. In this way, the active learning and semi-supervised learning techniques are seamlessly unified for learning an optimal classifier. 3. The relevance feedback technique is crucial to image retrieval. For all the five algorithms, the retrieval performance improves with more feedbacks provided by the user. 7. CONCLUSIONS AND FUTURE WORK This paper describes a novel active learning algorithm, called Laplacian Optimal Design, to enable more effective relevance feedback image retrieval. Our algorithm is based on an objective function which simultaneously minimizes the empirical error and preserves the local geometrical structure of the data space. Using techniques from experimental design, our algorithm finds the most informative images to label. These labeled images and the unlabeled images in the database are used to learn a classifier. The experimental results on Corel database show that both active learning and semi-supervised learning can significantly improve the retrieval performance. In this paper, we consider the image retrieval problem on a small, static, and closed-domain image data. A much more challenging domain is the World Wide Web (WWW). For Web image search, it is possible to collect a large amount of user click information. This information can be naturally used to construct the affinity graph in our algorithm. However, the computational complexity in Web scenario may become a crucial issue. Also, although our primary interest in this paper is focused on relevance feedback image retrieval, our results may also be of interest to researchers in patten recognition and machine learning, especially when a large amount of data is available but only a limited samples can be labeled. 8. REFERENCES [1] A. C. Atkinson and A. N. Donev. Optimum Experimental Designs. Oxford University Press, 2002. [2] M. Belkin, P. Niyogi, and V. Sindhwani. Manifold regularization: A geometric framework for learning from examples. Journal of Machine Learning Research, 7:2399-2434, 2006. [3] F. R. K. Chung. Spectral Graph Theory, volume 92 of Regional Conference Series in Mathematics. AMS, 1997. [4] D. A. Cohn, Z. Ghahramani, and M. I. Jordan. Active learning with statistical models. Journal of Artificial Intelligence Research, 4:129-145, 1996. [5] A. Dong and B. Bhanu. A new semi-supervised em algorithm for image retrieval. In IEEE Conf. on Computer Vision and Pattern Recognition, Madison, WI, 2003. [6] P. Flaherty, M. I. Jordan, and A. P. Arkin. Robust design of biological experiments. In Advances in Neural Information Processing Systems 18, Vancouver, Canada, 2005. [7] K.-S. Goh, E. Y. Chang, and W.-C. Lai. Multimodal concept-dependent active learning for image retrieval. In Proceedings of the ACM Conference on Multimedia, New York, October 2004. [8] X. He. Incremental semi-supervised subspace learning for image retrieval. In Proceedings of the ACM Conference on Multimedia, New York, October 2004. [9] S. C. Hoi and M. R. Lyu. A semi-supervised active learning framework for image retrieval. In IEEE International Conference on Computer Vision and Pattern Recognition, San Diego, CA, 2005. [10] D. P. Huijsmans and N. Sebe. How to complete performance graphs in content-based image retrieval: Add generality and normalize scope. IEEE Transactions on Pattern Analysis and Machine Intelligence, 27(2):245-251, 2005. [11] Y.-Y. Lin, T.-L. Liu, and H.-T. Chen. Semantic manifold learning for image retrieval. In Proceedings of the ACM Conference on Multimedia, Singapore, November 2005. [12] Y. Rui, T. S. Huang, M. Ortega, and S. Mehrotra. Relevance feedback: A power tool for interative content-based image retrieval. IEEE Transactions on Circuits and Systems for Video Technology, 8(5), 1998. [13] A. W. Smeulders, M. Worring, S. Santini, A. Gupta, and R. Jain. Content-based image retrieval at the end of the early years. IEEE Transactions on Pattern Analysis and Machine Intelligence, 22(12):1349-1380, 2000. [14] S. Tong and E. Chang. Support vector machine active learning for image retrieval. In Proceedings of the ninth ACM international conference on Multimedia, pages 107-118, 2001. [15] H. Yu, M. Li, H.-J. Zhang, and J. Feng. Color texture moments for content-based image retrieval. In International Conference on Image Processing, pages 24-28, 2002. [16] K. Yu, J. Bi, and V. Tresp. Active learning via transductive experimental design. In Proceedings of the 23rd International Conference on Machine Learning, Pittsburgh, PA, 2006.",
    "original_translation": "Diseño óptimo de Laplaciano para la recuperación de imágenes Xiaofei He Yahoo! El feedback de relevancia es una técnica poderosa para mejorar el rendimiento de la Recuperación de Imágenes Basada en Contenido (CBIR). Solicita las valoraciones de relevancia de los usuarios sobre las imágenes recuperadas por los sistemas CBIR. La etiqueta de los usuarios se utiliza luego para entrenar un clasificador que distinga entre imágenes relevantes e irrelevantes. Sin embargo, las imágenes principales que se devuelven pueden no ser las más informativas. El desafío consiste en determinar qué imágenes sin etiquetar serían las más informativas (es decir, mejorarían más al clasificador) si fueran etiquetadas y utilizadas como muestras de entrenamiento. En este artículo, proponemos un novedoso algoritmo de aprendizaje activo, llamado Diseño Óptimo Laplaciano (LOD), para la recuperación de imágenes con retroalimentación de relevancia. Nuestro algoritmo se basa en un modelo de regresión que minimiza el error cuadrático mínimo en las imágenes medidas (o etiquetadas) y al mismo tiempo preserva la estructura geométrica local del espacio de la imagen. Específicamente, asumimos que si dos imágenes están lo suficientemente cerca una de la otra, entonces sus medidas (o etiquetas) también son cercanas. Al construir un grafo de vecinos más cercanos, la estructura geométrica del espacio de la imagen puede ser descrita por el Laplaciano del grafo. Discutimos cómo los resultados del campo del diseño experimental óptimo pueden ser utilizados para guiar nuestra selección de un subconjunto de imágenes, que nos proporciona la mayor cantidad de información. Los resultados experimentales en la base de datos Corel sugieren que el enfoque propuesto logra una mayor precisión en la recuperación de imágenes con retroalimentación de relevancia. Categorías y Descriptores de Asignaturas H.3.3 [Almacenamiento y recuperación de información]: Búsqueda y recuperación de información-Retroalimentación de relevancia; G.3 [Matemáticas de la Computación]: Probabilidad y Estadística-Diseño experimental Términos Generales Algoritmos, Rendimiento, Teoría 1. INTRODUCCIÓN En muchas tareas de aprendizaje automático y recuperación de información, no hay escasez de datos no etiquetados pero las etiquetas son costosas. El desafío consiste en determinar qué muestras sin etiquetar serían las más informativas (es decir, mejorarían más el clasificador) si fueran etiquetadas y utilizadas como muestras de entrenamiento. Este problema se llama típicamente aprendizaje activo [4]. Aquí la tarea es minimizar un costo general, que depende tanto de la precisión del clasificador como del costo de la recolección de datos. Muchas aplicaciones del mundo real pueden ser adaptadas al marco de aprendizaje activo. Particularmente, consideramos el problema de la recuperación de imágenes basada en contenido impulsada por la retroalimentación de relevancia (CBIR) [13]. La Recuperación de Imágenes Basada en Contenido ha atraído un interés sustancial en la última década [13]. Está motivado por el rápido crecimiento de las bases de datos de imágenes digitales que, a su vez, requieren esquemas de búsqueda eficientes. En lugar de describir una imagen usando texto, en estos sistemas se describe una consulta de imagen utilizando una o más imágenes de ejemplo. Las características visuales de bajo nivel (color, textura, forma, etc.) se extraen automáticamente para representar las imágenes. Sin embargo, las características de bajo nivel pueden no caracterizar con precisión los conceptos semánticos de alto nivel. Para reducir la brecha semántica, se introduce la retroalimentación de relevancia en la recuperación de información basada en el contenido (CBIR) [12]. En muchos de los sistemas actuales de recuperación de imágenes basados en retroalimentación de relevancia, se requiere que el usuario proporcione sus juicios de relevancia sobre las imágenes principales devueltas por el sistema. Las imágenes etiquetadas se utilizan luego para entrenar un clasificador que separe las imágenes que coinciden con el concepto de la consulta de aquellas que no lo hacen. Sin embargo, en general, las imágenes principales que se devuelven pueden no ser las más informativas. En el peor de los casos, todas las imágenes principales etiquetadas por el usuario pueden ser positivas y, por lo tanto, las técnicas estándar de clasificación no pueden aplicarse debido a la falta de ejemplos negativos. A diferencia de los problemas de clasificación estándar donde las muestras etiquetadas están predefinidas, en la recuperación de imágenes con retroalimentación de relevancia, el sistema puede seleccionar activamente las imágenes a etiquetar. Por lo tanto, el aprendizaje activo puede ser introducido de forma natural en la recuperación de imágenes. A pesar de la existencia de muchas técnicas de aprendizaje activo, el aprendizaje activo de Máquina de Vectores de Soporte (SVM) [14] y el aprendizaje activo basado en regresión [1] han sido los que han despertado mayor interés. Basado en la observación de que cuanto más cerca del límite del SVM se encuentre una imagen, menos confiable es su clasificación, el aprendizaje activo del SVM selecciona aquellas imágenes no etiquetadas más cercanas al límite para solicitar retroalimentación del usuario con el fin de lograr un refinamiento máximo en el hiperplano entre las dos clases. La principal desventaja del aprendizaje activo de SVM es que es posible que el límite estimado no sea lo suficientemente preciso. Además, puede que no se aplique al principio de la recuperación cuando no hay imágenes etiquetadas. Algunos otros algoritmos de aprendizaje activo basados en SVM se pueden encontrar en [7], [9]. En estadística, el problema de seleccionar muestras para etiquetar se conoce típicamente como diseño experimental. La muestra x se denomina experimento, y su etiqueta y se denomina medición. El estudio del diseño experimental óptimo (DEO) se preocupa por el diseño de experimentos que se espera que minimicen las varianzas de un modelo parametrizado. La intención del diseño experimental óptimo suele ser maximizar la confianza en un modelo dado, minimizar las varianzas de los parámetros para la identificación del sistema, o minimizar la varianza de la salida de los modelos. Los enfoques clásicos de diseño experimental incluyen el Diseño A-Óptimo, el Diseño D-Óptimo y el Diseño E-Óptimo. Todos estos enfoques se basan en un modelo de regresión de mínimos cuadrados. En comparación con los algoritmos de aprendizaje activo basados en SVM, los enfoques de diseño experimental son mucho más eficientes en términos de computación. Sin embargo, este tipo de enfoques solo tienen en cuenta los datos medidos (o etiquetados) en su función objetivo, mientras que los datos no medidos (o no etiquetados) son ignorados. Beneficiar de los avances recientes en diseño experimental óptimo y aprendizaje semisupervisado, en este artículo proponemos un nuevo algoritmo de aprendizaje activo para recuperación de imágenes, llamado Diseño Óptimo Laplaciano (LOD). A diferencia de los métodos tradicionales de diseño experimental cuyas funciones de pérdida solo están definidas en los puntos medidos, la función de pérdida de nuestro algoritmo propuesto LOD está definida tanto en los puntos medidos como en los no medidos. Específicamente, introducimos un regularizador que preserva la localidad en la función de pérdida estándar basada en el error cuadrático mínimo. La nueva función de pérdida tiene como objetivo encontrar un clasificador que sea localmente lo más suave posible. En otras palabras, si dos puntos están suficientemente cerca uno del otro en el espacio de entrada, se espera que compartan la misma etiqueta. Una vez que se define la función de pérdida, podemos seleccionar los puntos de datos más informativos que se presentan al usuario para su etiquetado. Sería importante tener en cuenta que las imágenes más informativas pueden no ser las primeras imágenes devueltas. El resto del documento está organizado de la siguiente manera. En la Sección 2, proporcionamos una breve descripción del trabajo relacionado. Nuestro algoritmo propuesto de Diseño Óptimo de Laplaciano se introduce en la Sección 3. En la Sección 4, comparamos nuestro algoritmo con los algoritmos de última generación y presentamos los resultados experimentales sobre la recuperación de imágenes. Finalmente, proporcionamos algunas observaciones finales y sugerencias para trabajos futuros en la Sección 5.2. TRABAJO RELACIONADO Dado que nuestro algoritmo propuesto se basa en un marco de regresión. El trabajo más relacionado es el diseño experimental óptimo [1], que incluye el Diseño A-Óptimo, el Diseño D-Óptimo y el Diseño E-Óptimo. En esta sección, damos una breve descripción de estos enfoques. 2.1 El Problema del Aprendizaje Activo El problema genérico del aprendizaje activo es el siguiente. Dado un conjunto de puntos A = {x1, x2, · · · , xm} en Rd , encuentra un subconjunto B = {z1, z2, · · · , zk} ⊂ A que contenga los puntos más informativos. En otras palabras, los puntos zi(i = 1, · · · , k) pueden mejorar el clasificador al máximo si están etiquetados y se utilizan como puntos de entrenamiento. 2.2 Diseño Experimental Óptimo Consideramos un modelo de regresión lineal y = wT x + (1) donde y es la observación, x es la variable independiente, w es el vector de pesos y es un error desconocido con media cero. Diferentes observaciones tienen errores que son independientes, pero con varianzas iguales σ2. Definimos f(x) = wT x como la salida del aprendiz dada la entrada x y el vector de pesos w. Supongamos que tenemos un conjunto de puntos de muestra etiquetados (z1, y1), · · · , (zk, yk), donde yi es la etiqueta de zi. Por lo tanto, la estimación de máxima verosimilitud para el vector de peso, ˆw, es aquella que minimiza la suma del error cuadrado Jsse(w) = k i=1 wT zi − yi 2 (2). La estimación ˆw nos proporciona una estimación de la salida en una entrada novedosa: ˆy = ˆwT x. Según el teorema de Gauss-Markov, sabemos que ˆw − w tiene una media cero y una matriz de covarianza dada por σ2 H−1 sse, donde Hsse es la Hessiana de Jsse(w) Hsse = ∂2 Jsse ∂w2 = k i=1 zizT i = ZZT donde Z = (z1, z2, · · · , zk). Las tres medidas escalares más comunes del tamaño de la matriz de covarianza de parámetros en el diseño experimental óptimo son: • Diseño D-óptimo: determinante de Hsse. • Diseño A-óptimo: traza de Hsse. • Diseño E-óptimo: valor propio máximo de Hsse. Dado que el cálculo del determinante y los valores propios de una matriz es mucho más costoso que el cálculo de la traza de la matriz, el diseño A-óptimo es más eficiente que los otros dos. Algunos trabajos recientes sobre diseño experimental se pueden encontrar en [6], [16]. DISEÑO ÓPTIMO LAPLACIANO Dado que la matriz de covarianza Hsse utilizada en enfoques tradicionales solo depende de las muestras medidas, es decir, zis, estos enfoques no logran evaluar los errores esperados en las muestras no medidas. En esta sección, presentamos un novedoso algoritmo de aprendizaje activo llamado Diseño Óptimo Laplaciano (LOD) que hace un uso eficiente tanto de muestras medidas (etiquetadas) como no medidas (sin etiquetar). 3.1 La Función Objetivo En muchos problemas de aprendizaje automático, es natural asumir que si dos puntos xi, xj están suficientemente cerca uno del otro, entonces sus mediciones (f(xi), f(xj)) también son cercanas. Sea S una matriz de similitud. Por lo tanto, una nueva función de pérdida que respeta la estructura geométrica del espacio de datos se puede definir de la siguiente manera: J0(w) = k i=1 f(zi)−yi 2 + λ 2 m i,j=1 f(xi)−f(xj) 2 Sij (3) donde yi es la medición (o etiqueta) de zi. Se debe tener en cuenta que la función de pérdida (3) es esencialmente la misma que la utilizada en la Regresión Regularizada Laplaciana (LRR, [2]). Sin embargo, LRR es un algoritmo de aprendizaje pasivo donde se proporcionan los datos de entrenamiento. En este artículo, nos enfocamos en cómo seleccionar los datos más informativos para el entrenamiento. La función de pérdida con nuestra elección de pesos simétricos Sij (Sij = Sji) incurre en una penalización severa si los puntos vecinos xi y xj se asignan lejos uno del otro. Por lo tanto, minimizar J0(w) es un intento de asegurar que si xi y xj están cerca, entonces f(xi) y f(xj) también estén cerca. Hay muchas opciones de la matriz de similitud S. Una definición simple es la siguiente: Sij = ⎧ ⎨ ⎩ 1, si xi está entre los p vecinos más cercanos de xj, o xj está entre los p vecinos más cercanos de xi; 0, en otro caso. (4) Sea D una matriz diagonal, Dii = j Sij, y L = D−S. La matriz L se llama Laplaciano de grafo en la teoría espectral de grafos [3]. Sea y = (y1, · · · , yk)T y X = (x1, · · · , xm). Siguiendo algunos pasos algebraicos simples, vemos que: J0(w) = k i=1 wT zi − yi 2 + λ 2 m i,j=1 wT xi − wT xj 2 Sij = y − ZT w T y − ZT w + λwT m i=1 DiixixT i − m i,j=1 SijxixT j w = yT y − 2wT Zy + wT ZZT w +λwT m i=1 DiixixT i − m i,j=1 SijxixT j w = yT y − 2wT Zy + wT ZZT + λXLXT w La Hessiana de J0(w) se puede calcular de la siguiente manera: H0 = ∂2 J0 ∂w2 = ZZT + λXLXT En algunos casos, la matriz ZZT +λXLXT es singular (por ejemplo, si m < d). Por lo tanto, no hay una solución estable para el problema de optimización Ec. (3). Una forma común de abordar este problema mal planteado es introducir un regularizador de Tikhonov en nuestra función de pérdida: J(w) = k i=1 wT zi − yi 2 + λ1 2 m i,j=1 wT xi − wT xj 2 Sij +λ2 w 2 (5) El Hessiano de la nueva función de pérdida está dado por: H = ∂2 J ∂w2 = ZZT + λ1XLXT + λ2I := ZZT + Λ donde I es una matriz identidad y Λ = λ1XLXT + λ2I. Claramente, H tiene rango completo. Exigir que el gradiente de J(w) con respecto a w se anule proporciona la estimación óptima ˆw: ˆw = H−1 Zy. La siguiente proposición establece las propiedades de sesgo y varianza del estimador para el vector de coeficientes w. Proposición 3.1. E( ˆw − w) = −H−1 Λw, Cov( ˆw) = σ2 (H−1 − H−1 ΛH−1 ) Demostración. Dado que y = ZTw + y E( ) = 0, se deduce que E( ˆw − w) (6) = H−1 ZZTw − w = H−1 (ZZT + Λ − Λ)w − w = (I − H−1 Λ)w − w = −H−1 Λw (7) Nótese que Cov(y) = σ2 I, la matriz de covarianza de ˆw tiene la expresión: Cov( ˆw) = H−1 ZCov(y)ZT H−1 = σ2 H−1 ZZT H−1 = σ2 H−1 (H − Λ)H−1 = σ2 (H−1 − H−1 ΛH−1 ) (8) Por lo tanto, la matriz de error cuadrático medio para los coeficientes w es E(w − ˆw)(w − ˆw)T (9) = H−1 ΛwwT ΛH−1 + σ2 (H−1 − H−1 ΛH−1 ) (10) Para cualquier x, sea ˆy = ˆwT x su observación predicha. El error cuadrático de predicción esperado es E(y − ˆy)2 = E( + wT x − ˆwT x)2 = σ2 + xT [E(w − ˆw)(w − ˆw)T ]x = σ2 + xT [H−1 ΛwwT ΛH−1 + σ2 H−1 − σ2 H−1 ΛH−1 ]x Claramente, el error cuadrático de predicción esperado depende de la variable explicativa x, por lo tanto, el error cuadrático de predicción promedio esperado sobre el conjunto de datos completo A es 1 m m i=1 E(yi − ˆwT xi)2 = 1 m m i=1 xT i [H−1 ΛwwT ΛH−1 + σ2 H−1 − σ2 H−1 ΛH−1 ]xi +σ2 = 1 m Tr(XT [σ2 H−1 + H−1 ΛwwT ΛH−1 − σ2 H−1 ΛH−1 ]X) +σ2 Dado que Tr(XT [H−1 ΛwwT ΛH−1 − σ2 H−1 ΛH−1 ]X) Tr(σ2 XT H−1 X), nuestro criterio de optimalidad laplaciano se formula minimizando la traza de XT H−1 X. Definición 1. Diseño óptimo de Laplaciano min Z=(z1,··· ,zk) Tr XT ZZT + λ1XLXT + λ2I −1 X (11) donde z1, · · · , zk son seleccionados de {x1, · · · , xm}. 4. DISEÑO ÓPTIMO DEL NÚCLEO LAPLACIANO Enfoques canónicos de diseño experimental (por ejemplo, Los diseños A-óptimos, D-óptimos y E-óptimos solo consideran funciones lineales. No logran descubrir la geometría intrínseca en los datos cuando el espacio de datos es altamente no lineal. En esta sección, describimos cómo realizar el Diseño Experimental Laplaciano en el Espacio de Hilbert de Núcleos Reproductores (RKHS), lo que da lugar al Diseño Experimental Laplaciano de Núcleo (KLOD). Para los puntos de datos dados x1, · · · , xm ∈ X con un núcleo de Mercer positivo definido K : X ×X → R, existe un único RKHS HK de funciones de valores reales en X. Sea Kt(s) la función de s obtenida al fijar t y dejar que Kt(s) = K(s, t). HK consiste en todas las combinaciones lineales finitas de la forma ∑ i=1 αiKti con ti ∈ X y los límites de tales funciones a medida que los ti se vuelven densos en X. Tenemos Ks, Kt HK = K(s, t). 4.1 Derivación de LOD en el Espacio de Hilbert del Núcleo Reproductor. Considera el problema de optimización (5) en RKHS. Por lo tanto, buscamos una función f ∈ HK tal que se minimice la siguiente función objetivo: min f∈HK k i=1 f(zi)−yi 2 + λ1 2 m i,j=1 f(xi)−f(xj) 2 Sij+λ2 f 2 HK (12). Tenemos la siguiente proposición. Proposición 4.1. Sea H = { m i=1 αiK(·, xi)|αi ∈ R} un subespacio de HK, la solución al problema (12) está en H. Demostración. Sea H⊥ el complemento ortogonal de H, es decir, HK = H ⊕ H⊥. Por lo tanto, para cualquier función f ∈ HK, tiene una descomposición ortogonal de la siguiente manera: f = fH + fH⊥ Ahora, evaluemos f en xi: f(xi) = f, Kxi HK = fH + fH⊥ , Kxi HK = fH, Kxi HK + fH⊥ , Kxi HK Observa que Kxi ∈ H mientras que fH⊥ ∈ H⊥. Esto implica que fH⊥ , Kxi HK = 0. Por lo tanto, f(xi) = fH, Kxi HK = fH(xi). Esto completa la prueba. La Proposición 4.1 nos dice que el minimizador del problema (12) admite una representación f∗ = m i=1 αiK(·, xi). Por favor, consulte [2] para ver los detalles. Sea φ : Rd → H un mapeo de características del espacio de entrada Rd a H, y K(xi, xj) =< φ(xi), φ(xj) >. Que X denote la matriz de datos en RKHS, X = (φ(x1), φ(x2), · · · , φ(xm)). De manera similar, definimos Z = (φ(z1), φ(z2), · · · , φ(zk)). Por lo tanto, el problema de optimización en RKHS se puede escribir de la siguiente manera: min Z Tr XT ZZT + λ1XLXT + λ2I −1 X (13) Dado que la función de mapeo φ generalmente es desconocida, no hay una forma directa de resolver el problema (13). En lo siguiente, aplicamos trucos de kernel para resolver este problema de optimización. Sea X−1 la inversa de Moore-Penrose (también conocida como pseudoinversa) de X. Así, tenemos: XT ZZT + λ1XLXT + λ2I −1 X = XT XX−1 ZZT + λ1XLXT + λ2I −1 (XT )−1 XT X = XT X ZZT X + λ1XLXT X + λ2X −1 (XT )−1 XT X = XT X XT ZZT X + λ1XT XLXT X + λ2XT X −1 XT X = KXX KXZKZX + λ1KXXLKXX + λ2KXX −1 KXX donde KXX es una matriz m × m (KXX,ij = K(xi, xj)), KXZ es una matriz m×k (KXZ,ij = K(xi, zj)), y KZX es una matriz k×m (KZX,ij = K(zi, xj)). Por lo tanto, el Diseño Óptimo del Laplaciano del Núcleo se puede definir de la siguiente manera: Definición 2. En este subapartado, discutimos cómo resolver los problemas de optimización (11) y (14). Particularmente, si seleccionamos un núcleo lineal para KLOD, entonces se reduce a LOD. Por lo tanto, nos enfocaremos en el problema (14) a continuación. Se puede demostrar que el problema de optimización (14) es NP-duro. En esta subsección, desarrollamos un enfoque codicioso secuencial simple para resolver (14). Supongamos que se han seleccionado n puntos, denotados por una matriz Zn = (z1, · · · , zn). El punto (n + 1)-ésimo zn+1 puede ser seleccionado resolviendo el siguiente problema de optimización: max Zn+1=(Zn,zn+1) Tr KXX KXZn+1 KZn+1X + λ1KXXLKXX + λ2KXX −1 KXX (15) Las matrices de kernel KXZn+1 y KZn+1X pueden ser reescritas de la siguiente manera: KXZn+1 = KXZn , KXzn+1 , KZn+1X = KZnX Kzn+1X Por lo tanto, tenemos: KXZn+1 KZn+1X = KXZn KZnX + KXzn+1 Kzn+1X Definimos: A = KXZn KZnX + λ1KXXLKXX + λ2KXX A solo depende de X y Zn. Por lo tanto, el punto (n + 1)-ésimo zn+1 se da por: zn+1 = arg min zn+1 Tr KXX A + KXzn+1 Kzn+1X −1 KXX. Cada vez que seleccionamos un nuevo punto zn+1, la matriz A se actualiza por: A ← A + KXzn+1 Kzn+1X. Si la función de kernel se elige como producto interno K(x, y) = x, y, entonces HK es un espacio funcional lineal y el algoritmo se reduce a LOD. 5. RECUPERACIÓN DE IMÁGENES BASADA EN CONTENIDO UTILIZANDO DISEÑO ÓPTIMO LAPLACIANO En esta sección, describimos cómo aplicar el Diseño Óptimo Laplaciano a la RCIB. Comenzamos con una breve descripción de la representación de imágenes utilizando características visuales de nivel bajo. 5.1 Representación de Imágenes de Nivel Bajo La representación de imágenes de nivel bajo es un problema crucial en la Recuperación de Información Basada en el Contenido (CBIR). Las características visuales generales incluyen color, textura, forma, etc. Las características de color y textura son las características visuales más ampliamente utilizadas en la recuperación de información basada en contenido (CBIR). En comparación con las características de color y textura, las características de forma suelen describirse después de que las imágenes hayan sido segmentadas en regiones u objetos. Dado que la segmentación de imágenes robusta y precisa es difícil de lograr, el uso de características de forma para la recuperación de imágenes se ha limitado a aplicaciones especiales donde los objetos o regiones están fácilmente disponibles. En este trabajo, combinamos un histograma de color de 64 dimensiones y un Momento de Textura de Color (CTM, [15]) de 64 dimensiones para representar las imágenes. El histograma de color se calcula utilizando 4 × 4 × 4 contenedores en el espacio HSV. El Momento de Textura de Color es propuesto por Yu et al. [15], el cual integra las características de color y textura de la imagen en una forma compacta. CTM adopta la transformada de Fourier local como un esquema de representación de texturas y deriva ocho mapas característicos para describir diferentes aspectos de las relaciones de co-ocurrencia de píxeles de imagen en cada canal del espacio de color (SVcosH, SVsinH, V). Entonces, CTM calcula el primer y segundo momento de estos mapas como una representación de la distribución de píxeles de la imagen en color natural. Por favor, consulte [15] para más detalles. 5.2 Recuperación de imágenes con retroalimentación de relevancia La retroalimentación de relevancia es una de las técnicas más importantes para reducir la brecha entre las características visuales de bajo nivel y los conceptos semánticos de alto nivel [12]. Tradicionalmente, los comentarios de relevancia de los usuarios se utilizan para actualizar el vector de consulta o ajustar el peso de las diferentes dimensiones. Este proceso puede ser visto como un proceso de aprendizaje en línea en el que el sistema de recuperación de imágenes actúa como un aprendiz y el usuario actúa como un maestro. El proceso típico de recuperación se describe de la siguiente manera: 1. El usuario envía un ejemplo de imagen de consulta al sistema. El sistema clasifica las imágenes en la base de datos según alguna métrica de distancia predefinida y presenta al usuario las imágenes mejor clasificadas. El sistema selecciona algunas imágenes de la base de datos y solicita al usuario que las etiquete como relevantes o irrelevantes. El sistema utiliza la información proporcionada por los usuarios para reorganizar las imágenes en la base de datos y devolver al usuario las imágenes principales. Ve al paso 2 hasta que el usuario esté satisfecho. Nuestro algoritmo de Diseño Óptimo de Laplaciano se aplica en el segundo paso para seleccionar las imágenes más informativas. Una vez que obtenemos las etiquetas para las imágenes seleccionadas por LOD, aplicamos la Regresión Regularizada Laplaciana (LRR, [2]) para resolver el problema de optimización (3) y construir el clasificador. El clasificador se utiliza luego para reordenar las imágenes en la base de datos. Ten en cuenta que, para reducir la complejidad computacional, no utilizamos todas las imágenes sin etiquetar en la base de datos, sino solo aquellas dentro de los 500 primeros resultados de la iteración anterior. 6. RESULTADOS EXPERIMENTALES En esta sección, evaluamos el rendimiento de nuestro algoritmo propuesto en una gran base de datos de imágenes. Para demostrar la efectividad de nuestro algoritmo LOD propuesto, lo comparamos con la Regresión Regularizada de Laplaciano (LRR, [2]), la Máquina de Vectores de Soporte (SVM), el Aprendizaje Activo de Máquina de Vectores de Soporte (SVMactive) [14], y el Diseño A-Óptimo (AOD). Tanto SVMactive, AOD y LOD son algoritmos de aprendizaje activo, mientras que LRR y SVM son algoritmos de clasificación estándar. SVM solo hace uso de las imágenes etiquetadas, mientras que LRR es un algoritmo de aprendizaje semi-supervisado que hace uso tanto de imágenes etiquetadas como no etiquetadas. Para SVMactive, AOD y LOD, los algoritmos seleccionan 10 imágenes de entrenamiento en cada iteración. Para LRR y SVM, utilizamos las 10 imágenes principales como datos de entrenamiento. Sería importante señalar que SVMactive se basa en el SVM ordinario, LOD se basa en LRR y AOD se basa en la regresión ordinaria. Los parámetros λ1 y λ2 en nuestro algoritmo LOD se establecen empíricamente en 0.001 y 0.00001. Para ambos algoritmos LRR y LOD, utilizamos la misma estructura de grafo (ver Ecuación 4) y establecemos el valor de p (número de vecinos más cercanos) en 5. Comenzamos con un ejemplo sintético simple para dar una intuición sobre cómo funciona LOD. 6.1 Ejemplo Sintético Simple Se presenta un ejemplo sintético simple en la Figura 1. El conjunto de datos contiene dos círculos. Ocho puntos son seleccionados por AOD y LOD. Como se puede ver, todos los puntos seleccionados por AOD son del círculo grande, mientras que LOD selecciona cuatro puntos del círculo grande y cuatro del círculo pequeño. Los números junto a los puntos seleccionados indican su orden de selección. Claramente, los puntos seleccionados por nuestro algoritmo LOD pueden representar mejor el conjunto de datos original. No comparamos nuestro algoritmo con SVMactive porque SVMactive no se puede aplicar en este caso debido a la falta de puntos etiquetados. 6.2 Diseño Experimental de Recuperación de Imágenes La base de datos de imágenes que utilizamos consta de 7,900 imágenes de 79 categorías semánticas, del conjunto de datos COREL. Es un conjunto de imágenes grande y heterogéneo. Cada imagen se representa como un vector de 128 dimensiones según se describe en la Sección 5.1. La Figura 2 muestra algunas imágenes de muestra. Para exhibir las ventajas de usar nuestro algoritmo, necesitamos una forma confiable de evaluar el rendimiento de recuperación y las comparaciones con otros algoritmos. Listamos a continuación diferentes aspectos del diseño experimental. 6.2.1 Métricas de Evaluación Utilizamos la curva de precisión-alcance y la tasa de precisión [10] para evaluar la efectividad de los algoritmos de recuperación de imágenes. El alcance está especificado por el número (N) de imágenes mejor clasificadas presentadas al usuario. La precisión es la proporción entre el número de imágenes relevantes presentadas al usuario y el (a) Conjunto de datos 1 2 3 4 5 6 7 8 (b) AOD 1 2 3 4 5 6 7 8 (c) LOD Figura 1: Selección de datos por algoritmos de aprendizaje activo. Los números junto a los puntos seleccionados indican su orden de selección. Claramente, los puntos seleccionados por nuestro algoritmo LOD pueden representar mejor el conjunto de datos original. Se debe tener en cuenta que el algoritmo SVMactive no se puede aplicar en este caso debido a la falta de puntos etiquetados. (a) (b) (c) Figura 2: Imágenes de muestra de las categorías cuentas, elefante y barco. El alcance de precisión describe la precisión con varios alcances y, por lo tanto, proporciona una evaluación general del rendimiento de los algoritmos. Por otro lado, la tasa de precisión enfatiza la precisión en un valor particular de alcance. En general, es apropiado presentar 20 imágenes en una pantalla. Agregar más imágenes en una pantalla puede afectar la calidad de las imágenes presentadas. Por lo tanto, la precisión en los primeros 20 (N = 20) es especialmente importante. En los sistemas de recuperación de imágenes del mundo real, la imagen de consulta generalmente no se encuentra en la base de datos de imágenes. Para simular dicho entorno, utilizamos validación cruzada de cinco pliegues para evaluar los algoritmos. Más precisamente, dividimos toda la base de datos de imágenes en cinco subconjuntos de tamaño igual. Por lo tanto, hay 20 imágenes por categoría en cada subconjunto. En cada ejecución de validación cruzada, se selecciona un subconjunto como conjunto de consulta, y los otros cuatro subconjuntos se utilizan como base de datos para la recuperación. La curva de precisión del precisionscope y la tasa de precisión se calculan promediando los resultados de la validación cruzada de cinco pliegues. 6.2.2 Esquema de retroalimentación automática de relevancia Diseñamos un esquema de retroalimentación automática para modelar el proceso de recuperación. Para cada consulta enviada, nuestro sistema recupera y clasifica las imágenes en la base de datos. Se seleccionaron 10 imágenes de la base de datos para que los usuarios las etiqueten y la información de las etiquetas es utilizada por el sistema para volver a clasificarlas. Ten en cuenta que las imágenes seleccionadas en iteraciones anteriores están excluidas de selecciones posteriores. Para cada consulta, se realiza el mecanismo de retroalimentación automática de relevancia durante cuatro iteraciones. Es importante señalar que el esquema de retroalimentación automática de relevancia utilizado aquí es diferente de los descritos en [8], [11]. En [8], [11], las cuatro imágenes relevantes e irrelevantes principales fueron seleccionadas como las imágenes de retroalimentación. Sin embargo, esto puede no ser práctico. En los sistemas de recuperación de imágenes del mundo real, es posible que la mayoría de las imágenes mejor clasificadas sean relevantes (o irrelevantes). Por lo tanto, es difícil para el usuario encontrar tanto cuatro imágenes relevantes como irrelevantes. Es más razonable que los usuarios proporcionen información de retroalimentación solo sobre las 10 imágenes seleccionadas por el sistema. 6.3 Rendimiento de recuperación de imágenes En el mundo real, no es práctico requerir que el usuario proporcione muchas rondas de retroalimentación. El rendimiento de recuperación después de las dos primeras rondas de retroalimentación (especialmente la primera ronda) es más importante. La Figura 3 muestra las curvas de precisión-alcance promedio de los diferentes algoritmos para las dos primeras iteraciones de retroalimentación. Al principio de la recuperación, las distancias euclidianas en el espacio original de 128 dimensiones se utilizan para clasificar las imágenes en la base de datos. Después de que el usuario proporcione retroalimentación de relevancia, se aplican los algoritmos LRR, SVM, SVMactive, AOD y LOD para volver a clasificar las imágenes. Para reducir la complejidad temporal de los algoritmos de aprendizaje activo, no seleccionamos las imágenes más informativas de toda la base de datos, sino de las 500 imágenes principales. Para LRR y SVM, se requiere que el usuario etiquete las 10 imágenes principales. Para SVMactive, AOD y LOD, se requiere que el usuario etiquete las 10 imágenes más informativas seleccionadas por estos algoritmos. Tenga en cuenta que, SVMactive solo puede ser ap(a) Iteración de retroalimentación 1 (b) Iteración de retroalimentación 2 Figura 3: Las curvas de precisión promedio-alcance de diferentes algoritmos para las dos primeras iteraciones de retroalimentación. El algoritmo LOD funciona mejor en todo el alcance. Se debe tener en cuenta que, en la primera ronda de retroalimentación, el algoritmo SVMactive no se puede aplicar. Se aplica el SVM ordinario para construir el clasificador inicial. (a) Precisión en el Top 10 (b) Precisión en el Top 20 (c) Precisión en el Top 30 Figura 4: Evaluación del rendimiento de los cinco algoritmos de aprendizaje para la recuperación de imágenes con retroalimentación de relevancia. (a) Precisión en el top 10, (b) Precisión en el top 20 y (c) Precisión en el top 30. Como se puede observar, nuestro algoritmo LOD supera consistentemente a los otros cuatro algoritmos. Por lo tanto, no se puede aplicar en la primera ronda y utilizamos el SVM estándar para construir el clasificador inicial. Como se puede ver, nuestro algoritmo LOD supera a los otros cuatro algoritmos en todo el ámbito. Además, el algoritmo LRR tiene un mejor rendimiento que SVM. Esto se debe a que el algoritmo LRR hace un uso eficiente de las imágenes no etiquetadas al incorporar un regularizador de preservación de la localidad en la función objetivo de regresión ordinaria. El algoritmo AOD es el que tiene peor rendimiento. A medida que el alcance se amplía, la diferencia de rendimiento entre estos algoritmos disminuye. Al agregar de forma iterativa los comentarios de los usuarios, los resultados de precisión correspondientes (en los primeros 10, 20 y 30 lugares) de los cinco algoritmos se muestran respectivamente en la Figura 4. Como se puede ver, nuestro algoritmo LOD tiene el mejor rendimiento en todos los casos y el algoritmo LRR tiene el segundo mejor rendimiento. Ambos de estos dos algoritmos hacen uso de las imágenes sin etiquetar. Esto demuestra que las imágenes sin etiquetar son útiles para descubrir la estructura geométrica intrínseca del espacio de imágenes y, por lo tanto, mejorar el rendimiento de recuperación. En el mundo real, es posible que el usuario no esté dispuesto a proporcionar demasiadas retroalimentaciones de relevancia. Por lo tanto, el rendimiento de recuperación en las primeras dos rondas es especialmente importante. Como se puede observar, nuestro algoritmo LOD logra una mejora del rendimiento del 6.8% para los 10 mejores resultados, del 5.2% para los 20 mejores resultados y del 4.1% para los 30 mejores resultados, en comparación con el segundo mejor algoritmo (LRR) después de las dos primeras rondas de retroalimentación de relevancia. 6.4 Discusión Se han realizado sistemáticamente varios experimentos en la base de datos de Corel. Nos gustaría resaltar varios puntos interesantes: 1. Es claro que el uso del aprendizaje activo es beneficioso en el ámbito de la recuperación de imágenes. Hay un aumento significativo en el rendimiento al utilizar los métodos de aprendizaje activo. Especialmente, de los tres métodos de aprendizaje activo (SVMactive, AOD, LOD), nuestro algoritmo propuesto LOD es el que tiene mejor rendimiento. En muchas aplicaciones del mundo real, como la recuperación de imágenes con retroalimentación de relevancia, generalmente hay dos formas de reducir la tarea laboriosa de etiquetado manual. Uno es el aprendizaje activo que selecciona las muestras más informativas para etiquetar, y el otro es el aprendizaje semi-supervisado que utiliza las muestras no etiquetadas para mejorar el rendimiento del aprendizaje. Ambas estrategias han sido estudiadas extensamente en el pasado [14], [7], [5], [8]. El trabajo presentado en este artículo se centra en el aprendizaje activo, pero también aprovecha los avances recientes en el aprendizaje semi-supervisado [2]. Específicamente, incorporamos un regularizador que preserva la localidad en el marco de regresión estándar y encontramos las muestras más informativas con respecto a la nueva función objetivo. De esta manera, las técnicas de aprendizaje activo y de aprendizaje semi-supervisado se unifican de manera fluida para aprender un clasificador óptimo. 3. La técnica de retroalimentación de relevancia es crucial para la recuperación de imágenes. Para los cinco algoritmos, el rendimiento de recuperación mejora con más retroalimentación proporcionada por el usuario. CONCLUSIONES Y TRABAJOS FUTUROS Este artículo describe un novedoso algoritmo de aprendizaje activo, llamado Diseño Óptimo Laplaciano, para permitir una recuperación de imágenes con retroalimentación de relevancia más efectiva. Nuestro algoritmo se basa en una función objetivo que minimiza simultáneamente el error empírico y preserva la estructura geométrica local del espacio de datos. Utilizando técnicas de diseño experimental, nuestro algoritmo encuentra las imágenes más informativas para etiquetar. Estas imágenes etiquetadas y las imágenes sin etiquetar en la base de datos se utilizan para aprender un clasificador. Los resultados experimentales en la base de datos Corel muestran que tanto el aprendizaje activo como el aprendizaje semi-supervisado pueden mejorar significativamente el rendimiento de recuperación. En este documento, consideramos el problema de recuperación de imágenes en un conjunto de datos de imágenes pequeño, estático y de dominio cerrado. Un dominio mucho más desafiante es la World Wide Web (WWW). Para la búsqueda de imágenes en la web, es posible recopilar una gran cantidad de información sobre los clics de los usuarios. Esta información puede ser utilizada de forma natural para construir el grafo de afinidad en nuestro algoritmo. Sin embargo, la complejidad computacional en el escenario web puede convertirse en un problema crucial. Además, aunque nuestro interés principal en este artículo se centra en la recuperación de imágenes con retroalimentación de relevancia, nuestros resultados también pueden ser de interés para investigadores en reconocimiento de patrones y aprendizaje automático, especialmente cuando hay una gran cantidad de datos disponibles pero solo se pueden etiquetar muestras limitadas. 8. REFERENCIAS [1] A. C. Atkinson y A. N. Donev. Diseños experimentales óptimos. Oxford University Press, 2002. [2] M. Belkin, P. Niyogi, y V. Sindhwani. Regularización de variedades: Un marco geométrico para el aprendizaje a partir de ejemplos. Revista de Investigación de Aprendizaje Automático, 7:2399-2434, 2006. [3] F. R. K. Chung. Teoría Espectral de Grafos, volumen 92 de la Serie de Conferencias Regionales en Matemáticas. AMS, 1997. [4] D. A. Cohn, Z. Ghahramani y M. I. Jordan. Aprendizaje activo con modelos estadísticos. Revista de Investigación en Inteligencia Artificial, 4:129-145, 1996. [5] A. Dong y B. Bhanu. Un nuevo algoritmo EM semisupervisado para la recuperación de imágenes. En la Conferencia IEEE sobre Visión por Computadora y Reconocimiento de Patrones, Madison, WI, 2003. [6] P. Flaherty, M. I. Jordan y A. P. Arkin. Diseño robusto de experimentos biológicos. En Advances in Neural Information Processing Systems 18, Vancouver, Canadá, 2005. [7] K.-S. Goh, E. Y. Chang y W.-C. Lai. Aprendizaje activo dependiente del concepto multimodal para la recuperación de imágenes. En Actas de la Conferencia ACM sobre Multimedia, Nueva York, octubre de 2004. [8] X. Lo siento, la oración \"He.\" no tiene un significado claro en inglés. ¿Podrías proporcionar más contexto o una oración completa para que pueda traducirla al español de manera precisa? Aprendizaje de subespacios semisupervisado incremental para la recuperación de imágenes. En Actas de la Conferencia ACM sobre Multimedia, Nueva York, octubre de 2004. [9] S. C. Hoi y M. R. Lyu. Un marco de aprendizaje activo semi-supervisado para la recuperación de imágenes. En la Conferencia Internacional de IEEE sobre Visión por Computadora y Reconocimiento de Patrones, San Diego, CA, 2005. [10] D. P. Huijsmans y N. Sebe. Cómo completar los gráficos de rendimiento en la recuperación de imágenes basada en contenido: Agregar generalidad y normalizar el alcance. IEEE Transactions on Pattern Analysis and Machine Intelligence, 27(2):245-251, 2005. [11] Y.-Y.\n\nTransacciones del IEEE sobre Inteligencia Artificial y Análisis de Patrones, 27(2):245-251, 2005. [11] Y.-Y. Lin, T.-L. Liu y H.-T. Chen. Aprendizaje de variedades semánticas para la recuperación de imágenes. En Actas de la Conferencia ACM sobre Multimedia, Singapur, noviembre de 2005. [12] Y. Rui, T. S. Huang, M. Ortega y S. Mehrotra. Retroalimentación de relevancia: Una herramienta poderosa para la recuperación de imágenes basada en contenido de forma interactiva. IEEE Transactions on Circuits and Systems for Video Technology, 8(5), 1998. [13] A. W. Smeulders, M. Worring, S. Santini, A. Gupta, and R. Jain. \n\nTraducción: IEEE Transactions on Circuits and Systems for Video Technology, 8(5), 1998. [13] A. W. Smeulders, M. Worring, S. Santini, A. Gupta y R. Jain. Recuperación de imágenes basada en contenido al final de los primeros años. IEEE Transactions on Pattern Analysis and Machine Intelligence, 22(12):1349-1380, 2000. [14] S. Tong y E. Chang. Aprendizaje activo de máquina de vectores de soporte para recuperación de imágenes. En Actas de la novena conferencia internacional de ACM sobre Multimedia, páginas 107-118, 2001. [15] H. Yu, M. Li, H.-J. Zhang y J. Feng. Momentos de textura de color para la recuperación de imágenes basada en contenido. En la Conferencia Internacional de Procesamiento de Imágenes, páginas 24-28, 2002. [16] K. Yu, J. Bi y V. Tresp. Aprendizaje activo a través del diseño experimental transductivo. En Actas de la 23ª Conferencia Internacional sobre Aprendizaje Automático, Pittsburgh, PA, 2006.",
    "original_sentences": [
        "Laplacian Optimal Design for Image Retrieval Xiaofei He Yahoo!",
        "Burbank, CA 91504 hex@yahoo-inc.com Wanli Min IBM Yorktown Heights, NY 10598 wanlimin@us.ibm.com Deng Cai CS Dept., UIUC Urbana, IL 61801 dengcai2@cs.uiuc.edu Kun Zhou Microsoft Research Asia Beijing, China kunzhou@microsoft.com ABSTRACT Relevance feedback is a powerful technique to enhance ContentBased Image Retrieval (CBIR) performance.",
        "It solicits the users relevance judgments on the retrieved images returned by the CBIR systems.",
        "The users labeling is then used to learn a classifier to distinguish between relevant and irrelevant images.",
        "However, the top returned images may not be the most informative ones.",
        "The challenge is thus to determine which unlabeled images would be the most informative (i.e., improve the classifier the most) if they were labeled and used as training samples.",
        "In this paper, we propose a novel active learning algorithm, called Laplacian Optimal Design (LOD), for relevance feedback image retrieval.",
        "Our algorithm is based on a regression model which minimizes the least square error on the measured (or, labeled) images and simultaneously preserves the local geometrical structure of the image space.",
        "Specifically, we assume that if two images are sufficiently close to each other, then their measurements (or, labels) are close as well.",
        "By constructing a nearest neighbor graph, the geometrical structure of the image space can be described by the graph Laplacian.",
        "We discuss how results from the field of optimal experimental design may be used to guide our selection of a subset of images, which gives us the most amount of information.",
        "Experimental results on Corel database suggest that the proposed approach achieves higher precision in relevance feedback image retrieval.",
        "Categories and Subject Descriptors H.3.3 [Information storage and retrieval]: Information search and retrieval-Relevance feedback; G.3 [Mathematics of Computing]: Probability and Statistics-Experimental design General Terms Algorithms, Performance, Theory 1.",
        "INTRODUCTION In many machine learning and information retrieval tasks, there is no shortage of unlabeled data but labels are expensive.",
        "The challenge is thus to determine which unlabeled samples would be the most informative (i.e., improve the classifier the most) if they were labeled and used as training samples.",
        "This problem is typically called active learning [4].",
        "Here the task is to minimize an overall cost, which depends both on the classifier accuracy and the cost of data collection.",
        "Many real world applications can be casted into active learning framework.",
        "Particularly, we consider the problem of relevance feedback driven Content-Based Image Retrieval (CBIR) [13].",
        "Content-Based Image Retrieval has attracted substantial interests in the last decade [13].",
        "It is motivated by the fast growth of digital image databases which, in turn, require efficient search schemes.",
        "Rather than describe an image using text, in these systems an image query is described using one or more example images.",
        "The low level visual features (color, texture, shape, etc.) are automatically extracted to represent the images.",
        "However, the low level features may not accurately characterize the high level semantic concepts.",
        "To narrow down the semantic gap, relevance feedback is introduced into CBIR [12].",
        "In many of the current relevance feedback driven CBIR systems, the user is required to provide his/her relevance judgments on the top images returned by the system.",
        "The labeled images are then used to train a classifier to separate images that match the query concept from those that do not.",
        "However, in general the top returned images may not be the most informative ones.",
        "In the worst case, all the top images labeled by the user may be positive and thus the standard classification techniques can not be applied due to the lack of negative examples.",
        "Unlike the standard classification problems where the labeled samples are pregiven, in relevance feedback image retrieval the system can actively select the images to label.",
        "Thus active learning can be naturally introduced into image retrieval.",
        "Despite many existing active learning techniques, Support Vector Machine (SVM) active learning [14] and regression based active learning [1] have received the most interests.",
        "Based on the observation that the closer to the SVM boundary an image is, the less reliable its classification is, SVM active learning selects those unlabeled images closest to the boundary to solicit user feedback so as to achieve maximal refinement on the hyperplane between the two classes.",
        "The major disadvantage of SVM active learning is that the estimated boundary may not be accurate enough.",
        "Moreover, it may not be applied at the beginning of the retrieval when there is no labeled images.",
        "Some other SVM based active learning algorithms can be found in [7], [9].",
        "In statistics, the problem of selecting samples to label is typically referred to as experimental design.",
        "The sample x is referred to as experiment, and its label y is referred to as measurement.",
        "The study of optimal experimental design (OED) [1] is concerned with the design of experiments that are expected to minimize variances of a parameterized model.",
        "The intent of optimal experimental design is usually to maximize confidence in a given model, minimize parameter variances for system identification, or minimize the models output variance.",
        "Classical experimental design approaches include A-Optimal Design, D-Optimal Design, and E-Optimal Design.",
        "All of these approaches are based on a least squares regression model.",
        "Comparing to SVM based active learning algorithms, experimental design approaches are much more efficient in computation.",
        "However, this kind of approaches takes only measured (or, labeled) data into account in their objective function, while the unmeasured (or, unlabeled) data is ignored.",
        "Benefit from recent progresses on optimal experimental design and semi-supervised learning, in this paper we propose a novel active learning algorithm for image retrieval, called Laplacian Optimal Design (LOD).",
        "Unlike traditional experimental design methods whose loss functions are only defined on the measured points, the loss function of our proposed LOD algorithm is defined on both measured and unmeasured points.",
        "Specifically, we introduce a locality preserving regularizer into the standard least-square-error based loss function.",
        "The new loss function aims to find a classifier which is locally as smooth as possible.",
        "In other words, if two points are sufficiently close to each other in the input space, then they are expected to share the same label.",
        "Once the loss function is defined, we can select the most informative data points which are presented to the user for labeling.",
        "It would be important to note that the most informative images may not be the top returned images.",
        "The rest of the paper is organized as follows.",
        "In Section 2, we provide a brief description of the related work.",
        "Our proposed Laplacian Optimal Design algorithm is introduced in Section 3.",
        "In Section 4, we compare our algorithm with the state-or-the-art algorithms and present the experimental results on image retrieval.",
        "Finally, we provide some concluding remarks and suggestions for future work in Section 5. 2.",
        "RELATED WORK Since our proposed algorithm is based on regression framework.",
        "The most related work is optimal experimental design [1], including A-Optimal Design, D-Optimal Design, and EOptimal Design.",
        "In this Section, we give a brief description of these approaches. 2.1 The Active Learning Problem The generic problem of active learning is the following.",
        "Given a set of points A = {x1, x2, · · · , xm} in Rd , find a subset B = {z1, z2, · · · , zk} ⊂ A which contains the most informative points.",
        "In other words, the points zi(i = 1, · · · , k) can improve the classifier the most if they are labeled and used as training points. 2.2 Optimal Experimental Design We consider a linear regression model y = wT x + (1) where y is the observation, x is the independent variable, w is the weight vector and is an unknown error with zero mean.",
        "Different observations have errors that are independent, but with equal variances σ2 .",
        "We define f(x) = wT x to be the learners output given input x and the weight vector w. Suppose we have a set of labeled sample points (z1, y1), · · · , (zk, yk), where yi is the label of zi.",
        "Thus, the maximum likelihood estimate for the weight vector, ˆw, is that which minimizes the sum squared error Jsse(w) = k i=1 wT zi − yi 2 (2) The estimate ˆw gives us an estimate of the output at a novel input: ˆy = ˆwT x.",
        "By Gauss-Markov theorem, we know that ˆw − w has a zero mean and a covariance matrix given by σ2 H−1 sse, where Hsse is the Hessian of Jsse(w) Hsse = ∂2 Jsse ∂w2 = k i=1 zizT i = ZZT where Z = (z1, z2, · · · , zk).",
        "The three most common scalar measures of the size of the parameter covariance matrix in optimal experimental design are: • D-optimal design: determinant of Hsse. • A-optimal design: trace of Hsse. • E-optimal design: maximum eigenvalue of Hsse.",
        "Since the computation of the determinant and eigenvalues of a matrix is much more expensive than the computation of matrix trace, A-optimal design is more efficient than the other two.",
        "Some recent work on experimental design can be found in [6], [16]. 3.",
        "LAPLACIAN OPTIMAL DESIGN Since the covariance matrix Hsse used in traditional approaches is only dependent on the measured samples, i.e. zis, these approaches fail to evaluate the expected errors on the unmeasured samples.",
        "In this Section, we introduce a novel active learning algorithm called Laplacian Optimal Design (LOD) which makes efficient use of both measured (labeled) and unmeasured (unlabeled) samples. 3.1 The Objective Function In many machine learning problems, it is natural to assume that if two points xi, xj are sufficiently close to each other, then their measurements (f(xi), f(xj)) are close as well.",
        "Let S be a similarity matrix.",
        "Thus, a new loss function which respects the geometrical structure of the data space can be defined as follows: J0(w) = k i=1 f(zi)−yi 2 + λ 2 m i,j=1 f(xi)−f(xj) 2 Sij (3) where yi is the measurement (or, label) of zi.",
        "Note that, the loss function (3) is essentially the same as the one used in Laplacian Regularized Regression (LRR, [2]).",
        "However, LRR is a passive learning algorithm where the training data is given.",
        "In this paper, we are focused on how to select the most informative data for training.",
        "The loss function with our choice of symmetric weights Sij (Sij = Sji) incurs a heavy penalty if neighboring points xi and xj are mapped far apart.",
        "Therefore, minimizing J0(w) is an attempt to ensure that if xi and xj are close then f(xi) and f(xj) are close as well.",
        "There are many choices of the similarity matrix S. A simple definition is as follows: Sij = ⎧ ⎨ ⎩ 1, if xi is among the p nearest neighbors of xj, or xj is among the p nearest neighbors of xi; 0, otherwise. (4) Let D be a diagonal matrix, Dii = j Sij, and L = D−S.",
        "The matrix L is called graph Laplacian in spectral graph theory [3].",
        "Let y = (y1, · · · , yk)T and X = (x1, · · · , xm).",
        "Following some simple algebraic steps, we see that: J0(w) = k i=1 wT zi − yi 2 + λ 2 m i,j=1 wT xi − wT xj 2 Sij = y − ZT w T y − ZT w + λwT m i=1 DiixixT i − m i,j=1 SijxixT j w = yT y − 2wT Zy + wT ZZT w +λwT XDXT − XSXT w = yT y − 2wT Zy + wT ZZT + λXLXT w The Hessian of J0(w) can be computed as follows: H0 = ∂2 J0 ∂w2 = ZZT + λXLXT In some cases, the matrix ZZT +λXLXT is singular (e.g. if m < d).",
        "Thus, there is no stable solution to the optimization problem Eq. (3).",
        "A common way to deal with this ill-posed problem is to introduce a Tikhonov regularizer into our loss function: J(w) = k i=1 wT zi − yi 2 + λ1 2 m i,j=1 wT xi − wT xj 2 Sij +λ2 w 2 (5) The Hessian of the new loss function is given by: H = ∂2 J ∂w2 = ZZT + λ1XLXT + λ2I := ZZT + Λ where I is an identity matrix and Λ = λ1XLXT + λ2I.",
        "Clearly, H is of full rank.",
        "Requiring that the gradient of J(w) with respect to w vanish gives the optimal estimate ˆw: ˆw = H−1 Zy The following proposition states the bias and variance properties of the estimator for the coefficient vector w. Proposition 3.1.",
        "E( ˆw − w) = −H−1 Λw, Cov( ˆw) = σ2 (H−1 − H−1 ΛH−1 ) Proof.",
        "Since y = ZT w + and E( ) = 0, it follows that E( ˆw − w) (6) = H−1 ZZT w − w = H−1 (ZZT + Λ − Λ)w − w = (I − H−1 Λ)w − w = −H−1 Λw (7) Notice Cov(y) = σ2 I, the covariance matrix of ˆw has the expression: Cov( ˆw) = H−1 ZCov(y)ZT H−1 = σ2 H−1 ZZT H−1 = σ2 H−1 (H − Λ)H−1 = σ2 (H−1 − H−1 ΛH−1 ) (8) Therefore mean squared error matrix for the coefficients w is E(w − ˆw)(w − ˆw)T (9) = H−1 ΛwwT ΛH−1 + σ2 (H−1 − H−1 ΛH−1 ) (10) For any x, let ˆy = ˆwT x be its predicted observation.",
        "The expected squared prediction error is E(y − ˆy)2 = E( + wT x − ˆwT x)2 = σ2 + xT [E(w − ˆw)(w − ˆw)T ]x = σ2 + xT [H−1 ΛwwT ΛH−1 + σ2 H−1 − σ2 H−1 ΛH−1 ]x Clearly the expected square prediction error depends on the explanatory variable x, therefore average expected square predictive error over the complete data set A is 1 m m i=1 E(yi − ˆwT xi)2 = 1 m m i=1 xT i [H−1 ΛwwT ΛH−1 + σ2 H−1 − σ2 H−1 ΛH−1 ]xi +σ2 = 1 m Tr(XT [σ2 H−1 + H−1 ΛwwT ΛH−1 − σ2 H−1 ΛH−1 ]X) +σ2 Since Tr(XT [H−1 ΛwwT ΛH−1 − σ2 H−1 ΛH−1 ]X) Tr(σ2 XT H−1 X), Our Laplacian optimality criterion is thus formulated by minimizing the trace of XT H−1 X.",
        "Definition 1.",
        "Laplacian Optimal Design min Z=(z1,··· ,zk) Tr XT ZZT + λ1XLXT + λ2I −1 X (11) where z1, · · · , zk are selected from {x1, · · · , xm}. 4.",
        "KERNEL LAPLACIAN OPTIMAL DESIGN Canonical experimental design approaches (e.g.",
        "A-Optimal Design, D-Optimal Design, and E-Optimal) only consider linear functions.",
        "They fail to discover the intrinsic geometry in the data when the data space is highly nonlinear.",
        "In this section, we describe how to perform Laplacian Experimental Design in Reproducing Kernel Hilbert Space (RKHS) which gives rise to Kernel Laplacian Experimental Design (KLOD).",
        "For given data points x1, · · · , xm ∈ X with a positive definite mercer kernel K : X ×X → R, there exists a unique RKHS HK of real valued functions on X.",
        "Let Kt(s) be the function of s obtained by fixing t and letting Kt(s) . = K(s, t).",
        "HK consists of all finite linear combinations of the form l i=1 αiKti with ti ∈ X and limits of such functions as the ti become dense in X.",
        "We have Ks, Kt HK = K(s, t). 4.1 Derivation of LOD in Reproducing Kernel Hilbert Space Consider the optimization problem (5) in RKHS.",
        "Thus, we seek a function f ∈ HK such that the following objective function is minimized: min f∈HK k i=1 f(zi)−yi 2 + λ1 2 m i,j=1 f(xi)−f(xj) 2 Sij+λ2 f 2 HK (12) We have the following proposition.",
        "Proposition 4.1.",
        "Let H = { m i=1 αiK(·, xi)|αi ∈ R} be a subspace of HK , the solution to the problem (12) is in H. Proof.",
        "Let H⊥ be the orthogonal complement of H, i.e.",
        "HK = H ⊕ H⊥ .",
        "Thus, for any function f ∈ HK , it has orthogonal decomposition as follows: f = fH + fH⊥ Now, lets evaluate f at xi: f(xi) = f, Kxi HK = fH + fH⊥ , Kxi HK = fH, Kxi HK + fH⊥ , Kxi HK Notice that Kxi ∈ H while fH⊥ ∈ H⊥ .",
        "This implies that fH⊥ , Kxi HK = 0.",
        "Therefore, f(xi) = fH, Kxi HK = fH(xi) This completes the proof.",
        "Proposition 4.1 tells us the minimizer of problem (12) admits a representation f∗ = m i=1 αiK(·, xi).",
        "Please see [2] for the details.",
        "Let φ : Rd → H be a feature map from the input space Rd to H, and K(xi, xj) =< φ(xi), φ(xj) >.",
        "Let X denote the data matrix in RKHS, X = (φ(x1), φ(x2), · · · , φ(xm)).",
        "Similarly, we define Z = (φ(z1), φ(z2), · · · , φ(zk)).",
        "Thus, the optimization problem in RKHS can be written as follows: min Z Tr XT ZZT + λ1XLXT + λ2I −1 X (13) Since the mapping function φ is generally unknown, there is no direct way to solve problem (13).",
        "In the following, we apply kernel tricks to solve this optimization problem.",
        "Let X−1 be the Moore-Penrose inverse (also known as pseudo inverse) of X.",
        "Thus, we have: XT ZZT + λ1XLXT + λ2I −1 X = XT XX−1 ZZT + λ1XLXT + λ2I −1 (XT )−1 XT X = XT X ZZT X + λ1XLXT X + λ2X −1 (XT )−1 XT X = XT X XT ZZT X + λ1XT XLXT X + λ2XT X −1 XT X = KXX KXZKZX + λ1KXXLKXX + λ2KXX −1 KXX where KXX is a m × m matrix (KXX,ij = K(xi, xj)), KXZ is a m×k matrix (KXZ,ij = K(xi, zj)), and KZX is a k×m matrix (KZX,ij = K(zi, xj)).",
        "Thus, the Kernel Laplacian Optimal Design can be defined as follows: Definition 2.",
        "Kernel Laplacian Optimal Design minZ=(z1,··· ,zk) Tr KXX KXZKZX + λ1KXXLKXX λ2KXX −1 KXX (14) 4.2 Optimization Scheme In this subsection, we discuss how to solve the optimization problems (11) and (14).",
        "Particularly, if we select a linear kernel for KLOD, then it reduces to LOD.",
        "Therefore, we will focus on problem (14) in the following.",
        "It can be shown that the optimization problem (14) is NP-hard.",
        "In this subsection, we develop a simple sequential greedy approach to solve (14).",
        "Suppose n points have been selected, denoted by a matrix Zn = (z1, · · · , zn).",
        "The (n + 1)-th point zn+1 can be selected by solving the following optimization problem: max Zn+1=(Zn,zn+1) Tr KXX KXZn+1 KZn+1X + λ1KXXLKXX + λ2KXX −1 KXX (15) The kernel matrices KXZn+1 and KZn+1X can be rewritten as follows: KXZn+1 = KXZn , KXzn+1 , KZn+1X = KZnX Kzn+1X Thus, we have: KXZn+1 KZn+1X = KXZn KZnX + KXzn+1 Kzn+1X We define: A = KXZn KZnX + λ1KXXLKXX + λ2KXX A is only dependent on X and Zn .",
        "Thus, the (n + 1)-th point zn+1 is given by: zn+1 = arg min zn+1 Tr KXX A + KXzn+1 Kzn+1X −1 KXX (16) Each time we select a new point zn+1, the matrix A is updated by: A ← A + KXzn+1 Kzn+1X If the kernel function is chosen as inner product K(x, y) = x, y , then HK is a linear functional space and the algorithm reduces to LOD. 5.",
        "CONTENT-BASED IMAGE RETRIEVAL USING LAPLACIAN OPTIMAL DESIGN In this section, we describe how to apply Laplacian Optimal Design to CBIR.",
        "We begin with a brief description of image representation using low level visual features. 5.1 Low-Level Image Representation Low-level image representation is a crucial problem in CBIR.",
        "General visual features includes color, texture, shape, etc.",
        "Color and texture features are the most extensively used visual features in CBIR.",
        "Compared with color and texture features, shape features are usually described after images have been segmented into regions or objects.",
        "Since robust and accurate image segmentation is difficult to achieve, the use of shape features for image retrieval has been limited to special applications where objects or regions are readily available.",
        "In this work, We combine 64-dimensional color histogram and 64-dimensional Color Texture Moment (CTM, [15]) to represent the images.",
        "The color histogram is calculated using 4 × 4 × 4 bins in HSV space.",
        "The Color Texture Moment is proposed by Yu et al. [15], which integrates the color and texture characteristics of the image in a compact form.",
        "CTM adopts local Fourier transform as a texture representation scheme and derives eight characteristic maps to describe different aspects of co-occurrence relations of image pixels in each channel of the (SVcosH, SVsinH, V) color space.",
        "Then CTM calculates the first and second moment of these maps as a representation of the natural color image pixel distribution.",
        "Please see [15] for details. 5.2 Relevance Feedback Image Retrieval Relevance feedback is one of the most important techniques to narrow down the gap between low level visual features and high level semantic concepts [12].",
        "Traditionally, the users relevance feedbacks are used to update the query vector or adjust the weighting of different dimensions.",
        "This process can be viewed as an on-line learning process in which the image retrieval system acts as a learner and the user acts as a teacher.",
        "They typical retrieval process is outlined as follows: 1.",
        "The user submits a query image example to the system.",
        "The system ranks the images in database according to some pre-defined distance metric and presents to the user the top ranked images. 2.",
        "The system selects some images from the database and request the user to label them as relevant or irrelevant. 3.",
        "The system uses the users provided information to rerank the images in database and returns to the user the top images.",
        "Go to step 2 until the user is satisfied.",
        "Our Laplacian Optimal Design algorithm is applied in the second step for selecting the most informative images.",
        "Once we get the labels for the images selected by LOD, we apply Laplacian Regularized Regression (LRR, [2]) to solve the optimization problem (3) and build the classifier.",
        "The classifier is then used to re-rank the images in database.",
        "Note that, in order to reduce the computational complexity, we do not use all the unlabeled images in the database but only those within top 500 returns of previous iteration. 6.",
        "EXPERIMENTAL RESULTS In this section, we evaluate the performance of our proposed algorithm on a large image database.",
        "To demonstrate the effectiveness of our proposed LOD algorithm, we compare it with Laplacian Regularized Regression (LRR, [2]), Support Vector Machine (SVM), Support Vector Machine Active Learning (SVMactive) [14], and A-Optimal Design (AOD).",
        "Both SVMactive, AOD, and LOD are active learning algorithms, while LRR and SVM are standard classification algorithms.",
        "SVM only makes use of the labeled images, while LRR is a semi-supervised learning algorithm which makes use of both labeled and unlabeled images.",
        "For SVMactive, AOD, and LOD, 10 training images are selected by the algorithms themselves at each iteration.",
        "While for LRR and SVM, we use the top 10 images as training data.",
        "It would be important to note that SVMactive is based on the ordinary SVM, LOD is based on LRR, and AOD is based on the ordinary regression.",
        "The parameters λ1 and λ2 in our LOD algorithm are empirically set to be 0.001 and 0.00001.",
        "For both LRR and LOD algorithms, we use the same graph structure (see Eq. 4) and set the value of p (number of nearest neighbors) to be 5.",
        "We begin with a simple synthetic example to give some intuition about how LOD works. 6.1 Simple Synthetic Example A simple synthetic example is given in Figure 1.",
        "The data set contains two circles.",
        "Eight points are selected by AOD and LOD.",
        "As can be seen, all the points selected by AOD are from the big circle, while LOD selects four points from the big circle and four from the small circle.",
        "The numbers beside the selected points denote their orders to be selected.",
        "Clearly, the points selected by our LOD algorithm can better represent the original data set.",
        "We did not compare our algorithm with SVMactive because SVMactive can not be applied in this case due to the lack of the labeled points. 6.2 Image Retrieval Experimental Design The image database we used consists of 7,900 images of 79 semantic categories, from COREL data set.",
        "It is a large and heterogeneous image set.",
        "Each image is represented as a 128-dimensional vector as described in Section 5.1.",
        "Figure 2 shows some sample images.",
        "To exhibit the advantages of using our algorithm, we need a reliable way of evaluating the retrieval performance and the comparisons with other algorithms.",
        "We list different aspects of the experimental design below. 6.2.1 Evaluation Metrics We use precision-scope curve and precision rate [10] to evaluate the effectiveness of the image retrieval algorithms.",
        "The scope is specified by the number (N) of top-ranked images presented to the user.",
        "The precision is the ratio of the number of relevant images presented to the user to the (a) Data set 1 2 3 4 5 6 7 8 (b) AOD 1 2 3 4 5 6 7 8 (c) LOD Figure 1: Data selection by active learning algorithms.",
        "The numbers beside the selected points denote their orders to be selected.",
        "Clearly, the points selected by our LOD algorithm can better represent the original data set.",
        "Note that, the SVMactive algorithm can not be applied in this case due to the lack of labeled points. (a) (b) (c) Figure 2: Sample images from category bead, elephant, and ship. scope N. The precision-scope curve describes the precision with various scopes and thus gives an overall performance evaluation of the algorithms.",
        "On the other hand, the precision rate emphasizes the precision at a particular value of scope.",
        "In general, it is appropriate to present 20 images on a screen.",
        "Putting more images on a screen may affect the quality of the presented images.",
        "Therefore, the precision at top 20 (N = 20) is especially important.",
        "In real world image retrieval systems, the query image is usually not in the image database.",
        "To simulate such environment, we use five-fold cross validation to evaluate the algorithms.",
        "More precisely, we divide the whole image database into five subsets with equal size.",
        "Thus, there are 20 images per category in each subset.",
        "At each run of cross validation, one subset is selected as the query set, and the other four subsets are used as the database for retrieval.",
        "The precisionscope curve and precision rate are computed by averaging the results from the five-fold cross validation. 6.2.2 Automatic Relevance Feedback Scheme We designed an automatic feedback scheme to model the retrieval process.",
        "For each submitted query, our system retrieves and ranks the images in the database. 10 images were selected from the database for user labeling and the label information is used by the system for re-ranking.",
        "Note that, the images which have been selected at previous iterations are excluded from later selections.",
        "For each query, the automatic relevance feedback mechanism is performed for four iterations.",
        "It is important to note that the automatic relevance feedback scheme used here is different from the ones described in [8], [11].",
        "In [8], [11], the top four relevant and irrelevant images were selected as the feedback images.",
        "However, this may not be practical.",
        "In real world image retrieval systems, it is possible that most of the top-ranked images are relevant (or, irrelevant).",
        "Thus, it is difficult for the user to find both four relevant and irrelevant images.",
        "It is more reasonable for the users to provide feedback information only on the 10 images selected by the system. 6.3 Image Retrieval Performance In real world, it is not practical to require the user to provide many rounds of feedbacks.",
        "The retrieval performance after the first two rounds of feedbacks (especially the first round) is more important.",
        "Figure 3 shows the average precision-scope curves of the different algorithms for the first two feedback iterations.",
        "At the beginning of retrieval, the Euclidean distances in the original 128-dimensional space are used to rank the images in database.",
        "After the user provides relevance feedbacks, the LRR, SVM, SVMactive, AOD, and LOD algorithms are then applied to re-rank the images.",
        "In order to reduce the time complexity of active learning algorithms, we didnt select the most informative images from the whole database but from the top 500 images.",
        "For LRR and SVM, the user is required to label the top 10 images.",
        "For SVMactive, AOD, and LOD, the user is required to label 10 most informative images selected by these algorithms.",
        "Note that, SVMactive can only be ap(a) Feedback Iteration 1 (b) Feedback Iteration 2 Figure 3: The average precision-scope curves of different algorithms for the first two feedback iterations.",
        "The LOD algorithm performs the best on the entire scope.",
        "Note that, at the first round of feedback, the SVMactive algorithm can not be applied.",
        "It applies the ordinary SVM to build the initial classifier. (a) Precision at Top 10 (b) Precision at Top 20 (c) Precision at Top 30 Figure 4: Performance evaluation of the five learning algorithms for relevance feedback image retrieval. (a) Precision at top 10, (b) Precision at top 20, and (c) Precision at top 30.",
        "As can be seen, our LOD algorithm consistently outperforms the other four algorithms. plied when the classifier is already built.",
        "Therefore, it can not be applied at the first round and we use the standard SVM to build the initial classifier.",
        "As can be seen, our LOD algorithm outperforms the other four algorithms on the entire scope.",
        "Also, the LRR algorithm performs better than SVM.",
        "This is because that the LRR algorithm makes efficient use of the unlabeled images by incorporating a locality preserving regularizer into the ordinary regression objective function.",
        "The AOD algorithm performs the worst.",
        "As the scope gets larger, the performance difference between these algorithms gets smaller.",
        "By iteratively adding the users feedbacks, the corresponding precision results (at top 10, top 20, and top 30) of the five algorithms are respectively shown in Figure 4.",
        "As can be seen, our LOD algorithm performs the best in all the cases and the LRR algorithm performs the second best.",
        "Both of these two algorithms make use of the unlabeled images.",
        "This shows that the unlabeled images are helpful for discovering the intrinsic geometrical structure of the image space and therefore enhance the retrieval performance.",
        "In real world, the user may not be willing to provide too many relevance feedbacks.",
        "Therefore, the retrieval performance at the first two rounds are especially important.",
        "As can be seen, our LOD algorithm achieves 6.8% performance improvement for top 10 results, 5.2% for top 20 results, and 4.1% for top 30 results, comparing to the second best algorithm (LRR) after the first two rounds of relevance feedbacks. 6.4 Discussion Several experiments on Corel database have been systematically performed.",
        "We would like to highlight several interesting points: 1.",
        "It is clear that the use of active learning is beneficial in the image retrieval domain.",
        "There is a significant increase in performance from using the active learning methods.",
        "Especially, out of the three active learning methods (SVMactive, AOD, LOD), our proposed LOD algorithm performs the best. 2.",
        "In many real world applications like relevance feedback image retrieval, there are generally two ways of reducing labor-intensive manual labeling task.",
        "One is active learning which selects the most informative samples to label, and the other is semi-supervised learning which makes use of the unlabeled samples to enhance the learning performance.",
        "Both of these two strategies have been studied extensively in the past [14], [7], [5], [8].",
        "The work presented in this paper is focused on active learning, but it also takes advantage of the recent progresses on semi-supervised learning [2].",
        "Specifically, we incorporate a locality preserving regularizer into the standard regression framework and find the most informative samples with respect to the new objective function.",
        "In this way, the active learning and semi-supervised learning techniques are seamlessly unified for learning an optimal classifier. 3.",
        "The relevance feedback technique is crucial to image retrieval.",
        "For all the five algorithms, the retrieval performance improves with more feedbacks provided by the user. 7.",
        "CONCLUSIONS AND FUTURE WORK This paper describes a novel active learning algorithm, called Laplacian Optimal Design, to enable more effective relevance feedback image retrieval.",
        "Our algorithm is based on an objective function which simultaneously minimizes the empirical error and preserves the local geometrical structure of the data space.",
        "Using techniques from experimental design, our algorithm finds the most informative images to label.",
        "These labeled images and the unlabeled images in the database are used to learn a classifier.",
        "The experimental results on Corel database show that both active learning and semi-supervised learning can significantly improve the retrieval performance.",
        "In this paper, we consider the image retrieval problem on a small, static, and closed-domain image data.",
        "A much more challenging domain is the World Wide Web (WWW).",
        "For Web image search, it is possible to collect a large amount of user click information.",
        "This information can be naturally used to construct the affinity graph in our algorithm.",
        "However, the computational complexity in Web scenario may become a crucial issue.",
        "Also, although our primary interest in this paper is focused on relevance feedback image retrieval, our results may also be of interest to researchers in patten recognition and machine learning, especially when a large amount of data is available but only a limited samples can be labeled. 8.",
        "REFERENCES [1] A. C. Atkinson and A. N. Donev.",
        "Optimum Experimental Designs.",
        "Oxford University Press, 2002. [2] M. Belkin, P. Niyogi, and V. Sindhwani.",
        "Manifold regularization: A geometric framework for learning from examples.",
        "Journal of Machine Learning Research, 7:2399-2434, 2006. [3] F. R. K. Chung.",
        "Spectral Graph Theory, volume 92 of Regional Conference Series in Mathematics.",
        "AMS, 1997. [4] D. A. Cohn, Z. Ghahramani, and M. I. Jordan.",
        "Active learning with statistical models.",
        "Journal of Artificial Intelligence Research, 4:129-145, 1996. [5] A. Dong and B. Bhanu.",
        "A new semi-supervised em algorithm for image retrieval.",
        "In IEEE Conf. on Computer Vision and Pattern Recognition, Madison, WI, 2003. [6] P. Flaherty, M. I. Jordan, and A. P. Arkin.",
        "Robust design of biological experiments.",
        "In Advances in Neural Information Processing Systems 18, Vancouver, Canada, 2005. [7] K.-S. Goh, E. Y. Chang, and W.-C. Lai.",
        "Multimodal concept-dependent active learning for image retrieval.",
        "In Proceedings of the ACM Conference on Multimedia, New York, October 2004. [8] X.",
        "He.",
        "Incremental semi-supervised subspace learning for image retrieval.",
        "In Proceedings of the ACM Conference on Multimedia, New York, October 2004. [9] S. C. Hoi and M. R. Lyu.",
        "A semi-supervised active learning framework for image retrieval.",
        "In IEEE International Conference on Computer Vision and Pattern Recognition, San Diego, CA, 2005. [10] D. P. Huijsmans and N. Sebe.",
        "How to complete performance graphs in content-based image retrieval: Add generality and normalize scope.",
        "IEEE Transactions on Pattern Analysis and Machine Intelligence, 27(2):245-251, 2005. [11] Y.-Y.",
        "Lin, T.-L. Liu, and H.-T. Chen.",
        "Semantic manifold learning for image retrieval.",
        "In Proceedings of the ACM Conference on Multimedia, Singapore, November 2005. [12] Y. Rui, T. S. Huang, M. Ortega, and S. Mehrotra.",
        "Relevance feedback: A power tool for interative content-based image retrieval.",
        "IEEE Transactions on Circuits and Systems for Video Technology, 8(5), 1998. [13] A. W. Smeulders, M. Worring, S. Santini, A. Gupta, and R. Jain.",
        "Content-based image retrieval at the end of the early years.",
        "IEEE Transactions on Pattern Analysis and Machine Intelligence, 22(12):1349-1380, 2000. [14] S. Tong and E. Chang.",
        "Support vector machine active learning for image retrieval.",
        "In Proceedings of the ninth ACM international conference on Multimedia, pages 107-118, 2001. [15] H. Yu, M. Li, H.-J.",
        "Zhang, and J. Feng.",
        "Color texture moments for content-based image retrieval.",
        "In International Conference on Image Processing, pages 24-28, 2002. [16] K. Yu, J. Bi, and V. Tresp.",
        "Active learning via transductive experimental design.",
        "In Proceedings of the 23rd International Conference on Machine Learning, Pittsburgh, PA, 2006."
    ],
    "translated_text_sentences": [
        "Diseño óptimo de Laplaciano para la recuperación de imágenes Xiaofei He Yahoo!",
        "El feedback de relevancia es una técnica poderosa para mejorar el rendimiento de la Recuperación de Imágenes Basada en Contenido (CBIR).",
        "Solicita las valoraciones de relevancia de los usuarios sobre las imágenes recuperadas por los sistemas CBIR.",
        "La etiqueta de los usuarios se utiliza luego para entrenar un clasificador que distinga entre imágenes relevantes e irrelevantes.",
        "Sin embargo, las imágenes principales que se devuelven pueden no ser las más informativas.",
        "El desafío consiste en determinar qué imágenes sin etiquetar serían las más informativas (es decir, mejorarían más al clasificador) si fueran etiquetadas y utilizadas como muestras de entrenamiento.",
        "En este artículo, proponemos un novedoso algoritmo de aprendizaje activo, llamado Diseño Óptimo Laplaciano (LOD), para la recuperación de imágenes con retroalimentación de relevancia.",
        "Nuestro algoritmo se basa en un modelo de regresión que minimiza el error cuadrático mínimo en las imágenes medidas (o etiquetadas) y al mismo tiempo preserva la estructura geométrica local del espacio de la imagen.",
        "Específicamente, asumimos que si dos imágenes están lo suficientemente cerca una de la otra, entonces sus medidas (o etiquetas) también son cercanas.",
        "Al construir un grafo de vecinos más cercanos, la estructura geométrica del espacio de la imagen puede ser descrita por el Laplaciano del grafo.",
        "Discutimos cómo los resultados del campo del diseño experimental óptimo pueden ser utilizados para guiar nuestra selección de un subconjunto de imágenes, que nos proporciona la mayor cantidad de información.",
        "Los resultados experimentales en la base de datos Corel sugieren que el enfoque propuesto logra una mayor precisión en la recuperación de imágenes con retroalimentación de relevancia.",
        "Categorías y Descriptores de Asignaturas H.3.3 [Almacenamiento y recuperación de información]: Búsqueda y recuperación de información-Retroalimentación de relevancia; G.3 [Matemáticas de la Computación]: Probabilidad y Estadística-Diseño experimental Términos Generales Algoritmos, Rendimiento, Teoría 1.",
        "INTRODUCCIÓN En muchas tareas de aprendizaje automático y recuperación de información, no hay escasez de datos no etiquetados pero las etiquetas son costosas.",
        "El desafío consiste en determinar qué muestras sin etiquetar serían las más informativas (es decir, mejorarían más el clasificador) si fueran etiquetadas y utilizadas como muestras de entrenamiento.",
        "Este problema se llama típicamente aprendizaje activo [4].",
        "Aquí la tarea es minimizar un costo general, que depende tanto de la precisión del clasificador como del costo de la recolección de datos.",
        "Muchas aplicaciones del mundo real pueden ser adaptadas al marco de aprendizaje activo.",
        "Particularmente, consideramos el problema de la recuperación de imágenes basada en contenido impulsada por la retroalimentación de relevancia (CBIR) [13].",
        "La Recuperación de Imágenes Basada en Contenido ha atraído un interés sustancial en la última década [13].",
        "Está motivado por el rápido crecimiento de las bases de datos de imágenes digitales que, a su vez, requieren esquemas de búsqueda eficientes.",
        "En lugar de describir una imagen usando texto, en estos sistemas se describe una consulta de imagen utilizando una o más imágenes de ejemplo.",
        "Las características visuales de bajo nivel (color, textura, forma, etc.) se extraen automáticamente para representar las imágenes.",
        "Sin embargo, las características de bajo nivel pueden no caracterizar con precisión los conceptos semánticos de alto nivel.",
        "Para reducir la brecha semántica, se introduce la retroalimentación de relevancia en la recuperación de información basada en el contenido (CBIR) [12].",
        "En muchos de los sistemas actuales de recuperación de imágenes basados en retroalimentación de relevancia, se requiere que el usuario proporcione sus juicios de relevancia sobre las imágenes principales devueltas por el sistema.",
        "Las imágenes etiquetadas se utilizan luego para entrenar un clasificador que separe las imágenes que coinciden con el concepto de la consulta de aquellas que no lo hacen.",
        "Sin embargo, en general, las imágenes principales que se devuelven pueden no ser las más informativas.",
        "En el peor de los casos, todas las imágenes principales etiquetadas por el usuario pueden ser positivas y, por lo tanto, las técnicas estándar de clasificación no pueden aplicarse debido a la falta de ejemplos negativos.",
        "A diferencia de los problemas de clasificación estándar donde las muestras etiquetadas están predefinidas, en la recuperación de imágenes con retroalimentación de relevancia, el sistema puede seleccionar activamente las imágenes a etiquetar.",
        "Por lo tanto, el aprendizaje activo puede ser introducido de forma natural en la recuperación de imágenes.",
        "A pesar de la existencia de muchas técnicas de aprendizaje activo, el aprendizaje activo de Máquina de Vectores de Soporte (SVM) [14] y el aprendizaje activo basado en regresión [1] han sido los que han despertado mayor interés.",
        "Basado en la observación de que cuanto más cerca del límite del SVM se encuentre una imagen, menos confiable es su clasificación, el aprendizaje activo del SVM selecciona aquellas imágenes no etiquetadas más cercanas al límite para solicitar retroalimentación del usuario con el fin de lograr un refinamiento máximo en el hiperplano entre las dos clases.",
        "La principal desventaja del aprendizaje activo de SVM es que es posible que el límite estimado no sea lo suficientemente preciso.",
        "Además, puede que no se aplique al principio de la recuperación cuando no hay imágenes etiquetadas.",
        "Algunos otros algoritmos de aprendizaje activo basados en SVM se pueden encontrar en [7], [9].",
        "En estadística, el problema de seleccionar muestras para etiquetar se conoce típicamente como diseño experimental.",
        "La muestra x se denomina experimento, y su etiqueta y se denomina medición.",
        "El estudio del diseño experimental óptimo (DEO) se preocupa por el diseño de experimentos que se espera que minimicen las varianzas de un modelo parametrizado.",
        "La intención del diseño experimental óptimo suele ser maximizar la confianza en un modelo dado, minimizar las varianzas de los parámetros para la identificación del sistema, o minimizar la varianza de la salida de los modelos.",
        "Los enfoques clásicos de diseño experimental incluyen el Diseño A-Óptimo, el Diseño D-Óptimo y el Diseño E-Óptimo.",
        "Todos estos enfoques se basan en un modelo de regresión de mínimos cuadrados.",
        "En comparación con los algoritmos de aprendizaje activo basados en SVM, los enfoques de diseño experimental son mucho más eficientes en términos de computación.",
        "Sin embargo, este tipo de enfoques solo tienen en cuenta los datos medidos (o etiquetados) en su función objetivo, mientras que los datos no medidos (o no etiquetados) son ignorados.",
        "Beneficiar de los avances recientes en diseño experimental óptimo y aprendizaje semisupervisado, en este artículo proponemos un nuevo algoritmo de aprendizaje activo para recuperación de imágenes, llamado Diseño Óptimo Laplaciano (LOD).",
        "A diferencia de los métodos tradicionales de diseño experimental cuyas funciones de pérdida solo están definidas en los puntos medidos, la función de pérdida de nuestro algoritmo propuesto LOD está definida tanto en los puntos medidos como en los no medidos.",
        "Específicamente, introducimos un regularizador que preserva la localidad en la función de pérdida estándar basada en el error cuadrático mínimo.",
        "La nueva función de pérdida tiene como objetivo encontrar un clasificador que sea localmente lo más suave posible.",
        "En otras palabras, si dos puntos están suficientemente cerca uno del otro en el espacio de entrada, se espera que compartan la misma etiqueta.",
        "Una vez que se define la función de pérdida, podemos seleccionar los puntos de datos más informativos que se presentan al usuario para su etiquetado.",
        "Sería importante tener en cuenta que las imágenes más informativas pueden no ser las primeras imágenes devueltas.",
        "El resto del documento está organizado de la siguiente manera.",
        "En la Sección 2, proporcionamos una breve descripción del trabajo relacionado.",
        "Nuestro algoritmo propuesto de Diseño Óptimo de Laplaciano se introduce en la Sección 3.",
        "En la Sección 4, comparamos nuestro algoritmo con los algoritmos de última generación y presentamos los resultados experimentales sobre la recuperación de imágenes.",
        "Finalmente, proporcionamos algunas observaciones finales y sugerencias para trabajos futuros en la Sección 5.2.",
        "TRABAJO RELACIONADO Dado que nuestro algoritmo propuesto se basa en un marco de regresión.",
        "El trabajo más relacionado es el diseño experimental óptimo [1], que incluye el Diseño A-Óptimo, el Diseño D-Óptimo y el Diseño E-Óptimo.",
        "En esta sección, damos una breve descripción de estos enfoques. 2.1 El Problema del Aprendizaje Activo El problema genérico del aprendizaje activo es el siguiente.",
        "Dado un conjunto de puntos A = {x1, x2, · · · , xm} en Rd , encuentra un subconjunto B = {z1, z2, · · · , zk} ⊂ A que contenga los puntos más informativos.",
        "En otras palabras, los puntos zi(i = 1, · · · , k) pueden mejorar el clasificador al máximo si están etiquetados y se utilizan como puntos de entrenamiento. 2.2 Diseño Experimental Óptimo Consideramos un modelo de regresión lineal y = wT x + (1) donde y es la observación, x es la variable independiente, w es el vector de pesos y es un error desconocido con media cero.",
        "Diferentes observaciones tienen errores que son independientes, pero con varianzas iguales σ2.",
        "Definimos f(x) = wT x como la salida del aprendiz dada la entrada x y el vector de pesos w. Supongamos que tenemos un conjunto de puntos de muestra etiquetados (z1, y1), · · · , (zk, yk), donde yi es la etiqueta de zi.",
        "Por lo tanto, la estimación de máxima verosimilitud para el vector de peso, ˆw, es aquella que minimiza la suma del error cuadrado Jsse(w) = k i=1 wT zi − yi 2 (2). La estimación ˆw nos proporciona una estimación de la salida en una entrada novedosa: ˆy = ˆwT x.",
        "Según el teorema de Gauss-Markov, sabemos que ˆw − w tiene una media cero y una matriz de covarianza dada por σ2 H−1 sse, donde Hsse es la Hessiana de Jsse(w) Hsse = ∂2 Jsse ∂w2 = k i=1 zizT i = ZZT donde Z = (z1, z2, · · · , zk).",
        "Las tres medidas escalares más comunes del tamaño de la matriz de covarianza de parámetros en el diseño experimental óptimo son: • Diseño D-óptimo: determinante de Hsse. • Diseño A-óptimo: traza de Hsse. • Diseño E-óptimo: valor propio máximo de Hsse.",
        "Dado que el cálculo del determinante y los valores propios de una matriz es mucho más costoso que el cálculo de la traza de la matriz, el diseño A-óptimo es más eficiente que los otros dos.",
        "Algunos trabajos recientes sobre diseño experimental se pueden encontrar en [6], [16].",
        "DISEÑO ÓPTIMO LAPLACIANO Dado que la matriz de covarianza Hsse utilizada en enfoques tradicionales solo depende de las muestras medidas, es decir, zis, estos enfoques no logran evaluar los errores esperados en las muestras no medidas.",
        "En esta sección, presentamos un novedoso algoritmo de aprendizaje activo llamado Diseño Óptimo Laplaciano (LOD) que hace un uso eficiente tanto de muestras medidas (etiquetadas) como no medidas (sin etiquetar). 3.1 La Función Objetivo En muchos problemas de aprendizaje automático, es natural asumir que si dos puntos xi, xj están suficientemente cerca uno del otro, entonces sus mediciones (f(xi), f(xj)) también son cercanas.",
        "Sea S una matriz de similitud.",
        "Por lo tanto, una nueva función de pérdida que respeta la estructura geométrica del espacio de datos se puede definir de la siguiente manera: J0(w) = k i=1 f(zi)−yi 2 + λ 2 m i,j=1 f(xi)−f(xj) 2 Sij (3) donde yi es la medición (o etiqueta) de zi.",
        "Se debe tener en cuenta que la función de pérdida (3) es esencialmente la misma que la utilizada en la Regresión Regularizada Laplaciana (LRR, [2]).",
        "Sin embargo, LRR es un algoritmo de aprendizaje pasivo donde se proporcionan los datos de entrenamiento.",
        "En este artículo, nos enfocamos en cómo seleccionar los datos más informativos para el entrenamiento.",
        "La función de pérdida con nuestra elección de pesos simétricos Sij (Sij = Sji) incurre en una penalización severa si los puntos vecinos xi y xj se asignan lejos uno del otro.",
        "Por lo tanto, minimizar J0(w) es un intento de asegurar que si xi y xj están cerca, entonces f(xi) y f(xj) también estén cerca.",
        "Hay muchas opciones de la matriz de similitud S. Una definición simple es la siguiente: Sij = ⎧ ⎨ ⎩ 1, si xi está entre los p vecinos más cercanos de xj, o xj está entre los p vecinos más cercanos de xi; 0, en otro caso. (4) Sea D una matriz diagonal, Dii = j Sij, y L = D−S.",
        "La matriz L se llama Laplaciano de grafo en la teoría espectral de grafos [3].",
        "Sea y = (y1, · · · , yk)T y X = (x1, · · · , xm).",
        "Siguiendo algunos pasos algebraicos simples, vemos que: J0(w) = k i=1 wT zi − yi 2 + λ 2 m i,j=1 wT xi − wT xj 2 Sij = y − ZT w T y − ZT w + λwT m i=1 DiixixT i − m i,j=1 SijxixT j w = yT y − 2wT Zy + wT ZZT w +λwT m i=1 DiixixT i − m i,j=1 SijxixT j w = yT y − 2wT Zy + wT ZZT + λXLXT w La Hessiana de J0(w) se puede calcular de la siguiente manera: H0 = ∂2 J0 ∂w2 = ZZT + λXLXT En algunos casos, la matriz ZZT +λXLXT es singular (por ejemplo, si m < d).",
        "Por lo tanto, no hay una solución estable para el problema de optimización Ec. (3).",
        "Una forma común de abordar este problema mal planteado es introducir un regularizador de Tikhonov en nuestra función de pérdida: J(w) = k i=1 wT zi − yi 2 + λ1 2 m i,j=1 wT xi − wT xj 2 Sij +λ2 w 2 (5) El Hessiano de la nueva función de pérdida está dado por: H = ∂2 J ∂w2 = ZZT + λ1XLXT + λ2I := ZZT + Λ donde I es una matriz identidad y Λ = λ1XLXT + λ2I.",
        "Claramente, H tiene rango completo.",
        "Exigir que el gradiente de J(w) con respecto a w se anule proporciona la estimación óptima ˆw: ˆw = H−1 Zy. La siguiente proposición establece las propiedades de sesgo y varianza del estimador para el vector de coeficientes w. Proposición 3.1.",
        "E( ˆw − w) = −H−1 Λw, Cov( ˆw) = σ2 (H−1 − H−1 ΛH−1 ) Demostración.",
        "Dado que y = ZTw + y E( ) = 0, se deduce que E( ˆw − w) (6) = H−1 ZZTw − w = H−1 (ZZT + Λ − Λ)w − w = (I − H−1 Λ)w − w = −H−1 Λw (7) Nótese que Cov(y) = σ2 I, la matriz de covarianza de ˆw tiene la expresión: Cov( ˆw) = H−1 ZCov(y)ZT H−1 = σ2 H−1 ZZT H−1 = σ2 H−1 (H − Λ)H−1 = σ2 (H−1 − H−1 ΛH−1 ) (8) Por lo tanto, la matriz de error cuadrático medio para los coeficientes w es E(w − ˆw)(w − ˆw)T (9) = H−1 ΛwwT ΛH−1 + σ2 (H−1 − H−1 ΛH−1 ) (10) Para cualquier x, sea ˆy = ˆwT x su observación predicha.",
        "El error cuadrático de predicción esperado es E(y − ˆy)2 = E( + wT x − ˆwT x)2 = σ2 + xT [E(w − ˆw)(w − ˆw)T ]x = σ2 + xT [H−1 ΛwwT ΛH−1 + σ2 H−1 − σ2 H−1 ΛH−1 ]x Claramente, el error cuadrático de predicción esperado depende de la variable explicativa x, por lo tanto, el error cuadrático de predicción promedio esperado sobre el conjunto de datos completo A es 1 m m i=1 E(yi − ˆwT xi)2 = 1 m m i=1 xT i [H−1 ΛwwT ΛH−1 + σ2 H−1 − σ2 H−1 ΛH−1 ]xi +σ2 = 1 m Tr(XT [σ2 H−1 + H−1 ΛwwT ΛH−1 − σ2 H−1 ΛH−1 ]X) +σ2 Dado que Tr(XT [H−1 ΛwwT ΛH−1 − σ2 H−1 ΛH−1 ]X) Tr(σ2 XT H−1 X), nuestro criterio de optimalidad laplaciano se formula minimizando la traza de XT H−1 X.",
        "Definición 1.",
        "Diseño óptimo de Laplaciano min Z=(z1,··· ,zk) Tr XT ZZT + λ1XLXT + λ2I −1 X (11) donde z1, · · · , zk son seleccionados de {x1, · · · , xm}. 4.",
        "DISEÑO ÓPTIMO DEL NÚCLEO LAPLACIANO Enfoques canónicos de diseño experimental (por ejemplo,",
        "Los diseños A-óptimos, D-óptimos y E-óptimos solo consideran funciones lineales.",
        "No logran descubrir la geometría intrínseca en los datos cuando el espacio de datos es altamente no lineal.",
        "En esta sección, describimos cómo realizar el Diseño Experimental Laplaciano en el Espacio de Hilbert de Núcleos Reproductores (RKHS), lo que da lugar al Diseño Experimental Laplaciano de Núcleo (KLOD).",
        "Para los puntos de datos dados x1, · · · , xm ∈ X con un núcleo de Mercer positivo definido K : X ×X → R, existe un único RKHS HK de funciones de valores reales en X.",
        "Sea Kt(s) la función de s obtenida al fijar t y dejar que Kt(s) = K(s, t).",
        "HK consiste en todas las combinaciones lineales finitas de la forma ∑ i=1 αiKti con ti ∈ X y los límites de tales funciones a medida que los ti se vuelven densos en X.",
        "Tenemos Ks, Kt HK = K(s, t). 4.1 Derivación de LOD en el Espacio de Hilbert del Núcleo Reproductor. Considera el problema de optimización (5) en RKHS.",
        "Por lo tanto, buscamos una función f ∈ HK tal que se minimice la siguiente función objetivo: min f∈HK k i=1 f(zi)−yi 2 + λ1 2 m i,j=1 f(xi)−f(xj) 2 Sij+λ2 f 2 HK (12). Tenemos la siguiente proposición.",
        "Proposición 4.1.",
        "Sea H = { m i=1 αiK(·, xi)|αi ∈ R} un subespacio de HK, la solución al problema (12) está en H. Demostración.",
        "Sea H⊥ el complemento ortogonal de H, es decir,",
        "HK = H ⊕ H⊥.",
        "Por lo tanto, para cualquier función f ∈ HK, tiene una descomposición ortogonal de la siguiente manera: f = fH + fH⊥ Ahora, evaluemos f en xi: f(xi) = f, Kxi HK = fH + fH⊥ , Kxi HK = fH, Kxi HK + fH⊥ , Kxi HK Observa que Kxi ∈ H mientras que fH⊥ ∈ H⊥.",
        "Esto implica que fH⊥ , Kxi HK = 0.",
        "Por lo tanto, f(xi) = fH, Kxi HK = fH(xi). Esto completa la prueba.",
        "La Proposición 4.1 nos dice que el minimizador del problema (12) admite una representación f∗ = m i=1 αiK(·, xi).",
        "Por favor, consulte [2] para ver los detalles.",
        "Sea φ : Rd → H un mapeo de características del espacio de entrada Rd a H, y K(xi, xj) =< φ(xi), φ(xj) >.",
        "Que X denote la matriz de datos en RKHS, X = (φ(x1), φ(x2), · · · , φ(xm)).",
        "De manera similar, definimos Z = (φ(z1), φ(z2), · · · , φ(zk)).",
        "Por lo tanto, el problema de optimización en RKHS se puede escribir de la siguiente manera: min Z Tr XT ZZT + λ1XLXT + λ2I −1 X (13) Dado que la función de mapeo φ generalmente es desconocida, no hay una forma directa de resolver el problema (13).",
        "En lo siguiente, aplicamos trucos de kernel para resolver este problema de optimización.",
        "Sea X−1 la inversa de Moore-Penrose (también conocida como pseudoinversa) de X.",
        "Así, tenemos: XT ZZT + λ1XLXT + λ2I −1 X = XT XX−1 ZZT + λ1XLXT + λ2I −1 (XT )−1 XT X = XT X ZZT X + λ1XLXT X + λ2X −1 (XT )−1 XT X = XT X XT ZZT X + λ1XT XLXT X + λ2XT X −1 XT X = KXX KXZKZX + λ1KXXLKXX + λ2KXX −1 KXX donde KXX es una matriz m × m (KXX,ij = K(xi, xj)), KXZ es una matriz m×k (KXZ,ij = K(xi, zj)), y KZX es una matriz k×m (KZX,ij = K(zi, xj)).",
        "Por lo tanto, el Diseño Óptimo del Laplaciano del Núcleo se puede definir de la siguiente manera: Definición 2.",
        "En este subapartado, discutimos cómo resolver los problemas de optimización (11) y (14).",
        "Particularmente, si seleccionamos un núcleo lineal para KLOD, entonces se reduce a LOD.",
        "Por lo tanto, nos enfocaremos en el problema (14) a continuación.",
        "Se puede demostrar que el problema de optimización (14) es NP-duro.",
        "En esta subsección, desarrollamos un enfoque codicioso secuencial simple para resolver (14).",
        "Supongamos que se han seleccionado n puntos, denotados por una matriz Zn = (z1, · · · , zn).",
        "El punto (n + 1)-ésimo zn+1 puede ser seleccionado resolviendo el siguiente problema de optimización: max Zn+1=(Zn,zn+1) Tr KXX KXZn+1 KZn+1X + λ1KXXLKXX + λ2KXX −1 KXX (15) Las matrices de kernel KXZn+1 y KZn+1X pueden ser reescritas de la siguiente manera: KXZn+1 = KXZn , KXzn+1 , KZn+1X = KZnX Kzn+1X Por lo tanto, tenemos: KXZn+1 KZn+1X = KXZn KZnX + KXzn+1 Kzn+1X Definimos: A = KXZn KZnX + λ1KXXLKXX + λ2KXX A solo depende de X y Zn.",
        "Por lo tanto, el punto (n + 1)-ésimo zn+1 se da por: zn+1 = arg min zn+1 Tr KXX A + KXzn+1 Kzn+1X −1 KXX. Cada vez que seleccionamos un nuevo punto zn+1, la matriz A se actualiza por: A ← A + KXzn+1 Kzn+1X. Si la función de kernel se elige como producto interno K(x, y) = x, y, entonces HK es un espacio funcional lineal y el algoritmo se reduce a LOD. 5.",
        "RECUPERACIÓN DE IMÁGENES BASADA EN CONTENIDO UTILIZANDO DISEÑO ÓPTIMO LAPLACIANO En esta sección, describimos cómo aplicar el Diseño Óptimo Laplaciano a la RCIB.",
        "Comenzamos con una breve descripción de la representación de imágenes utilizando características visuales de nivel bajo. 5.1 Representación de Imágenes de Nivel Bajo La representación de imágenes de nivel bajo es un problema crucial en la Recuperación de Información Basada en el Contenido (CBIR).",
        "Las características visuales generales incluyen color, textura, forma, etc.",
        "Las características de color y textura son las características visuales más ampliamente utilizadas en la recuperación de información basada en contenido (CBIR).",
        "En comparación con las características de color y textura, las características de forma suelen describirse después de que las imágenes hayan sido segmentadas en regiones u objetos.",
        "Dado que la segmentación de imágenes robusta y precisa es difícil de lograr, el uso de características de forma para la recuperación de imágenes se ha limitado a aplicaciones especiales donde los objetos o regiones están fácilmente disponibles.",
        "En este trabajo, combinamos un histograma de color de 64 dimensiones y un Momento de Textura de Color (CTM, [15]) de 64 dimensiones para representar las imágenes.",
        "El histograma de color se calcula utilizando 4 × 4 × 4 contenedores en el espacio HSV.",
        "El Momento de Textura de Color es propuesto por Yu et al. [15], el cual integra las características de color y textura de la imagen en una forma compacta.",
        "CTM adopta la transformada de Fourier local como un esquema de representación de texturas y deriva ocho mapas característicos para describir diferentes aspectos de las relaciones de co-ocurrencia de píxeles de imagen en cada canal del espacio de color (SVcosH, SVsinH, V).",
        "Entonces, CTM calcula el primer y segundo momento de estos mapas como una representación de la distribución de píxeles de la imagen en color natural.",
        "Por favor, consulte [15] para más detalles. 5.2 Recuperación de imágenes con retroalimentación de relevancia La retroalimentación de relevancia es una de las técnicas más importantes para reducir la brecha entre las características visuales de bajo nivel y los conceptos semánticos de alto nivel [12].",
        "Tradicionalmente, los comentarios de relevancia de los usuarios se utilizan para actualizar el vector de consulta o ajustar el peso de las diferentes dimensiones.",
        "Este proceso puede ser visto como un proceso de aprendizaje en línea en el que el sistema de recuperación de imágenes actúa como un aprendiz y el usuario actúa como un maestro.",
        "El proceso típico de recuperación se describe de la siguiente manera: 1.",
        "El usuario envía un ejemplo de imagen de consulta al sistema.",
        "El sistema clasifica las imágenes en la base de datos según alguna métrica de distancia predefinida y presenta al usuario las imágenes mejor clasificadas.",
        "El sistema selecciona algunas imágenes de la base de datos y solicita al usuario que las etiquete como relevantes o irrelevantes.",
        "El sistema utiliza la información proporcionada por los usuarios para reorganizar las imágenes en la base de datos y devolver al usuario las imágenes principales.",
        "Ve al paso 2 hasta que el usuario esté satisfecho.",
        "Nuestro algoritmo de Diseño Óptimo de Laplaciano se aplica en el segundo paso para seleccionar las imágenes más informativas.",
        "Una vez que obtenemos las etiquetas para las imágenes seleccionadas por LOD, aplicamos la Regresión Regularizada Laplaciana (LRR, [2]) para resolver el problema de optimización (3) y construir el clasificador.",
        "El clasificador se utiliza luego para reordenar las imágenes en la base de datos.",
        "Ten en cuenta que, para reducir la complejidad computacional, no utilizamos todas las imágenes sin etiquetar en la base de datos, sino solo aquellas dentro de los 500 primeros resultados de la iteración anterior. 6.",
        "RESULTADOS EXPERIMENTALES En esta sección, evaluamos el rendimiento de nuestro algoritmo propuesto en una gran base de datos de imágenes.",
        "Para demostrar la efectividad de nuestro algoritmo LOD propuesto, lo comparamos con la Regresión Regularizada de Laplaciano (LRR, [2]), la Máquina de Vectores de Soporte (SVM), el Aprendizaje Activo de Máquina de Vectores de Soporte (SVMactive) [14], y el Diseño A-Óptimo (AOD).",
        "Tanto SVMactive, AOD y LOD son algoritmos de aprendizaje activo, mientras que LRR y SVM son algoritmos de clasificación estándar.",
        "SVM solo hace uso de las imágenes etiquetadas, mientras que LRR es un algoritmo de aprendizaje semi-supervisado que hace uso tanto de imágenes etiquetadas como no etiquetadas.",
        "Para SVMactive, AOD y LOD, los algoritmos seleccionan 10 imágenes de entrenamiento en cada iteración.",
        "Para LRR y SVM, utilizamos las 10 imágenes principales como datos de entrenamiento.",
        "Sería importante señalar que SVMactive se basa en el SVM ordinario, LOD se basa en LRR y AOD se basa en la regresión ordinaria.",
        "Los parámetros λ1 y λ2 en nuestro algoritmo LOD se establecen empíricamente en 0.001 y 0.00001.",
        "Para ambos algoritmos LRR y LOD, utilizamos la misma estructura de grafo (ver Ecuación 4) y establecemos el valor de p (número de vecinos más cercanos) en 5.",
        "Comenzamos con un ejemplo sintético simple para dar una intuición sobre cómo funciona LOD. 6.1 Ejemplo Sintético Simple Se presenta un ejemplo sintético simple en la Figura 1.",
        "El conjunto de datos contiene dos círculos.",
        "Ocho puntos son seleccionados por AOD y LOD.",
        "Como se puede ver, todos los puntos seleccionados por AOD son del círculo grande, mientras que LOD selecciona cuatro puntos del círculo grande y cuatro del círculo pequeño.",
        "Los números junto a los puntos seleccionados indican su orden de selección.",
        "Claramente, los puntos seleccionados por nuestro algoritmo LOD pueden representar mejor el conjunto de datos original.",
        "No comparamos nuestro algoritmo con SVMactive porque SVMactive no se puede aplicar en este caso debido a la falta de puntos etiquetados. 6.2 Diseño Experimental de Recuperación de Imágenes La base de datos de imágenes que utilizamos consta de 7,900 imágenes de 79 categorías semánticas, del conjunto de datos COREL.",
        "Es un conjunto de imágenes grande y heterogéneo.",
        "Cada imagen se representa como un vector de 128 dimensiones según se describe en la Sección 5.1.",
        "La Figura 2 muestra algunas imágenes de muestra.",
        "Para exhibir las ventajas de usar nuestro algoritmo, necesitamos una forma confiable de evaluar el rendimiento de recuperación y las comparaciones con otros algoritmos.",
        "Listamos a continuación diferentes aspectos del diseño experimental. 6.2.1 Métricas de Evaluación Utilizamos la curva de precisión-alcance y la tasa de precisión [10] para evaluar la efectividad de los algoritmos de recuperación de imágenes.",
        "El alcance está especificado por el número (N) de imágenes mejor clasificadas presentadas al usuario.",
        "La precisión es la proporción entre el número de imágenes relevantes presentadas al usuario y el (a) Conjunto de datos 1 2 3 4 5 6 7 8 (b) AOD 1 2 3 4 5 6 7 8 (c) LOD Figura 1: Selección de datos por algoritmos de aprendizaje activo.",
        "Los números junto a los puntos seleccionados indican su orden de selección.",
        "Claramente, los puntos seleccionados por nuestro algoritmo LOD pueden representar mejor el conjunto de datos original.",
        "Se debe tener en cuenta que el algoritmo SVMactive no se puede aplicar en este caso debido a la falta de puntos etiquetados. (a) (b) (c) Figura 2: Imágenes de muestra de las categorías cuentas, elefante y barco. El alcance de precisión describe la precisión con varios alcances y, por lo tanto, proporciona una evaluación general del rendimiento de los algoritmos.",
        "Por otro lado, la tasa de precisión enfatiza la precisión en un valor particular de alcance.",
        "En general, es apropiado presentar 20 imágenes en una pantalla.",
        "Agregar más imágenes en una pantalla puede afectar la calidad de las imágenes presentadas.",
        "Por lo tanto, la precisión en los primeros 20 (N = 20) es especialmente importante.",
        "En los sistemas de recuperación de imágenes del mundo real, la imagen de consulta generalmente no se encuentra en la base de datos de imágenes.",
        "Para simular dicho entorno, utilizamos validación cruzada de cinco pliegues para evaluar los algoritmos.",
        "Más precisamente, dividimos toda la base de datos de imágenes en cinco subconjuntos de tamaño igual.",
        "Por lo tanto, hay 20 imágenes por categoría en cada subconjunto.",
        "En cada ejecución de validación cruzada, se selecciona un subconjunto como conjunto de consulta, y los otros cuatro subconjuntos se utilizan como base de datos para la recuperación.",
        "La curva de precisión del precisionscope y la tasa de precisión se calculan promediando los resultados de la validación cruzada de cinco pliegues. 6.2.2 Esquema de retroalimentación automática de relevancia Diseñamos un esquema de retroalimentación automática para modelar el proceso de recuperación.",
        "Para cada consulta enviada, nuestro sistema recupera y clasifica las imágenes en la base de datos. Se seleccionaron 10 imágenes de la base de datos para que los usuarios las etiqueten y la información de las etiquetas es utilizada por el sistema para volver a clasificarlas.",
        "Ten en cuenta que las imágenes seleccionadas en iteraciones anteriores están excluidas de selecciones posteriores.",
        "Para cada consulta, se realiza el mecanismo de retroalimentación automática de relevancia durante cuatro iteraciones.",
        "Es importante señalar que el esquema de retroalimentación automática de relevancia utilizado aquí es diferente de los descritos en [8], [11].",
        "En [8], [11], las cuatro imágenes relevantes e irrelevantes principales fueron seleccionadas como las imágenes de retroalimentación.",
        "Sin embargo, esto puede no ser práctico.",
        "En los sistemas de recuperación de imágenes del mundo real, es posible que la mayoría de las imágenes mejor clasificadas sean relevantes (o irrelevantes).",
        "Por lo tanto, es difícil para el usuario encontrar tanto cuatro imágenes relevantes como irrelevantes.",
        "Es más razonable que los usuarios proporcionen información de retroalimentación solo sobre las 10 imágenes seleccionadas por el sistema. 6.3 Rendimiento de recuperación de imágenes En el mundo real, no es práctico requerir que el usuario proporcione muchas rondas de retroalimentación.",
        "El rendimiento de recuperación después de las dos primeras rondas de retroalimentación (especialmente la primera ronda) es más importante.",
        "La Figura 3 muestra las curvas de precisión-alcance promedio de los diferentes algoritmos para las dos primeras iteraciones de retroalimentación.",
        "Al principio de la recuperación, las distancias euclidianas en el espacio original de 128 dimensiones se utilizan para clasificar las imágenes en la base de datos.",
        "Después de que el usuario proporcione retroalimentación de relevancia, se aplican los algoritmos LRR, SVM, SVMactive, AOD y LOD para volver a clasificar las imágenes.",
        "Para reducir la complejidad temporal de los algoritmos de aprendizaje activo, no seleccionamos las imágenes más informativas de toda la base de datos, sino de las 500 imágenes principales.",
        "Para LRR y SVM, se requiere que el usuario etiquete las 10 imágenes principales.",
        "Para SVMactive, AOD y LOD, se requiere que el usuario etiquete las 10 imágenes más informativas seleccionadas por estos algoritmos.",
        "Tenga en cuenta que, SVMactive solo puede ser ap(a) Iteración de retroalimentación 1 (b) Iteración de retroalimentación 2 Figura 3: Las curvas de precisión promedio-alcance de diferentes algoritmos para las dos primeras iteraciones de retroalimentación.",
        "El algoritmo LOD funciona mejor en todo el alcance.",
        "Se debe tener en cuenta que, en la primera ronda de retroalimentación, el algoritmo SVMactive no se puede aplicar.",
        "Se aplica el SVM ordinario para construir el clasificador inicial. (a) Precisión en el Top 10 (b) Precisión en el Top 20 (c) Precisión en el Top 30 Figura 4: Evaluación del rendimiento de los cinco algoritmos de aprendizaje para la recuperación de imágenes con retroalimentación de relevancia. (a) Precisión en el top 10, (b) Precisión en el top 20 y (c) Precisión en el top 30.",
        "Como se puede observar, nuestro algoritmo LOD supera consistentemente a los otros cuatro algoritmos.",
        "Por lo tanto, no se puede aplicar en la primera ronda y utilizamos el SVM estándar para construir el clasificador inicial.",
        "Como se puede ver, nuestro algoritmo LOD supera a los otros cuatro algoritmos en todo el ámbito.",
        "Además, el algoritmo LRR tiene un mejor rendimiento que SVM.",
        "Esto se debe a que el algoritmo LRR hace un uso eficiente de las imágenes no etiquetadas al incorporar un regularizador de preservación de la localidad en la función objetivo de regresión ordinaria.",
        "El algoritmo AOD es el que tiene peor rendimiento.",
        "A medida que el alcance se amplía, la diferencia de rendimiento entre estos algoritmos disminuye.",
        "Al agregar de forma iterativa los comentarios de los usuarios, los resultados de precisión correspondientes (en los primeros 10, 20 y 30 lugares) de los cinco algoritmos se muestran respectivamente en la Figura 4.",
        "Como se puede ver, nuestro algoritmo LOD tiene el mejor rendimiento en todos los casos y el algoritmo LRR tiene el segundo mejor rendimiento.",
        "Ambos de estos dos algoritmos hacen uso de las imágenes sin etiquetar.",
        "Esto demuestra que las imágenes sin etiquetar son útiles para descubrir la estructura geométrica intrínseca del espacio de imágenes y, por lo tanto, mejorar el rendimiento de recuperación.",
        "En el mundo real, es posible que el usuario no esté dispuesto a proporcionar demasiadas retroalimentaciones de relevancia.",
        "Por lo tanto, el rendimiento de recuperación en las primeras dos rondas es especialmente importante.",
        "Como se puede observar, nuestro algoritmo LOD logra una mejora del rendimiento del 6.8% para los 10 mejores resultados, del 5.2% para los 20 mejores resultados y del 4.1% para los 30 mejores resultados, en comparación con el segundo mejor algoritmo (LRR) después de las dos primeras rondas de retroalimentación de relevancia. 6.4 Discusión Se han realizado sistemáticamente varios experimentos en la base de datos de Corel.",
        "Nos gustaría resaltar varios puntos interesantes: 1.",
        "Es claro que el uso del aprendizaje activo es beneficioso en el ámbito de la recuperación de imágenes.",
        "Hay un aumento significativo en el rendimiento al utilizar los métodos de aprendizaje activo.",
        "Especialmente, de los tres métodos de aprendizaje activo (SVMactive, AOD, LOD), nuestro algoritmo propuesto LOD es el que tiene mejor rendimiento.",
        "En muchas aplicaciones del mundo real, como la recuperación de imágenes con retroalimentación de relevancia, generalmente hay dos formas de reducir la tarea laboriosa de etiquetado manual.",
        "Uno es el aprendizaje activo que selecciona las muestras más informativas para etiquetar, y el otro es el aprendizaje semi-supervisado que utiliza las muestras no etiquetadas para mejorar el rendimiento del aprendizaje.",
        "Ambas estrategias han sido estudiadas extensamente en el pasado [14], [7], [5], [8].",
        "El trabajo presentado en este artículo se centra en el aprendizaje activo, pero también aprovecha los avances recientes en el aprendizaje semi-supervisado [2].",
        "Específicamente, incorporamos un regularizador que preserva la localidad en el marco de regresión estándar y encontramos las muestras más informativas con respecto a la nueva función objetivo.",
        "De esta manera, las técnicas de aprendizaje activo y de aprendizaje semi-supervisado se unifican de manera fluida para aprender un clasificador óptimo. 3.",
        "La técnica de retroalimentación de relevancia es crucial para la recuperación de imágenes.",
        "Para los cinco algoritmos, el rendimiento de recuperación mejora con más retroalimentación proporcionada por el usuario.",
        "CONCLUSIONES Y TRABAJOS FUTUROS Este artículo describe un novedoso algoritmo de aprendizaje activo, llamado Diseño Óptimo Laplaciano, para permitir una recuperación de imágenes con retroalimentación de relevancia más efectiva.",
        "Nuestro algoritmo se basa en una función objetivo que minimiza simultáneamente el error empírico y preserva la estructura geométrica local del espacio de datos.",
        "Utilizando técnicas de diseño experimental, nuestro algoritmo encuentra las imágenes más informativas para etiquetar.",
        "Estas imágenes etiquetadas y las imágenes sin etiquetar en la base de datos se utilizan para aprender un clasificador.",
        "Los resultados experimentales en la base de datos Corel muestran que tanto el aprendizaje activo como el aprendizaje semi-supervisado pueden mejorar significativamente el rendimiento de recuperación.",
        "En este documento, consideramos el problema de recuperación de imágenes en un conjunto de datos de imágenes pequeño, estático y de dominio cerrado.",
        "Un dominio mucho más desafiante es la World Wide Web (WWW).",
        "Para la búsqueda de imágenes en la web, es posible recopilar una gran cantidad de información sobre los clics de los usuarios.",
        "Esta información puede ser utilizada de forma natural para construir el grafo de afinidad en nuestro algoritmo.",
        "Sin embargo, la complejidad computacional en el escenario web puede convertirse en un problema crucial.",
        "Además, aunque nuestro interés principal en este artículo se centra en la recuperación de imágenes con retroalimentación de relevancia, nuestros resultados también pueden ser de interés para investigadores en reconocimiento de patrones y aprendizaje automático, especialmente cuando hay una gran cantidad de datos disponibles pero solo se pueden etiquetar muestras limitadas. 8.",
        "REFERENCIAS [1] A. C. Atkinson y A. N. Donev.",
        "Diseños experimentales óptimos.",
        "Oxford University Press, 2002. [2] M. Belkin, P. Niyogi, y V. Sindhwani.",
        "Regularización de variedades: Un marco geométrico para el aprendizaje a partir de ejemplos.",
        "Revista de Investigación de Aprendizaje Automático, 7:2399-2434, 2006. [3] F. R. K. Chung.",
        "Teoría Espectral de Grafos, volumen 92 de la Serie de Conferencias Regionales en Matemáticas.",
        "AMS, 1997. [4] D. A. Cohn, Z. Ghahramani y M. I. Jordan.",
        "Aprendizaje activo con modelos estadísticos.",
        "Revista de Investigación en Inteligencia Artificial, 4:129-145, 1996. [5] A. Dong y B. Bhanu.",
        "Un nuevo algoritmo EM semisupervisado para la recuperación de imágenes.",
        "En la Conferencia IEEE sobre Visión por Computadora y Reconocimiento de Patrones, Madison, WI, 2003. [6] P. Flaherty, M. I. Jordan y A. P. Arkin.",
        "Diseño robusto de experimentos biológicos.",
        "En Advances in Neural Information Processing Systems 18, Vancouver, Canadá, 2005. [7] K.-S. Goh, E. Y. Chang y W.-C. Lai.",
        "Aprendizaje activo dependiente del concepto multimodal para la recuperación de imágenes.",
        "En Actas de la Conferencia ACM sobre Multimedia, Nueva York, octubre de 2004. [8] X.",
        "Lo siento, la oración \"He.\" no tiene un significado claro en inglés. ¿Podrías proporcionar más contexto o una oración completa para que pueda traducirla al español de manera precisa?",
        "Aprendizaje de subespacios semisupervisado incremental para la recuperación de imágenes.",
        "En Actas de la Conferencia ACM sobre Multimedia, Nueva York, octubre de 2004. [9] S. C. Hoi y M. R. Lyu.",
        "Un marco de aprendizaje activo semi-supervisado para la recuperación de imágenes.",
        "En la Conferencia Internacional de IEEE sobre Visión por Computadora y Reconocimiento de Patrones, San Diego, CA, 2005. [10] D. P. Huijsmans y N. Sebe.",
        "Cómo completar los gráficos de rendimiento en la recuperación de imágenes basada en contenido: Agregar generalidad y normalizar el alcance.",
        "IEEE Transactions on Pattern Analysis and Machine Intelligence, 27(2):245-251, 2005. [11] Y.-Y.\n\nTransacciones del IEEE sobre Inteligencia Artificial y Análisis de Patrones, 27(2):245-251, 2005. [11] Y.-Y.",
        "Lin, T.-L. Liu y H.-T. Chen.",
        "Aprendizaje de variedades semánticas para la recuperación de imágenes.",
        "En Actas de la Conferencia ACM sobre Multimedia, Singapur, noviembre de 2005. [12] Y. Rui, T. S. Huang, M. Ortega y S. Mehrotra.",
        "Retroalimentación de relevancia: Una herramienta poderosa para la recuperación de imágenes basada en contenido de forma interactiva.",
        "IEEE Transactions on Circuits and Systems for Video Technology, 8(5), 1998. [13] A. W. Smeulders, M. Worring, S. Santini, A. Gupta, and R. Jain. \n\nTraducción: IEEE Transactions on Circuits and Systems for Video Technology, 8(5), 1998. [13] A. W. Smeulders, M. Worring, S. Santini, A. Gupta y R. Jain.",
        "Recuperación de imágenes basada en contenido al final de los primeros años.",
        "IEEE Transactions on Pattern Analysis and Machine Intelligence, 22(12):1349-1380, 2000. [14] S. Tong y E. Chang.",
        "Aprendizaje activo de máquina de vectores de soporte para recuperación de imágenes.",
        "En Actas de la novena conferencia internacional de ACM sobre Multimedia, páginas 107-118, 2001. [15] H. Yu, M. Li, H.-J.",
        "Zhang y J. Feng.",
        "Momentos de textura de color para la recuperación de imágenes basada en contenido.",
        "En la Conferencia Internacional de Procesamiento de Imágenes, páginas 24-28, 2002. [16] K. Yu, J. Bi y V. Tresp.",
        "Aprendizaje activo a través del diseño experimental transductivo.",
        "En Actas de la 23ª Conferencia Internacional sobre Aprendizaje Automático, Pittsburgh, PA, 2006."
    ],
    "error_count": 2,
    "keys": {
        "relevance feedback": {
            "translated_key": "retroalimentación de relevancia",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Laplacian Optimal Design for Image Retrieval Xiaofei He Yahoo!",
                "Burbank, CA 91504 hex@yahoo-inc.com Wanli Min IBM Yorktown Heights, NY 10598 wanlimin@us.ibm.com Deng Cai CS Dept., UIUC Urbana, IL 61801 dengcai2@cs.uiuc.edu Kun Zhou Microsoft Research Asia Beijing, China kunzhou@microsoft.com ABSTRACT <br>relevance feedback</br> is a powerful technique to enhance ContentBased Image Retrieval (CBIR) performance.",
                "It solicits the users relevance judgments on the retrieved images returned by the CBIR systems.",
                "The users labeling is then used to learn a classifier to distinguish between relevant and irrelevant images.",
                "However, the top returned images may not be the most informative ones.",
                "The challenge is thus to determine which unlabeled images would be the most informative (i.e., improve the classifier the most) if they were labeled and used as training samples.",
                "In this paper, we propose a novel active learning algorithm, called Laplacian Optimal Design (LOD), for <br>relevance feedback</br> image retrieval.",
                "Our algorithm is based on a regression model which minimizes the least square error on the measured (or, labeled) images and simultaneously preserves the local geometrical structure of the image space.",
                "Specifically, we assume that if two images are sufficiently close to each other, then their measurements (or, labels) are close as well.",
                "By constructing a nearest neighbor graph, the geometrical structure of the image space can be described by the graph Laplacian.",
                "We discuss how results from the field of optimal experimental design may be used to guide our selection of a subset of images, which gives us the most amount of information.",
                "Experimental results on Corel database suggest that the proposed approach achieves higher precision in <br>relevance feedback</br> image retrieval.",
                "Categories and Subject Descriptors H.3.3 [Information storage and retrieval]: Information search and retrieval-<br>relevance feedback</br>; G.3 [Mathematics of Computing]: Probability and Statistics-Experimental design General Terms Algorithms, Performance, Theory 1.",
                "INTRODUCTION In many machine learning and information retrieval tasks, there is no shortage of unlabeled data but labels are expensive.",
                "The challenge is thus to determine which unlabeled samples would be the most informative (i.e., improve the classifier the most) if they were labeled and used as training samples.",
                "This problem is typically called active learning [4].",
                "Here the task is to minimize an overall cost, which depends both on the classifier accuracy and the cost of data collection.",
                "Many real world applications can be casted into active learning framework.",
                "Particularly, we consider the problem of <br>relevance feedback</br> driven Content-Based Image Retrieval (CBIR) [13].",
                "Content-Based Image Retrieval has attracted substantial interests in the last decade [13].",
                "It is motivated by the fast growth of digital image databases which, in turn, require efficient search schemes.",
                "Rather than describe an image using text, in these systems an image query is described using one or more example images.",
                "The low level visual features (color, texture, shape, etc.) are automatically extracted to represent the images.",
                "However, the low level features may not accurately characterize the high level semantic concepts.",
                "To narrow down the semantic gap, <br>relevance feedback</br> is introduced into CBIR [12].",
                "In many of the current <br>relevance feedback</br> driven CBIR systems, the user is required to provide his/her relevance judgments on the top images returned by the system.",
                "The labeled images are then used to train a classifier to separate images that match the query concept from those that do not.",
                "However, in general the top returned images may not be the most informative ones.",
                "In the worst case, all the top images labeled by the user may be positive and thus the standard classification techniques can not be applied due to the lack of negative examples.",
                "Unlike the standard classification problems where the labeled samples are pregiven, in <br>relevance feedback</br> image retrieval the system can actively select the images to label.",
                "Thus active learning can be naturally introduced into image retrieval.",
                "Despite many existing active learning techniques, Support Vector Machine (SVM) active learning [14] and regression based active learning [1] have received the most interests.",
                "Based on the observation that the closer to the SVM boundary an image is, the less reliable its classification is, SVM active learning selects those unlabeled images closest to the boundary to solicit user feedback so as to achieve maximal refinement on the hyperplane between the two classes.",
                "The major disadvantage of SVM active learning is that the estimated boundary may not be accurate enough.",
                "Moreover, it may not be applied at the beginning of the retrieval when there is no labeled images.",
                "Some other SVM based active learning algorithms can be found in [7], [9].",
                "In statistics, the problem of selecting samples to label is typically referred to as experimental design.",
                "The sample x is referred to as experiment, and its label y is referred to as measurement.",
                "The study of optimal experimental design (OED) [1] is concerned with the design of experiments that are expected to minimize variances of a parameterized model.",
                "The intent of optimal experimental design is usually to maximize confidence in a given model, minimize parameter variances for system identification, or minimize the models output variance.",
                "Classical experimental design approaches include A-Optimal Design, D-Optimal Design, and E-Optimal Design.",
                "All of these approaches are based on a least squares regression model.",
                "Comparing to SVM based active learning algorithms, experimental design approaches are much more efficient in computation.",
                "However, this kind of approaches takes only measured (or, labeled) data into account in their objective function, while the unmeasured (or, unlabeled) data is ignored.",
                "Benefit from recent progresses on optimal experimental design and semi-supervised learning, in this paper we propose a novel active learning algorithm for image retrieval, called Laplacian Optimal Design (LOD).",
                "Unlike traditional experimental design methods whose loss functions are only defined on the measured points, the loss function of our proposed LOD algorithm is defined on both measured and unmeasured points.",
                "Specifically, we introduce a locality preserving regularizer into the standard least-square-error based loss function.",
                "The new loss function aims to find a classifier which is locally as smooth as possible.",
                "In other words, if two points are sufficiently close to each other in the input space, then they are expected to share the same label.",
                "Once the loss function is defined, we can select the most informative data points which are presented to the user for labeling.",
                "It would be important to note that the most informative images may not be the top returned images.",
                "The rest of the paper is organized as follows.",
                "In Section 2, we provide a brief description of the related work.",
                "Our proposed Laplacian Optimal Design algorithm is introduced in Section 3.",
                "In Section 4, we compare our algorithm with the state-or-the-art algorithms and present the experimental results on image retrieval.",
                "Finally, we provide some concluding remarks and suggestions for future work in Section 5. 2.",
                "RELATED WORK Since our proposed algorithm is based on regression framework.",
                "The most related work is optimal experimental design [1], including A-Optimal Design, D-Optimal Design, and EOptimal Design.",
                "In this Section, we give a brief description of these approaches. 2.1 The Active Learning Problem The generic problem of active learning is the following.",
                "Given a set of points A = {x1, x2, · · · , xm} in Rd , find a subset B = {z1, z2, · · · , zk} ⊂ A which contains the most informative points.",
                "In other words, the points zi(i = 1, · · · , k) can improve the classifier the most if they are labeled and used as training points. 2.2 Optimal Experimental Design We consider a linear regression model y = wT x + (1) where y is the observation, x is the independent variable, w is the weight vector and is an unknown error with zero mean.",
                "Different observations have errors that are independent, but with equal variances σ2 .",
                "We define f(x) = wT x to be the learners output given input x and the weight vector w. Suppose we have a set of labeled sample points (z1, y1), · · · , (zk, yk), where yi is the label of zi.",
                "Thus, the maximum likelihood estimate for the weight vector, ˆw, is that which minimizes the sum squared error Jsse(w) = k i=1 wT zi − yi 2 (2) The estimate ˆw gives us an estimate of the output at a novel input: ˆy = ˆwT x.",
                "By Gauss-Markov theorem, we know that ˆw − w has a zero mean and a covariance matrix given by σ2 H−1 sse, where Hsse is the Hessian of Jsse(w) Hsse = ∂2 Jsse ∂w2 = k i=1 zizT i = ZZT where Z = (z1, z2, · · · , zk).",
                "The three most common scalar measures of the size of the parameter covariance matrix in optimal experimental design are: • D-optimal design: determinant of Hsse. • A-optimal design: trace of Hsse. • E-optimal design: maximum eigenvalue of Hsse.",
                "Since the computation of the determinant and eigenvalues of a matrix is much more expensive than the computation of matrix trace, A-optimal design is more efficient than the other two.",
                "Some recent work on experimental design can be found in [6], [16]. 3.",
                "LAPLACIAN OPTIMAL DESIGN Since the covariance matrix Hsse used in traditional approaches is only dependent on the measured samples, i.e. zis, these approaches fail to evaluate the expected errors on the unmeasured samples.",
                "In this Section, we introduce a novel active learning algorithm called Laplacian Optimal Design (LOD) which makes efficient use of both measured (labeled) and unmeasured (unlabeled) samples. 3.1 The Objective Function In many machine learning problems, it is natural to assume that if two points xi, xj are sufficiently close to each other, then their measurements (f(xi), f(xj)) are close as well.",
                "Let S be a similarity matrix.",
                "Thus, a new loss function which respects the geometrical structure of the data space can be defined as follows: J0(w) = k i=1 f(zi)−yi 2 + λ 2 m i,j=1 f(xi)−f(xj) 2 Sij (3) where yi is the measurement (or, label) of zi.",
                "Note that, the loss function (3) is essentially the same as the one used in Laplacian Regularized Regression (LRR, [2]).",
                "However, LRR is a passive learning algorithm where the training data is given.",
                "In this paper, we are focused on how to select the most informative data for training.",
                "The loss function with our choice of symmetric weights Sij (Sij = Sji) incurs a heavy penalty if neighboring points xi and xj are mapped far apart.",
                "Therefore, minimizing J0(w) is an attempt to ensure that if xi and xj are close then f(xi) and f(xj) are close as well.",
                "There are many choices of the similarity matrix S. A simple definition is as follows: Sij = ⎧ ⎨ ⎩ 1, if xi is among the p nearest neighbors of xj, or xj is among the p nearest neighbors of xi; 0, otherwise. (4) Let D be a diagonal matrix, Dii = j Sij, and L = D−S.",
                "The matrix L is called graph Laplacian in spectral graph theory [3].",
                "Let y = (y1, · · · , yk)T and X = (x1, · · · , xm).",
                "Following some simple algebraic steps, we see that: J0(w) = k i=1 wT zi − yi 2 + λ 2 m i,j=1 wT xi − wT xj 2 Sij = y − ZT w T y − ZT w + λwT m i=1 DiixixT i − m i,j=1 SijxixT j w = yT y − 2wT Zy + wT ZZT w +λwT XDXT − XSXT w = yT y − 2wT Zy + wT ZZT + λXLXT w The Hessian of J0(w) can be computed as follows: H0 = ∂2 J0 ∂w2 = ZZT + λXLXT In some cases, the matrix ZZT +λXLXT is singular (e.g. if m < d).",
                "Thus, there is no stable solution to the optimization problem Eq. (3).",
                "A common way to deal with this ill-posed problem is to introduce a Tikhonov regularizer into our loss function: J(w) = k i=1 wT zi − yi 2 + λ1 2 m i,j=1 wT xi − wT xj 2 Sij +λ2 w 2 (5) The Hessian of the new loss function is given by: H = ∂2 J ∂w2 = ZZT + λ1XLXT + λ2I := ZZT + Λ where I is an identity matrix and Λ = λ1XLXT + λ2I.",
                "Clearly, H is of full rank.",
                "Requiring that the gradient of J(w) with respect to w vanish gives the optimal estimate ˆw: ˆw = H−1 Zy The following proposition states the bias and variance properties of the estimator for the coefficient vector w. Proposition 3.1.",
                "E( ˆw − w) = −H−1 Λw, Cov( ˆw) = σ2 (H−1 − H−1 ΛH−1 ) Proof.",
                "Since y = ZT w + and E( ) = 0, it follows that E( ˆw − w) (6) = H−1 ZZT w − w = H−1 (ZZT + Λ − Λ)w − w = (I − H−1 Λ)w − w = −H−1 Λw (7) Notice Cov(y) = σ2 I, the covariance matrix of ˆw has the expression: Cov( ˆw) = H−1 ZCov(y)ZT H−1 = σ2 H−1 ZZT H−1 = σ2 H−1 (H − Λ)H−1 = σ2 (H−1 − H−1 ΛH−1 ) (8) Therefore mean squared error matrix for the coefficients w is E(w − ˆw)(w − ˆw)T (9) = H−1 ΛwwT ΛH−1 + σ2 (H−1 − H−1 ΛH−1 ) (10) For any x, let ˆy = ˆwT x be its predicted observation.",
                "The expected squared prediction error is E(y − ˆy)2 = E( + wT x − ˆwT x)2 = σ2 + xT [E(w − ˆw)(w − ˆw)T ]x = σ2 + xT [H−1 ΛwwT ΛH−1 + σ2 H−1 − σ2 H−1 ΛH−1 ]x Clearly the expected square prediction error depends on the explanatory variable x, therefore average expected square predictive error over the complete data set A is 1 m m i=1 E(yi − ˆwT xi)2 = 1 m m i=1 xT i [H−1 ΛwwT ΛH−1 + σ2 H−1 − σ2 H−1 ΛH−1 ]xi +σ2 = 1 m Tr(XT [σ2 H−1 + H−1 ΛwwT ΛH−1 − σ2 H−1 ΛH−1 ]X) +σ2 Since Tr(XT [H−1 ΛwwT ΛH−1 − σ2 H−1 ΛH−1 ]X) Tr(σ2 XT H−1 X), Our Laplacian optimality criterion is thus formulated by minimizing the trace of XT H−1 X.",
                "Definition 1.",
                "Laplacian Optimal Design min Z=(z1,··· ,zk) Tr XT ZZT + λ1XLXT + λ2I −1 X (11) where z1, · · · , zk are selected from {x1, · · · , xm}. 4.",
                "KERNEL LAPLACIAN OPTIMAL DESIGN Canonical experimental design approaches (e.g.",
                "A-Optimal Design, D-Optimal Design, and E-Optimal) only consider linear functions.",
                "They fail to discover the intrinsic geometry in the data when the data space is highly nonlinear.",
                "In this section, we describe how to perform Laplacian Experimental Design in Reproducing Kernel Hilbert Space (RKHS) which gives rise to Kernel Laplacian Experimental Design (KLOD).",
                "For given data points x1, · · · , xm ∈ X with a positive definite mercer kernel K : X ×X → R, there exists a unique RKHS HK of real valued functions on X.",
                "Let Kt(s) be the function of s obtained by fixing t and letting Kt(s) . = K(s, t).",
                "HK consists of all finite linear combinations of the form l i=1 αiKti with ti ∈ X and limits of such functions as the ti become dense in X.",
                "We have Ks, Kt HK = K(s, t). 4.1 Derivation of LOD in Reproducing Kernel Hilbert Space Consider the optimization problem (5) in RKHS.",
                "Thus, we seek a function f ∈ HK such that the following objective function is minimized: min f∈HK k i=1 f(zi)−yi 2 + λ1 2 m i,j=1 f(xi)−f(xj) 2 Sij+λ2 f 2 HK (12) We have the following proposition.",
                "Proposition 4.1.",
                "Let H = { m i=1 αiK(·, xi)|αi ∈ R} be a subspace of HK , the solution to the problem (12) is in H. Proof.",
                "Let H⊥ be the orthogonal complement of H, i.e.",
                "HK = H ⊕ H⊥ .",
                "Thus, for any function f ∈ HK , it has orthogonal decomposition as follows: f = fH + fH⊥ Now, lets evaluate f at xi: f(xi) = f, Kxi HK = fH + fH⊥ , Kxi HK = fH, Kxi HK + fH⊥ , Kxi HK Notice that Kxi ∈ H while fH⊥ ∈ H⊥ .",
                "This implies that fH⊥ , Kxi HK = 0.",
                "Therefore, f(xi) = fH, Kxi HK = fH(xi) This completes the proof.",
                "Proposition 4.1 tells us the minimizer of problem (12) admits a representation f∗ = m i=1 αiK(·, xi).",
                "Please see [2] for the details.",
                "Let φ : Rd → H be a feature map from the input space Rd to H, and K(xi, xj) =< φ(xi), φ(xj) >.",
                "Let X denote the data matrix in RKHS, X = (φ(x1), φ(x2), · · · , φ(xm)).",
                "Similarly, we define Z = (φ(z1), φ(z2), · · · , φ(zk)).",
                "Thus, the optimization problem in RKHS can be written as follows: min Z Tr XT ZZT + λ1XLXT + λ2I −1 X (13) Since the mapping function φ is generally unknown, there is no direct way to solve problem (13).",
                "In the following, we apply kernel tricks to solve this optimization problem.",
                "Let X−1 be the Moore-Penrose inverse (also known as pseudo inverse) of X.",
                "Thus, we have: XT ZZT + λ1XLXT + λ2I −1 X = XT XX−1 ZZT + λ1XLXT + λ2I −1 (XT )−1 XT X = XT X ZZT X + λ1XLXT X + λ2X −1 (XT )−1 XT X = XT X XT ZZT X + λ1XT XLXT X + λ2XT X −1 XT X = KXX KXZKZX + λ1KXXLKXX + λ2KXX −1 KXX where KXX is a m × m matrix (KXX,ij = K(xi, xj)), KXZ is a m×k matrix (KXZ,ij = K(xi, zj)), and KZX is a k×m matrix (KZX,ij = K(zi, xj)).",
                "Thus, the Kernel Laplacian Optimal Design can be defined as follows: Definition 2.",
                "Kernel Laplacian Optimal Design minZ=(z1,··· ,zk) Tr KXX KXZKZX + λ1KXXLKXX λ2KXX −1 KXX (14) 4.2 Optimization Scheme In this subsection, we discuss how to solve the optimization problems (11) and (14).",
                "Particularly, if we select a linear kernel for KLOD, then it reduces to LOD.",
                "Therefore, we will focus on problem (14) in the following.",
                "It can be shown that the optimization problem (14) is NP-hard.",
                "In this subsection, we develop a simple sequential greedy approach to solve (14).",
                "Suppose n points have been selected, denoted by a matrix Zn = (z1, · · · , zn).",
                "The (n + 1)-th point zn+1 can be selected by solving the following optimization problem: max Zn+1=(Zn,zn+1) Tr KXX KXZn+1 KZn+1X + λ1KXXLKXX + λ2KXX −1 KXX (15) The kernel matrices KXZn+1 and KZn+1X can be rewritten as follows: KXZn+1 = KXZn , KXzn+1 , KZn+1X = KZnX Kzn+1X Thus, we have: KXZn+1 KZn+1X = KXZn KZnX + KXzn+1 Kzn+1X We define: A = KXZn KZnX + λ1KXXLKXX + λ2KXX A is only dependent on X and Zn .",
                "Thus, the (n + 1)-th point zn+1 is given by: zn+1 = arg min zn+1 Tr KXX A + KXzn+1 Kzn+1X −1 KXX (16) Each time we select a new point zn+1, the matrix A is updated by: A ← A + KXzn+1 Kzn+1X If the kernel function is chosen as inner product K(x, y) = x, y , then HK is a linear functional space and the algorithm reduces to LOD. 5.",
                "CONTENT-BASED IMAGE RETRIEVAL USING LAPLACIAN OPTIMAL DESIGN In this section, we describe how to apply Laplacian Optimal Design to CBIR.",
                "We begin with a brief description of image representation using low level visual features. 5.1 Low-Level Image Representation Low-level image representation is a crucial problem in CBIR.",
                "General visual features includes color, texture, shape, etc.",
                "Color and texture features are the most extensively used visual features in CBIR.",
                "Compared with color and texture features, shape features are usually described after images have been segmented into regions or objects.",
                "Since robust and accurate image segmentation is difficult to achieve, the use of shape features for image retrieval has been limited to special applications where objects or regions are readily available.",
                "In this work, We combine 64-dimensional color histogram and 64-dimensional Color Texture Moment (CTM, [15]) to represent the images.",
                "The color histogram is calculated using 4 × 4 × 4 bins in HSV space.",
                "The Color Texture Moment is proposed by Yu et al. [15], which integrates the color and texture characteristics of the image in a compact form.",
                "CTM adopts local Fourier transform as a texture representation scheme and derives eight characteristic maps to describe different aspects of co-occurrence relations of image pixels in each channel of the (SVcosH, SVsinH, V) color space.",
                "Then CTM calculates the first and second moment of these maps as a representation of the natural color image pixel distribution.",
                "Please see [15] for details. 5.2 <br>relevance feedback</br> Image Retrieval <br>relevance feedback</br> is one of the most important techniques to narrow down the gap between low level visual features and high level semantic concepts [12].",
                "Traditionally, the users relevance feedbacks are used to update the query vector or adjust the weighting of different dimensions.",
                "This process can be viewed as an on-line learning process in which the image retrieval system acts as a learner and the user acts as a teacher.",
                "They typical retrieval process is outlined as follows: 1.",
                "The user submits a query image example to the system.",
                "The system ranks the images in database according to some pre-defined distance metric and presents to the user the top ranked images. 2.",
                "The system selects some images from the database and request the user to label them as relevant or irrelevant. 3.",
                "The system uses the users provided information to rerank the images in database and returns to the user the top images.",
                "Go to step 2 until the user is satisfied.",
                "Our Laplacian Optimal Design algorithm is applied in the second step for selecting the most informative images.",
                "Once we get the labels for the images selected by LOD, we apply Laplacian Regularized Regression (LRR, [2]) to solve the optimization problem (3) and build the classifier.",
                "The classifier is then used to re-rank the images in database.",
                "Note that, in order to reduce the computational complexity, we do not use all the unlabeled images in the database but only those within top 500 returns of previous iteration. 6.",
                "EXPERIMENTAL RESULTS In this section, we evaluate the performance of our proposed algorithm on a large image database.",
                "To demonstrate the effectiveness of our proposed LOD algorithm, we compare it with Laplacian Regularized Regression (LRR, [2]), Support Vector Machine (SVM), Support Vector Machine Active Learning (SVMactive) [14], and A-Optimal Design (AOD).",
                "Both SVMactive, AOD, and LOD are active learning algorithms, while LRR and SVM are standard classification algorithms.",
                "SVM only makes use of the labeled images, while LRR is a semi-supervised learning algorithm which makes use of both labeled and unlabeled images.",
                "For SVMactive, AOD, and LOD, 10 training images are selected by the algorithms themselves at each iteration.",
                "While for LRR and SVM, we use the top 10 images as training data.",
                "It would be important to note that SVMactive is based on the ordinary SVM, LOD is based on LRR, and AOD is based on the ordinary regression.",
                "The parameters λ1 and λ2 in our LOD algorithm are empirically set to be 0.001 and 0.00001.",
                "For both LRR and LOD algorithms, we use the same graph structure (see Eq. 4) and set the value of p (number of nearest neighbors) to be 5.",
                "We begin with a simple synthetic example to give some intuition about how LOD works. 6.1 Simple Synthetic Example A simple synthetic example is given in Figure 1.",
                "The data set contains two circles.",
                "Eight points are selected by AOD and LOD.",
                "As can be seen, all the points selected by AOD are from the big circle, while LOD selects four points from the big circle and four from the small circle.",
                "The numbers beside the selected points denote their orders to be selected.",
                "Clearly, the points selected by our LOD algorithm can better represent the original data set.",
                "We did not compare our algorithm with SVMactive because SVMactive can not be applied in this case due to the lack of the labeled points. 6.2 Image Retrieval Experimental Design The image database we used consists of 7,900 images of 79 semantic categories, from COREL data set.",
                "It is a large and heterogeneous image set.",
                "Each image is represented as a 128-dimensional vector as described in Section 5.1.",
                "Figure 2 shows some sample images.",
                "To exhibit the advantages of using our algorithm, we need a reliable way of evaluating the retrieval performance and the comparisons with other algorithms.",
                "We list different aspects of the experimental design below. 6.2.1 Evaluation Metrics We use precision-scope curve and precision rate [10] to evaluate the effectiveness of the image retrieval algorithms.",
                "The scope is specified by the number (N) of top-ranked images presented to the user.",
                "The precision is the ratio of the number of relevant images presented to the user to the (a) Data set 1 2 3 4 5 6 7 8 (b) AOD 1 2 3 4 5 6 7 8 (c) LOD Figure 1: Data selection by active learning algorithms.",
                "The numbers beside the selected points denote their orders to be selected.",
                "Clearly, the points selected by our LOD algorithm can better represent the original data set.",
                "Note that, the SVMactive algorithm can not be applied in this case due to the lack of labeled points. (a) (b) (c) Figure 2: Sample images from category bead, elephant, and ship. scope N. The precision-scope curve describes the precision with various scopes and thus gives an overall performance evaluation of the algorithms.",
                "On the other hand, the precision rate emphasizes the precision at a particular value of scope.",
                "In general, it is appropriate to present 20 images on a screen.",
                "Putting more images on a screen may affect the quality of the presented images.",
                "Therefore, the precision at top 20 (N = 20) is especially important.",
                "In real world image retrieval systems, the query image is usually not in the image database.",
                "To simulate such environment, we use five-fold cross validation to evaluate the algorithms.",
                "More precisely, we divide the whole image database into five subsets with equal size.",
                "Thus, there are 20 images per category in each subset.",
                "At each run of cross validation, one subset is selected as the query set, and the other four subsets are used as the database for retrieval.",
                "The precisionscope curve and precision rate are computed by averaging the results from the five-fold cross validation. 6.2.2 Automatic <br>relevance feedback</br> Scheme We designed an automatic feedback scheme to model the retrieval process.",
                "For each submitted query, our system retrieves and ranks the images in the database. 10 images were selected from the database for user labeling and the label information is used by the system for re-ranking.",
                "Note that, the images which have been selected at previous iterations are excluded from later selections.",
                "For each query, the automatic <br>relevance feedback</br> mechanism is performed for four iterations.",
                "It is important to note that the automatic <br>relevance feedback</br> scheme used here is different from the ones described in [8], [11].",
                "In [8], [11], the top four relevant and irrelevant images were selected as the feedback images.",
                "However, this may not be practical.",
                "In real world image retrieval systems, it is possible that most of the top-ranked images are relevant (or, irrelevant).",
                "Thus, it is difficult for the user to find both four relevant and irrelevant images.",
                "It is more reasonable for the users to provide feedback information only on the 10 images selected by the system. 6.3 Image Retrieval Performance In real world, it is not practical to require the user to provide many rounds of feedbacks.",
                "The retrieval performance after the first two rounds of feedbacks (especially the first round) is more important.",
                "Figure 3 shows the average precision-scope curves of the different algorithms for the first two feedback iterations.",
                "At the beginning of retrieval, the Euclidean distances in the original 128-dimensional space are used to rank the images in database.",
                "After the user provides relevance feedbacks, the LRR, SVM, SVMactive, AOD, and LOD algorithms are then applied to re-rank the images.",
                "In order to reduce the time complexity of active learning algorithms, we didnt select the most informative images from the whole database but from the top 500 images.",
                "For LRR and SVM, the user is required to label the top 10 images.",
                "For SVMactive, AOD, and LOD, the user is required to label 10 most informative images selected by these algorithms.",
                "Note that, SVMactive can only be ap(a) Feedback Iteration 1 (b) Feedback Iteration 2 Figure 3: The average precision-scope curves of different algorithms for the first two feedback iterations.",
                "The LOD algorithm performs the best on the entire scope.",
                "Note that, at the first round of feedback, the SVMactive algorithm can not be applied.",
                "It applies the ordinary SVM to build the initial classifier. (a) Precision at Top 10 (b) Precision at Top 20 (c) Precision at Top 30 Figure 4: Performance evaluation of the five learning algorithms for <br>relevance feedback</br> image retrieval. (a) Precision at top 10, (b) Precision at top 20, and (c) Precision at top 30.",
                "As can be seen, our LOD algorithm consistently outperforms the other four algorithms. plied when the classifier is already built.",
                "Therefore, it can not be applied at the first round and we use the standard SVM to build the initial classifier.",
                "As can be seen, our LOD algorithm outperforms the other four algorithms on the entire scope.",
                "Also, the LRR algorithm performs better than SVM.",
                "This is because that the LRR algorithm makes efficient use of the unlabeled images by incorporating a locality preserving regularizer into the ordinary regression objective function.",
                "The AOD algorithm performs the worst.",
                "As the scope gets larger, the performance difference between these algorithms gets smaller.",
                "By iteratively adding the users feedbacks, the corresponding precision results (at top 10, top 20, and top 30) of the five algorithms are respectively shown in Figure 4.",
                "As can be seen, our LOD algorithm performs the best in all the cases and the LRR algorithm performs the second best.",
                "Both of these two algorithms make use of the unlabeled images.",
                "This shows that the unlabeled images are helpful for discovering the intrinsic geometrical structure of the image space and therefore enhance the retrieval performance.",
                "In real world, the user may not be willing to provide too many relevance feedbacks.",
                "Therefore, the retrieval performance at the first two rounds are especially important.",
                "As can be seen, our LOD algorithm achieves 6.8% performance improvement for top 10 results, 5.2% for top 20 results, and 4.1% for top 30 results, comparing to the second best algorithm (LRR) after the first two rounds of relevance feedbacks. 6.4 Discussion Several experiments on Corel database have been systematically performed.",
                "We would like to highlight several interesting points: 1.",
                "It is clear that the use of active learning is beneficial in the image retrieval domain.",
                "There is a significant increase in performance from using the active learning methods.",
                "Especially, out of the three active learning methods (SVMactive, AOD, LOD), our proposed LOD algorithm performs the best. 2.",
                "In many real world applications like <br>relevance feedback</br> image retrieval, there are generally two ways of reducing labor-intensive manual labeling task.",
                "One is active learning which selects the most informative samples to label, and the other is semi-supervised learning which makes use of the unlabeled samples to enhance the learning performance.",
                "Both of these two strategies have been studied extensively in the past [14], [7], [5], [8].",
                "The work presented in this paper is focused on active learning, but it also takes advantage of the recent progresses on semi-supervised learning [2].",
                "Specifically, we incorporate a locality preserving regularizer into the standard regression framework and find the most informative samples with respect to the new objective function.",
                "In this way, the active learning and semi-supervised learning techniques are seamlessly unified for learning an optimal classifier. 3.",
                "The <br>relevance feedback</br> technique is crucial to image retrieval.",
                "For all the five algorithms, the retrieval performance improves with more feedbacks provided by the user. 7.",
                "CONCLUSIONS AND FUTURE WORK This paper describes a novel active learning algorithm, called Laplacian Optimal Design, to enable more effective <br>relevance feedback</br> image retrieval.",
                "Our algorithm is based on an objective function which simultaneously minimizes the empirical error and preserves the local geometrical structure of the data space.",
                "Using techniques from experimental design, our algorithm finds the most informative images to label.",
                "These labeled images and the unlabeled images in the database are used to learn a classifier.",
                "The experimental results on Corel database show that both active learning and semi-supervised learning can significantly improve the retrieval performance.",
                "In this paper, we consider the image retrieval problem on a small, static, and closed-domain image data.",
                "A much more challenging domain is the World Wide Web (WWW).",
                "For Web image search, it is possible to collect a large amount of user click information.",
                "This information can be naturally used to construct the affinity graph in our algorithm.",
                "However, the computational complexity in Web scenario may become a crucial issue.",
                "Also, although our primary interest in this paper is focused on <br>relevance feedback</br> image retrieval, our results may also be of interest to researchers in patten recognition and machine learning, especially when a large amount of data is available but only a limited samples can be labeled. 8.",
                "REFERENCES [1] A. C. Atkinson and A. N. Donev.",
                "Optimum Experimental Designs.",
                "Oxford University Press, 2002. [2] M. Belkin, P. Niyogi, and V. Sindhwani.",
                "Manifold regularization: A geometric framework for learning from examples.",
                "Journal of Machine Learning Research, 7:2399-2434, 2006. [3] F. R. K. Chung.",
                "Spectral Graph Theory, volume 92 of Regional Conference Series in Mathematics.",
                "AMS, 1997. [4] D. A. Cohn, Z. Ghahramani, and M. I. Jordan.",
                "Active learning with statistical models.",
                "Journal of Artificial Intelligence Research, 4:129-145, 1996. [5] A. Dong and B. Bhanu.",
                "A new semi-supervised em algorithm for image retrieval.",
                "In IEEE Conf. on Computer Vision and Pattern Recognition, Madison, WI, 2003. [6] P. Flaherty, M. I. Jordan, and A. P. Arkin.",
                "Robust design of biological experiments.",
                "In Advances in Neural Information Processing Systems 18, Vancouver, Canada, 2005. [7] K.-S. Goh, E. Y. Chang, and W.-C. Lai.",
                "Multimodal concept-dependent active learning for image retrieval.",
                "In Proceedings of the ACM Conference on Multimedia, New York, October 2004. [8] X.",
                "He.",
                "Incremental semi-supervised subspace learning for image retrieval.",
                "In Proceedings of the ACM Conference on Multimedia, New York, October 2004. [9] S. C. Hoi and M. R. Lyu.",
                "A semi-supervised active learning framework for image retrieval.",
                "In IEEE International Conference on Computer Vision and Pattern Recognition, San Diego, CA, 2005. [10] D. P. Huijsmans and N. Sebe.",
                "How to complete performance graphs in content-based image retrieval: Add generality and normalize scope.",
                "IEEE Transactions on Pattern Analysis and Machine Intelligence, 27(2):245-251, 2005. [11] Y.-Y.",
                "Lin, T.-L. Liu, and H.-T. Chen.",
                "Semantic manifold learning for image retrieval.",
                "In Proceedings of the ACM Conference on Multimedia, Singapore, November 2005. [12] Y. Rui, T. S. Huang, M. Ortega, and S. Mehrotra.",
                "<br>relevance feedback</br>: A power tool for interative content-based image retrieval.",
                "IEEE Transactions on Circuits and Systems for Video Technology, 8(5), 1998. [13] A. W. Smeulders, M. Worring, S. Santini, A. Gupta, and R. Jain.",
                "Content-based image retrieval at the end of the early years.",
                "IEEE Transactions on Pattern Analysis and Machine Intelligence, 22(12):1349-1380, 2000. [14] S. Tong and E. Chang.",
                "Support vector machine active learning for image retrieval.",
                "In Proceedings of the ninth ACM international conference on Multimedia, pages 107-118, 2001. [15] H. Yu, M. Li, H.-J.",
                "Zhang, and J. Feng.",
                "Color texture moments for content-based image retrieval.",
                "In International Conference on Image Processing, pages 24-28, 2002. [16] K. Yu, J. Bi, and V. Tresp.",
                "Active learning via transductive experimental design.",
                "In Proceedings of the 23rd International Conference on Machine Learning, Pittsburgh, PA, 2006."
            ],
            "original_annotated_samples": [
                "Burbank, CA 91504 hex@yahoo-inc.com Wanli Min IBM Yorktown Heights, NY 10598 wanlimin@us.ibm.com Deng Cai CS Dept., UIUC Urbana, IL 61801 dengcai2@cs.uiuc.edu Kun Zhou Microsoft Research Asia Beijing, China kunzhou@microsoft.com ABSTRACT <br>relevance feedback</br> is a powerful technique to enhance ContentBased Image Retrieval (CBIR) performance.",
                "In this paper, we propose a novel active learning algorithm, called Laplacian Optimal Design (LOD), for <br>relevance feedback</br> image retrieval.",
                "Experimental results on Corel database suggest that the proposed approach achieves higher precision in <br>relevance feedback</br> image retrieval.",
                "Categories and Subject Descriptors H.3.3 [Information storage and retrieval]: Information search and retrieval-<br>relevance feedback</br>; G.3 [Mathematics of Computing]: Probability and Statistics-Experimental design General Terms Algorithms, Performance, Theory 1.",
                "Particularly, we consider the problem of <br>relevance feedback</br> driven Content-Based Image Retrieval (CBIR) [13]."
            ],
            "translated_annotated_samples": [
                "El <br>feedback de relevancia</br> es una técnica poderosa para mejorar el rendimiento de la Recuperación de Imágenes Basada en Contenido (CBIR).",
                "En este artículo, proponemos un novedoso algoritmo de aprendizaje activo, llamado Diseño Óptimo Laplaciano (LOD), para la recuperación de imágenes con <br>retroalimentación de relevancia</br>.",
                "Los resultados experimentales en la base de datos Corel sugieren que el enfoque propuesto logra una mayor precisión en la recuperación de imágenes con <br>retroalimentación de relevancia</br>.",
                "Categorías y Descriptores de Asignaturas H.3.3 [Almacenamiento y recuperación de información]: Búsqueda y recuperación de información-Retroalimentación de relevancia; G.3 [Matemáticas de la Computación]: Probabilidad y Estadística-Diseño experimental Términos Generales Algoritmos, Rendimiento, Teoría 1.",
                "Particularmente, consideramos el problema de la recuperación de imágenes basada en contenido impulsada por la <br>retroalimentación de relevancia</br> (CBIR) [13]."
            ],
            "translated_text": "Diseño óptimo de Laplaciano para la recuperación de imágenes Xiaofei He Yahoo! El <br>feedback de relevancia</br> es una técnica poderosa para mejorar el rendimiento de la Recuperación de Imágenes Basada en Contenido (CBIR). Solicita las valoraciones de relevancia de los usuarios sobre las imágenes recuperadas por los sistemas CBIR. La etiqueta de los usuarios se utiliza luego para entrenar un clasificador que distinga entre imágenes relevantes e irrelevantes. Sin embargo, las imágenes principales que se devuelven pueden no ser las más informativas. El desafío consiste en determinar qué imágenes sin etiquetar serían las más informativas (es decir, mejorarían más al clasificador) si fueran etiquetadas y utilizadas como muestras de entrenamiento. En este artículo, proponemos un novedoso algoritmo de aprendizaje activo, llamado Diseño Óptimo Laplaciano (LOD), para la recuperación de imágenes con <br>retroalimentación de relevancia</br>. Nuestro algoritmo se basa en un modelo de regresión que minimiza el error cuadrático mínimo en las imágenes medidas (o etiquetadas) y al mismo tiempo preserva la estructura geométrica local del espacio de la imagen. Específicamente, asumimos que si dos imágenes están lo suficientemente cerca una de la otra, entonces sus medidas (o etiquetas) también son cercanas. Al construir un grafo de vecinos más cercanos, la estructura geométrica del espacio de la imagen puede ser descrita por el Laplaciano del grafo. Discutimos cómo los resultados del campo del diseño experimental óptimo pueden ser utilizados para guiar nuestra selección de un subconjunto de imágenes, que nos proporciona la mayor cantidad de información. Los resultados experimentales en la base de datos Corel sugieren que el enfoque propuesto logra una mayor precisión en la recuperación de imágenes con <br>retroalimentación de relevancia</br>. Categorías y Descriptores de Asignaturas H.3.3 [Almacenamiento y recuperación de información]: Búsqueda y recuperación de información-Retroalimentación de relevancia; G.3 [Matemáticas de la Computación]: Probabilidad y Estadística-Diseño experimental Términos Generales Algoritmos, Rendimiento, Teoría 1. INTRODUCCIÓN En muchas tareas de aprendizaje automático y recuperación de información, no hay escasez de datos no etiquetados pero las etiquetas son costosas. El desafío consiste en determinar qué muestras sin etiquetar serían las más informativas (es decir, mejorarían más el clasificador) si fueran etiquetadas y utilizadas como muestras de entrenamiento. Este problema se llama típicamente aprendizaje activo [4]. Aquí la tarea es minimizar un costo general, que depende tanto de la precisión del clasificador como del costo de la recolección de datos. Muchas aplicaciones del mundo real pueden ser adaptadas al marco de aprendizaje activo. Particularmente, consideramos el problema de la recuperación de imágenes basada en contenido impulsada por la <br>retroalimentación de relevancia</br> (CBIR) [13]. ",
            "candidates": [],
            "error": [
                [
                    "feedback de relevancia",
                    "retroalimentación de relevancia",
                    "retroalimentación de relevancia",
                    "retroalimentación de relevancia"
                ]
            ]
        },
        "image representation": {
            "translated_key": "representación de imágenes",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Laplacian Optimal Design for Image Retrieval Xiaofei He Yahoo!",
                "Burbank, CA 91504 hex@yahoo-inc.com Wanli Min IBM Yorktown Heights, NY 10598 wanlimin@us.ibm.com Deng Cai CS Dept., UIUC Urbana, IL 61801 dengcai2@cs.uiuc.edu Kun Zhou Microsoft Research Asia Beijing, China kunzhou@microsoft.com ABSTRACT Relevance feedback is a powerful technique to enhance ContentBased Image Retrieval (CBIR) performance.",
                "It solicits the users relevance judgments on the retrieved images returned by the CBIR systems.",
                "The users labeling is then used to learn a classifier to distinguish between relevant and irrelevant images.",
                "However, the top returned images may not be the most informative ones.",
                "The challenge is thus to determine which unlabeled images would be the most informative (i.e., improve the classifier the most) if they were labeled and used as training samples.",
                "In this paper, we propose a novel active learning algorithm, called Laplacian Optimal Design (LOD), for relevance feedback image retrieval.",
                "Our algorithm is based on a regression model which minimizes the least square error on the measured (or, labeled) images and simultaneously preserves the local geometrical structure of the image space.",
                "Specifically, we assume that if two images are sufficiently close to each other, then their measurements (or, labels) are close as well.",
                "By constructing a nearest neighbor graph, the geometrical structure of the image space can be described by the graph Laplacian.",
                "We discuss how results from the field of optimal experimental design may be used to guide our selection of a subset of images, which gives us the most amount of information.",
                "Experimental results on Corel database suggest that the proposed approach achieves higher precision in relevance feedback image retrieval.",
                "Categories and Subject Descriptors H.3.3 [Information storage and retrieval]: Information search and retrieval-Relevance feedback; G.3 [Mathematics of Computing]: Probability and Statistics-Experimental design General Terms Algorithms, Performance, Theory 1.",
                "INTRODUCTION In many machine learning and information retrieval tasks, there is no shortage of unlabeled data but labels are expensive.",
                "The challenge is thus to determine which unlabeled samples would be the most informative (i.e., improve the classifier the most) if they were labeled and used as training samples.",
                "This problem is typically called active learning [4].",
                "Here the task is to minimize an overall cost, which depends both on the classifier accuracy and the cost of data collection.",
                "Many real world applications can be casted into active learning framework.",
                "Particularly, we consider the problem of relevance feedback driven Content-Based Image Retrieval (CBIR) [13].",
                "Content-Based Image Retrieval has attracted substantial interests in the last decade [13].",
                "It is motivated by the fast growth of digital image databases which, in turn, require efficient search schemes.",
                "Rather than describe an image using text, in these systems an image query is described using one or more example images.",
                "The low level visual features (color, texture, shape, etc.) are automatically extracted to represent the images.",
                "However, the low level features may not accurately characterize the high level semantic concepts.",
                "To narrow down the semantic gap, relevance feedback is introduced into CBIR [12].",
                "In many of the current relevance feedback driven CBIR systems, the user is required to provide his/her relevance judgments on the top images returned by the system.",
                "The labeled images are then used to train a classifier to separate images that match the query concept from those that do not.",
                "However, in general the top returned images may not be the most informative ones.",
                "In the worst case, all the top images labeled by the user may be positive and thus the standard classification techniques can not be applied due to the lack of negative examples.",
                "Unlike the standard classification problems where the labeled samples are pregiven, in relevance feedback image retrieval the system can actively select the images to label.",
                "Thus active learning can be naturally introduced into image retrieval.",
                "Despite many existing active learning techniques, Support Vector Machine (SVM) active learning [14] and regression based active learning [1] have received the most interests.",
                "Based on the observation that the closer to the SVM boundary an image is, the less reliable its classification is, SVM active learning selects those unlabeled images closest to the boundary to solicit user feedback so as to achieve maximal refinement on the hyperplane between the two classes.",
                "The major disadvantage of SVM active learning is that the estimated boundary may not be accurate enough.",
                "Moreover, it may not be applied at the beginning of the retrieval when there is no labeled images.",
                "Some other SVM based active learning algorithms can be found in [7], [9].",
                "In statistics, the problem of selecting samples to label is typically referred to as experimental design.",
                "The sample x is referred to as experiment, and its label y is referred to as measurement.",
                "The study of optimal experimental design (OED) [1] is concerned with the design of experiments that are expected to minimize variances of a parameterized model.",
                "The intent of optimal experimental design is usually to maximize confidence in a given model, minimize parameter variances for system identification, or minimize the models output variance.",
                "Classical experimental design approaches include A-Optimal Design, D-Optimal Design, and E-Optimal Design.",
                "All of these approaches are based on a least squares regression model.",
                "Comparing to SVM based active learning algorithms, experimental design approaches are much more efficient in computation.",
                "However, this kind of approaches takes only measured (or, labeled) data into account in their objective function, while the unmeasured (or, unlabeled) data is ignored.",
                "Benefit from recent progresses on optimal experimental design and semi-supervised learning, in this paper we propose a novel active learning algorithm for image retrieval, called Laplacian Optimal Design (LOD).",
                "Unlike traditional experimental design methods whose loss functions are only defined on the measured points, the loss function of our proposed LOD algorithm is defined on both measured and unmeasured points.",
                "Specifically, we introduce a locality preserving regularizer into the standard least-square-error based loss function.",
                "The new loss function aims to find a classifier which is locally as smooth as possible.",
                "In other words, if two points are sufficiently close to each other in the input space, then they are expected to share the same label.",
                "Once the loss function is defined, we can select the most informative data points which are presented to the user for labeling.",
                "It would be important to note that the most informative images may not be the top returned images.",
                "The rest of the paper is organized as follows.",
                "In Section 2, we provide a brief description of the related work.",
                "Our proposed Laplacian Optimal Design algorithm is introduced in Section 3.",
                "In Section 4, we compare our algorithm with the state-or-the-art algorithms and present the experimental results on image retrieval.",
                "Finally, we provide some concluding remarks and suggestions for future work in Section 5. 2.",
                "RELATED WORK Since our proposed algorithm is based on regression framework.",
                "The most related work is optimal experimental design [1], including A-Optimal Design, D-Optimal Design, and EOptimal Design.",
                "In this Section, we give a brief description of these approaches. 2.1 The Active Learning Problem The generic problem of active learning is the following.",
                "Given a set of points A = {x1, x2, · · · , xm} in Rd , find a subset B = {z1, z2, · · · , zk} ⊂ A which contains the most informative points.",
                "In other words, the points zi(i = 1, · · · , k) can improve the classifier the most if they are labeled and used as training points. 2.2 Optimal Experimental Design We consider a linear regression model y = wT x + (1) where y is the observation, x is the independent variable, w is the weight vector and is an unknown error with zero mean.",
                "Different observations have errors that are independent, but with equal variances σ2 .",
                "We define f(x) = wT x to be the learners output given input x and the weight vector w. Suppose we have a set of labeled sample points (z1, y1), · · · , (zk, yk), where yi is the label of zi.",
                "Thus, the maximum likelihood estimate for the weight vector, ˆw, is that which minimizes the sum squared error Jsse(w) = k i=1 wT zi − yi 2 (2) The estimate ˆw gives us an estimate of the output at a novel input: ˆy = ˆwT x.",
                "By Gauss-Markov theorem, we know that ˆw − w has a zero mean and a covariance matrix given by σ2 H−1 sse, where Hsse is the Hessian of Jsse(w) Hsse = ∂2 Jsse ∂w2 = k i=1 zizT i = ZZT where Z = (z1, z2, · · · , zk).",
                "The three most common scalar measures of the size of the parameter covariance matrix in optimal experimental design are: • D-optimal design: determinant of Hsse. • A-optimal design: trace of Hsse. • E-optimal design: maximum eigenvalue of Hsse.",
                "Since the computation of the determinant and eigenvalues of a matrix is much more expensive than the computation of matrix trace, A-optimal design is more efficient than the other two.",
                "Some recent work on experimental design can be found in [6], [16]. 3.",
                "LAPLACIAN OPTIMAL DESIGN Since the covariance matrix Hsse used in traditional approaches is only dependent on the measured samples, i.e. zis, these approaches fail to evaluate the expected errors on the unmeasured samples.",
                "In this Section, we introduce a novel active learning algorithm called Laplacian Optimal Design (LOD) which makes efficient use of both measured (labeled) and unmeasured (unlabeled) samples. 3.1 The Objective Function In many machine learning problems, it is natural to assume that if two points xi, xj are sufficiently close to each other, then their measurements (f(xi), f(xj)) are close as well.",
                "Let S be a similarity matrix.",
                "Thus, a new loss function which respects the geometrical structure of the data space can be defined as follows: J0(w) = k i=1 f(zi)−yi 2 + λ 2 m i,j=1 f(xi)−f(xj) 2 Sij (3) where yi is the measurement (or, label) of zi.",
                "Note that, the loss function (3) is essentially the same as the one used in Laplacian Regularized Regression (LRR, [2]).",
                "However, LRR is a passive learning algorithm where the training data is given.",
                "In this paper, we are focused on how to select the most informative data for training.",
                "The loss function with our choice of symmetric weights Sij (Sij = Sji) incurs a heavy penalty if neighboring points xi and xj are mapped far apart.",
                "Therefore, minimizing J0(w) is an attempt to ensure that if xi and xj are close then f(xi) and f(xj) are close as well.",
                "There are many choices of the similarity matrix S. A simple definition is as follows: Sij = ⎧ ⎨ ⎩ 1, if xi is among the p nearest neighbors of xj, or xj is among the p nearest neighbors of xi; 0, otherwise. (4) Let D be a diagonal matrix, Dii = j Sij, and L = D−S.",
                "The matrix L is called graph Laplacian in spectral graph theory [3].",
                "Let y = (y1, · · · , yk)T and X = (x1, · · · , xm).",
                "Following some simple algebraic steps, we see that: J0(w) = k i=1 wT zi − yi 2 + λ 2 m i,j=1 wT xi − wT xj 2 Sij = y − ZT w T y − ZT w + λwT m i=1 DiixixT i − m i,j=1 SijxixT j w = yT y − 2wT Zy + wT ZZT w +λwT XDXT − XSXT w = yT y − 2wT Zy + wT ZZT + λXLXT w The Hessian of J0(w) can be computed as follows: H0 = ∂2 J0 ∂w2 = ZZT + λXLXT In some cases, the matrix ZZT +λXLXT is singular (e.g. if m < d).",
                "Thus, there is no stable solution to the optimization problem Eq. (3).",
                "A common way to deal with this ill-posed problem is to introduce a Tikhonov regularizer into our loss function: J(w) = k i=1 wT zi − yi 2 + λ1 2 m i,j=1 wT xi − wT xj 2 Sij +λ2 w 2 (5) The Hessian of the new loss function is given by: H = ∂2 J ∂w2 = ZZT + λ1XLXT + λ2I := ZZT + Λ where I is an identity matrix and Λ = λ1XLXT + λ2I.",
                "Clearly, H is of full rank.",
                "Requiring that the gradient of J(w) with respect to w vanish gives the optimal estimate ˆw: ˆw = H−1 Zy The following proposition states the bias and variance properties of the estimator for the coefficient vector w. Proposition 3.1.",
                "E( ˆw − w) = −H−1 Λw, Cov( ˆw) = σ2 (H−1 − H−1 ΛH−1 ) Proof.",
                "Since y = ZT w + and E( ) = 0, it follows that E( ˆw − w) (6) = H−1 ZZT w − w = H−1 (ZZT + Λ − Λ)w − w = (I − H−1 Λ)w − w = −H−1 Λw (7) Notice Cov(y) = σ2 I, the covariance matrix of ˆw has the expression: Cov( ˆw) = H−1 ZCov(y)ZT H−1 = σ2 H−1 ZZT H−1 = σ2 H−1 (H − Λ)H−1 = σ2 (H−1 − H−1 ΛH−1 ) (8) Therefore mean squared error matrix for the coefficients w is E(w − ˆw)(w − ˆw)T (9) = H−1 ΛwwT ΛH−1 + σ2 (H−1 − H−1 ΛH−1 ) (10) For any x, let ˆy = ˆwT x be its predicted observation.",
                "The expected squared prediction error is E(y − ˆy)2 = E( + wT x − ˆwT x)2 = σ2 + xT [E(w − ˆw)(w − ˆw)T ]x = σ2 + xT [H−1 ΛwwT ΛH−1 + σ2 H−1 − σ2 H−1 ΛH−1 ]x Clearly the expected square prediction error depends on the explanatory variable x, therefore average expected square predictive error over the complete data set A is 1 m m i=1 E(yi − ˆwT xi)2 = 1 m m i=1 xT i [H−1 ΛwwT ΛH−1 + σ2 H−1 − σ2 H−1 ΛH−1 ]xi +σ2 = 1 m Tr(XT [σ2 H−1 + H−1 ΛwwT ΛH−1 − σ2 H−1 ΛH−1 ]X) +σ2 Since Tr(XT [H−1 ΛwwT ΛH−1 − σ2 H−1 ΛH−1 ]X) Tr(σ2 XT H−1 X), Our Laplacian optimality criterion is thus formulated by minimizing the trace of XT H−1 X.",
                "Definition 1.",
                "Laplacian Optimal Design min Z=(z1,··· ,zk) Tr XT ZZT + λ1XLXT + λ2I −1 X (11) where z1, · · · , zk are selected from {x1, · · · , xm}. 4.",
                "KERNEL LAPLACIAN OPTIMAL DESIGN Canonical experimental design approaches (e.g.",
                "A-Optimal Design, D-Optimal Design, and E-Optimal) only consider linear functions.",
                "They fail to discover the intrinsic geometry in the data when the data space is highly nonlinear.",
                "In this section, we describe how to perform Laplacian Experimental Design in Reproducing Kernel Hilbert Space (RKHS) which gives rise to Kernel Laplacian Experimental Design (KLOD).",
                "For given data points x1, · · · , xm ∈ X with a positive definite mercer kernel K : X ×X → R, there exists a unique RKHS HK of real valued functions on X.",
                "Let Kt(s) be the function of s obtained by fixing t and letting Kt(s) . = K(s, t).",
                "HK consists of all finite linear combinations of the form l i=1 αiKti with ti ∈ X and limits of such functions as the ti become dense in X.",
                "We have Ks, Kt HK = K(s, t). 4.1 Derivation of LOD in Reproducing Kernel Hilbert Space Consider the optimization problem (5) in RKHS.",
                "Thus, we seek a function f ∈ HK such that the following objective function is minimized: min f∈HK k i=1 f(zi)−yi 2 + λ1 2 m i,j=1 f(xi)−f(xj) 2 Sij+λ2 f 2 HK (12) We have the following proposition.",
                "Proposition 4.1.",
                "Let H = { m i=1 αiK(·, xi)|αi ∈ R} be a subspace of HK , the solution to the problem (12) is in H. Proof.",
                "Let H⊥ be the orthogonal complement of H, i.e.",
                "HK = H ⊕ H⊥ .",
                "Thus, for any function f ∈ HK , it has orthogonal decomposition as follows: f = fH + fH⊥ Now, lets evaluate f at xi: f(xi) = f, Kxi HK = fH + fH⊥ , Kxi HK = fH, Kxi HK + fH⊥ , Kxi HK Notice that Kxi ∈ H while fH⊥ ∈ H⊥ .",
                "This implies that fH⊥ , Kxi HK = 0.",
                "Therefore, f(xi) = fH, Kxi HK = fH(xi) This completes the proof.",
                "Proposition 4.1 tells us the minimizer of problem (12) admits a representation f∗ = m i=1 αiK(·, xi).",
                "Please see [2] for the details.",
                "Let φ : Rd → H be a feature map from the input space Rd to H, and K(xi, xj) =< φ(xi), φ(xj) >.",
                "Let X denote the data matrix in RKHS, X = (φ(x1), φ(x2), · · · , φ(xm)).",
                "Similarly, we define Z = (φ(z1), φ(z2), · · · , φ(zk)).",
                "Thus, the optimization problem in RKHS can be written as follows: min Z Tr XT ZZT + λ1XLXT + λ2I −1 X (13) Since the mapping function φ is generally unknown, there is no direct way to solve problem (13).",
                "In the following, we apply kernel tricks to solve this optimization problem.",
                "Let X−1 be the Moore-Penrose inverse (also known as pseudo inverse) of X.",
                "Thus, we have: XT ZZT + λ1XLXT + λ2I −1 X = XT XX−1 ZZT + λ1XLXT + λ2I −1 (XT )−1 XT X = XT X ZZT X + λ1XLXT X + λ2X −1 (XT )−1 XT X = XT X XT ZZT X + λ1XT XLXT X + λ2XT X −1 XT X = KXX KXZKZX + λ1KXXLKXX + λ2KXX −1 KXX where KXX is a m × m matrix (KXX,ij = K(xi, xj)), KXZ is a m×k matrix (KXZ,ij = K(xi, zj)), and KZX is a k×m matrix (KZX,ij = K(zi, xj)).",
                "Thus, the Kernel Laplacian Optimal Design can be defined as follows: Definition 2.",
                "Kernel Laplacian Optimal Design minZ=(z1,··· ,zk) Tr KXX KXZKZX + λ1KXXLKXX λ2KXX −1 KXX (14) 4.2 Optimization Scheme In this subsection, we discuss how to solve the optimization problems (11) and (14).",
                "Particularly, if we select a linear kernel for KLOD, then it reduces to LOD.",
                "Therefore, we will focus on problem (14) in the following.",
                "It can be shown that the optimization problem (14) is NP-hard.",
                "In this subsection, we develop a simple sequential greedy approach to solve (14).",
                "Suppose n points have been selected, denoted by a matrix Zn = (z1, · · · , zn).",
                "The (n + 1)-th point zn+1 can be selected by solving the following optimization problem: max Zn+1=(Zn,zn+1) Tr KXX KXZn+1 KZn+1X + λ1KXXLKXX + λ2KXX −1 KXX (15) The kernel matrices KXZn+1 and KZn+1X can be rewritten as follows: KXZn+1 = KXZn , KXzn+1 , KZn+1X = KZnX Kzn+1X Thus, we have: KXZn+1 KZn+1X = KXZn KZnX + KXzn+1 Kzn+1X We define: A = KXZn KZnX + λ1KXXLKXX + λ2KXX A is only dependent on X and Zn .",
                "Thus, the (n + 1)-th point zn+1 is given by: zn+1 = arg min zn+1 Tr KXX A + KXzn+1 Kzn+1X −1 KXX (16) Each time we select a new point zn+1, the matrix A is updated by: A ← A + KXzn+1 Kzn+1X If the kernel function is chosen as inner product K(x, y) = x, y , then HK is a linear functional space and the algorithm reduces to LOD. 5.",
                "CONTENT-BASED IMAGE RETRIEVAL USING LAPLACIAN OPTIMAL DESIGN In this section, we describe how to apply Laplacian Optimal Design to CBIR.",
                "We begin with a brief description of <br>image representation</br> using low level visual features. 5.1 Low-Level <br>image representation</br> Low-level image representation is a crucial problem in CBIR.",
                "General visual features includes color, texture, shape, etc.",
                "Color and texture features are the most extensively used visual features in CBIR.",
                "Compared with color and texture features, shape features are usually described after images have been segmented into regions or objects.",
                "Since robust and accurate image segmentation is difficult to achieve, the use of shape features for image retrieval has been limited to special applications where objects or regions are readily available.",
                "In this work, We combine 64-dimensional color histogram and 64-dimensional Color Texture Moment (CTM, [15]) to represent the images.",
                "The color histogram is calculated using 4 × 4 × 4 bins in HSV space.",
                "The Color Texture Moment is proposed by Yu et al. [15], which integrates the color and texture characteristics of the image in a compact form.",
                "CTM adopts local Fourier transform as a texture representation scheme and derives eight characteristic maps to describe different aspects of co-occurrence relations of image pixels in each channel of the (SVcosH, SVsinH, V) color space.",
                "Then CTM calculates the first and second moment of these maps as a representation of the natural color image pixel distribution.",
                "Please see [15] for details. 5.2 Relevance Feedback Image Retrieval Relevance feedback is one of the most important techniques to narrow down the gap between low level visual features and high level semantic concepts [12].",
                "Traditionally, the users relevance feedbacks are used to update the query vector or adjust the weighting of different dimensions.",
                "This process can be viewed as an on-line learning process in which the image retrieval system acts as a learner and the user acts as a teacher.",
                "They typical retrieval process is outlined as follows: 1.",
                "The user submits a query image example to the system.",
                "The system ranks the images in database according to some pre-defined distance metric and presents to the user the top ranked images. 2.",
                "The system selects some images from the database and request the user to label them as relevant or irrelevant. 3.",
                "The system uses the users provided information to rerank the images in database and returns to the user the top images.",
                "Go to step 2 until the user is satisfied.",
                "Our Laplacian Optimal Design algorithm is applied in the second step for selecting the most informative images.",
                "Once we get the labels for the images selected by LOD, we apply Laplacian Regularized Regression (LRR, [2]) to solve the optimization problem (3) and build the classifier.",
                "The classifier is then used to re-rank the images in database.",
                "Note that, in order to reduce the computational complexity, we do not use all the unlabeled images in the database but only those within top 500 returns of previous iteration. 6.",
                "EXPERIMENTAL RESULTS In this section, we evaluate the performance of our proposed algorithm on a large image database.",
                "To demonstrate the effectiveness of our proposed LOD algorithm, we compare it with Laplacian Regularized Regression (LRR, [2]), Support Vector Machine (SVM), Support Vector Machine Active Learning (SVMactive) [14], and A-Optimal Design (AOD).",
                "Both SVMactive, AOD, and LOD are active learning algorithms, while LRR and SVM are standard classification algorithms.",
                "SVM only makes use of the labeled images, while LRR is a semi-supervised learning algorithm which makes use of both labeled and unlabeled images.",
                "For SVMactive, AOD, and LOD, 10 training images are selected by the algorithms themselves at each iteration.",
                "While for LRR and SVM, we use the top 10 images as training data.",
                "It would be important to note that SVMactive is based on the ordinary SVM, LOD is based on LRR, and AOD is based on the ordinary regression.",
                "The parameters λ1 and λ2 in our LOD algorithm are empirically set to be 0.001 and 0.00001.",
                "For both LRR and LOD algorithms, we use the same graph structure (see Eq. 4) and set the value of p (number of nearest neighbors) to be 5.",
                "We begin with a simple synthetic example to give some intuition about how LOD works. 6.1 Simple Synthetic Example A simple synthetic example is given in Figure 1.",
                "The data set contains two circles.",
                "Eight points are selected by AOD and LOD.",
                "As can be seen, all the points selected by AOD are from the big circle, while LOD selects four points from the big circle and four from the small circle.",
                "The numbers beside the selected points denote their orders to be selected.",
                "Clearly, the points selected by our LOD algorithm can better represent the original data set.",
                "We did not compare our algorithm with SVMactive because SVMactive can not be applied in this case due to the lack of the labeled points. 6.2 Image Retrieval Experimental Design The image database we used consists of 7,900 images of 79 semantic categories, from COREL data set.",
                "It is a large and heterogeneous image set.",
                "Each image is represented as a 128-dimensional vector as described in Section 5.1.",
                "Figure 2 shows some sample images.",
                "To exhibit the advantages of using our algorithm, we need a reliable way of evaluating the retrieval performance and the comparisons with other algorithms.",
                "We list different aspects of the experimental design below. 6.2.1 Evaluation Metrics We use precision-scope curve and precision rate [10] to evaluate the effectiveness of the image retrieval algorithms.",
                "The scope is specified by the number (N) of top-ranked images presented to the user.",
                "The precision is the ratio of the number of relevant images presented to the user to the (a) Data set 1 2 3 4 5 6 7 8 (b) AOD 1 2 3 4 5 6 7 8 (c) LOD Figure 1: Data selection by active learning algorithms.",
                "The numbers beside the selected points denote their orders to be selected.",
                "Clearly, the points selected by our LOD algorithm can better represent the original data set.",
                "Note that, the SVMactive algorithm can not be applied in this case due to the lack of labeled points. (a) (b) (c) Figure 2: Sample images from category bead, elephant, and ship. scope N. The precision-scope curve describes the precision with various scopes and thus gives an overall performance evaluation of the algorithms.",
                "On the other hand, the precision rate emphasizes the precision at a particular value of scope.",
                "In general, it is appropriate to present 20 images on a screen.",
                "Putting more images on a screen may affect the quality of the presented images.",
                "Therefore, the precision at top 20 (N = 20) is especially important.",
                "In real world image retrieval systems, the query image is usually not in the image database.",
                "To simulate such environment, we use five-fold cross validation to evaluate the algorithms.",
                "More precisely, we divide the whole image database into five subsets with equal size.",
                "Thus, there are 20 images per category in each subset.",
                "At each run of cross validation, one subset is selected as the query set, and the other four subsets are used as the database for retrieval.",
                "The precisionscope curve and precision rate are computed by averaging the results from the five-fold cross validation. 6.2.2 Automatic Relevance Feedback Scheme We designed an automatic feedback scheme to model the retrieval process.",
                "For each submitted query, our system retrieves and ranks the images in the database. 10 images were selected from the database for user labeling and the label information is used by the system for re-ranking.",
                "Note that, the images which have been selected at previous iterations are excluded from later selections.",
                "For each query, the automatic relevance feedback mechanism is performed for four iterations.",
                "It is important to note that the automatic relevance feedback scheme used here is different from the ones described in [8], [11].",
                "In [8], [11], the top four relevant and irrelevant images were selected as the feedback images.",
                "However, this may not be practical.",
                "In real world image retrieval systems, it is possible that most of the top-ranked images are relevant (or, irrelevant).",
                "Thus, it is difficult for the user to find both four relevant and irrelevant images.",
                "It is more reasonable for the users to provide feedback information only on the 10 images selected by the system. 6.3 Image Retrieval Performance In real world, it is not practical to require the user to provide many rounds of feedbacks.",
                "The retrieval performance after the first two rounds of feedbacks (especially the first round) is more important.",
                "Figure 3 shows the average precision-scope curves of the different algorithms for the first two feedback iterations.",
                "At the beginning of retrieval, the Euclidean distances in the original 128-dimensional space are used to rank the images in database.",
                "After the user provides relevance feedbacks, the LRR, SVM, SVMactive, AOD, and LOD algorithms are then applied to re-rank the images.",
                "In order to reduce the time complexity of active learning algorithms, we didnt select the most informative images from the whole database but from the top 500 images.",
                "For LRR and SVM, the user is required to label the top 10 images.",
                "For SVMactive, AOD, and LOD, the user is required to label 10 most informative images selected by these algorithms.",
                "Note that, SVMactive can only be ap(a) Feedback Iteration 1 (b) Feedback Iteration 2 Figure 3: The average precision-scope curves of different algorithms for the first two feedback iterations.",
                "The LOD algorithm performs the best on the entire scope.",
                "Note that, at the first round of feedback, the SVMactive algorithm can not be applied.",
                "It applies the ordinary SVM to build the initial classifier. (a) Precision at Top 10 (b) Precision at Top 20 (c) Precision at Top 30 Figure 4: Performance evaluation of the five learning algorithms for relevance feedback image retrieval. (a) Precision at top 10, (b) Precision at top 20, and (c) Precision at top 30.",
                "As can be seen, our LOD algorithm consistently outperforms the other four algorithms. plied when the classifier is already built.",
                "Therefore, it can not be applied at the first round and we use the standard SVM to build the initial classifier.",
                "As can be seen, our LOD algorithm outperforms the other four algorithms on the entire scope.",
                "Also, the LRR algorithm performs better than SVM.",
                "This is because that the LRR algorithm makes efficient use of the unlabeled images by incorporating a locality preserving regularizer into the ordinary regression objective function.",
                "The AOD algorithm performs the worst.",
                "As the scope gets larger, the performance difference between these algorithms gets smaller.",
                "By iteratively adding the users feedbacks, the corresponding precision results (at top 10, top 20, and top 30) of the five algorithms are respectively shown in Figure 4.",
                "As can be seen, our LOD algorithm performs the best in all the cases and the LRR algorithm performs the second best.",
                "Both of these two algorithms make use of the unlabeled images.",
                "This shows that the unlabeled images are helpful for discovering the intrinsic geometrical structure of the image space and therefore enhance the retrieval performance.",
                "In real world, the user may not be willing to provide too many relevance feedbacks.",
                "Therefore, the retrieval performance at the first two rounds are especially important.",
                "As can be seen, our LOD algorithm achieves 6.8% performance improvement for top 10 results, 5.2% for top 20 results, and 4.1% for top 30 results, comparing to the second best algorithm (LRR) after the first two rounds of relevance feedbacks. 6.4 Discussion Several experiments on Corel database have been systematically performed.",
                "We would like to highlight several interesting points: 1.",
                "It is clear that the use of active learning is beneficial in the image retrieval domain.",
                "There is a significant increase in performance from using the active learning methods.",
                "Especially, out of the three active learning methods (SVMactive, AOD, LOD), our proposed LOD algorithm performs the best. 2.",
                "In many real world applications like relevance feedback image retrieval, there are generally two ways of reducing labor-intensive manual labeling task.",
                "One is active learning which selects the most informative samples to label, and the other is semi-supervised learning which makes use of the unlabeled samples to enhance the learning performance.",
                "Both of these two strategies have been studied extensively in the past [14], [7], [5], [8].",
                "The work presented in this paper is focused on active learning, but it also takes advantage of the recent progresses on semi-supervised learning [2].",
                "Specifically, we incorporate a locality preserving regularizer into the standard regression framework and find the most informative samples with respect to the new objective function.",
                "In this way, the active learning and semi-supervised learning techniques are seamlessly unified for learning an optimal classifier. 3.",
                "The relevance feedback technique is crucial to image retrieval.",
                "For all the five algorithms, the retrieval performance improves with more feedbacks provided by the user. 7.",
                "CONCLUSIONS AND FUTURE WORK This paper describes a novel active learning algorithm, called Laplacian Optimal Design, to enable more effective relevance feedback image retrieval.",
                "Our algorithm is based on an objective function which simultaneously minimizes the empirical error and preserves the local geometrical structure of the data space.",
                "Using techniques from experimental design, our algorithm finds the most informative images to label.",
                "These labeled images and the unlabeled images in the database are used to learn a classifier.",
                "The experimental results on Corel database show that both active learning and semi-supervised learning can significantly improve the retrieval performance.",
                "In this paper, we consider the image retrieval problem on a small, static, and closed-domain image data.",
                "A much more challenging domain is the World Wide Web (WWW).",
                "For Web image search, it is possible to collect a large amount of user click information.",
                "This information can be naturally used to construct the affinity graph in our algorithm.",
                "However, the computational complexity in Web scenario may become a crucial issue.",
                "Also, although our primary interest in this paper is focused on relevance feedback image retrieval, our results may also be of interest to researchers in patten recognition and machine learning, especially when a large amount of data is available but only a limited samples can be labeled. 8.",
                "REFERENCES [1] A. C. Atkinson and A. N. Donev.",
                "Optimum Experimental Designs.",
                "Oxford University Press, 2002. [2] M. Belkin, P. Niyogi, and V. Sindhwani.",
                "Manifold regularization: A geometric framework for learning from examples.",
                "Journal of Machine Learning Research, 7:2399-2434, 2006. [3] F. R. K. Chung.",
                "Spectral Graph Theory, volume 92 of Regional Conference Series in Mathematics.",
                "AMS, 1997. [4] D. A. Cohn, Z. Ghahramani, and M. I. Jordan.",
                "Active learning with statistical models.",
                "Journal of Artificial Intelligence Research, 4:129-145, 1996. [5] A. Dong and B. Bhanu.",
                "A new semi-supervised em algorithm for image retrieval.",
                "In IEEE Conf. on Computer Vision and Pattern Recognition, Madison, WI, 2003. [6] P. Flaherty, M. I. Jordan, and A. P. Arkin.",
                "Robust design of biological experiments.",
                "In Advances in Neural Information Processing Systems 18, Vancouver, Canada, 2005. [7] K.-S. Goh, E. Y. Chang, and W.-C. Lai.",
                "Multimodal concept-dependent active learning for image retrieval.",
                "In Proceedings of the ACM Conference on Multimedia, New York, October 2004. [8] X.",
                "He.",
                "Incremental semi-supervised subspace learning for image retrieval.",
                "In Proceedings of the ACM Conference on Multimedia, New York, October 2004. [9] S. C. Hoi and M. R. Lyu.",
                "A semi-supervised active learning framework for image retrieval.",
                "In IEEE International Conference on Computer Vision and Pattern Recognition, San Diego, CA, 2005. [10] D. P. Huijsmans and N. Sebe.",
                "How to complete performance graphs in content-based image retrieval: Add generality and normalize scope.",
                "IEEE Transactions on Pattern Analysis and Machine Intelligence, 27(2):245-251, 2005. [11] Y.-Y.",
                "Lin, T.-L. Liu, and H.-T. Chen.",
                "Semantic manifold learning for image retrieval.",
                "In Proceedings of the ACM Conference on Multimedia, Singapore, November 2005. [12] Y. Rui, T. S. Huang, M. Ortega, and S. Mehrotra.",
                "Relevance feedback: A power tool for interative content-based image retrieval.",
                "IEEE Transactions on Circuits and Systems for Video Technology, 8(5), 1998. [13] A. W. Smeulders, M. Worring, S. Santini, A. Gupta, and R. Jain.",
                "Content-based image retrieval at the end of the early years.",
                "IEEE Transactions on Pattern Analysis and Machine Intelligence, 22(12):1349-1380, 2000. [14] S. Tong and E. Chang.",
                "Support vector machine active learning for image retrieval.",
                "In Proceedings of the ninth ACM international conference on Multimedia, pages 107-118, 2001. [15] H. Yu, M. Li, H.-J.",
                "Zhang, and J. Feng.",
                "Color texture moments for content-based image retrieval.",
                "In International Conference on Image Processing, pages 24-28, 2002. [16] K. Yu, J. Bi, and V. Tresp.",
                "Active learning via transductive experimental design.",
                "In Proceedings of the 23rd International Conference on Machine Learning, Pittsburgh, PA, 2006."
            ],
            "original_annotated_samples": [
                "We begin with a brief description of <br>image representation</br> using low level visual features. 5.1 Low-Level <br>image representation</br> Low-level image representation is a crucial problem in CBIR."
            ],
            "translated_annotated_samples": [
                "Comenzamos con una breve descripción de la <br>representación de imágenes</br> utilizando características visuales de nivel bajo. 5.1 Representación de Imágenes de Nivel Bajo La <br>representación de imágenes</br> de nivel bajo es un problema crucial en la Recuperación de Información Basada en el Contenido (CBIR)."
            ],
            "translated_text": "Diseño óptimo de Laplaciano para la recuperación de imágenes Xiaofei He Yahoo! El feedback de relevancia es una técnica poderosa para mejorar el rendimiento de la Recuperación de Imágenes Basada en Contenido (CBIR). Solicita las valoraciones de relevancia de los usuarios sobre las imágenes recuperadas por los sistemas CBIR. La etiqueta de los usuarios se utiliza luego para entrenar un clasificador que distinga entre imágenes relevantes e irrelevantes. Sin embargo, las imágenes principales que se devuelven pueden no ser las más informativas. El desafío consiste en determinar qué imágenes sin etiquetar serían las más informativas (es decir, mejorarían más al clasificador) si fueran etiquetadas y utilizadas como muestras de entrenamiento. En este artículo, proponemos un novedoso algoritmo de aprendizaje activo, llamado Diseño Óptimo Laplaciano (LOD), para la recuperación de imágenes con retroalimentación de relevancia. Nuestro algoritmo se basa en un modelo de regresión que minimiza el error cuadrático mínimo en las imágenes medidas (o etiquetadas) y al mismo tiempo preserva la estructura geométrica local del espacio de la imagen. Específicamente, asumimos que si dos imágenes están lo suficientemente cerca una de la otra, entonces sus medidas (o etiquetas) también son cercanas. Al construir un grafo de vecinos más cercanos, la estructura geométrica del espacio de la imagen puede ser descrita por el Laplaciano del grafo. Discutimos cómo los resultados del campo del diseño experimental óptimo pueden ser utilizados para guiar nuestra selección de un subconjunto de imágenes, que nos proporciona la mayor cantidad de información. Los resultados experimentales en la base de datos Corel sugieren que el enfoque propuesto logra una mayor precisión en la recuperación de imágenes con retroalimentación de relevancia. Categorías y Descriptores de Asignaturas H.3.3 [Almacenamiento y recuperación de información]: Búsqueda y recuperación de información-Retroalimentación de relevancia; G.3 [Matemáticas de la Computación]: Probabilidad y Estadística-Diseño experimental Términos Generales Algoritmos, Rendimiento, Teoría 1. INTRODUCCIÓN En muchas tareas de aprendizaje automático y recuperación de información, no hay escasez de datos no etiquetados pero las etiquetas son costosas. El desafío consiste en determinar qué muestras sin etiquetar serían las más informativas (es decir, mejorarían más el clasificador) si fueran etiquetadas y utilizadas como muestras de entrenamiento. Este problema se llama típicamente aprendizaje activo [4]. Aquí la tarea es minimizar un costo general, que depende tanto de la precisión del clasificador como del costo de la recolección de datos. Muchas aplicaciones del mundo real pueden ser adaptadas al marco de aprendizaje activo. Particularmente, consideramos el problema de la recuperación de imágenes basada en contenido impulsada por la retroalimentación de relevancia (CBIR) [13]. La Recuperación de Imágenes Basada en Contenido ha atraído un interés sustancial en la última década [13]. Está motivado por el rápido crecimiento de las bases de datos de imágenes digitales que, a su vez, requieren esquemas de búsqueda eficientes. En lugar de describir una imagen usando texto, en estos sistemas se describe una consulta de imagen utilizando una o más imágenes de ejemplo. Las características visuales de bajo nivel (color, textura, forma, etc.) se extraen automáticamente para representar las imágenes. Sin embargo, las características de bajo nivel pueden no caracterizar con precisión los conceptos semánticos de alto nivel. Para reducir la brecha semántica, se introduce la retroalimentación de relevancia en la recuperación de información basada en el contenido (CBIR) [12]. En muchos de los sistemas actuales de recuperación de imágenes basados en retroalimentación de relevancia, se requiere que el usuario proporcione sus juicios de relevancia sobre las imágenes principales devueltas por el sistema. Las imágenes etiquetadas se utilizan luego para entrenar un clasificador que separe las imágenes que coinciden con el concepto de la consulta de aquellas que no lo hacen. Sin embargo, en general, las imágenes principales que se devuelven pueden no ser las más informativas. En el peor de los casos, todas las imágenes principales etiquetadas por el usuario pueden ser positivas y, por lo tanto, las técnicas estándar de clasificación no pueden aplicarse debido a la falta de ejemplos negativos. A diferencia de los problemas de clasificación estándar donde las muestras etiquetadas están predefinidas, en la recuperación de imágenes con retroalimentación de relevancia, el sistema puede seleccionar activamente las imágenes a etiquetar. Por lo tanto, el aprendizaje activo puede ser introducido de forma natural en la recuperación de imágenes. A pesar de la existencia de muchas técnicas de aprendizaje activo, el aprendizaje activo de Máquina de Vectores de Soporte (SVM) [14] y el aprendizaje activo basado en regresión [1] han sido los que han despertado mayor interés. Basado en la observación de que cuanto más cerca del límite del SVM se encuentre una imagen, menos confiable es su clasificación, el aprendizaje activo del SVM selecciona aquellas imágenes no etiquetadas más cercanas al límite para solicitar retroalimentación del usuario con el fin de lograr un refinamiento máximo en el hiperplano entre las dos clases. La principal desventaja del aprendizaje activo de SVM es que es posible que el límite estimado no sea lo suficientemente preciso. Además, puede que no se aplique al principio de la recuperación cuando no hay imágenes etiquetadas. Algunos otros algoritmos de aprendizaje activo basados en SVM se pueden encontrar en [7], [9]. En estadística, el problema de seleccionar muestras para etiquetar se conoce típicamente como diseño experimental. La muestra x se denomina experimento, y su etiqueta y se denomina medición. El estudio del diseño experimental óptimo (DEO) se preocupa por el diseño de experimentos que se espera que minimicen las varianzas de un modelo parametrizado. La intención del diseño experimental óptimo suele ser maximizar la confianza en un modelo dado, minimizar las varianzas de los parámetros para la identificación del sistema, o minimizar la varianza de la salida de los modelos. Los enfoques clásicos de diseño experimental incluyen el Diseño A-Óptimo, el Diseño D-Óptimo y el Diseño E-Óptimo. Todos estos enfoques se basan en un modelo de regresión de mínimos cuadrados. En comparación con los algoritmos de aprendizaje activo basados en SVM, los enfoques de diseño experimental son mucho más eficientes en términos de computación. Sin embargo, este tipo de enfoques solo tienen en cuenta los datos medidos (o etiquetados) en su función objetivo, mientras que los datos no medidos (o no etiquetados) son ignorados. Beneficiar de los avances recientes en diseño experimental óptimo y aprendizaje semisupervisado, en este artículo proponemos un nuevo algoritmo de aprendizaje activo para recuperación de imágenes, llamado Diseño Óptimo Laplaciano (LOD). A diferencia de los métodos tradicionales de diseño experimental cuyas funciones de pérdida solo están definidas en los puntos medidos, la función de pérdida de nuestro algoritmo propuesto LOD está definida tanto en los puntos medidos como en los no medidos. Específicamente, introducimos un regularizador que preserva la localidad en la función de pérdida estándar basada en el error cuadrático mínimo. La nueva función de pérdida tiene como objetivo encontrar un clasificador que sea localmente lo más suave posible. En otras palabras, si dos puntos están suficientemente cerca uno del otro en el espacio de entrada, se espera que compartan la misma etiqueta. Una vez que se define la función de pérdida, podemos seleccionar los puntos de datos más informativos que se presentan al usuario para su etiquetado. Sería importante tener en cuenta que las imágenes más informativas pueden no ser las primeras imágenes devueltas. El resto del documento está organizado de la siguiente manera. En la Sección 2, proporcionamos una breve descripción del trabajo relacionado. Nuestro algoritmo propuesto de Diseño Óptimo de Laplaciano se introduce en la Sección 3. En la Sección 4, comparamos nuestro algoritmo con los algoritmos de última generación y presentamos los resultados experimentales sobre la recuperación de imágenes. Finalmente, proporcionamos algunas observaciones finales y sugerencias para trabajos futuros en la Sección 5.2. TRABAJO RELACIONADO Dado que nuestro algoritmo propuesto se basa en un marco de regresión. El trabajo más relacionado es el diseño experimental óptimo [1], que incluye el Diseño A-Óptimo, el Diseño D-Óptimo y el Diseño E-Óptimo. En esta sección, damos una breve descripción de estos enfoques. 2.1 El Problema del Aprendizaje Activo El problema genérico del aprendizaje activo es el siguiente. Dado un conjunto de puntos A = {x1, x2, · · · , xm} en Rd , encuentra un subconjunto B = {z1, z2, · · · , zk} ⊂ A que contenga los puntos más informativos. En otras palabras, los puntos zi(i = 1, · · · , k) pueden mejorar el clasificador al máximo si están etiquetados y se utilizan como puntos de entrenamiento. 2.2 Diseño Experimental Óptimo Consideramos un modelo de regresión lineal y = wT x + (1) donde y es la observación, x es la variable independiente, w es el vector de pesos y es un error desconocido con media cero. Diferentes observaciones tienen errores que son independientes, pero con varianzas iguales σ2. Definimos f(x) = wT x como la salida del aprendiz dada la entrada x y el vector de pesos w. Supongamos que tenemos un conjunto de puntos de muestra etiquetados (z1, y1), · · · , (zk, yk), donde yi es la etiqueta de zi. Por lo tanto, la estimación de máxima verosimilitud para el vector de peso, ˆw, es aquella que minimiza la suma del error cuadrado Jsse(w) = k i=1 wT zi − yi 2 (2). La estimación ˆw nos proporciona una estimación de la salida en una entrada novedosa: ˆy = ˆwT x. Según el teorema de Gauss-Markov, sabemos que ˆw − w tiene una media cero y una matriz de covarianza dada por σ2 H−1 sse, donde Hsse es la Hessiana de Jsse(w) Hsse = ∂2 Jsse ∂w2 = k i=1 zizT i = ZZT donde Z = (z1, z2, · · · , zk). Las tres medidas escalares más comunes del tamaño de la matriz de covarianza de parámetros en el diseño experimental óptimo son: • Diseño D-óptimo: determinante de Hsse. • Diseño A-óptimo: traza de Hsse. • Diseño E-óptimo: valor propio máximo de Hsse. Dado que el cálculo del determinante y los valores propios de una matriz es mucho más costoso que el cálculo de la traza de la matriz, el diseño A-óptimo es más eficiente que los otros dos. Algunos trabajos recientes sobre diseño experimental se pueden encontrar en [6], [16]. DISEÑO ÓPTIMO LAPLACIANO Dado que la matriz de covarianza Hsse utilizada en enfoques tradicionales solo depende de las muestras medidas, es decir, zis, estos enfoques no logran evaluar los errores esperados en las muestras no medidas. En esta sección, presentamos un novedoso algoritmo de aprendizaje activo llamado Diseño Óptimo Laplaciano (LOD) que hace un uso eficiente tanto de muestras medidas (etiquetadas) como no medidas (sin etiquetar). 3.1 La Función Objetivo En muchos problemas de aprendizaje automático, es natural asumir que si dos puntos xi, xj están suficientemente cerca uno del otro, entonces sus mediciones (f(xi), f(xj)) también son cercanas. Sea S una matriz de similitud. Por lo tanto, una nueva función de pérdida que respeta la estructura geométrica del espacio de datos se puede definir de la siguiente manera: J0(w) = k i=1 f(zi)−yi 2 + λ 2 m i,j=1 f(xi)−f(xj) 2 Sij (3) donde yi es la medición (o etiqueta) de zi. Se debe tener en cuenta que la función de pérdida (3) es esencialmente la misma que la utilizada en la Regresión Regularizada Laplaciana (LRR, [2]). Sin embargo, LRR es un algoritmo de aprendizaje pasivo donde se proporcionan los datos de entrenamiento. En este artículo, nos enfocamos en cómo seleccionar los datos más informativos para el entrenamiento. La función de pérdida con nuestra elección de pesos simétricos Sij (Sij = Sji) incurre en una penalización severa si los puntos vecinos xi y xj se asignan lejos uno del otro. Por lo tanto, minimizar J0(w) es un intento de asegurar que si xi y xj están cerca, entonces f(xi) y f(xj) también estén cerca. Hay muchas opciones de la matriz de similitud S. Una definición simple es la siguiente: Sij = ⎧ ⎨ ⎩ 1, si xi está entre los p vecinos más cercanos de xj, o xj está entre los p vecinos más cercanos de xi; 0, en otro caso. (4) Sea D una matriz diagonal, Dii = j Sij, y L = D−S. La matriz L se llama Laplaciano de grafo en la teoría espectral de grafos [3]. Sea y = (y1, · · · , yk)T y X = (x1, · · · , xm). Siguiendo algunos pasos algebraicos simples, vemos que: J0(w) = k i=1 wT zi − yi 2 + λ 2 m i,j=1 wT xi − wT xj 2 Sij = y − ZT w T y − ZT w + λwT m i=1 DiixixT i − m i,j=1 SijxixT j w = yT y − 2wT Zy + wT ZZT w +λwT m i=1 DiixixT i − m i,j=1 SijxixT j w = yT y − 2wT Zy + wT ZZT + λXLXT w La Hessiana de J0(w) se puede calcular de la siguiente manera: H0 = ∂2 J0 ∂w2 = ZZT + λXLXT En algunos casos, la matriz ZZT +λXLXT es singular (por ejemplo, si m < d). Por lo tanto, no hay una solución estable para el problema de optimización Ec. (3). Una forma común de abordar este problema mal planteado es introducir un regularizador de Tikhonov en nuestra función de pérdida: J(w) = k i=1 wT zi − yi 2 + λ1 2 m i,j=1 wT xi − wT xj 2 Sij +λ2 w 2 (5) El Hessiano de la nueva función de pérdida está dado por: H = ∂2 J ∂w2 = ZZT + λ1XLXT + λ2I := ZZT + Λ donde I es una matriz identidad y Λ = λ1XLXT + λ2I. Claramente, H tiene rango completo. Exigir que el gradiente de J(w) con respecto a w se anule proporciona la estimación óptima ˆw: ˆw = H−1 Zy. La siguiente proposición establece las propiedades de sesgo y varianza del estimador para el vector de coeficientes w. Proposición 3.1. E( ˆw − w) = −H−1 Λw, Cov( ˆw) = σ2 (H−1 − H−1 ΛH−1 ) Demostración. Dado que y = ZTw + y E( ) = 0, se deduce que E( ˆw − w) (6) = H−1 ZZTw − w = H−1 (ZZT + Λ − Λ)w − w = (I − H−1 Λ)w − w = −H−1 Λw (7) Nótese que Cov(y) = σ2 I, la matriz de covarianza de ˆw tiene la expresión: Cov( ˆw) = H−1 ZCov(y)ZT H−1 = σ2 H−1 ZZT H−1 = σ2 H−1 (H − Λ)H−1 = σ2 (H−1 − H−1 ΛH−1 ) (8) Por lo tanto, la matriz de error cuadrático medio para los coeficientes w es E(w − ˆw)(w − ˆw)T (9) = H−1 ΛwwT ΛH−1 + σ2 (H−1 − H−1 ΛH−1 ) (10) Para cualquier x, sea ˆy = ˆwT x su observación predicha. El error cuadrático de predicción esperado es E(y − ˆy)2 = E( + wT x − ˆwT x)2 = σ2 + xT [E(w − ˆw)(w − ˆw)T ]x = σ2 + xT [H−1 ΛwwT ΛH−1 + σ2 H−1 − σ2 H−1 ΛH−1 ]x Claramente, el error cuadrático de predicción esperado depende de la variable explicativa x, por lo tanto, el error cuadrático de predicción promedio esperado sobre el conjunto de datos completo A es 1 m m i=1 E(yi − ˆwT xi)2 = 1 m m i=1 xT i [H−1 ΛwwT ΛH−1 + σ2 H−1 − σ2 H−1 ΛH−1 ]xi +σ2 = 1 m Tr(XT [σ2 H−1 + H−1 ΛwwT ΛH−1 − σ2 H−1 ΛH−1 ]X) +σ2 Dado que Tr(XT [H−1 ΛwwT ΛH−1 − σ2 H−1 ΛH−1 ]X) Tr(σ2 XT H−1 X), nuestro criterio de optimalidad laplaciano se formula minimizando la traza de XT H−1 X. Definición 1. Diseño óptimo de Laplaciano min Z=(z1,··· ,zk) Tr XT ZZT + λ1XLXT + λ2I −1 X (11) donde z1, · · · , zk son seleccionados de {x1, · · · , xm}. 4. DISEÑO ÓPTIMO DEL NÚCLEO LAPLACIANO Enfoques canónicos de diseño experimental (por ejemplo, Los diseños A-óptimos, D-óptimos y E-óptimos solo consideran funciones lineales. No logran descubrir la geometría intrínseca en los datos cuando el espacio de datos es altamente no lineal. En esta sección, describimos cómo realizar el Diseño Experimental Laplaciano en el Espacio de Hilbert de Núcleos Reproductores (RKHS), lo que da lugar al Diseño Experimental Laplaciano de Núcleo (KLOD). Para los puntos de datos dados x1, · · · , xm ∈ X con un núcleo de Mercer positivo definido K : X ×X → R, existe un único RKHS HK de funciones de valores reales en X. Sea Kt(s) la función de s obtenida al fijar t y dejar que Kt(s) = K(s, t). HK consiste en todas las combinaciones lineales finitas de la forma ∑ i=1 αiKti con ti ∈ X y los límites de tales funciones a medida que los ti se vuelven densos en X. Tenemos Ks, Kt HK = K(s, t). 4.1 Derivación de LOD en el Espacio de Hilbert del Núcleo Reproductor. Considera el problema de optimización (5) en RKHS. Por lo tanto, buscamos una función f ∈ HK tal que se minimice la siguiente función objetivo: min f∈HK k i=1 f(zi)−yi 2 + λ1 2 m i,j=1 f(xi)−f(xj) 2 Sij+λ2 f 2 HK (12). Tenemos la siguiente proposición. Proposición 4.1. Sea H = { m i=1 αiK(·, xi)|αi ∈ R} un subespacio de HK, la solución al problema (12) está en H. Demostración. Sea H⊥ el complemento ortogonal de H, es decir, HK = H ⊕ H⊥. Por lo tanto, para cualquier función f ∈ HK, tiene una descomposición ortogonal de la siguiente manera: f = fH + fH⊥ Ahora, evaluemos f en xi: f(xi) = f, Kxi HK = fH + fH⊥ , Kxi HK = fH, Kxi HK + fH⊥ , Kxi HK Observa que Kxi ∈ H mientras que fH⊥ ∈ H⊥. Esto implica que fH⊥ , Kxi HK = 0. Por lo tanto, f(xi) = fH, Kxi HK = fH(xi). Esto completa la prueba. La Proposición 4.1 nos dice que el minimizador del problema (12) admite una representación f∗ = m i=1 αiK(·, xi). Por favor, consulte [2] para ver los detalles. Sea φ : Rd → H un mapeo de características del espacio de entrada Rd a H, y K(xi, xj) =< φ(xi), φ(xj) >. Que X denote la matriz de datos en RKHS, X = (φ(x1), φ(x2), · · · , φ(xm)). De manera similar, definimos Z = (φ(z1), φ(z2), · · · , φ(zk)). Por lo tanto, el problema de optimización en RKHS se puede escribir de la siguiente manera: min Z Tr XT ZZT + λ1XLXT + λ2I −1 X (13) Dado que la función de mapeo φ generalmente es desconocida, no hay una forma directa de resolver el problema (13). En lo siguiente, aplicamos trucos de kernel para resolver este problema de optimización. Sea X−1 la inversa de Moore-Penrose (también conocida como pseudoinversa) de X. Así, tenemos: XT ZZT + λ1XLXT + λ2I −1 X = XT XX−1 ZZT + λ1XLXT + λ2I −1 (XT )−1 XT X = XT X ZZT X + λ1XLXT X + λ2X −1 (XT )−1 XT X = XT X XT ZZT X + λ1XT XLXT X + λ2XT X −1 XT X = KXX KXZKZX + λ1KXXLKXX + λ2KXX −1 KXX donde KXX es una matriz m × m (KXX,ij = K(xi, xj)), KXZ es una matriz m×k (KXZ,ij = K(xi, zj)), y KZX es una matriz k×m (KZX,ij = K(zi, xj)). Por lo tanto, el Diseño Óptimo del Laplaciano del Núcleo se puede definir de la siguiente manera: Definición 2. En este subapartado, discutimos cómo resolver los problemas de optimización (11) y (14). Particularmente, si seleccionamos un núcleo lineal para KLOD, entonces se reduce a LOD. Por lo tanto, nos enfocaremos en el problema (14) a continuación. Se puede demostrar que el problema de optimización (14) es NP-duro. En esta subsección, desarrollamos un enfoque codicioso secuencial simple para resolver (14). Supongamos que se han seleccionado n puntos, denotados por una matriz Zn = (z1, · · · , zn). El punto (n + 1)-ésimo zn+1 puede ser seleccionado resolviendo el siguiente problema de optimización: max Zn+1=(Zn,zn+1) Tr KXX KXZn+1 KZn+1X + λ1KXXLKXX + λ2KXX −1 KXX (15) Las matrices de kernel KXZn+1 y KZn+1X pueden ser reescritas de la siguiente manera: KXZn+1 = KXZn , KXzn+1 , KZn+1X = KZnX Kzn+1X Por lo tanto, tenemos: KXZn+1 KZn+1X = KXZn KZnX + KXzn+1 Kzn+1X Definimos: A = KXZn KZnX + λ1KXXLKXX + λ2KXX A solo depende de X y Zn. Por lo tanto, el punto (n + 1)-ésimo zn+1 se da por: zn+1 = arg min zn+1 Tr KXX A + KXzn+1 Kzn+1X −1 KXX. Cada vez que seleccionamos un nuevo punto zn+1, la matriz A se actualiza por: A ← A + KXzn+1 Kzn+1X. Si la función de kernel se elige como producto interno K(x, y) = x, y, entonces HK es un espacio funcional lineal y el algoritmo se reduce a LOD. 5. RECUPERACIÓN DE IMÁGENES BASADA EN CONTENIDO UTILIZANDO DISEÑO ÓPTIMO LAPLACIANO En esta sección, describimos cómo aplicar el Diseño Óptimo Laplaciano a la RCIB. Comenzamos con una breve descripción de la <br>representación de imágenes</br> utilizando características visuales de nivel bajo. 5.1 Representación de Imágenes de Nivel Bajo La <br>representación de imágenes</br> de nivel bajo es un problema crucial en la Recuperación de Información Basada en el Contenido (CBIR). Las características visuales generales incluyen color, textura, forma, etc. Las características de color y textura son las características visuales más ampliamente utilizadas en la recuperación de información basada en contenido (CBIR). En comparación con las características de color y textura, las características de forma suelen describirse después de que las imágenes hayan sido segmentadas en regiones u objetos. Dado que la segmentación de imágenes robusta y precisa es difícil de lograr, el uso de características de forma para la recuperación de imágenes se ha limitado a aplicaciones especiales donde los objetos o regiones están fácilmente disponibles. En este trabajo, combinamos un histograma de color de 64 dimensiones y un Momento de Textura de Color (CTM, [15]) de 64 dimensiones para representar las imágenes. El histograma de color se calcula utilizando 4 × 4 × 4 contenedores en el espacio HSV. El Momento de Textura de Color es propuesto por Yu et al. [15], el cual integra las características de color y textura de la imagen en una forma compacta. CTM adopta la transformada de Fourier local como un esquema de representación de texturas y deriva ocho mapas característicos para describir diferentes aspectos de las relaciones de co-ocurrencia de píxeles de imagen en cada canal del espacio de color (SVcosH, SVsinH, V). Entonces, CTM calcula el primer y segundo momento de estos mapas como una representación de la distribución de píxeles de la imagen en color natural. Por favor, consulte [15] para más detalles. 5.2 Recuperación de imágenes con retroalimentación de relevancia La retroalimentación de relevancia es una de las técnicas más importantes para reducir la brecha entre las características visuales de bajo nivel y los conceptos semánticos de alto nivel [12]. Tradicionalmente, los comentarios de relevancia de los usuarios se utilizan para actualizar el vector de consulta o ajustar el peso de las diferentes dimensiones. Este proceso puede ser visto como un proceso de aprendizaje en línea en el que el sistema de recuperación de imágenes actúa como un aprendiz y el usuario actúa como un maestro. El proceso típico de recuperación se describe de la siguiente manera: 1. El usuario envía un ejemplo de imagen de consulta al sistema. El sistema clasifica las imágenes en la base de datos según alguna métrica de distancia predefinida y presenta al usuario las imágenes mejor clasificadas. El sistema selecciona algunas imágenes de la base de datos y solicita al usuario que las etiquete como relevantes o irrelevantes. El sistema utiliza la información proporcionada por los usuarios para reorganizar las imágenes en la base de datos y devolver al usuario las imágenes principales. Ve al paso 2 hasta que el usuario esté satisfecho. Nuestro algoritmo de Diseño Óptimo de Laplaciano se aplica en el segundo paso para seleccionar las imágenes más informativas. Una vez que obtenemos las etiquetas para las imágenes seleccionadas por LOD, aplicamos la Regresión Regularizada Laplaciana (LRR, [2]) para resolver el problema de optimización (3) y construir el clasificador. El clasificador se utiliza luego para reordenar las imágenes en la base de datos. Ten en cuenta que, para reducir la complejidad computacional, no utilizamos todas las imágenes sin etiquetar en la base de datos, sino solo aquellas dentro de los 500 primeros resultados de la iteración anterior. 6. RESULTADOS EXPERIMENTALES En esta sección, evaluamos el rendimiento de nuestro algoritmo propuesto en una gran base de datos de imágenes. Para demostrar la efectividad de nuestro algoritmo LOD propuesto, lo comparamos con la Regresión Regularizada de Laplaciano (LRR, [2]), la Máquina de Vectores de Soporte (SVM), el Aprendizaje Activo de Máquina de Vectores de Soporte (SVMactive) [14], y el Diseño A-Óptimo (AOD). Tanto SVMactive, AOD y LOD son algoritmos de aprendizaje activo, mientras que LRR y SVM son algoritmos de clasificación estándar. SVM solo hace uso de las imágenes etiquetadas, mientras que LRR es un algoritmo de aprendizaje semi-supervisado que hace uso tanto de imágenes etiquetadas como no etiquetadas. Para SVMactive, AOD y LOD, los algoritmos seleccionan 10 imágenes de entrenamiento en cada iteración. Para LRR y SVM, utilizamos las 10 imágenes principales como datos de entrenamiento. Sería importante señalar que SVMactive se basa en el SVM ordinario, LOD se basa en LRR y AOD se basa en la regresión ordinaria. Los parámetros λ1 y λ2 en nuestro algoritmo LOD se establecen empíricamente en 0.001 y 0.00001. Para ambos algoritmos LRR y LOD, utilizamos la misma estructura de grafo (ver Ecuación 4) y establecemos el valor de p (número de vecinos más cercanos) en 5. Comenzamos con un ejemplo sintético simple para dar una intuición sobre cómo funciona LOD. 6.1 Ejemplo Sintético Simple Se presenta un ejemplo sintético simple en la Figura 1. El conjunto de datos contiene dos círculos. Ocho puntos son seleccionados por AOD y LOD. Como se puede ver, todos los puntos seleccionados por AOD son del círculo grande, mientras que LOD selecciona cuatro puntos del círculo grande y cuatro del círculo pequeño. Los números junto a los puntos seleccionados indican su orden de selección. Claramente, los puntos seleccionados por nuestro algoritmo LOD pueden representar mejor el conjunto de datos original. No comparamos nuestro algoritmo con SVMactive porque SVMactive no se puede aplicar en este caso debido a la falta de puntos etiquetados. 6.2 Diseño Experimental de Recuperación de Imágenes La base de datos de imágenes que utilizamos consta de 7,900 imágenes de 79 categorías semánticas, del conjunto de datos COREL. Es un conjunto de imágenes grande y heterogéneo. Cada imagen se representa como un vector de 128 dimensiones según se describe en la Sección 5.1. La Figura 2 muestra algunas imágenes de muestra. Para exhibir las ventajas de usar nuestro algoritmo, necesitamos una forma confiable de evaluar el rendimiento de recuperación y las comparaciones con otros algoritmos. Listamos a continuación diferentes aspectos del diseño experimental. 6.2.1 Métricas de Evaluación Utilizamos la curva de precisión-alcance y la tasa de precisión [10] para evaluar la efectividad de los algoritmos de recuperación de imágenes. El alcance está especificado por el número (N) de imágenes mejor clasificadas presentadas al usuario. La precisión es la proporción entre el número de imágenes relevantes presentadas al usuario y el (a) Conjunto de datos 1 2 3 4 5 6 7 8 (b) AOD 1 2 3 4 5 6 7 8 (c) LOD Figura 1: Selección de datos por algoritmos de aprendizaje activo. Los números junto a los puntos seleccionados indican su orden de selección. Claramente, los puntos seleccionados por nuestro algoritmo LOD pueden representar mejor el conjunto de datos original. Se debe tener en cuenta que el algoritmo SVMactive no se puede aplicar en este caso debido a la falta de puntos etiquetados. (a) (b) (c) Figura 2: Imágenes de muestra de las categorías cuentas, elefante y barco. El alcance de precisión describe la precisión con varios alcances y, por lo tanto, proporciona una evaluación general del rendimiento de los algoritmos. Por otro lado, la tasa de precisión enfatiza la precisión en un valor particular de alcance. En general, es apropiado presentar 20 imágenes en una pantalla. Agregar más imágenes en una pantalla puede afectar la calidad de las imágenes presentadas. Por lo tanto, la precisión en los primeros 20 (N = 20) es especialmente importante. En los sistemas de recuperación de imágenes del mundo real, la imagen de consulta generalmente no se encuentra en la base de datos de imágenes. Para simular dicho entorno, utilizamos validación cruzada de cinco pliegues para evaluar los algoritmos. Más precisamente, dividimos toda la base de datos de imágenes en cinco subconjuntos de tamaño igual. Por lo tanto, hay 20 imágenes por categoría en cada subconjunto. En cada ejecución de validación cruzada, se selecciona un subconjunto como conjunto de consulta, y los otros cuatro subconjuntos se utilizan como base de datos para la recuperación. La curva de precisión del precisionscope y la tasa de precisión se calculan promediando los resultados de la validación cruzada de cinco pliegues. 6.2.2 Esquema de retroalimentación automática de relevancia Diseñamos un esquema de retroalimentación automática para modelar el proceso de recuperación. Para cada consulta enviada, nuestro sistema recupera y clasifica las imágenes en la base de datos. Se seleccionaron 10 imágenes de la base de datos para que los usuarios las etiqueten y la información de las etiquetas es utilizada por el sistema para volver a clasificarlas. Ten en cuenta que las imágenes seleccionadas en iteraciones anteriores están excluidas de selecciones posteriores. Para cada consulta, se realiza el mecanismo de retroalimentación automática de relevancia durante cuatro iteraciones. Es importante señalar que el esquema de retroalimentación automática de relevancia utilizado aquí es diferente de los descritos en [8], [11]. En [8], [11], las cuatro imágenes relevantes e irrelevantes principales fueron seleccionadas como las imágenes de retroalimentación. Sin embargo, esto puede no ser práctico. En los sistemas de recuperación de imágenes del mundo real, es posible que la mayoría de las imágenes mejor clasificadas sean relevantes (o irrelevantes). Por lo tanto, es difícil para el usuario encontrar tanto cuatro imágenes relevantes como irrelevantes. Es más razonable que los usuarios proporcionen información de retroalimentación solo sobre las 10 imágenes seleccionadas por el sistema. 6.3 Rendimiento de recuperación de imágenes En el mundo real, no es práctico requerir que el usuario proporcione muchas rondas de retroalimentación. El rendimiento de recuperación después de las dos primeras rondas de retroalimentación (especialmente la primera ronda) es más importante. La Figura 3 muestra las curvas de precisión-alcance promedio de los diferentes algoritmos para las dos primeras iteraciones de retroalimentación. Al principio de la recuperación, las distancias euclidianas en el espacio original de 128 dimensiones se utilizan para clasificar las imágenes en la base de datos. Después de que el usuario proporcione retroalimentación de relevancia, se aplican los algoritmos LRR, SVM, SVMactive, AOD y LOD para volver a clasificar las imágenes. Para reducir la complejidad temporal de los algoritmos de aprendizaje activo, no seleccionamos las imágenes más informativas de toda la base de datos, sino de las 500 imágenes principales. Para LRR y SVM, se requiere que el usuario etiquete las 10 imágenes principales. Para SVMactive, AOD y LOD, se requiere que el usuario etiquete las 10 imágenes más informativas seleccionadas por estos algoritmos. Tenga en cuenta que, SVMactive solo puede ser ap(a) Iteración de retroalimentación 1 (b) Iteración de retroalimentación 2 Figura 3: Las curvas de precisión promedio-alcance de diferentes algoritmos para las dos primeras iteraciones de retroalimentación. El algoritmo LOD funciona mejor en todo el alcance. Se debe tener en cuenta que, en la primera ronda de retroalimentación, el algoritmo SVMactive no se puede aplicar. Se aplica el SVM ordinario para construir el clasificador inicial. (a) Precisión en el Top 10 (b) Precisión en el Top 20 (c) Precisión en el Top 30 Figura 4: Evaluación del rendimiento de los cinco algoritmos de aprendizaje para la recuperación de imágenes con retroalimentación de relevancia. (a) Precisión en el top 10, (b) Precisión en el top 20 y (c) Precisión en el top 30. Como se puede observar, nuestro algoritmo LOD supera consistentemente a los otros cuatro algoritmos. Por lo tanto, no se puede aplicar en la primera ronda y utilizamos el SVM estándar para construir el clasificador inicial. Como se puede ver, nuestro algoritmo LOD supera a los otros cuatro algoritmos en todo el ámbito. Además, el algoritmo LRR tiene un mejor rendimiento que SVM. Esto se debe a que el algoritmo LRR hace un uso eficiente de las imágenes no etiquetadas al incorporar un regularizador de preservación de la localidad en la función objetivo de regresión ordinaria. El algoritmo AOD es el que tiene peor rendimiento. A medida que el alcance se amplía, la diferencia de rendimiento entre estos algoritmos disminuye. Al agregar de forma iterativa los comentarios de los usuarios, los resultados de precisión correspondientes (en los primeros 10, 20 y 30 lugares) de los cinco algoritmos se muestran respectivamente en la Figura 4. Como se puede ver, nuestro algoritmo LOD tiene el mejor rendimiento en todos los casos y el algoritmo LRR tiene el segundo mejor rendimiento. Ambos de estos dos algoritmos hacen uso de las imágenes sin etiquetar. Esto demuestra que las imágenes sin etiquetar son útiles para descubrir la estructura geométrica intrínseca del espacio de imágenes y, por lo tanto, mejorar el rendimiento de recuperación. En el mundo real, es posible que el usuario no esté dispuesto a proporcionar demasiadas retroalimentaciones de relevancia. Por lo tanto, el rendimiento de recuperación en las primeras dos rondas es especialmente importante. Como se puede observar, nuestro algoritmo LOD logra una mejora del rendimiento del 6.8% para los 10 mejores resultados, del 5.2% para los 20 mejores resultados y del 4.1% para los 30 mejores resultados, en comparación con el segundo mejor algoritmo (LRR) después de las dos primeras rondas de retroalimentación de relevancia. 6.4 Discusión Se han realizado sistemáticamente varios experimentos en la base de datos de Corel. Nos gustaría resaltar varios puntos interesantes: 1. Es claro que el uso del aprendizaje activo es beneficioso en el ámbito de la recuperación de imágenes. Hay un aumento significativo en el rendimiento al utilizar los métodos de aprendizaje activo. Especialmente, de los tres métodos de aprendizaje activo (SVMactive, AOD, LOD), nuestro algoritmo propuesto LOD es el que tiene mejor rendimiento. En muchas aplicaciones del mundo real, como la recuperación de imágenes con retroalimentación de relevancia, generalmente hay dos formas de reducir la tarea laboriosa de etiquetado manual. Uno es el aprendizaje activo que selecciona las muestras más informativas para etiquetar, y el otro es el aprendizaje semi-supervisado que utiliza las muestras no etiquetadas para mejorar el rendimiento del aprendizaje. Ambas estrategias han sido estudiadas extensamente en el pasado [14], [7], [5], [8]. El trabajo presentado en este artículo se centra en el aprendizaje activo, pero también aprovecha los avances recientes en el aprendizaje semi-supervisado [2]. Específicamente, incorporamos un regularizador que preserva la localidad en el marco de regresión estándar y encontramos las muestras más informativas con respecto a la nueva función objetivo. De esta manera, las técnicas de aprendizaje activo y de aprendizaje semi-supervisado se unifican de manera fluida para aprender un clasificador óptimo. 3. La técnica de retroalimentación de relevancia es crucial para la recuperación de imágenes. Para los cinco algoritmos, el rendimiento de recuperación mejora con más retroalimentación proporcionada por el usuario. CONCLUSIONES Y TRABAJOS FUTUROS Este artículo describe un novedoso algoritmo de aprendizaje activo, llamado Diseño Óptimo Laplaciano, para permitir una recuperación de imágenes con retroalimentación de relevancia más efectiva. Nuestro algoritmo se basa en una función objetivo que minimiza simultáneamente el error empírico y preserva la estructura geométrica local del espacio de datos. Utilizando técnicas de diseño experimental, nuestro algoritmo encuentra las imágenes más informativas para etiquetar. Estas imágenes etiquetadas y las imágenes sin etiquetar en la base de datos se utilizan para aprender un clasificador. Los resultados experimentales en la base de datos Corel muestran que tanto el aprendizaje activo como el aprendizaje semi-supervisado pueden mejorar significativamente el rendimiento de recuperación. En este documento, consideramos el problema de recuperación de imágenes en un conjunto de datos de imágenes pequeño, estático y de dominio cerrado. Un dominio mucho más desafiante es la World Wide Web (WWW). Para la búsqueda de imágenes en la web, es posible recopilar una gran cantidad de información sobre los clics de los usuarios. Esta información puede ser utilizada de forma natural para construir el grafo de afinidad en nuestro algoritmo. Sin embargo, la complejidad computacional en el escenario web puede convertirse en un problema crucial. Además, aunque nuestro interés principal en este artículo se centra en la recuperación de imágenes con retroalimentación de relevancia, nuestros resultados también pueden ser de interés para investigadores en reconocimiento de patrones y aprendizaje automático, especialmente cuando hay una gran cantidad de datos disponibles pero solo se pueden etiquetar muestras limitadas. 8. REFERENCIAS [1] A. C. Atkinson y A. N. Donev. Diseños experimentales óptimos. Oxford University Press, 2002. [2] M. Belkin, P. Niyogi, y V. Sindhwani. Regularización de variedades: Un marco geométrico para el aprendizaje a partir de ejemplos. Revista de Investigación de Aprendizaje Automático, 7:2399-2434, 2006. [3] F. R. K. Chung. Teoría Espectral de Grafos, volumen 92 de la Serie de Conferencias Regionales en Matemáticas. AMS, 1997. [4] D. A. Cohn, Z. Ghahramani y M. I. Jordan. Aprendizaje activo con modelos estadísticos. Revista de Investigación en Inteligencia Artificial, 4:129-145, 1996. [5] A. Dong y B. Bhanu. Un nuevo algoritmo EM semisupervisado para la recuperación de imágenes. En la Conferencia IEEE sobre Visión por Computadora y Reconocimiento de Patrones, Madison, WI, 2003. [6] P. Flaherty, M. I. Jordan y A. P. Arkin. Diseño robusto de experimentos biológicos. En Advances in Neural Information Processing Systems 18, Vancouver, Canadá, 2005. [7] K.-S. Goh, E. Y. Chang y W.-C. Lai. Aprendizaje activo dependiente del concepto multimodal para la recuperación de imágenes. En Actas de la Conferencia ACM sobre Multimedia, Nueva York, octubre de 2004. [8] X. Lo siento, la oración \"He.\" no tiene un significado claro en inglés. ¿Podrías proporcionar más contexto o una oración completa para que pueda traducirla al español de manera precisa? Aprendizaje de subespacios semisupervisado incremental para la recuperación de imágenes. En Actas de la Conferencia ACM sobre Multimedia, Nueva York, octubre de 2004. [9] S. C. Hoi y M. R. Lyu. Un marco de aprendizaje activo semi-supervisado para la recuperación de imágenes. En la Conferencia Internacional de IEEE sobre Visión por Computadora y Reconocimiento de Patrones, San Diego, CA, 2005. [10] D. P. Huijsmans y N. Sebe. Cómo completar los gráficos de rendimiento en la recuperación de imágenes basada en contenido: Agregar generalidad y normalizar el alcance. IEEE Transactions on Pattern Analysis and Machine Intelligence, 27(2):245-251, 2005. [11] Y.-Y.\n\nTransacciones del IEEE sobre Inteligencia Artificial y Análisis de Patrones, 27(2):245-251, 2005. [11] Y.-Y. Lin, T.-L. Liu y H.-T. Chen. Aprendizaje de variedades semánticas para la recuperación de imágenes. En Actas de la Conferencia ACM sobre Multimedia, Singapur, noviembre de 2005. [12] Y. Rui, T. S. Huang, M. Ortega y S. Mehrotra. Retroalimentación de relevancia: Una herramienta poderosa para la recuperación de imágenes basada en contenido de forma interactiva. IEEE Transactions on Circuits and Systems for Video Technology, 8(5), 1998. [13] A. W. Smeulders, M. Worring, S. Santini, A. Gupta, and R. Jain. \n\nTraducción: IEEE Transactions on Circuits and Systems for Video Technology, 8(5), 1998. [13] A. W. Smeulders, M. Worring, S. Santini, A. Gupta y R. Jain. Recuperación de imágenes basada en contenido al final de los primeros años. IEEE Transactions on Pattern Analysis and Machine Intelligence, 22(12):1349-1380, 2000. [14] S. Tong y E. Chang. Aprendizaje activo de máquina de vectores de soporte para recuperación de imágenes. En Actas de la novena conferencia internacional de ACM sobre Multimedia, páginas 107-118, 2001. [15] H. Yu, M. Li, H.-J. Zhang y J. Feng. Momentos de textura de color para la recuperación de imágenes basada en contenido. En la Conferencia Internacional de Procesamiento de Imágenes, páginas 24-28, 2002. [16] K. Yu, J. Bi y V. Tresp. Aprendizaje activo a través del diseño experimental transductivo. En Actas de la 23ª Conferencia Internacional sobre Aprendizaje Automático, Pittsburgh, PA, 2006. ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "contentbased image retrieval": {
            "translated_key": "Recuperación de Imágenes Basada en Contenido",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Laplacian Optimal Design for Image Retrieval Xiaofei He Yahoo!",
                "Burbank, CA 91504 hex@yahoo-inc.com Wanli Min IBM Yorktown Heights, NY 10598 wanlimin@us.ibm.com Deng Cai CS Dept., UIUC Urbana, IL 61801 dengcai2@cs.uiuc.edu Kun Zhou Microsoft Research Asia Beijing, China kunzhou@microsoft.com ABSTRACT Relevance feedback is a powerful technique to enhance <br>contentbased image retrieval</br> (CBIR) performance.",
                "It solicits the users relevance judgments on the retrieved images returned by the CBIR systems.",
                "The users labeling is then used to learn a classifier to distinguish between relevant and irrelevant images.",
                "However, the top returned images may not be the most informative ones.",
                "The challenge is thus to determine which unlabeled images would be the most informative (i.e., improve the classifier the most) if they were labeled and used as training samples.",
                "In this paper, we propose a novel active learning algorithm, called Laplacian Optimal Design (LOD), for relevance feedback image retrieval.",
                "Our algorithm is based on a regression model which minimizes the least square error on the measured (or, labeled) images and simultaneously preserves the local geometrical structure of the image space.",
                "Specifically, we assume that if two images are sufficiently close to each other, then their measurements (or, labels) are close as well.",
                "By constructing a nearest neighbor graph, the geometrical structure of the image space can be described by the graph Laplacian.",
                "We discuss how results from the field of optimal experimental design may be used to guide our selection of a subset of images, which gives us the most amount of information.",
                "Experimental results on Corel database suggest that the proposed approach achieves higher precision in relevance feedback image retrieval.",
                "Categories and Subject Descriptors H.3.3 [Information storage and retrieval]: Information search and retrieval-Relevance feedback; G.3 [Mathematics of Computing]: Probability and Statistics-Experimental design General Terms Algorithms, Performance, Theory 1.",
                "INTRODUCTION In many machine learning and information retrieval tasks, there is no shortage of unlabeled data but labels are expensive.",
                "The challenge is thus to determine which unlabeled samples would be the most informative (i.e., improve the classifier the most) if they were labeled and used as training samples.",
                "This problem is typically called active learning [4].",
                "Here the task is to minimize an overall cost, which depends both on the classifier accuracy and the cost of data collection.",
                "Many real world applications can be casted into active learning framework.",
                "Particularly, we consider the problem of relevance feedback driven Content-Based Image Retrieval (CBIR) [13].",
                "Content-Based Image Retrieval has attracted substantial interests in the last decade [13].",
                "It is motivated by the fast growth of digital image databases which, in turn, require efficient search schemes.",
                "Rather than describe an image using text, in these systems an image query is described using one or more example images.",
                "The low level visual features (color, texture, shape, etc.) are automatically extracted to represent the images.",
                "However, the low level features may not accurately characterize the high level semantic concepts.",
                "To narrow down the semantic gap, relevance feedback is introduced into CBIR [12].",
                "In many of the current relevance feedback driven CBIR systems, the user is required to provide his/her relevance judgments on the top images returned by the system.",
                "The labeled images are then used to train a classifier to separate images that match the query concept from those that do not.",
                "However, in general the top returned images may not be the most informative ones.",
                "In the worst case, all the top images labeled by the user may be positive and thus the standard classification techniques can not be applied due to the lack of negative examples.",
                "Unlike the standard classification problems where the labeled samples are pregiven, in relevance feedback image retrieval the system can actively select the images to label.",
                "Thus active learning can be naturally introduced into image retrieval.",
                "Despite many existing active learning techniques, Support Vector Machine (SVM) active learning [14] and regression based active learning [1] have received the most interests.",
                "Based on the observation that the closer to the SVM boundary an image is, the less reliable its classification is, SVM active learning selects those unlabeled images closest to the boundary to solicit user feedback so as to achieve maximal refinement on the hyperplane between the two classes.",
                "The major disadvantage of SVM active learning is that the estimated boundary may not be accurate enough.",
                "Moreover, it may not be applied at the beginning of the retrieval when there is no labeled images.",
                "Some other SVM based active learning algorithms can be found in [7], [9].",
                "In statistics, the problem of selecting samples to label is typically referred to as experimental design.",
                "The sample x is referred to as experiment, and its label y is referred to as measurement.",
                "The study of optimal experimental design (OED) [1] is concerned with the design of experiments that are expected to minimize variances of a parameterized model.",
                "The intent of optimal experimental design is usually to maximize confidence in a given model, minimize parameter variances for system identification, or minimize the models output variance.",
                "Classical experimental design approaches include A-Optimal Design, D-Optimal Design, and E-Optimal Design.",
                "All of these approaches are based on a least squares regression model.",
                "Comparing to SVM based active learning algorithms, experimental design approaches are much more efficient in computation.",
                "However, this kind of approaches takes only measured (or, labeled) data into account in their objective function, while the unmeasured (or, unlabeled) data is ignored.",
                "Benefit from recent progresses on optimal experimental design and semi-supervised learning, in this paper we propose a novel active learning algorithm for image retrieval, called Laplacian Optimal Design (LOD).",
                "Unlike traditional experimental design methods whose loss functions are only defined on the measured points, the loss function of our proposed LOD algorithm is defined on both measured and unmeasured points.",
                "Specifically, we introduce a locality preserving regularizer into the standard least-square-error based loss function.",
                "The new loss function aims to find a classifier which is locally as smooth as possible.",
                "In other words, if two points are sufficiently close to each other in the input space, then they are expected to share the same label.",
                "Once the loss function is defined, we can select the most informative data points which are presented to the user for labeling.",
                "It would be important to note that the most informative images may not be the top returned images.",
                "The rest of the paper is organized as follows.",
                "In Section 2, we provide a brief description of the related work.",
                "Our proposed Laplacian Optimal Design algorithm is introduced in Section 3.",
                "In Section 4, we compare our algorithm with the state-or-the-art algorithms and present the experimental results on image retrieval.",
                "Finally, we provide some concluding remarks and suggestions for future work in Section 5. 2.",
                "RELATED WORK Since our proposed algorithm is based on regression framework.",
                "The most related work is optimal experimental design [1], including A-Optimal Design, D-Optimal Design, and EOptimal Design.",
                "In this Section, we give a brief description of these approaches. 2.1 The Active Learning Problem The generic problem of active learning is the following.",
                "Given a set of points A = {x1, x2, · · · , xm} in Rd , find a subset B = {z1, z2, · · · , zk} ⊂ A which contains the most informative points.",
                "In other words, the points zi(i = 1, · · · , k) can improve the classifier the most if they are labeled and used as training points. 2.2 Optimal Experimental Design We consider a linear regression model y = wT x + (1) where y is the observation, x is the independent variable, w is the weight vector and is an unknown error with zero mean.",
                "Different observations have errors that are independent, but with equal variances σ2 .",
                "We define f(x) = wT x to be the learners output given input x and the weight vector w. Suppose we have a set of labeled sample points (z1, y1), · · · , (zk, yk), where yi is the label of zi.",
                "Thus, the maximum likelihood estimate for the weight vector, ˆw, is that which minimizes the sum squared error Jsse(w) = k i=1 wT zi − yi 2 (2) The estimate ˆw gives us an estimate of the output at a novel input: ˆy = ˆwT x.",
                "By Gauss-Markov theorem, we know that ˆw − w has a zero mean and a covariance matrix given by σ2 H−1 sse, where Hsse is the Hessian of Jsse(w) Hsse = ∂2 Jsse ∂w2 = k i=1 zizT i = ZZT where Z = (z1, z2, · · · , zk).",
                "The three most common scalar measures of the size of the parameter covariance matrix in optimal experimental design are: • D-optimal design: determinant of Hsse. • A-optimal design: trace of Hsse. • E-optimal design: maximum eigenvalue of Hsse.",
                "Since the computation of the determinant and eigenvalues of a matrix is much more expensive than the computation of matrix trace, A-optimal design is more efficient than the other two.",
                "Some recent work on experimental design can be found in [6], [16]. 3.",
                "LAPLACIAN OPTIMAL DESIGN Since the covariance matrix Hsse used in traditional approaches is only dependent on the measured samples, i.e. zis, these approaches fail to evaluate the expected errors on the unmeasured samples.",
                "In this Section, we introduce a novel active learning algorithm called Laplacian Optimal Design (LOD) which makes efficient use of both measured (labeled) and unmeasured (unlabeled) samples. 3.1 The Objective Function In many machine learning problems, it is natural to assume that if two points xi, xj are sufficiently close to each other, then their measurements (f(xi), f(xj)) are close as well.",
                "Let S be a similarity matrix.",
                "Thus, a new loss function which respects the geometrical structure of the data space can be defined as follows: J0(w) = k i=1 f(zi)−yi 2 + λ 2 m i,j=1 f(xi)−f(xj) 2 Sij (3) where yi is the measurement (or, label) of zi.",
                "Note that, the loss function (3) is essentially the same as the one used in Laplacian Regularized Regression (LRR, [2]).",
                "However, LRR is a passive learning algorithm where the training data is given.",
                "In this paper, we are focused on how to select the most informative data for training.",
                "The loss function with our choice of symmetric weights Sij (Sij = Sji) incurs a heavy penalty if neighboring points xi and xj are mapped far apart.",
                "Therefore, minimizing J0(w) is an attempt to ensure that if xi and xj are close then f(xi) and f(xj) are close as well.",
                "There are many choices of the similarity matrix S. A simple definition is as follows: Sij = ⎧ ⎨ ⎩ 1, if xi is among the p nearest neighbors of xj, or xj is among the p nearest neighbors of xi; 0, otherwise. (4) Let D be a diagonal matrix, Dii = j Sij, and L = D−S.",
                "The matrix L is called graph Laplacian in spectral graph theory [3].",
                "Let y = (y1, · · · , yk)T and X = (x1, · · · , xm).",
                "Following some simple algebraic steps, we see that: J0(w) = k i=1 wT zi − yi 2 + λ 2 m i,j=1 wT xi − wT xj 2 Sij = y − ZT w T y − ZT w + λwT m i=1 DiixixT i − m i,j=1 SijxixT j w = yT y − 2wT Zy + wT ZZT w +λwT XDXT − XSXT w = yT y − 2wT Zy + wT ZZT + λXLXT w The Hessian of J0(w) can be computed as follows: H0 = ∂2 J0 ∂w2 = ZZT + λXLXT In some cases, the matrix ZZT +λXLXT is singular (e.g. if m < d).",
                "Thus, there is no stable solution to the optimization problem Eq. (3).",
                "A common way to deal with this ill-posed problem is to introduce a Tikhonov regularizer into our loss function: J(w) = k i=1 wT zi − yi 2 + λ1 2 m i,j=1 wT xi − wT xj 2 Sij +λ2 w 2 (5) The Hessian of the new loss function is given by: H = ∂2 J ∂w2 = ZZT + λ1XLXT + λ2I := ZZT + Λ where I is an identity matrix and Λ = λ1XLXT + λ2I.",
                "Clearly, H is of full rank.",
                "Requiring that the gradient of J(w) with respect to w vanish gives the optimal estimate ˆw: ˆw = H−1 Zy The following proposition states the bias and variance properties of the estimator for the coefficient vector w. Proposition 3.1.",
                "E( ˆw − w) = −H−1 Λw, Cov( ˆw) = σ2 (H−1 − H−1 ΛH−1 ) Proof.",
                "Since y = ZT w + and E( ) = 0, it follows that E( ˆw − w) (6) = H−1 ZZT w − w = H−1 (ZZT + Λ − Λ)w − w = (I − H−1 Λ)w − w = −H−1 Λw (7) Notice Cov(y) = σ2 I, the covariance matrix of ˆw has the expression: Cov( ˆw) = H−1 ZCov(y)ZT H−1 = σ2 H−1 ZZT H−1 = σ2 H−1 (H − Λ)H−1 = σ2 (H−1 − H−1 ΛH−1 ) (8) Therefore mean squared error matrix for the coefficients w is E(w − ˆw)(w − ˆw)T (9) = H−1 ΛwwT ΛH−1 + σ2 (H−1 − H−1 ΛH−1 ) (10) For any x, let ˆy = ˆwT x be its predicted observation.",
                "The expected squared prediction error is E(y − ˆy)2 = E( + wT x − ˆwT x)2 = σ2 + xT [E(w − ˆw)(w − ˆw)T ]x = σ2 + xT [H−1 ΛwwT ΛH−1 + σ2 H−1 − σ2 H−1 ΛH−1 ]x Clearly the expected square prediction error depends on the explanatory variable x, therefore average expected square predictive error over the complete data set A is 1 m m i=1 E(yi − ˆwT xi)2 = 1 m m i=1 xT i [H−1 ΛwwT ΛH−1 + σ2 H−1 − σ2 H−1 ΛH−1 ]xi +σ2 = 1 m Tr(XT [σ2 H−1 + H−1 ΛwwT ΛH−1 − σ2 H−1 ΛH−1 ]X) +σ2 Since Tr(XT [H−1 ΛwwT ΛH−1 − σ2 H−1 ΛH−1 ]X) Tr(σ2 XT H−1 X), Our Laplacian optimality criterion is thus formulated by minimizing the trace of XT H−1 X.",
                "Definition 1.",
                "Laplacian Optimal Design min Z=(z1,··· ,zk) Tr XT ZZT + λ1XLXT + λ2I −1 X (11) where z1, · · · , zk are selected from {x1, · · · , xm}. 4.",
                "KERNEL LAPLACIAN OPTIMAL DESIGN Canonical experimental design approaches (e.g.",
                "A-Optimal Design, D-Optimal Design, and E-Optimal) only consider linear functions.",
                "They fail to discover the intrinsic geometry in the data when the data space is highly nonlinear.",
                "In this section, we describe how to perform Laplacian Experimental Design in Reproducing Kernel Hilbert Space (RKHS) which gives rise to Kernel Laplacian Experimental Design (KLOD).",
                "For given data points x1, · · · , xm ∈ X with a positive definite mercer kernel K : X ×X → R, there exists a unique RKHS HK of real valued functions on X.",
                "Let Kt(s) be the function of s obtained by fixing t and letting Kt(s) . = K(s, t).",
                "HK consists of all finite linear combinations of the form l i=1 αiKti with ti ∈ X and limits of such functions as the ti become dense in X.",
                "We have Ks, Kt HK = K(s, t). 4.1 Derivation of LOD in Reproducing Kernel Hilbert Space Consider the optimization problem (5) in RKHS.",
                "Thus, we seek a function f ∈ HK such that the following objective function is minimized: min f∈HK k i=1 f(zi)−yi 2 + λ1 2 m i,j=1 f(xi)−f(xj) 2 Sij+λ2 f 2 HK (12) We have the following proposition.",
                "Proposition 4.1.",
                "Let H = { m i=1 αiK(·, xi)|αi ∈ R} be a subspace of HK , the solution to the problem (12) is in H. Proof.",
                "Let H⊥ be the orthogonal complement of H, i.e.",
                "HK = H ⊕ H⊥ .",
                "Thus, for any function f ∈ HK , it has orthogonal decomposition as follows: f = fH + fH⊥ Now, lets evaluate f at xi: f(xi) = f, Kxi HK = fH + fH⊥ , Kxi HK = fH, Kxi HK + fH⊥ , Kxi HK Notice that Kxi ∈ H while fH⊥ ∈ H⊥ .",
                "This implies that fH⊥ , Kxi HK = 0.",
                "Therefore, f(xi) = fH, Kxi HK = fH(xi) This completes the proof.",
                "Proposition 4.1 tells us the minimizer of problem (12) admits a representation f∗ = m i=1 αiK(·, xi).",
                "Please see [2] for the details.",
                "Let φ : Rd → H be a feature map from the input space Rd to H, and K(xi, xj) =< φ(xi), φ(xj) >.",
                "Let X denote the data matrix in RKHS, X = (φ(x1), φ(x2), · · · , φ(xm)).",
                "Similarly, we define Z = (φ(z1), φ(z2), · · · , φ(zk)).",
                "Thus, the optimization problem in RKHS can be written as follows: min Z Tr XT ZZT + λ1XLXT + λ2I −1 X (13) Since the mapping function φ is generally unknown, there is no direct way to solve problem (13).",
                "In the following, we apply kernel tricks to solve this optimization problem.",
                "Let X−1 be the Moore-Penrose inverse (also known as pseudo inverse) of X.",
                "Thus, we have: XT ZZT + λ1XLXT + λ2I −1 X = XT XX−1 ZZT + λ1XLXT + λ2I −1 (XT )−1 XT X = XT X ZZT X + λ1XLXT X + λ2X −1 (XT )−1 XT X = XT X XT ZZT X + λ1XT XLXT X + λ2XT X −1 XT X = KXX KXZKZX + λ1KXXLKXX + λ2KXX −1 KXX where KXX is a m × m matrix (KXX,ij = K(xi, xj)), KXZ is a m×k matrix (KXZ,ij = K(xi, zj)), and KZX is a k×m matrix (KZX,ij = K(zi, xj)).",
                "Thus, the Kernel Laplacian Optimal Design can be defined as follows: Definition 2.",
                "Kernel Laplacian Optimal Design minZ=(z1,··· ,zk) Tr KXX KXZKZX + λ1KXXLKXX λ2KXX −1 KXX (14) 4.2 Optimization Scheme In this subsection, we discuss how to solve the optimization problems (11) and (14).",
                "Particularly, if we select a linear kernel for KLOD, then it reduces to LOD.",
                "Therefore, we will focus on problem (14) in the following.",
                "It can be shown that the optimization problem (14) is NP-hard.",
                "In this subsection, we develop a simple sequential greedy approach to solve (14).",
                "Suppose n points have been selected, denoted by a matrix Zn = (z1, · · · , zn).",
                "The (n + 1)-th point zn+1 can be selected by solving the following optimization problem: max Zn+1=(Zn,zn+1) Tr KXX KXZn+1 KZn+1X + λ1KXXLKXX + λ2KXX −1 KXX (15) The kernel matrices KXZn+1 and KZn+1X can be rewritten as follows: KXZn+1 = KXZn , KXzn+1 , KZn+1X = KZnX Kzn+1X Thus, we have: KXZn+1 KZn+1X = KXZn KZnX + KXzn+1 Kzn+1X We define: A = KXZn KZnX + λ1KXXLKXX + λ2KXX A is only dependent on X and Zn .",
                "Thus, the (n + 1)-th point zn+1 is given by: zn+1 = arg min zn+1 Tr KXX A + KXzn+1 Kzn+1X −1 KXX (16) Each time we select a new point zn+1, the matrix A is updated by: A ← A + KXzn+1 Kzn+1X If the kernel function is chosen as inner product K(x, y) = x, y , then HK is a linear functional space and the algorithm reduces to LOD. 5.",
                "CONTENT-BASED IMAGE RETRIEVAL USING LAPLACIAN OPTIMAL DESIGN In this section, we describe how to apply Laplacian Optimal Design to CBIR.",
                "We begin with a brief description of image representation using low level visual features. 5.1 Low-Level Image Representation Low-level image representation is a crucial problem in CBIR.",
                "General visual features includes color, texture, shape, etc.",
                "Color and texture features are the most extensively used visual features in CBIR.",
                "Compared with color and texture features, shape features are usually described after images have been segmented into regions or objects.",
                "Since robust and accurate image segmentation is difficult to achieve, the use of shape features for image retrieval has been limited to special applications where objects or regions are readily available.",
                "In this work, We combine 64-dimensional color histogram and 64-dimensional Color Texture Moment (CTM, [15]) to represent the images.",
                "The color histogram is calculated using 4 × 4 × 4 bins in HSV space.",
                "The Color Texture Moment is proposed by Yu et al. [15], which integrates the color and texture characteristics of the image in a compact form.",
                "CTM adopts local Fourier transform as a texture representation scheme and derives eight characteristic maps to describe different aspects of co-occurrence relations of image pixels in each channel of the (SVcosH, SVsinH, V) color space.",
                "Then CTM calculates the first and second moment of these maps as a representation of the natural color image pixel distribution.",
                "Please see [15] for details. 5.2 Relevance Feedback Image Retrieval Relevance feedback is one of the most important techniques to narrow down the gap between low level visual features and high level semantic concepts [12].",
                "Traditionally, the users relevance feedbacks are used to update the query vector or adjust the weighting of different dimensions.",
                "This process can be viewed as an on-line learning process in which the image retrieval system acts as a learner and the user acts as a teacher.",
                "They typical retrieval process is outlined as follows: 1.",
                "The user submits a query image example to the system.",
                "The system ranks the images in database according to some pre-defined distance metric and presents to the user the top ranked images. 2.",
                "The system selects some images from the database and request the user to label them as relevant or irrelevant. 3.",
                "The system uses the users provided information to rerank the images in database and returns to the user the top images.",
                "Go to step 2 until the user is satisfied.",
                "Our Laplacian Optimal Design algorithm is applied in the second step for selecting the most informative images.",
                "Once we get the labels for the images selected by LOD, we apply Laplacian Regularized Regression (LRR, [2]) to solve the optimization problem (3) and build the classifier.",
                "The classifier is then used to re-rank the images in database.",
                "Note that, in order to reduce the computational complexity, we do not use all the unlabeled images in the database but only those within top 500 returns of previous iteration. 6.",
                "EXPERIMENTAL RESULTS In this section, we evaluate the performance of our proposed algorithm on a large image database.",
                "To demonstrate the effectiveness of our proposed LOD algorithm, we compare it with Laplacian Regularized Regression (LRR, [2]), Support Vector Machine (SVM), Support Vector Machine Active Learning (SVMactive) [14], and A-Optimal Design (AOD).",
                "Both SVMactive, AOD, and LOD are active learning algorithms, while LRR and SVM are standard classification algorithms.",
                "SVM only makes use of the labeled images, while LRR is a semi-supervised learning algorithm which makes use of both labeled and unlabeled images.",
                "For SVMactive, AOD, and LOD, 10 training images are selected by the algorithms themselves at each iteration.",
                "While for LRR and SVM, we use the top 10 images as training data.",
                "It would be important to note that SVMactive is based on the ordinary SVM, LOD is based on LRR, and AOD is based on the ordinary regression.",
                "The parameters λ1 and λ2 in our LOD algorithm are empirically set to be 0.001 and 0.00001.",
                "For both LRR and LOD algorithms, we use the same graph structure (see Eq. 4) and set the value of p (number of nearest neighbors) to be 5.",
                "We begin with a simple synthetic example to give some intuition about how LOD works. 6.1 Simple Synthetic Example A simple synthetic example is given in Figure 1.",
                "The data set contains two circles.",
                "Eight points are selected by AOD and LOD.",
                "As can be seen, all the points selected by AOD are from the big circle, while LOD selects four points from the big circle and four from the small circle.",
                "The numbers beside the selected points denote their orders to be selected.",
                "Clearly, the points selected by our LOD algorithm can better represent the original data set.",
                "We did not compare our algorithm with SVMactive because SVMactive can not be applied in this case due to the lack of the labeled points. 6.2 Image Retrieval Experimental Design The image database we used consists of 7,900 images of 79 semantic categories, from COREL data set.",
                "It is a large and heterogeneous image set.",
                "Each image is represented as a 128-dimensional vector as described in Section 5.1.",
                "Figure 2 shows some sample images.",
                "To exhibit the advantages of using our algorithm, we need a reliable way of evaluating the retrieval performance and the comparisons with other algorithms.",
                "We list different aspects of the experimental design below. 6.2.1 Evaluation Metrics We use precision-scope curve and precision rate [10] to evaluate the effectiveness of the image retrieval algorithms.",
                "The scope is specified by the number (N) of top-ranked images presented to the user.",
                "The precision is the ratio of the number of relevant images presented to the user to the (a) Data set 1 2 3 4 5 6 7 8 (b) AOD 1 2 3 4 5 6 7 8 (c) LOD Figure 1: Data selection by active learning algorithms.",
                "The numbers beside the selected points denote their orders to be selected.",
                "Clearly, the points selected by our LOD algorithm can better represent the original data set.",
                "Note that, the SVMactive algorithm can not be applied in this case due to the lack of labeled points. (a) (b) (c) Figure 2: Sample images from category bead, elephant, and ship. scope N. The precision-scope curve describes the precision with various scopes and thus gives an overall performance evaluation of the algorithms.",
                "On the other hand, the precision rate emphasizes the precision at a particular value of scope.",
                "In general, it is appropriate to present 20 images on a screen.",
                "Putting more images on a screen may affect the quality of the presented images.",
                "Therefore, the precision at top 20 (N = 20) is especially important.",
                "In real world image retrieval systems, the query image is usually not in the image database.",
                "To simulate such environment, we use five-fold cross validation to evaluate the algorithms.",
                "More precisely, we divide the whole image database into five subsets with equal size.",
                "Thus, there are 20 images per category in each subset.",
                "At each run of cross validation, one subset is selected as the query set, and the other four subsets are used as the database for retrieval.",
                "The precisionscope curve and precision rate are computed by averaging the results from the five-fold cross validation. 6.2.2 Automatic Relevance Feedback Scheme We designed an automatic feedback scheme to model the retrieval process.",
                "For each submitted query, our system retrieves and ranks the images in the database. 10 images were selected from the database for user labeling and the label information is used by the system for re-ranking.",
                "Note that, the images which have been selected at previous iterations are excluded from later selections.",
                "For each query, the automatic relevance feedback mechanism is performed for four iterations.",
                "It is important to note that the automatic relevance feedback scheme used here is different from the ones described in [8], [11].",
                "In [8], [11], the top four relevant and irrelevant images were selected as the feedback images.",
                "However, this may not be practical.",
                "In real world image retrieval systems, it is possible that most of the top-ranked images are relevant (or, irrelevant).",
                "Thus, it is difficult for the user to find both four relevant and irrelevant images.",
                "It is more reasonable for the users to provide feedback information only on the 10 images selected by the system. 6.3 Image Retrieval Performance In real world, it is not practical to require the user to provide many rounds of feedbacks.",
                "The retrieval performance after the first two rounds of feedbacks (especially the first round) is more important.",
                "Figure 3 shows the average precision-scope curves of the different algorithms for the first two feedback iterations.",
                "At the beginning of retrieval, the Euclidean distances in the original 128-dimensional space are used to rank the images in database.",
                "After the user provides relevance feedbacks, the LRR, SVM, SVMactive, AOD, and LOD algorithms are then applied to re-rank the images.",
                "In order to reduce the time complexity of active learning algorithms, we didnt select the most informative images from the whole database but from the top 500 images.",
                "For LRR and SVM, the user is required to label the top 10 images.",
                "For SVMactive, AOD, and LOD, the user is required to label 10 most informative images selected by these algorithms.",
                "Note that, SVMactive can only be ap(a) Feedback Iteration 1 (b) Feedback Iteration 2 Figure 3: The average precision-scope curves of different algorithms for the first two feedback iterations.",
                "The LOD algorithm performs the best on the entire scope.",
                "Note that, at the first round of feedback, the SVMactive algorithm can not be applied.",
                "It applies the ordinary SVM to build the initial classifier. (a) Precision at Top 10 (b) Precision at Top 20 (c) Precision at Top 30 Figure 4: Performance evaluation of the five learning algorithms for relevance feedback image retrieval. (a) Precision at top 10, (b) Precision at top 20, and (c) Precision at top 30.",
                "As can be seen, our LOD algorithm consistently outperforms the other four algorithms. plied when the classifier is already built.",
                "Therefore, it can not be applied at the first round and we use the standard SVM to build the initial classifier.",
                "As can be seen, our LOD algorithm outperforms the other four algorithms on the entire scope.",
                "Also, the LRR algorithm performs better than SVM.",
                "This is because that the LRR algorithm makes efficient use of the unlabeled images by incorporating a locality preserving regularizer into the ordinary regression objective function.",
                "The AOD algorithm performs the worst.",
                "As the scope gets larger, the performance difference between these algorithms gets smaller.",
                "By iteratively adding the users feedbacks, the corresponding precision results (at top 10, top 20, and top 30) of the five algorithms are respectively shown in Figure 4.",
                "As can be seen, our LOD algorithm performs the best in all the cases and the LRR algorithm performs the second best.",
                "Both of these two algorithms make use of the unlabeled images.",
                "This shows that the unlabeled images are helpful for discovering the intrinsic geometrical structure of the image space and therefore enhance the retrieval performance.",
                "In real world, the user may not be willing to provide too many relevance feedbacks.",
                "Therefore, the retrieval performance at the first two rounds are especially important.",
                "As can be seen, our LOD algorithm achieves 6.8% performance improvement for top 10 results, 5.2% for top 20 results, and 4.1% for top 30 results, comparing to the second best algorithm (LRR) after the first two rounds of relevance feedbacks. 6.4 Discussion Several experiments on Corel database have been systematically performed.",
                "We would like to highlight several interesting points: 1.",
                "It is clear that the use of active learning is beneficial in the image retrieval domain.",
                "There is a significant increase in performance from using the active learning methods.",
                "Especially, out of the three active learning methods (SVMactive, AOD, LOD), our proposed LOD algorithm performs the best. 2.",
                "In many real world applications like relevance feedback image retrieval, there are generally two ways of reducing labor-intensive manual labeling task.",
                "One is active learning which selects the most informative samples to label, and the other is semi-supervised learning which makes use of the unlabeled samples to enhance the learning performance.",
                "Both of these two strategies have been studied extensively in the past [14], [7], [5], [8].",
                "The work presented in this paper is focused on active learning, but it also takes advantage of the recent progresses on semi-supervised learning [2].",
                "Specifically, we incorporate a locality preserving regularizer into the standard regression framework and find the most informative samples with respect to the new objective function.",
                "In this way, the active learning and semi-supervised learning techniques are seamlessly unified for learning an optimal classifier. 3.",
                "The relevance feedback technique is crucial to image retrieval.",
                "For all the five algorithms, the retrieval performance improves with more feedbacks provided by the user. 7.",
                "CONCLUSIONS AND FUTURE WORK This paper describes a novel active learning algorithm, called Laplacian Optimal Design, to enable more effective relevance feedback image retrieval.",
                "Our algorithm is based on an objective function which simultaneously minimizes the empirical error and preserves the local geometrical structure of the data space.",
                "Using techniques from experimental design, our algorithm finds the most informative images to label.",
                "These labeled images and the unlabeled images in the database are used to learn a classifier.",
                "The experimental results on Corel database show that both active learning and semi-supervised learning can significantly improve the retrieval performance.",
                "In this paper, we consider the image retrieval problem on a small, static, and closed-domain image data.",
                "A much more challenging domain is the World Wide Web (WWW).",
                "For Web image search, it is possible to collect a large amount of user click information.",
                "This information can be naturally used to construct the affinity graph in our algorithm.",
                "However, the computational complexity in Web scenario may become a crucial issue.",
                "Also, although our primary interest in this paper is focused on relevance feedback image retrieval, our results may also be of interest to researchers in patten recognition and machine learning, especially when a large amount of data is available but only a limited samples can be labeled. 8.",
                "REFERENCES [1] A. C. Atkinson and A. N. Donev.",
                "Optimum Experimental Designs.",
                "Oxford University Press, 2002. [2] M. Belkin, P. Niyogi, and V. Sindhwani.",
                "Manifold regularization: A geometric framework for learning from examples.",
                "Journal of Machine Learning Research, 7:2399-2434, 2006. [3] F. R. K. Chung.",
                "Spectral Graph Theory, volume 92 of Regional Conference Series in Mathematics.",
                "AMS, 1997. [4] D. A. Cohn, Z. Ghahramani, and M. I. Jordan.",
                "Active learning with statistical models.",
                "Journal of Artificial Intelligence Research, 4:129-145, 1996. [5] A. Dong and B. Bhanu.",
                "A new semi-supervised em algorithm for image retrieval.",
                "In IEEE Conf. on Computer Vision and Pattern Recognition, Madison, WI, 2003. [6] P. Flaherty, M. I. Jordan, and A. P. Arkin.",
                "Robust design of biological experiments.",
                "In Advances in Neural Information Processing Systems 18, Vancouver, Canada, 2005. [7] K.-S. Goh, E. Y. Chang, and W.-C. Lai.",
                "Multimodal concept-dependent active learning for image retrieval.",
                "In Proceedings of the ACM Conference on Multimedia, New York, October 2004. [8] X.",
                "He.",
                "Incremental semi-supervised subspace learning for image retrieval.",
                "In Proceedings of the ACM Conference on Multimedia, New York, October 2004. [9] S. C. Hoi and M. R. Lyu.",
                "A semi-supervised active learning framework for image retrieval.",
                "In IEEE International Conference on Computer Vision and Pattern Recognition, San Diego, CA, 2005. [10] D. P. Huijsmans and N. Sebe.",
                "How to complete performance graphs in content-based image retrieval: Add generality and normalize scope.",
                "IEEE Transactions on Pattern Analysis and Machine Intelligence, 27(2):245-251, 2005. [11] Y.-Y.",
                "Lin, T.-L. Liu, and H.-T. Chen.",
                "Semantic manifold learning for image retrieval.",
                "In Proceedings of the ACM Conference on Multimedia, Singapore, November 2005. [12] Y. Rui, T. S. Huang, M. Ortega, and S. Mehrotra.",
                "Relevance feedback: A power tool for interative content-based image retrieval.",
                "IEEE Transactions on Circuits and Systems for Video Technology, 8(5), 1998. [13] A. W. Smeulders, M. Worring, S. Santini, A. Gupta, and R. Jain.",
                "Content-based image retrieval at the end of the early years.",
                "IEEE Transactions on Pattern Analysis and Machine Intelligence, 22(12):1349-1380, 2000. [14] S. Tong and E. Chang.",
                "Support vector machine active learning for image retrieval.",
                "In Proceedings of the ninth ACM international conference on Multimedia, pages 107-118, 2001. [15] H. Yu, M. Li, H.-J.",
                "Zhang, and J. Feng.",
                "Color texture moments for content-based image retrieval.",
                "In International Conference on Image Processing, pages 24-28, 2002. [16] K. Yu, J. Bi, and V. Tresp.",
                "Active learning via transductive experimental design.",
                "In Proceedings of the 23rd International Conference on Machine Learning, Pittsburgh, PA, 2006."
            ],
            "original_annotated_samples": [
                "Burbank, CA 91504 hex@yahoo-inc.com Wanli Min IBM Yorktown Heights, NY 10598 wanlimin@us.ibm.com Deng Cai CS Dept., UIUC Urbana, IL 61801 dengcai2@cs.uiuc.edu Kun Zhou Microsoft Research Asia Beijing, China kunzhou@microsoft.com ABSTRACT Relevance feedback is a powerful technique to enhance <br>contentbased image retrieval</br> (CBIR) performance."
            ],
            "translated_annotated_samples": [
                "El feedback de relevancia es una técnica poderosa para mejorar el rendimiento de la <br>Recuperación de Imágenes Basada en Contenido</br> (CBIR)."
            ],
            "translated_text": "Diseño óptimo de Laplaciano para la recuperación de imágenes Xiaofei He Yahoo! El feedback de relevancia es una técnica poderosa para mejorar el rendimiento de la <br>Recuperación de Imágenes Basada en Contenido</br> (CBIR). Solicita las valoraciones de relevancia de los usuarios sobre las imágenes recuperadas por los sistemas CBIR. La etiqueta de los usuarios se utiliza luego para entrenar un clasificador que distinga entre imágenes relevantes e irrelevantes. Sin embargo, las imágenes principales que se devuelven pueden no ser las más informativas. El desafío consiste en determinar qué imágenes sin etiquetar serían las más informativas (es decir, mejorarían más al clasificador) si fueran etiquetadas y utilizadas como muestras de entrenamiento. En este artículo, proponemos un novedoso algoritmo de aprendizaje activo, llamado Diseño Óptimo Laplaciano (LOD), para la recuperación de imágenes con retroalimentación de relevancia. Nuestro algoritmo se basa en un modelo de regresión que minimiza el error cuadrático mínimo en las imágenes medidas (o etiquetadas) y al mismo tiempo preserva la estructura geométrica local del espacio de la imagen. Específicamente, asumimos que si dos imágenes están lo suficientemente cerca una de la otra, entonces sus medidas (o etiquetas) también son cercanas. Al construir un grafo de vecinos más cercanos, la estructura geométrica del espacio de la imagen puede ser descrita por el Laplaciano del grafo. Discutimos cómo los resultados del campo del diseño experimental óptimo pueden ser utilizados para guiar nuestra selección de un subconjunto de imágenes, que nos proporciona la mayor cantidad de información. Los resultados experimentales en la base de datos Corel sugieren que el enfoque propuesto logra una mayor precisión en la recuperación de imágenes con retroalimentación de relevancia. Categorías y Descriptores de Asignaturas H.3.3 [Almacenamiento y recuperación de información]: Búsqueda y recuperación de información-Retroalimentación de relevancia; G.3 [Matemáticas de la Computación]: Probabilidad y Estadística-Diseño experimental Términos Generales Algoritmos, Rendimiento, Teoría 1. INTRODUCCIÓN En muchas tareas de aprendizaje automático y recuperación de información, no hay escasez de datos no etiquetados pero las etiquetas son costosas. El desafío consiste en determinar qué muestras sin etiquetar serían las más informativas (es decir, mejorarían más el clasificador) si fueran etiquetadas y utilizadas como muestras de entrenamiento. Este problema se llama típicamente aprendizaje activo [4]. Aquí la tarea es minimizar un costo general, que depende tanto de la precisión del clasificador como del costo de la recolección de datos. Muchas aplicaciones del mundo real pueden ser adaptadas al marco de aprendizaje activo. Particularmente, consideramos el problema de la recuperación de imágenes basada en contenido impulsada por la retroalimentación de relevancia (CBIR) [13]. La Recuperación de Imágenes Basada en Contenido ha atraído un interés sustancial en la última década [13]. Está motivado por el rápido crecimiento de las bases de datos de imágenes digitales que, a su vez, requieren esquemas de búsqueda eficientes. En lugar de describir una imagen usando texto, en estos sistemas se describe una consulta de imagen utilizando una o más imágenes de ejemplo. Las características visuales de bajo nivel (color, textura, forma, etc.) se extraen automáticamente para representar las imágenes. Sin embargo, las características de bajo nivel pueden no caracterizar con precisión los conceptos semánticos de alto nivel. Para reducir la brecha semántica, se introduce la retroalimentación de relevancia en la recuperación de información basada en el contenido (CBIR) [12]. En muchos de los sistemas actuales de recuperación de imágenes basados en retroalimentación de relevancia, se requiere que el usuario proporcione sus juicios de relevancia sobre las imágenes principales devueltas por el sistema. Las imágenes etiquetadas se utilizan luego para entrenar un clasificador que separe las imágenes que coinciden con el concepto de la consulta de aquellas que no lo hacen. Sin embargo, en general, las imágenes principales que se devuelven pueden no ser las más informativas. En el peor de los casos, todas las imágenes principales etiquetadas por el usuario pueden ser positivas y, por lo tanto, las técnicas estándar de clasificación no pueden aplicarse debido a la falta de ejemplos negativos. A diferencia de los problemas de clasificación estándar donde las muestras etiquetadas están predefinidas, en la recuperación de imágenes con retroalimentación de relevancia, el sistema puede seleccionar activamente las imágenes a etiquetar. Por lo tanto, el aprendizaje activo puede ser introducido de forma natural en la recuperación de imágenes. A pesar de la existencia de muchas técnicas de aprendizaje activo, el aprendizaje activo de Máquina de Vectores de Soporte (SVM) [14] y el aprendizaje activo basado en regresión [1] han sido los que han despertado mayor interés. Basado en la observación de que cuanto más cerca del límite del SVM se encuentre una imagen, menos confiable es su clasificación, el aprendizaje activo del SVM selecciona aquellas imágenes no etiquetadas más cercanas al límite para solicitar retroalimentación del usuario con el fin de lograr un refinamiento máximo en el hiperplano entre las dos clases. La principal desventaja del aprendizaje activo de SVM es que es posible que el límite estimado no sea lo suficientemente preciso. Además, puede que no se aplique al principio de la recuperación cuando no hay imágenes etiquetadas. Algunos otros algoritmos de aprendizaje activo basados en SVM se pueden encontrar en [7], [9]. En estadística, el problema de seleccionar muestras para etiquetar se conoce típicamente como diseño experimental. La muestra x se denomina experimento, y su etiqueta y se denomina medición. El estudio del diseño experimental óptimo (DEO) se preocupa por el diseño de experimentos que se espera que minimicen las varianzas de un modelo parametrizado. La intención del diseño experimental óptimo suele ser maximizar la confianza en un modelo dado, minimizar las varianzas de los parámetros para la identificación del sistema, o minimizar la varianza de la salida de los modelos. Los enfoques clásicos de diseño experimental incluyen el Diseño A-Óptimo, el Diseño D-Óptimo y el Diseño E-Óptimo. Todos estos enfoques se basan en un modelo de regresión de mínimos cuadrados. En comparación con los algoritmos de aprendizaje activo basados en SVM, los enfoques de diseño experimental son mucho más eficientes en términos de computación. Sin embargo, este tipo de enfoques solo tienen en cuenta los datos medidos (o etiquetados) en su función objetivo, mientras que los datos no medidos (o no etiquetados) son ignorados. Beneficiar de los avances recientes en diseño experimental óptimo y aprendizaje semisupervisado, en este artículo proponemos un nuevo algoritmo de aprendizaje activo para recuperación de imágenes, llamado Diseño Óptimo Laplaciano (LOD). A diferencia de los métodos tradicionales de diseño experimental cuyas funciones de pérdida solo están definidas en los puntos medidos, la función de pérdida de nuestro algoritmo propuesto LOD está definida tanto en los puntos medidos como en los no medidos. Específicamente, introducimos un regularizador que preserva la localidad en la función de pérdida estándar basada en el error cuadrático mínimo. La nueva función de pérdida tiene como objetivo encontrar un clasificador que sea localmente lo más suave posible. En otras palabras, si dos puntos están suficientemente cerca uno del otro en el espacio de entrada, se espera que compartan la misma etiqueta. Una vez que se define la función de pérdida, podemos seleccionar los puntos de datos más informativos que se presentan al usuario para su etiquetado. Sería importante tener en cuenta que las imágenes más informativas pueden no ser las primeras imágenes devueltas. El resto del documento está organizado de la siguiente manera. En la Sección 2, proporcionamos una breve descripción del trabajo relacionado. Nuestro algoritmo propuesto de Diseño Óptimo de Laplaciano se introduce en la Sección 3. En la Sección 4, comparamos nuestro algoritmo con los algoritmos de última generación y presentamos los resultados experimentales sobre la recuperación de imágenes. Finalmente, proporcionamos algunas observaciones finales y sugerencias para trabajos futuros en la Sección 5.2. TRABAJO RELACIONADO Dado que nuestro algoritmo propuesto se basa en un marco de regresión. El trabajo más relacionado es el diseño experimental óptimo [1], que incluye el Diseño A-Óptimo, el Diseño D-Óptimo y el Diseño E-Óptimo. En esta sección, damos una breve descripción de estos enfoques. 2.1 El Problema del Aprendizaje Activo El problema genérico del aprendizaje activo es el siguiente. Dado un conjunto de puntos A = {x1, x2, · · · , xm} en Rd , encuentra un subconjunto B = {z1, z2, · · · , zk} ⊂ A que contenga los puntos más informativos. En otras palabras, los puntos zi(i = 1, · · · , k) pueden mejorar el clasificador al máximo si están etiquetados y se utilizan como puntos de entrenamiento. 2.2 Diseño Experimental Óptimo Consideramos un modelo de regresión lineal y = wT x + (1) donde y es la observación, x es la variable independiente, w es el vector de pesos y es un error desconocido con media cero. Diferentes observaciones tienen errores que son independientes, pero con varianzas iguales σ2. Definimos f(x) = wT x como la salida del aprendiz dada la entrada x y el vector de pesos w. Supongamos que tenemos un conjunto de puntos de muestra etiquetados (z1, y1), · · · , (zk, yk), donde yi es la etiqueta de zi. Por lo tanto, la estimación de máxima verosimilitud para el vector de peso, ˆw, es aquella que minimiza la suma del error cuadrado Jsse(w) = k i=1 wT zi − yi 2 (2). La estimación ˆw nos proporciona una estimación de la salida en una entrada novedosa: ˆy = ˆwT x. Según el teorema de Gauss-Markov, sabemos que ˆw − w tiene una media cero y una matriz de covarianza dada por σ2 H−1 sse, donde Hsse es la Hessiana de Jsse(w) Hsse = ∂2 Jsse ∂w2 = k i=1 zizT i = ZZT donde Z = (z1, z2, · · · , zk). Las tres medidas escalares más comunes del tamaño de la matriz de covarianza de parámetros en el diseño experimental óptimo son: • Diseño D-óptimo: determinante de Hsse. • Diseño A-óptimo: traza de Hsse. • Diseño E-óptimo: valor propio máximo de Hsse. Dado que el cálculo del determinante y los valores propios de una matriz es mucho más costoso que el cálculo de la traza de la matriz, el diseño A-óptimo es más eficiente que los otros dos. Algunos trabajos recientes sobre diseño experimental se pueden encontrar en [6], [16]. DISEÑO ÓPTIMO LAPLACIANO Dado que la matriz de covarianza Hsse utilizada en enfoques tradicionales solo depende de las muestras medidas, es decir, zis, estos enfoques no logran evaluar los errores esperados en las muestras no medidas. En esta sección, presentamos un novedoso algoritmo de aprendizaje activo llamado Diseño Óptimo Laplaciano (LOD) que hace un uso eficiente tanto de muestras medidas (etiquetadas) como no medidas (sin etiquetar). 3.1 La Función Objetivo En muchos problemas de aprendizaje automático, es natural asumir que si dos puntos xi, xj están suficientemente cerca uno del otro, entonces sus mediciones (f(xi), f(xj)) también son cercanas. Sea S una matriz de similitud. Por lo tanto, una nueva función de pérdida que respeta la estructura geométrica del espacio de datos se puede definir de la siguiente manera: J0(w) = k i=1 f(zi)−yi 2 + λ 2 m i,j=1 f(xi)−f(xj) 2 Sij (3) donde yi es la medición (o etiqueta) de zi. Se debe tener en cuenta que la función de pérdida (3) es esencialmente la misma que la utilizada en la Regresión Regularizada Laplaciana (LRR, [2]). Sin embargo, LRR es un algoritmo de aprendizaje pasivo donde se proporcionan los datos de entrenamiento. En este artículo, nos enfocamos en cómo seleccionar los datos más informativos para el entrenamiento. La función de pérdida con nuestra elección de pesos simétricos Sij (Sij = Sji) incurre en una penalización severa si los puntos vecinos xi y xj se asignan lejos uno del otro. Por lo tanto, minimizar J0(w) es un intento de asegurar que si xi y xj están cerca, entonces f(xi) y f(xj) también estén cerca. Hay muchas opciones de la matriz de similitud S. Una definición simple es la siguiente: Sij = ⎧ ⎨ ⎩ 1, si xi está entre los p vecinos más cercanos de xj, o xj está entre los p vecinos más cercanos de xi; 0, en otro caso. (4) Sea D una matriz diagonal, Dii = j Sij, y L = D−S. La matriz L se llama Laplaciano de grafo en la teoría espectral de grafos [3]. Sea y = (y1, · · · , yk)T y X = (x1, · · · , xm). Siguiendo algunos pasos algebraicos simples, vemos que: J0(w) = k i=1 wT zi − yi 2 + λ 2 m i,j=1 wT xi − wT xj 2 Sij = y − ZT w T y − ZT w + λwT m i=1 DiixixT i − m i,j=1 SijxixT j w = yT y − 2wT Zy + wT ZZT w +λwT m i=1 DiixixT i − m i,j=1 SijxixT j w = yT y − 2wT Zy + wT ZZT + λXLXT w La Hessiana de J0(w) se puede calcular de la siguiente manera: H0 = ∂2 J0 ∂w2 = ZZT + λXLXT En algunos casos, la matriz ZZT +λXLXT es singular (por ejemplo, si m < d). Por lo tanto, no hay una solución estable para el problema de optimización Ec. (3). Una forma común de abordar este problema mal planteado es introducir un regularizador de Tikhonov en nuestra función de pérdida: J(w) = k i=1 wT zi − yi 2 + λ1 2 m i,j=1 wT xi − wT xj 2 Sij +λ2 w 2 (5) El Hessiano de la nueva función de pérdida está dado por: H = ∂2 J ∂w2 = ZZT + λ1XLXT + λ2I := ZZT + Λ donde I es una matriz identidad y Λ = λ1XLXT + λ2I. Claramente, H tiene rango completo. Exigir que el gradiente de J(w) con respecto a w se anule proporciona la estimación óptima ˆw: ˆw = H−1 Zy. La siguiente proposición establece las propiedades de sesgo y varianza del estimador para el vector de coeficientes w. Proposición 3.1. E( ˆw − w) = −H−1 Λw, Cov( ˆw) = σ2 (H−1 − H−1 ΛH−1 ) Demostración. Dado que y = ZTw + y E( ) = 0, se deduce que E( ˆw − w) (6) = H−1 ZZTw − w = H−1 (ZZT + Λ − Λ)w − w = (I − H−1 Λ)w − w = −H−1 Λw (7) Nótese que Cov(y) = σ2 I, la matriz de covarianza de ˆw tiene la expresión: Cov( ˆw) = H−1 ZCov(y)ZT H−1 = σ2 H−1 ZZT H−1 = σ2 H−1 (H − Λ)H−1 = σ2 (H−1 − H−1 ΛH−1 ) (8) Por lo tanto, la matriz de error cuadrático medio para los coeficientes w es E(w − ˆw)(w − ˆw)T (9) = H−1 ΛwwT ΛH−1 + σ2 (H−1 − H−1 ΛH−1 ) (10) Para cualquier x, sea ˆy = ˆwT x su observación predicha. El error cuadrático de predicción esperado es E(y − ˆy)2 = E( + wT x − ˆwT x)2 = σ2 + xT [E(w − ˆw)(w − ˆw)T ]x = σ2 + xT [H−1 ΛwwT ΛH−1 + σ2 H−1 − σ2 H−1 ΛH−1 ]x Claramente, el error cuadrático de predicción esperado depende de la variable explicativa x, por lo tanto, el error cuadrático de predicción promedio esperado sobre el conjunto de datos completo A es 1 m m i=1 E(yi − ˆwT xi)2 = 1 m m i=1 xT i [H−1 ΛwwT ΛH−1 + σ2 H−1 − σ2 H−1 ΛH−1 ]xi +σ2 = 1 m Tr(XT [σ2 H−1 + H−1 ΛwwT ΛH−1 − σ2 H−1 ΛH−1 ]X) +σ2 Dado que Tr(XT [H−1 ΛwwT ΛH−1 − σ2 H−1 ΛH−1 ]X) Tr(σ2 XT H−1 X), nuestro criterio de optimalidad laplaciano se formula minimizando la traza de XT H−1 X. Definición 1. Diseño óptimo de Laplaciano min Z=(z1,··· ,zk) Tr XT ZZT + λ1XLXT + λ2I −1 X (11) donde z1, · · · , zk son seleccionados de {x1, · · · , xm}. 4. DISEÑO ÓPTIMO DEL NÚCLEO LAPLACIANO Enfoques canónicos de diseño experimental (por ejemplo, Los diseños A-óptimos, D-óptimos y E-óptimos solo consideran funciones lineales. No logran descubrir la geometría intrínseca en los datos cuando el espacio de datos es altamente no lineal. En esta sección, describimos cómo realizar el Diseño Experimental Laplaciano en el Espacio de Hilbert de Núcleos Reproductores (RKHS), lo que da lugar al Diseño Experimental Laplaciano de Núcleo (KLOD). Para los puntos de datos dados x1, · · · , xm ∈ X con un núcleo de Mercer positivo definido K : X ×X → R, existe un único RKHS HK de funciones de valores reales en X. Sea Kt(s) la función de s obtenida al fijar t y dejar que Kt(s) = K(s, t). HK consiste en todas las combinaciones lineales finitas de la forma ∑ i=1 αiKti con ti ∈ X y los límites de tales funciones a medida que los ti se vuelven densos en X. Tenemos Ks, Kt HK = K(s, t). 4.1 Derivación de LOD en el Espacio de Hilbert del Núcleo Reproductor. Considera el problema de optimización (5) en RKHS. Por lo tanto, buscamos una función f ∈ HK tal que se minimice la siguiente función objetivo: min f∈HK k i=1 f(zi)−yi 2 + λ1 2 m i,j=1 f(xi)−f(xj) 2 Sij+λ2 f 2 HK (12). Tenemos la siguiente proposición. Proposición 4.1. Sea H = { m i=1 αiK(·, xi)|αi ∈ R} un subespacio de HK, la solución al problema (12) está en H. Demostración. Sea H⊥ el complemento ortogonal de H, es decir, HK = H ⊕ H⊥. Por lo tanto, para cualquier función f ∈ HK, tiene una descomposición ortogonal de la siguiente manera: f = fH + fH⊥ Ahora, evaluemos f en xi: f(xi) = f, Kxi HK = fH + fH⊥ , Kxi HK = fH, Kxi HK + fH⊥ , Kxi HK Observa que Kxi ∈ H mientras que fH⊥ ∈ H⊥. Esto implica que fH⊥ , Kxi HK = 0. Por lo tanto, f(xi) = fH, Kxi HK = fH(xi). Esto completa la prueba. La Proposición 4.1 nos dice que el minimizador del problema (12) admite una representación f∗ = m i=1 αiK(·, xi). Por favor, consulte [2] para ver los detalles. Sea φ : Rd → H un mapeo de características del espacio de entrada Rd a H, y K(xi, xj) =< φ(xi), φ(xj) >. Que X denote la matriz de datos en RKHS, X = (φ(x1), φ(x2), · · · , φ(xm)). De manera similar, definimos Z = (φ(z1), φ(z2), · · · , φ(zk)). Por lo tanto, el problema de optimización en RKHS se puede escribir de la siguiente manera: min Z Tr XT ZZT + λ1XLXT + λ2I −1 X (13) Dado que la función de mapeo φ generalmente es desconocida, no hay una forma directa de resolver el problema (13). En lo siguiente, aplicamos trucos de kernel para resolver este problema de optimización. Sea X−1 la inversa de Moore-Penrose (también conocida como pseudoinversa) de X. Así, tenemos: XT ZZT + λ1XLXT + λ2I −1 X = XT XX−1 ZZT + λ1XLXT + λ2I −1 (XT )−1 XT X = XT X ZZT X + λ1XLXT X + λ2X −1 (XT )−1 XT X = XT X XT ZZT X + λ1XT XLXT X + λ2XT X −1 XT X = KXX KXZKZX + λ1KXXLKXX + λ2KXX −1 KXX donde KXX es una matriz m × m (KXX,ij = K(xi, xj)), KXZ es una matriz m×k (KXZ,ij = K(xi, zj)), y KZX es una matriz k×m (KZX,ij = K(zi, xj)). Por lo tanto, el Diseño Óptimo del Laplaciano del Núcleo se puede definir de la siguiente manera: Definición 2. En este subapartado, discutimos cómo resolver los problemas de optimización (11) y (14). Particularmente, si seleccionamos un núcleo lineal para KLOD, entonces se reduce a LOD. Por lo tanto, nos enfocaremos en el problema (14) a continuación. Se puede demostrar que el problema de optimización (14) es NP-duro. En esta subsección, desarrollamos un enfoque codicioso secuencial simple para resolver (14). Supongamos que se han seleccionado n puntos, denotados por una matriz Zn = (z1, · · · , zn). El punto (n + 1)-ésimo zn+1 puede ser seleccionado resolviendo el siguiente problema de optimización: max Zn+1=(Zn,zn+1) Tr KXX KXZn+1 KZn+1X + λ1KXXLKXX + λ2KXX −1 KXX (15) Las matrices de kernel KXZn+1 y KZn+1X pueden ser reescritas de la siguiente manera: KXZn+1 = KXZn , KXzn+1 , KZn+1X = KZnX Kzn+1X Por lo tanto, tenemos: KXZn+1 KZn+1X = KXZn KZnX + KXzn+1 Kzn+1X Definimos: A = KXZn KZnX + λ1KXXLKXX + λ2KXX A solo depende de X y Zn. Por lo tanto, el punto (n + 1)-ésimo zn+1 se da por: zn+1 = arg min zn+1 Tr KXX A + KXzn+1 Kzn+1X −1 KXX. Cada vez que seleccionamos un nuevo punto zn+1, la matriz A se actualiza por: A ← A + KXzn+1 Kzn+1X. Si la función de kernel se elige como producto interno K(x, y) = x, y, entonces HK es un espacio funcional lineal y el algoritmo se reduce a LOD. 5. RECUPERACIÓN DE IMÁGENES BASADA EN CONTENIDO UTILIZANDO DISEÑO ÓPTIMO LAPLACIANO En esta sección, describimos cómo aplicar el Diseño Óptimo Laplaciano a la RCIB. Comenzamos con una breve descripción de la representación de imágenes utilizando características visuales de nivel bajo. 5.1 Representación de Imágenes de Nivel Bajo La representación de imágenes de nivel bajo es un problema crucial en la Recuperación de Información Basada en el Contenido (CBIR). Las características visuales generales incluyen color, textura, forma, etc. Las características de color y textura son las características visuales más ampliamente utilizadas en la recuperación de información basada en contenido (CBIR). En comparación con las características de color y textura, las características de forma suelen describirse después de que las imágenes hayan sido segmentadas en regiones u objetos. Dado que la segmentación de imágenes robusta y precisa es difícil de lograr, el uso de características de forma para la recuperación de imágenes se ha limitado a aplicaciones especiales donde los objetos o regiones están fácilmente disponibles. En este trabajo, combinamos un histograma de color de 64 dimensiones y un Momento de Textura de Color (CTM, [15]) de 64 dimensiones para representar las imágenes. El histograma de color se calcula utilizando 4 × 4 × 4 contenedores en el espacio HSV. El Momento de Textura de Color es propuesto por Yu et al. [15], el cual integra las características de color y textura de la imagen en una forma compacta. CTM adopta la transformada de Fourier local como un esquema de representación de texturas y deriva ocho mapas característicos para describir diferentes aspectos de las relaciones de co-ocurrencia de píxeles de imagen en cada canal del espacio de color (SVcosH, SVsinH, V). Entonces, CTM calcula el primer y segundo momento de estos mapas como una representación de la distribución de píxeles de la imagen en color natural. Por favor, consulte [15] para más detalles. 5.2 Recuperación de imágenes con retroalimentación de relevancia La retroalimentación de relevancia es una de las técnicas más importantes para reducir la brecha entre las características visuales de bajo nivel y los conceptos semánticos de alto nivel [12]. Tradicionalmente, los comentarios de relevancia de los usuarios se utilizan para actualizar el vector de consulta o ajustar el peso de las diferentes dimensiones. Este proceso puede ser visto como un proceso de aprendizaje en línea en el que el sistema de recuperación de imágenes actúa como un aprendiz y el usuario actúa como un maestro. El proceso típico de recuperación se describe de la siguiente manera: 1. El usuario envía un ejemplo de imagen de consulta al sistema. El sistema clasifica las imágenes en la base de datos según alguna métrica de distancia predefinida y presenta al usuario las imágenes mejor clasificadas. El sistema selecciona algunas imágenes de la base de datos y solicita al usuario que las etiquete como relevantes o irrelevantes. El sistema utiliza la información proporcionada por los usuarios para reorganizar las imágenes en la base de datos y devolver al usuario las imágenes principales. Ve al paso 2 hasta que el usuario esté satisfecho. Nuestro algoritmo de Diseño Óptimo de Laplaciano se aplica en el segundo paso para seleccionar las imágenes más informativas. Una vez que obtenemos las etiquetas para las imágenes seleccionadas por LOD, aplicamos la Regresión Regularizada Laplaciana (LRR, [2]) para resolver el problema de optimización (3) y construir el clasificador. El clasificador se utiliza luego para reordenar las imágenes en la base de datos. Ten en cuenta que, para reducir la complejidad computacional, no utilizamos todas las imágenes sin etiquetar en la base de datos, sino solo aquellas dentro de los 500 primeros resultados de la iteración anterior. 6. RESULTADOS EXPERIMENTALES En esta sección, evaluamos el rendimiento de nuestro algoritmo propuesto en una gran base de datos de imágenes. Para demostrar la efectividad de nuestro algoritmo LOD propuesto, lo comparamos con la Regresión Regularizada de Laplaciano (LRR, [2]), la Máquina de Vectores de Soporte (SVM), el Aprendizaje Activo de Máquina de Vectores de Soporte (SVMactive) [14], y el Diseño A-Óptimo (AOD). Tanto SVMactive, AOD y LOD son algoritmos de aprendizaje activo, mientras que LRR y SVM son algoritmos de clasificación estándar. SVM solo hace uso de las imágenes etiquetadas, mientras que LRR es un algoritmo de aprendizaje semi-supervisado que hace uso tanto de imágenes etiquetadas como no etiquetadas. Para SVMactive, AOD y LOD, los algoritmos seleccionan 10 imágenes de entrenamiento en cada iteración. Para LRR y SVM, utilizamos las 10 imágenes principales como datos de entrenamiento. Sería importante señalar que SVMactive se basa en el SVM ordinario, LOD se basa en LRR y AOD se basa en la regresión ordinaria. Los parámetros λ1 y λ2 en nuestro algoritmo LOD se establecen empíricamente en 0.001 y 0.00001. Para ambos algoritmos LRR y LOD, utilizamos la misma estructura de grafo (ver Ecuación 4) y establecemos el valor de p (número de vecinos más cercanos) en 5. Comenzamos con un ejemplo sintético simple para dar una intuición sobre cómo funciona LOD. 6.1 Ejemplo Sintético Simple Se presenta un ejemplo sintético simple en la Figura 1. El conjunto de datos contiene dos círculos. Ocho puntos son seleccionados por AOD y LOD. Como se puede ver, todos los puntos seleccionados por AOD son del círculo grande, mientras que LOD selecciona cuatro puntos del círculo grande y cuatro del círculo pequeño. Los números junto a los puntos seleccionados indican su orden de selección. Claramente, los puntos seleccionados por nuestro algoritmo LOD pueden representar mejor el conjunto de datos original. No comparamos nuestro algoritmo con SVMactive porque SVMactive no se puede aplicar en este caso debido a la falta de puntos etiquetados. 6.2 Diseño Experimental de Recuperación de Imágenes La base de datos de imágenes que utilizamos consta de 7,900 imágenes de 79 categorías semánticas, del conjunto de datos COREL. Es un conjunto de imágenes grande y heterogéneo. Cada imagen se representa como un vector de 128 dimensiones según se describe en la Sección 5.1. La Figura 2 muestra algunas imágenes de muestra. Para exhibir las ventajas de usar nuestro algoritmo, necesitamos una forma confiable de evaluar el rendimiento de recuperación y las comparaciones con otros algoritmos. Listamos a continuación diferentes aspectos del diseño experimental. 6.2.1 Métricas de Evaluación Utilizamos la curva de precisión-alcance y la tasa de precisión [10] para evaluar la efectividad de los algoritmos de recuperación de imágenes. El alcance está especificado por el número (N) de imágenes mejor clasificadas presentadas al usuario. La precisión es la proporción entre el número de imágenes relevantes presentadas al usuario y el (a) Conjunto de datos 1 2 3 4 5 6 7 8 (b) AOD 1 2 3 4 5 6 7 8 (c) LOD Figura 1: Selección de datos por algoritmos de aprendizaje activo. Los números junto a los puntos seleccionados indican su orden de selección. Claramente, los puntos seleccionados por nuestro algoritmo LOD pueden representar mejor el conjunto de datos original. Se debe tener en cuenta que el algoritmo SVMactive no se puede aplicar en este caso debido a la falta de puntos etiquetados. (a) (b) (c) Figura 2: Imágenes de muestra de las categorías cuentas, elefante y barco. El alcance de precisión describe la precisión con varios alcances y, por lo tanto, proporciona una evaluación general del rendimiento de los algoritmos. Por otro lado, la tasa de precisión enfatiza la precisión en un valor particular de alcance. En general, es apropiado presentar 20 imágenes en una pantalla. Agregar más imágenes en una pantalla puede afectar la calidad de las imágenes presentadas. Por lo tanto, la precisión en los primeros 20 (N = 20) es especialmente importante. En los sistemas de recuperación de imágenes del mundo real, la imagen de consulta generalmente no se encuentra en la base de datos de imágenes. Para simular dicho entorno, utilizamos validación cruzada de cinco pliegues para evaluar los algoritmos. Más precisamente, dividimos toda la base de datos de imágenes en cinco subconjuntos de tamaño igual. Por lo tanto, hay 20 imágenes por categoría en cada subconjunto. En cada ejecución de validación cruzada, se selecciona un subconjunto como conjunto de consulta, y los otros cuatro subconjuntos se utilizan como base de datos para la recuperación. La curva de precisión del precisionscope y la tasa de precisión se calculan promediando los resultados de la validación cruzada de cinco pliegues. 6.2.2 Esquema de retroalimentación automática de relevancia Diseñamos un esquema de retroalimentación automática para modelar el proceso de recuperación. Para cada consulta enviada, nuestro sistema recupera y clasifica las imágenes en la base de datos. Se seleccionaron 10 imágenes de la base de datos para que los usuarios las etiqueten y la información de las etiquetas es utilizada por el sistema para volver a clasificarlas. Ten en cuenta que las imágenes seleccionadas en iteraciones anteriores están excluidas de selecciones posteriores. Para cada consulta, se realiza el mecanismo de retroalimentación automática de relevancia durante cuatro iteraciones. Es importante señalar que el esquema de retroalimentación automática de relevancia utilizado aquí es diferente de los descritos en [8], [11]. En [8], [11], las cuatro imágenes relevantes e irrelevantes principales fueron seleccionadas como las imágenes de retroalimentación. Sin embargo, esto puede no ser práctico. En los sistemas de recuperación de imágenes del mundo real, es posible que la mayoría de las imágenes mejor clasificadas sean relevantes (o irrelevantes). Por lo tanto, es difícil para el usuario encontrar tanto cuatro imágenes relevantes como irrelevantes. Es más razonable que los usuarios proporcionen información de retroalimentación solo sobre las 10 imágenes seleccionadas por el sistema. 6.3 Rendimiento de recuperación de imágenes En el mundo real, no es práctico requerir que el usuario proporcione muchas rondas de retroalimentación. El rendimiento de recuperación después de las dos primeras rondas de retroalimentación (especialmente la primera ronda) es más importante. La Figura 3 muestra las curvas de precisión-alcance promedio de los diferentes algoritmos para las dos primeras iteraciones de retroalimentación. Al principio de la recuperación, las distancias euclidianas en el espacio original de 128 dimensiones se utilizan para clasificar las imágenes en la base de datos. Después de que el usuario proporcione retroalimentación de relevancia, se aplican los algoritmos LRR, SVM, SVMactive, AOD y LOD para volver a clasificar las imágenes. Para reducir la complejidad temporal de los algoritmos de aprendizaje activo, no seleccionamos las imágenes más informativas de toda la base de datos, sino de las 500 imágenes principales. Para LRR y SVM, se requiere que el usuario etiquete las 10 imágenes principales. Para SVMactive, AOD y LOD, se requiere que el usuario etiquete las 10 imágenes más informativas seleccionadas por estos algoritmos. Tenga en cuenta que, SVMactive solo puede ser ap(a) Iteración de retroalimentación 1 (b) Iteración de retroalimentación 2 Figura 3: Las curvas de precisión promedio-alcance de diferentes algoritmos para las dos primeras iteraciones de retroalimentación. El algoritmo LOD funciona mejor en todo el alcance. Se debe tener en cuenta que, en la primera ronda de retroalimentación, el algoritmo SVMactive no se puede aplicar. Se aplica el SVM ordinario para construir el clasificador inicial. (a) Precisión en el Top 10 (b) Precisión en el Top 20 (c) Precisión en el Top 30 Figura 4: Evaluación del rendimiento de los cinco algoritmos de aprendizaje para la recuperación de imágenes con retroalimentación de relevancia. (a) Precisión en el top 10, (b) Precisión en el top 20 y (c) Precisión en el top 30. Como se puede observar, nuestro algoritmo LOD supera consistentemente a los otros cuatro algoritmos. Por lo tanto, no se puede aplicar en la primera ronda y utilizamos el SVM estándar para construir el clasificador inicial. Como se puede ver, nuestro algoritmo LOD supera a los otros cuatro algoritmos en todo el ámbito. Además, el algoritmo LRR tiene un mejor rendimiento que SVM. Esto se debe a que el algoritmo LRR hace un uso eficiente de las imágenes no etiquetadas al incorporar un regularizador de preservación de la localidad en la función objetivo de regresión ordinaria. El algoritmo AOD es el que tiene peor rendimiento. A medida que el alcance se amplía, la diferencia de rendimiento entre estos algoritmos disminuye. Al agregar de forma iterativa los comentarios de los usuarios, los resultados de precisión correspondientes (en los primeros 10, 20 y 30 lugares) de los cinco algoritmos se muestran respectivamente en la Figura 4. Como se puede ver, nuestro algoritmo LOD tiene el mejor rendimiento en todos los casos y el algoritmo LRR tiene el segundo mejor rendimiento. Ambos de estos dos algoritmos hacen uso de las imágenes sin etiquetar. Esto demuestra que las imágenes sin etiquetar son útiles para descubrir la estructura geométrica intrínseca del espacio de imágenes y, por lo tanto, mejorar el rendimiento de recuperación. En el mundo real, es posible que el usuario no esté dispuesto a proporcionar demasiadas retroalimentaciones de relevancia. Por lo tanto, el rendimiento de recuperación en las primeras dos rondas es especialmente importante. Como se puede observar, nuestro algoritmo LOD logra una mejora del rendimiento del 6.8% para los 10 mejores resultados, del 5.2% para los 20 mejores resultados y del 4.1% para los 30 mejores resultados, en comparación con el segundo mejor algoritmo (LRR) después de las dos primeras rondas de retroalimentación de relevancia. 6.4 Discusión Se han realizado sistemáticamente varios experimentos en la base de datos de Corel. Nos gustaría resaltar varios puntos interesantes: 1. Es claro que el uso del aprendizaje activo es beneficioso en el ámbito de la recuperación de imágenes. Hay un aumento significativo en el rendimiento al utilizar los métodos de aprendizaje activo. Especialmente, de los tres métodos de aprendizaje activo (SVMactive, AOD, LOD), nuestro algoritmo propuesto LOD es el que tiene mejor rendimiento. En muchas aplicaciones del mundo real, como la recuperación de imágenes con retroalimentación de relevancia, generalmente hay dos formas de reducir la tarea laboriosa de etiquetado manual. Uno es el aprendizaje activo que selecciona las muestras más informativas para etiquetar, y el otro es el aprendizaje semi-supervisado que utiliza las muestras no etiquetadas para mejorar el rendimiento del aprendizaje. Ambas estrategias han sido estudiadas extensamente en el pasado [14], [7], [5], [8]. El trabajo presentado en este artículo se centra en el aprendizaje activo, pero también aprovecha los avances recientes en el aprendizaje semi-supervisado [2]. Específicamente, incorporamos un regularizador que preserva la localidad en el marco de regresión estándar y encontramos las muestras más informativas con respecto a la nueva función objetivo. De esta manera, las técnicas de aprendizaje activo y de aprendizaje semi-supervisado se unifican de manera fluida para aprender un clasificador óptimo. 3. La técnica de retroalimentación de relevancia es crucial para la recuperación de imágenes. Para los cinco algoritmos, el rendimiento de recuperación mejora con más retroalimentación proporcionada por el usuario. CONCLUSIONES Y TRABAJOS FUTUROS Este artículo describe un novedoso algoritmo de aprendizaje activo, llamado Diseño Óptimo Laplaciano, para permitir una recuperación de imágenes con retroalimentación de relevancia más efectiva. Nuestro algoritmo se basa en una función objetivo que minimiza simultáneamente el error empírico y preserva la estructura geométrica local del espacio de datos. Utilizando técnicas de diseño experimental, nuestro algoritmo encuentra las imágenes más informativas para etiquetar. Estas imágenes etiquetadas y las imágenes sin etiquetar en la base de datos se utilizan para aprender un clasificador. Los resultados experimentales en la base de datos Corel muestran que tanto el aprendizaje activo como el aprendizaje semi-supervisado pueden mejorar significativamente el rendimiento de recuperación. En este documento, consideramos el problema de recuperación de imágenes en un conjunto de datos de imágenes pequeño, estático y de dominio cerrado. Un dominio mucho más desafiante es la World Wide Web (WWW). Para la búsqueda de imágenes en la web, es posible recopilar una gran cantidad de información sobre los clics de los usuarios. Esta información puede ser utilizada de forma natural para construir el grafo de afinidad en nuestro algoritmo. Sin embargo, la complejidad computacional en el escenario web puede convertirse en un problema crucial. Además, aunque nuestro interés principal en este artículo se centra en la recuperación de imágenes con retroalimentación de relevancia, nuestros resultados también pueden ser de interés para investigadores en reconocimiento de patrones y aprendizaje automático, especialmente cuando hay una gran cantidad de datos disponibles pero solo se pueden etiquetar muestras limitadas. 8. REFERENCIAS [1] A. C. Atkinson y A. N. Donev. Diseños experimentales óptimos. Oxford University Press, 2002. [2] M. Belkin, P. Niyogi, y V. Sindhwani. Regularización de variedades: Un marco geométrico para el aprendizaje a partir de ejemplos. Revista de Investigación de Aprendizaje Automático, 7:2399-2434, 2006. [3] F. R. K. Chung. Teoría Espectral de Grafos, volumen 92 de la Serie de Conferencias Regionales en Matemáticas. AMS, 1997. [4] D. A. Cohn, Z. Ghahramani y M. I. Jordan. Aprendizaje activo con modelos estadísticos. Revista de Investigación en Inteligencia Artificial, 4:129-145, 1996. [5] A. Dong y B. Bhanu. Un nuevo algoritmo EM semisupervisado para la recuperación de imágenes. En la Conferencia IEEE sobre Visión por Computadora y Reconocimiento de Patrones, Madison, WI, 2003. [6] P. Flaherty, M. I. Jordan y A. P. Arkin. Diseño robusto de experimentos biológicos. En Advances in Neural Information Processing Systems 18, Vancouver, Canadá, 2005. [7] K.-S. Goh, E. Y. Chang y W.-C. Lai. Aprendizaje activo dependiente del concepto multimodal para la recuperación de imágenes. En Actas de la Conferencia ACM sobre Multimedia, Nueva York, octubre de 2004. [8] X. Lo siento, la oración \"He.\" no tiene un significado claro en inglés. ¿Podrías proporcionar más contexto o una oración completa para que pueda traducirla al español de manera precisa? Aprendizaje de subespacios semisupervisado incremental para la recuperación de imágenes. En Actas de la Conferencia ACM sobre Multimedia, Nueva York, octubre de 2004. [9] S. C. Hoi y M. R. Lyu. Un marco de aprendizaje activo semi-supervisado para la recuperación de imágenes. En la Conferencia Internacional de IEEE sobre Visión por Computadora y Reconocimiento de Patrones, San Diego, CA, 2005. [10] D. P. Huijsmans y N. Sebe. Cómo completar los gráficos de rendimiento en la recuperación de imágenes basada en contenido: Agregar generalidad y normalizar el alcance. IEEE Transactions on Pattern Analysis and Machine Intelligence, 27(2):245-251, 2005. [11] Y.-Y.\n\nTransacciones del IEEE sobre Inteligencia Artificial y Análisis de Patrones, 27(2):245-251, 2005. [11] Y.-Y. Lin, T.-L. Liu y H.-T. Chen. Aprendizaje de variedades semánticas para la recuperación de imágenes. En Actas de la Conferencia ACM sobre Multimedia, Singapur, noviembre de 2005. [12] Y. Rui, T. S. Huang, M. Ortega y S. Mehrotra. Retroalimentación de relevancia: Una herramienta poderosa para la recuperación de imágenes basada en contenido de forma interactiva. IEEE Transactions on Circuits and Systems for Video Technology, 8(5), 1998. [13] A. W. Smeulders, M. Worring, S. Santini, A. Gupta, and R. Jain. \n\nTraducción: IEEE Transactions on Circuits and Systems for Video Technology, 8(5), 1998. [13] A. W. Smeulders, M. Worring, S. Santini, A. Gupta y R. Jain. Recuperación de imágenes basada en contenido al final de los primeros años. IEEE Transactions on Pattern Analysis and Machine Intelligence, 22(12):1349-1380, 2000. [14] S. Tong y E. Chang. Aprendizaje activo de máquina de vectores de soporte para recuperación de imágenes. En Actas de la novena conferencia internacional de ACM sobre Multimedia, páginas 107-118, 2001. [15] H. Yu, M. Li, H.-J. Zhang y J. Feng. Momentos de textura de color para la recuperación de imágenes basada en contenido. En la Conferencia Internacional de Procesamiento de Imágenes, páginas 24-28, 2002. [16] K. Yu, J. Bi y V. Tresp. Aprendizaje activo a través del diseño experimental transductivo. En Actas de la 23ª Conferencia Internacional sobre Aprendizaje Automático, Pittsburgh, PA, 2006. ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "active learning": {
            "translated_key": "aprendizaje activo",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Laplacian Optimal Design for Image Retrieval Xiaofei He Yahoo!",
                "Burbank, CA 91504 hex@yahoo-inc.com Wanli Min IBM Yorktown Heights, NY 10598 wanlimin@us.ibm.com Deng Cai CS Dept., UIUC Urbana, IL 61801 dengcai2@cs.uiuc.edu Kun Zhou Microsoft Research Asia Beijing, China kunzhou@microsoft.com ABSTRACT Relevance feedback is a powerful technique to enhance ContentBased Image Retrieval (CBIR) performance.",
                "It solicits the users relevance judgments on the retrieved images returned by the CBIR systems.",
                "The users labeling is then used to learn a classifier to distinguish between relevant and irrelevant images.",
                "However, the top returned images may not be the most informative ones.",
                "The challenge is thus to determine which unlabeled images would be the most informative (i.e., improve the classifier the most) if they were labeled and used as training samples.",
                "In this paper, we propose a novel <br>active learning</br> algorithm, called Laplacian Optimal Design (LOD), for relevance feedback image retrieval.",
                "Our algorithm is based on a regression model which minimizes the least square error on the measured (or, labeled) images and simultaneously preserves the local geometrical structure of the image space.",
                "Specifically, we assume that if two images are sufficiently close to each other, then their measurements (or, labels) are close as well.",
                "By constructing a nearest neighbor graph, the geometrical structure of the image space can be described by the graph Laplacian.",
                "We discuss how results from the field of optimal experimental design may be used to guide our selection of a subset of images, which gives us the most amount of information.",
                "Experimental results on Corel database suggest that the proposed approach achieves higher precision in relevance feedback image retrieval.",
                "Categories and Subject Descriptors H.3.3 [Information storage and retrieval]: Information search and retrieval-Relevance feedback; G.3 [Mathematics of Computing]: Probability and Statistics-Experimental design General Terms Algorithms, Performance, Theory 1.",
                "INTRODUCTION In many machine learning and information retrieval tasks, there is no shortage of unlabeled data but labels are expensive.",
                "The challenge is thus to determine which unlabeled samples would be the most informative (i.e., improve the classifier the most) if they were labeled and used as training samples.",
                "This problem is typically called <br>active learning</br> [4].",
                "Here the task is to minimize an overall cost, which depends both on the classifier accuracy and the cost of data collection.",
                "Many real world applications can be casted into <br>active learning</br> framework.",
                "Particularly, we consider the problem of relevance feedback driven Content-Based Image Retrieval (CBIR) [13].",
                "Content-Based Image Retrieval has attracted substantial interests in the last decade [13].",
                "It is motivated by the fast growth of digital image databases which, in turn, require efficient search schemes.",
                "Rather than describe an image using text, in these systems an image query is described using one or more example images.",
                "The low level visual features (color, texture, shape, etc.) are automatically extracted to represent the images.",
                "However, the low level features may not accurately characterize the high level semantic concepts.",
                "To narrow down the semantic gap, relevance feedback is introduced into CBIR [12].",
                "In many of the current relevance feedback driven CBIR systems, the user is required to provide his/her relevance judgments on the top images returned by the system.",
                "The labeled images are then used to train a classifier to separate images that match the query concept from those that do not.",
                "However, in general the top returned images may not be the most informative ones.",
                "In the worst case, all the top images labeled by the user may be positive and thus the standard classification techniques can not be applied due to the lack of negative examples.",
                "Unlike the standard classification problems where the labeled samples are pregiven, in relevance feedback image retrieval the system can actively select the images to label.",
                "Thus <br>active learning</br> can be naturally introduced into image retrieval.",
                "Despite many existing <br>active learning</br> techniques, Support Vector Machine (SVM) <br>active learning</br> [14] and regression based active learning [1] have received the most interests.",
                "Based on the observation that the closer to the SVM boundary an image is, the less reliable its classification is, SVM <br>active learning</br> selects those unlabeled images closest to the boundary to solicit user feedback so as to achieve maximal refinement on the hyperplane between the two classes.",
                "The major disadvantage of SVM <br>active learning</br> is that the estimated boundary may not be accurate enough.",
                "Moreover, it may not be applied at the beginning of the retrieval when there is no labeled images.",
                "Some other SVM based <br>active learning</br> algorithms can be found in [7], [9].",
                "In statistics, the problem of selecting samples to label is typically referred to as experimental design.",
                "The sample x is referred to as experiment, and its label y is referred to as measurement.",
                "The study of optimal experimental design (OED) [1] is concerned with the design of experiments that are expected to minimize variances of a parameterized model.",
                "The intent of optimal experimental design is usually to maximize confidence in a given model, minimize parameter variances for system identification, or minimize the models output variance.",
                "Classical experimental design approaches include A-Optimal Design, D-Optimal Design, and E-Optimal Design.",
                "All of these approaches are based on a least squares regression model.",
                "Comparing to SVM based <br>active learning</br> algorithms, experimental design approaches are much more efficient in computation.",
                "However, this kind of approaches takes only measured (or, labeled) data into account in their objective function, while the unmeasured (or, unlabeled) data is ignored.",
                "Benefit from recent progresses on optimal experimental design and semi-supervised learning, in this paper we propose a novel <br>active learning</br> algorithm for image retrieval, called Laplacian Optimal Design (LOD).",
                "Unlike traditional experimental design methods whose loss functions are only defined on the measured points, the loss function of our proposed LOD algorithm is defined on both measured and unmeasured points.",
                "Specifically, we introduce a locality preserving regularizer into the standard least-square-error based loss function.",
                "The new loss function aims to find a classifier which is locally as smooth as possible.",
                "In other words, if two points are sufficiently close to each other in the input space, then they are expected to share the same label.",
                "Once the loss function is defined, we can select the most informative data points which are presented to the user for labeling.",
                "It would be important to note that the most informative images may not be the top returned images.",
                "The rest of the paper is organized as follows.",
                "In Section 2, we provide a brief description of the related work.",
                "Our proposed Laplacian Optimal Design algorithm is introduced in Section 3.",
                "In Section 4, we compare our algorithm with the state-or-the-art algorithms and present the experimental results on image retrieval.",
                "Finally, we provide some concluding remarks and suggestions for future work in Section 5. 2.",
                "RELATED WORK Since our proposed algorithm is based on regression framework.",
                "The most related work is optimal experimental design [1], including A-Optimal Design, D-Optimal Design, and EOptimal Design.",
                "In this Section, we give a brief description of these approaches. 2.1 The <br>active learning</br> Problem The generic problem of <br>active learning</br> is the following.",
                "Given a set of points A = {x1, x2, · · · , xm} in Rd , find a subset B = {z1, z2, · · · , zk} ⊂ A which contains the most informative points.",
                "In other words, the points zi(i = 1, · · · , k) can improve the classifier the most if they are labeled and used as training points. 2.2 Optimal Experimental Design We consider a linear regression model y = wT x + (1) where y is the observation, x is the independent variable, w is the weight vector and is an unknown error with zero mean.",
                "Different observations have errors that are independent, but with equal variances σ2 .",
                "We define f(x) = wT x to be the learners output given input x and the weight vector w. Suppose we have a set of labeled sample points (z1, y1), · · · , (zk, yk), where yi is the label of zi.",
                "Thus, the maximum likelihood estimate for the weight vector, ˆw, is that which minimizes the sum squared error Jsse(w) = k i=1 wT zi − yi 2 (2) The estimate ˆw gives us an estimate of the output at a novel input: ˆy = ˆwT x.",
                "By Gauss-Markov theorem, we know that ˆw − w has a zero mean and a covariance matrix given by σ2 H−1 sse, where Hsse is the Hessian of Jsse(w) Hsse = ∂2 Jsse ∂w2 = k i=1 zizT i = ZZT where Z = (z1, z2, · · · , zk).",
                "The three most common scalar measures of the size of the parameter covariance matrix in optimal experimental design are: • D-optimal design: determinant of Hsse. • A-optimal design: trace of Hsse. • E-optimal design: maximum eigenvalue of Hsse.",
                "Since the computation of the determinant and eigenvalues of a matrix is much more expensive than the computation of matrix trace, A-optimal design is more efficient than the other two.",
                "Some recent work on experimental design can be found in [6], [16]. 3.",
                "LAPLACIAN OPTIMAL DESIGN Since the covariance matrix Hsse used in traditional approaches is only dependent on the measured samples, i.e. zis, these approaches fail to evaluate the expected errors on the unmeasured samples.",
                "In this Section, we introduce a novel <br>active learning</br> algorithm called Laplacian Optimal Design (LOD) which makes efficient use of both measured (labeled) and unmeasured (unlabeled) samples. 3.1 The Objective Function In many machine learning problems, it is natural to assume that if two points xi, xj are sufficiently close to each other, then their measurements (f(xi), f(xj)) are close as well.",
                "Let S be a similarity matrix.",
                "Thus, a new loss function which respects the geometrical structure of the data space can be defined as follows: J0(w) = k i=1 f(zi)−yi 2 + λ 2 m i,j=1 f(xi)−f(xj) 2 Sij (3) where yi is the measurement (or, label) of zi.",
                "Note that, the loss function (3) is essentially the same as the one used in Laplacian Regularized Regression (LRR, [2]).",
                "However, LRR is a passive learning algorithm where the training data is given.",
                "In this paper, we are focused on how to select the most informative data for training.",
                "The loss function with our choice of symmetric weights Sij (Sij = Sji) incurs a heavy penalty if neighboring points xi and xj are mapped far apart.",
                "Therefore, minimizing J0(w) is an attempt to ensure that if xi and xj are close then f(xi) and f(xj) are close as well.",
                "There are many choices of the similarity matrix S. A simple definition is as follows: Sij = ⎧ ⎨ ⎩ 1, if xi is among the p nearest neighbors of xj, or xj is among the p nearest neighbors of xi; 0, otherwise. (4) Let D be a diagonal matrix, Dii = j Sij, and L = D−S.",
                "The matrix L is called graph Laplacian in spectral graph theory [3].",
                "Let y = (y1, · · · , yk)T and X = (x1, · · · , xm).",
                "Following some simple algebraic steps, we see that: J0(w) = k i=1 wT zi − yi 2 + λ 2 m i,j=1 wT xi − wT xj 2 Sij = y − ZT w T y − ZT w + λwT m i=1 DiixixT i − m i,j=1 SijxixT j w = yT y − 2wT Zy + wT ZZT w +λwT XDXT − XSXT w = yT y − 2wT Zy + wT ZZT + λXLXT w The Hessian of J0(w) can be computed as follows: H0 = ∂2 J0 ∂w2 = ZZT + λXLXT In some cases, the matrix ZZT +λXLXT is singular (e.g. if m < d).",
                "Thus, there is no stable solution to the optimization problem Eq. (3).",
                "A common way to deal with this ill-posed problem is to introduce a Tikhonov regularizer into our loss function: J(w) = k i=1 wT zi − yi 2 + λ1 2 m i,j=1 wT xi − wT xj 2 Sij +λ2 w 2 (5) The Hessian of the new loss function is given by: H = ∂2 J ∂w2 = ZZT + λ1XLXT + λ2I := ZZT + Λ where I is an identity matrix and Λ = λ1XLXT + λ2I.",
                "Clearly, H is of full rank.",
                "Requiring that the gradient of J(w) with respect to w vanish gives the optimal estimate ˆw: ˆw = H−1 Zy The following proposition states the bias and variance properties of the estimator for the coefficient vector w. Proposition 3.1.",
                "E( ˆw − w) = −H−1 Λw, Cov( ˆw) = σ2 (H−1 − H−1 ΛH−1 ) Proof.",
                "Since y = ZT w + and E( ) = 0, it follows that E( ˆw − w) (6) = H−1 ZZT w − w = H−1 (ZZT + Λ − Λ)w − w = (I − H−1 Λ)w − w = −H−1 Λw (7) Notice Cov(y) = σ2 I, the covariance matrix of ˆw has the expression: Cov( ˆw) = H−1 ZCov(y)ZT H−1 = σ2 H−1 ZZT H−1 = σ2 H−1 (H − Λ)H−1 = σ2 (H−1 − H−1 ΛH−1 ) (8) Therefore mean squared error matrix for the coefficients w is E(w − ˆw)(w − ˆw)T (9) = H−1 ΛwwT ΛH−1 + σ2 (H−1 − H−1 ΛH−1 ) (10) For any x, let ˆy = ˆwT x be its predicted observation.",
                "The expected squared prediction error is E(y − ˆy)2 = E( + wT x − ˆwT x)2 = σ2 + xT [E(w − ˆw)(w − ˆw)T ]x = σ2 + xT [H−1 ΛwwT ΛH−1 + σ2 H−1 − σ2 H−1 ΛH−1 ]x Clearly the expected square prediction error depends on the explanatory variable x, therefore average expected square predictive error over the complete data set A is 1 m m i=1 E(yi − ˆwT xi)2 = 1 m m i=1 xT i [H−1 ΛwwT ΛH−1 + σ2 H−1 − σ2 H−1 ΛH−1 ]xi +σ2 = 1 m Tr(XT [σ2 H−1 + H−1 ΛwwT ΛH−1 − σ2 H−1 ΛH−1 ]X) +σ2 Since Tr(XT [H−1 ΛwwT ΛH−1 − σ2 H−1 ΛH−1 ]X) Tr(σ2 XT H−1 X), Our Laplacian optimality criterion is thus formulated by minimizing the trace of XT H−1 X.",
                "Definition 1.",
                "Laplacian Optimal Design min Z=(z1,··· ,zk) Tr XT ZZT + λ1XLXT + λ2I −1 X (11) where z1, · · · , zk are selected from {x1, · · · , xm}. 4.",
                "KERNEL LAPLACIAN OPTIMAL DESIGN Canonical experimental design approaches (e.g.",
                "A-Optimal Design, D-Optimal Design, and E-Optimal) only consider linear functions.",
                "They fail to discover the intrinsic geometry in the data when the data space is highly nonlinear.",
                "In this section, we describe how to perform Laplacian Experimental Design in Reproducing Kernel Hilbert Space (RKHS) which gives rise to Kernel Laplacian Experimental Design (KLOD).",
                "For given data points x1, · · · , xm ∈ X with a positive definite mercer kernel K : X ×X → R, there exists a unique RKHS HK of real valued functions on X.",
                "Let Kt(s) be the function of s obtained by fixing t and letting Kt(s) . = K(s, t).",
                "HK consists of all finite linear combinations of the form l i=1 αiKti with ti ∈ X and limits of such functions as the ti become dense in X.",
                "We have Ks, Kt HK = K(s, t). 4.1 Derivation of LOD in Reproducing Kernel Hilbert Space Consider the optimization problem (5) in RKHS.",
                "Thus, we seek a function f ∈ HK such that the following objective function is minimized: min f∈HK k i=1 f(zi)−yi 2 + λ1 2 m i,j=1 f(xi)−f(xj) 2 Sij+λ2 f 2 HK (12) We have the following proposition.",
                "Proposition 4.1.",
                "Let H = { m i=1 αiK(·, xi)|αi ∈ R} be a subspace of HK , the solution to the problem (12) is in H. Proof.",
                "Let H⊥ be the orthogonal complement of H, i.e.",
                "HK = H ⊕ H⊥ .",
                "Thus, for any function f ∈ HK , it has orthogonal decomposition as follows: f = fH + fH⊥ Now, lets evaluate f at xi: f(xi) = f, Kxi HK = fH + fH⊥ , Kxi HK = fH, Kxi HK + fH⊥ , Kxi HK Notice that Kxi ∈ H while fH⊥ ∈ H⊥ .",
                "This implies that fH⊥ , Kxi HK = 0.",
                "Therefore, f(xi) = fH, Kxi HK = fH(xi) This completes the proof.",
                "Proposition 4.1 tells us the minimizer of problem (12) admits a representation f∗ = m i=1 αiK(·, xi).",
                "Please see [2] for the details.",
                "Let φ : Rd → H be a feature map from the input space Rd to H, and K(xi, xj) =< φ(xi), φ(xj) >.",
                "Let X denote the data matrix in RKHS, X = (φ(x1), φ(x2), · · · , φ(xm)).",
                "Similarly, we define Z = (φ(z1), φ(z2), · · · , φ(zk)).",
                "Thus, the optimization problem in RKHS can be written as follows: min Z Tr XT ZZT + λ1XLXT + λ2I −1 X (13) Since the mapping function φ is generally unknown, there is no direct way to solve problem (13).",
                "In the following, we apply kernel tricks to solve this optimization problem.",
                "Let X−1 be the Moore-Penrose inverse (also known as pseudo inverse) of X.",
                "Thus, we have: XT ZZT + λ1XLXT + λ2I −1 X = XT XX−1 ZZT + λ1XLXT + λ2I −1 (XT )−1 XT X = XT X ZZT X + λ1XLXT X + λ2X −1 (XT )−1 XT X = XT X XT ZZT X + λ1XT XLXT X + λ2XT X −1 XT X = KXX KXZKZX + λ1KXXLKXX + λ2KXX −1 KXX where KXX is a m × m matrix (KXX,ij = K(xi, xj)), KXZ is a m×k matrix (KXZ,ij = K(xi, zj)), and KZX is a k×m matrix (KZX,ij = K(zi, xj)).",
                "Thus, the Kernel Laplacian Optimal Design can be defined as follows: Definition 2.",
                "Kernel Laplacian Optimal Design minZ=(z1,··· ,zk) Tr KXX KXZKZX + λ1KXXLKXX λ2KXX −1 KXX (14) 4.2 Optimization Scheme In this subsection, we discuss how to solve the optimization problems (11) and (14).",
                "Particularly, if we select a linear kernel for KLOD, then it reduces to LOD.",
                "Therefore, we will focus on problem (14) in the following.",
                "It can be shown that the optimization problem (14) is NP-hard.",
                "In this subsection, we develop a simple sequential greedy approach to solve (14).",
                "Suppose n points have been selected, denoted by a matrix Zn = (z1, · · · , zn).",
                "The (n + 1)-th point zn+1 can be selected by solving the following optimization problem: max Zn+1=(Zn,zn+1) Tr KXX KXZn+1 KZn+1X + λ1KXXLKXX + λ2KXX −1 KXX (15) The kernel matrices KXZn+1 and KZn+1X can be rewritten as follows: KXZn+1 = KXZn , KXzn+1 , KZn+1X = KZnX Kzn+1X Thus, we have: KXZn+1 KZn+1X = KXZn KZnX + KXzn+1 Kzn+1X We define: A = KXZn KZnX + λ1KXXLKXX + λ2KXX A is only dependent on X and Zn .",
                "Thus, the (n + 1)-th point zn+1 is given by: zn+1 = arg min zn+1 Tr KXX A + KXzn+1 Kzn+1X −1 KXX (16) Each time we select a new point zn+1, the matrix A is updated by: A ← A + KXzn+1 Kzn+1X If the kernel function is chosen as inner product K(x, y) = x, y , then HK is a linear functional space and the algorithm reduces to LOD. 5.",
                "CONTENT-BASED IMAGE RETRIEVAL USING LAPLACIAN OPTIMAL DESIGN In this section, we describe how to apply Laplacian Optimal Design to CBIR.",
                "We begin with a brief description of image representation using low level visual features. 5.1 Low-Level Image Representation Low-level image representation is a crucial problem in CBIR.",
                "General visual features includes color, texture, shape, etc.",
                "Color and texture features are the most extensively used visual features in CBIR.",
                "Compared with color and texture features, shape features are usually described after images have been segmented into regions or objects.",
                "Since robust and accurate image segmentation is difficult to achieve, the use of shape features for image retrieval has been limited to special applications where objects or regions are readily available.",
                "In this work, We combine 64-dimensional color histogram and 64-dimensional Color Texture Moment (CTM, [15]) to represent the images.",
                "The color histogram is calculated using 4 × 4 × 4 bins in HSV space.",
                "The Color Texture Moment is proposed by Yu et al. [15], which integrates the color and texture characteristics of the image in a compact form.",
                "CTM adopts local Fourier transform as a texture representation scheme and derives eight characteristic maps to describe different aspects of co-occurrence relations of image pixels in each channel of the (SVcosH, SVsinH, V) color space.",
                "Then CTM calculates the first and second moment of these maps as a representation of the natural color image pixel distribution.",
                "Please see [15] for details. 5.2 Relevance Feedback Image Retrieval Relevance feedback is one of the most important techniques to narrow down the gap between low level visual features and high level semantic concepts [12].",
                "Traditionally, the users relevance feedbacks are used to update the query vector or adjust the weighting of different dimensions.",
                "This process can be viewed as an on-line learning process in which the image retrieval system acts as a learner and the user acts as a teacher.",
                "They typical retrieval process is outlined as follows: 1.",
                "The user submits a query image example to the system.",
                "The system ranks the images in database according to some pre-defined distance metric and presents to the user the top ranked images. 2.",
                "The system selects some images from the database and request the user to label them as relevant or irrelevant. 3.",
                "The system uses the users provided information to rerank the images in database and returns to the user the top images.",
                "Go to step 2 until the user is satisfied.",
                "Our Laplacian Optimal Design algorithm is applied in the second step for selecting the most informative images.",
                "Once we get the labels for the images selected by LOD, we apply Laplacian Regularized Regression (LRR, [2]) to solve the optimization problem (3) and build the classifier.",
                "The classifier is then used to re-rank the images in database.",
                "Note that, in order to reduce the computational complexity, we do not use all the unlabeled images in the database but only those within top 500 returns of previous iteration. 6.",
                "EXPERIMENTAL RESULTS In this section, we evaluate the performance of our proposed algorithm on a large image database.",
                "To demonstrate the effectiveness of our proposed LOD algorithm, we compare it with Laplacian Regularized Regression (LRR, [2]), Support Vector Machine (SVM), Support Vector Machine <br>active learning</br> (SVMactive) [14], and A-Optimal Design (AOD).",
                "Both SVMactive, AOD, and LOD are <br>active learning</br> algorithms, while LRR and SVM are standard classification algorithms.",
                "SVM only makes use of the labeled images, while LRR is a semi-supervised learning algorithm which makes use of both labeled and unlabeled images.",
                "For SVMactive, AOD, and LOD, 10 training images are selected by the algorithms themselves at each iteration.",
                "While for LRR and SVM, we use the top 10 images as training data.",
                "It would be important to note that SVMactive is based on the ordinary SVM, LOD is based on LRR, and AOD is based on the ordinary regression.",
                "The parameters λ1 and λ2 in our LOD algorithm are empirically set to be 0.001 and 0.00001.",
                "For both LRR and LOD algorithms, we use the same graph structure (see Eq. 4) and set the value of p (number of nearest neighbors) to be 5.",
                "We begin with a simple synthetic example to give some intuition about how LOD works. 6.1 Simple Synthetic Example A simple synthetic example is given in Figure 1.",
                "The data set contains two circles.",
                "Eight points are selected by AOD and LOD.",
                "As can be seen, all the points selected by AOD are from the big circle, while LOD selects four points from the big circle and four from the small circle.",
                "The numbers beside the selected points denote their orders to be selected.",
                "Clearly, the points selected by our LOD algorithm can better represent the original data set.",
                "We did not compare our algorithm with SVMactive because SVMactive can not be applied in this case due to the lack of the labeled points. 6.2 Image Retrieval Experimental Design The image database we used consists of 7,900 images of 79 semantic categories, from COREL data set.",
                "It is a large and heterogeneous image set.",
                "Each image is represented as a 128-dimensional vector as described in Section 5.1.",
                "Figure 2 shows some sample images.",
                "To exhibit the advantages of using our algorithm, we need a reliable way of evaluating the retrieval performance and the comparisons with other algorithms.",
                "We list different aspects of the experimental design below. 6.2.1 Evaluation Metrics We use precision-scope curve and precision rate [10] to evaluate the effectiveness of the image retrieval algorithms.",
                "The scope is specified by the number (N) of top-ranked images presented to the user.",
                "The precision is the ratio of the number of relevant images presented to the user to the (a) Data set 1 2 3 4 5 6 7 8 (b) AOD 1 2 3 4 5 6 7 8 (c) LOD Figure 1: Data selection by <br>active learning</br> algorithms.",
                "The numbers beside the selected points denote their orders to be selected.",
                "Clearly, the points selected by our LOD algorithm can better represent the original data set.",
                "Note that, the SVMactive algorithm can not be applied in this case due to the lack of labeled points. (a) (b) (c) Figure 2: Sample images from category bead, elephant, and ship. scope N. The precision-scope curve describes the precision with various scopes and thus gives an overall performance evaluation of the algorithms.",
                "On the other hand, the precision rate emphasizes the precision at a particular value of scope.",
                "In general, it is appropriate to present 20 images on a screen.",
                "Putting more images on a screen may affect the quality of the presented images.",
                "Therefore, the precision at top 20 (N = 20) is especially important.",
                "In real world image retrieval systems, the query image is usually not in the image database.",
                "To simulate such environment, we use five-fold cross validation to evaluate the algorithms.",
                "More precisely, we divide the whole image database into five subsets with equal size.",
                "Thus, there are 20 images per category in each subset.",
                "At each run of cross validation, one subset is selected as the query set, and the other four subsets are used as the database for retrieval.",
                "The precisionscope curve and precision rate are computed by averaging the results from the five-fold cross validation. 6.2.2 Automatic Relevance Feedback Scheme We designed an automatic feedback scheme to model the retrieval process.",
                "For each submitted query, our system retrieves and ranks the images in the database. 10 images were selected from the database for user labeling and the label information is used by the system for re-ranking.",
                "Note that, the images which have been selected at previous iterations are excluded from later selections.",
                "For each query, the automatic relevance feedback mechanism is performed for four iterations.",
                "It is important to note that the automatic relevance feedback scheme used here is different from the ones described in [8], [11].",
                "In [8], [11], the top four relevant and irrelevant images were selected as the feedback images.",
                "However, this may not be practical.",
                "In real world image retrieval systems, it is possible that most of the top-ranked images are relevant (or, irrelevant).",
                "Thus, it is difficult for the user to find both four relevant and irrelevant images.",
                "It is more reasonable for the users to provide feedback information only on the 10 images selected by the system. 6.3 Image Retrieval Performance In real world, it is not practical to require the user to provide many rounds of feedbacks.",
                "The retrieval performance after the first two rounds of feedbacks (especially the first round) is more important.",
                "Figure 3 shows the average precision-scope curves of the different algorithms for the first two feedback iterations.",
                "At the beginning of retrieval, the Euclidean distances in the original 128-dimensional space are used to rank the images in database.",
                "After the user provides relevance feedbacks, the LRR, SVM, SVMactive, AOD, and LOD algorithms are then applied to re-rank the images.",
                "In order to reduce the time complexity of <br>active learning</br> algorithms, we didnt select the most informative images from the whole database but from the top 500 images.",
                "For LRR and SVM, the user is required to label the top 10 images.",
                "For SVMactive, AOD, and LOD, the user is required to label 10 most informative images selected by these algorithms.",
                "Note that, SVMactive can only be ap(a) Feedback Iteration 1 (b) Feedback Iteration 2 Figure 3: The average precision-scope curves of different algorithms for the first two feedback iterations.",
                "The LOD algorithm performs the best on the entire scope.",
                "Note that, at the first round of feedback, the SVMactive algorithm can not be applied.",
                "It applies the ordinary SVM to build the initial classifier. (a) Precision at Top 10 (b) Precision at Top 20 (c) Precision at Top 30 Figure 4: Performance evaluation of the five learning algorithms for relevance feedback image retrieval. (a) Precision at top 10, (b) Precision at top 20, and (c) Precision at top 30.",
                "As can be seen, our LOD algorithm consistently outperforms the other four algorithms. plied when the classifier is already built.",
                "Therefore, it can not be applied at the first round and we use the standard SVM to build the initial classifier.",
                "As can be seen, our LOD algorithm outperforms the other four algorithms on the entire scope.",
                "Also, the LRR algorithm performs better than SVM.",
                "This is because that the LRR algorithm makes efficient use of the unlabeled images by incorporating a locality preserving regularizer into the ordinary regression objective function.",
                "The AOD algorithm performs the worst.",
                "As the scope gets larger, the performance difference between these algorithms gets smaller.",
                "By iteratively adding the users feedbacks, the corresponding precision results (at top 10, top 20, and top 30) of the five algorithms are respectively shown in Figure 4.",
                "As can be seen, our LOD algorithm performs the best in all the cases and the LRR algorithm performs the second best.",
                "Both of these two algorithms make use of the unlabeled images.",
                "This shows that the unlabeled images are helpful for discovering the intrinsic geometrical structure of the image space and therefore enhance the retrieval performance.",
                "In real world, the user may not be willing to provide too many relevance feedbacks.",
                "Therefore, the retrieval performance at the first two rounds are especially important.",
                "As can be seen, our LOD algorithm achieves 6.8% performance improvement for top 10 results, 5.2% for top 20 results, and 4.1% for top 30 results, comparing to the second best algorithm (LRR) after the first two rounds of relevance feedbacks. 6.4 Discussion Several experiments on Corel database have been systematically performed.",
                "We would like to highlight several interesting points: 1.",
                "It is clear that the use of <br>active learning</br> is beneficial in the image retrieval domain.",
                "There is a significant increase in performance from using the <br>active learning</br> methods.",
                "Especially, out of the three <br>active learning</br> methods (SVMactive, AOD, LOD), our proposed LOD algorithm performs the best. 2.",
                "In many real world applications like relevance feedback image retrieval, there are generally two ways of reducing labor-intensive manual labeling task.",
                "One is <br>active learning</br> which selects the most informative samples to label, and the other is semi-supervised learning which makes use of the unlabeled samples to enhance the learning performance.",
                "Both of these two strategies have been studied extensively in the past [14], [7], [5], [8].",
                "The work presented in this paper is focused on <br>active learning</br>, but it also takes advantage of the recent progresses on semi-supervised learning [2].",
                "Specifically, we incorporate a locality preserving regularizer into the standard regression framework and find the most informative samples with respect to the new objective function.",
                "In this way, the <br>active learning</br> and semi-supervised learning techniques are seamlessly unified for learning an optimal classifier. 3.",
                "The relevance feedback technique is crucial to image retrieval.",
                "For all the five algorithms, the retrieval performance improves with more feedbacks provided by the user. 7.",
                "CONCLUSIONS AND FUTURE WORK This paper describes a novel <br>active learning</br> algorithm, called Laplacian Optimal Design, to enable more effective relevance feedback image retrieval.",
                "Our algorithm is based on an objective function which simultaneously minimizes the empirical error and preserves the local geometrical structure of the data space.",
                "Using techniques from experimental design, our algorithm finds the most informative images to label.",
                "These labeled images and the unlabeled images in the database are used to learn a classifier.",
                "The experimental results on Corel database show that both <br>active learning</br> and semi-supervised learning can significantly improve the retrieval performance.",
                "In this paper, we consider the image retrieval problem on a small, static, and closed-domain image data.",
                "A much more challenging domain is the World Wide Web (WWW).",
                "For Web image search, it is possible to collect a large amount of user click information.",
                "This information can be naturally used to construct the affinity graph in our algorithm.",
                "However, the computational complexity in Web scenario may become a crucial issue.",
                "Also, although our primary interest in this paper is focused on relevance feedback image retrieval, our results may also be of interest to researchers in patten recognition and machine learning, especially when a large amount of data is available but only a limited samples can be labeled. 8.",
                "REFERENCES [1] A. C. Atkinson and A. N. Donev.",
                "Optimum Experimental Designs.",
                "Oxford University Press, 2002. [2] M. Belkin, P. Niyogi, and V. Sindhwani.",
                "Manifold regularization: A geometric framework for learning from examples.",
                "Journal of Machine Learning Research, 7:2399-2434, 2006. [3] F. R. K. Chung.",
                "Spectral Graph Theory, volume 92 of Regional Conference Series in Mathematics.",
                "AMS, 1997. [4] D. A. Cohn, Z. Ghahramani, and M. I. Jordan.",
                "<br>active learning</br> with statistical models.",
                "Journal of Artificial Intelligence Research, 4:129-145, 1996. [5] A. Dong and B. Bhanu.",
                "A new semi-supervised em algorithm for image retrieval.",
                "In IEEE Conf. on Computer Vision and Pattern Recognition, Madison, WI, 2003. [6] P. Flaherty, M. I. Jordan, and A. P. Arkin.",
                "Robust design of biological experiments.",
                "In Advances in Neural Information Processing Systems 18, Vancouver, Canada, 2005. [7] K.-S. Goh, E. Y. Chang, and W.-C. Lai.",
                "Multimodal concept-dependent <br>active learning</br> for image retrieval.",
                "In Proceedings of the ACM Conference on Multimedia, New York, October 2004. [8] X.",
                "He.",
                "Incremental semi-supervised subspace learning for image retrieval.",
                "In Proceedings of the ACM Conference on Multimedia, New York, October 2004. [9] S. C. Hoi and M. R. Lyu.",
                "A semi-supervised <br>active learning</br> framework for image retrieval.",
                "In IEEE International Conference on Computer Vision and Pattern Recognition, San Diego, CA, 2005. [10] D. P. Huijsmans and N. Sebe.",
                "How to complete performance graphs in content-based image retrieval: Add generality and normalize scope.",
                "IEEE Transactions on Pattern Analysis and Machine Intelligence, 27(2):245-251, 2005. [11] Y.-Y.",
                "Lin, T.-L. Liu, and H.-T. Chen.",
                "Semantic manifold learning for image retrieval.",
                "In Proceedings of the ACM Conference on Multimedia, Singapore, November 2005. [12] Y. Rui, T. S. Huang, M. Ortega, and S. Mehrotra.",
                "Relevance feedback: A power tool for interative content-based image retrieval.",
                "IEEE Transactions on Circuits and Systems for Video Technology, 8(5), 1998. [13] A. W. Smeulders, M. Worring, S. Santini, A. Gupta, and R. Jain.",
                "Content-based image retrieval at the end of the early years.",
                "IEEE Transactions on Pattern Analysis and Machine Intelligence, 22(12):1349-1380, 2000. [14] S. Tong and E. Chang.",
                "Support vector machine <br>active learning</br> for image retrieval.",
                "In Proceedings of the ninth ACM international conference on Multimedia, pages 107-118, 2001. [15] H. Yu, M. Li, H.-J.",
                "Zhang, and J. Feng.",
                "Color texture moments for content-based image retrieval.",
                "In International Conference on Image Processing, pages 24-28, 2002. [16] K. Yu, J. Bi, and V. Tresp.",
                "<br>active learning</br> via transductive experimental design.",
                "In Proceedings of the 23rd International Conference on Machine Learning, Pittsburgh, PA, 2006."
            ],
            "original_annotated_samples": [
                "In this paper, we propose a novel <br>active learning</br> algorithm, called Laplacian Optimal Design (LOD), for relevance feedback image retrieval.",
                "This problem is typically called <br>active learning</br> [4].",
                "Many real world applications can be casted into <br>active learning</br> framework.",
                "Thus <br>active learning</br> can be naturally introduced into image retrieval.",
                "Despite many existing <br>active learning</br> techniques, Support Vector Machine (SVM) <br>active learning</br> [14] and regression based active learning [1] have received the most interests."
            ],
            "translated_annotated_samples": [
                "En este artículo, proponemos un novedoso algoritmo de <br>aprendizaje activo</br>, llamado Diseño Óptimo Laplaciano (LOD), para la recuperación de imágenes con retroalimentación de relevancia.",
                "Este problema se llama típicamente <br>aprendizaje activo</br> [4].",
                "Muchas aplicaciones del mundo real pueden ser adaptadas al marco de <br>aprendizaje activo</br>.",
                "Por lo tanto, el <br>aprendizaje activo</br> puede ser introducido de forma natural en la recuperación de imágenes.",
                "A pesar de la existencia de muchas técnicas de <br>aprendizaje activo</br>, el <br>aprendizaje activo</br> de Máquina de Vectores de Soporte (SVM) [14] y el aprendizaje activo basado en regresión [1] han sido los que han despertado mayor interés."
            ],
            "translated_text": "Diseño óptimo de Laplaciano para la recuperación de imágenes Xiaofei He Yahoo! El feedback de relevancia es una técnica poderosa para mejorar el rendimiento de la Recuperación de Imágenes Basada en Contenido (CBIR). Solicita las valoraciones de relevancia de los usuarios sobre las imágenes recuperadas por los sistemas CBIR. La etiqueta de los usuarios se utiliza luego para entrenar un clasificador que distinga entre imágenes relevantes e irrelevantes. Sin embargo, las imágenes principales que se devuelven pueden no ser las más informativas. El desafío consiste en determinar qué imágenes sin etiquetar serían las más informativas (es decir, mejorarían más al clasificador) si fueran etiquetadas y utilizadas como muestras de entrenamiento. En este artículo, proponemos un novedoso algoritmo de <br>aprendizaje activo</br>, llamado Diseño Óptimo Laplaciano (LOD), para la recuperación de imágenes con retroalimentación de relevancia. Nuestro algoritmo se basa en un modelo de regresión que minimiza el error cuadrático mínimo en las imágenes medidas (o etiquetadas) y al mismo tiempo preserva la estructura geométrica local del espacio de la imagen. Específicamente, asumimos que si dos imágenes están lo suficientemente cerca una de la otra, entonces sus medidas (o etiquetas) también son cercanas. Al construir un grafo de vecinos más cercanos, la estructura geométrica del espacio de la imagen puede ser descrita por el Laplaciano del grafo. Discutimos cómo los resultados del campo del diseño experimental óptimo pueden ser utilizados para guiar nuestra selección de un subconjunto de imágenes, que nos proporciona la mayor cantidad de información. Los resultados experimentales en la base de datos Corel sugieren que el enfoque propuesto logra una mayor precisión en la recuperación de imágenes con retroalimentación de relevancia. Categorías y Descriptores de Asignaturas H.3.3 [Almacenamiento y recuperación de información]: Búsqueda y recuperación de información-Retroalimentación de relevancia; G.3 [Matemáticas de la Computación]: Probabilidad y Estadística-Diseño experimental Términos Generales Algoritmos, Rendimiento, Teoría 1. INTRODUCCIÓN En muchas tareas de aprendizaje automático y recuperación de información, no hay escasez de datos no etiquetados pero las etiquetas son costosas. El desafío consiste en determinar qué muestras sin etiquetar serían las más informativas (es decir, mejorarían más el clasificador) si fueran etiquetadas y utilizadas como muestras de entrenamiento. Este problema se llama típicamente <br>aprendizaje activo</br> [4]. Aquí la tarea es minimizar un costo general, que depende tanto de la precisión del clasificador como del costo de la recolección de datos. Muchas aplicaciones del mundo real pueden ser adaptadas al marco de <br>aprendizaje activo</br>. Particularmente, consideramos el problema de la recuperación de imágenes basada en contenido impulsada por la retroalimentación de relevancia (CBIR) [13]. La Recuperación de Imágenes Basada en Contenido ha atraído un interés sustancial en la última década [13]. Está motivado por el rápido crecimiento de las bases de datos de imágenes digitales que, a su vez, requieren esquemas de búsqueda eficientes. En lugar de describir una imagen usando texto, en estos sistemas se describe una consulta de imagen utilizando una o más imágenes de ejemplo. Las características visuales de bajo nivel (color, textura, forma, etc.) se extraen automáticamente para representar las imágenes. Sin embargo, las características de bajo nivel pueden no caracterizar con precisión los conceptos semánticos de alto nivel. Para reducir la brecha semántica, se introduce la retroalimentación de relevancia en la recuperación de información basada en el contenido (CBIR) [12]. En muchos de los sistemas actuales de recuperación de imágenes basados en retroalimentación de relevancia, se requiere que el usuario proporcione sus juicios de relevancia sobre las imágenes principales devueltas por el sistema. Las imágenes etiquetadas se utilizan luego para entrenar un clasificador que separe las imágenes que coinciden con el concepto de la consulta de aquellas que no lo hacen. Sin embargo, en general, las imágenes principales que se devuelven pueden no ser las más informativas. En el peor de los casos, todas las imágenes principales etiquetadas por el usuario pueden ser positivas y, por lo tanto, las técnicas estándar de clasificación no pueden aplicarse debido a la falta de ejemplos negativos. A diferencia de los problemas de clasificación estándar donde las muestras etiquetadas están predefinidas, en la recuperación de imágenes con retroalimentación de relevancia, el sistema puede seleccionar activamente las imágenes a etiquetar. Por lo tanto, el <br>aprendizaje activo</br> puede ser introducido de forma natural en la recuperación de imágenes. A pesar de la existencia de muchas técnicas de <br>aprendizaje activo</br>, el <br>aprendizaje activo</br> de Máquina de Vectores de Soporte (SVM) [14] y el aprendizaje activo basado en regresión [1] han sido los que han despertado mayor interés. ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "least square regression model": {
            "translated_key": "modelo de regresión de mínimos cuadrados",
            "is_in_text": false,
            "original_annotated_sentences": [
                "Laplacian Optimal Design for Image Retrieval Xiaofei He Yahoo!",
                "Burbank, CA 91504 hex@yahoo-inc.com Wanli Min IBM Yorktown Heights, NY 10598 wanlimin@us.ibm.com Deng Cai CS Dept., UIUC Urbana, IL 61801 dengcai2@cs.uiuc.edu Kun Zhou Microsoft Research Asia Beijing, China kunzhou@microsoft.com ABSTRACT Relevance feedback is a powerful technique to enhance ContentBased Image Retrieval (CBIR) performance.",
                "It solicits the users relevance judgments on the retrieved images returned by the CBIR systems.",
                "The users labeling is then used to learn a classifier to distinguish between relevant and irrelevant images.",
                "However, the top returned images may not be the most informative ones.",
                "The challenge is thus to determine which unlabeled images would be the most informative (i.e., improve the classifier the most) if they were labeled and used as training samples.",
                "In this paper, we propose a novel active learning algorithm, called Laplacian Optimal Design (LOD), for relevance feedback image retrieval.",
                "Our algorithm is based on a regression model which minimizes the least square error on the measured (or, labeled) images and simultaneously preserves the local geometrical structure of the image space.",
                "Specifically, we assume that if two images are sufficiently close to each other, then their measurements (or, labels) are close as well.",
                "By constructing a nearest neighbor graph, the geometrical structure of the image space can be described by the graph Laplacian.",
                "We discuss how results from the field of optimal experimental design may be used to guide our selection of a subset of images, which gives us the most amount of information.",
                "Experimental results on Corel database suggest that the proposed approach achieves higher precision in relevance feedback image retrieval.",
                "Categories and Subject Descriptors H.3.3 [Information storage and retrieval]: Information search and retrieval-Relevance feedback; G.3 [Mathematics of Computing]: Probability and Statistics-Experimental design General Terms Algorithms, Performance, Theory 1.",
                "INTRODUCTION In many machine learning and information retrieval tasks, there is no shortage of unlabeled data but labels are expensive.",
                "The challenge is thus to determine which unlabeled samples would be the most informative (i.e., improve the classifier the most) if they were labeled and used as training samples.",
                "This problem is typically called active learning [4].",
                "Here the task is to minimize an overall cost, which depends both on the classifier accuracy and the cost of data collection.",
                "Many real world applications can be casted into active learning framework.",
                "Particularly, we consider the problem of relevance feedback driven Content-Based Image Retrieval (CBIR) [13].",
                "Content-Based Image Retrieval has attracted substantial interests in the last decade [13].",
                "It is motivated by the fast growth of digital image databases which, in turn, require efficient search schemes.",
                "Rather than describe an image using text, in these systems an image query is described using one or more example images.",
                "The low level visual features (color, texture, shape, etc.) are automatically extracted to represent the images.",
                "However, the low level features may not accurately characterize the high level semantic concepts.",
                "To narrow down the semantic gap, relevance feedback is introduced into CBIR [12].",
                "In many of the current relevance feedback driven CBIR systems, the user is required to provide his/her relevance judgments on the top images returned by the system.",
                "The labeled images are then used to train a classifier to separate images that match the query concept from those that do not.",
                "However, in general the top returned images may not be the most informative ones.",
                "In the worst case, all the top images labeled by the user may be positive and thus the standard classification techniques can not be applied due to the lack of negative examples.",
                "Unlike the standard classification problems where the labeled samples are pregiven, in relevance feedback image retrieval the system can actively select the images to label.",
                "Thus active learning can be naturally introduced into image retrieval.",
                "Despite many existing active learning techniques, Support Vector Machine (SVM) active learning [14] and regression based active learning [1] have received the most interests.",
                "Based on the observation that the closer to the SVM boundary an image is, the less reliable its classification is, SVM active learning selects those unlabeled images closest to the boundary to solicit user feedback so as to achieve maximal refinement on the hyperplane between the two classes.",
                "The major disadvantage of SVM active learning is that the estimated boundary may not be accurate enough.",
                "Moreover, it may not be applied at the beginning of the retrieval when there is no labeled images.",
                "Some other SVM based active learning algorithms can be found in [7], [9].",
                "In statistics, the problem of selecting samples to label is typically referred to as experimental design.",
                "The sample x is referred to as experiment, and its label y is referred to as measurement.",
                "The study of optimal experimental design (OED) [1] is concerned with the design of experiments that are expected to minimize variances of a parameterized model.",
                "The intent of optimal experimental design is usually to maximize confidence in a given model, minimize parameter variances for system identification, or minimize the models output variance.",
                "Classical experimental design approaches include A-Optimal Design, D-Optimal Design, and E-Optimal Design.",
                "All of these approaches are based on a least squares regression model.",
                "Comparing to SVM based active learning algorithms, experimental design approaches are much more efficient in computation.",
                "However, this kind of approaches takes only measured (or, labeled) data into account in their objective function, while the unmeasured (or, unlabeled) data is ignored.",
                "Benefit from recent progresses on optimal experimental design and semi-supervised learning, in this paper we propose a novel active learning algorithm for image retrieval, called Laplacian Optimal Design (LOD).",
                "Unlike traditional experimental design methods whose loss functions are only defined on the measured points, the loss function of our proposed LOD algorithm is defined on both measured and unmeasured points.",
                "Specifically, we introduce a locality preserving regularizer into the standard least-square-error based loss function.",
                "The new loss function aims to find a classifier which is locally as smooth as possible.",
                "In other words, if two points are sufficiently close to each other in the input space, then they are expected to share the same label.",
                "Once the loss function is defined, we can select the most informative data points which are presented to the user for labeling.",
                "It would be important to note that the most informative images may not be the top returned images.",
                "The rest of the paper is organized as follows.",
                "In Section 2, we provide a brief description of the related work.",
                "Our proposed Laplacian Optimal Design algorithm is introduced in Section 3.",
                "In Section 4, we compare our algorithm with the state-or-the-art algorithms and present the experimental results on image retrieval.",
                "Finally, we provide some concluding remarks and suggestions for future work in Section 5. 2.",
                "RELATED WORK Since our proposed algorithm is based on regression framework.",
                "The most related work is optimal experimental design [1], including A-Optimal Design, D-Optimal Design, and EOptimal Design.",
                "In this Section, we give a brief description of these approaches. 2.1 The Active Learning Problem The generic problem of active learning is the following.",
                "Given a set of points A = {x1, x2, · · · , xm} in Rd , find a subset B = {z1, z2, · · · , zk} ⊂ A which contains the most informative points.",
                "In other words, the points zi(i = 1, · · · , k) can improve the classifier the most if they are labeled and used as training points. 2.2 Optimal Experimental Design We consider a linear regression model y = wT x + (1) where y is the observation, x is the independent variable, w is the weight vector and is an unknown error with zero mean.",
                "Different observations have errors that are independent, but with equal variances σ2 .",
                "We define f(x) = wT x to be the learners output given input x and the weight vector w. Suppose we have a set of labeled sample points (z1, y1), · · · , (zk, yk), where yi is the label of zi.",
                "Thus, the maximum likelihood estimate for the weight vector, ˆw, is that which minimizes the sum squared error Jsse(w) = k i=1 wT zi − yi 2 (2) The estimate ˆw gives us an estimate of the output at a novel input: ˆy = ˆwT x.",
                "By Gauss-Markov theorem, we know that ˆw − w has a zero mean and a covariance matrix given by σ2 H−1 sse, where Hsse is the Hessian of Jsse(w) Hsse = ∂2 Jsse ∂w2 = k i=1 zizT i = ZZT where Z = (z1, z2, · · · , zk).",
                "The three most common scalar measures of the size of the parameter covariance matrix in optimal experimental design are: • D-optimal design: determinant of Hsse. • A-optimal design: trace of Hsse. • E-optimal design: maximum eigenvalue of Hsse.",
                "Since the computation of the determinant and eigenvalues of a matrix is much more expensive than the computation of matrix trace, A-optimal design is more efficient than the other two.",
                "Some recent work on experimental design can be found in [6], [16]. 3.",
                "LAPLACIAN OPTIMAL DESIGN Since the covariance matrix Hsse used in traditional approaches is only dependent on the measured samples, i.e. zis, these approaches fail to evaluate the expected errors on the unmeasured samples.",
                "In this Section, we introduce a novel active learning algorithm called Laplacian Optimal Design (LOD) which makes efficient use of both measured (labeled) and unmeasured (unlabeled) samples. 3.1 The Objective Function In many machine learning problems, it is natural to assume that if two points xi, xj are sufficiently close to each other, then their measurements (f(xi), f(xj)) are close as well.",
                "Let S be a similarity matrix.",
                "Thus, a new loss function which respects the geometrical structure of the data space can be defined as follows: J0(w) = k i=1 f(zi)−yi 2 + λ 2 m i,j=1 f(xi)−f(xj) 2 Sij (3) where yi is the measurement (or, label) of zi.",
                "Note that, the loss function (3) is essentially the same as the one used in Laplacian Regularized Regression (LRR, [2]).",
                "However, LRR is a passive learning algorithm where the training data is given.",
                "In this paper, we are focused on how to select the most informative data for training.",
                "The loss function with our choice of symmetric weights Sij (Sij = Sji) incurs a heavy penalty if neighboring points xi and xj are mapped far apart.",
                "Therefore, minimizing J0(w) is an attempt to ensure that if xi and xj are close then f(xi) and f(xj) are close as well.",
                "There are many choices of the similarity matrix S. A simple definition is as follows: Sij = ⎧ ⎨ ⎩ 1, if xi is among the p nearest neighbors of xj, or xj is among the p nearest neighbors of xi; 0, otherwise. (4) Let D be a diagonal matrix, Dii = j Sij, and L = D−S.",
                "The matrix L is called graph Laplacian in spectral graph theory [3].",
                "Let y = (y1, · · · , yk)T and X = (x1, · · · , xm).",
                "Following some simple algebraic steps, we see that: J0(w) = k i=1 wT zi − yi 2 + λ 2 m i,j=1 wT xi − wT xj 2 Sij = y − ZT w T y − ZT w + λwT m i=1 DiixixT i − m i,j=1 SijxixT j w = yT y − 2wT Zy + wT ZZT w +λwT XDXT − XSXT w = yT y − 2wT Zy + wT ZZT + λXLXT w The Hessian of J0(w) can be computed as follows: H0 = ∂2 J0 ∂w2 = ZZT + λXLXT In some cases, the matrix ZZT +λXLXT is singular (e.g. if m < d).",
                "Thus, there is no stable solution to the optimization problem Eq. (3).",
                "A common way to deal with this ill-posed problem is to introduce a Tikhonov regularizer into our loss function: J(w) = k i=1 wT zi − yi 2 + λ1 2 m i,j=1 wT xi − wT xj 2 Sij +λ2 w 2 (5) The Hessian of the new loss function is given by: H = ∂2 J ∂w2 = ZZT + λ1XLXT + λ2I := ZZT + Λ where I is an identity matrix and Λ = λ1XLXT + λ2I.",
                "Clearly, H is of full rank.",
                "Requiring that the gradient of J(w) with respect to w vanish gives the optimal estimate ˆw: ˆw = H−1 Zy The following proposition states the bias and variance properties of the estimator for the coefficient vector w. Proposition 3.1.",
                "E( ˆw − w) = −H−1 Λw, Cov( ˆw) = σ2 (H−1 − H−1 ΛH−1 ) Proof.",
                "Since y = ZT w + and E( ) = 0, it follows that E( ˆw − w) (6) = H−1 ZZT w − w = H−1 (ZZT + Λ − Λ)w − w = (I − H−1 Λ)w − w = −H−1 Λw (7) Notice Cov(y) = σ2 I, the covariance matrix of ˆw has the expression: Cov( ˆw) = H−1 ZCov(y)ZT H−1 = σ2 H−1 ZZT H−1 = σ2 H−1 (H − Λ)H−1 = σ2 (H−1 − H−1 ΛH−1 ) (8) Therefore mean squared error matrix for the coefficients w is E(w − ˆw)(w − ˆw)T (9) = H−1 ΛwwT ΛH−1 + σ2 (H−1 − H−1 ΛH−1 ) (10) For any x, let ˆy = ˆwT x be its predicted observation.",
                "The expected squared prediction error is E(y − ˆy)2 = E( + wT x − ˆwT x)2 = σ2 + xT [E(w − ˆw)(w − ˆw)T ]x = σ2 + xT [H−1 ΛwwT ΛH−1 + σ2 H−1 − σ2 H−1 ΛH−1 ]x Clearly the expected square prediction error depends on the explanatory variable x, therefore average expected square predictive error over the complete data set A is 1 m m i=1 E(yi − ˆwT xi)2 = 1 m m i=1 xT i [H−1 ΛwwT ΛH−1 + σ2 H−1 − σ2 H−1 ΛH−1 ]xi +σ2 = 1 m Tr(XT [σ2 H−1 + H−1 ΛwwT ΛH−1 − σ2 H−1 ΛH−1 ]X) +σ2 Since Tr(XT [H−1 ΛwwT ΛH−1 − σ2 H−1 ΛH−1 ]X) Tr(σ2 XT H−1 X), Our Laplacian optimality criterion is thus formulated by minimizing the trace of XT H−1 X.",
                "Definition 1.",
                "Laplacian Optimal Design min Z=(z1,··· ,zk) Tr XT ZZT + λ1XLXT + λ2I −1 X (11) where z1, · · · , zk are selected from {x1, · · · , xm}. 4.",
                "KERNEL LAPLACIAN OPTIMAL DESIGN Canonical experimental design approaches (e.g.",
                "A-Optimal Design, D-Optimal Design, and E-Optimal) only consider linear functions.",
                "They fail to discover the intrinsic geometry in the data when the data space is highly nonlinear.",
                "In this section, we describe how to perform Laplacian Experimental Design in Reproducing Kernel Hilbert Space (RKHS) which gives rise to Kernel Laplacian Experimental Design (KLOD).",
                "For given data points x1, · · · , xm ∈ X with a positive definite mercer kernel K : X ×X → R, there exists a unique RKHS HK of real valued functions on X.",
                "Let Kt(s) be the function of s obtained by fixing t and letting Kt(s) . = K(s, t).",
                "HK consists of all finite linear combinations of the form l i=1 αiKti with ti ∈ X and limits of such functions as the ti become dense in X.",
                "We have Ks, Kt HK = K(s, t). 4.1 Derivation of LOD in Reproducing Kernel Hilbert Space Consider the optimization problem (5) in RKHS.",
                "Thus, we seek a function f ∈ HK such that the following objective function is minimized: min f∈HK k i=1 f(zi)−yi 2 + λ1 2 m i,j=1 f(xi)−f(xj) 2 Sij+λ2 f 2 HK (12) We have the following proposition.",
                "Proposition 4.1.",
                "Let H = { m i=1 αiK(·, xi)|αi ∈ R} be a subspace of HK , the solution to the problem (12) is in H. Proof.",
                "Let H⊥ be the orthogonal complement of H, i.e.",
                "HK = H ⊕ H⊥ .",
                "Thus, for any function f ∈ HK , it has orthogonal decomposition as follows: f = fH + fH⊥ Now, lets evaluate f at xi: f(xi) = f, Kxi HK = fH + fH⊥ , Kxi HK = fH, Kxi HK + fH⊥ , Kxi HK Notice that Kxi ∈ H while fH⊥ ∈ H⊥ .",
                "This implies that fH⊥ , Kxi HK = 0.",
                "Therefore, f(xi) = fH, Kxi HK = fH(xi) This completes the proof.",
                "Proposition 4.1 tells us the minimizer of problem (12) admits a representation f∗ = m i=1 αiK(·, xi).",
                "Please see [2] for the details.",
                "Let φ : Rd → H be a feature map from the input space Rd to H, and K(xi, xj) =< φ(xi), φ(xj) >.",
                "Let X denote the data matrix in RKHS, X = (φ(x1), φ(x2), · · · , φ(xm)).",
                "Similarly, we define Z = (φ(z1), φ(z2), · · · , φ(zk)).",
                "Thus, the optimization problem in RKHS can be written as follows: min Z Tr XT ZZT + λ1XLXT + λ2I −1 X (13) Since the mapping function φ is generally unknown, there is no direct way to solve problem (13).",
                "In the following, we apply kernel tricks to solve this optimization problem.",
                "Let X−1 be the Moore-Penrose inverse (also known as pseudo inverse) of X.",
                "Thus, we have: XT ZZT + λ1XLXT + λ2I −1 X = XT XX−1 ZZT + λ1XLXT + λ2I −1 (XT )−1 XT X = XT X ZZT X + λ1XLXT X + λ2X −1 (XT )−1 XT X = XT X XT ZZT X + λ1XT XLXT X + λ2XT X −1 XT X = KXX KXZKZX + λ1KXXLKXX + λ2KXX −1 KXX where KXX is a m × m matrix (KXX,ij = K(xi, xj)), KXZ is a m×k matrix (KXZ,ij = K(xi, zj)), and KZX is a k×m matrix (KZX,ij = K(zi, xj)).",
                "Thus, the Kernel Laplacian Optimal Design can be defined as follows: Definition 2.",
                "Kernel Laplacian Optimal Design minZ=(z1,··· ,zk) Tr KXX KXZKZX + λ1KXXLKXX λ2KXX −1 KXX (14) 4.2 Optimization Scheme In this subsection, we discuss how to solve the optimization problems (11) and (14).",
                "Particularly, if we select a linear kernel for KLOD, then it reduces to LOD.",
                "Therefore, we will focus on problem (14) in the following.",
                "It can be shown that the optimization problem (14) is NP-hard.",
                "In this subsection, we develop a simple sequential greedy approach to solve (14).",
                "Suppose n points have been selected, denoted by a matrix Zn = (z1, · · · , zn).",
                "The (n + 1)-th point zn+1 can be selected by solving the following optimization problem: max Zn+1=(Zn,zn+1) Tr KXX KXZn+1 KZn+1X + λ1KXXLKXX + λ2KXX −1 KXX (15) The kernel matrices KXZn+1 and KZn+1X can be rewritten as follows: KXZn+1 = KXZn , KXzn+1 , KZn+1X = KZnX Kzn+1X Thus, we have: KXZn+1 KZn+1X = KXZn KZnX + KXzn+1 Kzn+1X We define: A = KXZn KZnX + λ1KXXLKXX + λ2KXX A is only dependent on X and Zn .",
                "Thus, the (n + 1)-th point zn+1 is given by: zn+1 = arg min zn+1 Tr KXX A + KXzn+1 Kzn+1X −1 KXX (16) Each time we select a new point zn+1, the matrix A is updated by: A ← A + KXzn+1 Kzn+1X If the kernel function is chosen as inner product K(x, y) = x, y , then HK is a linear functional space and the algorithm reduces to LOD. 5.",
                "CONTENT-BASED IMAGE RETRIEVAL USING LAPLACIAN OPTIMAL DESIGN In this section, we describe how to apply Laplacian Optimal Design to CBIR.",
                "We begin with a brief description of image representation using low level visual features. 5.1 Low-Level Image Representation Low-level image representation is a crucial problem in CBIR.",
                "General visual features includes color, texture, shape, etc.",
                "Color and texture features are the most extensively used visual features in CBIR.",
                "Compared with color and texture features, shape features are usually described after images have been segmented into regions or objects.",
                "Since robust and accurate image segmentation is difficult to achieve, the use of shape features for image retrieval has been limited to special applications where objects or regions are readily available.",
                "In this work, We combine 64-dimensional color histogram and 64-dimensional Color Texture Moment (CTM, [15]) to represent the images.",
                "The color histogram is calculated using 4 × 4 × 4 bins in HSV space.",
                "The Color Texture Moment is proposed by Yu et al. [15], which integrates the color and texture characteristics of the image in a compact form.",
                "CTM adopts local Fourier transform as a texture representation scheme and derives eight characteristic maps to describe different aspects of co-occurrence relations of image pixels in each channel of the (SVcosH, SVsinH, V) color space.",
                "Then CTM calculates the first and second moment of these maps as a representation of the natural color image pixel distribution.",
                "Please see [15] for details. 5.2 Relevance Feedback Image Retrieval Relevance feedback is one of the most important techniques to narrow down the gap between low level visual features and high level semantic concepts [12].",
                "Traditionally, the users relevance feedbacks are used to update the query vector or adjust the weighting of different dimensions.",
                "This process can be viewed as an on-line learning process in which the image retrieval system acts as a learner and the user acts as a teacher.",
                "They typical retrieval process is outlined as follows: 1.",
                "The user submits a query image example to the system.",
                "The system ranks the images in database according to some pre-defined distance metric and presents to the user the top ranked images. 2.",
                "The system selects some images from the database and request the user to label them as relevant or irrelevant. 3.",
                "The system uses the users provided information to rerank the images in database and returns to the user the top images.",
                "Go to step 2 until the user is satisfied.",
                "Our Laplacian Optimal Design algorithm is applied in the second step for selecting the most informative images.",
                "Once we get the labels for the images selected by LOD, we apply Laplacian Regularized Regression (LRR, [2]) to solve the optimization problem (3) and build the classifier.",
                "The classifier is then used to re-rank the images in database.",
                "Note that, in order to reduce the computational complexity, we do not use all the unlabeled images in the database but only those within top 500 returns of previous iteration. 6.",
                "EXPERIMENTAL RESULTS In this section, we evaluate the performance of our proposed algorithm on a large image database.",
                "To demonstrate the effectiveness of our proposed LOD algorithm, we compare it with Laplacian Regularized Regression (LRR, [2]), Support Vector Machine (SVM), Support Vector Machine Active Learning (SVMactive) [14], and A-Optimal Design (AOD).",
                "Both SVMactive, AOD, and LOD are active learning algorithms, while LRR and SVM are standard classification algorithms.",
                "SVM only makes use of the labeled images, while LRR is a semi-supervised learning algorithm which makes use of both labeled and unlabeled images.",
                "For SVMactive, AOD, and LOD, 10 training images are selected by the algorithms themselves at each iteration.",
                "While for LRR and SVM, we use the top 10 images as training data.",
                "It would be important to note that SVMactive is based on the ordinary SVM, LOD is based on LRR, and AOD is based on the ordinary regression.",
                "The parameters λ1 and λ2 in our LOD algorithm are empirically set to be 0.001 and 0.00001.",
                "For both LRR and LOD algorithms, we use the same graph structure (see Eq. 4) and set the value of p (number of nearest neighbors) to be 5.",
                "We begin with a simple synthetic example to give some intuition about how LOD works. 6.1 Simple Synthetic Example A simple synthetic example is given in Figure 1.",
                "The data set contains two circles.",
                "Eight points are selected by AOD and LOD.",
                "As can be seen, all the points selected by AOD are from the big circle, while LOD selects four points from the big circle and four from the small circle.",
                "The numbers beside the selected points denote their orders to be selected.",
                "Clearly, the points selected by our LOD algorithm can better represent the original data set.",
                "We did not compare our algorithm with SVMactive because SVMactive can not be applied in this case due to the lack of the labeled points. 6.2 Image Retrieval Experimental Design The image database we used consists of 7,900 images of 79 semantic categories, from COREL data set.",
                "It is a large and heterogeneous image set.",
                "Each image is represented as a 128-dimensional vector as described in Section 5.1.",
                "Figure 2 shows some sample images.",
                "To exhibit the advantages of using our algorithm, we need a reliable way of evaluating the retrieval performance and the comparisons with other algorithms.",
                "We list different aspects of the experimental design below. 6.2.1 Evaluation Metrics We use precision-scope curve and precision rate [10] to evaluate the effectiveness of the image retrieval algorithms.",
                "The scope is specified by the number (N) of top-ranked images presented to the user.",
                "The precision is the ratio of the number of relevant images presented to the user to the (a) Data set 1 2 3 4 5 6 7 8 (b) AOD 1 2 3 4 5 6 7 8 (c) LOD Figure 1: Data selection by active learning algorithms.",
                "The numbers beside the selected points denote their orders to be selected.",
                "Clearly, the points selected by our LOD algorithm can better represent the original data set.",
                "Note that, the SVMactive algorithm can not be applied in this case due to the lack of labeled points. (a) (b) (c) Figure 2: Sample images from category bead, elephant, and ship. scope N. The precision-scope curve describes the precision with various scopes and thus gives an overall performance evaluation of the algorithms.",
                "On the other hand, the precision rate emphasizes the precision at a particular value of scope.",
                "In general, it is appropriate to present 20 images on a screen.",
                "Putting more images on a screen may affect the quality of the presented images.",
                "Therefore, the precision at top 20 (N = 20) is especially important.",
                "In real world image retrieval systems, the query image is usually not in the image database.",
                "To simulate such environment, we use five-fold cross validation to evaluate the algorithms.",
                "More precisely, we divide the whole image database into five subsets with equal size.",
                "Thus, there are 20 images per category in each subset.",
                "At each run of cross validation, one subset is selected as the query set, and the other four subsets are used as the database for retrieval.",
                "The precisionscope curve and precision rate are computed by averaging the results from the five-fold cross validation. 6.2.2 Automatic Relevance Feedback Scheme We designed an automatic feedback scheme to model the retrieval process.",
                "For each submitted query, our system retrieves and ranks the images in the database. 10 images were selected from the database for user labeling and the label information is used by the system for re-ranking.",
                "Note that, the images which have been selected at previous iterations are excluded from later selections.",
                "For each query, the automatic relevance feedback mechanism is performed for four iterations.",
                "It is important to note that the automatic relevance feedback scheme used here is different from the ones described in [8], [11].",
                "In [8], [11], the top four relevant and irrelevant images were selected as the feedback images.",
                "However, this may not be practical.",
                "In real world image retrieval systems, it is possible that most of the top-ranked images are relevant (or, irrelevant).",
                "Thus, it is difficult for the user to find both four relevant and irrelevant images.",
                "It is more reasonable for the users to provide feedback information only on the 10 images selected by the system. 6.3 Image Retrieval Performance In real world, it is not practical to require the user to provide many rounds of feedbacks.",
                "The retrieval performance after the first two rounds of feedbacks (especially the first round) is more important.",
                "Figure 3 shows the average precision-scope curves of the different algorithms for the first two feedback iterations.",
                "At the beginning of retrieval, the Euclidean distances in the original 128-dimensional space are used to rank the images in database.",
                "After the user provides relevance feedbacks, the LRR, SVM, SVMactive, AOD, and LOD algorithms are then applied to re-rank the images.",
                "In order to reduce the time complexity of active learning algorithms, we didnt select the most informative images from the whole database but from the top 500 images.",
                "For LRR and SVM, the user is required to label the top 10 images.",
                "For SVMactive, AOD, and LOD, the user is required to label 10 most informative images selected by these algorithms.",
                "Note that, SVMactive can only be ap(a) Feedback Iteration 1 (b) Feedback Iteration 2 Figure 3: The average precision-scope curves of different algorithms for the first two feedback iterations.",
                "The LOD algorithm performs the best on the entire scope.",
                "Note that, at the first round of feedback, the SVMactive algorithm can not be applied.",
                "It applies the ordinary SVM to build the initial classifier. (a) Precision at Top 10 (b) Precision at Top 20 (c) Precision at Top 30 Figure 4: Performance evaluation of the five learning algorithms for relevance feedback image retrieval. (a) Precision at top 10, (b) Precision at top 20, and (c) Precision at top 30.",
                "As can be seen, our LOD algorithm consistently outperforms the other four algorithms. plied when the classifier is already built.",
                "Therefore, it can not be applied at the first round and we use the standard SVM to build the initial classifier.",
                "As can be seen, our LOD algorithm outperforms the other four algorithms on the entire scope.",
                "Also, the LRR algorithm performs better than SVM.",
                "This is because that the LRR algorithm makes efficient use of the unlabeled images by incorporating a locality preserving regularizer into the ordinary regression objective function.",
                "The AOD algorithm performs the worst.",
                "As the scope gets larger, the performance difference between these algorithms gets smaller.",
                "By iteratively adding the users feedbacks, the corresponding precision results (at top 10, top 20, and top 30) of the five algorithms are respectively shown in Figure 4.",
                "As can be seen, our LOD algorithm performs the best in all the cases and the LRR algorithm performs the second best.",
                "Both of these two algorithms make use of the unlabeled images.",
                "This shows that the unlabeled images are helpful for discovering the intrinsic geometrical structure of the image space and therefore enhance the retrieval performance.",
                "In real world, the user may not be willing to provide too many relevance feedbacks.",
                "Therefore, the retrieval performance at the first two rounds are especially important.",
                "As can be seen, our LOD algorithm achieves 6.8% performance improvement for top 10 results, 5.2% for top 20 results, and 4.1% for top 30 results, comparing to the second best algorithm (LRR) after the first two rounds of relevance feedbacks. 6.4 Discussion Several experiments on Corel database have been systematically performed.",
                "We would like to highlight several interesting points: 1.",
                "It is clear that the use of active learning is beneficial in the image retrieval domain.",
                "There is a significant increase in performance from using the active learning methods.",
                "Especially, out of the three active learning methods (SVMactive, AOD, LOD), our proposed LOD algorithm performs the best. 2.",
                "In many real world applications like relevance feedback image retrieval, there are generally two ways of reducing labor-intensive manual labeling task.",
                "One is active learning which selects the most informative samples to label, and the other is semi-supervised learning which makes use of the unlabeled samples to enhance the learning performance.",
                "Both of these two strategies have been studied extensively in the past [14], [7], [5], [8].",
                "The work presented in this paper is focused on active learning, but it also takes advantage of the recent progresses on semi-supervised learning [2].",
                "Specifically, we incorporate a locality preserving regularizer into the standard regression framework and find the most informative samples with respect to the new objective function.",
                "In this way, the active learning and semi-supervised learning techniques are seamlessly unified for learning an optimal classifier. 3.",
                "The relevance feedback technique is crucial to image retrieval.",
                "For all the five algorithms, the retrieval performance improves with more feedbacks provided by the user. 7.",
                "CONCLUSIONS AND FUTURE WORK This paper describes a novel active learning algorithm, called Laplacian Optimal Design, to enable more effective relevance feedback image retrieval.",
                "Our algorithm is based on an objective function which simultaneously minimizes the empirical error and preserves the local geometrical structure of the data space.",
                "Using techniques from experimental design, our algorithm finds the most informative images to label.",
                "These labeled images and the unlabeled images in the database are used to learn a classifier.",
                "The experimental results on Corel database show that both active learning and semi-supervised learning can significantly improve the retrieval performance.",
                "In this paper, we consider the image retrieval problem on a small, static, and closed-domain image data.",
                "A much more challenging domain is the World Wide Web (WWW).",
                "For Web image search, it is possible to collect a large amount of user click information.",
                "This information can be naturally used to construct the affinity graph in our algorithm.",
                "However, the computational complexity in Web scenario may become a crucial issue.",
                "Also, although our primary interest in this paper is focused on relevance feedback image retrieval, our results may also be of interest to researchers in patten recognition and machine learning, especially when a large amount of data is available but only a limited samples can be labeled. 8.",
                "REFERENCES [1] A. C. Atkinson and A. N. Donev.",
                "Optimum Experimental Designs.",
                "Oxford University Press, 2002. [2] M. Belkin, P. Niyogi, and V. Sindhwani.",
                "Manifold regularization: A geometric framework for learning from examples.",
                "Journal of Machine Learning Research, 7:2399-2434, 2006. [3] F. R. K. Chung.",
                "Spectral Graph Theory, volume 92 of Regional Conference Series in Mathematics.",
                "AMS, 1997. [4] D. A. Cohn, Z. Ghahramani, and M. I. Jordan.",
                "Active learning with statistical models.",
                "Journal of Artificial Intelligence Research, 4:129-145, 1996. [5] A. Dong and B. Bhanu.",
                "A new semi-supervised em algorithm for image retrieval.",
                "In IEEE Conf. on Computer Vision and Pattern Recognition, Madison, WI, 2003. [6] P. Flaherty, M. I. Jordan, and A. P. Arkin.",
                "Robust design of biological experiments.",
                "In Advances in Neural Information Processing Systems 18, Vancouver, Canada, 2005. [7] K.-S. Goh, E. Y. Chang, and W.-C. Lai.",
                "Multimodal concept-dependent active learning for image retrieval.",
                "In Proceedings of the ACM Conference on Multimedia, New York, October 2004. [8] X.",
                "He.",
                "Incremental semi-supervised subspace learning for image retrieval.",
                "In Proceedings of the ACM Conference on Multimedia, New York, October 2004. [9] S. C. Hoi and M. R. Lyu.",
                "A semi-supervised active learning framework for image retrieval.",
                "In IEEE International Conference on Computer Vision and Pattern Recognition, San Diego, CA, 2005. [10] D. P. Huijsmans and N. Sebe.",
                "How to complete performance graphs in content-based image retrieval: Add generality and normalize scope.",
                "IEEE Transactions on Pattern Analysis and Machine Intelligence, 27(2):245-251, 2005. [11] Y.-Y.",
                "Lin, T.-L. Liu, and H.-T. Chen.",
                "Semantic manifold learning for image retrieval.",
                "In Proceedings of the ACM Conference on Multimedia, Singapore, November 2005. [12] Y. Rui, T. S. Huang, M. Ortega, and S. Mehrotra.",
                "Relevance feedback: A power tool for interative content-based image retrieval.",
                "IEEE Transactions on Circuits and Systems for Video Technology, 8(5), 1998. [13] A. W. Smeulders, M. Worring, S. Santini, A. Gupta, and R. Jain.",
                "Content-based image retrieval at the end of the early years.",
                "IEEE Transactions on Pattern Analysis and Machine Intelligence, 22(12):1349-1380, 2000. [14] S. Tong and E. Chang.",
                "Support vector machine active learning for image retrieval.",
                "In Proceedings of the ninth ACM international conference on Multimedia, pages 107-118, 2001. [15] H. Yu, M. Li, H.-J.",
                "Zhang, and J. Feng.",
                "Color texture moments for content-based image retrieval.",
                "In International Conference on Image Processing, pages 24-28, 2002. [16] K. Yu, J. Bi, and V. Tresp.",
                "Active learning via transductive experimental design.",
                "In Proceedings of the 23rd International Conference on Machine Learning, Pittsburgh, PA, 2006."
            ],
            "original_annotated_samples": [],
            "translated_annotated_samples": [],
            "translated_text": "",
            "candidates": [],
            "error": [
                []
            ]
        },
        "optimal experimental design": {
            "translated_key": "diseño experimental óptimo",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Laplacian Optimal Design for Image Retrieval Xiaofei He Yahoo!",
                "Burbank, CA 91504 hex@yahoo-inc.com Wanli Min IBM Yorktown Heights, NY 10598 wanlimin@us.ibm.com Deng Cai CS Dept., UIUC Urbana, IL 61801 dengcai2@cs.uiuc.edu Kun Zhou Microsoft Research Asia Beijing, China kunzhou@microsoft.com ABSTRACT Relevance feedback is a powerful technique to enhance ContentBased Image Retrieval (CBIR) performance.",
                "It solicits the users relevance judgments on the retrieved images returned by the CBIR systems.",
                "The users labeling is then used to learn a classifier to distinguish between relevant and irrelevant images.",
                "However, the top returned images may not be the most informative ones.",
                "The challenge is thus to determine which unlabeled images would be the most informative (i.e., improve the classifier the most) if they were labeled and used as training samples.",
                "In this paper, we propose a novel active learning algorithm, called Laplacian Optimal Design (LOD), for relevance feedback image retrieval.",
                "Our algorithm is based on a regression model which minimizes the least square error on the measured (or, labeled) images and simultaneously preserves the local geometrical structure of the image space.",
                "Specifically, we assume that if two images are sufficiently close to each other, then their measurements (or, labels) are close as well.",
                "By constructing a nearest neighbor graph, the geometrical structure of the image space can be described by the graph Laplacian.",
                "We discuss how results from the field of <br>optimal experimental design</br> may be used to guide our selection of a subset of images, which gives us the most amount of information.",
                "Experimental results on Corel database suggest that the proposed approach achieves higher precision in relevance feedback image retrieval.",
                "Categories and Subject Descriptors H.3.3 [Information storage and retrieval]: Information search and retrieval-Relevance feedback; G.3 [Mathematics of Computing]: Probability and Statistics-Experimental design General Terms Algorithms, Performance, Theory 1.",
                "INTRODUCTION In many machine learning and information retrieval tasks, there is no shortage of unlabeled data but labels are expensive.",
                "The challenge is thus to determine which unlabeled samples would be the most informative (i.e., improve the classifier the most) if they were labeled and used as training samples.",
                "This problem is typically called active learning [4].",
                "Here the task is to minimize an overall cost, which depends both on the classifier accuracy and the cost of data collection.",
                "Many real world applications can be casted into active learning framework.",
                "Particularly, we consider the problem of relevance feedback driven Content-Based Image Retrieval (CBIR) [13].",
                "Content-Based Image Retrieval has attracted substantial interests in the last decade [13].",
                "It is motivated by the fast growth of digital image databases which, in turn, require efficient search schemes.",
                "Rather than describe an image using text, in these systems an image query is described using one or more example images.",
                "The low level visual features (color, texture, shape, etc.) are automatically extracted to represent the images.",
                "However, the low level features may not accurately characterize the high level semantic concepts.",
                "To narrow down the semantic gap, relevance feedback is introduced into CBIR [12].",
                "In many of the current relevance feedback driven CBIR systems, the user is required to provide his/her relevance judgments on the top images returned by the system.",
                "The labeled images are then used to train a classifier to separate images that match the query concept from those that do not.",
                "However, in general the top returned images may not be the most informative ones.",
                "In the worst case, all the top images labeled by the user may be positive and thus the standard classification techniques can not be applied due to the lack of negative examples.",
                "Unlike the standard classification problems where the labeled samples are pregiven, in relevance feedback image retrieval the system can actively select the images to label.",
                "Thus active learning can be naturally introduced into image retrieval.",
                "Despite many existing active learning techniques, Support Vector Machine (SVM) active learning [14] and regression based active learning [1] have received the most interests.",
                "Based on the observation that the closer to the SVM boundary an image is, the less reliable its classification is, SVM active learning selects those unlabeled images closest to the boundary to solicit user feedback so as to achieve maximal refinement on the hyperplane between the two classes.",
                "The major disadvantage of SVM active learning is that the estimated boundary may not be accurate enough.",
                "Moreover, it may not be applied at the beginning of the retrieval when there is no labeled images.",
                "Some other SVM based active learning algorithms can be found in [7], [9].",
                "In statistics, the problem of selecting samples to label is typically referred to as experimental design.",
                "The sample x is referred to as experiment, and its label y is referred to as measurement.",
                "The study of <br>optimal experimental design</br> (OED) [1] is concerned with the design of experiments that are expected to minimize variances of a parameterized model.",
                "The intent of <br>optimal experimental design</br> is usually to maximize confidence in a given model, minimize parameter variances for system identification, or minimize the models output variance.",
                "Classical experimental design approaches include A-Optimal Design, D-Optimal Design, and E-Optimal Design.",
                "All of these approaches are based on a least squares regression model.",
                "Comparing to SVM based active learning algorithms, experimental design approaches are much more efficient in computation.",
                "However, this kind of approaches takes only measured (or, labeled) data into account in their objective function, while the unmeasured (or, unlabeled) data is ignored.",
                "Benefit from recent progresses on <br>optimal experimental design</br> and semi-supervised learning, in this paper we propose a novel active learning algorithm for image retrieval, called Laplacian Optimal Design (LOD).",
                "Unlike traditional experimental design methods whose loss functions are only defined on the measured points, the loss function of our proposed LOD algorithm is defined on both measured and unmeasured points.",
                "Specifically, we introduce a locality preserving regularizer into the standard least-square-error based loss function.",
                "The new loss function aims to find a classifier which is locally as smooth as possible.",
                "In other words, if two points are sufficiently close to each other in the input space, then they are expected to share the same label.",
                "Once the loss function is defined, we can select the most informative data points which are presented to the user for labeling.",
                "It would be important to note that the most informative images may not be the top returned images.",
                "The rest of the paper is organized as follows.",
                "In Section 2, we provide a brief description of the related work.",
                "Our proposed Laplacian Optimal Design algorithm is introduced in Section 3.",
                "In Section 4, we compare our algorithm with the state-or-the-art algorithms and present the experimental results on image retrieval.",
                "Finally, we provide some concluding remarks and suggestions for future work in Section 5. 2.",
                "RELATED WORK Since our proposed algorithm is based on regression framework.",
                "The most related work is <br>optimal experimental design</br> [1], including A-Optimal Design, D-Optimal Design, and EOptimal Design.",
                "In this Section, we give a brief description of these approaches. 2.1 The Active Learning Problem The generic problem of active learning is the following.",
                "Given a set of points A = {x1, x2, · · · , xm} in Rd , find a subset B = {z1, z2, · · · , zk} ⊂ A which contains the most informative points.",
                "In other words, the points zi(i = 1, · · · , k) can improve the classifier the most if they are labeled and used as training points. 2.2 <br>optimal experimental design</br> We consider a linear regression model y = wT x + (1) where y is the observation, x is the independent variable, w is the weight vector and is an unknown error with zero mean.",
                "Different observations have errors that are independent, but with equal variances σ2 .",
                "We define f(x) = wT x to be the learners output given input x and the weight vector w. Suppose we have a set of labeled sample points (z1, y1), · · · , (zk, yk), where yi is the label of zi.",
                "Thus, the maximum likelihood estimate for the weight vector, ˆw, is that which minimizes the sum squared error Jsse(w) = k i=1 wT zi − yi 2 (2) The estimate ˆw gives us an estimate of the output at a novel input: ˆy = ˆwT x.",
                "By Gauss-Markov theorem, we know that ˆw − w has a zero mean and a covariance matrix given by σ2 H−1 sse, where Hsse is the Hessian of Jsse(w) Hsse = ∂2 Jsse ∂w2 = k i=1 zizT i = ZZT where Z = (z1, z2, · · · , zk).",
                "The three most common scalar measures of the size of the parameter covariance matrix in <br>optimal experimental design</br> are: • D-optimal design: determinant of Hsse. • A-optimal design: trace of Hsse. • E-optimal design: maximum eigenvalue of Hsse.",
                "Since the computation of the determinant and eigenvalues of a matrix is much more expensive than the computation of matrix trace, A-optimal design is more efficient than the other two.",
                "Some recent work on experimental design can be found in [6], [16]. 3.",
                "LAPLACIAN OPTIMAL DESIGN Since the covariance matrix Hsse used in traditional approaches is only dependent on the measured samples, i.e. zis, these approaches fail to evaluate the expected errors on the unmeasured samples.",
                "In this Section, we introduce a novel active learning algorithm called Laplacian Optimal Design (LOD) which makes efficient use of both measured (labeled) and unmeasured (unlabeled) samples. 3.1 The Objective Function In many machine learning problems, it is natural to assume that if two points xi, xj are sufficiently close to each other, then their measurements (f(xi), f(xj)) are close as well.",
                "Let S be a similarity matrix.",
                "Thus, a new loss function which respects the geometrical structure of the data space can be defined as follows: J0(w) = k i=1 f(zi)−yi 2 + λ 2 m i,j=1 f(xi)−f(xj) 2 Sij (3) where yi is the measurement (or, label) of zi.",
                "Note that, the loss function (3) is essentially the same as the one used in Laplacian Regularized Regression (LRR, [2]).",
                "However, LRR is a passive learning algorithm where the training data is given.",
                "In this paper, we are focused on how to select the most informative data for training.",
                "The loss function with our choice of symmetric weights Sij (Sij = Sji) incurs a heavy penalty if neighboring points xi and xj are mapped far apart.",
                "Therefore, minimizing J0(w) is an attempt to ensure that if xi and xj are close then f(xi) and f(xj) are close as well.",
                "There are many choices of the similarity matrix S. A simple definition is as follows: Sij = ⎧ ⎨ ⎩ 1, if xi is among the p nearest neighbors of xj, or xj is among the p nearest neighbors of xi; 0, otherwise. (4) Let D be a diagonal matrix, Dii = j Sij, and L = D−S.",
                "The matrix L is called graph Laplacian in spectral graph theory [3].",
                "Let y = (y1, · · · , yk)T and X = (x1, · · · , xm).",
                "Following some simple algebraic steps, we see that: J0(w) = k i=1 wT zi − yi 2 + λ 2 m i,j=1 wT xi − wT xj 2 Sij = y − ZT w T y − ZT w + λwT m i=1 DiixixT i − m i,j=1 SijxixT j w = yT y − 2wT Zy + wT ZZT w +λwT XDXT − XSXT w = yT y − 2wT Zy + wT ZZT + λXLXT w The Hessian of J0(w) can be computed as follows: H0 = ∂2 J0 ∂w2 = ZZT + λXLXT In some cases, the matrix ZZT +λXLXT is singular (e.g. if m < d).",
                "Thus, there is no stable solution to the optimization problem Eq. (3).",
                "A common way to deal with this ill-posed problem is to introduce a Tikhonov regularizer into our loss function: J(w) = k i=1 wT zi − yi 2 + λ1 2 m i,j=1 wT xi − wT xj 2 Sij +λ2 w 2 (5) The Hessian of the new loss function is given by: H = ∂2 J ∂w2 = ZZT + λ1XLXT + λ2I := ZZT + Λ where I is an identity matrix and Λ = λ1XLXT + λ2I.",
                "Clearly, H is of full rank.",
                "Requiring that the gradient of J(w) with respect to w vanish gives the optimal estimate ˆw: ˆw = H−1 Zy The following proposition states the bias and variance properties of the estimator for the coefficient vector w. Proposition 3.1.",
                "E( ˆw − w) = −H−1 Λw, Cov( ˆw) = σ2 (H−1 − H−1 ΛH−1 ) Proof.",
                "Since y = ZT w + and E( ) = 0, it follows that E( ˆw − w) (6) = H−1 ZZT w − w = H−1 (ZZT + Λ − Λ)w − w = (I − H−1 Λ)w − w = −H−1 Λw (7) Notice Cov(y) = σ2 I, the covariance matrix of ˆw has the expression: Cov( ˆw) = H−1 ZCov(y)ZT H−1 = σ2 H−1 ZZT H−1 = σ2 H−1 (H − Λ)H−1 = σ2 (H−1 − H−1 ΛH−1 ) (8) Therefore mean squared error matrix for the coefficients w is E(w − ˆw)(w − ˆw)T (9) = H−1 ΛwwT ΛH−1 + σ2 (H−1 − H−1 ΛH−1 ) (10) For any x, let ˆy = ˆwT x be its predicted observation.",
                "The expected squared prediction error is E(y − ˆy)2 = E( + wT x − ˆwT x)2 = σ2 + xT [E(w − ˆw)(w − ˆw)T ]x = σ2 + xT [H−1 ΛwwT ΛH−1 + σ2 H−1 − σ2 H−1 ΛH−1 ]x Clearly the expected square prediction error depends on the explanatory variable x, therefore average expected square predictive error over the complete data set A is 1 m m i=1 E(yi − ˆwT xi)2 = 1 m m i=1 xT i [H−1 ΛwwT ΛH−1 + σ2 H−1 − σ2 H−1 ΛH−1 ]xi +σ2 = 1 m Tr(XT [σ2 H−1 + H−1 ΛwwT ΛH−1 − σ2 H−1 ΛH−1 ]X) +σ2 Since Tr(XT [H−1 ΛwwT ΛH−1 − σ2 H−1 ΛH−1 ]X) Tr(σ2 XT H−1 X), Our Laplacian optimality criterion is thus formulated by minimizing the trace of XT H−1 X.",
                "Definition 1.",
                "Laplacian Optimal Design min Z=(z1,··· ,zk) Tr XT ZZT + λ1XLXT + λ2I −1 X (11) where z1, · · · , zk are selected from {x1, · · · , xm}. 4.",
                "KERNEL LAPLACIAN OPTIMAL DESIGN Canonical experimental design approaches (e.g.",
                "A-Optimal Design, D-Optimal Design, and E-Optimal) only consider linear functions.",
                "They fail to discover the intrinsic geometry in the data when the data space is highly nonlinear.",
                "In this section, we describe how to perform Laplacian Experimental Design in Reproducing Kernel Hilbert Space (RKHS) which gives rise to Kernel Laplacian Experimental Design (KLOD).",
                "For given data points x1, · · · , xm ∈ X with a positive definite mercer kernel K : X ×X → R, there exists a unique RKHS HK of real valued functions on X.",
                "Let Kt(s) be the function of s obtained by fixing t and letting Kt(s) . = K(s, t).",
                "HK consists of all finite linear combinations of the form l i=1 αiKti with ti ∈ X and limits of such functions as the ti become dense in X.",
                "We have Ks, Kt HK = K(s, t). 4.1 Derivation of LOD in Reproducing Kernel Hilbert Space Consider the optimization problem (5) in RKHS.",
                "Thus, we seek a function f ∈ HK such that the following objective function is minimized: min f∈HK k i=1 f(zi)−yi 2 + λ1 2 m i,j=1 f(xi)−f(xj) 2 Sij+λ2 f 2 HK (12) We have the following proposition.",
                "Proposition 4.1.",
                "Let H = { m i=1 αiK(·, xi)|αi ∈ R} be a subspace of HK , the solution to the problem (12) is in H. Proof.",
                "Let H⊥ be the orthogonal complement of H, i.e.",
                "HK = H ⊕ H⊥ .",
                "Thus, for any function f ∈ HK , it has orthogonal decomposition as follows: f = fH + fH⊥ Now, lets evaluate f at xi: f(xi) = f, Kxi HK = fH + fH⊥ , Kxi HK = fH, Kxi HK + fH⊥ , Kxi HK Notice that Kxi ∈ H while fH⊥ ∈ H⊥ .",
                "This implies that fH⊥ , Kxi HK = 0.",
                "Therefore, f(xi) = fH, Kxi HK = fH(xi) This completes the proof.",
                "Proposition 4.1 tells us the minimizer of problem (12) admits a representation f∗ = m i=1 αiK(·, xi).",
                "Please see [2] for the details.",
                "Let φ : Rd → H be a feature map from the input space Rd to H, and K(xi, xj) =< φ(xi), φ(xj) >.",
                "Let X denote the data matrix in RKHS, X = (φ(x1), φ(x2), · · · , φ(xm)).",
                "Similarly, we define Z = (φ(z1), φ(z2), · · · , φ(zk)).",
                "Thus, the optimization problem in RKHS can be written as follows: min Z Tr XT ZZT + λ1XLXT + λ2I −1 X (13) Since the mapping function φ is generally unknown, there is no direct way to solve problem (13).",
                "In the following, we apply kernel tricks to solve this optimization problem.",
                "Let X−1 be the Moore-Penrose inverse (also known as pseudo inverse) of X.",
                "Thus, we have: XT ZZT + λ1XLXT + λ2I −1 X = XT XX−1 ZZT + λ1XLXT + λ2I −1 (XT )−1 XT X = XT X ZZT X + λ1XLXT X + λ2X −1 (XT )−1 XT X = XT X XT ZZT X + λ1XT XLXT X + λ2XT X −1 XT X = KXX KXZKZX + λ1KXXLKXX + λ2KXX −1 KXX where KXX is a m × m matrix (KXX,ij = K(xi, xj)), KXZ is a m×k matrix (KXZ,ij = K(xi, zj)), and KZX is a k×m matrix (KZX,ij = K(zi, xj)).",
                "Thus, the Kernel Laplacian Optimal Design can be defined as follows: Definition 2.",
                "Kernel Laplacian Optimal Design minZ=(z1,··· ,zk) Tr KXX KXZKZX + λ1KXXLKXX λ2KXX −1 KXX (14) 4.2 Optimization Scheme In this subsection, we discuss how to solve the optimization problems (11) and (14).",
                "Particularly, if we select a linear kernel for KLOD, then it reduces to LOD.",
                "Therefore, we will focus on problem (14) in the following.",
                "It can be shown that the optimization problem (14) is NP-hard.",
                "In this subsection, we develop a simple sequential greedy approach to solve (14).",
                "Suppose n points have been selected, denoted by a matrix Zn = (z1, · · · , zn).",
                "The (n + 1)-th point zn+1 can be selected by solving the following optimization problem: max Zn+1=(Zn,zn+1) Tr KXX KXZn+1 KZn+1X + λ1KXXLKXX + λ2KXX −1 KXX (15) The kernel matrices KXZn+1 and KZn+1X can be rewritten as follows: KXZn+1 = KXZn , KXzn+1 , KZn+1X = KZnX Kzn+1X Thus, we have: KXZn+1 KZn+1X = KXZn KZnX + KXzn+1 Kzn+1X We define: A = KXZn KZnX + λ1KXXLKXX + λ2KXX A is only dependent on X and Zn .",
                "Thus, the (n + 1)-th point zn+1 is given by: zn+1 = arg min zn+1 Tr KXX A + KXzn+1 Kzn+1X −1 KXX (16) Each time we select a new point zn+1, the matrix A is updated by: A ← A + KXzn+1 Kzn+1X If the kernel function is chosen as inner product K(x, y) = x, y , then HK is a linear functional space and the algorithm reduces to LOD. 5.",
                "CONTENT-BASED IMAGE RETRIEVAL USING LAPLACIAN OPTIMAL DESIGN In this section, we describe how to apply Laplacian Optimal Design to CBIR.",
                "We begin with a brief description of image representation using low level visual features. 5.1 Low-Level Image Representation Low-level image representation is a crucial problem in CBIR.",
                "General visual features includes color, texture, shape, etc.",
                "Color and texture features are the most extensively used visual features in CBIR.",
                "Compared with color and texture features, shape features are usually described after images have been segmented into regions or objects.",
                "Since robust and accurate image segmentation is difficult to achieve, the use of shape features for image retrieval has been limited to special applications where objects or regions are readily available.",
                "In this work, We combine 64-dimensional color histogram and 64-dimensional Color Texture Moment (CTM, [15]) to represent the images.",
                "The color histogram is calculated using 4 × 4 × 4 bins in HSV space.",
                "The Color Texture Moment is proposed by Yu et al. [15], which integrates the color and texture characteristics of the image in a compact form.",
                "CTM adopts local Fourier transform as a texture representation scheme and derives eight characteristic maps to describe different aspects of co-occurrence relations of image pixels in each channel of the (SVcosH, SVsinH, V) color space.",
                "Then CTM calculates the first and second moment of these maps as a representation of the natural color image pixel distribution.",
                "Please see [15] for details. 5.2 Relevance Feedback Image Retrieval Relevance feedback is one of the most important techniques to narrow down the gap between low level visual features and high level semantic concepts [12].",
                "Traditionally, the users relevance feedbacks are used to update the query vector or adjust the weighting of different dimensions.",
                "This process can be viewed as an on-line learning process in which the image retrieval system acts as a learner and the user acts as a teacher.",
                "They typical retrieval process is outlined as follows: 1.",
                "The user submits a query image example to the system.",
                "The system ranks the images in database according to some pre-defined distance metric and presents to the user the top ranked images. 2.",
                "The system selects some images from the database and request the user to label them as relevant or irrelevant. 3.",
                "The system uses the users provided information to rerank the images in database and returns to the user the top images.",
                "Go to step 2 until the user is satisfied.",
                "Our Laplacian Optimal Design algorithm is applied in the second step for selecting the most informative images.",
                "Once we get the labels for the images selected by LOD, we apply Laplacian Regularized Regression (LRR, [2]) to solve the optimization problem (3) and build the classifier.",
                "The classifier is then used to re-rank the images in database.",
                "Note that, in order to reduce the computational complexity, we do not use all the unlabeled images in the database but only those within top 500 returns of previous iteration. 6.",
                "EXPERIMENTAL RESULTS In this section, we evaluate the performance of our proposed algorithm on a large image database.",
                "To demonstrate the effectiveness of our proposed LOD algorithm, we compare it with Laplacian Regularized Regression (LRR, [2]), Support Vector Machine (SVM), Support Vector Machine Active Learning (SVMactive) [14], and A-Optimal Design (AOD).",
                "Both SVMactive, AOD, and LOD are active learning algorithms, while LRR and SVM are standard classification algorithms.",
                "SVM only makes use of the labeled images, while LRR is a semi-supervised learning algorithm which makes use of both labeled and unlabeled images.",
                "For SVMactive, AOD, and LOD, 10 training images are selected by the algorithms themselves at each iteration.",
                "While for LRR and SVM, we use the top 10 images as training data.",
                "It would be important to note that SVMactive is based on the ordinary SVM, LOD is based on LRR, and AOD is based on the ordinary regression.",
                "The parameters λ1 and λ2 in our LOD algorithm are empirically set to be 0.001 and 0.00001.",
                "For both LRR and LOD algorithms, we use the same graph structure (see Eq. 4) and set the value of p (number of nearest neighbors) to be 5.",
                "We begin with a simple synthetic example to give some intuition about how LOD works. 6.1 Simple Synthetic Example A simple synthetic example is given in Figure 1.",
                "The data set contains two circles.",
                "Eight points are selected by AOD and LOD.",
                "As can be seen, all the points selected by AOD are from the big circle, while LOD selects four points from the big circle and four from the small circle.",
                "The numbers beside the selected points denote their orders to be selected.",
                "Clearly, the points selected by our LOD algorithm can better represent the original data set.",
                "We did not compare our algorithm with SVMactive because SVMactive can not be applied in this case due to the lack of the labeled points. 6.2 Image Retrieval Experimental Design The image database we used consists of 7,900 images of 79 semantic categories, from COREL data set.",
                "It is a large and heterogeneous image set.",
                "Each image is represented as a 128-dimensional vector as described in Section 5.1.",
                "Figure 2 shows some sample images.",
                "To exhibit the advantages of using our algorithm, we need a reliable way of evaluating the retrieval performance and the comparisons with other algorithms.",
                "We list different aspects of the experimental design below. 6.2.1 Evaluation Metrics We use precision-scope curve and precision rate [10] to evaluate the effectiveness of the image retrieval algorithms.",
                "The scope is specified by the number (N) of top-ranked images presented to the user.",
                "The precision is the ratio of the number of relevant images presented to the user to the (a) Data set 1 2 3 4 5 6 7 8 (b) AOD 1 2 3 4 5 6 7 8 (c) LOD Figure 1: Data selection by active learning algorithms.",
                "The numbers beside the selected points denote their orders to be selected.",
                "Clearly, the points selected by our LOD algorithm can better represent the original data set.",
                "Note that, the SVMactive algorithm can not be applied in this case due to the lack of labeled points. (a) (b) (c) Figure 2: Sample images from category bead, elephant, and ship. scope N. The precision-scope curve describes the precision with various scopes and thus gives an overall performance evaluation of the algorithms.",
                "On the other hand, the precision rate emphasizes the precision at a particular value of scope.",
                "In general, it is appropriate to present 20 images on a screen.",
                "Putting more images on a screen may affect the quality of the presented images.",
                "Therefore, the precision at top 20 (N = 20) is especially important.",
                "In real world image retrieval systems, the query image is usually not in the image database.",
                "To simulate such environment, we use five-fold cross validation to evaluate the algorithms.",
                "More precisely, we divide the whole image database into five subsets with equal size.",
                "Thus, there are 20 images per category in each subset.",
                "At each run of cross validation, one subset is selected as the query set, and the other four subsets are used as the database for retrieval.",
                "The precisionscope curve and precision rate are computed by averaging the results from the five-fold cross validation. 6.2.2 Automatic Relevance Feedback Scheme We designed an automatic feedback scheme to model the retrieval process.",
                "For each submitted query, our system retrieves and ranks the images in the database. 10 images were selected from the database for user labeling and the label information is used by the system for re-ranking.",
                "Note that, the images which have been selected at previous iterations are excluded from later selections.",
                "For each query, the automatic relevance feedback mechanism is performed for four iterations.",
                "It is important to note that the automatic relevance feedback scheme used here is different from the ones described in [8], [11].",
                "In [8], [11], the top four relevant and irrelevant images were selected as the feedback images.",
                "However, this may not be practical.",
                "In real world image retrieval systems, it is possible that most of the top-ranked images are relevant (or, irrelevant).",
                "Thus, it is difficult for the user to find both four relevant and irrelevant images.",
                "It is more reasonable for the users to provide feedback information only on the 10 images selected by the system. 6.3 Image Retrieval Performance In real world, it is not practical to require the user to provide many rounds of feedbacks.",
                "The retrieval performance after the first two rounds of feedbacks (especially the first round) is more important.",
                "Figure 3 shows the average precision-scope curves of the different algorithms for the first two feedback iterations.",
                "At the beginning of retrieval, the Euclidean distances in the original 128-dimensional space are used to rank the images in database.",
                "After the user provides relevance feedbacks, the LRR, SVM, SVMactive, AOD, and LOD algorithms are then applied to re-rank the images.",
                "In order to reduce the time complexity of active learning algorithms, we didnt select the most informative images from the whole database but from the top 500 images.",
                "For LRR and SVM, the user is required to label the top 10 images.",
                "For SVMactive, AOD, and LOD, the user is required to label 10 most informative images selected by these algorithms.",
                "Note that, SVMactive can only be ap(a) Feedback Iteration 1 (b) Feedback Iteration 2 Figure 3: The average precision-scope curves of different algorithms for the first two feedback iterations.",
                "The LOD algorithm performs the best on the entire scope.",
                "Note that, at the first round of feedback, the SVMactive algorithm can not be applied.",
                "It applies the ordinary SVM to build the initial classifier. (a) Precision at Top 10 (b) Precision at Top 20 (c) Precision at Top 30 Figure 4: Performance evaluation of the five learning algorithms for relevance feedback image retrieval. (a) Precision at top 10, (b) Precision at top 20, and (c) Precision at top 30.",
                "As can be seen, our LOD algorithm consistently outperforms the other four algorithms. plied when the classifier is already built.",
                "Therefore, it can not be applied at the first round and we use the standard SVM to build the initial classifier.",
                "As can be seen, our LOD algorithm outperforms the other four algorithms on the entire scope.",
                "Also, the LRR algorithm performs better than SVM.",
                "This is because that the LRR algorithm makes efficient use of the unlabeled images by incorporating a locality preserving regularizer into the ordinary regression objective function.",
                "The AOD algorithm performs the worst.",
                "As the scope gets larger, the performance difference between these algorithms gets smaller.",
                "By iteratively adding the users feedbacks, the corresponding precision results (at top 10, top 20, and top 30) of the five algorithms are respectively shown in Figure 4.",
                "As can be seen, our LOD algorithm performs the best in all the cases and the LRR algorithm performs the second best.",
                "Both of these two algorithms make use of the unlabeled images.",
                "This shows that the unlabeled images are helpful for discovering the intrinsic geometrical structure of the image space and therefore enhance the retrieval performance.",
                "In real world, the user may not be willing to provide too many relevance feedbacks.",
                "Therefore, the retrieval performance at the first two rounds are especially important.",
                "As can be seen, our LOD algorithm achieves 6.8% performance improvement for top 10 results, 5.2% for top 20 results, and 4.1% for top 30 results, comparing to the second best algorithm (LRR) after the first two rounds of relevance feedbacks. 6.4 Discussion Several experiments on Corel database have been systematically performed.",
                "We would like to highlight several interesting points: 1.",
                "It is clear that the use of active learning is beneficial in the image retrieval domain.",
                "There is a significant increase in performance from using the active learning methods.",
                "Especially, out of the three active learning methods (SVMactive, AOD, LOD), our proposed LOD algorithm performs the best. 2.",
                "In many real world applications like relevance feedback image retrieval, there are generally two ways of reducing labor-intensive manual labeling task.",
                "One is active learning which selects the most informative samples to label, and the other is semi-supervised learning which makes use of the unlabeled samples to enhance the learning performance.",
                "Both of these two strategies have been studied extensively in the past [14], [7], [5], [8].",
                "The work presented in this paper is focused on active learning, but it also takes advantage of the recent progresses on semi-supervised learning [2].",
                "Specifically, we incorporate a locality preserving regularizer into the standard regression framework and find the most informative samples with respect to the new objective function.",
                "In this way, the active learning and semi-supervised learning techniques are seamlessly unified for learning an optimal classifier. 3.",
                "The relevance feedback technique is crucial to image retrieval.",
                "For all the five algorithms, the retrieval performance improves with more feedbacks provided by the user. 7.",
                "CONCLUSIONS AND FUTURE WORK This paper describes a novel active learning algorithm, called Laplacian Optimal Design, to enable more effective relevance feedback image retrieval.",
                "Our algorithm is based on an objective function which simultaneously minimizes the empirical error and preserves the local geometrical structure of the data space.",
                "Using techniques from experimental design, our algorithm finds the most informative images to label.",
                "These labeled images and the unlabeled images in the database are used to learn a classifier.",
                "The experimental results on Corel database show that both active learning and semi-supervised learning can significantly improve the retrieval performance.",
                "In this paper, we consider the image retrieval problem on a small, static, and closed-domain image data.",
                "A much more challenging domain is the World Wide Web (WWW).",
                "For Web image search, it is possible to collect a large amount of user click information.",
                "This information can be naturally used to construct the affinity graph in our algorithm.",
                "However, the computational complexity in Web scenario may become a crucial issue.",
                "Also, although our primary interest in this paper is focused on relevance feedback image retrieval, our results may also be of interest to researchers in patten recognition and machine learning, especially when a large amount of data is available but only a limited samples can be labeled. 8.",
                "REFERENCES [1] A. C. Atkinson and A. N. Donev.",
                "Optimum Experimental Designs.",
                "Oxford University Press, 2002. [2] M. Belkin, P. Niyogi, and V. Sindhwani.",
                "Manifold regularization: A geometric framework for learning from examples.",
                "Journal of Machine Learning Research, 7:2399-2434, 2006. [3] F. R. K. Chung.",
                "Spectral Graph Theory, volume 92 of Regional Conference Series in Mathematics.",
                "AMS, 1997. [4] D. A. Cohn, Z. Ghahramani, and M. I. Jordan.",
                "Active learning with statistical models.",
                "Journal of Artificial Intelligence Research, 4:129-145, 1996. [5] A. Dong and B. Bhanu.",
                "A new semi-supervised em algorithm for image retrieval.",
                "In IEEE Conf. on Computer Vision and Pattern Recognition, Madison, WI, 2003. [6] P. Flaherty, M. I. Jordan, and A. P. Arkin.",
                "Robust design of biological experiments.",
                "In Advances in Neural Information Processing Systems 18, Vancouver, Canada, 2005. [7] K.-S. Goh, E. Y. Chang, and W.-C. Lai.",
                "Multimodal concept-dependent active learning for image retrieval.",
                "In Proceedings of the ACM Conference on Multimedia, New York, October 2004. [8] X.",
                "He.",
                "Incremental semi-supervised subspace learning for image retrieval.",
                "In Proceedings of the ACM Conference on Multimedia, New York, October 2004. [9] S. C. Hoi and M. R. Lyu.",
                "A semi-supervised active learning framework for image retrieval.",
                "In IEEE International Conference on Computer Vision and Pattern Recognition, San Diego, CA, 2005. [10] D. P. Huijsmans and N. Sebe.",
                "How to complete performance graphs in content-based image retrieval: Add generality and normalize scope.",
                "IEEE Transactions on Pattern Analysis and Machine Intelligence, 27(2):245-251, 2005. [11] Y.-Y.",
                "Lin, T.-L. Liu, and H.-T. Chen.",
                "Semantic manifold learning for image retrieval.",
                "In Proceedings of the ACM Conference on Multimedia, Singapore, November 2005. [12] Y. Rui, T. S. Huang, M. Ortega, and S. Mehrotra.",
                "Relevance feedback: A power tool for interative content-based image retrieval.",
                "IEEE Transactions on Circuits and Systems for Video Technology, 8(5), 1998. [13] A. W. Smeulders, M. Worring, S. Santini, A. Gupta, and R. Jain.",
                "Content-based image retrieval at the end of the early years.",
                "IEEE Transactions on Pattern Analysis and Machine Intelligence, 22(12):1349-1380, 2000. [14] S. Tong and E. Chang.",
                "Support vector machine active learning for image retrieval.",
                "In Proceedings of the ninth ACM international conference on Multimedia, pages 107-118, 2001. [15] H. Yu, M. Li, H.-J.",
                "Zhang, and J. Feng.",
                "Color texture moments for content-based image retrieval.",
                "In International Conference on Image Processing, pages 24-28, 2002. [16] K. Yu, J. Bi, and V. Tresp.",
                "Active learning via transductive experimental design.",
                "In Proceedings of the 23rd International Conference on Machine Learning, Pittsburgh, PA, 2006."
            ],
            "original_annotated_samples": [
                "We discuss how results from the field of <br>optimal experimental design</br> may be used to guide our selection of a subset of images, which gives us the most amount of information.",
                "The study of <br>optimal experimental design</br> (OED) [1] is concerned with the design of experiments that are expected to minimize variances of a parameterized model.",
                "The intent of <br>optimal experimental design</br> is usually to maximize confidence in a given model, minimize parameter variances for system identification, or minimize the models output variance.",
                "Benefit from recent progresses on <br>optimal experimental design</br> and semi-supervised learning, in this paper we propose a novel active learning algorithm for image retrieval, called Laplacian Optimal Design (LOD).",
                "The most related work is <br>optimal experimental design</br> [1], including A-Optimal Design, D-Optimal Design, and EOptimal Design."
            ],
            "translated_annotated_samples": [
                "Discutimos cómo los resultados del campo del <br>diseño experimental óptimo</br> pueden ser utilizados para guiar nuestra selección de un subconjunto de imágenes, que nos proporciona la mayor cantidad de información.",
                "El estudio del <br>diseño experimental óptimo</br> (DEO) se preocupa por el diseño de experimentos que se espera que minimicen las varianzas de un modelo parametrizado.",
                "La intención del <br>diseño experimental óptimo</br> suele ser maximizar la confianza en un modelo dado, minimizar las varianzas de los parámetros para la identificación del sistema, o minimizar la varianza de la salida de los modelos.",
                "Beneficiar de los avances recientes en <br>diseño experimental óptimo</br> y aprendizaje semisupervisado, en este artículo proponemos un nuevo algoritmo de aprendizaje activo para recuperación de imágenes, llamado Diseño Óptimo Laplaciano (LOD).",
                "El trabajo más relacionado es el <br>diseño experimental óptimo</br> [1], que incluye el Diseño A-Óptimo, el Diseño D-Óptimo y el Diseño E-Óptimo."
            ],
            "translated_text": "Diseño óptimo de Laplaciano para la recuperación de imágenes Xiaofei He Yahoo! El feedback de relevancia es una técnica poderosa para mejorar el rendimiento de la Recuperación de Imágenes Basada en Contenido (CBIR). Solicita las valoraciones de relevancia de los usuarios sobre las imágenes recuperadas por los sistemas CBIR. La etiqueta de los usuarios se utiliza luego para entrenar un clasificador que distinga entre imágenes relevantes e irrelevantes. Sin embargo, las imágenes principales que se devuelven pueden no ser las más informativas. El desafío consiste en determinar qué imágenes sin etiquetar serían las más informativas (es decir, mejorarían más al clasificador) si fueran etiquetadas y utilizadas como muestras de entrenamiento. En este artículo, proponemos un novedoso algoritmo de aprendizaje activo, llamado Diseño Óptimo Laplaciano (LOD), para la recuperación de imágenes con retroalimentación de relevancia. Nuestro algoritmo se basa en un modelo de regresión que minimiza el error cuadrático mínimo en las imágenes medidas (o etiquetadas) y al mismo tiempo preserva la estructura geométrica local del espacio de la imagen. Específicamente, asumimos que si dos imágenes están lo suficientemente cerca una de la otra, entonces sus medidas (o etiquetas) también son cercanas. Al construir un grafo de vecinos más cercanos, la estructura geométrica del espacio de la imagen puede ser descrita por el Laplaciano del grafo. Discutimos cómo los resultados del campo del <br>diseño experimental óptimo</br> pueden ser utilizados para guiar nuestra selección de un subconjunto de imágenes, que nos proporciona la mayor cantidad de información. Los resultados experimentales en la base de datos Corel sugieren que el enfoque propuesto logra una mayor precisión en la recuperación de imágenes con retroalimentación de relevancia. Categorías y Descriptores de Asignaturas H.3.3 [Almacenamiento y recuperación de información]: Búsqueda y recuperación de información-Retroalimentación de relevancia; G.3 [Matemáticas de la Computación]: Probabilidad y Estadística-Diseño experimental Términos Generales Algoritmos, Rendimiento, Teoría 1. INTRODUCCIÓN En muchas tareas de aprendizaje automático y recuperación de información, no hay escasez de datos no etiquetados pero las etiquetas son costosas. El desafío consiste en determinar qué muestras sin etiquetar serían las más informativas (es decir, mejorarían más el clasificador) si fueran etiquetadas y utilizadas como muestras de entrenamiento. Este problema se llama típicamente aprendizaje activo [4]. Aquí la tarea es minimizar un costo general, que depende tanto de la precisión del clasificador como del costo de la recolección de datos. Muchas aplicaciones del mundo real pueden ser adaptadas al marco de aprendizaje activo. Particularmente, consideramos el problema de la recuperación de imágenes basada en contenido impulsada por la retroalimentación de relevancia (CBIR) [13]. La Recuperación de Imágenes Basada en Contenido ha atraído un interés sustancial en la última década [13]. Está motivado por el rápido crecimiento de las bases de datos de imágenes digitales que, a su vez, requieren esquemas de búsqueda eficientes. En lugar de describir una imagen usando texto, en estos sistemas se describe una consulta de imagen utilizando una o más imágenes de ejemplo. Las características visuales de bajo nivel (color, textura, forma, etc.) se extraen automáticamente para representar las imágenes. Sin embargo, las características de bajo nivel pueden no caracterizar con precisión los conceptos semánticos de alto nivel. Para reducir la brecha semántica, se introduce la retroalimentación de relevancia en la recuperación de información basada en el contenido (CBIR) [12]. En muchos de los sistemas actuales de recuperación de imágenes basados en retroalimentación de relevancia, se requiere que el usuario proporcione sus juicios de relevancia sobre las imágenes principales devueltas por el sistema. Las imágenes etiquetadas se utilizan luego para entrenar un clasificador que separe las imágenes que coinciden con el concepto de la consulta de aquellas que no lo hacen. Sin embargo, en general, las imágenes principales que se devuelven pueden no ser las más informativas. En el peor de los casos, todas las imágenes principales etiquetadas por el usuario pueden ser positivas y, por lo tanto, las técnicas estándar de clasificación no pueden aplicarse debido a la falta de ejemplos negativos. A diferencia de los problemas de clasificación estándar donde las muestras etiquetadas están predefinidas, en la recuperación de imágenes con retroalimentación de relevancia, el sistema puede seleccionar activamente las imágenes a etiquetar. Por lo tanto, el aprendizaje activo puede ser introducido de forma natural en la recuperación de imágenes. A pesar de la existencia de muchas técnicas de aprendizaje activo, el aprendizaje activo de Máquina de Vectores de Soporte (SVM) [14] y el aprendizaje activo basado en regresión [1] han sido los que han despertado mayor interés. Basado en la observación de que cuanto más cerca del límite del SVM se encuentre una imagen, menos confiable es su clasificación, el aprendizaje activo del SVM selecciona aquellas imágenes no etiquetadas más cercanas al límite para solicitar retroalimentación del usuario con el fin de lograr un refinamiento máximo en el hiperplano entre las dos clases. La principal desventaja del aprendizaje activo de SVM es que es posible que el límite estimado no sea lo suficientemente preciso. Además, puede que no se aplique al principio de la recuperación cuando no hay imágenes etiquetadas. Algunos otros algoritmos de aprendizaje activo basados en SVM se pueden encontrar en [7], [9]. En estadística, el problema de seleccionar muestras para etiquetar se conoce típicamente como diseño experimental. La muestra x se denomina experimento, y su etiqueta y se denomina medición. El estudio del <br>diseño experimental óptimo</br> (DEO) se preocupa por el diseño de experimentos que se espera que minimicen las varianzas de un modelo parametrizado. La intención del <br>diseño experimental óptimo</br> suele ser maximizar la confianza en un modelo dado, minimizar las varianzas de los parámetros para la identificación del sistema, o minimizar la varianza de la salida de los modelos. Los enfoques clásicos de diseño experimental incluyen el Diseño A-Óptimo, el Diseño D-Óptimo y el Diseño E-Óptimo. Todos estos enfoques se basan en un modelo de regresión de mínimos cuadrados. En comparación con los algoritmos de aprendizaje activo basados en SVM, los enfoques de diseño experimental son mucho más eficientes en términos de computación. Sin embargo, este tipo de enfoques solo tienen en cuenta los datos medidos (o etiquetados) en su función objetivo, mientras que los datos no medidos (o no etiquetados) son ignorados. Beneficiar de los avances recientes en <br>diseño experimental óptimo</br> y aprendizaje semisupervisado, en este artículo proponemos un nuevo algoritmo de aprendizaje activo para recuperación de imágenes, llamado Diseño Óptimo Laplaciano (LOD). A diferencia de los métodos tradicionales de diseño experimental cuyas funciones de pérdida solo están definidas en los puntos medidos, la función de pérdida de nuestro algoritmo propuesto LOD está definida tanto en los puntos medidos como en los no medidos. Específicamente, introducimos un regularizador que preserva la localidad en la función de pérdida estándar basada en el error cuadrático mínimo. La nueva función de pérdida tiene como objetivo encontrar un clasificador que sea localmente lo más suave posible. En otras palabras, si dos puntos están suficientemente cerca uno del otro en el espacio de entrada, se espera que compartan la misma etiqueta. Una vez que se define la función de pérdida, podemos seleccionar los puntos de datos más informativos que se presentan al usuario para su etiquetado. Sería importante tener en cuenta que las imágenes más informativas pueden no ser las primeras imágenes devueltas. El resto del documento está organizado de la siguiente manera. En la Sección 2, proporcionamos una breve descripción del trabajo relacionado. Nuestro algoritmo propuesto de Diseño Óptimo de Laplaciano se introduce en la Sección 3. En la Sección 4, comparamos nuestro algoritmo con los algoritmos de última generación y presentamos los resultados experimentales sobre la recuperación de imágenes. Finalmente, proporcionamos algunas observaciones finales y sugerencias para trabajos futuros en la Sección 5.2. TRABAJO RELACIONADO Dado que nuestro algoritmo propuesto se basa en un marco de regresión. El trabajo más relacionado es el <br>diseño experimental óptimo</br> [1], que incluye el Diseño A-Óptimo, el Diseño D-Óptimo y el Diseño E-Óptimo. ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "top returned image": {
            "translated_key": "imágenes principales que se devuelven",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Laplacian Optimal Design for Image Retrieval Xiaofei He Yahoo!",
                "Burbank, CA 91504 hex@yahoo-inc.com Wanli Min IBM Yorktown Heights, NY 10598 wanlimin@us.ibm.com Deng Cai CS Dept., UIUC Urbana, IL 61801 dengcai2@cs.uiuc.edu Kun Zhou Microsoft Research Asia Beijing, China kunzhou@microsoft.com ABSTRACT Relevance feedback is a powerful technique to enhance ContentBased Image Retrieval (CBIR) performance.",
                "It solicits the users relevance judgments on the retrieved images returned by the CBIR systems.",
                "The users labeling is then used to learn a classifier to distinguish between relevant and irrelevant images.",
                "However, the <br>top returned image</br>s may not be the most informative ones.",
                "The challenge is thus to determine which unlabeled images would be the most informative (i.e., improve the classifier the most) if they were labeled and used as training samples.",
                "In this paper, we propose a novel active learning algorithm, called Laplacian Optimal Design (LOD), for relevance feedback image retrieval.",
                "Our algorithm is based on a regression model which minimizes the least square error on the measured (or, labeled) images and simultaneously preserves the local geometrical structure of the image space.",
                "Specifically, we assume that if two images are sufficiently close to each other, then their measurements (or, labels) are close as well.",
                "By constructing a nearest neighbor graph, the geometrical structure of the image space can be described by the graph Laplacian.",
                "We discuss how results from the field of optimal experimental design may be used to guide our selection of a subset of images, which gives us the most amount of information.",
                "Experimental results on Corel database suggest that the proposed approach achieves higher precision in relevance feedback image retrieval.",
                "Categories and Subject Descriptors H.3.3 [Information storage and retrieval]: Information search and retrieval-Relevance feedback; G.3 [Mathematics of Computing]: Probability and Statistics-Experimental design General Terms Algorithms, Performance, Theory 1.",
                "INTRODUCTION In many machine learning and information retrieval tasks, there is no shortage of unlabeled data but labels are expensive.",
                "The challenge is thus to determine which unlabeled samples would be the most informative (i.e., improve the classifier the most) if they were labeled and used as training samples.",
                "This problem is typically called active learning [4].",
                "Here the task is to minimize an overall cost, which depends both on the classifier accuracy and the cost of data collection.",
                "Many real world applications can be casted into active learning framework.",
                "Particularly, we consider the problem of relevance feedback driven Content-Based Image Retrieval (CBIR) [13].",
                "Content-Based Image Retrieval has attracted substantial interests in the last decade [13].",
                "It is motivated by the fast growth of digital image databases which, in turn, require efficient search schemes.",
                "Rather than describe an image using text, in these systems an image query is described using one or more example images.",
                "The low level visual features (color, texture, shape, etc.) are automatically extracted to represent the images.",
                "However, the low level features may not accurately characterize the high level semantic concepts.",
                "To narrow down the semantic gap, relevance feedback is introduced into CBIR [12].",
                "In many of the current relevance feedback driven CBIR systems, the user is required to provide his/her relevance judgments on the top images returned by the system.",
                "The labeled images are then used to train a classifier to separate images that match the query concept from those that do not.",
                "However, in general the <br>top returned image</br>s may not be the most informative ones.",
                "In the worst case, all the top images labeled by the user may be positive and thus the standard classification techniques can not be applied due to the lack of negative examples.",
                "Unlike the standard classification problems where the labeled samples are pregiven, in relevance feedback image retrieval the system can actively select the images to label.",
                "Thus active learning can be naturally introduced into image retrieval.",
                "Despite many existing active learning techniques, Support Vector Machine (SVM) active learning [14] and regression based active learning [1] have received the most interests.",
                "Based on the observation that the closer to the SVM boundary an image is, the less reliable its classification is, SVM active learning selects those unlabeled images closest to the boundary to solicit user feedback so as to achieve maximal refinement on the hyperplane between the two classes.",
                "The major disadvantage of SVM active learning is that the estimated boundary may not be accurate enough.",
                "Moreover, it may not be applied at the beginning of the retrieval when there is no labeled images.",
                "Some other SVM based active learning algorithms can be found in [7], [9].",
                "In statistics, the problem of selecting samples to label is typically referred to as experimental design.",
                "The sample x is referred to as experiment, and its label y is referred to as measurement.",
                "The study of optimal experimental design (OED) [1] is concerned with the design of experiments that are expected to minimize variances of a parameterized model.",
                "The intent of optimal experimental design is usually to maximize confidence in a given model, minimize parameter variances for system identification, or minimize the models output variance.",
                "Classical experimental design approaches include A-Optimal Design, D-Optimal Design, and E-Optimal Design.",
                "All of these approaches are based on a least squares regression model.",
                "Comparing to SVM based active learning algorithms, experimental design approaches are much more efficient in computation.",
                "However, this kind of approaches takes only measured (or, labeled) data into account in their objective function, while the unmeasured (or, unlabeled) data is ignored.",
                "Benefit from recent progresses on optimal experimental design and semi-supervised learning, in this paper we propose a novel active learning algorithm for image retrieval, called Laplacian Optimal Design (LOD).",
                "Unlike traditional experimental design methods whose loss functions are only defined on the measured points, the loss function of our proposed LOD algorithm is defined on both measured and unmeasured points.",
                "Specifically, we introduce a locality preserving regularizer into the standard least-square-error based loss function.",
                "The new loss function aims to find a classifier which is locally as smooth as possible.",
                "In other words, if two points are sufficiently close to each other in the input space, then they are expected to share the same label.",
                "Once the loss function is defined, we can select the most informative data points which are presented to the user for labeling.",
                "It would be important to note that the most informative images may not be the <br>top returned image</br>s.",
                "The rest of the paper is organized as follows.",
                "In Section 2, we provide a brief description of the related work.",
                "Our proposed Laplacian Optimal Design algorithm is introduced in Section 3.",
                "In Section 4, we compare our algorithm with the state-or-the-art algorithms and present the experimental results on image retrieval.",
                "Finally, we provide some concluding remarks and suggestions for future work in Section 5. 2.",
                "RELATED WORK Since our proposed algorithm is based on regression framework.",
                "The most related work is optimal experimental design [1], including A-Optimal Design, D-Optimal Design, and EOptimal Design.",
                "In this Section, we give a brief description of these approaches. 2.1 The Active Learning Problem The generic problem of active learning is the following.",
                "Given a set of points A = {x1, x2, · · · , xm} in Rd , find a subset B = {z1, z2, · · · , zk} ⊂ A which contains the most informative points.",
                "In other words, the points zi(i = 1, · · · , k) can improve the classifier the most if they are labeled and used as training points. 2.2 Optimal Experimental Design We consider a linear regression model y = wT x + (1) where y is the observation, x is the independent variable, w is the weight vector and is an unknown error with zero mean.",
                "Different observations have errors that are independent, but with equal variances σ2 .",
                "We define f(x) = wT x to be the learners output given input x and the weight vector w. Suppose we have a set of labeled sample points (z1, y1), · · · , (zk, yk), where yi is the label of zi.",
                "Thus, the maximum likelihood estimate for the weight vector, ˆw, is that which minimizes the sum squared error Jsse(w) = k i=1 wT zi − yi 2 (2) The estimate ˆw gives us an estimate of the output at a novel input: ˆy = ˆwT x.",
                "By Gauss-Markov theorem, we know that ˆw − w has a zero mean and a covariance matrix given by σ2 H−1 sse, where Hsse is the Hessian of Jsse(w) Hsse = ∂2 Jsse ∂w2 = k i=1 zizT i = ZZT where Z = (z1, z2, · · · , zk).",
                "The three most common scalar measures of the size of the parameter covariance matrix in optimal experimental design are: • D-optimal design: determinant of Hsse. • A-optimal design: trace of Hsse. • E-optimal design: maximum eigenvalue of Hsse.",
                "Since the computation of the determinant and eigenvalues of a matrix is much more expensive than the computation of matrix trace, A-optimal design is more efficient than the other two.",
                "Some recent work on experimental design can be found in [6], [16]. 3.",
                "LAPLACIAN OPTIMAL DESIGN Since the covariance matrix Hsse used in traditional approaches is only dependent on the measured samples, i.e. zis, these approaches fail to evaluate the expected errors on the unmeasured samples.",
                "In this Section, we introduce a novel active learning algorithm called Laplacian Optimal Design (LOD) which makes efficient use of both measured (labeled) and unmeasured (unlabeled) samples. 3.1 The Objective Function In many machine learning problems, it is natural to assume that if two points xi, xj are sufficiently close to each other, then their measurements (f(xi), f(xj)) are close as well.",
                "Let S be a similarity matrix.",
                "Thus, a new loss function which respects the geometrical structure of the data space can be defined as follows: J0(w) = k i=1 f(zi)−yi 2 + λ 2 m i,j=1 f(xi)−f(xj) 2 Sij (3) where yi is the measurement (or, label) of zi.",
                "Note that, the loss function (3) is essentially the same as the one used in Laplacian Regularized Regression (LRR, [2]).",
                "However, LRR is a passive learning algorithm where the training data is given.",
                "In this paper, we are focused on how to select the most informative data for training.",
                "The loss function with our choice of symmetric weights Sij (Sij = Sji) incurs a heavy penalty if neighboring points xi and xj are mapped far apart.",
                "Therefore, minimizing J0(w) is an attempt to ensure that if xi and xj are close then f(xi) and f(xj) are close as well.",
                "There are many choices of the similarity matrix S. A simple definition is as follows: Sij = ⎧ ⎨ ⎩ 1, if xi is among the p nearest neighbors of xj, or xj is among the p nearest neighbors of xi; 0, otherwise. (4) Let D be a diagonal matrix, Dii = j Sij, and L = D−S.",
                "The matrix L is called graph Laplacian in spectral graph theory [3].",
                "Let y = (y1, · · · , yk)T and X = (x1, · · · , xm).",
                "Following some simple algebraic steps, we see that: J0(w) = k i=1 wT zi − yi 2 + λ 2 m i,j=1 wT xi − wT xj 2 Sij = y − ZT w T y − ZT w + λwT m i=1 DiixixT i − m i,j=1 SijxixT j w = yT y − 2wT Zy + wT ZZT w +λwT XDXT − XSXT w = yT y − 2wT Zy + wT ZZT + λXLXT w The Hessian of J0(w) can be computed as follows: H0 = ∂2 J0 ∂w2 = ZZT + λXLXT In some cases, the matrix ZZT +λXLXT is singular (e.g. if m < d).",
                "Thus, there is no stable solution to the optimization problem Eq. (3).",
                "A common way to deal with this ill-posed problem is to introduce a Tikhonov regularizer into our loss function: J(w) = k i=1 wT zi − yi 2 + λ1 2 m i,j=1 wT xi − wT xj 2 Sij +λ2 w 2 (5) The Hessian of the new loss function is given by: H = ∂2 J ∂w2 = ZZT + λ1XLXT + λ2I := ZZT + Λ where I is an identity matrix and Λ = λ1XLXT + λ2I.",
                "Clearly, H is of full rank.",
                "Requiring that the gradient of J(w) with respect to w vanish gives the optimal estimate ˆw: ˆw = H−1 Zy The following proposition states the bias and variance properties of the estimator for the coefficient vector w. Proposition 3.1.",
                "E( ˆw − w) = −H−1 Λw, Cov( ˆw) = σ2 (H−1 − H−1 ΛH−1 ) Proof.",
                "Since y = ZT w + and E( ) = 0, it follows that E( ˆw − w) (6) = H−1 ZZT w − w = H−1 (ZZT + Λ − Λ)w − w = (I − H−1 Λ)w − w = −H−1 Λw (7) Notice Cov(y) = σ2 I, the covariance matrix of ˆw has the expression: Cov( ˆw) = H−1 ZCov(y)ZT H−1 = σ2 H−1 ZZT H−1 = σ2 H−1 (H − Λ)H−1 = σ2 (H−1 − H−1 ΛH−1 ) (8) Therefore mean squared error matrix for the coefficients w is E(w − ˆw)(w − ˆw)T (9) = H−1 ΛwwT ΛH−1 + σ2 (H−1 − H−1 ΛH−1 ) (10) For any x, let ˆy = ˆwT x be its predicted observation.",
                "The expected squared prediction error is E(y − ˆy)2 = E( + wT x − ˆwT x)2 = σ2 + xT [E(w − ˆw)(w − ˆw)T ]x = σ2 + xT [H−1 ΛwwT ΛH−1 + σ2 H−1 − σ2 H−1 ΛH−1 ]x Clearly the expected square prediction error depends on the explanatory variable x, therefore average expected square predictive error over the complete data set A is 1 m m i=1 E(yi − ˆwT xi)2 = 1 m m i=1 xT i [H−1 ΛwwT ΛH−1 + σ2 H−1 − σ2 H−1 ΛH−1 ]xi +σ2 = 1 m Tr(XT [σ2 H−1 + H−1 ΛwwT ΛH−1 − σ2 H−1 ΛH−1 ]X) +σ2 Since Tr(XT [H−1 ΛwwT ΛH−1 − σ2 H−1 ΛH−1 ]X) Tr(σ2 XT H−1 X), Our Laplacian optimality criterion is thus formulated by minimizing the trace of XT H−1 X.",
                "Definition 1.",
                "Laplacian Optimal Design min Z=(z1,··· ,zk) Tr XT ZZT + λ1XLXT + λ2I −1 X (11) where z1, · · · , zk are selected from {x1, · · · , xm}. 4.",
                "KERNEL LAPLACIAN OPTIMAL DESIGN Canonical experimental design approaches (e.g.",
                "A-Optimal Design, D-Optimal Design, and E-Optimal) only consider linear functions.",
                "They fail to discover the intrinsic geometry in the data when the data space is highly nonlinear.",
                "In this section, we describe how to perform Laplacian Experimental Design in Reproducing Kernel Hilbert Space (RKHS) which gives rise to Kernel Laplacian Experimental Design (KLOD).",
                "For given data points x1, · · · , xm ∈ X with a positive definite mercer kernel K : X ×X → R, there exists a unique RKHS HK of real valued functions on X.",
                "Let Kt(s) be the function of s obtained by fixing t and letting Kt(s) . = K(s, t).",
                "HK consists of all finite linear combinations of the form l i=1 αiKti with ti ∈ X and limits of such functions as the ti become dense in X.",
                "We have Ks, Kt HK = K(s, t). 4.1 Derivation of LOD in Reproducing Kernel Hilbert Space Consider the optimization problem (5) in RKHS.",
                "Thus, we seek a function f ∈ HK such that the following objective function is minimized: min f∈HK k i=1 f(zi)−yi 2 + λ1 2 m i,j=1 f(xi)−f(xj) 2 Sij+λ2 f 2 HK (12) We have the following proposition.",
                "Proposition 4.1.",
                "Let H = { m i=1 αiK(·, xi)|αi ∈ R} be a subspace of HK , the solution to the problem (12) is in H. Proof.",
                "Let H⊥ be the orthogonal complement of H, i.e.",
                "HK = H ⊕ H⊥ .",
                "Thus, for any function f ∈ HK , it has orthogonal decomposition as follows: f = fH + fH⊥ Now, lets evaluate f at xi: f(xi) = f, Kxi HK = fH + fH⊥ , Kxi HK = fH, Kxi HK + fH⊥ , Kxi HK Notice that Kxi ∈ H while fH⊥ ∈ H⊥ .",
                "This implies that fH⊥ , Kxi HK = 0.",
                "Therefore, f(xi) = fH, Kxi HK = fH(xi) This completes the proof.",
                "Proposition 4.1 tells us the minimizer of problem (12) admits a representation f∗ = m i=1 αiK(·, xi).",
                "Please see [2] for the details.",
                "Let φ : Rd → H be a feature map from the input space Rd to H, and K(xi, xj) =< φ(xi), φ(xj) >.",
                "Let X denote the data matrix in RKHS, X = (φ(x1), φ(x2), · · · , φ(xm)).",
                "Similarly, we define Z = (φ(z1), φ(z2), · · · , φ(zk)).",
                "Thus, the optimization problem in RKHS can be written as follows: min Z Tr XT ZZT + λ1XLXT + λ2I −1 X (13) Since the mapping function φ is generally unknown, there is no direct way to solve problem (13).",
                "In the following, we apply kernel tricks to solve this optimization problem.",
                "Let X−1 be the Moore-Penrose inverse (also known as pseudo inverse) of X.",
                "Thus, we have: XT ZZT + λ1XLXT + λ2I −1 X = XT XX−1 ZZT + λ1XLXT + λ2I −1 (XT )−1 XT X = XT X ZZT X + λ1XLXT X + λ2X −1 (XT )−1 XT X = XT X XT ZZT X + λ1XT XLXT X + λ2XT X −1 XT X = KXX KXZKZX + λ1KXXLKXX + λ2KXX −1 KXX where KXX is a m × m matrix (KXX,ij = K(xi, xj)), KXZ is a m×k matrix (KXZ,ij = K(xi, zj)), and KZX is a k×m matrix (KZX,ij = K(zi, xj)).",
                "Thus, the Kernel Laplacian Optimal Design can be defined as follows: Definition 2.",
                "Kernel Laplacian Optimal Design minZ=(z1,··· ,zk) Tr KXX KXZKZX + λ1KXXLKXX λ2KXX −1 KXX (14) 4.2 Optimization Scheme In this subsection, we discuss how to solve the optimization problems (11) and (14).",
                "Particularly, if we select a linear kernel for KLOD, then it reduces to LOD.",
                "Therefore, we will focus on problem (14) in the following.",
                "It can be shown that the optimization problem (14) is NP-hard.",
                "In this subsection, we develop a simple sequential greedy approach to solve (14).",
                "Suppose n points have been selected, denoted by a matrix Zn = (z1, · · · , zn).",
                "The (n + 1)-th point zn+1 can be selected by solving the following optimization problem: max Zn+1=(Zn,zn+1) Tr KXX KXZn+1 KZn+1X + λ1KXXLKXX + λ2KXX −1 KXX (15) The kernel matrices KXZn+1 and KZn+1X can be rewritten as follows: KXZn+1 = KXZn , KXzn+1 , KZn+1X = KZnX Kzn+1X Thus, we have: KXZn+1 KZn+1X = KXZn KZnX + KXzn+1 Kzn+1X We define: A = KXZn KZnX + λ1KXXLKXX + λ2KXX A is only dependent on X and Zn .",
                "Thus, the (n + 1)-th point zn+1 is given by: zn+1 = arg min zn+1 Tr KXX A + KXzn+1 Kzn+1X −1 KXX (16) Each time we select a new point zn+1, the matrix A is updated by: A ← A + KXzn+1 Kzn+1X If the kernel function is chosen as inner product K(x, y) = x, y , then HK is a linear functional space and the algorithm reduces to LOD. 5.",
                "CONTENT-BASED IMAGE RETRIEVAL USING LAPLACIAN OPTIMAL DESIGN In this section, we describe how to apply Laplacian Optimal Design to CBIR.",
                "We begin with a brief description of image representation using low level visual features. 5.1 Low-Level Image Representation Low-level image representation is a crucial problem in CBIR.",
                "General visual features includes color, texture, shape, etc.",
                "Color and texture features are the most extensively used visual features in CBIR.",
                "Compared with color and texture features, shape features are usually described after images have been segmented into regions or objects.",
                "Since robust and accurate image segmentation is difficult to achieve, the use of shape features for image retrieval has been limited to special applications where objects or regions are readily available.",
                "In this work, We combine 64-dimensional color histogram and 64-dimensional Color Texture Moment (CTM, [15]) to represent the images.",
                "The color histogram is calculated using 4 × 4 × 4 bins in HSV space.",
                "The Color Texture Moment is proposed by Yu et al. [15], which integrates the color and texture characteristics of the image in a compact form.",
                "CTM adopts local Fourier transform as a texture representation scheme and derives eight characteristic maps to describe different aspects of co-occurrence relations of image pixels in each channel of the (SVcosH, SVsinH, V) color space.",
                "Then CTM calculates the first and second moment of these maps as a representation of the natural color image pixel distribution.",
                "Please see [15] for details. 5.2 Relevance Feedback Image Retrieval Relevance feedback is one of the most important techniques to narrow down the gap between low level visual features and high level semantic concepts [12].",
                "Traditionally, the users relevance feedbacks are used to update the query vector or adjust the weighting of different dimensions.",
                "This process can be viewed as an on-line learning process in which the image retrieval system acts as a learner and the user acts as a teacher.",
                "They typical retrieval process is outlined as follows: 1.",
                "The user submits a query image example to the system.",
                "The system ranks the images in database according to some pre-defined distance metric and presents to the user the top ranked images. 2.",
                "The system selects some images from the database and request the user to label them as relevant or irrelevant. 3.",
                "The system uses the users provided information to rerank the images in database and returns to the user the top images.",
                "Go to step 2 until the user is satisfied.",
                "Our Laplacian Optimal Design algorithm is applied in the second step for selecting the most informative images.",
                "Once we get the labels for the images selected by LOD, we apply Laplacian Regularized Regression (LRR, [2]) to solve the optimization problem (3) and build the classifier.",
                "The classifier is then used to re-rank the images in database.",
                "Note that, in order to reduce the computational complexity, we do not use all the unlabeled images in the database but only those within top 500 returns of previous iteration. 6.",
                "EXPERIMENTAL RESULTS In this section, we evaluate the performance of our proposed algorithm on a large image database.",
                "To demonstrate the effectiveness of our proposed LOD algorithm, we compare it with Laplacian Regularized Regression (LRR, [2]), Support Vector Machine (SVM), Support Vector Machine Active Learning (SVMactive) [14], and A-Optimal Design (AOD).",
                "Both SVMactive, AOD, and LOD are active learning algorithms, while LRR and SVM are standard classification algorithms.",
                "SVM only makes use of the labeled images, while LRR is a semi-supervised learning algorithm which makes use of both labeled and unlabeled images.",
                "For SVMactive, AOD, and LOD, 10 training images are selected by the algorithms themselves at each iteration.",
                "While for LRR and SVM, we use the top 10 images as training data.",
                "It would be important to note that SVMactive is based on the ordinary SVM, LOD is based on LRR, and AOD is based on the ordinary regression.",
                "The parameters λ1 and λ2 in our LOD algorithm are empirically set to be 0.001 and 0.00001.",
                "For both LRR and LOD algorithms, we use the same graph structure (see Eq. 4) and set the value of p (number of nearest neighbors) to be 5.",
                "We begin with a simple synthetic example to give some intuition about how LOD works. 6.1 Simple Synthetic Example A simple synthetic example is given in Figure 1.",
                "The data set contains two circles.",
                "Eight points are selected by AOD and LOD.",
                "As can be seen, all the points selected by AOD are from the big circle, while LOD selects four points from the big circle and four from the small circle.",
                "The numbers beside the selected points denote their orders to be selected.",
                "Clearly, the points selected by our LOD algorithm can better represent the original data set.",
                "We did not compare our algorithm with SVMactive because SVMactive can not be applied in this case due to the lack of the labeled points. 6.2 Image Retrieval Experimental Design The image database we used consists of 7,900 images of 79 semantic categories, from COREL data set.",
                "It is a large and heterogeneous image set.",
                "Each image is represented as a 128-dimensional vector as described in Section 5.1.",
                "Figure 2 shows some sample images.",
                "To exhibit the advantages of using our algorithm, we need a reliable way of evaluating the retrieval performance and the comparisons with other algorithms.",
                "We list different aspects of the experimental design below. 6.2.1 Evaluation Metrics We use precision-scope curve and precision rate [10] to evaluate the effectiveness of the image retrieval algorithms.",
                "The scope is specified by the number (N) of top-ranked images presented to the user.",
                "The precision is the ratio of the number of relevant images presented to the user to the (a) Data set 1 2 3 4 5 6 7 8 (b) AOD 1 2 3 4 5 6 7 8 (c) LOD Figure 1: Data selection by active learning algorithms.",
                "The numbers beside the selected points denote their orders to be selected.",
                "Clearly, the points selected by our LOD algorithm can better represent the original data set.",
                "Note that, the SVMactive algorithm can not be applied in this case due to the lack of labeled points. (a) (b) (c) Figure 2: Sample images from category bead, elephant, and ship. scope N. The precision-scope curve describes the precision with various scopes and thus gives an overall performance evaluation of the algorithms.",
                "On the other hand, the precision rate emphasizes the precision at a particular value of scope.",
                "In general, it is appropriate to present 20 images on a screen.",
                "Putting more images on a screen may affect the quality of the presented images.",
                "Therefore, the precision at top 20 (N = 20) is especially important.",
                "In real world image retrieval systems, the query image is usually not in the image database.",
                "To simulate such environment, we use five-fold cross validation to evaluate the algorithms.",
                "More precisely, we divide the whole image database into five subsets with equal size.",
                "Thus, there are 20 images per category in each subset.",
                "At each run of cross validation, one subset is selected as the query set, and the other four subsets are used as the database for retrieval.",
                "The precisionscope curve and precision rate are computed by averaging the results from the five-fold cross validation. 6.2.2 Automatic Relevance Feedback Scheme We designed an automatic feedback scheme to model the retrieval process.",
                "For each submitted query, our system retrieves and ranks the images in the database. 10 images were selected from the database for user labeling and the label information is used by the system for re-ranking.",
                "Note that, the images which have been selected at previous iterations are excluded from later selections.",
                "For each query, the automatic relevance feedback mechanism is performed for four iterations.",
                "It is important to note that the automatic relevance feedback scheme used here is different from the ones described in [8], [11].",
                "In [8], [11], the top four relevant and irrelevant images were selected as the feedback images.",
                "However, this may not be practical.",
                "In real world image retrieval systems, it is possible that most of the top-ranked images are relevant (or, irrelevant).",
                "Thus, it is difficult for the user to find both four relevant and irrelevant images.",
                "It is more reasonable for the users to provide feedback information only on the 10 images selected by the system. 6.3 Image Retrieval Performance In real world, it is not practical to require the user to provide many rounds of feedbacks.",
                "The retrieval performance after the first two rounds of feedbacks (especially the first round) is more important.",
                "Figure 3 shows the average precision-scope curves of the different algorithms for the first two feedback iterations.",
                "At the beginning of retrieval, the Euclidean distances in the original 128-dimensional space are used to rank the images in database.",
                "After the user provides relevance feedbacks, the LRR, SVM, SVMactive, AOD, and LOD algorithms are then applied to re-rank the images.",
                "In order to reduce the time complexity of active learning algorithms, we didnt select the most informative images from the whole database but from the top 500 images.",
                "For LRR and SVM, the user is required to label the top 10 images.",
                "For SVMactive, AOD, and LOD, the user is required to label 10 most informative images selected by these algorithms.",
                "Note that, SVMactive can only be ap(a) Feedback Iteration 1 (b) Feedback Iteration 2 Figure 3: The average precision-scope curves of different algorithms for the first two feedback iterations.",
                "The LOD algorithm performs the best on the entire scope.",
                "Note that, at the first round of feedback, the SVMactive algorithm can not be applied.",
                "It applies the ordinary SVM to build the initial classifier. (a) Precision at Top 10 (b) Precision at Top 20 (c) Precision at Top 30 Figure 4: Performance evaluation of the five learning algorithms for relevance feedback image retrieval. (a) Precision at top 10, (b) Precision at top 20, and (c) Precision at top 30.",
                "As can be seen, our LOD algorithm consistently outperforms the other four algorithms. plied when the classifier is already built.",
                "Therefore, it can not be applied at the first round and we use the standard SVM to build the initial classifier.",
                "As can be seen, our LOD algorithm outperforms the other four algorithms on the entire scope.",
                "Also, the LRR algorithm performs better than SVM.",
                "This is because that the LRR algorithm makes efficient use of the unlabeled images by incorporating a locality preserving regularizer into the ordinary regression objective function.",
                "The AOD algorithm performs the worst.",
                "As the scope gets larger, the performance difference between these algorithms gets smaller.",
                "By iteratively adding the users feedbacks, the corresponding precision results (at top 10, top 20, and top 30) of the five algorithms are respectively shown in Figure 4.",
                "As can be seen, our LOD algorithm performs the best in all the cases and the LRR algorithm performs the second best.",
                "Both of these two algorithms make use of the unlabeled images.",
                "This shows that the unlabeled images are helpful for discovering the intrinsic geometrical structure of the image space and therefore enhance the retrieval performance.",
                "In real world, the user may not be willing to provide too many relevance feedbacks.",
                "Therefore, the retrieval performance at the first two rounds are especially important.",
                "As can be seen, our LOD algorithm achieves 6.8% performance improvement for top 10 results, 5.2% for top 20 results, and 4.1% for top 30 results, comparing to the second best algorithm (LRR) after the first two rounds of relevance feedbacks. 6.4 Discussion Several experiments on Corel database have been systematically performed.",
                "We would like to highlight several interesting points: 1.",
                "It is clear that the use of active learning is beneficial in the image retrieval domain.",
                "There is a significant increase in performance from using the active learning methods.",
                "Especially, out of the three active learning methods (SVMactive, AOD, LOD), our proposed LOD algorithm performs the best. 2.",
                "In many real world applications like relevance feedback image retrieval, there are generally two ways of reducing labor-intensive manual labeling task.",
                "One is active learning which selects the most informative samples to label, and the other is semi-supervised learning which makes use of the unlabeled samples to enhance the learning performance.",
                "Both of these two strategies have been studied extensively in the past [14], [7], [5], [8].",
                "The work presented in this paper is focused on active learning, but it also takes advantage of the recent progresses on semi-supervised learning [2].",
                "Specifically, we incorporate a locality preserving regularizer into the standard regression framework and find the most informative samples with respect to the new objective function.",
                "In this way, the active learning and semi-supervised learning techniques are seamlessly unified for learning an optimal classifier. 3.",
                "The relevance feedback technique is crucial to image retrieval.",
                "For all the five algorithms, the retrieval performance improves with more feedbacks provided by the user. 7.",
                "CONCLUSIONS AND FUTURE WORK This paper describes a novel active learning algorithm, called Laplacian Optimal Design, to enable more effective relevance feedback image retrieval.",
                "Our algorithm is based on an objective function which simultaneously minimizes the empirical error and preserves the local geometrical structure of the data space.",
                "Using techniques from experimental design, our algorithm finds the most informative images to label.",
                "These labeled images and the unlabeled images in the database are used to learn a classifier.",
                "The experimental results on Corel database show that both active learning and semi-supervised learning can significantly improve the retrieval performance.",
                "In this paper, we consider the image retrieval problem on a small, static, and closed-domain image data.",
                "A much more challenging domain is the World Wide Web (WWW).",
                "For Web image search, it is possible to collect a large amount of user click information.",
                "This information can be naturally used to construct the affinity graph in our algorithm.",
                "However, the computational complexity in Web scenario may become a crucial issue.",
                "Also, although our primary interest in this paper is focused on relevance feedback image retrieval, our results may also be of interest to researchers in patten recognition and machine learning, especially when a large amount of data is available but only a limited samples can be labeled. 8.",
                "REFERENCES [1] A. C. Atkinson and A. N. Donev.",
                "Optimum Experimental Designs.",
                "Oxford University Press, 2002. [2] M. Belkin, P. Niyogi, and V. Sindhwani.",
                "Manifold regularization: A geometric framework for learning from examples.",
                "Journal of Machine Learning Research, 7:2399-2434, 2006. [3] F. R. K. Chung.",
                "Spectral Graph Theory, volume 92 of Regional Conference Series in Mathematics.",
                "AMS, 1997. [4] D. A. Cohn, Z. Ghahramani, and M. I. Jordan.",
                "Active learning with statistical models.",
                "Journal of Artificial Intelligence Research, 4:129-145, 1996. [5] A. Dong and B. Bhanu.",
                "A new semi-supervised em algorithm for image retrieval.",
                "In IEEE Conf. on Computer Vision and Pattern Recognition, Madison, WI, 2003. [6] P. Flaherty, M. I. Jordan, and A. P. Arkin.",
                "Robust design of biological experiments.",
                "In Advances in Neural Information Processing Systems 18, Vancouver, Canada, 2005. [7] K.-S. Goh, E. Y. Chang, and W.-C. Lai.",
                "Multimodal concept-dependent active learning for image retrieval.",
                "In Proceedings of the ACM Conference on Multimedia, New York, October 2004. [8] X.",
                "He.",
                "Incremental semi-supervised subspace learning for image retrieval.",
                "In Proceedings of the ACM Conference on Multimedia, New York, October 2004. [9] S. C. Hoi and M. R. Lyu.",
                "A semi-supervised active learning framework for image retrieval.",
                "In IEEE International Conference on Computer Vision and Pattern Recognition, San Diego, CA, 2005. [10] D. P. Huijsmans and N. Sebe.",
                "How to complete performance graphs in content-based image retrieval: Add generality and normalize scope.",
                "IEEE Transactions on Pattern Analysis and Machine Intelligence, 27(2):245-251, 2005. [11] Y.-Y.",
                "Lin, T.-L. Liu, and H.-T. Chen.",
                "Semantic manifold learning for image retrieval.",
                "In Proceedings of the ACM Conference on Multimedia, Singapore, November 2005. [12] Y. Rui, T. S. Huang, M. Ortega, and S. Mehrotra.",
                "Relevance feedback: A power tool for interative content-based image retrieval.",
                "IEEE Transactions on Circuits and Systems for Video Technology, 8(5), 1998. [13] A. W. Smeulders, M. Worring, S. Santini, A. Gupta, and R. Jain.",
                "Content-based image retrieval at the end of the early years.",
                "IEEE Transactions on Pattern Analysis and Machine Intelligence, 22(12):1349-1380, 2000. [14] S. Tong and E. Chang.",
                "Support vector machine active learning for image retrieval.",
                "In Proceedings of the ninth ACM international conference on Multimedia, pages 107-118, 2001. [15] H. Yu, M. Li, H.-J.",
                "Zhang, and J. Feng.",
                "Color texture moments for content-based image retrieval.",
                "In International Conference on Image Processing, pages 24-28, 2002. [16] K. Yu, J. Bi, and V. Tresp.",
                "Active learning via transductive experimental design.",
                "In Proceedings of the 23rd International Conference on Machine Learning, Pittsburgh, PA, 2006."
            ],
            "original_annotated_samples": [
                "However, the <br>top returned image</br>s may not be the most informative ones.",
                "However, in general the <br>top returned image</br>s may not be the most informative ones.",
                "It would be important to note that the most informative images may not be the <br>top returned image</br>s."
            ],
            "translated_annotated_samples": [
                "Sin embargo, las <br>imágenes principales que se devuelven</br> pueden no ser las más informativas.",
                "Sin embargo, en general, las <br>imágenes principales que se devuelven</br> pueden no ser las más informativas.",
                "Sería importante tener en cuenta que las imágenes más informativas pueden no ser las primeras <br>imágenes devueltas</br>."
            ],
            "translated_text": "Diseño óptimo de Laplaciano para la recuperación de imágenes Xiaofei He Yahoo! El feedback de relevancia es una técnica poderosa para mejorar el rendimiento de la Recuperación de Imágenes Basada en Contenido (CBIR). Solicita las valoraciones de relevancia de los usuarios sobre las imágenes recuperadas por los sistemas CBIR. La etiqueta de los usuarios se utiliza luego para entrenar un clasificador que distinga entre imágenes relevantes e irrelevantes. Sin embargo, las <br>imágenes principales que se devuelven</br> pueden no ser las más informativas. El desafío consiste en determinar qué imágenes sin etiquetar serían las más informativas (es decir, mejorarían más al clasificador) si fueran etiquetadas y utilizadas como muestras de entrenamiento. En este artículo, proponemos un novedoso algoritmo de aprendizaje activo, llamado Diseño Óptimo Laplaciano (LOD), para la recuperación de imágenes con retroalimentación de relevancia. Nuestro algoritmo se basa en un modelo de regresión que minimiza el error cuadrático mínimo en las imágenes medidas (o etiquetadas) y al mismo tiempo preserva la estructura geométrica local del espacio de la imagen. Específicamente, asumimos que si dos imágenes están lo suficientemente cerca una de la otra, entonces sus medidas (o etiquetas) también son cercanas. Al construir un grafo de vecinos más cercanos, la estructura geométrica del espacio de la imagen puede ser descrita por el Laplaciano del grafo. Discutimos cómo los resultados del campo del diseño experimental óptimo pueden ser utilizados para guiar nuestra selección de un subconjunto de imágenes, que nos proporciona la mayor cantidad de información. Los resultados experimentales en la base de datos Corel sugieren que el enfoque propuesto logra una mayor precisión en la recuperación de imágenes con retroalimentación de relevancia. Categorías y Descriptores de Asignaturas H.3.3 [Almacenamiento y recuperación de información]: Búsqueda y recuperación de información-Retroalimentación de relevancia; G.3 [Matemáticas de la Computación]: Probabilidad y Estadística-Diseño experimental Términos Generales Algoritmos, Rendimiento, Teoría 1. INTRODUCCIÓN En muchas tareas de aprendizaje automático y recuperación de información, no hay escasez de datos no etiquetados pero las etiquetas son costosas. El desafío consiste en determinar qué muestras sin etiquetar serían las más informativas (es decir, mejorarían más el clasificador) si fueran etiquetadas y utilizadas como muestras de entrenamiento. Este problema se llama típicamente aprendizaje activo [4]. Aquí la tarea es minimizar un costo general, que depende tanto de la precisión del clasificador como del costo de la recolección de datos. Muchas aplicaciones del mundo real pueden ser adaptadas al marco de aprendizaje activo. Particularmente, consideramos el problema de la recuperación de imágenes basada en contenido impulsada por la retroalimentación de relevancia (CBIR) [13]. La Recuperación de Imágenes Basada en Contenido ha atraído un interés sustancial en la última década [13]. Está motivado por el rápido crecimiento de las bases de datos de imágenes digitales que, a su vez, requieren esquemas de búsqueda eficientes. En lugar de describir una imagen usando texto, en estos sistemas se describe una consulta de imagen utilizando una o más imágenes de ejemplo. Las características visuales de bajo nivel (color, textura, forma, etc.) se extraen automáticamente para representar las imágenes. Sin embargo, las características de bajo nivel pueden no caracterizar con precisión los conceptos semánticos de alto nivel. Para reducir la brecha semántica, se introduce la retroalimentación de relevancia en la recuperación de información basada en el contenido (CBIR) [12]. En muchos de los sistemas actuales de recuperación de imágenes basados en retroalimentación de relevancia, se requiere que el usuario proporcione sus juicios de relevancia sobre las imágenes principales devueltas por el sistema. Las imágenes etiquetadas se utilizan luego para entrenar un clasificador que separe las imágenes que coinciden con el concepto de la consulta de aquellas que no lo hacen. Sin embargo, en general, las <br>imágenes principales que se devuelven</br> pueden no ser las más informativas. En el peor de los casos, todas las imágenes principales etiquetadas por el usuario pueden ser positivas y, por lo tanto, las técnicas estándar de clasificación no pueden aplicarse debido a la falta de ejemplos negativos. A diferencia de los problemas de clasificación estándar donde las muestras etiquetadas están predefinidas, en la recuperación de imágenes con retroalimentación de relevancia, el sistema puede seleccionar activamente las imágenes a etiquetar. Por lo tanto, el aprendizaje activo puede ser introducido de forma natural en la recuperación de imágenes. A pesar de la existencia de muchas técnicas de aprendizaje activo, el aprendizaje activo de Máquina de Vectores de Soporte (SVM) [14] y el aprendizaje activo basado en regresión [1] han sido los que han despertado mayor interés. Basado en la observación de que cuanto más cerca del límite del SVM se encuentre una imagen, menos confiable es su clasificación, el aprendizaje activo del SVM selecciona aquellas imágenes no etiquetadas más cercanas al límite para solicitar retroalimentación del usuario con el fin de lograr un refinamiento máximo en el hiperplano entre las dos clases. La principal desventaja del aprendizaje activo de SVM es que es posible que el límite estimado no sea lo suficientemente preciso. Además, puede que no se aplique al principio de la recuperación cuando no hay imágenes etiquetadas. Algunos otros algoritmos de aprendizaje activo basados en SVM se pueden encontrar en [7], [9]. En estadística, el problema de seleccionar muestras para etiquetar se conoce típicamente como diseño experimental. La muestra x se denomina experimento, y su etiqueta y se denomina medición. El estudio del diseño experimental óptimo (DEO) se preocupa por el diseño de experimentos que se espera que minimicen las varianzas de un modelo parametrizado. La intención del diseño experimental óptimo suele ser maximizar la confianza en un modelo dado, minimizar las varianzas de los parámetros para la identificación del sistema, o minimizar la varianza de la salida de los modelos. Los enfoques clásicos de diseño experimental incluyen el Diseño A-Óptimo, el Diseño D-Óptimo y el Diseño E-Óptimo. Todos estos enfoques se basan en un modelo de regresión de mínimos cuadrados. En comparación con los algoritmos de aprendizaje activo basados en SVM, los enfoques de diseño experimental son mucho más eficientes en términos de computación. Sin embargo, este tipo de enfoques solo tienen en cuenta los datos medidos (o etiquetados) en su función objetivo, mientras que los datos no medidos (o no etiquetados) son ignorados. Beneficiar de los avances recientes en diseño experimental óptimo y aprendizaje semisupervisado, en este artículo proponemos un nuevo algoritmo de aprendizaje activo para recuperación de imágenes, llamado Diseño Óptimo Laplaciano (LOD). A diferencia de los métodos tradicionales de diseño experimental cuyas funciones de pérdida solo están definidas en los puntos medidos, la función de pérdida de nuestro algoritmo propuesto LOD está definida tanto en los puntos medidos como en los no medidos. Específicamente, introducimos un regularizador que preserva la localidad en la función de pérdida estándar basada en el error cuadrático mínimo. La nueva función de pérdida tiene como objetivo encontrar un clasificador que sea localmente lo más suave posible. En otras palabras, si dos puntos están suficientemente cerca uno del otro en el espacio de entrada, se espera que compartan la misma etiqueta. Una vez que se define la función de pérdida, podemos seleccionar los puntos de datos más informativos que se presentan al usuario para su etiquetado. Sería importante tener en cuenta que las imágenes más informativas pueden no ser las primeras <br>imágenes devueltas</br>. El resto del documento está organizado de la siguiente manera. En la Sección 2, proporcionamos una breve descripción del trabajo relacionado. Nuestro algoritmo propuesto de Diseño Óptimo de Laplaciano se introduce en la Sección 3. En la Sección 4, comparamos nuestro algoritmo con los algoritmos de última generación y presentamos los resultados experimentales sobre la recuperación de imágenes. Finalmente, proporcionamos algunas observaciones finales y sugerencias para trabajos futuros en la Sección 5.2. TRABAJO RELACIONADO Dado que nuestro algoritmo propuesto se basa en un marco de regresión. El trabajo más relacionado es el diseño experimental óptimo [1], que incluye el Diseño A-Óptimo, el Diseño D-Óptimo y el Diseño E-Óptimo. En esta sección, damos una breve descripción de estos enfoques. 2.1 El Problema del Aprendizaje Activo El problema genérico del aprendizaje activo es el siguiente. Dado un conjunto de puntos A = {x1, x2, · · · , xm} en Rd , encuentra un subconjunto B = {z1, z2, · · · , zk} ⊂ A que contenga los puntos más informativos. En otras palabras, los puntos zi(i = 1, · · · , k) pueden mejorar el clasificador al máximo si están etiquetados y se utilizan como puntos de entrenamiento. 2.2 Diseño Experimental Óptimo Consideramos un modelo de regresión lineal y = wT x + (1) donde y es la observación, x es la variable independiente, w es el vector de pesos y es un error desconocido con media cero. Diferentes observaciones tienen errores que son independientes, pero con varianzas iguales σ2. Definimos f(x) = wT x como la salida del aprendiz dada la entrada x y el vector de pesos w. Supongamos que tenemos un conjunto de puntos de muestra etiquetados (z1, y1), · · · , (zk, yk), donde yi es la etiqueta de zi. Por lo tanto, la estimación de máxima verosimilitud para el vector de peso, ˆw, es aquella que minimiza la suma del error cuadrado Jsse(w) = k i=1 wT zi − yi 2 (2). La estimación ˆw nos proporciona una estimación de la salida en una entrada novedosa: ˆy = ˆwT x. Según el teorema de Gauss-Markov, sabemos que ˆw − w tiene una media cero y una matriz de covarianza dada por σ2 H−1 sse, donde Hsse es la Hessiana de Jsse(w) Hsse = ∂2 Jsse ∂w2 = k i=1 zizT i = ZZT donde Z = (z1, z2, · · · , zk). Las tres medidas escalares más comunes del tamaño de la matriz de covarianza de parámetros en el diseño experimental óptimo son: • Diseño D-óptimo: determinante de Hsse. • Diseño A-óptimo: traza de Hsse. • Diseño E-óptimo: valor propio máximo de Hsse. Dado que el cálculo del determinante y los valores propios de una matriz es mucho más costoso que el cálculo de la traza de la matriz, el diseño A-óptimo es más eficiente que los otros dos. Algunos trabajos recientes sobre diseño experimental se pueden encontrar en [6], [16]. DISEÑO ÓPTIMO LAPLACIANO Dado que la matriz de covarianza Hsse utilizada en enfoques tradicionales solo depende de las muestras medidas, es decir, zis, estos enfoques no logran evaluar los errores esperados en las muestras no medidas. En esta sección, presentamos un novedoso algoritmo de aprendizaje activo llamado Diseño Óptimo Laplaciano (LOD) que hace un uso eficiente tanto de muestras medidas (etiquetadas) como no medidas (sin etiquetar). 3.1 La Función Objetivo En muchos problemas de aprendizaje automático, es natural asumir que si dos puntos xi, xj están suficientemente cerca uno del otro, entonces sus mediciones (f(xi), f(xj)) también son cercanas. Sea S una matriz de similitud. Por lo tanto, una nueva función de pérdida que respeta la estructura geométrica del espacio de datos se puede definir de la siguiente manera: J0(w) = k i=1 f(zi)−yi 2 + λ 2 m i,j=1 f(xi)−f(xj) 2 Sij (3) donde yi es la medición (o etiqueta) de zi. Se debe tener en cuenta que la función de pérdida (3) es esencialmente la misma que la utilizada en la Regresión Regularizada Laplaciana (LRR, [2]). Sin embargo, LRR es un algoritmo de aprendizaje pasivo donde se proporcionan los datos de entrenamiento. En este artículo, nos enfocamos en cómo seleccionar los datos más informativos para el entrenamiento. La función de pérdida con nuestra elección de pesos simétricos Sij (Sij = Sji) incurre en una penalización severa si los puntos vecinos xi y xj se asignan lejos uno del otro. Por lo tanto, minimizar J0(w) es un intento de asegurar que si xi y xj están cerca, entonces f(xi) y f(xj) también estén cerca. Hay muchas opciones de la matriz de similitud S. Una definición simple es la siguiente: Sij = ⎧ ⎨ ⎩ 1, si xi está entre los p vecinos más cercanos de xj, o xj está entre los p vecinos más cercanos de xi; 0, en otro caso. (4) Sea D una matriz diagonal, Dii = j Sij, y L = D−S. La matriz L se llama Laplaciano de grafo en la teoría espectral de grafos [3]. Sea y = (y1, · · · , yk)T y X = (x1, · · · , xm). Siguiendo algunos pasos algebraicos simples, vemos que: J0(w) = k i=1 wT zi − yi 2 + λ 2 m i,j=1 wT xi − wT xj 2 Sij = y − ZT w T y − ZT w + λwT m i=1 DiixixT i − m i,j=1 SijxixT j w = yT y − 2wT Zy + wT ZZT w +λwT m i=1 DiixixT i − m i,j=1 SijxixT j w = yT y − 2wT Zy + wT ZZT + λXLXT w La Hessiana de J0(w) se puede calcular de la siguiente manera: H0 = ∂2 J0 ∂w2 = ZZT + λXLXT En algunos casos, la matriz ZZT +λXLXT es singular (por ejemplo, si m < d). Por lo tanto, no hay una solución estable para el problema de optimización Ec. (3). Una forma común de abordar este problema mal planteado es introducir un regularizador de Tikhonov en nuestra función de pérdida: J(w) = k i=1 wT zi − yi 2 + λ1 2 m i,j=1 wT xi − wT xj 2 Sij +λ2 w 2 (5) El Hessiano de la nueva función de pérdida está dado por: H = ∂2 J ∂w2 = ZZT + λ1XLXT + λ2I := ZZT + Λ donde I es una matriz identidad y Λ = λ1XLXT + λ2I. Claramente, H tiene rango completo. Exigir que el gradiente de J(w) con respecto a w se anule proporciona la estimación óptima ˆw: ˆw = H−1 Zy. La siguiente proposición establece las propiedades de sesgo y varianza del estimador para el vector de coeficientes w. Proposición 3.1. E( ˆw − w) = −H−1 Λw, Cov( ˆw) = σ2 (H−1 − H−1 ΛH−1 ) Demostración. Dado que y = ZTw + y E( ) = 0, se deduce que E( ˆw − w) (6) = H−1 ZZTw − w = H−1 (ZZT + Λ − Λ)w − w = (I − H−1 Λ)w − w = −H−1 Λw (7) Nótese que Cov(y) = σ2 I, la matriz de covarianza de ˆw tiene la expresión: Cov( ˆw) = H−1 ZCov(y)ZT H−1 = σ2 H−1 ZZT H−1 = σ2 H−1 (H − Λ)H−1 = σ2 (H−1 − H−1 ΛH−1 ) (8) Por lo tanto, la matriz de error cuadrático medio para los coeficientes w es E(w − ˆw)(w − ˆw)T (9) = H−1 ΛwwT ΛH−1 + σ2 (H−1 − H−1 ΛH−1 ) (10) Para cualquier x, sea ˆy = ˆwT x su observación predicha. El error cuadrático de predicción esperado es E(y − ˆy)2 = E( + wT x − ˆwT x)2 = σ2 + xT [E(w − ˆw)(w − ˆw)T ]x = σ2 + xT [H−1 ΛwwT ΛH−1 + σ2 H−1 − σ2 H−1 ΛH−1 ]x Claramente, el error cuadrático de predicción esperado depende de la variable explicativa x, por lo tanto, el error cuadrático de predicción promedio esperado sobre el conjunto de datos completo A es 1 m m i=1 E(yi − ˆwT xi)2 = 1 m m i=1 xT i [H−1 ΛwwT ΛH−1 + σ2 H−1 − σ2 H−1 ΛH−1 ]xi +σ2 = 1 m Tr(XT [σ2 H−1 + H−1 ΛwwT ΛH−1 − σ2 H−1 ΛH−1 ]X) +σ2 Dado que Tr(XT [H−1 ΛwwT ΛH−1 − σ2 H−1 ΛH−1 ]X) Tr(σ2 XT H−1 X), nuestro criterio de optimalidad laplaciano se formula minimizando la traza de XT H−1 X. Definición 1. Diseño óptimo de Laplaciano min Z=(z1,··· ,zk) Tr XT ZZT + λ1XLXT + λ2I −1 X (11) donde z1, · · · , zk son seleccionados de {x1, · · · , xm}. 4. DISEÑO ÓPTIMO DEL NÚCLEO LAPLACIANO Enfoques canónicos de diseño experimental (por ejemplo, Los diseños A-óptimos, D-óptimos y E-óptimos solo consideran funciones lineales. No logran descubrir la geometría intrínseca en los datos cuando el espacio de datos es altamente no lineal. En esta sección, describimos cómo realizar el Diseño Experimental Laplaciano en el Espacio de Hilbert de Núcleos Reproductores (RKHS), lo que da lugar al Diseño Experimental Laplaciano de Núcleo (KLOD). Para los puntos de datos dados x1, · · · , xm ∈ X con un núcleo de Mercer positivo definido K : X ×X → R, existe un único RKHS HK de funciones de valores reales en X. Sea Kt(s) la función de s obtenida al fijar t y dejar que Kt(s) = K(s, t). HK consiste en todas las combinaciones lineales finitas de la forma ∑ i=1 αiKti con ti ∈ X y los límites de tales funciones a medida que los ti se vuelven densos en X. Tenemos Ks, Kt HK = K(s, t). 4.1 Derivación de LOD en el Espacio de Hilbert del Núcleo Reproductor. Considera el problema de optimización (5) en RKHS. Por lo tanto, buscamos una función f ∈ HK tal que se minimice la siguiente función objetivo: min f∈HK k i=1 f(zi)−yi 2 + λ1 2 m i,j=1 f(xi)−f(xj) 2 Sij+λ2 f 2 HK (12). Tenemos la siguiente proposición. Proposición 4.1. Sea H = { m i=1 αiK(·, xi)|αi ∈ R} un subespacio de HK, la solución al problema (12) está en H. Demostración. Sea H⊥ el complemento ortogonal de H, es decir, HK = H ⊕ H⊥. Por lo tanto, para cualquier función f ∈ HK, tiene una descomposición ortogonal de la siguiente manera: f = fH + fH⊥ Ahora, evaluemos f en xi: f(xi) = f, Kxi HK = fH + fH⊥ , Kxi HK = fH, Kxi HK + fH⊥ , Kxi HK Observa que Kxi ∈ H mientras que fH⊥ ∈ H⊥. Esto implica que fH⊥ , Kxi HK = 0. Por lo tanto, f(xi) = fH, Kxi HK = fH(xi). Esto completa la prueba. La Proposición 4.1 nos dice que el minimizador del problema (12) admite una representación f∗ = m i=1 αiK(·, xi). Por favor, consulte [2] para ver los detalles. Sea φ : Rd → H un mapeo de características del espacio de entrada Rd a H, y K(xi, xj) =< φ(xi), φ(xj) >. Que X denote la matriz de datos en RKHS, X = (φ(x1), φ(x2), · · · , φ(xm)). De manera similar, definimos Z = (φ(z1), φ(z2), · · · , φ(zk)). Por lo tanto, el problema de optimización en RKHS se puede escribir de la siguiente manera: min Z Tr XT ZZT + λ1XLXT + λ2I −1 X (13) Dado que la función de mapeo φ generalmente es desconocida, no hay una forma directa de resolver el problema (13). En lo siguiente, aplicamos trucos de kernel para resolver este problema de optimización. Sea X−1 la inversa de Moore-Penrose (también conocida como pseudoinversa) de X. Así, tenemos: XT ZZT + λ1XLXT + λ2I −1 X = XT XX−1 ZZT + λ1XLXT + λ2I −1 (XT )−1 XT X = XT X ZZT X + λ1XLXT X + λ2X −1 (XT )−1 XT X = XT X XT ZZT X + λ1XT XLXT X + λ2XT X −1 XT X = KXX KXZKZX + λ1KXXLKXX + λ2KXX −1 KXX donde KXX es una matriz m × m (KXX,ij = K(xi, xj)), KXZ es una matriz m×k (KXZ,ij = K(xi, zj)), y KZX es una matriz k×m (KZX,ij = K(zi, xj)). Por lo tanto, el Diseño Óptimo del Laplaciano del Núcleo se puede definir de la siguiente manera: Definición 2. En este subapartado, discutimos cómo resolver los problemas de optimización (11) y (14). Particularmente, si seleccionamos un núcleo lineal para KLOD, entonces se reduce a LOD. Por lo tanto, nos enfocaremos en el problema (14) a continuación. Se puede demostrar que el problema de optimización (14) es NP-duro. En esta subsección, desarrollamos un enfoque codicioso secuencial simple para resolver (14). Supongamos que se han seleccionado n puntos, denotados por una matriz Zn = (z1, · · · , zn). El punto (n + 1)-ésimo zn+1 puede ser seleccionado resolviendo el siguiente problema de optimización: max Zn+1=(Zn,zn+1) Tr KXX KXZn+1 KZn+1X + λ1KXXLKXX + λ2KXX −1 KXX (15) Las matrices de kernel KXZn+1 y KZn+1X pueden ser reescritas de la siguiente manera: KXZn+1 = KXZn , KXzn+1 , KZn+1X = KZnX Kzn+1X Por lo tanto, tenemos: KXZn+1 KZn+1X = KXZn KZnX + KXzn+1 Kzn+1X Definimos: A = KXZn KZnX + λ1KXXLKXX + λ2KXX A solo depende de X y Zn. Por lo tanto, el punto (n + 1)-ésimo zn+1 se da por: zn+1 = arg min zn+1 Tr KXX A + KXzn+1 Kzn+1X −1 KXX. Cada vez que seleccionamos un nuevo punto zn+1, la matriz A se actualiza por: A ← A + KXzn+1 Kzn+1X. Si la función de kernel se elige como producto interno K(x, y) = x, y, entonces HK es un espacio funcional lineal y el algoritmo se reduce a LOD. 5. RECUPERACIÓN DE IMÁGENES BASADA EN CONTENIDO UTILIZANDO DISEÑO ÓPTIMO LAPLACIANO En esta sección, describimos cómo aplicar el Diseño Óptimo Laplaciano a la RCIB. Comenzamos con una breve descripción de la representación de imágenes utilizando características visuales de nivel bajo. 5.1 Representación de Imágenes de Nivel Bajo La representación de imágenes de nivel bajo es un problema crucial en la Recuperación de Información Basada en el Contenido (CBIR). Las características visuales generales incluyen color, textura, forma, etc. Las características de color y textura son las características visuales más ampliamente utilizadas en la recuperación de información basada en contenido (CBIR). En comparación con las características de color y textura, las características de forma suelen describirse después de que las imágenes hayan sido segmentadas en regiones u objetos. Dado que la segmentación de imágenes robusta y precisa es difícil de lograr, el uso de características de forma para la recuperación de imágenes se ha limitado a aplicaciones especiales donde los objetos o regiones están fácilmente disponibles. En este trabajo, combinamos un histograma de color de 64 dimensiones y un Momento de Textura de Color (CTM, [15]) de 64 dimensiones para representar las imágenes. El histograma de color se calcula utilizando 4 × 4 × 4 contenedores en el espacio HSV. El Momento de Textura de Color es propuesto por Yu et al. [15], el cual integra las características de color y textura de la imagen en una forma compacta. CTM adopta la transformada de Fourier local como un esquema de representación de texturas y deriva ocho mapas característicos para describir diferentes aspectos de las relaciones de co-ocurrencia de píxeles de imagen en cada canal del espacio de color (SVcosH, SVsinH, V). Entonces, CTM calcula el primer y segundo momento de estos mapas como una representación de la distribución de píxeles de la imagen en color natural. Por favor, consulte [15] para más detalles. 5.2 Recuperación de imágenes con retroalimentación de relevancia La retroalimentación de relevancia es una de las técnicas más importantes para reducir la brecha entre las características visuales de bajo nivel y los conceptos semánticos de alto nivel [12]. Tradicionalmente, los comentarios de relevancia de los usuarios se utilizan para actualizar el vector de consulta o ajustar el peso de las diferentes dimensiones. Este proceso puede ser visto como un proceso de aprendizaje en línea en el que el sistema de recuperación de imágenes actúa como un aprendiz y el usuario actúa como un maestro. El proceso típico de recuperación se describe de la siguiente manera: 1. El usuario envía un ejemplo de imagen de consulta al sistema. El sistema clasifica las imágenes en la base de datos según alguna métrica de distancia predefinida y presenta al usuario las imágenes mejor clasificadas. El sistema selecciona algunas imágenes de la base de datos y solicita al usuario que las etiquete como relevantes o irrelevantes. El sistema utiliza la información proporcionada por los usuarios para reorganizar las imágenes en la base de datos y devolver al usuario las imágenes principales. Ve al paso 2 hasta que el usuario esté satisfecho. Nuestro algoritmo de Diseño Óptimo de Laplaciano se aplica en el segundo paso para seleccionar las imágenes más informativas. Una vez que obtenemos las etiquetas para las imágenes seleccionadas por LOD, aplicamos la Regresión Regularizada Laplaciana (LRR, [2]) para resolver el problema de optimización (3) y construir el clasificador. El clasificador se utiliza luego para reordenar las imágenes en la base de datos. Ten en cuenta que, para reducir la complejidad computacional, no utilizamos todas las imágenes sin etiquetar en la base de datos, sino solo aquellas dentro de los 500 primeros resultados de la iteración anterior. 6. RESULTADOS EXPERIMENTALES En esta sección, evaluamos el rendimiento de nuestro algoritmo propuesto en una gran base de datos de imágenes. Para demostrar la efectividad de nuestro algoritmo LOD propuesto, lo comparamos con la Regresión Regularizada de Laplaciano (LRR, [2]), la Máquina de Vectores de Soporte (SVM), el Aprendizaje Activo de Máquina de Vectores de Soporte (SVMactive) [14], y el Diseño A-Óptimo (AOD). Tanto SVMactive, AOD y LOD son algoritmos de aprendizaje activo, mientras que LRR y SVM son algoritmos de clasificación estándar. SVM solo hace uso de las imágenes etiquetadas, mientras que LRR es un algoritmo de aprendizaje semi-supervisado que hace uso tanto de imágenes etiquetadas como no etiquetadas. Para SVMactive, AOD y LOD, los algoritmos seleccionan 10 imágenes de entrenamiento en cada iteración. Para LRR y SVM, utilizamos las 10 imágenes principales como datos de entrenamiento. Sería importante señalar que SVMactive se basa en el SVM ordinario, LOD se basa en LRR y AOD se basa en la regresión ordinaria. Los parámetros λ1 y λ2 en nuestro algoritmo LOD se establecen empíricamente en 0.001 y 0.00001. Para ambos algoritmos LRR y LOD, utilizamos la misma estructura de grafo (ver Ecuación 4) y establecemos el valor de p (número de vecinos más cercanos) en 5. Comenzamos con un ejemplo sintético simple para dar una intuición sobre cómo funciona LOD. 6.1 Ejemplo Sintético Simple Se presenta un ejemplo sintético simple en la Figura 1. El conjunto de datos contiene dos círculos. Ocho puntos son seleccionados por AOD y LOD. Como se puede ver, todos los puntos seleccionados por AOD son del círculo grande, mientras que LOD selecciona cuatro puntos del círculo grande y cuatro del círculo pequeño. Los números junto a los puntos seleccionados indican su orden de selección. Claramente, los puntos seleccionados por nuestro algoritmo LOD pueden representar mejor el conjunto de datos original. No comparamos nuestro algoritmo con SVMactive porque SVMactive no se puede aplicar en este caso debido a la falta de puntos etiquetados. 6.2 Diseño Experimental de Recuperación de Imágenes La base de datos de imágenes que utilizamos consta de 7,900 imágenes de 79 categorías semánticas, del conjunto de datos COREL. Es un conjunto de imágenes grande y heterogéneo. Cada imagen se representa como un vector de 128 dimensiones según se describe en la Sección 5.1. La Figura 2 muestra algunas imágenes de muestra. Para exhibir las ventajas de usar nuestro algoritmo, necesitamos una forma confiable de evaluar el rendimiento de recuperación y las comparaciones con otros algoritmos. Listamos a continuación diferentes aspectos del diseño experimental. 6.2.1 Métricas de Evaluación Utilizamos la curva de precisión-alcance y la tasa de precisión [10] para evaluar la efectividad de los algoritmos de recuperación de imágenes. El alcance está especificado por el número (N) de imágenes mejor clasificadas presentadas al usuario. La precisión es la proporción entre el número de imágenes relevantes presentadas al usuario y el (a) Conjunto de datos 1 2 3 4 5 6 7 8 (b) AOD 1 2 3 4 5 6 7 8 (c) LOD Figura 1: Selección de datos por algoritmos de aprendizaje activo. Los números junto a los puntos seleccionados indican su orden de selección. Claramente, los puntos seleccionados por nuestro algoritmo LOD pueden representar mejor el conjunto de datos original. Se debe tener en cuenta que el algoritmo SVMactive no se puede aplicar en este caso debido a la falta de puntos etiquetados. (a) (b) (c) Figura 2: Imágenes de muestra de las categorías cuentas, elefante y barco. El alcance de precisión describe la precisión con varios alcances y, por lo tanto, proporciona una evaluación general del rendimiento de los algoritmos. Por otro lado, la tasa de precisión enfatiza la precisión en un valor particular de alcance. En general, es apropiado presentar 20 imágenes en una pantalla. Agregar más imágenes en una pantalla puede afectar la calidad de las imágenes presentadas. Por lo tanto, la precisión en los primeros 20 (N = 20) es especialmente importante. En los sistemas de recuperación de imágenes del mundo real, la imagen de consulta generalmente no se encuentra en la base de datos de imágenes. Para simular dicho entorno, utilizamos validación cruzada de cinco pliegues para evaluar los algoritmos. Más precisamente, dividimos toda la base de datos de imágenes en cinco subconjuntos de tamaño igual. Por lo tanto, hay 20 imágenes por categoría en cada subconjunto. En cada ejecución de validación cruzada, se selecciona un subconjunto como conjunto de consulta, y los otros cuatro subconjuntos se utilizan como base de datos para la recuperación. La curva de precisión del precisionscope y la tasa de precisión se calculan promediando los resultados de la validación cruzada de cinco pliegues. 6.2.2 Esquema de retroalimentación automática de relevancia Diseñamos un esquema de retroalimentación automática para modelar el proceso de recuperación. Para cada consulta enviada, nuestro sistema recupera y clasifica las imágenes en la base de datos. Se seleccionaron 10 imágenes de la base de datos para que los usuarios las etiqueten y la información de las etiquetas es utilizada por el sistema para volver a clasificarlas. Ten en cuenta que las imágenes seleccionadas en iteraciones anteriores están excluidas de selecciones posteriores. Para cada consulta, se realiza el mecanismo de retroalimentación automática de relevancia durante cuatro iteraciones. Es importante señalar que el esquema de retroalimentación automática de relevancia utilizado aquí es diferente de los descritos en [8], [11]. En [8], [11], las cuatro imágenes relevantes e irrelevantes principales fueron seleccionadas como las imágenes de retroalimentación. Sin embargo, esto puede no ser práctico. En los sistemas de recuperación de imágenes del mundo real, es posible que la mayoría de las imágenes mejor clasificadas sean relevantes (o irrelevantes). Por lo tanto, es difícil para el usuario encontrar tanto cuatro imágenes relevantes como irrelevantes. Es más razonable que los usuarios proporcionen información de retroalimentación solo sobre las 10 imágenes seleccionadas por el sistema. 6.3 Rendimiento de recuperación de imágenes En el mundo real, no es práctico requerir que el usuario proporcione muchas rondas de retroalimentación. El rendimiento de recuperación después de las dos primeras rondas de retroalimentación (especialmente la primera ronda) es más importante. La Figura 3 muestra las curvas de precisión-alcance promedio de los diferentes algoritmos para las dos primeras iteraciones de retroalimentación. Al principio de la recuperación, las distancias euclidianas en el espacio original de 128 dimensiones se utilizan para clasificar las imágenes en la base de datos. Después de que el usuario proporcione retroalimentación de relevancia, se aplican los algoritmos LRR, SVM, SVMactive, AOD y LOD para volver a clasificar las imágenes. Para reducir la complejidad temporal de los algoritmos de aprendizaje activo, no seleccionamos las imágenes más informativas de toda la base de datos, sino de las 500 imágenes principales. Para LRR y SVM, se requiere que el usuario etiquete las 10 imágenes principales. Para SVMactive, AOD y LOD, se requiere que el usuario etiquete las 10 imágenes más informativas seleccionadas por estos algoritmos. Tenga en cuenta que, SVMactive solo puede ser ap(a) Iteración de retroalimentación 1 (b) Iteración de retroalimentación 2 Figura 3: Las curvas de precisión promedio-alcance de diferentes algoritmos para las dos primeras iteraciones de retroalimentación. El algoritmo LOD funciona mejor en todo el alcance. Se debe tener en cuenta que, en la primera ronda de retroalimentación, el algoritmo SVMactive no se puede aplicar. Se aplica el SVM ordinario para construir el clasificador inicial. (a) Precisión en el Top 10 (b) Precisión en el Top 20 (c) Precisión en el Top 30 Figura 4: Evaluación del rendimiento de los cinco algoritmos de aprendizaje para la recuperación de imágenes con retroalimentación de relevancia. (a) Precisión en el top 10, (b) Precisión en el top 20 y (c) Precisión en el top 30. Como se puede observar, nuestro algoritmo LOD supera consistentemente a los otros cuatro algoritmos. Por lo tanto, no se puede aplicar en la primera ronda y utilizamos el SVM estándar para construir el clasificador inicial. Como se puede ver, nuestro algoritmo LOD supera a los otros cuatro algoritmos en todo el ámbito. Además, el algoritmo LRR tiene un mejor rendimiento que SVM. Esto se debe a que el algoritmo LRR hace un uso eficiente de las imágenes no etiquetadas al incorporar un regularizador de preservación de la localidad en la función objetivo de regresión ordinaria. El algoritmo AOD es el que tiene peor rendimiento. A medida que el alcance se amplía, la diferencia de rendimiento entre estos algoritmos disminuye. Al agregar de forma iterativa los comentarios de los usuarios, los resultados de precisión correspondientes (en los primeros 10, 20 y 30 lugares) de los cinco algoritmos se muestran respectivamente en la Figura 4. Como se puede ver, nuestro algoritmo LOD tiene el mejor rendimiento en todos los casos y el algoritmo LRR tiene el segundo mejor rendimiento. Ambos de estos dos algoritmos hacen uso de las imágenes sin etiquetar. Esto demuestra que las imágenes sin etiquetar son útiles para descubrir la estructura geométrica intrínseca del espacio de imágenes y, por lo tanto, mejorar el rendimiento de recuperación. En el mundo real, es posible que el usuario no esté dispuesto a proporcionar demasiadas retroalimentaciones de relevancia. Por lo tanto, el rendimiento de recuperación en las primeras dos rondas es especialmente importante. Como se puede observar, nuestro algoritmo LOD logra una mejora del rendimiento del 6.8% para los 10 mejores resultados, del 5.2% para los 20 mejores resultados y del 4.1% para los 30 mejores resultados, en comparación con el segundo mejor algoritmo (LRR) después de las dos primeras rondas de retroalimentación de relevancia. 6.4 Discusión Se han realizado sistemáticamente varios experimentos en la base de datos de Corel. Nos gustaría resaltar varios puntos interesantes: 1. Es claro que el uso del aprendizaje activo es beneficioso en el ámbito de la recuperación de imágenes. Hay un aumento significativo en el rendimiento al utilizar los métodos de aprendizaje activo. Especialmente, de los tres métodos de aprendizaje activo (SVMactive, AOD, LOD), nuestro algoritmo propuesto LOD es el que tiene mejor rendimiento. En muchas aplicaciones del mundo real, como la recuperación de imágenes con retroalimentación de relevancia, generalmente hay dos formas de reducir la tarea laboriosa de etiquetado manual. Uno es el aprendizaje activo que selecciona las muestras más informativas para etiquetar, y el otro es el aprendizaje semi-supervisado que utiliza las muestras no etiquetadas para mejorar el rendimiento del aprendizaje. Ambas estrategias han sido estudiadas extensamente en el pasado [14], [7], [5], [8]. El trabajo presentado en este artículo se centra en el aprendizaje activo, pero también aprovecha los avances recientes en el aprendizaje semi-supervisado [2]. Específicamente, incorporamos un regularizador que preserva la localidad en el marco de regresión estándar y encontramos las muestras más informativas con respecto a la nueva función objetivo. De esta manera, las técnicas de aprendizaje activo y de aprendizaje semi-supervisado se unifican de manera fluida para aprender un clasificador óptimo. 3. La técnica de retroalimentación de relevancia es crucial para la recuperación de imágenes. Para los cinco algoritmos, el rendimiento de recuperación mejora con más retroalimentación proporcionada por el usuario. CONCLUSIONES Y TRABAJOS FUTUROS Este artículo describe un novedoso algoritmo de aprendizaje activo, llamado Diseño Óptimo Laplaciano, para permitir una recuperación de imágenes con retroalimentación de relevancia más efectiva. Nuestro algoritmo se basa en una función objetivo que minimiza simultáneamente el error empírico y preserva la estructura geométrica local del espacio de datos. Utilizando técnicas de diseño experimental, nuestro algoritmo encuentra las imágenes más informativas para etiquetar. Estas imágenes etiquetadas y las imágenes sin etiquetar en la base de datos se utilizan para aprender un clasificador. Los resultados experimentales en la base de datos Corel muestran que tanto el aprendizaje activo como el aprendizaje semi-supervisado pueden mejorar significativamente el rendimiento de recuperación. En este documento, consideramos el problema de recuperación de imágenes en un conjunto de datos de imágenes pequeño, estático y de dominio cerrado. Un dominio mucho más desafiante es la World Wide Web (WWW). Para la búsqueda de imágenes en la web, es posible recopilar una gran cantidad de información sobre los clics de los usuarios. Esta información puede ser utilizada de forma natural para construir el grafo de afinidad en nuestro algoritmo. Sin embargo, la complejidad computacional en el escenario web puede convertirse en un problema crucial. Además, aunque nuestro interés principal en este artículo se centra en la recuperación de imágenes con retroalimentación de relevancia, nuestros resultados también pueden ser de interés para investigadores en reconocimiento de patrones y aprendizaje automático, especialmente cuando hay una gran cantidad de datos disponibles pero solo se pueden etiquetar muestras limitadas. 8. REFERENCIAS [1] A. C. Atkinson y A. N. Donev. Diseños experimentales óptimos. Oxford University Press, 2002. [2] M. Belkin, P. Niyogi, y V. Sindhwani. Regularización de variedades: Un marco geométrico para el aprendizaje a partir de ejemplos. Revista de Investigación de Aprendizaje Automático, 7:2399-2434, 2006. [3] F. R. K. Chung. Teoría Espectral de Grafos, volumen 92 de la Serie de Conferencias Regionales en Matemáticas. AMS, 1997. [4] D. A. Cohn, Z. Ghahramani y M. I. Jordan. Aprendizaje activo con modelos estadísticos. Revista de Investigación en Inteligencia Artificial, 4:129-145, 1996. [5] A. Dong y B. Bhanu. Un nuevo algoritmo EM semisupervisado para la recuperación de imágenes. En la Conferencia IEEE sobre Visión por Computadora y Reconocimiento de Patrones, Madison, WI, 2003. [6] P. Flaherty, M. I. Jordan y A. P. Arkin. Diseño robusto de experimentos biológicos. En Advances in Neural Information Processing Systems 18, Vancouver, Canadá, 2005. [7] K.-S. Goh, E. Y. Chang y W.-C. Lai. Aprendizaje activo dependiente del concepto multimodal para la recuperación de imágenes. En Actas de la Conferencia ACM sobre Multimedia, Nueva York, octubre de 2004. [8] X. Lo siento, la oración \"He.\" no tiene un significado claro en inglés. ¿Podrías proporcionar más contexto o una oración completa para que pueda traducirla al español de manera precisa? Aprendizaje de subespacios semisupervisado incremental para la recuperación de imágenes. En Actas de la Conferencia ACM sobre Multimedia, Nueva York, octubre de 2004. [9] S. C. Hoi y M. R. Lyu. Un marco de aprendizaje activo semi-supervisado para la recuperación de imágenes. En la Conferencia Internacional de IEEE sobre Visión por Computadora y Reconocimiento de Patrones, San Diego, CA, 2005. [10] D. P. Huijsmans y N. Sebe. Cómo completar los gráficos de rendimiento en la recuperación de imágenes basada en contenido: Agregar generalidad y normalizar el alcance. IEEE Transactions on Pattern Analysis and Machine Intelligence, 27(2):245-251, 2005. [11] Y.-Y.\n\nTransacciones del IEEE sobre Inteligencia Artificial y Análisis de Patrones, 27(2):245-251, 2005. [11] Y.-Y. Lin, T.-L. Liu y H.-T. Chen. Aprendizaje de variedades semánticas para la recuperación de imágenes. En Actas de la Conferencia ACM sobre Multimedia, Singapur, noviembre de 2005. [12] Y. Rui, T. S. Huang, M. Ortega y S. Mehrotra. Retroalimentación de relevancia: Una herramienta poderosa para la recuperación de imágenes basada en contenido de forma interactiva. IEEE Transactions on Circuits and Systems for Video Technology, 8(5), 1998. [13] A. W. Smeulders, M. Worring, S. Santini, A. Gupta, and R. Jain. \n\nTraducción: IEEE Transactions on Circuits and Systems for Video Technology, 8(5), 1998. [13] A. W. Smeulders, M. Worring, S. Santini, A. Gupta y R. Jain. Recuperación de imágenes basada en contenido al final de los primeros años. IEEE Transactions on Pattern Analysis and Machine Intelligence, 22(12):1349-1380, 2000. [14] S. Tong y E. Chang. Aprendizaje activo de máquina de vectores de soporte para recuperación de imágenes. En Actas de la novena conferencia internacional de ACM sobre Multimedia, páginas 107-118, 2001. [15] H. Yu, M. Li, H.-J. Zhang y J. Feng. Momentos de textura de color para la recuperación de imágenes basada en contenido. En la Conferencia Internacional de Procesamiento de Imágenes, páginas 24-28, 2002. [16] K. Yu, J. Bi y V. Tresp. Aprendizaje activo a través del diseño experimental transductivo. En Actas de la 23ª Conferencia Internacional sobre Aprendizaje Automático, Pittsburgh, PA, 2006. ",
            "candidates": [],
            "error": [
                [
                    "imágenes principales que se devuelven",
                    "imágenes principales que se devuelven",
                    "imágenes devueltas"
                ]
            ]
        },
        "precision rate": {
            "translated_key": "tasa de precisión",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Laplacian Optimal Design for Image Retrieval Xiaofei He Yahoo!",
                "Burbank, CA 91504 hex@yahoo-inc.com Wanli Min IBM Yorktown Heights, NY 10598 wanlimin@us.ibm.com Deng Cai CS Dept., UIUC Urbana, IL 61801 dengcai2@cs.uiuc.edu Kun Zhou Microsoft Research Asia Beijing, China kunzhou@microsoft.com ABSTRACT Relevance feedback is a powerful technique to enhance ContentBased Image Retrieval (CBIR) performance.",
                "It solicits the users relevance judgments on the retrieved images returned by the CBIR systems.",
                "The users labeling is then used to learn a classifier to distinguish between relevant and irrelevant images.",
                "However, the top returned images may not be the most informative ones.",
                "The challenge is thus to determine which unlabeled images would be the most informative (i.e., improve the classifier the most) if they were labeled and used as training samples.",
                "In this paper, we propose a novel active learning algorithm, called Laplacian Optimal Design (LOD), for relevance feedback image retrieval.",
                "Our algorithm is based on a regression model which minimizes the least square error on the measured (or, labeled) images and simultaneously preserves the local geometrical structure of the image space.",
                "Specifically, we assume that if two images are sufficiently close to each other, then their measurements (or, labels) are close as well.",
                "By constructing a nearest neighbor graph, the geometrical structure of the image space can be described by the graph Laplacian.",
                "We discuss how results from the field of optimal experimental design may be used to guide our selection of a subset of images, which gives us the most amount of information.",
                "Experimental results on Corel database suggest that the proposed approach achieves higher precision in relevance feedback image retrieval.",
                "Categories and Subject Descriptors H.3.3 [Information storage and retrieval]: Information search and retrieval-Relevance feedback; G.3 [Mathematics of Computing]: Probability and Statistics-Experimental design General Terms Algorithms, Performance, Theory 1.",
                "INTRODUCTION In many machine learning and information retrieval tasks, there is no shortage of unlabeled data but labels are expensive.",
                "The challenge is thus to determine which unlabeled samples would be the most informative (i.e., improve the classifier the most) if they were labeled and used as training samples.",
                "This problem is typically called active learning [4].",
                "Here the task is to minimize an overall cost, which depends both on the classifier accuracy and the cost of data collection.",
                "Many real world applications can be casted into active learning framework.",
                "Particularly, we consider the problem of relevance feedback driven Content-Based Image Retrieval (CBIR) [13].",
                "Content-Based Image Retrieval has attracted substantial interests in the last decade [13].",
                "It is motivated by the fast growth of digital image databases which, in turn, require efficient search schemes.",
                "Rather than describe an image using text, in these systems an image query is described using one or more example images.",
                "The low level visual features (color, texture, shape, etc.) are automatically extracted to represent the images.",
                "However, the low level features may not accurately characterize the high level semantic concepts.",
                "To narrow down the semantic gap, relevance feedback is introduced into CBIR [12].",
                "In many of the current relevance feedback driven CBIR systems, the user is required to provide his/her relevance judgments on the top images returned by the system.",
                "The labeled images are then used to train a classifier to separate images that match the query concept from those that do not.",
                "However, in general the top returned images may not be the most informative ones.",
                "In the worst case, all the top images labeled by the user may be positive and thus the standard classification techniques can not be applied due to the lack of negative examples.",
                "Unlike the standard classification problems where the labeled samples are pregiven, in relevance feedback image retrieval the system can actively select the images to label.",
                "Thus active learning can be naturally introduced into image retrieval.",
                "Despite many existing active learning techniques, Support Vector Machine (SVM) active learning [14] and regression based active learning [1] have received the most interests.",
                "Based on the observation that the closer to the SVM boundary an image is, the less reliable its classification is, SVM active learning selects those unlabeled images closest to the boundary to solicit user feedback so as to achieve maximal refinement on the hyperplane between the two classes.",
                "The major disadvantage of SVM active learning is that the estimated boundary may not be accurate enough.",
                "Moreover, it may not be applied at the beginning of the retrieval when there is no labeled images.",
                "Some other SVM based active learning algorithms can be found in [7], [9].",
                "In statistics, the problem of selecting samples to label is typically referred to as experimental design.",
                "The sample x is referred to as experiment, and its label y is referred to as measurement.",
                "The study of optimal experimental design (OED) [1] is concerned with the design of experiments that are expected to minimize variances of a parameterized model.",
                "The intent of optimal experimental design is usually to maximize confidence in a given model, minimize parameter variances for system identification, or minimize the models output variance.",
                "Classical experimental design approaches include A-Optimal Design, D-Optimal Design, and E-Optimal Design.",
                "All of these approaches are based on a least squares regression model.",
                "Comparing to SVM based active learning algorithms, experimental design approaches are much more efficient in computation.",
                "However, this kind of approaches takes only measured (or, labeled) data into account in their objective function, while the unmeasured (or, unlabeled) data is ignored.",
                "Benefit from recent progresses on optimal experimental design and semi-supervised learning, in this paper we propose a novel active learning algorithm for image retrieval, called Laplacian Optimal Design (LOD).",
                "Unlike traditional experimental design methods whose loss functions are only defined on the measured points, the loss function of our proposed LOD algorithm is defined on both measured and unmeasured points.",
                "Specifically, we introduce a locality preserving regularizer into the standard least-square-error based loss function.",
                "The new loss function aims to find a classifier which is locally as smooth as possible.",
                "In other words, if two points are sufficiently close to each other in the input space, then they are expected to share the same label.",
                "Once the loss function is defined, we can select the most informative data points which are presented to the user for labeling.",
                "It would be important to note that the most informative images may not be the top returned images.",
                "The rest of the paper is organized as follows.",
                "In Section 2, we provide a brief description of the related work.",
                "Our proposed Laplacian Optimal Design algorithm is introduced in Section 3.",
                "In Section 4, we compare our algorithm with the state-or-the-art algorithms and present the experimental results on image retrieval.",
                "Finally, we provide some concluding remarks and suggestions for future work in Section 5. 2.",
                "RELATED WORK Since our proposed algorithm is based on regression framework.",
                "The most related work is optimal experimental design [1], including A-Optimal Design, D-Optimal Design, and EOptimal Design.",
                "In this Section, we give a brief description of these approaches. 2.1 The Active Learning Problem The generic problem of active learning is the following.",
                "Given a set of points A = {x1, x2, · · · , xm} in Rd , find a subset B = {z1, z2, · · · , zk} ⊂ A which contains the most informative points.",
                "In other words, the points zi(i = 1, · · · , k) can improve the classifier the most if they are labeled and used as training points. 2.2 Optimal Experimental Design We consider a linear regression model y = wT x + (1) where y is the observation, x is the independent variable, w is the weight vector and is an unknown error with zero mean.",
                "Different observations have errors that are independent, but with equal variances σ2 .",
                "We define f(x) = wT x to be the learners output given input x and the weight vector w. Suppose we have a set of labeled sample points (z1, y1), · · · , (zk, yk), where yi is the label of zi.",
                "Thus, the maximum likelihood estimate for the weight vector, ˆw, is that which minimizes the sum squared error Jsse(w) = k i=1 wT zi − yi 2 (2) The estimate ˆw gives us an estimate of the output at a novel input: ˆy = ˆwT x.",
                "By Gauss-Markov theorem, we know that ˆw − w has a zero mean and a covariance matrix given by σ2 H−1 sse, where Hsse is the Hessian of Jsse(w) Hsse = ∂2 Jsse ∂w2 = k i=1 zizT i = ZZT where Z = (z1, z2, · · · , zk).",
                "The three most common scalar measures of the size of the parameter covariance matrix in optimal experimental design are: • D-optimal design: determinant of Hsse. • A-optimal design: trace of Hsse. • E-optimal design: maximum eigenvalue of Hsse.",
                "Since the computation of the determinant and eigenvalues of a matrix is much more expensive than the computation of matrix trace, A-optimal design is more efficient than the other two.",
                "Some recent work on experimental design can be found in [6], [16]. 3.",
                "LAPLACIAN OPTIMAL DESIGN Since the covariance matrix Hsse used in traditional approaches is only dependent on the measured samples, i.e. zis, these approaches fail to evaluate the expected errors on the unmeasured samples.",
                "In this Section, we introduce a novel active learning algorithm called Laplacian Optimal Design (LOD) which makes efficient use of both measured (labeled) and unmeasured (unlabeled) samples. 3.1 The Objective Function In many machine learning problems, it is natural to assume that if two points xi, xj are sufficiently close to each other, then their measurements (f(xi), f(xj)) are close as well.",
                "Let S be a similarity matrix.",
                "Thus, a new loss function which respects the geometrical structure of the data space can be defined as follows: J0(w) = k i=1 f(zi)−yi 2 + λ 2 m i,j=1 f(xi)−f(xj) 2 Sij (3) where yi is the measurement (or, label) of zi.",
                "Note that, the loss function (3) is essentially the same as the one used in Laplacian Regularized Regression (LRR, [2]).",
                "However, LRR is a passive learning algorithm where the training data is given.",
                "In this paper, we are focused on how to select the most informative data for training.",
                "The loss function with our choice of symmetric weights Sij (Sij = Sji) incurs a heavy penalty if neighboring points xi and xj are mapped far apart.",
                "Therefore, minimizing J0(w) is an attempt to ensure that if xi and xj are close then f(xi) and f(xj) are close as well.",
                "There are many choices of the similarity matrix S. A simple definition is as follows: Sij = ⎧ ⎨ ⎩ 1, if xi is among the p nearest neighbors of xj, or xj is among the p nearest neighbors of xi; 0, otherwise. (4) Let D be a diagonal matrix, Dii = j Sij, and L = D−S.",
                "The matrix L is called graph Laplacian in spectral graph theory [3].",
                "Let y = (y1, · · · , yk)T and X = (x1, · · · , xm).",
                "Following some simple algebraic steps, we see that: J0(w) = k i=1 wT zi − yi 2 + λ 2 m i,j=1 wT xi − wT xj 2 Sij = y − ZT w T y − ZT w + λwT m i=1 DiixixT i − m i,j=1 SijxixT j w = yT y − 2wT Zy + wT ZZT w +λwT XDXT − XSXT w = yT y − 2wT Zy + wT ZZT + λXLXT w The Hessian of J0(w) can be computed as follows: H0 = ∂2 J0 ∂w2 = ZZT + λXLXT In some cases, the matrix ZZT +λXLXT is singular (e.g. if m < d).",
                "Thus, there is no stable solution to the optimization problem Eq. (3).",
                "A common way to deal with this ill-posed problem is to introduce a Tikhonov regularizer into our loss function: J(w) = k i=1 wT zi − yi 2 + λ1 2 m i,j=1 wT xi − wT xj 2 Sij +λ2 w 2 (5) The Hessian of the new loss function is given by: H = ∂2 J ∂w2 = ZZT + λ1XLXT + λ2I := ZZT + Λ where I is an identity matrix and Λ = λ1XLXT + λ2I.",
                "Clearly, H is of full rank.",
                "Requiring that the gradient of J(w) with respect to w vanish gives the optimal estimate ˆw: ˆw = H−1 Zy The following proposition states the bias and variance properties of the estimator for the coefficient vector w. Proposition 3.1.",
                "E( ˆw − w) = −H−1 Λw, Cov( ˆw) = σ2 (H−1 − H−1 ΛH−1 ) Proof.",
                "Since y = ZT w + and E( ) = 0, it follows that E( ˆw − w) (6) = H−1 ZZT w − w = H−1 (ZZT + Λ − Λ)w − w = (I − H−1 Λ)w − w = −H−1 Λw (7) Notice Cov(y) = σ2 I, the covariance matrix of ˆw has the expression: Cov( ˆw) = H−1 ZCov(y)ZT H−1 = σ2 H−1 ZZT H−1 = σ2 H−1 (H − Λ)H−1 = σ2 (H−1 − H−1 ΛH−1 ) (8) Therefore mean squared error matrix for the coefficients w is E(w − ˆw)(w − ˆw)T (9) = H−1 ΛwwT ΛH−1 + σ2 (H−1 − H−1 ΛH−1 ) (10) For any x, let ˆy = ˆwT x be its predicted observation.",
                "The expected squared prediction error is E(y − ˆy)2 = E( + wT x − ˆwT x)2 = σ2 + xT [E(w − ˆw)(w − ˆw)T ]x = σ2 + xT [H−1 ΛwwT ΛH−1 + σ2 H−1 − σ2 H−1 ΛH−1 ]x Clearly the expected square prediction error depends on the explanatory variable x, therefore average expected square predictive error over the complete data set A is 1 m m i=1 E(yi − ˆwT xi)2 = 1 m m i=1 xT i [H−1 ΛwwT ΛH−1 + σ2 H−1 − σ2 H−1 ΛH−1 ]xi +σ2 = 1 m Tr(XT [σ2 H−1 + H−1 ΛwwT ΛH−1 − σ2 H−1 ΛH−1 ]X) +σ2 Since Tr(XT [H−1 ΛwwT ΛH−1 − σ2 H−1 ΛH−1 ]X) Tr(σ2 XT H−1 X), Our Laplacian optimality criterion is thus formulated by minimizing the trace of XT H−1 X.",
                "Definition 1.",
                "Laplacian Optimal Design min Z=(z1,··· ,zk) Tr XT ZZT + λ1XLXT + λ2I −1 X (11) where z1, · · · , zk are selected from {x1, · · · , xm}. 4.",
                "KERNEL LAPLACIAN OPTIMAL DESIGN Canonical experimental design approaches (e.g.",
                "A-Optimal Design, D-Optimal Design, and E-Optimal) only consider linear functions.",
                "They fail to discover the intrinsic geometry in the data when the data space is highly nonlinear.",
                "In this section, we describe how to perform Laplacian Experimental Design in Reproducing Kernel Hilbert Space (RKHS) which gives rise to Kernel Laplacian Experimental Design (KLOD).",
                "For given data points x1, · · · , xm ∈ X with a positive definite mercer kernel K : X ×X → R, there exists a unique RKHS HK of real valued functions on X.",
                "Let Kt(s) be the function of s obtained by fixing t and letting Kt(s) . = K(s, t).",
                "HK consists of all finite linear combinations of the form l i=1 αiKti with ti ∈ X and limits of such functions as the ti become dense in X.",
                "We have Ks, Kt HK = K(s, t). 4.1 Derivation of LOD in Reproducing Kernel Hilbert Space Consider the optimization problem (5) in RKHS.",
                "Thus, we seek a function f ∈ HK such that the following objective function is minimized: min f∈HK k i=1 f(zi)−yi 2 + λ1 2 m i,j=1 f(xi)−f(xj) 2 Sij+λ2 f 2 HK (12) We have the following proposition.",
                "Proposition 4.1.",
                "Let H = { m i=1 αiK(·, xi)|αi ∈ R} be a subspace of HK , the solution to the problem (12) is in H. Proof.",
                "Let H⊥ be the orthogonal complement of H, i.e.",
                "HK = H ⊕ H⊥ .",
                "Thus, for any function f ∈ HK , it has orthogonal decomposition as follows: f = fH + fH⊥ Now, lets evaluate f at xi: f(xi) = f, Kxi HK = fH + fH⊥ , Kxi HK = fH, Kxi HK + fH⊥ , Kxi HK Notice that Kxi ∈ H while fH⊥ ∈ H⊥ .",
                "This implies that fH⊥ , Kxi HK = 0.",
                "Therefore, f(xi) = fH, Kxi HK = fH(xi) This completes the proof.",
                "Proposition 4.1 tells us the minimizer of problem (12) admits a representation f∗ = m i=1 αiK(·, xi).",
                "Please see [2] for the details.",
                "Let φ : Rd → H be a feature map from the input space Rd to H, and K(xi, xj) =< φ(xi), φ(xj) >.",
                "Let X denote the data matrix in RKHS, X = (φ(x1), φ(x2), · · · , φ(xm)).",
                "Similarly, we define Z = (φ(z1), φ(z2), · · · , φ(zk)).",
                "Thus, the optimization problem in RKHS can be written as follows: min Z Tr XT ZZT + λ1XLXT + λ2I −1 X (13) Since the mapping function φ is generally unknown, there is no direct way to solve problem (13).",
                "In the following, we apply kernel tricks to solve this optimization problem.",
                "Let X−1 be the Moore-Penrose inverse (also known as pseudo inverse) of X.",
                "Thus, we have: XT ZZT + λ1XLXT + λ2I −1 X = XT XX−1 ZZT + λ1XLXT + λ2I −1 (XT )−1 XT X = XT X ZZT X + λ1XLXT X + λ2X −1 (XT )−1 XT X = XT X XT ZZT X + λ1XT XLXT X + λ2XT X −1 XT X = KXX KXZKZX + λ1KXXLKXX + λ2KXX −1 KXX where KXX is a m × m matrix (KXX,ij = K(xi, xj)), KXZ is a m×k matrix (KXZ,ij = K(xi, zj)), and KZX is a k×m matrix (KZX,ij = K(zi, xj)).",
                "Thus, the Kernel Laplacian Optimal Design can be defined as follows: Definition 2.",
                "Kernel Laplacian Optimal Design minZ=(z1,··· ,zk) Tr KXX KXZKZX + λ1KXXLKXX λ2KXX −1 KXX (14) 4.2 Optimization Scheme In this subsection, we discuss how to solve the optimization problems (11) and (14).",
                "Particularly, if we select a linear kernel for KLOD, then it reduces to LOD.",
                "Therefore, we will focus on problem (14) in the following.",
                "It can be shown that the optimization problem (14) is NP-hard.",
                "In this subsection, we develop a simple sequential greedy approach to solve (14).",
                "Suppose n points have been selected, denoted by a matrix Zn = (z1, · · · , zn).",
                "The (n + 1)-th point zn+1 can be selected by solving the following optimization problem: max Zn+1=(Zn,zn+1) Tr KXX KXZn+1 KZn+1X + λ1KXXLKXX + λ2KXX −1 KXX (15) The kernel matrices KXZn+1 and KZn+1X can be rewritten as follows: KXZn+1 = KXZn , KXzn+1 , KZn+1X = KZnX Kzn+1X Thus, we have: KXZn+1 KZn+1X = KXZn KZnX + KXzn+1 Kzn+1X We define: A = KXZn KZnX + λ1KXXLKXX + λ2KXX A is only dependent on X and Zn .",
                "Thus, the (n + 1)-th point zn+1 is given by: zn+1 = arg min zn+1 Tr KXX A + KXzn+1 Kzn+1X −1 KXX (16) Each time we select a new point zn+1, the matrix A is updated by: A ← A + KXzn+1 Kzn+1X If the kernel function is chosen as inner product K(x, y) = x, y , then HK is a linear functional space and the algorithm reduces to LOD. 5.",
                "CONTENT-BASED IMAGE RETRIEVAL USING LAPLACIAN OPTIMAL DESIGN In this section, we describe how to apply Laplacian Optimal Design to CBIR.",
                "We begin with a brief description of image representation using low level visual features. 5.1 Low-Level Image Representation Low-level image representation is a crucial problem in CBIR.",
                "General visual features includes color, texture, shape, etc.",
                "Color and texture features are the most extensively used visual features in CBIR.",
                "Compared with color and texture features, shape features are usually described after images have been segmented into regions or objects.",
                "Since robust and accurate image segmentation is difficult to achieve, the use of shape features for image retrieval has been limited to special applications where objects or regions are readily available.",
                "In this work, We combine 64-dimensional color histogram and 64-dimensional Color Texture Moment (CTM, [15]) to represent the images.",
                "The color histogram is calculated using 4 × 4 × 4 bins in HSV space.",
                "The Color Texture Moment is proposed by Yu et al. [15], which integrates the color and texture characteristics of the image in a compact form.",
                "CTM adopts local Fourier transform as a texture representation scheme and derives eight characteristic maps to describe different aspects of co-occurrence relations of image pixels in each channel of the (SVcosH, SVsinH, V) color space.",
                "Then CTM calculates the first and second moment of these maps as a representation of the natural color image pixel distribution.",
                "Please see [15] for details. 5.2 Relevance Feedback Image Retrieval Relevance feedback is one of the most important techniques to narrow down the gap between low level visual features and high level semantic concepts [12].",
                "Traditionally, the users relevance feedbacks are used to update the query vector or adjust the weighting of different dimensions.",
                "This process can be viewed as an on-line learning process in which the image retrieval system acts as a learner and the user acts as a teacher.",
                "They typical retrieval process is outlined as follows: 1.",
                "The user submits a query image example to the system.",
                "The system ranks the images in database according to some pre-defined distance metric and presents to the user the top ranked images. 2.",
                "The system selects some images from the database and request the user to label them as relevant or irrelevant. 3.",
                "The system uses the users provided information to rerank the images in database and returns to the user the top images.",
                "Go to step 2 until the user is satisfied.",
                "Our Laplacian Optimal Design algorithm is applied in the second step for selecting the most informative images.",
                "Once we get the labels for the images selected by LOD, we apply Laplacian Regularized Regression (LRR, [2]) to solve the optimization problem (3) and build the classifier.",
                "The classifier is then used to re-rank the images in database.",
                "Note that, in order to reduce the computational complexity, we do not use all the unlabeled images in the database but only those within top 500 returns of previous iteration. 6.",
                "EXPERIMENTAL RESULTS In this section, we evaluate the performance of our proposed algorithm on a large image database.",
                "To demonstrate the effectiveness of our proposed LOD algorithm, we compare it with Laplacian Regularized Regression (LRR, [2]), Support Vector Machine (SVM), Support Vector Machine Active Learning (SVMactive) [14], and A-Optimal Design (AOD).",
                "Both SVMactive, AOD, and LOD are active learning algorithms, while LRR and SVM are standard classification algorithms.",
                "SVM only makes use of the labeled images, while LRR is a semi-supervised learning algorithm which makes use of both labeled and unlabeled images.",
                "For SVMactive, AOD, and LOD, 10 training images are selected by the algorithms themselves at each iteration.",
                "While for LRR and SVM, we use the top 10 images as training data.",
                "It would be important to note that SVMactive is based on the ordinary SVM, LOD is based on LRR, and AOD is based on the ordinary regression.",
                "The parameters λ1 and λ2 in our LOD algorithm are empirically set to be 0.001 and 0.00001.",
                "For both LRR and LOD algorithms, we use the same graph structure (see Eq. 4) and set the value of p (number of nearest neighbors) to be 5.",
                "We begin with a simple synthetic example to give some intuition about how LOD works. 6.1 Simple Synthetic Example A simple synthetic example is given in Figure 1.",
                "The data set contains two circles.",
                "Eight points are selected by AOD and LOD.",
                "As can be seen, all the points selected by AOD are from the big circle, while LOD selects four points from the big circle and four from the small circle.",
                "The numbers beside the selected points denote their orders to be selected.",
                "Clearly, the points selected by our LOD algorithm can better represent the original data set.",
                "We did not compare our algorithm with SVMactive because SVMactive can not be applied in this case due to the lack of the labeled points. 6.2 Image Retrieval Experimental Design The image database we used consists of 7,900 images of 79 semantic categories, from COREL data set.",
                "It is a large and heterogeneous image set.",
                "Each image is represented as a 128-dimensional vector as described in Section 5.1.",
                "Figure 2 shows some sample images.",
                "To exhibit the advantages of using our algorithm, we need a reliable way of evaluating the retrieval performance and the comparisons with other algorithms.",
                "We list different aspects of the experimental design below. 6.2.1 Evaluation Metrics We use precision-scope curve and <br>precision rate</br> [10] to evaluate the effectiveness of the image retrieval algorithms.",
                "The scope is specified by the number (N) of top-ranked images presented to the user.",
                "The precision is the ratio of the number of relevant images presented to the user to the (a) Data set 1 2 3 4 5 6 7 8 (b) AOD 1 2 3 4 5 6 7 8 (c) LOD Figure 1: Data selection by active learning algorithms.",
                "The numbers beside the selected points denote their orders to be selected.",
                "Clearly, the points selected by our LOD algorithm can better represent the original data set.",
                "Note that, the SVMactive algorithm can not be applied in this case due to the lack of labeled points. (a) (b) (c) Figure 2: Sample images from category bead, elephant, and ship. scope N. The precision-scope curve describes the precision with various scopes and thus gives an overall performance evaluation of the algorithms.",
                "On the other hand, the <br>precision rate</br> emphasizes the precision at a particular value of scope.",
                "In general, it is appropriate to present 20 images on a screen.",
                "Putting more images on a screen may affect the quality of the presented images.",
                "Therefore, the precision at top 20 (N = 20) is especially important.",
                "In real world image retrieval systems, the query image is usually not in the image database.",
                "To simulate such environment, we use five-fold cross validation to evaluate the algorithms.",
                "More precisely, we divide the whole image database into five subsets with equal size.",
                "Thus, there are 20 images per category in each subset.",
                "At each run of cross validation, one subset is selected as the query set, and the other four subsets are used as the database for retrieval.",
                "The precisionscope curve and <br>precision rate</br> are computed by averaging the results from the five-fold cross validation. 6.2.2 Automatic Relevance Feedback Scheme We designed an automatic feedback scheme to model the retrieval process.",
                "For each submitted query, our system retrieves and ranks the images in the database. 10 images were selected from the database for user labeling and the label information is used by the system for re-ranking.",
                "Note that, the images which have been selected at previous iterations are excluded from later selections.",
                "For each query, the automatic relevance feedback mechanism is performed for four iterations.",
                "It is important to note that the automatic relevance feedback scheme used here is different from the ones described in [8], [11].",
                "In [8], [11], the top four relevant and irrelevant images were selected as the feedback images.",
                "However, this may not be practical.",
                "In real world image retrieval systems, it is possible that most of the top-ranked images are relevant (or, irrelevant).",
                "Thus, it is difficult for the user to find both four relevant and irrelevant images.",
                "It is more reasonable for the users to provide feedback information only on the 10 images selected by the system. 6.3 Image Retrieval Performance In real world, it is not practical to require the user to provide many rounds of feedbacks.",
                "The retrieval performance after the first two rounds of feedbacks (especially the first round) is more important.",
                "Figure 3 shows the average precision-scope curves of the different algorithms for the first two feedback iterations.",
                "At the beginning of retrieval, the Euclidean distances in the original 128-dimensional space are used to rank the images in database.",
                "After the user provides relevance feedbacks, the LRR, SVM, SVMactive, AOD, and LOD algorithms are then applied to re-rank the images.",
                "In order to reduce the time complexity of active learning algorithms, we didnt select the most informative images from the whole database but from the top 500 images.",
                "For LRR and SVM, the user is required to label the top 10 images.",
                "For SVMactive, AOD, and LOD, the user is required to label 10 most informative images selected by these algorithms.",
                "Note that, SVMactive can only be ap(a) Feedback Iteration 1 (b) Feedback Iteration 2 Figure 3: The average precision-scope curves of different algorithms for the first two feedback iterations.",
                "The LOD algorithm performs the best on the entire scope.",
                "Note that, at the first round of feedback, the SVMactive algorithm can not be applied.",
                "It applies the ordinary SVM to build the initial classifier. (a) Precision at Top 10 (b) Precision at Top 20 (c) Precision at Top 30 Figure 4: Performance evaluation of the five learning algorithms for relevance feedback image retrieval. (a) Precision at top 10, (b) Precision at top 20, and (c) Precision at top 30.",
                "As can be seen, our LOD algorithm consistently outperforms the other four algorithms. plied when the classifier is already built.",
                "Therefore, it can not be applied at the first round and we use the standard SVM to build the initial classifier.",
                "As can be seen, our LOD algorithm outperforms the other four algorithms on the entire scope.",
                "Also, the LRR algorithm performs better than SVM.",
                "This is because that the LRR algorithm makes efficient use of the unlabeled images by incorporating a locality preserving regularizer into the ordinary regression objective function.",
                "The AOD algorithm performs the worst.",
                "As the scope gets larger, the performance difference between these algorithms gets smaller.",
                "By iteratively adding the users feedbacks, the corresponding precision results (at top 10, top 20, and top 30) of the five algorithms are respectively shown in Figure 4.",
                "As can be seen, our LOD algorithm performs the best in all the cases and the LRR algorithm performs the second best.",
                "Both of these two algorithms make use of the unlabeled images.",
                "This shows that the unlabeled images are helpful for discovering the intrinsic geometrical structure of the image space and therefore enhance the retrieval performance.",
                "In real world, the user may not be willing to provide too many relevance feedbacks.",
                "Therefore, the retrieval performance at the first two rounds are especially important.",
                "As can be seen, our LOD algorithm achieves 6.8% performance improvement for top 10 results, 5.2% for top 20 results, and 4.1% for top 30 results, comparing to the second best algorithm (LRR) after the first two rounds of relevance feedbacks. 6.4 Discussion Several experiments on Corel database have been systematically performed.",
                "We would like to highlight several interesting points: 1.",
                "It is clear that the use of active learning is beneficial in the image retrieval domain.",
                "There is a significant increase in performance from using the active learning methods.",
                "Especially, out of the three active learning methods (SVMactive, AOD, LOD), our proposed LOD algorithm performs the best. 2.",
                "In many real world applications like relevance feedback image retrieval, there are generally two ways of reducing labor-intensive manual labeling task.",
                "One is active learning which selects the most informative samples to label, and the other is semi-supervised learning which makes use of the unlabeled samples to enhance the learning performance.",
                "Both of these two strategies have been studied extensively in the past [14], [7], [5], [8].",
                "The work presented in this paper is focused on active learning, but it also takes advantage of the recent progresses on semi-supervised learning [2].",
                "Specifically, we incorporate a locality preserving regularizer into the standard regression framework and find the most informative samples with respect to the new objective function.",
                "In this way, the active learning and semi-supervised learning techniques are seamlessly unified for learning an optimal classifier. 3.",
                "The relevance feedback technique is crucial to image retrieval.",
                "For all the five algorithms, the retrieval performance improves with more feedbacks provided by the user. 7.",
                "CONCLUSIONS AND FUTURE WORK This paper describes a novel active learning algorithm, called Laplacian Optimal Design, to enable more effective relevance feedback image retrieval.",
                "Our algorithm is based on an objective function which simultaneously minimizes the empirical error and preserves the local geometrical structure of the data space.",
                "Using techniques from experimental design, our algorithm finds the most informative images to label.",
                "These labeled images and the unlabeled images in the database are used to learn a classifier.",
                "The experimental results on Corel database show that both active learning and semi-supervised learning can significantly improve the retrieval performance.",
                "In this paper, we consider the image retrieval problem on a small, static, and closed-domain image data.",
                "A much more challenging domain is the World Wide Web (WWW).",
                "For Web image search, it is possible to collect a large amount of user click information.",
                "This information can be naturally used to construct the affinity graph in our algorithm.",
                "However, the computational complexity in Web scenario may become a crucial issue.",
                "Also, although our primary interest in this paper is focused on relevance feedback image retrieval, our results may also be of interest to researchers in patten recognition and machine learning, especially when a large amount of data is available but only a limited samples can be labeled. 8.",
                "REFERENCES [1] A. C. Atkinson and A. N. Donev.",
                "Optimum Experimental Designs.",
                "Oxford University Press, 2002. [2] M. Belkin, P. Niyogi, and V. Sindhwani.",
                "Manifold regularization: A geometric framework for learning from examples.",
                "Journal of Machine Learning Research, 7:2399-2434, 2006. [3] F. R. K. Chung.",
                "Spectral Graph Theory, volume 92 of Regional Conference Series in Mathematics.",
                "AMS, 1997. [4] D. A. Cohn, Z. Ghahramani, and M. I. Jordan.",
                "Active learning with statistical models.",
                "Journal of Artificial Intelligence Research, 4:129-145, 1996. [5] A. Dong and B. Bhanu.",
                "A new semi-supervised em algorithm for image retrieval.",
                "In IEEE Conf. on Computer Vision and Pattern Recognition, Madison, WI, 2003. [6] P. Flaherty, M. I. Jordan, and A. P. Arkin.",
                "Robust design of biological experiments.",
                "In Advances in Neural Information Processing Systems 18, Vancouver, Canada, 2005. [7] K.-S. Goh, E. Y. Chang, and W.-C. Lai.",
                "Multimodal concept-dependent active learning for image retrieval.",
                "In Proceedings of the ACM Conference on Multimedia, New York, October 2004. [8] X.",
                "He.",
                "Incremental semi-supervised subspace learning for image retrieval.",
                "In Proceedings of the ACM Conference on Multimedia, New York, October 2004. [9] S. C. Hoi and M. R. Lyu.",
                "A semi-supervised active learning framework for image retrieval.",
                "In IEEE International Conference on Computer Vision and Pattern Recognition, San Diego, CA, 2005. [10] D. P. Huijsmans and N. Sebe.",
                "How to complete performance graphs in content-based image retrieval: Add generality and normalize scope.",
                "IEEE Transactions on Pattern Analysis and Machine Intelligence, 27(2):245-251, 2005. [11] Y.-Y.",
                "Lin, T.-L. Liu, and H.-T. Chen.",
                "Semantic manifold learning for image retrieval.",
                "In Proceedings of the ACM Conference on Multimedia, Singapore, November 2005. [12] Y. Rui, T. S. Huang, M. Ortega, and S. Mehrotra.",
                "Relevance feedback: A power tool for interative content-based image retrieval.",
                "IEEE Transactions on Circuits and Systems for Video Technology, 8(5), 1998. [13] A. W. Smeulders, M. Worring, S. Santini, A. Gupta, and R. Jain.",
                "Content-based image retrieval at the end of the early years.",
                "IEEE Transactions on Pattern Analysis and Machine Intelligence, 22(12):1349-1380, 2000. [14] S. Tong and E. Chang.",
                "Support vector machine active learning for image retrieval.",
                "In Proceedings of the ninth ACM international conference on Multimedia, pages 107-118, 2001. [15] H. Yu, M. Li, H.-J.",
                "Zhang, and J. Feng.",
                "Color texture moments for content-based image retrieval.",
                "In International Conference on Image Processing, pages 24-28, 2002. [16] K. Yu, J. Bi, and V. Tresp.",
                "Active learning via transductive experimental design.",
                "In Proceedings of the 23rd International Conference on Machine Learning, Pittsburgh, PA, 2006."
            ],
            "original_annotated_samples": [
                "We list different aspects of the experimental design below. 6.2.1 Evaluation Metrics We use precision-scope curve and <br>precision rate</br> [10] to evaluate the effectiveness of the image retrieval algorithms.",
                "On the other hand, the <br>precision rate</br> emphasizes the precision at a particular value of scope.",
                "The precisionscope curve and <br>precision rate</br> are computed by averaging the results from the five-fold cross validation. 6.2.2 Automatic Relevance Feedback Scheme We designed an automatic feedback scheme to model the retrieval process."
            ],
            "translated_annotated_samples": [
                "Listamos a continuación diferentes aspectos del diseño experimental. 6.2.1 Métricas de Evaluación Utilizamos la curva de precisión-alcance y la <br>tasa de precisión</br> [10] para evaluar la efectividad de los algoritmos de recuperación de imágenes.",
                "Por otro lado, la <br>tasa de precisión</br> enfatiza la precisión en un valor particular de alcance.",
                "La curva de precisión del precisionscope y la <br>tasa de precisión</br> se calculan promediando los resultados de la validación cruzada de cinco pliegues. 6.2.2 Esquema de retroalimentación automática de relevancia Diseñamos un esquema de retroalimentación automática para modelar el proceso de recuperación."
            ],
            "translated_text": "Diseño óptimo de Laplaciano para la recuperación de imágenes Xiaofei He Yahoo! El feedback de relevancia es una técnica poderosa para mejorar el rendimiento de la Recuperación de Imágenes Basada en Contenido (CBIR). Solicita las valoraciones de relevancia de los usuarios sobre las imágenes recuperadas por los sistemas CBIR. La etiqueta de los usuarios se utiliza luego para entrenar un clasificador que distinga entre imágenes relevantes e irrelevantes. Sin embargo, las imágenes principales que se devuelven pueden no ser las más informativas. El desafío consiste en determinar qué imágenes sin etiquetar serían las más informativas (es decir, mejorarían más al clasificador) si fueran etiquetadas y utilizadas como muestras de entrenamiento. En este artículo, proponemos un novedoso algoritmo de aprendizaje activo, llamado Diseño Óptimo Laplaciano (LOD), para la recuperación de imágenes con retroalimentación de relevancia. Nuestro algoritmo se basa en un modelo de regresión que minimiza el error cuadrático mínimo en las imágenes medidas (o etiquetadas) y al mismo tiempo preserva la estructura geométrica local del espacio de la imagen. Específicamente, asumimos que si dos imágenes están lo suficientemente cerca una de la otra, entonces sus medidas (o etiquetas) también son cercanas. Al construir un grafo de vecinos más cercanos, la estructura geométrica del espacio de la imagen puede ser descrita por el Laplaciano del grafo. Discutimos cómo los resultados del campo del diseño experimental óptimo pueden ser utilizados para guiar nuestra selección de un subconjunto de imágenes, que nos proporciona la mayor cantidad de información. Los resultados experimentales en la base de datos Corel sugieren que el enfoque propuesto logra una mayor precisión en la recuperación de imágenes con retroalimentación de relevancia. Categorías y Descriptores de Asignaturas H.3.3 [Almacenamiento y recuperación de información]: Búsqueda y recuperación de información-Retroalimentación de relevancia; G.3 [Matemáticas de la Computación]: Probabilidad y Estadística-Diseño experimental Términos Generales Algoritmos, Rendimiento, Teoría 1. INTRODUCCIÓN En muchas tareas de aprendizaje automático y recuperación de información, no hay escasez de datos no etiquetados pero las etiquetas son costosas. El desafío consiste en determinar qué muestras sin etiquetar serían las más informativas (es decir, mejorarían más el clasificador) si fueran etiquetadas y utilizadas como muestras de entrenamiento. Este problema se llama típicamente aprendizaje activo [4]. Aquí la tarea es minimizar un costo general, que depende tanto de la precisión del clasificador como del costo de la recolección de datos. Muchas aplicaciones del mundo real pueden ser adaptadas al marco de aprendizaje activo. Particularmente, consideramos el problema de la recuperación de imágenes basada en contenido impulsada por la retroalimentación de relevancia (CBIR) [13]. La Recuperación de Imágenes Basada en Contenido ha atraído un interés sustancial en la última década [13]. Está motivado por el rápido crecimiento de las bases de datos de imágenes digitales que, a su vez, requieren esquemas de búsqueda eficientes. En lugar de describir una imagen usando texto, en estos sistemas se describe una consulta de imagen utilizando una o más imágenes de ejemplo. Las características visuales de bajo nivel (color, textura, forma, etc.) se extraen automáticamente para representar las imágenes. Sin embargo, las características de bajo nivel pueden no caracterizar con precisión los conceptos semánticos de alto nivel. Para reducir la brecha semántica, se introduce la retroalimentación de relevancia en la recuperación de información basada en el contenido (CBIR) [12]. En muchos de los sistemas actuales de recuperación de imágenes basados en retroalimentación de relevancia, se requiere que el usuario proporcione sus juicios de relevancia sobre las imágenes principales devueltas por el sistema. Las imágenes etiquetadas se utilizan luego para entrenar un clasificador que separe las imágenes que coinciden con el concepto de la consulta de aquellas que no lo hacen. Sin embargo, en general, las imágenes principales que se devuelven pueden no ser las más informativas. En el peor de los casos, todas las imágenes principales etiquetadas por el usuario pueden ser positivas y, por lo tanto, las técnicas estándar de clasificación no pueden aplicarse debido a la falta de ejemplos negativos. A diferencia de los problemas de clasificación estándar donde las muestras etiquetadas están predefinidas, en la recuperación de imágenes con retroalimentación de relevancia, el sistema puede seleccionar activamente las imágenes a etiquetar. Por lo tanto, el aprendizaje activo puede ser introducido de forma natural en la recuperación de imágenes. A pesar de la existencia de muchas técnicas de aprendizaje activo, el aprendizaje activo de Máquina de Vectores de Soporte (SVM) [14] y el aprendizaje activo basado en regresión [1] han sido los que han despertado mayor interés. Basado en la observación de que cuanto más cerca del límite del SVM se encuentre una imagen, menos confiable es su clasificación, el aprendizaje activo del SVM selecciona aquellas imágenes no etiquetadas más cercanas al límite para solicitar retroalimentación del usuario con el fin de lograr un refinamiento máximo en el hiperplano entre las dos clases. La principal desventaja del aprendizaje activo de SVM es que es posible que el límite estimado no sea lo suficientemente preciso. Además, puede que no se aplique al principio de la recuperación cuando no hay imágenes etiquetadas. Algunos otros algoritmos de aprendizaje activo basados en SVM se pueden encontrar en [7], [9]. En estadística, el problema de seleccionar muestras para etiquetar se conoce típicamente como diseño experimental. La muestra x se denomina experimento, y su etiqueta y se denomina medición. El estudio del diseño experimental óptimo (DEO) se preocupa por el diseño de experimentos que se espera que minimicen las varianzas de un modelo parametrizado. La intención del diseño experimental óptimo suele ser maximizar la confianza en un modelo dado, minimizar las varianzas de los parámetros para la identificación del sistema, o minimizar la varianza de la salida de los modelos. Los enfoques clásicos de diseño experimental incluyen el Diseño A-Óptimo, el Diseño D-Óptimo y el Diseño E-Óptimo. Todos estos enfoques se basan en un modelo de regresión de mínimos cuadrados. En comparación con los algoritmos de aprendizaje activo basados en SVM, los enfoques de diseño experimental son mucho más eficientes en términos de computación. Sin embargo, este tipo de enfoques solo tienen en cuenta los datos medidos (o etiquetados) en su función objetivo, mientras que los datos no medidos (o no etiquetados) son ignorados. Beneficiar de los avances recientes en diseño experimental óptimo y aprendizaje semisupervisado, en este artículo proponemos un nuevo algoritmo de aprendizaje activo para recuperación de imágenes, llamado Diseño Óptimo Laplaciano (LOD). A diferencia de los métodos tradicionales de diseño experimental cuyas funciones de pérdida solo están definidas en los puntos medidos, la función de pérdida de nuestro algoritmo propuesto LOD está definida tanto en los puntos medidos como en los no medidos. Específicamente, introducimos un regularizador que preserva la localidad en la función de pérdida estándar basada en el error cuadrático mínimo. La nueva función de pérdida tiene como objetivo encontrar un clasificador que sea localmente lo más suave posible. En otras palabras, si dos puntos están suficientemente cerca uno del otro en el espacio de entrada, se espera que compartan la misma etiqueta. Una vez que se define la función de pérdida, podemos seleccionar los puntos de datos más informativos que se presentan al usuario para su etiquetado. Sería importante tener en cuenta que las imágenes más informativas pueden no ser las primeras imágenes devueltas. El resto del documento está organizado de la siguiente manera. En la Sección 2, proporcionamos una breve descripción del trabajo relacionado. Nuestro algoritmo propuesto de Diseño Óptimo de Laplaciano se introduce en la Sección 3. En la Sección 4, comparamos nuestro algoritmo con los algoritmos de última generación y presentamos los resultados experimentales sobre la recuperación de imágenes. Finalmente, proporcionamos algunas observaciones finales y sugerencias para trabajos futuros en la Sección 5.2. TRABAJO RELACIONADO Dado que nuestro algoritmo propuesto se basa en un marco de regresión. El trabajo más relacionado es el diseño experimental óptimo [1], que incluye el Diseño A-Óptimo, el Diseño D-Óptimo y el Diseño E-Óptimo. En esta sección, damos una breve descripción de estos enfoques. 2.1 El Problema del Aprendizaje Activo El problema genérico del aprendizaje activo es el siguiente. Dado un conjunto de puntos A = {x1, x2, · · · , xm} en Rd , encuentra un subconjunto B = {z1, z2, · · · , zk} ⊂ A que contenga los puntos más informativos. En otras palabras, los puntos zi(i = 1, · · · , k) pueden mejorar el clasificador al máximo si están etiquetados y se utilizan como puntos de entrenamiento. 2.2 Diseño Experimental Óptimo Consideramos un modelo de regresión lineal y = wT x + (1) donde y es la observación, x es la variable independiente, w es el vector de pesos y es un error desconocido con media cero. Diferentes observaciones tienen errores que son independientes, pero con varianzas iguales σ2. Definimos f(x) = wT x como la salida del aprendiz dada la entrada x y el vector de pesos w. Supongamos que tenemos un conjunto de puntos de muestra etiquetados (z1, y1), · · · , (zk, yk), donde yi es la etiqueta de zi. Por lo tanto, la estimación de máxima verosimilitud para el vector de peso, ˆw, es aquella que minimiza la suma del error cuadrado Jsse(w) = k i=1 wT zi − yi 2 (2). La estimación ˆw nos proporciona una estimación de la salida en una entrada novedosa: ˆy = ˆwT x. Según el teorema de Gauss-Markov, sabemos que ˆw − w tiene una media cero y una matriz de covarianza dada por σ2 H−1 sse, donde Hsse es la Hessiana de Jsse(w) Hsse = ∂2 Jsse ∂w2 = k i=1 zizT i = ZZT donde Z = (z1, z2, · · · , zk). Las tres medidas escalares más comunes del tamaño de la matriz de covarianza de parámetros en el diseño experimental óptimo son: • Diseño D-óptimo: determinante de Hsse. • Diseño A-óptimo: traza de Hsse. • Diseño E-óptimo: valor propio máximo de Hsse. Dado que el cálculo del determinante y los valores propios de una matriz es mucho más costoso que el cálculo de la traza de la matriz, el diseño A-óptimo es más eficiente que los otros dos. Algunos trabajos recientes sobre diseño experimental se pueden encontrar en [6], [16]. DISEÑO ÓPTIMO LAPLACIANO Dado que la matriz de covarianza Hsse utilizada en enfoques tradicionales solo depende de las muestras medidas, es decir, zis, estos enfoques no logran evaluar los errores esperados en las muestras no medidas. En esta sección, presentamos un novedoso algoritmo de aprendizaje activo llamado Diseño Óptimo Laplaciano (LOD) que hace un uso eficiente tanto de muestras medidas (etiquetadas) como no medidas (sin etiquetar). 3.1 La Función Objetivo En muchos problemas de aprendizaje automático, es natural asumir que si dos puntos xi, xj están suficientemente cerca uno del otro, entonces sus mediciones (f(xi), f(xj)) también son cercanas. Sea S una matriz de similitud. Por lo tanto, una nueva función de pérdida que respeta la estructura geométrica del espacio de datos se puede definir de la siguiente manera: J0(w) = k i=1 f(zi)−yi 2 + λ 2 m i,j=1 f(xi)−f(xj) 2 Sij (3) donde yi es la medición (o etiqueta) de zi. Se debe tener en cuenta que la función de pérdida (3) es esencialmente la misma que la utilizada en la Regresión Regularizada Laplaciana (LRR, [2]). Sin embargo, LRR es un algoritmo de aprendizaje pasivo donde se proporcionan los datos de entrenamiento. En este artículo, nos enfocamos en cómo seleccionar los datos más informativos para el entrenamiento. La función de pérdida con nuestra elección de pesos simétricos Sij (Sij = Sji) incurre en una penalización severa si los puntos vecinos xi y xj se asignan lejos uno del otro. Por lo tanto, minimizar J0(w) es un intento de asegurar que si xi y xj están cerca, entonces f(xi) y f(xj) también estén cerca. Hay muchas opciones de la matriz de similitud S. Una definición simple es la siguiente: Sij = ⎧ ⎨ ⎩ 1, si xi está entre los p vecinos más cercanos de xj, o xj está entre los p vecinos más cercanos de xi; 0, en otro caso. (4) Sea D una matriz diagonal, Dii = j Sij, y L = D−S. La matriz L se llama Laplaciano de grafo en la teoría espectral de grafos [3]. Sea y = (y1, · · · , yk)T y X = (x1, · · · , xm). Siguiendo algunos pasos algebraicos simples, vemos que: J0(w) = k i=1 wT zi − yi 2 + λ 2 m i,j=1 wT xi − wT xj 2 Sij = y − ZT w T y − ZT w + λwT m i=1 DiixixT i − m i,j=1 SijxixT j w = yT y − 2wT Zy + wT ZZT w +λwT m i=1 DiixixT i − m i,j=1 SijxixT j w = yT y − 2wT Zy + wT ZZT + λXLXT w La Hessiana de J0(w) se puede calcular de la siguiente manera: H0 = ∂2 J0 ∂w2 = ZZT + λXLXT En algunos casos, la matriz ZZT +λXLXT es singular (por ejemplo, si m < d). Por lo tanto, no hay una solución estable para el problema de optimización Ec. (3). Una forma común de abordar este problema mal planteado es introducir un regularizador de Tikhonov en nuestra función de pérdida: J(w) = k i=1 wT zi − yi 2 + λ1 2 m i,j=1 wT xi − wT xj 2 Sij +λ2 w 2 (5) El Hessiano de la nueva función de pérdida está dado por: H = ∂2 J ∂w2 = ZZT + λ1XLXT + λ2I := ZZT + Λ donde I es una matriz identidad y Λ = λ1XLXT + λ2I. Claramente, H tiene rango completo. Exigir que el gradiente de J(w) con respecto a w se anule proporciona la estimación óptima ˆw: ˆw = H−1 Zy. La siguiente proposición establece las propiedades de sesgo y varianza del estimador para el vector de coeficientes w. Proposición 3.1. E( ˆw − w) = −H−1 Λw, Cov( ˆw) = σ2 (H−1 − H−1 ΛH−1 ) Demostración. Dado que y = ZTw + y E( ) = 0, se deduce que E( ˆw − w) (6) = H−1 ZZTw − w = H−1 (ZZT + Λ − Λ)w − w = (I − H−1 Λ)w − w = −H−1 Λw (7) Nótese que Cov(y) = σ2 I, la matriz de covarianza de ˆw tiene la expresión: Cov( ˆw) = H−1 ZCov(y)ZT H−1 = σ2 H−1 ZZT H−1 = σ2 H−1 (H − Λ)H−1 = σ2 (H−1 − H−1 ΛH−1 ) (8) Por lo tanto, la matriz de error cuadrático medio para los coeficientes w es E(w − ˆw)(w − ˆw)T (9) = H−1 ΛwwT ΛH−1 + σ2 (H−1 − H−1 ΛH−1 ) (10) Para cualquier x, sea ˆy = ˆwT x su observación predicha. El error cuadrático de predicción esperado es E(y − ˆy)2 = E( + wT x − ˆwT x)2 = σ2 + xT [E(w − ˆw)(w − ˆw)T ]x = σ2 + xT [H−1 ΛwwT ΛH−1 + σ2 H−1 − σ2 H−1 ΛH−1 ]x Claramente, el error cuadrático de predicción esperado depende de la variable explicativa x, por lo tanto, el error cuadrático de predicción promedio esperado sobre el conjunto de datos completo A es 1 m m i=1 E(yi − ˆwT xi)2 = 1 m m i=1 xT i [H−1 ΛwwT ΛH−1 + σ2 H−1 − σ2 H−1 ΛH−1 ]xi +σ2 = 1 m Tr(XT [σ2 H−1 + H−1 ΛwwT ΛH−1 − σ2 H−1 ΛH−1 ]X) +σ2 Dado que Tr(XT [H−1 ΛwwT ΛH−1 − σ2 H−1 ΛH−1 ]X) Tr(σ2 XT H−1 X), nuestro criterio de optimalidad laplaciano se formula minimizando la traza de XT H−1 X. Definición 1. Diseño óptimo de Laplaciano min Z=(z1,··· ,zk) Tr XT ZZT + λ1XLXT + λ2I −1 X (11) donde z1, · · · , zk son seleccionados de {x1, · · · , xm}. 4. DISEÑO ÓPTIMO DEL NÚCLEO LAPLACIANO Enfoques canónicos de diseño experimental (por ejemplo, Los diseños A-óptimos, D-óptimos y E-óptimos solo consideran funciones lineales. No logran descubrir la geometría intrínseca en los datos cuando el espacio de datos es altamente no lineal. En esta sección, describimos cómo realizar el Diseño Experimental Laplaciano en el Espacio de Hilbert de Núcleos Reproductores (RKHS), lo que da lugar al Diseño Experimental Laplaciano de Núcleo (KLOD). Para los puntos de datos dados x1, · · · , xm ∈ X con un núcleo de Mercer positivo definido K : X ×X → R, existe un único RKHS HK de funciones de valores reales en X. Sea Kt(s) la función de s obtenida al fijar t y dejar que Kt(s) = K(s, t). HK consiste en todas las combinaciones lineales finitas de la forma ∑ i=1 αiKti con ti ∈ X y los límites de tales funciones a medida que los ti se vuelven densos en X. Tenemos Ks, Kt HK = K(s, t). 4.1 Derivación de LOD en el Espacio de Hilbert del Núcleo Reproductor. Considera el problema de optimización (5) en RKHS. Por lo tanto, buscamos una función f ∈ HK tal que se minimice la siguiente función objetivo: min f∈HK k i=1 f(zi)−yi 2 + λ1 2 m i,j=1 f(xi)−f(xj) 2 Sij+λ2 f 2 HK (12). Tenemos la siguiente proposición. Proposición 4.1. Sea H = { m i=1 αiK(·, xi)|αi ∈ R} un subespacio de HK, la solución al problema (12) está en H. Demostración. Sea H⊥ el complemento ortogonal de H, es decir, HK = H ⊕ H⊥. Por lo tanto, para cualquier función f ∈ HK, tiene una descomposición ortogonal de la siguiente manera: f = fH + fH⊥ Ahora, evaluemos f en xi: f(xi) = f, Kxi HK = fH + fH⊥ , Kxi HK = fH, Kxi HK + fH⊥ , Kxi HK Observa que Kxi ∈ H mientras que fH⊥ ∈ H⊥. Esto implica que fH⊥ , Kxi HK = 0. Por lo tanto, f(xi) = fH, Kxi HK = fH(xi). Esto completa la prueba. La Proposición 4.1 nos dice que el minimizador del problema (12) admite una representación f∗ = m i=1 αiK(·, xi). Por favor, consulte [2] para ver los detalles. Sea φ : Rd → H un mapeo de características del espacio de entrada Rd a H, y K(xi, xj) =< φ(xi), φ(xj) >. Que X denote la matriz de datos en RKHS, X = (φ(x1), φ(x2), · · · , φ(xm)). De manera similar, definimos Z = (φ(z1), φ(z2), · · · , φ(zk)). Por lo tanto, el problema de optimización en RKHS se puede escribir de la siguiente manera: min Z Tr XT ZZT + λ1XLXT + λ2I −1 X (13) Dado que la función de mapeo φ generalmente es desconocida, no hay una forma directa de resolver el problema (13). En lo siguiente, aplicamos trucos de kernel para resolver este problema de optimización. Sea X−1 la inversa de Moore-Penrose (también conocida como pseudoinversa) de X. Así, tenemos: XT ZZT + λ1XLXT + λ2I −1 X = XT XX−1 ZZT + λ1XLXT + λ2I −1 (XT )−1 XT X = XT X ZZT X + λ1XLXT X + λ2X −1 (XT )−1 XT X = XT X XT ZZT X + λ1XT XLXT X + λ2XT X −1 XT X = KXX KXZKZX + λ1KXXLKXX + λ2KXX −1 KXX donde KXX es una matriz m × m (KXX,ij = K(xi, xj)), KXZ es una matriz m×k (KXZ,ij = K(xi, zj)), y KZX es una matriz k×m (KZX,ij = K(zi, xj)). Por lo tanto, el Diseño Óptimo del Laplaciano del Núcleo se puede definir de la siguiente manera: Definición 2. En este subapartado, discutimos cómo resolver los problemas de optimización (11) y (14). Particularmente, si seleccionamos un núcleo lineal para KLOD, entonces se reduce a LOD. Por lo tanto, nos enfocaremos en el problema (14) a continuación. Se puede demostrar que el problema de optimización (14) es NP-duro. En esta subsección, desarrollamos un enfoque codicioso secuencial simple para resolver (14). Supongamos que se han seleccionado n puntos, denotados por una matriz Zn = (z1, · · · , zn). El punto (n + 1)-ésimo zn+1 puede ser seleccionado resolviendo el siguiente problema de optimización: max Zn+1=(Zn,zn+1) Tr KXX KXZn+1 KZn+1X + λ1KXXLKXX + λ2KXX −1 KXX (15) Las matrices de kernel KXZn+1 y KZn+1X pueden ser reescritas de la siguiente manera: KXZn+1 = KXZn , KXzn+1 , KZn+1X = KZnX Kzn+1X Por lo tanto, tenemos: KXZn+1 KZn+1X = KXZn KZnX + KXzn+1 Kzn+1X Definimos: A = KXZn KZnX + λ1KXXLKXX + λ2KXX A solo depende de X y Zn. Por lo tanto, el punto (n + 1)-ésimo zn+1 se da por: zn+1 = arg min zn+1 Tr KXX A + KXzn+1 Kzn+1X −1 KXX. Cada vez que seleccionamos un nuevo punto zn+1, la matriz A se actualiza por: A ← A + KXzn+1 Kzn+1X. Si la función de kernel se elige como producto interno K(x, y) = x, y, entonces HK es un espacio funcional lineal y el algoritmo se reduce a LOD. 5. RECUPERACIÓN DE IMÁGENES BASADA EN CONTENIDO UTILIZANDO DISEÑO ÓPTIMO LAPLACIANO En esta sección, describimos cómo aplicar el Diseño Óptimo Laplaciano a la RCIB. Comenzamos con una breve descripción de la representación de imágenes utilizando características visuales de nivel bajo. 5.1 Representación de Imágenes de Nivel Bajo La representación de imágenes de nivel bajo es un problema crucial en la Recuperación de Información Basada en el Contenido (CBIR). Las características visuales generales incluyen color, textura, forma, etc. Las características de color y textura son las características visuales más ampliamente utilizadas en la recuperación de información basada en contenido (CBIR). En comparación con las características de color y textura, las características de forma suelen describirse después de que las imágenes hayan sido segmentadas en regiones u objetos. Dado que la segmentación de imágenes robusta y precisa es difícil de lograr, el uso de características de forma para la recuperación de imágenes se ha limitado a aplicaciones especiales donde los objetos o regiones están fácilmente disponibles. En este trabajo, combinamos un histograma de color de 64 dimensiones y un Momento de Textura de Color (CTM, [15]) de 64 dimensiones para representar las imágenes. El histograma de color se calcula utilizando 4 × 4 × 4 contenedores en el espacio HSV. El Momento de Textura de Color es propuesto por Yu et al. [15], el cual integra las características de color y textura de la imagen en una forma compacta. CTM adopta la transformada de Fourier local como un esquema de representación de texturas y deriva ocho mapas característicos para describir diferentes aspectos de las relaciones de co-ocurrencia de píxeles de imagen en cada canal del espacio de color (SVcosH, SVsinH, V). Entonces, CTM calcula el primer y segundo momento de estos mapas como una representación de la distribución de píxeles de la imagen en color natural. Por favor, consulte [15] para más detalles. 5.2 Recuperación de imágenes con retroalimentación de relevancia La retroalimentación de relevancia es una de las técnicas más importantes para reducir la brecha entre las características visuales de bajo nivel y los conceptos semánticos de alto nivel [12]. Tradicionalmente, los comentarios de relevancia de los usuarios se utilizan para actualizar el vector de consulta o ajustar el peso de las diferentes dimensiones. Este proceso puede ser visto como un proceso de aprendizaje en línea en el que el sistema de recuperación de imágenes actúa como un aprendiz y el usuario actúa como un maestro. El proceso típico de recuperación se describe de la siguiente manera: 1. El usuario envía un ejemplo de imagen de consulta al sistema. El sistema clasifica las imágenes en la base de datos según alguna métrica de distancia predefinida y presenta al usuario las imágenes mejor clasificadas. El sistema selecciona algunas imágenes de la base de datos y solicita al usuario que las etiquete como relevantes o irrelevantes. El sistema utiliza la información proporcionada por los usuarios para reorganizar las imágenes en la base de datos y devolver al usuario las imágenes principales. Ve al paso 2 hasta que el usuario esté satisfecho. Nuestro algoritmo de Diseño Óptimo de Laplaciano se aplica en el segundo paso para seleccionar las imágenes más informativas. Una vez que obtenemos las etiquetas para las imágenes seleccionadas por LOD, aplicamos la Regresión Regularizada Laplaciana (LRR, [2]) para resolver el problema de optimización (3) y construir el clasificador. El clasificador se utiliza luego para reordenar las imágenes en la base de datos. Ten en cuenta que, para reducir la complejidad computacional, no utilizamos todas las imágenes sin etiquetar en la base de datos, sino solo aquellas dentro de los 500 primeros resultados de la iteración anterior. 6. RESULTADOS EXPERIMENTALES En esta sección, evaluamos el rendimiento de nuestro algoritmo propuesto en una gran base de datos de imágenes. Para demostrar la efectividad de nuestro algoritmo LOD propuesto, lo comparamos con la Regresión Regularizada de Laplaciano (LRR, [2]), la Máquina de Vectores de Soporte (SVM), el Aprendizaje Activo de Máquina de Vectores de Soporte (SVMactive) [14], y el Diseño A-Óptimo (AOD). Tanto SVMactive, AOD y LOD son algoritmos de aprendizaje activo, mientras que LRR y SVM son algoritmos de clasificación estándar. SVM solo hace uso de las imágenes etiquetadas, mientras que LRR es un algoritmo de aprendizaje semi-supervisado que hace uso tanto de imágenes etiquetadas como no etiquetadas. Para SVMactive, AOD y LOD, los algoritmos seleccionan 10 imágenes de entrenamiento en cada iteración. Para LRR y SVM, utilizamos las 10 imágenes principales como datos de entrenamiento. Sería importante señalar que SVMactive se basa en el SVM ordinario, LOD se basa en LRR y AOD se basa en la regresión ordinaria. Los parámetros λ1 y λ2 en nuestro algoritmo LOD se establecen empíricamente en 0.001 y 0.00001. Para ambos algoritmos LRR y LOD, utilizamos la misma estructura de grafo (ver Ecuación 4) y establecemos el valor de p (número de vecinos más cercanos) en 5. Comenzamos con un ejemplo sintético simple para dar una intuición sobre cómo funciona LOD. 6.1 Ejemplo Sintético Simple Se presenta un ejemplo sintético simple en la Figura 1. El conjunto de datos contiene dos círculos. Ocho puntos son seleccionados por AOD y LOD. Como se puede ver, todos los puntos seleccionados por AOD son del círculo grande, mientras que LOD selecciona cuatro puntos del círculo grande y cuatro del círculo pequeño. Los números junto a los puntos seleccionados indican su orden de selección. Claramente, los puntos seleccionados por nuestro algoritmo LOD pueden representar mejor el conjunto de datos original. No comparamos nuestro algoritmo con SVMactive porque SVMactive no se puede aplicar en este caso debido a la falta de puntos etiquetados. 6.2 Diseño Experimental de Recuperación de Imágenes La base de datos de imágenes que utilizamos consta de 7,900 imágenes de 79 categorías semánticas, del conjunto de datos COREL. Es un conjunto de imágenes grande y heterogéneo. Cada imagen se representa como un vector de 128 dimensiones según se describe en la Sección 5.1. La Figura 2 muestra algunas imágenes de muestra. Para exhibir las ventajas de usar nuestro algoritmo, necesitamos una forma confiable de evaluar el rendimiento de recuperación y las comparaciones con otros algoritmos. Listamos a continuación diferentes aspectos del diseño experimental. 6.2.1 Métricas de Evaluación Utilizamos la curva de precisión-alcance y la <br>tasa de precisión</br> [10] para evaluar la efectividad de los algoritmos de recuperación de imágenes. El alcance está especificado por el número (N) de imágenes mejor clasificadas presentadas al usuario. La precisión es la proporción entre el número de imágenes relevantes presentadas al usuario y el (a) Conjunto de datos 1 2 3 4 5 6 7 8 (b) AOD 1 2 3 4 5 6 7 8 (c) LOD Figura 1: Selección de datos por algoritmos de aprendizaje activo. Los números junto a los puntos seleccionados indican su orden de selección. Claramente, los puntos seleccionados por nuestro algoritmo LOD pueden representar mejor el conjunto de datos original. Se debe tener en cuenta que el algoritmo SVMactive no se puede aplicar en este caso debido a la falta de puntos etiquetados. (a) (b) (c) Figura 2: Imágenes de muestra de las categorías cuentas, elefante y barco. El alcance de precisión describe la precisión con varios alcances y, por lo tanto, proporciona una evaluación general del rendimiento de los algoritmos. Por otro lado, la <br>tasa de precisión</br> enfatiza la precisión en un valor particular de alcance. En general, es apropiado presentar 20 imágenes en una pantalla. Agregar más imágenes en una pantalla puede afectar la calidad de las imágenes presentadas. Por lo tanto, la precisión en los primeros 20 (N = 20) es especialmente importante. En los sistemas de recuperación de imágenes del mundo real, la imagen de consulta generalmente no se encuentra en la base de datos de imágenes. Para simular dicho entorno, utilizamos validación cruzada de cinco pliegues para evaluar los algoritmos. Más precisamente, dividimos toda la base de datos de imágenes en cinco subconjuntos de tamaño igual. Por lo tanto, hay 20 imágenes por categoría en cada subconjunto. En cada ejecución de validación cruzada, se selecciona un subconjunto como conjunto de consulta, y los otros cuatro subconjuntos se utilizan como base de datos para la recuperación. La curva de precisión del precisionscope y la <br>tasa de precisión</br> se calculan promediando los resultados de la validación cruzada de cinco pliegues. 6.2.2 Esquema de retroalimentación automática de relevancia Diseñamos un esquema de retroalimentación automática para modelar el proceso de recuperación. Para cada consulta enviada, nuestro sistema recupera y clasifica las imágenes en la base de datos. Se seleccionaron 10 imágenes de la base de datos para que los usuarios las etiqueten y la información de las etiquetas es utilizada por el sistema para volver a clasificarlas. Ten en cuenta que las imágenes seleccionadas en iteraciones anteriores están excluidas de selecciones posteriores. Para cada consulta, se realiza el mecanismo de retroalimentación automática de relevancia durante cuatro iteraciones. Es importante señalar que el esquema de retroalimentación automática de relevancia utilizado aquí es diferente de los descritos en [8], [11]. En [8], [11], las cuatro imágenes relevantes e irrelevantes principales fueron seleccionadas como las imágenes de retroalimentación. Sin embargo, esto puede no ser práctico. En los sistemas de recuperación de imágenes del mundo real, es posible que la mayoría de las imágenes mejor clasificadas sean relevantes (o irrelevantes). Por lo tanto, es difícil para el usuario encontrar tanto cuatro imágenes relevantes como irrelevantes. Es más razonable que los usuarios proporcionen información de retroalimentación solo sobre las 10 imágenes seleccionadas por el sistema. 6.3 Rendimiento de recuperación de imágenes En el mundo real, no es práctico requerir que el usuario proporcione muchas rondas de retroalimentación. El rendimiento de recuperación después de las dos primeras rondas de retroalimentación (especialmente la primera ronda) es más importante. La Figura 3 muestra las curvas de precisión-alcance promedio de los diferentes algoritmos para las dos primeras iteraciones de retroalimentación. Al principio de la recuperación, las distancias euclidianas en el espacio original de 128 dimensiones se utilizan para clasificar las imágenes en la base de datos. Después de que el usuario proporcione retroalimentación de relevancia, se aplican los algoritmos LRR, SVM, SVMactive, AOD y LOD para volver a clasificar las imágenes. Para reducir la complejidad temporal de los algoritmos de aprendizaje activo, no seleccionamos las imágenes más informativas de toda la base de datos, sino de las 500 imágenes principales. Para LRR y SVM, se requiere que el usuario etiquete las 10 imágenes principales. Para SVMactive, AOD y LOD, se requiere que el usuario etiquete las 10 imágenes más informativas seleccionadas por estos algoritmos. Tenga en cuenta que, SVMactive solo puede ser ap(a) Iteración de retroalimentación 1 (b) Iteración de retroalimentación 2 Figura 3: Las curvas de precisión promedio-alcance de diferentes algoritmos para las dos primeras iteraciones de retroalimentación. El algoritmo LOD funciona mejor en todo el alcance. Se debe tener en cuenta que, en la primera ronda de retroalimentación, el algoritmo SVMactive no se puede aplicar. Se aplica el SVM ordinario para construir el clasificador inicial. (a) Precisión en el Top 10 (b) Precisión en el Top 20 (c) Precisión en el Top 30 Figura 4: Evaluación del rendimiento de los cinco algoritmos de aprendizaje para la recuperación de imágenes con retroalimentación de relevancia. (a) Precisión en el top 10, (b) Precisión en el top 20 y (c) Precisión en el top 30. Como se puede observar, nuestro algoritmo LOD supera consistentemente a los otros cuatro algoritmos. Por lo tanto, no se puede aplicar en la primera ronda y utilizamos el SVM estándar para construir el clasificador inicial. Como se puede ver, nuestro algoritmo LOD supera a los otros cuatro algoritmos en todo el ámbito. Además, el algoritmo LRR tiene un mejor rendimiento que SVM. Esto se debe a que el algoritmo LRR hace un uso eficiente de las imágenes no etiquetadas al incorporar un regularizador de preservación de la localidad en la función objetivo de regresión ordinaria. El algoritmo AOD es el que tiene peor rendimiento. A medida que el alcance se amplía, la diferencia de rendimiento entre estos algoritmos disminuye. Al agregar de forma iterativa los comentarios de los usuarios, los resultados de precisión correspondientes (en los primeros 10, 20 y 30 lugares) de los cinco algoritmos se muestran respectivamente en la Figura 4. Como se puede ver, nuestro algoritmo LOD tiene el mejor rendimiento en todos los casos y el algoritmo LRR tiene el segundo mejor rendimiento. Ambos de estos dos algoritmos hacen uso de las imágenes sin etiquetar. Esto demuestra que las imágenes sin etiquetar son útiles para descubrir la estructura geométrica intrínseca del espacio de imágenes y, por lo tanto, mejorar el rendimiento de recuperación. En el mundo real, es posible que el usuario no esté dispuesto a proporcionar demasiadas retroalimentaciones de relevancia. Por lo tanto, el rendimiento de recuperación en las primeras dos rondas es especialmente importante. Como se puede observar, nuestro algoritmo LOD logra una mejora del rendimiento del 6.8% para los 10 mejores resultados, del 5.2% para los 20 mejores resultados y del 4.1% para los 30 mejores resultados, en comparación con el segundo mejor algoritmo (LRR) después de las dos primeras rondas de retroalimentación de relevancia. 6.4 Discusión Se han realizado sistemáticamente varios experimentos en la base de datos de Corel. Nos gustaría resaltar varios puntos interesantes: 1. Es claro que el uso del aprendizaje activo es beneficioso en el ámbito de la recuperación de imágenes. Hay un aumento significativo en el rendimiento al utilizar los métodos de aprendizaje activo. Especialmente, de los tres métodos de aprendizaje activo (SVMactive, AOD, LOD), nuestro algoritmo propuesto LOD es el que tiene mejor rendimiento. En muchas aplicaciones del mundo real, como la recuperación de imágenes con retroalimentación de relevancia, generalmente hay dos formas de reducir la tarea laboriosa de etiquetado manual. Uno es el aprendizaje activo que selecciona las muestras más informativas para etiquetar, y el otro es el aprendizaje semi-supervisado que utiliza las muestras no etiquetadas para mejorar el rendimiento del aprendizaje. Ambas estrategias han sido estudiadas extensamente en el pasado [14], [7], [5], [8]. El trabajo presentado en este artículo se centra en el aprendizaje activo, pero también aprovecha los avances recientes en el aprendizaje semi-supervisado [2]. Específicamente, incorporamos un regularizador que preserva la localidad en el marco de regresión estándar y encontramos las muestras más informativas con respecto a la nueva función objetivo. De esta manera, las técnicas de aprendizaje activo y de aprendizaje semi-supervisado se unifican de manera fluida para aprender un clasificador óptimo. 3. La técnica de retroalimentación de relevancia es crucial para la recuperación de imágenes. Para los cinco algoritmos, el rendimiento de recuperación mejora con más retroalimentación proporcionada por el usuario. CONCLUSIONES Y TRABAJOS FUTUROS Este artículo describe un novedoso algoritmo de aprendizaje activo, llamado Diseño Óptimo Laplaciano, para permitir una recuperación de imágenes con retroalimentación de relevancia más efectiva. Nuestro algoritmo se basa en una función objetivo que minimiza simultáneamente el error empírico y preserva la estructura geométrica local del espacio de datos. Utilizando técnicas de diseño experimental, nuestro algoritmo encuentra las imágenes más informativas para etiquetar. Estas imágenes etiquetadas y las imágenes sin etiquetar en la base de datos se utilizan para aprender un clasificador. Los resultados experimentales en la base de datos Corel muestran que tanto el aprendizaje activo como el aprendizaje semi-supervisado pueden mejorar significativamente el rendimiento de recuperación. En este documento, consideramos el problema de recuperación de imágenes en un conjunto de datos de imágenes pequeño, estático y de dominio cerrado. Un dominio mucho más desafiante es la World Wide Web (WWW). Para la búsqueda de imágenes en la web, es posible recopilar una gran cantidad de información sobre los clics de los usuarios. Esta información puede ser utilizada de forma natural para construir el grafo de afinidad en nuestro algoritmo. Sin embargo, la complejidad computacional en el escenario web puede convertirse en un problema crucial. Además, aunque nuestro interés principal en este artículo se centra en la recuperación de imágenes con retroalimentación de relevancia, nuestros resultados también pueden ser de interés para investigadores en reconocimiento de patrones y aprendizaje automático, especialmente cuando hay una gran cantidad de datos disponibles pero solo se pueden etiquetar muestras limitadas. 8. REFERENCIAS [1] A. C. Atkinson y A. N. Donev. Diseños experimentales óptimos. Oxford University Press, 2002. [2] M. Belkin, P. Niyogi, y V. Sindhwani. Regularización de variedades: Un marco geométrico para el aprendizaje a partir de ejemplos. Revista de Investigación de Aprendizaje Automático, 7:2399-2434, 2006. [3] F. R. K. Chung. Teoría Espectral de Grafos, volumen 92 de la Serie de Conferencias Regionales en Matemáticas. AMS, 1997. [4] D. A. Cohn, Z. Ghahramani y M. I. Jordan. Aprendizaje activo con modelos estadísticos. Revista de Investigación en Inteligencia Artificial, 4:129-145, 1996. [5] A. Dong y B. Bhanu. Un nuevo algoritmo EM semisupervisado para la recuperación de imágenes. En la Conferencia IEEE sobre Visión por Computadora y Reconocimiento de Patrones, Madison, WI, 2003. [6] P. Flaherty, M. I. Jordan y A. P. Arkin. Diseño robusto de experimentos biológicos. En Advances in Neural Information Processing Systems 18, Vancouver, Canadá, 2005. [7] K.-S. Goh, E. Y. Chang y W.-C. Lai. Aprendizaje activo dependiente del concepto multimodal para la recuperación de imágenes. En Actas de la Conferencia ACM sobre Multimedia, Nueva York, octubre de 2004. [8] X. Lo siento, la oración \"He.\" no tiene un significado claro en inglés. ¿Podrías proporcionar más contexto o una oración completa para que pueda traducirla al español de manera precisa? Aprendizaje de subespacios semisupervisado incremental para la recuperación de imágenes. En Actas de la Conferencia ACM sobre Multimedia, Nueva York, octubre de 2004. [9] S. C. Hoi y M. R. Lyu. Un marco de aprendizaje activo semi-supervisado para la recuperación de imágenes. En la Conferencia Internacional de IEEE sobre Visión por Computadora y Reconocimiento de Patrones, San Diego, CA, 2005. [10] D. P. Huijsmans y N. Sebe. Cómo completar los gráficos de rendimiento en la recuperación de imágenes basada en contenido: Agregar generalidad y normalizar el alcance. IEEE Transactions on Pattern Analysis and Machine Intelligence, 27(2):245-251, 2005. [11] Y.-Y.\n\nTransacciones del IEEE sobre Inteligencia Artificial y Análisis de Patrones, 27(2):245-251, 2005. [11] Y.-Y. Lin, T.-L. Liu y H.-T. Chen. Aprendizaje de variedades semánticas para la recuperación de imágenes. En Actas de la Conferencia ACM sobre Multimedia, Singapur, noviembre de 2005. [12] Y. Rui, T. S. Huang, M. Ortega y S. Mehrotra. Retroalimentación de relevancia: Una herramienta poderosa para la recuperación de imágenes basada en contenido de forma interactiva. IEEE Transactions on Circuits and Systems for Video Technology, 8(5), 1998. [13] A. W. Smeulders, M. Worring, S. Santini, A. Gupta, and R. Jain. \n\nTraducción: IEEE Transactions on Circuits and Systems for Video Technology, 8(5), 1998. [13] A. W. Smeulders, M. Worring, S. Santini, A. Gupta y R. Jain. Recuperación de imágenes basada en contenido al final de los primeros años. IEEE Transactions on Pattern Analysis and Machine Intelligence, 22(12):1349-1380, 2000. [14] S. Tong y E. Chang. Aprendizaje activo de máquina de vectores de soporte para recuperación de imágenes. En Actas de la novena conferencia internacional de ACM sobre Multimedia, páginas 107-118, 2001. [15] H. Yu, M. Li, H.-J. Zhang y J. Feng. Momentos de textura de color para la recuperación de imágenes basada en contenido. En la Conferencia Internacional de Procesamiento de Imágenes, páginas 24-28, 2002. [16] K. Yu, J. Bi y V. Tresp. Aprendizaje activo a través del diseño experimental transductivo. En Actas de la 23ª Conferencia Internacional sobre Aprendizaje Automático, Pittsburgh, PA, 2006. ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "intrinsic geometrical structure": {
            "translated_key": "estructura geométrica intrínseca",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Laplacian Optimal Design for Image Retrieval Xiaofei He Yahoo!",
                "Burbank, CA 91504 hex@yahoo-inc.com Wanli Min IBM Yorktown Heights, NY 10598 wanlimin@us.ibm.com Deng Cai CS Dept., UIUC Urbana, IL 61801 dengcai2@cs.uiuc.edu Kun Zhou Microsoft Research Asia Beijing, China kunzhou@microsoft.com ABSTRACT Relevance feedback is a powerful technique to enhance ContentBased Image Retrieval (CBIR) performance.",
                "It solicits the users relevance judgments on the retrieved images returned by the CBIR systems.",
                "The users labeling is then used to learn a classifier to distinguish between relevant and irrelevant images.",
                "However, the top returned images may not be the most informative ones.",
                "The challenge is thus to determine which unlabeled images would be the most informative (i.e., improve the classifier the most) if they were labeled and used as training samples.",
                "In this paper, we propose a novel active learning algorithm, called Laplacian Optimal Design (LOD), for relevance feedback image retrieval.",
                "Our algorithm is based on a regression model which minimizes the least square error on the measured (or, labeled) images and simultaneously preserves the local geometrical structure of the image space.",
                "Specifically, we assume that if two images are sufficiently close to each other, then their measurements (or, labels) are close as well.",
                "By constructing a nearest neighbor graph, the geometrical structure of the image space can be described by the graph Laplacian.",
                "We discuss how results from the field of optimal experimental design may be used to guide our selection of a subset of images, which gives us the most amount of information.",
                "Experimental results on Corel database suggest that the proposed approach achieves higher precision in relevance feedback image retrieval.",
                "Categories and Subject Descriptors H.3.3 [Information storage and retrieval]: Information search and retrieval-Relevance feedback; G.3 [Mathematics of Computing]: Probability and Statistics-Experimental design General Terms Algorithms, Performance, Theory 1.",
                "INTRODUCTION In many machine learning and information retrieval tasks, there is no shortage of unlabeled data but labels are expensive.",
                "The challenge is thus to determine which unlabeled samples would be the most informative (i.e., improve the classifier the most) if they were labeled and used as training samples.",
                "This problem is typically called active learning [4].",
                "Here the task is to minimize an overall cost, which depends both on the classifier accuracy and the cost of data collection.",
                "Many real world applications can be casted into active learning framework.",
                "Particularly, we consider the problem of relevance feedback driven Content-Based Image Retrieval (CBIR) [13].",
                "Content-Based Image Retrieval has attracted substantial interests in the last decade [13].",
                "It is motivated by the fast growth of digital image databases which, in turn, require efficient search schemes.",
                "Rather than describe an image using text, in these systems an image query is described using one or more example images.",
                "The low level visual features (color, texture, shape, etc.) are automatically extracted to represent the images.",
                "However, the low level features may not accurately characterize the high level semantic concepts.",
                "To narrow down the semantic gap, relevance feedback is introduced into CBIR [12].",
                "In many of the current relevance feedback driven CBIR systems, the user is required to provide his/her relevance judgments on the top images returned by the system.",
                "The labeled images are then used to train a classifier to separate images that match the query concept from those that do not.",
                "However, in general the top returned images may not be the most informative ones.",
                "In the worst case, all the top images labeled by the user may be positive and thus the standard classification techniques can not be applied due to the lack of negative examples.",
                "Unlike the standard classification problems where the labeled samples are pregiven, in relevance feedback image retrieval the system can actively select the images to label.",
                "Thus active learning can be naturally introduced into image retrieval.",
                "Despite many existing active learning techniques, Support Vector Machine (SVM) active learning [14] and regression based active learning [1] have received the most interests.",
                "Based on the observation that the closer to the SVM boundary an image is, the less reliable its classification is, SVM active learning selects those unlabeled images closest to the boundary to solicit user feedback so as to achieve maximal refinement on the hyperplane between the two classes.",
                "The major disadvantage of SVM active learning is that the estimated boundary may not be accurate enough.",
                "Moreover, it may not be applied at the beginning of the retrieval when there is no labeled images.",
                "Some other SVM based active learning algorithms can be found in [7], [9].",
                "In statistics, the problem of selecting samples to label is typically referred to as experimental design.",
                "The sample x is referred to as experiment, and its label y is referred to as measurement.",
                "The study of optimal experimental design (OED) [1] is concerned with the design of experiments that are expected to minimize variances of a parameterized model.",
                "The intent of optimal experimental design is usually to maximize confidence in a given model, minimize parameter variances for system identification, or minimize the models output variance.",
                "Classical experimental design approaches include A-Optimal Design, D-Optimal Design, and E-Optimal Design.",
                "All of these approaches are based on a least squares regression model.",
                "Comparing to SVM based active learning algorithms, experimental design approaches are much more efficient in computation.",
                "However, this kind of approaches takes only measured (or, labeled) data into account in their objective function, while the unmeasured (or, unlabeled) data is ignored.",
                "Benefit from recent progresses on optimal experimental design and semi-supervised learning, in this paper we propose a novel active learning algorithm for image retrieval, called Laplacian Optimal Design (LOD).",
                "Unlike traditional experimental design methods whose loss functions are only defined on the measured points, the loss function of our proposed LOD algorithm is defined on both measured and unmeasured points.",
                "Specifically, we introduce a locality preserving regularizer into the standard least-square-error based loss function.",
                "The new loss function aims to find a classifier which is locally as smooth as possible.",
                "In other words, if two points are sufficiently close to each other in the input space, then they are expected to share the same label.",
                "Once the loss function is defined, we can select the most informative data points which are presented to the user for labeling.",
                "It would be important to note that the most informative images may not be the top returned images.",
                "The rest of the paper is organized as follows.",
                "In Section 2, we provide a brief description of the related work.",
                "Our proposed Laplacian Optimal Design algorithm is introduced in Section 3.",
                "In Section 4, we compare our algorithm with the state-or-the-art algorithms and present the experimental results on image retrieval.",
                "Finally, we provide some concluding remarks and suggestions for future work in Section 5. 2.",
                "RELATED WORK Since our proposed algorithm is based on regression framework.",
                "The most related work is optimal experimental design [1], including A-Optimal Design, D-Optimal Design, and EOptimal Design.",
                "In this Section, we give a brief description of these approaches. 2.1 The Active Learning Problem The generic problem of active learning is the following.",
                "Given a set of points A = {x1, x2, · · · , xm} in Rd , find a subset B = {z1, z2, · · · , zk} ⊂ A which contains the most informative points.",
                "In other words, the points zi(i = 1, · · · , k) can improve the classifier the most if they are labeled and used as training points. 2.2 Optimal Experimental Design We consider a linear regression model y = wT x + (1) where y is the observation, x is the independent variable, w is the weight vector and is an unknown error with zero mean.",
                "Different observations have errors that are independent, but with equal variances σ2 .",
                "We define f(x) = wT x to be the learners output given input x and the weight vector w. Suppose we have a set of labeled sample points (z1, y1), · · · , (zk, yk), where yi is the label of zi.",
                "Thus, the maximum likelihood estimate for the weight vector, ˆw, is that which minimizes the sum squared error Jsse(w) = k i=1 wT zi − yi 2 (2) The estimate ˆw gives us an estimate of the output at a novel input: ˆy = ˆwT x.",
                "By Gauss-Markov theorem, we know that ˆw − w has a zero mean and a covariance matrix given by σ2 H−1 sse, where Hsse is the Hessian of Jsse(w) Hsse = ∂2 Jsse ∂w2 = k i=1 zizT i = ZZT where Z = (z1, z2, · · · , zk).",
                "The three most common scalar measures of the size of the parameter covariance matrix in optimal experimental design are: • D-optimal design: determinant of Hsse. • A-optimal design: trace of Hsse. • E-optimal design: maximum eigenvalue of Hsse.",
                "Since the computation of the determinant and eigenvalues of a matrix is much more expensive than the computation of matrix trace, A-optimal design is more efficient than the other two.",
                "Some recent work on experimental design can be found in [6], [16]. 3.",
                "LAPLACIAN OPTIMAL DESIGN Since the covariance matrix Hsse used in traditional approaches is only dependent on the measured samples, i.e. zis, these approaches fail to evaluate the expected errors on the unmeasured samples.",
                "In this Section, we introduce a novel active learning algorithm called Laplacian Optimal Design (LOD) which makes efficient use of both measured (labeled) and unmeasured (unlabeled) samples. 3.1 The Objective Function In many machine learning problems, it is natural to assume that if two points xi, xj are sufficiently close to each other, then their measurements (f(xi), f(xj)) are close as well.",
                "Let S be a similarity matrix.",
                "Thus, a new loss function which respects the geometrical structure of the data space can be defined as follows: J0(w) = k i=1 f(zi)−yi 2 + λ 2 m i,j=1 f(xi)−f(xj) 2 Sij (3) where yi is the measurement (or, label) of zi.",
                "Note that, the loss function (3) is essentially the same as the one used in Laplacian Regularized Regression (LRR, [2]).",
                "However, LRR is a passive learning algorithm where the training data is given.",
                "In this paper, we are focused on how to select the most informative data for training.",
                "The loss function with our choice of symmetric weights Sij (Sij = Sji) incurs a heavy penalty if neighboring points xi and xj are mapped far apart.",
                "Therefore, minimizing J0(w) is an attempt to ensure that if xi and xj are close then f(xi) and f(xj) are close as well.",
                "There are many choices of the similarity matrix S. A simple definition is as follows: Sij = ⎧ ⎨ ⎩ 1, if xi is among the p nearest neighbors of xj, or xj is among the p nearest neighbors of xi; 0, otherwise. (4) Let D be a diagonal matrix, Dii = j Sij, and L = D−S.",
                "The matrix L is called graph Laplacian in spectral graph theory [3].",
                "Let y = (y1, · · · , yk)T and X = (x1, · · · , xm).",
                "Following some simple algebraic steps, we see that: J0(w) = k i=1 wT zi − yi 2 + λ 2 m i,j=1 wT xi − wT xj 2 Sij = y − ZT w T y − ZT w + λwT m i=1 DiixixT i − m i,j=1 SijxixT j w = yT y − 2wT Zy + wT ZZT w +λwT XDXT − XSXT w = yT y − 2wT Zy + wT ZZT + λXLXT w The Hessian of J0(w) can be computed as follows: H0 = ∂2 J0 ∂w2 = ZZT + λXLXT In some cases, the matrix ZZT +λXLXT is singular (e.g. if m < d).",
                "Thus, there is no stable solution to the optimization problem Eq. (3).",
                "A common way to deal with this ill-posed problem is to introduce a Tikhonov regularizer into our loss function: J(w) = k i=1 wT zi − yi 2 + λ1 2 m i,j=1 wT xi − wT xj 2 Sij +λ2 w 2 (5) The Hessian of the new loss function is given by: H = ∂2 J ∂w2 = ZZT + λ1XLXT + λ2I := ZZT + Λ where I is an identity matrix and Λ = λ1XLXT + λ2I.",
                "Clearly, H is of full rank.",
                "Requiring that the gradient of J(w) with respect to w vanish gives the optimal estimate ˆw: ˆw = H−1 Zy The following proposition states the bias and variance properties of the estimator for the coefficient vector w. Proposition 3.1.",
                "E( ˆw − w) = −H−1 Λw, Cov( ˆw) = σ2 (H−1 − H−1 ΛH−1 ) Proof.",
                "Since y = ZT w + and E( ) = 0, it follows that E( ˆw − w) (6) = H−1 ZZT w − w = H−1 (ZZT + Λ − Λ)w − w = (I − H−1 Λ)w − w = −H−1 Λw (7) Notice Cov(y) = σ2 I, the covariance matrix of ˆw has the expression: Cov( ˆw) = H−1 ZCov(y)ZT H−1 = σ2 H−1 ZZT H−1 = σ2 H−1 (H − Λ)H−1 = σ2 (H−1 − H−1 ΛH−1 ) (8) Therefore mean squared error matrix for the coefficients w is E(w − ˆw)(w − ˆw)T (9) = H−1 ΛwwT ΛH−1 + σ2 (H−1 − H−1 ΛH−1 ) (10) For any x, let ˆy = ˆwT x be its predicted observation.",
                "The expected squared prediction error is E(y − ˆy)2 = E( + wT x − ˆwT x)2 = σ2 + xT [E(w − ˆw)(w − ˆw)T ]x = σ2 + xT [H−1 ΛwwT ΛH−1 + σ2 H−1 − σ2 H−1 ΛH−1 ]x Clearly the expected square prediction error depends on the explanatory variable x, therefore average expected square predictive error over the complete data set A is 1 m m i=1 E(yi − ˆwT xi)2 = 1 m m i=1 xT i [H−1 ΛwwT ΛH−1 + σ2 H−1 − σ2 H−1 ΛH−1 ]xi +σ2 = 1 m Tr(XT [σ2 H−1 + H−1 ΛwwT ΛH−1 − σ2 H−1 ΛH−1 ]X) +σ2 Since Tr(XT [H−1 ΛwwT ΛH−1 − σ2 H−1 ΛH−1 ]X) Tr(σ2 XT H−1 X), Our Laplacian optimality criterion is thus formulated by minimizing the trace of XT H−1 X.",
                "Definition 1.",
                "Laplacian Optimal Design min Z=(z1,··· ,zk) Tr XT ZZT + λ1XLXT + λ2I −1 X (11) where z1, · · · , zk are selected from {x1, · · · , xm}. 4.",
                "KERNEL LAPLACIAN OPTIMAL DESIGN Canonical experimental design approaches (e.g.",
                "A-Optimal Design, D-Optimal Design, and E-Optimal) only consider linear functions.",
                "They fail to discover the intrinsic geometry in the data when the data space is highly nonlinear.",
                "In this section, we describe how to perform Laplacian Experimental Design in Reproducing Kernel Hilbert Space (RKHS) which gives rise to Kernel Laplacian Experimental Design (KLOD).",
                "For given data points x1, · · · , xm ∈ X with a positive definite mercer kernel K : X ×X → R, there exists a unique RKHS HK of real valued functions on X.",
                "Let Kt(s) be the function of s obtained by fixing t and letting Kt(s) . = K(s, t).",
                "HK consists of all finite linear combinations of the form l i=1 αiKti with ti ∈ X and limits of such functions as the ti become dense in X.",
                "We have Ks, Kt HK = K(s, t). 4.1 Derivation of LOD in Reproducing Kernel Hilbert Space Consider the optimization problem (5) in RKHS.",
                "Thus, we seek a function f ∈ HK such that the following objective function is minimized: min f∈HK k i=1 f(zi)−yi 2 + λ1 2 m i,j=1 f(xi)−f(xj) 2 Sij+λ2 f 2 HK (12) We have the following proposition.",
                "Proposition 4.1.",
                "Let H = { m i=1 αiK(·, xi)|αi ∈ R} be a subspace of HK , the solution to the problem (12) is in H. Proof.",
                "Let H⊥ be the orthogonal complement of H, i.e.",
                "HK = H ⊕ H⊥ .",
                "Thus, for any function f ∈ HK , it has orthogonal decomposition as follows: f = fH + fH⊥ Now, lets evaluate f at xi: f(xi) = f, Kxi HK = fH + fH⊥ , Kxi HK = fH, Kxi HK + fH⊥ , Kxi HK Notice that Kxi ∈ H while fH⊥ ∈ H⊥ .",
                "This implies that fH⊥ , Kxi HK = 0.",
                "Therefore, f(xi) = fH, Kxi HK = fH(xi) This completes the proof.",
                "Proposition 4.1 tells us the minimizer of problem (12) admits a representation f∗ = m i=1 αiK(·, xi).",
                "Please see [2] for the details.",
                "Let φ : Rd → H be a feature map from the input space Rd to H, and K(xi, xj) =< φ(xi), φ(xj) >.",
                "Let X denote the data matrix in RKHS, X = (φ(x1), φ(x2), · · · , φ(xm)).",
                "Similarly, we define Z = (φ(z1), φ(z2), · · · , φ(zk)).",
                "Thus, the optimization problem in RKHS can be written as follows: min Z Tr XT ZZT + λ1XLXT + λ2I −1 X (13) Since the mapping function φ is generally unknown, there is no direct way to solve problem (13).",
                "In the following, we apply kernel tricks to solve this optimization problem.",
                "Let X−1 be the Moore-Penrose inverse (also known as pseudo inverse) of X.",
                "Thus, we have: XT ZZT + λ1XLXT + λ2I −1 X = XT XX−1 ZZT + λ1XLXT + λ2I −1 (XT )−1 XT X = XT X ZZT X + λ1XLXT X + λ2X −1 (XT )−1 XT X = XT X XT ZZT X + λ1XT XLXT X + λ2XT X −1 XT X = KXX KXZKZX + λ1KXXLKXX + λ2KXX −1 KXX where KXX is a m × m matrix (KXX,ij = K(xi, xj)), KXZ is a m×k matrix (KXZ,ij = K(xi, zj)), and KZX is a k×m matrix (KZX,ij = K(zi, xj)).",
                "Thus, the Kernel Laplacian Optimal Design can be defined as follows: Definition 2.",
                "Kernel Laplacian Optimal Design minZ=(z1,··· ,zk) Tr KXX KXZKZX + λ1KXXLKXX λ2KXX −1 KXX (14) 4.2 Optimization Scheme In this subsection, we discuss how to solve the optimization problems (11) and (14).",
                "Particularly, if we select a linear kernel for KLOD, then it reduces to LOD.",
                "Therefore, we will focus on problem (14) in the following.",
                "It can be shown that the optimization problem (14) is NP-hard.",
                "In this subsection, we develop a simple sequential greedy approach to solve (14).",
                "Suppose n points have been selected, denoted by a matrix Zn = (z1, · · · , zn).",
                "The (n + 1)-th point zn+1 can be selected by solving the following optimization problem: max Zn+1=(Zn,zn+1) Tr KXX KXZn+1 KZn+1X + λ1KXXLKXX + λ2KXX −1 KXX (15) The kernel matrices KXZn+1 and KZn+1X can be rewritten as follows: KXZn+1 = KXZn , KXzn+1 , KZn+1X = KZnX Kzn+1X Thus, we have: KXZn+1 KZn+1X = KXZn KZnX + KXzn+1 Kzn+1X We define: A = KXZn KZnX + λ1KXXLKXX + λ2KXX A is only dependent on X and Zn .",
                "Thus, the (n + 1)-th point zn+1 is given by: zn+1 = arg min zn+1 Tr KXX A + KXzn+1 Kzn+1X −1 KXX (16) Each time we select a new point zn+1, the matrix A is updated by: A ← A + KXzn+1 Kzn+1X If the kernel function is chosen as inner product K(x, y) = x, y , then HK is a linear functional space and the algorithm reduces to LOD. 5.",
                "CONTENT-BASED IMAGE RETRIEVAL USING LAPLACIAN OPTIMAL DESIGN In this section, we describe how to apply Laplacian Optimal Design to CBIR.",
                "We begin with a brief description of image representation using low level visual features. 5.1 Low-Level Image Representation Low-level image representation is a crucial problem in CBIR.",
                "General visual features includes color, texture, shape, etc.",
                "Color and texture features are the most extensively used visual features in CBIR.",
                "Compared with color and texture features, shape features are usually described after images have been segmented into regions or objects.",
                "Since robust and accurate image segmentation is difficult to achieve, the use of shape features for image retrieval has been limited to special applications where objects or regions are readily available.",
                "In this work, We combine 64-dimensional color histogram and 64-dimensional Color Texture Moment (CTM, [15]) to represent the images.",
                "The color histogram is calculated using 4 × 4 × 4 bins in HSV space.",
                "The Color Texture Moment is proposed by Yu et al. [15], which integrates the color and texture characteristics of the image in a compact form.",
                "CTM adopts local Fourier transform as a texture representation scheme and derives eight characteristic maps to describe different aspects of co-occurrence relations of image pixels in each channel of the (SVcosH, SVsinH, V) color space.",
                "Then CTM calculates the first and second moment of these maps as a representation of the natural color image pixel distribution.",
                "Please see [15] for details. 5.2 Relevance Feedback Image Retrieval Relevance feedback is one of the most important techniques to narrow down the gap between low level visual features and high level semantic concepts [12].",
                "Traditionally, the users relevance feedbacks are used to update the query vector or adjust the weighting of different dimensions.",
                "This process can be viewed as an on-line learning process in which the image retrieval system acts as a learner and the user acts as a teacher.",
                "They typical retrieval process is outlined as follows: 1.",
                "The user submits a query image example to the system.",
                "The system ranks the images in database according to some pre-defined distance metric and presents to the user the top ranked images. 2.",
                "The system selects some images from the database and request the user to label them as relevant or irrelevant. 3.",
                "The system uses the users provided information to rerank the images in database and returns to the user the top images.",
                "Go to step 2 until the user is satisfied.",
                "Our Laplacian Optimal Design algorithm is applied in the second step for selecting the most informative images.",
                "Once we get the labels for the images selected by LOD, we apply Laplacian Regularized Regression (LRR, [2]) to solve the optimization problem (3) and build the classifier.",
                "The classifier is then used to re-rank the images in database.",
                "Note that, in order to reduce the computational complexity, we do not use all the unlabeled images in the database but only those within top 500 returns of previous iteration. 6.",
                "EXPERIMENTAL RESULTS In this section, we evaluate the performance of our proposed algorithm on a large image database.",
                "To demonstrate the effectiveness of our proposed LOD algorithm, we compare it with Laplacian Regularized Regression (LRR, [2]), Support Vector Machine (SVM), Support Vector Machine Active Learning (SVMactive) [14], and A-Optimal Design (AOD).",
                "Both SVMactive, AOD, and LOD are active learning algorithms, while LRR and SVM are standard classification algorithms.",
                "SVM only makes use of the labeled images, while LRR is a semi-supervised learning algorithm which makes use of both labeled and unlabeled images.",
                "For SVMactive, AOD, and LOD, 10 training images are selected by the algorithms themselves at each iteration.",
                "While for LRR and SVM, we use the top 10 images as training data.",
                "It would be important to note that SVMactive is based on the ordinary SVM, LOD is based on LRR, and AOD is based on the ordinary regression.",
                "The parameters λ1 and λ2 in our LOD algorithm are empirically set to be 0.001 and 0.00001.",
                "For both LRR and LOD algorithms, we use the same graph structure (see Eq. 4) and set the value of p (number of nearest neighbors) to be 5.",
                "We begin with a simple synthetic example to give some intuition about how LOD works. 6.1 Simple Synthetic Example A simple synthetic example is given in Figure 1.",
                "The data set contains two circles.",
                "Eight points are selected by AOD and LOD.",
                "As can be seen, all the points selected by AOD are from the big circle, while LOD selects four points from the big circle and four from the small circle.",
                "The numbers beside the selected points denote their orders to be selected.",
                "Clearly, the points selected by our LOD algorithm can better represent the original data set.",
                "We did not compare our algorithm with SVMactive because SVMactive can not be applied in this case due to the lack of the labeled points. 6.2 Image Retrieval Experimental Design The image database we used consists of 7,900 images of 79 semantic categories, from COREL data set.",
                "It is a large and heterogeneous image set.",
                "Each image is represented as a 128-dimensional vector as described in Section 5.1.",
                "Figure 2 shows some sample images.",
                "To exhibit the advantages of using our algorithm, we need a reliable way of evaluating the retrieval performance and the comparisons with other algorithms.",
                "We list different aspects of the experimental design below. 6.2.1 Evaluation Metrics We use precision-scope curve and precision rate [10] to evaluate the effectiveness of the image retrieval algorithms.",
                "The scope is specified by the number (N) of top-ranked images presented to the user.",
                "The precision is the ratio of the number of relevant images presented to the user to the (a) Data set 1 2 3 4 5 6 7 8 (b) AOD 1 2 3 4 5 6 7 8 (c) LOD Figure 1: Data selection by active learning algorithms.",
                "The numbers beside the selected points denote their orders to be selected.",
                "Clearly, the points selected by our LOD algorithm can better represent the original data set.",
                "Note that, the SVMactive algorithm can not be applied in this case due to the lack of labeled points. (a) (b) (c) Figure 2: Sample images from category bead, elephant, and ship. scope N. The precision-scope curve describes the precision with various scopes and thus gives an overall performance evaluation of the algorithms.",
                "On the other hand, the precision rate emphasizes the precision at a particular value of scope.",
                "In general, it is appropriate to present 20 images on a screen.",
                "Putting more images on a screen may affect the quality of the presented images.",
                "Therefore, the precision at top 20 (N = 20) is especially important.",
                "In real world image retrieval systems, the query image is usually not in the image database.",
                "To simulate such environment, we use five-fold cross validation to evaluate the algorithms.",
                "More precisely, we divide the whole image database into five subsets with equal size.",
                "Thus, there are 20 images per category in each subset.",
                "At each run of cross validation, one subset is selected as the query set, and the other four subsets are used as the database for retrieval.",
                "The precisionscope curve and precision rate are computed by averaging the results from the five-fold cross validation. 6.2.2 Automatic Relevance Feedback Scheme We designed an automatic feedback scheme to model the retrieval process.",
                "For each submitted query, our system retrieves and ranks the images in the database. 10 images were selected from the database for user labeling and the label information is used by the system for re-ranking.",
                "Note that, the images which have been selected at previous iterations are excluded from later selections.",
                "For each query, the automatic relevance feedback mechanism is performed for four iterations.",
                "It is important to note that the automatic relevance feedback scheme used here is different from the ones described in [8], [11].",
                "In [8], [11], the top four relevant and irrelevant images were selected as the feedback images.",
                "However, this may not be practical.",
                "In real world image retrieval systems, it is possible that most of the top-ranked images are relevant (or, irrelevant).",
                "Thus, it is difficult for the user to find both four relevant and irrelevant images.",
                "It is more reasonable for the users to provide feedback information only on the 10 images selected by the system. 6.3 Image Retrieval Performance In real world, it is not practical to require the user to provide many rounds of feedbacks.",
                "The retrieval performance after the first two rounds of feedbacks (especially the first round) is more important.",
                "Figure 3 shows the average precision-scope curves of the different algorithms for the first two feedback iterations.",
                "At the beginning of retrieval, the Euclidean distances in the original 128-dimensional space are used to rank the images in database.",
                "After the user provides relevance feedbacks, the LRR, SVM, SVMactive, AOD, and LOD algorithms are then applied to re-rank the images.",
                "In order to reduce the time complexity of active learning algorithms, we didnt select the most informative images from the whole database but from the top 500 images.",
                "For LRR and SVM, the user is required to label the top 10 images.",
                "For SVMactive, AOD, and LOD, the user is required to label 10 most informative images selected by these algorithms.",
                "Note that, SVMactive can only be ap(a) Feedback Iteration 1 (b) Feedback Iteration 2 Figure 3: The average precision-scope curves of different algorithms for the first two feedback iterations.",
                "The LOD algorithm performs the best on the entire scope.",
                "Note that, at the first round of feedback, the SVMactive algorithm can not be applied.",
                "It applies the ordinary SVM to build the initial classifier. (a) Precision at Top 10 (b) Precision at Top 20 (c) Precision at Top 30 Figure 4: Performance evaluation of the five learning algorithms for relevance feedback image retrieval. (a) Precision at top 10, (b) Precision at top 20, and (c) Precision at top 30.",
                "As can be seen, our LOD algorithm consistently outperforms the other four algorithms. plied when the classifier is already built.",
                "Therefore, it can not be applied at the first round and we use the standard SVM to build the initial classifier.",
                "As can be seen, our LOD algorithm outperforms the other four algorithms on the entire scope.",
                "Also, the LRR algorithm performs better than SVM.",
                "This is because that the LRR algorithm makes efficient use of the unlabeled images by incorporating a locality preserving regularizer into the ordinary regression objective function.",
                "The AOD algorithm performs the worst.",
                "As the scope gets larger, the performance difference between these algorithms gets smaller.",
                "By iteratively adding the users feedbacks, the corresponding precision results (at top 10, top 20, and top 30) of the five algorithms are respectively shown in Figure 4.",
                "As can be seen, our LOD algorithm performs the best in all the cases and the LRR algorithm performs the second best.",
                "Both of these two algorithms make use of the unlabeled images.",
                "This shows that the unlabeled images are helpful for discovering the <br>intrinsic geometrical structure</br> of the image space and therefore enhance the retrieval performance.",
                "In real world, the user may not be willing to provide too many relevance feedbacks.",
                "Therefore, the retrieval performance at the first two rounds are especially important.",
                "As can be seen, our LOD algorithm achieves 6.8% performance improvement for top 10 results, 5.2% for top 20 results, and 4.1% for top 30 results, comparing to the second best algorithm (LRR) after the first two rounds of relevance feedbacks. 6.4 Discussion Several experiments on Corel database have been systematically performed.",
                "We would like to highlight several interesting points: 1.",
                "It is clear that the use of active learning is beneficial in the image retrieval domain.",
                "There is a significant increase in performance from using the active learning methods.",
                "Especially, out of the three active learning methods (SVMactive, AOD, LOD), our proposed LOD algorithm performs the best. 2.",
                "In many real world applications like relevance feedback image retrieval, there are generally two ways of reducing labor-intensive manual labeling task.",
                "One is active learning which selects the most informative samples to label, and the other is semi-supervised learning which makes use of the unlabeled samples to enhance the learning performance.",
                "Both of these two strategies have been studied extensively in the past [14], [7], [5], [8].",
                "The work presented in this paper is focused on active learning, but it also takes advantage of the recent progresses on semi-supervised learning [2].",
                "Specifically, we incorporate a locality preserving regularizer into the standard regression framework and find the most informative samples with respect to the new objective function.",
                "In this way, the active learning and semi-supervised learning techniques are seamlessly unified for learning an optimal classifier. 3.",
                "The relevance feedback technique is crucial to image retrieval.",
                "For all the five algorithms, the retrieval performance improves with more feedbacks provided by the user. 7.",
                "CONCLUSIONS AND FUTURE WORK This paper describes a novel active learning algorithm, called Laplacian Optimal Design, to enable more effective relevance feedback image retrieval.",
                "Our algorithm is based on an objective function which simultaneously minimizes the empirical error and preserves the local geometrical structure of the data space.",
                "Using techniques from experimental design, our algorithm finds the most informative images to label.",
                "These labeled images and the unlabeled images in the database are used to learn a classifier.",
                "The experimental results on Corel database show that both active learning and semi-supervised learning can significantly improve the retrieval performance.",
                "In this paper, we consider the image retrieval problem on a small, static, and closed-domain image data.",
                "A much more challenging domain is the World Wide Web (WWW).",
                "For Web image search, it is possible to collect a large amount of user click information.",
                "This information can be naturally used to construct the affinity graph in our algorithm.",
                "However, the computational complexity in Web scenario may become a crucial issue.",
                "Also, although our primary interest in this paper is focused on relevance feedback image retrieval, our results may also be of interest to researchers in patten recognition and machine learning, especially when a large amount of data is available but only a limited samples can be labeled. 8.",
                "REFERENCES [1] A. C. Atkinson and A. N. Donev.",
                "Optimum Experimental Designs.",
                "Oxford University Press, 2002. [2] M. Belkin, P. Niyogi, and V. Sindhwani.",
                "Manifold regularization: A geometric framework for learning from examples.",
                "Journal of Machine Learning Research, 7:2399-2434, 2006. [3] F. R. K. Chung.",
                "Spectral Graph Theory, volume 92 of Regional Conference Series in Mathematics.",
                "AMS, 1997. [4] D. A. Cohn, Z. Ghahramani, and M. I. Jordan.",
                "Active learning with statistical models.",
                "Journal of Artificial Intelligence Research, 4:129-145, 1996. [5] A. Dong and B. Bhanu.",
                "A new semi-supervised em algorithm for image retrieval.",
                "In IEEE Conf. on Computer Vision and Pattern Recognition, Madison, WI, 2003. [6] P. Flaherty, M. I. Jordan, and A. P. Arkin.",
                "Robust design of biological experiments.",
                "In Advances in Neural Information Processing Systems 18, Vancouver, Canada, 2005. [7] K.-S. Goh, E. Y. Chang, and W.-C. Lai.",
                "Multimodal concept-dependent active learning for image retrieval.",
                "In Proceedings of the ACM Conference on Multimedia, New York, October 2004. [8] X.",
                "He.",
                "Incremental semi-supervised subspace learning for image retrieval.",
                "In Proceedings of the ACM Conference on Multimedia, New York, October 2004. [9] S. C. Hoi and M. R. Lyu.",
                "A semi-supervised active learning framework for image retrieval.",
                "In IEEE International Conference on Computer Vision and Pattern Recognition, San Diego, CA, 2005. [10] D. P. Huijsmans and N. Sebe.",
                "How to complete performance graphs in content-based image retrieval: Add generality and normalize scope.",
                "IEEE Transactions on Pattern Analysis and Machine Intelligence, 27(2):245-251, 2005. [11] Y.-Y.",
                "Lin, T.-L. Liu, and H.-T. Chen.",
                "Semantic manifold learning for image retrieval.",
                "In Proceedings of the ACM Conference on Multimedia, Singapore, November 2005. [12] Y. Rui, T. S. Huang, M. Ortega, and S. Mehrotra.",
                "Relevance feedback: A power tool for interative content-based image retrieval.",
                "IEEE Transactions on Circuits and Systems for Video Technology, 8(5), 1998. [13] A. W. Smeulders, M. Worring, S. Santini, A. Gupta, and R. Jain.",
                "Content-based image retrieval at the end of the early years.",
                "IEEE Transactions on Pattern Analysis and Machine Intelligence, 22(12):1349-1380, 2000. [14] S. Tong and E. Chang.",
                "Support vector machine active learning for image retrieval.",
                "In Proceedings of the ninth ACM international conference on Multimedia, pages 107-118, 2001. [15] H. Yu, M. Li, H.-J.",
                "Zhang, and J. Feng.",
                "Color texture moments for content-based image retrieval.",
                "In International Conference on Image Processing, pages 24-28, 2002. [16] K. Yu, J. Bi, and V. Tresp.",
                "Active learning via transductive experimental design.",
                "In Proceedings of the 23rd International Conference on Machine Learning, Pittsburgh, PA, 2006."
            ],
            "original_annotated_samples": [
                "This shows that the unlabeled images are helpful for discovering the <br>intrinsic geometrical structure</br> of the image space and therefore enhance the retrieval performance."
            ],
            "translated_annotated_samples": [
                "Esto demuestra que las imágenes sin etiquetar son útiles para descubrir la <br>estructura geométrica intrínseca</br> del espacio de imágenes y, por lo tanto, mejorar el rendimiento de recuperación."
            ],
            "translated_text": "Diseño óptimo de Laplaciano para la recuperación de imágenes Xiaofei He Yahoo! El feedback de relevancia es una técnica poderosa para mejorar el rendimiento de la Recuperación de Imágenes Basada en Contenido (CBIR). Solicita las valoraciones de relevancia de los usuarios sobre las imágenes recuperadas por los sistemas CBIR. La etiqueta de los usuarios se utiliza luego para entrenar un clasificador que distinga entre imágenes relevantes e irrelevantes. Sin embargo, las imágenes principales que se devuelven pueden no ser las más informativas. El desafío consiste en determinar qué imágenes sin etiquetar serían las más informativas (es decir, mejorarían más al clasificador) si fueran etiquetadas y utilizadas como muestras de entrenamiento. En este artículo, proponemos un novedoso algoritmo de aprendizaje activo, llamado Diseño Óptimo Laplaciano (LOD), para la recuperación de imágenes con retroalimentación de relevancia. Nuestro algoritmo se basa en un modelo de regresión que minimiza el error cuadrático mínimo en las imágenes medidas (o etiquetadas) y al mismo tiempo preserva la estructura geométrica local del espacio de la imagen. Específicamente, asumimos que si dos imágenes están lo suficientemente cerca una de la otra, entonces sus medidas (o etiquetas) también son cercanas. Al construir un grafo de vecinos más cercanos, la estructura geométrica del espacio de la imagen puede ser descrita por el Laplaciano del grafo. Discutimos cómo los resultados del campo del diseño experimental óptimo pueden ser utilizados para guiar nuestra selección de un subconjunto de imágenes, que nos proporciona la mayor cantidad de información. Los resultados experimentales en la base de datos Corel sugieren que el enfoque propuesto logra una mayor precisión en la recuperación de imágenes con retroalimentación de relevancia. Categorías y Descriptores de Asignaturas H.3.3 [Almacenamiento y recuperación de información]: Búsqueda y recuperación de información-Retroalimentación de relevancia; G.3 [Matemáticas de la Computación]: Probabilidad y Estadística-Diseño experimental Términos Generales Algoritmos, Rendimiento, Teoría 1. INTRODUCCIÓN En muchas tareas de aprendizaje automático y recuperación de información, no hay escasez de datos no etiquetados pero las etiquetas son costosas. El desafío consiste en determinar qué muestras sin etiquetar serían las más informativas (es decir, mejorarían más el clasificador) si fueran etiquetadas y utilizadas como muestras de entrenamiento. Este problema se llama típicamente aprendizaje activo [4]. Aquí la tarea es minimizar un costo general, que depende tanto de la precisión del clasificador como del costo de la recolección de datos. Muchas aplicaciones del mundo real pueden ser adaptadas al marco de aprendizaje activo. Particularmente, consideramos el problema de la recuperación de imágenes basada en contenido impulsada por la retroalimentación de relevancia (CBIR) [13]. La Recuperación de Imágenes Basada en Contenido ha atraído un interés sustancial en la última década [13]. Está motivado por el rápido crecimiento de las bases de datos de imágenes digitales que, a su vez, requieren esquemas de búsqueda eficientes. En lugar de describir una imagen usando texto, en estos sistemas se describe una consulta de imagen utilizando una o más imágenes de ejemplo. Las características visuales de bajo nivel (color, textura, forma, etc.) se extraen automáticamente para representar las imágenes. Sin embargo, las características de bajo nivel pueden no caracterizar con precisión los conceptos semánticos de alto nivel. Para reducir la brecha semántica, se introduce la retroalimentación de relevancia en la recuperación de información basada en el contenido (CBIR) [12]. En muchos de los sistemas actuales de recuperación de imágenes basados en retroalimentación de relevancia, se requiere que el usuario proporcione sus juicios de relevancia sobre las imágenes principales devueltas por el sistema. Las imágenes etiquetadas se utilizan luego para entrenar un clasificador que separe las imágenes que coinciden con el concepto de la consulta de aquellas que no lo hacen. Sin embargo, en general, las imágenes principales que se devuelven pueden no ser las más informativas. En el peor de los casos, todas las imágenes principales etiquetadas por el usuario pueden ser positivas y, por lo tanto, las técnicas estándar de clasificación no pueden aplicarse debido a la falta de ejemplos negativos. A diferencia de los problemas de clasificación estándar donde las muestras etiquetadas están predefinidas, en la recuperación de imágenes con retroalimentación de relevancia, el sistema puede seleccionar activamente las imágenes a etiquetar. Por lo tanto, el aprendizaje activo puede ser introducido de forma natural en la recuperación de imágenes. A pesar de la existencia de muchas técnicas de aprendizaje activo, el aprendizaje activo de Máquina de Vectores de Soporte (SVM) [14] y el aprendizaje activo basado en regresión [1] han sido los que han despertado mayor interés. Basado en la observación de que cuanto más cerca del límite del SVM se encuentre una imagen, menos confiable es su clasificación, el aprendizaje activo del SVM selecciona aquellas imágenes no etiquetadas más cercanas al límite para solicitar retroalimentación del usuario con el fin de lograr un refinamiento máximo en el hiperplano entre las dos clases. La principal desventaja del aprendizaje activo de SVM es que es posible que el límite estimado no sea lo suficientemente preciso. Además, puede que no se aplique al principio de la recuperación cuando no hay imágenes etiquetadas. Algunos otros algoritmos de aprendizaje activo basados en SVM se pueden encontrar en [7], [9]. En estadística, el problema de seleccionar muestras para etiquetar se conoce típicamente como diseño experimental. La muestra x se denomina experimento, y su etiqueta y se denomina medición. El estudio del diseño experimental óptimo (DEO) se preocupa por el diseño de experimentos que se espera que minimicen las varianzas de un modelo parametrizado. La intención del diseño experimental óptimo suele ser maximizar la confianza en un modelo dado, minimizar las varianzas de los parámetros para la identificación del sistema, o minimizar la varianza de la salida de los modelos. Los enfoques clásicos de diseño experimental incluyen el Diseño A-Óptimo, el Diseño D-Óptimo y el Diseño E-Óptimo. Todos estos enfoques se basan en un modelo de regresión de mínimos cuadrados. En comparación con los algoritmos de aprendizaje activo basados en SVM, los enfoques de diseño experimental son mucho más eficientes en términos de computación. Sin embargo, este tipo de enfoques solo tienen en cuenta los datos medidos (o etiquetados) en su función objetivo, mientras que los datos no medidos (o no etiquetados) son ignorados. Beneficiar de los avances recientes en diseño experimental óptimo y aprendizaje semisupervisado, en este artículo proponemos un nuevo algoritmo de aprendizaje activo para recuperación de imágenes, llamado Diseño Óptimo Laplaciano (LOD). A diferencia de los métodos tradicionales de diseño experimental cuyas funciones de pérdida solo están definidas en los puntos medidos, la función de pérdida de nuestro algoritmo propuesto LOD está definida tanto en los puntos medidos como en los no medidos. Específicamente, introducimos un regularizador que preserva la localidad en la función de pérdida estándar basada en el error cuadrático mínimo. La nueva función de pérdida tiene como objetivo encontrar un clasificador que sea localmente lo más suave posible. En otras palabras, si dos puntos están suficientemente cerca uno del otro en el espacio de entrada, se espera que compartan la misma etiqueta. Una vez que se define la función de pérdida, podemos seleccionar los puntos de datos más informativos que se presentan al usuario para su etiquetado. Sería importante tener en cuenta que las imágenes más informativas pueden no ser las primeras imágenes devueltas. El resto del documento está organizado de la siguiente manera. En la Sección 2, proporcionamos una breve descripción del trabajo relacionado. Nuestro algoritmo propuesto de Diseño Óptimo de Laplaciano se introduce en la Sección 3. En la Sección 4, comparamos nuestro algoritmo con los algoritmos de última generación y presentamos los resultados experimentales sobre la recuperación de imágenes. Finalmente, proporcionamos algunas observaciones finales y sugerencias para trabajos futuros en la Sección 5.2. TRABAJO RELACIONADO Dado que nuestro algoritmo propuesto se basa en un marco de regresión. El trabajo más relacionado es el diseño experimental óptimo [1], que incluye el Diseño A-Óptimo, el Diseño D-Óptimo y el Diseño E-Óptimo. En esta sección, damos una breve descripción de estos enfoques. 2.1 El Problema del Aprendizaje Activo El problema genérico del aprendizaje activo es el siguiente. Dado un conjunto de puntos A = {x1, x2, · · · , xm} en Rd , encuentra un subconjunto B = {z1, z2, · · · , zk} ⊂ A que contenga los puntos más informativos. En otras palabras, los puntos zi(i = 1, · · · , k) pueden mejorar el clasificador al máximo si están etiquetados y se utilizan como puntos de entrenamiento. 2.2 Diseño Experimental Óptimo Consideramos un modelo de regresión lineal y = wT x + (1) donde y es la observación, x es la variable independiente, w es el vector de pesos y es un error desconocido con media cero. Diferentes observaciones tienen errores que son independientes, pero con varianzas iguales σ2. Definimos f(x) = wT x como la salida del aprendiz dada la entrada x y el vector de pesos w. Supongamos que tenemos un conjunto de puntos de muestra etiquetados (z1, y1), · · · , (zk, yk), donde yi es la etiqueta de zi. Por lo tanto, la estimación de máxima verosimilitud para el vector de peso, ˆw, es aquella que minimiza la suma del error cuadrado Jsse(w) = k i=1 wT zi − yi 2 (2). La estimación ˆw nos proporciona una estimación de la salida en una entrada novedosa: ˆy = ˆwT x. Según el teorema de Gauss-Markov, sabemos que ˆw − w tiene una media cero y una matriz de covarianza dada por σ2 H−1 sse, donde Hsse es la Hessiana de Jsse(w) Hsse = ∂2 Jsse ∂w2 = k i=1 zizT i = ZZT donde Z = (z1, z2, · · · , zk). Las tres medidas escalares más comunes del tamaño de la matriz de covarianza de parámetros en el diseño experimental óptimo son: • Diseño D-óptimo: determinante de Hsse. • Diseño A-óptimo: traza de Hsse. • Diseño E-óptimo: valor propio máximo de Hsse. Dado que el cálculo del determinante y los valores propios de una matriz es mucho más costoso que el cálculo de la traza de la matriz, el diseño A-óptimo es más eficiente que los otros dos. Algunos trabajos recientes sobre diseño experimental se pueden encontrar en [6], [16]. DISEÑO ÓPTIMO LAPLACIANO Dado que la matriz de covarianza Hsse utilizada en enfoques tradicionales solo depende de las muestras medidas, es decir, zis, estos enfoques no logran evaluar los errores esperados en las muestras no medidas. En esta sección, presentamos un novedoso algoritmo de aprendizaje activo llamado Diseño Óptimo Laplaciano (LOD) que hace un uso eficiente tanto de muestras medidas (etiquetadas) como no medidas (sin etiquetar). 3.1 La Función Objetivo En muchos problemas de aprendizaje automático, es natural asumir que si dos puntos xi, xj están suficientemente cerca uno del otro, entonces sus mediciones (f(xi), f(xj)) también son cercanas. Sea S una matriz de similitud. Por lo tanto, una nueva función de pérdida que respeta la estructura geométrica del espacio de datos se puede definir de la siguiente manera: J0(w) = k i=1 f(zi)−yi 2 + λ 2 m i,j=1 f(xi)−f(xj) 2 Sij (3) donde yi es la medición (o etiqueta) de zi. Se debe tener en cuenta que la función de pérdida (3) es esencialmente la misma que la utilizada en la Regresión Regularizada Laplaciana (LRR, [2]). Sin embargo, LRR es un algoritmo de aprendizaje pasivo donde se proporcionan los datos de entrenamiento. En este artículo, nos enfocamos en cómo seleccionar los datos más informativos para el entrenamiento. La función de pérdida con nuestra elección de pesos simétricos Sij (Sij = Sji) incurre en una penalización severa si los puntos vecinos xi y xj se asignan lejos uno del otro. Por lo tanto, minimizar J0(w) es un intento de asegurar que si xi y xj están cerca, entonces f(xi) y f(xj) también estén cerca. Hay muchas opciones de la matriz de similitud S. Una definición simple es la siguiente: Sij = ⎧ ⎨ ⎩ 1, si xi está entre los p vecinos más cercanos de xj, o xj está entre los p vecinos más cercanos de xi; 0, en otro caso. (4) Sea D una matriz diagonal, Dii = j Sij, y L = D−S. La matriz L se llama Laplaciano de grafo en la teoría espectral de grafos [3]. Sea y = (y1, · · · , yk)T y X = (x1, · · · , xm). Siguiendo algunos pasos algebraicos simples, vemos que: J0(w) = k i=1 wT zi − yi 2 + λ 2 m i,j=1 wT xi − wT xj 2 Sij = y − ZT w T y − ZT w + λwT m i=1 DiixixT i − m i,j=1 SijxixT j w = yT y − 2wT Zy + wT ZZT w +λwT m i=1 DiixixT i − m i,j=1 SijxixT j w = yT y − 2wT Zy + wT ZZT + λXLXT w La Hessiana de J0(w) se puede calcular de la siguiente manera: H0 = ∂2 J0 ∂w2 = ZZT + λXLXT En algunos casos, la matriz ZZT +λXLXT es singular (por ejemplo, si m < d). Por lo tanto, no hay una solución estable para el problema de optimización Ec. (3). Una forma común de abordar este problema mal planteado es introducir un regularizador de Tikhonov en nuestra función de pérdida: J(w) = k i=1 wT zi − yi 2 + λ1 2 m i,j=1 wT xi − wT xj 2 Sij +λ2 w 2 (5) El Hessiano de la nueva función de pérdida está dado por: H = ∂2 J ∂w2 = ZZT + λ1XLXT + λ2I := ZZT + Λ donde I es una matriz identidad y Λ = λ1XLXT + λ2I. Claramente, H tiene rango completo. Exigir que el gradiente de J(w) con respecto a w se anule proporciona la estimación óptima ˆw: ˆw = H−1 Zy. La siguiente proposición establece las propiedades de sesgo y varianza del estimador para el vector de coeficientes w. Proposición 3.1. E( ˆw − w) = −H−1 Λw, Cov( ˆw) = σ2 (H−1 − H−1 ΛH−1 ) Demostración. Dado que y = ZTw + y E( ) = 0, se deduce que E( ˆw − w) (6) = H−1 ZZTw − w = H−1 (ZZT + Λ − Λ)w − w = (I − H−1 Λ)w − w = −H−1 Λw (7) Nótese que Cov(y) = σ2 I, la matriz de covarianza de ˆw tiene la expresión: Cov( ˆw) = H−1 ZCov(y)ZT H−1 = σ2 H−1 ZZT H−1 = σ2 H−1 (H − Λ)H−1 = σ2 (H−1 − H−1 ΛH−1 ) (8) Por lo tanto, la matriz de error cuadrático medio para los coeficientes w es E(w − ˆw)(w − ˆw)T (9) = H−1 ΛwwT ΛH−1 + σ2 (H−1 − H−1 ΛH−1 ) (10) Para cualquier x, sea ˆy = ˆwT x su observación predicha. El error cuadrático de predicción esperado es E(y − ˆy)2 = E( + wT x − ˆwT x)2 = σ2 + xT [E(w − ˆw)(w − ˆw)T ]x = σ2 + xT [H−1 ΛwwT ΛH−1 + σ2 H−1 − σ2 H−1 ΛH−1 ]x Claramente, el error cuadrático de predicción esperado depende de la variable explicativa x, por lo tanto, el error cuadrático de predicción promedio esperado sobre el conjunto de datos completo A es 1 m m i=1 E(yi − ˆwT xi)2 = 1 m m i=1 xT i [H−1 ΛwwT ΛH−1 + σ2 H−1 − σ2 H−1 ΛH−1 ]xi +σ2 = 1 m Tr(XT [σ2 H−1 + H−1 ΛwwT ΛH−1 − σ2 H−1 ΛH−1 ]X) +σ2 Dado que Tr(XT [H−1 ΛwwT ΛH−1 − σ2 H−1 ΛH−1 ]X) Tr(σ2 XT H−1 X), nuestro criterio de optimalidad laplaciano se formula minimizando la traza de XT H−1 X. Definición 1. Diseño óptimo de Laplaciano min Z=(z1,··· ,zk) Tr XT ZZT + λ1XLXT + λ2I −1 X (11) donde z1, · · · , zk son seleccionados de {x1, · · · , xm}. 4. DISEÑO ÓPTIMO DEL NÚCLEO LAPLACIANO Enfoques canónicos de diseño experimental (por ejemplo, Los diseños A-óptimos, D-óptimos y E-óptimos solo consideran funciones lineales. No logran descubrir la geometría intrínseca en los datos cuando el espacio de datos es altamente no lineal. En esta sección, describimos cómo realizar el Diseño Experimental Laplaciano en el Espacio de Hilbert de Núcleos Reproductores (RKHS), lo que da lugar al Diseño Experimental Laplaciano de Núcleo (KLOD). Para los puntos de datos dados x1, · · · , xm ∈ X con un núcleo de Mercer positivo definido K : X ×X → R, existe un único RKHS HK de funciones de valores reales en X. Sea Kt(s) la función de s obtenida al fijar t y dejar que Kt(s) = K(s, t). HK consiste en todas las combinaciones lineales finitas de la forma ∑ i=1 αiKti con ti ∈ X y los límites de tales funciones a medida que los ti se vuelven densos en X. Tenemos Ks, Kt HK = K(s, t). 4.1 Derivación de LOD en el Espacio de Hilbert del Núcleo Reproductor. Considera el problema de optimización (5) en RKHS. Por lo tanto, buscamos una función f ∈ HK tal que se minimice la siguiente función objetivo: min f∈HK k i=1 f(zi)−yi 2 + λ1 2 m i,j=1 f(xi)−f(xj) 2 Sij+λ2 f 2 HK (12). Tenemos la siguiente proposición. Proposición 4.1. Sea H = { m i=1 αiK(·, xi)|αi ∈ R} un subespacio de HK, la solución al problema (12) está en H. Demostración. Sea H⊥ el complemento ortogonal de H, es decir, HK = H ⊕ H⊥. Por lo tanto, para cualquier función f ∈ HK, tiene una descomposición ortogonal de la siguiente manera: f = fH + fH⊥ Ahora, evaluemos f en xi: f(xi) = f, Kxi HK = fH + fH⊥ , Kxi HK = fH, Kxi HK + fH⊥ , Kxi HK Observa que Kxi ∈ H mientras que fH⊥ ∈ H⊥. Esto implica que fH⊥ , Kxi HK = 0. Por lo tanto, f(xi) = fH, Kxi HK = fH(xi). Esto completa la prueba. La Proposición 4.1 nos dice que el minimizador del problema (12) admite una representación f∗ = m i=1 αiK(·, xi). Por favor, consulte [2] para ver los detalles. Sea φ : Rd → H un mapeo de características del espacio de entrada Rd a H, y K(xi, xj) =< φ(xi), φ(xj) >. Que X denote la matriz de datos en RKHS, X = (φ(x1), φ(x2), · · · , φ(xm)). De manera similar, definimos Z = (φ(z1), φ(z2), · · · , φ(zk)). Por lo tanto, el problema de optimización en RKHS se puede escribir de la siguiente manera: min Z Tr XT ZZT + λ1XLXT + λ2I −1 X (13) Dado que la función de mapeo φ generalmente es desconocida, no hay una forma directa de resolver el problema (13). En lo siguiente, aplicamos trucos de kernel para resolver este problema de optimización. Sea X−1 la inversa de Moore-Penrose (también conocida como pseudoinversa) de X. Así, tenemos: XT ZZT + λ1XLXT + λ2I −1 X = XT XX−1 ZZT + λ1XLXT + λ2I −1 (XT )−1 XT X = XT X ZZT X + λ1XLXT X + λ2X −1 (XT )−1 XT X = XT X XT ZZT X + λ1XT XLXT X + λ2XT X −1 XT X = KXX KXZKZX + λ1KXXLKXX + λ2KXX −1 KXX donde KXX es una matriz m × m (KXX,ij = K(xi, xj)), KXZ es una matriz m×k (KXZ,ij = K(xi, zj)), y KZX es una matriz k×m (KZX,ij = K(zi, xj)). Por lo tanto, el Diseño Óptimo del Laplaciano del Núcleo se puede definir de la siguiente manera: Definición 2. En este subapartado, discutimos cómo resolver los problemas de optimización (11) y (14). Particularmente, si seleccionamos un núcleo lineal para KLOD, entonces se reduce a LOD. Por lo tanto, nos enfocaremos en el problema (14) a continuación. Se puede demostrar que el problema de optimización (14) es NP-duro. En esta subsección, desarrollamos un enfoque codicioso secuencial simple para resolver (14). Supongamos que se han seleccionado n puntos, denotados por una matriz Zn = (z1, · · · , zn). El punto (n + 1)-ésimo zn+1 puede ser seleccionado resolviendo el siguiente problema de optimización: max Zn+1=(Zn,zn+1) Tr KXX KXZn+1 KZn+1X + λ1KXXLKXX + λ2KXX −1 KXX (15) Las matrices de kernel KXZn+1 y KZn+1X pueden ser reescritas de la siguiente manera: KXZn+1 = KXZn , KXzn+1 , KZn+1X = KZnX Kzn+1X Por lo tanto, tenemos: KXZn+1 KZn+1X = KXZn KZnX + KXzn+1 Kzn+1X Definimos: A = KXZn KZnX + λ1KXXLKXX + λ2KXX A solo depende de X y Zn. Por lo tanto, el punto (n + 1)-ésimo zn+1 se da por: zn+1 = arg min zn+1 Tr KXX A + KXzn+1 Kzn+1X −1 KXX. Cada vez que seleccionamos un nuevo punto zn+1, la matriz A se actualiza por: A ← A + KXzn+1 Kzn+1X. Si la función de kernel se elige como producto interno K(x, y) = x, y, entonces HK es un espacio funcional lineal y el algoritmo se reduce a LOD. 5. RECUPERACIÓN DE IMÁGENES BASADA EN CONTENIDO UTILIZANDO DISEÑO ÓPTIMO LAPLACIANO En esta sección, describimos cómo aplicar el Diseño Óptimo Laplaciano a la RCIB. Comenzamos con una breve descripción de la representación de imágenes utilizando características visuales de nivel bajo. 5.1 Representación de Imágenes de Nivel Bajo La representación de imágenes de nivel bajo es un problema crucial en la Recuperación de Información Basada en el Contenido (CBIR). Las características visuales generales incluyen color, textura, forma, etc. Las características de color y textura son las características visuales más ampliamente utilizadas en la recuperación de información basada en contenido (CBIR). En comparación con las características de color y textura, las características de forma suelen describirse después de que las imágenes hayan sido segmentadas en regiones u objetos. Dado que la segmentación de imágenes robusta y precisa es difícil de lograr, el uso de características de forma para la recuperación de imágenes se ha limitado a aplicaciones especiales donde los objetos o regiones están fácilmente disponibles. En este trabajo, combinamos un histograma de color de 64 dimensiones y un Momento de Textura de Color (CTM, [15]) de 64 dimensiones para representar las imágenes. El histograma de color se calcula utilizando 4 × 4 × 4 contenedores en el espacio HSV. El Momento de Textura de Color es propuesto por Yu et al. [15], el cual integra las características de color y textura de la imagen en una forma compacta. CTM adopta la transformada de Fourier local como un esquema de representación de texturas y deriva ocho mapas característicos para describir diferentes aspectos de las relaciones de co-ocurrencia de píxeles de imagen en cada canal del espacio de color (SVcosH, SVsinH, V). Entonces, CTM calcula el primer y segundo momento de estos mapas como una representación de la distribución de píxeles de la imagen en color natural. Por favor, consulte [15] para más detalles. 5.2 Recuperación de imágenes con retroalimentación de relevancia La retroalimentación de relevancia es una de las técnicas más importantes para reducir la brecha entre las características visuales de bajo nivel y los conceptos semánticos de alto nivel [12]. Tradicionalmente, los comentarios de relevancia de los usuarios se utilizan para actualizar el vector de consulta o ajustar el peso de las diferentes dimensiones. Este proceso puede ser visto como un proceso de aprendizaje en línea en el que el sistema de recuperación de imágenes actúa como un aprendiz y el usuario actúa como un maestro. El proceso típico de recuperación se describe de la siguiente manera: 1. El usuario envía un ejemplo de imagen de consulta al sistema. El sistema clasifica las imágenes en la base de datos según alguna métrica de distancia predefinida y presenta al usuario las imágenes mejor clasificadas. El sistema selecciona algunas imágenes de la base de datos y solicita al usuario que las etiquete como relevantes o irrelevantes. El sistema utiliza la información proporcionada por los usuarios para reorganizar las imágenes en la base de datos y devolver al usuario las imágenes principales. Ve al paso 2 hasta que el usuario esté satisfecho. Nuestro algoritmo de Diseño Óptimo de Laplaciano se aplica en el segundo paso para seleccionar las imágenes más informativas. Una vez que obtenemos las etiquetas para las imágenes seleccionadas por LOD, aplicamos la Regresión Regularizada Laplaciana (LRR, [2]) para resolver el problema de optimización (3) y construir el clasificador. El clasificador se utiliza luego para reordenar las imágenes en la base de datos. Ten en cuenta que, para reducir la complejidad computacional, no utilizamos todas las imágenes sin etiquetar en la base de datos, sino solo aquellas dentro de los 500 primeros resultados de la iteración anterior. 6. RESULTADOS EXPERIMENTALES En esta sección, evaluamos el rendimiento de nuestro algoritmo propuesto en una gran base de datos de imágenes. Para demostrar la efectividad de nuestro algoritmo LOD propuesto, lo comparamos con la Regresión Regularizada de Laplaciano (LRR, [2]), la Máquina de Vectores de Soporte (SVM), el Aprendizaje Activo de Máquina de Vectores de Soporte (SVMactive) [14], y el Diseño A-Óptimo (AOD). Tanto SVMactive, AOD y LOD son algoritmos de aprendizaje activo, mientras que LRR y SVM son algoritmos de clasificación estándar. SVM solo hace uso de las imágenes etiquetadas, mientras que LRR es un algoritmo de aprendizaje semi-supervisado que hace uso tanto de imágenes etiquetadas como no etiquetadas. Para SVMactive, AOD y LOD, los algoritmos seleccionan 10 imágenes de entrenamiento en cada iteración. Para LRR y SVM, utilizamos las 10 imágenes principales como datos de entrenamiento. Sería importante señalar que SVMactive se basa en el SVM ordinario, LOD se basa en LRR y AOD se basa en la regresión ordinaria. Los parámetros λ1 y λ2 en nuestro algoritmo LOD se establecen empíricamente en 0.001 y 0.00001. Para ambos algoritmos LRR y LOD, utilizamos la misma estructura de grafo (ver Ecuación 4) y establecemos el valor de p (número de vecinos más cercanos) en 5. Comenzamos con un ejemplo sintético simple para dar una intuición sobre cómo funciona LOD. 6.1 Ejemplo Sintético Simple Se presenta un ejemplo sintético simple en la Figura 1. El conjunto de datos contiene dos círculos. Ocho puntos son seleccionados por AOD y LOD. Como se puede ver, todos los puntos seleccionados por AOD son del círculo grande, mientras que LOD selecciona cuatro puntos del círculo grande y cuatro del círculo pequeño. Los números junto a los puntos seleccionados indican su orden de selección. Claramente, los puntos seleccionados por nuestro algoritmo LOD pueden representar mejor el conjunto de datos original. No comparamos nuestro algoritmo con SVMactive porque SVMactive no se puede aplicar en este caso debido a la falta de puntos etiquetados. 6.2 Diseño Experimental de Recuperación de Imágenes La base de datos de imágenes que utilizamos consta de 7,900 imágenes de 79 categorías semánticas, del conjunto de datos COREL. Es un conjunto de imágenes grande y heterogéneo. Cada imagen se representa como un vector de 128 dimensiones según se describe en la Sección 5.1. La Figura 2 muestra algunas imágenes de muestra. Para exhibir las ventajas de usar nuestro algoritmo, necesitamos una forma confiable de evaluar el rendimiento de recuperación y las comparaciones con otros algoritmos. Listamos a continuación diferentes aspectos del diseño experimental. 6.2.1 Métricas de Evaluación Utilizamos la curva de precisión-alcance y la tasa de precisión [10] para evaluar la efectividad de los algoritmos de recuperación de imágenes. El alcance está especificado por el número (N) de imágenes mejor clasificadas presentadas al usuario. La precisión es la proporción entre el número de imágenes relevantes presentadas al usuario y el (a) Conjunto de datos 1 2 3 4 5 6 7 8 (b) AOD 1 2 3 4 5 6 7 8 (c) LOD Figura 1: Selección de datos por algoritmos de aprendizaje activo. Los números junto a los puntos seleccionados indican su orden de selección. Claramente, los puntos seleccionados por nuestro algoritmo LOD pueden representar mejor el conjunto de datos original. Se debe tener en cuenta que el algoritmo SVMactive no se puede aplicar en este caso debido a la falta de puntos etiquetados. (a) (b) (c) Figura 2: Imágenes de muestra de las categorías cuentas, elefante y barco. El alcance de precisión describe la precisión con varios alcances y, por lo tanto, proporciona una evaluación general del rendimiento de los algoritmos. Por otro lado, la tasa de precisión enfatiza la precisión en un valor particular de alcance. En general, es apropiado presentar 20 imágenes en una pantalla. Agregar más imágenes en una pantalla puede afectar la calidad de las imágenes presentadas. Por lo tanto, la precisión en los primeros 20 (N = 20) es especialmente importante. En los sistemas de recuperación de imágenes del mundo real, la imagen de consulta generalmente no se encuentra en la base de datos de imágenes. Para simular dicho entorno, utilizamos validación cruzada de cinco pliegues para evaluar los algoritmos. Más precisamente, dividimos toda la base de datos de imágenes en cinco subconjuntos de tamaño igual. Por lo tanto, hay 20 imágenes por categoría en cada subconjunto. En cada ejecución de validación cruzada, se selecciona un subconjunto como conjunto de consulta, y los otros cuatro subconjuntos se utilizan como base de datos para la recuperación. La curva de precisión del precisionscope y la tasa de precisión se calculan promediando los resultados de la validación cruzada de cinco pliegues. 6.2.2 Esquema de retroalimentación automática de relevancia Diseñamos un esquema de retroalimentación automática para modelar el proceso de recuperación. Para cada consulta enviada, nuestro sistema recupera y clasifica las imágenes en la base de datos. Se seleccionaron 10 imágenes de la base de datos para que los usuarios las etiqueten y la información de las etiquetas es utilizada por el sistema para volver a clasificarlas. Ten en cuenta que las imágenes seleccionadas en iteraciones anteriores están excluidas de selecciones posteriores. Para cada consulta, se realiza el mecanismo de retroalimentación automática de relevancia durante cuatro iteraciones. Es importante señalar que el esquema de retroalimentación automática de relevancia utilizado aquí es diferente de los descritos en [8], [11]. En [8], [11], las cuatro imágenes relevantes e irrelevantes principales fueron seleccionadas como las imágenes de retroalimentación. Sin embargo, esto puede no ser práctico. En los sistemas de recuperación de imágenes del mundo real, es posible que la mayoría de las imágenes mejor clasificadas sean relevantes (o irrelevantes). Por lo tanto, es difícil para el usuario encontrar tanto cuatro imágenes relevantes como irrelevantes. Es más razonable que los usuarios proporcionen información de retroalimentación solo sobre las 10 imágenes seleccionadas por el sistema. 6.3 Rendimiento de recuperación de imágenes En el mundo real, no es práctico requerir que el usuario proporcione muchas rondas de retroalimentación. El rendimiento de recuperación después de las dos primeras rondas de retroalimentación (especialmente la primera ronda) es más importante. La Figura 3 muestra las curvas de precisión-alcance promedio de los diferentes algoritmos para las dos primeras iteraciones de retroalimentación. Al principio de la recuperación, las distancias euclidianas en el espacio original de 128 dimensiones se utilizan para clasificar las imágenes en la base de datos. Después de que el usuario proporcione retroalimentación de relevancia, se aplican los algoritmos LRR, SVM, SVMactive, AOD y LOD para volver a clasificar las imágenes. Para reducir la complejidad temporal de los algoritmos de aprendizaje activo, no seleccionamos las imágenes más informativas de toda la base de datos, sino de las 500 imágenes principales. Para LRR y SVM, se requiere que el usuario etiquete las 10 imágenes principales. Para SVMactive, AOD y LOD, se requiere que el usuario etiquete las 10 imágenes más informativas seleccionadas por estos algoritmos. Tenga en cuenta que, SVMactive solo puede ser ap(a) Iteración de retroalimentación 1 (b) Iteración de retroalimentación 2 Figura 3: Las curvas de precisión promedio-alcance de diferentes algoritmos para las dos primeras iteraciones de retroalimentación. El algoritmo LOD funciona mejor en todo el alcance. Se debe tener en cuenta que, en la primera ronda de retroalimentación, el algoritmo SVMactive no se puede aplicar. Se aplica el SVM ordinario para construir el clasificador inicial. (a) Precisión en el Top 10 (b) Precisión en el Top 20 (c) Precisión en el Top 30 Figura 4: Evaluación del rendimiento de los cinco algoritmos de aprendizaje para la recuperación de imágenes con retroalimentación de relevancia. (a) Precisión en el top 10, (b) Precisión en el top 20 y (c) Precisión en el top 30. Como se puede observar, nuestro algoritmo LOD supera consistentemente a los otros cuatro algoritmos. Por lo tanto, no se puede aplicar en la primera ronda y utilizamos el SVM estándar para construir el clasificador inicial. Como se puede ver, nuestro algoritmo LOD supera a los otros cuatro algoritmos en todo el ámbito. Además, el algoritmo LRR tiene un mejor rendimiento que SVM. Esto se debe a que el algoritmo LRR hace un uso eficiente de las imágenes no etiquetadas al incorporar un regularizador de preservación de la localidad en la función objetivo de regresión ordinaria. El algoritmo AOD es el que tiene peor rendimiento. A medida que el alcance se amplía, la diferencia de rendimiento entre estos algoritmos disminuye. Al agregar de forma iterativa los comentarios de los usuarios, los resultados de precisión correspondientes (en los primeros 10, 20 y 30 lugares) de los cinco algoritmos se muestran respectivamente en la Figura 4. Como se puede ver, nuestro algoritmo LOD tiene el mejor rendimiento en todos los casos y el algoritmo LRR tiene el segundo mejor rendimiento. Ambos de estos dos algoritmos hacen uso de las imágenes sin etiquetar. Esto demuestra que las imágenes sin etiquetar son útiles para descubrir la <br>estructura geométrica intrínseca</br> del espacio de imágenes y, por lo tanto, mejorar el rendimiento de recuperación. En el mundo real, es posible que el usuario no esté dispuesto a proporcionar demasiadas retroalimentaciones de relevancia. Por lo tanto, el rendimiento de recuperación en las primeras dos rondas es especialmente importante. Como se puede observar, nuestro algoritmo LOD logra una mejora del rendimiento del 6.8% para los 10 mejores resultados, del 5.2% para los 20 mejores resultados y del 4.1% para los 30 mejores resultados, en comparación con el segundo mejor algoritmo (LRR) después de las dos primeras rondas de retroalimentación de relevancia. 6.4 Discusión Se han realizado sistemáticamente varios experimentos en la base de datos de Corel. Nos gustaría resaltar varios puntos interesantes: 1. Es claro que el uso del aprendizaje activo es beneficioso en el ámbito de la recuperación de imágenes. Hay un aumento significativo en el rendimiento al utilizar los métodos de aprendizaje activo. Especialmente, de los tres métodos de aprendizaje activo (SVMactive, AOD, LOD), nuestro algoritmo propuesto LOD es el que tiene mejor rendimiento. En muchas aplicaciones del mundo real, como la recuperación de imágenes con retroalimentación de relevancia, generalmente hay dos formas de reducir la tarea laboriosa de etiquetado manual. Uno es el aprendizaje activo que selecciona las muestras más informativas para etiquetar, y el otro es el aprendizaje semi-supervisado que utiliza las muestras no etiquetadas para mejorar el rendimiento del aprendizaje. Ambas estrategias han sido estudiadas extensamente en el pasado [14], [7], [5], [8]. El trabajo presentado en este artículo se centra en el aprendizaje activo, pero también aprovecha los avances recientes en el aprendizaje semi-supervisado [2]. Específicamente, incorporamos un regularizador que preserva la localidad en el marco de regresión estándar y encontramos las muestras más informativas con respecto a la nueva función objetivo. De esta manera, las técnicas de aprendizaje activo y de aprendizaje semi-supervisado se unifican de manera fluida para aprender un clasificador óptimo. 3. La técnica de retroalimentación de relevancia es crucial para la recuperación de imágenes. Para los cinco algoritmos, el rendimiento de recuperación mejora con más retroalimentación proporcionada por el usuario. CONCLUSIONES Y TRABAJOS FUTUROS Este artículo describe un novedoso algoritmo de aprendizaje activo, llamado Diseño Óptimo Laplaciano, para permitir una recuperación de imágenes con retroalimentación de relevancia más efectiva. Nuestro algoritmo se basa en una función objetivo que minimiza simultáneamente el error empírico y preserva la estructura geométrica local del espacio de datos. Utilizando técnicas de diseño experimental, nuestro algoritmo encuentra las imágenes más informativas para etiquetar. Estas imágenes etiquetadas y las imágenes sin etiquetar en la base de datos se utilizan para aprender un clasificador. Los resultados experimentales en la base de datos Corel muestran que tanto el aprendizaje activo como el aprendizaje semi-supervisado pueden mejorar significativamente el rendimiento de recuperación. En este documento, consideramos el problema de recuperación de imágenes en un conjunto de datos de imágenes pequeño, estático y de dominio cerrado. Un dominio mucho más desafiante es la World Wide Web (WWW). Para la búsqueda de imágenes en la web, es posible recopilar una gran cantidad de información sobre los clics de los usuarios. Esta información puede ser utilizada de forma natural para construir el grafo de afinidad en nuestro algoritmo. Sin embargo, la complejidad computacional en el escenario web puede convertirse en un problema crucial. Además, aunque nuestro interés principal en este artículo se centra en la recuperación de imágenes con retroalimentación de relevancia, nuestros resultados también pueden ser de interés para investigadores en reconocimiento de patrones y aprendizaje automático, especialmente cuando hay una gran cantidad de datos disponibles pero solo se pueden etiquetar muestras limitadas. 8. REFERENCIAS [1] A. C. Atkinson y A. N. Donev. Diseños experimentales óptimos. Oxford University Press, 2002. [2] M. Belkin, P. Niyogi, y V. Sindhwani. Regularización de variedades: Un marco geométrico para el aprendizaje a partir de ejemplos. Revista de Investigación de Aprendizaje Automático, 7:2399-2434, 2006. [3] F. R. K. Chung. Teoría Espectral de Grafos, volumen 92 de la Serie de Conferencias Regionales en Matemáticas. AMS, 1997. [4] D. A. Cohn, Z. Ghahramani y M. I. Jordan. Aprendizaje activo con modelos estadísticos. Revista de Investigación en Inteligencia Artificial, 4:129-145, 1996. [5] A. Dong y B. Bhanu. Un nuevo algoritmo EM semisupervisado para la recuperación de imágenes. En la Conferencia IEEE sobre Visión por Computadora y Reconocimiento de Patrones, Madison, WI, 2003. [6] P. Flaherty, M. I. Jordan y A. P. Arkin. Diseño robusto de experimentos biológicos. En Advances in Neural Information Processing Systems 18, Vancouver, Canadá, 2005. [7] K.-S. Goh, E. Y. Chang y W.-C. Lai. Aprendizaje activo dependiente del concepto multimodal para la recuperación de imágenes. En Actas de la Conferencia ACM sobre Multimedia, Nueva York, octubre de 2004. [8] X. Lo siento, la oración \"He.\" no tiene un significado claro en inglés. ¿Podrías proporcionar más contexto o una oración completa para que pueda traducirla al español de manera precisa? Aprendizaje de subespacios semisupervisado incremental para la recuperación de imágenes. En Actas de la Conferencia ACM sobre Multimedia, Nueva York, octubre de 2004. [9] S. C. Hoi y M. R. Lyu. Un marco de aprendizaje activo semi-supervisado para la recuperación de imágenes. En la Conferencia Internacional de IEEE sobre Visión por Computadora y Reconocimiento de Patrones, San Diego, CA, 2005. [10] D. P. Huijsmans y N. Sebe. Cómo completar los gráficos de rendimiento en la recuperación de imágenes basada en contenido: Agregar generalidad y normalizar el alcance. IEEE Transactions on Pattern Analysis and Machine Intelligence, 27(2):245-251, 2005. [11] Y.-Y.\n\nTransacciones del IEEE sobre Inteligencia Artificial y Análisis de Patrones, 27(2):245-251, 2005. [11] Y.-Y. Lin, T.-L. Liu y H.-T. Chen. Aprendizaje de variedades semánticas para la recuperación de imágenes. En Actas de la Conferencia ACM sobre Multimedia, Singapur, noviembre de 2005. [12] Y. Rui, T. S. Huang, M. Ortega y S. Mehrotra. Retroalimentación de relevancia: Una herramienta poderosa para la recuperación de imágenes basada en contenido de forma interactiva. IEEE Transactions on Circuits and Systems for Video Technology, 8(5), 1998. [13] A. W. Smeulders, M. Worring, S. Santini, A. Gupta, and R. Jain. \n\nTraducción: IEEE Transactions on Circuits and Systems for Video Technology, 8(5), 1998. [13] A. W. Smeulders, M. Worring, S. Santini, A. Gupta y R. Jain. Recuperación de imágenes basada en contenido al final de los primeros años. IEEE Transactions on Pattern Analysis and Machine Intelligence, 22(12):1349-1380, 2000. [14] S. Tong y E. Chang. Aprendizaje activo de máquina de vectores de soporte para recuperación de imágenes. En Actas de la novena conferencia internacional de ACM sobre Multimedia, páginas 107-118, 2001. [15] H. Yu, M. Li, H.-J. Zhang y J. Feng. Momentos de textura de color para la recuperación de imágenes basada en contenido. En la Conferencia Internacional de Procesamiento de Imágenes, páginas 24-28, 2002. [16] K. Yu, J. Bi y V. Tresp. Aprendizaje activo a través del diseño experimental transductivo. En Actas de la 23ª Conferencia Internacional sobre Aprendizaje Automático, Pittsburgh, PA, 2006. ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "patten recognition": {
            "translated_key": "reconocimiento de patrones",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Laplacian Optimal Design for Image Retrieval Xiaofei He Yahoo!",
                "Burbank, CA 91504 hex@yahoo-inc.com Wanli Min IBM Yorktown Heights, NY 10598 wanlimin@us.ibm.com Deng Cai CS Dept., UIUC Urbana, IL 61801 dengcai2@cs.uiuc.edu Kun Zhou Microsoft Research Asia Beijing, China kunzhou@microsoft.com ABSTRACT Relevance feedback is a powerful technique to enhance ContentBased Image Retrieval (CBIR) performance.",
                "It solicits the users relevance judgments on the retrieved images returned by the CBIR systems.",
                "The users labeling is then used to learn a classifier to distinguish between relevant and irrelevant images.",
                "However, the top returned images may not be the most informative ones.",
                "The challenge is thus to determine which unlabeled images would be the most informative (i.e., improve the classifier the most) if they were labeled and used as training samples.",
                "In this paper, we propose a novel active learning algorithm, called Laplacian Optimal Design (LOD), for relevance feedback image retrieval.",
                "Our algorithm is based on a regression model which minimizes the least square error on the measured (or, labeled) images and simultaneously preserves the local geometrical structure of the image space.",
                "Specifically, we assume that if two images are sufficiently close to each other, then their measurements (or, labels) are close as well.",
                "By constructing a nearest neighbor graph, the geometrical structure of the image space can be described by the graph Laplacian.",
                "We discuss how results from the field of optimal experimental design may be used to guide our selection of a subset of images, which gives us the most amount of information.",
                "Experimental results on Corel database suggest that the proposed approach achieves higher precision in relevance feedback image retrieval.",
                "Categories and Subject Descriptors H.3.3 [Information storage and retrieval]: Information search and retrieval-Relevance feedback; G.3 [Mathematics of Computing]: Probability and Statistics-Experimental design General Terms Algorithms, Performance, Theory 1.",
                "INTRODUCTION In many machine learning and information retrieval tasks, there is no shortage of unlabeled data but labels are expensive.",
                "The challenge is thus to determine which unlabeled samples would be the most informative (i.e., improve the classifier the most) if they were labeled and used as training samples.",
                "This problem is typically called active learning [4].",
                "Here the task is to minimize an overall cost, which depends both on the classifier accuracy and the cost of data collection.",
                "Many real world applications can be casted into active learning framework.",
                "Particularly, we consider the problem of relevance feedback driven Content-Based Image Retrieval (CBIR) [13].",
                "Content-Based Image Retrieval has attracted substantial interests in the last decade [13].",
                "It is motivated by the fast growth of digital image databases which, in turn, require efficient search schemes.",
                "Rather than describe an image using text, in these systems an image query is described using one or more example images.",
                "The low level visual features (color, texture, shape, etc.) are automatically extracted to represent the images.",
                "However, the low level features may not accurately characterize the high level semantic concepts.",
                "To narrow down the semantic gap, relevance feedback is introduced into CBIR [12].",
                "In many of the current relevance feedback driven CBIR systems, the user is required to provide his/her relevance judgments on the top images returned by the system.",
                "The labeled images are then used to train a classifier to separate images that match the query concept from those that do not.",
                "However, in general the top returned images may not be the most informative ones.",
                "In the worst case, all the top images labeled by the user may be positive and thus the standard classification techniques can not be applied due to the lack of negative examples.",
                "Unlike the standard classification problems where the labeled samples are pregiven, in relevance feedback image retrieval the system can actively select the images to label.",
                "Thus active learning can be naturally introduced into image retrieval.",
                "Despite many existing active learning techniques, Support Vector Machine (SVM) active learning [14] and regression based active learning [1] have received the most interests.",
                "Based on the observation that the closer to the SVM boundary an image is, the less reliable its classification is, SVM active learning selects those unlabeled images closest to the boundary to solicit user feedback so as to achieve maximal refinement on the hyperplane between the two classes.",
                "The major disadvantage of SVM active learning is that the estimated boundary may not be accurate enough.",
                "Moreover, it may not be applied at the beginning of the retrieval when there is no labeled images.",
                "Some other SVM based active learning algorithms can be found in [7], [9].",
                "In statistics, the problem of selecting samples to label is typically referred to as experimental design.",
                "The sample x is referred to as experiment, and its label y is referred to as measurement.",
                "The study of optimal experimental design (OED) [1] is concerned with the design of experiments that are expected to minimize variances of a parameterized model.",
                "The intent of optimal experimental design is usually to maximize confidence in a given model, minimize parameter variances for system identification, or minimize the models output variance.",
                "Classical experimental design approaches include A-Optimal Design, D-Optimal Design, and E-Optimal Design.",
                "All of these approaches are based on a least squares regression model.",
                "Comparing to SVM based active learning algorithms, experimental design approaches are much more efficient in computation.",
                "However, this kind of approaches takes only measured (or, labeled) data into account in their objective function, while the unmeasured (or, unlabeled) data is ignored.",
                "Benefit from recent progresses on optimal experimental design and semi-supervised learning, in this paper we propose a novel active learning algorithm for image retrieval, called Laplacian Optimal Design (LOD).",
                "Unlike traditional experimental design methods whose loss functions are only defined on the measured points, the loss function of our proposed LOD algorithm is defined on both measured and unmeasured points.",
                "Specifically, we introduce a locality preserving regularizer into the standard least-square-error based loss function.",
                "The new loss function aims to find a classifier which is locally as smooth as possible.",
                "In other words, if two points are sufficiently close to each other in the input space, then they are expected to share the same label.",
                "Once the loss function is defined, we can select the most informative data points which are presented to the user for labeling.",
                "It would be important to note that the most informative images may not be the top returned images.",
                "The rest of the paper is organized as follows.",
                "In Section 2, we provide a brief description of the related work.",
                "Our proposed Laplacian Optimal Design algorithm is introduced in Section 3.",
                "In Section 4, we compare our algorithm with the state-or-the-art algorithms and present the experimental results on image retrieval.",
                "Finally, we provide some concluding remarks and suggestions for future work in Section 5. 2.",
                "RELATED WORK Since our proposed algorithm is based on regression framework.",
                "The most related work is optimal experimental design [1], including A-Optimal Design, D-Optimal Design, and EOptimal Design.",
                "In this Section, we give a brief description of these approaches. 2.1 The Active Learning Problem The generic problem of active learning is the following.",
                "Given a set of points A = {x1, x2, · · · , xm} in Rd , find a subset B = {z1, z2, · · · , zk} ⊂ A which contains the most informative points.",
                "In other words, the points zi(i = 1, · · · , k) can improve the classifier the most if they are labeled and used as training points. 2.2 Optimal Experimental Design We consider a linear regression model y = wT x + (1) where y is the observation, x is the independent variable, w is the weight vector and is an unknown error with zero mean.",
                "Different observations have errors that are independent, but with equal variances σ2 .",
                "We define f(x) = wT x to be the learners output given input x and the weight vector w. Suppose we have a set of labeled sample points (z1, y1), · · · , (zk, yk), where yi is the label of zi.",
                "Thus, the maximum likelihood estimate for the weight vector, ˆw, is that which minimizes the sum squared error Jsse(w) = k i=1 wT zi − yi 2 (2) The estimate ˆw gives us an estimate of the output at a novel input: ˆy = ˆwT x.",
                "By Gauss-Markov theorem, we know that ˆw − w has a zero mean and a covariance matrix given by σ2 H−1 sse, where Hsse is the Hessian of Jsse(w) Hsse = ∂2 Jsse ∂w2 = k i=1 zizT i = ZZT where Z = (z1, z2, · · · , zk).",
                "The three most common scalar measures of the size of the parameter covariance matrix in optimal experimental design are: • D-optimal design: determinant of Hsse. • A-optimal design: trace of Hsse. • E-optimal design: maximum eigenvalue of Hsse.",
                "Since the computation of the determinant and eigenvalues of a matrix is much more expensive than the computation of matrix trace, A-optimal design is more efficient than the other two.",
                "Some recent work on experimental design can be found in [6], [16]. 3.",
                "LAPLACIAN OPTIMAL DESIGN Since the covariance matrix Hsse used in traditional approaches is only dependent on the measured samples, i.e. zis, these approaches fail to evaluate the expected errors on the unmeasured samples.",
                "In this Section, we introduce a novel active learning algorithm called Laplacian Optimal Design (LOD) which makes efficient use of both measured (labeled) and unmeasured (unlabeled) samples. 3.1 The Objective Function In many machine learning problems, it is natural to assume that if two points xi, xj are sufficiently close to each other, then their measurements (f(xi), f(xj)) are close as well.",
                "Let S be a similarity matrix.",
                "Thus, a new loss function which respects the geometrical structure of the data space can be defined as follows: J0(w) = k i=1 f(zi)−yi 2 + λ 2 m i,j=1 f(xi)−f(xj) 2 Sij (3) where yi is the measurement (or, label) of zi.",
                "Note that, the loss function (3) is essentially the same as the one used in Laplacian Regularized Regression (LRR, [2]).",
                "However, LRR is a passive learning algorithm where the training data is given.",
                "In this paper, we are focused on how to select the most informative data for training.",
                "The loss function with our choice of symmetric weights Sij (Sij = Sji) incurs a heavy penalty if neighboring points xi and xj are mapped far apart.",
                "Therefore, minimizing J0(w) is an attempt to ensure that if xi and xj are close then f(xi) and f(xj) are close as well.",
                "There are many choices of the similarity matrix S. A simple definition is as follows: Sij = ⎧ ⎨ ⎩ 1, if xi is among the p nearest neighbors of xj, or xj is among the p nearest neighbors of xi; 0, otherwise. (4) Let D be a diagonal matrix, Dii = j Sij, and L = D−S.",
                "The matrix L is called graph Laplacian in spectral graph theory [3].",
                "Let y = (y1, · · · , yk)T and X = (x1, · · · , xm).",
                "Following some simple algebraic steps, we see that: J0(w) = k i=1 wT zi − yi 2 + λ 2 m i,j=1 wT xi − wT xj 2 Sij = y − ZT w T y − ZT w + λwT m i=1 DiixixT i − m i,j=1 SijxixT j w = yT y − 2wT Zy + wT ZZT w +λwT XDXT − XSXT w = yT y − 2wT Zy + wT ZZT + λXLXT w The Hessian of J0(w) can be computed as follows: H0 = ∂2 J0 ∂w2 = ZZT + λXLXT In some cases, the matrix ZZT +λXLXT is singular (e.g. if m < d).",
                "Thus, there is no stable solution to the optimization problem Eq. (3).",
                "A common way to deal with this ill-posed problem is to introduce a Tikhonov regularizer into our loss function: J(w) = k i=1 wT zi − yi 2 + λ1 2 m i,j=1 wT xi − wT xj 2 Sij +λ2 w 2 (5) The Hessian of the new loss function is given by: H = ∂2 J ∂w2 = ZZT + λ1XLXT + λ2I := ZZT + Λ where I is an identity matrix and Λ = λ1XLXT + λ2I.",
                "Clearly, H is of full rank.",
                "Requiring that the gradient of J(w) with respect to w vanish gives the optimal estimate ˆw: ˆw = H−1 Zy The following proposition states the bias and variance properties of the estimator for the coefficient vector w. Proposition 3.1.",
                "E( ˆw − w) = −H−1 Λw, Cov( ˆw) = σ2 (H−1 − H−1 ΛH−1 ) Proof.",
                "Since y = ZT w + and E( ) = 0, it follows that E( ˆw − w) (6) = H−1 ZZT w − w = H−1 (ZZT + Λ − Λ)w − w = (I − H−1 Λ)w − w = −H−1 Λw (7) Notice Cov(y) = σ2 I, the covariance matrix of ˆw has the expression: Cov( ˆw) = H−1 ZCov(y)ZT H−1 = σ2 H−1 ZZT H−1 = σ2 H−1 (H − Λ)H−1 = σ2 (H−1 − H−1 ΛH−1 ) (8) Therefore mean squared error matrix for the coefficients w is E(w − ˆw)(w − ˆw)T (9) = H−1 ΛwwT ΛH−1 + σ2 (H−1 − H−1 ΛH−1 ) (10) For any x, let ˆy = ˆwT x be its predicted observation.",
                "The expected squared prediction error is E(y − ˆy)2 = E( + wT x − ˆwT x)2 = σ2 + xT [E(w − ˆw)(w − ˆw)T ]x = σ2 + xT [H−1 ΛwwT ΛH−1 + σ2 H−1 − σ2 H−1 ΛH−1 ]x Clearly the expected square prediction error depends on the explanatory variable x, therefore average expected square predictive error over the complete data set A is 1 m m i=1 E(yi − ˆwT xi)2 = 1 m m i=1 xT i [H−1 ΛwwT ΛH−1 + σ2 H−1 − σ2 H−1 ΛH−1 ]xi +σ2 = 1 m Tr(XT [σ2 H−1 + H−1 ΛwwT ΛH−1 − σ2 H−1 ΛH−1 ]X) +σ2 Since Tr(XT [H−1 ΛwwT ΛH−1 − σ2 H−1 ΛH−1 ]X) Tr(σ2 XT H−1 X), Our Laplacian optimality criterion is thus formulated by minimizing the trace of XT H−1 X.",
                "Definition 1.",
                "Laplacian Optimal Design min Z=(z1,··· ,zk) Tr XT ZZT + λ1XLXT + λ2I −1 X (11) where z1, · · · , zk are selected from {x1, · · · , xm}. 4.",
                "KERNEL LAPLACIAN OPTIMAL DESIGN Canonical experimental design approaches (e.g.",
                "A-Optimal Design, D-Optimal Design, and E-Optimal) only consider linear functions.",
                "They fail to discover the intrinsic geometry in the data when the data space is highly nonlinear.",
                "In this section, we describe how to perform Laplacian Experimental Design in Reproducing Kernel Hilbert Space (RKHS) which gives rise to Kernel Laplacian Experimental Design (KLOD).",
                "For given data points x1, · · · , xm ∈ X with a positive definite mercer kernel K : X ×X → R, there exists a unique RKHS HK of real valued functions on X.",
                "Let Kt(s) be the function of s obtained by fixing t and letting Kt(s) . = K(s, t).",
                "HK consists of all finite linear combinations of the form l i=1 αiKti with ti ∈ X and limits of such functions as the ti become dense in X.",
                "We have Ks, Kt HK = K(s, t). 4.1 Derivation of LOD in Reproducing Kernel Hilbert Space Consider the optimization problem (5) in RKHS.",
                "Thus, we seek a function f ∈ HK such that the following objective function is minimized: min f∈HK k i=1 f(zi)−yi 2 + λ1 2 m i,j=1 f(xi)−f(xj) 2 Sij+λ2 f 2 HK (12) We have the following proposition.",
                "Proposition 4.1.",
                "Let H = { m i=1 αiK(·, xi)|αi ∈ R} be a subspace of HK , the solution to the problem (12) is in H. Proof.",
                "Let H⊥ be the orthogonal complement of H, i.e.",
                "HK = H ⊕ H⊥ .",
                "Thus, for any function f ∈ HK , it has orthogonal decomposition as follows: f = fH + fH⊥ Now, lets evaluate f at xi: f(xi) = f, Kxi HK = fH + fH⊥ , Kxi HK = fH, Kxi HK + fH⊥ , Kxi HK Notice that Kxi ∈ H while fH⊥ ∈ H⊥ .",
                "This implies that fH⊥ , Kxi HK = 0.",
                "Therefore, f(xi) = fH, Kxi HK = fH(xi) This completes the proof.",
                "Proposition 4.1 tells us the minimizer of problem (12) admits a representation f∗ = m i=1 αiK(·, xi).",
                "Please see [2] for the details.",
                "Let φ : Rd → H be a feature map from the input space Rd to H, and K(xi, xj) =< φ(xi), φ(xj) >.",
                "Let X denote the data matrix in RKHS, X = (φ(x1), φ(x2), · · · , φ(xm)).",
                "Similarly, we define Z = (φ(z1), φ(z2), · · · , φ(zk)).",
                "Thus, the optimization problem in RKHS can be written as follows: min Z Tr XT ZZT + λ1XLXT + λ2I −1 X (13) Since the mapping function φ is generally unknown, there is no direct way to solve problem (13).",
                "In the following, we apply kernel tricks to solve this optimization problem.",
                "Let X−1 be the Moore-Penrose inverse (also known as pseudo inverse) of X.",
                "Thus, we have: XT ZZT + λ1XLXT + λ2I −1 X = XT XX−1 ZZT + λ1XLXT + λ2I −1 (XT )−1 XT X = XT X ZZT X + λ1XLXT X + λ2X −1 (XT )−1 XT X = XT X XT ZZT X + λ1XT XLXT X + λ2XT X −1 XT X = KXX KXZKZX + λ1KXXLKXX + λ2KXX −1 KXX where KXX is a m × m matrix (KXX,ij = K(xi, xj)), KXZ is a m×k matrix (KXZ,ij = K(xi, zj)), and KZX is a k×m matrix (KZX,ij = K(zi, xj)).",
                "Thus, the Kernel Laplacian Optimal Design can be defined as follows: Definition 2.",
                "Kernel Laplacian Optimal Design minZ=(z1,··· ,zk) Tr KXX KXZKZX + λ1KXXLKXX λ2KXX −1 KXX (14) 4.2 Optimization Scheme In this subsection, we discuss how to solve the optimization problems (11) and (14).",
                "Particularly, if we select a linear kernel for KLOD, then it reduces to LOD.",
                "Therefore, we will focus on problem (14) in the following.",
                "It can be shown that the optimization problem (14) is NP-hard.",
                "In this subsection, we develop a simple sequential greedy approach to solve (14).",
                "Suppose n points have been selected, denoted by a matrix Zn = (z1, · · · , zn).",
                "The (n + 1)-th point zn+1 can be selected by solving the following optimization problem: max Zn+1=(Zn,zn+1) Tr KXX KXZn+1 KZn+1X + λ1KXXLKXX + λ2KXX −1 KXX (15) The kernel matrices KXZn+1 and KZn+1X can be rewritten as follows: KXZn+1 = KXZn , KXzn+1 , KZn+1X = KZnX Kzn+1X Thus, we have: KXZn+1 KZn+1X = KXZn KZnX + KXzn+1 Kzn+1X We define: A = KXZn KZnX + λ1KXXLKXX + λ2KXX A is only dependent on X and Zn .",
                "Thus, the (n + 1)-th point zn+1 is given by: zn+1 = arg min zn+1 Tr KXX A + KXzn+1 Kzn+1X −1 KXX (16) Each time we select a new point zn+1, the matrix A is updated by: A ← A + KXzn+1 Kzn+1X If the kernel function is chosen as inner product K(x, y) = x, y , then HK is a linear functional space and the algorithm reduces to LOD. 5.",
                "CONTENT-BASED IMAGE RETRIEVAL USING LAPLACIAN OPTIMAL DESIGN In this section, we describe how to apply Laplacian Optimal Design to CBIR.",
                "We begin with a brief description of image representation using low level visual features. 5.1 Low-Level Image Representation Low-level image representation is a crucial problem in CBIR.",
                "General visual features includes color, texture, shape, etc.",
                "Color and texture features are the most extensively used visual features in CBIR.",
                "Compared with color and texture features, shape features are usually described after images have been segmented into regions or objects.",
                "Since robust and accurate image segmentation is difficult to achieve, the use of shape features for image retrieval has been limited to special applications where objects or regions are readily available.",
                "In this work, We combine 64-dimensional color histogram and 64-dimensional Color Texture Moment (CTM, [15]) to represent the images.",
                "The color histogram is calculated using 4 × 4 × 4 bins in HSV space.",
                "The Color Texture Moment is proposed by Yu et al. [15], which integrates the color and texture characteristics of the image in a compact form.",
                "CTM adopts local Fourier transform as a texture representation scheme and derives eight characteristic maps to describe different aspects of co-occurrence relations of image pixels in each channel of the (SVcosH, SVsinH, V) color space.",
                "Then CTM calculates the first and second moment of these maps as a representation of the natural color image pixel distribution.",
                "Please see [15] for details. 5.2 Relevance Feedback Image Retrieval Relevance feedback is one of the most important techniques to narrow down the gap between low level visual features and high level semantic concepts [12].",
                "Traditionally, the users relevance feedbacks are used to update the query vector or adjust the weighting of different dimensions.",
                "This process can be viewed as an on-line learning process in which the image retrieval system acts as a learner and the user acts as a teacher.",
                "They typical retrieval process is outlined as follows: 1.",
                "The user submits a query image example to the system.",
                "The system ranks the images in database according to some pre-defined distance metric and presents to the user the top ranked images. 2.",
                "The system selects some images from the database and request the user to label them as relevant or irrelevant. 3.",
                "The system uses the users provided information to rerank the images in database and returns to the user the top images.",
                "Go to step 2 until the user is satisfied.",
                "Our Laplacian Optimal Design algorithm is applied in the second step for selecting the most informative images.",
                "Once we get the labels for the images selected by LOD, we apply Laplacian Regularized Regression (LRR, [2]) to solve the optimization problem (3) and build the classifier.",
                "The classifier is then used to re-rank the images in database.",
                "Note that, in order to reduce the computational complexity, we do not use all the unlabeled images in the database but only those within top 500 returns of previous iteration. 6.",
                "EXPERIMENTAL RESULTS In this section, we evaluate the performance of our proposed algorithm on a large image database.",
                "To demonstrate the effectiveness of our proposed LOD algorithm, we compare it with Laplacian Regularized Regression (LRR, [2]), Support Vector Machine (SVM), Support Vector Machine Active Learning (SVMactive) [14], and A-Optimal Design (AOD).",
                "Both SVMactive, AOD, and LOD are active learning algorithms, while LRR and SVM are standard classification algorithms.",
                "SVM only makes use of the labeled images, while LRR is a semi-supervised learning algorithm which makes use of both labeled and unlabeled images.",
                "For SVMactive, AOD, and LOD, 10 training images are selected by the algorithms themselves at each iteration.",
                "While for LRR and SVM, we use the top 10 images as training data.",
                "It would be important to note that SVMactive is based on the ordinary SVM, LOD is based on LRR, and AOD is based on the ordinary regression.",
                "The parameters λ1 and λ2 in our LOD algorithm are empirically set to be 0.001 and 0.00001.",
                "For both LRR and LOD algorithms, we use the same graph structure (see Eq. 4) and set the value of p (number of nearest neighbors) to be 5.",
                "We begin with a simple synthetic example to give some intuition about how LOD works. 6.1 Simple Synthetic Example A simple synthetic example is given in Figure 1.",
                "The data set contains two circles.",
                "Eight points are selected by AOD and LOD.",
                "As can be seen, all the points selected by AOD are from the big circle, while LOD selects four points from the big circle and four from the small circle.",
                "The numbers beside the selected points denote their orders to be selected.",
                "Clearly, the points selected by our LOD algorithm can better represent the original data set.",
                "We did not compare our algorithm with SVMactive because SVMactive can not be applied in this case due to the lack of the labeled points. 6.2 Image Retrieval Experimental Design The image database we used consists of 7,900 images of 79 semantic categories, from COREL data set.",
                "It is a large and heterogeneous image set.",
                "Each image is represented as a 128-dimensional vector as described in Section 5.1.",
                "Figure 2 shows some sample images.",
                "To exhibit the advantages of using our algorithm, we need a reliable way of evaluating the retrieval performance and the comparisons with other algorithms.",
                "We list different aspects of the experimental design below. 6.2.1 Evaluation Metrics We use precision-scope curve and precision rate [10] to evaluate the effectiveness of the image retrieval algorithms.",
                "The scope is specified by the number (N) of top-ranked images presented to the user.",
                "The precision is the ratio of the number of relevant images presented to the user to the (a) Data set 1 2 3 4 5 6 7 8 (b) AOD 1 2 3 4 5 6 7 8 (c) LOD Figure 1: Data selection by active learning algorithms.",
                "The numbers beside the selected points denote their orders to be selected.",
                "Clearly, the points selected by our LOD algorithm can better represent the original data set.",
                "Note that, the SVMactive algorithm can not be applied in this case due to the lack of labeled points. (a) (b) (c) Figure 2: Sample images from category bead, elephant, and ship. scope N. The precision-scope curve describes the precision with various scopes and thus gives an overall performance evaluation of the algorithms.",
                "On the other hand, the precision rate emphasizes the precision at a particular value of scope.",
                "In general, it is appropriate to present 20 images on a screen.",
                "Putting more images on a screen may affect the quality of the presented images.",
                "Therefore, the precision at top 20 (N = 20) is especially important.",
                "In real world image retrieval systems, the query image is usually not in the image database.",
                "To simulate such environment, we use five-fold cross validation to evaluate the algorithms.",
                "More precisely, we divide the whole image database into five subsets with equal size.",
                "Thus, there are 20 images per category in each subset.",
                "At each run of cross validation, one subset is selected as the query set, and the other four subsets are used as the database for retrieval.",
                "The precisionscope curve and precision rate are computed by averaging the results from the five-fold cross validation. 6.2.2 Automatic Relevance Feedback Scheme We designed an automatic feedback scheme to model the retrieval process.",
                "For each submitted query, our system retrieves and ranks the images in the database. 10 images were selected from the database for user labeling and the label information is used by the system for re-ranking.",
                "Note that, the images which have been selected at previous iterations are excluded from later selections.",
                "For each query, the automatic relevance feedback mechanism is performed for four iterations.",
                "It is important to note that the automatic relevance feedback scheme used here is different from the ones described in [8], [11].",
                "In [8], [11], the top four relevant and irrelevant images were selected as the feedback images.",
                "However, this may not be practical.",
                "In real world image retrieval systems, it is possible that most of the top-ranked images are relevant (or, irrelevant).",
                "Thus, it is difficult for the user to find both four relevant and irrelevant images.",
                "It is more reasonable for the users to provide feedback information only on the 10 images selected by the system. 6.3 Image Retrieval Performance In real world, it is not practical to require the user to provide many rounds of feedbacks.",
                "The retrieval performance after the first two rounds of feedbacks (especially the first round) is more important.",
                "Figure 3 shows the average precision-scope curves of the different algorithms for the first two feedback iterations.",
                "At the beginning of retrieval, the Euclidean distances in the original 128-dimensional space are used to rank the images in database.",
                "After the user provides relevance feedbacks, the LRR, SVM, SVMactive, AOD, and LOD algorithms are then applied to re-rank the images.",
                "In order to reduce the time complexity of active learning algorithms, we didnt select the most informative images from the whole database but from the top 500 images.",
                "For LRR and SVM, the user is required to label the top 10 images.",
                "For SVMactive, AOD, and LOD, the user is required to label 10 most informative images selected by these algorithms.",
                "Note that, SVMactive can only be ap(a) Feedback Iteration 1 (b) Feedback Iteration 2 Figure 3: The average precision-scope curves of different algorithms for the first two feedback iterations.",
                "The LOD algorithm performs the best on the entire scope.",
                "Note that, at the first round of feedback, the SVMactive algorithm can not be applied.",
                "It applies the ordinary SVM to build the initial classifier. (a) Precision at Top 10 (b) Precision at Top 20 (c) Precision at Top 30 Figure 4: Performance evaluation of the five learning algorithms for relevance feedback image retrieval. (a) Precision at top 10, (b) Precision at top 20, and (c) Precision at top 30.",
                "As can be seen, our LOD algorithm consistently outperforms the other four algorithms. plied when the classifier is already built.",
                "Therefore, it can not be applied at the first round and we use the standard SVM to build the initial classifier.",
                "As can be seen, our LOD algorithm outperforms the other four algorithms on the entire scope.",
                "Also, the LRR algorithm performs better than SVM.",
                "This is because that the LRR algorithm makes efficient use of the unlabeled images by incorporating a locality preserving regularizer into the ordinary regression objective function.",
                "The AOD algorithm performs the worst.",
                "As the scope gets larger, the performance difference between these algorithms gets smaller.",
                "By iteratively adding the users feedbacks, the corresponding precision results (at top 10, top 20, and top 30) of the five algorithms are respectively shown in Figure 4.",
                "As can be seen, our LOD algorithm performs the best in all the cases and the LRR algorithm performs the second best.",
                "Both of these two algorithms make use of the unlabeled images.",
                "This shows that the unlabeled images are helpful for discovering the intrinsic geometrical structure of the image space and therefore enhance the retrieval performance.",
                "In real world, the user may not be willing to provide too many relevance feedbacks.",
                "Therefore, the retrieval performance at the first two rounds are especially important.",
                "As can be seen, our LOD algorithm achieves 6.8% performance improvement for top 10 results, 5.2% for top 20 results, and 4.1% for top 30 results, comparing to the second best algorithm (LRR) after the first two rounds of relevance feedbacks. 6.4 Discussion Several experiments on Corel database have been systematically performed.",
                "We would like to highlight several interesting points: 1.",
                "It is clear that the use of active learning is beneficial in the image retrieval domain.",
                "There is a significant increase in performance from using the active learning methods.",
                "Especially, out of the three active learning methods (SVMactive, AOD, LOD), our proposed LOD algorithm performs the best. 2.",
                "In many real world applications like relevance feedback image retrieval, there are generally two ways of reducing labor-intensive manual labeling task.",
                "One is active learning which selects the most informative samples to label, and the other is semi-supervised learning which makes use of the unlabeled samples to enhance the learning performance.",
                "Both of these two strategies have been studied extensively in the past [14], [7], [5], [8].",
                "The work presented in this paper is focused on active learning, but it also takes advantage of the recent progresses on semi-supervised learning [2].",
                "Specifically, we incorporate a locality preserving regularizer into the standard regression framework and find the most informative samples with respect to the new objective function.",
                "In this way, the active learning and semi-supervised learning techniques are seamlessly unified for learning an optimal classifier. 3.",
                "The relevance feedback technique is crucial to image retrieval.",
                "For all the five algorithms, the retrieval performance improves with more feedbacks provided by the user. 7.",
                "CONCLUSIONS AND FUTURE WORK This paper describes a novel active learning algorithm, called Laplacian Optimal Design, to enable more effective relevance feedback image retrieval.",
                "Our algorithm is based on an objective function which simultaneously minimizes the empirical error and preserves the local geometrical structure of the data space.",
                "Using techniques from experimental design, our algorithm finds the most informative images to label.",
                "These labeled images and the unlabeled images in the database are used to learn a classifier.",
                "The experimental results on Corel database show that both active learning and semi-supervised learning can significantly improve the retrieval performance.",
                "In this paper, we consider the image retrieval problem on a small, static, and closed-domain image data.",
                "A much more challenging domain is the World Wide Web (WWW).",
                "For Web image search, it is possible to collect a large amount of user click information.",
                "This information can be naturally used to construct the affinity graph in our algorithm.",
                "However, the computational complexity in Web scenario may become a crucial issue.",
                "Also, although our primary interest in this paper is focused on relevance feedback image retrieval, our results may also be of interest to researchers in <br>patten recognition</br> and machine learning, especially when a large amount of data is available but only a limited samples can be labeled. 8.",
                "REFERENCES [1] A. C. Atkinson and A. N. Donev.",
                "Optimum Experimental Designs.",
                "Oxford University Press, 2002. [2] M. Belkin, P. Niyogi, and V. Sindhwani.",
                "Manifold regularization: A geometric framework for learning from examples.",
                "Journal of Machine Learning Research, 7:2399-2434, 2006. [3] F. R. K. Chung.",
                "Spectral Graph Theory, volume 92 of Regional Conference Series in Mathematics.",
                "AMS, 1997. [4] D. A. Cohn, Z. Ghahramani, and M. I. Jordan.",
                "Active learning with statistical models.",
                "Journal of Artificial Intelligence Research, 4:129-145, 1996. [5] A. Dong and B. Bhanu.",
                "A new semi-supervised em algorithm for image retrieval.",
                "In IEEE Conf. on Computer Vision and Pattern Recognition, Madison, WI, 2003. [6] P. Flaherty, M. I. Jordan, and A. P. Arkin.",
                "Robust design of biological experiments.",
                "In Advances in Neural Information Processing Systems 18, Vancouver, Canada, 2005. [7] K.-S. Goh, E. Y. Chang, and W.-C. Lai.",
                "Multimodal concept-dependent active learning for image retrieval.",
                "In Proceedings of the ACM Conference on Multimedia, New York, October 2004. [8] X.",
                "He.",
                "Incremental semi-supervised subspace learning for image retrieval.",
                "In Proceedings of the ACM Conference on Multimedia, New York, October 2004. [9] S. C. Hoi and M. R. Lyu.",
                "A semi-supervised active learning framework for image retrieval.",
                "In IEEE International Conference on Computer Vision and Pattern Recognition, San Diego, CA, 2005. [10] D. P. Huijsmans and N. Sebe.",
                "How to complete performance graphs in content-based image retrieval: Add generality and normalize scope.",
                "IEEE Transactions on Pattern Analysis and Machine Intelligence, 27(2):245-251, 2005. [11] Y.-Y.",
                "Lin, T.-L. Liu, and H.-T. Chen.",
                "Semantic manifold learning for image retrieval.",
                "In Proceedings of the ACM Conference on Multimedia, Singapore, November 2005. [12] Y. Rui, T. S. Huang, M. Ortega, and S. Mehrotra.",
                "Relevance feedback: A power tool for interative content-based image retrieval.",
                "IEEE Transactions on Circuits and Systems for Video Technology, 8(5), 1998. [13] A. W. Smeulders, M. Worring, S. Santini, A. Gupta, and R. Jain.",
                "Content-based image retrieval at the end of the early years.",
                "IEEE Transactions on Pattern Analysis and Machine Intelligence, 22(12):1349-1380, 2000. [14] S. Tong and E. Chang.",
                "Support vector machine active learning for image retrieval.",
                "In Proceedings of the ninth ACM international conference on Multimedia, pages 107-118, 2001. [15] H. Yu, M. Li, H.-J.",
                "Zhang, and J. Feng.",
                "Color texture moments for content-based image retrieval.",
                "In International Conference on Image Processing, pages 24-28, 2002. [16] K. Yu, J. Bi, and V. Tresp.",
                "Active learning via transductive experimental design.",
                "In Proceedings of the 23rd International Conference on Machine Learning, Pittsburgh, PA, 2006."
            ],
            "original_annotated_samples": [
                "Also, although our primary interest in this paper is focused on relevance feedback image retrieval, our results may also be of interest to researchers in <br>patten recognition</br> and machine learning, especially when a large amount of data is available but only a limited samples can be labeled. 8."
            ],
            "translated_annotated_samples": [
                "Además, aunque nuestro interés principal en este artículo se centra en la recuperación de imágenes con retroalimentación de relevancia, nuestros resultados también pueden ser de interés para investigadores en <br>reconocimiento de patrones</br> y aprendizaje automático, especialmente cuando hay una gran cantidad de datos disponibles pero solo se pueden etiquetar muestras limitadas. 8."
            ],
            "translated_text": "Diseño óptimo de Laplaciano para la recuperación de imágenes Xiaofei He Yahoo! El feedback de relevancia es una técnica poderosa para mejorar el rendimiento de la Recuperación de Imágenes Basada en Contenido (CBIR). Solicita las valoraciones de relevancia de los usuarios sobre las imágenes recuperadas por los sistemas CBIR. La etiqueta de los usuarios se utiliza luego para entrenar un clasificador que distinga entre imágenes relevantes e irrelevantes. Sin embargo, las imágenes principales que se devuelven pueden no ser las más informativas. El desafío consiste en determinar qué imágenes sin etiquetar serían las más informativas (es decir, mejorarían más al clasificador) si fueran etiquetadas y utilizadas como muestras de entrenamiento. En este artículo, proponemos un novedoso algoritmo de aprendizaje activo, llamado Diseño Óptimo Laplaciano (LOD), para la recuperación de imágenes con retroalimentación de relevancia. Nuestro algoritmo se basa en un modelo de regresión que minimiza el error cuadrático mínimo en las imágenes medidas (o etiquetadas) y al mismo tiempo preserva la estructura geométrica local del espacio de la imagen. Específicamente, asumimos que si dos imágenes están lo suficientemente cerca una de la otra, entonces sus medidas (o etiquetas) también son cercanas. Al construir un grafo de vecinos más cercanos, la estructura geométrica del espacio de la imagen puede ser descrita por el Laplaciano del grafo. Discutimos cómo los resultados del campo del diseño experimental óptimo pueden ser utilizados para guiar nuestra selección de un subconjunto de imágenes, que nos proporciona la mayor cantidad de información. Los resultados experimentales en la base de datos Corel sugieren que el enfoque propuesto logra una mayor precisión en la recuperación de imágenes con retroalimentación de relevancia. Categorías y Descriptores de Asignaturas H.3.3 [Almacenamiento y recuperación de información]: Búsqueda y recuperación de información-Retroalimentación de relevancia; G.3 [Matemáticas de la Computación]: Probabilidad y Estadística-Diseño experimental Términos Generales Algoritmos, Rendimiento, Teoría 1. INTRODUCCIÓN En muchas tareas de aprendizaje automático y recuperación de información, no hay escasez de datos no etiquetados pero las etiquetas son costosas. El desafío consiste en determinar qué muestras sin etiquetar serían las más informativas (es decir, mejorarían más el clasificador) si fueran etiquetadas y utilizadas como muestras de entrenamiento. Este problema se llama típicamente aprendizaje activo [4]. Aquí la tarea es minimizar un costo general, que depende tanto de la precisión del clasificador como del costo de la recolección de datos. Muchas aplicaciones del mundo real pueden ser adaptadas al marco de aprendizaje activo. Particularmente, consideramos el problema de la recuperación de imágenes basada en contenido impulsada por la retroalimentación de relevancia (CBIR) [13]. La Recuperación de Imágenes Basada en Contenido ha atraído un interés sustancial en la última década [13]. Está motivado por el rápido crecimiento de las bases de datos de imágenes digitales que, a su vez, requieren esquemas de búsqueda eficientes. En lugar de describir una imagen usando texto, en estos sistemas se describe una consulta de imagen utilizando una o más imágenes de ejemplo. Las características visuales de bajo nivel (color, textura, forma, etc.) se extraen automáticamente para representar las imágenes. Sin embargo, las características de bajo nivel pueden no caracterizar con precisión los conceptos semánticos de alto nivel. Para reducir la brecha semántica, se introduce la retroalimentación de relevancia en la recuperación de información basada en el contenido (CBIR) [12]. En muchos de los sistemas actuales de recuperación de imágenes basados en retroalimentación de relevancia, se requiere que el usuario proporcione sus juicios de relevancia sobre las imágenes principales devueltas por el sistema. Las imágenes etiquetadas se utilizan luego para entrenar un clasificador que separe las imágenes que coinciden con el concepto de la consulta de aquellas que no lo hacen. Sin embargo, en general, las imágenes principales que se devuelven pueden no ser las más informativas. En el peor de los casos, todas las imágenes principales etiquetadas por el usuario pueden ser positivas y, por lo tanto, las técnicas estándar de clasificación no pueden aplicarse debido a la falta de ejemplos negativos. A diferencia de los problemas de clasificación estándar donde las muestras etiquetadas están predefinidas, en la recuperación de imágenes con retroalimentación de relevancia, el sistema puede seleccionar activamente las imágenes a etiquetar. Por lo tanto, el aprendizaje activo puede ser introducido de forma natural en la recuperación de imágenes. A pesar de la existencia de muchas técnicas de aprendizaje activo, el aprendizaje activo de Máquina de Vectores de Soporte (SVM) [14] y el aprendizaje activo basado en regresión [1] han sido los que han despertado mayor interés. Basado en la observación de que cuanto más cerca del límite del SVM se encuentre una imagen, menos confiable es su clasificación, el aprendizaje activo del SVM selecciona aquellas imágenes no etiquetadas más cercanas al límite para solicitar retroalimentación del usuario con el fin de lograr un refinamiento máximo en el hiperplano entre las dos clases. La principal desventaja del aprendizaje activo de SVM es que es posible que el límite estimado no sea lo suficientemente preciso. Además, puede que no se aplique al principio de la recuperación cuando no hay imágenes etiquetadas. Algunos otros algoritmos de aprendizaje activo basados en SVM se pueden encontrar en [7], [9]. En estadística, el problema de seleccionar muestras para etiquetar se conoce típicamente como diseño experimental. La muestra x se denomina experimento, y su etiqueta y se denomina medición. El estudio del diseño experimental óptimo (DEO) se preocupa por el diseño de experimentos que se espera que minimicen las varianzas de un modelo parametrizado. La intención del diseño experimental óptimo suele ser maximizar la confianza en un modelo dado, minimizar las varianzas de los parámetros para la identificación del sistema, o minimizar la varianza de la salida de los modelos. Los enfoques clásicos de diseño experimental incluyen el Diseño A-Óptimo, el Diseño D-Óptimo y el Diseño E-Óptimo. Todos estos enfoques se basan en un modelo de regresión de mínimos cuadrados. En comparación con los algoritmos de aprendizaje activo basados en SVM, los enfoques de diseño experimental son mucho más eficientes en términos de computación. Sin embargo, este tipo de enfoques solo tienen en cuenta los datos medidos (o etiquetados) en su función objetivo, mientras que los datos no medidos (o no etiquetados) son ignorados. Beneficiar de los avances recientes en diseño experimental óptimo y aprendizaje semisupervisado, en este artículo proponemos un nuevo algoritmo de aprendizaje activo para recuperación de imágenes, llamado Diseño Óptimo Laplaciano (LOD). A diferencia de los métodos tradicionales de diseño experimental cuyas funciones de pérdida solo están definidas en los puntos medidos, la función de pérdida de nuestro algoritmo propuesto LOD está definida tanto en los puntos medidos como en los no medidos. Específicamente, introducimos un regularizador que preserva la localidad en la función de pérdida estándar basada en el error cuadrático mínimo. La nueva función de pérdida tiene como objetivo encontrar un clasificador que sea localmente lo más suave posible. En otras palabras, si dos puntos están suficientemente cerca uno del otro en el espacio de entrada, se espera que compartan la misma etiqueta. Una vez que se define la función de pérdida, podemos seleccionar los puntos de datos más informativos que se presentan al usuario para su etiquetado. Sería importante tener en cuenta que las imágenes más informativas pueden no ser las primeras imágenes devueltas. El resto del documento está organizado de la siguiente manera. En la Sección 2, proporcionamos una breve descripción del trabajo relacionado. Nuestro algoritmo propuesto de Diseño Óptimo de Laplaciano se introduce en la Sección 3. En la Sección 4, comparamos nuestro algoritmo con los algoritmos de última generación y presentamos los resultados experimentales sobre la recuperación de imágenes. Finalmente, proporcionamos algunas observaciones finales y sugerencias para trabajos futuros en la Sección 5.2. TRABAJO RELACIONADO Dado que nuestro algoritmo propuesto se basa en un marco de regresión. El trabajo más relacionado es el diseño experimental óptimo [1], que incluye el Diseño A-Óptimo, el Diseño D-Óptimo y el Diseño E-Óptimo. En esta sección, damos una breve descripción de estos enfoques. 2.1 El Problema del Aprendizaje Activo El problema genérico del aprendizaje activo es el siguiente. Dado un conjunto de puntos A = {x1, x2, · · · , xm} en Rd , encuentra un subconjunto B = {z1, z2, · · · , zk} ⊂ A que contenga los puntos más informativos. En otras palabras, los puntos zi(i = 1, · · · , k) pueden mejorar el clasificador al máximo si están etiquetados y se utilizan como puntos de entrenamiento. 2.2 Diseño Experimental Óptimo Consideramos un modelo de regresión lineal y = wT x + (1) donde y es la observación, x es la variable independiente, w es el vector de pesos y es un error desconocido con media cero. Diferentes observaciones tienen errores que son independientes, pero con varianzas iguales σ2. Definimos f(x) = wT x como la salida del aprendiz dada la entrada x y el vector de pesos w. Supongamos que tenemos un conjunto de puntos de muestra etiquetados (z1, y1), · · · , (zk, yk), donde yi es la etiqueta de zi. Por lo tanto, la estimación de máxima verosimilitud para el vector de peso, ˆw, es aquella que minimiza la suma del error cuadrado Jsse(w) = k i=1 wT zi − yi 2 (2). La estimación ˆw nos proporciona una estimación de la salida en una entrada novedosa: ˆy = ˆwT x. Según el teorema de Gauss-Markov, sabemos que ˆw − w tiene una media cero y una matriz de covarianza dada por σ2 H−1 sse, donde Hsse es la Hessiana de Jsse(w) Hsse = ∂2 Jsse ∂w2 = k i=1 zizT i = ZZT donde Z = (z1, z2, · · · , zk). Las tres medidas escalares más comunes del tamaño de la matriz de covarianza de parámetros en el diseño experimental óptimo son: • Diseño D-óptimo: determinante de Hsse. • Diseño A-óptimo: traza de Hsse. • Diseño E-óptimo: valor propio máximo de Hsse. Dado que el cálculo del determinante y los valores propios de una matriz es mucho más costoso que el cálculo de la traza de la matriz, el diseño A-óptimo es más eficiente que los otros dos. Algunos trabajos recientes sobre diseño experimental se pueden encontrar en [6], [16]. DISEÑO ÓPTIMO LAPLACIANO Dado que la matriz de covarianza Hsse utilizada en enfoques tradicionales solo depende de las muestras medidas, es decir, zis, estos enfoques no logran evaluar los errores esperados en las muestras no medidas. En esta sección, presentamos un novedoso algoritmo de aprendizaje activo llamado Diseño Óptimo Laplaciano (LOD) que hace un uso eficiente tanto de muestras medidas (etiquetadas) como no medidas (sin etiquetar). 3.1 La Función Objetivo En muchos problemas de aprendizaje automático, es natural asumir que si dos puntos xi, xj están suficientemente cerca uno del otro, entonces sus mediciones (f(xi), f(xj)) también son cercanas. Sea S una matriz de similitud. Por lo tanto, una nueva función de pérdida que respeta la estructura geométrica del espacio de datos se puede definir de la siguiente manera: J0(w) = k i=1 f(zi)−yi 2 + λ 2 m i,j=1 f(xi)−f(xj) 2 Sij (3) donde yi es la medición (o etiqueta) de zi. Se debe tener en cuenta que la función de pérdida (3) es esencialmente la misma que la utilizada en la Regresión Regularizada Laplaciana (LRR, [2]). Sin embargo, LRR es un algoritmo de aprendizaje pasivo donde se proporcionan los datos de entrenamiento. En este artículo, nos enfocamos en cómo seleccionar los datos más informativos para el entrenamiento. La función de pérdida con nuestra elección de pesos simétricos Sij (Sij = Sji) incurre en una penalización severa si los puntos vecinos xi y xj se asignan lejos uno del otro. Por lo tanto, minimizar J0(w) es un intento de asegurar que si xi y xj están cerca, entonces f(xi) y f(xj) también estén cerca. Hay muchas opciones de la matriz de similitud S. Una definición simple es la siguiente: Sij = ⎧ ⎨ ⎩ 1, si xi está entre los p vecinos más cercanos de xj, o xj está entre los p vecinos más cercanos de xi; 0, en otro caso. (4) Sea D una matriz diagonal, Dii = j Sij, y L = D−S. La matriz L se llama Laplaciano de grafo en la teoría espectral de grafos [3]. Sea y = (y1, · · · , yk)T y X = (x1, · · · , xm). Siguiendo algunos pasos algebraicos simples, vemos que: J0(w) = k i=1 wT zi − yi 2 + λ 2 m i,j=1 wT xi − wT xj 2 Sij = y − ZT w T y − ZT w + λwT m i=1 DiixixT i − m i,j=1 SijxixT j w = yT y − 2wT Zy + wT ZZT w +λwT m i=1 DiixixT i − m i,j=1 SijxixT j w = yT y − 2wT Zy + wT ZZT + λXLXT w La Hessiana de J0(w) se puede calcular de la siguiente manera: H0 = ∂2 J0 ∂w2 = ZZT + λXLXT En algunos casos, la matriz ZZT +λXLXT es singular (por ejemplo, si m < d). Por lo tanto, no hay una solución estable para el problema de optimización Ec. (3). Una forma común de abordar este problema mal planteado es introducir un regularizador de Tikhonov en nuestra función de pérdida: J(w) = k i=1 wT zi − yi 2 + λ1 2 m i,j=1 wT xi − wT xj 2 Sij +λ2 w 2 (5) El Hessiano de la nueva función de pérdida está dado por: H = ∂2 J ∂w2 = ZZT + λ1XLXT + λ2I := ZZT + Λ donde I es una matriz identidad y Λ = λ1XLXT + λ2I. Claramente, H tiene rango completo. Exigir que el gradiente de J(w) con respecto a w se anule proporciona la estimación óptima ˆw: ˆw = H−1 Zy. La siguiente proposición establece las propiedades de sesgo y varianza del estimador para el vector de coeficientes w. Proposición 3.1. E( ˆw − w) = −H−1 Λw, Cov( ˆw) = σ2 (H−1 − H−1 ΛH−1 ) Demostración. Dado que y = ZTw + y E( ) = 0, se deduce que E( ˆw − w) (6) = H−1 ZZTw − w = H−1 (ZZT + Λ − Λ)w − w = (I − H−1 Λ)w − w = −H−1 Λw (7) Nótese que Cov(y) = σ2 I, la matriz de covarianza de ˆw tiene la expresión: Cov( ˆw) = H−1 ZCov(y)ZT H−1 = σ2 H−1 ZZT H−1 = σ2 H−1 (H − Λ)H−1 = σ2 (H−1 − H−1 ΛH−1 ) (8) Por lo tanto, la matriz de error cuadrático medio para los coeficientes w es E(w − ˆw)(w − ˆw)T (9) = H−1 ΛwwT ΛH−1 + σ2 (H−1 − H−1 ΛH−1 ) (10) Para cualquier x, sea ˆy = ˆwT x su observación predicha. El error cuadrático de predicción esperado es E(y − ˆy)2 = E( + wT x − ˆwT x)2 = σ2 + xT [E(w − ˆw)(w − ˆw)T ]x = σ2 + xT [H−1 ΛwwT ΛH−1 + σ2 H−1 − σ2 H−1 ΛH−1 ]x Claramente, el error cuadrático de predicción esperado depende de la variable explicativa x, por lo tanto, el error cuadrático de predicción promedio esperado sobre el conjunto de datos completo A es 1 m m i=1 E(yi − ˆwT xi)2 = 1 m m i=1 xT i [H−1 ΛwwT ΛH−1 + σ2 H−1 − σ2 H−1 ΛH−1 ]xi +σ2 = 1 m Tr(XT [σ2 H−1 + H−1 ΛwwT ΛH−1 − σ2 H−1 ΛH−1 ]X) +σ2 Dado que Tr(XT [H−1 ΛwwT ΛH−1 − σ2 H−1 ΛH−1 ]X) Tr(σ2 XT H−1 X), nuestro criterio de optimalidad laplaciano se formula minimizando la traza de XT H−1 X. Definición 1. Diseño óptimo de Laplaciano min Z=(z1,··· ,zk) Tr XT ZZT + λ1XLXT + λ2I −1 X (11) donde z1, · · · , zk son seleccionados de {x1, · · · , xm}. 4. DISEÑO ÓPTIMO DEL NÚCLEO LAPLACIANO Enfoques canónicos de diseño experimental (por ejemplo, Los diseños A-óptimos, D-óptimos y E-óptimos solo consideran funciones lineales. No logran descubrir la geometría intrínseca en los datos cuando el espacio de datos es altamente no lineal. En esta sección, describimos cómo realizar el Diseño Experimental Laplaciano en el Espacio de Hilbert de Núcleos Reproductores (RKHS), lo que da lugar al Diseño Experimental Laplaciano de Núcleo (KLOD). Para los puntos de datos dados x1, · · · , xm ∈ X con un núcleo de Mercer positivo definido K : X ×X → R, existe un único RKHS HK de funciones de valores reales en X. Sea Kt(s) la función de s obtenida al fijar t y dejar que Kt(s) = K(s, t). HK consiste en todas las combinaciones lineales finitas de la forma ∑ i=1 αiKti con ti ∈ X y los límites de tales funciones a medida que los ti se vuelven densos en X. Tenemos Ks, Kt HK = K(s, t). 4.1 Derivación de LOD en el Espacio de Hilbert del Núcleo Reproductor. Considera el problema de optimización (5) en RKHS. Por lo tanto, buscamos una función f ∈ HK tal que se minimice la siguiente función objetivo: min f∈HK k i=1 f(zi)−yi 2 + λ1 2 m i,j=1 f(xi)−f(xj) 2 Sij+λ2 f 2 HK (12). Tenemos la siguiente proposición. Proposición 4.1. Sea H = { m i=1 αiK(·, xi)|αi ∈ R} un subespacio de HK, la solución al problema (12) está en H. Demostración. Sea H⊥ el complemento ortogonal de H, es decir, HK = H ⊕ H⊥. Por lo tanto, para cualquier función f ∈ HK, tiene una descomposición ortogonal de la siguiente manera: f = fH + fH⊥ Ahora, evaluemos f en xi: f(xi) = f, Kxi HK = fH + fH⊥ , Kxi HK = fH, Kxi HK + fH⊥ , Kxi HK Observa que Kxi ∈ H mientras que fH⊥ ∈ H⊥. Esto implica que fH⊥ , Kxi HK = 0. Por lo tanto, f(xi) = fH, Kxi HK = fH(xi). Esto completa la prueba. La Proposición 4.1 nos dice que el minimizador del problema (12) admite una representación f∗ = m i=1 αiK(·, xi). Por favor, consulte [2] para ver los detalles. Sea φ : Rd → H un mapeo de características del espacio de entrada Rd a H, y K(xi, xj) =< φ(xi), φ(xj) >. Que X denote la matriz de datos en RKHS, X = (φ(x1), φ(x2), · · · , φ(xm)). De manera similar, definimos Z = (φ(z1), φ(z2), · · · , φ(zk)). Por lo tanto, el problema de optimización en RKHS se puede escribir de la siguiente manera: min Z Tr XT ZZT + λ1XLXT + λ2I −1 X (13) Dado que la función de mapeo φ generalmente es desconocida, no hay una forma directa de resolver el problema (13). En lo siguiente, aplicamos trucos de kernel para resolver este problema de optimización. Sea X−1 la inversa de Moore-Penrose (también conocida como pseudoinversa) de X. Así, tenemos: XT ZZT + λ1XLXT + λ2I −1 X = XT XX−1 ZZT + λ1XLXT + λ2I −1 (XT )−1 XT X = XT X ZZT X + λ1XLXT X + λ2X −1 (XT )−1 XT X = XT X XT ZZT X + λ1XT XLXT X + λ2XT X −1 XT X = KXX KXZKZX + λ1KXXLKXX + λ2KXX −1 KXX donde KXX es una matriz m × m (KXX,ij = K(xi, xj)), KXZ es una matriz m×k (KXZ,ij = K(xi, zj)), y KZX es una matriz k×m (KZX,ij = K(zi, xj)). Por lo tanto, el Diseño Óptimo del Laplaciano del Núcleo se puede definir de la siguiente manera: Definición 2. En este subapartado, discutimos cómo resolver los problemas de optimización (11) y (14). Particularmente, si seleccionamos un núcleo lineal para KLOD, entonces se reduce a LOD. Por lo tanto, nos enfocaremos en el problema (14) a continuación. Se puede demostrar que el problema de optimización (14) es NP-duro. En esta subsección, desarrollamos un enfoque codicioso secuencial simple para resolver (14). Supongamos que se han seleccionado n puntos, denotados por una matriz Zn = (z1, · · · , zn). El punto (n + 1)-ésimo zn+1 puede ser seleccionado resolviendo el siguiente problema de optimización: max Zn+1=(Zn,zn+1) Tr KXX KXZn+1 KZn+1X + λ1KXXLKXX + λ2KXX −1 KXX (15) Las matrices de kernel KXZn+1 y KZn+1X pueden ser reescritas de la siguiente manera: KXZn+1 = KXZn , KXzn+1 , KZn+1X = KZnX Kzn+1X Por lo tanto, tenemos: KXZn+1 KZn+1X = KXZn KZnX + KXzn+1 Kzn+1X Definimos: A = KXZn KZnX + λ1KXXLKXX + λ2KXX A solo depende de X y Zn. Por lo tanto, el punto (n + 1)-ésimo zn+1 se da por: zn+1 = arg min zn+1 Tr KXX A + KXzn+1 Kzn+1X −1 KXX. Cada vez que seleccionamos un nuevo punto zn+1, la matriz A se actualiza por: A ← A + KXzn+1 Kzn+1X. Si la función de kernel se elige como producto interno K(x, y) = x, y, entonces HK es un espacio funcional lineal y el algoritmo se reduce a LOD. 5. RECUPERACIÓN DE IMÁGENES BASADA EN CONTENIDO UTILIZANDO DISEÑO ÓPTIMO LAPLACIANO En esta sección, describimos cómo aplicar el Diseño Óptimo Laplaciano a la RCIB. Comenzamos con una breve descripción de la representación de imágenes utilizando características visuales de nivel bajo. 5.1 Representación de Imágenes de Nivel Bajo La representación de imágenes de nivel bajo es un problema crucial en la Recuperación de Información Basada en el Contenido (CBIR). Las características visuales generales incluyen color, textura, forma, etc. Las características de color y textura son las características visuales más ampliamente utilizadas en la recuperación de información basada en contenido (CBIR). En comparación con las características de color y textura, las características de forma suelen describirse después de que las imágenes hayan sido segmentadas en regiones u objetos. Dado que la segmentación de imágenes robusta y precisa es difícil de lograr, el uso de características de forma para la recuperación de imágenes se ha limitado a aplicaciones especiales donde los objetos o regiones están fácilmente disponibles. En este trabajo, combinamos un histograma de color de 64 dimensiones y un Momento de Textura de Color (CTM, [15]) de 64 dimensiones para representar las imágenes. El histograma de color se calcula utilizando 4 × 4 × 4 contenedores en el espacio HSV. El Momento de Textura de Color es propuesto por Yu et al. [15], el cual integra las características de color y textura de la imagen en una forma compacta. CTM adopta la transformada de Fourier local como un esquema de representación de texturas y deriva ocho mapas característicos para describir diferentes aspectos de las relaciones de co-ocurrencia de píxeles de imagen en cada canal del espacio de color (SVcosH, SVsinH, V). Entonces, CTM calcula el primer y segundo momento de estos mapas como una representación de la distribución de píxeles de la imagen en color natural. Por favor, consulte [15] para más detalles. 5.2 Recuperación de imágenes con retroalimentación de relevancia La retroalimentación de relevancia es una de las técnicas más importantes para reducir la brecha entre las características visuales de bajo nivel y los conceptos semánticos de alto nivel [12]. Tradicionalmente, los comentarios de relevancia de los usuarios se utilizan para actualizar el vector de consulta o ajustar el peso de las diferentes dimensiones. Este proceso puede ser visto como un proceso de aprendizaje en línea en el que el sistema de recuperación de imágenes actúa como un aprendiz y el usuario actúa como un maestro. El proceso típico de recuperación se describe de la siguiente manera: 1. El usuario envía un ejemplo de imagen de consulta al sistema. El sistema clasifica las imágenes en la base de datos según alguna métrica de distancia predefinida y presenta al usuario las imágenes mejor clasificadas. El sistema selecciona algunas imágenes de la base de datos y solicita al usuario que las etiquete como relevantes o irrelevantes. El sistema utiliza la información proporcionada por los usuarios para reorganizar las imágenes en la base de datos y devolver al usuario las imágenes principales. Ve al paso 2 hasta que el usuario esté satisfecho. Nuestro algoritmo de Diseño Óptimo de Laplaciano se aplica en el segundo paso para seleccionar las imágenes más informativas. Una vez que obtenemos las etiquetas para las imágenes seleccionadas por LOD, aplicamos la Regresión Regularizada Laplaciana (LRR, [2]) para resolver el problema de optimización (3) y construir el clasificador. El clasificador se utiliza luego para reordenar las imágenes en la base de datos. Ten en cuenta que, para reducir la complejidad computacional, no utilizamos todas las imágenes sin etiquetar en la base de datos, sino solo aquellas dentro de los 500 primeros resultados de la iteración anterior. 6. RESULTADOS EXPERIMENTALES En esta sección, evaluamos el rendimiento de nuestro algoritmo propuesto en una gran base de datos de imágenes. Para demostrar la efectividad de nuestro algoritmo LOD propuesto, lo comparamos con la Regresión Regularizada de Laplaciano (LRR, [2]), la Máquina de Vectores de Soporte (SVM), el Aprendizaje Activo de Máquina de Vectores de Soporte (SVMactive) [14], y el Diseño A-Óptimo (AOD). Tanto SVMactive, AOD y LOD son algoritmos de aprendizaje activo, mientras que LRR y SVM son algoritmos de clasificación estándar. SVM solo hace uso de las imágenes etiquetadas, mientras que LRR es un algoritmo de aprendizaje semi-supervisado que hace uso tanto de imágenes etiquetadas como no etiquetadas. Para SVMactive, AOD y LOD, los algoritmos seleccionan 10 imágenes de entrenamiento en cada iteración. Para LRR y SVM, utilizamos las 10 imágenes principales como datos de entrenamiento. Sería importante señalar que SVMactive se basa en el SVM ordinario, LOD se basa en LRR y AOD se basa en la regresión ordinaria. Los parámetros λ1 y λ2 en nuestro algoritmo LOD se establecen empíricamente en 0.001 y 0.00001. Para ambos algoritmos LRR y LOD, utilizamos la misma estructura de grafo (ver Ecuación 4) y establecemos el valor de p (número de vecinos más cercanos) en 5. Comenzamos con un ejemplo sintético simple para dar una intuición sobre cómo funciona LOD. 6.1 Ejemplo Sintético Simple Se presenta un ejemplo sintético simple en la Figura 1. El conjunto de datos contiene dos círculos. Ocho puntos son seleccionados por AOD y LOD. Como se puede ver, todos los puntos seleccionados por AOD son del círculo grande, mientras que LOD selecciona cuatro puntos del círculo grande y cuatro del círculo pequeño. Los números junto a los puntos seleccionados indican su orden de selección. Claramente, los puntos seleccionados por nuestro algoritmo LOD pueden representar mejor el conjunto de datos original. No comparamos nuestro algoritmo con SVMactive porque SVMactive no se puede aplicar en este caso debido a la falta de puntos etiquetados. 6.2 Diseño Experimental de Recuperación de Imágenes La base de datos de imágenes que utilizamos consta de 7,900 imágenes de 79 categorías semánticas, del conjunto de datos COREL. Es un conjunto de imágenes grande y heterogéneo. Cada imagen se representa como un vector de 128 dimensiones según se describe en la Sección 5.1. La Figura 2 muestra algunas imágenes de muestra. Para exhibir las ventajas de usar nuestro algoritmo, necesitamos una forma confiable de evaluar el rendimiento de recuperación y las comparaciones con otros algoritmos. Listamos a continuación diferentes aspectos del diseño experimental. 6.2.1 Métricas de Evaluación Utilizamos la curva de precisión-alcance y la tasa de precisión [10] para evaluar la efectividad de los algoritmos de recuperación de imágenes. El alcance está especificado por el número (N) de imágenes mejor clasificadas presentadas al usuario. La precisión es la proporción entre el número de imágenes relevantes presentadas al usuario y el (a) Conjunto de datos 1 2 3 4 5 6 7 8 (b) AOD 1 2 3 4 5 6 7 8 (c) LOD Figura 1: Selección de datos por algoritmos de aprendizaje activo. Los números junto a los puntos seleccionados indican su orden de selección. Claramente, los puntos seleccionados por nuestro algoritmo LOD pueden representar mejor el conjunto de datos original. Se debe tener en cuenta que el algoritmo SVMactive no se puede aplicar en este caso debido a la falta de puntos etiquetados. (a) (b) (c) Figura 2: Imágenes de muestra de las categorías cuentas, elefante y barco. El alcance de precisión describe la precisión con varios alcances y, por lo tanto, proporciona una evaluación general del rendimiento de los algoritmos. Por otro lado, la tasa de precisión enfatiza la precisión en un valor particular de alcance. En general, es apropiado presentar 20 imágenes en una pantalla. Agregar más imágenes en una pantalla puede afectar la calidad de las imágenes presentadas. Por lo tanto, la precisión en los primeros 20 (N = 20) es especialmente importante. En los sistemas de recuperación de imágenes del mundo real, la imagen de consulta generalmente no se encuentra en la base de datos de imágenes. Para simular dicho entorno, utilizamos validación cruzada de cinco pliegues para evaluar los algoritmos. Más precisamente, dividimos toda la base de datos de imágenes en cinco subconjuntos de tamaño igual. Por lo tanto, hay 20 imágenes por categoría en cada subconjunto. En cada ejecución de validación cruzada, se selecciona un subconjunto como conjunto de consulta, y los otros cuatro subconjuntos se utilizan como base de datos para la recuperación. La curva de precisión del precisionscope y la tasa de precisión se calculan promediando los resultados de la validación cruzada de cinco pliegues. 6.2.2 Esquema de retroalimentación automática de relevancia Diseñamos un esquema de retroalimentación automática para modelar el proceso de recuperación. Para cada consulta enviada, nuestro sistema recupera y clasifica las imágenes en la base de datos. Se seleccionaron 10 imágenes de la base de datos para que los usuarios las etiqueten y la información de las etiquetas es utilizada por el sistema para volver a clasificarlas. Ten en cuenta que las imágenes seleccionadas en iteraciones anteriores están excluidas de selecciones posteriores. Para cada consulta, se realiza el mecanismo de retroalimentación automática de relevancia durante cuatro iteraciones. Es importante señalar que el esquema de retroalimentación automática de relevancia utilizado aquí es diferente de los descritos en [8], [11]. En [8], [11], las cuatro imágenes relevantes e irrelevantes principales fueron seleccionadas como las imágenes de retroalimentación. Sin embargo, esto puede no ser práctico. En los sistemas de recuperación de imágenes del mundo real, es posible que la mayoría de las imágenes mejor clasificadas sean relevantes (o irrelevantes). Por lo tanto, es difícil para el usuario encontrar tanto cuatro imágenes relevantes como irrelevantes. Es más razonable que los usuarios proporcionen información de retroalimentación solo sobre las 10 imágenes seleccionadas por el sistema. 6.3 Rendimiento de recuperación de imágenes En el mundo real, no es práctico requerir que el usuario proporcione muchas rondas de retroalimentación. El rendimiento de recuperación después de las dos primeras rondas de retroalimentación (especialmente la primera ronda) es más importante. La Figura 3 muestra las curvas de precisión-alcance promedio de los diferentes algoritmos para las dos primeras iteraciones de retroalimentación. Al principio de la recuperación, las distancias euclidianas en el espacio original de 128 dimensiones se utilizan para clasificar las imágenes en la base de datos. Después de que el usuario proporcione retroalimentación de relevancia, se aplican los algoritmos LRR, SVM, SVMactive, AOD y LOD para volver a clasificar las imágenes. Para reducir la complejidad temporal de los algoritmos de aprendizaje activo, no seleccionamos las imágenes más informativas de toda la base de datos, sino de las 500 imágenes principales. Para LRR y SVM, se requiere que el usuario etiquete las 10 imágenes principales. Para SVMactive, AOD y LOD, se requiere que el usuario etiquete las 10 imágenes más informativas seleccionadas por estos algoritmos. Tenga en cuenta que, SVMactive solo puede ser ap(a) Iteración de retroalimentación 1 (b) Iteración de retroalimentación 2 Figura 3: Las curvas de precisión promedio-alcance de diferentes algoritmos para las dos primeras iteraciones de retroalimentación. El algoritmo LOD funciona mejor en todo el alcance. Se debe tener en cuenta que, en la primera ronda de retroalimentación, el algoritmo SVMactive no se puede aplicar. Se aplica el SVM ordinario para construir el clasificador inicial. (a) Precisión en el Top 10 (b) Precisión en el Top 20 (c) Precisión en el Top 30 Figura 4: Evaluación del rendimiento de los cinco algoritmos de aprendizaje para la recuperación de imágenes con retroalimentación de relevancia. (a) Precisión en el top 10, (b) Precisión en el top 20 y (c) Precisión en el top 30. Como se puede observar, nuestro algoritmo LOD supera consistentemente a los otros cuatro algoritmos. Por lo tanto, no se puede aplicar en la primera ronda y utilizamos el SVM estándar para construir el clasificador inicial. Como se puede ver, nuestro algoritmo LOD supera a los otros cuatro algoritmos en todo el ámbito. Además, el algoritmo LRR tiene un mejor rendimiento que SVM. Esto se debe a que el algoritmo LRR hace un uso eficiente de las imágenes no etiquetadas al incorporar un regularizador de preservación de la localidad en la función objetivo de regresión ordinaria. El algoritmo AOD es el que tiene peor rendimiento. A medida que el alcance se amplía, la diferencia de rendimiento entre estos algoritmos disminuye. Al agregar de forma iterativa los comentarios de los usuarios, los resultados de precisión correspondientes (en los primeros 10, 20 y 30 lugares) de los cinco algoritmos se muestran respectivamente en la Figura 4. Como se puede ver, nuestro algoritmo LOD tiene el mejor rendimiento en todos los casos y el algoritmo LRR tiene el segundo mejor rendimiento. Ambos de estos dos algoritmos hacen uso de las imágenes sin etiquetar. Esto demuestra que las imágenes sin etiquetar son útiles para descubrir la estructura geométrica intrínseca del espacio de imágenes y, por lo tanto, mejorar el rendimiento de recuperación. En el mundo real, es posible que el usuario no esté dispuesto a proporcionar demasiadas retroalimentaciones de relevancia. Por lo tanto, el rendimiento de recuperación en las primeras dos rondas es especialmente importante. Como se puede observar, nuestro algoritmo LOD logra una mejora del rendimiento del 6.8% para los 10 mejores resultados, del 5.2% para los 20 mejores resultados y del 4.1% para los 30 mejores resultados, en comparación con el segundo mejor algoritmo (LRR) después de las dos primeras rondas de retroalimentación de relevancia. 6.4 Discusión Se han realizado sistemáticamente varios experimentos en la base de datos de Corel. Nos gustaría resaltar varios puntos interesantes: 1. Es claro que el uso del aprendizaje activo es beneficioso en el ámbito de la recuperación de imágenes. Hay un aumento significativo en el rendimiento al utilizar los métodos de aprendizaje activo. Especialmente, de los tres métodos de aprendizaje activo (SVMactive, AOD, LOD), nuestro algoritmo propuesto LOD es el que tiene mejor rendimiento. En muchas aplicaciones del mundo real, como la recuperación de imágenes con retroalimentación de relevancia, generalmente hay dos formas de reducir la tarea laboriosa de etiquetado manual. Uno es el aprendizaje activo que selecciona las muestras más informativas para etiquetar, y el otro es el aprendizaje semi-supervisado que utiliza las muestras no etiquetadas para mejorar el rendimiento del aprendizaje. Ambas estrategias han sido estudiadas extensamente en el pasado [14], [7], [5], [8]. El trabajo presentado en este artículo se centra en el aprendizaje activo, pero también aprovecha los avances recientes en el aprendizaje semi-supervisado [2]. Específicamente, incorporamos un regularizador que preserva la localidad en el marco de regresión estándar y encontramos las muestras más informativas con respecto a la nueva función objetivo. De esta manera, las técnicas de aprendizaje activo y de aprendizaje semi-supervisado se unifican de manera fluida para aprender un clasificador óptimo. 3. La técnica de retroalimentación de relevancia es crucial para la recuperación de imágenes. Para los cinco algoritmos, el rendimiento de recuperación mejora con más retroalimentación proporcionada por el usuario. CONCLUSIONES Y TRABAJOS FUTUROS Este artículo describe un novedoso algoritmo de aprendizaje activo, llamado Diseño Óptimo Laplaciano, para permitir una recuperación de imágenes con retroalimentación de relevancia más efectiva. Nuestro algoritmo se basa en una función objetivo que minimiza simultáneamente el error empírico y preserva la estructura geométrica local del espacio de datos. Utilizando técnicas de diseño experimental, nuestro algoritmo encuentra las imágenes más informativas para etiquetar. Estas imágenes etiquetadas y las imágenes sin etiquetar en la base de datos se utilizan para aprender un clasificador. Los resultados experimentales en la base de datos Corel muestran que tanto el aprendizaje activo como el aprendizaje semi-supervisado pueden mejorar significativamente el rendimiento de recuperación. En este documento, consideramos el problema de recuperación de imágenes en un conjunto de datos de imágenes pequeño, estático y de dominio cerrado. Un dominio mucho más desafiante es la World Wide Web (WWW). Para la búsqueda de imágenes en la web, es posible recopilar una gran cantidad de información sobre los clics de los usuarios. Esta información puede ser utilizada de forma natural para construir el grafo de afinidad en nuestro algoritmo. Sin embargo, la complejidad computacional en el escenario web puede convertirse en un problema crucial. Además, aunque nuestro interés principal en este artículo se centra en la recuperación de imágenes con retroalimentación de relevancia, nuestros resultados también pueden ser de interés para investigadores en <br>reconocimiento de patrones</br> y aprendizaje automático, especialmente cuando hay una gran cantidad de datos disponibles pero solo se pueden etiquetar muestras limitadas. 8. REFERENCIAS [1] A. C. Atkinson y A. N. Donev. Diseños experimentales óptimos. Oxford University Press, 2002. [2] M. Belkin, P. Niyogi, y V. Sindhwani. Regularización de variedades: Un marco geométrico para el aprendizaje a partir de ejemplos. Revista de Investigación de Aprendizaje Automático, 7:2399-2434, 2006. [3] F. R. K. Chung. Teoría Espectral de Grafos, volumen 92 de la Serie de Conferencias Regionales en Matemáticas. AMS, 1997. [4] D. A. Cohn, Z. Ghahramani y M. I. Jordan. Aprendizaje activo con modelos estadísticos. Revista de Investigación en Inteligencia Artificial, 4:129-145, 1996. [5] A. Dong y B. Bhanu. Un nuevo algoritmo EM semisupervisado para la recuperación de imágenes. En la Conferencia IEEE sobre Visión por Computadora y Reconocimiento de Patrones, Madison, WI, 2003. [6] P. Flaherty, M. I. Jordan y A. P. Arkin. Diseño robusto de experimentos biológicos. En Advances in Neural Information Processing Systems 18, Vancouver, Canadá, 2005. [7] K.-S. Goh, E. Y. Chang y W.-C. Lai. Aprendizaje activo dependiente del concepto multimodal para la recuperación de imágenes. En Actas de la Conferencia ACM sobre Multimedia, Nueva York, octubre de 2004. [8] X. Lo siento, la oración \"He.\" no tiene un significado claro en inglés. ¿Podrías proporcionar más contexto o una oración completa para que pueda traducirla al español de manera precisa? Aprendizaje de subespacios semisupervisado incremental para la recuperación de imágenes. En Actas de la Conferencia ACM sobre Multimedia, Nueva York, octubre de 2004. [9] S. C. Hoi y M. R. Lyu. Un marco de aprendizaje activo semi-supervisado para la recuperación de imágenes. En la Conferencia Internacional de IEEE sobre Visión por Computadora y Reconocimiento de Patrones, San Diego, CA, 2005. [10] D. P. Huijsmans y N. Sebe. Cómo completar los gráficos de rendimiento en la recuperación de imágenes basada en contenido: Agregar generalidad y normalizar el alcance. IEEE Transactions on Pattern Analysis and Machine Intelligence, 27(2):245-251, 2005. [11] Y.-Y.\n\nTransacciones del IEEE sobre Inteligencia Artificial y Análisis de Patrones, 27(2):245-251, 2005. [11] Y.-Y. Lin, T.-L. Liu y H.-T. Chen. Aprendizaje de variedades semánticas para la recuperación de imágenes. En Actas de la Conferencia ACM sobre Multimedia, Singapur, noviembre de 2005. [12] Y. Rui, T. S. Huang, M. Ortega y S. Mehrotra. Retroalimentación de relevancia: Una herramienta poderosa para la recuperación de imágenes basada en contenido de forma interactiva. IEEE Transactions on Circuits and Systems for Video Technology, 8(5), 1998. [13] A. W. Smeulders, M. Worring, S. Santini, A. Gupta, and R. Jain. \n\nTraducción: IEEE Transactions on Circuits and Systems for Video Technology, 8(5), 1998. [13] A. W. Smeulders, M. Worring, S. Santini, A. Gupta y R. Jain. Recuperación de imágenes basada en contenido al final de los primeros años. IEEE Transactions on Pattern Analysis and Machine Intelligence, 22(12):1349-1380, 2000. [14] S. Tong y E. Chang. Aprendizaje activo de máquina de vectores de soporte para recuperación de imágenes. En Actas de la novena conferencia internacional de ACM sobre Multimedia, páginas 107-118, 2001. [15] H. Yu, M. Li, H.-J. Zhang y J. Feng. Momentos de textura de color para la recuperación de imágenes basada en contenido. En la Conferencia Internacional de Procesamiento de Imágenes, páginas 24-28, 2002. [16] K. Yu, J. Bi y V. Tresp. Aprendizaje activo a través del diseño experimental transductivo. En Actas de la 23ª Conferencia Internacional sobre Aprendizaje Automático, Pittsburgh, PA, 2006. ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "labelling": {
            "translated_key": "etiquetado",
            "is_in_text": false,
            "original_annotated_sentences": [
                "Laplacian Optimal Design for Image Retrieval Xiaofei He Yahoo!",
                "Burbank, CA 91504 hex@yahoo-inc.com Wanli Min IBM Yorktown Heights, NY 10598 wanlimin@us.ibm.com Deng Cai CS Dept., UIUC Urbana, IL 61801 dengcai2@cs.uiuc.edu Kun Zhou Microsoft Research Asia Beijing, China kunzhou@microsoft.com ABSTRACT Relevance feedback is a powerful technique to enhance ContentBased Image Retrieval (CBIR) performance.",
                "It solicits the users relevance judgments on the retrieved images returned by the CBIR systems.",
                "The users labeling is then used to learn a classifier to distinguish between relevant and irrelevant images.",
                "However, the top returned images may not be the most informative ones.",
                "The challenge is thus to determine which unlabeled images would be the most informative (i.e., improve the classifier the most) if they were labeled and used as training samples.",
                "In this paper, we propose a novel active learning algorithm, called Laplacian Optimal Design (LOD), for relevance feedback image retrieval.",
                "Our algorithm is based on a regression model which minimizes the least square error on the measured (or, labeled) images and simultaneously preserves the local geometrical structure of the image space.",
                "Specifically, we assume that if two images are sufficiently close to each other, then their measurements (or, labels) are close as well.",
                "By constructing a nearest neighbor graph, the geometrical structure of the image space can be described by the graph Laplacian.",
                "We discuss how results from the field of optimal experimental design may be used to guide our selection of a subset of images, which gives us the most amount of information.",
                "Experimental results on Corel database suggest that the proposed approach achieves higher precision in relevance feedback image retrieval.",
                "Categories and Subject Descriptors H.3.3 [Information storage and retrieval]: Information search and retrieval-Relevance feedback; G.3 [Mathematics of Computing]: Probability and Statistics-Experimental design General Terms Algorithms, Performance, Theory 1.",
                "INTRODUCTION In many machine learning and information retrieval tasks, there is no shortage of unlabeled data but labels are expensive.",
                "The challenge is thus to determine which unlabeled samples would be the most informative (i.e., improve the classifier the most) if they were labeled and used as training samples.",
                "This problem is typically called active learning [4].",
                "Here the task is to minimize an overall cost, which depends both on the classifier accuracy and the cost of data collection.",
                "Many real world applications can be casted into active learning framework.",
                "Particularly, we consider the problem of relevance feedback driven Content-Based Image Retrieval (CBIR) [13].",
                "Content-Based Image Retrieval has attracted substantial interests in the last decade [13].",
                "It is motivated by the fast growth of digital image databases which, in turn, require efficient search schemes.",
                "Rather than describe an image using text, in these systems an image query is described using one or more example images.",
                "The low level visual features (color, texture, shape, etc.) are automatically extracted to represent the images.",
                "However, the low level features may not accurately characterize the high level semantic concepts.",
                "To narrow down the semantic gap, relevance feedback is introduced into CBIR [12].",
                "In many of the current relevance feedback driven CBIR systems, the user is required to provide his/her relevance judgments on the top images returned by the system.",
                "The labeled images are then used to train a classifier to separate images that match the query concept from those that do not.",
                "However, in general the top returned images may not be the most informative ones.",
                "In the worst case, all the top images labeled by the user may be positive and thus the standard classification techniques can not be applied due to the lack of negative examples.",
                "Unlike the standard classification problems where the labeled samples are pregiven, in relevance feedback image retrieval the system can actively select the images to label.",
                "Thus active learning can be naturally introduced into image retrieval.",
                "Despite many existing active learning techniques, Support Vector Machine (SVM) active learning [14] and regression based active learning [1] have received the most interests.",
                "Based on the observation that the closer to the SVM boundary an image is, the less reliable its classification is, SVM active learning selects those unlabeled images closest to the boundary to solicit user feedback so as to achieve maximal refinement on the hyperplane between the two classes.",
                "The major disadvantage of SVM active learning is that the estimated boundary may not be accurate enough.",
                "Moreover, it may not be applied at the beginning of the retrieval when there is no labeled images.",
                "Some other SVM based active learning algorithms can be found in [7], [9].",
                "In statistics, the problem of selecting samples to label is typically referred to as experimental design.",
                "The sample x is referred to as experiment, and its label y is referred to as measurement.",
                "The study of optimal experimental design (OED) [1] is concerned with the design of experiments that are expected to minimize variances of a parameterized model.",
                "The intent of optimal experimental design is usually to maximize confidence in a given model, minimize parameter variances for system identification, or minimize the models output variance.",
                "Classical experimental design approaches include A-Optimal Design, D-Optimal Design, and E-Optimal Design.",
                "All of these approaches are based on a least squares regression model.",
                "Comparing to SVM based active learning algorithms, experimental design approaches are much more efficient in computation.",
                "However, this kind of approaches takes only measured (or, labeled) data into account in their objective function, while the unmeasured (or, unlabeled) data is ignored.",
                "Benefit from recent progresses on optimal experimental design and semi-supervised learning, in this paper we propose a novel active learning algorithm for image retrieval, called Laplacian Optimal Design (LOD).",
                "Unlike traditional experimental design methods whose loss functions are only defined on the measured points, the loss function of our proposed LOD algorithm is defined on both measured and unmeasured points.",
                "Specifically, we introduce a locality preserving regularizer into the standard least-square-error based loss function.",
                "The new loss function aims to find a classifier which is locally as smooth as possible.",
                "In other words, if two points are sufficiently close to each other in the input space, then they are expected to share the same label.",
                "Once the loss function is defined, we can select the most informative data points which are presented to the user for labeling.",
                "It would be important to note that the most informative images may not be the top returned images.",
                "The rest of the paper is organized as follows.",
                "In Section 2, we provide a brief description of the related work.",
                "Our proposed Laplacian Optimal Design algorithm is introduced in Section 3.",
                "In Section 4, we compare our algorithm with the state-or-the-art algorithms and present the experimental results on image retrieval.",
                "Finally, we provide some concluding remarks and suggestions for future work in Section 5. 2.",
                "RELATED WORK Since our proposed algorithm is based on regression framework.",
                "The most related work is optimal experimental design [1], including A-Optimal Design, D-Optimal Design, and EOptimal Design.",
                "In this Section, we give a brief description of these approaches. 2.1 The Active Learning Problem The generic problem of active learning is the following.",
                "Given a set of points A = {x1, x2, · · · , xm} in Rd , find a subset B = {z1, z2, · · · , zk} ⊂ A which contains the most informative points.",
                "In other words, the points zi(i = 1, · · · , k) can improve the classifier the most if they are labeled and used as training points. 2.2 Optimal Experimental Design We consider a linear regression model y = wT x + (1) where y is the observation, x is the independent variable, w is the weight vector and is an unknown error with zero mean.",
                "Different observations have errors that are independent, but with equal variances σ2 .",
                "We define f(x) = wT x to be the learners output given input x and the weight vector w. Suppose we have a set of labeled sample points (z1, y1), · · · , (zk, yk), where yi is the label of zi.",
                "Thus, the maximum likelihood estimate for the weight vector, ˆw, is that which minimizes the sum squared error Jsse(w) = k i=1 wT zi − yi 2 (2) The estimate ˆw gives us an estimate of the output at a novel input: ˆy = ˆwT x.",
                "By Gauss-Markov theorem, we know that ˆw − w has a zero mean and a covariance matrix given by σ2 H−1 sse, where Hsse is the Hessian of Jsse(w) Hsse = ∂2 Jsse ∂w2 = k i=1 zizT i = ZZT where Z = (z1, z2, · · · , zk).",
                "The three most common scalar measures of the size of the parameter covariance matrix in optimal experimental design are: • D-optimal design: determinant of Hsse. • A-optimal design: trace of Hsse. • E-optimal design: maximum eigenvalue of Hsse.",
                "Since the computation of the determinant and eigenvalues of a matrix is much more expensive than the computation of matrix trace, A-optimal design is more efficient than the other two.",
                "Some recent work on experimental design can be found in [6], [16]. 3.",
                "LAPLACIAN OPTIMAL DESIGN Since the covariance matrix Hsse used in traditional approaches is only dependent on the measured samples, i.e. zis, these approaches fail to evaluate the expected errors on the unmeasured samples.",
                "In this Section, we introduce a novel active learning algorithm called Laplacian Optimal Design (LOD) which makes efficient use of both measured (labeled) and unmeasured (unlabeled) samples. 3.1 The Objective Function In many machine learning problems, it is natural to assume that if two points xi, xj are sufficiently close to each other, then their measurements (f(xi), f(xj)) are close as well.",
                "Let S be a similarity matrix.",
                "Thus, a new loss function which respects the geometrical structure of the data space can be defined as follows: J0(w) = k i=1 f(zi)−yi 2 + λ 2 m i,j=1 f(xi)−f(xj) 2 Sij (3) where yi is the measurement (or, label) of zi.",
                "Note that, the loss function (3) is essentially the same as the one used in Laplacian Regularized Regression (LRR, [2]).",
                "However, LRR is a passive learning algorithm where the training data is given.",
                "In this paper, we are focused on how to select the most informative data for training.",
                "The loss function with our choice of symmetric weights Sij (Sij = Sji) incurs a heavy penalty if neighboring points xi and xj are mapped far apart.",
                "Therefore, minimizing J0(w) is an attempt to ensure that if xi and xj are close then f(xi) and f(xj) are close as well.",
                "There are many choices of the similarity matrix S. A simple definition is as follows: Sij = ⎧ ⎨ ⎩ 1, if xi is among the p nearest neighbors of xj, or xj is among the p nearest neighbors of xi; 0, otherwise. (4) Let D be a diagonal matrix, Dii = j Sij, and L = D−S.",
                "The matrix L is called graph Laplacian in spectral graph theory [3].",
                "Let y = (y1, · · · , yk)T and X = (x1, · · · , xm).",
                "Following some simple algebraic steps, we see that: J0(w) = k i=1 wT zi − yi 2 + λ 2 m i,j=1 wT xi − wT xj 2 Sij = y − ZT w T y − ZT w + λwT m i=1 DiixixT i − m i,j=1 SijxixT j w = yT y − 2wT Zy + wT ZZT w +λwT XDXT − XSXT w = yT y − 2wT Zy + wT ZZT + λXLXT w The Hessian of J0(w) can be computed as follows: H0 = ∂2 J0 ∂w2 = ZZT + λXLXT In some cases, the matrix ZZT +λXLXT is singular (e.g. if m < d).",
                "Thus, there is no stable solution to the optimization problem Eq. (3).",
                "A common way to deal with this ill-posed problem is to introduce a Tikhonov regularizer into our loss function: J(w) = k i=1 wT zi − yi 2 + λ1 2 m i,j=1 wT xi − wT xj 2 Sij +λ2 w 2 (5) The Hessian of the new loss function is given by: H = ∂2 J ∂w2 = ZZT + λ1XLXT + λ2I := ZZT + Λ where I is an identity matrix and Λ = λ1XLXT + λ2I.",
                "Clearly, H is of full rank.",
                "Requiring that the gradient of J(w) with respect to w vanish gives the optimal estimate ˆw: ˆw = H−1 Zy The following proposition states the bias and variance properties of the estimator for the coefficient vector w. Proposition 3.1.",
                "E( ˆw − w) = −H−1 Λw, Cov( ˆw) = σ2 (H−1 − H−1 ΛH−1 ) Proof.",
                "Since y = ZT w + and E( ) = 0, it follows that E( ˆw − w) (6) = H−1 ZZT w − w = H−1 (ZZT + Λ − Λ)w − w = (I − H−1 Λ)w − w = −H−1 Λw (7) Notice Cov(y) = σ2 I, the covariance matrix of ˆw has the expression: Cov( ˆw) = H−1 ZCov(y)ZT H−1 = σ2 H−1 ZZT H−1 = σ2 H−1 (H − Λ)H−1 = σ2 (H−1 − H−1 ΛH−1 ) (8) Therefore mean squared error matrix for the coefficients w is E(w − ˆw)(w − ˆw)T (9) = H−1 ΛwwT ΛH−1 + σ2 (H−1 − H−1 ΛH−1 ) (10) For any x, let ˆy = ˆwT x be its predicted observation.",
                "The expected squared prediction error is E(y − ˆy)2 = E( + wT x − ˆwT x)2 = σ2 + xT [E(w − ˆw)(w − ˆw)T ]x = σ2 + xT [H−1 ΛwwT ΛH−1 + σ2 H−1 − σ2 H−1 ΛH−1 ]x Clearly the expected square prediction error depends on the explanatory variable x, therefore average expected square predictive error over the complete data set A is 1 m m i=1 E(yi − ˆwT xi)2 = 1 m m i=1 xT i [H−1 ΛwwT ΛH−1 + σ2 H−1 − σ2 H−1 ΛH−1 ]xi +σ2 = 1 m Tr(XT [σ2 H−1 + H−1 ΛwwT ΛH−1 − σ2 H−1 ΛH−1 ]X) +σ2 Since Tr(XT [H−1 ΛwwT ΛH−1 − σ2 H−1 ΛH−1 ]X) Tr(σ2 XT H−1 X), Our Laplacian optimality criterion is thus formulated by minimizing the trace of XT H−1 X.",
                "Definition 1.",
                "Laplacian Optimal Design min Z=(z1,··· ,zk) Tr XT ZZT + λ1XLXT + λ2I −1 X (11) where z1, · · · , zk are selected from {x1, · · · , xm}. 4.",
                "KERNEL LAPLACIAN OPTIMAL DESIGN Canonical experimental design approaches (e.g.",
                "A-Optimal Design, D-Optimal Design, and E-Optimal) only consider linear functions.",
                "They fail to discover the intrinsic geometry in the data when the data space is highly nonlinear.",
                "In this section, we describe how to perform Laplacian Experimental Design in Reproducing Kernel Hilbert Space (RKHS) which gives rise to Kernel Laplacian Experimental Design (KLOD).",
                "For given data points x1, · · · , xm ∈ X with a positive definite mercer kernel K : X ×X → R, there exists a unique RKHS HK of real valued functions on X.",
                "Let Kt(s) be the function of s obtained by fixing t and letting Kt(s) . = K(s, t).",
                "HK consists of all finite linear combinations of the form l i=1 αiKti with ti ∈ X and limits of such functions as the ti become dense in X.",
                "We have Ks, Kt HK = K(s, t). 4.1 Derivation of LOD in Reproducing Kernel Hilbert Space Consider the optimization problem (5) in RKHS.",
                "Thus, we seek a function f ∈ HK such that the following objective function is minimized: min f∈HK k i=1 f(zi)−yi 2 + λ1 2 m i,j=1 f(xi)−f(xj) 2 Sij+λ2 f 2 HK (12) We have the following proposition.",
                "Proposition 4.1.",
                "Let H = { m i=1 αiK(·, xi)|αi ∈ R} be a subspace of HK , the solution to the problem (12) is in H. Proof.",
                "Let H⊥ be the orthogonal complement of H, i.e.",
                "HK = H ⊕ H⊥ .",
                "Thus, for any function f ∈ HK , it has orthogonal decomposition as follows: f = fH + fH⊥ Now, lets evaluate f at xi: f(xi) = f, Kxi HK = fH + fH⊥ , Kxi HK = fH, Kxi HK + fH⊥ , Kxi HK Notice that Kxi ∈ H while fH⊥ ∈ H⊥ .",
                "This implies that fH⊥ , Kxi HK = 0.",
                "Therefore, f(xi) = fH, Kxi HK = fH(xi) This completes the proof.",
                "Proposition 4.1 tells us the minimizer of problem (12) admits a representation f∗ = m i=1 αiK(·, xi).",
                "Please see [2] for the details.",
                "Let φ : Rd → H be a feature map from the input space Rd to H, and K(xi, xj) =< φ(xi), φ(xj) >.",
                "Let X denote the data matrix in RKHS, X = (φ(x1), φ(x2), · · · , φ(xm)).",
                "Similarly, we define Z = (φ(z1), φ(z2), · · · , φ(zk)).",
                "Thus, the optimization problem in RKHS can be written as follows: min Z Tr XT ZZT + λ1XLXT + λ2I −1 X (13) Since the mapping function φ is generally unknown, there is no direct way to solve problem (13).",
                "In the following, we apply kernel tricks to solve this optimization problem.",
                "Let X−1 be the Moore-Penrose inverse (also known as pseudo inverse) of X.",
                "Thus, we have: XT ZZT + λ1XLXT + λ2I −1 X = XT XX−1 ZZT + λ1XLXT + λ2I −1 (XT )−1 XT X = XT X ZZT X + λ1XLXT X + λ2X −1 (XT )−1 XT X = XT X XT ZZT X + λ1XT XLXT X + λ2XT X −1 XT X = KXX KXZKZX + λ1KXXLKXX + λ2KXX −1 KXX where KXX is a m × m matrix (KXX,ij = K(xi, xj)), KXZ is a m×k matrix (KXZ,ij = K(xi, zj)), and KZX is a k×m matrix (KZX,ij = K(zi, xj)).",
                "Thus, the Kernel Laplacian Optimal Design can be defined as follows: Definition 2.",
                "Kernel Laplacian Optimal Design minZ=(z1,··· ,zk) Tr KXX KXZKZX + λ1KXXLKXX λ2KXX −1 KXX (14) 4.2 Optimization Scheme In this subsection, we discuss how to solve the optimization problems (11) and (14).",
                "Particularly, if we select a linear kernel for KLOD, then it reduces to LOD.",
                "Therefore, we will focus on problem (14) in the following.",
                "It can be shown that the optimization problem (14) is NP-hard.",
                "In this subsection, we develop a simple sequential greedy approach to solve (14).",
                "Suppose n points have been selected, denoted by a matrix Zn = (z1, · · · , zn).",
                "The (n + 1)-th point zn+1 can be selected by solving the following optimization problem: max Zn+1=(Zn,zn+1) Tr KXX KXZn+1 KZn+1X + λ1KXXLKXX + λ2KXX −1 KXX (15) The kernel matrices KXZn+1 and KZn+1X can be rewritten as follows: KXZn+1 = KXZn , KXzn+1 , KZn+1X = KZnX Kzn+1X Thus, we have: KXZn+1 KZn+1X = KXZn KZnX + KXzn+1 Kzn+1X We define: A = KXZn KZnX + λ1KXXLKXX + λ2KXX A is only dependent on X and Zn .",
                "Thus, the (n + 1)-th point zn+1 is given by: zn+1 = arg min zn+1 Tr KXX A + KXzn+1 Kzn+1X −1 KXX (16) Each time we select a new point zn+1, the matrix A is updated by: A ← A + KXzn+1 Kzn+1X If the kernel function is chosen as inner product K(x, y) = x, y , then HK is a linear functional space and the algorithm reduces to LOD. 5.",
                "CONTENT-BASED IMAGE RETRIEVAL USING LAPLACIAN OPTIMAL DESIGN In this section, we describe how to apply Laplacian Optimal Design to CBIR.",
                "We begin with a brief description of image representation using low level visual features. 5.1 Low-Level Image Representation Low-level image representation is a crucial problem in CBIR.",
                "General visual features includes color, texture, shape, etc.",
                "Color and texture features are the most extensively used visual features in CBIR.",
                "Compared with color and texture features, shape features are usually described after images have been segmented into regions or objects.",
                "Since robust and accurate image segmentation is difficult to achieve, the use of shape features for image retrieval has been limited to special applications where objects or regions are readily available.",
                "In this work, We combine 64-dimensional color histogram and 64-dimensional Color Texture Moment (CTM, [15]) to represent the images.",
                "The color histogram is calculated using 4 × 4 × 4 bins in HSV space.",
                "The Color Texture Moment is proposed by Yu et al. [15], which integrates the color and texture characteristics of the image in a compact form.",
                "CTM adopts local Fourier transform as a texture representation scheme and derives eight characteristic maps to describe different aspects of co-occurrence relations of image pixels in each channel of the (SVcosH, SVsinH, V) color space.",
                "Then CTM calculates the first and second moment of these maps as a representation of the natural color image pixel distribution.",
                "Please see [15] for details. 5.2 Relevance Feedback Image Retrieval Relevance feedback is one of the most important techniques to narrow down the gap between low level visual features and high level semantic concepts [12].",
                "Traditionally, the users relevance feedbacks are used to update the query vector or adjust the weighting of different dimensions.",
                "This process can be viewed as an on-line learning process in which the image retrieval system acts as a learner and the user acts as a teacher.",
                "They typical retrieval process is outlined as follows: 1.",
                "The user submits a query image example to the system.",
                "The system ranks the images in database according to some pre-defined distance metric and presents to the user the top ranked images. 2.",
                "The system selects some images from the database and request the user to label them as relevant or irrelevant. 3.",
                "The system uses the users provided information to rerank the images in database and returns to the user the top images.",
                "Go to step 2 until the user is satisfied.",
                "Our Laplacian Optimal Design algorithm is applied in the second step for selecting the most informative images.",
                "Once we get the labels for the images selected by LOD, we apply Laplacian Regularized Regression (LRR, [2]) to solve the optimization problem (3) and build the classifier.",
                "The classifier is then used to re-rank the images in database.",
                "Note that, in order to reduce the computational complexity, we do not use all the unlabeled images in the database but only those within top 500 returns of previous iteration. 6.",
                "EXPERIMENTAL RESULTS In this section, we evaluate the performance of our proposed algorithm on a large image database.",
                "To demonstrate the effectiveness of our proposed LOD algorithm, we compare it with Laplacian Regularized Regression (LRR, [2]), Support Vector Machine (SVM), Support Vector Machine Active Learning (SVMactive) [14], and A-Optimal Design (AOD).",
                "Both SVMactive, AOD, and LOD are active learning algorithms, while LRR and SVM are standard classification algorithms.",
                "SVM only makes use of the labeled images, while LRR is a semi-supervised learning algorithm which makes use of both labeled and unlabeled images.",
                "For SVMactive, AOD, and LOD, 10 training images are selected by the algorithms themselves at each iteration.",
                "While for LRR and SVM, we use the top 10 images as training data.",
                "It would be important to note that SVMactive is based on the ordinary SVM, LOD is based on LRR, and AOD is based on the ordinary regression.",
                "The parameters λ1 and λ2 in our LOD algorithm are empirically set to be 0.001 and 0.00001.",
                "For both LRR and LOD algorithms, we use the same graph structure (see Eq. 4) and set the value of p (number of nearest neighbors) to be 5.",
                "We begin with a simple synthetic example to give some intuition about how LOD works. 6.1 Simple Synthetic Example A simple synthetic example is given in Figure 1.",
                "The data set contains two circles.",
                "Eight points are selected by AOD and LOD.",
                "As can be seen, all the points selected by AOD are from the big circle, while LOD selects four points from the big circle and four from the small circle.",
                "The numbers beside the selected points denote their orders to be selected.",
                "Clearly, the points selected by our LOD algorithm can better represent the original data set.",
                "We did not compare our algorithm with SVMactive because SVMactive can not be applied in this case due to the lack of the labeled points. 6.2 Image Retrieval Experimental Design The image database we used consists of 7,900 images of 79 semantic categories, from COREL data set.",
                "It is a large and heterogeneous image set.",
                "Each image is represented as a 128-dimensional vector as described in Section 5.1.",
                "Figure 2 shows some sample images.",
                "To exhibit the advantages of using our algorithm, we need a reliable way of evaluating the retrieval performance and the comparisons with other algorithms.",
                "We list different aspects of the experimental design below. 6.2.1 Evaluation Metrics We use precision-scope curve and precision rate [10] to evaluate the effectiveness of the image retrieval algorithms.",
                "The scope is specified by the number (N) of top-ranked images presented to the user.",
                "The precision is the ratio of the number of relevant images presented to the user to the (a) Data set 1 2 3 4 5 6 7 8 (b) AOD 1 2 3 4 5 6 7 8 (c) LOD Figure 1: Data selection by active learning algorithms.",
                "The numbers beside the selected points denote their orders to be selected.",
                "Clearly, the points selected by our LOD algorithm can better represent the original data set.",
                "Note that, the SVMactive algorithm can not be applied in this case due to the lack of labeled points. (a) (b) (c) Figure 2: Sample images from category bead, elephant, and ship. scope N. The precision-scope curve describes the precision with various scopes and thus gives an overall performance evaluation of the algorithms.",
                "On the other hand, the precision rate emphasizes the precision at a particular value of scope.",
                "In general, it is appropriate to present 20 images on a screen.",
                "Putting more images on a screen may affect the quality of the presented images.",
                "Therefore, the precision at top 20 (N = 20) is especially important.",
                "In real world image retrieval systems, the query image is usually not in the image database.",
                "To simulate such environment, we use five-fold cross validation to evaluate the algorithms.",
                "More precisely, we divide the whole image database into five subsets with equal size.",
                "Thus, there are 20 images per category in each subset.",
                "At each run of cross validation, one subset is selected as the query set, and the other four subsets are used as the database for retrieval.",
                "The precisionscope curve and precision rate are computed by averaging the results from the five-fold cross validation. 6.2.2 Automatic Relevance Feedback Scheme We designed an automatic feedback scheme to model the retrieval process.",
                "For each submitted query, our system retrieves and ranks the images in the database. 10 images were selected from the database for user labeling and the label information is used by the system for re-ranking.",
                "Note that, the images which have been selected at previous iterations are excluded from later selections.",
                "For each query, the automatic relevance feedback mechanism is performed for four iterations.",
                "It is important to note that the automatic relevance feedback scheme used here is different from the ones described in [8], [11].",
                "In [8], [11], the top four relevant and irrelevant images were selected as the feedback images.",
                "However, this may not be practical.",
                "In real world image retrieval systems, it is possible that most of the top-ranked images are relevant (or, irrelevant).",
                "Thus, it is difficult for the user to find both four relevant and irrelevant images.",
                "It is more reasonable for the users to provide feedback information only on the 10 images selected by the system. 6.3 Image Retrieval Performance In real world, it is not practical to require the user to provide many rounds of feedbacks.",
                "The retrieval performance after the first two rounds of feedbacks (especially the first round) is more important.",
                "Figure 3 shows the average precision-scope curves of the different algorithms for the first two feedback iterations.",
                "At the beginning of retrieval, the Euclidean distances in the original 128-dimensional space are used to rank the images in database.",
                "After the user provides relevance feedbacks, the LRR, SVM, SVMactive, AOD, and LOD algorithms are then applied to re-rank the images.",
                "In order to reduce the time complexity of active learning algorithms, we didnt select the most informative images from the whole database but from the top 500 images.",
                "For LRR and SVM, the user is required to label the top 10 images.",
                "For SVMactive, AOD, and LOD, the user is required to label 10 most informative images selected by these algorithms.",
                "Note that, SVMactive can only be ap(a) Feedback Iteration 1 (b) Feedback Iteration 2 Figure 3: The average precision-scope curves of different algorithms for the first two feedback iterations.",
                "The LOD algorithm performs the best on the entire scope.",
                "Note that, at the first round of feedback, the SVMactive algorithm can not be applied.",
                "It applies the ordinary SVM to build the initial classifier. (a) Precision at Top 10 (b) Precision at Top 20 (c) Precision at Top 30 Figure 4: Performance evaluation of the five learning algorithms for relevance feedback image retrieval. (a) Precision at top 10, (b) Precision at top 20, and (c) Precision at top 30.",
                "As can be seen, our LOD algorithm consistently outperforms the other four algorithms. plied when the classifier is already built.",
                "Therefore, it can not be applied at the first round and we use the standard SVM to build the initial classifier.",
                "As can be seen, our LOD algorithm outperforms the other four algorithms on the entire scope.",
                "Also, the LRR algorithm performs better than SVM.",
                "This is because that the LRR algorithm makes efficient use of the unlabeled images by incorporating a locality preserving regularizer into the ordinary regression objective function.",
                "The AOD algorithm performs the worst.",
                "As the scope gets larger, the performance difference between these algorithms gets smaller.",
                "By iteratively adding the users feedbacks, the corresponding precision results (at top 10, top 20, and top 30) of the five algorithms are respectively shown in Figure 4.",
                "As can be seen, our LOD algorithm performs the best in all the cases and the LRR algorithm performs the second best.",
                "Both of these two algorithms make use of the unlabeled images.",
                "This shows that the unlabeled images are helpful for discovering the intrinsic geometrical structure of the image space and therefore enhance the retrieval performance.",
                "In real world, the user may not be willing to provide too many relevance feedbacks.",
                "Therefore, the retrieval performance at the first two rounds are especially important.",
                "As can be seen, our LOD algorithm achieves 6.8% performance improvement for top 10 results, 5.2% for top 20 results, and 4.1% for top 30 results, comparing to the second best algorithm (LRR) after the first two rounds of relevance feedbacks. 6.4 Discussion Several experiments on Corel database have been systematically performed.",
                "We would like to highlight several interesting points: 1.",
                "It is clear that the use of active learning is beneficial in the image retrieval domain.",
                "There is a significant increase in performance from using the active learning methods.",
                "Especially, out of the three active learning methods (SVMactive, AOD, LOD), our proposed LOD algorithm performs the best. 2.",
                "In many real world applications like relevance feedback image retrieval, there are generally two ways of reducing labor-intensive manual labeling task.",
                "One is active learning which selects the most informative samples to label, and the other is semi-supervised learning which makes use of the unlabeled samples to enhance the learning performance.",
                "Both of these two strategies have been studied extensively in the past [14], [7], [5], [8].",
                "The work presented in this paper is focused on active learning, but it also takes advantage of the recent progresses on semi-supervised learning [2].",
                "Specifically, we incorporate a locality preserving regularizer into the standard regression framework and find the most informative samples with respect to the new objective function.",
                "In this way, the active learning and semi-supervised learning techniques are seamlessly unified for learning an optimal classifier. 3.",
                "The relevance feedback technique is crucial to image retrieval.",
                "For all the five algorithms, the retrieval performance improves with more feedbacks provided by the user. 7.",
                "CONCLUSIONS AND FUTURE WORK This paper describes a novel active learning algorithm, called Laplacian Optimal Design, to enable more effective relevance feedback image retrieval.",
                "Our algorithm is based on an objective function which simultaneously minimizes the empirical error and preserves the local geometrical structure of the data space.",
                "Using techniques from experimental design, our algorithm finds the most informative images to label.",
                "These labeled images and the unlabeled images in the database are used to learn a classifier.",
                "The experimental results on Corel database show that both active learning and semi-supervised learning can significantly improve the retrieval performance.",
                "In this paper, we consider the image retrieval problem on a small, static, and closed-domain image data.",
                "A much more challenging domain is the World Wide Web (WWW).",
                "For Web image search, it is possible to collect a large amount of user click information.",
                "This information can be naturally used to construct the affinity graph in our algorithm.",
                "However, the computational complexity in Web scenario may become a crucial issue.",
                "Also, although our primary interest in this paper is focused on relevance feedback image retrieval, our results may also be of interest to researchers in patten recognition and machine learning, especially when a large amount of data is available but only a limited samples can be labeled. 8.",
                "REFERENCES [1] A. C. Atkinson and A. N. Donev.",
                "Optimum Experimental Designs.",
                "Oxford University Press, 2002. [2] M. Belkin, P. Niyogi, and V. Sindhwani.",
                "Manifold regularization: A geometric framework for learning from examples.",
                "Journal of Machine Learning Research, 7:2399-2434, 2006. [3] F. R. K. Chung.",
                "Spectral Graph Theory, volume 92 of Regional Conference Series in Mathematics.",
                "AMS, 1997. [4] D. A. Cohn, Z. Ghahramani, and M. I. Jordan.",
                "Active learning with statistical models.",
                "Journal of Artificial Intelligence Research, 4:129-145, 1996. [5] A. Dong and B. Bhanu.",
                "A new semi-supervised em algorithm for image retrieval.",
                "In IEEE Conf. on Computer Vision and Pattern Recognition, Madison, WI, 2003. [6] P. Flaherty, M. I. Jordan, and A. P. Arkin.",
                "Robust design of biological experiments.",
                "In Advances in Neural Information Processing Systems 18, Vancouver, Canada, 2005. [7] K.-S. Goh, E. Y. Chang, and W.-C. Lai.",
                "Multimodal concept-dependent active learning for image retrieval.",
                "In Proceedings of the ACM Conference on Multimedia, New York, October 2004. [8] X.",
                "He.",
                "Incremental semi-supervised subspace learning for image retrieval.",
                "In Proceedings of the ACM Conference on Multimedia, New York, October 2004. [9] S. C. Hoi and M. R. Lyu.",
                "A semi-supervised active learning framework for image retrieval.",
                "In IEEE International Conference on Computer Vision and Pattern Recognition, San Diego, CA, 2005. [10] D. P. Huijsmans and N. Sebe.",
                "How to complete performance graphs in content-based image retrieval: Add generality and normalize scope.",
                "IEEE Transactions on Pattern Analysis and Machine Intelligence, 27(2):245-251, 2005. [11] Y.-Y.",
                "Lin, T.-L. Liu, and H.-T. Chen.",
                "Semantic manifold learning for image retrieval.",
                "In Proceedings of the ACM Conference on Multimedia, Singapore, November 2005. [12] Y. Rui, T. S. Huang, M. Ortega, and S. Mehrotra.",
                "Relevance feedback: A power tool for interative content-based image retrieval.",
                "IEEE Transactions on Circuits and Systems for Video Technology, 8(5), 1998. [13] A. W. Smeulders, M. Worring, S. Santini, A. Gupta, and R. Jain.",
                "Content-based image retrieval at the end of the early years.",
                "IEEE Transactions on Pattern Analysis and Machine Intelligence, 22(12):1349-1380, 2000. [14] S. Tong and E. Chang.",
                "Support vector machine active learning for image retrieval.",
                "In Proceedings of the ninth ACM international conference on Multimedia, pages 107-118, 2001. [15] H. Yu, M. Li, H.-J.",
                "Zhang, and J. Feng.",
                "Color texture moments for content-based image retrieval.",
                "In International Conference on Image Processing, pages 24-28, 2002. [16] K. Yu, J. Bi, and V. Tresp.",
                "Active learning via transductive experimental design.",
                "In Proceedings of the 23rd International Conference on Machine Learning, Pittsburgh, PA, 2006."
            ],
            "original_annotated_samples": [],
            "translated_annotated_samples": [],
            "translated_text": "",
            "candidates": [],
            "error": [
                []
            ]
        },
        "image retrieval": {
            "translated_key": "recuperación de imágenes",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Laplacian Optimal Design for <br>image retrieval</br> Xiaofei He Yahoo!",
                "Burbank, CA 91504 hex@yahoo-inc.com Wanli Min IBM Yorktown Heights, NY 10598 wanlimin@us.ibm.com Deng Cai CS Dept., UIUC Urbana, IL 61801 dengcai2@cs.uiuc.edu Kun Zhou Microsoft Research Asia Beijing, China kunzhou@microsoft.com ABSTRACT Relevance feedback is a powerful technique to enhance ContentBased <br>image retrieval</br> (CBIR) performance.",
                "It solicits the users relevance judgments on the retrieved images returned by the CBIR systems.",
                "The users labeling is then used to learn a classifier to distinguish between relevant and irrelevant images.",
                "However, the top returned images may not be the most informative ones.",
                "The challenge is thus to determine which unlabeled images would be the most informative (i.e., improve the classifier the most) if they were labeled and used as training samples.",
                "In this paper, we propose a novel active learning algorithm, called Laplacian Optimal Design (LOD), for relevance feedback <br>image retrieval</br>.",
                "Our algorithm is based on a regression model which minimizes the least square error on the measured (or, labeled) images and simultaneously preserves the local geometrical structure of the image space.",
                "Specifically, we assume that if two images are sufficiently close to each other, then their measurements (or, labels) are close as well.",
                "By constructing a nearest neighbor graph, the geometrical structure of the image space can be described by the graph Laplacian.",
                "We discuss how results from the field of optimal experimental design may be used to guide our selection of a subset of images, which gives us the most amount of information.",
                "Experimental results on Corel database suggest that the proposed approach achieves higher precision in relevance feedback <br>image retrieval</br>.",
                "Categories and Subject Descriptors H.3.3 [Information storage and retrieval]: Information search and retrieval-Relevance feedback; G.3 [Mathematics of Computing]: Probability and Statistics-Experimental design General Terms Algorithms, Performance, Theory 1.",
                "INTRODUCTION In many machine learning and information retrieval tasks, there is no shortage of unlabeled data but labels are expensive.",
                "The challenge is thus to determine which unlabeled samples would be the most informative (i.e., improve the classifier the most) if they were labeled and used as training samples.",
                "This problem is typically called active learning [4].",
                "Here the task is to minimize an overall cost, which depends both on the classifier accuracy and the cost of data collection.",
                "Many real world applications can be casted into active learning framework.",
                "Particularly, we consider the problem of relevance feedback driven Content-Based <br>image retrieval</br> (CBIR) [13].",
                "Content-Based <br>image retrieval</br> has attracted substantial interests in the last decade [13].",
                "It is motivated by the fast growth of digital image databases which, in turn, require efficient search schemes.",
                "Rather than describe an image using text, in these systems an image query is described using one or more example images.",
                "The low level visual features (color, texture, shape, etc.) are automatically extracted to represent the images.",
                "However, the low level features may not accurately characterize the high level semantic concepts.",
                "To narrow down the semantic gap, relevance feedback is introduced into CBIR [12].",
                "In many of the current relevance feedback driven CBIR systems, the user is required to provide his/her relevance judgments on the top images returned by the system.",
                "The labeled images are then used to train a classifier to separate images that match the query concept from those that do not.",
                "However, in general the top returned images may not be the most informative ones.",
                "In the worst case, all the top images labeled by the user may be positive and thus the standard classification techniques can not be applied due to the lack of negative examples.",
                "Unlike the standard classification problems where the labeled samples are pregiven, in relevance feedback <br>image retrieval</br> the system can actively select the images to label.",
                "Thus active learning can be naturally introduced into <br>image retrieval</br>.",
                "Despite many existing active learning techniques, Support Vector Machine (SVM) active learning [14] and regression based active learning [1] have received the most interests.",
                "Based on the observation that the closer to the SVM boundary an image is, the less reliable its classification is, SVM active learning selects those unlabeled images closest to the boundary to solicit user feedback so as to achieve maximal refinement on the hyperplane between the two classes.",
                "The major disadvantage of SVM active learning is that the estimated boundary may not be accurate enough.",
                "Moreover, it may not be applied at the beginning of the retrieval when there is no labeled images.",
                "Some other SVM based active learning algorithms can be found in [7], [9].",
                "In statistics, the problem of selecting samples to label is typically referred to as experimental design.",
                "The sample x is referred to as experiment, and its label y is referred to as measurement.",
                "The study of optimal experimental design (OED) [1] is concerned with the design of experiments that are expected to minimize variances of a parameterized model.",
                "The intent of optimal experimental design is usually to maximize confidence in a given model, minimize parameter variances for system identification, or minimize the models output variance.",
                "Classical experimental design approaches include A-Optimal Design, D-Optimal Design, and E-Optimal Design.",
                "All of these approaches are based on a least squares regression model.",
                "Comparing to SVM based active learning algorithms, experimental design approaches are much more efficient in computation.",
                "However, this kind of approaches takes only measured (or, labeled) data into account in their objective function, while the unmeasured (or, unlabeled) data is ignored.",
                "Benefit from recent progresses on optimal experimental design and semi-supervised learning, in this paper we propose a novel active learning algorithm for <br>image retrieval</br>, called Laplacian Optimal Design (LOD).",
                "Unlike traditional experimental design methods whose loss functions are only defined on the measured points, the loss function of our proposed LOD algorithm is defined on both measured and unmeasured points.",
                "Specifically, we introduce a locality preserving regularizer into the standard least-square-error based loss function.",
                "The new loss function aims to find a classifier which is locally as smooth as possible.",
                "In other words, if two points are sufficiently close to each other in the input space, then they are expected to share the same label.",
                "Once the loss function is defined, we can select the most informative data points which are presented to the user for labeling.",
                "It would be important to note that the most informative images may not be the top returned images.",
                "The rest of the paper is organized as follows.",
                "In Section 2, we provide a brief description of the related work.",
                "Our proposed Laplacian Optimal Design algorithm is introduced in Section 3.",
                "In Section 4, we compare our algorithm with the state-or-the-art algorithms and present the experimental results on <br>image retrieval</br>.",
                "Finally, we provide some concluding remarks and suggestions for future work in Section 5. 2.",
                "RELATED WORK Since our proposed algorithm is based on regression framework.",
                "The most related work is optimal experimental design [1], including A-Optimal Design, D-Optimal Design, and EOptimal Design.",
                "In this Section, we give a brief description of these approaches. 2.1 The Active Learning Problem The generic problem of active learning is the following.",
                "Given a set of points A = {x1, x2, · · · , xm} in Rd , find a subset B = {z1, z2, · · · , zk} ⊂ A which contains the most informative points.",
                "In other words, the points zi(i = 1, · · · , k) can improve the classifier the most if they are labeled and used as training points. 2.2 Optimal Experimental Design We consider a linear regression model y = wT x + (1) where y is the observation, x is the independent variable, w is the weight vector and is an unknown error with zero mean.",
                "Different observations have errors that are independent, but with equal variances σ2 .",
                "We define f(x) = wT x to be the learners output given input x and the weight vector w. Suppose we have a set of labeled sample points (z1, y1), · · · , (zk, yk), where yi is the label of zi.",
                "Thus, the maximum likelihood estimate for the weight vector, ˆw, is that which minimizes the sum squared error Jsse(w) = k i=1 wT zi − yi 2 (2) The estimate ˆw gives us an estimate of the output at a novel input: ˆy = ˆwT x.",
                "By Gauss-Markov theorem, we know that ˆw − w has a zero mean and a covariance matrix given by σ2 H−1 sse, where Hsse is the Hessian of Jsse(w) Hsse = ∂2 Jsse ∂w2 = k i=1 zizT i = ZZT where Z = (z1, z2, · · · , zk).",
                "The three most common scalar measures of the size of the parameter covariance matrix in optimal experimental design are: • D-optimal design: determinant of Hsse. • A-optimal design: trace of Hsse. • E-optimal design: maximum eigenvalue of Hsse.",
                "Since the computation of the determinant and eigenvalues of a matrix is much more expensive than the computation of matrix trace, A-optimal design is more efficient than the other two.",
                "Some recent work on experimental design can be found in [6], [16]. 3.",
                "LAPLACIAN OPTIMAL DESIGN Since the covariance matrix Hsse used in traditional approaches is only dependent on the measured samples, i.e. zis, these approaches fail to evaluate the expected errors on the unmeasured samples.",
                "In this Section, we introduce a novel active learning algorithm called Laplacian Optimal Design (LOD) which makes efficient use of both measured (labeled) and unmeasured (unlabeled) samples. 3.1 The Objective Function In many machine learning problems, it is natural to assume that if two points xi, xj are sufficiently close to each other, then their measurements (f(xi), f(xj)) are close as well.",
                "Let S be a similarity matrix.",
                "Thus, a new loss function which respects the geometrical structure of the data space can be defined as follows: J0(w) = k i=1 f(zi)−yi 2 + λ 2 m i,j=1 f(xi)−f(xj) 2 Sij (3) where yi is the measurement (or, label) of zi.",
                "Note that, the loss function (3) is essentially the same as the one used in Laplacian Regularized Regression (LRR, [2]).",
                "However, LRR is a passive learning algorithm where the training data is given.",
                "In this paper, we are focused on how to select the most informative data for training.",
                "The loss function with our choice of symmetric weights Sij (Sij = Sji) incurs a heavy penalty if neighboring points xi and xj are mapped far apart.",
                "Therefore, minimizing J0(w) is an attempt to ensure that if xi and xj are close then f(xi) and f(xj) are close as well.",
                "There are many choices of the similarity matrix S. A simple definition is as follows: Sij = ⎧ ⎨ ⎩ 1, if xi is among the p nearest neighbors of xj, or xj is among the p nearest neighbors of xi; 0, otherwise. (4) Let D be a diagonal matrix, Dii = j Sij, and L = D−S.",
                "The matrix L is called graph Laplacian in spectral graph theory [3].",
                "Let y = (y1, · · · , yk)T and X = (x1, · · · , xm).",
                "Following some simple algebraic steps, we see that: J0(w) = k i=1 wT zi − yi 2 + λ 2 m i,j=1 wT xi − wT xj 2 Sij = y − ZT w T y − ZT w + λwT m i=1 DiixixT i − m i,j=1 SijxixT j w = yT y − 2wT Zy + wT ZZT w +λwT XDXT − XSXT w = yT y − 2wT Zy + wT ZZT + λXLXT w The Hessian of J0(w) can be computed as follows: H0 = ∂2 J0 ∂w2 = ZZT + λXLXT In some cases, the matrix ZZT +λXLXT is singular (e.g. if m < d).",
                "Thus, there is no stable solution to the optimization problem Eq. (3).",
                "A common way to deal with this ill-posed problem is to introduce a Tikhonov regularizer into our loss function: J(w) = k i=1 wT zi − yi 2 + λ1 2 m i,j=1 wT xi − wT xj 2 Sij +λ2 w 2 (5) The Hessian of the new loss function is given by: H = ∂2 J ∂w2 = ZZT + λ1XLXT + λ2I := ZZT + Λ where I is an identity matrix and Λ = λ1XLXT + λ2I.",
                "Clearly, H is of full rank.",
                "Requiring that the gradient of J(w) with respect to w vanish gives the optimal estimate ˆw: ˆw = H−1 Zy The following proposition states the bias and variance properties of the estimator for the coefficient vector w. Proposition 3.1.",
                "E( ˆw − w) = −H−1 Λw, Cov( ˆw) = σ2 (H−1 − H−1 ΛH−1 ) Proof.",
                "Since y = ZT w + and E( ) = 0, it follows that E( ˆw − w) (6) = H−1 ZZT w − w = H−1 (ZZT + Λ − Λ)w − w = (I − H−1 Λ)w − w = −H−1 Λw (7) Notice Cov(y) = σ2 I, the covariance matrix of ˆw has the expression: Cov( ˆw) = H−1 ZCov(y)ZT H−1 = σ2 H−1 ZZT H−1 = σ2 H−1 (H − Λ)H−1 = σ2 (H−1 − H−1 ΛH−1 ) (8) Therefore mean squared error matrix for the coefficients w is E(w − ˆw)(w − ˆw)T (9) = H−1 ΛwwT ΛH−1 + σ2 (H−1 − H−1 ΛH−1 ) (10) For any x, let ˆy = ˆwT x be its predicted observation.",
                "The expected squared prediction error is E(y − ˆy)2 = E( + wT x − ˆwT x)2 = σ2 + xT [E(w − ˆw)(w − ˆw)T ]x = σ2 + xT [H−1 ΛwwT ΛH−1 + σ2 H−1 − σ2 H−1 ΛH−1 ]x Clearly the expected square prediction error depends on the explanatory variable x, therefore average expected square predictive error over the complete data set A is 1 m m i=1 E(yi − ˆwT xi)2 = 1 m m i=1 xT i [H−1 ΛwwT ΛH−1 + σ2 H−1 − σ2 H−1 ΛH−1 ]xi +σ2 = 1 m Tr(XT [σ2 H−1 + H−1 ΛwwT ΛH−1 − σ2 H−1 ΛH−1 ]X) +σ2 Since Tr(XT [H−1 ΛwwT ΛH−1 − σ2 H−1 ΛH−1 ]X) Tr(σ2 XT H−1 X), Our Laplacian optimality criterion is thus formulated by minimizing the trace of XT H−1 X.",
                "Definition 1.",
                "Laplacian Optimal Design min Z=(z1,··· ,zk) Tr XT ZZT + λ1XLXT + λ2I −1 X (11) where z1, · · · , zk are selected from {x1, · · · , xm}. 4.",
                "KERNEL LAPLACIAN OPTIMAL DESIGN Canonical experimental design approaches (e.g.",
                "A-Optimal Design, D-Optimal Design, and E-Optimal) only consider linear functions.",
                "They fail to discover the intrinsic geometry in the data when the data space is highly nonlinear.",
                "In this section, we describe how to perform Laplacian Experimental Design in Reproducing Kernel Hilbert Space (RKHS) which gives rise to Kernel Laplacian Experimental Design (KLOD).",
                "For given data points x1, · · · , xm ∈ X with a positive definite mercer kernel K : X ×X → R, there exists a unique RKHS HK of real valued functions on X.",
                "Let Kt(s) be the function of s obtained by fixing t and letting Kt(s) . = K(s, t).",
                "HK consists of all finite linear combinations of the form l i=1 αiKti with ti ∈ X and limits of such functions as the ti become dense in X.",
                "We have Ks, Kt HK = K(s, t). 4.1 Derivation of LOD in Reproducing Kernel Hilbert Space Consider the optimization problem (5) in RKHS.",
                "Thus, we seek a function f ∈ HK such that the following objective function is minimized: min f∈HK k i=1 f(zi)−yi 2 + λ1 2 m i,j=1 f(xi)−f(xj) 2 Sij+λ2 f 2 HK (12) We have the following proposition.",
                "Proposition 4.1.",
                "Let H = { m i=1 αiK(·, xi)|αi ∈ R} be a subspace of HK , the solution to the problem (12) is in H. Proof.",
                "Let H⊥ be the orthogonal complement of H, i.e.",
                "HK = H ⊕ H⊥ .",
                "Thus, for any function f ∈ HK , it has orthogonal decomposition as follows: f = fH + fH⊥ Now, lets evaluate f at xi: f(xi) = f, Kxi HK = fH + fH⊥ , Kxi HK = fH, Kxi HK + fH⊥ , Kxi HK Notice that Kxi ∈ H while fH⊥ ∈ H⊥ .",
                "This implies that fH⊥ , Kxi HK = 0.",
                "Therefore, f(xi) = fH, Kxi HK = fH(xi) This completes the proof.",
                "Proposition 4.1 tells us the minimizer of problem (12) admits a representation f∗ = m i=1 αiK(·, xi).",
                "Please see [2] for the details.",
                "Let φ : Rd → H be a feature map from the input space Rd to H, and K(xi, xj) =< φ(xi), φ(xj) >.",
                "Let X denote the data matrix in RKHS, X = (φ(x1), φ(x2), · · · , φ(xm)).",
                "Similarly, we define Z = (φ(z1), φ(z2), · · · , φ(zk)).",
                "Thus, the optimization problem in RKHS can be written as follows: min Z Tr XT ZZT + λ1XLXT + λ2I −1 X (13) Since the mapping function φ is generally unknown, there is no direct way to solve problem (13).",
                "In the following, we apply kernel tricks to solve this optimization problem.",
                "Let X−1 be the Moore-Penrose inverse (also known as pseudo inverse) of X.",
                "Thus, we have: XT ZZT + λ1XLXT + λ2I −1 X = XT XX−1 ZZT + λ1XLXT + λ2I −1 (XT )−1 XT X = XT X ZZT X + λ1XLXT X + λ2X −1 (XT )−1 XT X = XT X XT ZZT X + λ1XT XLXT X + λ2XT X −1 XT X = KXX KXZKZX + λ1KXXLKXX + λ2KXX −1 KXX where KXX is a m × m matrix (KXX,ij = K(xi, xj)), KXZ is a m×k matrix (KXZ,ij = K(xi, zj)), and KZX is a k×m matrix (KZX,ij = K(zi, xj)).",
                "Thus, the Kernel Laplacian Optimal Design can be defined as follows: Definition 2.",
                "Kernel Laplacian Optimal Design minZ=(z1,··· ,zk) Tr KXX KXZKZX + λ1KXXLKXX λ2KXX −1 KXX (14) 4.2 Optimization Scheme In this subsection, we discuss how to solve the optimization problems (11) and (14).",
                "Particularly, if we select a linear kernel for KLOD, then it reduces to LOD.",
                "Therefore, we will focus on problem (14) in the following.",
                "It can be shown that the optimization problem (14) is NP-hard.",
                "In this subsection, we develop a simple sequential greedy approach to solve (14).",
                "Suppose n points have been selected, denoted by a matrix Zn = (z1, · · · , zn).",
                "The (n + 1)-th point zn+1 can be selected by solving the following optimization problem: max Zn+1=(Zn,zn+1) Tr KXX KXZn+1 KZn+1X + λ1KXXLKXX + λ2KXX −1 KXX (15) The kernel matrices KXZn+1 and KZn+1X can be rewritten as follows: KXZn+1 = KXZn , KXzn+1 , KZn+1X = KZnX Kzn+1X Thus, we have: KXZn+1 KZn+1X = KXZn KZnX + KXzn+1 Kzn+1X We define: A = KXZn KZnX + λ1KXXLKXX + λ2KXX A is only dependent on X and Zn .",
                "Thus, the (n + 1)-th point zn+1 is given by: zn+1 = arg min zn+1 Tr KXX A + KXzn+1 Kzn+1X −1 KXX (16) Each time we select a new point zn+1, the matrix A is updated by: A ← A + KXzn+1 Kzn+1X If the kernel function is chosen as inner product K(x, y) = x, y , then HK is a linear functional space and the algorithm reduces to LOD. 5.",
                "CONTENT-BASED <br>image retrieval</br> USING LAPLACIAN OPTIMAL DESIGN In this section, we describe how to apply Laplacian Optimal Design to CBIR.",
                "We begin with a brief description of image representation using low level visual features. 5.1 Low-Level Image Representation Low-level image representation is a crucial problem in CBIR.",
                "General visual features includes color, texture, shape, etc.",
                "Color and texture features are the most extensively used visual features in CBIR.",
                "Compared with color and texture features, shape features are usually described after images have been segmented into regions or objects.",
                "Since robust and accurate image segmentation is difficult to achieve, the use of shape features for <br>image retrieval</br> has been limited to special applications where objects or regions are readily available.",
                "In this work, We combine 64-dimensional color histogram and 64-dimensional Color Texture Moment (CTM, [15]) to represent the images.",
                "The color histogram is calculated using 4 × 4 × 4 bins in HSV space.",
                "The Color Texture Moment is proposed by Yu et al. [15], which integrates the color and texture characteristics of the image in a compact form.",
                "CTM adopts local Fourier transform as a texture representation scheme and derives eight characteristic maps to describe different aspects of co-occurrence relations of image pixels in each channel of the (SVcosH, SVsinH, V) color space.",
                "Then CTM calculates the first and second moment of these maps as a representation of the natural color image pixel distribution.",
                "Please see [15] for details. 5.2 Relevance Feedback <br>image retrieval</br> Relevance feedback is one of the most important techniques to narrow down the gap between low level visual features and high level semantic concepts [12].",
                "Traditionally, the users relevance feedbacks are used to update the query vector or adjust the weighting of different dimensions.",
                "This process can be viewed as an on-line learning process in which the <br>image retrieval</br> system acts as a learner and the user acts as a teacher.",
                "They typical retrieval process is outlined as follows: 1.",
                "The user submits a query image example to the system.",
                "The system ranks the images in database according to some pre-defined distance metric and presents to the user the top ranked images. 2.",
                "The system selects some images from the database and request the user to label them as relevant or irrelevant. 3.",
                "The system uses the users provided information to rerank the images in database and returns to the user the top images.",
                "Go to step 2 until the user is satisfied.",
                "Our Laplacian Optimal Design algorithm is applied in the second step for selecting the most informative images.",
                "Once we get the labels for the images selected by LOD, we apply Laplacian Regularized Regression (LRR, [2]) to solve the optimization problem (3) and build the classifier.",
                "The classifier is then used to re-rank the images in database.",
                "Note that, in order to reduce the computational complexity, we do not use all the unlabeled images in the database but only those within top 500 returns of previous iteration. 6.",
                "EXPERIMENTAL RESULTS In this section, we evaluate the performance of our proposed algorithm on a large image database.",
                "To demonstrate the effectiveness of our proposed LOD algorithm, we compare it with Laplacian Regularized Regression (LRR, [2]), Support Vector Machine (SVM), Support Vector Machine Active Learning (SVMactive) [14], and A-Optimal Design (AOD).",
                "Both SVMactive, AOD, and LOD are active learning algorithms, while LRR and SVM are standard classification algorithms.",
                "SVM only makes use of the labeled images, while LRR is a semi-supervised learning algorithm which makes use of both labeled and unlabeled images.",
                "For SVMactive, AOD, and LOD, 10 training images are selected by the algorithms themselves at each iteration.",
                "While for LRR and SVM, we use the top 10 images as training data.",
                "It would be important to note that SVMactive is based on the ordinary SVM, LOD is based on LRR, and AOD is based on the ordinary regression.",
                "The parameters λ1 and λ2 in our LOD algorithm are empirically set to be 0.001 and 0.00001.",
                "For both LRR and LOD algorithms, we use the same graph structure (see Eq. 4) and set the value of p (number of nearest neighbors) to be 5.",
                "We begin with a simple synthetic example to give some intuition about how LOD works. 6.1 Simple Synthetic Example A simple synthetic example is given in Figure 1.",
                "The data set contains two circles.",
                "Eight points are selected by AOD and LOD.",
                "As can be seen, all the points selected by AOD are from the big circle, while LOD selects four points from the big circle and four from the small circle.",
                "The numbers beside the selected points denote their orders to be selected.",
                "Clearly, the points selected by our LOD algorithm can better represent the original data set.",
                "We did not compare our algorithm with SVMactive because SVMactive can not be applied in this case due to the lack of the labeled points. 6.2 <br>image retrieval</br> Experimental Design The image database we used consists of 7,900 images of 79 semantic categories, from COREL data set.",
                "It is a large and heterogeneous image set.",
                "Each image is represented as a 128-dimensional vector as described in Section 5.1.",
                "Figure 2 shows some sample images.",
                "To exhibit the advantages of using our algorithm, we need a reliable way of evaluating the retrieval performance and the comparisons with other algorithms.",
                "We list different aspects of the experimental design below. 6.2.1 Evaluation Metrics We use precision-scope curve and precision rate [10] to evaluate the effectiveness of the <br>image retrieval</br> algorithms.",
                "The scope is specified by the number (N) of top-ranked images presented to the user.",
                "The precision is the ratio of the number of relevant images presented to the user to the (a) Data set 1 2 3 4 5 6 7 8 (b) AOD 1 2 3 4 5 6 7 8 (c) LOD Figure 1: Data selection by active learning algorithms.",
                "The numbers beside the selected points denote their orders to be selected.",
                "Clearly, the points selected by our LOD algorithm can better represent the original data set.",
                "Note that, the SVMactive algorithm can not be applied in this case due to the lack of labeled points. (a) (b) (c) Figure 2: Sample images from category bead, elephant, and ship. scope N. The precision-scope curve describes the precision with various scopes and thus gives an overall performance evaluation of the algorithms.",
                "On the other hand, the precision rate emphasizes the precision at a particular value of scope.",
                "In general, it is appropriate to present 20 images on a screen.",
                "Putting more images on a screen may affect the quality of the presented images.",
                "Therefore, the precision at top 20 (N = 20) is especially important.",
                "In real world <br>image retrieval</br> systems, the query image is usually not in the image database.",
                "To simulate such environment, we use five-fold cross validation to evaluate the algorithms.",
                "More precisely, we divide the whole image database into five subsets with equal size.",
                "Thus, there are 20 images per category in each subset.",
                "At each run of cross validation, one subset is selected as the query set, and the other four subsets are used as the database for retrieval.",
                "The precisionscope curve and precision rate are computed by averaging the results from the five-fold cross validation. 6.2.2 Automatic Relevance Feedback Scheme We designed an automatic feedback scheme to model the retrieval process.",
                "For each submitted query, our system retrieves and ranks the images in the database. 10 images were selected from the database for user labeling and the label information is used by the system for re-ranking.",
                "Note that, the images which have been selected at previous iterations are excluded from later selections.",
                "For each query, the automatic relevance feedback mechanism is performed for four iterations.",
                "It is important to note that the automatic relevance feedback scheme used here is different from the ones described in [8], [11].",
                "In [8], [11], the top four relevant and irrelevant images were selected as the feedback images.",
                "However, this may not be practical.",
                "In real world <br>image retrieval</br> systems, it is possible that most of the top-ranked images are relevant (or, irrelevant).",
                "Thus, it is difficult for the user to find both four relevant and irrelevant images.",
                "It is more reasonable for the users to provide feedback information only on the 10 images selected by the system. 6.3 <br>image retrieval</br> Performance In real world, it is not practical to require the user to provide many rounds of feedbacks.",
                "The retrieval performance after the first two rounds of feedbacks (especially the first round) is more important.",
                "Figure 3 shows the average precision-scope curves of the different algorithms for the first two feedback iterations.",
                "At the beginning of retrieval, the Euclidean distances in the original 128-dimensional space are used to rank the images in database.",
                "After the user provides relevance feedbacks, the LRR, SVM, SVMactive, AOD, and LOD algorithms are then applied to re-rank the images.",
                "In order to reduce the time complexity of active learning algorithms, we didnt select the most informative images from the whole database but from the top 500 images.",
                "For LRR and SVM, the user is required to label the top 10 images.",
                "For SVMactive, AOD, and LOD, the user is required to label 10 most informative images selected by these algorithms.",
                "Note that, SVMactive can only be ap(a) Feedback Iteration 1 (b) Feedback Iteration 2 Figure 3: The average precision-scope curves of different algorithms for the first two feedback iterations.",
                "The LOD algorithm performs the best on the entire scope.",
                "Note that, at the first round of feedback, the SVMactive algorithm can not be applied.",
                "It applies the ordinary SVM to build the initial classifier. (a) Precision at Top 10 (b) Precision at Top 20 (c) Precision at Top 30 Figure 4: Performance evaluation of the five learning algorithms for relevance feedback <br>image retrieval</br>. (a) Precision at top 10, (b) Precision at top 20, and (c) Precision at top 30.",
                "As can be seen, our LOD algorithm consistently outperforms the other four algorithms. plied when the classifier is already built.",
                "Therefore, it can not be applied at the first round and we use the standard SVM to build the initial classifier.",
                "As can be seen, our LOD algorithm outperforms the other four algorithms on the entire scope.",
                "Also, the LRR algorithm performs better than SVM.",
                "This is because that the LRR algorithm makes efficient use of the unlabeled images by incorporating a locality preserving regularizer into the ordinary regression objective function.",
                "The AOD algorithm performs the worst.",
                "As the scope gets larger, the performance difference between these algorithms gets smaller.",
                "By iteratively adding the users feedbacks, the corresponding precision results (at top 10, top 20, and top 30) of the five algorithms are respectively shown in Figure 4.",
                "As can be seen, our LOD algorithm performs the best in all the cases and the LRR algorithm performs the second best.",
                "Both of these two algorithms make use of the unlabeled images.",
                "This shows that the unlabeled images are helpful for discovering the intrinsic geometrical structure of the image space and therefore enhance the retrieval performance.",
                "In real world, the user may not be willing to provide too many relevance feedbacks.",
                "Therefore, the retrieval performance at the first two rounds are especially important.",
                "As can be seen, our LOD algorithm achieves 6.8% performance improvement for top 10 results, 5.2% for top 20 results, and 4.1% for top 30 results, comparing to the second best algorithm (LRR) after the first two rounds of relevance feedbacks. 6.4 Discussion Several experiments on Corel database have been systematically performed.",
                "We would like to highlight several interesting points: 1.",
                "It is clear that the use of active learning is beneficial in the <br>image retrieval</br> domain.",
                "There is a significant increase in performance from using the active learning methods.",
                "Especially, out of the three active learning methods (SVMactive, AOD, LOD), our proposed LOD algorithm performs the best. 2.",
                "In many real world applications like relevance feedback <br>image retrieval</br>, there are generally two ways of reducing labor-intensive manual labeling task.",
                "One is active learning which selects the most informative samples to label, and the other is semi-supervised learning which makes use of the unlabeled samples to enhance the learning performance.",
                "Both of these two strategies have been studied extensively in the past [14], [7], [5], [8].",
                "The work presented in this paper is focused on active learning, but it also takes advantage of the recent progresses on semi-supervised learning [2].",
                "Specifically, we incorporate a locality preserving regularizer into the standard regression framework and find the most informative samples with respect to the new objective function.",
                "In this way, the active learning and semi-supervised learning techniques are seamlessly unified for learning an optimal classifier. 3.",
                "The relevance feedback technique is crucial to <br>image retrieval</br>.",
                "For all the five algorithms, the retrieval performance improves with more feedbacks provided by the user. 7.",
                "CONCLUSIONS AND FUTURE WORK This paper describes a novel active learning algorithm, called Laplacian Optimal Design, to enable more effective relevance feedback <br>image retrieval</br>.",
                "Our algorithm is based on an objective function which simultaneously minimizes the empirical error and preserves the local geometrical structure of the data space.",
                "Using techniques from experimental design, our algorithm finds the most informative images to label.",
                "These labeled images and the unlabeled images in the database are used to learn a classifier.",
                "The experimental results on Corel database show that both active learning and semi-supervised learning can significantly improve the retrieval performance.",
                "In this paper, we consider the <br>image retrieval</br> problem on a small, static, and closed-domain image data.",
                "A much more challenging domain is the World Wide Web (WWW).",
                "For Web image search, it is possible to collect a large amount of user click information.",
                "This information can be naturally used to construct the affinity graph in our algorithm.",
                "However, the computational complexity in Web scenario may become a crucial issue.",
                "Also, although our primary interest in this paper is focused on relevance feedback <br>image retrieval</br>, our results may also be of interest to researchers in patten recognition and machine learning, especially when a large amount of data is available but only a limited samples can be labeled. 8.",
                "REFERENCES [1] A. C. Atkinson and A. N. Donev.",
                "Optimum Experimental Designs.",
                "Oxford University Press, 2002. [2] M. Belkin, P. Niyogi, and V. Sindhwani.",
                "Manifold regularization: A geometric framework for learning from examples.",
                "Journal of Machine Learning Research, 7:2399-2434, 2006. [3] F. R. K. Chung.",
                "Spectral Graph Theory, volume 92 of Regional Conference Series in Mathematics.",
                "AMS, 1997. [4] D. A. Cohn, Z. Ghahramani, and M. I. Jordan.",
                "Active learning with statistical models.",
                "Journal of Artificial Intelligence Research, 4:129-145, 1996. [5] A. Dong and B. Bhanu.",
                "A new semi-supervised em algorithm for <br>image retrieval</br>.",
                "In IEEE Conf. on Computer Vision and Pattern Recognition, Madison, WI, 2003. [6] P. Flaherty, M. I. Jordan, and A. P. Arkin.",
                "Robust design of biological experiments.",
                "In Advances in Neural Information Processing Systems 18, Vancouver, Canada, 2005. [7] K.-S. Goh, E. Y. Chang, and W.-C. Lai.",
                "Multimodal concept-dependent active learning for <br>image retrieval</br>.",
                "In Proceedings of the ACM Conference on Multimedia, New York, October 2004. [8] X.",
                "He.",
                "Incremental semi-supervised subspace learning for <br>image retrieval</br>.",
                "In Proceedings of the ACM Conference on Multimedia, New York, October 2004. [9] S. C. Hoi and M. R. Lyu.",
                "A semi-supervised active learning framework for <br>image retrieval</br>.",
                "In IEEE International Conference on Computer Vision and Pattern Recognition, San Diego, CA, 2005. [10] D. P. Huijsmans and N. Sebe.",
                "How to complete performance graphs in content-based <br>image retrieval</br>: Add generality and normalize scope.",
                "IEEE Transactions on Pattern Analysis and Machine Intelligence, 27(2):245-251, 2005. [11] Y.-Y.",
                "Lin, T.-L. Liu, and H.-T. Chen.",
                "Semantic manifold learning for <br>image retrieval</br>.",
                "In Proceedings of the ACM Conference on Multimedia, Singapore, November 2005. [12] Y. Rui, T. S. Huang, M. Ortega, and S. Mehrotra.",
                "Relevance feedback: A power tool for interative content-based <br>image retrieval</br>.",
                "IEEE Transactions on Circuits and Systems for Video Technology, 8(5), 1998. [13] A. W. Smeulders, M. Worring, S. Santini, A. Gupta, and R. Jain.",
                "Content-based <br>image retrieval</br> at the end of the early years.",
                "IEEE Transactions on Pattern Analysis and Machine Intelligence, 22(12):1349-1380, 2000. [14] S. Tong and E. Chang.",
                "Support vector machine active learning for <br>image retrieval</br>.",
                "In Proceedings of the ninth ACM international conference on Multimedia, pages 107-118, 2001. [15] H. Yu, M. Li, H.-J.",
                "Zhang, and J. Feng.",
                "Color texture moments for content-based <br>image retrieval</br>.",
                "In International Conference on Image Processing, pages 24-28, 2002. [16] K. Yu, J. Bi, and V. Tresp.",
                "Active learning via transductive experimental design.",
                "In Proceedings of the 23rd International Conference on Machine Learning, Pittsburgh, PA, 2006."
            ],
            "original_annotated_samples": [
                "Laplacian Optimal Design for <br>image retrieval</br> Xiaofei He Yahoo!",
                "Burbank, CA 91504 hex@yahoo-inc.com Wanli Min IBM Yorktown Heights, NY 10598 wanlimin@us.ibm.com Deng Cai CS Dept., UIUC Urbana, IL 61801 dengcai2@cs.uiuc.edu Kun Zhou Microsoft Research Asia Beijing, China kunzhou@microsoft.com ABSTRACT Relevance feedback is a powerful technique to enhance ContentBased <br>image retrieval</br> (CBIR) performance.",
                "In this paper, we propose a novel active learning algorithm, called Laplacian Optimal Design (LOD), for relevance feedback <br>image retrieval</br>.",
                "Experimental results on Corel database suggest that the proposed approach achieves higher precision in relevance feedback <br>image retrieval</br>.",
                "Particularly, we consider the problem of relevance feedback driven Content-Based <br>image retrieval</br> (CBIR) [13]."
            ],
            "translated_annotated_samples": [
                "Diseño óptimo de Laplaciano para la <br>recuperación de imágenes</br> Xiaofei He Yahoo!",
                "El feedback de relevancia es una técnica poderosa para mejorar el rendimiento de la <br>Recuperación de Imágenes</br> Basada en Contenido (CBIR).",
                "En este artículo, proponemos un novedoso algoritmo de aprendizaje activo, llamado Diseño Óptimo Laplaciano (LOD), para la <br>recuperación de imágenes</br> con retroalimentación de relevancia.",
                "Los resultados experimentales en la base de datos Corel sugieren que el enfoque propuesto logra una mayor precisión en la <br>recuperación de imágenes</br> con retroalimentación de relevancia.",
                "Particularmente, consideramos el problema de la <br>recuperación de imágenes basada en contenido</br> impulsada por la retroalimentación de relevancia (CBIR) [13]."
            ],
            "translated_text": "Diseño óptimo de Laplaciano para la <br>recuperación de imágenes</br> Xiaofei He Yahoo! El feedback de relevancia es una técnica poderosa para mejorar el rendimiento de la <br>Recuperación de Imágenes</br> Basada en Contenido (CBIR). Solicita las valoraciones de relevancia de los usuarios sobre las imágenes recuperadas por los sistemas CBIR. La etiqueta de los usuarios se utiliza luego para entrenar un clasificador que distinga entre imágenes relevantes e irrelevantes. Sin embargo, las imágenes principales que se devuelven pueden no ser las más informativas. El desafío consiste en determinar qué imágenes sin etiquetar serían las más informativas (es decir, mejorarían más al clasificador) si fueran etiquetadas y utilizadas como muestras de entrenamiento. En este artículo, proponemos un novedoso algoritmo de aprendizaje activo, llamado Diseño Óptimo Laplaciano (LOD), para la <br>recuperación de imágenes</br> con retroalimentación de relevancia. Nuestro algoritmo se basa en un modelo de regresión que minimiza el error cuadrático mínimo en las imágenes medidas (o etiquetadas) y al mismo tiempo preserva la estructura geométrica local del espacio de la imagen. Específicamente, asumimos que si dos imágenes están lo suficientemente cerca una de la otra, entonces sus medidas (o etiquetas) también son cercanas. Al construir un grafo de vecinos más cercanos, la estructura geométrica del espacio de la imagen puede ser descrita por el Laplaciano del grafo. Discutimos cómo los resultados del campo del diseño experimental óptimo pueden ser utilizados para guiar nuestra selección de un subconjunto de imágenes, que nos proporciona la mayor cantidad de información. Los resultados experimentales en la base de datos Corel sugieren que el enfoque propuesto logra una mayor precisión en la <br>recuperación de imágenes</br> con retroalimentación de relevancia. Categorías y Descriptores de Asignaturas H.3.3 [Almacenamiento y recuperación de información]: Búsqueda y recuperación de información-Retroalimentación de relevancia; G.3 [Matemáticas de la Computación]: Probabilidad y Estadística-Diseño experimental Términos Generales Algoritmos, Rendimiento, Teoría 1. INTRODUCCIÓN En muchas tareas de aprendizaje automático y recuperación de información, no hay escasez de datos no etiquetados pero las etiquetas son costosas. El desafío consiste en determinar qué muestras sin etiquetar serían las más informativas (es decir, mejorarían más el clasificador) si fueran etiquetadas y utilizadas como muestras de entrenamiento. Este problema se llama típicamente aprendizaje activo [4]. Aquí la tarea es minimizar un costo general, que depende tanto de la precisión del clasificador como del costo de la recolección de datos. Muchas aplicaciones del mundo real pueden ser adaptadas al marco de aprendizaje activo. Particularmente, consideramos el problema de la <br>recuperación de imágenes basada en contenido</br> impulsada por la retroalimentación de relevancia (CBIR) [13]. ",
            "candidates": [],
            "error": [
                [
                    "recuperación de imágenes",
                    "Recuperación de Imágenes",
                    "recuperación de imágenes",
                    "recuperación de imágenes",
                    "recuperación de imágenes basada en contenido"
                ]
            ]
        },
        "active learn": {
            "translated_key": "aprendizaje activo",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Laplacian Optimal Design for Image Retrieval Xiaofei He Yahoo!",
                "Burbank, CA 91504 hex@yahoo-inc.com Wanli Min IBM Yorktown Heights, NY 10598 wanlimin@us.ibm.com Deng Cai CS Dept., UIUC Urbana, IL 61801 dengcai2@cs.uiuc.edu Kun Zhou Microsoft Research Asia Beijing, China kunzhou@microsoft.com ABSTRACT Relevance feedback is a powerful technique to enhance ContentBased Image Retrieval (CBIR) performance.",
                "It solicits the users relevance judgments on the retrieved images returned by the CBIR systems.",
                "The users labeling is then used to learn a classifier to distinguish between relevant and irrelevant images.",
                "However, the top returned images may not be the most informative ones.",
                "The challenge is thus to determine which unlabeled images would be the most informative (i.e., improve the classifier the most) if they were labeled and used as training samples.",
                "In this paper, we propose a novel <br>active learn</br>ing algorithm, called Laplacian Optimal Design (LOD), for relevance feedback image retrieval.",
                "Our algorithm is based on a regression model which minimizes the least square error on the measured (or, labeled) images and simultaneously preserves the local geometrical structure of the image space.",
                "Specifically, we assume that if two images are sufficiently close to each other, then their measurements (or, labels) are close as well.",
                "By constructing a nearest neighbor graph, the geometrical structure of the image space can be described by the graph Laplacian.",
                "We discuss how results from the field of optimal experimental design may be used to guide our selection of a subset of images, which gives us the most amount of information.",
                "Experimental results on Corel database suggest that the proposed approach achieves higher precision in relevance feedback image retrieval.",
                "Categories and Subject Descriptors H.3.3 [Information storage and retrieval]: Information search and retrieval-Relevance feedback; G.3 [Mathematics of Computing]: Probability and Statistics-Experimental design General Terms Algorithms, Performance, Theory 1.",
                "INTRODUCTION In many machine learning and information retrieval tasks, there is no shortage of unlabeled data but labels are expensive.",
                "The challenge is thus to determine which unlabeled samples would be the most informative (i.e., improve the classifier the most) if they were labeled and used as training samples.",
                "This problem is typically called <br>active learn</br>ing [4].",
                "Here the task is to minimize an overall cost, which depends both on the classifier accuracy and the cost of data collection.",
                "Many real world applications can be casted into <br>active learn</br>ing framework.",
                "Particularly, we consider the problem of relevance feedback driven Content-Based Image Retrieval (CBIR) [13].",
                "Content-Based Image Retrieval has attracted substantial interests in the last decade [13].",
                "It is motivated by the fast growth of digital image databases which, in turn, require efficient search schemes.",
                "Rather than describe an image using text, in these systems an image query is described using one or more example images.",
                "The low level visual features (color, texture, shape, etc.) are automatically extracted to represent the images.",
                "However, the low level features may not accurately characterize the high level semantic concepts.",
                "To narrow down the semantic gap, relevance feedback is introduced into CBIR [12].",
                "In many of the current relevance feedback driven CBIR systems, the user is required to provide his/her relevance judgments on the top images returned by the system.",
                "The labeled images are then used to train a classifier to separate images that match the query concept from those that do not.",
                "However, in general the top returned images may not be the most informative ones.",
                "In the worst case, all the top images labeled by the user may be positive and thus the standard classification techniques can not be applied due to the lack of negative examples.",
                "Unlike the standard classification problems where the labeled samples are pregiven, in relevance feedback image retrieval the system can actively select the images to label.",
                "Thus <br>active learn</br>ing can be naturally introduced into image retrieval.",
                "Despite many existing <br>active learn</br>ing techniques, Support Vector Machine (SVM) <br>active learn</br>ing [14] and regression based active learning [1] have received the most interests.",
                "Based on the observation that the closer to the SVM boundary an image is, the less reliable its classification is, SVM <br>active learn</br>ing selects those unlabeled images closest to the boundary to solicit user feedback so as to achieve maximal refinement on the hyperplane between the two classes.",
                "The major disadvantage of SVM <br>active learn</br>ing is that the estimated boundary may not be accurate enough.",
                "Moreover, it may not be applied at the beginning of the retrieval when there is no labeled images.",
                "Some other SVM based <br>active learn</br>ing algorithms can be found in [7], [9].",
                "In statistics, the problem of selecting samples to label is typically referred to as experimental design.",
                "The sample x is referred to as experiment, and its label y is referred to as measurement.",
                "The study of optimal experimental design (OED) [1] is concerned with the design of experiments that are expected to minimize variances of a parameterized model.",
                "The intent of optimal experimental design is usually to maximize confidence in a given model, minimize parameter variances for system identification, or minimize the models output variance.",
                "Classical experimental design approaches include A-Optimal Design, D-Optimal Design, and E-Optimal Design.",
                "All of these approaches are based on a least squares regression model.",
                "Comparing to SVM based <br>active learn</br>ing algorithms, experimental design approaches are much more efficient in computation.",
                "However, this kind of approaches takes only measured (or, labeled) data into account in their objective function, while the unmeasured (or, unlabeled) data is ignored.",
                "Benefit from recent progresses on optimal experimental design and semi-supervised learning, in this paper we propose a novel <br>active learn</br>ing algorithm for image retrieval, called Laplacian Optimal Design (LOD).",
                "Unlike traditional experimental design methods whose loss functions are only defined on the measured points, the loss function of our proposed LOD algorithm is defined on both measured and unmeasured points.",
                "Specifically, we introduce a locality preserving regularizer into the standard least-square-error based loss function.",
                "The new loss function aims to find a classifier which is locally as smooth as possible.",
                "In other words, if two points are sufficiently close to each other in the input space, then they are expected to share the same label.",
                "Once the loss function is defined, we can select the most informative data points which are presented to the user for labeling.",
                "It would be important to note that the most informative images may not be the top returned images.",
                "The rest of the paper is organized as follows.",
                "In Section 2, we provide a brief description of the related work.",
                "Our proposed Laplacian Optimal Design algorithm is introduced in Section 3.",
                "In Section 4, we compare our algorithm with the state-or-the-art algorithms and present the experimental results on image retrieval.",
                "Finally, we provide some concluding remarks and suggestions for future work in Section 5. 2.",
                "RELATED WORK Since our proposed algorithm is based on regression framework.",
                "The most related work is optimal experimental design [1], including A-Optimal Design, D-Optimal Design, and EOptimal Design.",
                "In this Section, we give a brief description of these approaches. 2.1 The Active Learning Problem The generic problem of <br>active learn</br>ing is the following.",
                "Given a set of points A = {x1, x2, · · · , xm} in Rd , find a subset B = {z1, z2, · · · , zk} ⊂ A which contains the most informative points.",
                "In other words, the points zi(i = 1, · · · , k) can improve the classifier the most if they are labeled and used as training points. 2.2 Optimal Experimental Design We consider a linear regression model y = wT x + (1) where y is the observation, x is the independent variable, w is the weight vector and is an unknown error with zero mean.",
                "Different observations have errors that are independent, but with equal variances σ2 .",
                "We define f(x) = wT x to be the learners output given input x and the weight vector w. Suppose we have a set of labeled sample points (z1, y1), · · · , (zk, yk), where yi is the label of zi.",
                "Thus, the maximum likelihood estimate for the weight vector, ˆw, is that which minimizes the sum squared error Jsse(w) = k i=1 wT zi − yi 2 (2) The estimate ˆw gives us an estimate of the output at a novel input: ˆy = ˆwT x.",
                "By Gauss-Markov theorem, we know that ˆw − w has a zero mean and a covariance matrix given by σ2 H−1 sse, where Hsse is the Hessian of Jsse(w) Hsse = ∂2 Jsse ∂w2 = k i=1 zizT i = ZZT where Z = (z1, z2, · · · , zk).",
                "The three most common scalar measures of the size of the parameter covariance matrix in optimal experimental design are: • D-optimal design: determinant of Hsse. • A-optimal design: trace of Hsse. • E-optimal design: maximum eigenvalue of Hsse.",
                "Since the computation of the determinant and eigenvalues of a matrix is much more expensive than the computation of matrix trace, A-optimal design is more efficient than the other two.",
                "Some recent work on experimental design can be found in [6], [16]. 3.",
                "LAPLACIAN OPTIMAL DESIGN Since the covariance matrix Hsse used in traditional approaches is only dependent on the measured samples, i.e. zis, these approaches fail to evaluate the expected errors on the unmeasured samples.",
                "In this Section, we introduce a novel <br>active learn</br>ing algorithm called Laplacian Optimal Design (LOD) which makes efficient use of both measured (labeled) and unmeasured (unlabeled) samples. 3.1 The Objective Function In many machine learning problems, it is natural to assume that if two points xi, xj are sufficiently close to each other, then their measurements (f(xi), f(xj)) are close as well.",
                "Let S be a similarity matrix.",
                "Thus, a new loss function which respects the geometrical structure of the data space can be defined as follows: J0(w) = k i=1 f(zi)−yi 2 + λ 2 m i,j=1 f(xi)−f(xj) 2 Sij (3) where yi is the measurement (or, label) of zi.",
                "Note that, the loss function (3) is essentially the same as the one used in Laplacian Regularized Regression (LRR, [2]).",
                "However, LRR is a passive learning algorithm where the training data is given.",
                "In this paper, we are focused on how to select the most informative data for training.",
                "The loss function with our choice of symmetric weights Sij (Sij = Sji) incurs a heavy penalty if neighboring points xi and xj are mapped far apart.",
                "Therefore, minimizing J0(w) is an attempt to ensure that if xi and xj are close then f(xi) and f(xj) are close as well.",
                "There are many choices of the similarity matrix S. A simple definition is as follows: Sij = ⎧ ⎨ ⎩ 1, if xi is among the p nearest neighbors of xj, or xj is among the p nearest neighbors of xi; 0, otherwise. (4) Let D be a diagonal matrix, Dii = j Sij, and L = D−S.",
                "The matrix L is called graph Laplacian in spectral graph theory [3].",
                "Let y = (y1, · · · , yk)T and X = (x1, · · · , xm).",
                "Following some simple algebraic steps, we see that: J0(w) = k i=1 wT zi − yi 2 + λ 2 m i,j=1 wT xi − wT xj 2 Sij = y − ZT w T y − ZT w + λwT m i=1 DiixixT i − m i,j=1 SijxixT j w = yT y − 2wT Zy + wT ZZT w +λwT XDXT − XSXT w = yT y − 2wT Zy + wT ZZT + λXLXT w The Hessian of J0(w) can be computed as follows: H0 = ∂2 J0 ∂w2 = ZZT + λXLXT In some cases, the matrix ZZT +λXLXT is singular (e.g. if m < d).",
                "Thus, there is no stable solution to the optimization problem Eq. (3).",
                "A common way to deal with this ill-posed problem is to introduce a Tikhonov regularizer into our loss function: J(w) = k i=1 wT zi − yi 2 + λ1 2 m i,j=1 wT xi − wT xj 2 Sij +λ2 w 2 (5) The Hessian of the new loss function is given by: H = ∂2 J ∂w2 = ZZT + λ1XLXT + λ2I := ZZT + Λ where I is an identity matrix and Λ = λ1XLXT + λ2I.",
                "Clearly, H is of full rank.",
                "Requiring that the gradient of J(w) with respect to w vanish gives the optimal estimate ˆw: ˆw = H−1 Zy The following proposition states the bias and variance properties of the estimator for the coefficient vector w. Proposition 3.1.",
                "E( ˆw − w) = −H−1 Λw, Cov( ˆw) = σ2 (H−1 − H−1 ΛH−1 ) Proof.",
                "Since y = ZT w + and E( ) = 0, it follows that E( ˆw − w) (6) = H−1 ZZT w − w = H−1 (ZZT + Λ − Λ)w − w = (I − H−1 Λ)w − w = −H−1 Λw (7) Notice Cov(y) = σ2 I, the covariance matrix of ˆw has the expression: Cov( ˆw) = H−1 ZCov(y)ZT H−1 = σ2 H−1 ZZT H−1 = σ2 H−1 (H − Λ)H−1 = σ2 (H−1 − H−1 ΛH−1 ) (8) Therefore mean squared error matrix for the coefficients w is E(w − ˆw)(w − ˆw)T (9) = H−1 ΛwwT ΛH−1 + σ2 (H−1 − H−1 ΛH−1 ) (10) For any x, let ˆy = ˆwT x be its predicted observation.",
                "The expected squared prediction error is E(y − ˆy)2 = E( + wT x − ˆwT x)2 = σ2 + xT [E(w − ˆw)(w − ˆw)T ]x = σ2 + xT [H−1 ΛwwT ΛH−1 + σ2 H−1 − σ2 H−1 ΛH−1 ]x Clearly the expected square prediction error depends on the explanatory variable x, therefore average expected square predictive error over the complete data set A is 1 m m i=1 E(yi − ˆwT xi)2 = 1 m m i=1 xT i [H−1 ΛwwT ΛH−1 + σ2 H−1 − σ2 H−1 ΛH−1 ]xi +σ2 = 1 m Tr(XT [σ2 H−1 + H−1 ΛwwT ΛH−1 − σ2 H−1 ΛH−1 ]X) +σ2 Since Tr(XT [H−1 ΛwwT ΛH−1 − σ2 H−1 ΛH−1 ]X) Tr(σ2 XT H−1 X), Our Laplacian optimality criterion is thus formulated by minimizing the trace of XT H−1 X.",
                "Definition 1.",
                "Laplacian Optimal Design min Z=(z1,··· ,zk) Tr XT ZZT + λ1XLXT + λ2I −1 X (11) where z1, · · · , zk are selected from {x1, · · · , xm}. 4.",
                "KERNEL LAPLACIAN OPTIMAL DESIGN Canonical experimental design approaches (e.g.",
                "A-Optimal Design, D-Optimal Design, and E-Optimal) only consider linear functions.",
                "They fail to discover the intrinsic geometry in the data when the data space is highly nonlinear.",
                "In this section, we describe how to perform Laplacian Experimental Design in Reproducing Kernel Hilbert Space (RKHS) which gives rise to Kernel Laplacian Experimental Design (KLOD).",
                "For given data points x1, · · · , xm ∈ X with a positive definite mercer kernel K : X ×X → R, there exists a unique RKHS HK of real valued functions on X.",
                "Let Kt(s) be the function of s obtained by fixing t and letting Kt(s) . = K(s, t).",
                "HK consists of all finite linear combinations of the form l i=1 αiKti with ti ∈ X and limits of such functions as the ti become dense in X.",
                "We have Ks, Kt HK = K(s, t). 4.1 Derivation of LOD in Reproducing Kernel Hilbert Space Consider the optimization problem (5) in RKHS.",
                "Thus, we seek a function f ∈ HK such that the following objective function is minimized: min f∈HK k i=1 f(zi)−yi 2 + λ1 2 m i,j=1 f(xi)−f(xj) 2 Sij+λ2 f 2 HK (12) We have the following proposition.",
                "Proposition 4.1.",
                "Let H = { m i=1 αiK(·, xi)|αi ∈ R} be a subspace of HK , the solution to the problem (12) is in H. Proof.",
                "Let H⊥ be the orthogonal complement of H, i.e.",
                "HK = H ⊕ H⊥ .",
                "Thus, for any function f ∈ HK , it has orthogonal decomposition as follows: f = fH + fH⊥ Now, lets evaluate f at xi: f(xi) = f, Kxi HK = fH + fH⊥ , Kxi HK = fH, Kxi HK + fH⊥ , Kxi HK Notice that Kxi ∈ H while fH⊥ ∈ H⊥ .",
                "This implies that fH⊥ , Kxi HK = 0.",
                "Therefore, f(xi) = fH, Kxi HK = fH(xi) This completes the proof.",
                "Proposition 4.1 tells us the minimizer of problem (12) admits a representation f∗ = m i=1 αiK(·, xi).",
                "Please see [2] for the details.",
                "Let φ : Rd → H be a feature map from the input space Rd to H, and K(xi, xj) =< φ(xi), φ(xj) >.",
                "Let X denote the data matrix in RKHS, X = (φ(x1), φ(x2), · · · , φ(xm)).",
                "Similarly, we define Z = (φ(z1), φ(z2), · · · , φ(zk)).",
                "Thus, the optimization problem in RKHS can be written as follows: min Z Tr XT ZZT + λ1XLXT + λ2I −1 X (13) Since the mapping function φ is generally unknown, there is no direct way to solve problem (13).",
                "In the following, we apply kernel tricks to solve this optimization problem.",
                "Let X−1 be the Moore-Penrose inverse (also known as pseudo inverse) of X.",
                "Thus, we have: XT ZZT + λ1XLXT + λ2I −1 X = XT XX−1 ZZT + λ1XLXT + λ2I −1 (XT )−1 XT X = XT X ZZT X + λ1XLXT X + λ2X −1 (XT )−1 XT X = XT X XT ZZT X + λ1XT XLXT X + λ2XT X −1 XT X = KXX KXZKZX + λ1KXXLKXX + λ2KXX −1 KXX where KXX is a m × m matrix (KXX,ij = K(xi, xj)), KXZ is a m×k matrix (KXZ,ij = K(xi, zj)), and KZX is a k×m matrix (KZX,ij = K(zi, xj)).",
                "Thus, the Kernel Laplacian Optimal Design can be defined as follows: Definition 2.",
                "Kernel Laplacian Optimal Design minZ=(z1,··· ,zk) Tr KXX KXZKZX + λ1KXXLKXX λ2KXX −1 KXX (14) 4.2 Optimization Scheme In this subsection, we discuss how to solve the optimization problems (11) and (14).",
                "Particularly, if we select a linear kernel for KLOD, then it reduces to LOD.",
                "Therefore, we will focus on problem (14) in the following.",
                "It can be shown that the optimization problem (14) is NP-hard.",
                "In this subsection, we develop a simple sequential greedy approach to solve (14).",
                "Suppose n points have been selected, denoted by a matrix Zn = (z1, · · · , zn).",
                "The (n + 1)-th point zn+1 can be selected by solving the following optimization problem: max Zn+1=(Zn,zn+1) Tr KXX KXZn+1 KZn+1X + λ1KXXLKXX + λ2KXX −1 KXX (15) The kernel matrices KXZn+1 and KZn+1X can be rewritten as follows: KXZn+1 = KXZn , KXzn+1 , KZn+1X = KZnX Kzn+1X Thus, we have: KXZn+1 KZn+1X = KXZn KZnX + KXzn+1 Kzn+1X We define: A = KXZn KZnX + λ1KXXLKXX + λ2KXX A is only dependent on X and Zn .",
                "Thus, the (n + 1)-th point zn+1 is given by: zn+1 = arg min zn+1 Tr KXX A + KXzn+1 Kzn+1X −1 KXX (16) Each time we select a new point zn+1, the matrix A is updated by: A ← A + KXzn+1 Kzn+1X If the kernel function is chosen as inner product K(x, y) = x, y , then HK is a linear functional space and the algorithm reduces to LOD. 5.",
                "CONTENT-BASED IMAGE RETRIEVAL USING LAPLACIAN OPTIMAL DESIGN In this section, we describe how to apply Laplacian Optimal Design to CBIR.",
                "We begin with a brief description of image representation using low level visual features. 5.1 Low-Level Image Representation Low-level image representation is a crucial problem in CBIR.",
                "General visual features includes color, texture, shape, etc.",
                "Color and texture features are the most extensively used visual features in CBIR.",
                "Compared with color and texture features, shape features are usually described after images have been segmented into regions or objects.",
                "Since robust and accurate image segmentation is difficult to achieve, the use of shape features for image retrieval has been limited to special applications where objects or regions are readily available.",
                "In this work, We combine 64-dimensional color histogram and 64-dimensional Color Texture Moment (CTM, [15]) to represent the images.",
                "The color histogram is calculated using 4 × 4 × 4 bins in HSV space.",
                "The Color Texture Moment is proposed by Yu et al. [15], which integrates the color and texture characteristics of the image in a compact form.",
                "CTM adopts local Fourier transform as a texture representation scheme and derives eight characteristic maps to describe different aspects of co-occurrence relations of image pixels in each channel of the (SVcosH, SVsinH, V) color space.",
                "Then CTM calculates the first and second moment of these maps as a representation of the natural color image pixel distribution.",
                "Please see [15] for details. 5.2 Relevance Feedback Image Retrieval Relevance feedback is one of the most important techniques to narrow down the gap between low level visual features and high level semantic concepts [12].",
                "Traditionally, the users relevance feedbacks are used to update the query vector or adjust the weighting of different dimensions.",
                "This process can be viewed as an on-line learning process in which the image retrieval system acts as a learner and the user acts as a teacher.",
                "They typical retrieval process is outlined as follows: 1.",
                "The user submits a query image example to the system.",
                "The system ranks the images in database according to some pre-defined distance metric and presents to the user the top ranked images. 2.",
                "The system selects some images from the database and request the user to label them as relevant or irrelevant. 3.",
                "The system uses the users provided information to rerank the images in database and returns to the user the top images.",
                "Go to step 2 until the user is satisfied.",
                "Our Laplacian Optimal Design algorithm is applied in the second step for selecting the most informative images.",
                "Once we get the labels for the images selected by LOD, we apply Laplacian Regularized Regression (LRR, [2]) to solve the optimization problem (3) and build the classifier.",
                "The classifier is then used to re-rank the images in database.",
                "Note that, in order to reduce the computational complexity, we do not use all the unlabeled images in the database but only those within top 500 returns of previous iteration. 6.",
                "EXPERIMENTAL RESULTS In this section, we evaluate the performance of our proposed algorithm on a large image database.",
                "To demonstrate the effectiveness of our proposed LOD algorithm, we compare it with Laplacian Regularized Regression (LRR, [2]), Support Vector Machine (SVM), Support Vector Machine Active Learning (SVMactive) [14], and A-Optimal Design (AOD).",
                "Both SVMactive, AOD, and LOD are <br>active learn</br>ing algorithms, while LRR and SVM are standard classification algorithms.",
                "SVM only makes use of the labeled images, while LRR is a semi-supervised learning algorithm which makes use of both labeled and unlabeled images.",
                "For SVMactive, AOD, and LOD, 10 training images are selected by the algorithms themselves at each iteration.",
                "While for LRR and SVM, we use the top 10 images as training data.",
                "It would be important to note that SVMactive is based on the ordinary SVM, LOD is based on LRR, and AOD is based on the ordinary regression.",
                "The parameters λ1 and λ2 in our LOD algorithm are empirically set to be 0.001 and 0.00001.",
                "For both LRR and LOD algorithms, we use the same graph structure (see Eq. 4) and set the value of p (number of nearest neighbors) to be 5.",
                "We begin with a simple synthetic example to give some intuition about how LOD works. 6.1 Simple Synthetic Example A simple synthetic example is given in Figure 1.",
                "The data set contains two circles.",
                "Eight points are selected by AOD and LOD.",
                "As can be seen, all the points selected by AOD are from the big circle, while LOD selects four points from the big circle and four from the small circle.",
                "The numbers beside the selected points denote their orders to be selected.",
                "Clearly, the points selected by our LOD algorithm can better represent the original data set.",
                "We did not compare our algorithm with SVMactive because SVMactive can not be applied in this case due to the lack of the labeled points. 6.2 Image Retrieval Experimental Design The image database we used consists of 7,900 images of 79 semantic categories, from COREL data set.",
                "It is a large and heterogeneous image set.",
                "Each image is represented as a 128-dimensional vector as described in Section 5.1.",
                "Figure 2 shows some sample images.",
                "To exhibit the advantages of using our algorithm, we need a reliable way of evaluating the retrieval performance and the comparisons with other algorithms.",
                "We list different aspects of the experimental design below. 6.2.1 Evaluation Metrics We use precision-scope curve and precision rate [10] to evaluate the effectiveness of the image retrieval algorithms.",
                "The scope is specified by the number (N) of top-ranked images presented to the user.",
                "The precision is the ratio of the number of relevant images presented to the user to the (a) Data set 1 2 3 4 5 6 7 8 (b) AOD 1 2 3 4 5 6 7 8 (c) LOD Figure 1: Data selection by <br>active learn</br>ing algorithms.",
                "The numbers beside the selected points denote their orders to be selected.",
                "Clearly, the points selected by our LOD algorithm can better represent the original data set.",
                "Note that, the SVMactive algorithm can not be applied in this case due to the lack of labeled points. (a) (b) (c) Figure 2: Sample images from category bead, elephant, and ship. scope N. The precision-scope curve describes the precision with various scopes and thus gives an overall performance evaluation of the algorithms.",
                "On the other hand, the precision rate emphasizes the precision at a particular value of scope.",
                "In general, it is appropriate to present 20 images on a screen.",
                "Putting more images on a screen may affect the quality of the presented images.",
                "Therefore, the precision at top 20 (N = 20) is especially important.",
                "In real world image retrieval systems, the query image is usually not in the image database.",
                "To simulate such environment, we use five-fold cross validation to evaluate the algorithms.",
                "More precisely, we divide the whole image database into five subsets with equal size.",
                "Thus, there are 20 images per category in each subset.",
                "At each run of cross validation, one subset is selected as the query set, and the other four subsets are used as the database for retrieval.",
                "The precisionscope curve and precision rate are computed by averaging the results from the five-fold cross validation. 6.2.2 Automatic Relevance Feedback Scheme We designed an automatic feedback scheme to model the retrieval process.",
                "For each submitted query, our system retrieves and ranks the images in the database. 10 images were selected from the database for user labeling and the label information is used by the system for re-ranking.",
                "Note that, the images which have been selected at previous iterations are excluded from later selections.",
                "For each query, the automatic relevance feedback mechanism is performed for four iterations.",
                "It is important to note that the automatic relevance feedback scheme used here is different from the ones described in [8], [11].",
                "In [8], [11], the top four relevant and irrelevant images were selected as the feedback images.",
                "However, this may not be practical.",
                "In real world image retrieval systems, it is possible that most of the top-ranked images are relevant (or, irrelevant).",
                "Thus, it is difficult for the user to find both four relevant and irrelevant images.",
                "It is more reasonable for the users to provide feedback information only on the 10 images selected by the system. 6.3 Image Retrieval Performance In real world, it is not practical to require the user to provide many rounds of feedbacks.",
                "The retrieval performance after the first two rounds of feedbacks (especially the first round) is more important.",
                "Figure 3 shows the average precision-scope curves of the different algorithms for the first two feedback iterations.",
                "At the beginning of retrieval, the Euclidean distances in the original 128-dimensional space are used to rank the images in database.",
                "After the user provides relevance feedbacks, the LRR, SVM, SVMactive, AOD, and LOD algorithms are then applied to re-rank the images.",
                "In order to reduce the time complexity of <br>active learn</br>ing algorithms, we didnt select the most informative images from the whole database but from the top 500 images.",
                "For LRR and SVM, the user is required to label the top 10 images.",
                "For SVMactive, AOD, and LOD, the user is required to label 10 most informative images selected by these algorithms.",
                "Note that, SVMactive can only be ap(a) Feedback Iteration 1 (b) Feedback Iteration 2 Figure 3: The average precision-scope curves of different algorithms for the first two feedback iterations.",
                "The LOD algorithm performs the best on the entire scope.",
                "Note that, at the first round of feedback, the SVMactive algorithm can not be applied.",
                "It applies the ordinary SVM to build the initial classifier. (a) Precision at Top 10 (b) Precision at Top 20 (c) Precision at Top 30 Figure 4: Performance evaluation of the five learning algorithms for relevance feedback image retrieval. (a) Precision at top 10, (b) Precision at top 20, and (c) Precision at top 30.",
                "As can be seen, our LOD algorithm consistently outperforms the other four algorithms. plied when the classifier is already built.",
                "Therefore, it can not be applied at the first round and we use the standard SVM to build the initial classifier.",
                "As can be seen, our LOD algorithm outperforms the other four algorithms on the entire scope.",
                "Also, the LRR algorithm performs better than SVM.",
                "This is because that the LRR algorithm makes efficient use of the unlabeled images by incorporating a locality preserving regularizer into the ordinary regression objective function.",
                "The AOD algorithm performs the worst.",
                "As the scope gets larger, the performance difference between these algorithms gets smaller.",
                "By iteratively adding the users feedbacks, the corresponding precision results (at top 10, top 20, and top 30) of the five algorithms are respectively shown in Figure 4.",
                "As can be seen, our LOD algorithm performs the best in all the cases and the LRR algorithm performs the second best.",
                "Both of these two algorithms make use of the unlabeled images.",
                "This shows that the unlabeled images are helpful for discovering the intrinsic geometrical structure of the image space and therefore enhance the retrieval performance.",
                "In real world, the user may not be willing to provide too many relevance feedbacks.",
                "Therefore, the retrieval performance at the first two rounds are especially important.",
                "As can be seen, our LOD algorithm achieves 6.8% performance improvement for top 10 results, 5.2% for top 20 results, and 4.1% for top 30 results, comparing to the second best algorithm (LRR) after the first two rounds of relevance feedbacks. 6.4 Discussion Several experiments on Corel database have been systematically performed.",
                "We would like to highlight several interesting points: 1.",
                "It is clear that the use of <br>active learn</br>ing is beneficial in the image retrieval domain.",
                "There is a significant increase in performance from using the <br>active learn</br>ing methods.",
                "Especially, out of the three <br>active learn</br>ing methods (SVMactive, AOD, LOD), our proposed LOD algorithm performs the best. 2.",
                "In many real world applications like relevance feedback image retrieval, there are generally two ways of reducing labor-intensive manual labeling task.",
                "One is <br>active learn</br>ing which selects the most informative samples to label, and the other is semi-supervised learning which makes use of the unlabeled samples to enhance the learning performance.",
                "Both of these two strategies have been studied extensively in the past [14], [7], [5], [8].",
                "The work presented in this paper is focused on <br>active learn</br>ing, but it also takes advantage of the recent progresses on semi-supervised learning [2].",
                "Specifically, we incorporate a locality preserving regularizer into the standard regression framework and find the most informative samples with respect to the new objective function.",
                "In this way, the <br>active learn</br>ing and semi-supervised learning techniques are seamlessly unified for learning an optimal classifier. 3.",
                "The relevance feedback technique is crucial to image retrieval.",
                "For all the five algorithms, the retrieval performance improves with more feedbacks provided by the user. 7.",
                "CONCLUSIONS AND FUTURE WORK This paper describes a novel <br>active learn</br>ing algorithm, called Laplacian Optimal Design, to enable more effective relevance feedback image retrieval.",
                "Our algorithm is based on an objective function which simultaneously minimizes the empirical error and preserves the local geometrical structure of the data space.",
                "Using techniques from experimental design, our algorithm finds the most informative images to label.",
                "These labeled images and the unlabeled images in the database are used to learn a classifier.",
                "The experimental results on Corel database show that both <br>active learn</br>ing and semi-supervised learning can significantly improve the retrieval performance.",
                "In this paper, we consider the image retrieval problem on a small, static, and closed-domain image data.",
                "A much more challenging domain is the World Wide Web (WWW).",
                "For Web image search, it is possible to collect a large amount of user click information.",
                "This information can be naturally used to construct the affinity graph in our algorithm.",
                "However, the computational complexity in Web scenario may become a crucial issue.",
                "Also, although our primary interest in this paper is focused on relevance feedback image retrieval, our results may also be of interest to researchers in patten recognition and machine learning, especially when a large amount of data is available but only a limited samples can be labeled. 8.",
                "REFERENCES [1] A. C. Atkinson and A. N. Donev.",
                "Optimum Experimental Designs.",
                "Oxford University Press, 2002. [2] M. Belkin, P. Niyogi, and V. Sindhwani.",
                "Manifold regularization: A geometric framework for learning from examples.",
                "Journal of Machine Learning Research, 7:2399-2434, 2006. [3] F. R. K. Chung.",
                "Spectral Graph Theory, volume 92 of Regional Conference Series in Mathematics.",
                "AMS, 1997. [4] D. A. Cohn, Z. Ghahramani, and M. I. Jordan.",
                "Active learning with statistical models.",
                "Journal of Artificial Intelligence Research, 4:129-145, 1996. [5] A. Dong and B. Bhanu.",
                "A new semi-supervised em algorithm for image retrieval.",
                "In IEEE Conf. on Computer Vision and Pattern Recognition, Madison, WI, 2003. [6] P. Flaherty, M. I. Jordan, and A. P. Arkin.",
                "Robust design of biological experiments.",
                "In Advances in Neural Information Processing Systems 18, Vancouver, Canada, 2005. [7] K.-S. Goh, E. Y. Chang, and W.-C. Lai.",
                "Multimodal concept-dependent <br>active learn</br>ing for image retrieval.",
                "In Proceedings of the ACM Conference on Multimedia, New York, October 2004. [8] X.",
                "He.",
                "Incremental semi-supervised subspace learning for image retrieval.",
                "In Proceedings of the ACM Conference on Multimedia, New York, October 2004. [9] S. C. Hoi and M. R. Lyu.",
                "A semi-supervised <br>active learn</br>ing framework for image retrieval.",
                "In IEEE International Conference on Computer Vision and Pattern Recognition, San Diego, CA, 2005. [10] D. P. Huijsmans and N. Sebe.",
                "How to complete performance graphs in content-based image retrieval: Add generality and normalize scope.",
                "IEEE Transactions on Pattern Analysis and Machine Intelligence, 27(2):245-251, 2005. [11] Y.-Y.",
                "Lin, T.-L. Liu, and H.-T. Chen.",
                "Semantic manifold learning for image retrieval.",
                "In Proceedings of the ACM Conference on Multimedia, Singapore, November 2005. [12] Y. Rui, T. S. Huang, M. Ortega, and S. Mehrotra.",
                "Relevance feedback: A power tool for interative content-based image retrieval.",
                "IEEE Transactions on Circuits and Systems for Video Technology, 8(5), 1998. [13] A. W. Smeulders, M. Worring, S. Santini, A. Gupta, and R. Jain.",
                "Content-based image retrieval at the end of the early years.",
                "IEEE Transactions on Pattern Analysis and Machine Intelligence, 22(12):1349-1380, 2000. [14] S. Tong and E. Chang.",
                "Support vector machine <br>active learn</br>ing for image retrieval.",
                "In Proceedings of the ninth ACM international conference on Multimedia, pages 107-118, 2001. [15] H. Yu, M. Li, H.-J.",
                "Zhang, and J. Feng.",
                "Color texture moments for content-based image retrieval.",
                "In International Conference on Image Processing, pages 24-28, 2002. [16] K. Yu, J. Bi, and V. Tresp.",
                "Active learning via transductive experimental design.",
                "In Proceedings of the 23rd International Conference on Machine Learning, Pittsburgh, PA, 2006."
            ],
            "original_annotated_samples": [
                "In this paper, we propose a novel <br>active learn</br>ing algorithm, called Laplacian Optimal Design (LOD), for relevance feedback image retrieval.",
                "This problem is typically called <br>active learn</br>ing [4].",
                "Many real world applications can be casted into <br>active learn</br>ing framework.",
                "Thus <br>active learn</br>ing can be naturally introduced into image retrieval.",
                "Despite many existing <br>active learn</br>ing techniques, Support Vector Machine (SVM) <br>active learn</br>ing [14] and regression based active learning [1] have received the most interests."
            ],
            "translated_annotated_samples": [
                "En este artículo, proponemos un novedoso algoritmo de <br>aprendizaje activo</br>, llamado Diseño Óptimo Laplaciano (LOD), para la recuperación de imágenes con retroalimentación de relevancia.",
                "Este problema se llama típicamente <br>aprendizaje activo</br> [4].",
                "Muchas aplicaciones del mundo real pueden ser adaptadas al marco de <br>aprendizaje activo</br>.",
                "Por lo tanto, el <br>aprendizaje activo</br> puede ser introducido de forma natural en la recuperación de imágenes.",
                "A pesar de la existencia de muchas técnicas de <br>aprendizaje activo</br>, el <br>aprendizaje activo</br> de Máquina de Vectores de Soporte (SVM) [14] y el aprendizaje activo basado en regresión [1] han sido los que han despertado mayor interés."
            ],
            "translated_text": "Diseño óptimo de Laplaciano para la recuperación de imágenes Xiaofei He Yahoo! El feedback de relevancia es una técnica poderosa para mejorar el rendimiento de la Recuperación de Imágenes Basada en Contenido (CBIR). Solicita las valoraciones de relevancia de los usuarios sobre las imágenes recuperadas por los sistemas CBIR. La etiqueta de los usuarios se utiliza luego para entrenar un clasificador que distinga entre imágenes relevantes e irrelevantes. Sin embargo, las imágenes principales que se devuelven pueden no ser las más informativas. El desafío consiste en determinar qué imágenes sin etiquetar serían las más informativas (es decir, mejorarían más al clasificador) si fueran etiquetadas y utilizadas como muestras de entrenamiento. En este artículo, proponemos un novedoso algoritmo de <br>aprendizaje activo</br>, llamado Diseño Óptimo Laplaciano (LOD), para la recuperación de imágenes con retroalimentación de relevancia. Nuestro algoritmo se basa en un modelo de regresión que minimiza el error cuadrático mínimo en las imágenes medidas (o etiquetadas) y al mismo tiempo preserva la estructura geométrica local del espacio de la imagen. Específicamente, asumimos que si dos imágenes están lo suficientemente cerca una de la otra, entonces sus medidas (o etiquetas) también son cercanas. Al construir un grafo de vecinos más cercanos, la estructura geométrica del espacio de la imagen puede ser descrita por el Laplaciano del grafo. Discutimos cómo los resultados del campo del diseño experimental óptimo pueden ser utilizados para guiar nuestra selección de un subconjunto de imágenes, que nos proporciona la mayor cantidad de información. Los resultados experimentales en la base de datos Corel sugieren que el enfoque propuesto logra una mayor precisión en la recuperación de imágenes con retroalimentación de relevancia. Categorías y Descriptores de Asignaturas H.3.3 [Almacenamiento y recuperación de información]: Búsqueda y recuperación de información-Retroalimentación de relevancia; G.3 [Matemáticas de la Computación]: Probabilidad y Estadística-Diseño experimental Términos Generales Algoritmos, Rendimiento, Teoría 1. INTRODUCCIÓN En muchas tareas de aprendizaje automático y recuperación de información, no hay escasez de datos no etiquetados pero las etiquetas son costosas. El desafío consiste en determinar qué muestras sin etiquetar serían las más informativas (es decir, mejorarían más el clasificador) si fueran etiquetadas y utilizadas como muestras de entrenamiento. Este problema se llama típicamente <br>aprendizaje activo</br> [4]. Aquí la tarea es minimizar un costo general, que depende tanto de la precisión del clasificador como del costo de la recolección de datos. Muchas aplicaciones del mundo real pueden ser adaptadas al marco de <br>aprendizaje activo</br>. Particularmente, consideramos el problema de la recuperación de imágenes basada en contenido impulsada por la retroalimentación de relevancia (CBIR) [13]. La Recuperación de Imágenes Basada en Contenido ha atraído un interés sustancial en la última década [13]. Está motivado por el rápido crecimiento de las bases de datos de imágenes digitales que, a su vez, requieren esquemas de búsqueda eficientes. En lugar de describir una imagen usando texto, en estos sistemas se describe una consulta de imagen utilizando una o más imágenes de ejemplo. Las características visuales de bajo nivel (color, textura, forma, etc.) se extraen automáticamente para representar las imágenes. Sin embargo, las características de bajo nivel pueden no caracterizar con precisión los conceptos semánticos de alto nivel. Para reducir la brecha semántica, se introduce la retroalimentación de relevancia en la recuperación de información basada en el contenido (CBIR) [12]. En muchos de los sistemas actuales de recuperación de imágenes basados en retroalimentación de relevancia, se requiere que el usuario proporcione sus juicios de relevancia sobre las imágenes principales devueltas por el sistema. Las imágenes etiquetadas se utilizan luego para entrenar un clasificador que separe las imágenes que coinciden con el concepto de la consulta de aquellas que no lo hacen. Sin embargo, en general, las imágenes principales que se devuelven pueden no ser las más informativas. En el peor de los casos, todas las imágenes principales etiquetadas por el usuario pueden ser positivas y, por lo tanto, las técnicas estándar de clasificación no pueden aplicarse debido a la falta de ejemplos negativos. A diferencia de los problemas de clasificación estándar donde las muestras etiquetadas están predefinidas, en la recuperación de imágenes con retroalimentación de relevancia, el sistema puede seleccionar activamente las imágenes a etiquetar. Por lo tanto, el <br>aprendizaje activo</br> puede ser introducido de forma natural en la recuperación de imágenes. A pesar de la existencia de muchas técnicas de <br>aprendizaje activo</br>, el <br>aprendizaje activo</br> de Máquina de Vectores de Soporte (SVM) [14] y el aprendizaje activo basado en regresión [1] han sido los que han despertado mayor interés. ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        }
    }
}