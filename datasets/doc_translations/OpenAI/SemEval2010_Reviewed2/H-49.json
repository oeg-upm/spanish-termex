{
    "id": "H-49",
    "original_text": "Performance Prediction Using Spatial Autocorrelation Fernando Diaz Center for Intelligent Information Retrieval Department of Computer Science University of Massachusetts Amherst, MA 01003 fdiaz@cs.umass.edu ABSTRACT Evaluation of information retrieval systems is one of the core tasks in information retrieval. Problems include the inability to exhaustively label all documents for a topic, nongeneralizability from a small number of topics, and incorporating the variability of retrieval systems. Previous work addresses the evaluation of systems, the ranking of queries by difficulty, and the ranking of individual retrievals by performance. Approaches exist for the case of few and even no relevance judgments. Our focus is on zero-judgment performance prediction of individual retrievals. One common shortcoming of previous techniques is the assumption of uncorrelated document scores and judgments. If documents are embedded in a high-dimensional space (as they often are), we can apply techniques from spatial data analysis to detect correlations between document scores. We find that the low correlation between scores of topically close documents often implies a poor retrieval performance. When compared to a state of the art baseline, we demonstrate that the spatial analysis of retrieval scores provides significantly better prediction performance. These new predictors can also be incorporated with classic predictors to improve performance further. We also describe the first large-scale experiment to evaluate zero-judgment performance prediction for a massive number of retrieval systems over a variety of collections in several languages. Categories and Subject Descriptors H.3.3 [Information Search and Retrieval]: Retrieval models; H.3.4 [Systems and Software]: Performance evaluation (efficiency and effectiveness) General Terms Performance, Design, Reliability, Experimentation 1. INTRODUCTION In information retrieval, a user poses a query to a system. The system retrieves n documents each receiving a realvalued score indicating the predicted degree of relevance. If we randomly select pairs of documents from this set, we expect some pairs to share the same topic and other pairs to not share the same topic. Take two topically-related documents from the set and call them a and b. If the scores of a and b are very different, we may be concerned about the performance of our system. That is, if a and b are both on the topic of the query, we would like them both to receive a high score; if a and b are not on the topic of the query, we would like them both to receive a low score. We might become more worried as we find more differences between scores of related documents. We would be more comfortable with a retrieval where scores are consistent between related documents. Our paper studies the quantification of this inconsistency in a retrieval from a spatial perspective. Spatial analysis is appropriate since many retrieval models embed documents in some vector space. If documents are embedded in a space, proximity correlates with topical relationships. Score consistency can be measured by the spatial version of autocorrelation known as the Moran coefficient or IM [5, 10]. In this paper, we demonstrate a strong correlation between IM and retrieval performance. The discussion up to this point is reminiscent of the cluster hypothesis. The cluster hypothesis states: closely-related documents tend to be relevant to the same request [12]. As we shall see, a retrieval functions spatial autocorrelation measures the degree to which closely-related documents receive similar scores. Because of this, we interpret autocorrelation as measuring the degree to which a retrieval function satisfies the clustering hypothesis. If this connection is reasonable, in Section 6, we present evidence that failure to satisfy the cluster hypothesis correlates strongly with poor performance. In this work, we provide the following contributions, 1. A general, robust method for predicting the performance of retrievals with zero relevance judgments (Section 3). 2. A theoretical treatment of the similarities and motivations behind several state-of-the-art performance prediction techniques (Section 4). 3. The first large-scale experiments of zero-judgment, single run performance prediction (Sections 5 and 6). 2. PROBLEM DEFINITION Given a query, an information retrieval system produces a ranking of documents in the collection encoded as a set of scores associated with documents. We refer to the set of scores for a particular query-system combination as a retrieval. We would like to predict the performance of this retrieval with respect to some evaluation measure (eg, mean average precision). In this paper, we present results for ranking retrievals from arbitrary systems. We would like this ranking to approximate the ranking of retrievals by the evaluation measure. This is different from ranking queries by the average performance on each query. It is also different from ranking systems by the average performance on a set of queries. Scores are often only computed for the top n documents from the collection. We place these scores in the length n vector, y, where yi refers to the score of the ith-ranked document. We adjust scores to have zero mean and unit variance. We use this method because of its simplicity and its success in previous work [15]. 3. SPATIAL CORRELATION In information retrieval, we often assume that the representations of documents exist in some high-dimensional vector space. For example, given a vocabulary, V, this vector space may be an arbitrary |V|-dimensional space with cosine inner-product or a multinomial simplex with a distributionbased distance measure. An embedding space is often selected to respect topical proximity; if two documents are near, they are more likely to share a topic. Because of the prevalence and success of spatial models of information retrieval, we believe that the application of spatial data analysis techniques are appropriate. Whereas in information retrieval, we are concerned with the score at a point in a space, in spatial data analysis, we are concerned with the value of a function at a point or location in a space. We use the term function here to mean a mapping from a location to a real value. For example, we might be interested in the prevalence of a disease in the neighborhood of some city. The function would map the location of a neighborhood to an infection rate. If we want to quantify the spatial dependencies of a function, we would employ a measure referred to as the spatial autocorrelation [5, 10]. High spatial autocorrelation suggests that knowing the value of a function at location a will tell us a great deal about the value at a neighboring location b. There is a high spatial autocorrelation for a function representing the temperature of a location since knowing the temperature at a location a will tell us a lot about the temperature at a neighboring location b. Low spatial autocorrelation suggests that knowing the value of a function at location a tells us little about the value at a neighboring location b. There is low spatial autocorrelation in a function measuring the outcome of a coin toss at a and b. In this section, we will begin by describing what we mean by spatial proximity for documents and then define a measure of spatial autocorrelation. We conclude by extending this model to include information from multiple retrievals from multiple systems for a single query. 3.1 Spatial Representation of Documents Our work does not focus on improving a specific similarity measure or defining a novel vector space. Instead, we choose an inner product known to be effective at detecting interdocument topical relationships. Specifically, we adopt tf.idf document vectors, ˜di = di log „ (n + 0.5) − ci 0.5 + ci « (1) where d is a vector of term frequencies, c is the length-|V| document frequency vector. We use this weighting scheme due to its success for topical link detection in the context of Topic Detection and Tracking (TDT) evaluations [6]. Assuming vectors are scaled by their L2 norm, we use the inner product, ˜di, ˜dj , to define similarity. Given documents and some similarity measure, we can construct a matrix which encodes the similarity between pairs of documents. Recall that we are given the top n documents retrieved in y. We can compute an n × n similarity matrix, W. An element of this matrix, Wij represents the similarity between documents ranked i and j. In practice, we only include the affinities for a documents k-nearest neighbors. In all of our experiments, we have fixed k to 5. We leave exploration of parameter sensitivity to future work. We also row normalize the matrix so that Pn j=1 Wij = 1 for all i. 3.2 Spatial Autocorrelation of a Retrieval Recall that we are interested in measuring the similarity between the scores of spatially-close documents. One such suitable measure is the Moran coefficient of spatial autocorrelation. Assuming the function y over n locations, this is defined as ˜IM = n eTWe P i,j Wijyiyj P i y2 i = n eTWe yT Wy yTy (2) where eT We = P ij Wij. We would like to compare autocorrelation values for different retrievals. Unfortunately, the bound for Equation 2 is not consistent for different W and y. Therefore, we use the Cauchy-Schwartz inequality to establish a bound, ˜IM ≤ n eTWe s yTWTWy yTy And we define the normalized spatial autocorrelation as IM = yT Wy p yTy × yTWTWy Notice that if we let ˜y = Wy, then we can write this formula as, IM = yT ˜y y 2 ˜y 2 (3) which can be interpreted as the correlation between the original retrieval scores and a set of retrieval scores diffused in the space. We present some examples of autocorrelations of functions on a grid in Figure 1. 3.3 Correlation with Other Retrievals Sometimes we are interested in the performance of a single retrieval but have access to scores from multiple systems for (a) IM = 0.006 (b) IM = 0.241 (c) IM = 0.487 Figure 1: The Moran coefficient, IM for a several binary functions on a grid. The Moran coefficient is a local measure of function consistency. From the perspective of information retrieval, each of these grid spaces would represent a document and documents would be organized so that they lay next to topically-related documents. Binary retrieval scores would define a pattern on this grid. Notice that, as the Moran coefficient increases, neighboring cells tend to have similar values. the same query. In this situation, we can use combined information from these scores to construct a surrogate for a high-quality ranking [17]. We can treat the correlation between the retrieval we are interested in and the combined scores as a predictor of performance. Assume that we are given m score functions, yi, for the same n documents. We will represent the mean of these vectors as yµ = Pm i=1 yi. We use the mean vector as an approximation to relevance. Since we use zero mean and unit variance normalization, work in metasearch suggests that this assumption is justified [15]. Because yµ represents a very good retrieval, we hypothesize that a strong similarity between yµ and y will correlate positively with system performance. We use Pearsons product-moment correlation to measure the similarity between these vectors, ρ(y, yµ) = yT yµ y 2 yµ 2 (4) We will comment on the similarity between Equation 3 and 4 in Section 7. Of course, we can combine ρ(y, ˜y) and ρ(y, yµ) if we assume that they capture different factors in the prediction. One way to accomplish this is to combine these predictors as independent variables in a linear regression. An alternative means of combination is suggested by the mathematical form of our predictors. Since ˜y encodes the spatial dependencies in y and yµ encodes the spatial properties of the multiple runs, we can compute a third correlation between these two vectors, ρ(˜y, yµ) = ˜yT yµ ˜y 2 yµ 2 (5) We can interpret Equation 5 as measuring the correlation between a high quality ranking (yµ) and a spatially smoothed version of the retrieval (˜y). 4. RELATIONSHIP WITH OTHER PREDICTORS One way to predict the effectiveness of a retrieval is to look at the shared vocabulary of the top n retrieved documents. If we computed the most frequent content words in this set, we would hope that they would be consistent with our topic. In fact, we might believe that a bad retrieval would include documents on many disparate topics, resulting in an overlap of terminological noise. The Clarity of a query attempts to quantify exactly this [7]. Specifically, Clarity measures the similarity of the words most frequently used in retrieved documents to those most frequently used in the whole corpus. The conjecture is that a good retrieval will use language distinct from general text; the overlapping language in a bad retrieval will tend to be more similar to general text. Mathematically, we can compute a representation of the language used in the initial retrieval as a weighted combination of document language models, P(w|θQ) = nX i=1 P(w|θi) P(Q|θi) Z (6) where θi is the language model of the ith-ranked document, P(Q|θi) is the query likelihood score of the ith-ranked document and Z = Pn i=1 P(Q|θi) is a normalization constant. The similarity between the multinomial P(w|θQ) and a model of general text can be computed using the Kullback-Leibler divergence, DV KL(θQ θC ). Here, the distribution P(w|θC ) is our model of general text which can be computed using term frequencies in the corpus. In Figure 2a, we present Clarity as measuring the distance between the weighted center of mass of the retrieval (labeled y) and the unweighted center of mass of the collection (labeled O). Clarity reaches a minimum when a retrieval assigns every document the same score. Lets again assume we have a set of n documents retrieved for our query. Another way to quantify the dispersion of a set of documents is to look at how clustered they are. We may hypothesize that a good retrieval will return a single, tight cluster. A poorly performing retrieval will return a loosely related set of documents covering many topics. One proposed method of quantifying this dispersion is to measure the distance from a random document a to its nearest neighbor, b. A retrieval which is tightly clustered will, on average, have a low distance between a and b; a retrieval which is less tightly-closed will, on average have high distances between a and b. This average corresponds to using the Cox-Lewis statistic to measure the randomness of the top n documents retrieved from a system [18]. In Figure 2a, this is roughly equivalent to measuring the area of the set n. Notice that we are throwing away information about the retrieval function y. Therefore the Cox-Lewis statistic is highly dependent on selecting the top n documents.1 Remember that we have n documents and a set of scores. Lets assume that we have access to the system which provided the original scores and that we can also request scores for new documents. This suggests a third method for predicting performance. Take some document, a, from the retrieved set and arbitrarily add or remove words at random to create a new document ˜a. Now, we can ask our system to score ˜a with respect to our query. If, on average over the n documents, the scores of a and ˜a tend to be very different, we might suspect that the system is failing on this query. So, an alternative approach is to measure the simi1 The authors have suggested coupling the query with the distance measure [18]. The information introduced by the query, though, is retrieval-independent so that, if two retrievals return the same set of documents, the approximate Cox-Lewis statistic will be the same regardless of the retrieval scores. yOy (a) Global Divergence µ(y)˜y y (b) Score Perturbation µ(y) y (c) Multirun Averaging Figure 2: Representation of several performance predictors on a grid. In Figure 2a, we depict predictors which measure the divergence between the center of mass of a retrieval and the center of the embedding space. In Figure 2b, we depict predictors which compare the original retrieval, y, to a perturbed version of the retrieval, ˜y. Our approach uses a particular type of perturbation based on score diffusion. Finally, in Figure 2c, we depict prediction when given retrievals from several other systems on the same query. Here, we can consider the fusion of these retrieval as a surrogate for relevance. larity between the retrieval and a perturbed version of that retrieval [18, 19]. This can be accomplished by either perturbing the documents or queries. The similarity between the two retrievals can be measured using some correlation measure. This is depicted in Figure 2b. The upper grid represents the original retrieval, y, while the lower grid represents the function after having been perturbed, ˜y. The nature of the perturbation process requires additional scorings or retrievals. Our predictor does not require access to the original scoring function or additional retrievals. So, although our method is similar to other perturbation methods in spirit, it can be applied in situations when the retrieval system is inaccessible or costly to access. Finally, assume that we have, in addition to the retrieval we want to evaluate, m retrievals from a variety of different systems. In this case, we might take a document a, compare its rank in the retrieval to its average rank in the m retrievals. If we believe that the m retrievals provide a satisfactory approximation to relevance, then a very large difference in rank would suggest that our retrieval is misranking a. If this difference is large on average over all n documents, then we might predict that the retrieval is bad. If, on the other hand, the retrieval is very consistent with the m retrievals, then we might predict that the retrieval is good. The similarity between the retrieval and the combined retrieval may be computed using some correlation measure. This is depicted in Figure 2c. In previous work, the Kullback-Leibler divergence between the normalized scores of the retrieval and the normalized scores of the combined retrieval provides the similarity [1]. 5. EXPERIMENTS Our experiments focus on testing the predictive power of each of our predictors: ρ(y, ˜y), ρ(y, yµ), and ρ(˜y, yµ). As stated in Section 2, we are interested in predicting the performance of the retrieval generated by an arbitrary system. Our methodology is consistent with previous research in that we predict the relative performance of a retrieval by comparing a ranking based on our predictor to a ranking based on average precision. We present results for two sets of experiments. The first set of experiments presents detailed comparisons of our predictors to previously-proposed predictors using identical data sets. Our second set of experiments demonstrates the generalizability of our approach to arbitrary retrieval methods, corpus types, and corpus languages. 5.1 Detailed Experiments In these experiments, we will predict the performance of language modeling scores using our autocorrelation predictor, ρ(y, ˜y); we do not consider ρ(y, yµ) or ρ(˜y, yµ) because, in these detailed experiments, we focus on ranking the retrievals from a single system. We use retrievals, values for baseline predictors, and evaluation measures reported in previous work [19]. 5.1.1 Topics and Collections These performance prediction experiments use language model retrievals performed for queries associated with collections in the TREC corpora. Using TREC collections allows us to confidently associate an average precision with a retrieval. In these experiments, we use the following topic collections: TREC 4 ad-hoc, TREC 5 ad-hoc, Robust 2004, Terabyte 2004, and Terabyte 2005. 5.1.2 Baselines We provide two baselines. Our first baseline is the classic Clarity predictor presented in Equation 6. Clarity is designed to be used with language modeling systems. Our second baseline is Zhou and Crofts ranking robustness predictor. This predictor corrupts the top k documents from retrieval and re-computes the language model scores for these corrupted documents. The value of the predictor is the Spearman rank correlation between the original ranking and the corrupted ranking. In our tables, we will label results for Clarity using DV KL and the ranking robustness predictor using P. 5.2 Generalizability Experiments Our predictors do not require a particular baseline retrieval system; the predictors can be computed for an arbitrary retrieval, regardless of how scores were generated. We believe that that is one of the most attractive aspects of our algorithm. Therefore, in a second set of experiments, we demonstrate the ability of our techniques to generalize to a variety of collections, topics, and retrieval systems. 5.2.1 Topics and Collections We gathered a diverse set of collections from all possible TREC corpora. We cast a wide net in order to locate collections where our predictors might fail. Our hypothesis is that documents with high topical similarity should have correlated scores. Therefore, we avoided collections where scores were unlikely to be correlated (eg, question-answering) or were likely to be negatively correlated (eg, novelty). Nevertheless, our collections include corpora where correlations are weakly justified (eg, non-English corpora) or not justified at all (eg, expert search). We use the ad-hoc tracks from TREC3-8, TREC Robust 2003-2005, TREC Terabyte 20042005, TREC4-5 Spanish, TREC5-6 Chinese, and TREC Enterprise Expert Search 2005. In all cases, we use only the automatic runs for ad-hoc tracks submitted to NIST. For all English and Spanish corpora, we construct the matrix W according to the process described in Section 3.1. For Chinese corpora, we use na¨ıve character-based tf.idf vectors. For entities, entries in W are proportional to the number of documents in which two entities cooccur. 5.2.2 Baselines In our detailed experiments, we used the Clarity measure as a baseline. Since we are predicting the performance of retrievals which are not based on language modeling, we use a version of Clarity referred to as ranked-list Clarity [7]. Ranked-list clarity converts document ranks to P(Q|θi) values. This conversion begins by replacing all of the scores in y with the respective ranks. Our estimation of P(Q|θi) from the ranks, then is, P(Q|θi) = ( 2(c+1−yi) c(c+1) if yi ≤ c 0 otherwise (7) where c is a cutoff parameter. As suggested by the authors, we fix the algorithm parameters c and λ2 so that c = 60 and λ2 = 0.10. We use Equation 6 to estimate P(w|θQ) and DV KL(θQ θC ) to compute the value of the predictor. We will refer to this predictor as DV KL, superscripted by V to indicate that the Kullback-Leibler divergence is with respect to the term embedding space. When information from multiple runs on the same query is available, we use Aslam and Pavlus document-space multinomial divergence as a baseline [1]. This rank-based method first normalizes the scores in a retrieval as an n-dimensional multinomial. As with ranked-list Clarity, we begin by replacing all of the scores in y with their respective ranks. Then, we adjust the elements of y in the following way, ˆyi = 1 2n 0 @1 + nX k=yi 1 k 1 A (8) In our multirun experiments, we only use the top 75 documents from each retrieval (n = 75); this is within the range of parameter values suggested by the authors. However, we admit not tuning this parameter for either our system or the baseline. The predictor is the divergence between the candidate distribution, y, and the mean distribution, yµ . With the uniform linear combination of these m retrievals represented as yµ, we can compute the divergence as Dn KL(ˆy ˆyµ) where we use the superscript n to indicate that the summation is over the set of n documents. This baseline was developed in the context of predicting query difficulty but we adopt it as a reasonable baseline for predicting retrieval performance. 5.2.3 Parameter Settings When given multiple retrievals, we use documents in the union of the top k = 75 documents from each of the m retrievals for that query. If the size of this union is ˜n, then yµ and each yi is of length ˜n. In some cases, a system did not score a document in the union. Since we are making a Gaussian assumption about our scores, we can sample scores for these unseen documents from the negative tail of the distribution. Specifically, we sample from the part of the distribution lower than the minimum value of in the normalized retrieval. This introduces randomness into our algorithm but we believe it is more appropriate than assigning an arbitrary fixed value. We optimized the linear regression using the square root of each predictor. We found that this substantially improved fits for all predictors, including the baselines. We considered linear combinations of pairs of predictors (labeled by the components) and all predictors (labeled as β). 5.3 Evaluation Given a set of retrievals, potentially from a combination of queries and systems, we measure the correlation of the rank ordering of this set by the predictor and by the performance metric. In order to ensure comparability with previous results, we present Kendalls τ correlation between the predictors ranking and ranking based on average precision of the retrieval. Unless explicitly noted, all correlations are significant with p < 0.05. Predictors can sometimes perform better when linearly combined [9, 11]. Although previous work has presented the coefficient of determination (R2 ) to measure the quality of the regression, this measure cannot be reliably used when comparing slight improvements from combining predictors. Therefore, we adopt the adjusted coefficient of determination which penalizes models with more variables. The adjusted R2 allows us to evaluate the improvement in prediction achieved by adding a parameter but loses the statistical interpretation of R2 . We will use Kendalls τ to evaluate the magnitude of the correlation and the adjusted R2 to evaluate the combination of variables. 6. RESULTS We present results for our detailed experiments comparing the prediction of language model scores in Table 1. Although the Clarity measure is theoretically designed for language model scores, it consistently underperforms our system-agnostic predictor. Ranking robustness was presented as an improvement to Clarity for web collections (represented in our experiments by the terabyte04 and terabyte05 collections), shifting the τ correlation from 0.139 to 0.150 for terabyte04 and 0.171 to 0.208 for terabyte05. However, these improvements are slight compared to the performance of autocorrelation on these collections. Our predictor achieves a τ correlation of 0.454 for terabyte04 and 0.383 for terabyte05. Though not always the strongest, autocorrelation achieves correlations competitive with baseline predictors. When examining the performance of linear combinations of predictors, we note that in every case, autocorrelation factors as a necessary component of a strong predictor. We also note that the adjusted R2 for individual baselines are always significantly improved by incorporating autocorrelation. We present our generalizability results in Table 2. We begin by examining the situation in column (a) where we are presented with a single retrieval and no information from additional retrievals. For every collection except one, we achieve significantly better correlations than ranked-list Clarity. Surprisingly, we achieve relatively strong correlations for Spanish and Chinese collections despite our na¨ıve processing. We do not have a ranked-list clarity correlation for ent05 because entity modeling is itself an open research question. However, our autocorrelation measure does not achieve high correlations perhaps because relevance for entity retrieval does not propagate according to the cooccurrence links we use. As noted above, the poor Clarity performance on web data is consistent with our findings in the detailed experiments. Clarity also notably underperforms for several news corpora (trec5, trec7, and robust04). On the other hand, autocorrelation seems robust to the changes between different corpora. Next, we turn to the introduction of information from multiple retrievals. We compare the correlations between those predictors which do not use this information in column (a) and those which do in column (b). For every collection, the predictors in column (b) outperform the predictors in column (a), indicating that the information from additional runs can be critical to making good predictions. Inspecting the predictors in column (b), we only draw weak conclusions. Our new predictors tend to perform better on news corpora. And between our new predictors, the hybrid ρ(˜y, yµ) predictor tends to perform better. Recall that our ρ(˜y, yµ) measure incorporates both spatial and multiple retrieval information. Therefore, we believe that the improvement in correlation is the result of incorporating information from spatial behavior. In column (c), we can investigate the utility of incorporating spatial information with information from multiple retrievals. Notice that in the cases where autocorrelation, ρ(y, ˜y), alone performs well (trec3, trec5-spanish, and trec6-chinese), it is substantially improved by incorporating multiple-retrieval information from ρ(y, yµ) in the linear regression, β. In the cases where ρ(y, yµ) performs well, incorporating autocorrelation rarely results in a significant improvement in performance. In fact, in every case where our predictor outperforms the baseline, it includes information from multiple runs. 7. DISCUSSION The most important result from our experiments involves prediction when no information is available from multiple runs (Tables 1 and 2a). This situation arises often in system design. For example, a system may need to, at retrieval time, assess its performance before deciding to conduct more intensive processing such as pseudo-relevance feedback or interaction. Assuming the presence of multiple retrievals is unrealistic in this case. We believe that autocorrelation is, like multiple-retrieval algorithms, approximating a good ranking; in this case by diffusing scores. Why is ˜y a reasonable surrogate? We know that diffusion of scores on the web graph and language model graphs improves performance [14, 16]. Therefore, if score diffusion tends to, in general, improve performance, then diffused scores will, in general, provide a good surrogate for relevance. Our results demonstrate that this approximation is not as powerful as information from multiple retrievals. Nevertheless, in situations where this information is lacking, autocorrelation provides substantial information. The success of autocorrelation as a predictor may also have roots in the clustering hypothesis. Recall that we regard autocorrelation as the degree to which a retrieval satisfies the clustering hypothesis. Our experiments, then, demonstrate that a failure to respect the clustering hypothesis correlates with poor performance. Why might systems fail to conform to the cluster hypothesis? Query-based information retrieval systems often score documents independently. The score of document a may be computed by examining query term or phrase matches, the document length, and perhaps global collection statistics. Once computed, a system rarely compares the score of a to the score of a topically-related document b. With some exceptions, the correlation of document scores has largely been ignored. We should make it clear that we have selected tasks where topical autocorrelation is appropriate. There are certainly cases where there is no reason to believe that retrieval scores will have topical autocorrelation. For example, ranked lists which incorporate document novelty should not exhibit spatial autocorrelation; if anything autocorrelation should be negative for this task. Similarly, answer candidates in a question-answering task may or may not exhibit autocorrelation; in this case, the semantics of links is questionable too. It is important before applying this measure to confirm that, given the semantics for some link between two retrieved items, we should expect a correlation between scores. 8. RELATED WORK In this section we draw more general comparisons to other work in performance prediction and spatial data analysis. There is a growing body of work which attempts to predict the performance of individual retrievals [7, 3, 11, 9, 19]. We have attempted to place our work in the context of much of this work in Section 4. However, a complete comparison is beyond the scope of this paper. We note, though, that our experiments cover a larger and more diverse set of retrievals, collections, and topics than previously examined. Much previous work-particularly in the context of TRECfocuses on predicting the performance of systems. Here, each system generates k retrievals. The task is, given these retrievals, to predict the ranking of systems according to some performance measure. Several papers attempt to address this task under the constraint of few judgments [2, 4]. Some work even attempts to use zero judgments by leveraging multiple retrievals for the same query [17]. Our task differs because we focus on ranking retrievals independent of the generating system. The task here is not to test the hypothesis system A is superior to system B but to test the hypothesis retrieval A is superior to retrieval B. Autocorrelation manifests itself in many classification tasks. Neville and Jensen define relational autocorrelation for relational learning problems and demonstrate that many classification tasks manifest autocorrelation [13]. Temporal autocorrelation of initial retrievals has also been used to predict performance [9]. However, temporal autocorrelation is performed by projecting the retrieval function into the temporal embedding space. In our work, we focus on the behavior of the function over the relationships between documents. τ adjusted R2 DV KL P ρ(y, ˜y) DV KL P ρ(y, ˜y) DV KL, P DV KL, ρ(y, ˜y) Pρ(y, ˜y) β trec4 0.353 0.548 0.513 0.168 0.363 0.422 0.466 0.420 0.557 0.553 trec5 0.311 0.329 0.357 0.116 0.190 0.236 0.238 0.244 0.266 0.269 robust04 0.418 0.398 0.373 0.256 0.304 0.278 0.403 0.373 0.402 0.442 terabyte04 0.139 0.150 0.454 0.059 0.045 0.292 0.076 0.293 0.289 0.284 terabyte05 0.171 0.208 0.383 0.022 0.072 0.193 0.120 0.225 0.218 0.257 Table 1: Comparison to Robustness and Clarity measures for language model scores. Evaluation replicates experiments from [19]. We present correlations between the classic Clarity measure (DV KL), the ranking robustness measure (P), and autocorrelation (ρ(y, ˜y)) each with mean average precision in terms of Kendalls τ. The adjusted coefficient of determination is presented to measure the effectiveness of combining predictors. Measures in bold represent the strongest correlation for that test/collection pair. multiple run (a) (b) (c) τ τ adjusted R2 DKL ρ(y, ˜y) Dn KL ρ(y, yµ) ρ(˜y, yµ) Dn KL ρ(y, ˜y) ρ(y, yµ) ρ(˜y, yµ) β trec3 0.201 0.461 0.461 0.439 0.456 0.444 0.395 0.394 0.386 0.498 trec4 0.252 0.396 0.455 0.482 0.489 0.379 0.263 0.429 0.482 0.483 trec5 0.016 0.277 0.433 0.459 0.393 0.280 0.157 0.375 0.323 0.386 trec6 0.230 0.227 0.352 0.428 0.418 0.203 0.089 0.323 0.325 0.325 trec7 0.083 0.326 0.341 0.430 0.483 0.264 0.182 0.363 0.442 0.400 trec8 0.235 0.396 0.454 0.508 0.567 0.402 0.272 0.490 0.580 0.523 robust03 0.302 0.354 0.377 0.385 0.447 0.269 0.206 0.274 0.392 0.303 robust04 0.183 0.308 0.301 0.384 0.453 0.200 0.182 0.301 0.393 0.335 robust05 0.224 0.249 0.371 0.377 0.404 0.341 0.108 0.313 0.328 0.336 terabyte04 0.043 0.245 0.544 0.420 0.392 0.516 0.105 0.357 0.343 0.365 terabyte05 0.068 0.306 0.480 0.434 0.390 0.491 0.168 0.384 0.309 0.403 trec4-spanish 0.307 0.388 0.488 0.398 0.395 0.423 0.299 0.282 0.299 0.388 trec5-spanish 0.220 0.458 0.446 0.484 0.475 0.411 0.398 0.428 0.437 0.529 trec5-chinese 0.092 0.199 0.367 0.379 0.384 0.379 0.199 0.273 0.276 0.310 trec6-chinese 0.144 0.276 0.265 0.353 0.376 0.115 0.128 0.188 0.223 0.199 ent05 - 0.181 0.324 0.305 0.282 0.211 0.043 0.158 0.155 0.179 Table 2: Large scale prediction experiments. We predict the ranking of large sets of retrievals for various collections and retrieval systems. Kendalls τ correlations are computed between the predicted ranking and a ranking based on the retrievals average precision. In column (a), we have predictors which do not use information from other retrievals for the same query. In columns (b) and (c) we present performance for predictors which incorporate information from multiple retrievals. The adjusted coefficient of determination is computed to determine effectiveness of combining predictors. Measures in bold represent the strongest correlation for that test/collection pair. Finally, regularization-based re-ranking processes are also closely-related to our work [8]. These techniques seek to maximize the agreement between scores of related documents by solving a constrained optimization problem. The maximization of consistency is equivalent to maximizing the Moran autocorrelation. Therefore, we believe that our work provides explanation for why regularization-based re-ranking works. 9. CONCLUSION We have presented a new method for predicting the performance of a retrieval ranking without any relevance judgments. We consider two cases. First, when making predictions in the absence of retrievals from other systems, our predictors demonstrate robust, strong correlations with average precision. This performance, combined with a simple implementation, makes our predictors, in particular, very attractive. We have demonstrated this improvement for many, diverse settings. To our knowledge, this is the first large scale examination of zero-judgment, single-retrieval performance prediction. Second, when provided retrievals from other systems, our extended methods demonstrate competitive performance with state of the art baselines. Our experiments also demonstrate the limits of the usefulness of our predictors when information from multiple runs is provided. Our results suggest two conclusions. First, our results could affect retrieval algorithm design. Retrieval algorithms designed to consider spatial autocorrelation will conform to the cluster hypothesis and improve performance. Second, our results could affect the design of minimal test collection algorithms. Much of the recent work in ranking systems sometimes ignores correlations between document labels and scores. We believe that these two directions could be rewarding given the theoretical and experimental evidence in this paper. 10. ACKNOWLEDGMENTS This work was supported in part by the Center for Intelligent Information Retrieval and in part by the Defense Advanced Research Projects Agency (DARPA) under contract number HR0011-06-C-0023. Any opinions, findings and conclusions or recommendations expressed in this material are the authors and do not necessarily reflect those of the sponsor. We thank Yun Zhou and Desislava Petkova for providing data and Andre Gauthier for technical assistance. 11. REFERENCES [1] J. Aslam and V. Pavlu. Query hardness estimation using jensen-shannon divergence among multiple scoring functions. In ECIR 2007: Proceedings of the 29th European Conference on Information Retrieval, 2007. [2] J. A. Aslam, V. Pavlu, and E. Yilmaz. A statistical method for system evaluation using incomplete judgments. In S. Dumais, E. N. Efthimiadis, D. Hawking, and K. Jarvelin, editors, Proceedings of the 29th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 541-548. ACM Press, August 2006. [3] D. Carmel, E. Yom-Tov, A. Darlow, and D. Pelleg. What makes a query difficult? In SIGIR 06: Proceedings of the 29th annual international ACM SIGIR conference on Research and development in information retrieval, pages 390-397, New York, NY, USA, 2006. ACM Press. [4] B. Carterette, J. Allan, and R. Sitaraman. Minimal test collections for retrieval evaluation. In SIGIR 06: Proceedings of the 29th annual international ACM SIGIR conference on Research and development in information retrieval, pages 268-275, New York, NY, USA, 2006. ACM Press. [5] A. D. Cliff and J. K. Ord. Spatial Autocorrelation. Pion Ltd., 1973. [6] M. Connell, A. Feng, G. Kumaran, H. Raghavan, C. Shah, and J. Allan. Umass at tdt 2004. Technical Report CIIR Technical Report IR - 357, Department of Computer Science, University of Massachusetts, 2004. [7] S. Cronen-Townsend, Y. Zhou, and W. B. Croft. Precision prediction based on ranked list coherence. Inf. Retr., 9(6):723-755, 2006. [8] F. Diaz. Regularizing ad-hoc retrieval scores. In CIKM 05: Proceedings of the 14th ACM international conference on Information and knowledge management, pages 672-679, New York, NY, USA, 2005. ACM Press. [9] F. Diaz and R. Jones. Using temporal profiles of queries for precision prediction. In SIGIR 04: Proceedings of the 27th annual international ACM SIGIR conference on Research and development in information retrieval, pages 18-24, New York, NY, USA, 2004. ACM Press. [10] D. A. Griffith. Spatial Autocorrelation and Spatial Filtering. Springer Verlag, 2003. [11] B. He and I. Ounis. Inferring Query Performance Using Pre-retrieval Predictors. In The Eleventh Symposium on String Processing and Information Retrieval (SPIRE), 2004. [12] N. Jardine and C. J. V. Rijsbergen. The use of hierarchic clustering in information retrieval. Information Storage and Retrieval, 7:217-240, 1971. [13] D. Jensen and J. Neville. Linkage and autocorrelation cause feature selection bias in relational learning. In ICML 02: Proceedings of the Nineteenth International Conference on Machine Learning, pages 259-266, San Francisco, CA, USA, 2002. Morgan Kaufmann Publishers Inc. [14] O. Kurland and L. Lee. Corpus structure, language models, and ad-hoc information retrieval. In SIGIR 04: Proceedings of the 27th annual international conference on Research and development in information retrieval, pages 194-201, New York, NY, USA, 2004. ACM Press. [15] M. Montague and J. A. Aslam. Relevance score normalization for metasearch. In CIKM 01: Proceedings of the tenth international conference on Information and knowledge management, pages 427-433, New York, NY, USA, 2001. ACM Press. [16] T. Qin, T.-Y. Liu, X.-D. Zhang, Z. Chen, and W.-Y. Ma. A study of relevance propagation for web search. In SIGIR 05: Proceedings of the 28th annual international ACM SIGIR conference on Research and development in information retrieval, pages 408-415, New York, NY, USA, 2005. ACM Press. [17] I. Soboroff, C. Nicholas, and P. Cahan. Ranking retrieval systems without relevance judgments. In SIGIR 01: Proceedings of the 24th annual international ACM SIGIR conference on Research and development in information retrieval, pages 66-73, New York, NY, USA, 2001. ACM Press. [18] V. Vinay, I. J. Cox, N. Milic-Frayling, and K. Wood. On ranking the effectiveness of searches. In SIGIR 06: Proceedings of the 29th annual international ACM SIGIR conference on Research and development in information retrieval, pages 398-404, New York, NY, USA, 2006. ACM Press. [19] Y. Zhou and W. B. Croft. Ranking robustness: a novel framework to predict query performance. In CIKM 06: Proceedings of the 15th ACM international conference on Information and knowledge management, pages 567-574, New York, NY, USA, 2006. ACM Press.",
    "original_translation": "Predicción del rendimiento utilizando autocorrelación espacial. Fernando Díaz. Centro de Recuperación de Información Inteligente. Departamento de Ciencias de la Computación. Universidad de Massachusetts Amherst, MA 01003. fdiaz@cs.umass.edu. RESUMEN La evaluación de sistemas de recuperación de información es una de las tareas fundamentales en la recuperación de información. Los problemas incluyen la incapacidad de etiquetar exhaustivamente todos los documentos sobre un tema, la falta de generalización a partir de un pequeño número de temas e incorporar la variabilidad de los sistemas de recuperación. Trabajos anteriores abordan la evaluación de sistemas, la clasificación de consultas por dificultad y la clasificación de recuperaciones individuales por rendimiento. Existen enfoques para el caso de pocos e incluso ningún juicio de relevancia. Nuestro enfoque está en la predicción del rendimiento sin juicios de las recuperaciones individuales. Una deficiencia común de las técnicas anteriores es la suposición de que las puntuaciones de los documentos y los juicios no están correlacionados. Si los documentos están incrustados en un espacio de alta dimensión (como a menudo lo están), podemos aplicar técnicas de análisis de datos espaciales para detectar correlaciones entre las puntuaciones de los documentos. Observamos que la baja correlación entre las puntuaciones de documentos temáticamente cercanos a menudo implica un bajo rendimiento en la recuperación. Cuando se compara con una línea base de última generación, demostramos que el análisis espacial de las puntuaciones de recuperación ofrece un rendimiento predictivo significativamente mejor. Estos nuevos predictores también pueden ser incorporados con predictores clásicos para mejorar aún más el rendimiento. También describimos el primer experimento a gran escala para evaluar la predicción de rendimiento sin juicio para un gran número de sistemas de recuperación en una variedad de colecciones en varios idiomas. Categorías y Descriptores de Asignaturas H.3.3 [Búsqueda y Recuperación de Información]: Modelos de recuperación; H.3.4 [Sistemas y Software]: Evaluación del rendimiento (eficiencia y efectividad) Términos Generales Rendimiento, Diseño, Confiabilidad, Experimentación 1. En la recuperación de información, un usuario plantea una consulta a un sistema. El sistema recupera n documentos, cada uno recibiendo una puntuación de valor real que indica el grado de relevancia predicho. Si seleccionamos aleatoriamente pares de documentos de este conjunto, esperamos que algunos pares compartan el mismo tema y otros pares no compartan el mismo tema. Toma dos documentos relacionados entre sí del conjunto y llámalos a y b. Si las puntuaciones de a y b son muy diferentes, podríamos estar preocupados por el rendimiento de nuestro sistema. Es decir, si tanto a como b están relacionados con el tema de la consulta, nos gustaría que ambos reciban una puntuación alta; si a y b no están relacionados con el tema de la consulta, nos gustaría que ambos reciban una puntuación baja. Podríamos preocuparnos más a medida que encontramos más diferencias entre las puntuaciones de documentos relacionados. Estaríamos más cómodos con una recuperación en la que las puntuaciones sean consistentes entre documentos relacionados. Nuestro artículo estudia la cuantificación de esta inconsistencia en una recuperación desde una perspectiva espacial. El análisis espacial es apropiado ya que muchos modelos de recuperación incrustan documentos en algún espacio vectorial. Si los documentos están incrustados en un espacio, la proximidad se correlaciona con las relaciones temáticas. La consistencia de la puntuación puede medirse mediante la versión espacial de la autocorrelación conocida como el coeficiente de Moran o IM [5, 10]. En este artículo, demostramos una fuerte correlación entre IM y el rendimiento de recuperación. La discusión hasta este punto recuerda a la hipótesis del cúmulo. La hipótesis del clúster establece que los documentos estrechamente relacionados tienden a ser relevantes para la misma solicitud [12]. Como veremos, una función de recuperación de medidas de autocorrelación espacial mide el grado en que los documentos relacionados reciben puntuaciones similares. Debido a esto, interpretamos la autocorrelación como la medida del grado en que una función de recuperación satisface la hipótesis de agrupamiento. Si esta conexión es razonable, en la Sección 6 presentamos evidencia de que la falta de cumplimiento de la hipótesis de agrupamiento se correlaciona fuertemente con un bajo rendimiento. En este trabajo, proporcionamos las siguientes contribuciones: 1. Un método general y robusto para predecir el rendimiento de recuperaciones sin juicios de relevancia (Sección 3). 2. Un tratamiento teórico de las similitudes y motivaciones detrás de varias técnicas de predicción de rendimiento de vanguardia (Sección 4). 3. Las primeras experimentaciones a gran escala de predicción de rendimiento de una sola ejecución sin juicio (Secciones 5 y 6). 2. Dada una consulta, un sistema de recuperación de información produce una clasificación de documentos en la colección codificada como un conjunto de puntuaciones asociadas con los documentos. Nos referimos al conjunto de puntuaciones para una combinación particular de consulta-sistema como una recuperación. Nos gustaría predecir el rendimiento de esta recuperación con respecto a alguna medida de evaluación (por ejemplo, precisión promedio). En este artículo, presentamos resultados para clasificar recuperaciones de sistemas arbitrarios. Nos gustaría que este ranking se aproximara al ranking de recuperaciones según la medida de evaluación. Esto es diferente de clasificar las consultas por el rendimiento promedio en cada consulta. También es diferente de los sistemas de clasificación por el rendimiento promedio en un conjunto de consultas. Las puntuaciones a menudo solo se calculan para los primeros n documentos de la colección. Colocamos estos puntajes en el vector de longitud n, y, donde yi se refiere al puntaje del documento clasificado en la posición i. Ajustamos las puntuaciones para que tengan una media de cero y una varianza unitaria. Utilizamos este método debido a su simplicidad y su éxito en trabajos anteriores [15]. CORRELACIÓN ESPACIAL En la recuperación de información, a menudo asumimos que las representaciones de los documentos existen en algún espacio vectorial de alta dimensión. Por ejemplo, dado un vocabulario, V, este espacio vectorial puede ser un espacio arbitrario de dimensión |V| con producto interno de coseno o un simplejo multinomial con una medida de distancia basada en distribución. Un espacio de incrustación suele ser seleccionado para respetar la proximidad temática; si dos documentos están cerca, es más probable que compartan un tema. Debido a la prevalencia y éxito de los modelos espaciales de recuperación de información, creemos que la aplicación de técnicas de análisis de datos espaciales es apropiada. Mientras que en la recuperación de información nos preocupa la puntuación en un punto en el espacio, en el análisis de datos espaciales nos preocupa el valor de una función en un punto o ubicación en el espacio. Utilizamos el término función aquí para referirnos a una asignación de una ubicación a un valor real. Por ejemplo, podríamos estar interesados en la prevalencia de una enfermedad en el vecindario de alguna ciudad. La función asignaría la ubicación de un vecindario a una tasa de infección. Si queremos cuantificar las dependencias espaciales de una función, emplearíamos una medida conocida como la autocorrelación espacial [5, 10]. Una alta autocorrelación espacial sugiere que conocer el valor de una función en la ubicación a nos dirá mucho sobre el valor en una ubicación vecina b. Existe una alta autocorrelación espacial para una función que representa la temperatura de una ubicación, ya que saber la temperatura en una ubicación a nos dirá mucho sobre la temperatura en una ubicación vecina b. La baja autocorrelación espacial sugiere que conocer el valor de una función en la ubicación a nos dice poco sobre el valor en una ubicación vecina b. Hay una baja autocorrelación espacial en una función que mide el resultado de lanzar una moneda en a y b. En esta sección, comenzaremos describiendo lo que entendemos por proximidad espacial para documentos y luego definiremos una medida de autocorrelación espacial. Concluimos extendiendo este modelo para incluir información de múltiples recuperaciones de múltiples sistemas para una sola consulta. 3.1 Representación Espacial de Documentos Nuestro trabajo no se centra en mejorar una medida de similitud específica o definir un espacio vectorial novedoso. En cambio, elegimos un producto interno conocido por ser efectivo en la detección de relaciones temáticas entre documentos. Específicamente, adoptamos vectores de documentos tf.idf, ˜di = di log „ (n + 0.5) − ci 0.5 + ci « (1) donde d es un vector de frecuencias de términos, c es el vector de frecuencia de documentos de longitud |V|. Utilizamos este esquema de ponderación debido a su éxito en la detección de enlaces temáticos en el contexto de las evaluaciones de Detección y Seguimiento de Temas (TDT) [6]. Suponiendo que los vectores están escalados por su norma L2, usamos el producto interno, ˜di, ˜dj, para definir la similitud. Dado un conjunto de documentos y alguna medida de similitud, podemos construir una matriz que codifica la similitud entre pares de documentos. Recuerde que se nos dan los primeros n documentos recuperados en y. Podemos calcular una matriz de similitud n × n, W. Un elemento de esta matriz, Wij, representa la similitud entre los documentos clasificados i y j. En la práctica, solo incluimos las afinidades para los k vecinos más cercanos de un documento. En todos nuestros experimentos, hemos fijado k en 5. Dejamos la exploración de la sensibilidad de los parámetros para trabajos futuros. También normalizamos por filas la matriz para que Pn j=1 Wij = 1 para todos los i. 3.2 Autocorrelación Espacial de una Recuperación Recuerde que estamos interesados en medir la similitud entre las puntuaciones de documentos cercanos espacialmente. Una medida adecuada es el coeficiente de Moran de autocorrelación espacial. Suponiendo la función y sobre n ubicaciones, esto se define como ˜IM = n eTWe P i,j Wijyiyj P i y2 i = n eTWe yT Wy yTy (2) donde eT We = P ij Wij. Nos gustaría comparar los valores de autocorrelación para diferentes recuperaciones. Desafortunadamente, el límite para la Ecuación 2 no es consistente para diferentes valores de W y y. Por lo tanto, utilizamos la desigualdad de Cauchy-Schwartz para establecer un límite, ˜IM ≤ n eTWe s yTWTWy yTy Y definimos la autocorrelación espacial normalizada como IM = yT Wy p yTy × yTWTWy. Nótese que si dejamos ˜y = Wy, entonces podemos escribir esta fórmula como, IM = yT ˜y y 2 ˜y 2 (3) lo cual puede interpretarse como la correlación entre las puntuaciones originales de recuperación y un conjunto de puntuaciones de recuperación difundidas en el espacio. Presentamos algunos ejemplos de autocorrelaciones de funciones en una cuadrícula en la Figura 1. 3.3 Correlación con Otros Recuperos A veces estamos interesados en el rendimiento de un solo recuperación pero tenemos acceso a puntajes de múltiples sistemas para (a) IM = 0.006 (b) IM = 0.241 (c) IM = 0.487 Figura 1: El coeficiente de Moran, IM para varias funciones binarias en una cuadrícula. El coeficiente de Moran es una medida local de consistencia de la función. Desde la perspectiva de la recuperación de información, cada uno de estos espacios de la cuadrícula representaría un documento y los documentos estarían organizados de manera que se encuentren junto a documentos relacionados temáticamente. Las puntuaciones de recuperación binaria definirían un patrón en esta cuadrícula. Ten en cuenta que, a medida que el coeficiente de Moran aumenta, las celdas vecinas tienden a tener valores similares. En esta situación, podemos utilizar la información combinada de estas puntuaciones para construir un sustituto de una clasificación de alta calidad [17]. Podemos tratar la correlación entre la recuperación que nos interesa y las puntuaciones combinadas como un predictor del rendimiento. Supongamos que se nos dan m funciones de puntuación, yi, para los mismos n documentos. Representaremos la media de estos vectores como yµ = Σm i=1 yi. Utilizamos el vector medio como una aproximación a la relevancia. Dado que utilizamos normalización de media cero y varianza unitaria, el trabajo en metabusqueda sugiere que esta suposición está justificada [15]. Dado que yµ representa una recuperación muy buena, hipotetizamos que una similitud fuerte entre yµ e y correlacionará positivamente con el rendimiento del sistema. Utilizamos la correlación de Pearson para medir la similitud entre estos vectores, ρ(y, yµ) = yT yµ y 2 yµ 2 (4). Comentaremos sobre la similitud entre la Ecuación 3 y 4 en la Sección 7. Por supuesto, podemos combinar ρ(y, ˜y) y ρ(y, yµ) si asumimos que capturan diferentes factores en la predicción. Una forma de lograr esto es combinar estos predictores como variables independientes en una regresión lineal. Se sugiere un medio alternativo de combinación basado en la forma matemática de nuestros predictores. Dado que ˜y codifica las dependencias espaciales en y y yµ codifica las propiedades espaciales de las múltiples ejecuciones, podemos calcular una tercera correlación entre estos dos vectores, ρ(˜y, yµ) = ˜yT yµ ˜y 2 yµ 2 (5). Podemos interpretar la Ecuación 5 como la medición de la correlación entre un ranking de alta calidad (yµ) y una versión suavizada espacialmente de la recuperación (˜y). 4. RELACIÓN CON OTROS PREDICTORES Una forma de predecir la efectividad de una recuperación es observar el vocabulario compartido de los n documentos principales recuperados. Si calculáramos las palabras de contenido más frecuentes en este conjunto, esperaríamos que fueran coherentes con nuestro tema. De hecho, podríamos creer que una mala recuperación incluiría documentos sobre muchos temas dispares, lo que resultaría en una superposición de ruido terminológico. La claridad de una consulta intenta cuantificar exactamente esto [7]. Específicamente, la Claridad mide la similitud de las palabras más frecuentemente utilizadas en los documentos recuperados con aquellas más frecuentemente utilizadas en todo el corpus. La conjetura es que una buena recuperación utilizará un lenguaje distinto al del texto general; el lenguaje superpuesto en una mala recuperación tenderá a ser más similar al texto general. Matemáticamente, podemos calcular una representación del lenguaje utilizado en la recuperación inicial como una combinación ponderada de modelos de lenguaje de documentos, P(w|θQ) = Σ i=1 P(w|θi) P(Q|θi) Z (6) donde θi es el modelo de lenguaje del documento clasificado en la posición i, P(Q|θi) es la puntuación de probabilidad de la consulta del documento clasificado en la posición i y Z = Σ i=1 P(Q|θi) es una constante de normalización. La similitud entre el multinomial P(w|θQ) y un modelo de texto general se puede calcular utilizando la divergencia de Kullback-Leibler, DV KL(θQ θC). Aquí, la distribución P(w|θC) es nuestro modelo de texto general que puede ser calculado utilizando las frecuencias de términos en el corpus. En la Figura 2a, presentamos la Claridad como la medida de la distancia entre el centro de masa ponderado de la recuperación (etiquetado como y) y el centro de masa no ponderado de la colección (etiquetado como O). La claridad alcanza un mínimo cuando una recuperación asigna a cada documento la misma puntuación. Volvamos a asumir que tenemos un conjunto de n documentos recuperados para nuestra consulta. Otra forma de cuantificar la dispersión de un conjunto de documentos es observar qué tan agrupados están. Podemos hipotetizar que una buena recuperación devolverá un único y compacto grupo. Una recuperación de bajo rendimiento devolverá un conjunto de documentos poco relacionados que abarcan muchos temas. Un método propuesto para cuantificar esta dispersión es medir la distancia desde un documento aleatorio a su vecino más cercano, b. Una recuperación que esté estrechamente agrupada, en promedio, tendrá una distancia baja entre a y b; una recuperación que esté menos cerrada tendrá, en promedio, distancias altas entre a y b. Este promedio corresponde al uso de la estadística de Cox-Lewis para medir la aleatoriedad de los primeros n documentos recuperados de un sistema [18]. En la Figura 2a, esto es aproximadamente equivalente a medir el área del conjunto n. Observa que estamos descartando información sobre la función de recuperación y. Por lo tanto, la estadística de Cox-Lewis depende en gran medida de la selección de los primeros n documentos. Recuerda que tenemos n documentos y un conjunto de puntuaciones. Supongamos que tenemos acceso al sistema que proporcionó las puntuaciones originales y que también podemos solicitar puntuaciones para nuevos documentos. Esto sugiere un tercer método para predecir el rendimiento. Toma algún documento, a, del conjunto recuperado y agrega o elimina palabras al azar de forma arbitraria para crear un nuevo documento ˜a. Ahora, podemos pedirle a nuestro sistema que puntúe ˜a con respecto a nuestra consulta. Si, en promedio, a lo largo de los n documentos, las puntuaciones de a y ˜a tienden a ser muy diferentes, podríamos sospechar que el sistema está fallando en esta consulta. Los autores han sugerido acoplar la consulta con la medida de distancia [18]. La información introducida por la consulta, sin embargo, es independiente de la recuperación, de modo que, si dos recuperaciones devuelven el mismo conjunto de documentos, la estadística aproximada de Cox-Lewis será la misma independientemente de las puntuaciones de recuperación. yOy (a) Divergencia Global µ(y)˜y y (b) Perturbación de Puntuación µ(y) y (c) Promedio de Múltiples Ejecuciones Figura 2: Representación de varios predictores de rendimiento en una cuadrícula. En la Figura 2a, representamos los predictores que miden la divergencia entre el centro de masa de una recuperación y el centro del espacio de incrustación. En la Figura 2b, representamos los predictores que comparan la recuperación original, y, con una versión perturbada de la recuperación, ˜y. Nuestro enfoque utiliza un tipo particular de perturbación basado en la difusión de puntajes. Finalmente, en la Figura 2c, representamos la predicción cuando se proporcionan recuperaciones de varios otros sistemas en la misma consulta. Aquí, podemos considerar la fusión de estas recuperaciones como un sustituto de la relevancia. Esto se puede lograr ya sea perturbando los documentos o las consultas. La similitud entre los dos recuperos se puede medir utilizando alguna medida de correlación. Esto se muestra en la Figura 2b. La cuadrícula superior representa la recuperación original, y, mientras que la cuadrícula inferior representa la función después de haber sido perturbada, ˜y. La naturaleza del proceso de perturbación requiere puntuaciones o recuperaciones adicionales. Nuestro predictor no requiere acceso a la función de puntuación original ni a recuperaciones adicionales. Por lo tanto, aunque nuestro método es similar a otros métodos de perturbación en espíritu, se puede aplicar en situaciones en las que el sistema de recuperación es inaccesible o costoso de acceder. Finalmente, supongamos que tenemos, además de la recuperación que queremos evaluar, m recuperaciones de una variedad de sistemas diferentes. En este caso, podríamos tomar un documento a, comparar su rango en la recuperación con su rango promedio en los m recuperos. Si creemos que las m recuperaciones proporcionan una aproximación satisfactoria a la relevancia, entonces una diferencia muy grande en el rango sugeriría que nuestra recuperación está clasificando incorrectamente a. Si esta diferencia es grande en promedio en todos los n documentos, entonces podríamos predecir que la recuperación es mala. Si, por otro lado, la recuperación es muy consistente con las m recuperaciones, entonces podríamos predecir que la recuperación es buena. La similitud entre la recuperación y la recuperación combinada puede calcularse utilizando alguna medida de correlación. Esto se muestra en la Figura 2c. En trabajos anteriores, la divergencia de Kullback-Leibler entre las puntuaciones normalizadas de la recuperación y las puntuaciones normalizadas de la recuperación combinada proporciona la similitud [1]. 5. Nuestros experimentos se centran en probar el poder predictivo de cada uno de nuestros predictores: ρ(y, ˜y), ρ(y, yµ) y ρ(˜y, yµ). Como se indica en la Sección 2, estamos interesados en predecir el rendimiento de la recuperación generada por un sistema arbitrario. Nuestra metodología es consistente con investigaciones previas en el sentido de que predecimos el rendimiento relativo de una recuperación al comparar una clasificación basada en nuestro predictor con una clasificación basada en la precisión promedio. Presentamos los resultados de dos conjuntos de experimentos. El primer conjunto de experimentos presenta comparaciones detalladas de nuestros predictores con predictores previamente propuestos utilizando conjuntos de datos idénticos. Nuestro segundo conjunto de experimentos demuestra la generalizabilidad de nuestro enfoque a métodos de recuperación arbitrarios, tipos de corpus y lenguajes de corpus. 5.1 Experimentos Detallados En estos experimentos, predeciremos el rendimiento de los puntajes de modelado de lenguaje utilizando nuestro predictor de autocorrelación, ρ(y, ˜y); no consideramos ρ(y, yµ) o ρ(˜y, yµ) porque, en estos experimentos detallados, nos enfocamos en clasificar las recuperaciones de un solo sistema. Utilizamos recuperaciones, valores de predictores de referencia y medidas de evaluación reportadas en trabajos anteriores [19]. 5.1.1 Temas y Colecciones Estos experimentos de predicción de rendimiento utilizan recuperaciones de modelos de lenguaje realizadas para consultas asociadas con colecciones en las corpora de TREC. El uso de las colecciones TREC nos permite asociar con confianza una precisión promedio con una recuperación. En estos experimentos, utilizamos las siguientes colecciones de temas: TREC 4 ad-hoc, TREC 5 ad-hoc, Robust 2004, Terabyte 2004 y Terabyte 2005. 5.1.2 Baselines Proporcionamos dos líneas base. Nuestro primer punto de referencia es el predictor clásico de Claridad presentado en la Ecuación 6. La claridad está diseñada para ser utilizada con sistemas de modelado de lenguaje. Nuestro segundo punto de referencia es el predictor de robustez de clasificación de Zhou y Crofts. Este predictor corrompe los k documentos principales de la recuperación y vuelve a calcular las puntuaciones del modelo de lenguaje para estos documentos corruptos. El valor del predictor es la correlación de rangos de Spearman entre la clasificación original y la clasificación corrupta. En nuestras tablas, etiquetaremos los resultados para Claridad utilizando DV KL y el predictor de robustez de clasificación utilizando P. 5.2 Experimentos de Generalizabilidad Nuestros predictores no requieren un sistema de recuperación base particular; los predictores pueden calcularse para una recuperación arbitraria, independientemente de cómo se generaron los puntajes. Creemos que ese es uno de los aspectos más atractivos de nuestro algoritmo. Por lo tanto, en un segundo conjunto de experimentos, demostramos la capacidad de nuestras técnicas para generalizar a una variedad de colecciones, temas y sistemas de recuperación. 5.2.1 Temas y Colecciones Recopilamos un conjunto diverso de colecciones de todos los corpus posibles de TREC. Lanzamos una red amplia para localizar colecciones donde nuestros predictores podrían fallar. Nuestra hipótesis es que los documentos con alta similitud temática deberían tener puntuaciones correlacionadas. Por lo tanto, evitamos las colecciones donde las puntuaciones eran poco probables de estar correlacionadas (por ejemplo, preguntas y respuestas) o donde probablemente estuvieran negativamente correlacionadas (por ejemplo, novedad). Sin embargo, nuestras colecciones incluyen corpus donde las correlaciones están débilmente justificadas (por ejemplo, corpus no en inglés) o no justificadas en absoluto (por ejemplo, búsqueda de expertos). Utilizamos las pistas ad-hoc de TREC3-8, TREC Robust 2003-2005, TREC Terabyte 2004-2005, TREC4-5 en español, TREC5-6 en chino y TREC Enterprise Expert Search 2005. En todos los casos, solo utilizamos las ejecuciones automáticas para las pistas ad-hoc enviadas a NIST. Para todos los corpus en inglés y español, construimos la matriz W de acuerdo con el proceso descrito en la Sección 3.1. Para los corpus chinos, utilizamos vectores tf.idf basados en caracteres ingenuos. Para las entidades, las entradas en W son proporcionales al número de documentos en los que dos entidades coocurren. 5.2.2 Baselines En nuestros experimentos detallados, utilizamos la medida de Claridad como referencia. Dado que estamos prediciendo el rendimiento de recuperaciones que no se basan en modelado de lenguaje, utilizamos una versión de Claridad conocida como Claridad de lista clasificada [7]. La claridad de la lista clasificada convierte las clasificaciones de documentos en valores P(Q|θi). Esta conversión comienza reemplazando todas las puntuaciones en y con los rangos respectivos. Nuestra estimación de P(Q|θi) a partir de los rangos, entonces es, P(Q|θi) = ( 2(c+1−yi) c(c+1) si yi ≤ c 0 en otro caso donde c es un parámetro de corte. Como sugieren los autores, fijamos los parámetros del algoritmo c y λ2 de manera que c = 60 y λ2 = 0.10. Utilizamos la Ecuación 6 para estimar P(w|θQ) y DV KL(θQ θC) para calcular el valor del predictor. Nos referiremos a este predictor como DV KL, con superíndice V para indicar que la divergencia de Kullback-Leibler es con respecto al espacio de incrustación de términos. Cuando la información de múltiples ejecuciones de la misma consulta está disponible, utilizamos la divergencia multinomial en el espacio de documentos de Aslam y Pavlus como referencia [1]. Este método basado en rangos primero normaliza las puntuaciones en una recuperación como un multinomial n-dimensional. Al igual que con la Claridad de la lista clasificada, comenzamos reemplazando todas las puntuaciones en y con sus respectivas posiciones. Luego, ajustamos los elementos de y de la siguiente manera, ˆyi = 1 2n 0 @1 + nX k=yi 1 k 1 A (8) En nuestros experimentos de múltiples ejecuciones, solo utilizamos los 75 documentos principales de cada recuperación (n = 75); esto está dentro del rango de valores de parámetros sugeridos por los autores. Sin embargo, admitimos no haber ajustado este parámetro ni para nuestro sistema ni para la línea base. El predictor es la divergencia entre la distribución candidata, y, y la distribución media, yµ. Con la combinación lineal uniforme de estos m recuperaciones representadas como yµ, podemos calcular la divergencia como Dn KL(ˆy ˆyµ) donde usamos el superíndice n para indicar que la suma es sobre el conjunto de n documentos. Este punto de referencia fue desarrollado en el contexto de predecir la dificultad de la consulta, pero lo adoptamos como un punto de referencia razonable para predecir el rendimiento de la recuperación. 5.2.3 Configuración de parámetros Cuando se proporcionan múltiples recuperaciones, utilizamos documentos en la unión de los mejores k = 75 documentos de cada una de las m recuperaciones para esa consulta. Si el tamaño de esta unión es ˜n, entonces yµ y cada yi tiene una longitud de ˜n. En algunos casos, un sistema no puntuó un documento en la unión. Dado que estamos haciendo una suposición gaussiana sobre nuestras puntuaciones, podemos muestrear puntuaciones para estos documentos no vistos de la cola negativa de la distribución. Específicamente, muestreamos de la parte de la distribución inferior al valor mínimo en la recuperación normalizada. Esto introduce aleatoriedad en nuestro algoritmo, pero creemos que es más apropiado que asignar un valor fijo arbitrario. Optimizamos la regresión lineal utilizando la raíz cuadrada de cada predictor. Encontramos que esto mejoró sustancialmente los ajustes para todos los predictores, incluidos los basales. Consideramos combinaciones lineales de pares de predictores (etiquetados por los componentes) y todos los predictores (etiquetados como β). 5.3 Evaluación Dado un conjunto de recuperaciones, potencialmente de una combinación de consultas y sistemas, medimos la correlación del ordenamiento de rango de este conjunto por el predictor y por la métrica de rendimiento. Para garantizar la comparabilidad con los resultados anteriores, presentamos la correlación de Kendalls τ entre la clasificación de los predictores y la clasificación basada en la precisión promedio de la recuperación. A menos que se indique explícitamente, todas las correlaciones son significativas con p < 0.05. Los predictores a veces pueden tener un mejor rendimiento cuando se combinan linealmente [9, 11]. Aunque trabajos anteriores han presentado el coeficiente de determinación (R2) para medir la calidad de la regresión, esta medida no puede ser utilizada de manera confiable al comparar pequeñas mejoras al combinar predictores. Por lo tanto, adoptamos el coeficiente de determinación ajustado que penaliza los modelos con más variables. El R2 ajustado nos permite evaluar la mejora en la predicción lograda al agregar un parámetro pero pierde la interpretación estadística del R2. Utilizaremos τ de Kendall para evaluar la magnitud de la correlación y R2 ajustado para evaluar la combinación de variables. RESULTADOS Presentamos los resultados de nuestros experimentos detallados comparando la predicción de puntuaciones de modelos de lenguaje en la Tabla 1. Aunque la medida de Claridad está teóricamente diseñada para puntuaciones de modelos de lenguaje, consistentemente tiene un rendimiento inferior a nuestro predictor independiente del sistema. La robustez del ranking se presentó como una mejora a la Claridad para colecciones web (representadas en nuestros experimentos por las colecciones terabyte04 y terabyte05), desplazando la correlación τ de 0.139 a 0.150 para terabyte04 y de 0.171 a 0.208 para terabyte05. Sin embargo, estas mejoras son leves en comparación con el rendimiento de la autocorrelación en estas colecciones. Nuestro predictor logra una correlación τ de 0.454 para terabyte04 y 0.383 para terabyte05. Aunque no siempre es la más fuerte, la autocorrelación logra correlaciones competitivas con los predictores de referencia. Al examinar el rendimiento de las combinaciones lineales de predictores, observamos que en cada caso, los factores de autocorrelación son un componente necesario de un predictor sólido. También observamos que el R2 ajustado para las líneas de base individuales siempre mejora significativamente al incorporar la autocorrelación. Presentamos nuestros resultados de generalizabilidad en la Tabla 2. Comenzamos examinando la situación en la columna (a) donde se nos presenta una sola recuperación y ninguna información de recuperaciones adicionales. Para cada colección excepto una, logramos correlaciones significativamente mejores que la claridad de la lista clasificada. Sorprendentemente, logramos correlaciones relativamente fuertes para las colecciones en español y chino a pesar de nuestro procesamiento ingenuo. No tenemos una correlación de claridad de lista clasificada para ent05 porque la modelización de entidades es en sí misma una pregunta de investigación abierta. Sin embargo, nuestra medida de autocorrelación no logra altas correlaciones, quizás porque la relevancia para la recuperación de entidades no se propaga de acuerdo con los enlaces de coocurrencia que utilizamos. Como se señaló anteriormente, el bajo rendimiento de Claridad en datos web es consistente con nuestros hallazgos en los experimentos detallados. La claridad también tiene un rendimiento notablemente inferior en varios corpus de noticias (trec5, trec7 y robust04). Por otro lado, la autocorrelación parece ser robusta a los cambios entre diferentes corpora. A continuación, pasamos a la introducción de información de múltiples recuperaciones. Comparamos las correlaciones entre aquellos predictores que no utilizan esta información en la columna (a) y aquellos que sí lo hacen en la columna (b). Para cada colección, los predictores en la columna (b) superan a los predictores en la columna (a), lo que indica que la información de ejecuciones adicionales puede ser crítica para hacer buenas predicciones. Inspeccionando los predictores en la columna (b), solo podemos sacar conclusiones débiles. Nuestros nuevos predictores tienden a tener un mejor rendimiento en corpora de noticias. Y entre nuestros nuevos predictores, el predictor híbrido ρ(˜y, yµ) tiende a tener un mejor rendimiento. Recuerde que nuestra medida ρ(˜y, yµ) incorpora tanto información espacial como de múltiples recuperaciones. Por lo tanto, creemos que la mejora en la correlación es el resultado de incorporar información del comportamiento espacial. En la columna (c), podemos investigar la utilidad de incorporar información espacial con información de múltiples recuperaciones. Observa que en los casos donde la autocorrelación, ρ(y, ˜y), por sí sola funciona bien (trec3, trec5-spanish y trec6-chinese), se mejora sustancialmente al incorporar información de múltiples recuperaciones de ρ(y, yµ) en la regresión lineal, β. En los casos en los que ρ(y, yµ) funciona bien, la incorporación de la autocorrelación rara vez resulta en una mejora significativa en el rendimiento. De hecho, en cada caso en el que nuestro predictor supera al valor de referencia, incluye información de múltiples ejecuciones. 7. DISCUSIÓN El resultado más importante de nuestros experimentos implica la predicción cuando no hay información disponible de múltiples ejecuciones (Tablas 1 y 2a). Esta situación surge a menudo en el diseño de sistemas. Por ejemplo, un sistema puede necesitar, en el momento de la recuperación, evaluar su rendimiento antes de decidir llevar a cabo un procesamiento más intensivo como la retroalimentación de pseudo relevancia o la interacción. Suponiendo que la presencia de múltiples recuperaciones es irrealista en este caso. Creemos que la autocorrelación, al igual que los algoritmos de recuperación múltiple, aproxima un buen ranking; en este caso mediante la difusión de puntajes. ¿Por qué es ˜y un sustituto razonable? Sabemos que la difusión de puntuaciones en el grafo web y en los grafos de modelos de lenguaje mejora el rendimiento [14, 16]. Por lo tanto, si la difusión de puntuaciones tiende, en general, a mejorar el rendimiento, entonces las puntuaciones difusas proporcionarán, en general, un buen sustituto de la relevancia. Nuestros resultados demuestran que esta aproximación no es tan potente como la información de múltiples recuperaciones. Sin embargo, en situaciones donde esta información falta, la autocorrelación proporciona información sustancial. El éxito de la autocorrelación como predictor también puede tener sus raíces en la hipótesis de agrupamiento. Recuerde que consideramos la autocorrelación como el grado en que una recuperación satisface la hipótesis de agrupamiento. Nuestros experimentos, entonces, demuestran que una falta de respeto a la hipótesis de agrupamiento se correlaciona con un bajo rendimiento. ¿Por qué los sistemas podrían no cumplir con la hipótesis del clúster? Los sistemas de recuperación de información basados en consultas a menudo puntúan los documentos de forma independiente. El puntaje del documento a puede ser calculado examinando las coincidencias de términos o frases de la consulta, la longitud del documento y quizás las estadísticas globales de la colección. Una vez calculado, un sistema rara vez compara la puntuación de un documento a con la puntuación de un documento relacionado temáticamente b. Con algunas excepciones, la correlación de las puntuaciones de los documentos ha sido ampliamente ignorada. Debemos dejar claro que hemos seleccionado tareas donde la autocorrelación temática es apropiada. Ciertamente hay casos en los que no hay motivo para creer que las puntuaciones de recuperación tendrán autocorrelación temática. Por ejemplo, las listas clasificadas que incorporan novedad de documentos no deben mostrar autocorrelación espacial; si acaso, la autocorrelación debería ser negativa para esta tarea. Del mismo modo, los candidatos de respuestas en una tarea de pregunta-respuesta pueden o no mostrar autocorrelación; en este caso, la semántica de los enlaces también es cuestionable. Es importante antes de aplicar esta medida confirmar que, dada la semántica para algún enlace entre dos elementos recuperados, deberíamos esperar una correlación entre las puntuaciones. 8. TRABAJO RELACIONADO En esta sección realizamos comparaciones más generales con otros trabajos en predicción de rendimiento y análisis de datos espaciales. Existe un creciente cuerpo de trabajo que intenta predecir el rendimiento de recuperaciones individuales [7, 3, 11, 9, 19]. Hemos intentado situar nuestro trabajo en el contexto de gran parte de este trabajo en la Sección 4. Sin embargo, una comparación completa está fuera del alcance de este documento. Sin embargo, cabe destacar que nuestros experimentos abarcan un conjunto más amplio y diverso de recuperaciones, colecciones y temas que los examinados previamente. Gran parte del trabajo previo, especialmente en el contexto de TREC, se centra en predecir el rendimiento de los sistemas. Aquí, cada sistema genera k recuperaciones. La tarea consiste en, dadas estas recuperaciones, predecir la clasificación de los sistemas según alguna medida de rendimiento. Varios artículos intentan abordar esta tarea bajo la restricción de pocas evaluaciones [2, 4]. Algunos trabajos incluso intentan utilizar cero juicios aprovechando múltiples recuperaciones para la misma consulta [17]. Nuestra tarea difiere porque nos enfocamos en clasificar recuperaciones independientemente del sistema generador. La tarea aquí no es probar que el sistema A es superior al sistema B, sino probar que la recuperación A es superior a la recuperación B. La autocorrelación se manifiesta en muchas tareas de clasificación. Neville y Jensen definen la autocorrelación relacional para problemas de aprendizaje relacional y demuestran que muchas tareas de clasificación manifiestan autocorrelación [13]. La autocorrelación temporal de las recuperaciones iniciales también se ha utilizado para predecir el rendimiento [9]. Sin embargo, la autocorrelación temporal se realiza proyectando la función de recuperación en el espacio de incrustación temporal. En nuestro trabajo, nos enfocamos en el comportamiento de la función sobre las relaciones entre documentos. τ ajustado R2 DV KL P ρ(y, ˜y) DV KL P ρ(y, ˜y) DV KL, P DV KL, ρ(y, ˜y) Pρ(y, ˜y) β trec4 0.353 0.548 0.513 0.168 0.363 0.422 0.466 0.420 0.557 0.553 trec5 0.311 0.329 0.357 0.116 0.190 0.236 0.238 0.244 0.266 0.269 robust04 0.418 0.398 0.373 0.256 0.304 0.278 0.403 0.373 0.402 0.442 terabyte04 0.139 0.150 0.454 0.059 0.045 0.292 0.076 0.293 0.289 0.284 terabyte05 0.171 0.208 0.383 0.022 0.072 0.193 0.120 0.225 0.218 0.257 Tabla 1: Comparación de medidas de robustez y claridad para puntuaciones de modelos de lenguaje. La evaluación replica experimentos de [19]. Presentamos las correlaciones entre la medida clásica de Claridad (DV KL), la medida de robustez de clasificación (P) y la autocorrelación (ρ(y, ˜y)) cada una con la precisión media promedio en términos de τ de Kendall. El coeficiente de determinación ajustado se presenta para medir la efectividad de combinar predictores. Las medidas en negrita representan la correlación más fuerte para ese par de prueba/colección. múltiples ejecuciones (a) (b) (c) τ τ ajustado R2 DKL ρ(y, ˜y) Dn KL ρ(y, yµ) ρ(˜y, yµ) Dn KL ρ(y, ˜y) ρ(y, yµ) ρ(˜y, yµ) β trec3 0.201 0.461 0.461 0.439 0.456 0.444 0.395 0.394 0.386 0.498 trec4 0.252 0.396 0.455 0.482 0.489 0.379 0.263 0.429 0.482 0.483 trec5 0.016 0.277 0.433 0.459 0.393 0.280 0.157 0.375 0.323 0.386 trec6 0.230 0.227 0.352 0.428 0.418 0.203 0.089 0.323 0.325 0.325 trec7 0.083 0.326 0.341 0.430 0.483 0.264 0.182 0.363 0.442 0.400 trec8 0.235 0.396 0.454 0.508 0.567 0.402 0.272 0.490 0.580 0.523 robust03 0.302 0.354 0.377 0.385 0.447 0.269 0.206 0.274 0.392 0.303 robust04 0.183 0.308 0.301 0.384 0.453 0.200 0.182 0.301 0.393 0.335 robust05 0.224 0.249 0.371 0.377 0.404 0.341 0.108 0.313 0.328 0.336 terabyte04 0.043 0.245 0.544 0.420 0.392 0.516 0.105 0.357 0.343 0.365 terabyte05 0.068 0.306 0.480 0.434 0.390 0.491 0.168 0.384 0.309 0.403 trec4-spanish 0.307 0.388 0.488 0.398 0.395 0.423 0.299 0.282 0.299 0.388 trec5-spanish 0.220 0.458 0.446 0.484 0.475 0.411 0.398 0.428 0.437 0.529 trec5-chinese 0.092 0.199 0.367 0.379 0.384 0.379 0.199 0.273 0.276 0.310 trec6-chinese 0.144 0.276 0.265 0.353 0.376 0.115 0.128 0.188 0.223 0.199 ent05 - 0.181 0.324 0.305 0.282 0.211 0.043 0.158 0.155 0.179 Tabla 2: Experimentos de predicción a gran escala. Predecimos la clasificación de grandes conjuntos de recuperaciones para varias colecciones y sistemas de recuperación. Las correlaciones de τ de Kendall se calculan entre la clasificación predicha y una clasificación basada en la precisión promedio de las recuperaciones. En la columna (a), tenemos predictores que no utilizan información de otras recuperaciones para la misma consulta. En las columnas (b) y (c) presentamos el rendimiento de los predictores que incorporan información de múltiples recuperaciones. El coeficiente de determinación ajustado se calcula para determinar la efectividad de combinar predictores. Las medidas en negrita representan la correlación más fuerte para ese par de prueba/colección. Finalmente, los procesos de reordenamiento basados en regularización también están estrechamente relacionados con nuestro trabajo [8]. Estas técnicas buscan maximizar el acuerdo entre las puntuaciones de documentos relacionados al resolver un problema de optimización restringida. La maximización de la consistencia es equivalente a maximizar la autocorrelación de Moran. Por lo tanto, creemos que nuestro trabajo proporciona una explicación de por qué funciona el reordenamiento basado en regularización. 9. CONCLUSIÓN Hemos presentado un nuevo método para predecir el rendimiento de un ranking de recuperación sin necesidad de juicios de relevancia. Consideramos dos casos. Primero, al hacer predicciones en ausencia de recuperaciones de otros sistemas, nuestros predictores muestran correlaciones sólidas y robustas con la precisión promedio. Esta actuación, combinada con una implementación sencilla, hace que nuestros predictores, en particular, sean muy atractivos. Hemos demostrado esta mejora en muchos entornos diversos. Según nuestro conocimiento, esta es la primera evaluación a gran escala de la predicción del rendimiento de una sola recuperación sin juicio. Segundo, cuando se proporcionan recuperaciones de otros sistemas, nuestros métodos ampliados demuestran un rendimiento competitivo con las líneas de base de vanguardia. Nuestros experimentos también demuestran los límites de la utilidad de nuestros predictores cuando se proporciona información de múltiples ejecuciones. Nuestros resultados sugieren dos conclusiones. Primero, nuestros resultados podrían afectar el diseño de algoritmos de recuperación. Los algoritmos de recuperación diseñados para considerar la autocorrelación espacial se ajustarán a la hipótesis de agrupamiento y mejorarán el rendimiento. Segundo, nuestros resultados podrían afectar el diseño de algoritmos de colección de pruebas mínimas. Gran parte del trabajo reciente en sistemas de clasificación a veces ignora las correlaciones entre las etiquetas de los documentos y las puntuaciones. Creemos que estas dos direcciones podrían ser gratificantes dadas las pruebas teóricas y experimentales en este documento. 10. AGRADECIMIENTOS Este trabajo fue apoyado en parte por el Centro de Recuperación de Información Inteligente y en parte por la Agencia de Proyectos de Investigación Avanzada de Defensa (DARPA) bajo el número de contrato HR0011-06-C-0023. Cualquier opinión, hallazgo y conclusión o recomendación expresada en este material son del autor y no necesariamente reflejan las del patrocinador. Agradecemos a Yun Zhou y Desislava Petkova por proporcionar los datos y a Andre Gauthier por la asistencia técnica. 11. REFERENCIAS [1] J. Aslam y V. Pavlu. Estimación de la dificultad de la consulta utilizando la divergencia de Jensen-Shannon entre múltiples funciones de puntuación. En ECIR 2007: Actas de la 29ª Conferencia Europea sobre Recuperación de Información, 2007. [2] J. A. Aslam, V. Pavlu y E. Yilmaz. Un método estadístico para la evaluación de sistemas utilizando juicios incompletos. En S. Dumais, E. N. Efthimiadis, D. Hawking y K. Jarvelin, editores, Actas de la 29ª Conferencia Internacional Anual de ACM SIGIR sobre Investigación y Desarrollo en Recuperación de Información, páginas 541-548. ACM Press, agosto de 2006. [3] D. Carmel, E. Yom-Tov, A. Darlow y D. Pelleg. ¿Qué hace que una consulta sea difícil? En SIGIR 06: Actas de la 29ª conferencia internacional anual de ACM SIGIR sobre investigación y desarrollo en recuperación de información, páginas 390-397, Nueva York, NY, EE. UU., 2006. ACM Press. [4] B. Carterette, J. Allan y R. Sitaraman. Colecciones de prueba mínimas para evaluación de recuperación. En SIGIR 06: Actas de la 29ª conferencia internacional anual de ACM SIGIR sobre investigación y desarrollo en recuperación de información, páginas 268-275, Nueva York, NY, EE. UU., 2006. ACM Press. [5] A. D. Cliff y J. K. Ord. Autocorrelación espacial. Pion Ltd., 1973. [6] M. Connell, A. Feng, G. Kumaran, H. Raghavan, C. Shah y J. Allan. Umass en tdt 2004. Informe técnico CIIR Informe técnico IR - 357, Departamento de Ciencias de la Computación, Universidad de Massachusetts, 2004. [7] S. Cronen-Townsend, Y. Zhou y W. B. Croft. Predicción de precisión basada en la coherencia de la lista clasificada. I'm sorry, but the sentence \"Inf.\" is not a complete sentence. Could you please provide more context or a full sentence for me to translate to Spanish? Rev., 9(6):723-755, 2006. [8] F. Diaz. Normalizando las puntuaciones de recuperación ad-hoc. En CIKM 05: Actas de la 14ª conferencia internacional de ACM sobre gestión de la información y el conocimiento, páginas 672-679, Nueva York, NY, EE. UU., 2005. ACM Press. [9] F. Diaz y R. Jones. Utilizando perfiles temporales de consultas para predecir la precisión. En SIGIR 04: Actas de la 27ª conferencia internacional anual de ACM SIGIR sobre investigación y desarrollo en recuperación de información, páginas 18-24, Nueva York, NY, EE. UU., 2004. ACM Press. [10] D. A. Griffith. \n\nACM Press. [10] D. A. Griffith. Autocorrelación espacial y filtrado espacial. Springer Verlag, 2003. [11] B. \n\nSpringer Verlag, 2003. [11] B. Él y yo. Ounis. Inferir el rendimiento de la consulta utilizando predictores previos a la recuperación. En el Undécimo Simposio sobre Procesamiento de Cadenas y Recuperación de Información (SPIRE), 2004. [12] N. Jardine y C. J. V. Rijsbergen. El uso de agrupamiento jerárquico en la recuperación de información. Almacenamiento y recuperación de información, 7:217-240, 1971. [13] D. Jensen y J. Neville. El enlace y la autocorrelación causan sesgo en la selección de características en el aprendizaje relacional. En ICML 02: Actas de la Decimonovena Conferencia Internacional sobre Aprendizaje Automático, páginas 259-266, San Francisco, CA, EE. UU., 2002. Morgan Kaufmann Publishers Inc. [14] O. Kurland y L. Lee. Estructura del corpus, modelos de lenguaje y recuperación de información ad-hoc. En SIGIR 04: Actas de la 27ª conferencia internacional anual sobre investigación y desarrollo en recuperación de información, páginas 194-201, Nueva York, NY, EE. UU., 2004. ACM Press. [15] M. Montague y J. A. Aslam. Normalización de la puntuación de relevancia para metabusqueda. En CIKM 01: Actas de la décima conferencia internacional sobre gestión de la información y el conocimiento, páginas 427-433, Nueva York, NY, EE. UU., 2001. ACM Press. [16] T. Qin, T.-Y. Liu, X.-D. Zhang, Z. Chen y W.-Y. I'm sorry, but \"Ma.\" is not a complete sentence. Could you please provide more context or a complete sentence for me to translate into Spanish? Un estudio de propagación de relevancia para la búsqueda en la web. En SIGIR 05: Actas de la 28ª conferencia internacional anual de ACM SIGIR sobre investigación y desarrollo en recuperación de información, páginas 408-415, Nueva York, NY, EE. UU., 2005. ACM Press. [17] I. Soboroff, C. Nicholas y P. Cahan. Sistemas de recuperación de clasificación sin juicios de relevancia. En SIGIR 01: Actas de la 24ª conferencia internacional anual de ACM SIGIR sobre investigación y desarrollo en recuperación de información, páginas 66-73, Nueva York, NY, EE. UU., 2001. ACM Press. [18] V. Vinay, I. J. Cox, N. Milic-Frayling y K. Wood. Sobre la clasificación de la efectividad de las búsquedas. En SIGIR 06: Actas de la 29ª conferencia internacional anual de ACM SIGIR sobre investigación y desarrollo en recuperación de información, páginas 398-404, Nueva York, NY, EE. UU., 2006. ACM Press. [19] Y. Zhou y W. B. Croft. Robustez del ranking: un nuevo marco para predecir el rendimiento de la consulta. En CIKM 06: Actas de la 15ª conferencia internacional de ACM sobre gestión de la información y el conocimiento, páginas 567-574, Nueva York, NY, EE. UU., 2006. ACM Press.",
    "original_sentences": [
        "Performance Prediction Using Spatial Autocorrelation Fernando Diaz Center for Intelligent Information Retrieval Department of Computer Science University of Massachusetts Amherst, MA 01003 fdiaz@cs.umass.edu ABSTRACT Evaluation of information retrieval systems is one of the core tasks in information retrieval.",
        "Problems include the inability to exhaustively label all documents for a topic, nongeneralizability from a small number of topics, and incorporating the variability of retrieval systems.",
        "Previous work addresses the evaluation of systems, the ranking of queries by difficulty, and the ranking of individual retrievals by performance.",
        "Approaches exist for the case of few and even no relevance judgments.",
        "Our focus is on zero-judgment performance prediction of individual retrievals.",
        "One common shortcoming of previous techniques is the assumption of uncorrelated document scores and judgments.",
        "If documents are embedded in a high-dimensional space (as they often are), we can apply techniques from spatial data analysis to detect correlations between document scores.",
        "We find that the low correlation between scores of topically close documents often implies a poor retrieval performance.",
        "When compared to a state of the art baseline, we demonstrate that the spatial analysis of retrieval scores provides significantly better prediction performance.",
        "These new predictors can also be incorporated with classic predictors to improve performance further.",
        "We also describe the first large-scale experiment to evaluate zero-judgment performance prediction for a massive number of retrieval systems over a variety of collections in several languages.",
        "Categories and Subject Descriptors H.3.3 [Information Search and Retrieval]: Retrieval models; H.3.4 [Systems and Software]: Performance evaluation (efficiency and effectiveness) General Terms Performance, Design, Reliability, Experimentation 1.",
        "INTRODUCTION In information retrieval, a user poses a query to a system.",
        "The system retrieves n documents each receiving a realvalued score indicating the predicted degree of relevance.",
        "If we randomly select pairs of documents from this set, we expect some pairs to share the same topic and other pairs to not share the same topic.",
        "Take two topically-related documents from the set and call them a and b.",
        "If the scores of a and b are very different, we may be concerned about the performance of our system.",
        "That is, if a and b are both on the topic of the query, we would like them both to receive a high score; if a and b are not on the topic of the query, we would like them both to receive a low score.",
        "We might become more worried as we find more differences between scores of related documents.",
        "We would be more comfortable with a retrieval where scores are consistent between related documents.",
        "Our paper studies the quantification of this inconsistency in a retrieval from a spatial perspective.",
        "Spatial analysis is appropriate since many retrieval models embed documents in some vector space.",
        "If documents are embedded in a space, proximity correlates with topical relationships.",
        "Score consistency can be measured by the spatial version of autocorrelation known as the Moran coefficient or IM [5, 10].",
        "In this paper, we demonstrate a strong correlation between IM and retrieval performance.",
        "The discussion up to this point is reminiscent of the cluster hypothesis.",
        "The cluster hypothesis states: closely-related documents tend to be relevant to the same request [12].",
        "As we shall see, a retrieval functions spatial autocorrelation measures the degree to which closely-related documents receive similar scores.",
        "Because of this, we interpret autocorrelation as measuring the degree to which a retrieval function satisfies the clustering hypothesis.",
        "If this connection is reasonable, in Section 6, we present evidence that failure to satisfy the cluster hypothesis correlates strongly with poor performance.",
        "In this work, we provide the following contributions, 1.",
        "A general, robust method for predicting the performance of retrievals with zero relevance judgments (Section 3). 2.",
        "A theoretical treatment of the similarities and motivations behind several state-of-the-art performance prediction techniques (Section 4). 3.",
        "The first large-scale experiments of zero-judgment, single run performance prediction (Sections 5 and 6). 2.",
        "PROBLEM DEFINITION Given a query, an information retrieval system produces a ranking of documents in the collection encoded as a set of scores associated with documents.",
        "We refer to the set of scores for a particular query-system combination as a retrieval.",
        "We would like to predict the performance of this retrieval with respect to some evaluation measure (eg, mean average precision).",
        "In this paper, we present results for ranking retrievals from arbitrary systems.",
        "We would like this ranking to approximate the ranking of retrievals by the evaluation measure.",
        "This is different from ranking queries by the average performance on each query.",
        "It is also different from ranking systems by the average performance on a set of queries.",
        "Scores are often only computed for the top n documents from the collection.",
        "We place these scores in the length n vector, y, where yi refers to the score of the ith-ranked document.",
        "We adjust scores to have zero mean and unit variance.",
        "We use this method because of its simplicity and its success in previous work [15]. 3.",
        "SPATIAL CORRELATION In information retrieval, we often assume that the representations of documents exist in some high-dimensional vector space.",
        "For example, given a vocabulary, V, this vector space may be an arbitrary |V|-dimensional space with cosine inner-product or a multinomial simplex with a distributionbased distance measure.",
        "An embedding space is often selected to respect topical proximity; if two documents are near, they are more likely to share a topic.",
        "Because of the prevalence and success of spatial models of information retrieval, we believe that the application of spatial data analysis techniques are appropriate.",
        "Whereas in information retrieval, we are concerned with the score at a point in a space, in spatial data analysis, we are concerned with the value of a function at a point or location in a space.",
        "We use the term function here to mean a mapping from a location to a real value.",
        "For example, we might be interested in the prevalence of a disease in the neighborhood of some city.",
        "The function would map the location of a neighborhood to an infection rate.",
        "If we want to quantify the spatial dependencies of a function, we would employ a measure referred to as the spatial autocorrelation [5, 10].",
        "High spatial autocorrelation suggests that knowing the value of a function at location a will tell us a great deal about the value at a neighboring location b.",
        "There is a high spatial autocorrelation for a function representing the temperature of a location since knowing the temperature at a location a will tell us a lot about the temperature at a neighboring location b.",
        "Low spatial autocorrelation suggests that knowing the value of a function at location a tells us little about the value at a neighboring location b.",
        "There is low spatial autocorrelation in a function measuring the outcome of a coin toss at a and b.",
        "In this section, we will begin by describing what we mean by spatial proximity for documents and then define a measure of spatial autocorrelation.",
        "We conclude by extending this model to include information from multiple retrievals from multiple systems for a single query. 3.1 Spatial Representation of Documents Our work does not focus on improving a specific similarity measure or defining a novel vector space.",
        "Instead, we choose an inner product known to be effective at detecting interdocument topical relationships.",
        "Specifically, we adopt tf.idf document vectors, ˜di = di log „ (n + 0.5) − ci 0.5 + ci « (1) where d is a vector of term frequencies, c is the length-|V| document frequency vector.",
        "We use this weighting scheme due to its success for topical link detection in the context of Topic Detection and Tracking (TDT) evaluations [6].",
        "Assuming vectors are scaled by their L2 norm, we use the inner product, ˜di, ˜dj , to define similarity.",
        "Given documents and some similarity measure, we can construct a matrix which encodes the similarity between pairs of documents.",
        "Recall that we are given the top n documents retrieved in y.",
        "We can compute an n × n similarity matrix, W. An element of this matrix, Wij represents the similarity between documents ranked i and j.",
        "In practice, we only include the affinities for a documents k-nearest neighbors.",
        "In all of our experiments, we have fixed k to 5.",
        "We leave exploration of parameter sensitivity to future work.",
        "We also row normalize the matrix so that Pn j=1 Wij = 1 for all i. 3.2 Spatial Autocorrelation of a Retrieval Recall that we are interested in measuring the similarity between the scores of spatially-close documents.",
        "One such suitable measure is the Moran coefficient of spatial autocorrelation.",
        "Assuming the function y over n locations, this is defined as ˜IM = n eTWe P i,j Wijyiyj P i y2 i = n eTWe yT Wy yTy (2) where eT We = P ij Wij.",
        "We would like to compare autocorrelation values for different retrievals.",
        "Unfortunately, the bound for Equation 2 is not consistent for different W and y.",
        "Therefore, we use the Cauchy-Schwartz inequality to establish a bound, ˜IM ≤ n eTWe s yTWTWy yTy And we define the normalized spatial autocorrelation as IM = yT Wy p yTy × yTWTWy Notice that if we let ˜y = Wy, then we can write this formula as, IM = yT ˜y y 2 ˜y 2 (3) which can be interpreted as the correlation between the original retrieval scores and a set of retrieval scores diffused in the space.",
        "We present some examples of autocorrelations of functions on a grid in Figure 1. 3.3 Correlation with Other Retrievals Sometimes we are interested in the performance of a single retrieval but have access to scores from multiple systems for (a) IM = 0.006 (b) IM = 0.241 (c) IM = 0.487 Figure 1: The Moran coefficient, IM for a several binary functions on a grid.",
        "The Moran coefficient is a local measure of function consistency.",
        "From the perspective of information retrieval, each of these grid spaces would represent a document and documents would be organized so that they lay next to topically-related documents.",
        "Binary retrieval scores would define a pattern on this grid.",
        "Notice that, as the Moran coefficient increases, neighboring cells tend to have similar values. the same query.",
        "In this situation, we can use combined information from these scores to construct a surrogate for a high-quality ranking [17].",
        "We can treat the correlation between the retrieval we are interested in and the combined scores as a predictor of performance.",
        "Assume that we are given m score functions, yi, for the same n documents.",
        "We will represent the mean of these vectors as yµ = Pm i=1 yi.",
        "We use the mean vector as an approximation to relevance.",
        "Since we use zero mean and unit variance normalization, work in metasearch suggests that this assumption is justified [15].",
        "Because yµ represents a very good retrieval, we hypothesize that a strong similarity between yµ and y will correlate positively with system performance.",
        "We use Pearsons product-moment correlation to measure the similarity between these vectors, ρ(y, yµ) = yT yµ y 2 yµ 2 (4) We will comment on the similarity between Equation 3 and 4 in Section 7.",
        "Of course, we can combine ρ(y, ˜y) and ρ(y, yµ) if we assume that they capture different factors in the prediction.",
        "One way to accomplish this is to combine these predictors as independent variables in a linear regression.",
        "An alternative means of combination is suggested by the mathematical form of our predictors.",
        "Since ˜y encodes the spatial dependencies in y and yµ encodes the spatial properties of the multiple runs, we can compute a third correlation between these two vectors, ρ(˜y, yµ) = ˜yT yµ ˜y 2 yµ 2 (5) We can interpret Equation 5 as measuring the correlation between a high quality ranking (yµ) and a spatially smoothed version of the retrieval (˜y). 4.",
        "RELATIONSHIP WITH OTHER PREDICTORS One way to predict the effectiveness of a retrieval is to look at the shared vocabulary of the top n retrieved documents.",
        "If we computed the most frequent content words in this set, we would hope that they would be consistent with our topic.",
        "In fact, we might believe that a bad retrieval would include documents on many disparate topics, resulting in an overlap of terminological noise.",
        "The Clarity of a query attempts to quantify exactly this [7].",
        "Specifically, Clarity measures the similarity of the words most frequently used in retrieved documents to those most frequently used in the whole corpus.",
        "The conjecture is that a good retrieval will use language distinct from general text; the overlapping language in a bad retrieval will tend to be more similar to general text.",
        "Mathematically, we can compute a representation of the language used in the initial retrieval as a weighted combination of document language models, P(w|θQ) = nX i=1 P(w|θi) P(Q|θi) Z (6) where θi is the language model of the ith-ranked document, P(Q|θi) is the query likelihood score of the ith-ranked document and Z = Pn i=1 P(Q|θi) is a normalization constant.",
        "The similarity between the multinomial P(w|θQ) and a model of general text can be computed using the Kullback-Leibler divergence, DV KL(θQ θC ).",
        "Here, the distribution P(w|θC ) is our model of general text which can be computed using term frequencies in the corpus.",
        "In Figure 2a, we present Clarity as measuring the distance between the weighted center of mass of the retrieval (labeled y) and the unweighted center of mass of the collection (labeled O).",
        "Clarity reaches a minimum when a retrieval assigns every document the same score.",
        "Lets again assume we have a set of n documents retrieved for our query.",
        "Another way to quantify the dispersion of a set of documents is to look at how clustered they are.",
        "We may hypothesize that a good retrieval will return a single, tight cluster.",
        "A poorly performing retrieval will return a loosely related set of documents covering many topics.",
        "One proposed method of quantifying this dispersion is to measure the distance from a random document a to its nearest neighbor, b.",
        "A retrieval which is tightly clustered will, on average, have a low distance between a and b; a retrieval which is less tightly-closed will, on average have high distances between a and b.",
        "This average corresponds to using the Cox-Lewis statistic to measure the randomness of the top n documents retrieved from a system [18].",
        "In Figure 2a, this is roughly equivalent to measuring the area of the set n. Notice that we are throwing away information about the retrieval function y.",
        "Therefore the Cox-Lewis statistic is highly dependent on selecting the top n documents.1 Remember that we have n documents and a set of scores.",
        "Lets assume that we have access to the system which provided the original scores and that we can also request scores for new documents.",
        "This suggests a third method for predicting performance.",
        "Take some document, a, from the retrieved set and arbitrarily add or remove words at random to create a new document ˜a.",
        "Now, we can ask our system to score ˜a with respect to our query.",
        "If, on average over the n documents, the scores of a and ˜a tend to be very different, we might suspect that the system is failing on this query.",
        "So, an alternative approach is to measure the simi1 The authors have suggested coupling the query with the distance measure [18].",
        "The information introduced by the query, though, is retrieval-independent so that, if two retrievals return the same set of documents, the approximate Cox-Lewis statistic will be the same regardless of the retrieval scores. yOy (a) Global Divergence µ(y)˜y y (b) Score Perturbation µ(y) y (c) Multirun Averaging Figure 2: Representation of several performance predictors on a grid.",
        "In Figure 2a, we depict predictors which measure the divergence between the center of mass of a retrieval and the center of the embedding space.",
        "In Figure 2b, we depict predictors which compare the original retrieval, y, to a perturbed version of the retrieval, ˜y.",
        "Our approach uses a particular type of perturbation based on score diffusion.",
        "Finally, in Figure 2c, we depict prediction when given retrievals from several other systems on the same query.",
        "Here, we can consider the fusion of these retrieval as a surrogate for relevance. larity between the retrieval and a perturbed version of that retrieval [18, 19].",
        "This can be accomplished by either perturbing the documents or queries.",
        "The similarity between the two retrievals can be measured using some correlation measure.",
        "This is depicted in Figure 2b.",
        "The upper grid represents the original retrieval, y, while the lower grid represents the function after having been perturbed, ˜y.",
        "The nature of the perturbation process requires additional scorings or retrievals.",
        "Our predictor does not require access to the original scoring function or additional retrievals.",
        "So, although our method is similar to other perturbation methods in spirit, it can be applied in situations when the retrieval system is inaccessible or costly to access.",
        "Finally, assume that we have, in addition to the retrieval we want to evaluate, m retrievals from a variety of different systems.",
        "In this case, we might take a document a, compare its rank in the retrieval to its average rank in the m retrievals.",
        "If we believe that the m retrievals provide a satisfactory approximation to relevance, then a very large difference in rank would suggest that our retrieval is misranking a.",
        "If this difference is large on average over all n documents, then we might predict that the retrieval is bad.",
        "If, on the other hand, the retrieval is very consistent with the m retrievals, then we might predict that the retrieval is good.",
        "The similarity between the retrieval and the combined retrieval may be computed using some correlation measure.",
        "This is depicted in Figure 2c.",
        "In previous work, the Kullback-Leibler divergence between the normalized scores of the retrieval and the normalized scores of the combined retrieval provides the similarity [1]. 5.",
        "EXPERIMENTS Our experiments focus on testing the predictive power of each of our predictors: ρ(y, ˜y), ρ(y, yµ), and ρ(˜y, yµ).",
        "As stated in Section 2, we are interested in predicting the performance of the retrieval generated by an arbitrary system.",
        "Our methodology is consistent with previous research in that we predict the relative performance of a retrieval by comparing a ranking based on our predictor to a ranking based on average precision.",
        "We present results for two sets of experiments.",
        "The first set of experiments presents detailed comparisons of our predictors to previously-proposed predictors using identical data sets.",
        "Our second set of experiments demonstrates the generalizability of our approach to arbitrary retrieval methods, corpus types, and corpus languages. 5.1 Detailed Experiments In these experiments, we will predict the performance of language modeling scores using our autocorrelation predictor, ρ(y, ˜y); we do not consider ρ(y, yµ) or ρ(˜y, yµ) because, in these detailed experiments, we focus on ranking the retrievals from a single system.",
        "We use retrievals, values for baseline predictors, and evaluation measures reported in previous work [19]. 5.1.1 Topics and Collections These performance prediction experiments use language model retrievals performed for queries associated with collections in the TREC corpora.",
        "Using TREC collections allows us to confidently associate an average precision with a retrieval.",
        "In these experiments, we use the following topic collections: TREC 4 ad-hoc, TREC 5 ad-hoc, Robust 2004, Terabyte 2004, and Terabyte 2005. 5.1.2 Baselines We provide two baselines.",
        "Our first baseline is the classic Clarity predictor presented in Equation 6.",
        "Clarity is designed to be used with language modeling systems.",
        "Our second baseline is Zhou and Crofts ranking robustness predictor.",
        "This predictor corrupts the top k documents from retrieval and re-computes the language model scores for these corrupted documents.",
        "The value of the predictor is the Spearman rank correlation between the original ranking and the corrupted ranking.",
        "In our tables, we will label results for Clarity using DV KL and the ranking robustness predictor using P. 5.2 Generalizability Experiments Our predictors do not require a particular baseline retrieval system; the predictors can be computed for an arbitrary retrieval, regardless of how scores were generated.",
        "We believe that that is one of the most attractive aspects of our algorithm.",
        "Therefore, in a second set of experiments, we demonstrate the ability of our techniques to generalize to a variety of collections, topics, and retrieval systems. 5.2.1 Topics and Collections We gathered a diverse set of collections from all possible TREC corpora.",
        "We cast a wide net in order to locate collections where our predictors might fail.",
        "Our hypothesis is that documents with high topical similarity should have correlated scores.",
        "Therefore, we avoided collections where scores were unlikely to be correlated (eg, question-answering) or were likely to be negatively correlated (eg, novelty).",
        "Nevertheless, our collections include corpora where correlations are weakly justified (eg, non-English corpora) or not justified at all (eg, expert search).",
        "We use the ad-hoc tracks from TREC3-8, TREC Robust 2003-2005, TREC Terabyte 20042005, TREC4-5 Spanish, TREC5-6 Chinese, and TREC Enterprise Expert Search 2005.",
        "In all cases, we use only the automatic runs for ad-hoc tracks submitted to NIST.",
        "For all English and Spanish corpora, we construct the matrix W according to the process described in Section 3.1.",
        "For Chinese corpora, we use na¨ıve character-based tf.idf vectors.",
        "For entities, entries in W are proportional to the number of documents in which two entities cooccur. 5.2.2 Baselines In our detailed experiments, we used the Clarity measure as a baseline.",
        "Since we are predicting the performance of retrievals which are not based on language modeling, we use a version of Clarity referred to as ranked-list Clarity [7].",
        "Ranked-list clarity converts document ranks to P(Q|θi) values.",
        "This conversion begins by replacing all of the scores in y with the respective ranks.",
        "Our estimation of P(Q|θi) from the ranks, then is, P(Q|θi) = ( 2(c+1−yi) c(c+1) if yi ≤ c 0 otherwise (7) where c is a cutoff parameter.",
        "As suggested by the authors, we fix the algorithm parameters c and λ2 so that c = 60 and λ2 = 0.10.",
        "We use Equation 6 to estimate P(w|θQ) and DV KL(θQ θC ) to compute the value of the predictor.",
        "We will refer to this predictor as DV KL, superscripted by V to indicate that the Kullback-Leibler divergence is with respect to the term embedding space.",
        "When information from multiple runs on the same query is available, we use Aslam and Pavlus document-space multinomial divergence as a baseline [1].",
        "This rank-based method first normalizes the scores in a retrieval as an n-dimensional multinomial.",
        "As with ranked-list Clarity, we begin by replacing all of the scores in y with their respective ranks.",
        "Then, we adjust the elements of y in the following way, ˆyi = 1 2n 0 @1 + nX k=yi 1 k 1 A (8) In our multirun experiments, we only use the top 75 documents from each retrieval (n = 75); this is within the range of parameter values suggested by the authors.",
        "However, we admit not tuning this parameter for either our system or the baseline.",
        "The predictor is the divergence between the candidate distribution, y, and the mean distribution, yµ .",
        "With the uniform linear combination of these m retrievals represented as yµ, we can compute the divergence as Dn KL(ˆy ˆyµ) where we use the superscript n to indicate that the summation is over the set of n documents.",
        "This baseline was developed in the context of predicting query difficulty but we adopt it as a reasonable baseline for predicting retrieval performance. 5.2.3 Parameter Settings When given multiple retrievals, we use documents in the union of the top k = 75 documents from each of the m retrievals for that query.",
        "If the size of this union is ˜n, then yµ and each yi is of length ˜n.",
        "In some cases, a system did not score a document in the union.",
        "Since we are making a Gaussian assumption about our scores, we can sample scores for these unseen documents from the negative tail of the distribution.",
        "Specifically, we sample from the part of the distribution lower than the minimum value of in the normalized retrieval.",
        "This introduces randomness into our algorithm but we believe it is more appropriate than assigning an arbitrary fixed value.",
        "We optimized the linear regression using the square root of each predictor.",
        "We found that this substantially improved fits for all predictors, including the baselines.",
        "We considered linear combinations of pairs of predictors (labeled by the components) and all predictors (labeled as β). 5.3 Evaluation Given a set of retrievals, potentially from a combination of queries and systems, we measure the correlation of the rank ordering of this set by the predictor and by the performance metric.",
        "In order to ensure comparability with previous results, we present Kendalls τ correlation between the predictors ranking and ranking based on average precision of the retrieval.",
        "Unless explicitly noted, all correlations are significant with p < 0.05.",
        "Predictors can sometimes perform better when linearly combined [9, 11].",
        "Although previous work has presented the coefficient of determination (R2 ) to measure the quality of the regression, this measure cannot be reliably used when comparing slight improvements from combining predictors.",
        "Therefore, we adopt the adjusted coefficient of determination which penalizes models with more variables.",
        "The adjusted R2 allows us to evaluate the improvement in prediction achieved by adding a parameter but loses the statistical interpretation of R2 .",
        "We will use Kendalls τ to evaluate the magnitude of the correlation and the adjusted R2 to evaluate the combination of variables. 6.",
        "RESULTS We present results for our detailed experiments comparing the prediction of language model scores in Table 1.",
        "Although the Clarity measure is theoretically designed for language model scores, it consistently underperforms our system-agnostic predictor.",
        "Ranking robustness was presented as an improvement to Clarity for web collections (represented in our experiments by the terabyte04 and terabyte05 collections), shifting the τ correlation from 0.139 to 0.150 for terabyte04 and 0.171 to 0.208 for terabyte05.",
        "However, these improvements are slight compared to the performance of autocorrelation on these collections.",
        "Our predictor achieves a τ correlation of 0.454 for terabyte04 and 0.383 for terabyte05.",
        "Though not always the strongest, autocorrelation achieves correlations competitive with baseline predictors.",
        "When examining the performance of linear combinations of predictors, we note that in every case, autocorrelation factors as a necessary component of a strong predictor.",
        "We also note that the adjusted R2 for individual baselines are always significantly improved by incorporating autocorrelation.",
        "We present our generalizability results in Table 2.",
        "We begin by examining the situation in column (a) where we are presented with a single retrieval and no information from additional retrievals.",
        "For every collection except one, we achieve significantly better correlations than ranked-list Clarity.",
        "Surprisingly, we achieve relatively strong correlations for Spanish and Chinese collections despite our na¨ıve processing.",
        "We do not have a ranked-list clarity correlation for ent05 because entity modeling is itself an open research question.",
        "However, our autocorrelation measure does not achieve high correlations perhaps because relevance for entity retrieval does not propagate according to the cooccurrence links we use.",
        "As noted above, the poor Clarity performance on web data is consistent with our findings in the detailed experiments.",
        "Clarity also notably underperforms for several news corpora (trec5, trec7, and robust04).",
        "On the other hand, autocorrelation seems robust to the changes between different corpora.",
        "Next, we turn to the introduction of information from multiple retrievals.",
        "We compare the correlations between those predictors which do not use this information in column (a) and those which do in column (b).",
        "For every collection, the predictors in column (b) outperform the predictors in column (a), indicating that the information from additional runs can be critical to making good predictions.",
        "Inspecting the predictors in column (b), we only draw weak conclusions.",
        "Our new predictors tend to perform better on news corpora.",
        "And between our new predictors, the hybrid ρ(˜y, yµ) predictor tends to perform better.",
        "Recall that our ρ(˜y, yµ) measure incorporates both spatial and multiple retrieval information.",
        "Therefore, we believe that the improvement in correlation is the result of incorporating information from spatial behavior.",
        "In column (c), we can investigate the utility of incorporating spatial information with information from multiple retrievals.",
        "Notice that in the cases where autocorrelation, ρ(y, ˜y), alone performs well (trec3, trec5-spanish, and trec6-chinese), it is substantially improved by incorporating multiple-retrieval information from ρ(y, yµ) in the linear regression, β.",
        "In the cases where ρ(y, yµ) performs well, incorporating autocorrelation rarely results in a significant improvement in performance.",
        "In fact, in every case where our predictor outperforms the baseline, it includes information from multiple runs. 7.",
        "DISCUSSION The most important result from our experiments involves prediction when no information is available from multiple runs (Tables 1 and 2a).",
        "This situation arises often in system design.",
        "For example, a system may need to, at retrieval time, assess its performance before deciding to conduct more intensive processing such as pseudo-relevance feedback or interaction.",
        "Assuming the presence of multiple retrievals is unrealistic in this case.",
        "We believe that autocorrelation is, like multiple-retrieval algorithms, approximating a good ranking; in this case by diffusing scores.",
        "Why is ˜y a reasonable surrogate?",
        "We know that diffusion of scores on the web graph and language model graphs improves performance [14, 16].",
        "Therefore, if score diffusion tends to, in general, improve performance, then diffused scores will, in general, provide a good surrogate for relevance.",
        "Our results demonstrate that this approximation is not as powerful as information from multiple retrievals.",
        "Nevertheless, in situations where this information is lacking, autocorrelation provides substantial information.",
        "The success of autocorrelation as a predictor may also have roots in the clustering hypothesis.",
        "Recall that we regard autocorrelation as the degree to which a retrieval satisfies the clustering hypothesis.",
        "Our experiments, then, demonstrate that a failure to respect the clustering hypothesis correlates with poor performance.",
        "Why might systems fail to conform to the cluster hypothesis?",
        "Query-based information retrieval systems often score documents independently.",
        "The score of document a may be computed by examining query term or phrase matches, the document length, and perhaps global collection statistics.",
        "Once computed, a system rarely compares the score of a to the score of a topically-related document b.",
        "With some exceptions, the correlation of document scores has largely been ignored.",
        "We should make it clear that we have selected tasks where topical autocorrelation is appropriate.",
        "There are certainly cases where there is no reason to believe that retrieval scores will have topical autocorrelation.",
        "For example, ranked lists which incorporate document novelty should not exhibit spatial autocorrelation; if anything autocorrelation should be negative for this task.",
        "Similarly, answer candidates in a question-answering task may or may not exhibit autocorrelation; in this case, the semantics of links is questionable too.",
        "It is important before applying this measure to confirm that, given the semantics for some link between two retrieved items, we should expect a correlation between scores. 8.",
        "RELATED WORK In this section we draw more general comparisons to other work in performance prediction and spatial data analysis.",
        "There is a growing body of work which attempts to predict the performance of individual retrievals [7, 3, 11, 9, 19].",
        "We have attempted to place our work in the context of much of this work in Section 4.",
        "However, a complete comparison is beyond the scope of this paper.",
        "We note, though, that our experiments cover a larger and more diverse set of retrievals, collections, and topics than previously examined.",
        "Much previous work-particularly in the context of TRECfocuses on predicting the performance of systems.",
        "Here, each system generates k retrievals.",
        "The task is, given these retrievals, to predict the ranking of systems according to some performance measure.",
        "Several papers attempt to address this task under the constraint of few judgments [2, 4].",
        "Some work even attempts to use zero judgments by leveraging multiple retrievals for the same query [17].",
        "Our task differs because we focus on ranking retrievals independent of the generating system.",
        "The task here is not to test the hypothesis system A is superior to system B but to test the hypothesis retrieval A is superior to retrieval B. Autocorrelation manifests itself in many classification tasks.",
        "Neville and Jensen define relational autocorrelation for relational learning problems and demonstrate that many classification tasks manifest autocorrelation [13].",
        "Temporal autocorrelation of initial retrievals has also been used to predict performance [9].",
        "However, temporal autocorrelation is performed by projecting the retrieval function into the temporal embedding space.",
        "In our work, we focus on the behavior of the function over the relationships between documents. τ adjusted R2 DV KL P ρ(y, ˜y) DV KL P ρ(y, ˜y) DV KL, P DV KL, ρ(y, ˜y) Pρ(y, ˜y) β trec4 0.353 0.548 0.513 0.168 0.363 0.422 0.466 0.420 0.557 0.553 trec5 0.311 0.329 0.357 0.116 0.190 0.236 0.238 0.244 0.266 0.269 robust04 0.418 0.398 0.373 0.256 0.304 0.278 0.403 0.373 0.402 0.442 terabyte04 0.139 0.150 0.454 0.059 0.045 0.292 0.076 0.293 0.289 0.284 terabyte05 0.171 0.208 0.383 0.022 0.072 0.193 0.120 0.225 0.218 0.257 Table 1: Comparison to Robustness and Clarity measures for language model scores.",
        "Evaluation replicates experiments from [19].",
        "We present correlations between the classic Clarity measure (DV KL), the ranking robustness measure (P), and autocorrelation (ρ(y, ˜y)) each with mean average precision in terms of Kendalls τ.",
        "The adjusted coefficient of determination is presented to measure the effectiveness of combining predictors.",
        "Measures in bold represent the strongest correlation for that test/collection pair. multiple run (a) (b) (c) τ τ adjusted R2 DKL ρ(y, ˜y) Dn KL ρ(y, yµ) ρ(˜y, yµ) Dn KL ρ(y, ˜y) ρ(y, yµ) ρ(˜y, yµ) β trec3 0.201 0.461 0.461 0.439 0.456 0.444 0.395 0.394 0.386 0.498 trec4 0.252 0.396 0.455 0.482 0.489 0.379 0.263 0.429 0.482 0.483 trec5 0.016 0.277 0.433 0.459 0.393 0.280 0.157 0.375 0.323 0.386 trec6 0.230 0.227 0.352 0.428 0.418 0.203 0.089 0.323 0.325 0.325 trec7 0.083 0.326 0.341 0.430 0.483 0.264 0.182 0.363 0.442 0.400 trec8 0.235 0.396 0.454 0.508 0.567 0.402 0.272 0.490 0.580 0.523 robust03 0.302 0.354 0.377 0.385 0.447 0.269 0.206 0.274 0.392 0.303 robust04 0.183 0.308 0.301 0.384 0.453 0.200 0.182 0.301 0.393 0.335 robust05 0.224 0.249 0.371 0.377 0.404 0.341 0.108 0.313 0.328 0.336 terabyte04 0.043 0.245 0.544 0.420 0.392 0.516 0.105 0.357 0.343 0.365 terabyte05 0.068 0.306 0.480 0.434 0.390 0.491 0.168 0.384 0.309 0.403 trec4-spanish 0.307 0.388 0.488 0.398 0.395 0.423 0.299 0.282 0.299 0.388 trec5-spanish 0.220 0.458 0.446 0.484 0.475 0.411 0.398 0.428 0.437 0.529 trec5-chinese 0.092 0.199 0.367 0.379 0.384 0.379 0.199 0.273 0.276 0.310 trec6-chinese 0.144 0.276 0.265 0.353 0.376 0.115 0.128 0.188 0.223 0.199 ent05 - 0.181 0.324 0.305 0.282 0.211 0.043 0.158 0.155 0.179 Table 2: Large scale prediction experiments.",
        "We predict the ranking of large sets of retrievals for various collections and retrieval systems.",
        "Kendalls τ correlations are computed between the predicted ranking and a ranking based on the retrievals average precision.",
        "In column (a), we have predictors which do not use information from other retrievals for the same query.",
        "In columns (b) and (c) we present performance for predictors which incorporate information from multiple retrievals.",
        "The adjusted coefficient of determination is computed to determine effectiveness of combining predictors.",
        "Measures in bold represent the strongest correlation for that test/collection pair.",
        "Finally, regularization-based re-ranking processes are also closely-related to our work [8].",
        "These techniques seek to maximize the agreement between scores of related documents by solving a constrained optimization problem.",
        "The maximization of consistency is equivalent to maximizing the Moran autocorrelation.",
        "Therefore, we believe that our work provides explanation for why regularization-based re-ranking works. 9.",
        "CONCLUSION We have presented a new method for predicting the performance of a retrieval ranking without any relevance judgments.",
        "We consider two cases.",
        "First, when making predictions in the absence of retrievals from other systems, our predictors demonstrate robust, strong correlations with average precision.",
        "This performance, combined with a simple implementation, makes our predictors, in particular, very attractive.",
        "We have demonstrated this improvement for many, diverse settings.",
        "To our knowledge, this is the first large scale examination of zero-judgment, single-retrieval performance prediction.",
        "Second, when provided retrievals from other systems, our extended methods demonstrate competitive performance with state of the art baselines.",
        "Our experiments also demonstrate the limits of the usefulness of our predictors when information from multiple runs is provided.",
        "Our results suggest two conclusions.",
        "First, our results could affect retrieval algorithm design.",
        "Retrieval algorithms designed to consider spatial autocorrelation will conform to the cluster hypothesis and improve performance.",
        "Second, our results could affect the design of minimal test collection algorithms.",
        "Much of the recent work in ranking systems sometimes ignores correlations between document labels and scores.",
        "We believe that these two directions could be rewarding given the theoretical and experimental evidence in this paper. 10.",
        "ACKNOWLEDGMENTS This work was supported in part by the Center for Intelligent Information Retrieval and in part by the Defense Advanced Research Projects Agency (DARPA) under contract number HR0011-06-C-0023.",
        "Any opinions, findings and conclusions or recommendations expressed in this material are the authors and do not necessarily reflect those of the sponsor.",
        "We thank Yun Zhou and Desislava Petkova for providing data and Andre Gauthier for technical assistance. 11.",
        "REFERENCES [1] J. Aslam and V. Pavlu.",
        "Query hardness estimation using jensen-shannon divergence among multiple scoring functions.",
        "In ECIR 2007: Proceedings of the 29th European Conference on Information Retrieval, 2007. [2] J.",
        "A. Aslam, V. Pavlu, and E. Yilmaz.",
        "A statistical method for system evaluation using incomplete judgments.",
        "In S. Dumais, E. N. Efthimiadis, D. Hawking, and K. Jarvelin, editors, Proceedings of the 29th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 541-548.",
        "ACM Press, August 2006. [3] D. Carmel, E. Yom-Tov, A. Darlow, and D. Pelleg.",
        "What makes a query difficult?",
        "In SIGIR 06: Proceedings of the 29th annual international ACM SIGIR conference on Research and development in information retrieval, pages 390-397, New York, NY, USA, 2006.",
        "ACM Press. [4] B. Carterette, J. Allan, and R. Sitaraman.",
        "Minimal test collections for retrieval evaluation.",
        "In SIGIR 06: Proceedings of the 29th annual international ACM SIGIR conference on Research and development in information retrieval, pages 268-275, New York, NY, USA, 2006.",
        "ACM Press. [5] A. D. Cliff and J. K. Ord.",
        "Spatial Autocorrelation.",
        "Pion Ltd., 1973. [6] M. Connell, A. Feng, G. Kumaran, H. Raghavan, C. Shah, and J. Allan.",
        "Umass at tdt 2004.",
        "Technical Report CIIR Technical Report IR - 357, Department of Computer Science, University of Massachusetts, 2004. [7] S. Cronen-Townsend, Y. Zhou, and W. B. Croft.",
        "Precision prediction based on ranked list coherence.",
        "Inf.",
        "Retr., 9(6):723-755, 2006. [8] F. Diaz.",
        "Regularizing ad-hoc retrieval scores.",
        "In CIKM 05: Proceedings of the 14th ACM international conference on Information and knowledge management, pages 672-679, New York, NY, USA, 2005.",
        "ACM Press. [9] F. Diaz and R. Jones.",
        "Using temporal profiles of queries for precision prediction.",
        "In SIGIR 04: Proceedings of the 27th annual international ACM SIGIR conference on Research and development in information retrieval, pages 18-24, New York, NY, USA, 2004.",
        "ACM Press. [10] D. A. Griffith.",
        "Spatial Autocorrelation and Spatial Filtering.",
        "Springer Verlag, 2003. [11] B.",
        "He and I. Ounis.",
        "Inferring Query Performance Using Pre-retrieval Predictors.",
        "In The Eleventh Symposium on String Processing and Information Retrieval (SPIRE), 2004. [12] N. Jardine and C. J. V. Rijsbergen.",
        "The use of hierarchic clustering in information retrieval.",
        "Information Storage and Retrieval, 7:217-240, 1971. [13] D. Jensen and J. Neville.",
        "Linkage and autocorrelation cause feature selection bias in relational learning.",
        "In ICML 02: Proceedings of the Nineteenth International Conference on Machine Learning, pages 259-266, San Francisco, CA, USA, 2002.",
        "Morgan Kaufmann Publishers Inc. [14] O. Kurland and L. Lee.",
        "Corpus structure, language models, and ad-hoc information retrieval.",
        "In SIGIR 04: Proceedings of the 27th annual international conference on Research and development in information retrieval, pages 194-201, New York, NY, USA, 2004.",
        "ACM Press. [15] M. Montague and J.",
        "A. Aslam.",
        "Relevance score normalization for metasearch.",
        "In CIKM 01: Proceedings of the tenth international conference on Information and knowledge management, pages 427-433, New York, NY, USA, 2001.",
        "ACM Press. [16] T. Qin, T.-Y.",
        "Liu, X.-D. Zhang, Z. Chen, and W.-Y.",
        "Ma.",
        "A study of relevance propagation for web search.",
        "In SIGIR 05: Proceedings of the 28th annual international ACM SIGIR conference on Research and development in information retrieval, pages 408-415, New York, NY, USA, 2005.",
        "ACM Press. [17] I. Soboroff, C. Nicholas, and P. Cahan.",
        "Ranking retrieval systems without relevance judgments.",
        "In SIGIR 01: Proceedings of the 24th annual international ACM SIGIR conference on Research and development in information retrieval, pages 66-73, New York, NY, USA, 2001.",
        "ACM Press. [18] V. Vinay, I. J. Cox, N. Milic-Frayling, and K. Wood.",
        "On ranking the effectiveness of searches.",
        "In SIGIR 06: Proceedings of the 29th annual international ACM SIGIR conference on Research and development in information retrieval, pages 398-404, New York, NY, USA, 2006.",
        "ACM Press. [19] Y. Zhou and W. B. Croft.",
        "Ranking robustness: a novel framework to predict query performance.",
        "In CIKM 06: Proceedings of the 15th ACM international conference on Information and knowledge management, pages 567-574, New York, NY, USA, 2006.",
        "ACM Press."
    ],
    "translated_text_sentences": [
        "Predicción del rendimiento utilizando autocorrelación espacial. Fernando Díaz. Centro de Recuperación de Información Inteligente. Departamento de Ciencias de la Computación. Universidad de Massachusetts Amherst, MA 01003. fdiaz@cs.umass.edu. RESUMEN La evaluación de sistemas de recuperación de información es una de las tareas fundamentales en la recuperación de información.",
        "Los problemas incluyen la incapacidad de etiquetar exhaustivamente todos los documentos sobre un tema, la falta de generalización a partir de un pequeño número de temas e incorporar la variabilidad de los sistemas de recuperación.",
        "Trabajos anteriores abordan la evaluación de sistemas, la clasificación de consultas por dificultad y la clasificación de recuperaciones individuales por rendimiento.",
        "Existen enfoques para el caso de pocos e incluso ningún juicio de relevancia.",
        "Nuestro enfoque está en la predicción del rendimiento sin juicios de las recuperaciones individuales.",
        "Una deficiencia común de las técnicas anteriores es la suposición de que las puntuaciones de los documentos y los juicios no están correlacionados.",
        "Si los documentos están incrustados en un espacio de alta dimensión (como a menudo lo están), podemos aplicar técnicas de análisis de datos espaciales para detectar correlaciones entre las puntuaciones de los documentos.",
        "Observamos que la baja correlación entre las puntuaciones de documentos temáticamente cercanos a menudo implica un bajo rendimiento en la recuperación.",
        "Cuando se compara con una línea base de última generación, demostramos que el análisis espacial de las puntuaciones de recuperación ofrece un rendimiento predictivo significativamente mejor.",
        "Estos nuevos predictores también pueden ser incorporados con predictores clásicos para mejorar aún más el rendimiento.",
        "También describimos el primer experimento a gran escala para evaluar la predicción de rendimiento sin juicio para un gran número de sistemas de recuperación en una variedad de colecciones en varios idiomas.",
        "Categorías y Descriptores de Asignaturas H.3.3 [Búsqueda y Recuperación de Información]: Modelos de recuperación; H.3.4 [Sistemas y Software]: Evaluación del rendimiento (eficiencia y efectividad) Términos Generales Rendimiento, Diseño, Confiabilidad, Experimentación 1.",
        "En la recuperación de información, un usuario plantea una consulta a un sistema.",
        "El sistema recupera n documentos, cada uno recibiendo una puntuación de valor real que indica el grado de relevancia predicho.",
        "Si seleccionamos aleatoriamente pares de documentos de este conjunto, esperamos que algunos pares compartan el mismo tema y otros pares no compartan el mismo tema.",
        "Toma dos documentos relacionados entre sí del conjunto y llámalos a y b.",
        "Si las puntuaciones de a y b son muy diferentes, podríamos estar preocupados por el rendimiento de nuestro sistema.",
        "Es decir, si tanto a como b están relacionados con el tema de la consulta, nos gustaría que ambos reciban una puntuación alta; si a y b no están relacionados con el tema de la consulta, nos gustaría que ambos reciban una puntuación baja.",
        "Podríamos preocuparnos más a medida que encontramos más diferencias entre las puntuaciones de documentos relacionados.",
        "Estaríamos más cómodos con una recuperación en la que las puntuaciones sean consistentes entre documentos relacionados.",
        "Nuestro artículo estudia la cuantificación de esta inconsistencia en una recuperación desde una perspectiva espacial.",
        "El análisis espacial es apropiado ya que muchos modelos de recuperación incrustan documentos en algún espacio vectorial.",
        "Si los documentos están incrustados en un espacio, la proximidad se correlaciona con las relaciones temáticas.",
        "La consistencia de la puntuación puede medirse mediante la versión espacial de la autocorrelación conocida como el coeficiente de Moran o IM [5, 10].",
        "En este artículo, demostramos una fuerte correlación entre IM y el rendimiento de recuperación.",
        "La discusión hasta este punto recuerda a la hipótesis del cúmulo.",
        "La hipótesis del clúster establece que los documentos estrechamente relacionados tienden a ser relevantes para la misma solicitud [12].",
        "Como veremos, una función de recuperación de medidas de autocorrelación espacial mide el grado en que los documentos relacionados reciben puntuaciones similares.",
        "Debido a esto, interpretamos la autocorrelación como la medida del grado en que una función de recuperación satisface la hipótesis de agrupamiento.",
        "Si esta conexión es razonable, en la Sección 6 presentamos evidencia de que la falta de cumplimiento de la hipótesis de agrupamiento se correlaciona fuertemente con un bajo rendimiento.",
        "En este trabajo, proporcionamos las siguientes contribuciones: 1.",
        "Un método general y robusto para predecir el rendimiento de recuperaciones sin juicios de relevancia (Sección 3). 2.",
        "Un tratamiento teórico de las similitudes y motivaciones detrás de varias técnicas de predicción de rendimiento de vanguardia (Sección 4). 3.",
        "Las primeras experimentaciones a gran escala de predicción de rendimiento de una sola ejecución sin juicio (Secciones 5 y 6). 2.",
        "Dada una consulta, un sistema de recuperación de información produce una clasificación de documentos en la colección codificada como un conjunto de puntuaciones asociadas con los documentos.",
        "Nos referimos al conjunto de puntuaciones para una combinación particular de consulta-sistema como una recuperación.",
        "Nos gustaría predecir el rendimiento de esta recuperación con respecto a alguna medida de evaluación (por ejemplo, precisión promedio).",
        "En este artículo, presentamos resultados para clasificar recuperaciones de sistemas arbitrarios.",
        "Nos gustaría que este ranking se aproximara al ranking de recuperaciones según la medida de evaluación.",
        "Esto es diferente de clasificar las consultas por el rendimiento promedio en cada consulta.",
        "También es diferente de los sistemas de clasificación por el rendimiento promedio en un conjunto de consultas.",
        "Las puntuaciones a menudo solo se calculan para los primeros n documentos de la colección.",
        "Colocamos estos puntajes en el vector de longitud n, y, donde yi se refiere al puntaje del documento clasificado en la posición i.",
        "Ajustamos las puntuaciones para que tengan una media de cero y una varianza unitaria.",
        "Utilizamos este método debido a su simplicidad y su éxito en trabajos anteriores [15].",
        "CORRELACIÓN ESPACIAL En la recuperación de información, a menudo asumimos que las representaciones de los documentos existen en algún espacio vectorial de alta dimensión.",
        "Por ejemplo, dado un vocabulario, V, este espacio vectorial puede ser un espacio arbitrario de dimensión |V| con producto interno de coseno o un simplejo multinomial con una medida de distancia basada en distribución.",
        "Un espacio de incrustación suele ser seleccionado para respetar la proximidad temática; si dos documentos están cerca, es más probable que compartan un tema.",
        "Debido a la prevalencia y éxito de los modelos espaciales de recuperación de información, creemos que la aplicación de técnicas de análisis de datos espaciales es apropiada.",
        "Mientras que en la recuperación de información nos preocupa la puntuación en un punto en el espacio, en el análisis de datos espaciales nos preocupa el valor de una función en un punto o ubicación en el espacio.",
        "Utilizamos el término función aquí para referirnos a una asignación de una ubicación a un valor real.",
        "Por ejemplo, podríamos estar interesados en la prevalencia de una enfermedad en el vecindario de alguna ciudad.",
        "La función asignaría la ubicación de un vecindario a una tasa de infección.",
        "Si queremos cuantificar las dependencias espaciales de una función, emplearíamos una medida conocida como la autocorrelación espacial [5, 10].",
        "Una alta autocorrelación espacial sugiere que conocer el valor de una función en la ubicación a nos dirá mucho sobre el valor en una ubicación vecina b.",
        "Existe una alta autocorrelación espacial para una función que representa la temperatura de una ubicación, ya que saber la temperatura en una ubicación a nos dirá mucho sobre la temperatura en una ubicación vecina b.",
        "La baja autocorrelación espacial sugiere que conocer el valor de una función en la ubicación a nos dice poco sobre el valor en una ubicación vecina b.",
        "Hay una baja autocorrelación espacial en una función que mide el resultado de lanzar una moneda en a y b.",
        "En esta sección, comenzaremos describiendo lo que entendemos por proximidad espacial para documentos y luego definiremos una medida de autocorrelación espacial.",
        "Concluimos extendiendo este modelo para incluir información de múltiples recuperaciones de múltiples sistemas para una sola consulta. 3.1 Representación Espacial de Documentos Nuestro trabajo no se centra en mejorar una medida de similitud específica o definir un espacio vectorial novedoso.",
        "En cambio, elegimos un producto interno conocido por ser efectivo en la detección de relaciones temáticas entre documentos.",
        "Específicamente, adoptamos vectores de documentos tf.idf, ˜di = di log „ (n + 0.5) − ci 0.5 + ci « (1) donde d es un vector de frecuencias de términos, c es el vector de frecuencia de documentos de longitud |V|.",
        "Utilizamos este esquema de ponderación debido a su éxito en la detección de enlaces temáticos en el contexto de las evaluaciones de Detección y Seguimiento de Temas (TDT) [6].",
        "Suponiendo que los vectores están escalados por su norma L2, usamos el producto interno, ˜di, ˜dj, para definir la similitud.",
        "Dado un conjunto de documentos y alguna medida de similitud, podemos construir una matriz que codifica la similitud entre pares de documentos.",
        "Recuerde que se nos dan los primeros n documentos recuperados en y.",
        "Podemos calcular una matriz de similitud n × n, W. Un elemento de esta matriz, Wij, representa la similitud entre los documentos clasificados i y j.",
        "En la práctica, solo incluimos las afinidades para los k vecinos más cercanos de un documento.",
        "En todos nuestros experimentos, hemos fijado k en 5.",
        "Dejamos la exploración de la sensibilidad de los parámetros para trabajos futuros.",
        "También normalizamos por filas la matriz para que Pn j=1 Wij = 1 para todos los i. 3.2 Autocorrelación Espacial de una Recuperación Recuerde que estamos interesados en medir la similitud entre las puntuaciones de documentos cercanos espacialmente.",
        "Una medida adecuada es el coeficiente de Moran de autocorrelación espacial.",
        "Suponiendo la función y sobre n ubicaciones, esto se define como ˜IM = n eTWe P i,j Wijyiyj P i y2 i = n eTWe yT Wy yTy (2) donde eT We = P ij Wij.",
        "Nos gustaría comparar los valores de autocorrelación para diferentes recuperaciones.",
        "Desafortunadamente, el límite para la Ecuación 2 no es consistente para diferentes valores de W y y.",
        "Por lo tanto, utilizamos la desigualdad de Cauchy-Schwartz para establecer un límite, ˜IM ≤ n eTWe s yTWTWy yTy Y definimos la autocorrelación espacial normalizada como IM = yT Wy p yTy × yTWTWy. Nótese que si dejamos ˜y = Wy, entonces podemos escribir esta fórmula como, IM = yT ˜y y 2 ˜y 2 (3) lo cual puede interpretarse como la correlación entre las puntuaciones originales de recuperación y un conjunto de puntuaciones de recuperación difundidas en el espacio.",
        "Presentamos algunos ejemplos de autocorrelaciones de funciones en una cuadrícula en la Figura 1. 3.3 Correlación con Otros Recuperos A veces estamos interesados en el rendimiento de un solo recuperación pero tenemos acceso a puntajes de múltiples sistemas para (a) IM = 0.006 (b) IM = 0.241 (c) IM = 0.487 Figura 1: El coeficiente de Moran, IM para varias funciones binarias en una cuadrícula.",
        "El coeficiente de Moran es una medida local de consistencia de la función.",
        "Desde la perspectiva de la recuperación de información, cada uno de estos espacios de la cuadrícula representaría un documento y los documentos estarían organizados de manera que se encuentren junto a documentos relacionados temáticamente.",
        "Las puntuaciones de recuperación binaria definirían un patrón en esta cuadrícula.",
        "Ten en cuenta que, a medida que el coeficiente de Moran aumenta, las celdas vecinas tienden a tener valores similares.",
        "En esta situación, podemos utilizar la información combinada de estas puntuaciones para construir un sustituto de una clasificación de alta calidad [17].",
        "Podemos tratar la correlación entre la recuperación que nos interesa y las puntuaciones combinadas como un predictor del rendimiento.",
        "Supongamos que se nos dan m funciones de puntuación, yi, para los mismos n documentos.",
        "Representaremos la media de estos vectores como yµ = Σm i=1 yi.",
        "Utilizamos el vector medio como una aproximación a la relevancia.",
        "Dado que utilizamos normalización de media cero y varianza unitaria, el trabajo en metabusqueda sugiere que esta suposición está justificada [15].",
        "Dado que yµ representa una recuperación muy buena, hipotetizamos que una similitud fuerte entre yµ e y correlacionará positivamente con el rendimiento del sistema.",
        "Utilizamos la correlación de Pearson para medir la similitud entre estos vectores, ρ(y, yµ) = yT yµ y 2 yµ 2 (4). Comentaremos sobre la similitud entre la Ecuación 3 y 4 en la Sección 7.",
        "Por supuesto, podemos combinar ρ(y, ˜y) y ρ(y, yµ) si asumimos que capturan diferentes factores en la predicción.",
        "Una forma de lograr esto es combinar estos predictores como variables independientes en una regresión lineal.",
        "Se sugiere un medio alternativo de combinación basado en la forma matemática de nuestros predictores.",
        "Dado que ˜y codifica las dependencias espaciales en y y yµ codifica las propiedades espaciales de las múltiples ejecuciones, podemos calcular una tercera correlación entre estos dos vectores, ρ(˜y, yµ) = ˜yT yµ ˜y 2 yµ 2 (5). Podemos interpretar la Ecuación 5 como la medición de la correlación entre un ranking de alta calidad (yµ) y una versión suavizada espacialmente de la recuperación (˜y). 4.",
        "RELACIÓN CON OTROS PREDICTORES Una forma de predecir la efectividad de una recuperación es observar el vocabulario compartido de los n documentos principales recuperados.",
        "Si calculáramos las palabras de contenido más frecuentes en este conjunto, esperaríamos que fueran coherentes con nuestro tema.",
        "De hecho, podríamos creer que una mala recuperación incluiría documentos sobre muchos temas dispares, lo que resultaría en una superposición de ruido terminológico.",
        "La claridad de una consulta intenta cuantificar exactamente esto [7].",
        "Específicamente, la Claridad mide la similitud de las palabras más frecuentemente utilizadas en los documentos recuperados con aquellas más frecuentemente utilizadas en todo el corpus.",
        "La conjetura es que una buena recuperación utilizará un lenguaje distinto al del texto general; el lenguaje superpuesto en una mala recuperación tenderá a ser más similar al texto general.",
        "Matemáticamente, podemos calcular una representación del lenguaje utilizado en la recuperación inicial como una combinación ponderada de modelos de lenguaje de documentos, P(w|θQ) = Σ i=1 P(w|θi) P(Q|θi) Z (6) donde θi es el modelo de lenguaje del documento clasificado en la posición i, P(Q|θi) es la puntuación de probabilidad de la consulta del documento clasificado en la posición i y Z = Σ i=1 P(Q|θi) es una constante de normalización.",
        "La similitud entre el multinomial P(w|θQ) y un modelo de texto general se puede calcular utilizando la divergencia de Kullback-Leibler, DV KL(θQ θC).",
        "Aquí, la distribución P(w|θC) es nuestro modelo de texto general que puede ser calculado utilizando las frecuencias de términos en el corpus.",
        "En la Figura 2a, presentamos la Claridad como la medida de la distancia entre el centro de masa ponderado de la recuperación (etiquetado como y) y el centro de masa no ponderado de la colección (etiquetado como O).",
        "La claridad alcanza un mínimo cuando una recuperación asigna a cada documento la misma puntuación.",
        "Volvamos a asumir que tenemos un conjunto de n documentos recuperados para nuestra consulta.",
        "Otra forma de cuantificar la dispersión de un conjunto de documentos es observar qué tan agrupados están.",
        "Podemos hipotetizar que una buena recuperación devolverá un único y compacto grupo.",
        "Una recuperación de bajo rendimiento devolverá un conjunto de documentos poco relacionados que abarcan muchos temas.",
        "Un método propuesto para cuantificar esta dispersión es medir la distancia desde un documento aleatorio a su vecino más cercano, b.",
        "Una recuperación que esté estrechamente agrupada, en promedio, tendrá una distancia baja entre a y b; una recuperación que esté menos cerrada tendrá, en promedio, distancias altas entre a y b.",
        "Este promedio corresponde al uso de la estadística de Cox-Lewis para medir la aleatoriedad de los primeros n documentos recuperados de un sistema [18].",
        "En la Figura 2a, esto es aproximadamente equivalente a medir el área del conjunto n. Observa que estamos descartando información sobre la función de recuperación y.",
        "Por lo tanto, la estadística de Cox-Lewis depende en gran medida de la selección de los primeros n documentos. Recuerda que tenemos n documentos y un conjunto de puntuaciones.",
        "Supongamos que tenemos acceso al sistema que proporcionó las puntuaciones originales y que también podemos solicitar puntuaciones para nuevos documentos.",
        "Esto sugiere un tercer método para predecir el rendimiento.",
        "Toma algún documento, a, del conjunto recuperado y agrega o elimina palabras al azar de forma arbitraria para crear un nuevo documento ˜a.",
        "Ahora, podemos pedirle a nuestro sistema que puntúe ˜a con respecto a nuestra consulta.",
        "Si, en promedio, a lo largo de los n documentos, las puntuaciones de a y ˜a tienden a ser muy diferentes, podríamos sospechar que el sistema está fallando en esta consulta.",
        "Los autores han sugerido acoplar la consulta con la medida de distancia [18].",
        "La información introducida por la consulta, sin embargo, es independiente de la recuperación, de modo que, si dos recuperaciones devuelven el mismo conjunto de documentos, la estadística aproximada de Cox-Lewis será la misma independientemente de las puntuaciones de recuperación. yOy (a) Divergencia Global µ(y)˜y y (b) Perturbación de Puntuación µ(y) y (c) Promedio de Múltiples Ejecuciones Figura 2: Representación de varios predictores de rendimiento en una cuadrícula.",
        "En la Figura 2a, representamos los predictores que miden la divergencia entre el centro de masa de una recuperación y el centro del espacio de incrustación.",
        "En la Figura 2b, representamos los predictores que comparan la recuperación original, y, con una versión perturbada de la recuperación, ˜y.",
        "Nuestro enfoque utiliza un tipo particular de perturbación basado en la difusión de puntajes.",
        "Finalmente, en la Figura 2c, representamos la predicción cuando se proporcionan recuperaciones de varios otros sistemas en la misma consulta.",
        "Aquí, podemos considerar la fusión de estas recuperaciones como un sustituto de la relevancia.",
        "Esto se puede lograr ya sea perturbando los documentos o las consultas.",
        "La similitud entre los dos recuperos se puede medir utilizando alguna medida de correlación.",
        "Esto se muestra en la Figura 2b.",
        "La cuadrícula superior representa la recuperación original, y, mientras que la cuadrícula inferior representa la función después de haber sido perturbada, ˜y.",
        "La naturaleza del proceso de perturbación requiere puntuaciones o recuperaciones adicionales.",
        "Nuestro predictor no requiere acceso a la función de puntuación original ni a recuperaciones adicionales.",
        "Por lo tanto, aunque nuestro método es similar a otros métodos de perturbación en espíritu, se puede aplicar en situaciones en las que el sistema de recuperación es inaccesible o costoso de acceder.",
        "Finalmente, supongamos que tenemos, además de la recuperación que queremos evaluar, m recuperaciones de una variedad de sistemas diferentes.",
        "En este caso, podríamos tomar un documento a, comparar su rango en la recuperación con su rango promedio en los m recuperos.",
        "Si creemos que las m recuperaciones proporcionan una aproximación satisfactoria a la relevancia, entonces una diferencia muy grande en el rango sugeriría que nuestra recuperación está clasificando incorrectamente a.",
        "Si esta diferencia es grande en promedio en todos los n documentos, entonces podríamos predecir que la recuperación es mala.",
        "Si, por otro lado, la recuperación es muy consistente con las m recuperaciones, entonces podríamos predecir que la recuperación es buena.",
        "La similitud entre la recuperación y la recuperación combinada puede calcularse utilizando alguna medida de correlación.",
        "Esto se muestra en la Figura 2c.",
        "En trabajos anteriores, la divergencia de Kullback-Leibler entre las puntuaciones normalizadas de la recuperación y las puntuaciones normalizadas de la recuperación combinada proporciona la similitud [1]. 5.",
        "Nuestros experimentos se centran en probar el poder predictivo de cada uno de nuestros predictores: ρ(y, ˜y), ρ(y, yµ) y ρ(˜y, yµ).",
        "Como se indica en la Sección 2, estamos interesados en predecir el rendimiento de la recuperación generada por un sistema arbitrario.",
        "Nuestra metodología es consistente con investigaciones previas en el sentido de que predecimos el rendimiento relativo de una recuperación al comparar una clasificación basada en nuestro predictor con una clasificación basada en la precisión promedio.",
        "Presentamos los resultados de dos conjuntos de experimentos.",
        "El primer conjunto de experimentos presenta comparaciones detalladas de nuestros predictores con predictores previamente propuestos utilizando conjuntos de datos idénticos.",
        "Nuestro segundo conjunto de experimentos demuestra la generalizabilidad de nuestro enfoque a métodos de recuperación arbitrarios, tipos de corpus y lenguajes de corpus. 5.1 Experimentos Detallados En estos experimentos, predeciremos el rendimiento de los puntajes de modelado de lenguaje utilizando nuestro predictor de autocorrelación, ρ(y, ˜y); no consideramos ρ(y, yµ) o ρ(˜y, yµ) porque, en estos experimentos detallados, nos enfocamos en clasificar las recuperaciones de un solo sistema.",
        "Utilizamos recuperaciones, valores de predictores de referencia y medidas de evaluación reportadas en trabajos anteriores [19]. 5.1.1 Temas y Colecciones Estos experimentos de predicción de rendimiento utilizan recuperaciones de modelos de lenguaje realizadas para consultas asociadas con colecciones en las corpora de TREC.",
        "El uso de las colecciones TREC nos permite asociar con confianza una precisión promedio con una recuperación.",
        "En estos experimentos, utilizamos las siguientes colecciones de temas: TREC 4 ad-hoc, TREC 5 ad-hoc, Robust 2004, Terabyte 2004 y Terabyte 2005. 5.1.2 Baselines Proporcionamos dos líneas base.",
        "Nuestro primer punto de referencia es el predictor clásico de Claridad presentado en la Ecuación 6.",
        "La claridad está diseñada para ser utilizada con sistemas de modelado de lenguaje.",
        "Nuestro segundo punto de referencia es el predictor de robustez de clasificación de Zhou y Crofts.",
        "Este predictor corrompe los k documentos principales de la recuperación y vuelve a calcular las puntuaciones del modelo de lenguaje para estos documentos corruptos.",
        "El valor del predictor es la correlación de rangos de Spearman entre la clasificación original y la clasificación corrupta.",
        "En nuestras tablas, etiquetaremos los resultados para Claridad utilizando DV KL y el predictor de robustez de clasificación utilizando P. 5.2 Experimentos de Generalizabilidad Nuestros predictores no requieren un sistema de recuperación base particular; los predictores pueden calcularse para una recuperación arbitraria, independientemente de cómo se generaron los puntajes.",
        "Creemos que ese es uno de los aspectos más atractivos de nuestro algoritmo.",
        "Por lo tanto, en un segundo conjunto de experimentos, demostramos la capacidad de nuestras técnicas para generalizar a una variedad de colecciones, temas y sistemas de recuperación. 5.2.1 Temas y Colecciones Recopilamos un conjunto diverso de colecciones de todos los corpus posibles de TREC.",
        "Lanzamos una red amplia para localizar colecciones donde nuestros predictores podrían fallar.",
        "Nuestra hipótesis es que los documentos con alta similitud temática deberían tener puntuaciones correlacionadas.",
        "Por lo tanto, evitamos las colecciones donde las puntuaciones eran poco probables de estar correlacionadas (por ejemplo, preguntas y respuestas) o donde probablemente estuvieran negativamente correlacionadas (por ejemplo, novedad).",
        "Sin embargo, nuestras colecciones incluyen corpus donde las correlaciones están débilmente justificadas (por ejemplo, corpus no en inglés) o no justificadas en absoluto (por ejemplo, búsqueda de expertos).",
        "Utilizamos las pistas ad-hoc de TREC3-8, TREC Robust 2003-2005, TREC Terabyte 2004-2005, TREC4-5 en español, TREC5-6 en chino y TREC Enterprise Expert Search 2005.",
        "En todos los casos, solo utilizamos las ejecuciones automáticas para las pistas ad-hoc enviadas a NIST.",
        "Para todos los corpus en inglés y español, construimos la matriz W de acuerdo con el proceso descrito en la Sección 3.1.",
        "Para los corpus chinos, utilizamos vectores tf.idf basados en caracteres ingenuos.",
        "Para las entidades, las entradas en W son proporcionales al número de documentos en los que dos entidades coocurren. 5.2.2 Baselines En nuestros experimentos detallados, utilizamos la medida de Claridad como referencia.",
        "Dado que estamos prediciendo el rendimiento de recuperaciones que no se basan en modelado de lenguaje, utilizamos una versión de Claridad conocida como Claridad de lista clasificada [7].",
        "La claridad de la lista clasificada convierte las clasificaciones de documentos en valores P(Q|θi).",
        "Esta conversión comienza reemplazando todas las puntuaciones en y con los rangos respectivos.",
        "Nuestra estimación de P(Q|θi) a partir de los rangos, entonces es, P(Q|θi) = ( 2(c+1−yi) c(c+1) si yi ≤ c 0 en otro caso donde c es un parámetro de corte.",
        "Como sugieren los autores, fijamos los parámetros del algoritmo c y λ2 de manera que c = 60 y λ2 = 0.10.",
        "Utilizamos la Ecuación 6 para estimar P(w|θQ) y DV KL(θQ θC) para calcular el valor del predictor.",
        "Nos referiremos a este predictor como DV KL, con superíndice V para indicar que la divergencia de Kullback-Leibler es con respecto al espacio de incrustación de términos.",
        "Cuando la información de múltiples ejecuciones de la misma consulta está disponible, utilizamos la divergencia multinomial en el espacio de documentos de Aslam y Pavlus como referencia [1].",
        "Este método basado en rangos primero normaliza las puntuaciones en una recuperación como un multinomial n-dimensional.",
        "Al igual que con la Claridad de la lista clasificada, comenzamos reemplazando todas las puntuaciones en y con sus respectivas posiciones.",
        "Luego, ajustamos los elementos de y de la siguiente manera, ˆyi = 1 2n 0 @1 + nX k=yi 1 k 1 A (8) En nuestros experimentos de múltiples ejecuciones, solo utilizamos los 75 documentos principales de cada recuperación (n = 75); esto está dentro del rango de valores de parámetros sugeridos por los autores.",
        "Sin embargo, admitimos no haber ajustado este parámetro ni para nuestro sistema ni para la línea base.",
        "El predictor es la divergencia entre la distribución candidata, y, y la distribución media, yµ.",
        "Con la combinación lineal uniforme de estos m recuperaciones representadas como yµ, podemos calcular la divergencia como Dn KL(ˆy ˆyµ) donde usamos el superíndice n para indicar que la suma es sobre el conjunto de n documentos.",
        "Este punto de referencia fue desarrollado en el contexto de predecir la dificultad de la consulta, pero lo adoptamos como un punto de referencia razonable para predecir el rendimiento de la recuperación. 5.2.3 Configuración de parámetros Cuando se proporcionan múltiples recuperaciones, utilizamos documentos en la unión de los mejores k = 75 documentos de cada una de las m recuperaciones para esa consulta.",
        "Si el tamaño de esta unión es ˜n, entonces yµ y cada yi tiene una longitud de ˜n.",
        "En algunos casos, un sistema no puntuó un documento en la unión.",
        "Dado que estamos haciendo una suposición gaussiana sobre nuestras puntuaciones, podemos muestrear puntuaciones para estos documentos no vistos de la cola negativa de la distribución.",
        "Específicamente, muestreamos de la parte de la distribución inferior al valor mínimo en la recuperación normalizada.",
        "Esto introduce aleatoriedad en nuestro algoritmo, pero creemos que es más apropiado que asignar un valor fijo arbitrario.",
        "Optimizamos la regresión lineal utilizando la raíz cuadrada de cada predictor.",
        "Encontramos que esto mejoró sustancialmente los ajustes para todos los predictores, incluidos los basales.",
        "Consideramos combinaciones lineales de pares de predictores (etiquetados por los componentes) y todos los predictores (etiquetados como β). 5.3 Evaluación Dado un conjunto de recuperaciones, potencialmente de una combinación de consultas y sistemas, medimos la correlación del ordenamiento de rango de este conjunto por el predictor y por la métrica de rendimiento.",
        "Para garantizar la comparabilidad con los resultados anteriores, presentamos la correlación de Kendalls τ entre la clasificación de los predictores y la clasificación basada en la precisión promedio de la recuperación.",
        "A menos que se indique explícitamente, todas las correlaciones son significativas con p < 0.05.",
        "Los predictores a veces pueden tener un mejor rendimiento cuando se combinan linealmente [9, 11].",
        "Aunque trabajos anteriores han presentado el coeficiente de determinación (R2) para medir la calidad de la regresión, esta medida no puede ser utilizada de manera confiable al comparar pequeñas mejoras al combinar predictores.",
        "Por lo tanto, adoptamos el coeficiente de determinación ajustado que penaliza los modelos con más variables.",
        "El R2 ajustado nos permite evaluar la mejora en la predicción lograda al agregar un parámetro pero pierde la interpretación estadística del R2.",
        "Utilizaremos τ de Kendall para evaluar la magnitud de la correlación y R2 ajustado para evaluar la combinación de variables.",
        "RESULTADOS Presentamos los resultados de nuestros experimentos detallados comparando la predicción de puntuaciones de modelos de lenguaje en la Tabla 1.",
        "Aunque la medida de Claridad está teóricamente diseñada para puntuaciones de modelos de lenguaje, consistentemente tiene un rendimiento inferior a nuestro predictor independiente del sistema.",
        "La robustez del ranking se presentó como una mejora a la Claridad para colecciones web (representadas en nuestros experimentos por las colecciones terabyte04 y terabyte05), desplazando la correlación τ de 0.139 a 0.150 para terabyte04 y de 0.171 a 0.208 para terabyte05.",
        "Sin embargo, estas mejoras son leves en comparación con el rendimiento de la autocorrelación en estas colecciones.",
        "Nuestro predictor logra una correlación τ de 0.454 para terabyte04 y 0.383 para terabyte05.",
        "Aunque no siempre es la más fuerte, la autocorrelación logra correlaciones competitivas con los predictores de referencia.",
        "Al examinar el rendimiento de las combinaciones lineales de predictores, observamos que en cada caso, los factores de autocorrelación son un componente necesario de un predictor sólido.",
        "También observamos que el R2 ajustado para las líneas de base individuales siempre mejora significativamente al incorporar la autocorrelación.",
        "Presentamos nuestros resultados de generalizabilidad en la Tabla 2.",
        "Comenzamos examinando la situación en la columna (a) donde se nos presenta una sola recuperación y ninguna información de recuperaciones adicionales.",
        "Para cada colección excepto una, logramos correlaciones significativamente mejores que la claridad de la lista clasificada.",
        "Sorprendentemente, logramos correlaciones relativamente fuertes para las colecciones en español y chino a pesar de nuestro procesamiento ingenuo.",
        "No tenemos una correlación de claridad de lista clasificada para ent05 porque la modelización de entidades es en sí misma una pregunta de investigación abierta.",
        "Sin embargo, nuestra medida de autocorrelación no logra altas correlaciones, quizás porque la relevancia para la recuperación de entidades no se propaga de acuerdo con los enlaces de coocurrencia que utilizamos.",
        "Como se señaló anteriormente, el bajo rendimiento de Claridad en datos web es consistente con nuestros hallazgos en los experimentos detallados.",
        "La claridad también tiene un rendimiento notablemente inferior en varios corpus de noticias (trec5, trec7 y robust04).",
        "Por otro lado, la autocorrelación parece ser robusta a los cambios entre diferentes corpora.",
        "A continuación, pasamos a la introducción de información de múltiples recuperaciones.",
        "Comparamos las correlaciones entre aquellos predictores que no utilizan esta información en la columna (a) y aquellos que sí lo hacen en la columna (b).",
        "Para cada colección, los predictores en la columna (b) superan a los predictores en la columna (a), lo que indica que la información de ejecuciones adicionales puede ser crítica para hacer buenas predicciones.",
        "Inspeccionando los predictores en la columna (b), solo podemos sacar conclusiones débiles.",
        "Nuestros nuevos predictores tienden a tener un mejor rendimiento en corpora de noticias.",
        "Y entre nuestros nuevos predictores, el predictor híbrido ρ(˜y, yµ) tiende a tener un mejor rendimiento.",
        "Recuerde que nuestra medida ρ(˜y, yµ) incorpora tanto información espacial como de múltiples recuperaciones.",
        "Por lo tanto, creemos que la mejora en la correlación es el resultado de incorporar información del comportamiento espacial.",
        "En la columna (c), podemos investigar la utilidad de incorporar información espacial con información de múltiples recuperaciones.",
        "Observa que en los casos donde la autocorrelación, ρ(y, ˜y), por sí sola funciona bien (trec3, trec5-spanish y trec6-chinese), se mejora sustancialmente al incorporar información de múltiples recuperaciones de ρ(y, yµ) en la regresión lineal, β.",
        "En los casos en los que ρ(y, yµ) funciona bien, la incorporación de la autocorrelación rara vez resulta en una mejora significativa en el rendimiento.",
        "De hecho, en cada caso en el que nuestro predictor supera al valor de referencia, incluye información de múltiples ejecuciones. 7.",
        "DISCUSIÓN El resultado más importante de nuestros experimentos implica la predicción cuando no hay información disponible de múltiples ejecuciones (Tablas 1 y 2a).",
        "Esta situación surge a menudo en el diseño de sistemas.",
        "Por ejemplo, un sistema puede necesitar, en el momento de la recuperación, evaluar su rendimiento antes de decidir llevar a cabo un procesamiento más intensivo como la retroalimentación de pseudo relevancia o la interacción.",
        "Suponiendo que la presencia de múltiples recuperaciones es irrealista en este caso.",
        "Creemos que la autocorrelación, al igual que los algoritmos de recuperación múltiple, aproxima un buen ranking; en este caso mediante la difusión de puntajes.",
        "¿Por qué es ˜y un sustituto razonable?",
        "Sabemos que la difusión de puntuaciones en el grafo web y en los grafos de modelos de lenguaje mejora el rendimiento [14, 16].",
        "Por lo tanto, si la difusión de puntuaciones tiende, en general, a mejorar el rendimiento, entonces las puntuaciones difusas proporcionarán, en general, un buen sustituto de la relevancia.",
        "Nuestros resultados demuestran que esta aproximación no es tan potente como la información de múltiples recuperaciones.",
        "Sin embargo, en situaciones donde esta información falta, la autocorrelación proporciona información sustancial.",
        "El éxito de la autocorrelación como predictor también puede tener sus raíces en la hipótesis de agrupamiento.",
        "Recuerde que consideramos la autocorrelación como el grado en que una recuperación satisface la hipótesis de agrupamiento.",
        "Nuestros experimentos, entonces, demuestran que una falta de respeto a la hipótesis de agrupamiento se correlaciona con un bajo rendimiento.",
        "¿Por qué los sistemas podrían no cumplir con la hipótesis del clúster?",
        "Los sistemas de recuperación de información basados en consultas a menudo puntúan los documentos de forma independiente.",
        "El puntaje del documento a puede ser calculado examinando las coincidencias de términos o frases de la consulta, la longitud del documento y quizás las estadísticas globales de la colección.",
        "Una vez calculado, un sistema rara vez compara la puntuación de un documento a con la puntuación de un documento relacionado temáticamente b.",
        "Con algunas excepciones, la correlación de las puntuaciones de los documentos ha sido ampliamente ignorada.",
        "Debemos dejar claro que hemos seleccionado tareas donde la autocorrelación temática es apropiada.",
        "Ciertamente hay casos en los que no hay motivo para creer que las puntuaciones de recuperación tendrán autocorrelación temática.",
        "Por ejemplo, las listas clasificadas que incorporan novedad de documentos no deben mostrar autocorrelación espacial; si acaso, la autocorrelación debería ser negativa para esta tarea.",
        "Del mismo modo, los candidatos de respuestas en una tarea de pregunta-respuesta pueden o no mostrar autocorrelación; en este caso, la semántica de los enlaces también es cuestionable.",
        "Es importante antes de aplicar esta medida confirmar que, dada la semántica para algún enlace entre dos elementos recuperados, deberíamos esperar una correlación entre las puntuaciones. 8.",
        "TRABAJO RELACIONADO En esta sección realizamos comparaciones más generales con otros trabajos en predicción de rendimiento y análisis de datos espaciales.",
        "Existe un creciente cuerpo de trabajo que intenta predecir el rendimiento de recuperaciones individuales [7, 3, 11, 9, 19].",
        "Hemos intentado situar nuestro trabajo en el contexto de gran parte de este trabajo en la Sección 4.",
        "Sin embargo, una comparación completa está fuera del alcance de este documento.",
        "Sin embargo, cabe destacar que nuestros experimentos abarcan un conjunto más amplio y diverso de recuperaciones, colecciones y temas que los examinados previamente.",
        "Gran parte del trabajo previo, especialmente en el contexto de TREC, se centra en predecir el rendimiento de los sistemas.",
        "Aquí, cada sistema genera k recuperaciones.",
        "La tarea consiste en, dadas estas recuperaciones, predecir la clasificación de los sistemas según alguna medida de rendimiento.",
        "Varios artículos intentan abordar esta tarea bajo la restricción de pocas evaluaciones [2, 4].",
        "Algunos trabajos incluso intentan utilizar cero juicios aprovechando múltiples recuperaciones para la misma consulta [17].",
        "Nuestra tarea difiere porque nos enfocamos en clasificar recuperaciones independientemente del sistema generador.",
        "La tarea aquí no es probar que el sistema A es superior al sistema B, sino probar que la recuperación A es superior a la recuperación B. La autocorrelación se manifiesta en muchas tareas de clasificación.",
        "Neville y Jensen definen la autocorrelación relacional para problemas de aprendizaje relacional y demuestran que muchas tareas de clasificación manifiestan autocorrelación [13].",
        "La autocorrelación temporal de las recuperaciones iniciales también se ha utilizado para predecir el rendimiento [9].",
        "Sin embargo, la autocorrelación temporal se realiza proyectando la función de recuperación en el espacio de incrustación temporal.",
        "En nuestro trabajo, nos enfocamos en el comportamiento de la función sobre las relaciones entre documentos. τ ajustado R2 DV KL P ρ(y, ˜y) DV KL P ρ(y, ˜y) DV KL, P DV KL, ρ(y, ˜y) Pρ(y, ˜y) β trec4 0.353 0.548 0.513 0.168 0.363 0.422 0.466 0.420 0.557 0.553 trec5 0.311 0.329 0.357 0.116 0.190 0.236 0.238 0.244 0.266 0.269 robust04 0.418 0.398 0.373 0.256 0.304 0.278 0.403 0.373 0.402 0.442 terabyte04 0.139 0.150 0.454 0.059 0.045 0.292 0.076 0.293 0.289 0.284 terabyte05 0.171 0.208 0.383 0.022 0.072 0.193 0.120 0.225 0.218 0.257 Tabla 1: Comparación de medidas de robustez y claridad para puntuaciones de modelos de lenguaje.",
        "La evaluación replica experimentos de [19].",
        "Presentamos las correlaciones entre la medida clásica de Claridad (DV KL), la medida de robustez de clasificación (P) y la autocorrelación (ρ(y, ˜y)) cada una con la precisión media promedio en términos de τ de Kendall.",
        "El coeficiente de determinación ajustado se presenta para medir la efectividad de combinar predictores.",
        "Las medidas en negrita representan la correlación más fuerte para ese par de prueba/colección. múltiples ejecuciones (a) (b) (c) τ τ ajustado R2 DKL ρ(y, ˜y) Dn KL ρ(y, yµ) ρ(˜y, yµ) Dn KL ρ(y, ˜y) ρ(y, yµ) ρ(˜y, yµ) β trec3 0.201 0.461 0.461 0.439 0.456 0.444 0.395 0.394 0.386 0.498 trec4 0.252 0.396 0.455 0.482 0.489 0.379 0.263 0.429 0.482 0.483 trec5 0.016 0.277 0.433 0.459 0.393 0.280 0.157 0.375 0.323 0.386 trec6 0.230 0.227 0.352 0.428 0.418 0.203 0.089 0.323 0.325 0.325 trec7 0.083 0.326 0.341 0.430 0.483 0.264 0.182 0.363 0.442 0.400 trec8 0.235 0.396 0.454 0.508 0.567 0.402 0.272 0.490 0.580 0.523 robust03 0.302 0.354 0.377 0.385 0.447 0.269 0.206 0.274 0.392 0.303 robust04 0.183 0.308 0.301 0.384 0.453 0.200 0.182 0.301 0.393 0.335 robust05 0.224 0.249 0.371 0.377 0.404 0.341 0.108 0.313 0.328 0.336 terabyte04 0.043 0.245 0.544 0.420 0.392 0.516 0.105 0.357 0.343 0.365 terabyte05 0.068 0.306 0.480 0.434 0.390 0.491 0.168 0.384 0.309 0.403 trec4-spanish 0.307 0.388 0.488 0.398 0.395 0.423 0.299 0.282 0.299 0.388 trec5-spanish 0.220 0.458 0.446 0.484 0.475 0.411 0.398 0.428 0.437 0.529 trec5-chinese 0.092 0.199 0.367 0.379 0.384 0.379 0.199 0.273 0.276 0.310 trec6-chinese 0.144 0.276 0.265 0.353 0.376 0.115 0.128 0.188 0.223 0.199 ent05 - 0.181 0.324 0.305 0.282 0.211 0.043 0.158 0.155 0.179 Tabla 2: Experimentos de predicción a gran escala.",
        "Predecimos la clasificación de grandes conjuntos de recuperaciones para varias colecciones y sistemas de recuperación.",
        "Las correlaciones de τ de Kendall se calculan entre la clasificación predicha y una clasificación basada en la precisión promedio de las recuperaciones.",
        "En la columna (a), tenemos predictores que no utilizan información de otras recuperaciones para la misma consulta.",
        "En las columnas (b) y (c) presentamos el rendimiento de los predictores que incorporan información de múltiples recuperaciones.",
        "El coeficiente de determinación ajustado se calcula para determinar la efectividad de combinar predictores.",
        "Las medidas en negrita representan la correlación más fuerte para ese par de prueba/colección.",
        "Finalmente, los procesos de reordenamiento basados en regularización también están estrechamente relacionados con nuestro trabajo [8].",
        "Estas técnicas buscan maximizar el acuerdo entre las puntuaciones de documentos relacionados al resolver un problema de optimización restringida.",
        "La maximización de la consistencia es equivalente a maximizar la autocorrelación de Moran.",
        "Por lo tanto, creemos que nuestro trabajo proporciona una explicación de por qué funciona el reordenamiento basado en regularización. 9.",
        "CONCLUSIÓN Hemos presentado un nuevo método para predecir el rendimiento de un ranking de recuperación sin necesidad de juicios de relevancia.",
        "Consideramos dos casos.",
        "Primero, al hacer predicciones en ausencia de recuperaciones de otros sistemas, nuestros predictores muestran correlaciones sólidas y robustas con la precisión promedio.",
        "Esta actuación, combinada con una implementación sencilla, hace que nuestros predictores, en particular, sean muy atractivos.",
        "Hemos demostrado esta mejora en muchos entornos diversos.",
        "Según nuestro conocimiento, esta es la primera evaluación a gran escala de la predicción del rendimiento de una sola recuperación sin juicio.",
        "Segundo, cuando se proporcionan recuperaciones de otros sistemas, nuestros métodos ampliados demuestran un rendimiento competitivo con las líneas de base de vanguardia.",
        "Nuestros experimentos también demuestran los límites de la utilidad de nuestros predictores cuando se proporciona información de múltiples ejecuciones.",
        "Nuestros resultados sugieren dos conclusiones.",
        "Primero, nuestros resultados podrían afectar el diseño de algoritmos de recuperación.",
        "Los algoritmos de recuperación diseñados para considerar la autocorrelación espacial se ajustarán a la hipótesis de agrupamiento y mejorarán el rendimiento.",
        "Segundo, nuestros resultados podrían afectar el diseño de algoritmos de colección de pruebas mínimas.",
        "Gran parte del trabajo reciente en sistemas de clasificación a veces ignora las correlaciones entre las etiquetas de los documentos y las puntuaciones.",
        "Creemos que estas dos direcciones podrían ser gratificantes dadas las pruebas teóricas y experimentales en este documento. 10.",
        "AGRADECIMIENTOS Este trabajo fue apoyado en parte por el Centro de Recuperación de Información Inteligente y en parte por la Agencia de Proyectos de Investigación Avanzada de Defensa (DARPA) bajo el número de contrato HR0011-06-C-0023.",
        "Cualquier opinión, hallazgo y conclusión o recomendación expresada en este material son del autor y no necesariamente reflejan las del patrocinador.",
        "Agradecemos a Yun Zhou y Desislava Petkova por proporcionar los datos y a Andre Gauthier por la asistencia técnica. 11.",
        "REFERENCIAS [1] J. Aslam y V. Pavlu.",
        "Estimación de la dificultad de la consulta utilizando la divergencia de Jensen-Shannon entre múltiples funciones de puntuación.",
        "En ECIR 2007: Actas de la 29ª Conferencia Europea sobre Recuperación de Información, 2007. [2] J.",
        "A. Aslam, V. Pavlu y E. Yilmaz.",
        "Un método estadístico para la evaluación de sistemas utilizando juicios incompletos.",
        "En S. Dumais, E. N. Efthimiadis, D. Hawking y K. Jarvelin, editores, Actas de la 29ª Conferencia Internacional Anual de ACM SIGIR sobre Investigación y Desarrollo en Recuperación de Información, páginas 541-548.",
        "ACM Press, agosto de 2006. [3] D. Carmel, E. Yom-Tov, A. Darlow y D. Pelleg.",
        "¿Qué hace que una consulta sea difícil?",
        "En SIGIR 06: Actas de la 29ª conferencia internacional anual de ACM SIGIR sobre investigación y desarrollo en recuperación de información, páginas 390-397, Nueva York, NY, EE. UU., 2006.",
        "ACM Press. [4] B. Carterette, J. Allan y R. Sitaraman.",
        "Colecciones de prueba mínimas para evaluación de recuperación.",
        "En SIGIR 06: Actas de la 29ª conferencia internacional anual de ACM SIGIR sobre investigación y desarrollo en recuperación de información, páginas 268-275, Nueva York, NY, EE. UU., 2006.",
        "ACM Press. [5] A. D. Cliff y J. K. Ord.",
        "Autocorrelación espacial.",
        "Pion Ltd., 1973. [6] M. Connell, A. Feng, G. Kumaran, H. Raghavan, C. Shah y J. Allan.",
        "Umass en tdt 2004.",
        "Informe técnico CIIR Informe técnico IR - 357, Departamento de Ciencias de la Computación, Universidad de Massachusetts, 2004. [7] S. Cronen-Townsend, Y. Zhou y W. B. Croft.",
        "Predicción de precisión basada en la coherencia de la lista clasificada.",
        "I'm sorry, but the sentence \"Inf.\" is not a complete sentence. Could you please provide more context or a full sentence for me to translate to Spanish?",
        "Rev., 9(6):723-755, 2006. [8] F. Diaz.",
        "Normalizando las puntuaciones de recuperación ad-hoc.",
        "En CIKM 05: Actas de la 14ª conferencia internacional de ACM sobre gestión de la información y el conocimiento, páginas 672-679, Nueva York, NY, EE. UU., 2005.",
        "ACM Press. [9] F. Diaz y R. Jones.",
        "Utilizando perfiles temporales de consultas para predecir la precisión.",
        "En SIGIR 04: Actas de la 27ª conferencia internacional anual de ACM SIGIR sobre investigación y desarrollo en recuperación de información, páginas 18-24, Nueva York, NY, EE. UU., 2004.",
        "ACM Press. [10] D. A. Griffith. \n\nACM Press. [10] D. A. Griffith.",
        "Autocorrelación espacial y filtrado espacial.",
        "Springer Verlag, 2003. [11] B. \n\nSpringer Verlag, 2003. [11] B.",
        "Él y yo. Ounis.",
        "Inferir el rendimiento de la consulta utilizando predictores previos a la recuperación.",
        "En el Undécimo Simposio sobre Procesamiento de Cadenas y Recuperación de Información (SPIRE), 2004. [12] N. Jardine y C. J. V. Rijsbergen.",
        "El uso de agrupamiento jerárquico en la recuperación de información.",
        "Almacenamiento y recuperación de información, 7:217-240, 1971. [13] D. Jensen y J. Neville.",
        "El enlace y la autocorrelación causan sesgo en la selección de características en el aprendizaje relacional.",
        "En ICML 02: Actas de la Decimonovena Conferencia Internacional sobre Aprendizaje Automático, páginas 259-266, San Francisco, CA, EE. UU., 2002.",
        "Morgan Kaufmann Publishers Inc. [14] O. Kurland y L. Lee.",
        "Estructura del corpus, modelos de lenguaje y recuperación de información ad-hoc.",
        "En SIGIR 04: Actas de la 27ª conferencia internacional anual sobre investigación y desarrollo en recuperación de información, páginas 194-201, Nueva York, NY, EE. UU., 2004.",
        "ACM Press. [15] M. Montague y J.",
        "A. Aslam.",
        "Normalización de la puntuación de relevancia para metabusqueda.",
        "En CIKM 01: Actas de la décima conferencia internacional sobre gestión de la información y el conocimiento, páginas 427-433, Nueva York, NY, EE. UU., 2001.",
        "ACM Press. [16] T. Qin, T.-Y.",
        "Liu, X.-D. Zhang, Z. Chen y W.-Y.",
        "I'm sorry, but \"Ma.\" is not a complete sentence. Could you please provide more context or a complete sentence for me to translate into Spanish?",
        "Un estudio de propagación de relevancia para la búsqueda en la web.",
        "En SIGIR 05: Actas de la 28ª conferencia internacional anual de ACM SIGIR sobre investigación y desarrollo en recuperación de información, páginas 408-415, Nueva York, NY, EE. UU., 2005.",
        "ACM Press. [17] I. Soboroff, C. Nicholas y P. Cahan.",
        "Sistemas de recuperación de clasificación sin juicios de relevancia.",
        "En SIGIR 01: Actas de la 24ª conferencia internacional anual de ACM SIGIR sobre investigación y desarrollo en recuperación de información, páginas 66-73, Nueva York, NY, EE. UU., 2001.",
        "ACM Press. [18] V. Vinay, I. J. Cox, N. Milic-Frayling y K. Wood.",
        "Sobre la clasificación de la efectividad de las búsquedas.",
        "En SIGIR 06: Actas de la 29ª conferencia internacional anual de ACM SIGIR sobre investigación y desarrollo en recuperación de información, páginas 398-404, Nueva York, NY, EE. UU., 2006.",
        "ACM Press. [19] Y. Zhou y W. B. Croft.",
        "Robustez del ranking: un nuevo marco para predecir el rendimiento de la consulta.",
        "En CIKM 06: Actas de la 15ª conferencia internacional de ACM sobre gestión de la información y el conocimiento, páginas 567-574, Nueva York, NY, EE. UU., 2006.",
        "ACM Press."
    ],
    "error_count": 5,
    "keys": {
        "performance prediction": {
            "translated_key": "predicción de rendimiento",
            "is_in_text": true,
            "original_annotated_sentences": [
                "<br>performance prediction</br> Using Spatial Autocorrelation Fernando Diaz Center for Intelligent Information Retrieval Department of Computer Science University of Massachusetts Amherst, MA 01003 fdiaz@cs.umass.edu ABSTRACT Evaluation of information retrieval systems is one of the core tasks in information retrieval.",
                "Problems include the inability to exhaustively label all documents for a topic, nongeneralizability from a small number of topics, and incorporating the variability of retrieval systems.",
                "Previous work addresses the evaluation of systems, the ranking of queries by difficulty, and the ranking of individual retrievals by performance.",
                "Approaches exist for the case of few and even no relevance judgments.",
                "Our focus is on zero-judgment <br>performance prediction</br> of individual retrievals.",
                "One common shortcoming of previous techniques is the assumption of uncorrelated document scores and judgments.",
                "If documents are embedded in a high-dimensional space (as they often are), we can apply techniques from spatial data analysis to detect correlations between document scores.",
                "We find that the low correlation between scores of topically close documents often implies a poor retrieval performance.",
                "When compared to a state of the art baseline, we demonstrate that the spatial analysis of retrieval scores provides significantly better prediction performance.",
                "These new predictors can also be incorporated with classic predictors to improve performance further.",
                "We also describe the first large-scale experiment to evaluate zero-judgment <br>performance prediction</br> for a massive number of retrieval systems over a variety of collections in several languages.",
                "Categories and Subject Descriptors H.3.3 [Information Search and Retrieval]: Retrieval models; H.3.4 [Systems and Software]: Performance evaluation (efficiency and effectiveness) General Terms Performance, Design, Reliability, Experimentation 1.",
                "INTRODUCTION In information retrieval, a user poses a query to a system.",
                "The system retrieves n documents each receiving a realvalued score indicating the predicted degree of relevance.",
                "If we randomly select pairs of documents from this set, we expect some pairs to share the same topic and other pairs to not share the same topic.",
                "Take two topically-related documents from the set and call them a and b.",
                "If the scores of a and b are very different, we may be concerned about the performance of our system.",
                "That is, if a and b are both on the topic of the query, we would like them both to receive a high score; if a and b are not on the topic of the query, we would like them both to receive a low score.",
                "We might become more worried as we find more differences between scores of related documents.",
                "We would be more comfortable with a retrieval where scores are consistent between related documents.",
                "Our paper studies the quantification of this inconsistency in a retrieval from a spatial perspective.",
                "Spatial analysis is appropriate since many retrieval models embed documents in some vector space.",
                "If documents are embedded in a space, proximity correlates with topical relationships.",
                "Score consistency can be measured by the spatial version of autocorrelation known as the Moran coefficient or IM [5, 10].",
                "In this paper, we demonstrate a strong correlation between IM and retrieval performance.",
                "The discussion up to this point is reminiscent of the cluster hypothesis.",
                "The cluster hypothesis states: closely-related documents tend to be relevant to the same request [12].",
                "As we shall see, a retrieval functions spatial autocorrelation measures the degree to which closely-related documents receive similar scores.",
                "Because of this, we interpret autocorrelation as measuring the degree to which a retrieval function satisfies the clustering hypothesis.",
                "If this connection is reasonable, in Section 6, we present evidence that failure to satisfy the cluster hypothesis correlates strongly with poor performance.",
                "In this work, we provide the following contributions, 1.",
                "A general, robust method for predicting the performance of retrievals with zero relevance judgments (Section 3). 2.",
                "A theoretical treatment of the similarities and motivations behind several state-of-the-art <br>performance prediction</br> techniques (Section 4). 3.",
                "The first large-scale experiments of zero-judgment, single run <br>performance prediction</br> (Sections 5 and 6). 2.",
                "PROBLEM DEFINITION Given a query, an information retrieval system produces a ranking of documents in the collection encoded as a set of scores associated with documents.",
                "We refer to the set of scores for a particular query-system combination as a retrieval.",
                "We would like to predict the performance of this retrieval with respect to some evaluation measure (eg, mean average precision).",
                "In this paper, we present results for ranking retrievals from arbitrary systems.",
                "We would like this ranking to approximate the ranking of retrievals by the evaluation measure.",
                "This is different from ranking queries by the average performance on each query.",
                "It is also different from ranking systems by the average performance on a set of queries.",
                "Scores are often only computed for the top n documents from the collection.",
                "We place these scores in the length n vector, y, where yi refers to the score of the ith-ranked document.",
                "We adjust scores to have zero mean and unit variance.",
                "We use this method because of its simplicity and its success in previous work [15]. 3.",
                "SPATIAL CORRELATION In information retrieval, we often assume that the representations of documents exist in some high-dimensional vector space.",
                "For example, given a vocabulary, V, this vector space may be an arbitrary |V|-dimensional space with cosine inner-product or a multinomial simplex with a distributionbased distance measure.",
                "An embedding space is often selected to respect topical proximity; if two documents are near, they are more likely to share a topic.",
                "Because of the prevalence and success of spatial models of information retrieval, we believe that the application of spatial data analysis techniques are appropriate.",
                "Whereas in information retrieval, we are concerned with the score at a point in a space, in spatial data analysis, we are concerned with the value of a function at a point or location in a space.",
                "We use the term function here to mean a mapping from a location to a real value.",
                "For example, we might be interested in the prevalence of a disease in the neighborhood of some city.",
                "The function would map the location of a neighborhood to an infection rate.",
                "If we want to quantify the spatial dependencies of a function, we would employ a measure referred to as the spatial autocorrelation [5, 10].",
                "High spatial autocorrelation suggests that knowing the value of a function at location a will tell us a great deal about the value at a neighboring location b.",
                "There is a high spatial autocorrelation for a function representing the temperature of a location since knowing the temperature at a location a will tell us a lot about the temperature at a neighboring location b.",
                "Low spatial autocorrelation suggests that knowing the value of a function at location a tells us little about the value at a neighboring location b.",
                "There is low spatial autocorrelation in a function measuring the outcome of a coin toss at a and b.",
                "In this section, we will begin by describing what we mean by spatial proximity for documents and then define a measure of spatial autocorrelation.",
                "We conclude by extending this model to include information from multiple retrievals from multiple systems for a single query. 3.1 Spatial Representation of Documents Our work does not focus on improving a specific similarity measure or defining a novel vector space.",
                "Instead, we choose an inner product known to be effective at detecting interdocument topical relationships.",
                "Specifically, we adopt tf.idf document vectors, ˜di = di log „ (n + 0.5) − ci 0.5 + ci « (1) where d is a vector of term frequencies, c is the length-|V| document frequency vector.",
                "We use this weighting scheme due to its success for topical link detection in the context of Topic Detection and Tracking (TDT) evaluations [6].",
                "Assuming vectors are scaled by their L2 norm, we use the inner product, ˜di, ˜dj , to define similarity.",
                "Given documents and some similarity measure, we can construct a matrix which encodes the similarity between pairs of documents.",
                "Recall that we are given the top n documents retrieved in y.",
                "We can compute an n × n similarity matrix, W. An element of this matrix, Wij represents the similarity between documents ranked i and j.",
                "In practice, we only include the affinities for a documents k-nearest neighbors.",
                "In all of our experiments, we have fixed k to 5.",
                "We leave exploration of parameter sensitivity to future work.",
                "We also row normalize the matrix so that Pn j=1 Wij = 1 for all i. 3.2 Spatial Autocorrelation of a Retrieval Recall that we are interested in measuring the similarity between the scores of spatially-close documents.",
                "One such suitable measure is the Moran coefficient of spatial autocorrelation.",
                "Assuming the function y over n locations, this is defined as ˜IM = n eTWe P i,j Wijyiyj P i y2 i = n eTWe yT Wy yTy (2) where eT We = P ij Wij.",
                "We would like to compare autocorrelation values for different retrievals.",
                "Unfortunately, the bound for Equation 2 is not consistent for different W and y.",
                "Therefore, we use the Cauchy-Schwartz inequality to establish a bound, ˜IM ≤ n eTWe s yTWTWy yTy And we define the normalized spatial autocorrelation as IM = yT Wy p yTy × yTWTWy Notice that if we let ˜y = Wy, then we can write this formula as, IM = yT ˜y y 2 ˜y 2 (3) which can be interpreted as the correlation between the original retrieval scores and a set of retrieval scores diffused in the space.",
                "We present some examples of autocorrelations of functions on a grid in Figure 1. 3.3 Correlation with Other Retrievals Sometimes we are interested in the performance of a single retrieval but have access to scores from multiple systems for (a) IM = 0.006 (b) IM = 0.241 (c) IM = 0.487 Figure 1: The Moran coefficient, IM for a several binary functions on a grid.",
                "The Moran coefficient is a local measure of function consistency.",
                "From the perspective of information retrieval, each of these grid spaces would represent a document and documents would be organized so that they lay next to topically-related documents.",
                "Binary retrieval scores would define a pattern on this grid.",
                "Notice that, as the Moran coefficient increases, neighboring cells tend to have similar values. the same query.",
                "In this situation, we can use combined information from these scores to construct a surrogate for a high-quality ranking [17].",
                "We can treat the correlation between the retrieval we are interested in and the combined scores as a predictor of performance.",
                "Assume that we are given m score functions, yi, for the same n documents.",
                "We will represent the mean of these vectors as yµ = Pm i=1 yi.",
                "We use the mean vector as an approximation to relevance.",
                "Since we use zero mean and unit variance normalization, work in metasearch suggests that this assumption is justified [15].",
                "Because yµ represents a very good retrieval, we hypothesize that a strong similarity between yµ and y will correlate positively with system performance.",
                "We use Pearsons product-moment correlation to measure the similarity between these vectors, ρ(y, yµ) = yT yµ y 2 yµ 2 (4) We will comment on the similarity between Equation 3 and 4 in Section 7.",
                "Of course, we can combine ρ(y, ˜y) and ρ(y, yµ) if we assume that they capture different factors in the prediction.",
                "One way to accomplish this is to combine these predictors as independent variables in a linear regression.",
                "An alternative means of combination is suggested by the mathematical form of our predictors.",
                "Since ˜y encodes the spatial dependencies in y and yµ encodes the spatial properties of the multiple runs, we can compute a third correlation between these two vectors, ρ(˜y, yµ) = ˜yT yµ ˜y 2 yµ 2 (5) We can interpret Equation 5 as measuring the correlation between a high quality ranking (yµ) and a spatially smoothed version of the retrieval (˜y). 4.",
                "RELATIONSHIP WITH OTHER PREDICTORS One way to predict the effectiveness of a retrieval is to look at the shared vocabulary of the top n retrieved documents.",
                "If we computed the most frequent content words in this set, we would hope that they would be consistent with our topic.",
                "In fact, we might believe that a bad retrieval would include documents on many disparate topics, resulting in an overlap of terminological noise.",
                "The Clarity of a query attempts to quantify exactly this [7].",
                "Specifically, Clarity measures the similarity of the words most frequently used in retrieved documents to those most frequently used in the whole corpus.",
                "The conjecture is that a good retrieval will use language distinct from general text; the overlapping language in a bad retrieval will tend to be more similar to general text.",
                "Mathematically, we can compute a representation of the language used in the initial retrieval as a weighted combination of document language models, P(w|θQ) = nX i=1 P(w|θi) P(Q|θi) Z (6) where θi is the language model of the ith-ranked document, P(Q|θi) is the query likelihood score of the ith-ranked document and Z = Pn i=1 P(Q|θi) is a normalization constant.",
                "The similarity between the multinomial P(w|θQ) and a model of general text can be computed using the Kullback-Leibler divergence, DV KL(θQ θC ).",
                "Here, the distribution P(w|θC ) is our model of general text which can be computed using term frequencies in the corpus.",
                "In Figure 2a, we present Clarity as measuring the distance between the weighted center of mass of the retrieval (labeled y) and the unweighted center of mass of the collection (labeled O).",
                "Clarity reaches a minimum when a retrieval assigns every document the same score.",
                "Lets again assume we have a set of n documents retrieved for our query.",
                "Another way to quantify the dispersion of a set of documents is to look at how clustered they are.",
                "We may hypothesize that a good retrieval will return a single, tight cluster.",
                "A poorly performing retrieval will return a loosely related set of documents covering many topics.",
                "One proposed method of quantifying this dispersion is to measure the distance from a random document a to its nearest neighbor, b.",
                "A retrieval which is tightly clustered will, on average, have a low distance between a and b; a retrieval which is less tightly-closed will, on average have high distances between a and b.",
                "This average corresponds to using the Cox-Lewis statistic to measure the randomness of the top n documents retrieved from a system [18].",
                "In Figure 2a, this is roughly equivalent to measuring the area of the set n. Notice that we are throwing away information about the retrieval function y.",
                "Therefore the Cox-Lewis statistic is highly dependent on selecting the top n documents.1 Remember that we have n documents and a set of scores.",
                "Lets assume that we have access to the system which provided the original scores and that we can also request scores for new documents.",
                "This suggests a third method for predicting performance.",
                "Take some document, a, from the retrieved set and arbitrarily add or remove words at random to create a new document ˜a.",
                "Now, we can ask our system to score ˜a with respect to our query.",
                "If, on average over the n documents, the scores of a and ˜a tend to be very different, we might suspect that the system is failing on this query.",
                "So, an alternative approach is to measure the simi1 The authors have suggested coupling the query with the distance measure [18].",
                "The information introduced by the query, though, is retrieval-independent so that, if two retrievals return the same set of documents, the approximate Cox-Lewis statistic will be the same regardless of the retrieval scores. yOy (a) Global Divergence µ(y)˜y y (b) Score Perturbation µ(y) y (c) Multirun Averaging Figure 2: Representation of several performance predictors on a grid.",
                "In Figure 2a, we depict predictors which measure the divergence between the center of mass of a retrieval and the center of the embedding space.",
                "In Figure 2b, we depict predictors which compare the original retrieval, y, to a perturbed version of the retrieval, ˜y.",
                "Our approach uses a particular type of perturbation based on score diffusion.",
                "Finally, in Figure 2c, we depict prediction when given retrievals from several other systems on the same query.",
                "Here, we can consider the fusion of these retrieval as a surrogate for relevance. larity between the retrieval and a perturbed version of that retrieval [18, 19].",
                "This can be accomplished by either perturbing the documents or queries.",
                "The similarity between the two retrievals can be measured using some correlation measure.",
                "This is depicted in Figure 2b.",
                "The upper grid represents the original retrieval, y, while the lower grid represents the function after having been perturbed, ˜y.",
                "The nature of the perturbation process requires additional scorings or retrievals.",
                "Our predictor does not require access to the original scoring function or additional retrievals.",
                "So, although our method is similar to other perturbation methods in spirit, it can be applied in situations when the retrieval system is inaccessible or costly to access.",
                "Finally, assume that we have, in addition to the retrieval we want to evaluate, m retrievals from a variety of different systems.",
                "In this case, we might take a document a, compare its rank in the retrieval to its average rank in the m retrievals.",
                "If we believe that the m retrievals provide a satisfactory approximation to relevance, then a very large difference in rank would suggest that our retrieval is misranking a.",
                "If this difference is large on average over all n documents, then we might predict that the retrieval is bad.",
                "If, on the other hand, the retrieval is very consistent with the m retrievals, then we might predict that the retrieval is good.",
                "The similarity between the retrieval and the combined retrieval may be computed using some correlation measure.",
                "This is depicted in Figure 2c.",
                "In previous work, the Kullback-Leibler divergence between the normalized scores of the retrieval and the normalized scores of the combined retrieval provides the similarity [1]. 5.",
                "EXPERIMENTS Our experiments focus on testing the predictive power of each of our predictors: ρ(y, ˜y), ρ(y, yµ), and ρ(˜y, yµ).",
                "As stated in Section 2, we are interested in predicting the performance of the retrieval generated by an arbitrary system.",
                "Our methodology is consistent with previous research in that we predict the relative performance of a retrieval by comparing a ranking based on our predictor to a ranking based on average precision.",
                "We present results for two sets of experiments.",
                "The first set of experiments presents detailed comparisons of our predictors to previously-proposed predictors using identical data sets.",
                "Our second set of experiments demonstrates the generalizability of our approach to arbitrary retrieval methods, corpus types, and corpus languages. 5.1 Detailed Experiments In these experiments, we will predict the performance of language modeling scores using our autocorrelation predictor, ρ(y, ˜y); we do not consider ρ(y, yµ) or ρ(˜y, yµ) because, in these detailed experiments, we focus on ranking the retrievals from a single system.",
                "We use retrievals, values for baseline predictors, and evaluation measures reported in previous work [19]. 5.1.1 Topics and Collections These <br>performance prediction</br> experiments use language model retrievals performed for queries associated with collections in the TREC corpora.",
                "Using TREC collections allows us to confidently associate an average precision with a retrieval.",
                "In these experiments, we use the following topic collections: TREC 4 ad-hoc, TREC 5 ad-hoc, Robust 2004, Terabyte 2004, and Terabyte 2005. 5.1.2 Baselines We provide two baselines.",
                "Our first baseline is the classic Clarity predictor presented in Equation 6.",
                "Clarity is designed to be used with language modeling systems.",
                "Our second baseline is Zhou and Crofts ranking robustness predictor.",
                "This predictor corrupts the top k documents from retrieval and re-computes the language model scores for these corrupted documents.",
                "The value of the predictor is the Spearman rank correlation between the original ranking and the corrupted ranking.",
                "In our tables, we will label results for Clarity using DV KL and the ranking robustness predictor using P. 5.2 Generalizability Experiments Our predictors do not require a particular baseline retrieval system; the predictors can be computed for an arbitrary retrieval, regardless of how scores were generated.",
                "We believe that that is one of the most attractive aspects of our algorithm.",
                "Therefore, in a second set of experiments, we demonstrate the ability of our techniques to generalize to a variety of collections, topics, and retrieval systems. 5.2.1 Topics and Collections We gathered a diverse set of collections from all possible TREC corpora.",
                "We cast a wide net in order to locate collections where our predictors might fail.",
                "Our hypothesis is that documents with high topical similarity should have correlated scores.",
                "Therefore, we avoided collections where scores were unlikely to be correlated (eg, question-answering) or were likely to be negatively correlated (eg, novelty).",
                "Nevertheless, our collections include corpora where correlations are weakly justified (eg, non-English corpora) or not justified at all (eg, expert search).",
                "We use the ad-hoc tracks from TREC3-8, TREC Robust 2003-2005, TREC Terabyte 20042005, TREC4-5 Spanish, TREC5-6 Chinese, and TREC Enterprise Expert Search 2005.",
                "In all cases, we use only the automatic runs for ad-hoc tracks submitted to NIST.",
                "For all English and Spanish corpora, we construct the matrix W according to the process described in Section 3.1.",
                "For Chinese corpora, we use na¨ıve character-based tf.idf vectors.",
                "For entities, entries in W are proportional to the number of documents in which two entities cooccur. 5.2.2 Baselines In our detailed experiments, we used the Clarity measure as a baseline.",
                "Since we are predicting the performance of retrievals which are not based on language modeling, we use a version of Clarity referred to as ranked-list Clarity [7].",
                "Ranked-list clarity converts document ranks to P(Q|θi) values.",
                "This conversion begins by replacing all of the scores in y with the respective ranks.",
                "Our estimation of P(Q|θi) from the ranks, then is, P(Q|θi) = ( 2(c+1−yi) c(c+1) if yi ≤ c 0 otherwise (7) where c is a cutoff parameter.",
                "As suggested by the authors, we fix the algorithm parameters c and λ2 so that c = 60 and λ2 = 0.10.",
                "We use Equation 6 to estimate P(w|θQ) and DV KL(θQ θC ) to compute the value of the predictor.",
                "We will refer to this predictor as DV KL, superscripted by V to indicate that the Kullback-Leibler divergence is with respect to the term embedding space.",
                "When information from multiple runs on the same query is available, we use Aslam and Pavlus document-space multinomial divergence as a baseline [1].",
                "This rank-based method first normalizes the scores in a retrieval as an n-dimensional multinomial.",
                "As with ranked-list Clarity, we begin by replacing all of the scores in y with their respective ranks.",
                "Then, we adjust the elements of y in the following way, ˆyi = 1 2n 0 @1 + nX k=yi 1 k 1 A (8) In our multirun experiments, we only use the top 75 documents from each retrieval (n = 75); this is within the range of parameter values suggested by the authors.",
                "However, we admit not tuning this parameter for either our system or the baseline.",
                "The predictor is the divergence between the candidate distribution, y, and the mean distribution, yµ .",
                "With the uniform linear combination of these m retrievals represented as yµ, we can compute the divergence as Dn KL(ˆy ˆyµ) where we use the superscript n to indicate that the summation is over the set of n documents.",
                "This baseline was developed in the context of predicting query difficulty but we adopt it as a reasonable baseline for predicting retrieval performance. 5.2.3 Parameter Settings When given multiple retrievals, we use documents in the union of the top k = 75 documents from each of the m retrievals for that query.",
                "If the size of this union is ˜n, then yµ and each yi is of length ˜n.",
                "In some cases, a system did not score a document in the union.",
                "Since we are making a Gaussian assumption about our scores, we can sample scores for these unseen documents from the negative tail of the distribution.",
                "Specifically, we sample from the part of the distribution lower than the minimum value of in the normalized retrieval.",
                "This introduces randomness into our algorithm but we believe it is more appropriate than assigning an arbitrary fixed value.",
                "We optimized the linear regression using the square root of each predictor.",
                "We found that this substantially improved fits for all predictors, including the baselines.",
                "We considered linear combinations of pairs of predictors (labeled by the components) and all predictors (labeled as β). 5.3 Evaluation Given a set of retrievals, potentially from a combination of queries and systems, we measure the correlation of the rank ordering of this set by the predictor and by the performance metric.",
                "In order to ensure comparability with previous results, we present Kendalls τ correlation between the predictors ranking and ranking based on average precision of the retrieval.",
                "Unless explicitly noted, all correlations are significant with p < 0.05.",
                "Predictors can sometimes perform better when linearly combined [9, 11].",
                "Although previous work has presented the coefficient of determination (R2 ) to measure the quality of the regression, this measure cannot be reliably used when comparing slight improvements from combining predictors.",
                "Therefore, we adopt the adjusted coefficient of determination which penalizes models with more variables.",
                "The adjusted R2 allows us to evaluate the improvement in prediction achieved by adding a parameter but loses the statistical interpretation of R2 .",
                "We will use Kendalls τ to evaluate the magnitude of the correlation and the adjusted R2 to evaluate the combination of variables. 6.",
                "RESULTS We present results for our detailed experiments comparing the prediction of language model scores in Table 1.",
                "Although the Clarity measure is theoretically designed for language model scores, it consistently underperforms our system-agnostic predictor.",
                "Ranking robustness was presented as an improvement to Clarity for web collections (represented in our experiments by the terabyte04 and terabyte05 collections), shifting the τ correlation from 0.139 to 0.150 for terabyte04 and 0.171 to 0.208 for terabyte05.",
                "However, these improvements are slight compared to the performance of autocorrelation on these collections.",
                "Our predictor achieves a τ correlation of 0.454 for terabyte04 and 0.383 for terabyte05.",
                "Though not always the strongest, autocorrelation achieves correlations competitive with baseline predictors.",
                "When examining the performance of linear combinations of predictors, we note that in every case, autocorrelation factors as a necessary component of a strong predictor.",
                "We also note that the adjusted R2 for individual baselines are always significantly improved by incorporating autocorrelation.",
                "We present our generalizability results in Table 2.",
                "We begin by examining the situation in column (a) where we are presented with a single retrieval and no information from additional retrievals.",
                "For every collection except one, we achieve significantly better correlations than ranked-list Clarity.",
                "Surprisingly, we achieve relatively strong correlations for Spanish and Chinese collections despite our na¨ıve processing.",
                "We do not have a ranked-list clarity correlation for ent05 because entity modeling is itself an open research question.",
                "However, our autocorrelation measure does not achieve high correlations perhaps because relevance for entity retrieval does not propagate according to the cooccurrence links we use.",
                "As noted above, the poor Clarity performance on web data is consistent with our findings in the detailed experiments.",
                "Clarity also notably underperforms for several news corpora (trec5, trec7, and robust04).",
                "On the other hand, autocorrelation seems robust to the changes between different corpora.",
                "Next, we turn to the introduction of information from multiple retrievals.",
                "We compare the correlations between those predictors which do not use this information in column (a) and those which do in column (b).",
                "For every collection, the predictors in column (b) outperform the predictors in column (a), indicating that the information from additional runs can be critical to making good predictions.",
                "Inspecting the predictors in column (b), we only draw weak conclusions.",
                "Our new predictors tend to perform better on news corpora.",
                "And between our new predictors, the hybrid ρ(˜y, yµ) predictor tends to perform better.",
                "Recall that our ρ(˜y, yµ) measure incorporates both spatial and multiple retrieval information.",
                "Therefore, we believe that the improvement in correlation is the result of incorporating information from spatial behavior.",
                "In column (c), we can investigate the utility of incorporating spatial information with information from multiple retrievals.",
                "Notice that in the cases where autocorrelation, ρ(y, ˜y), alone performs well (trec3, trec5-spanish, and trec6-chinese), it is substantially improved by incorporating multiple-retrieval information from ρ(y, yµ) in the linear regression, β.",
                "In the cases where ρ(y, yµ) performs well, incorporating autocorrelation rarely results in a significant improvement in performance.",
                "In fact, in every case where our predictor outperforms the baseline, it includes information from multiple runs. 7.",
                "DISCUSSION The most important result from our experiments involves prediction when no information is available from multiple runs (Tables 1 and 2a).",
                "This situation arises often in system design.",
                "For example, a system may need to, at retrieval time, assess its performance before deciding to conduct more intensive processing such as pseudo-relevance feedback or interaction.",
                "Assuming the presence of multiple retrievals is unrealistic in this case.",
                "We believe that autocorrelation is, like multiple-retrieval algorithms, approximating a good ranking; in this case by diffusing scores.",
                "Why is ˜y a reasonable surrogate?",
                "We know that diffusion of scores on the web graph and language model graphs improves performance [14, 16].",
                "Therefore, if score diffusion tends to, in general, improve performance, then diffused scores will, in general, provide a good surrogate for relevance.",
                "Our results demonstrate that this approximation is not as powerful as information from multiple retrievals.",
                "Nevertheless, in situations where this information is lacking, autocorrelation provides substantial information.",
                "The success of autocorrelation as a predictor may also have roots in the clustering hypothesis.",
                "Recall that we regard autocorrelation as the degree to which a retrieval satisfies the clustering hypothesis.",
                "Our experiments, then, demonstrate that a failure to respect the clustering hypothesis correlates with poor performance.",
                "Why might systems fail to conform to the cluster hypothesis?",
                "Query-based information retrieval systems often score documents independently.",
                "The score of document a may be computed by examining query term or phrase matches, the document length, and perhaps global collection statistics.",
                "Once computed, a system rarely compares the score of a to the score of a topically-related document b.",
                "With some exceptions, the correlation of document scores has largely been ignored.",
                "We should make it clear that we have selected tasks where topical autocorrelation is appropriate.",
                "There are certainly cases where there is no reason to believe that retrieval scores will have topical autocorrelation.",
                "For example, ranked lists which incorporate document novelty should not exhibit spatial autocorrelation; if anything autocorrelation should be negative for this task.",
                "Similarly, answer candidates in a question-answering task may or may not exhibit autocorrelation; in this case, the semantics of links is questionable too.",
                "It is important before applying this measure to confirm that, given the semantics for some link between two retrieved items, we should expect a correlation between scores. 8.",
                "RELATED WORK In this section we draw more general comparisons to other work in <br>performance prediction</br> and spatial data analysis.",
                "There is a growing body of work which attempts to predict the performance of individual retrievals [7, 3, 11, 9, 19].",
                "We have attempted to place our work in the context of much of this work in Section 4.",
                "However, a complete comparison is beyond the scope of this paper.",
                "We note, though, that our experiments cover a larger and more diverse set of retrievals, collections, and topics than previously examined.",
                "Much previous work-particularly in the context of TRECfocuses on predicting the performance of systems.",
                "Here, each system generates k retrievals.",
                "The task is, given these retrievals, to predict the ranking of systems according to some performance measure.",
                "Several papers attempt to address this task under the constraint of few judgments [2, 4].",
                "Some work even attempts to use zero judgments by leveraging multiple retrievals for the same query [17].",
                "Our task differs because we focus on ranking retrievals independent of the generating system.",
                "The task here is not to test the hypothesis system A is superior to system B but to test the hypothesis retrieval A is superior to retrieval B. Autocorrelation manifests itself in many classification tasks.",
                "Neville and Jensen define relational autocorrelation for relational learning problems and demonstrate that many classification tasks manifest autocorrelation [13].",
                "Temporal autocorrelation of initial retrievals has also been used to predict performance [9].",
                "However, temporal autocorrelation is performed by projecting the retrieval function into the temporal embedding space.",
                "In our work, we focus on the behavior of the function over the relationships between documents. τ adjusted R2 DV KL P ρ(y, ˜y) DV KL P ρ(y, ˜y) DV KL, P DV KL, ρ(y, ˜y) Pρ(y, ˜y) β trec4 0.353 0.548 0.513 0.168 0.363 0.422 0.466 0.420 0.557 0.553 trec5 0.311 0.329 0.357 0.116 0.190 0.236 0.238 0.244 0.266 0.269 robust04 0.418 0.398 0.373 0.256 0.304 0.278 0.403 0.373 0.402 0.442 terabyte04 0.139 0.150 0.454 0.059 0.045 0.292 0.076 0.293 0.289 0.284 terabyte05 0.171 0.208 0.383 0.022 0.072 0.193 0.120 0.225 0.218 0.257 Table 1: Comparison to Robustness and Clarity measures for language model scores.",
                "Evaluation replicates experiments from [19].",
                "We present correlations between the classic Clarity measure (DV KL), the ranking robustness measure (P), and autocorrelation (ρ(y, ˜y)) each with mean average precision in terms of Kendalls τ.",
                "The adjusted coefficient of determination is presented to measure the effectiveness of combining predictors.",
                "Measures in bold represent the strongest correlation for that test/collection pair. multiple run (a) (b) (c) τ τ adjusted R2 DKL ρ(y, ˜y) Dn KL ρ(y, yµ) ρ(˜y, yµ) Dn KL ρ(y, ˜y) ρ(y, yµ) ρ(˜y, yµ) β trec3 0.201 0.461 0.461 0.439 0.456 0.444 0.395 0.394 0.386 0.498 trec4 0.252 0.396 0.455 0.482 0.489 0.379 0.263 0.429 0.482 0.483 trec5 0.016 0.277 0.433 0.459 0.393 0.280 0.157 0.375 0.323 0.386 trec6 0.230 0.227 0.352 0.428 0.418 0.203 0.089 0.323 0.325 0.325 trec7 0.083 0.326 0.341 0.430 0.483 0.264 0.182 0.363 0.442 0.400 trec8 0.235 0.396 0.454 0.508 0.567 0.402 0.272 0.490 0.580 0.523 robust03 0.302 0.354 0.377 0.385 0.447 0.269 0.206 0.274 0.392 0.303 robust04 0.183 0.308 0.301 0.384 0.453 0.200 0.182 0.301 0.393 0.335 robust05 0.224 0.249 0.371 0.377 0.404 0.341 0.108 0.313 0.328 0.336 terabyte04 0.043 0.245 0.544 0.420 0.392 0.516 0.105 0.357 0.343 0.365 terabyte05 0.068 0.306 0.480 0.434 0.390 0.491 0.168 0.384 0.309 0.403 trec4-spanish 0.307 0.388 0.488 0.398 0.395 0.423 0.299 0.282 0.299 0.388 trec5-spanish 0.220 0.458 0.446 0.484 0.475 0.411 0.398 0.428 0.437 0.529 trec5-chinese 0.092 0.199 0.367 0.379 0.384 0.379 0.199 0.273 0.276 0.310 trec6-chinese 0.144 0.276 0.265 0.353 0.376 0.115 0.128 0.188 0.223 0.199 ent05 - 0.181 0.324 0.305 0.282 0.211 0.043 0.158 0.155 0.179 Table 2: Large scale prediction experiments.",
                "We predict the ranking of large sets of retrievals for various collections and retrieval systems.",
                "Kendalls τ correlations are computed between the predicted ranking and a ranking based on the retrievals average precision.",
                "In column (a), we have predictors which do not use information from other retrievals for the same query.",
                "In columns (b) and (c) we present performance for predictors which incorporate information from multiple retrievals.",
                "The adjusted coefficient of determination is computed to determine effectiveness of combining predictors.",
                "Measures in bold represent the strongest correlation for that test/collection pair.",
                "Finally, regularization-based re-ranking processes are also closely-related to our work [8].",
                "These techniques seek to maximize the agreement between scores of related documents by solving a constrained optimization problem.",
                "The maximization of consistency is equivalent to maximizing the Moran autocorrelation.",
                "Therefore, we believe that our work provides explanation for why regularization-based re-ranking works. 9.",
                "CONCLUSION We have presented a new method for predicting the performance of a retrieval ranking without any relevance judgments.",
                "We consider two cases.",
                "First, when making predictions in the absence of retrievals from other systems, our predictors demonstrate robust, strong correlations with average precision.",
                "This performance, combined with a simple implementation, makes our predictors, in particular, very attractive.",
                "We have demonstrated this improvement for many, diverse settings.",
                "To our knowledge, this is the first large scale examination of zero-judgment, single-retrieval <br>performance prediction</br>.",
                "Second, when provided retrievals from other systems, our extended methods demonstrate competitive performance with state of the art baselines.",
                "Our experiments also demonstrate the limits of the usefulness of our predictors when information from multiple runs is provided.",
                "Our results suggest two conclusions.",
                "First, our results could affect retrieval algorithm design.",
                "Retrieval algorithms designed to consider spatial autocorrelation will conform to the cluster hypothesis and improve performance.",
                "Second, our results could affect the design of minimal test collection algorithms.",
                "Much of the recent work in ranking systems sometimes ignores correlations between document labels and scores.",
                "We believe that these two directions could be rewarding given the theoretical and experimental evidence in this paper. 10.",
                "ACKNOWLEDGMENTS This work was supported in part by the Center for Intelligent Information Retrieval and in part by the Defense Advanced Research Projects Agency (DARPA) under contract number HR0011-06-C-0023.",
                "Any opinions, findings and conclusions or recommendations expressed in this material are the authors and do not necessarily reflect those of the sponsor.",
                "We thank Yun Zhou and Desislava Petkova for providing data and Andre Gauthier for technical assistance. 11.",
                "REFERENCES [1] J. Aslam and V. Pavlu.",
                "Query hardness estimation using jensen-shannon divergence among multiple scoring functions.",
                "In ECIR 2007: Proceedings of the 29th European Conference on Information Retrieval, 2007. [2] J.",
                "A. Aslam, V. Pavlu, and E. Yilmaz.",
                "A statistical method for system evaluation using incomplete judgments.",
                "In S. Dumais, E. N. Efthimiadis, D. Hawking, and K. Jarvelin, editors, Proceedings of the 29th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 541-548.",
                "ACM Press, August 2006. [3] D. Carmel, E. Yom-Tov, A. Darlow, and D. Pelleg.",
                "What makes a query difficult?",
                "In SIGIR 06: Proceedings of the 29th annual international ACM SIGIR conference on Research and development in information retrieval, pages 390-397, New York, NY, USA, 2006.",
                "ACM Press. [4] B. Carterette, J. Allan, and R. Sitaraman.",
                "Minimal test collections for retrieval evaluation.",
                "In SIGIR 06: Proceedings of the 29th annual international ACM SIGIR conference on Research and development in information retrieval, pages 268-275, New York, NY, USA, 2006.",
                "ACM Press. [5] A. D. Cliff and J. K. Ord.",
                "Spatial Autocorrelation.",
                "Pion Ltd., 1973. [6] M. Connell, A. Feng, G. Kumaran, H. Raghavan, C. Shah, and J. Allan.",
                "Umass at tdt 2004.",
                "Technical Report CIIR Technical Report IR - 357, Department of Computer Science, University of Massachusetts, 2004. [7] S. Cronen-Townsend, Y. Zhou, and W. B. Croft.",
                "Precision prediction based on ranked list coherence.",
                "Inf.",
                "Retr., 9(6):723-755, 2006. [8] F. Diaz.",
                "Regularizing ad-hoc retrieval scores.",
                "In CIKM 05: Proceedings of the 14th ACM international conference on Information and knowledge management, pages 672-679, New York, NY, USA, 2005.",
                "ACM Press. [9] F. Diaz and R. Jones.",
                "Using temporal profiles of queries for precision prediction.",
                "In SIGIR 04: Proceedings of the 27th annual international ACM SIGIR conference on Research and development in information retrieval, pages 18-24, New York, NY, USA, 2004.",
                "ACM Press. [10] D. A. Griffith.",
                "Spatial Autocorrelation and Spatial Filtering.",
                "Springer Verlag, 2003. [11] B.",
                "He and I. Ounis.",
                "Inferring Query Performance Using Pre-retrieval Predictors.",
                "In The Eleventh Symposium on String Processing and Information Retrieval (SPIRE), 2004. [12] N. Jardine and C. J. V. Rijsbergen.",
                "The use of hierarchic clustering in information retrieval.",
                "Information Storage and Retrieval, 7:217-240, 1971. [13] D. Jensen and J. Neville.",
                "Linkage and autocorrelation cause feature selection bias in relational learning.",
                "In ICML 02: Proceedings of the Nineteenth International Conference on Machine Learning, pages 259-266, San Francisco, CA, USA, 2002.",
                "Morgan Kaufmann Publishers Inc. [14] O. Kurland and L. Lee.",
                "Corpus structure, language models, and ad-hoc information retrieval.",
                "In SIGIR 04: Proceedings of the 27th annual international conference on Research and development in information retrieval, pages 194-201, New York, NY, USA, 2004.",
                "ACM Press. [15] M. Montague and J.",
                "A. Aslam.",
                "Relevance score normalization for metasearch.",
                "In CIKM 01: Proceedings of the tenth international conference on Information and knowledge management, pages 427-433, New York, NY, USA, 2001.",
                "ACM Press. [16] T. Qin, T.-Y.",
                "Liu, X.-D. Zhang, Z. Chen, and W.-Y.",
                "Ma.",
                "A study of relevance propagation for web search.",
                "In SIGIR 05: Proceedings of the 28th annual international ACM SIGIR conference on Research and development in information retrieval, pages 408-415, New York, NY, USA, 2005.",
                "ACM Press. [17] I. Soboroff, C. Nicholas, and P. Cahan.",
                "Ranking retrieval systems without relevance judgments.",
                "In SIGIR 01: Proceedings of the 24th annual international ACM SIGIR conference on Research and development in information retrieval, pages 66-73, New York, NY, USA, 2001.",
                "ACM Press. [18] V. Vinay, I. J. Cox, N. Milic-Frayling, and K. Wood.",
                "On ranking the effectiveness of searches.",
                "In SIGIR 06: Proceedings of the 29th annual international ACM SIGIR conference on Research and development in information retrieval, pages 398-404, New York, NY, USA, 2006.",
                "ACM Press. [19] Y. Zhou and W. B. Croft.",
                "Ranking robustness: a novel framework to predict query performance.",
                "In CIKM 06: Proceedings of the 15th ACM international conference on Information and knowledge management, pages 567-574, New York, NY, USA, 2006.",
                "ACM Press."
            ],
            "original_annotated_samples": [
                "<br>performance prediction</br> Using Spatial Autocorrelation Fernando Diaz Center for Intelligent Information Retrieval Department of Computer Science University of Massachusetts Amherst, MA 01003 fdiaz@cs.umass.edu ABSTRACT Evaluation of information retrieval systems is one of the core tasks in information retrieval.",
                "Our focus is on zero-judgment <br>performance prediction</br> of individual retrievals.",
                "We also describe the first large-scale experiment to evaluate zero-judgment <br>performance prediction</br> for a massive number of retrieval systems over a variety of collections in several languages.",
                "A theoretical treatment of the similarities and motivations behind several state-of-the-art <br>performance prediction</br> techniques (Section 4). 3.",
                "The first large-scale experiments of zero-judgment, single run <br>performance prediction</br> (Sections 5 and 6). 2."
            ],
            "translated_annotated_samples": [
                "Predicción del rendimiento utilizando autocorrelación espacial. Fernando Díaz. Centro de Recuperación de Información Inteligente. Departamento de Ciencias de la Computación. Universidad de Massachusetts Amherst, MA 01003. fdiaz@cs.umass.edu. RESUMEN La evaluación de sistemas de recuperación de información es una de las tareas fundamentales en la recuperación de información.",
                "Nuestro enfoque está en la <br>predicción del rendimiento</br> sin juicios de las recuperaciones individuales.",
                "También describimos el primer experimento a gran escala para evaluar la <br>predicción de rendimiento</br> sin juicio para un gran número de sistemas de recuperación en una variedad de colecciones en varios idiomas.",
                "Un tratamiento teórico de las similitudes y motivaciones detrás de varias técnicas de <br>predicción de rendimiento</br> de vanguardia (Sección 4). 3.",
                "Las primeras experimentaciones a gran escala de <br>predicción de rendimiento</br> de una sola ejecución sin juicio (Secciones 5 y 6). 2."
            ],
            "translated_text": "Predicción del rendimiento utilizando autocorrelación espacial. Fernando Díaz. Centro de Recuperación de Información Inteligente. Departamento de Ciencias de la Computación. Universidad de Massachusetts Amherst, MA 01003. fdiaz@cs.umass.edu. RESUMEN La evaluación de sistemas de recuperación de información es una de las tareas fundamentales en la recuperación de información. Los problemas incluyen la incapacidad de etiquetar exhaustivamente todos los documentos sobre un tema, la falta de generalización a partir de un pequeño número de temas e incorporar la variabilidad de los sistemas de recuperación. Trabajos anteriores abordan la evaluación de sistemas, la clasificación de consultas por dificultad y la clasificación de recuperaciones individuales por rendimiento. Existen enfoques para el caso de pocos e incluso ningún juicio de relevancia. Nuestro enfoque está en la <br>predicción del rendimiento</br> sin juicios de las recuperaciones individuales. Una deficiencia común de las técnicas anteriores es la suposición de que las puntuaciones de los documentos y los juicios no están correlacionados. Si los documentos están incrustados en un espacio de alta dimensión (como a menudo lo están), podemos aplicar técnicas de análisis de datos espaciales para detectar correlaciones entre las puntuaciones de los documentos. Observamos que la baja correlación entre las puntuaciones de documentos temáticamente cercanos a menudo implica un bajo rendimiento en la recuperación. Cuando se compara con una línea base de última generación, demostramos que el análisis espacial de las puntuaciones de recuperación ofrece un rendimiento predictivo significativamente mejor. Estos nuevos predictores también pueden ser incorporados con predictores clásicos para mejorar aún más el rendimiento. También describimos el primer experimento a gran escala para evaluar la <br>predicción de rendimiento</br> sin juicio para un gran número de sistemas de recuperación en una variedad de colecciones en varios idiomas. Categorías y Descriptores de Asignaturas H.3.3 [Búsqueda y Recuperación de Información]: Modelos de recuperación; H.3.4 [Sistemas y Software]: Evaluación del rendimiento (eficiencia y efectividad) Términos Generales Rendimiento, Diseño, Confiabilidad, Experimentación 1. En la recuperación de información, un usuario plantea una consulta a un sistema. El sistema recupera n documentos, cada uno recibiendo una puntuación de valor real que indica el grado de relevancia predicho. Si seleccionamos aleatoriamente pares de documentos de este conjunto, esperamos que algunos pares compartan el mismo tema y otros pares no compartan el mismo tema. Toma dos documentos relacionados entre sí del conjunto y llámalos a y b. Si las puntuaciones de a y b son muy diferentes, podríamos estar preocupados por el rendimiento de nuestro sistema. Es decir, si tanto a como b están relacionados con el tema de la consulta, nos gustaría que ambos reciban una puntuación alta; si a y b no están relacionados con el tema de la consulta, nos gustaría que ambos reciban una puntuación baja. Podríamos preocuparnos más a medida que encontramos más diferencias entre las puntuaciones de documentos relacionados. Estaríamos más cómodos con una recuperación en la que las puntuaciones sean consistentes entre documentos relacionados. Nuestro artículo estudia la cuantificación de esta inconsistencia en una recuperación desde una perspectiva espacial. El análisis espacial es apropiado ya que muchos modelos de recuperación incrustan documentos en algún espacio vectorial. Si los documentos están incrustados en un espacio, la proximidad se correlaciona con las relaciones temáticas. La consistencia de la puntuación puede medirse mediante la versión espacial de la autocorrelación conocida como el coeficiente de Moran o IM [5, 10]. En este artículo, demostramos una fuerte correlación entre IM y el rendimiento de recuperación. La discusión hasta este punto recuerda a la hipótesis del cúmulo. La hipótesis del clúster establece que los documentos estrechamente relacionados tienden a ser relevantes para la misma solicitud [12]. Como veremos, una función de recuperación de medidas de autocorrelación espacial mide el grado en que los documentos relacionados reciben puntuaciones similares. Debido a esto, interpretamos la autocorrelación como la medida del grado en que una función de recuperación satisface la hipótesis de agrupamiento. Si esta conexión es razonable, en la Sección 6 presentamos evidencia de que la falta de cumplimiento de la hipótesis de agrupamiento se correlaciona fuertemente con un bajo rendimiento. En este trabajo, proporcionamos las siguientes contribuciones: 1. Un método general y robusto para predecir el rendimiento de recuperaciones sin juicios de relevancia (Sección 3). 2. Un tratamiento teórico de las similitudes y motivaciones detrás de varias técnicas de <br>predicción de rendimiento</br> de vanguardia (Sección 4). 3. Las primeras experimentaciones a gran escala de <br>predicción de rendimiento</br> de una sola ejecución sin juicio (Secciones 5 y 6). 2. ",
            "candidates": [],
            "error": [
                [
                    "predicción del rendimiento",
                    "predicción de rendimiento",
                    "predicción de rendimiento",
                    "predicción de rendimiento"
                ]
            ]
        },
        "information retrieval": {
            "translated_key": "recuperación de información",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Performance Prediction Using Spatial Autocorrelation Fernando Diaz Center for Intelligent <br>information retrieval</br> Department of Computer Science University of Massachusetts Amherst, MA 01003 fdiaz@cs.umass.edu ABSTRACT Evaluation of <br>information retrieval</br> systems is one of the core tasks in information retrieval.",
                "Problems include the inability to exhaustively label all documents for a topic, nongeneralizability from a small number of topics, and incorporating the variability of retrieval systems.",
                "Previous work addresses the evaluation of systems, the ranking of queries by difficulty, and the ranking of individual retrievals by performance.",
                "Approaches exist for the case of few and even no relevance judgments.",
                "Our focus is on zero-judgment performance prediction of individual retrievals.",
                "One common shortcoming of previous techniques is the assumption of uncorrelated document scores and judgments.",
                "If documents are embedded in a high-dimensional space (as they often are), we can apply techniques from spatial data analysis to detect correlations between document scores.",
                "We find that the low correlation between scores of topically close documents often implies a poor retrieval performance.",
                "When compared to a state of the art baseline, we demonstrate that the spatial analysis of retrieval scores provides significantly better prediction performance.",
                "These new predictors can also be incorporated with classic predictors to improve performance further.",
                "We also describe the first large-scale experiment to evaluate zero-judgment performance prediction for a massive number of retrieval systems over a variety of collections in several languages.",
                "Categories and Subject Descriptors H.3.3 [Information Search and Retrieval]: Retrieval models; H.3.4 [Systems and Software]: Performance evaluation (efficiency and effectiveness) General Terms Performance, Design, Reliability, Experimentation 1.",
                "INTRODUCTION In <br>information retrieval</br>, a user poses a query to a system.",
                "The system retrieves n documents each receiving a realvalued score indicating the predicted degree of relevance.",
                "If we randomly select pairs of documents from this set, we expect some pairs to share the same topic and other pairs to not share the same topic.",
                "Take two topically-related documents from the set and call them a and b.",
                "If the scores of a and b are very different, we may be concerned about the performance of our system.",
                "That is, if a and b are both on the topic of the query, we would like them both to receive a high score; if a and b are not on the topic of the query, we would like them both to receive a low score.",
                "We might become more worried as we find more differences between scores of related documents.",
                "We would be more comfortable with a retrieval where scores are consistent between related documents.",
                "Our paper studies the quantification of this inconsistency in a retrieval from a spatial perspective.",
                "Spatial analysis is appropriate since many retrieval models embed documents in some vector space.",
                "If documents are embedded in a space, proximity correlates with topical relationships.",
                "Score consistency can be measured by the spatial version of autocorrelation known as the Moran coefficient or IM [5, 10].",
                "In this paper, we demonstrate a strong correlation between IM and retrieval performance.",
                "The discussion up to this point is reminiscent of the cluster hypothesis.",
                "The cluster hypothesis states: closely-related documents tend to be relevant to the same request [12].",
                "As we shall see, a retrieval functions spatial autocorrelation measures the degree to which closely-related documents receive similar scores.",
                "Because of this, we interpret autocorrelation as measuring the degree to which a retrieval function satisfies the clustering hypothesis.",
                "If this connection is reasonable, in Section 6, we present evidence that failure to satisfy the cluster hypothesis correlates strongly with poor performance.",
                "In this work, we provide the following contributions, 1.",
                "A general, robust method for predicting the performance of retrievals with zero relevance judgments (Section 3). 2.",
                "A theoretical treatment of the similarities and motivations behind several state-of-the-art performance prediction techniques (Section 4). 3.",
                "The first large-scale experiments of zero-judgment, single run performance prediction (Sections 5 and 6). 2.",
                "PROBLEM DEFINITION Given a query, an <br>information retrieval</br> system produces a ranking of documents in the collection encoded as a set of scores associated with documents.",
                "We refer to the set of scores for a particular query-system combination as a retrieval.",
                "We would like to predict the performance of this retrieval with respect to some evaluation measure (eg, mean average precision).",
                "In this paper, we present results for ranking retrievals from arbitrary systems.",
                "We would like this ranking to approximate the ranking of retrievals by the evaluation measure.",
                "This is different from ranking queries by the average performance on each query.",
                "It is also different from ranking systems by the average performance on a set of queries.",
                "Scores are often only computed for the top n documents from the collection.",
                "We place these scores in the length n vector, y, where yi refers to the score of the ith-ranked document.",
                "We adjust scores to have zero mean and unit variance.",
                "We use this method because of its simplicity and its success in previous work [15]. 3.",
                "SPATIAL CORRELATION In <br>information retrieval</br>, we often assume that the representations of documents exist in some high-dimensional vector space.",
                "For example, given a vocabulary, V, this vector space may be an arbitrary |V|-dimensional space with cosine inner-product or a multinomial simplex with a distributionbased distance measure.",
                "An embedding space is often selected to respect topical proximity; if two documents are near, they are more likely to share a topic.",
                "Because of the prevalence and success of spatial models of <br>information retrieval</br>, we believe that the application of spatial data analysis techniques are appropriate.",
                "Whereas in <br>information retrieval</br>, we are concerned with the score at a point in a space, in spatial data analysis, we are concerned with the value of a function at a point or location in a space.",
                "We use the term function here to mean a mapping from a location to a real value.",
                "For example, we might be interested in the prevalence of a disease in the neighborhood of some city.",
                "The function would map the location of a neighborhood to an infection rate.",
                "If we want to quantify the spatial dependencies of a function, we would employ a measure referred to as the spatial autocorrelation [5, 10].",
                "High spatial autocorrelation suggests that knowing the value of a function at location a will tell us a great deal about the value at a neighboring location b.",
                "There is a high spatial autocorrelation for a function representing the temperature of a location since knowing the temperature at a location a will tell us a lot about the temperature at a neighboring location b.",
                "Low spatial autocorrelation suggests that knowing the value of a function at location a tells us little about the value at a neighboring location b.",
                "There is low spatial autocorrelation in a function measuring the outcome of a coin toss at a and b.",
                "In this section, we will begin by describing what we mean by spatial proximity for documents and then define a measure of spatial autocorrelation.",
                "We conclude by extending this model to include information from multiple retrievals from multiple systems for a single query. 3.1 Spatial Representation of Documents Our work does not focus on improving a specific similarity measure or defining a novel vector space.",
                "Instead, we choose an inner product known to be effective at detecting interdocument topical relationships.",
                "Specifically, we adopt tf.idf document vectors, ˜di = di log „ (n + 0.5) − ci 0.5 + ci « (1) where d is a vector of term frequencies, c is the length-|V| document frequency vector.",
                "We use this weighting scheme due to its success for topical link detection in the context of Topic Detection and Tracking (TDT) evaluations [6].",
                "Assuming vectors are scaled by their L2 norm, we use the inner product, ˜di, ˜dj , to define similarity.",
                "Given documents and some similarity measure, we can construct a matrix which encodes the similarity between pairs of documents.",
                "Recall that we are given the top n documents retrieved in y.",
                "We can compute an n × n similarity matrix, W. An element of this matrix, Wij represents the similarity between documents ranked i and j.",
                "In practice, we only include the affinities for a documents k-nearest neighbors.",
                "In all of our experiments, we have fixed k to 5.",
                "We leave exploration of parameter sensitivity to future work.",
                "We also row normalize the matrix so that Pn j=1 Wij = 1 for all i. 3.2 Spatial Autocorrelation of a Retrieval Recall that we are interested in measuring the similarity between the scores of spatially-close documents.",
                "One such suitable measure is the Moran coefficient of spatial autocorrelation.",
                "Assuming the function y over n locations, this is defined as ˜IM = n eTWe P i,j Wijyiyj P i y2 i = n eTWe yT Wy yTy (2) where eT We = P ij Wij.",
                "We would like to compare autocorrelation values for different retrievals.",
                "Unfortunately, the bound for Equation 2 is not consistent for different W and y.",
                "Therefore, we use the Cauchy-Schwartz inequality to establish a bound, ˜IM ≤ n eTWe s yTWTWy yTy And we define the normalized spatial autocorrelation as IM = yT Wy p yTy × yTWTWy Notice that if we let ˜y = Wy, then we can write this formula as, IM = yT ˜y y 2 ˜y 2 (3) which can be interpreted as the correlation between the original retrieval scores and a set of retrieval scores diffused in the space.",
                "We present some examples of autocorrelations of functions on a grid in Figure 1. 3.3 Correlation with Other Retrievals Sometimes we are interested in the performance of a single retrieval but have access to scores from multiple systems for (a) IM = 0.006 (b) IM = 0.241 (c) IM = 0.487 Figure 1: The Moran coefficient, IM for a several binary functions on a grid.",
                "The Moran coefficient is a local measure of function consistency.",
                "From the perspective of <br>information retrieval</br>, each of these grid spaces would represent a document and documents would be organized so that they lay next to topically-related documents.",
                "Binary retrieval scores would define a pattern on this grid.",
                "Notice that, as the Moran coefficient increases, neighboring cells tend to have similar values. the same query.",
                "In this situation, we can use combined information from these scores to construct a surrogate for a high-quality ranking [17].",
                "We can treat the correlation between the retrieval we are interested in and the combined scores as a predictor of performance.",
                "Assume that we are given m score functions, yi, for the same n documents.",
                "We will represent the mean of these vectors as yµ = Pm i=1 yi.",
                "We use the mean vector as an approximation to relevance.",
                "Since we use zero mean and unit variance normalization, work in metasearch suggests that this assumption is justified [15].",
                "Because yµ represents a very good retrieval, we hypothesize that a strong similarity between yµ and y will correlate positively with system performance.",
                "We use Pearsons product-moment correlation to measure the similarity between these vectors, ρ(y, yµ) = yT yµ y 2 yµ 2 (4) We will comment on the similarity between Equation 3 and 4 in Section 7.",
                "Of course, we can combine ρ(y, ˜y) and ρ(y, yµ) if we assume that they capture different factors in the prediction.",
                "One way to accomplish this is to combine these predictors as independent variables in a linear regression.",
                "An alternative means of combination is suggested by the mathematical form of our predictors.",
                "Since ˜y encodes the spatial dependencies in y and yµ encodes the spatial properties of the multiple runs, we can compute a third correlation between these two vectors, ρ(˜y, yµ) = ˜yT yµ ˜y 2 yµ 2 (5) We can interpret Equation 5 as measuring the correlation between a high quality ranking (yµ) and a spatially smoothed version of the retrieval (˜y). 4.",
                "RELATIONSHIP WITH OTHER PREDICTORS One way to predict the effectiveness of a retrieval is to look at the shared vocabulary of the top n retrieved documents.",
                "If we computed the most frequent content words in this set, we would hope that they would be consistent with our topic.",
                "In fact, we might believe that a bad retrieval would include documents on many disparate topics, resulting in an overlap of terminological noise.",
                "The Clarity of a query attempts to quantify exactly this [7].",
                "Specifically, Clarity measures the similarity of the words most frequently used in retrieved documents to those most frequently used in the whole corpus.",
                "The conjecture is that a good retrieval will use language distinct from general text; the overlapping language in a bad retrieval will tend to be more similar to general text.",
                "Mathematically, we can compute a representation of the language used in the initial retrieval as a weighted combination of document language models, P(w|θQ) = nX i=1 P(w|θi) P(Q|θi) Z (6) where θi is the language model of the ith-ranked document, P(Q|θi) is the query likelihood score of the ith-ranked document and Z = Pn i=1 P(Q|θi) is a normalization constant.",
                "The similarity between the multinomial P(w|θQ) and a model of general text can be computed using the Kullback-Leibler divergence, DV KL(θQ θC ).",
                "Here, the distribution P(w|θC ) is our model of general text which can be computed using term frequencies in the corpus.",
                "In Figure 2a, we present Clarity as measuring the distance between the weighted center of mass of the retrieval (labeled y) and the unweighted center of mass of the collection (labeled O).",
                "Clarity reaches a minimum when a retrieval assigns every document the same score.",
                "Lets again assume we have a set of n documents retrieved for our query.",
                "Another way to quantify the dispersion of a set of documents is to look at how clustered they are.",
                "We may hypothesize that a good retrieval will return a single, tight cluster.",
                "A poorly performing retrieval will return a loosely related set of documents covering many topics.",
                "One proposed method of quantifying this dispersion is to measure the distance from a random document a to its nearest neighbor, b.",
                "A retrieval which is tightly clustered will, on average, have a low distance between a and b; a retrieval which is less tightly-closed will, on average have high distances between a and b.",
                "This average corresponds to using the Cox-Lewis statistic to measure the randomness of the top n documents retrieved from a system [18].",
                "In Figure 2a, this is roughly equivalent to measuring the area of the set n. Notice that we are throwing away information about the retrieval function y.",
                "Therefore the Cox-Lewis statistic is highly dependent on selecting the top n documents.1 Remember that we have n documents and a set of scores.",
                "Lets assume that we have access to the system which provided the original scores and that we can also request scores for new documents.",
                "This suggests a third method for predicting performance.",
                "Take some document, a, from the retrieved set and arbitrarily add or remove words at random to create a new document ˜a.",
                "Now, we can ask our system to score ˜a with respect to our query.",
                "If, on average over the n documents, the scores of a and ˜a tend to be very different, we might suspect that the system is failing on this query.",
                "So, an alternative approach is to measure the simi1 The authors have suggested coupling the query with the distance measure [18].",
                "The information introduced by the query, though, is retrieval-independent so that, if two retrievals return the same set of documents, the approximate Cox-Lewis statistic will be the same regardless of the retrieval scores. yOy (a) Global Divergence µ(y)˜y y (b) Score Perturbation µ(y) y (c) Multirun Averaging Figure 2: Representation of several performance predictors on a grid.",
                "In Figure 2a, we depict predictors which measure the divergence between the center of mass of a retrieval and the center of the embedding space.",
                "In Figure 2b, we depict predictors which compare the original retrieval, y, to a perturbed version of the retrieval, ˜y.",
                "Our approach uses a particular type of perturbation based on score diffusion.",
                "Finally, in Figure 2c, we depict prediction when given retrievals from several other systems on the same query.",
                "Here, we can consider the fusion of these retrieval as a surrogate for relevance. larity between the retrieval and a perturbed version of that retrieval [18, 19].",
                "This can be accomplished by either perturbing the documents or queries.",
                "The similarity between the two retrievals can be measured using some correlation measure.",
                "This is depicted in Figure 2b.",
                "The upper grid represents the original retrieval, y, while the lower grid represents the function after having been perturbed, ˜y.",
                "The nature of the perturbation process requires additional scorings or retrievals.",
                "Our predictor does not require access to the original scoring function or additional retrievals.",
                "So, although our method is similar to other perturbation methods in spirit, it can be applied in situations when the retrieval system is inaccessible or costly to access.",
                "Finally, assume that we have, in addition to the retrieval we want to evaluate, m retrievals from a variety of different systems.",
                "In this case, we might take a document a, compare its rank in the retrieval to its average rank in the m retrievals.",
                "If we believe that the m retrievals provide a satisfactory approximation to relevance, then a very large difference in rank would suggest that our retrieval is misranking a.",
                "If this difference is large on average over all n documents, then we might predict that the retrieval is bad.",
                "If, on the other hand, the retrieval is very consistent with the m retrievals, then we might predict that the retrieval is good.",
                "The similarity between the retrieval and the combined retrieval may be computed using some correlation measure.",
                "This is depicted in Figure 2c.",
                "In previous work, the Kullback-Leibler divergence between the normalized scores of the retrieval and the normalized scores of the combined retrieval provides the similarity [1]. 5.",
                "EXPERIMENTS Our experiments focus on testing the predictive power of each of our predictors: ρ(y, ˜y), ρ(y, yµ), and ρ(˜y, yµ).",
                "As stated in Section 2, we are interested in predicting the performance of the retrieval generated by an arbitrary system.",
                "Our methodology is consistent with previous research in that we predict the relative performance of a retrieval by comparing a ranking based on our predictor to a ranking based on average precision.",
                "We present results for two sets of experiments.",
                "The first set of experiments presents detailed comparisons of our predictors to previously-proposed predictors using identical data sets.",
                "Our second set of experiments demonstrates the generalizability of our approach to arbitrary retrieval methods, corpus types, and corpus languages. 5.1 Detailed Experiments In these experiments, we will predict the performance of language modeling scores using our autocorrelation predictor, ρ(y, ˜y); we do not consider ρ(y, yµ) or ρ(˜y, yµ) because, in these detailed experiments, we focus on ranking the retrievals from a single system.",
                "We use retrievals, values for baseline predictors, and evaluation measures reported in previous work [19]. 5.1.1 Topics and Collections These performance prediction experiments use language model retrievals performed for queries associated with collections in the TREC corpora.",
                "Using TREC collections allows us to confidently associate an average precision with a retrieval.",
                "In these experiments, we use the following topic collections: TREC 4 ad-hoc, TREC 5 ad-hoc, Robust 2004, Terabyte 2004, and Terabyte 2005. 5.1.2 Baselines We provide two baselines.",
                "Our first baseline is the classic Clarity predictor presented in Equation 6.",
                "Clarity is designed to be used with language modeling systems.",
                "Our second baseline is Zhou and Crofts ranking robustness predictor.",
                "This predictor corrupts the top k documents from retrieval and re-computes the language model scores for these corrupted documents.",
                "The value of the predictor is the Spearman rank correlation between the original ranking and the corrupted ranking.",
                "In our tables, we will label results for Clarity using DV KL and the ranking robustness predictor using P. 5.2 Generalizability Experiments Our predictors do not require a particular baseline retrieval system; the predictors can be computed for an arbitrary retrieval, regardless of how scores were generated.",
                "We believe that that is one of the most attractive aspects of our algorithm.",
                "Therefore, in a second set of experiments, we demonstrate the ability of our techniques to generalize to a variety of collections, topics, and retrieval systems. 5.2.1 Topics and Collections We gathered a diverse set of collections from all possible TREC corpora.",
                "We cast a wide net in order to locate collections where our predictors might fail.",
                "Our hypothesis is that documents with high topical similarity should have correlated scores.",
                "Therefore, we avoided collections where scores were unlikely to be correlated (eg, question-answering) or were likely to be negatively correlated (eg, novelty).",
                "Nevertheless, our collections include corpora where correlations are weakly justified (eg, non-English corpora) or not justified at all (eg, expert search).",
                "We use the ad-hoc tracks from TREC3-8, TREC Robust 2003-2005, TREC Terabyte 20042005, TREC4-5 Spanish, TREC5-6 Chinese, and TREC Enterprise Expert Search 2005.",
                "In all cases, we use only the automatic runs for ad-hoc tracks submitted to NIST.",
                "For all English and Spanish corpora, we construct the matrix W according to the process described in Section 3.1.",
                "For Chinese corpora, we use na¨ıve character-based tf.idf vectors.",
                "For entities, entries in W are proportional to the number of documents in which two entities cooccur. 5.2.2 Baselines In our detailed experiments, we used the Clarity measure as a baseline.",
                "Since we are predicting the performance of retrievals which are not based on language modeling, we use a version of Clarity referred to as ranked-list Clarity [7].",
                "Ranked-list clarity converts document ranks to P(Q|θi) values.",
                "This conversion begins by replacing all of the scores in y with the respective ranks.",
                "Our estimation of P(Q|θi) from the ranks, then is, P(Q|θi) = ( 2(c+1−yi) c(c+1) if yi ≤ c 0 otherwise (7) where c is a cutoff parameter.",
                "As suggested by the authors, we fix the algorithm parameters c and λ2 so that c = 60 and λ2 = 0.10.",
                "We use Equation 6 to estimate P(w|θQ) and DV KL(θQ θC ) to compute the value of the predictor.",
                "We will refer to this predictor as DV KL, superscripted by V to indicate that the Kullback-Leibler divergence is with respect to the term embedding space.",
                "When information from multiple runs on the same query is available, we use Aslam and Pavlus document-space multinomial divergence as a baseline [1].",
                "This rank-based method first normalizes the scores in a retrieval as an n-dimensional multinomial.",
                "As with ranked-list Clarity, we begin by replacing all of the scores in y with their respective ranks.",
                "Then, we adjust the elements of y in the following way, ˆyi = 1 2n 0 @1 + nX k=yi 1 k 1 A (8) In our multirun experiments, we only use the top 75 documents from each retrieval (n = 75); this is within the range of parameter values suggested by the authors.",
                "However, we admit not tuning this parameter for either our system or the baseline.",
                "The predictor is the divergence between the candidate distribution, y, and the mean distribution, yµ .",
                "With the uniform linear combination of these m retrievals represented as yµ, we can compute the divergence as Dn KL(ˆy ˆyµ) where we use the superscript n to indicate that the summation is over the set of n documents.",
                "This baseline was developed in the context of predicting query difficulty but we adopt it as a reasonable baseline for predicting retrieval performance. 5.2.3 Parameter Settings When given multiple retrievals, we use documents in the union of the top k = 75 documents from each of the m retrievals for that query.",
                "If the size of this union is ˜n, then yµ and each yi is of length ˜n.",
                "In some cases, a system did not score a document in the union.",
                "Since we are making a Gaussian assumption about our scores, we can sample scores for these unseen documents from the negative tail of the distribution.",
                "Specifically, we sample from the part of the distribution lower than the minimum value of in the normalized retrieval.",
                "This introduces randomness into our algorithm but we believe it is more appropriate than assigning an arbitrary fixed value.",
                "We optimized the linear regression using the square root of each predictor.",
                "We found that this substantially improved fits for all predictors, including the baselines.",
                "We considered linear combinations of pairs of predictors (labeled by the components) and all predictors (labeled as β). 5.3 Evaluation Given a set of retrievals, potentially from a combination of queries and systems, we measure the correlation of the rank ordering of this set by the predictor and by the performance metric.",
                "In order to ensure comparability with previous results, we present Kendalls τ correlation between the predictors ranking and ranking based on average precision of the retrieval.",
                "Unless explicitly noted, all correlations are significant with p < 0.05.",
                "Predictors can sometimes perform better when linearly combined [9, 11].",
                "Although previous work has presented the coefficient of determination (R2 ) to measure the quality of the regression, this measure cannot be reliably used when comparing slight improvements from combining predictors.",
                "Therefore, we adopt the adjusted coefficient of determination which penalizes models with more variables.",
                "The adjusted R2 allows us to evaluate the improvement in prediction achieved by adding a parameter but loses the statistical interpretation of R2 .",
                "We will use Kendalls τ to evaluate the magnitude of the correlation and the adjusted R2 to evaluate the combination of variables. 6.",
                "RESULTS We present results for our detailed experiments comparing the prediction of language model scores in Table 1.",
                "Although the Clarity measure is theoretically designed for language model scores, it consistently underperforms our system-agnostic predictor.",
                "Ranking robustness was presented as an improvement to Clarity for web collections (represented in our experiments by the terabyte04 and terabyte05 collections), shifting the τ correlation from 0.139 to 0.150 for terabyte04 and 0.171 to 0.208 for terabyte05.",
                "However, these improvements are slight compared to the performance of autocorrelation on these collections.",
                "Our predictor achieves a τ correlation of 0.454 for terabyte04 and 0.383 for terabyte05.",
                "Though not always the strongest, autocorrelation achieves correlations competitive with baseline predictors.",
                "When examining the performance of linear combinations of predictors, we note that in every case, autocorrelation factors as a necessary component of a strong predictor.",
                "We also note that the adjusted R2 for individual baselines are always significantly improved by incorporating autocorrelation.",
                "We present our generalizability results in Table 2.",
                "We begin by examining the situation in column (a) where we are presented with a single retrieval and no information from additional retrievals.",
                "For every collection except one, we achieve significantly better correlations than ranked-list Clarity.",
                "Surprisingly, we achieve relatively strong correlations for Spanish and Chinese collections despite our na¨ıve processing.",
                "We do not have a ranked-list clarity correlation for ent05 because entity modeling is itself an open research question.",
                "However, our autocorrelation measure does not achieve high correlations perhaps because relevance for entity retrieval does not propagate according to the cooccurrence links we use.",
                "As noted above, the poor Clarity performance on web data is consistent with our findings in the detailed experiments.",
                "Clarity also notably underperforms for several news corpora (trec5, trec7, and robust04).",
                "On the other hand, autocorrelation seems robust to the changes between different corpora.",
                "Next, we turn to the introduction of information from multiple retrievals.",
                "We compare the correlations between those predictors which do not use this information in column (a) and those which do in column (b).",
                "For every collection, the predictors in column (b) outperform the predictors in column (a), indicating that the information from additional runs can be critical to making good predictions.",
                "Inspecting the predictors in column (b), we only draw weak conclusions.",
                "Our new predictors tend to perform better on news corpora.",
                "And between our new predictors, the hybrid ρ(˜y, yµ) predictor tends to perform better.",
                "Recall that our ρ(˜y, yµ) measure incorporates both spatial and multiple retrieval information.",
                "Therefore, we believe that the improvement in correlation is the result of incorporating information from spatial behavior.",
                "In column (c), we can investigate the utility of incorporating spatial information with information from multiple retrievals.",
                "Notice that in the cases where autocorrelation, ρ(y, ˜y), alone performs well (trec3, trec5-spanish, and trec6-chinese), it is substantially improved by incorporating multiple-retrieval information from ρ(y, yµ) in the linear regression, β.",
                "In the cases where ρ(y, yµ) performs well, incorporating autocorrelation rarely results in a significant improvement in performance.",
                "In fact, in every case where our predictor outperforms the baseline, it includes information from multiple runs. 7.",
                "DISCUSSION The most important result from our experiments involves prediction when no information is available from multiple runs (Tables 1 and 2a).",
                "This situation arises often in system design.",
                "For example, a system may need to, at retrieval time, assess its performance before deciding to conduct more intensive processing such as pseudo-relevance feedback or interaction.",
                "Assuming the presence of multiple retrievals is unrealistic in this case.",
                "We believe that autocorrelation is, like multiple-retrieval algorithms, approximating a good ranking; in this case by diffusing scores.",
                "Why is ˜y a reasonable surrogate?",
                "We know that diffusion of scores on the web graph and language model graphs improves performance [14, 16].",
                "Therefore, if score diffusion tends to, in general, improve performance, then diffused scores will, in general, provide a good surrogate for relevance.",
                "Our results demonstrate that this approximation is not as powerful as information from multiple retrievals.",
                "Nevertheless, in situations where this information is lacking, autocorrelation provides substantial information.",
                "The success of autocorrelation as a predictor may also have roots in the clustering hypothesis.",
                "Recall that we regard autocorrelation as the degree to which a retrieval satisfies the clustering hypothesis.",
                "Our experiments, then, demonstrate that a failure to respect the clustering hypothesis correlates with poor performance.",
                "Why might systems fail to conform to the cluster hypothesis?",
                "Query-based <br>information retrieval</br> systems often score documents independently.",
                "The score of document a may be computed by examining query term or phrase matches, the document length, and perhaps global collection statistics.",
                "Once computed, a system rarely compares the score of a to the score of a topically-related document b.",
                "With some exceptions, the correlation of document scores has largely been ignored.",
                "We should make it clear that we have selected tasks where topical autocorrelation is appropriate.",
                "There are certainly cases where there is no reason to believe that retrieval scores will have topical autocorrelation.",
                "For example, ranked lists which incorporate document novelty should not exhibit spatial autocorrelation; if anything autocorrelation should be negative for this task.",
                "Similarly, answer candidates in a question-answering task may or may not exhibit autocorrelation; in this case, the semantics of links is questionable too.",
                "It is important before applying this measure to confirm that, given the semantics for some link between two retrieved items, we should expect a correlation between scores. 8.",
                "RELATED WORK In this section we draw more general comparisons to other work in performance prediction and spatial data analysis.",
                "There is a growing body of work which attempts to predict the performance of individual retrievals [7, 3, 11, 9, 19].",
                "We have attempted to place our work in the context of much of this work in Section 4.",
                "However, a complete comparison is beyond the scope of this paper.",
                "We note, though, that our experiments cover a larger and more diverse set of retrievals, collections, and topics than previously examined.",
                "Much previous work-particularly in the context of TRECfocuses on predicting the performance of systems.",
                "Here, each system generates k retrievals.",
                "The task is, given these retrievals, to predict the ranking of systems according to some performance measure.",
                "Several papers attempt to address this task under the constraint of few judgments [2, 4].",
                "Some work even attempts to use zero judgments by leveraging multiple retrievals for the same query [17].",
                "Our task differs because we focus on ranking retrievals independent of the generating system.",
                "The task here is not to test the hypothesis system A is superior to system B but to test the hypothesis retrieval A is superior to retrieval B. Autocorrelation manifests itself in many classification tasks.",
                "Neville and Jensen define relational autocorrelation for relational learning problems and demonstrate that many classification tasks manifest autocorrelation [13].",
                "Temporal autocorrelation of initial retrievals has also been used to predict performance [9].",
                "However, temporal autocorrelation is performed by projecting the retrieval function into the temporal embedding space.",
                "In our work, we focus on the behavior of the function over the relationships between documents. τ adjusted R2 DV KL P ρ(y, ˜y) DV KL P ρ(y, ˜y) DV KL, P DV KL, ρ(y, ˜y) Pρ(y, ˜y) β trec4 0.353 0.548 0.513 0.168 0.363 0.422 0.466 0.420 0.557 0.553 trec5 0.311 0.329 0.357 0.116 0.190 0.236 0.238 0.244 0.266 0.269 robust04 0.418 0.398 0.373 0.256 0.304 0.278 0.403 0.373 0.402 0.442 terabyte04 0.139 0.150 0.454 0.059 0.045 0.292 0.076 0.293 0.289 0.284 terabyte05 0.171 0.208 0.383 0.022 0.072 0.193 0.120 0.225 0.218 0.257 Table 1: Comparison to Robustness and Clarity measures for language model scores.",
                "Evaluation replicates experiments from [19].",
                "We present correlations between the classic Clarity measure (DV KL), the ranking robustness measure (P), and autocorrelation (ρ(y, ˜y)) each with mean average precision in terms of Kendalls τ.",
                "The adjusted coefficient of determination is presented to measure the effectiveness of combining predictors.",
                "Measures in bold represent the strongest correlation for that test/collection pair. multiple run (a) (b) (c) τ τ adjusted R2 DKL ρ(y, ˜y) Dn KL ρ(y, yµ) ρ(˜y, yµ) Dn KL ρ(y, ˜y) ρ(y, yµ) ρ(˜y, yµ) β trec3 0.201 0.461 0.461 0.439 0.456 0.444 0.395 0.394 0.386 0.498 trec4 0.252 0.396 0.455 0.482 0.489 0.379 0.263 0.429 0.482 0.483 trec5 0.016 0.277 0.433 0.459 0.393 0.280 0.157 0.375 0.323 0.386 trec6 0.230 0.227 0.352 0.428 0.418 0.203 0.089 0.323 0.325 0.325 trec7 0.083 0.326 0.341 0.430 0.483 0.264 0.182 0.363 0.442 0.400 trec8 0.235 0.396 0.454 0.508 0.567 0.402 0.272 0.490 0.580 0.523 robust03 0.302 0.354 0.377 0.385 0.447 0.269 0.206 0.274 0.392 0.303 robust04 0.183 0.308 0.301 0.384 0.453 0.200 0.182 0.301 0.393 0.335 robust05 0.224 0.249 0.371 0.377 0.404 0.341 0.108 0.313 0.328 0.336 terabyte04 0.043 0.245 0.544 0.420 0.392 0.516 0.105 0.357 0.343 0.365 terabyte05 0.068 0.306 0.480 0.434 0.390 0.491 0.168 0.384 0.309 0.403 trec4-spanish 0.307 0.388 0.488 0.398 0.395 0.423 0.299 0.282 0.299 0.388 trec5-spanish 0.220 0.458 0.446 0.484 0.475 0.411 0.398 0.428 0.437 0.529 trec5-chinese 0.092 0.199 0.367 0.379 0.384 0.379 0.199 0.273 0.276 0.310 trec6-chinese 0.144 0.276 0.265 0.353 0.376 0.115 0.128 0.188 0.223 0.199 ent05 - 0.181 0.324 0.305 0.282 0.211 0.043 0.158 0.155 0.179 Table 2: Large scale prediction experiments.",
                "We predict the ranking of large sets of retrievals for various collections and retrieval systems.",
                "Kendalls τ correlations are computed between the predicted ranking and a ranking based on the retrievals average precision.",
                "In column (a), we have predictors which do not use information from other retrievals for the same query.",
                "In columns (b) and (c) we present performance for predictors which incorporate information from multiple retrievals.",
                "The adjusted coefficient of determination is computed to determine effectiveness of combining predictors.",
                "Measures in bold represent the strongest correlation for that test/collection pair.",
                "Finally, regularization-based re-ranking processes are also closely-related to our work [8].",
                "These techniques seek to maximize the agreement between scores of related documents by solving a constrained optimization problem.",
                "The maximization of consistency is equivalent to maximizing the Moran autocorrelation.",
                "Therefore, we believe that our work provides explanation for why regularization-based re-ranking works. 9.",
                "CONCLUSION We have presented a new method for predicting the performance of a retrieval ranking without any relevance judgments.",
                "We consider two cases.",
                "First, when making predictions in the absence of retrievals from other systems, our predictors demonstrate robust, strong correlations with average precision.",
                "This performance, combined with a simple implementation, makes our predictors, in particular, very attractive.",
                "We have demonstrated this improvement for many, diverse settings.",
                "To our knowledge, this is the first large scale examination of zero-judgment, single-retrieval performance prediction.",
                "Second, when provided retrievals from other systems, our extended methods demonstrate competitive performance with state of the art baselines.",
                "Our experiments also demonstrate the limits of the usefulness of our predictors when information from multiple runs is provided.",
                "Our results suggest two conclusions.",
                "First, our results could affect retrieval algorithm design.",
                "Retrieval algorithms designed to consider spatial autocorrelation will conform to the cluster hypothesis and improve performance.",
                "Second, our results could affect the design of minimal test collection algorithms.",
                "Much of the recent work in ranking systems sometimes ignores correlations between document labels and scores.",
                "We believe that these two directions could be rewarding given the theoretical and experimental evidence in this paper. 10.",
                "ACKNOWLEDGMENTS This work was supported in part by the Center for Intelligent <br>information retrieval</br> and in part by the Defense Advanced Research Projects Agency (DARPA) under contract number HR0011-06-C-0023.",
                "Any opinions, findings and conclusions or recommendations expressed in this material are the authors and do not necessarily reflect those of the sponsor.",
                "We thank Yun Zhou and Desislava Petkova for providing data and Andre Gauthier for technical assistance. 11.",
                "REFERENCES [1] J. Aslam and V. Pavlu.",
                "Query hardness estimation using jensen-shannon divergence among multiple scoring functions.",
                "In ECIR 2007: Proceedings of the 29th European Conference on <br>information retrieval</br>, 2007. [2] J.",
                "A. Aslam, V. Pavlu, and E. Yilmaz.",
                "A statistical method for system evaluation using incomplete judgments.",
                "In S. Dumais, E. N. Efthimiadis, D. Hawking, and K. Jarvelin, editors, Proceedings of the 29th Annual International ACM SIGIR Conference on Research and Development in <br>information retrieval</br>, pages 541-548.",
                "ACM Press, August 2006. [3] D. Carmel, E. Yom-Tov, A. Darlow, and D. Pelleg.",
                "What makes a query difficult?",
                "In SIGIR 06: Proceedings of the 29th annual international ACM SIGIR conference on Research and development in <br>information retrieval</br>, pages 390-397, New York, NY, USA, 2006.",
                "ACM Press. [4] B. Carterette, J. Allan, and R. Sitaraman.",
                "Minimal test collections for retrieval evaluation.",
                "In SIGIR 06: Proceedings of the 29th annual international ACM SIGIR conference on Research and development in <br>information retrieval</br>, pages 268-275, New York, NY, USA, 2006.",
                "ACM Press. [5] A. D. Cliff and J. K. Ord.",
                "Spatial Autocorrelation.",
                "Pion Ltd., 1973. [6] M. Connell, A. Feng, G. Kumaran, H. Raghavan, C. Shah, and J. Allan.",
                "Umass at tdt 2004.",
                "Technical Report CIIR Technical Report IR - 357, Department of Computer Science, University of Massachusetts, 2004. [7] S. Cronen-Townsend, Y. Zhou, and W. B. Croft.",
                "Precision prediction based on ranked list coherence.",
                "Inf.",
                "Retr., 9(6):723-755, 2006. [8] F. Diaz.",
                "Regularizing ad-hoc retrieval scores.",
                "In CIKM 05: Proceedings of the 14th ACM international conference on Information and knowledge management, pages 672-679, New York, NY, USA, 2005.",
                "ACM Press. [9] F. Diaz and R. Jones.",
                "Using temporal profiles of queries for precision prediction.",
                "In SIGIR 04: Proceedings of the 27th annual international ACM SIGIR conference on Research and development in <br>information retrieval</br>, pages 18-24, New York, NY, USA, 2004.",
                "ACM Press. [10] D. A. Griffith.",
                "Spatial Autocorrelation and Spatial Filtering.",
                "Springer Verlag, 2003. [11] B.",
                "He and I. Ounis.",
                "Inferring Query Performance Using Pre-retrieval Predictors.",
                "In The Eleventh Symposium on String Processing and <br>information retrieval</br> (SPIRE), 2004. [12] N. Jardine and C. J. V. Rijsbergen.",
                "The use of hierarchic clustering in <br>information retrieval</br>.",
                "Information Storage and Retrieval, 7:217-240, 1971. [13] D. Jensen and J. Neville.",
                "Linkage and autocorrelation cause feature selection bias in relational learning.",
                "In ICML 02: Proceedings of the Nineteenth International Conference on Machine Learning, pages 259-266, San Francisco, CA, USA, 2002.",
                "Morgan Kaufmann Publishers Inc. [14] O. Kurland and L. Lee.",
                "Corpus structure, language models, and ad-hoc <br>information retrieval</br>.",
                "In SIGIR 04: Proceedings of the 27th annual international conference on Research and development in <br>information retrieval</br>, pages 194-201, New York, NY, USA, 2004.",
                "ACM Press. [15] M. Montague and J.",
                "A. Aslam.",
                "Relevance score normalization for metasearch.",
                "In CIKM 01: Proceedings of the tenth international conference on Information and knowledge management, pages 427-433, New York, NY, USA, 2001.",
                "ACM Press. [16] T. Qin, T.-Y.",
                "Liu, X.-D. Zhang, Z. Chen, and W.-Y.",
                "Ma.",
                "A study of relevance propagation for web search.",
                "In SIGIR 05: Proceedings of the 28th annual international ACM SIGIR conference on Research and development in <br>information retrieval</br>, pages 408-415, New York, NY, USA, 2005.",
                "ACM Press. [17] I. Soboroff, C. Nicholas, and P. Cahan.",
                "Ranking retrieval systems without relevance judgments.",
                "In SIGIR 01: Proceedings of the 24th annual international ACM SIGIR conference on Research and development in <br>information retrieval</br>, pages 66-73, New York, NY, USA, 2001.",
                "ACM Press. [18] V. Vinay, I. J. Cox, N. Milic-Frayling, and K. Wood.",
                "On ranking the effectiveness of searches.",
                "In SIGIR 06: Proceedings of the 29th annual international ACM SIGIR conference on Research and development in <br>information retrieval</br>, pages 398-404, New York, NY, USA, 2006.",
                "ACM Press. [19] Y. Zhou and W. B. Croft.",
                "Ranking robustness: a novel framework to predict query performance.",
                "In CIKM 06: Proceedings of the 15th ACM international conference on Information and knowledge management, pages 567-574, New York, NY, USA, 2006.",
                "ACM Press."
            ],
            "original_annotated_samples": [
                "Performance Prediction Using Spatial Autocorrelation Fernando Diaz Center for Intelligent <br>information retrieval</br> Department of Computer Science University of Massachusetts Amherst, MA 01003 fdiaz@cs.umass.edu ABSTRACT Evaluation of <br>information retrieval</br> systems is one of the core tasks in information retrieval.",
                "INTRODUCTION In <br>information retrieval</br>, a user poses a query to a system.",
                "PROBLEM DEFINITION Given a query, an <br>information retrieval</br> system produces a ranking of documents in the collection encoded as a set of scores associated with documents.",
                "SPATIAL CORRELATION In <br>information retrieval</br>, we often assume that the representations of documents exist in some high-dimensional vector space.",
                "Because of the prevalence and success of spatial models of <br>information retrieval</br>, we believe that the application of spatial data analysis techniques are appropriate."
            ],
            "translated_annotated_samples": [
                "Predicción del rendimiento utilizando autocorrelación espacial. Fernando Díaz. Centro de Recuperación de Información Inteligente. Departamento de Ciencias de la Computación. Universidad de Massachusetts Amherst, MA 01003. fdiaz@cs.umass.edu. RESUMEN La evaluación de sistemas de <br>recuperación de información</br> es una de las tareas fundamentales en la <br>recuperación de información</br>.",
                "En la <br>recuperación de información</br>, un usuario plantea una consulta a un sistema.",
                "Dada una consulta, un sistema de <br>recuperación de información</br> produce una clasificación de documentos en la colección codificada como un conjunto de puntuaciones asociadas con los documentos.",
                "CORRELACIÓN ESPACIAL En la <br>recuperación de información</br>, a menudo asumimos que las representaciones de los documentos existen en algún espacio vectorial de alta dimensión.",
                "Debido a la prevalencia y éxito de los modelos espaciales de <br>recuperación de información</br>, creemos que la aplicación de técnicas de análisis de datos espaciales es apropiada."
            ],
            "translated_text": "Predicción del rendimiento utilizando autocorrelación espacial. Fernando Díaz. Centro de Recuperación de Información Inteligente. Departamento de Ciencias de la Computación. Universidad de Massachusetts Amherst, MA 01003. fdiaz@cs.umass.edu. RESUMEN La evaluación de sistemas de <br>recuperación de información</br> es una de las tareas fundamentales en la <br>recuperación de información</br>. Los problemas incluyen la incapacidad de etiquetar exhaustivamente todos los documentos sobre un tema, la falta de generalización a partir de un pequeño número de temas e incorporar la variabilidad de los sistemas de recuperación. Trabajos anteriores abordan la evaluación de sistemas, la clasificación de consultas por dificultad y la clasificación de recuperaciones individuales por rendimiento. Existen enfoques para el caso de pocos e incluso ningún juicio de relevancia. Nuestro enfoque está en la predicción del rendimiento sin juicios de las recuperaciones individuales. Una deficiencia común de las técnicas anteriores es la suposición de que las puntuaciones de los documentos y los juicios no están correlacionados. Si los documentos están incrustados en un espacio de alta dimensión (como a menudo lo están), podemos aplicar técnicas de análisis de datos espaciales para detectar correlaciones entre las puntuaciones de los documentos. Observamos que la baja correlación entre las puntuaciones de documentos temáticamente cercanos a menudo implica un bajo rendimiento en la recuperación. Cuando se compara con una línea base de última generación, demostramos que el análisis espacial de las puntuaciones de recuperación ofrece un rendimiento predictivo significativamente mejor. Estos nuevos predictores también pueden ser incorporados con predictores clásicos para mejorar aún más el rendimiento. También describimos el primer experimento a gran escala para evaluar la predicción de rendimiento sin juicio para un gran número de sistemas de recuperación en una variedad de colecciones en varios idiomas. Categorías y Descriptores de Asignaturas H.3.3 [Búsqueda y Recuperación de Información]: Modelos de recuperación; H.3.4 [Sistemas y Software]: Evaluación del rendimiento (eficiencia y efectividad) Términos Generales Rendimiento, Diseño, Confiabilidad, Experimentación 1. En la <br>recuperación de información</br>, un usuario plantea una consulta a un sistema. El sistema recupera n documentos, cada uno recibiendo una puntuación de valor real que indica el grado de relevancia predicho. Si seleccionamos aleatoriamente pares de documentos de este conjunto, esperamos que algunos pares compartan el mismo tema y otros pares no compartan el mismo tema. Toma dos documentos relacionados entre sí del conjunto y llámalos a y b. Si las puntuaciones de a y b son muy diferentes, podríamos estar preocupados por el rendimiento de nuestro sistema. Es decir, si tanto a como b están relacionados con el tema de la consulta, nos gustaría que ambos reciban una puntuación alta; si a y b no están relacionados con el tema de la consulta, nos gustaría que ambos reciban una puntuación baja. Podríamos preocuparnos más a medida que encontramos más diferencias entre las puntuaciones de documentos relacionados. Estaríamos más cómodos con una recuperación en la que las puntuaciones sean consistentes entre documentos relacionados. Nuestro artículo estudia la cuantificación de esta inconsistencia en una recuperación desde una perspectiva espacial. El análisis espacial es apropiado ya que muchos modelos de recuperación incrustan documentos en algún espacio vectorial. Si los documentos están incrustados en un espacio, la proximidad se correlaciona con las relaciones temáticas. La consistencia de la puntuación puede medirse mediante la versión espacial de la autocorrelación conocida como el coeficiente de Moran o IM [5, 10]. En este artículo, demostramos una fuerte correlación entre IM y el rendimiento de recuperación. La discusión hasta este punto recuerda a la hipótesis del cúmulo. La hipótesis del clúster establece que los documentos estrechamente relacionados tienden a ser relevantes para la misma solicitud [12]. Como veremos, una función de recuperación de medidas de autocorrelación espacial mide el grado en que los documentos relacionados reciben puntuaciones similares. Debido a esto, interpretamos la autocorrelación como la medida del grado en que una función de recuperación satisface la hipótesis de agrupamiento. Si esta conexión es razonable, en la Sección 6 presentamos evidencia de que la falta de cumplimiento de la hipótesis de agrupamiento se correlaciona fuertemente con un bajo rendimiento. En este trabajo, proporcionamos las siguientes contribuciones: 1. Un método general y robusto para predecir el rendimiento de recuperaciones sin juicios de relevancia (Sección 3). 2. Un tratamiento teórico de las similitudes y motivaciones detrás de varias técnicas de predicción de rendimiento de vanguardia (Sección 4). 3. Las primeras experimentaciones a gran escala de predicción de rendimiento de una sola ejecución sin juicio (Secciones 5 y 6). 2. Dada una consulta, un sistema de <br>recuperación de información</br> produce una clasificación de documentos en la colección codificada como un conjunto de puntuaciones asociadas con los documentos. Nos referimos al conjunto de puntuaciones para una combinación particular de consulta-sistema como una recuperación. Nos gustaría predecir el rendimiento de esta recuperación con respecto a alguna medida de evaluación (por ejemplo, precisión promedio). En este artículo, presentamos resultados para clasificar recuperaciones de sistemas arbitrarios. Nos gustaría que este ranking se aproximara al ranking de recuperaciones según la medida de evaluación. Esto es diferente de clasificar las consultas por el rendimiento promedio en cada consulta. También es diferente de los sistemas de clasificación por el rendimiento promedio en un conjunto de consultas. Las puntuaciones a menudo solo se calculan para los primeros n documentos de la colección. Colocamos estos puntajes en el vector de longitud n, y, donde yi se refiere al puntaje del documento clasificado en la posición i. Ajustamos las puntuaciones para que tengan una media de cero y una varianza unitaria. Utilizamos este método debido a su simplicidad y su éxito en trabajos anteriores [15]. CORRELACIÓN ESPACIAL En la <br>recuperación de información</br>, a menudo asumimos que las representaciones de los documentos existen en algún espacio vectorial de alta dimensión. Por ejemplo, dado un vocabulario, V, este espacio vectorial puede ser un espacio arbitrario de dimensión |V| con producto interno de coseno o un simplejo multinomial con una medida de distancia basada en distribución. Un espacio de incrustación suele ser seleccionado para respetar la proximidad temática; si dos documentos están cerca, es más probable que compartan un tema. Debido a la prevalencia y éxito de los modelos espaciales de <br>recuperación de información</br>, creemos que la aplicación de técnicas de análisis de datos espaciales es apropiada. ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "spatial autocorrelation": {
            "translated_key": "autocorrelación espacial",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Performance Prediction Using <br>spatial autocorrelation</br> Fernando Diaz Center for Intelligent Information Retrieval Department of Computer Science University of Massachusetts Amherst, MA 01003 fdiaz@cs.umass.edu ABSTRACT Evaluation of information retrieval systems is one of the core tasks in information retrieval.",
                "Problems include the inability to exhaustively label all documents for a topic, nongeneralizability from a small number of topics, and incorporating the variability of retrieval systems.",
                "Previous work addresses the evaluation of systems, the ranking of queries by difficulty, and the ranking of individual retrievals by performance.",
                "Approaches exist for the case of few and even no relevance judgments.",
                "Our focus is on zero-judgment performance prediction of individual retrievals.",
                "One common shortcoming of previous techniques is the assumption of uncorrelated document scores and judgments.",
                "If documents are embedded in a high-dimensional space (as they often are), we can apply techniques from spatial data analysis to detect correlations between document scores.",
                "We find that the low correlation between scores of topically close documents often implies a poor retrieval performance.",
                "When compared to a state of the art baseline, we demonstrate that the spatial analysis of retrieval scores provides significantly better prediction performance.",
                "These new predictors can also be incorporated with classic predictors to improve performance further.",
                "We also describe the first large-scale experiment to evaluate zero-judgment performance prediction for a massive number of retrieval systems over a variety of collections in several languages.",
                "Categories and Subject Descriptors H.3.3 [Information Search and Retrieval]: Retrieval models; H.3.4 [Systems and Software]: Performance evaluation (efficiency and effectiveness) General Terms Performance, Design, Reliability, Experimentation 1.",
                "INTRODUCTION In information retrieval, a user poses a query to a system.",
                "The system retrieves n documents each receiving a realvalued score indicating the predicted degree of relevance.",
                "If we randomly select pairs of documents from this set, we expect some pairs to share the same topic and other pairs to not share the same topic.",
                "Take two topically-related documents from the set and call them a and b.",
                "If the scores of a and b are very different, we may be concerned about the performance of our system.",
                "That is, if a and b are both on the topic of the query, we would like them both to receive a high score; if a and b are not on the topic of the query, we would like them both to receive a low score.",
                "We might become more worried as we find more differences between scores of related documents.",
                "We would be more comfortable with a retrieval where scores are consistent between related documents.",
                "Our paper studies the quantification of this inconsistency in a retrieval from a spatial perspective.",
                "Spatial analysis is appropriate since many retrieval models embed documents in some vector space.",
                "If documents are embedded in a space, proximity correlates with topical relationships.",
                "Score consistency can be measured by the spatial version of autocorrelation known as the Moran coefficient or IM [5, 10].",
                "In this paper, we demonstrate a strong correlation between IM and retrieval performance.",
                "The discussion up to this point is reminiscent of the cluster hypothesis.",
                "The cluster hypothesis states: closely-related documents tend to be relevant to the same request [12].",
                "As we shall see, a retrieval functions <br>spatial autocorrelation</br> measures the degree to which closely-related documents receive similar scores.",
                "Because of this, we interpret autocorrelation as measuring the degree to which a retrieval function satisfies the clustering hypothesis.",
                "If this connection is reasonable, in Section 6, we present evidence that failure to satisfy the cluster hypothesis correlates strongly with poor performance.",
                "In this work, we provide the following contributions, 1.",
                "A general, robust method for predicting the performance of retrievals with zero relevance judgments (Section 3). 2.",
                "A theoretical treatment of the similarities and motivations behind several state-of-the-art performance prediction techniques (Section 4). 3.",
                "The first large-scale experiments of zero-judgment, single run performance prediction (Sections 5 and 6). 2.",
                "PROBLEM DEFINITION Given a query, an information retrieval system produces a ranking of documents in the collection encoded as a set of scores associated with documents.",
                "We refer to the set of scores for a particular query-system combination as a retrieval.",
                "We would like to predict the performance of this retrieval with respect to some evaluation measure (eg, mean average precision).",
                "In this paper, we present results for ranking retrievals from arbitrary systems.",
                "We would like this ranking to approximate the ranking of retrievals by the evaluation measure.",
                "This is different from ranking queries by the average performance on each query.",
                "It is also different from ranking systems by the average performance on a set of queries.",
                "Scores are often only computed for the top n documents from the collection.",
                "We place these scores in the length n vector, y, where yi refers to the score of the ith-ranked document.",
                "We adjust scores to have zero mean and unit variance.",
                "We use this method because of its simplicity and its success in previous work [15]. 3.",
                "SPATIAL CORRELATION In information retrieval, we often assume that the representations of documents exist in some high-dimensional vector space.",
                "For example, given a vocabulary, V, this vector space may be an arbitrary |V|-dimensional space with cosine inner-product or a multinomial simplex with a distributionbased distance measure.",
                "An embedding space is often selected to respect topical proximity; if two documents are near, they are more likely to share a topic.",
                "Because of the prevalence and success of spatial models of information retrieval, we believe that the application of spatial data analysis techniques are appropriate.",
                "Whereas in information retrieval, we are concerned with the score at a point in a space, in spatial data analysis, we are concerned with the value of a function at a point or location in a space.",
                "We use the term function here to mean a mapping from a location to a real value.",
                "For example, we might be interested in the prevalence of a disease in the neighborhood of some city.",
                "The function would map the location of a neighborhood to an infection rate.",
                "If we want to quantify the spatial dependencies of a function, we would employ a measure referred to as the <br>spatial autocorrelation</br> [5, 10].",
                "High <br>spatial autocorrelation</br> suggests that knowing the value of a function at location a will tell us a great deal about the value at a neighboring location b.",
                "There is a high <br>spatial autocorrelation</br> for a function representing the temperature of a location since knowing the temperature at a location a will tell us a lot about the temperature at a neighboring location b.",
                "Low <br>spatial autocorrelation</br> suggests that knowing the value of a function at location a tells us little about the value at a neighboring location b.",
                "There is low <br>spatial autocorrelation</br> in a function measuring the outcome of a coin toss at a and b.",
                "In this section, we will begin by describing what we mean by spatial proximity for documents and then define a measure of <br>spatial autocorrelation</br>.",
                "We conclude by extending this model to include information from multiple retrievals from multiple systems for a single query. 3.1 Spatial Representation of Documents Our work does not focus on improving a specific similarity measure or defining a novel vector space.",
                "Instead, we choose an inner product known to be effective at detecting interdocument topical relationships.",
                "Specifically, we adopt tf.idf document vectors, ˜di = di log „ (n + 0.5) − ci 0.5 + ci « (1) where d is a vector of term frequencies, c is the length-|V| document frequency vector.",
                "We use this weighting scheme due to its success for topical link detection in the context of Topic Detection and Tracking (TDT) evaluations [6].",
                "Assuming vectors are scaled by their L2 norm, we use the inner product, ˜di, ˜dj , to define similarity.",
                "Given documents and some similarity measure, we can construct a matrix which encodes the similarity between pairs of documents.",
                "Recall that we are given the top n documents retrieved in y.",
                "We can compute an n × n similarity matrix, W. An element of this matrix, Wij represents the similarity between documents ranked i and j.",
                "In practice, we only include the affinities for a documents k-nearest neighbors.",
                "In all of our experiments, we have fixed k to 5.",
                "We leave exploration of parameter sensitivity to future work.",
                "We also row normalize the matrix so that Pn j=1 Wij = 1 for all i. 3.2 <br>spatial autocorrelation</br> of a Retrieval Recall that we are interested in measuring the similarity between the scores of spatially-close documents.",
                "One such suitable measure is the Moran coefficient of <br>spatial autocorrelation</br>.",
                "Assuming the function y over n locations, this is defined as ˜IM = n eTWe P i,j Wijyiyj P i y2 i = n eTWe yT Wy yTy (2) where eT We = P ij Wij.",
                "We would like to compare autocorrelation values for different retrievals.",
                "Unfortunately, the bound for Equation 2 is not consistent for different W and y.",
                "Therefore, we use the Cauchy-Schwartz inequality to establish a bound, ˜IM ≤ n eTWe s yTWTWy yTy And we define the normalized <br>spatial autocorrelation</br> as IM = yT Wy p yTy × yTWTWy Notice that if we let ˜y = Wy, then we can write this formula as, IM = yT ˜y y 2 ˜y 2 (3) which can be interpreted as the correlation between the original retrieval scores and a set of retrieval scores diffused in the space.",
                "We present some examples of autocorrelations of functions on a grid in Figure 1. 3.3 Correlation with Other Retrievals Sometimes we are interested in the performance of a single retrieval but have access to scores from multiple systems for (a) IM = 0.006 (b) IM = 0.241 (c) IM = 0.487 Figure 1: The Moran coefficient, IM for a several binary functions on a grid.",
                "The Moran coefficient is a local measure of function consistency.",
                "From the perspective of information retrieval, each of these grid spaces would represent a document and documents would be organized so that they lay next to topically-related documents.",
                "Binary retrieval scores would define a pattern on this grid.",
                "Notice that, as the Moran coefficient increases, neighboring cells tend to have similar values. the same query.",
                "In this situation, we can use combined information from these scores to construct a surrogate for a high-quality ranking [17].",
                "We can treat the correlation between the retrieval we are interested in and the combined scores as a predictor of performance.",
                "Assume that we are given m score functions, yi, for the same n documents.",
                "We will represent the mean of these vectors as yµ = Pm i=1 yi.",
                "We use the mean vector as an approximation to relevance.",
                "Since we use zero mean and unit variance normalization, work in metasearch suggests that this assumption is justified [15].",
                "Because yµ represents a very good retrieval, we hypothesize that a strong similarity between yµ and y will correlate positively with system performance.",
                "We use Pearsons product-moment correlation to measure the similarity between these vectors, ρ(y, yµ) = yT yµ y 2 yµ 2 (4) We will comment on the similarity between Equation 3 and 4 in Section 7.",
                "Of course, we can combine ρ(y, ˜y) and ρ(y, yµ) if we assume that they capture different factors in the prediction.",
                "One way to accomplish this is to combine these predictors as independent variables in a linear regression.",
                "An alternative means of combination is suggested by the mathematical form of our predictors.",
                "Since ˜y encodes the spatial dependencies in y and yµ encodes the spatial properties of the multiple runs, we can compute a third correlation between these two vectors, ρ(˜y, yµ) = ˜yT yµ ˜y 2 yµ 2 (5) We can interpret Equation 5 as measuring the correlation between a high quality ranking (yµ) and a spatially smoothed version of the retrieval (˜y). 4.",
                "RELATIONSHIP WITH OTHER PREDICTORS One way to predict the effectiveness of a retrieval is to look at the shared vocabulary of the top n retrieved documents.",
                "If we computed the most frequent content words in this set, we would hope that they would be consistent with our topic.",
                "In fact, we might believe that a bad retrieval would include documents on many disparate topics, resulting in an overlap of terminological noise.",
                "The Clarity of a query attempts to quantify exactly this [7].",
                "Specifically, Clarity measures the similarity of the words most frequently used in retrieved documents to those most frequently used in the whole corpus.",
                "The conjecture is that a good retrieval will use language distinct from general text; the overlapping language in a bad retrieval will tend to be more similar to general text.",
                "Mathematically, we can compute a representation of the language used in the initial retrieval as a weighted combination of document language models, P(w|θQ) = nX i=1 P(w|θi) P(Q|θi) Z (6) where θi is the language model of the ith-ranked document, P(Q|θi) is the query likelihood score of the ith-ranked document and Z = Pn i=1 P(Q|θi) is a normalization constant.",
                "The similarity between the multinomial P(w|θQ) and a model of general text can be computed using the Kullback-Leibler divergence, DV KL(θQ θC ).",
                "Here, the distribution P(w|θC ) is our model of general text which can be computed using term frequencies in the corpus.",
                "In Figure 2a, we present Clarity as measuring the distance between the weighted center of mass of the retrieval (labeled y) and the unweighted center of mass of the collection (labeled O).",
                "Clarity reaches a minimum when a retrieval assigns every document the same score.",
                "Lets again assume we have a set of n documents retrieved for our query.",
                "Another way to quantify the dispersion of a set of documents is to look at how clustered they are.",
                "We may hypothesize that a good retrieval will return a single, tight cluster.",
                "A poorly performing retrieval will return a loosely related set of documents covering many topics.",
                "One proposed method of quantifying this dispersion is to measure the distance from a random document a to its nearest neighbor, b.",
                "A retrieval which is tightly clustered will, on average, have a low distance between a and b; a retrieval which is less tightly-closed will, on average have high distances between a and b.",
                "This average corresponds to using the Cox-Lewis statistic to measure the randomness of the top n documents retrieved from a system [18].",
                "In Figure 2a, this is roughly equivalent to measuring the area of the set n. Notice that we are throwing away information about the retrieval function y.",
                "Therefore the Cox-Lewis statistic is highly dependent on selecting the top n documents.1 Remember that we have n documents and a set of scores.",
                "Lets assume that we have access to the system which provided the original scores and that we can also request scores for new documents.",
                "This suggests a third method for predicting performance.",
                "Take some document, a, from the retrieved set and arbitrarily add or remove words at random to create a new document ˜a.",
                "Now, we can ask our system to score ˜a with respect to our query.",
                "If, on average over the n documents, the scores of a and ˜a tend to be very different, we might suspect that the system is failing on this query.",
                "So, an alternative approach is to measure the simi1 The authors have suggested coupling the query with the distance measure [18].",
                "The information introduced by the query, though, is retrieval-independent so that, if two retrievals return the same set of documents, the approximate Cox-Lewis statistic will be the same regardless of the retrieval scores. yOy (a) Global Divergence µ(y)˜y y (b) Score Perturbation µ(y) y (c) Multirun Averaging Figure 2: Representation of several performance predictors on a grid.",
                "In Figure 2a, we depict predictors which measure the divergence between the center of mass of a retrieval and the center of the embedding space.",
                "In Figure 2b, we depict predictors which compare the original retrieval, y, to a perturbed version of the retrieval, ˜y.",
                "Our approach uses a particular type of perturbation based on score diffusion.",
                "Finally, in Figure 2c, we depict prediction when given retrievals from several other systems on the same query.",
                "Here, we can consider the fusion of these retrieval as a surrogate for relevance. larity between the retrieval and a perturbed version of that retrieval [18, 19].",
                "This can be accomplished by either perturbing the documents or queries.",
                "The similarity between the two retrievals can be measured using some correlation measure.",
                "This is depicted in Figure 2b.",
                "The upper grid represents the original retrieval, y, while the lower grid represents the function after having been perturbed, ˜y.",
                "The nature of the perturbation process requires additional scorings or retrievals.",
                "Our predictor does not require access to the original scoring function or additional retrievals.",
                "So, although our method is similar to other perturbation methods in spirit, it can be applied in situations when the retrieval system is inaccessible or costly to access.",
                "Finally, assume that we have, in addition to the retrieval we want to evaluate, m retrievals from a variety of different systems.",
                "In this case, we might take a document a, compare its rank in the retrieval to its average rank in the m retrievals.",
                "If we believe that the m retrievals provide a satisfactory approximation to relevance, then a very large difference in rank would suggest that our retrieval is misranking a.",
                "If this difference is large on average over all n documents, then we might predict that the retrieval is bad.",
                "If, on the other hand, the retrieval is very consistent with the m retrievals, then we might predict that the retrieval is good.",
                "The similarity between the retrieval and the combined retrieval may be computed using some correlation measure.",
                "This is depicted in Figure 2c.",
                "In previous work, the Kullback-Leibler divergence between the normalized scores of the retrieval and the normalized scores of the combined retrieval provides the similarity [1]. 5.",
                "EXPERIMENTS Our experiments focus on testing the predictive power of each of our predictors: ρ(y, ˜y), ρ(y, yµ), and ρ(˜y, yµ).",
                "As stated in Section 2, we are interested in predicting the performance of the retrieval generated by an arbitrary system.",
                "Our methodology is consistent with previous research in that we predict the relative performance of a retrieval by comparing a ranking based on our predictor to a ranking based on average precision.",
                "We present results for two sets of experiments.",
                "The first set of experiments presents detailed comparisons of our predictors to previously-proposed predictors using identical data sets.",
                "Our second set of experiments demonstrates the generalizability of our approach to arbitrary retrieval methods, corpus types, and corpus languages. 5.1 Detailed Experiments In these experiments, we will predict the performance of language modeling scores using our autocorrelation predictor, ρ(y, ˜y); we do not consider ρ(y, yµ) or ρ(˜y, yµ) because, in these detailed experiments, we focus on ranking the retrievals from a single system.",
                "We use retrievals, values for baseline predictors, and evaluation measures reported in previous work [19]. 5.1.1 Topics and Collections These performance prediction experiments use language model retrievals performed for queries associated with collections in the TREC corpora.",
                "Using TREC collections allows us to confidently associate an average precision with a retrieval.",
                "In these experiments, we use the following topic collections: TREC 4 ad-hoc, TREC 5 ad-hoc, Robust 2004, Terabyte 2004, and Terabyte 2005. 5.1.2 Baselines We provide two baselines.",
                "Our first baseline is the classic Clarity predictor presented in Equation 6.",
                "Clarity is designed to be used with language modeling systems.",
                "Our second baseline is Zhou and Crofts ranking robustness predictor.",
                "This predictor corrupts the top k documents from retrieval and re-computes the language model scores for these corrupted documents.",
                "The value of the predictor is the Spearman rank correlation between the original ranking and the corrupted ranking.",
                "In our tables, we will label results for Clarity using DV KL and the ranking robustness predictor using P. 5.2 Generalizability Experiments Our predictors do not require a particular baseline retrieval system; the predictors can be computed for an arbitrary retrieval, regardless of how scores were generated.",
                "We believe that that is one of the most attractive aspects of our algorithm.",
                "Therefore, in a second set of experiments, we demonstrate the ability of our techniques to generalize to a variety of collections, topics, and retrieval systems. 5.2.1 Topics and Collections We gathered a diverse set of collections from all possible TREC corpora.",
                "We cast a wide net in order to locate collections where our predictors might fail.",
                "Our hypothesis is that documents with high topical similarity should have correlated scores.",
                "Therefore, we avoided collections where scores were unlikely to be correlated (eg, question-answering) or were likely to be negatively correlated (eg, novelty).",
                "Nevertheless, our collections include corpora where correlations are weakly justified (eg, non-English corpora) or not justified at all (eg, expert search).",
                "We use the ad-hoc tracks from TREC3-8, TREC Robust 2003-2005, TREC Terabyte 20042005, TREC4-5 Spanish, TREC5-6 Chinese, and TREC Enterprise Expert Search 2005.",
                "In all cases, we use only the automatic runs for ad-hoc tracks submitted to NIST.",
                "For all English and Spanish corpora, we construct the matrix W according to the process described in Section 3.1.",
                "For Chinese corpora, we use na¨ıve character-based tf.idf vectors.",
                "For entities, entries in W are proportional to the number of documents in which two entities cooccur. 5.2.2 Baselines In our detailed experiments, we used the Clarity measure as a baseline.",
                "Since we are predicting the performance of retrievals which are not based on language modeling, we use a version of Clarity referred to as ranked-list Clarity [7].",
                "Ranked-list clarity converts document ranks to P(Q|θi) values.",
                "This conversion begins by replacing all of the scores in y with the respective ranks.",
                "Our estimation of P(Q|θi) from the ranks, then is, P(Q|θi) = ( 2(c+1−yi) c(c+1) if yi ≤ c 0 otherwise (7) where c is a cutoff parameter.",
                "As suggested by the authors, we fix the algorithm parameters c and λ2 so that c = 60 and λ2 = 0.10.",
                "We use Equation 6 to estimate P(w|θQ) and DV KL(θQ θC ) to compute the value of the predictor.",
                "We will refer to this predictor as DV KL, superscripted by V to indicate that the Kullback-Leibler divergence is with respect to the term embedding space.",
                "When information from multiple runs on the same query is available, we use Aslam and Pavlus document-space multinomial divergence as a baseline [1].",
                "This rank-based method first normalizes the scores in a retrieval as an n-dimensional multinomial.",
                "As with ranked-list Clarity, we begin by replacing all of the scores in y with their respective ranks.",
                "Then, we adjust the elements of y in the following way, ˆyi = 1 2n 0 @1 + nX k=yi 1 k 1 A (8) In our multirun experiments, we only use the top 75 documents from each retrieval (n = 75); this is within the range of parameter values suggested by the authors.",
                "However, we admit not tuning this parameter for either our system or the baseline.",
                "The predictor is the divergence between the candidate distribution, y, and the mean distribution, yµ .",
                "With the uniform linear combination of these m retrievals represented as yµ, we can compute the divergence as Dn KL(ˆy ˆyµ) where we use the superscript n to indicate that the summation is over the set of n documents.",
                "This baseline was developed in the context of predicting query difficulty but we adopt it as a reasonable baseline for predicting retrieval performance. 5.2.3 Parameter Settings When given multiple retrievals, we use documents in the union of the top k = 75 documents from each of the m retrievals for that query.",
                "If the size of this union is ˜n, then yµ and each yi is of length ˜n.",
                "In some cases, a system did not score a document in the union.",
                "Since we are making a Gaussian assumption about our scores, we can sample scores for these unseen documents from the negative tail of the distribution.",
                "Specifically, we sample from the part of the distribution lower than the minimum value of in the normalized retrieval.",
                "This introduces randomness into our algorithm but we believe it is more appropriate than assigning an arbitrary fixed value.",
                "We optimized the linear regression using the square root of each predictor.",
                "We found that this substantially improved fits for all predictors, including the baselines.",
                "We considered linear combinations of pairs of predictors (labeled by the components) and all predictors (labeled as β). 5.3 Evaluation Given a set of retrievals, potentially from a combination of queries and systems, we measure the correlation of the rank ordering of this set by the predictor and by the performance metric.",
                "In order to ensure comparability with previous results, we present Kendalls τ correlation between the predictors ranking and ranking based on average precision of the retrieval.",
                "Unless explicitly noted, all correlations are significant with p < 0.05.",
                "Predictors can sometimes perform better when linearly combined [9, 11].",
                "Although previous work has presented the coefficient of determination (R2 ) to measure the quality of the regression, this measure cannot be reliably used when comparing slight improvements from combining predictors.",
                "Therefore, we adopt the adjusted coefficient of determination which penalizes models with more variables.",
                "The adjusted R2 allows us to evaluate the improvement in prediction achieved by adding a parameter but loses the statistical interpretation of R2 .",
                "We will use Kendalls τ to evaluate the magnitude of the correlation and the adjusted R2 to evaluate the combination of variables. 6.",
                "RESULTS We present results for our detailed experiments comparing the prediction of language model scores in Table 1.",
                "Although the Clarity measure is theoretically designed for language model scores, it consistently underperforms our system-agnostic predictor.",
                "Ranking robustness was presented as an improvement to Clarity for web collections (represented in our experiments by the terabyte04 and terabyte05 collections), shifting the τ correlation from 0.139 to 0.150 for terabyte04 and 0.171 to 0.208 for terabyte05.",
                "However, these improvements are slight compared to the performance of autocorrelation on these collections.",
                "Our predictor achieves a τ correlation of 0.454 for terabyte04 and 0.383 for terabyte05.",
                "Though not always the strongest, autocorrelation achieves correlations competitive with baseline predictors.",
                "When examining the performance of linear combinations of predictors, we note that in every case, autocorrelation factors as a necessary component of a strong predictor.",
                "We also note that the adjusted R2 for individual baselines are always significantly improved by incorporating autocorrelation.",
                "We present our generalizability results in Table 2.",
                "We begin by examining the situation in column (a) where we are presented with a single retrieval and no information from additional retrievals.",
                "For every collection except one, we achieve significantly better correlations than ranked-list Clarity.",
                "Surprisingly, we achieve relatively strong correlations for Spanish and Chinese collections despite our na¨ıve processing.",
                "We do not have a ranked-list clarity correlation for ent05 because entity modeling is itself an open research question.",
                "However, our autocorrelation measure does not achieve high correlations perhaps because relevance for entity retrieval does not propagate according to the cooccurrence links we use.",
                "As noted above, the poor Clarity performance on web data is consistent with our findings in the detailed experiments.",
                "Clarity also notably underperforms for several news corpora (trec5, trec7, and robust04).",
                "On the other hand, autocorrelation seems robust to the changes between different corpora.",
                "Next, we turn to the introduction of information from multiple retrievals.",
                "We compare the correlations between those predictors which do not use this information in column (a) and those which do in column (b).",
                "For every collection, the predictors in column (b) outperform the predictors in column (a), indicating that the information from additional runs can be critical to making good predictions.",
                "Inspecting the predictors in column (b), we only draw weak conclusions.",
                "Our new predictors tend to perform better on news corpora.",
                "And between our new predictors, the hybrid ρ(˜y, yµ) predictor tends to perform better.",
                "Recall that our ρ(˜y, yµ) measure incorporates both spatial and multiple retrieval information.",
                "Therefore, we believe that the improvement in correlation is the result of incorporating information from spatial behavior.",
                "In column (c), we can investigate the utility of incorporating spatial information with information from multiple retrievals.",
                "Notice that in the cases where autocorrelation, ρ(y, ˜y), alone performs well (trec3, trec5-spanish, and trec6-chinese), it is substantially improved by incorporating multiple-retrieval information from ρ(y, yµ) in the linear regression, β.",
                "In the cases where ρ(y, yµ) performs well, incorporating autocorrelation rarely results in a significant improvement in performance.",
                "In fact, in every case where our predictor outperforms the baseline, it includes information from multiple runs. 7.",
                "DISCUSSION The most important result from our experiments involves prediction when no information is available from multiple runs (Tables 1 and 2a).",
                "This situation arises often in system design.",
                "For example, a system may need to, at retrieval time, assess its performance before deciding to conduct more intensive processing such as pseudo-relevance feedback or interaction.",
                "Assuming the presence of multiple retrievals is unrealistic in this case.",
                "We believe that autocorrelation is, like multiple-retrieval algorithms, approximating a good ranking; in this case by diffusing scores.",
                "Why is ˜y a reasonable surrogate?",
                "We know that diffusion of scores on the web graph and language model graphs improves performance [14, 16].",
                "Therefore, if score diffusion tends to, in general, improve performance, then diffused scores will, in general, provide a good surrogate for relevance.",
                "Our results demonstrate that this approximation is not as powerful as information from multiple retrievals.",
                "Nevertheless, in situations where this information is lacking, autocorrelation provides substantial information.",
                "The success of autocorrelation as a predictor may also have roots in the clustering hypothesis.",
                "Recall that we regard autocorrelation as the degree to which a retrieval satisfies the clustering hypothesis.",
                "Our experiments, then, demonstrate that a failure to respect the clustering hypothesis correlates with poor performance.",
                "Why might systems fail to conform to the cluster hypothesis?",
                "Query-based information retrieval systems often score documents independently.",
                "The score of document a may be computed by examining query term or phrase matches, the document length, and perhaps global collection statistics.",
                "Once computed, a system rarely compares the score of a to the score of a topically-related document b.",
                "With some exceptions, the correlation of document scores has largely been ignored.",
                "We should make it clear that we have selected tasks where topical autocorrelation is appropriate.",
                "There are certainly cases where there is no reason to believe that retrieval scores will have topical autocorrelation.",
                "For example, ranked lists which incorporate document novelty should not exhibit <br>spatial autocorrelation</br>; if anything autocorrelation should be negative for this task.",
                "Similarly, answer candidates in a question-answering task may or may not exhibit autocorrelation; in this case, the semantics of links is questionable too.",
                "It is important before applying this measure to confirm that, given the semantics for some link between two retrieved items, we should expect a correlation between scores. 8.",
                "RELATED WORK In this section we draw more general comparisons to other work in performance prediction and spatial data analysis.",
                "There is a growing body of work which attempts to predict the performance of individual retrievals [7, 3, 11, 9, 19].",
                "We have attempted to place our work in the context of much of this work in Section 4.",
                "However, a complete comparison is beyond the scope of this paper.",
                "We note, though, that our experiments cover a larger and more diverse set of retrievals, collections, and topics than previously examined.",
                "Much previous work-particularly in the context of TRECfocuses on predicting the performance of systems.",
                "Here, each system generates k retrievals.",
                "The task is, given these retrievals, to predict the ranking of systems according to some performance measure.",
                "Several papers attempt to address this task under the constraint of few judgments [2, 4].",
                "Some work even attempts to use zero judgments by leveraging multiple retrievals for the same query [17].",
                "Our task differs because we focus on ranking retrievals independent of the generating system.",
                "The task here is not to test the hypothesis system A is superior to system B but to test the hypothesis retrieval A is superior to retrieval B. Autocorrelation manifests itself in many classification tasks.",
                "Neville and Jensen define relational autocorrelation for relational learning problems and demonstrate that many classification tasks manifest autocorrelation [13].",
                "Temporal autocorrelation of initial retrievals has also been used to predict performance [9].",
                "However, temporal autocorrelation is performed by projecting the retrieval function into the temporal embedding space.",
                "In our work, we focus on the behavior of the function over the relationships between documents. τ adjusted R2 DV KL P ρ(y, ˜y) DV KL P ρ(y, ˜y) DV KL, P DV KL, ρ(y, ˜y) Pρ(y, ˜y) β trec4 0.353 0.548 0.513 0.168 0.363 0.422 0.466 0.420 0.557 0.553 trec5 0.311 0.329 0.357 0.116 0.190 0.236 0.238 0.244 0.266 0.269 robust04 0.418 0.398 0.373 0.256 0.304 0.278 0.403 0.373 0.402 0.442 terabyte04 0.139 0.150 0.454 0.059 0.045 0.292 0.076 0.293 0.289 0.284 terabyte05 0.171 0.208 0.383 0.022 0.072 0.193 0.120 0.225 0.218 0.257 Table 1: Comparison to Robustness and Clarity measures for language model scores.",
                "Evaluation replicates experiments from [19].",
                "We present correlations between the classic Clarity measure (DV KL), the ranking robustness measure (P), and autocorrelation (ρ(y, ˜y)) each with mean average precision in terms of Kendalls τ.",
                "The adjusted coefficient of determination is presented to measure the effectiveness of combining predictors.",
                "Measures in bold represent the strongest correlation for that test/collection pair. multiple run (a) (b) (c) τ τ adjusted R2 DKL ρ(y, ˜y) Dn KL ρ(y, yµ) ρ(˜y, yµ) Dn KL ρ(y, ˜y) ρ(y, yµ) ρ(˜y, yµ) β trec3 0.201 0.461 0.461 0.439 0.456 0.444 0.395 0.394 0.386 0.498 trec4 0.252 0.396 0.455 0.482 0.489 0.379 0.263 0.429 0.482 0.483 trec5 0.016 0.277 0.433 0.459 0.393 0.280 0.157 0.375 0.323 0.386 trec6 0.230 0.227 0.352 0.428 0.418 0.203 0.089 0.323 0.325 0.325 trec7 0.083 0.326 0.341 0.430 0.483 0.264 0.182 0.363 0.442 0.400 trec8 0.235 0.396 0.454 0.508 0.567 0.402 0.272 0.490 0.580 0.523 robust03 0.302 0.354 0.377 0.385 0.447 0.269 0.206 0.274 0.392 0.303 robust04 0.183 0.308 0.301 0.384 0.453 0.200 0.182 0.301 0.393 0.335 robust05 0.224 0.249 0.371 0.377 0.404 0.341 0.108 0.313 0.328 0.336 terabyte04 0.043 0.245 0.544 0.420 0.392 0.516 0.105 0.357 0.343 0.365 terabyte05 0.068 0.306 0.480 0.434 0.390 0.491 0.168 0.384 0.309 0.403 trec4-spanish 0.307 0.388 0.488 0.398 0.395 0.423 0.299 0.282 0.299 0.388 trec5-spanish 0.220 0.458 0.446 0.484 0.475 0.411 0.398 0.428 0.437 0.529 trec5-chinese 0.092 0.199 0.367 0.379 0.384 0.379 0.199 0.273 0.276 0.310 trec6-chinese 0.144 0.276 0.265 0.353 0.376 0.115 0.128 0.188 0.223 0.199 ent05 - 0.181 0.324 0.305 0.282 0.211 0.043 0.158 0.155 0.179 Table 2: Large scale prediction experiments.",
                "We predict the ranking of large sets of retrievals for various collections and retrieval systems.",
                "Kendalls τ correlations are computed between the predicted ranking and a ranking based on the retrievals average precision.",
                "In column (a), we have predictors which do not use information from other retrievals for the same query.",
                "In columns (b) and (c) we present performance for predictors which incorporate information from multiple retrievals.",
                "The adjusted coefficient of determination is computed to determine effectiveness of combining predictors.",
                "Measures in bold represent the strongest correlation for that test/collection pair.",
                "Finally, regularization-based re-ranking processes are also closely-related to our work [8].",
                "These techniques seek to maximize the agreement between scores of related documents by solving a constrained optimization problem.",
                "The maximization of consistency is equivalent to maximizing the Moran autocorrelation.",
                "Therefore, we believe that our work provides explanation for why regularization-based re-ranking works. 9.",
                "CONCLUSION We have presented a new method for predicting the performance of a retrieval ranking without any relevance judgments.",
                "We consider two cases.",
                "First, when making predictions in the absence of retrievals from other systems, our predictors demonstrate robust, strong correlations with average precision.",
                "This performance, combined with a simple implementation, makes our predictors, in particular, very attractive.",
                "We have demonstrated this improvement for many, diverse settings.",
                "To our knowledge, this is the first large scale examination of zero-judgment, single-retrieval performance prediction.",
                "Second, when provided retrievals from other systems, our extended methods demonstrate competitive performance with state of the art baselines.",
                "Our experiments also demonstrate the limits of the usefulness of our predictors when information from multiple runs is provided.",
                "Our results suggest two conclusions.",
                "First, our results could affect retrieval algorithm design.",
                "Retrieval algorithms designed to consider <br>spatial autocorrelation</br> will conform to the cluster hypothesis and improve performance.",
                "Second, our results could affect the design of minimal test collection algorithms.",
                "Much of the recent work in ranking systems sometimes ignores correlations between document labels and scores.",
                "We believe that these two directions could be rewarding given the theoretical and experimental evidence in this paper. 10.",
                "ACKNOWLEDGMENTS This work was supported in part by the Center for Intelligent Information Retrieval and in part by the Defense Advanced Research Projects Agency (DARPA) under contract number HR0011-06-C-0023.",
                "Any opinions, findings and conclusions or recommendations expressed in this material are the authors and do not necessarily reflect those of the sponsor.",
                "We thank Yun Zhou and Desislava Petkova for providing data and Andre Gauthier for technical assistance. 11.",
                "REFERENCES [1] J. Aslam and V. Pavlu.",
                "Query hardness estimation using jensen-shannon divergence among multiple scoring functions.",
                "In ECIR 2007: Proceedings of the 29th European Conference on Information Retrieval, 2007. [2] J.",
                "A. Aslam, V. Pavlu, and E. Yilmaz.",
                "A statistical method for system evaluation using incomplete judgments.",
                "In S. Dumais, E. N. Efthimiadis, D. Hawking, and K. Jarvelin, editors, Proceedings of the 29th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 541-548.",
                "ACM Press, August 2006. [3] D. Carmel, E. Yom-Tov, A. Darlow, and D. Pelleg.",
                "What makes a query difficult?",
                "In SIGIR 06: Proceedings of the 29th annual international ACM SIGIR conference on Research and development in information retrieval, pages 390-397, New York, NY, USA, 2006.",
                "ACM Press. [4] B. Carterette, J. Allan, and R. Sitaraman.",
                "Minimal test collections for retrieval evaluation.",
                "In SIGIR 06: Proceedings of the 29th annual international ACM SIGIR conference on Research and development in information retrieval, pages 268-275, New York, NY, USA, 2006.",
                "ACM Press. [5] A. D. Cliff and J. K. Ord.",
                "<br>spatial autocorrelation</br>.",
                "Pion Ltd., 1973. [6] M. Connell, A. Feng, G. Kumaran, H. Raghavan, C. Shah, and J. Allan.",
                "Umass at tdt 2004.",
                "Technical Report CIIR Technical Report IR - 357, Department of Computer Science, University of Massachusetts, 2004. [7] S. Cronen-Townsend, Y. Zhou, and W. B. Croft.",
                "Precision prediction based on ranked list coherence.",
                "Inf.",
                "Retr., 9(6):723-755, 2006. [8] F. Diaz.",
                "Regularizing ad-hoc retrieval scores.",
                "In CIKM 05: Proceedings of the 14th ACM international conference on Information and knowledge management, pages 672-679, New York, NY, USA, 2005.",
                "ACM Press. [9] F. Diaz and R. Jones.",
                "Using temporal profiles of queries for precision prediction.",
                "In SIGIR 04: Proceedings of the 27th annual international ACM SIGIR conference on Research and development in information retrieval, pages 18-24, New York, NY, USA, 2004.",
                "ACM Press. [10] D. A. Griffith.",
                "<br>spatial autocorrelation</br> and Spatial Filtering.",
                "Springer Verlag, 2003. [11] B.",
                "He and I. Ounis.",
                "Inferring Query Performance Using Pre-retrieval Predictors.",
                "In The Eleventh Symposium on String Processing and Information Retrieval (SPIRE), 2004. [12] N. Jardine and C. J. V. Rijsbergen.",
                "The use of hierarchic clustering in information retrieval.",
                "Information Storage and Retrieval, 7:217-240, 1971. [13] D. Jensen and J. Neville.",
                "Linkage and autocorrelation cause feature selection bias in relational learning.",
                "In ICML 02: Proceedings of the Nineteenth International Conference on Machine Learning, pages 259-266, San Francisco, CA, USA, 2002.",
                "Morgan Kaufmann Publishers Inc. [14] O. Kurland and L. Lee.",
                "Corpus structure, language models, and ad-hoc information retrieval.",
                "In SIGIR 04: Proceedings of the 27th annual international conference on Research and development in information retrieval, pages 194-201, New York, NY, USA, 2004.",
                "ACM Press. [15] M. Montague and J.",
                "A. Aslam.",
                "Relevance score normalization for metasearch.",
                "In CIKM 01: Proceedings of the tenth international conference on Information and knowledge management, pages 427-433, New York, NY, USA, 2001.",
                "ACM Press. [16] T. Qin, T.-Y.",
                "Liu, X.-D. Zhang, Z. Chen, and W.-Y.",
                "Ma.",
                "A study of relevance propagation for web search.",
                "In SIGIR 05: Proceedings of the 28th annual international ACM SIGIR conference on Research and development in information retrieval, pages 408-415, New York, NY, USA, 2005.",
                "ACM Press. [17] I. Soboroff, C. Nicholas, and P. Cahan.",
                "Ranking retrieval systems without relevance judgments.",
                "In SIGIR 01: Proceedings of the 24th annual international ACM SIGIR conference on Research and development in information retrieval, pages 66-73, New York, NY, USA, 2001.",
                "ACM Press. [18] V. Vinay, I. J. Cox, N. Milic-Frayling, and K. Wood.",
                "On ranking the effectiveness of searches.",
                "In SIGIR 06: Proceedings of the 29th annual international ACM SIGIR conference on Research and development in information retrieval, pages 398-404, New York, NY, USA, 2006.",
                "ACM Press. [19] Y. Zhou and W. B. Croft.",
                "Ranking robustness: a novel framework to predict query performance.",
                "In CIKM 06: Proceedings of the 15th ACM international conference on Information and knowledge management, pages 567-574, New York, NY, USA, 2006.",
                "ACM Press."
            ],
            "original_annotated_samples": [
                "Performance Prediction Using <br>spatial autocorrelation</br> Fernando Diaz Center for Intelligent Information Retrieval Department of Computer Science University of Massachusetts Amherst, MA 01003 fdiaz@cs.umass.edu ABSTRACT Evaluation of information retrieval systems is one of the core tasks in information retrieval.",
                "As we shall see, a retrieval functions <br>spatial autocorrelation</br> measures the degree to which closely-related documents receive similar scores.",
                "If we want to quantify the spatial dependencies of a function, we would employ a measure referred to as the <br>spatial autocorrelation</br> [5, 10].",
                "High <br>spatial autocorrelation</br> suggests that knowing the value of a function at location a will tell us a great deal about the value at a neighboring location b.",
                "There is a high <br>spatial autocorrelation</br> for a function representing the temperature of a location since knowing the temperature at a location a will tell us a lot about the temperature at a neighboring location b."
            ],
            "translated_annotated_samples": [
                "Predicción del rendimiento utilizando <br>autocorrelación espacial</br>. Fernando Díaz. Centro de Recuperación de Información Inteligente. Departamento de Ciencias de la Computación. Universidad de Massachusetts Amherst, MA 01003. fdiaz@cs.umass.edu. RESUMEN La evaluación de sistemas de recuperación de información es una de las tareas fundamentales en la recuperación de información.",
                "Como veremos, una función de recuperación de medidas de <br>autocorrelación espacial</br> mide el grado en que los documentos relacionados reciben puntuaciones similares.",
                "Si queremos cuantificar las dependencias espaciales de una función, emplearíamos una medida conocida como la <br>autocorrelación espacial</br> [5, 10].",
                "Una alta <br>autocorrelación espacial</br> sugiere que conocer el valor de una función en la ubicación a nos dirá mucho sobre el valor en una ubicación vecina b.",
                "Existe una alta <br>autocorrelación espacial</br> para una función que representa la temperatura de una ubicación, ya que saber la temperatura en una ubicación a nos dirá mucho sobre la temperatura en una ubicación vecina b."
            ],
            "translated_text": "Predicción del rendimiento utilizando <br>autocorrelación espacial</br>. Fernando Díaz. Centro de Recuperación de Información Inteligente. Departamento de Ciencias de la Computación. Universidad de Massachusetts Amherst, MA 01003. fdiaz@cs.umass.edu. RESUMEN La evaluación de sistemas de recuperación de información es una de las tareas fundamentales en la recuperación de información. Los problemas incluyen la incapacidad de etiquetar exhaustivamente todos los documentos sobre un tema, la falta de generalización a partir de un pequeño número de temas e incorporar la variabilidad de los sistemas de recuperación. Trabajos anteriores abordan la evaluación de sistemas, la clasificación de consultas por dificultad y la clasificación de recuperaciones individuales por rendimiento. Existen enfoques para el caso de pocos e incluso ningún juicio de relevancia. Nuestro enfoque está en la predicción del rendimiento sin juicios de las recuperaciones individuales. Una deficiencia común de las técnicas anteriores es la suposición de que las puntuaciones de los documentos y los juicios no están correlacionados. Si los documentos están incrustados en un espacio de alta dimensión (como a menudo lo están), podemos aplicar técnicas de análisis de datos espaciales para detectar correlaciones entre las puntuaciones de los documentos. Observamos que la baja correlación entre las puntuaciones de documentos temáticamente cercanos a menudo implica un bajo rendimiento en la recuperación. Cuando se compara con una línea base de última generación, demostramos que el análisis espacial de las puntuaciones de recuperación ofrece un rendimiento predictivo significativamente mejor. Estos nuevos predictores también pueden ser incorporados con predictores clásicos para mejorar aún más el rendimiento. También describimos el primer experimento a gran escala para evaluar la predicción de rendimiento sin juicio para un gran número de sistemas de recuperación en una variedad de colecciones en varios idiomas. Categorías y Descriptores de Asignaturas H.3.3 [Búsqueda y Recuperación de Información]: Modelos de recuperación; H.3.4 [Sistemas y Software]: Evaluación del rendimiento (eficiencia y efectividad) Términos Generales Rendimiento, Diseño, Confiabilidad, Experimentación 1. En la recuperación de información, un usuario plantea una consulta a un sistema. El sistema recupera n documentos, cada uno recibiendo una puntuación de valor real que indica el grado de relevancia predicho. Si seleccionamos aleatoriamente pares de documentos de este conjunto, esperamos que algunos pares compartan el mismo tema y otros pares no compartan el mismo tema. Toma dos documentos relacionados entre sí del conjunto y llámalos a y b. Si las puntuaciones de a y b son muy diferentes, podríamos estar preocupados por el rendimiento de nuestro sistema. Es decir, si tanto a como b están relacionados con el tema de la consulta, nos gustaría que ambos reciban una puntuación alta; si a y b no están relacionados con el tema de la consulta, nos gustaría que ambos reciban una puntuación baja. Podríamos preocuparnos más a medida que encontramos más diferencias entre las puntuaciones de documentos relacionados. Estaríamos más cómodos con una recuperación en la que las puntuaciones sean consistentes entre documentos relacionados. Nuestro artículo estudia la cuantificación de esta inconsistencia en una recuperación desde una perspectiva espacial. El análisis espacial es apropiado ya que muchos modelos de recuperación incrustan documentos en algún espacio vectorial. Si los documentos están incrustados en un espacio, la proximidad se correlaciona con las relaciones temáticas. La consistencia de la puntuación puede medirse mediante la versión espacial de la autocorrelación conocida como el coeficiente de Moran o IM [5, 10]. En este artículo, demostramos una fuerte correlación entre IM y el rendimiento de recuperación. La discusión hasta este punto recuerda a la hipótesis del cúmulo. La hipótesis del clúster establece que los documentos estrechamente relacionados tienden a ser relevantes para la misma solicitud [12]. Como veremos, una función de recuperación de medidas de <br>autocorrelación espacial</br> mide el grado en que los documentos relacionados reciben puntuaciones similares. Debido a esto, interpretamos la autocorrelación como la medida del grado en que una función de recuperación satisface la hipótesis de agrupamiento. Si esta conexión es razonable, en la Sección 6 presentamos evidencia de que la falta de cumplimiento de la hipótesis de agrupamiento se correlaciona fuertemente con un bajo rendimiento. En este trabajo, proporcionamos las siguientes contribuciones: 1. Un método general y robusto para predecir el rendimiento de recuperaciones sin juicios de relevancia (Sección 3). 2. Un tratamiento teórico de las similitudes y motivaciones detrás de varias técnicas de predicción de rendimiento de vanguardia (Sección 4). 3. Las primeras experimentaciones a gran escala de predicción de rendimiento de una sola ejecución sin juicio (Secciones 5 y 6). 2. Dada una consulta, un sistema de recuperación de información produce una clasificación de documentos en la colección codificada como un conjunto de puntuaciones asociadas con los documentos. Nos referimos al conjunto de puntuaciones para una combinación particular de consulta-sistema como una recuperación. Nos gustaría predecir el rendimiento de esta recuperación con respecto a alguna medida de evaluación (por ejemplo, precisión promedio). En este artículo, presentamos resultados para clasificar recuperaciones de sistemas arbitrarios. Nos gustaría que este ranking se aproximara al ranking de recuperaciones según la medida de evaluación. Esto es diferente de clasificar las consultas por el rendimiento promedio en cada consulta. También es diferente de los sistemas de clasificación por el rendimiento promedio en un conjunto de consultas. Las puntuaciones a menudo solo se calculan para los primeros n documentos de la colección. Colocamos estos puntajes en el vector de longitud n, y, donde yi se refiere al puntaje del documento clasificado en la posición i. Ajustamos las puntuaciones para que tengan una media de cero y una varianza unitaria. Utilizamos este método debido a su simplicidad y su éxito en trabajos anteriores [15]. CORRELACIÓN ESPACIAL En la recuperación de información, a menudo asumimos que las representaciones de los documentos existen en algún espacio vectorial de alta dimensión. Por ejemplo, dado un vocabulario, V, este espacio vectorial puede ser un espacio arbitrario de dimensión |V| con producto interno de coseno o un simplejo multinomial con una medida de distancia basada en distribución. Un espacio de incrustación suele ser seleccionado para respetar la proximidad temática; si dos documentos están cerca, es más probable que compartan un tema. Debido a la prevalencia y éxito de los modelos espaciales de recuperación de información, creemos que la aplicación de técnicas de análisis de datos espaciales es apropiada. Mientras que en la recuperación de información nos preocupa la puntuación en un punto en el espacio, en el análisis de datos espaciales nos preocupa el valor de una función en un punto o ubicación en el espacio. Utilizamos el término función aquí para referirnos a una asignación de una ubicación a un valor real. Por ejemplo, podríamos estar interesados en la prevalencia de una enfermedad en el vecindario de alguna ciudad. La función asignaría la ubicación de un vecindario a una tasa de infección. Si queremos cuantificar las dependencias espaciales de una función, emplearíamos una medida conocida como la <br>autocorrelación espacial</br> [5, 10]. Una alta <br>autocorrelación espacial</br> sugiere que conocer el valor de una función en la ubicación a nos dirá mucho sobre el valor en una ubicación vecina b. Existe una alta <br>autocorrelación espacial</br> para una función que representa la temperatura de una ubicación, ya que saber la temperatura en una ubicación a nos dirá mucho sobre la temperatura en una ubicación vecina b. ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "autocorrelation": {
            "translated_key": "autocorrelación espacial",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Performance Prediction Using Spatial <br>autocorrelation</br> Fernando Diaz Center for Intelligent Information Retrieval Department of Computer Science University of Massachusetts Amherst, MA 01003 fdiaz@cs.umass.edu ABSTRACT Evaluation of information retrieval systems is one of the core tasks in information retrieval.",
                "Problems include the inability to exhaustively label all documents for a topic, nongeneralizability from a small number of topics, and incorporating the variability of retrieval systems.",
                "Previous work addresses the evaluation of systems, the ranking of queries by difficulty, and the ranking of individual retrievals by performance.",
                "Approaches exist for the case of few and even no relevance judgments.",
                "Our focus is on zero-judgment performance prediction of individual retrievals.",
                "One common shortcoming of previous techniques is the assumption of uncorrelated document scores and judgments.",
                "If documents are embedded in a high-dimensional space (as they often are), we can apply techniques from spatial data analysis to detect correlations between document scores.",
                "We find that the low correlation between scores of topically close documents often implies a poor retrieval performance.",
                "When compared to a state of the art baseline, we demonstrate that the spatial analysis of retrieval scores provides significantly better prediction performance.",
                "These new predictors can also be incorporated with classic predictors to improve performance further.",
                "We also describe the first large-scale experiment to evaluate zero-judgment performance prediction for a massive number of retrieval systems over a variety of collections in several languages.",
                "Categories and Subject Descriptors H.3.3 [Information Search and Retrieval]: Retrieval models; H.3.4 [Systems and Software]: Performance evaluation (efficiency and effectiveness) General Terms Performance, Design, Reliability, Experimentation 1.",
                "INTRODUCTION In information retrieval, a user poses a query to a system.",
                "The system retrieves n documents each receiving a realvalued score indicating the predicted degree of relevance.",
                "If we randomly select pairs of documents from this set, we expect some pairs to share the same topic and other pairs to not share the same topic.",
                "Take two topically-related documents from the set and call them a and b.",
                "If the scores of a and b are very different, we may be concerned about the performance of our system.",
                "That is, if a and b are both on the topic of the query, we would like them both to receive a high score; if a and b are not on the topic of the query, we would like them both to receive a low score.",
                "We might become more worried as we find more differences between scores of related documents.",
                "We would be more comfortable with a retrieval where scores are consistent between related documents.",
                "Our paper studies the quantification of this inconsistency in a retrieval from a spatial perspective.",
                "Spatial analysis is appropriate since many retrieval models embed documents in some vector space.",
                "If documents are embedded in a space, proximity correlates with topical relationships.",
                "Score consistency can be measured by the spatial version of <br>autocorrelation</br> known as the Moran coefficient or IM [5, 10].",
                "In this paper, we demonstrate a strong correlation between IM and retrieval performance.",
                "The discussion up to this point is reminiscent of the cluster hypothesis.",
                "The cluster hypothesis states: closely-related documents tend to be relevant to the same request [12].",
                "As we shall see, a retrieval functions spatial <br>autocorrelation</br> measures the degree to which closely-related documents receive similar scores.",
                "Because of this, we interpret <br>autocorrelation</br> as measuring the degree to which a retrieval function satisfies the clustering hypothesis.",
                "If this connection is reasonable, in Section 6, we present evidence that failure to satisfy the cluster hypothesis correlates strongly with poor performance.",
                "In this work, we provide the following contributions, 1.",
                "A general, robust method for predicting the performance of retrievals with zero relevance judgments (Section 3). 2.",
                "A theoretical treatment of the similarities and motivations behind several state-of-the-art performance prediction techniques (Section 4). 3.",
                "The first large-scale experiments of zero-judgment, single run performance prediction (Sections 5 and 6). 2.",
                "PROBLEM DEFINITION Given a query, an information retrieval system produces a ranking of documents in the collection encoded as a set of scores associated with documents.",
                "We refer to the set of scores for a particular query-system combination as a retrieval.",
                "We would like to predict the performance of this retrieval with respect to some evaluation measure (eg, mean average precision).",
                "In this paper, we present results for ranking retrievals from arbitrary systems.",
                "We would like this ranking to approximate the ranking of retrievals by the evaluation measure.",
                "This is different from ranking queries by the average performance on each query.",
                "It is also different from ranking systems by the average performance on a set of queries.",
                "Scores are often only computed for the top n documents from the collection.",
                "We place these scores in the length n vector, y, where yi refers to the score of the ith-ranked document.",
                "We adjust scores to have zero mean and unit variance.",
                "We use this method because of its simplicity and its success in previous work [15]. 3.",
                "SPATIAL CORRELATION In information retrieval, we often assume that the representations of documents exist in some high-dimensional vector space.",
                "For example, given a vocabulary, V, this vector space may be an arbitrary |V|-dimensional space with cosine inner-product or a multinomial simplex with a distributionbased distance measure.",
                "An embedding space is often selected to respect topical proximity; if two documents are near, they are more likely to share a topic.",
                "Because of the prevalence and success of spatial models of information retrieval, we believe that the application of spatial data analysis techniques are appropriate.",
                "Whereas in information retrieval, we are concerned with the score at a point in a space, in spatial data analysis, we are concerned with the value of a function at a point or location in a space.",
                "We use the term function here to mean a mapping from a location to a real value.",
                "For example, we might be interested in the prevalence of a disease in the neighborhood of some city.",
                "The function would map the location of a neighborhood to an infection rate.",
                "If we want to quantify the spatial dependencies of a function, we would employ a measure referred to as the spatial <br>autocorrelation</br> [5, 10].",
                "High spatial <br>autocorrelation</br> suggests that knowing the value of a function at location a will tell us a great deal about the value at a neighboring location b.",
                "There is a high spatial <br>autocorrelation</br> for a function representing the temperature of a location since knowing the temperature at a location a will tell us a lot about the temperature at a neighboring location b.",
                "Low spatial <br>autocorrelation</br> suggests that knowing the value of a function at location a tells us little about the value at a neighboring location b.",
                "There is low spatial <br>autocorrelation</br> in a function measuring the outcome of a coin toss at a and b.",
                "In this section, we will begin by describing what we mean by spatial proximity for documents and then define a measure of spatial <br>autocorrelation</br>.",
                "We conclude by extending this model to include information from multiple retrievals from multiple systems for a single query. 3.1 Spatial Representation of Documents Our work does not focus on improving a specific similarity measure or defining a novel vector space.",
                "Instead, we choose an inner product known to be effective at detecting interdocument topical relationships.",
                "Specifically, we adopt tf.idf document vectors, ˜di = di log „ (n + 0.5) − ci 0.5 + ci « (1) where d is a vector of term frequencies, c is the length-|V| document frequency vector.",
                "We use this weighting scheme due to its success for topical link detection in the context of Topic Detection and Tracking (TDT) evaluations [6].",
                "Assuming vectors are scaled by their L2 norm, we use the inner product, ˜di, ˜dj , to define similarity.",
                "Given documents and some similarity measure, we can construct a matrix which encodes the similarity between pairs of documents.",
                "Recall that we are given the top n documents retrieved in y.",
                "We can compute an n × n similarity matrix, W. An element of this matrix, Wij represents the similarity between documents ranked i and j.",
                "In practice, we only include the affinities for a documents k-nearest neighbors.",
                "In all of our experiments, we have fixed k to 5.",
                "We leave exploration of parameter sensitivity to future work.",
                "We also row normalize the matrix so that Pn j=1 Wij = 1 for all i. 3.2 Spatial <br>autocorrelation</br> of a Retrieval Recall that we are interested in measuring the similarity between the scores of spatially-close documents.",
                "One such suitable measure is the Moran coefficient of spatial <br>autocorrelation</br>.",
                "Assuming the function y over n locations, this is defined as ˜IM = n eTWe P i,j Wijyiyj P i y2 i = n eTWe yT Wy yTy (2) where eT We = P ij Wij.",
                "We would like to compare <br>autocorrelation</br> values for different retrievals.",
                "Unfortunately, the bound for Equation 2 is not consistent for different W and y.",
                "Therefore, we use the Cauchy-Schwartz inequality to establish a bound, ˜IM ≤ n eTWe s yTWTWy yTy And we define the normalized spatial <br>autocorrelation</br> as IM = yT Wy p yTy × yTWTWy Notice that if we let ˜y = Wy, then we can write this formula as, IM = yT ˜y y 2 ˜y 2 (3) which can be interpreted as the correlation between the original retrieval scores and a set of retrieval scores diffused in the space.",
                "We present some examples of autocorrelations of functions on a grid in Figure 1. 3.3 Correlation with Other Retrievals Sometimes we are interested in the performance of a single retrieval but have access to scores from multiple systems for (a) IM = 0.006 (b) IM = 0.241 (c) IM = 0.487 Figure 1: The Moran coefficient, IM for a several binary functions on a grid.",
                "The Moran coefficient is a local measure of function consistency.",
                "From the perspective of information retrieval, each of these grid spaces would represent a document and documents would be organized so that they lay next to topically-related documents.",
                "Binary retrieval scores would define a pattern on this grid.",
                "Notice that, as the Moran coefficient increases, neighboring cells tend to have similar values. the same query.",
                "In this situation, we can use combined information from these scores to construct a surrogate for a high-quality ranking [17].",
                "We can treat the correlation between the retrieval we are interested in and the combined scores as a predictor of performance.",
                "Assume that we are given m score functions, yi, for the same n documents.",
                "We will represent the mean of these vectors as yµ = Pm i=1 yi.",
                "We use the mean vector as an approximation to relevance.",
                "Since we use zero mean and unit variance normalization, work in metasearch suggests that this assumption is justified [15].",
                "Because yµ represents a very good retrieval, we hypothesize that a strong similarity between yµ and y will correlate positively with system performance.",
                "We use Pearsons product-moment correlation to measure the similarity between these vectors, ρ(y, yµ) = yT yµ y 2 yµ 2 (4) We will comment on the similarity between Equation 3 and 4 in Section 7.",
                "Of course, we can combine ρ(y, ˜y) and ρ(y, yµ) if we assume that they capture different factors in the prediction.",
                "One way to accomplish this is to combine these predictors as independent variables in a linear regression.",
                "An alternative means of combination is suggested by the mathematical form of our predictors.",
                "Since ˜y encodes the spatial dependencies in y and yµ encodes the spatial properties of the multiple runs, we can compute a third correlation between these two vectors, ρ(˜y, yµ) = ˜yT yµ ˜y 2 yµ 2 (5) We can interpret Equation 5 as measuring the correlation between a high quality ranking (yµ) and a spatially smoothed version of the retrieval (˜y). 4.",
                "RELATIONSHIP WITH OTHER PREDICTORS One way to predict the effectiveness of a retrieval is to look at the shared vocabulary of the top n retrieved documents.",
                "If we computed the most frequent content words in this set, we would hope that they would be consistent with our topic.",
                "In fact, we might believe that a bad retrieval would include documents on many disparate topics, resulting in an overlap of terminological noise.",
                "The Clarity of a query attempts to quantify exactly this [7].",
                "Specifically, Clarity measures the similarity of the words most frequently used in retrieved documents to those most frequently used in the whole corpus.",
                "The conjecture is that a good retrieval will use language distinct from general text; the overlapping language in a bad retrieval will tend to be more similar to general text.",
                "Mathematically, we can compute a representation of the language used in the initial retrieval as a weighted combination of document language models, P(w|θQ) = nX i=1 P(w|θi) P(Q|θi) Z (6) where θi is the language model of the ith-ranked document, P(Q|θi) is the query likelihood score of the ith-ranked document and Z = Pn i=1 P(Q|θi) is a normalization constant.",
                "The similarity between the multinomial P(w|θQ) and a model of general text can be computed using the Kullback-Leibler divergence, DV KL(θQ θC ).",
                "Here, the distribution P(w|θC ) is our model of general text which can be computed using term frequencies in the corpus.",
                "In Figure 2a, we present Clarity as measuring the distance between the weighted center of mass of the retrieval (labeled y) and the unweighted center of mass of the collection (labeled O).",
                "Clarity reaches a minimum when a retrieval assigns every document the same score.",
                "Lets again assume we have a set of n documents retrieved for our query.",
                "Another way to quantify the dispersion of a set of documents is to look at how clustered they are.",
                "We may hypothesize that a good retrieval will return a single, tight cluster.",
                "A poorly performing retrieval will return a loosely related set of documents covering many topics.",
                "One proposed method of quantifying this dispersion is to measure the distance from a random document a to its nearest neighbor, b.",
                "A retrieval which is tightly clustered will, on average, have a low distance between a and b; a retrieval which is less tightly-closed will, on average have high distances between a and b.",
                "This average corresponds to using the Cox-Lewis statistic to measure the randomness of the top n documents retrieved from a system [18].",
                "In Figure 2a, this is roughly equivalent to measuring the area of the set n. Notice that we are throwing away information about the retrieval function y.",
                "Therefore the Cox-Lewis statistic is highly dependent on selecting the top n documents.1 Remember that we have n documents and a set of scores.",
                "Lets assume that we have access to the system which provided the original scores and that we can also request scores for new documents.",
                "This suggests a third method for predicting performance.",
                "Take some document, a, from the retrieved set and arbitrarily add or remove words at random to create a new document ˜a.",
                "Now, we can ask our system to score ˜a with respect to our query.",
                "If, on average over the n documents, the scores of a and ˜a tend to be very different, we might suspect that the system is failing on this query.",
                "So, an alternative approach is to measure the simi1 The authors have suggested coupling the query with the distance measure [18].",
                "The information introduced by the query, though, is retrieval-independent so that, if two retrievals return the same set of documents, the approximate Cox-Lewis statistic will be the same regardless of the retrieval scores. yOy (a) Global Divergence µ(y)˜y y (b) Score Perturbation µ(y) y (c) Multirun Averaging Figure 2: Representation of several performance predictors on a grid.",
                "In Figure 2a, we depict predictors which measure the divergence between the center of mass of a retrieval and the center of the embedding space.",
                "In Figure 2b, we depict predictors which compare the original retrieval, y, to a perturbed version of the retrieval, ˜y.",
                "Our approach uses a particular type of perturbation based on score diffusion.",
                "Finally, in Figure 2c, we depict prediction when given retrievals from several other systems on the same query.",
                "Here, we can consider the fusion of these retrieval as a surrogate for relevance. larity between the retrieval and a perturbed version of that retrieval [18, 19].",
                "This can be accomplished by either perturbing the documents or queries.",
                "The similarity between the two retrievals can be measured using some correlation measure.",
                "This is depicted in Figure 2b.",
                "The upper grid represents the original retrieval, y, while the lower grid represents the function after having been perturbed, ˜y.",
                "The nature of the perturbation process requires additional scorings or retrievals.",
                "Our predictor does not require access to the original scoring function or additional retrievals.",
                "So, although our method is similar to other perturbation methods in spirit, it can be applied in situations when the retrieval system is inaccessible or costly to access.",
                "Finally, assume that we have, in addition to the retrieval we want to evaluate, m retrievals from a variety of different systems.",
                "In this case, we might take a document a, compare its rank in the retrieval to its average rank in the m retrievals.",
                "If we believe that the m retrievals provide a satisfactory approximation to relevance, then a very large difference in rank would suggest that our retrieval is misranking a.",
                "If this difference is large on average over all n documents, then we might predict that the retrieval is bad.",
                "If, on the other hand, the retrieval is very consistent with the m retrievals, then we might predict that the retrieval is good.",
                "The similarity between the retrieval and the combined retrieval may be computed using some correlation measure.",
                "This is depicted in Figure 2c.",
                "In previous work, the Kullback-Leibler divergence between the normalized scores of the retrieval and the normalized scores of the combined retrieval provides the similarity [1]. 5.",
                "EXPERIMENTS Our experiments focus on testing the predictive power of each of our predictors: ρ(y, ˜y), ρ(y, yµ), and ρ(˜y, yµ).",
                "As stated in Section 2, we are interested in predicting the performance of the retrieval generated by an arbitrary system.",
                "Our methodology is consistent with previous research in that we predict the relative performance of a retrieval by comparing a ranking based on our predictor to a ranking based on average precision.",
                "We present results for two sets of experiments.",
                "The first set of experiments presents detailed comparisons of our predictors to previously-proposed predictors using identical data sets.",
                "Our second set of experiments demonstrates the generalizability of our approach to arbitrary retrieval methods, corpus types, and corpus languages. 5.1 Detailed Experiments In these experiments, we will predict the performance of language modeling scores using our <br>autocorrelation</br> predictor, ρ(y, ˜y); we do not consider ρ(y, yµ) or ρ(˜y, yµ) because, in these detailed experiments, we focus on ranking the retrievals from a single system.",
                "We use retrievals, values for baseline predictors, and evaluation measures reported in previous work [19]. 5.1.1 Topics and Collections These performance prediction experiments use language model retrievals performed for queries associated with collections in the TREC corpora.",
                "Using TREC collections allows us to confidently associate an average precision with a retrieval.",
                "In these experiments, we use the following topic collections: TREC 4 ad-hoc, TREC 5 ad-hoc, Robust 2004, Terabyte 2004, and Terabyte 2005. 5.1.2 Baselines We provide two baselines.",
                "Our first baseline is the classic Clarity predictor presented in Equation 6.",
                "Clarity is designed to be used with language modeling systems.",
                "Our second baseline is Zhou and Crofts ranking robustness predictor.",
                "This predictor corrupts the top k documents from retrieval and re-computes the language model scores for these corrupted documents.",
                "The value of the predictor is the Spearman rank correlation between the original ranking and the corrupted ranking.",
                "In our tables, we will label results for Clarity using DV KL and the ranking robustness predictor using P. 5.2 Generalizability Experiments Our predictors do not require a particular baseline retrieval system; the predictors can be computed for an arbitrary retrieval, regardless of how scores were generated.",
                "We believe that that is one of the most attractive aspects of our algorithm.",
                "Therefore, in a second set of experiments, we demonstrate the ability of our techniques to generalize to a variety of collections, topics, and retrieval systems. 5.2.1 Topics and Collections We gathered a diverse set of collections from all possible TREC corpora.",
                "We cast a wide net in order to locate collections where our predictors might fail.",
                "Our hypothesis is that documents with high topical similarity should have correlated scores.",
                "Therefore, we avoided collections where scores were unlikely to be correlated (eg, question-answering) or were likely to be negatively correlated (eg, novelty).",
                "Nevertheless, our collections include corpora where correlations are weakly justified (eg, non-English corpora) or not justified at all (eg, expert search).",
                "We use the ad-hoc tracks from TREC3-8, TREC Robust 2003-2005, TREC Terabyte 20042005, TREC4-5 Spanish, TREC5-6 Chinese, and TREC Enterprise Expert Search 2005.",
                "In all cases, we use only the automatic runs for ad-hoc tracks submitted to NIST.",
                "For all English and Spanish corpora, we construct the matrix W according to the process described in Section 3.1.",
                "For Chinese corpora, we use na¨ıve character-based tf.idf vectors.",
                "For entities, entries in W are proportional to the number of documents in which two entities cooccur. 5.2.2 Baselines In our detailed experiments, we used the Clarity measure as a baseline.",
                "Since we are predicting the performance of retrievals which are not based on language modeling, we use a version of Clarity referred to as ranked-list Clarity [7].",
                "Ranked-list clarity converts document ranks to P(Q|θi) values.",
                "This conversion begins by replacing all of the scores in y with the respective ranks.",
                "Our estimation of P(Q|θi) from the ranks, then is, P(Q|θi) = ( 2(c+1−yi) c(c+1) if yi ≤ c 0 otherwise (7) where c is a cutoff parameter.",
                "As suggested by the authors, we fix the algorithm parameters c and λ2 so that c = 60 and λ2 = 0.10.",
                "We use Equation 6 to estimate P(w|θQ) and DV KL(θQ θC ) to compute the value of the predictor.",
                "We will refer to this predictor as DV KL, superscripted by V to indicate that the Kullback-Leibler divergence is with respect to the term embedding space.",
                "When information from multiple runs on the same query is available, we use Aslam and Pavlus document-space multinomial divergence as a baseline [1].",
                "This rank-based method first normalizes the scores in a retrieval as an n-dimensional multinomial.",
                "As with ranked-list Clarity, we begin by replacing all of the scores in y with their respective ranks.",
                "Then, we adjust the elements of y in the following way, ˆyi = 1 2n 0 @1 + nX k=yi 1 k 1 A (8) In our multirun experiments, we only use the top 75 documents from each retrieval (n = 75); this is within the range of parameter values suggested by the authors.",
                "However, we admit not tuning this parameter for either our system or the baseline.",
                "The predictor is the divergence between the candidate distribution, y, and the mean distribution, yµ .",
                "With the uniform linear combination of these m retrievals represented as yµ, we can compute the divergence as Dn KL(ˆy ˆyµ) where we use the superscript n to indicate that the summation is over the set of n documents.",
                "This baseline was developed in the context of predicting query difficulty but we adopt it as a reasonable baseline for predicting retrieval performance. 5.2.3 Parameter Settings When given multiple retrievals, we use documents in the union of the top k = 75 documents from each of the m retrievals for that query.",
                "If the size of this union is ˜n, then yµ and each yi is of length ˜n.",
                "In some cases, a system did not score a document in the union.",
                "Since we are making a Gaussian assumption about our scores, we can sample scores for these unseen documents from the negative tail of the distribution.",
                "Specifically, we sample from the part of the distribution lower than the minimum value of in the normalized retrieval.",
                "This introduces randomness into our algorithm but we believe it is more appropriate than assigning an arbitrary fixed value.",
                "We optimized the linear regression using the square root of each predictor.",
                "We found that this substantially improved fits for all predictors, including the baselines.",
                "We considered linear combinations of pairs of predictors (labeled by the components) and all predictors (labeled as β). 5.3 Evaluation Given a set of retrievals, potentially from a combination of queries and systems, we measure the correlation of the rank ordering of this set by the predictor and by the performance metric.",
                "In order to ensure comparability with previous results, we present Kendalls τ correlation between the predictors ranking and ranking based on average precision of the retrieval.",
                "Unless explicitly noted, all correlations are significant with p < 0.05.",
                "Predictors can sometimes perform better when linearly combined [9, 11].",
                "Although previous work has presented the coefficient of determination (R2 ) to measure the quality of the regression, this measure cannot be reliably used when comparing slight improvements from combining predictors.",
                "Therefore, we adopt the adjusted coefficient of determination which penalizes models with more variables.",
                "The adjusted R2 allows us to evaluate the improvement in prediction achieved by adding a parameter but loses the statistical interpretation of R2 .",
                "We will use Kendalls τ to evaluate the magnitude of the correlation and the adjusted R2 to evaluate the combination of variables. 6.",
                "RESULTS We present results for our detailed experiments comparing the prediction of language model scores in Table 1.",
                "Although the Clarity measure is theoretically designed for language model scores, it consistently underperforms our system-agnostic predictor.",
                "Ranking robustness was presented as an improvement to Clarity for web collections (represented in our experiments by the terabyte04 and terabyte05 collections), shifting the τ correlation from 0.139 to 0.150 for terabyte04 and 0.171 to 0.208 for terabyte05.",
                "However, these improvements are slight compared to the performance of <br>autocorrelation</br> on these collections.",
                "Our predictor achieves a τ correlation of 0.454 for terabyte04 and 0.383 for terabyte05.",
                "Though not always the strongest, <br>autocorrelation</br> achieves correlations competitive with baseline predictors.",
                "When examining the performance of linear combinations of predictors, we note that in every case, <br>autocorrelation</br> factors as a necessary component of a strong predictor.",
                "We also note that the adjusted R2 for individual baselines are always significantly improved by incorporating <br>autocorrelation</br>.",
                "We present our generalizability results in Table 2.",
                "We begin by examining the situation in column (a) where we are presented with a single retrieval and no information from additional retrievals.",
                "For every collection except one, we achieve significantly better correlations than ranked-list Clarity.",
                "Surprisingly, we achieve relatively strong correlations for Spanish and Chinese collections despite our na¨ıve processing.",
                "We do not have a ranked-list clarity correlation for ent05 because entity modeling is itself an open research question.",
                "However, our <br>autocorrelation</br> measure does not achieve high correlations perhaps because relevance for entity retrieval does not propagate according to the cooccurrence links we use.",
                "As noted above, the poor Clarity performance on web data is consistent with our findings in the detailed experiments.",
                "Clarity also notably underperforms for several news corpora (trec5, trec7, and robust04).",
                "On the other hand, <br>autocorrelation</br> seems robust to the changes between different corpora.",
                "Next, we turn to the introduction of information from multiple retrievals.",
                "We compare the correlations between those predictors which do not use this information in column (a) and those which do in column (b).",
                "For every collection, the predictors in column (b) outperform the predictors in column (a), indicating that the information from additional runs can be critical to making good predictions.",
                "Inspecting the predictors in column (b), we only draw weak conclusions.",
                "Our new predictors tend to perform better on news corpora.",
                "And between our new predictors, the hybrid ρ(˜y, yµ) predictor tends to perform better.",
                "Recall that our ρ(˜y, yµ) measure incorporates both spatial and multiple retrieval information.",
                "Therefore, we believe that the improvement in correlation is the result of incorporating information from spatial behavior.",
                "In column (c), we can investigate the utility of incorporating spatial information with information from multiple retrievals.",
                "Notice that in the cases where <br>autocorrelation</br>, ρ(y, ˜y), alone performs well (trec3, trec5-spanish, and trec6-chinese), it is substantially improved by incorporating multiple-retrieval information from ρ(y, yµ) in the linear regression, β.",
                "In the cases where ρ(y, yµ) performs well, incorporating <br>autocorrelation</br> rarely results in a significant improvement in performance.",
                "In fact, in every case where our predictor outperforms the baseline, it includes information from multiple runs. 7.",
                "DISCUSSION The most important result from our experiments involves prediction when no information is available from multiple runs (Tables 1 and 2a).",
                "This situation arises often in system design.",
                "For example, a system may need to, at retrieval time, assess its performance before deciding to conduct more intensive processing such as pseudo-relevance feedback or interaction.",
                "Assuming the presence of multiple retrievals is unrealistic in this case.",
                "We believe that <br>autocorrelation</br> is, like multiple-retrieval algorithms, approximating a good ranking; in this case by diffusing scores.",
                "Why is ˜y a reasonable surrogate?",
                "We know that diffusion of scores on the web graph and language model graphs improves performance [14, 16].",
                "Therefore, if score diffusion tends to, in general, improve performance, then diffused scores will, in general, provide a good surrogate for relevance.",
                "Our results demonstrate that this approximation is not as powerful as information from multiple retrievals.",
                "Nevertheless, in situations where this information is lacking, <br>autocorrelation</br> provides substantial information.",
                "The success of <br>autocorrelation</br> as a predictor may also have roots in the clustering hypothesis.",
                "Recall that we regard <br>autocorrelation</br> as the degree to which a retrieval satisfies the clustering hypothesis.",
                "Our experiments, then, demonstrate that a failure to respect the clustering hypothesis correlates with poor performance.",
                "Why might systems fail to conform to the cluster hypothesis?",
                "Query-based information retrieval systems often score documents independently.",
                "The score of document a may be computed by examining query term or phrase matches, the document length, and perhaps global collection statistics.",
                "Once computed, a system rarely compares the score of a to the score of a topically-related document b.",
                "With some exceptions, the correlation of document scores has largely been ignored.",
                "We should make it clear that we have selected tasks where topical <br>autocorrelation</br> is appropriate.",
                "There are certainly cases where there is no reason to believe that retrieval scores will have topical <br>autocorrelation</br>.",
                "For example, ranked lists which incorporate document novelty should not exhibit spatial <br>autocorrelation</br>; if anything <br>autocorrelation</br> should be negative for this task.",
                "Similarly, answer candidates in a question-answering task may or may not exhibit <br>autocorrelation</br>; in this case, the semantics of links is questionable too.",
                "It is important before applying this measure to confirm that, given the semantics for some link between two retrieved items, we should expect a correlation between scores. 8.",
                "RELATED WORK In this section we draw more general comparisons to other work in performance prediction and spatial data analysis.",
                "There is a growing body of work which attempts to predict the performance of individual retrievals [7, 3, 11, 9, 19].",
                "We have attempted to place our work in the context of much of this work in Section 4.",
                "However, a complete comparison is beyond the scope of this paper.",
                "We note, though, that our experiments cover a larger and more diverse set of retrievals, collections, and topics than previously examined.",
                "Much previous work-particularly in the context of TRECfocuses on predicting the performance of systems.",
                "Here, each system generates k retrievals.",
                "The task is, given these retrievals, to predict the ranking of systems according to some performance measure.",
                "Several papers attempt to address this task under the constraint of few judgments [2, 4].",
                "Some work even attempts to use zero judgments by leveraging multiple retrievals for the same query [17].",
                "Our task differs because we focus on ranking retrievals independent of the generating system.",
                "The task here is not to test the hypothesis system A is superior to system B but to test the hypothesis retrieval A is superior to retrieval B. <br>autocorrelation</br> manifests itself in many classification tasks.",
                "Neville and Jensen define relational <br>autocorrelation</br> for relational learning problems and demonstrate that many classification tasks manifest <br>autocorrelation</br> [13].",
                "Temporal <br>autocorrelation</br> of initial retrievals has also been used to predict performance [9].",
                "However, temporal <br>autocorrelation</br> is performed by projecting the retrieval function into the temporal embedding space.",
                "In our work, we focus on the behavior of the function over the relationships between documents. τ adjusted R2 DV KL P ρ(y, ˜y) DV KL P ρ(y, ˜y) DV KL, P DV KL, ρ(y, ˜y) Pρ(y, ˜y) β trec4 0.353 0.548 0.513 0.168 0.363 0.422 0.466 0.420 0.557 0.553 trec5 0.311 0.329 0.357 0.116 0.190 0.236 0.238 0.244 0.266 0.269 robust04 0.418 0.398 0.373 0.256 0.304 0.278 0.403 0.373 0.402 0.442 terabyte04 0.139 0.150 0.454 0.059 0.045 0.292 0.076 0.293 0.289 0.284 terabyte05 0.171 0.208 0.383 0.022 0.072 0.193 0.120 0.225 0.218 0.257 Table 1: Comparison to Robustness and Clarity measures for language model scores.",
                "Evaluation replicates experiments from [19].",
                "We present correlations between the classic Clarity measure (DV KL), the ranking robustness measure (P), and <br>autocorrelation</br> (ρ(y, ˜y)) each with mean average precision in terms of Kendalls τ.",
                "The adjusted coefficient of determination is presented to measure the effectiveness of combining predictors.",
                "Measures in bold represent the strongest correlation for that test/collection pair. multiple run (a) (b) (c) τ τ adjusted R2 DKL ρ(y, ˜y) Dn KL ρ(y, yµ) ρ(˜y, yµ) Dn KL ρ(y, ˜y) ρ(y, yµ) ρ(˜y, yµ) β trec3 0.201 0.461 0.461 0.439 0.456 0.444 0.395 0.394 0.386 0.498 trec4 0.252 0.396 0.455 0.482 0.489 0.379 0.263 0.429 0.482 0.483 trec5 0.016 0.277 0.433 0.459 0.393 0.280 0.157 0.375 0.323 0.386 trec6 0.230 0.227 0.352 0.428 0.418 0.203 0.089 0.323 0.325 0.325 trec7 0.083 0.326 0.341 0.430 0.483 0.264 0.182 0.363 0.442 0.400 trec8 0.235 0.396 0.454 0.508 0.567 0.402 0.272 0.490 0.580 0.523 robust03 0.302 0.354 0.377 0.385 0.447 0.269 0.206 0.274 0.392 0.303 robust04 0.183 0.308 0.301 0.384 0.453 0.200 0.182 0.301 0.393 0.335 robust05 0.224 0.249 0.371 0.377 0.404 0.341 0.108 0.313 0.328 0.336 terabyte04 0.043 0.245 0.544 0.420 0.392 0.516 0.105 0.357 0.343 0.365 terabyte05 0.068 0.306 0.480 0.434 0.390 0.491 0.168 0.384 0.309 0.403 trec4-spanish 0.307 0.388 0.488 0.398 0.395 0.423 0.299 0.282 0.299 0.388 trec5-spanish 0.220 0.458 0.446 0.484 0.475 0.411 0.398 0.428 0.437 0.529 trec5-chinese 0.092 0.199 0.367 0.379 0.384 0.379 0.199 0.273 0.276 0.310 trec6-chinese 0.144 0.276 0.265 0.353 0.376 0.115 0.128 0.188 0.223 0.199 ent05 - 0.181 0.324 0.305 0.282 0.211 0.043 0.158 0.155 0.179 Table 2: Large scale prediction experiments.",
                "We predict the ranking of large sets of retrievals for various collections and retrieval systems.",
                "Kendalls τ correlations are computed between the predicted ranking and a ranking based on the retrievals average precision.",
                "In column (a), we have predictors which do not use information from other retrievals for the same query.",
                "In columns (b) and (c) we present performance for predictors which incorporate information from multiple retrievals.",
                "The adjusted coefficient of determination is computed to determine effectiveness of combining predictors.",
                "Measures in bold represent the strongest correlation for that test/collection pair.",
                "Finally, regularization-based re-ranking processes are also closely-related to our work [8].",
                "These techniques seek to maximize the agreement between scores of related documents by solving a constrained optimization problem.",
                "The maximization of consistency is equivalent to maximizing the Moran <br>autocorrelation</br>.",
                "Therefore, we believe that our work provides explanation for why regularization-based re-ranking works. 9.",
                "CONCLUSION We have presented a new method for predicting the performance of a retrieval ranking without any relevance judgments.",
                "We consider two cases.",
                "First, when making predictions in the absence of retrievals from other systems, our predictors demonstrate robust, strong correlations with average precision.",
                "This performance, combined with a simple implementation, makes our predictors, in particular, very attractive.",
                "We have demonstrated this improvement for many, diverse settings.",
                "To our knowledge, this is the first large scale examination of zero-judgment, single-retrieval performance prediction.",
                "Second, when provided retrievals from other systems, our extended methods demonstrate competitive performance with state of the art baselines.",
                "Our experiments also demonstrate the limits of the usefulness of our predictors when information from multiple runs is provided.",
                "Our results suggest two conclusions.",
                "First, our results could affect retrieval algorithm design.",
                "Retrieval algorithms designed to consider spatial <br>autocorrelation</br> will conform to the cluster hypothesis and improve performance.",
                "Second, our results could affect the design of minimal test collection algorithms.",
                "Much of the recent work in ranking systems sometimes ignores correlations between document labels and scores.",
                "We believe that these two directions could be rewarding given the theoretical and experimental evidence in this paper. 10.",
                "ACKNOWLEDGMENTS This work was supported in part by the Center for Intelligent Information Retrieval and in part by the Defense Advanced Research Projects Agency (DARPA) under contract number HR0011-06-C-0023.",
                "Any opinions, findings and conclusions or recommendations expressed in this material are the authors and do not necessarily reflect those of the sponsor.",
                "We thank Yun Zhou and Desislava Petkova for providing data and Andre Gauthier for technical assistance. 11.",
                "REFERENCES [1] J. Aslam and V. Pavlu.",
                "Query hardness estimation using jensen-shannon divergence among multiple scoring functions.",
                "In ECIR 2007: Proceedings of the 29th European Conference on Information Retrieval, 2007. [2] J.",
                "A. Aslam, V. Pavlu, and E. Yilmaz.",
                "A statistical method for system evaluation using incomplete judgments.",
                "In S. Dumais, E. N. Efthimiadis, D. Hawking, and K. Jarvelin, editors, Proceedings of the 29th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 541-548.",
                "ACM Press, August 2006. [3] D. Carmel, E. Yom-Tov, A. Darlow, and D. Pelleg.",
                "What makes a query difficult?",
                "In SIGIR 06: Proceedings of the 29th annual international ACM SIGIR conference on Research and development in information retrieval, pages 390-397, New York, NY, USA, 2006.",
                "ACM Press. [4] B. Carterette, J. Allan, and R. Sitaraman.",
                "Minimal test collections for retrieval evaluation.",
                "In SIGIR 06: Proceedings of the 29th annual international ACM SIGIR conference on Research and development in information retrieval, pages 268-275, New York, NY, USA, 2006.",
                "ACM Press. [5] A. D. Cliff and J. K. Ord.",
                "Spatial <br>autocorrelation</br>.",
                "Pion Ltd., 1973. [6] M. Connell, A. Feng, G. Kumaran, H. Raghavan, C. Shah, and J. Allan.",
                "Umass at tdt 2004.",
                "Technical Report CIIR Technical Report IR - 357, Department of Computer Science, University of Massachusetts, 2004. [7] S. Cronen-Townsend, Y. Zhou, and W. B. Croft.",
                "Precision prediction based on ranked list coherence.",
                "Inf.",
                "Retr., 9(6):723-755, 2006. [8] F. Diaz.",
                "Regularizing ad-hoc retrieval scores.",
                "In CIKM 05: Proceedings of the 14th ACM international conference on Information and knowledge management, pages 672-679, New York, NY, USA, 2005.",
                "ACM Press. [9] F. Diaz and R. Jones.",
                "Using temporal profiles of queries for precision prediction.",
                "In SIGIR 04: Proceedings of the 27th annual international ACM SIGIR conference on Research and development in information retrieval, pages 18-24, New York, NY, USA, 2004.",
                "ACM Press. [10] D. A. Griffith.",
                "Spatial <br>autocorrelation</br> and Spatial Filtering.",
                "Springer Verlag, 2003. [11] B.",
                "He and I. Ounis.",
                "Inferring Query Performance Using Pre-retrieval Predictors.",
                "In The Eleventh Symposium on String Processing and Information Retrieval (SPIRE), 2004. [12] N. Jardine and C. J. V. Rijsbergen.",
                "The use of hierarchic clustering in information retrieval.",
                "Information Storage and Retrieval, 7:217-240, 1971. [13] D. Jensen and J. Neville.",
                "Linkage and <br>autocorrelation</br> cause feature selection bias in relational learning.",
                "In ICML 02: Proceedings of the Nineteenth International Conference on Machine Learning, pages 259-266, San Francisco, CA, USA, 2002.",
                "Morgan Kaufmann Publishers Inc. [14] O. Kurland and L. Lee.",
                "Corpus structure, language models, and ad-hoc information retrieval.",
                "In SIGIR 04: Proceedings of the 27th annual international conference on Research and development in information retrieval, pages 194-201, New York, NY, USA, 2004.",
                "ACM Press. [15] M. Montague and J.",
                "A. Aslam.",
                "Relevance score normalization for metasearch.",
                "In CIKM 01: Proceedings of the tenth international conference on Information and knowledge management, pages 427-433, New York, NY, USA, 2001.",
                "ACM Press. [16] T. Qin, T.-Y.",
                "Liu, X.-D. Zhang, Z. Chen, and W.-Y.",
                "Ma.",
                "A study of relevance propagation for web search.",
                "In SIGIR 05: Proceedings of the 28th annual international ACM SIGIR conference on Research and development in information retrieval, pages 408-415, New York, NY, USA, 2005.",
                "ACM Press. [17] I. Soboroff, C. Nicholas, and P. Cahan.",
                "Ranking retrieval systems without relevance judgments.",
                "In SIGIR 01: Proceedings of the 24th annual international ACM SIGIR conference on Research and development in information retrieval, pages 66-73, New York, NY, USA, 2001.",
                "ACM Press. [18] V. Vinay, I. J. Cox, N. Milic-Frayling, and K. Wood.",
                "On ranking the effectiveness of searches.",
                "In SIGIR 06: Proceedings of the 29th annual international ACM SIGIR conference on Research and development in information retrieval, pages 398-404, New York, NY, USA, 2006.",
                "ACM Press. [19] Y. Zhou and W. B. Croft.",
                "Ranking robustness: a novel framework to predict query performance.",
                "In CIKM 06: Proceedings of the 15th ACM international conference on Information and knowledge management, pages 567-574, New York, NY, USA, 2006.",
                "ACM Press."
            ],
            "original_annotated_samples": [
                "Performance Prediction Using Spatial <br>autocorrelation</br> Fernando Diaz Center for Intelligent Information Retrieval Department of Computer Science University of Massachusetts Amherst, MA 01003 fdiaz@cs.umass.edu ABSTRACT Evaluation of information retrieval systems is one of the core tasks in information retrieval.",
                "Score consistency can be measured by the spatial version of <br>autocorrelation</br> known as the Moran coefficient or IM [5, 10].",
                "As we shall see, a retrieval functions spatial <br>autocorrelation</br> measures the degree to which closely-related documents receive similar scores.",
                "Because of this, we interpret <br>autocorrelation</br> as measuring the degree to which a retrieval function satisfies the clustering hypothesis.",
                "If we want to quantify the spatial dependencies of a function, we would employ a measure referred to as the spatial <br>autocorrelation</br> [5, 10]."
            ],
            "translated_annotated_samples": [
                "Predicción del rendimiento utilizando <br>autocorrelación espacial</br>. Fernando Díaz. Centro de Recuperación de Información Inteligente. Departamento de Ciencias de la Computación. Universidad de Massachusetts Amherst, MA 01003. fdiaz@cs.umass.edu. RESUMEN La evaluación de sistemas de recuperación de información es una de las tareas fundamentales en la recuperación de información.",
                "La consistencia de la puntuación puede medirse mediante la versión espacial de la autocorrelación conocida como el <br>coeficiente de Moran</br> o IM [5, 10].",
                "Como veremos, una función de recuperación de medidas de <br>autocorrelación espacial</br> mide el grado en que los documentos relacionados reciben puntuaciones similares.",
                "Debido a esto, interpretamos la <br>autocorrelación</br> como la medida del grado en que una función de recuperación satisface la hipótesis de agrupamiento.",
                "Si queremos cuantificar las dependencias espaciales de una función, emplearíamos una medida conocida como la <br>autocorrelación espacial</br> [5, 10]."
            ],
            "translated_text": "Predicción del rendimiento utilizando <br>autocorrelación espacial</br>. Fernando Díaz. Centro de Recuperación de Información Inteligente. Departamento de Ciencias de la Computación. Universidad de Massachusetts Amherst, MA 01003. fdiaz@cs.umass.edu. RESUMEN La evaluación de sistemas de recuperación de información es una de las tareas fundamentales en la recuperación de información. Los problemas incluyen la incapacidad de etiquetar exhaustivamente todos los documentos sobre un tema, la falta de generalización a partir de un pequeño número de temas e incorporar la variabilidad de los sistemas de recuperación. Trabajos anteriores abordan la evaluación de sistemas, la clasificación de consultas por dificultad y la clasificación de recuperaciones individuales por rendimiento. Existen enfoques para el caso de pocos e incluso ningún juicio de relevancia. Nuestro enfoque está en la predicción del rendimiento sin juicios de las recuperaciones individuales. Una deficiencia común de las técnicas anteriores es la suposición de que las puntuaciones de los documentos y los juicios no están correlacionados. Si los documentos están incrustados en un espacio de alta dimensión (como a menudo lo están), podemos aplicar técnicas de análisis de datos espaciales para detectar correlaciones entre las puntuaciones de los documentos. Observamos que la baja correlación entre las puntuaciones de documentos temáticamente cercanos a menudo implica un bajo rendimiento en la recuperación. Cuando se compara con una línea base de última generación, demostramos que el análisis espacial de las puntuaciones de recuperación ofrece un rendimiento predictivo significativamente mejor. Estos nuevos predictores también pueden ser incorporados con predictores clásicos para mejorar aún más el rendimiento. También describimos el primer experimento a gran escala para evaluar la predicción de rendimiento sin juicio para un gran número de sistemas de recuperación en una variedad de colecciones en varios idiomas. Categorías y Descriptores de Asignaturas H.3.3 [Búsqueda y Recuperación de Información]: Modelos de recuperación; H.3.4 [Sistemas y Software]: Evaluación del rendimiento (eficiencia y efectividad) Términos Generales Rendimiento, Diseño, Confiabilidad, Experimentación 1. En la recuperación de información, un usuario plantea una consulta a un sistema. El sistema recupera n documentos, cada uno recibiendo una puntuación de valor real que indica el grado de relevancia predicho. Si seleccionamos aleatoriamente pares de documentos de este conjunto, esperamos que algunos pares compartan el mismo tema y otros pares no compartan el mismo tema. Toma dos documentos relacionados entre sí del conjunto y llámalos a y b. Si las puntuaciones de a y b son muy diferentes, podríamos estar preocupados por el rendimiento de nuestro sistema. Es decir, si tanto a como b están relacionados con el tema de la consulta, nos gustaría que ambos reciban una puntuación alta; si a y b no están relacionados con el tema de la consulta, nos gustaría que ambos reciban una puntuación baja. Podríamos preocuparnos más a medida que encontramos más diferencias entre las puntuaciones de documentos relacionados. Estaríamos más cómodos con una recuperación en la que las puntuaciones sean consistentes entre documentos relacionados. Nuestro artículo estudia la cuantificación de esta inconsistencia en una recuperación desde una perspectiva espacial. El análisis espacial es apropiado ya que muchos modelos de recuperación incrustan documentos en algún espacio vectorial. Si los documentos están incrustados en un espacio, la proximidad se correlaciona con las relaciones temáticas. La consistencia de la puntuación puede medirse mediante la versión espacial de la autocorrelación conocida como el <br>coeficiente de Moran</br> o IM [5, 10]. En este artículo, demostramos una fuerte correlación entre IM y el rendimiento de recuperación. La discusión hasta este punto recuerda a la hipótesis del cúmulo. La hipótesis del clúster establece que los documentos estrechamente relacionados tienden a ser relevantes para la misma solicitud [12]. Como veremos, una función de recuperación de medidas de <br>autocorrelación espacial</br> mide el grado en que los documentos relacionados reciben puntuaciones similares. Debido a esto, interpretamos la <br>autocorrelación</br> como la medida del grado en que una función de recuperación satisface la hipótesis de agrupamiento. Si esta conexión es razonable, en la Sección 6 presentamos evidencia de que la falta de cumplimiento de la hipótesis de agrupamiento se correlaciona fuertemente con un bajo rendimiento. En este trabajo, proporcionamos las siguientes contribuciones: 1. Un método general y robusto para predecir el rendimiento de recuperaciones sin juicios de relevancia (Sección 3). 2. Un tratamiento teórico de las similitudes y motivaciones detrás de varias técnicas de predicción de rendimiento de vanguardia (Sección 4). 3. Las primeras experimentaciones a gran escala de predicción de rendimiento de una sola ejecución sin juicio (Secciones 5 y 6). 2. Dada una consulta, un sistema de recuperación de información produce una clasificación de documentos en la colección codificada como un conjunto de puntuaciones asociadas con los documentos. Nos referimos al conjunto de puntuaciones para una combinación particular de consulta-sistema como una recuperación. Nos gustaría predecir el rendimiento de esta recuperación con respecto a alguna medida de evaluación (por ejemplo, precisión promedio). En este artículo, presentamos resultados para clasificar recuperaciones de sistemas arbitrarios. Nos gustaría que este ranking se aproximara al ranking de recuperaciones según la medida de evaluación. Esto es diferente de clasificar las consultas por el rendimiento promedio en cada consulta. También es diferente de los sistemas de clasificación por el rendimiento promedio en un conjunto de consultas. Las puntuaciones a menudo solo se calculan para los primeros n documentos de la colección. Colocamos estos puntajes en el vector de longitud n, y, donde yi se refiere al puntaje del documento clasificado en la posición i. Ajustamos las puntuaciones para que tengan una media de cero y una varianza unitaria. Utilizamos este método debido a su simplicidad y su éxito en trabajos anteriores [15]. CORRELACIÓN ESPACIAL En la recuperación de información, a menudo asumimos que las representaciones de los documentos existen en algún espacio vectorial de alta dimensión. Por ejemplo, dado un vocabulario, V, este espacio vectorial puede ser un espacio arbitrario de dimensión |V| con producto interno de coseno o un simplejo multinomial con una medida de distancia basada en distribución. Un espacio de incrustación suele ser seleccionado para respetar la proximidad temática; si dos documentos están cerca, es más probable que compartan un tema. Debido a la prevalencia y éxito de los modelos espaciales de recuperación de información, creemos que la aplicación de técnicas de análisis de datos espaciales es apropiada. Mientras que en la recuperación de información nos preocupa la puntuación en un punto en el espacio, en el análisis de datos espaciales nos preocupa el valor de una función en un punto o ubicación en el espacio. Utilizamos el término función aquí para referirnos a una asignación de una ubicación a un valor real. Por ejemplo, podríamos estar interesados en la prevalencia de una enfermedad en el vecindario de alguna ciudad. La función asignaría la ubicación de un vecindario a una tasa de infección. Si queremos cuantificar las dependencias espaciales de una función, emplearíamos una medida conocida como la <br>autocorrelación espacial</br> [5, 10]. ",
            "candidates": [],
            "error": [
                [
                    "autocorrelación espacial",
                    "coeficiente de Moran",
                    "autocorrelación espacial",
                    "autocorrelación",
                    "autocorrelación espacial"
                ]
            ]
        },
        "cluster hypothesis": {
            "translated_key": "hipótesis del clúster",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Performance Prediction Using Spatial Autocorrelation Fernando Diaz Center for Intelligent Information Retrieval Department of Computer Science University of Massachusetts Amherst, MA 01003 fdiaz@cs.umass.edu ABSTRACT Evaluation of information retrieval systems is one of the core tasks in information retrieval.",
                "Problems include the inability to exhaustively label all documents for a topic, nongeneralizability from a small number of topics, and incorporating the variability of retrieval systems.",
                "Previous work addresses the evaluation of systems, the ranking of queries by difficulty, and the ranking of individual retrievals by performance.",
                "Approaches exist for the case of few and even no relevance judgments.",
                "Our focus is on zero-judgment performance prediction of individual retrievals.",
                "One common shortcoming of previous techniques is the assumption of uncorrelated document scores and judgments.",
                "If documents are embedded in a high-dimensional space (as they often are), we can apply techniques from spatial data analysis to detect correlations between document scores.",
                "We find that the low correlation between scores of topically close documents often implies a poor retrieval performance.",
                "When compared to a state of the art baseline, we demonstrate that the spatial analysis of retrieval scores provides significantly better prediction performance.",
                "These new predictors can also be incorporated with classic predictors to improve performance further.",
                "We also describe the first large-scale experiment to evaluate zero-judgment performance prediction for a massive number of retrieval systems over a variety of collections in several languages.",
                "Categories and Subject Descriptors H.3.3 [Information Search and Retrieval]: Retrieval models; H.3.4 [Systems and Software]: Performance evaluation (efficiency and effectiveness) General Terms Performance, Design, Reliability, Experimentation 1.",
                "INTRODUCTION In information retrieval, a user poses a query to a system.",
                "The system retrieves n documents each receiving a realvalued score indicating the predicted degree of relevance.",
                "If we randomly select pairs of documents from this set, we expect some pairs to share the same topic and other pairs to not share the same topic.",
                "Take two topically-related documents from the set and call them a and b.",
                "If the scores of a and b are very different, we may be concerned about the performance of our system.",
                "That is, if a and b are both on the topic of the query, we would like them both to receive a high score; if a and b are not on the topic of the query, we would like them both to receive a low score.",
                "We might become more worried as we find more differences between scores of related documents.",
                "We would be more comfortable with a retrieval where scores are consistent between related documents.",
                "Our paper studies the quantification of this inconsistency in a retrieval from a spatial perspective.",
                "Spatial analysis is appropriate since many retrieval models embed documents in some vector space.",
                "If documents are embedded in a space, proximity correlates with topical relationships.",
                "Score consistency can be measured by the spatial version of autocorrelation known as the Moran coefficient or IM [5, 10].",
                "In this paper, we demonstrate a strong correlation between IM and retrieval performance.",
                "The discussion up to this point is reminiscent of the <br>cluster hypothesis</br>.",
                "The <br>cluster hypothesis</br> states: closely-related documents tend to be relevant to the same request [12].",
                "As we shall see, a retrieval functions spatial autocorrelation measures the degree to which closely-related documents receive similar scores.",
                "Because of this, we interpret autocorrelation as measuring the degree to which a retrieval function satisfies the clustering hypothesis.",
                "If this connection is reasonable, in Section 6, we present evidence that failure to satisfy the <br>cluster hypothesis</br> correlates strongly with poor performance.",
                "In this work, we provide the following contributions, 1.",
                "A general, robust method for predicting the performance of retrievals with zero relevance judgments (Section 3). 2.",
                "A theoretical treatment of the similarities and motivations behind several state-of-the-art performance prediction techniques (Section 4). 3.",
                "The first large-scale experiments of zero-judgment, single run performance prediction (Sections 5 and 6). 2.",
                "PROBLEM DEFINITION Given a query, an information retrieval system produces a ranking of documents in the collection encoded as a set of scores associated with documents.",
                "We refer to the set of scores for a particular query-system combination as a retrieval.",
                "We would like to predict the performance of this retrieval with respect to some evaluation measure (eg, mean average precision).",
                "In this paper, we present results for ranking retrievals from arbitrary systems.",
                "We would like this ranking to approximate the ranking of retrievals by the evaluation measure.",
                "This is different from ranking queries by the average performance on each query.",
                "It is also different from ranking systems by the average performance on a set of queries.",
                "Scores are often only computed for the top n documents from the collection.",
                "We place these scores in the length n vector, y, where yi refers to the score of the ith-ranked document.",
                "We adjust scores to have zero mean and unit variance.",
                "We use this method because of its simplicity and its success in previous work [15]. 3.",
                "SPATIAL CORRELATION In information retrieval, we often assume that the representations of documents exist in some high-dimensional vector space.",
                "For example, given a vocabulary, V, this vector space may be an arbitrary |V|-dimensional space with cosine inner-product or a multinomial simplex with a distributionbased distance measure.",
                "An embedding space is often selected to respect topical proximity; if two documents are near, they are more likely to share a topic.",
                "Because of the prevalence and success of spatial models of information retrieval, we believe that the application of spatial data analysis techniques are appropriate.",
                "Whereas in information retrieval, we are concerned with the score at a point in a space, in spatial data analysis, we are concerned with the value of a function at a point or location in a space.",
                "We use the term function here to mean a mapping from a location to a real value.",
                "For example, we might be interested in the prevalence of a disease in the neighborhood of some city.",
                "The function would map the location of a neighborhood to an infection rate.",
                "If we want to quantify the spatial dependencies of a function, we would employ a measure referred to as the spatial autocorrelation [5, 10].",
                "High spatial autocorrelation suggests that knowing the value of a function at location a will tell us a great deal about the value at a neighboring location b.",
                "There is a high spatial autocorrelation for a function representing the temperature of a location since knowing the temperature at a location a will tell us a lot about the temperature at a neighboring location b.",
                "Low spatial autocorrelation suggests that knowing the value of a function at location a tells us little about the value at a neighboring location b.",
                "There is low spatial autocorrelation in a function measuring the outcome of a coin toss at a and b.",
                "In this section, we will begin by describing what we mean by spatial proximity for documents and then define a measure of spatial autocorrelation.",
                "We conclude by extending this model to include information from multiple retrievals from multiple systems for a single query. 3.1 Spatial Representation of Documents Our work does not focus on improving a specific similarity measure or defining a novel vector space.",
                "Instead, we choose an inner product known to be effective at detecting interdocument topical relationships.",
                "Specifically, we adopt tf.idf document vectors, ˜di = di log „ (n + 0.5) − ci 0.5 + ci « (1) where d is a vector of term frequencies, c is the length-|V| document frequency vector.",
                "We use this weighting scheme due to its success for topical link detection in the context of Topic Detection and Tracking (TDT) evaluations [6].",
                "Assuming vectors are scaled by their L2 norm, we use the inner product, ˜di, ˜dj , to define similarity.",
                "Given documents and some similarity measure, we can construct a matrix which encodes the similarity between pairs of documents.",
                "Recall that we are given the top n documents retrieved in y.",
                "We can compute an n × n similarity matrix, W. An element of this matrix, Wij represents the similarity between documents ranked i and j.",
                "In practice, we only include the affinities for a documents k-nearest neighbors.",
                "In all of our experiments, we have fixed k to 5.",
                "We leave exploration of parameter sensitivity to future work.",
                "We also row normalize the matrix so that Pn j=1 Wij = 1 for all i. 3.2 Spatial Autocorrelation of a Retrieval Recall that we are interested in measuring the similarity between the scores of spatially-close documents.",
                "One such suitable measure is the Moran coefficient of spatial autocorrelation.",
                "Assuming the function y over n locations, this is defined as ˜IM = n eTWe P i,j Wijyiyj P i y2 i = n eTWe yT Wy yTy (2) where eT We = P ij Wij.",
                "We would like to compare autocorrelation values for different retrievals.",
                "Unfortunately, the bound for Equation 2 is not consistent for different W and y.",
                "Therefore, we use the Cauchy-Schwartz inequality to establish a bound, ˜IM ≤ n eTWe s yTWTWy yTy And we define the normalized spatial autocorrelation as IM = yT Wy p yTy × yTWTWy Notice that if we let ˜y = Wy, then we can write this formula as, IM = yT ˜y y 2 ˜y 2 (3) which can be interpreted as the correlation between the original retrieval scores and a set of retrieval scores diffused in the space.",
                "We present some examples of autocorrelations of functions on a grid in Figure 1. 3.3 Correlation with Other Retrievals Sometimes we are interested in the performance of a single retrieval but have access to scores from multiple systems for (a) IM = 0.006 (b) IM = 0.241 (c) IM = 0.487 Figure 1: The Moran coefficient, IM for a several binary functions on a grid.",
                "The Moran coefficient is a local measure of function consistency.",
                "From the perspective of information retrieval, each of these grid spaces would represent a document and documents would be organized so that they lay next to topically-related documents.",
                "Binary retrieval scores would define a pattern on this grid.",
                "Notice that, as the Moran coefficient increases, neighboring cells tend to have similar values. the same query.",
                "In this situation, we can use combined information from these scores to construct a surrogate for a high-quality ranking [17].",
                "We can treat the correlation between the retrieval we are interested in and the combined scores as a predictor of performance.",
                "Assume that we are given m score functions, yi, for the same n documents.",
                "We will represent the mean of these vectors as yµ = Pm i=1 yi.",
                "We use the mean vector as an approximation to relevance.",
                "Since we use zero mean and unit variance normalization, work in metasearch suggests that this assumption is justified [15].",
                "Because yµ represents a very good retrieval, we hypothesize that a strong similarity between yµ and y will correlate positively with system performance.",
                "We use Pearsons product-moment correlation to measure the similarity between these vectors, ρ(y, yµ) = yT yµ y 2 yµ 2 (4) We will comment on the similarity between Equation 3 and 4 in Section 7.",
                "Of course, we can combine ρ(y, ˜y) and ρ(y, yµ) if we assume that they capture different factors in the prediction.",
                "One way to accomplish this is to combine these predictors as independent variables in a linear regression.",
                "An alternative means of combination is suggested by the mathematical form of our predictors.",
                "Since ˜y encodes the spatial dependencies in y and yµ encodes the spatial properties of the multiple runs, we can compute a third correlation between these two vectors, ρ(˜y, yµ) = ˜yT yµ ˜y 2 yµ 2 (5) We can interpret Equation 5 as measuring the correlation between a high quality ranking (yµ) and a spatially smoothed version of the retrieval (˜y). 4.",
                "RELATIONSHIP WITH OTHER PREDICTORS One way to predict the effectiveness of a retrieval is to look at the shared vocabulary of the top n retrieved documents.",
                "If we computed the most frequent content words in this set, we would hope that they would be consistent with our topic.",
                "In fact, we might believe that a bad retrieval would include documents on many disparate topics, resulting in an overlap of terminological noise.",
                "The Clarity of a query attempts to quantify exactly this [7].",
                "Specifically, Clarity measures the similarity of the words most frequently used in retrieved documents to those most frequently used in the whole corpus.",
                "The conjecture is that a good retrieval will use language distinct from general text; the overlapping language in a bad retrieval will tend to be more similar to general text.",
                "Mathematically, we can compute a representation of the language used in the initial retrieval as a weighted combination of document language models, P(w|θQ) = nX i=1 P(w|θi) P(Q|θi) Z (6) where θi is the language model of the ith-ranked document, P(Q|θi) is the query likelihood score of the ith-ranked document and Z = Pn i=1 P(Q|θi) is a normalization constant.",
                "The similarity between the multinomial P(w|θQ) and a model of general text can be computed using the Kullback-Leibler divergence, DV KL(θQ θC ).",
                "Here, the distribution P(w|θC ) is our model of general text which can be computed using term frequencies in the corpus.",
                "In Figure 2a, we present Clarity as measuring the distance between the weighted center of mass of the retrieval (labeled y) and the unweighted center of mass of the collection (labeled O).",
                "Clarity reaches a minimum when a retrieval assigns every document the same score.",
                "Lets again assume we have a set of n documents retrieved for our query.",
                "Another way to quantify the dispersion of a set of documents is to look at how clustered they are.",
                "We may hypothesize that a good retrieval will return a single, tight cluster.",
                "A poorly performing retrieval will return a loosely related set of documents covering many topics.",
                "One proposed method of quantifying this dispersion is to measure the distance from a random document a to its nearest neighbor, b.",
                "A retrieval which is tightly clustered will, on average, have a low distance between a and b; a retrieval which is less tightly-closed will, on average have high distances between a and b.",
                "This average corresponds to using the Cox-Lewis statistic to measure the randomness of the top n documents retrieved from a system [18].",
                "In Figure 2a, this is roughly equivalent to measuring the area of the set n. Notice that we are throwing away information about the retrieval function y.",
                "Therefore the Cox-Lewis statistic is highly dependent on selecting the top n documents.1 Remember that we have n documents and a set of scores.",
                "Lets assume that we have access to the system which provided the original scores and that we can also request scores for new documents.",
                "This suggests a third method for predicting performance.",
                "Take some document, a, from the retrieved set and arbitrarily add or remove words at random to create a new document ˜a.",
                "Now, we can ask our system to score ˜a with respect to our query.",
                "If, on average over the n documents, the scores of a and ˜a tend to be very different, we might suspect that the system is failing on this query.",
                "So, an alternative approach is to measure the simi1 The authors have suggested coupling the query with the distance measure [18].",
                "The information introduced by the query, though, is retrieval-independent so that, if two retrievals return the same set of documents, the approximate Cox-Lewis statistic will be the same regardless of the retrieval scores. yOy (a) Global Divergence µ(y)˜y y (b) Score Perturbation µ(y) y (c) Multirun Averaging Figure 2: Representation of several performance predictors on a grid.",
                "In Figure 2a, we depict predictors which measure the divergence between the center of mass of a retrieval and the center of the embedding space.",
                "In Figure 2b, we depict predictors which compare the original retrieval, y, to a perturbed version of the retrieval, ˜y.",
                "Our approach uses a particular type of perturbation based on score diffusion.",
                "Finally, in Figure 2c, we depict prediction when given retrievals from several other systems on the same query.",
                "Here, we can consider the fusion of these retrieval as a surrogate for relevance. larity between the retrieval and a perturbed version of that retrieval [18, 19].",
                "This can be accomplished by either perturbing the documents or queries.",
                "The similarity between the two retrievals can be measured using some correlation measure.",
                "This is depicted in Figure 2b.",
                "The upper grid represents the original retrieval, y, while the lower grid represents the function after having been perturbed, ˜y.",
                "The nature of the perturbation process requires additional scorings or retrievals.",
                "Our predictor does not require access to the original scoring function or additional retrievals.",
                "So, although our method is similar to other perturbation methods in spirit, it can be applied in situations when the retrieval system is inaccessible or costly to access.",
                "Finally, assume that we have, in addition to the retrieval we want to evaluate, m retrievals from a variety of different systems.",
                "In this case, we might take a document a, compare its rank in the retrieval to its average rank in the m retrievals.",
                "If we believe that the m retrievals provide a satisfactory approximation to relevance, then a very large difference in rank would suggest that our retrieval is misranking a.",
                "If this difference is large on average over all n documents, then we might predict that the retrieval is bad.",
                "If, on the other hand, the retrieval is very consistent with the m retrievals, then we might predict that the retrieval is good.",
                "The similarity between the retrieval and the combined retrieval may be computed using some correlation measure.",
                "This is depicted in Figure 2c.",
                "In previous work, the Kullback-Leibler divergence between the normalized scores of the retrieval and the normalized scores of the combined retrieval provides the similarity [1]. 5.",
                "EXPERIMENTS Our experiments focus on testing the predictive power of each of our predictors: ρ(y, ˜y), ρ(y, yµ), and ρ(˜y, yµ).",
                "As stated in Section 2, we are interested in predicting the performance of the retrieval generated by an arbitrary system.",
                "Our methodology is consistent with previous research in that we predict the relative performance of a retrieval by comparing a ranking based on our predictor to a ranking based on average precision.",
                "We present results for two sets of experiments.",
                "The first set of experiments presents detailed comparisons of our predictors to previously-proposed predictors using identical data sets.",
                "Our second set of experiments demonstrates the generalizability of our approach to arbitrary retrieval methods, corpus types, and corpus languages. 5.1 Detailed Experiments In these experiments, we will predict the performance of language modeling scores using our autocorrelation predictor, ρ(y, ˜y); we do not consider ρ(y, yµ) or ρ(˜y, yµ) because, in these detailed experiments, we focus on ranking the retrievals from a single system.",
                "We use retrievals, values for baseline predictors, and evaluation measures reported in previous work [19]. 5.1.1 Topics and Collections These performance prediction experiments use language model retrievals performed for queries associated with collections in the TREC corpora.",
                "Using TREC collections allows us to confidently associate an average precision with a retrieval.",
                "In these experiments, we use the following topic collections: TREC 4 ad-hoc, TREC 5 ad-hoc, Robust 2004, Terabyte 2004, and Terabyte 2005. 5.1.2 Baselines We provide two baselines.",
                "Our first baseline is the classic Clarity predictor presented in Equation 6.",
                "Clarity is designed to be used with language modeling systems.",
                "Our second baseline is Zhou and Crofts ranking robustness predictor.",
                "This predictor corrupts the top k documents from retrieval and re-computes the language model scores for these corrupted documents.",
                "The value of the predictor is the Spearman rank correlation between the original ranking and the corrupted ranking.",
                "In our tables, we will label results for Clarity using DV KL and the ranking robustness predictor using P. 5.2 Generalizability Experiments Our predictors do not require a particular baseline retrieval system; the predictors can be computed for an arbitrary retrieval, regardless of how scores were generated.",
                "We believe that that is one of the most attractive aspects of our algorithm.",
                "Therefore, in a second set of experiments, we demonstrate the ability of our techniques to generalize to a variety of collections, topics, and retrieval systems. 5.2.1 Topics and Collections We gathered a diverse set of collections from all possible TREC corpora.",
                "We cast a wide net in order to locate collections where our predictors might fail.",
                "Our hypothesis is that documents with high topical similarity should have correlated scores.",
                "Therefore, we avoided collections where scores were unlikely to be correlated (eg, question-answering) or were likely to be negatively correlated (eg, novelty).",
                "Nevertheless, our collections include corpora where correlations are weakly justified (eg, non-English corpora) or not justified at all (eg, expert search).",
                "We use the ad-hoc tracks from TREC3-8, TREC Robust 2003-2005, TREC Terabyte 20042005, TREC4-5 Spanish, TREC5-6 Chinese, and TREC Enterprise Expert Search 2005.",
                "In all cases, we use only the automatic runs for ad-hoc tracks submitted to NIST.",
                "For all English and Spanish corpora, we construct the matrix W according to the process described in Section 3.1.",
                "For Chinese corpora, we use na¨ıve character-based tf.idf vectors.",
                "For entities, entries in W are proportional to the number of documents in which two entities cooccur. 5.2.2 Baselines In our detailed experiments, we used the Clarity measure as a baseline.",
                "Since we are predicting the performance of retrievals which are not based on language modeling, we use a version of Clarity referred to as ranked-list Clarity [7].",
                "Ranked-list clarity converts document ranks to P(Q|θi) values.",
                "This conversion begins by replacing all of the scores in y with the respective ranks.",
                "Our estimation of P(Q|θi) from the ranks, then is, P(Q|θi) = ( 2(c+1−yi) c(c+1) if yi ≤ c 0 otherwise (7) where c is a cutoff parameter.",
                "As suggested by the authors, we fix the algorithm parameters c and λ2 so that c = 60 and λ2 = 0.10.",
                "We use Equation 6 to estimate P(w|θQ) and DV KL(θQ θC ) to compute the value of the predictor.",
                "We will refer to this predictor as DV KL, superscripted by V to indicate that the Kullback-Leibler divergence is with respect to the term embedding space.",
                "When information from multiple runs on the same query is available, we use Aslam and Pavlus document-space multinomial divergence as a baseline [1].",
                "This rank-based method first normalizes the scores in a retrieval as an n-dimensional multinomial.",
                "As with ranked-list Clarity, we begin by replacing all of the scores in y with their respective ranks.",
                "Then, we adjust the elements of y in the following way, ˆyi = 1 2n 0 @1 + nX k=yi 1 k 1 A (8) In our multirun experiments, we only use the top 75 documents from each retrieval (n = 75); this is within the range of parameter values suggested by the authors.",
                "However, we admit not tuning this parameter for either our system or the baseline.",
                "The predictor is the divergence between the candidate distribution, y, and the mean distribution, yµ .",
                "With the uniform linear combination of these m retrievals represented as yµ, we can compute the divergence as Dn KL(ˆy ˆyµ) where we use the superscript n to indicate that the summation is over the set of n documents.",
                "This baseline was developed in the context of predicting query difficulty but we adopt it as a reasonable baseline for predicting retrieval performance. 5.2.3 Parameter Settings When given multiple retrievals, we use documents in the union of the top k = 75 documents from each of the m retrievals for that query.",
                "If the size of this union is ˜n, then yµ and each yi is of length ˜n.",
                "In some cases, a system did not score a document in the union.",
                "Since we are making a Gaussian assumption about our scores, we can sample scores for these unseen documents from the negative tail of the distribution.",
                "Specifically, we sample from the part of the distribution lower than the minimum value of in the normalized retrieval.",
                "This introduces randomness into our algorithm but we believe it is more appropriate than assigning an arbitrary fixed value.",
                "We optimized the linear regression using the square root of each predictor.",
                "We found that this substantially improved fits for all predictors, including the baselines.",
                "We considered linear combinations of pairs of predictors (labeled by the components) and all predictors (labeled as β). 5.3 Evaluation Given a set of retrievals, potentially from a combination of queries and systems, we measure the correlation of the rank ordering of this set by the predictor and by the performance metric.",
                "In order to ensure comparability with previous results, we present Kendalls τ correlation between the predictors ranking and ranking based on average precision of the retrieval.",
                "Unless explicitly noted, all correlations are significant with p < 0.05.",
                "Predictors can sometimes perform better when linearly combined [9, 11].",
                "Although previous work has presented the coefficient of determination (R2 ) to measure the quality of the regression, this measure cannot be reliably used when comparing slight improvements from combining predictors.",
                "Therefore, we adopt the adjusted coefficient of determination which penalizes models with more variables.",
                "The adjusted R2 allows us to evaluate the improvement in prediction achieved by adding a parameter but loses the statistical interpretation of R2 .",
                "We will use Kendalls τ to evaluate the magnitude of the correlation and the adjusted R2 to evaluate the combination of variables. 6.",
                "RESULTS We present results for our detailed experiments comparing the prediction of language model scores in Table 1.",
                "Although the Clarity measure is theoretically designed for language model scores, it consistently underperforms our system-agnostic predictor.",
                "Ranking robustness was presented as an improvement to Clarity for web collections (represented in our experiments by the terabyte04 and terabyte05 collections), shifting the τ correlation from 0.139 to 0.150 for terabyte04 and 0.171 to 0.208 for terabyte05.",
                "However, these improvements are slight compared to the performance of autocorrelation on these collections.",
                "Our predictor achieves a τ correlation of 0.454 for terabyte04 and 0.383 for terabyte05.",
                "Though not always the strongest, autocorrelation achieves correlations competitive with baseline predictors.",
                "When examining the performance of linear combinations of predictors, we note that in every case, autocorrelation factors as a necessary component of a strong predictor.",
                "We also note that the adjusted R2 for individual baselines are always significantly improved by incorporating autocorrelation.",
                "We present our generalizability results in Table 2.",
                "We begin by examining the situation in column (a) where we are presented with a single retrieval and no information from additional retrievals.",
                "For every collection except one, we achieve significantly better correlations than ranked-list Clarity.",
                "Surprisingly, we achieve relatively strong correlations for Spanish and Chinese collections despite our na¨ıve processing.",
                "We do not have a ranked-list clarity correlation for ent05 because entity modeling is itself an open research question.",
                "However, our autocorrelation measure does not achieve high correlations perhaps because relevance for entity retrieval does not propagate according to the cooccurrence links we use.",
                "As noted above, the poor Clarity performance on web data is consistent with our findings in the detailed experiments.",
                "Clarity also notably underperforms for several news corpora (trec5, trec7, and robust04).",
                "On the other hand, autocorrelation seems robust to the changes between different corpora.",
                "Next, we turn to the introduction of information from multiple retrievals.",
                "We compare the correlations between those predictors which do not use this information in column (a) and those which do in column (b).",
                "For every collection, the predictors in column (b) outperform the predictors in column (a), indicating that the information from additional runs can be critical to making good predictions.",
                "Inspecting the predictors in column (b), we only draw weak conclusions.",
                "Our new predictors tend to perform better on news corpora.",
                "And between our new predictors, the hybrid ρ(˜y, yµ) predictor tends to perform better.",
                "Recall that our ρ(˜y, yµ) measure incorporates both spatial and multiple retrieval information.",
                "Therefore, we believe that the improvement in correlation is the result of incorporating information from spatial behavior.",
                "In column (c), we can investigate the utility of incorporating spatial information with information from multiple retrievals.",
                "Notice that in the cases where autocorrelation, ρ(y, ˜y), alone performs well (trec3, trec5-spanish, and trec6-chinese), it is substantially improved by incorporating multiple-retrieval information from ρ(y, yµ) in the linear regression, β.",
                "In the cases where ρ(y, yµ) performs well, incorporating autocorrelation rarely results in a significant improvement in performance.",
                "In fact, in every case where our predictor outperforms the baseline, it includes information from multiple runs. 7.",
                "DISCUSSION The most important result from our experiments involves prediction when no information is available from multiple runs (Tables 1 and 2a).",
                "This situation arises often in system design.",
                "For example, a system may need to, at retrieval time, assess its performance before deciding to conduct more intensive processing such as pseudo-relevance feedback or interaction.",
                "Assuming the presence of multiple retrievals is unrealistic in this case.",
                "We believe that autocorrelation is, like multiple-retrieval algorithms, approximating a good ranking; in this case by diffusing scores.",
                "Why is ˜y a reasonable surrogate?",
                "We know that diffusion of scores on the web graph and language model graphs improves performance [14, 16].",
                "Therefore, if score diffusion tends to, in general, improve performance, then diffused scores will, in general, provide a good surrogate for relevance.",
                "Our results demonstrate that this approximation is not as powerful as information from multiple retrievals.",
                "Nevertheless, in situations where this information is lacking, autocorrelation provides substantial information.",
                "The success of autocorrelation as a predictor may also have roots in the clustering hypothesis.",
                "Recall that we regard autocorrelation as the degree to which a retrieval satisfies the clustering hypothesis.",
                "Our experiments, then, demonstrate that a failure to respect the clustering hypothesis correlates with poor performance.",
                "Why might systems fail to conform to the <br>cluster hypothesis</br>?",
                "Query-based information retrieval systems often score documents independently.",
                "The score of document a may be computed by examining query term or phrase matches, the document length, and perhaps global collection statistics.",
                "Once computed, a system rarely compares the score of a to the score of a topically-related document b.",
                "With some exceptions, the correlation of document scores has largely been ignored.",
                "We should make it clear that we have selected tasks where topical autocorrelation is appropriate.",
                "There are certainly cases where there is no reason to believe that retrieval scores will have topical autocorrelation.",
                "For example, ranked lists which incorporate document novelty should not exhibit spatial autocorrelation; if anything autocorrelation should be negative for this task.",
                "Similarly, answer candidates in a question-answering task may or may not exhibit autocorrelation; in this case, the semantics of links is questionable too.",
                "It is important before applying this measure to confirm that, given the semantics for some link between two retrieved items, we should expect a correlation between scores. 8.",
                "RELATED WORK In this section we draw more general comparisons to other work in performance prediction and spatial data analysis.",
                "There is a growing body of work which attempts to predict the performance of individual retrievals [7, 3, 11, 9, 19].",
                "We have attempted to place our work in the context of much of this work in Section 4.",
                "However, a complete comparison is beyond the scope of this paper.",
                "We note, though, that our experiments cover a larger and more diverse set of retrievals, collections, and topics than previously examined.",
                "Much previous work-particularly in the context of TRECfocuses on predicting the performance of systems.",
                "Here, each system generates k retrievals.",
                "The task is, given these retrievals, to predict the ranking of systems according to some performance measure.",
                "Several papers attempt to address this task under the constraint of few judgments [2, 4].",
                "Some work even attempts to use zero judgments by leveraging multiple retrievals for the same query [17].",
                "Our task differs because we focus on ranking retrievals independent of the generating system.",
                "The task here is not to test the hypothesis system A is superior to system B but to test the hypothesis retrieval A is superior to retrieval B. Autocorrelation manifests itself in many classification tasks.",
                "Neville and Jensen define relational autocorrelation for relational learning problems and demonstrate that many classification tasks manifest autocorrelation [13].",
                "Temporal autocorrelation of initial retrievals has also been used to predict performance [9].",
                "However, temporal autocorrelation is performed by projecting the retrieval function into the temporal embedding space.",
                "In our work, we focus on the behavior of the function over the relationships between documents. τ adjusted R2 DV KL P ρ(y, ˜y) DV KL P ρ(y, ˜y) DV KL, P DV KL, ρ(y, ˜y) Pρ(y, ˜y) β trec4 0.353 0.548 0.513 0.168 0.363 0.422 0.466 0.420 0.557 0.553 trec5 0.311 0.329 0.357 0.116 0.190 0.236 0.238 0.244 0.266 0.269 robust04 0.418 0.398 0.373 0.256 0.304 0.278 0.403 0.373 0.402 0.442 terabyte04 0.139 0.150 0.454 0.059 0.045 0.292 0.076 0.293 0.289 0.284 terabyte05 0.171 0.208 0.383 0.022 0.072 0.193 0.120 0.225 0.218 0.257 Table 1: Comparison to Robustness and Clarity measures for language model scores.",
                "Evaluation replicates experiments from [19].",
                "We present correlations between the classic Clarity measure (DV KL), the ranking robustness measure (P), and autocorrelation (ρ(y, ˜y)) each with mean average precision in terms of Kendalls τ.",
                "The adjusted coefficient of determination is presented to measure the effectiveness of combining predictors.",
                "Measures in bold represent the strongest correlation for that test/collection pair. multiple run (a) (b) (c) τ τ adjusted R2 DKL ρ(y, ˜y) Dn KL ρ(y, yµ) ρ(˜y, yµ) Dn KL ρ(y, ˜y) ρ(y, yµ) ρ(˜y, yµ) β trec3 0.201 0.461 0.461 0.439 0.456 0.444 0.395 0.394 0.386 0.498 trec4 0.252 0.396 0.455 0.482 0.489 0.379 0.263 0.429 0.482 0.483 trec5 0.016 0.277 0.433 0.459 0.393 0.280 0.157 0.375 0.323 0.386 trec6 0.230 0.227 0.352 0.428 0.418 0.203 0.089 0.323 0.325 0.325 trec7 0.083 0.326 0.341 0.430 0.483 0.264 0.182 0.363 0.442 0.400 trec8 0.235 0.396 0.454 0.508 0.567 0.402 0.272 0.490 0.580 0.523 robust03 0.302 0.354 0.377 0.385 0.447 0.269 0.206 0.274 0.392 0.303 robust04 0.183 0.308 0.301 0.384 0.453 0.200 0.182 0.301 0.393 0.335 robust05 0.224 0.249 0.371 0.377 0.404 0.341 0.108 0.313 0.328 0.336 terabyte04 0.043 0.245 0.544 0.420 0.392 0.516 0.105 0.357 0.343 0.365 terabyte05 0.068 0.306 0.480 0.434 0.390 0.491 0.168 0.384 0.309 0.403 trec4-spanish 0.307 0.388 0.488 0.398 0.395 0.423 0.299 0.282 0.299 0.388 trec5-spanish 0.220 0.458 0.446 0.484 0.475 0.411 0.398 0.428 0.437 0.529 trec5-chinese 0.092 0.199 0.367 0.379 0.384 0.379 0.199 0.273 0.276 0.310 trec6-chinese 0.144 0.276 0.265 0.353 0.376 0.115 0.128 0.188 0.223 0.199 ent05 - 0.181 0.324 0.305 0.282 0.211 0.043 0.158 0.155 0.179 Table 2: Large scale prediction experiments.",
                "We predict the ranking of large sets of retrievals for various collections and retrieval systems.",
                "Kendalls τ correlations are computed between the predicted ranking and a ranking based on the retrievals average precision.",
                "In column (a), we have predictors which do not use information from other retrievals for the same query.",
                "In columns (b) and (c) we present performance for predictors which incorporate information from multiple retrievals.",
                "The adjusted coefficient of determination is computed to determine effectiveness of combining predictors.",
                "Measures in bold represent the strongest correlation for that test/collection pair.",
                "Finally, regularization-based re-ranking processes are also closely-related to our work [8].",
                "These techniques seek to maximize the agreement between scores of related documents by solving a constrained optimization problem.",
                "The maximization of consistency is equivalent to maximizing the Moran autocorrelation.",
                "Therefore, we believe that our work provides explanation for why regularization-based re-ranking works. 9.",
                "CONCLUSION We have presented a new method for predicting the performance of a retrieval ranking without any relevance judgments.",
                "We consider two cases.",
                "First, when making predictions in the absence of retrievals from other systems, our predictors demonstrate robust, strong correlations with average precision.",
                "This performance, combined with a simple implementation, makes our predictors, in particular, very attractive.",
                "We have demonstrated this improvement for many, diverse settings.",
                "To our knowledge, this is the first large scale examination of zero-judgment, single-retrieval performance prediction.",
                "Second, when provided retrievals from other systems, our extended methods demonstrate competitive performance with state of the art baselines.",
                "Our experiments also demonstrate the limits of the usefulness of our predictors when information from multiple runs is provided.",
                "Our results suggest two conclusions.",
                "First, our results could affect retrieval algorithm design.",
                "Retrieval algorithms designed to consider spatial autocorrelation will conform to the <br>cluster hypothesis</br> and improve performance.",
                "Second, our results could affect the design of minimal test collection algorithms.",
                "Much of the recent work in ranking systems sometimes ignores correlations between document labels and scores.",
                "We believe that these two directions could be rewarding given the theoretical and experimental evidence in this paper. 10.",
                "ACKNOWLEDGMENTS This work was supported in part by the Center for Intelligent Information Retrieval and in part by the Defense Advanced Research Projects Agency (DARPA) under contract number HR0011-06-C-0023.",
                "Any opinions, findings and conclusions or recommendations expressed in this material are the authors and do not necessarily reflect those of the sponsor.",
                "We thank Yun Zhou and Desislava Petkova for providing data and Andre Gauthier for technical assistance. 11.",
                "REFERENCES [1] J. Aslam and V. Pavlu.",
                "Query hardness estimation using jensen-shannon divergence among multiple scoring functions.",
                "In ECIR 2007: Proceedings of the 29th European Conference on Information Retrieval, 2007. [2] J.",
                "A. Aslam, V. Pavlu, and E. Yilmaz.",
                "A statistical method for system evaluation using incomplete judgments.",
                "In S. Dumais, E. N. Efthimiadis, D. Hawking, and K. Jarvelin, editors, Proceedings of the 29th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 541-548.",
                "ACM Press, August 2006. [3] D. Carmel, E. Yom-Tov, A. Darlow, and D. Pelleg.",
                "What makes a query difficult?",
                "In SIGIR 06: Proceedings of the 29th annual international ACM SIGIR conference on Research and development in information retrieval, pages 390-397, New York, NY, USA, 2006.",
                "ACM Press. [4] B. Carterette, J. Allan, and R. Sitaraman.",
                "Minimal test collections for retrieval evaluation.",
                "In SIGIR 06: Proceedings of the 29th annual international ACM SIGIR conference on Research and development in information retrieval, pages 268-275, New York, NY, USA, 2006.",
                "ACM Press. [5] A. D. Cliff and J. K. Ord.",
                "Spatial Autocorrelation.",
                "Pion Ltd., 1973. [6] M. Connell, A. Feng, G. Kumaran, H. Raghavan, C. Shah, and J. Allan.",
                "Umass at tdt 2004.",
                "Technical Report CIIR Technical Report IR - 357, Department of Computer Science, University of Massachusetts, 2004. [7] S. Cronen-Townsend, Y. Zhou, and W. B. Croft.",
                "Precision prediction based on ranked list coherence.",
                "Inf.",
                "Retr., 9(6):723-755, 2006. [8] F. Diaz.",
                "Regularizing ad-hoc retrieval scores.",
                "In CIKM 05: Proceedings of the 14th ACM international conference on Information and knowledge management, pages 672-679, New York, NY, USA, 2005.",
                "ACM Press. [9] F. Diaz and R. Jones.",
                "Using temporal profiles of queries for precision prediction.",
                "In SIGIR 04: Proceedings of the 27th annual international ACM SIGIR conference on Research and development in information retrieval, pages 18-24, New York, NY, USA, 2004.",
                "ACM Press. [10] D. A. Griffith.",
                "Spatial Autocorrelation and Spatial Filtering.",
                "Springer Verlag, 2003. [11] B.",
                "He and I. Ounis.",
                "Inferring Query Performance Using Pre-retrieval Predictors.",
                "In The Eleventh Symposium on String Processing and Information Retrieval (SPIRE), 2004. [12] N. Jardine and C. J. V. Rijsbergen.",
                "The use of hierarchic clustering in information retrieval.",
                "Information Storage and Retrieval, 7:217-240, 1971. [13] D. Jensen and J. Neville.",
                "Linkage and autocorrelation cause feature selection bias in relational learning.",
                "In ICML 02: Proceedings of the Nineteenth International Conference on Machine Learning, pages 259-266, San Francisco, CA, USA, 2002.",
                "Morgan Kaufmann Publishers Inc. [14] O. Kurland and L. Lee.",
                "Corpus structure, language models, and ad-hoc information retrieval.",
                "In SIGIR 04: Proceedings of the 27th annual international conference on Research and development in information retrieval, pages 194-201, New York, NY, USA, 2004.",
                "ACM Press. [15] M. Montague and J.",
                "A. Aslam.",
                "Relevance score normalization for metasearch.",
                "In CIKM 01: Proceedings of the tenth international conference on Information and knowledge management, pages 427-433, New York, NY, USA, 2001.",
                "ACM Press. [16] T. Qin, T.-Y.",
                "Liu, X.-D. Zhang, Z. Chen, and W.-Y.",
                "Ma.",
                "A study of relevance propagation for web search.",
                "In SIGIR 05: Proceedings of the 28th annual international ACM SIGIR conference on Research and development in information retrieval, pages 408-415, New York, NY, USA, 2005.",
                "ACM Press. [17] I. Soboroff, C. Nicholas, and P. Cahan.",
                "Ranking retrieval systems without relevance judgments.",
                "In SIGIR 01: Proceedings of the 24th annual international ACM SIGIR conference on Research and development in information retrieval, pages 66-73, New York, NY, USA, 2001.",
                "ACM Press. [18] V. Vinay, I. J. Cox, N. Milic-Frayling, and K. Wood.",
                "On ranking the effectiveness of searches.",
                "In SIGIR 06: Proceedings of the 29th annual international ACM SIGIR conference on Research and development in information retrieval, pages 398-404, New York, NY, USA, 2006.",
                "ACM Press. [19] Y. Zhou and W. B. Croft.",
                "Ranking robustness: a novel framework to predict query performance.",
                "In CIKM 06: Proceedings of the 15th ACM international conference on Information and knowledge management, pages 567-574, New York, NY, USA, 2006.",
                "ACM Press."
            ],
            "original_annotated_samples": [
                "The discussion up to this point is reminiscent of the <br>cluster hypothesis</br>.",
                "The <br>cluster hypothesis</br> states: closely-related documents tend to be relevant to the same request [12].",
                "If this connection is reasonable, in Section 6, we present evidence that failure to satisfy the <br>cluster hypothesis</br> correlates strongly with poor performance.",
                "Why might systems fail to conform to the <br>cluster hypothesis</br>?",
                "Retrieval algorithms designed to consider spatial autocorrelation will conform to the <br>cluster hypothesis</br> and improve performance."
            ],
            "translated_annotated_samples": [
                "La discusión hasta este punto recuerda a la <br>hipótesis del cúmulo</br>.",
                "La <br>hipótesis del clúster</br> establece que los documentos estrechamente relacionados tienden a ser relevantes para la misma solicitud [12].",
                "Si esta conexión es razonable, en la Sección 6 presentamos evidencia de que la falta de cumplimiento de la <br>hipótesis de agrupamiento</br> se correlaciona fuertemente con un bajo rendimiento.",
                "¿Por qué los sistemas podrían no cumplir con la <br>hipótesis del clúster</br>?",
                "Los algoritmos de recuperación diseñados para considerar la autocorrelación espacial se ajustarán a la <br>hipótesis de agrupamiento</br> y mejorarán el rendimiento."
            ],
            "translated_text": "Predicción del rendimiento utilizando autocorrelación espacial. Fernando Díaz. Centro de Recuperación de Información Inteligente. Departamento de Ciencias de la Computación. Universidad de Massachusetts Amherst, MA 01003. fdiaz@cs.umass.edu. RESUMEN La evaluación de sistemas de recuperación de información es una de las tareas fundamentales en la recuperación de información. Los problemas incluyen la incapacidad de etiquetar exhaustivamente todos los documentos sobre un tema, la falta de generalización a partir de un pequeño número de temas e incorporar la variabilidad de los sistemas de recuperación. Trabajos anteriores abordan la evaluación de sistemas, la clasificación de consultas por dificultad y la clasificación de recuperaciones individuales por rendimiento. Existen enfoques para el caso de pocos e incluso ningún juicio de relevancia. Nuestro enfoque está en la predicción del rendimiento sin juicios de las recuperaciones individuales. Una deficiencia común de las técnicas anteriores es la suposición de que las puntuaciones de los documentos y los juicios no están correlacionados. Si los documentos están incrustados en un espacio de alta dimensión (como a menudo lo están), podemos aplicar técnicas de análisis de datos espaciales para detectar correlaciones entre las puntuaciones de los documentos. Observamos que la baja correlación entre las puntuaciones de documentos temáticamente cercanos a menudo implica un bajo rendimiento en la recuperación. Cuando se compara con una línea base de última generación, demostramos que el análisis espacial de las puntuaciones de recuperación ofrece un rendimiento predictivo significativamente mejor. Estos nuevos predictores también pueden ser incorporados con predictores clásicos para mejorar aún más el rendimiento. También describimos el primer experimento a gran escala para evaluar la predicción de rendimiento sin juicio para un gran número de sistemas de recuperación en una variedad de colecciones en varios idiomas. Categorías y Descriptores de Asignaturas H.3.3 [Búsqueda y Recuperación de Información]: Modelos de recuperación; H.3.4 [Sistemas y Software]: Evaluación del rendimiento (eficiencia y efectividad) Términos Generales Rendimiento, Diseño, Confiabilidad, Experimentación 1. En la recuperación de información, un usuario plantea una consulta a un sistema. El sistema recupera n documentos, cada uno recibiendo una puntuación de valor real que indica el grado de relevancia predicho. Si seleccionamos aleatoriamente pares de documentos de este conjunto, esperamos que algunos pares compartan el mismo tema y otros pares no compartan el mismo tema. Toma dos documentos relacionados entre sí del conjunto y llámalos a y b. Si las puntuaciones de a y b son muy diferentes, podríamos estar preocupados por el rendimiento de nuestro sistema. Es decir, si tanto a como b están relacionados con el tema de la consulta, nos gustaría que ambos reciban una puntuación alta; si a y b no están relacionados con el tema de la consulta, nos gustaría que ambos reciban una puntuación baja. Podríamos preocuparnos más a medida que encontramos más diferencias entre las puntuaciones de documentos relacionados. Estaríamos más cómodos con una recuperación en la que las puntuaciones sean consistentes entre documentos relacionados. Nuestro artículo estudia la cuantificación de esta inconsistencia en una recuperación desde una perspectiva espacial. El análisis espacial es apropiado ya que muchos modelos de recuperación incrustan documentos en algún espacio vectorial. Si los documentos están incrustados en un espacio, la proximidad se correlaciona con las relaciones temáticas. La consistencia de la puntuación puede medirse mediante la versión espacial de la autocorrelación conocida como el coeficiente de Moran o IM [5, 10]. En este artículo, demostramos una fuerte correlación entre IM y el rendimiento de recuperación. La discusión hasta este punto recuerda a la <br>hipótesis del cúmulo</br>. La <br>hipótesis del clúster</br> establece que los documentos estrechamente relacionados tienden a ser relevantes para la misma solicitud [12]. Como veremos, una función de recuperación de medidas de autocorrelación espacial mide el grado en que los documentos relacionados reciben puntuaciones similares. Debido a esto, interpretamos la autocorrelación como la medida del grado en que una función de recuperación satisface la hipótesis de agrupamiento. Si esta conexión es razonable, en la Sección 6 presentamos evidencia de que la falta de cumplimiento de la <br>hipótesis de agrupamiento</br> se correlaciona fuertemente con un bajo rendimiento. En este trabajo, proporcionamos las siguientes contribuciones: 1. Un método general y robusto para predecir el rendimiento de recuperaciones sin juicios de relevancia (Sección 3). 2. Un tratamiento teórico de las similitudes y motivaciones detrás de varias técnicas de predicción de rendimiento de vanguardia (Sección 4). 3. Las primeras experimentaciones a gran escala de predicción de rendimiento de una sola ejecución sin juicio (Secciones 5 y 6). 2. Dada una consulta, un sistema de recuperación de información produce una clasificación de documentos en la colección codificada como un conjunto de puntuaciones asociadas con los documentos. Nos referimos al conjunto de puntuaciones para una combinación particular de consulta-sistema como una recuperación. Nos gustaría predecir el rendimiento de esta recuperación con respecto a alguna medida de evaluación (por ejemplo, precisión promedio). En este artículo, presentamos resultados para clasificar recuperaciones de sistemas arbitrarios. Nos gustaría que este ranking se aproximara al ranking de recuperaciones según la medida de evaluación. Esto es diferente de clasificar las consultas por el rendimiento promedio en cada consulta. También es diferente de los sistemas de clasificación por el rendimiento promedio en un conjunto de consultas. Las puntuaciones a menudo solo se calculan para los primeros n documentos de la colección. Colocamos estos puntajes en el vector de longitud n, y, donde yi se refiere al puntaje del documento clasificado en la posición i. Ajustamos las puntuaciones para que tengan una media de cero y una varianza unitaria. Utilizamos este método debido a su simplicidad y su éxito en trabajos anteriores [15]. CORRELACIÓN ESPACIAL En la recuperación de información, a menudo asumimos que las representaciones de los documentos existen en algún espacio vectorial de alta dimensión. Por ejemplo, dado un vocabulario, V, este espacio vectorial puede ser un espacio arbitrario de dimensión |V| con producto interno de coseno o un simplejo multinomial con una medida de distancia basada en distribución. Un espacio de incrustación suele ser seleccionado para respetar la proximidad temática; si dos documentos están cerca, es más probable que compartan un tema. Debido a la prevalencia y éxito de los modelos espaciales de recuperación de información, creemos que la aplicación de técnicas de análisis de datos espaciales es apropiada. Mientras que en la recuperación de información nos preocupa la puntuación en un punto en el espacio, en el análisis de datos espaciales nos preocupa el valor de una función en un punto o ubicación en el espacio. Utilizamos el término función aquí para referirnos a una asignación de una ubicación a un valor real. Por ejemplo, podríamos estar interesados en la prevalencia de una enfermedad en el vecindario de alguna ciudad. La función asignaría la ubicación de un vecindario a una tasa de infección. Si queremos cuantificar las dependencias espaciales de una función, emplearíamos una medida conocida como la autocorrelación espacial [5, 10]. Una alta autocorrelación espacial sugiere que conocer el valor de una función en la ubicación a nos dirá mucho sobre el valor en una ubicación vecina b. Existe una alta autocorrelación espacial para una función que representa la temperatura de una ubicación, ya que saber la temperatura en una ubicación a nos dirá mucho sobre la temperatura en una ubicación vecina b. La baja autocorrelación espacial sugiere que conocer el valor de una función en la ubicación a nos dice poco sobre el valor en una ubicación vecina b. Hay una baja autocorrelación espacial en una función que mide el resultado de lanzar una moneda en a y b. En esta sección, comenzaremos describiendo lo que entendemos por proximidad espacial para documentos y luego definiremos una medida de autocorrelación espacial. Concluimos extendiendo este modelo para incluir información de múltiples recuperaciones de múltiples sistemas para una sola consulta. 3.1 Representación Espacial de Documentos Nuestro trabajo no se centra en mejorar una medida de similitud específica o definir un espacio vectorial novedoso. En cambio, elegimos un producto interno conocido por ser efectivo en la detección de relaciones temáticas entre documentos. Específicamente, adoptamos vectores de documentos tf.idf, ˜di = di log „ (n + 0.5) − ci 0.5 + ci « (1) donde d es un vector de frecuencias de términos, c es el vector de frecuencia de documentos de longitud |V|. Utilizamos este esquema de ponderación debido a su éxito en la detección de enlaces temáticos en el contexto de las evaluaciones de Detección y Seguimiento de Temas (TDT) [6]. Suponiendo que los vectores están escalados por su norma L2, usamos el producto interno, ˜di, ˜dj, para definir la similitud. Dado un conjunto de documentos y alguna medida de similitud, podemos construir una matriz que codifica la similitud entre pares de documentos. Recuerde que se nos dan los primeros n documentos recuperados en y. Podemos calcular una matriz de similitud n × n, W. Un elemento de esta matriz, Wij, representa la similitud entre los documentos clasificados i y j. En la práctica, solo incluimos las afinidades para los k vecinos más cercanos de un documento. En todos nuestros experimentos, hemos fijado k en 5. Dejamos la exploración de la sensibilidad de los parámetros para trabajos futuros. También normalizamos por filas la matriz para que Pn j=1 Wij = 1 para todos los i. 3.2 Autocorrelación Espacial de una Recuperación Recuerde que estamos interesados en medir la similitud entre las puntuaciones de documentos cercanos espacialmente. Una medida adecuada es el coeficiente de Moran de autocorrelación espacial. Suponiendo la función y sobre n ubicaciones, esto se define como ˜IM = n eTWe P i,j Wijyiyj P i y2 i = n eTWe yT Wy yTy (2) donde eT We = P ij Wij. Nos gustaría comparar los valores de autocorrelación para diferentes recuperaciones. Desafortunadamente, el límite para la Ecuación 2 no es consistente para diferentes valores de W y y. Por lo tanto, utilizamos la desigualdad de Cauchy-Schwartz para establecer un límite, ˜IM ≤ n eTWe s yTWTWy yTy Y definimos la autocorrelación espacial normalizada como IM = yT Wy p yTy × yTWTWy. Nótese que si dejamos ˜y = Wy, entonces podemos escribir esta fórmula como, IM = yT ˜y y 2 ˜y 2 (3) lo cual puede interpretarse como la correlación entre las puntuaciones originales de recuperación y un conjunto de puntuaciones de recuperación difundidas en el espacio. Presentamos algunos ejemplos de autocorrelaciones de funciones en una cuadrícula en la Figura 1. 3.3 Correlación con Otros Recuperos A veces estamos interesados en el rendimiento de un solo recuperación pero tenemos acceso a puntajes de múltiples sistemas para (a) IM = 0.006 (b) IM = 0.241 (c) IM = 0.487 Figura 1: El coeficiente de Moran, IM para varias funciones binarias en una cuadrícula. El coeficiente de Moran es una medida local de consistencia de la función. Desde la perspectiva de la recuperación de información, cada uno de estos espacios de la cuadrícula representaría un documento y los documentos estarían organizados de manera que se encuentren junto a documentos relacionados temáticamente. Las puntuaciones de recuperación binaria definirían un patrón en esta cuadrícula. Ten en cuenta que, a medida que el coeficiente de Moran aumenta, las celdas vecinas tienden a tener valores similares. En esta situación, podemos utilizar la información combinada de estas puntuaciones para construir un sustituto de una clasificación de alta calidad [17]. Podemos tratar la correlación entre la recuperación que nos interesa y las puntuaciones combinadas como un predictor del rendimiento. Supongamos que se nos dan m funciones de puntuación, yi, para los mismos n documentos. Representaremos la media de estos vectores como yµ = Σm i=1 yi. Utilizamos el vector medio como una aproximación a la relevancia. Dado que utilizamos normalización de media cero y varianza unitaria, el trabajo en metabusqueda sugiere que esta suposición está justificada [15]. Dado que yµ representa una recuperación muy buena, hipotetizamos que una similitud fuerte entre yµ e y correlacionará positivamente con el rendimiento del sistema. Utilizamos la correlación de Pearson para medir la similitud entre estos vectores, ρ(y, yµ) = yT yµ y 2 yµ 2 (4). Comentaremos sobre la similitud entre la Ecuación 3 y 4 en la Sección 7. Por supuesto, podemos combinar ρ(y, ˜y) y ρ(y, yµ) si asumimos que capturan diferentes factores en la predicción. Una forma de lograr esto es combinar estos predictores como variables independientes en una regresión lineal. Se sugiere un medio alternativo de combinación basado en la forma matemática de nuestros predictores. Dado que ˜y codifica las dependencias espaciales en y y yµ codifica las propiedades espaciales de las múltiples ejecuciones, podemos calcular una tercera correlación entre estos dos vectores, ρ(˜y, yµ) = ˜yT yµ ˜y 2 yµ 2 (5). Podemos interpretar la Ecuación 5 como la medición de la correlación entre un ranking de alta calidad (yµ) y una versión suavizada espacialmente de la recuperación (˜y). 4. RELACIÓN CON OTROS PREDICTORES Una forma de predecir la efectividad de una recuperación es observar el vocabulario compartido de los n documentos principales recuperados. Si calculáramos las palabras de contenido más frecuentes en este conjunto, esperaríamos que fueran coherentes con nuestro tema. De hecho, podríamos creer que una mala recuperación incluiría documentos sobre muchos temas dispares, lo que resultaría en una superposición de ruido terminológico. La claridad de una consulta intenta cuantificar exactamente esto [7]. Específicamente, la Claridad mide la similitud de las palabras más frecuentemente utilizadas en los documentos recuperados con aquellas más frecuentemente utilizadas en todo el corpus. La conjetura es que una buena recuperación utilizará un lenguaje distinto al del texto general; el lenguaje superpuesto en una mala recuperación tenderá a ser más similar al texto general. Matemáticamente, podemos calcular una representación del lenguaje utilizado en la recuperación inicial como una combinación ponderada de modelos de lenguaje de documentos, P(w|θQ) = Σ i=1 P(w|θi) P(Q|θi) Z (6) donde θi es el modelo de lenguaje del documento clasificado en la posición i, P(Q|θi) es la puntuación de probabilidad de la consulta del documento clasificado en la posición i y Z = Σ i=1 P(Q|θi) es una constante de normalización. La similitud entre el multinomial P(w|θQ) y un modelo de texto general se puede calcular utilizando la divergencia de Kullback-Leibler, DV KL(θQ θC). Aquí, la distribución P(w|θC) es nuestro modelo de texto general que puede ser calculado utilizando las frecuencias de términos en el corpus. En la Figura 2a, presentamos la Claridad como la medida de la distancia entre el centro de masa ponderado de la recuperación (etiquetado como y) y el centro de masa no ponderado de la colección (etiquetado como O). La claridad alcanza un mínimo cuando una recuperación asigna a cada documento la misma puntuación. Volvamos a asumir que tenemos un conjunto de n documentos recuperados para nuestra consulta. Otra forma de cuantificar la dispersión de un conjunto de documentos es observar qué tan agrupados están. Podemos hipotetizar que una buena recuperación devolverá un único y compacto grupo. Una recuperación de bajo rendimiento devolverá un conjunto de documentos poco relacionados que abarcan muchos temas. Un método propuesto para cuantificar esta dispersión es medir la distancia desde un documento aleatorio a su vecino más cercano, b. Una recuperación que esté estrechamente agrupada, en promedio, tendrá una distancia baja entre a y b; una recuperación que esté menos cerrada tendrá, en promedio, distancias altas entre a y b. Este promedio corresponde al uso de la estadística de Cox-Lewis para medir la aleatoriedad de los primeros n documentos recuperados de un sistema [18]. En la Figura 2a, esto es aproximadamente equivalente a medir el área del conjunto n. Observa que estamos descartando información sobre la función de recuperación y. Por lo tanto, la estadística de Cox-Lewis depende en gran medida de la selección de los primeros n documentos. Recuerda que tenemos n documentos y un conjunto de puntuaciones. Supongamos que tenemos acceso al sistema que proporcionó las puntuaciones originales y que también podemos solicitar puntuaciones para nuevos documentos. Esto sugiere un tercer método para predecir el rendimiento. Toma algún documento, a, del conjunto recuperado y agrega o elimina palabras al azar de forma arbitraria para crear un nuevo documento ˜a. Ahora, podemos pedirle a nuestro sistema que puntúe ˜a con respecto a nuestra consulta. Si, en promedio, a lo largo de los n documentos, las puntuaciones de a y ˜a tienden a ser muy diferentes, podríamos sospechar que el sistema está fallando en esta consulta. Los autores han sugerido acoplar la consulta con la medida de distancia [18]. La información introducida por la consulta, sin embargo, es independiente de la recuperación, de modo que, si dos recuperaciones devuelven el mismo conjunto de documentos, la estadística aproximada de Cox-Lewis será la misma independientemente de las puntuaciones de recuperación. yOy (a) Divergencia Global µ(y)˜y y (b) Perturbación de Puntuación µ(y) y (c) Promedio de Múltiples Ejecuciones Figura 2: Representación de varios predictores de rendimiento en una cuadrícula. En la Figura 2a, representamos los predictores que miden la divergencia entre el centro de masa de una recuperación y el centro del espacio de incrustación. En la Figura 2b, representamos los predictores que comparan la recuperación original, y, con una versión perturbada de la recuperación, ˜y. Nuestro enfoque utiliza un tipo particular de perturbación basado en la difusión de puntajes. Finalmente, en la Figura 2c, representamos la predicción cuando se proporcionan recuperaciones de varios otros sistemas en la misma consulta. Aquí, podemos considerar la fusión de estas recuperaciones como un sustituto de la relevancia. Esto se puede lograr ya sea perturbando los documentos o las consultas. La similitud entre los dos recuperos se puede medir utilizando alguna medida de correlación. Esto se muestra en la Figura 2b. La cuadrícula superior representa la recuperación original, y, mientras que la cuadrícula inferior representa la función después de haber sido perturbada, ˜y. La naturaleza del proceso de perturbación requiere puntuaciones o recuperaciones adicionales. Nuestro predictor no requiere acceso a la función de puntuación original ni a recuperaciones adicionales. Por lo tanto, aunque nuestro método es similar a otros métodos de perturbación en espíritu, se puede aplicar en situaciones en las que el sistema de recuperación es inaccesible o costoso de acceder. Finalmente, supongamos que tenemos, además de la recuperación que queremos evaluar, m recuperaciones de una variedad de sistemas diferentes. En este caso, podríamos tomar un documento a, comparar su rango en la recuperación con su rango promedio en los m recuperos. Si creemos que las m recuperaciones proporcionan una aproximación satisfactoria a la relevancia, entonces una diferencia muy grande en el rango sugeriría que nuestra recuperación está clasificando incorrectamente a. Si esta diferencia es grande en promedio en todos los n documentos, entonces podríamos predecir que la recuperación es mala. Si, por otro lado, la recuperación es muy consistente con las m recuperaciones, entonces podríamos predecir que la recuperación es buena. La similitud entre la recuperación y la recuperación combinada puede calcularse utilizando alguna medida de correlación. Esto se muestra en la Figura 2c. En trabajos anteriores, la divergencia de Kullback-Leibler entre las puntuaciones normalizadas de la recuperación y las puntuaciones normalizadas de la recuperación combinada proporciona la similitud [1]. 5. Nuestros experimentos se centran en probar el poder predictivo de cada uno de nuestros predictores: ρ(y, ˜y), ρ(y, yµ) y ρ(˜y, yµ). Como se indica en la Sección 2, estamos interesados en predecir el rendimiento de la recuperación generada por un sistema arbitrario. Nuestra metodología es consistente con investigaciones previas en el sentido de que predecimos el rendimiento relativo de una recuperación al comparar una clasificación basada en nuestro predictor con una clasificación basada en la precisión promedio. Presentamos los resultados de dos conjuntos de experimentos. El primer conjunto de experimentos presenta comparaciones detalladas de nuestros predictores con predictores previamente propuestos utilizando conjuntos de datos idénticos. Nuestro segundo conjunto de experimentos demuestra la generalizabilidad de nuestro enfoque a métodos de recuperación arbitrarios, tipos de corpus y lenguajes de corpus. 5.1 Experimentos Detallados En estos experimentos, predeciremos el rendimiento de los puntajes de modelado de lenguaje utilizando nuestro predictor de autocorrelación, ρ(y, ˜y); no consideramos ρ(y, yµ) o ρ(˜y, yµ) porque, en estos experimentos detallados, nos enfocamos en clasificar las recuperaciones de un solo sistema. Utilizamos recuperaciones, valores de predictores de referencia y medidas de evaluación reportadas en trabajos anteriores [19]. 5.1.1 Temas y Colecciones Estos experimentos de predicción de rendimiento utilizan recuperaciones de modelos de lenguaje realizadas para consultas asociadas con colecciones en las corpora de TREC. El uso de las colecciones TREC nos permite asociar con confianza una precisión promedio con una recuperación. En estos experimentos, utilizamos las siguientes colecciones de temas: TREC 4 ad-hoc, TREC 5 ad-hoc, Robust 2004, Terabyte 2004 y Terabyte 2005. 5.1.2 Baselines Proporcionamos dos líneas base. Nuestro primer punto de referencia es el predictor clásico de Claridad presentado en la Ecuación 6. La claridad está diseñada para ser utilizada con sistemas de modelado de lenguaje. Nuestro segundo punto de referencia es el predictor de robustez de clasificación de Zhou y Crofts. Este predictor corrompe los k documentos principales de la recuperación y vuelve a calcular las puntuaciones del modelo de lenguaje para estos documentos corruptos. El valor del predictor es la correlación de rangos de Spearman entre la clasificación original y la clasificación corrupta. En nuestras tablas, etiquetaremos los resultados para Claridad utilizando DV KL y el predictor de robustez de clasificación utilizando P. 5.2 Experimentos de Generalizabilidad Nuestros predictores no requieren un sistema de recuperación base particular; los predictores pueden calcularse para una recuperación arbitraria, independientemente de cómo se generaron los puntajes. Creemos que ese es uno de los aspectos más atractivos de nuestro algoritmo. Por lo tanto, en un segundo conjunto de experimentos, demostramos la capacidad de nuestras técnicas para generalizar a una variedad de colecciones, temas y sistemas de recuperación. 5.2.1 Temas y Colecciones Recopilamos un conjunto diverso de colecciones de todos los corpus posibles de TREC. Lanzamos una red amplia para localizar colecciones donde nuestros predictores podrían fallar. Nuestra hipótesis es que los documentos con alta similitud temática deberían tener puntuaciones correlacionadas. Por lo tanto, evitamos las colecciones donde las puntuaciones eran poco probables de estar correlacionadas (por ejemplo, preguntas y respuestas) o donde probablemente estuvieran negativamente correlacionadas (por ejemplo, novedad). Sin embargo, nuestras colecciones incluyen corpus donde las correlaciones están débilmente justificadas (por ejemplo, corpus no en inglés) o no justificadas en absoluto (por ejemplo, búsqueda de expertos). Utilizamos las pistas ad-hoc de TREC3-8, TREC Robust 2003-2005, TREC Terabyte 2004-2005, TREC4-5 en español, TREC5-6 en chino y TREC Enterprise Expert Search 2005. En todos los casos, solo utilizamos las ejecuciones automáticas para las pistas ad-hoc enviadas a NIST. Para todos los corpus en inglés y español, construimos la matriz W de acuerdo con el proceso descrito en la Sección 3.1. Para los corpus chinos, utilizamos vectores tf.idf basados en caracteres ingenuos. Para las entidades, las entradas en W son proporcionales al número de documentos en los que dos entidades coocurren. 5.2.2 Baselines En nuestros experimentos detallados, utilizamos la medida de Claridad como referencia. Dado que estamos prediciendo el rendimiento de recuperaciones que no se basan en modelado de lenguaje, utilizamos una versión de Claridad conocida como Claridad de lista clasificada [7]. La claridad de la lista clasificada convierte las clasificaciones de documentos en valores P(Q|θi). Esta conversión comienza reemplazando todas las puntuaciones en y con los rangos respectivos. Nuestra estimación de P(Q|θi) a partir de los rangos, entonces es, P(Q|θi) = ( 2(c+1−yi) c(c+1) si yi ≤ c 0 en otro caso donde c es un parámetro de corte. Como sugieren los autores, fijamos los parámetros del algoritmo c y λ2 de manera que c = 60 y λ2 = 0.10. Utilizamos la Ecuación 6 para estimar P(w|θQ) y DV KL(θQ θC) para calcular el valor del predictor. Nos referiremos a este predictor como DV KL, con superíndice V para indicar que la divergencia de Kullback-Leibler es con respecto al espacio de incrustación de términos. Cuando la información de múltiples ejecuciones de la misma consulta está disponible, utilizamos la divergencia multinomial en el espacio de documentos de Aslam y Pavlus como referencia [1]. Este método basado en rangos primero normaliza las puntuaciones en una recuperación como un multinomial n-dimensional. Al igual que con la Claridad de la lista clasificada, comenzamos reemplazando todas las puntuaciones en y con sus respectivas posiciones. Luego, ajustamos los elementos de y de la siguiente manera, ˆyi = 1 2n 0 @1 + nX k=yi 1 k 1 A (8) En nuestros experimentos de múltiples ejecuciones, solo utilizamos los 75 documentos principales de cada recuperación (n = 75); esto está dentro del rango de valores de parámetros sugeridos por los autores. Sin embargo, admitimos no haber ajustado este parámetro ni para nuestro sistema ni para la línea base. El predictor es la divergencia entre la distribución candidata, y, y la distribución media, yµ. Con la combinación lineal uniforme de estos m recuperaciones representadas como yµ, podemos calcular la divergencia como Dn KL(ˆy ˆyµ) donde usamos el superíndice n para indicar que la suma es sobre el conjunto de n documentos. Este punto de referencia fue desarrollado en el contexto de predecir la dificultad de la consulta, pero lo adoptamos como un punto de referencia razonable para predecir el rendimiento de la recuperación. 5.2.3 Configuración de parámetros Cuando se proporcionan múltiples recuperaciones, utilizamos documentos en la unión de los mejores k = 75 documentos de cada una de las m recuperaciones para esa consulta. Si el tamaño de esta unión es ˜n, entonces yµ y cada yi tiene una longitud de ˜n. En algunos casos, un sistema no puntuó un documento en la unión. Dado que estamos haciendo una suposición gaussiana sobre nuestras puntuaciones, podemos muestrear puntuaciones para estos documentos no vistos de la cola negativa de la distribución. Específicamente, muestreamos de la parte de la distribución inferior al valor mínimo en la recuperación normalizada. Esto introduce aleatoriedad en nuestro algoritmo, pero creemos que es más apropiado que asignar un valor fijo arbitrario. Optimizamos la regresión lineal utilizando la raíz cuadrada de cada predictor. Encontramos que esto mejoró sustancialmente los ajustes para todos los predictores, incluidos los basales. Consideramos combinaciones lineales de pares de predictores (etiquetados por los componentes) y todos los predictores (etiquetados como β). 5.3 Evaluación Dado un conjunto de recuperaciones, potencialmente de una combinación de consultas y sistemas, medimos la correlación del ordenamiento de rango de este conjunto por el predictor y por la métrica de rendimiento. Para garantizar la comparabilidad con los resultados anteriores, presentamos la correlación de Kendalls τ entre la clasificación de los predictores y la clasificación basada en la precisión promedio de la recuperación. A menos que se indique explícitamente, todas las correlaciones son significativas con p < 0.05. Los predictores a veces pueden tener un mejor rendimiento cuando se combinan linealmente [9, 11]. Aunque trabajos anteriores han presentado el coeficiente de determinación (R2) para medir la calidad de la regresión, esta medida no puede ser utilizada de manera confiable al comparar pequeñas mejoras al combinar predictores. Por lo tanto, adoptamos el coeficiente de determinación ajustado que penaliza los modelos con más variables. El R2 ajustado nos permite evaluar la mejora en la predicción lograda al agregar un parámetro pero pierde la interpretación estadística del R2. Utilizaremos τ de Kendall para evaluar la magnitud de la correlación y R2 ajustado para evaluar la combinación de variables. RESULTADOS Presentamos los resultados de nuestros experimentos detallados comparando la predicción de puntuaciones de modelos de lenguaje en la Tabla 1. Aunque la medida de Claridad está teóricamente diseñada para puntuaciones de modelos de lenguaje, consistentemente tiene un rendimiento inferior a nuestro predictor independiente del sistema. La robustez del ranking se presentó como una mejora a la Claridad para colecciones web (representadas en nuestros experimentos por las colecciones terabyte04 y terabyte05), desplazando la correlación τ de 0.139 a 0.150 para terabyte04 y de 0.171 a 0.208 para terabyte05. Sin embargo, estas mejoras son leves en comparación con el rendimiento de la autocorrelación en estas colecciones. Nuestro predictor logra una correlación τ de 0.454 para terabyte04 y 0.383 para terabyte05. Aunque no siempre es la más fuerte, la autocorrelación logra correlaciones competitivas con los predictores de referencia. Al examinar el rendimiento de las combinaciones lineales de predictores, observamos que en cada caso, los factores de autocorrelación son un componente necesario de un predictor sólido. También observamos que el R2 ajustado para las líneas de base individuales siempre mejora significativamente al incorporar la autocorrelación. Presentamos nuestros resultados de generalizabilidad en la Tabla 2. Comenzamos examinando la situación en la columna (a) donde se nos presenta una sola recuperación y ninguna información de recuperaciones adicionales. Para cada colección excepto una, logramos correlaciones significativamente mejores que la claridad de la lista clasificada. Sorprendentemente, logramos correlaciones relativamente fuertes para las colecciones en español y chino a pesar de nuestro procesamiento ingenuo. No tenemos una correlación de claridad de lista clasificada para ent05 porque la modelización de entidades es en sí misma una pregunta de investigación abierta. Sin embargo, nuestra medida de autocorrelación no logra altas correlaciones, quizás porque la relevancia para la recuperación de entidades no se propaga de acuerdo con los enlaces de coocurrencia que utilizamos. Como se señaló anteriormente, el bajo rendimiento de Claridad en datos web es consistente con nuestros hallazgos en los experimentos detallados. La claridad también tiene un rendimiento notablemente inferior en varios corpus de noticias (trec5, trec7 y robust04). Por otro lado, la autocorrelación parece ser robusta a los cambios entre diferentes corpora. A continuación, pasamos a la introducción de información de múltiples recuperaciones. Comparamos las correlaciones entre aquellos predictores que no utilizan esta información en la columna (a) y aquellos que sí lo hacen en la columna (b). Para cada colección, los predictores en la columna (b) superan a los predictores en la columna (a), lo que indica que la información de ejecuciones adicionales puede ser crítica para hacer buenas predicciones. Inspeccionando los predictores en la columna (b), solo podemos sacar conclusiones débiles. Nuestros nuevos predictores tienden a tener un mejor rendimiento en corpora de noticias. Y entre nuestros nuevos predictores, el predictor híbrido ρ(˜y, yµ) tiende a tener un mejor rendimiento. Recuerde que nuestra medida ρ(˜y, yµ) incorpora tanto información espacial como de múltiples recuperaciones. Por lo tanto, creemos que la mejora en la correlación es el resultado de incorporar información del comportamiento espacial. En la columna (c), podemos investigar la utilidad de incorporar información espacial con información de múltiples recuperaciones. Observa que en los casos donde la autocorrelación, ρ(y, ˜y), por sí sola funciona bien (trec3, trec5-spanish y trec6-chinese), se mejora sustancialmente al incorporar información de múltiples recuperaciones de ρ(y, yµ) en la regresión lineal, β. En los casos en los que ρ(y, yµ) funciona bien, la incorporación de la autocorrelación rara vez resulta en una mejora significativa en el rendimiento. De hecho, en cada caso en el que nuestro predictor supera al valor de referencia, incluye información de múltiples ejecuciones. 7. DISCUSIÓN El resultado más importante de nuestros experimentos implica la predicción cuando no hay información disponible de múltiples ejecuciones (Tablas 1 y 2a). Esta situación surge a menudo en el diseño de sistemas. Por ejemplo, un sistema puede necesitar, en el momento de la recuperación, evaluar su rendimiento antes de decidir llevar a cabo un procesamiento más intensivo como la retroalimentación de pseudo relevancia o la interacción. Suponiendo que la presencia de múltiples recuperaciones es irrealista en este caso. Creemos que la autocorrelación, al igual que los algoritmos de recuperación múltiple, aproxima un buen ranking; en este caso mediante la difusión de puntajes. ¿Por qué es ˜y un sustituto razonable? Sabemos que la difusión de puntuaciones en el grafo web y en los grafos de modelos de lenguaje mejora el rendimiento [14, 16]. Por lo tanto, si la difusión de puntuaciones tiende, en general, a mejorar el rendimiento, entonces las puntuaciones difusas proporcionarán, en general, un buen sustituto de la relevancia. Nuestros resultados demuestran que esta aproximación no es tan potente como la información de múltiples recuperaciones. Sin embargo, en situaciones donde esta información falta, la autocorrelación proporciona información sustancial. El éxito de la autocorrelación como predictor también puede tener sus raíces en la hipótesis de agrupamiento. Recuerde que consideramos la autocorrelación como el grado en que una recuperación satisface la hipótesis de agrupamiento. Nuestros experimentos, entonces, demuestran que una falta de respeto a la hipótesis de agrupamiento se correlaciona con un bajo rendimiento. ¿Por qué los sistemas podrían no cumplir con la <br>hipótesis del clúster</br>? Los sistemas de recuperación de información basados en consultas a menudo puntúan los documentos de forma independiente. El puntaje del documento a puede ser calculado examinando las coincidencias de términos o frases de la consulta, la longitud del documento y quizás las estadísticas globales de la colección. Una vez calculado, un sistema rara vez compara la puntuación de un documento a con la puntuación de un documento relacionado temáticamente b. Con algunas excepciones, la correlación de las puntuaciones de los documentos ha sido ampliamente ignorada. Debemos dejar claro que hemos seleccionado tareas donde la autocorrelación temática es apropiada. Ciertamente hay casos en los que no hay motivo para creer que las puntuaciones de recuperación tendrán autocorrelación temática. Por ejemplo, las listas clasificadas que incorporan novedad de documentos no deben mostrar autocorrelación espacial; si acaso, la autocorrelación debería ser negativa para esta tarea. Del mismo modo, los candidatos de respuestas en una tarea de pregunta-respuesta pueden o no mostrar autocorrelación; en este caso, la semántica de los enlaces también es cuestionable. Es importante antes de aplicar esta medida confirmar que, dada la semántica para algún enlace entre dos elementos recuperados, deberíamos esperar una correlación entre las puntuaciones. 8. TRABAJO RELACIONADO En esta sección realizamos comparaciones más generales con otros trabajos en predicción de rendimiento y análisis de datos espaciales. Existe un creciente cuerpo de trabajo que intenta predecir el rendimiento de recuperaciones individuales [7, 3, 11, 9, 19]. Hemos intentado situar nuestro trabajo en el contexto de gran parte de este trabajo en la Sección 4. Sin embargo, una comparación completa está fuera del alcance de este documento. Sin embargo, cabe destacar que nuestros experimentos abarcan un conjunto más amplio y diverso de recuperaciones, colecciones y temas que los examinados previamente. Gran parte del trabajo previo, especialmente en el contexto de TREC, se centra en predecir el rendimiento de los sistemas. Aquí, cada sistema genera k recuperaciones. La tarea consiste en, dadas estas recuperaciones, predecir la clasificación de los sistemas según alguna medida de rendimiento. Varios artículos intentan abordar esta tarea bajo la restricción de pocas evaluaciones [2, 4]. Algunos trabajos incluso intentan utilizar cero juicios aprovechando múltiples recuperaciones para la misma consulta [17]. Nuestra tarea difiere porque nos enfocamos en clasificar recuperaciones independientemente del sistema generador. La tarea aquí no es probar que el sistema A es superior al sistema B, sino probar que la recuperación A es superior a la recuperación B. La autocorrelación se manifiesta en muchas tareas de clasificación. Neville y Jensen definen la autocorrelación relacional para problemas de aprendizaje relacional y demuestran que muchas tareas de clasificación manifiestan autocorrelación [13]. La autocorrelación temporal de las recuperaciones iniciales también se ha utilizado para predecir el rendimiento [9]. Sin embargo, la autocorrelación temporal se realiza proyectando la función de recuperación en el espacio de incrustación temporal. En nuestro trabajo, nos enfocamos en el comportamiento de la función sobre las relaciones entre documentos. τ ajustado R2 DV KL P ρ(y, ˜y) DV KL P ρ(y, ˜y) DV KL, P DV KL, ρ(y, ˜y) Pρ(y, ˜y) β trec4 0.353 0.548 0.513 0.168 0.363 0.422 0.466 0.420 0.557 0.553 trec5 0.311 0.329 0.357 0.116 0.190 0.236 0.238 0.244 0.266 0.269 robust04 0.418 0.398 0.373 0.256 0.304 0.278 0.403 0.373 0.402 0.442 terabyte04 0.139 0.150 0.454 0.059 0.045 0.292 0.076 0.293 0.289 0.284 terabyte05 0.171 0.208 0.383 0.022 0.072 0.193 0.120 0.225 0.218 0.257 Tabla 1: Comparación de medidas de robustez y claridad para puntuaciones de modelos de lenguaje. La evaluación replica experimentos de [19]. Presentamos las correlaciones entre la medida clásica de Claridad (DV KL), la medida de robustez de clasificación (P) y la autocorrelación (ρ(y, ˜y)) cada una con la precisión media promedio en términos de τ de Kendall. El coeficiente de determinación ajustado se presenta para medir la efectividad de combinar predictores. Las medidas en negrita representan la correlación más fuerte para ese par de prueba/colección. múltiples ejecuciones (a) (b) (c) τ τ ajustado R2 DKL ρ(y, ˜y) Dn KL ρ(y, yµ) ρ(˜y, yµ) Dn KL ρ(y, ˜y) ρ(y, yµ) ρ(˜y, yµ) β trec3 0.201 0.461 0.461 0.439 0.456 0.444 0.395 0.394 0.386 0.498 trec4 0.252 0.396 0.455 0.482 0.489 0.379 0.263 0.429 0.482 0.483 trec5 0.016 0.277 0.433 0.459 0.393 0.280 0.157 0.375 0.323 0.386 trec6 0.230 0.227 0.352 0.428 0.418 0.203 0.089 0.323 0.325 0.325 trec7 0.083 0.326 0.341 0.430 0.483 0.264 0.182 0.363 0.442 0.400 trec8 0.235 0.396 0.454 0.508 0.567 0.402 0.272 0.490 0.580 0.523 robust03 0.302 0.354 0.377 0.385 0.447 0.269 0.206 0.274 0.392 0.303 robust04 0.183 0.308 0.301 0.384 0.453 0.200 0.182 0.301 0.393 0.335 robust05 0.224 0.249 0.371 0.377 0.404 0.341 0.108 0.313 0.328 0.336 terabyte04 0.043 0.245 0.544 0.420 0.392 0.516 0.105 0.357 0.343 0.365 terabyte05 0.068 0.306 0.480 0.434 0.390 0.491 0.168 0.384 0.309 0.403 trec4-spanish 0.307 0.388 0.488 0.398 0.395 0.423 0.299 0.282 0.299 0.388 trec5-spanish 0.220 0.458 0.446 0.484 0.475 0.411 0.398 0.428 0.437 0.529 trec5-chinese 0.092 0.199 0.367 0.379 0.384 0.379 0.199 0.273 0.276 0.310 trec6-chinese 0.144 0.276 0.265 0.353 0.376 0.115 0.128 0.188 0.223 0.199 ent05 - 0.181 0.324 0.305 0.282 0.211 0.043 0.158 0.155 0.179 Tabla 2: Experimentos de predicción a gran escala. Predecimos la clasificación de grandes conjuntos de recuperaciones para varias colecciones y sistemas de recuperación. Las correlaciones de τ de Kendall se calculan entre la clasificación predicha y una clasificación basada en la precisión promedio de las recuperaciones. En la columna (a), tenemos predictores que no utilizan información de otras recuperaciones para la misma consulta. En las columnas (b) y (c) presentamos el rendimiento de los predictores que incorporan información de múltiples recuperaciones. El coeficiente de determinación ajustado se calcula para determinar la efectividad de combinar predictores. Las medidas en negrita representan la correlación más fuerte para ese par de prueba/colección. Finalmente, los procesos de reordenamiento basados en regularización también están estrechamente relacionados con nuestro trabajo [8]. Estas técnicas buscan maximizar el acuerdo entre las puntuaciones de documentos relacionados al resolver un problema de optimización restringida. La maximización de la consistencia es equivalente a maximizar la autocorrelación de Moran. Por lo tanto, creemos que nuestro trabajo proporciona una explicación de por qué funciona el reordenamiento basado en regularización. 9. CONCLUSIÓN Hemos presentado un nuevo método para predecir el rendimiento de un ranking de recuperación sin necesidad de juicios de relevancia. Consideramos dos casos. Primero, al hacer predicciones en ausencia de recuperaciones de otros sistemas, nuestros predictores muestran correlaciones sólidas y robustas con la precisión promedio. Esta actuación, combinada con una implementación sencilla, hace que nuestros predictores, en particular, sean muy atractivos. Hemos demostrado esta mejora en muchos entornos diversos. Según nuestro conocimiento, esta es la primera evaluación a gran escala de la predicción del rendimiento de una sola recuperación sin juicio. Segundo, cuando se proporcionan recuperaciones de otros sistemas, nuestros métodos ampliados demuestran un rendimiento competitivo con las líneas de base de vanguardia. Nuestros experimentos también demuestran los límites de la utilidad de nuestros predictores cuando se proporciona información de múltiples ejecuciones. Nuestros resultados sugieren dos conclusiones. Primero, nuestros resultados podrían afectar el diseño de algoritmos de recuperación. Los algoritmos de recuperación diseñados para considerar la autocorrelación espacial se ajustarán a la <br>hipótesis de agrupamiento</br> y mejorarán el rendimiento. ",
            "candidates": [],
            "error": [
                [
                    "hipótesis del cúmulo",
                    "hipótesis del clúster",
                    "hipótesis de agrupamiento",
                    "hipótesis del clúster",
                    "hipótesis de agrupamiento"
                ]
            ]
        },
        "zero relevance judgment": {
            "translated_key": "juicios de relevancia",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Performance Prediction Using Spatial Autocorrelation Fernando Diaz Center for Intelligent Information Retrieval Department of Computer Science University of Massachusetts Amherst, MA 01003 fdiaz@cs.umass.edu ABSTRACT Evaluation of information retrieval systems is one of the core tasks in information retrieval.",
                "Problems include the inability to exhaustively label all documents for a topic, nongeneralizability from a small number of topics, and incorporating the variability of retrieval systems.",
                "Previous work addresses the evaluation of systems, the ranking of queries by difficulty, and the ranking of individual retrievals by performance.",
                "Approaches exist for the case of few and even no relevance judgments.",
                "Our focus is on zero-judgment performance prediction of individual retrievals.",
                "One common shortcoming of previous techniques is the assumption of uncorrelated document scores and judgments.",
                "If documents are embedded in a high-dimensional space (as they often are), we can apply techniques from spatial data analysis to detect correlations between document scores.",
                "We find that the low correlation between scores of topically close documents often implies a poor retrieval performance.",
                "When compared to a state of the art baseline, we demonstrate that the spatial analysis of retrieval scores provides significantly better prediction performance.",
                "These new predictors can also be incorporated with classic predictors to improve performance further.",
                "We also describe the first large-scale experiment to evaluate zero-judgment performance prediction for a massive number of retrieval systems over a variety of collections in several languages.",
                "Categories and Subject Descriptors H.3.3 [Information Search and Retrieval]: Retrieval models; H.3.4 [Systems and Software]: Performance evaluation (efficiency and effectiveness) General Terms Performance, Design, Reliability, Experimentation 1.",
                "INTRODUCTION In information retrieval, a user poses a query to a system.",
                "The system retrieves n documents each receiving a realvalued score indicating the predicted degree of relevance.",
                "If we randomly select pairs of documents from this set, we expect some pairs to share the same topic and other pairs to not share the same topic.",
                "Take two topically-related documents from the set and call them a and b.",
                "If the scores of a and b are very different, we may be concerned about the performance of our system.",
                "That is, if a and b are both on the topic of the query, we would like them both to receive a high score; if a and b are not on the topic of the query, we would like them both to receive a low score.",
                "We might become more worried as we find more differences between scores of related documents.",
                "We would be more comfortable with a retrieval where scores are consistent between related documents.",
                "Our paper studies the quantification of this inconsistency in a retrieval from a spatial perspective.",
                "Spatial analysis is appropriate since many retrieval models embed documents in some vector space.",
                "If documents are embedded in a space, proximity correlates with topical relationships.",
                "Score consistency can be measured by the spatial version of autocorrelation known as the Moran coefficient or IM [5, 10].",
                "In this paper, we demonstrate a strong correlation between IM and retrieval performance.",
                "The discussion up to this point is reminiscent of the cluster hypothesis.",
                "The cluster hypothesis states: closely-related documents tend to be relevant to the same request [12].",
                "As we shall see, a retrieval functions spatial autocorrelation measures the degree to which closely-related documents receive similar scores.",
                "Because of this, we interpret autocorrelation as measuring the degree to which a retrieval function satisfies the clustering hypothesis.",
                "If this connection is reasonable, in Section 6, we present evidence that failure to satisfy the cluster hypothesis correlates strongly with poor performance.",
                "In this work, we provide the following contributions, 1.",
                "A general, robust method for predicting the performance of retrievals with <br>zero relevance judgment</br>s (Section 3). 2.",
                "A theoretical treatment of the similarities and motivations behind several state-of-the-art performance prediction techniques (Section 4). 3.",
                "The first large-scale experiments of zero-judgment, single run performance prediction (Sections 5 and 6). 2.",
                "PROBLEM DEFINITION Given a query, an information retrieval system produces a ranking of documents in the collection encoded as a set of scores associated with documents.",
                "We refer to the set of scores for a particular query-system combination as a retrieval.",
                "We would like to predict the performance of this retrieval with respect to some evaluation measure (eg, mean average precision).",
                "In this paper, we present results for ranking retrievals from arbitrary systems.",
                "We would like this ranking to approximate the ranking of retrievals by the evaluation measure.",
                "This is different from ranking queries by the average performance on each query.",
                "It is also different from ranking systems by the average performance on a set of queries.",
                "Scores are often only computed for the top n documents from the collection.",
                "We place these scores in the length n vector, y, where yi refers to the score of the ith-ranked document.",
                "We adjust scores to have zero mean and unit variance.",
                "We use this method because of its simplicity and its success in previous work [15]. 3.",
                "SPATIAL CORRELATION In information retrieval, we often assume that the representations of documents exist in some high-dimensional vector space.",
                "For example, given a vocabulary, V, this vector space may be an arbitrary |V|-dimensional space with cosine inner-product or a multinomial simplex with a distributionbased distance measure.",
                "An embedding space is often selected to respect topical proximity; if two documents are near, they are more likely to share a topic.",
                "Because of the prevalence and success of spatial models of information retrieval, we believe that the application of spatial data analysis techniques are appropriate.",
                "Whereas in information retrieval, we are concerned with the score at a point in a space, in spatial data analysis, we are concerned with the value of a function at a point or location in a space.",
                "We use the term function here to mean a mapping from a location to a real value.",
                "For example, we might be interested in the prevalence of a disease in the neighborhood of some city.",
                "The function would map the location of a neighborhood to an infection rate.",
                "If we want to quantify the spatial dependencies of a function, we would employ a measure referred to as the spatial autocorrelation [5, 10].",
                "High spatial autocorrelation suggests that knowing the value of a function at location a will tell us a great deal about the value at a neighboring location b.",
                "There is a high spatial autocorrelation for a function representing the temperature of a location since knowing the temperature at a location a will tell us a lot about the temperature at a neighboring location b.",
                "Low spatial autocorrelation suggests that knowing the value of a function at location a tells us little about the value at a neighboring location b.",
                "There is low spatial autocorrelation in a function measuring the outcome of a coin toss at a and b.",
                "In this section, we will begin by describing what we mean by spatial proximity for documents and then define a measure of spatial autocorrelation.",
                "We conclude by extending this model to include information from multiple retrievals from multiple systems for a single query. 3.1 Spatial Representation of Documents Our work does not focus on improving a specific similarity measure or defining a novel vector space.",
                "Instead, we choose an inner product known to be effective at detecting interdocument topical relationships.",
                "Specifically, we adopt tf.idf document vectors, ˜di = di log „ (n + 0.5) − ci 0.5 + ci « (1) where d is a vector of term frequencies, c is the length-|V| document frequency vector.",
                "We use this weighting scheme due to its success for topical link detection in the context of Topic Detection and Tracking (TDT) evaluations [6].",
                "Assuming vectors are scaled by their L2 norm, we use the inner product, ˜di, ˜dj , to define similarity.",
                "Given documents and some similarity measure, we can construct a matrix which encodes the similarity between pairs of documents.",
                "Recall that we are given the top n documents retrieved in y.",
                "We can compute an n × n similarity matrix, W. An element of this matrix, Wij represents the similarity between documents ranked i and j.",
                "In practice, we only include the affinities for a documents k-nearest neighbors.",
                "In all of our experiments, we have fixed k to 5.",
                "We leave exploration of parameter sensitivity to future work.",
                "We also row normalize the matrix so that Pn j=1 Wij = 1 for all i. 3.2 Spatial Autocorrelation of a Retrieval Recall that we are interested in measuring the similarity between the scores of spatially-close documents.",
                "One such suitable measure is the Moran coefficient of spatial autocorrelation.",
                "Assuming the function y over n locations, this is defined as ˜IM = n eTWe P i,j Wijyiyj P i y2 i = n eTWe yT Wy yTy (2) where eT We = P ij Wij.",
                "We would like to compare autocorrelation values for different retrievals.",
                "Unfortunately, the bound for Equation 2 is not consistent for different W and y.",
                "Therefore, we use the Cauchy-Schwartz inequality to establish a bound, ˜IM ≤ n eTWe s yTWTWy yTy And we define the normalized spatial autocorrelation as IM = yT Wy p yTy × yTWTWy Notice that if we let ˜y = Wy, then we can write this formula as, IM = yT ˜y y 2 ˜y 2 (3) which can be interpreted as the correlation between the original retrieval scores and a set of retrieval scores diffused in the space.",
                "We present some examples of autocorrelations of functions on a grid in Figure 1. 3.3 Correlation with Other Retrievals Sometimes we are interested in the performance of a single retrieval but have access to scores from multiple systems for (a) IM = 0.006 (b) IM = 0.241 (c) IM = 0.487 Figure 1: The Moran coefficient, IM for a several binary functions on a grid.",
                "The Moran coefficient is a local measure of function consistency.",
                "From the perspective of information retrieval, each of these grid spaces would represent a document and documents would be organized so that they lay next to topically-related documents.",
                "Binary retrieval scores would define a pattern on this grid.",
                "Notice that, as the Moran coefficient increases, neighboring cells tend to have similar values. the same query.",
                "In this situation, we can use combined information from these scores to construct a surrogate for a high-quality ranking [17].",
                "We can treat the correlation between the retrieval we are interested in and the combined scores as a predictor of performance.",
                "Assume that we are given m score functions, yi, for the same n documents.",
                "We will represent the mean of these vectors as yµ = Pm i=1 yi.",
                "We use the mean vector as an approximation to relevance.",
                "Since we use zero mean and unit variance normalization, work in metasearch suggests that this assumption is justified [15].",
                "Because yµ represents a very good retrieval, we hypothesize that a strong similarity between yµ and y will correlate positively with system performance.",
                "We use Pearsons product-moment correlation to measure the similarity between these vectors, ρ(y, yµ) = yT yµ y 2 yµ 2 (4) We will comment on the similarity between Equation 3 and 4 in Section 7.",
                "Of course, we can combine ρ(y, ˜y) and ρ(y, yµ) if we assume that they capture different factors in the prediction.",
                "One way to accomplish this is to combine these predictors as independent variables in a linear regression.",
                "An alternative means of combination is suggested by the mathematical form of our predictors.",
                "Since ˜y encodes the spatial dependencies in y and yµ encodes the spatial properties of the multiple runs, we can compute a third correlation between these two vectors, ρ(˜y, yµ) = ˜yT yµ ˜y 2 yµ 2 (5) We can interpret Equation 5 as measuring the correlation between a high quality ranking (yµ) and a spatially smoothed version of the retrieval (˜y). 4.",
                "RELATIONSHIP WITH OTHER PREDICTORS One way to predict the effectiveness of a retrieval is to look at the shared vocabulary of the top n retrieved documents.",
                "If we computed the most frequent content words in this set, we would hope that they would be consistent with our topic.",
                "In fact, we might believe that a bad retrieval would include documents on many disparate topics, resulting in an overlap of terminological noise.",
                "The Clarity of a query attempts to quantify exactly this [7].",
                "Specifically, Clarity measures the similarity of the words most frequently used in retrieved documents to those most frequently used in the whole corpus.",
                "The conjecture is that a good retrieval will use language distinct from general text; the overlapping language in a bad retrieval will tend to be more similar to general text.",
                "Mathematically, we can compute a representation of the language used in the initial retrieval as a weighted combination of document language models, P(w|θQ) = nX i=1 P(w|θi) P(Q|θi) Z (6) where θi is the language model of the ith-ranked document, P(Q|θi) is the query likelihood score of the ith-ranked document and Z = Pn i=1 P(Q|θi) is a normalization constant.",
                "The similarity between the multinomial P(w|θQ) and a model of general text can be computed using the Kullback-Leibler divergence, DV KL(θQ θC ).",
                "Here, the distribution P(w|θC ) is our model of general text which can be computed using term frequencies in the corpus.",
                "In Figure 2a, we present Clarity as measuring the distance between the weighted center of mass of the retrieval (labeled y) and the unweighted center of mass of the collection (labeled O).",
                "Clarity reaches a minimum when a retrieval assigns every document the same score.",
                "Lets again assume we have a set of n documents retrieved for our query.",
                "Another way to quantify the dispersion of a set of documents is to look at how clustered they are.",
                "We may hypothesize that a good retrieval will return a single, tight cluster.",
                "A poorly performing retrieval will return a loosely related set of documents covering many topics.",
                "One proposed method of quantifying this dispersion is to measure the distance from a random document a to its nearest neighbor, b.",
                "A retrieval which is tightly clustered will, on average, have a low distance between a and b; a retrieval which is less tightly-closed will, on average have high distances between a and b.",
                "This average corresponds to using the Cox-Lewis statistic to measure the randomness of the top n documents retrieved from a system [18].",
                "In Figure 2a, this is roughly equivalent to measuring the area of the set n. Notice that we are throwing away information about the retrieval function y.",
                "Therefore the Cox-Lewis statistic is highly dependent on selecting the top n documents.1 Remember that we have n documents and a set of scores.",
                "Lets assume that we have access to the system which provided the original scores and that we can also request scores for new documents.",
                "This suggests a third method for predicting performance.",
                "Take some document, a, from the retrieved set and arbitrarily add or remove words at random to create a new document ˜a.",
                "Now, we can ask our system to score ˜a with respect to our query.",
                "If, on average over the n documents, the scores of a and ˜a tend to be very different, we might suspect that the system is failing on this query.",
                "So, an alternative approach is to measure the simi1 The authors have suggested coupling the query with the distance measure [18].",
                "The information introduced by the query, though, is retrieval-independent so that, if two retrievals return the same set of documents, the approximate Cox-Lewis statistic will be the same regardless of the retrieval scores. yOy (a) Global Divergence µ(y)˜y y (b) Score Perturbation µ(y) y (c) Multirun Averaging Figure 2: Representation of several performance predictors on a grid.",
                "In Figure 2a, we depict predictors which measure the divergence between the center of mass of a retrieval and the center of the embedding space.",
                "In Figure 2b, we depict predictors which compare the original retrieval, y, to a perturbed version of the retrieval, ˜y.",
                "Our approach uses a particular type of perturbation based on score diffusion.",
                "Finally, in Figure 2c, we depict prediction when given retrievals from several other systems on the same query.",
                "Here, we can consider the fusion of these retrieval as a surrogate for relevance. larity between the retrieval and a perturbed version of that retrieval [18, 19].",
                "This can be accomplished by either perturbing the documents or queries.",
                "The similarity between the two retrievals can be measured using some correlation measure.",
                "This is depicted in Figure 2b.",
                "The upper grid represents the original retrieval, y, while the lower grid represents the function after having been perturbed, ˜y.",
                "The nature of the perturbation process requires additional scorings or retrievals.",
                "Our predictor does not require access to the original scoring function or additional retrievals.",
                "So, although our method is similar to other perturbation methods in spirit, it can be applied in situations when the retrieval system is inaccessible or costly to access.",
                "Finally, assume that we have, in addition to the retrieval we want to evaluate, m retrievals from a variety of different systems.",
                "In this case, we might take a document a, compare its rank in the retrieval to its average rank in the m retrievals.",
                "If we believe that the m retrievals provide a satisfactory approximation to relevance, then a very large difference in rank would suggest that our retrieval is misranking a.",
                "If this difference is large on average over all n documents, then we might predict that the retrieval is bad.",
                "If, on the other hand, the retrieval is very consistent with the m retrievals, then we might predict that the retrieval is good.",
                "The similarity between the retrieval and the combined retrieval may be computed using some correlation measure.",
                "This is depicted in Figure 2c.",
                "In previous work, the Kullback-Leibler divergence between the normalized scores of the retrieval and the normalized scores of the combined retrieval provides the similarity [1]. 5.",
                "EXPERIMENTS Our experiments focus on testing the predictive power of each of our predictors: ρ(y, ˜y), ρ(y, yµ), and ρ(˜y, yµ).",
                "As stated in Section 2, we are interested in predicting the performance of the retrieval generated by an arbitrary system.",
                "Our methodology is consistent with previous research in that we predict the relative performance of a retrieval by comparing a ranking based on our predictor to a ranking based on average precision.",
                "We present results for two sets of experiments.",
                "The first set of experiments presents detailed comparisons of our predictors to previously-proposed predictors using identical data sets.",
                "Our second set of experiments demonstrates the generalizability of our approach to arbitrary retrieval methods, corpus types, and corpus languages. 5.1 Detailed Experiments In these experiments, we will predict the performance of language modeling scores using our autocorrelation predictor, ρ(y, ˜y); we do not consider ρ(y, yµ) or ρ(˜y, yµ) because, in these detailed experiments, we focus on ranking the retrievals from a single system.",
                "We use retrievals, values for baseline predictors, and evaluation measures reported in previous work [19]. 5.1.1 Topics and Collections These performance prediction experiments use language model retrievals performed for queries associated with collections in the TREC corpora.",
                "Using TREC collections allows us to confidently associate an average precision with a retrieval.",
                "In these experiments, we use the following topic collections: TREC 4 ad-hoc, TREC 5 ad-hoc, Robust 2004, Terabyte 2004, and Terabyte 2005. 5.1.2 Baselines We provide two baselines.",
                "Our first baseline is the classic Clarity predictor presented in Equation 6.",
                "Clarity is designed to be used with language modeling systems.",
                "Our second baseline is Zhou and Crofts ranking robustness predictor.",
                "This predictor corrupts the top k documents from retrieval and re-computes the language model scores for these corrupted documents.",
                "The value of the predictor is the Spearman rank correlation between the original ranking and the corrupted ranking.",
                "In our tables, we will label results for Clarity using DV KL and the ranking robustness predictor using P. 5.2 Generalizability Experiments Our predictors do not require a particular baseline retrieval system; the predictors can be computed for an arbitrary retrieval, regardless of how scores were generated.",
                "We believe that that is one of the most attractive aspects of our algorithm.",
                "Therefore, in a second set of experiments, we demonstrate the ability of our techniques to generalize to a variety of collections, topics, and retrieval systems. 5.2.1 Topics and Collections We gathered a diverse set of collections from all possible TREC corpora.",
                "We cast a wide net in order to locate collections where our predictors might fail.",
                "Our hypothesis is that documents with high topical similarity should have correlated scores.",
                "Therefore, we avoided collections where scores were unlikely to be correlated (eg, question-answering) or were likely to be negatively correlated (eg, novelty).",
                "Nevertheless, our collections include corpora where correlations are weakly justified (eg, non-English corpora) or not justified at all (eg, expert search).",
                "We use the ad-hoc tracks from TREC3-8, TREC Robust 2003-2005, TREC Terabyte 20042005, TREC4-5 Spanish, TREC5-6 Chinese, and TREC Enterprise Expert Search 2005.",
                "In all cases, we use only the automatic runs for ad-hoc tracks submitted to NIST.",
                "For all English and Spanish corpora, we construct the matrix W according to the process described in Section 3.1.",
                "For Chinese corpora, we use na¨ıve character-based tf.idf vectors.",
                "For entities, entries in W are proportional to the number of documents in which two entities cooccur. 5.2.2 Baselines In our detailed experiments, we used the Clarity measure as a baseline.",
                "Since we are predicting the performance of retrievals which are not based on language modeling, we use a version of Clarity referred to as ranked-list Clarity [7].",
                "Ranked-list clarity converts document ranks to P(Q|θi) values.",
                "This conversion begins by replacing all of the scores in y with the respective ranks.",
                "Our estimation of P(Q|θi) from the ranks, then is, P(Q|θi) = ( 2(c+1−yi) c(c+1) if yi ≤ c 0 otherwise (7) where c is a cutoff parameter.",
                "As suggested by the authors, we fix the algorithm parameters c and λ2 so that c = 60 and λ2 = 0.10.",
                "We use Equation 6 to estimate P(w|θQ) and DV KL(θQ θC ) to compute the value of the predictor.",
                "We will refer to this predictor as DV KL, superscripted by V to indicate that the Kullback-Leibler divergence is with respect to the term embedding space.",
                "When information from multiple runs on the same query is available, we use Aslam and Pavlus document-space multinomial divergence as a baseline [1].",
                "This rank-based method first normalizes the scores in a retrieval as an n-dimensional multinomial.",
                "As with ranked-list Clarity, we begin by replacing all of the scores in y with their respective ranks.",
                "Then, we adjust the elements of y in the following way, ˆyi = 1 2n 0 @1 + nX k=yi 1 k 1 A (8) In our multirun experiments, we only use the top 75 documents from each retrieval (n = 75); this is within the range of parameter values suggested by the authors.",
                "However, we admit not tuning this parameter for either our system or the baseline.",
                "The predictor is the divergence between the candidate distribution, y, and the mean distribution, yµ .",
                "With the uniform linear combination of these m retrievals represented as yµ, we can compute the divergence as Dn KL(ˆy ˆyµ) where we use the superscript n to indicate that the summation is over the set of n documents.",
                "This baseline was developed in the context of predicting query difficulty but we adopt it as a reasonable baseline for predicting retrieval performance. 5.2.3 Parameter Settings When given multiple retrievals, we use documents in the union of the top k = 75 documents from each of the m retrievals for that query.",
                "If the size of this union is ˜n, then yµ and each yi is of length ˜n.",
                "In some cases, a system did not score a document in the union.",
                "Since we are making a Gaussian assumption about our scores, we can sample scores for these unseen documents from the negative tail of the distribution.",
                "Specifically, we sample from the part of the distribution lower than the minimum value of in the normalized retrieval.",
                "This introduces randomness into our algorithm but we believe it is more appropriate than assigning an arbitrary fixed value.",
                "We optimized the linear regression using the square root of each predictor.",
                "We found that this substantially improved fits for all predictors, including the baselines.",
                "We considered linear combinations of pairs of predictors (labeled by the components) and all predictors (labeled as β). 5.3 Evaluation Given a set of retrievals, potentially from a combination of queries and systems, we measure the correlation of the rank ordering of this set by the predictor and by the performance metric.",
                "In order to ensure comparability with previous results, we present Kendalls τ correlation between the predictors ranking and ranking based on average precision of the retrieval.",
                "Unless explicitly noted, all correlations are significant with p < 0.05.",
                "Predictors can sometimes perform better when linearly combined [9, 11].",
                "Although previous work has presented the coefficient of determination (R2 ) to measure the quality of the regression, this measure cannot be reliably used when comparing slight improvements from combining predictors.",
                "Therefore, we adopt the adjusted coefficient of determination which penalizes models with more variables.",
                "The adjusted R2 allows us to evaluate the improvement in prediction achieved by adding a parameter but loses the statistical interpretation of R2 .",
                "We will use Kendalls τ to evaluate the magnitude of the correlation and the adjusted R2 to evaluate the combination of variables. 6.",
                "RESULTS We present results for our detailed experiments comparing the prediction of language model scores in Table 1.",
                "Although the Clarity measure is theoretically designed for language model scores, it consistently underperforms our system-agnostic predictor.",
                "Ranking robustness was presented as an improvement to Clarity for web collections (represented in our experiments by the terabyte04 and terabyte05 collections), shifting the τ correlation from 0.139 to 0.150 for terabyte04 and 0.171 to 0.208 for terabyte05.",
                "However, these improvements are slight compared to the performance of autocorrelation on these collections.",
                "Our predictor achieves a τ correlation of 0.454 for terabyte04 and 0.383 for terabyte05.",
                "Though not always the strongest, autocorrelation achieves correlations competitive with baseline predictors.",
                "When examining the performance of linear combinations of predictors, we note that in every case, autocorrelation factors as a necessary component of a strong predictor.",
                "We also note that the adjusted R2 for individual baselines are always significantly improved by incorporating autocorrelation.",
                "We present our generalizability results in Table 2.",
                "We begin by examining the situation in column (a) where we are presented with a single retrieval and no information from additional retrievals.",
                "For every collection except one, we achieve significantly better correlations than ranked-list Clarity.",
                "Surprisingly, we achieve relatively strong correlations for Spanish and Chinese collections despite our na¨ıve processing.",
                "We do not have a ranked-list clarity correlation for ent05 because entity modeling is itself an open research question.",
                "However, our autocorrelation measure does not achieve high correlations perhaps because relevance for entity retrieval does not propagate according to the cooccurrence links we use.",
                "As noted above, the poor Clarity performance on web data is consistent with our findings in the detailed experiments.",
                "Clarity also notably underperforms for several news corpora (trec5, trec7, and robust04).",
                "On the other hand, autocorrelation seems robust to the changes between different corpora.",
                "Next, we turn to the introduction of information from multiple retrievals.",
                "We compare the correlations between those predictors which do not use this information in column (a) and those which do in column (b).",
                "For every collection, the predictors in column (b) outperform the predictors in column (a), indicating that the information from additional runs can be critical to making good predictions.",
                "Inspecting the predictors in column (b), we only draw weak conclusions.",
                "Our new predictors tend to perform better on news corpora.",
                "And between our new predictors, the hybrid ρ(˜y, yµ) predictor tends to perform better.",
                "Recall that our ρ(˜y, yµ) measure incorporates both spatial and multiple retrieval information.",
                "Therefore, we believe that the improvement in correlation is the result of incorporating information from spatial behavior.",
                "In column (c), we can investigate the utility of incorporating spatial information with information from multiple retrievals.",
                "Notice that in the cases where autocorrelation, ρ(y, ˜y), alone performs well (trec3, trec5-spanish, and trec6-chinese), it is substantially improved by incorporating multiple-retrieval information from ρ(y, yµ) in the linear regression, β.",
                "In the cases where ρ(y, yµ) performs well, incorporating autocorrelation rarely results in a significant improvement in performance.",
                "In fact, in every case where our predictor outperforms the baseline, it includes information from multiple runs. 7.",
                "DISCUSSION The most important result from our experiments involves prediction when no information is available from multiple runs (Tables 1 and 2a).",
                "This situation arises often in system design.",
                "For example, a system may need to, at retrieval time, assess its performance before deciding to conduct more intensive processing such as pseudo-relevance feedback or interaction.",
                "Assuming the presence of multiple retrievals is unrealistic in this case.",
                "We believe that autocorrelation is, like multiple-retrieval algorithms, approximating a good ranking; in this case by diffusing scores.",
                "Why is ˜y a reasonable surrogate?",
                "We know that diffusion of scores on the web graph and language model graphs improves performance [14, 16].",
                "Therefore, if score diffusion tends to, in general, improve performance, then diffused scores will, in general, provide a good surrogate for relevance.",
                "Our results demonstrate that this approximation is not as powerful as information from multiple retrievals.",
                "Nevertheless, in situations where this information is lacking, autocorrelation provides substantial information.",
                "The success of autocorrelation as a predictor may also have roots in the clustering hypothesis.",
                "Recall that we regard autocorrelation as the degree to which a retrieval satisfies the clustering hypothesis.",
                "Our experiments, then, demonstrate that a failure to respect the clustering hypothesis correlates with poor performance.",
                "Why might systems fail to conform to the cluster hypothesis?",
                "Query-based information retrieval systems often score documents independently.",
                "The score of document a may be computed by examining query term or phrase matches, the document length, and perhaps global collection statistics.",
                "Once computed, a system rarely compares the score of a to the score of a topically-related document b.",
                "With some exceptions, the correlation of document scores has largely been ignored.",
                "We should make it clear that we have selected tasks where topical autocorrelation is appropriate.",
                "There are certainly cases where there is no reason to believe that retrieval scores will have topical autocorrelation.",
                "For example, ranked lists which incorporate document novelty should not exhibit spatial autocorrelation; if anything autocorrelation should be negative for this task.",
                "Similarly, answer candidates in a question-answering task may or may not exhibit autocorrelation; in this case, the semantics of links is questionable too.",
                "It is important before applying this measure to confirm that, given the semantics for some link between two retrieved items, we should expect a correlation between scores. 8.",
                "RELATED WORK In this section we draw more general comparisons to other work in performance prediction and spatial data analysis.",
                "There is a growing body of work which attempts to predict the performance of individual retrievals [7, 3, 11, 9, 19].",
                "We have attempted to place our work in the context of much of this work in Section 4.",
                "However, a complete comparison is beyond the scope of this paper.",
                "We note, though, that our experiments cover a larger and more diverse set of retrievals, collections, and topics than previously examined.",
                "Much previous work-particularly in the context of TRECfocuses on predicting the performance of systems.",
                "Here, each system generates k retrievals.",
                "The task is, given these retrievals, to predict the ranking of systems according to some performance measure.",
                "Several papers attempt to address this task under the constraint of few judgments [2, 4].",
                "Some work even attempts to use zero judgments by leveraging multiple retrievals for the same query [17].",
                "Our task differs because we focus on ranking retrievals independent of the generating system.",
                "The task here is not to test the hypothesis system A is superior to system B but to test the hypothesis retrieval A is superior to retrieval B. Autocorrelation manifests itself in many classification tasks.",
                "Neville and Jensen define relational autocorrelation for relational learning problems and demonstrate that many classification tasks manifest autocorrelation [13].",
                "Temporal autocorrelation of initial retrievals has also been used to predict performance [9].",
                "However, temporal autocorrelation is performed by projecting the retrieval function into the temporal embedding space.",
                "In our work, we focus on the behavior of the function over the relationships between documents. τ adjusted R2 DV KL P ρ(y, ˜y) DV KL P ρ(y, ˜y) DV KL, P DV KL, ρ(y, ˜y) Pρ(y, ˜y) β trec4 0.353 0.548 0.513 0.168 0.363 0.422 0.466 0.420 0.557 0.553 trec5 0.311 0.329 0.357 0.116 0.190 0.236 0.238 0.244 0.266 0.269 robust04 0.418 0.398 0.373 0.256 0.304 0.278 0.403 0.373 0.402 0.442 terabyte04 0.139 0.150 0.454 0.059 0.045 0.292 0.076 0.293 0.289 0.284 terabyte05 0.171 0.208 0.383 0.022 0.072 0.193 0.120 0.225 0.218 0.257 Table 1: Comparison to Robustness and Clarity measures for language model scores.",
                "Evaluation replicates experiments from [19].",
                "We present correlations between the classic Clarity measure (DV KL), the ranking robustness measure (P), and autocorrelation (ρ(y, ˜y)) each with mean average precision in terms of Kendalls τ.",
                "The adjusted coefficient of determination is presented to measure the effectiveness of combining predictors.",
                "Measures in bold represent the strongest correlation for that test/collection pair. multiple run (a) (b) (c) τ τ adjusted R2 DKL ρ(y, ˜y) Dn KL ρ(y, yµ) ρ(˜y, yµ) Dn KL ρ(y, ˜y) ρ(y, yµ) ρ(˜y, yµ) β trec3 0.201 0.461 0.461 0.439 0.456 0.444 0.395 0.394 0.386 0.498 trec4 0.252 0.396 0.455 0.482 0.489 0.379 0.263 0.429 0.482 0.483 trec5 0.016 0.277 0.433 0.459 0.393 0.280 0.157 0.375 0.323 0.386 trec6 0.230 0.227 0.352 0.428 0.418 0.203 0.089 0.323 0.325 0.325 trec7 0.083 0.326 0.341 0.430 0.483 0.264 0.182 0.363 0.442 0.400 trec8 0.235 0.396 0.454 0.508 0.567 0.402 0.272 0.490 0.580 0.523 robust03 0.302 0.354 0.377 0.385 0.447 0.269 0.206 0.274 0.392 0.303 robust04 0.183 0.308 0.301 0.384 0.453 0.200 0.182 0.301 0.393 0.335 robust05 0.224 0.249 0.371 0.377 0.404 0.341 0.108 0.313 0.328 0.336 terabyte04 0.043 0.245 0.544 0.420 0.392 0.516 0.105 0.357 0.343 0.365 terabyte05 0.068 0.306 0.480 0.434 0.390 0.491 0.168 0.384 0.309 0.403 trec4-spanish 0.307 0.388 0.488 0.398 0.395 0.423 0.299 0.282 0.299 0.388 trec5-spanish 0.220 0.458 0.446 0.484 0.475 0.411 0.398 0.428 0.437 0.529 trec5-chinese 0.092 0.199 0.367 0.379 0.384 0.379 0.199 0.273 0.276 0.310 trec6-chinese 0.144 0.276 0.265 0.353 0.376 0.115 0.128 0.188 0.223 0.199 ent05 - 0.181 0.324 0.305 0.282 0.211 0.043 0.158 0.155 0.179 Table 2: Large scale prediction experiments.",
                "We predict the ranking of large sets of retrievals for various collections and retrieval systems.",
                "Kendalls τ correlations are computed between the predicted ranking and a ranking based on the retrievals average precision.",
                "In column (a), we have predictors which do not use information from other retrievals for the same query.",
                "In columns (b) and (c) we present performance for predictors which incorporate information from multiple retrievals.",
                "The adjusted coefficient of determination is computed to determine effectiveness of combining predictors.",
                "Measures in bold represent the strongest correlation for that test/collection pair.",
                "Finally, regularization-based re-ranking processes are also closely-related to our work [8].",
                "These techniques seek to maximize the agreement between scores of related documents by solving a constrained optimization problem.",
                "The maximization of consistency is equivalent to maximizing the Moran autocorrelation.",
                "Therefore, we believe that our work provides explanation for why regularization-based re-ranking works. 9.",
                "CONCLUSION We have presented a new method for predicting the performance of a retrieval ranking without any relevance judgments.",
                "We consider two cases.",
                "First, when making predictions in the absence of retrievals from other systems, our predictors demonstrate robust, strong correlations with average precision.",
                "This performance, combined with a simple implementation, makes our predictors, in particular, very attractive.",
                "We have demonstrated this improvement for many, diverse settings.",
                "To our knowledge, this is the first large scale examination of zero-judgment, single-retrieval performance prediction.",
                "Second, when provided retrievals from other systems, our extended methods demonstrate competitive performance with state of the art baselines.",
                "Our experiments also demonstrate the limits of the usefulness of our predictors when information from multiple runs is provided.",
                "Our results suggest two conclusions.",
                "First, our results could affect retrieval algorithm design.",
                "Retrieval algorithms designed to consider spatial autocorrelation will conform to the cluster hypothesis and improve performance.",
                "Second, our results could affect the design of minimal test collection algorithms.",
                "Much of the recent work in ranking systems sometimes ignores correlations between document labels and scores.",
                "We believe that these two directions could be rewarding given the theoretical and experimental evidence in this paper. 10.",
                "ACKNOWLEDGMENTS This work was supported in part by the Center for Intelligent Information Retrieval and in part by the Defense Advanced Research Projects Agency (DARPA) under contract number HR0011-06-C-0023.",
                "Any opinions, findings and conclusions or recommendations expressed in this material are the authors and do not necessarily reflect those of the sponsor.",
                "We thank Yun Zhou and Desislava Petkova for providing data and Andre Gauthier for technical assistance. 11.",
                "REFERENCES [1] J. Aslam and V. Pavlu.",
                "Query hardness estimation using jensen-shannon divergence among multiple scoring functions.",
                "In ECIR 2007: Proceedings of the 29th European Conference on Information Retrieval, 2007. [2] J.",
                "A. Aslam, V. Pavlu, and E. Yilmaz.",
                "A statistical method for system evaluation using incomplete judgments.",
                "In S. Dumais, E. N. Efthimiadis, D. Hawking, and K. Jarvelin, editors, Proceedings of the 29th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 541-548.",
                "ACM Press, August 2006. [3] D. Carmel, E. Yom-Tov, A. Darlow, and D. Pelleg.",
                "What makes a query difficult?",
                "In SIGIR 06: Proceedings of the 29th annual international ACM SIGIR conference on Research and development in information retrieval, pages 390-397, New York, NY, USA, 2006.",
                "ACM Press. [4] B. Carterette, J. Allan, and R. Sitaraman.",
                "Minimal test collections for retrieval evaluation.",
                "In SIGIR 06: Proceedings of the 29th annual international ACM SIGIR conference on Research and development in information retrieval, pages 268-275, New York, NY, USA, 2006.",
                "ACM Press. [5] A. D. Cliff and J. K. Ord.",
                "Spatial Autocorrelation.",
                "Pion Ltd., 1973. [6] M. Connell, A. Feng, G. Kumaran, H. Raghavan, C. Shah, and J. Allan.",
                "Umass at tdt 2004.",
                "Technical Report CIIR Technical Report IR - 357, Department of Computer Science, University of Massachusetts, 2004. [7] S. Cronen-Townsend, Y. Zhou, and W. B. Croft.",
                "Precision prediction based on ranked list coherence.",
                "Inf.",
                "Retr., 9(6):723-755, 2006. [8] F. Diaz.",
                "Regularizing ad-hoc retrieval scores.",
                "In CIKM 05: Proceedings of the 14th ACM international conference on Information and knowledge management, pages 672-679, New York, NY, USA, 2005.",
                "ACM Press. [9] F. Diaz and R. Jones.",
                "Using temporal profiles of queries for precision prediction.",
                "In SIGIR 04: Proceedings of the 27th annual international ACM SIGIR conference on Research and development in information retrieval, pages 18-24, New York, NY, USA, 2004.",
                "ACM Press. [10] D. A. Griffith.",
                "Spatial Autocorrelation and Spatial Filtering.",
                "Springer Verlag, 2003. [11] B.",
                "He and I. Ounis.",
                "Inferring Query Performance Using Pre-retrieval Predictors.",
                "In The Eleventh Symposium on String Processing and Information Retrieval (SPIRE), 2004. [12] N. Jardine and C. J. V. Rijsbergen.",
                "The use of hierarchic clustering in information retrieval.",
                "Information Storage and Retrieval, 7:217-240, 1971. [13] D. Jensen and J. Neville.",
                "Linkage and autocorrelation cause feature selection bias in relational learning.",
                "In ICML 02: Proceedings of the Nineteenth International Conference on Machine Learning, pages 259-266, San Francisco, CA, USA, 2002.",
                "Morgan Kaufmann Publishers Inc. [14] O. Kurland and L. Lee.",
                "Corpus structure, language models, and ad-hoc information retrieval.",
                "In SIGIR 04: Proceedings of the 27th annual international conference on Research and development in information retrieval, pages 194-201, New York, NY, USA, 2004.",
                "ACM Press. [15] M. Montague and J.",
                "A. Aslam.",
                "Relevance score normalization for metasearch.",
                "In CIKM 01: Proceedings of the tenth international conference on Information and knowledge management, pages 427-433, New York, NY, USA, 2001.",
                "ACM Press. [16] T. Qin, T.-Y.",
                "Liu, X.-D. Zhang, Z. Chen, and W.-Y.",
                "Ma.",
                "A study of relevance propagation for web search.",
                "In SIGIR 05: Proceedings of the 28th annual international ACM SIGIR conference on Research and development in information retrieval, pages 408-415, New York, NY, USA, 2005.",
                "ACM Press. [17] I. Soboroff, C. Nicholas, and P. Cahan.",
                "Ranking retrieval systems without relevance judgments.",
                "In SIGIR 01: Proceedings of the 24th annual international ACM SIGIR conference on Research and development in information retrieval, pages 66-73, New York, NY, USA, 2001.",
                "ACM Press. [18] V. Vinay, I. J. Cox, N. Milic-Frayling, and K. Wood.",
                "On ranking the effectiveness of searches.",
                "In SIGIR 06: Proceedings of the 29th annual international ACM SIGIR conference on Research and development in information retrieval, pages 398-404, New York, NY, USA, 2006.",
                "ACM Press. [19] Y. Zhou and W. B. Croft.",
                "Ranking robustness: a novel framework to predict query performance.",
                "In CIKM 06: Proceedings of the 15th ACM international conference on Information and knowledge management, pages 567-574, New York, NY, USA, 2006.",
                "ACM Press."
            ],
            "original_annotated_samples": [
                "A general, robust method for predicting the performance of retrievals with <br>zero relevance judgment</br>s (Section 3). 2."
            ],
            "translated_annotated_samples": [
                "Un método general y robusto para predecir el rendimiento de recuperaciones sin <br>juicios de relevancia</br> (Sección 3). 2."
            ],
            "translated_text": "Predicción del rendimiento utilizando autocorrelación espacial. Fernando Díaz. Centro de Recuperación de Información Inteligente. Departamento de Ciencias de la Computación. Universidad de Massachusetts Amherst, MA 01003. fdiaz@cs.umass.edu. RESUMEN La evaluación de sistemas de recuperación de información es una de las tareas fundamentales en la recuperación de información. Los problemas incluyen la incapacidad de etiquetar exhaustivamente todos los documentos sobre un tema, la falta de generalización a partir de un pequeño número de temas e incorporar la variabilidad de los sistemas de recuperación. Trabajos anteriores abordan la evaluación de sistemas, la clasificación de consultas por dificultad y la clasificación de recuperaciones individuales por rendimiento. Existen enfoques para el caso de pocos e incluso ningún juicio de relevancia. Nuestro enfoque está en la predicción del rendimiento sin juicios de las recuperaciones individuales. Una deficiencia común de las técnicas anteriores es la suposición de que las puntuaciones de los documentos y los juicios no están correlacionados. Si los documentos están incrustados en un espacio de alta dimensión (como a menudo lo están), podemos aplicar técnicas de análisis de datos espaciales para detectar correlaciones entre las puntuaciones de los documentos. Observamos que la baja correlación entre las puntuaciones de documentos temáticamente cercanos a menudo implica un bajo rendimiento en la recuperación. Cuando se compara con una línea base de última generación, demostramos que el análisis espacial de las puntuaciones de recuperación ofrece un rendimiento predictivo significativamente mejor. Estos nuevos predictores también pueden ser incorporados con predictores clásicos para mejorar aún más el rendimiento. También describimos el primer experimento a gran escala para evaluar la predicción de rendimiento sin juicio para un gran número de sistemas de recuperación en una variedad de colecciones en varios idiomas. Categorías y Descriptores de Asignaturas H.3.3 [Búsqueda y Recuperación de Información]: Modelos de recuperación; H.3.4 [Sistemas y Software]: Evaluación del rendimiento (eficiencia y efectividad) Términos Generales Rendimiento, Diseño, Confiabilidad, Experimentación 1. En la recuperación de información, un usuario plantea una consulta a un sistema. El sistema recupera n documentos, cada uno recibiendo una puntuación de valor real que indica el grado de relevancia predicho. Si seleccionamos aleatoriamente pares de documentos de este conjunto, esperamos que algunos pares compartan el mismo tema y otros pares no compartan el mismo tema. Toma dos documentos relacionados entre sí del conjunto y llámalos a y b. Si las puntuaciones de a y b son muy diferentes, podríamos estar preocupados por el rendimiento de nuestro sistema. Es decir, si tanto a como b están relacionados con el tema de la consulta, nos gustaría que ambos reciban una puntuación alta; si a y b no están relacionados con el tema de la consulta, nos gustaría que ambos reciban una puntuación baja. Podríamos preocuparnos más a medida que encontramos más diferencias entre las puntuaciones de documentos relacionados. Estaríamos más cómodos con una recuperación en la que las puntuaciones sean consistentes entre documentos relacionados. Nuestro artículo estudia la cuantificación de esta inconsistencia en una recuperación desde una perspectiva espacial. El análisis espacial es apropiado ya que muchos modelos de recuperación incrustan documentos en algún espacio vectorial. Si los documentos están incrustados en un espacio, la proximidad se correlaciona con las relaciones temáticas. La consistencia de la puntuación puede medirse mediante la versión espacial de la autocorrelación conocida como el coeficiente de Moran o IM [5, 10]. En este artículo, demostramos una fuerte correlación entre IM y el rendimiento de recuperación. La discusión hasta este punto recuerda a la hipótesis del cúmulo. La hipótesis del clúster establece que los documentos estrechamente relacionados tienden a ser relevantes para la misma solicitud [12]. Como veremos, una función de recuperación de medidas de autocorrelación espacial mide el grado en que los documentos relacionados reciben puntuaciones similares. Debido a esto, interpretamos la autocorrelación como la medida del grado en que una función de recuperación satisface la hipótesis de agrupamiento. Si esta conexión es razonable, en la Sección 6 presentamos evidencia de que la falta de cumplimiento de la hipótesis de agrupamiento se correlaciona fuertemente con un bajo rendimiento. En este trabajo, proporcionamos las siguientes contribuciones: 1. Un método general y robusto para predecir el rendimiento de recuperaciones sin <br>juicios de relevancia</br> (Sección 3). 2. Un tratamiento teórico de las similitudes y motivaciones detrás de varias técnicas de predicción de rendimiento de vanguardia (Sección 4). 3. Las primeras experimentaciones a gran escala de predicción de rendimiento de una sola ejecución sin juicio (Secciones 5 y 6). 2. Dada una consulta, un sistema de recuperación de información produce una clasificación de documentos en la colección codificada como un conjunto de puntuaciones asociadas con los documentos. Nos referimos al conjunto de puntuaciones para una combinación particular de consulta-sistema como una recuperación. Nos gustaría predecir el rendimiento de esta recuperación con respecto a alguna medida de evaluación (por ejemplo, precisión promedio). En este artículo, presentamos resultados para clasificar recuperaciones de sistemas arbitrarios. Nos gustaría que este ranking se aproximara al ranking de recuperaciones según la medida de evaluación. Esto es diferente de clasificar las consultas por el rendimiento promedio en cada consulta. También es diferente de los sistemas de clasificación por el rendimiento promedio en un conjunto de consultas. Las puntuaciones a menudo solo se calculan para los primeros n documentos de la colección. Colocamos estos puntajes en el vector de longitud n, y, donde yi se refiere al puntaje del documento clasificado en la posición i. Ajustamos las puntuaciones para que tengan una media de cero y una varianza unitaria. Utilizamos este método debido a su simplicidad y su éxito en trabajos anteriores [15]. CORRELACIÓN ESPACIAL En la recuperación de información, a menudo asumimos que las representaciones de los documentos existen en algún espacio vectorial de alta dimensión. Por ejemplo, dado un vocabulario, V, este espacio vectorial puede ser un espacio arbitrario de dimensión |V| con producto interno de coseno o un simplejo multinomial con una medida de distancia basada en distribución. Un espacio de incrustación suele ser seleccionado para respetar la proximidad temática; si dos documentos están cerca, es más probable que compartan un tema. Debido a la prevalencia y éxito de los modelos espaciales de recuperación de información, creemos que la aplicación de técnicas de análisis de datos espaciales es apropiada. Mientras que en la recuperación de información nos preocupa la puntuación en un punto en el espacio, en el análisis de datos espaciales nos preocupa el valor de una función en un punto o ubicación en el espacio. Utilizamos el término función aquí para referirnos a una asignación de una ubicación a un valor real. Por ejemplo, podríamos estar interesados en la prevalencia de una enfermedad en el vecindario de alguna ciudad. La función asignaría la ubicación de un vecindario a una tasa de infección. Si queremos cuantificar las dependencias espaciales de una función, emplearíamos una medida conocida como la autocorrelación espacial [5, 10]. Una alta autocorrelación espacial sugiere que conocer el valor de una función en la ubicación a nos dirá mucho sobre el valor en una ubicación vecina b. Existe una alta autocorrelación espacial para una función que representa la temperatura de una ubicación, ya que saber la temperatura en una ubicación a nos dirá mucho sobre la temperatura en una ubicación vecina b. La baja autocorrelación espacial sugiere que conocer el valor de una función en la ubicación a nos dice poco sobre el valor en una ubicación vecina b. Hay una baja autocorrelación espacial en una función que mide el resultado de lanzar una moneda en a y b. En esta sección, comenzaremos describiendo lo que entendemos por proximidad espacial para documentos y luego definiremos una medida de autocorrelación espacial. Concluimos extendiendo este modelo para incluir información de múltiples recuperaciones de múltiples sistemas para una sola consulta. 3.1 Representación Espacial de Documentos Nuestro trabajo no se centra en mejorar una medida de similitud específica o definir un espacio vectorial novedoso. En cambio, elegimos un producto interno conocido por ser efectivo en la detección de relaciones temáticas entre documentos. Específicamente, adoptamos vectores de documentos tf.idf, ˜di = di log „ (n + 0.5) − ci 0.5 + ci « (1) donde d es un vector de frecuencias de términos, c es el vector de frecuencia de documentos de longitud |V|. Utilizamos este esquema de ponderación debido a su éxito en la detección de enlaces temáticos en el contexto de las evaluaciones de Detección y Seguimiento de Temas (TDT) [6]. Suponiendo que los vectores están escalados por su norma L2, usamos el producto interno, ˜di, ˜dj, para definir la similitud. Dado un conjunto de documentos y alguna medida de similitud, podemos construir una matriz que codifica la similitud entre pares de documentos. Recuerde que se nos dan los primeros n documentos recuperados en y. Podemos calcular una matriz de similitud n × n, W. Un elemento de esta matriz, Wij, representa la similitud entre los documentos clasificados i y j. En la práctica, solo incluimos las afinidades para los k vecinos más cercanos de un documento. En todos nuestros experimentos, hemos fijado k en 5. Dejamos la exploración de la sensibilidad de los parámetros para trabajos futuros. También normalizamos por filas la matriz para que Pn j=1 Wij = 1 para todos los i. 3.2 Autocorrelación Espacial de una Recuperación Recuerde que estamos interesados en medir la similitud entre las puntuaciones de documentos cercanos espacialmente. Una medida adecuada es el coeficiente de Moran de autocorrelación espacial. Suponiendo la función y sobre n ubicaciones, esto se define como ˜IM = n eTWe P i,j Wijyiyj P i y2 i = n eTWe yT Wy yTy (2) donde eT We = P ij Wij. Nos gustaría comparar los valores de autocorrelación para diferentes recuperaciones. Desafortunadamente, el límite para la Ecuación 2 no es consistente para diferentes valores de W y y. Por lo tanto, utilizamos la desigualdad de Cauchy-Schwartz para establecer un límite, ˜IM ≤ n eTWe s yTWTWy yTy Y definimos la autocorrelación espacial normalizada como IM = yT Wy p yTy × yTWTWy. Nótese que si dejamos ˜y = Wy, entonces podemos escribir esta fórmula como, IM = yT ˜y y 2 ˜y 2 (3) lo cual puede interpretarse como la correlación entre las puntuaciones originales de recuperación y un conjunto de puntuaciones de recuperación difundidas en el espacio. Presentamos algunos ejemplos de autocorrelaciones de funciones en una cuadrícula en la Figura 1. 3.3 Correlación con Otros Recuperos A veces estamos interesados en el rendimiento de un solo recuperación pero tenemos acceso a puntajes de múltiples sistemas para (a) IM = 0.006 (b) IM = 0.241 (c) IM = 0.487 Figura 1: El coeficiente de Moran, IM para varias funciones binarias en una cuadrícula. El coeficiente de Moran es una medida local de consistencia de la función. Desde la perspectiva de la recuperación de información, cada uno de estos espacios de la cuadrícula representaría un documento y los documentos estarían organizados de manera que se encuentren junto a documentos relacionados temáticamente. Las puntuaciones de recuperación binaria definirían un patrón en esta cuadrícula. Ten en cuenta que, a medida que el coeficiente de Moran aumenta, las celdas vecinas tienden a tener valores similares. En esta situación, podemos utilizar la información combinada de estas puntuaciones para construir un sustituto de una clasificación de alta calidad [17]. Podemos tratar la correlación entre la recuperación que nos interesa y las puntuaciones combinadas como un predictor del rendimiento. Supongamos que se nos dan m funciones de puntuación, yi, para los mismos n documentos. Representaremos la media de estos vectores como yµ = Σm i=1 yi. Utilizamos el vector medio como una aproximación a la relevancia. Dado que utilizamos normalización de media cero y varianza unitaria, el trabajo en metabusqueda sugiere que esta suposición está justificada [15]. Dado que yµ representa una recuperación muy buena, hipotetizamos que una similitud fuerte entre yµ e y correlacionará positivamente con el rendimiento del sistema. Utilizamos la correlación de Pearson para medir la similitud entre estos vectores, ρ(y, yµ) = yT yµ y 2 yµ 2 (4). Comentaremos sobre la similitud entre la Ecuación 3 y 4 en la Sección 7. Por supuesto, podemos combinar ρ(y, ˜y) y ρ(y, yµ) si asumimos que capturan diferentes factores en la predicción. Una forma de lograr esto es combinar estos predictores como variables independientes en una regresión lineal. Se sugiere un medio alternativo de combinación basado en la forma matemática de nuestros predictores. Dado que ˜y codifica las dependencias espaciales en y y yµ codifica las propiedades espaciales de las múltiples ejecuciones, podemos calcular una tercera correlación entre estos dos vectores, ρ(˜y, yµ) = ˜yT yµ ˜y 2 yµ 2 (5). Podemos interpretar la Ecuación 5 como la medición de la correlación entre un ranking de alta calidad (yµ) y una versión suavizada espacialmente de la recuperación (˜y). 4. RELACIÓN CON OTROS PREDICTORES Una forma de predecir la efectividad de una recuperación es observar el vocabulario compartido de los n documentos principales recuperados. Si calculáramos las palabras de contenido más frecuentes en este conjunto, esperaríamos que fueran coherentes con nuestro tema. De hecho, podríamos creer que una mala recuperación incluiría documentos sobre muchos temas dispares, lo que resultaría en una superposición de ruido terminológico. La claridad de una consulta intenta cuantificar exactamente esto [7]. Específicamente, la Claridad mide la similitud de las palabras más frecuentemente utilizadas en los documentos recuperados con aquellas más frecuentemente utilizadas en todo el corpus. La conjetura es que una buena recuperación utilizará un lenguaje distinto al del texto general; el lenguaje superpuesto en una mala recuperación tenderá a ser más similar al texto general. Matemáticamente, podemos calcular una representación del lenguaje utilizado en la recuperación inicial como una combinación ponderada de modelos de lenguaje de documentos, P(w|θQ) = Σ i=1 P(w|θi) P(Q|θi) Z (6) donde θi es el modelo de lenguaje del documento clasificado en la posición i, P(Q|θi) es la puntuación de probabilidad de la consulta del documento clasificado en la posición i y Z = Σ i=1 P(Q|θi) es una constante de normalización. La similitud entre el multinomial P(w|θQ) y un modelo de texto general se puede calcular utilizando la divergencia de Kullback-Leibler, DV KL(θQ θC). Aquí, la distribución P(w|θC) es nuestro modelo de texto general que puede ser calculado utilizando las frecuencias de términos en el corpus. En la Figura 2a, presentamos la Claridad como la medida de la distancia entre el centro de masa ponderado de la recuperación (etiquetado como y) y el centro de masa no ponderado de la colección (etiquetado como O). La claridad alcanza un mínimo cuando una recuperación asigna a cada documento la misma puntuación. Volvamos a asumir que tenemos un conjunto de n documentos recuperados para nuestra consulta. Otra forma de cuantificar la dispersión de un conjunto de documentos es observar qué tan agrupados están. Podemos hipotetizar que una buena recuperación devolverá un único y compacto grupo. Una recuperación de bajo rendimiento devolverá un conjunto de documentos poco relacionados que abarcan muchos temas. Un método propuesto para cuantificar esta dispersión es medir la distancia desde un documento aleatorio a su vecino más cercano, b. Una recuperación que esté estrechamente agrupada, en promedio, tendrá una distancia baja entre a y b; una recuperación que esté menos cerrada tendrá, en promedio, distancias altas entre a y b. Este promedio corresponde al uso de la estadística de Cox-Lewis para medir la aleatoriedad de los primeros n documentos recuperados de un sistema [18]. En la Figura 2a, esto es aproximadamente equivalente a medir el área del conjunto n. Observa que estamos descartando información sobre la función de recuperación y. Por lo tanto, la estadística de Cox-Lewis depende en gran medida de la selección de los primeros n documentos. Recuerda que tenemos n documentos y un conjunto de puntuaciones. Supongamos que tenemos acceso al sistema que proporcionó las puntuaciones originales y que también podemos solicitar puntuaciones para nuevos documentos. Esto sugiere un tercer método para predecir el rendimiento. Toma algún documento, a, del conjunto recuperado y agrega o elimina palabras al azar de forma arbitraria para crear un nuevo documento ˜a. Ahora, podemos pedirle a nuestro sistema que puntúe ˜a con respecto a nuestra consulta. Si, en promedio, a lo largo de los n documentos, las puntuaciones de a y ˜a tienden a ser muy diferentes, podríamos sospechar que el sistema está fallando en esta consulta. Los autores han sugerido acoplar la consulta con la medida de distancia [18]. La información introducida por la consulta, sin embargo, es independiente de la recuperación, de modo que, si dos recuperaciones devuelven el mismo conjunto de documentos, la estadística aproximada de Cox-Lewis será la misma independientemente de las puntuaciones de recuperación. yOy (a) Divergencia Global µ(y)˜y y (b) Perturbación de Puntuación µ(y) y (c) Promedio de Múltiples Ejecuciones Figura 2: Representación de varios predictores de rendimiento en una cuadrícula. En la Figura 2a, representamos los predictores que miden la divergencia entre el centro de masa de una recuperación y el centro del espacio de incrustación. En la Figura 2b, representamos los predictores que comparan la recuperación original, y, con una versión perturbada de la recuperación, ˜y. Nuestro enfoque utiliza un tipo particular de perturbación basado en la difusión de puntajes. Finalmente, en la Figura 2c, representamos la predicción cuando se proporcionan recuperaciones de varios otros sistemas en la misma consulta. Aquí, podemos considerar la fusión de estas recuperaciones como un sustituto de la relevancia. Esto se puede lograr ya sea perturbando los documentos o las consultas. La similitud entre los dos recuperos se puede medir utilizando alguna medida de correlación. Esto se muestra en la Figura 2b. La cuadrícula superior representa la recuperación original, y, mientras que la cuadrícula inferior representa la función después de haber sido perturbada, ˜y. La naturaleza del proceso de perturbación requiere puntuaciones o recuperaciones adicionales. Nuestro predictor no requiere acceso a la función de puntuación original ni a recuperaciones adicionales. Por lo tanto, aunque nuestro método es similar a otros métodos de perturbación en espíritu, se puede aplicar en situaciones en las que el sistema de recuperación es inaccesible o costoso de acceder. Finalmente, supongamos que tenemos, además de la recuperación que queremos evaluar, m recuperaciones de una variedad de sistemas diferentes. En este caso, podríamos tomar un documento a, comparar su rango en la recuperación con su rango promedio en los m recuperos. Si creemos que las m recuperaciones proporcionan una aproximación satisfactoria a la relevancia, entonces una diferencia muy grande en el rango sugeriría que nuestra recuperación está clasificando incorrectamente a. Si esta diferencia es grande en promedio en todos los n documentos, entonces podríamos predecir que la recuperación es mala. Si, por otro lado, la recuperación es muy consistente con las m recuperaciones, entonces podríamos predecir que la recuperación es buena. La similitud entre la recuperación y la recuperación combinada puede calcularse utilizando alguna medida de correlación. Esto se muestra en la Figura 2c. En trabajos anteriores, la divergencia de Kullback-Leibler entre las puntuaciones normalizadas de la recuperación y las puntuaciones normalizadas de la recuperación combinada proporciona la similitud [1]. 5. Nuestros experimentos se centran en probar el poder predictivo de cada uno de nuestros predictores: ρ(y, ˜y), ρ(y, yµ) y ρ(˜y, yµ). Como se indica en la Sección 2, estamos interesados en predecir el rendimiento de la recuperación generada por un sistema arbitrario. Nuestra metodología es consistente con investigaciones previas en el sentido de que predecimos el rendimiento relativo de una recuperación al comparar una clasificación basada en nuestro predictor con una clasificación basada en la precisión promedio. Presentamos los resultados de dos conjuntos de experimentos. El primer conjunto de experimentos presenta comparaciones detalladas de nuestros predictores con predictores previamente propuestos utilizando conjuntos de datos idénticos. Nuestro segundo conjunto de experimentos demuestra la generalizabilidad de nuestro enfoque a métodos de recuperación arbitrarios, tipos de corpus y lenguajes de corpus. 5.1 Experimentos Detallados En estos experimentos, predeciremos el rendimiento de los puntajes de modelado de lenguaje utilizando nuestro predictor de autocorrelación, ρ(y, ˜y); no consideramos ρ(y, yµ) o ρ(˜y, yµ) porque, en estos experimentos detallados, nos enfocamos en clasificar las recuperaciones de un solo sistema. Utilizamos recuperaciones, valores de predictores de referencia y medidas de evaluación reportadas en trabajos anteriores [19]. 5.1.1 Temas y Colecciones Estos experimentos de predicción de rendimiento utilizan recuperaciones de modelos de lenguaje realizadas para consultas asociadas con colecciones en las corpora de TREC. El uso de las colecciones TREC nos permite asociar con confianza una precisión promedio con una recuperación. En estos experimentos, utilizamos las siguientes colecciones de temas: TREC 4 ad-hoc, TREC 5 ad-hoc, Robust 2004, Terabyte 2004 y Terabyte 2005. 5.1.2 Baselines Proporcionamos dos líneas base. Nuestro primer punto de referencia es el predictor clásico de Claridad presentado en la Ecuación 6. La claridad está diseñada para ser utilizada con sistemas de modelado de lenguaje. Nuestro segundo punto de referencia es el predictor de robustez de clasificación de Zhou y Crofts. Este predictor corrompe los k documentos principales de la recuperación y vuelve a calcular las puntuaciones del modelo de lenguaje para estos documentos corruptos. El valor del predictor es la correlación de rangos de Spearman entre la clasificación original y la clasificación corrupta. En nuestras tablas, etiquetaremos los resultados para Claridad utilizando DV KL y el predictor de robustez de clasificación utilizando P. 5.2 Experimentos de Generalizabilidad Nuestros predictores no requieren un sistema de recuperación base particular; los predictores pueden calcularse para una recuperación arbitraria, independientemente de cómo se generaron los puntajes. Creemos que ese es uno de los aspectos más atractivos de nuestro algoritmo. Por lo tanto, en un segundo conjunto de experimentos, demostramos la capacidad de nuestras técnicas para generalizar a una variedad de colecciones, temas y sistemas de recuperación. 5.2.1 Temas y Colecciones Recopilamos un conjunto diverso de colecciones de todos los corpus posibles de TREC. Lanzamos una red amplia para localizar colecciones donde nuestros predictores podrían fallar. Nuestra hipótesis es que los documentos con alta similitud temática deberían tener puntuaciones correlacionadas. Por lo tanto, evitamos las colecciones donde las puntuaciones eran poco probables de estar correlacionadas (por ejemplo, preguntas y respuestas) o donde probablemente estuvieran negativamente correlacionadas (por ejemplo, novedad). Sin embargo, nuestras colecciones incluyen corpus donde las correlaciones están débilmente justificadas (por ejemplo, corpus no en inglés) o no justificadas en absoluto (por ejemplo, búsqueda de expertos). Utilizamos las pistas ad-hoc de TREC3-8, TREC Robust 2003-2005, TREC Terabyte 2004-2005, TREC4-5 en español, TREC5-6 en chino y TREC Enterprise Expert Search 2005. En todos los casos, solo utilizamos las ejecuciones automáticas para las pistas ad-hoc enviadas a NIST. Para todos los corpus en inglés y español, construimos la matriz W de acuerdo con el proceso descrito en la Sección 3.1. Para los corpus chinos, utilizamos vectores tf.idf basados en caracteres ingenuos. Para las entidades, las entradas en W son proporcionales al número de documentos en los que dos entidades coocurren. 5.2.2 Baselines En nuestros experimentos detallados, utilizamos la medida de Claridad como referencia. Dado que estamos prediciendo el rendimiento de recuperaciones que no se basan en modelado de lenguaje, utilizamos una versión de Claridad conocida como Claridad de lista clasificada [7]. La claridad de la lista clasificada convierte las clasificaciones de documentos en valores P(Q|θi). Esta conversión comienza reemplazando todas las puntuaciones en y con los rangos respectivos. Nuestra estimación de P(Q|θi) a partir de los rangos, entonces es, P(Q|θi) = ( 2(c+1−yi) c(c+1) si yi ≤ c 0 en otro caso donde c es un parámetro de corte. Como sugieren los autores, fijamos los parámetros del algoritmo c y λ2 de manera que c = 60 y λ2 = 0.10. Utilizamos la Ecuación 6 para estimar P(w|θQ) y DV KL(θQ θC) para calcular el valor del predictor. Nos referiremos a este predictor como DV KL, con superíndice V para indicar que la divergencia de Kullback-Leibler es con respecto al espacio de incrustación de términos. Cuando la información de múltiples ejecuciones de la misma consulta está disponible, utilizamos la divergencia multinomial en el espacio de documentos de Aslam y Pavlus como referencia [1]. Este método basado en rangos primero normaliza las puntuaciones en una recuperación como un multinomial n-dimensional. Al igual que con la Claridad de la lista clasificada, comenzamos reemplazando todas las puntuaciones en y con sus respectivas posiciones. Luego, ajustamos los elementos de y de la siguiente manera, ˆyi = 1 2n 0 @1 + nX k=yi 1 k 1 A (8) En nuestros experimentos de múltiples ejecuciones, solo utilizamos los 75 documentos principales de cada recuperación (n = 75); esto está dentro del rango de valores de parámetros sugeridos por los autores. Sin embargo, admitimos no haber ajustado este parámetro ni para nuestro sistema ni para la línea base. El predictor es la divergencia entre la distribución candidata, y, y la distribución media, yµ. Con la combinación lineal uniforme de estos m recuperaciones representadas como yµ, podemos calcular la divergencia como Dn KL(ˆy ˆyµ) donde usamos el superíndice n para indicar que la suma es sobre el conjunto de n documentos. Este punto de referencia fue desarrollado en el contexto de predecir la dificultad de la consulta, pero lo adoptamos como un punto de referencia razonable para predecir el rendimiento de la recuperación. 5.2.3 Configuración de parámetros Cuando se proporcionan múltiples recuperaciones, utilizamos documentos en la unión de los mejores k = 75 documentos de cada una de las m recuperaciones para esa consulta. Si el tamaño de esta unión es ˜n, entonces yµ y cada yi tiene una longitud de ˜n. En algunos casos, un sistema no puntuó un documento en la unión. Dado que estamos haciendo una suposición gaussiana sobre nuestras puntuaciones, podemos muestrear puntuaciones para estos documentos no vistos de la cola negativa de la distribución. Específicamente, muestreamos de la parte de la distribución inferior al valor mínimo en la recuperación normalizada. Esto introduce aleatoriedad en nuestro algoritmo, pero creemos que es más apropiado que asignar un valor fijo arbitrario. Optimizamos la regresión lineal utilizando la raíz cuadrada de cada predictor. Encontramos que esto mejoró sustancialmente los ajustes para todos los predictores, incluidos los basales. Consideramos combinaciones lineales de pares de predictores (etiquetados por los componentes) y todos los predictores (etiquetados como β). 5.3 Evaluación Dado un conjunto de recuperaciones, potencialmente de una combinación de consultas y sistemas, medimos la correlación del ordenamiento de rango de este conjunto por el predictor y por la métrica de rendimiento. Para garantizar la comparabilidad con los resultados anteriores, presentamos la correlación de Kendalls τ entre la clasificación de los predictores y la clasificación basada en la precisión promedio de la recuperación. A menos que se indique explícitamente, todas las correlaciones son significativas con p < 0.05. Los predictores a veces pueden tener un mejor rendimiento cuando se combinan linealmente [9, 11]. Aunque trabajos anteriores han presentado el coeficiente de determinación (R2) para medir la calidad de la regresión, esta medida no puede ser utilizada de manera confiable al comparar pequeñas mejoras al combinar predictores. Por lo tanto, adoptamos el coeficiente de determinación ajustado que penaliza los modelos con más variables. El R2 ajustado nos permite evaluar la mejora en la predicción lograda al agregar un parámetro pero pierde la interpretación estadística del R2. Utilizaremos τ de Kendall para evaluar la magnitud de la correlación y R2 ajustado para evaluar la combinación de variables. RESULTADOS Presentamos los resultados de nuestros experimentos detallados comparando la predicción de puntuaciones de modelos de lenguaje en la Tabla 1. Aunque la medida de Claridad está teóricamente diseñada para puntuaciones de modelos de lenguaje, consistentemente tiene un rendimiento inferior a nuestro predictor independiente del sistema. La robustez del ranking se presentó como una mejora a la Claridad para colecciones web (representadas en nuestros experimentos por las colecciones terabyte04 y terabyte05), desplazando la correlación τ de 0.139 a 0.150 para terabyte04 y de 0.171 a 0.208 para terabyte05. Sin embargo, estas mejoras son leves en comparación con el rendimiento de la autocorrelación en estas colecciones. Nuestro predictor logra una correlación τ de 0.454 para terabyte04 y 0.383 para terabyte05. Aunque no siempre es la más fuerte, la autocorrelación logra correlaciones competitivas con los predictores de referencia. Al examinar el rendimiento de las combinaciones lineales de predictores, observamos que en cada caso, los factores de autocorrelación son un componente necesario de un predictor sólido. También observamos que el R2 ajustado para las líneas de base individuales siempre mejora significativamente al incorporar la autocorrelación. Presentamos nuestros resultados de generalizabilidad en la Tabla 2. Comenzamos examinando la situación en la columna (a) donde se nos presenta una sola recuperación y ninguna información de recuperaciones adicionales. Para cada colección excepto una, logramos correlaciones significativamente mejores que la claridad de la lista clasificada. Sorprendentemente, logramos correlaciones relativamente fuertes para las colecciones en español y chino a pesar de nuestro procesamiento ingenuo. No tenemos una correlación de claridad de lista clasificada para ent05 porque la modelización de entidades es en sí misma una pregunta de investigación abierta. Sin embargo, nuestra medida de autocorrelación no logra altas correlaciones, quizás porque la relevancia para la recuperación de entidades no se propaga de acuerdo con los enlaces de coocurrencia que utilizamos. Como se señaló anteriormente, el bajo rendimiento de Claridad en datos web es consistente con nuestros hallazgos en los experimentos detallados. La claridad también tiene un rendimiento notablemente inferior en varios corpus de noticias (trec5, trec7 y robust04). Por otro lado, la autocorrelación parece ser robusta a los cambios entre diferentes corpora. A continuación, pasamos a la introducción de información de múltiples recuperaciones. Comparamos las correlaciones entre aquellos predictores que no utilizan esta información en la columna (a) y aquellos que sí lo hacen en la columna (b). Para cada colección, los predictores en la columna (b) superan a los predictores en la columna (a), lo que indica que la información de ejecuciones adicionales puede ser crítica para hacer buenas predicciones. Inspeccionando los predictores en la columna (b), solo podemos sacar conclusiones débiles. Nuestros nuevos predictores tienden a tener un mejor rendimiento en corpora de noticias. Y entre nuestros nuevos predictores, el predictor híbrido ρ(˜y, yµ) tiende a tener un mejor rendimiento. Recuerde que nuestra medida ρ(˜y, yµ) incorpora tanto información espacial como de múltiples recuperaciones. Por lo tanto, creemos que la mejora en la correlación es el resultado de incorporar información del comportamiento espacial. En la columna (c), podemos investigar la utilidad de incorporar información espacial con información de múltiples recuperaciones. Observa que en los casos donde la autocorrelación, ρ(y, ˜y), por sí sola funciona bien (trec3, trec5-spanish y trec6-chinese), se mejora sustancialmente al incorporar información de múltiples recuperaciones de ρ(y, yµ) en la regresión lineal, β. En los casos en los que ρ(y, yµ) funciona bien, la incorporación de la autocorrelación rara vez resulta en una mejora significativa en el rendimiento. De hecho, en cada caso en el que nuestro predictor supera al valor de referencia, incluye información de múltiples ejecuciones. 7. DISCUSIÓN El resultado más importante de nuestros experimentos implica la predicción cuando no hay información disponible de múltiples ejecuciones (Tablas 1 y 2a). Esta situación surge a menudo en el diseño de sistemas. Por ejemplo, un sistema puede necesitar, en el momento de la recuperación, evaluar su rendimiento antes de decidir llevar a cabo un procesamiento más intensivo como la retroalimentación de pseudo relevancia o la interacción. Suponiendo que la presencia de múltiples recuperaciones es irrealista en este caso. Creemos que la autocorrelación, al igual que los algoritmos de recuperación múltiple, aproxima un buen ranking; en este caso mediante la difusión de puntajes. ¿Por qué es ˜y un sustituto razonable? Sabemos que la difusión de puntuaciones en el grafo web y en los grafos de modelos de lenguaje mejora el rendimiento [14, 16]. Por lo tanto, si la difusión de puntuaciones tiende, en general, a mejorar el rendimiento, entonces las puntuaciones difusas proporcionarán, en general, un buen sustituto de la relevancia. Nuestros resultados demuestran que esta aproximación no es tan potente como la información de múltiples recuperaciones. Sin embargo, en situaciones donde esta información falta, la autocorrelación proporciona información sustancial. El éxito de la autocorrelación como predictor también puede tener sus raíces en la hipótesis de agrupamiento. Recuerde que consideramos la autocorrelación como el grado en que una recuperación satisface la hipótesis de agrupamiento. Nuestros experimentos, entonces, demuestran que una falta de respeto a la hipótesis de agrupamiento se correlaciona con un bajo rendimiento. ¿Por qué los sistemas podrían no cumplir con la hipótesis del clúster? Los sistemas de recuperación de información basados en consultas a menudo puntúan los documentos de forma independiente. El puntaje del documento a puede ser calculado examinando las coincidencias de términos o frases de la consulta, la longitud del documento y quizás las estadísticas globales de la colección. Una vez calculado, un sistema rara vez compara la puntuación de un documento a con la puntuación de un documento relacionado temáticamente b. Con algunas excepciones, la correlación de las puntuaciones de los documentos ha sido ampliamente ignorada. Debemos dejar claro que hemos seleccionado tareas donde la autocorrelación temática es apropiada. Ciertamente hay casos en los que no hay motivo para creer que las puntuaciones de recuperación tendrán autocorrelación temática. Por ejemplo, las listas clasificadas que incorporan novedad de documentos no deben mostrar autocorrelación espacial; si acaso, la autocorrelación debería ser negativa para esta tarea. Del mismo modo, los candidatos de respuestas en una tarea de pregunta-respuesta pueden o no mostrar autocorrelación; en este caso, la semántica de los enlaces también es cuestionable. Es importante antes de aplicar esta medida confirmar que, dada la semántica para algún enlace entre dos elementos recuperados, deberíamos esperar una correlación entre las puntuaciones. 8. TRABAJO RELACIONADO En esta sección realizamos comparaciones más generales con otros trabajos en predicción de rendimiento y análisis de datos espaciales. Existe un creciente cuerpo de trabajo que intenta predecir el rendimiento de recuperaciones individuales [7, 3, 11, 9, 19]. Hemos intentado situar nuestro trabajo en el contexto de gran parte de este trabajo en la Sección 4. Sin embargo, una comparación completa está fuera del alcance de este documento. Sin embargo, cabe destacar que nuestros experimentos abarcan un conjunto más amplio y diverso de recuperaciones, colecciones y temas que los examinados previamente. Gran parte del trabajo previo, especialmente en el contexto de TREC, se centra en predecir el rendimiento de los sistemas. Aquí, cada sistema genera k recuperaciones. La tarea consiste en, dadas estas recuperaciones, predecir la clasificación de los sistemas según alguna medida de rendimiento. Varios artículos intentan abordar esta tarea bajo la restricción de pocas evaluaciones [2, 4]. Algunos trabajos incluso intentan utilizar cero juicios aprovechando múltiples recuperaciones para la misma consulta [17]. Nuestra tarea difiere porque nos enfocamos en clasificar recuperaciones independientemente del sistema generador. La tarea aquí no es probar que el sistema A es superior al sistema B, sino probar que la recuperación A es superior a la recuperación B. La autocorrelación se manifiesta en muchas tareas de clasificación. Neville y Jensen definen la autocorrelación relacional para problemas de aprendizaje relacional y demuestran que muchas tareas de clasificación manifiestan autocorrelación [13]. La autocorrelación temporal de las recuperaciones iniciales también se ha utilizado para predecir el rendimiento [9]. Sin embargo, la autocorrelación temporal se realiza proyectando la función de recuperación en el espacio de incrustación temporal. En nuestro trabajo, nos enfocamos en el comportamiento de la función sobre las relaciones entre documentos. τ ajustado R2 DV KL P ρ(y, ˜y) DV KL P ρ(y, ˜y) DV KL, P DV KL, ρ(y, ˜y) Pρ(y, ˜y) β trec4 0.353 0.548 0.513 0.168 0.363 0.422 0.466 0.420 0.557 0.553 trec5 0.311 0.329 0.357 0.116 0.190 0.236 0.238 0.244 0.266 0.269 robust04 0.418 0.398 0.373 0.256 0.304 0.278 0.403 0.373 0.402 0.442 terabyte04 0.139 0.150 0.454 0.059 0.045 0.292 0.076 0.293 0.289 0.284 terabyte05 0.171 0.208 0.383 0.022 0.072 0.193 0.120 0.225 0.218 0.257 Tabla 1: Comparación de medidas de robustez y claridad para puntuaciones de modelos de lenguaje. La evaluación replica experimentos de [19]. Presentamos las correlaciones entre la medida clásica de Claridad (DV KL), la medida de robustez de clasificación (P) y la autocorrelación (ρ(y, ˜y)) cada una con la precisión media promedio en términos de τ de Kendall. El coeficiente de determinación ajustado se presenta para medir la efectividad de combinar predictores. Las medidas en negrita representan la correlación más fuerte para ese par de prueba/colección. múltiples ejecuciones (a) (b) (c) τ τ ajustado R2 DKL ρ(y, ˜y) Dn KL ρ(y, yµ) ρ(˜y, yµ) Dn KL ρ(y, ˜y) ρ(y, yµ) ρ(˜y, yµ) β trec3 0.201 0.461 0.461 0.439 0.456 0.444 0.395 0.394 0.386 0.498 trec4 0.252 0.396 0.455 0.482 0.489 0.379 0.263 0.429 0.482 0.483 trec5 0.016 0.277 0.433 0.459 0.393 0.280 0.157 0.375 0.323 0.386 trec6 0.230 0.227 0.352 0.428 0.418 0.203 0.089 0.323 0.325 0.325 trec7 0.083 0.326 0.341 0.430 0.483 0.264 0.182 0.363 0.442 0.400 trec8 0.235 0.396 0.454 0.508 0.567 0.402 0.272 0.490 0.580 0.523 robust03 0.302 0.354 0.377 0.385 0.447 0.269 0.206 0.274 0.392 0.303 robust04 0.183 0.308 0.301 0.384 0.453 0.200 0.182 0.301 0.393 0.335 robust05 0.224 0.249 0.371 0.377 0.404 0.341 0.108 0.313 0.328 0.336 terabyte04 0.043 0.245 0.544 0.420 0.392 0.516 0.105 0.357 0.343 0.365 terabyte05 0.068 0.306 0.480 0.434 0.390 0.491 0.168 0.384 0.309 0.403 trec4-spanish 0.307 0.388 0.488 0.398 0.395 0.423 0.299 0.282 0.299 0.388 trec5-spanish 0.220 0.458 0.446 0.484 0.475 0.411 0.398 0.428 0.437 0.529 trec5-chinese 0.092 0.199 0.367 0.379 0.384 0.379 0.199 0.273 0.276 0.310 trec6-chinese 0.144 0.276 0.265 0.353 0.376 0.115 0.128 0.188 0.223 0.199 ent05 - 0.181 0.324 0.305 0.282 0.211 0.043 0.158 0.155 0.179 Tabla 2: Experimentos de predicción a gran escala. Predecimos la clasificación de grandes conjuntos de recuperaciones para varias colecciones y sistemas de recuperación. Las correlaciones de τ de Kendall se calculan entre la clasificación predicha y una clasificación basada en la precisión promedio de las recuperaciones. En la columna (a), tenemos predictores que no utilizan información de otras recuperaciones para la misma consulta. En las columnas (b) y (c) presentamos el rendimiento de los predictores que incorporan información de múltiples recuperaciones. El coeficiente de determinación ajustado se calcula para determinar la efectividad de combinar predictores. Las medidas en negrita representan la correlación más fuerte para ese par de prueba/colección. Finalmente, los procesos de reordenamiento basados en regularización también están estrechamente relacionados con nuestro trabajo [8]. Estas técnicas buscan maximizar el acuerdo entre las puntuaciones de documentos relacionados al resolver un problema de optimización restringida. La maximización de la consistencia es equivalente a maximizar la autocorrelación de Moran. Por lo tanto, creemos que nuestro trabajo proporciona una explicación de por qué funciona el reordenamiento basado en regularización. 9. CONCLUSIÓN Hemos presentado un nuevo método para predecir el rendimiento de un ranking de recuperación sin necesidad de juicios de relevancia. Consideramos dos casos. Primero, al hacer predicciones en ausencia de recuperaciones de otros sistemas, nuestros predictores muestran correlaciones sólidas y robustas con la precisión promedio. Esta actuación, combinada con una implementación sencilla, hace que nuestros predictores, en particular, sean muy atractivos. Hemos demostrado esta mejora en muchos entornos diversos. Según nuestro conocimiento, esta es la primera evaluación a gran escala de la predicción del rendimiento de una sola recuperación sin juicio. Segundo, cuando se proporcionan recuperaciones de otros sistemas, nuestros métodos ampliados demuestran un rendimiento competitivo con las líneas de base de vanguardia. Nuestros experimentos también demuestran los límites de la utilidad de nuestros predictores cuando se proporciona información de múltiples ejecuciones. Nuestros resultados sugieren dos conclusiones. Primero, nuestros resultados podrían afectar el diseño de algoritmos de recuperación. Los algoritmos de recuperación diseñados para considerar la autocorrelación espacial se ajustarán a la hipótesis de agrupamiento y mejorarán el rendimiento. Segundo, nuestros resultados podrían afectar el diseño de algoritmos de colección de pruebas mínimas. Gran parte del trabajo reciente en sistemas de clasificación a veces ignora las correlaciones entre las etiquetas de los documentos y las puntuaciones. Creemos que estas dos direcciones podrían ser gratificantes dadas las pruebas teóricas y experimentales en este documento. 10. AGRADECIMIENTOS Este trabajo fue apoyado en parte por el Centro de Recuperación de Información Inteligente y en parte por la Agencia de Proyectos de Investigación Avanzada de Defensa (DARPA) bajo el número de contrato HR0011-06-C-0023. Cualquier opinión, hallazgo y conclusión o recomendación expresada en este material son del autor y no necesariamente reflejan las del patrocinador. Agradecemos a Yun Zhou y Desislava Petkova por proporcionar los datos y a Andre Gauthier por la asistencia técnica. 11. REFERENCIAS [1] J. Aslam y V. Pavlu. Estimación de la dificultad de la consulta utilizando la divergencia de Jensen-Shannon entre múltiples funciones de puntuación. En ECIR 2007: Actas de la 29ª Conferencia Europea sobre Recuperación de Información, 2007. [2] J. A. Aslam, V. Pavlu y E. Yilmaz. Un método estadístico para la evaluación de sistemas utilizando juicios incompletos. En S. Dumais, E. N. Efthimiadis, D. Hawking y K. Jarvelin, editores, Actas de la 29ª Conferencia Internacional Anual de ACM SIGIR sobre Investigación y Desarrollo en Recuperación de Información, páginas 541-548. ACM Press, agosto de 2006. [3] D. Carmel, E. Yom-Tov, A. Darlow y D. Pelleg. ¿Qué hace que una consulta sea difícil? En SIGIR 06: Actas de la 29ª conferencia internacional anual de ACM SIGIR sobre investigación y desarrollo en recuperación de información, páginas 390-397, Nueva York, NY, EE. UU., 2006. ACM Press. [4] B. Carterette, J. Allan y R. Sitaraman. Colecciones de prueba mínimas para evaluación de recuperación. En SIGIR 06: Actas de la 29ª conferencia internacional anual de ACM SIGIR sobre investigación y desarrollo en recuperación de información, páginas 268-275, Nueva York, NY, EE. UU., 2006. ACM Press. [5] A. D. Cliff y J. K. Ord. Autocorrelación espacial. Pion Ltd., 1973. [6] M. Connell, A. Feng, G. Kumaran, H. Raghavan, C. Shah y J. Allan. Umass en tdt 2004. Informe técnico CIIR Informe técnico IR - 357, Departamento de Ciencias de la Computación, Universidad de Massachusetts, 2004. [7] S. Cronen-Townsend, Y. Zhou y W. B. Croft. Predicción de precisión basada en la coherencia de la lista clasificada. I'm sorry, but the sentence \"Inf.\" is not a complete sentence. Could you please provide more context or a full sentence for me to translate to Spanish? Rev., 9(6):723-755, 2006. [8] F. Diaz. Normalizando las puntuaciones de recuperación ad-hoc. En CIKM 05: Actas de la 14ª conferencia internacional de ACM sobre gestión de la información y el conocimiento, páginas 672-679, Nueva York, NY, EE. UU., 2005. ACM Press. [9] F. Diaz y R. Jones. Utilizando perfiles temporales de consultas para predecir la precisión. En SIGIR 04: Actas de la 27ª conferencia internacional anual de ACM SIGIR sobre investigación y desarrollo en recuperación de información, páginas 18-24, Nueva York, NY, EE. UU., 2004. ACM Press. [10] D. A. Griffith. \n\nACM Press. [10] D. A. Griffith. Autocorrelación espacial y filtrado espacial. Springer Verlag, 2003. [11] B. \n\nSpringer Verlag, 2003. [11] B. Él y yo. Ounis. Inferir el rendimiento de la consulta utilizando predictores previos a la recuperación. En el Undécimo Simposio sobre Procesamiento de Cadenas y Recuperación de Información (SPIRE), 2004. [12] N. Jardine y C. J. V. Rijsbergen. El uso de agrupamiento jerárquico en la recuperación de información. Almacenamiento y recuperación de información, 7:217-240, 1971. [13] D. Jensen y J. Neville. El enlace y la autocorrelación causan sesgo en la selección de características en el aprendizaje relacional. En ICML 02: Actas de la Decimonovena Conferencia Internacional sobre Aprendizaje Automático, páginas 259-266, San Francisco, CA, EE. UU., 2002. Morgan Kaufmann Publishers Inc. [14] O. Kurland y L. Lee. Estructura del corpus, modelos de lenguaje y recuperación de información ad-hoc. En SIGIR 04: Actas de la 27ª conferencia internacional anual sobre investigación y desarrollo en recuperación de información, páginas 194-201, Nueva York, NY, EE. UU., 2004. ACM Press. [15] M. Montague y J. A. Aslam. Normalización de la puntuación de relevancia para metabusqueda. En CIKM 01: Actas de la décima conferencia internacional sobre gestión de la información y el conocimiento, páginas 427-433, Nueva York, NY, EE. UU., 2001. ACM Press. [16] T. Qin, T.-Y. Liu, X.-D. Zhang, Z. Chen y W.-Y. I'm sorry, but \"Ma.\" is not a complete sentence. Could you please provide more context or a complete sentence for me to translate into Spanish? Un estudio de propagación de relevancia para la búsqueda en la web. En SIGIR 05: Actas de la 28ª conferencia internacional anual de ACM SIGIR sobre investigación y desarrollo en recuperación de información, páginas 408-415, Nueva York, NY, EE. UU., 2005. ACM Press. [17] I. Soboroff, C. Nicholas y P. Cahan. Sistemas de recuperación de clasificación sin juicios de relevancia. En SIGIR 01: Actas de la 24ª conferencia internacional anual de ACM SIGIR sobre investigación y desarrollo en recuperación de información, páginas 66-73, Nueva York, NY, EE. UU., 2001. ACM Press. [18] V. Vinay, I. J. Cox, N. Milic-Frayling y K. Wood. Sobre la clasificación de la efectividad de las búsquedas. En SIGIR 06: Actas de la 29ª conferencia internacional anual de ACM SIGIR sobre investigación y desarrollo en recuperación de información, páginas 398-404, Nueva York, NY, EE. UU., 2006. ACM Press. [19] Y. Zhou y W. B. Croft. Robustez del ranking: un nuevo marco para predecir el rendimiento de la consulta. En CIKM 06: Actas de la 15ª conferencia internacional de ACM sobre gestión de la información y el conocimiento, páginas 567-574, Nueva York, NY, EE. UU., 2006. ACM Press. ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "relationship of predictor": {
            "translated_key": "relación del predictor",
            "is_in_text": false,
            "original_annotated_sentences": [
                "Performance Prediction Using Spatial Autocorrelation Fernando Diaz Center for Intelligent Information Retrieval Department of Computer Science University of Massachusetts Amherst, MA 01003 fdiaz@cs.umass.edu ABSTRACT Evaluation of information retrieval systems is one of the core tasks in information retrieval.",
                "Problems include the inability to exhaustively label all documents for a topic, nongeneralizability from a small number of topics, and incorporating the variability of retrieval systems.",
                "Previous work addresses the evaluation of systems, the ranking of queries by difficulty, and the ranking of individual retrievals by performance.",
                "Approaches exist for the case of few and even no relevance judgments.",
                "Our focus is on zero-judgment performance prediction of individual retrievals.",
                "One common shortcoming of previous techniques is the assumption of uncorrelated document scores and judgments.",
                "If documents are embedded in a high-dimensional space (as they often are), we can apply techniques from spatial data analysis to detect correlations between document scores.",
                "We find that the low correlation between scores of topically close documents often implies a poor retrieval performance.",
                "When compared to a state of the art baseline, we demonstrate that the spatial analysis of retrieval scores provides significantly better prediction performance.",
                "These new predictors can also be incorporated with classic predictors to improve performance further.",
                "We also describe the first large-scale experiment to evaluate zero-judgment performance prediction for a massive number of retrieval systems over a variety of collections in several languages.",
                "Categories and Subject Descriptors H.3.3 [Information Search and Retrieval]: Retrieval models; H.3.4 [Systems and Software]: Performance evaluation (efficiency and effectiveness) General Terms Performance, Design, Reliability, Experimentation 1.",
                "INTRODUCTION In information retrieval, a user poses a query to a system.",
                "The system retrieves n documents each receiving a realvalued score indicating the predicted degree of relevance.",
                "If we randomly select pairs of documents from this set, we expect some pairs to share the same topic and other pairs to not share the same topic.",
                "Take two topically-related documents from the set and call them a and b.",
                "If the scores of a and b are very different, we may be concerned about the performance of our system.",
                "That is, if a and b are both on the topic of the query, we would like them both to receive a high score; if a and b are not on the topic of the query, we would like them both to receive a low score.",
                "We might become more worried as we find more differences between scores of related documents.",
                "We would be more comfortable with a retrieval where scores are consistent between related documents.",
                "Our paper studies the quantification of this inconsistency in a retrieval from a spatial perspective.",
                "Spatial analysis is appropriate since many retrieval models embed documents in some vector space.",
                "If documents are embedded in a space, proximity correlates with topical relationships.",
                "Score consistency can be measured by the spatial version of autocorrelation known as the Moran coefficient or IM [5, 10].",
                "In this paper, we demonstrate a strong correlation between IM and retrieval performance.",
                "The discussion up to this point is reminiscent of the cluster hypothesis.",
                "The cluster hypothesis states: closely-related documents tend to be relevant to the same request [12].",
                "As we shall see, a retrieval functions spatial autocorrelation measures the degree to which closely-related documents receive similar scores.",
                "Because of this, we interpret autocorrelation as measuring the degree to which a retrieval function satisfies the clustering hypothesis.",
                "If this connection is reasonable, in Section 6, we present evidence that failure to satisfy the cluster hypothesis correlates strongly with poor performance.",
                "In this work, we provide the following contributions, 1.",
                "A general, robust method for predicting the performance of retrievals with zero relevance judgments (Section 3). 2.",
                "A theoretical treatment of the similarities and motivations behind several state-of-the-art performance prediction techniques (Section 4). 3.",
                "The first large-scale experiments of zero-judgment, single run performance prediction (Sections 5 and 6). 2.",
                "PROBLEM DEFINITION Given a query, an information retrieval system produces a ranking of documents in the collection encoded as a set of scores associated with documents.",
                "We refer to the set of scores for a particular query-system combination as a retrieval.",
                "We would like to predict the performance of this retrieval with respect to some evaluation measure (eg, mean average precision).",
                "In this paper, we present results for ranking retrievals from arbitrary systems.",
                "We would like this ranking to approximate the ranking of retrievals by the evaluation measure.",
                "This is different from ranking queries by the average performance on each query.",
                "It is also different from ranking systems by the average performance on a set of queries.",
                "Scores are often only computed for the top n documents from the collection.",
                "We place these scores in the length n vector, y, where yi refers to the score of the ith-ranked document.",
                "We adjust scores to have zero mean and unit variance.",
                "We use this method because of its simplicity and its success in previous work [15]. 3.",
                "SPATIAL CORRELATION In information retrieval, we often assume that the representations of documents exist in some high-dimensional vector space.",
                "For example, given a vocabulary, V, this vector space may be an arbitrary |V|-dimensional space with cosine inner-product or a multinomial simplex with a distributionbased distance measure.",
                "An embedding space is often selected to respect topical proximity; if two documents are near, they are more likely to share a topic.",
                "Because of the prevalence and success of spatial models of information retrieval, we believe that the application of spatial data analysis techniques are appropriate.",
                "Whereas in information retrieval, we are concerned with the score at a point in a space, in spatial data analysis, we are concerned with the value of a function at a point or location in a space.",
                "We use the term function here to mean a mapping from a location to a real value.",
                "For example, we might be interested in the prevalence of a disease in the neighborhood of some city.",
                "The function would map the location of a neighborhood to an infection rate.",
                "If we want to quantify the spatial dependencies of a function, we would employ a measure referred to as the spatial autocorrelation [5, 10].",
                "High spatial autocorrelation suggests that knowing the value of a function at location a will tell us a great deal about the value at a neighboring location b.",
                "There is a high spatial autocorrelation for a function representing the temperature of a location since knowing the temperature at a location a will tell us a lot about the temperature at a neighboring location b.",
                "Low spatial autocorrelation suggests that knowing the value of a function at location a tells us little about the value at a neighboring location b.",
                "There is low spatial autocorrelation in a function measuring the outcome of a coin toss at a and b.",
                "In this section, we will begin by describing what we mean by spatial proximity for documents and then define a measure of spatial autocorrelation.",
                "We conclude by extending this model to include information from multiple retrievals from multiple systems for a single query. 3.1 Spatial Representation of Documents Our work does not focus on improving a specific similarity measure or defining a novel vector space.",
                "Instead, we choose an inner product known to be effective at detecting interdocument topical relationships.",
                "Specifically, we adopt tf.idf document vectors, ˜di = di log „ (n + 0.5) − ci 0.5 + ci « (1) where d is a vector of term frequencies, c is the length-|V| document frequency vector.",
                "We use this weighting scheme due to its success for topical link detection in the context of Topic Detection and Tracking (TDT) evaluations [6].",
                "Assuming vectors are scaled by their L2 norm, we use the inner product, ˜di, ˜dj , to define similarity.",
                "Given documents and some similarity measure, we can construct a matrix which encodes the similarity between pairs of documents.",
                "Recall that we are given the top n documents retrieved in y.",
                "We can compute an n × n similarity matrix, W. An element of this matrix, Wij represents the similarity between documents ranked i and j.",
                "In practice, we only include the affinities for a documents k-nearest neighbors.",
                "In all of our experiments, we have fixed k to 5.",
                "We leave exploration of parameter sensitivity to future work.",
                "We also row normalize the matrix so that Pn j=1 Wij = 1 for all i. 3.2 Spatial Autocorrelation of a Retrieval Recall that we are interested in measuring the similarity between the scores of spatially-close documents.",
                "One such suitable measure is the Moran coefficient of spatial autocorrelation.",
                "Assuming the function y over n locations, this is defined as ˜IM = n eTWe P i,j Wijyiyj P i y2 i = n eTWe yT Wy yTy (2) where eT We = P ij Wij.",
                "We would like to compare autocorrelation values for different retrievals.",
                "Unfortunately, the bound for Equation 2 is not consistent for different W and y.",
                "Therefore, we use the Cauchy-Schwartz inequality to establish a bound, ˜IM ≤ n eTWe s yTWTWy yTy And we define the normalized spatial autocorrelation as IM = yT Wy p yTy × yTWTWy Notice that if we let ˜y = Wy, then we can write this formula as, IM = yT ˜y y 2 ˜y 2 (3) which can be interpreted as the correlation between the original retrieval scores and a set of retrieval scores diffused in the space.",
                "We present some examples of autocorrelations of functions on a grid in Figure 1. 3.3 Correlation with Other Retrievals Sometimes we are interested in the performance of a single retrieval but have access to scores from multiple systems for (a) IM = 0.006 (b) IM = 0.241 (c) IM = 0.487 Figure 1: The Moran coefficient, IM for a several binary functions on a grid.",
                "The Moran coefficient is a local measure of function consistency.",
                "From the perspective of information retrieval, each of these grid spaces would represent a document and documents would be organized so that they lay next to topically-related documents.",
                "Binary retrieval scores would define a pattern on this grid.",
                "Notice that, as the Moran coefficient increases, neighboring cells tend to have similar values. the same query.",
                "In this situation, we can use combined information from these scores to construct a surrogate for a high-quality ranking [17].",
                "We can treat the correlation between the retrieval we are interested in and the combined scores as a predictor of performance.",
                "Assume that we are given m score functions, yi, for the same n documents.",
                "We will represent the mean of these vectors as yµ = Pm i=1 yi.",
                "We use the mean vector as an approximation to relevance.",
                "Since we use zero mean and unit variance normalization, work in metasearch suggests that this assumption is justified [15].",
                "Because yµ represents a very good retrieval, we hypothesize that a strong similarity between yµ and y will correlate positively with system performance.",
                "We use Pearsons product-moment correlation to measure the similarity between these vectors, ρ(y, yµ) = yT yµ y 2 yµ 2 (4) We will comment on the similarity between Equation 3 and 4 in Section 7.",
                "Of course, we can combine ρ(y, ˜y) and ρ(y, yµ) if we assume that they capture different factors in the prediction.",
                "One way to accomplish this is to combine these predictors as independent variables in a linear regression.",
                "An alternative means of combination is suggested by the mathematical form of our predictors.",
                "Since ˜y encodes the spatial dependencies in y and yµ encodes the spatial properties of the multiple runs, we can compute a third correlation between these two vectors, ρ(˜y, yµ) = ˜yT yµ ˜y 2 yµ 2 (5) We can interpret Equation 5 as measuring the correlation between a high quality ranking (yµ) and a spatially smoothed version of the retrieval (˜y). 4.",
                "RELATIONSHIP WITH OTHER PREDICTORS One way to predict the effectiveness of a retrieval is to look at the shared vocabulary of the top n retrieved documents.",
                "If we computed the most frequent content words in this set, we would hope that they would be consistent with our topic.",
                "In fact, we might believe that a bad retrieval would include documents on many disparate topics, resulting in an overlap of terminological noise.",
                "The Clarity of a query attempts to quantify exactly this [7].",
                "Specifically, Clarity measures the similarity of the words most frequently used in retrieved documents to those most frequently used in the whole corpus.",
                "The conjecture is that a good retrieval will use language distinct from general text; the overlapping language in a bad retrieval will tend to be more similar to general text.",
                "Mathematically, we can compute a representation of the language used in the initial retrieval as a weighted combination of document language models, P(w|θQ) = nX i=1 P(w|θi) P(Q|θi) Z (6) where θi is the language model of the ith-ranked document, P(Q|θi) is the query likelihood score of the ith-ranked document and Z = Pn i=1 P(Q|θi) is a normalization constant.",
                "The similarity between the multinomial P(w|θQ) and a model of general text can be computed using the Kullback-Leibler divergence, DV KL(θQ θC ).",
                "Here, the distribution P(w|θC ) is our model of general text which can be computed using term frequencies in the corpus.",
                "In Figure 2a, we present Clarity as measuring the distance between the weighted center of mass of the retrieval (labeled y) and the unweighted center of mass of the collection (labeled O).",
                "Clarity reaches a minimum when a retrieval assigns every document the same score.",
                "Lets again assume we have a set of n documents retrieved for our query.",
                "Another way to quantify the dispersion of a set of documents is to look at how clustered they are.",
                "We may hypothesize that a good retrieval will return a single, tight cluster.",
                "A poorly performing retrieval will return a loosely related set of documents covering many topics.",
                "One proposed method of quantifying this dispersion is to measure the distance from a random document a to its nearest neighbor, b.",
                "A retrieval which is tightly clustered will, on average, have a low distance between a and b; a retrieval which is less tightly-closed will, on average have high distances between a and b.",
                "This average corresponds to using the Cox-Lewis statistic to measure the randomness of the top n documents retrieved from a system [18].",
                "In Figure 2a, this is roughly equivalent to measuring the area of the set n. Notice that we are throwing away information about the retrieval function y.",
                "Therefore the Cox-Lewis statistic is highly dependent on selecting the top n documents.1 Remember that we have n documents and a set of scores.",
                "Lets assume that we have access to the system which provided the original scores and that we can also request scores for new documents.",
                "This suggests a third method for predicting performance.",
                "Take some document, a, from the retrieved set and arbitrarily add or remove words at random to create a new document ˜a.",
                "Now, we can ask our system to score ˜a with respect to our query.",
                "If, on average over the n documents, the scores of a and ˜a tend to be very different, we might suspect that the system is failing on this query.",
                "So, an alternative approach is to measure the simi1 The authors have suggested coupling the query with the distance measure [18].",
                "The information introduced by the query, though, is retrieval-independent so that, if two retrievals return the same set of documents, the approximate Cox-Lewis statistic will be the same regardless of the retrieval scores. yOy (a) Global Divergence µ(y)˜y y (b) Score Perturbation µ(y) y (c) Multirun Averaging Figure 2: Representation of several performance predictors on a grid.",
                "In Figure 2a, we depict predictors which measure the divergence between the center of mass of a retrieval and the center of the embedding space.",
                "In Figure 2b, we depict predictors which compare the original retrieval, y, to a perturbed version of the retrieval, ˜y.",
                "Our approach uses a particular type of perturbation based on score diffusion.",
                "Finally, in Figure 2c, we depict prediction when given retrievals from several other systems on the same query.",
                "Here, we can consider the fusion of these retrieval as a surrogate for relevance. larity between the retrieval and a perturbed version of that retrieval [18, 19].",
                "This can be accomplished by either perturbing the documents or queries.",
                "The similarity between the two retrievals can be measured using some correlation measure.",
                "This is depicted in Figure 2b.",
                "The upper grid represents the original retrieval, y, while the lower grid represents the function after having been perturbed, ˜y.",
                "The nature of the perturbation process requires additional scorings or retrievals.",
                "Our predictor does not require access to the original scoring function or additional retrievals.",
                "So, although our method is similar to other perturbation methods in spirit, it can be applied in situations when the retrieval system is inaccessible or costly to access.",
                "Finally, assume that we have, in addition to the retrieval we want to evaluate, m retrievals from a variety of different systems.",
                "In this case, we might take a document a, compare its rank in the retrieval to its average rank in the m retrievals.",
                "If we believe that the m retrievals provide a satisfactory approximation to relevance, then a very large difference in rank would suggest that our retrieval is misranking a.",
                "If this difference is large on average over all n documents, then we might predict that the retrieval is bad.",
                "If, on the other hand, the retrieval is very consistent with the m retrievals, then we might predict that the retrieval is good.",
                "The similarity between the retrieval and the combined retrieval may be computed using some correlation measure.",
                "This is depicted in Figure 2c.",
                "In previous work, the Kullback-Leibler divergence between the normalized scores of the retrieval and the normalized scores of the combined retrieval provides the similarity [1]. 5.",
                "EXPERIMENTS Our experiments focus on testing the predictive power of each of our predictors: ρ(y, ˜y), ρ(y, yµ), and ρ(˜y, yµ).",
                "As stated in Section 2, we are interested in predicting the performance of the retrieval generated by an arbitrary system.",
                "Our methodology is consistent with previous research in that we predict the relative performance of a retrieval by comparing a ranking based on our predictor to a ranking based on average precision.",
                "We present results for two sets of experiments.",
                "The first set of experiments presents detailed comparisons of our predictors to previously-proposed predictors using identical data sets.",
                "Our second set of experiments demonstrates the generalizability of our approach to arbitrary retrieval methods, corpus types, and corpus languages. 5.1 Detailed Experiments In these experiments, we will predict the performance of language modeling scores using our autocorrelation predictor, ρ(y, ˜y); we do not consider ρ(y, yµ) or ρ(˜y, yµ) because, in these detailed experiments, we focus on ranking the retrievals from a single system.",
                "We use retrievals, values for baseline predictors, and evaluation measures reported in previous work [19]. 5.1.1 Topics and Collections These performance prediction experiments use language model retrievals performed for queries associated with collections in the TREC corpora.",
                "Using TREC collections allows us to confidently associate an average precision with a retrieval.",
                "In these experiments, we use the following topic collections: TREC 4 ad-hoc, TREC 5 ad-hoc, Robust 2004, Terabyte 2004, and Terabyte 2005. 5.1.2 Baselines We provide two baselines.",
                "Our first baseline is the classic Clarity predictor presented in Equation 6.",
                "Clarity is designed to be used with language modeling systems.",
                "Our second baseline is Zhou and Crofts ranking robustness predictor.",
                "This predictor corrupts the top k documents from retrieval and re-computes the language model scores for these corrupted documents.",
                "The value of the predictor is the Spearman rank correlation between the original ranking and the corrupted ranking.",
                "In our tables, we will label results for Clarity using DV KL and the ranking robustness predictor using P. 5.2 Generalizability Experiments Our predictors do not require a particular baseline retrieval system; the predictors can be computed for an arbitrary retrieval, regardless of how scores were generated.",
                "We believe that that is one of the most attractive aspects of our algorithm.",
                "Therefore, in a second set of experiments, we demonstrate the ability of our techniques to generalize to a variety of collections, topics, and retrieval systems. 5.2.1 Topics and Collections We gathered a diverse set of collections from all possible TREC corpora.",
                "We cast a wide net in order to locate collections where our predictors might fail.",
                "Our hypothesis is that documents with high topical similarity should have correlated scores.",
                "Therefore, we avoided collections where scores were unlikely to be correlated (eg, question-answering) or were likely to be negatively correlated (eg, novelty).",
                "Nevertheless, our collections include corpora where correlations are weakly justified (eg, non-English corpora) or not justified at all (eg, expert search).",
                "We use the ad-hoc tracks from TREC3-8, TREC Robust 2003-2005, TREC Terabyte 20042005, TREC4-5 Spanish, TREC5-6 Chinese, and TREC Enterprise Expert Search 2005.",
                "In all cases, we use only the automatic runs for ad-hoc tracks submitted to NIST.",
                "For all English and Spanish corpora, we construct the matrix W according to the process described in Section 3.1.",
                "For Chinese corpora, we use na¨ıve character-based tf.idf vectors.",
                "For entities, entries in W are proportional to the number of documents in which two entities cooccur. 5.2.2 Baselines In our detailed experiments, we used the Clarity measure as a baseline.",
                "Since we are predicting the performance of retrievals which are not based on language modeling, we use a version of Clarity referred to as ranked-list Clarity [7].",
                "Ranked-list clarity converts document ranks to P(Q|θi) values.",
                "This conversion begins by replacing all of the scores in y with the respective ranks.",
                "Our estimation of P(Q|θi) from the ranks, then is, P(Q|θi) = ( 2(c+1−yi) c(c+1) if yi ≤ c 0 otherwise (7) where c is a cutoff parameter.",
                "As suggested by the authors, we fix the algorithm parameters c and λ2 so that c = 60 and λ2 = 0.10.",
                "We use Equation 6 to estimate P(w|θQ) and DV KL(θQ θC ) to compute the value of the predictor.",
                "We will refer to this predictor as DV KL, superscripted by V to indicate that the Kullback-Leibler divergence is with respect to the term embedding space.",
                "When information from multiple runs on the same query is available, we use Aslam and Pavlus document-space multinomial divergence as a baseline [1].",
                "This rank-based method first normalizes the scores in a retrieval as an n-dimensional multinomial.",
                "As with ranked-list Clarity, we begin by replacing all of the scores in y with their respective ranks.",
                "Then, we adjust the elements of y in the following way, ˆyi = 1 2n 0 @1 + nX k=yi 1 k 1 A (8) In our multirun experiments, we only use the top 75 documents from each retrieval (n = 75); this is within the range of parameter values suggested by the authors.",
                "However, we admit not tuning this parameter for either our system or the baseline.",
                "The predictor is the divergence between the candidate distribution, y, and the mean distribution, yµ .",
                "With the uniform linear combination of these m retrievals represented as yµ, we can compute the divergence as Dn KL(ˆy ˆyµ) where we use the superscript n to indicate that the summation is over the set of n documents.",
                "This baseline was developed in the context of predicting query difficulty but we adopt it as a reasonable baseline for predicting retrieval performance. 5.2.3 Parameter Settings When given multiple retrievals, we use documents in the union of the top k = 75 documents from each of the m retrievals for that query.",
                "If the size of this union is ˜n, then yµ and each yi is of length ˜n.",
                "In some cases, a system did not score a document in the union.",
                "Since we are making a Gaussian assumption about our scores, we can sample scores for these unseen documents from the negative tail of the distribution.",
                "Specifically, we sample from the part of the distribution lower than the minimum value of in the normalized retrieval.",
                "This introduces randomness into our algorithm but we believe it is more appropriate than assigning an arbitrary fixed value.",
                "We optimized the linear regression using the square root of each predictor.",
                "We found that this substantially improved fits for all predictors, including the baselines.",
                "We considered linear combinations of pairs of predictors (labeled by the components) and all predictors (labeled as β). 5.3 Evaluation Given a set of retrievals, potentially from a combination of queries and systems, we measure the correlation of the rank ordering of this set by the predictor and by the performance metric.",
                "In order to ensure comparability with previous results, we present Kendalls τ correlation between the predictors ranking and ranking based on average precision of the retrieval.",
                "Unless explicitly noted, all correlations are significant with p < 0.05.",
                "Predictors can sometimes perform better when linearly combined [9, 11].",
                "Although previous work has presented the coefficient of determination (R2 ) to measure the quality of the regression, this measure cannot be reliably used when comparing slight improvements from combining predictors.",
                "Therefore, we adopt the adjusted coefficient of determination which penalizes models with more variables.",
                "The adjusted R2 allows us to evaluate the improvement in prediction achieved by adding a parameter but loses the statistical interpretation of R2 .",
                "We will use Kendalls τ to evaluate the magnitude of the correlation and the adjusted R2 to evaluate the combination of variables. 6.",
                "RESULTS We present results for our detailed experiments comparing the prediction of language model scores in Table 1.",
                "Although the Clarity measure is theoretically designed for language model scores, it consistently underperforms our system-agnostic predictor.",
                "Ranking robustness was presented as an improvement to Clarity for web collections (represented in our experiments by the terabyte04 and terabyte05 collections), shifting the τ correlation from 0.139 to 0.150 for terabyte04 and 0.171 to 0.208 for terabyte05.",
                "However, these improvements are slight compared to the performance of autocorrelation on these collections.",
                "Our predictor achieves a τ correlation of 0.454 for terabyte04 and 0.383 for terabyte05.",
                "Though not always the strongest, autocorrelation achieves correlations competitive with baseline predictors.",
                "When examining the performance of linear combinations of predictors, we note that in every case, autocorrelation factors as a necessary component of a strong predictor.",
                "We also note that the adjusted R2 for individual baselines are always significantly improved by incorporating autocorrelation.",
                "We present our generalizability results in Table 2.",
                "We begin by examining the situation in column (a) where we are presented with a single retrieval and no information from additional retrievals.",
                "For every collection except one, we achieve significantly better correlations than ranked-list Clarity.",
                "Surprisingly, we achieve relatively strong correlations for Spanish and Chinese collections despite our na¨ıve processing.",
                "We do not have a ranked-list clarity correlation for ent05 because entity modeling is itself an open research question.",
                "However, our autocorrelation measure does not achieve high correlations perhaps because relevance for entity retrieval does not propagate according to the cooccurrence links we use.",
                "As noted above, the poor Clarity performance on web data is consistent with our findings in the detailed experiments.",
                "Clarity also notably underperforms for several news corpora (trec5, trec7, and robust04).",
                "On the other hand, autocorrelation seems robust to the changes between different corpora.",
                "Next, we turn to the introduction of information from multiple retrievals.",
                "We compare the correlations between those predictors which do not use this information in column (a) and those which do in column (b).",
                "For every collection, the predictors in column (b) outperform the predictors in column (a), indicating that the information from additional runs can be critical to making good predictions.",
                "Inspecting the predictors in column (b), we only draw weak conclusions.",
                "Our new predictors tend to perform better on news corpora.",
                "And between our new predictors, the hybrid ρ(˜y, yµ) predictor tends to perform better.",
                "Recall that our ρ(˜y, yµ) measure incorporates both spatial and multiple retrieval information.",
                "Therefore, we believe that the improvement in correlation is the result of incorporating information from spatial behavior.",
                "In column (c), we can investigate the utility of incorporating spatial information with information from multiple retrievals.",
                "Notice that in the cases where autocorrelation, ρ(y, ˜y), alone performs well (trec3, trec5-spanish, and trec6-chinese), it is substantially improved by incorporating multiple-retrieval information from ρ(y, yµ) in the linear regression, β.",
                "In the cases where ρ(y, yµ) performs well, incorporating autocorrelation rarely results in a significant improvement in performance.",
                "In fact, in every case where our predictor outperforms the baseline, it includes information from multiple runs. 7.",
                "DISCUSSION The most important result from our experiments involves prediction when no information is available from multiple runs (Tables 1 and 2a).",
                "This situation arises often in system design.",
                "For example, a system may need to, at retrieval time, assess its performance before deciding to conduct more intensive processing such as pseudo-relevance feedback or interaction.",
                "Assuming the presence of multiple retrievals is unrealistic in this case.",
                "We believe that autocorrelation is, like multiple-retrieval algorithms, approximating a good ranking; in this case by diffusing scores.",
                "Why is ˜y a reasonable surrogate?",
                "We know that diffusion of scores on the web graph and language model graphs improves performance [14, 16].",
                "Therefore, if score diffusion tends to, in general, improve performance, then diffused scores will, in general, provide a good surrogate for relevance.",
                "Our results demonstrate that this approximation is not as powerful as information from multiple retrievals.",
                "Nevertheless, in situations where this information is lacking, autocorrelation provides substantial information.",
                "The success of autocorrelation as a predictor may also have roots in the clustering hypothesis.",
                "Recall that we regard autocorrelation as the degree to which a retrieval satisfies the clustering hypothesis.",
                "Our experiments, then, demonstrate that a failure to respect the clustering hypothesis correlates with poor performance.",
                "Why might systems fail to conform to the cluster hypothesis?",
                "Query-based information retrieval systems often score documents independently.",
                "The score of document a may be computed by examining query term or phrase matches, the document length, and perhaps global collection statistics.",
                "Once computed, a system rarely compares the score of a to the score of a topically-related document b.",
                "With some exceptions, the correlation of document scores has largely been ignored.",
                "We should make it clear that we have selected tasks where topical autocorrelation is appropriate.",
                "There are certainly cases where there is no reason to believe that retrieval scores will have topical autocorrelation.",
                "For example, ranked lists which incorporate document novelty should not exhibit spatial autocorrelation; if anything autocorrelation should be negative for this task.",
                "Similarly, answer candidates in a question-answering task may or may not exhibit autocorrelation; in this case, the semantics of links is questionable too.",
                "It is important before applying this measure to confirm that, given the semantics for some link between two retrieved items, we should expect a correlation between scores. 8.",
                "RELATED WORK In this section we draw more general comparisons to other work in performance prediction and spatial data analysis.",
                "There is a growing body of work which attempts to predict the performance of individual retrievals [7, 3, 11, 9, 19].",
                "We have attempted to place our work in the context of much of this work in Section 4.",
                "However, a complete comparison is beyond the scope of this paper.",
                "We note, though, that our experiments cover a larger and more diverse set of retrievals, collections, and topics than previously examined.",
                "Much previous work-particularly in the context of TRECfocuses on predicting the performance of systems.",
                "Here, each system generates k retrievals.",
                "The task is, given these retrievals, to predict the ranking of systems according to some performance measure.",
                "Several papers attempt to address this task under the constraint of few judgments [2, 4].",
                "Some work even attempts to use zero judgments by leveraging multiple retrievals for the same query [17].",
                "Our task differs because we focus on ranking retrievals independent of the generating system.",
                "The task here is not to test the hypothesis system A is superior to system B but to test the hypothesis retrieval A is superior to retrieval B. Autocorrelation manifests itself in many classification tasks.",
                "Neville and Jensen define relational autocorrelation for relational learning problems and demonstrate that many classification tasks manifest autocorrelation [13].",
                "Temporal autocorrelation of initial retrievals has also been used to predict performance [9].",
                "However, temporal autocorrelation is performed by projecting the retrieval function into the temporal embedding space.",
                "In our work, we focus on the behavior of the function over the relationships between documents. τ adjusted R2 DV KL P ρ(y, ˜y) DV KL P ρ(y, ˜y) DV KL, P DV KL, ρ(y, ˜y) Pρ(y, ˜y) β trec4 0.353 0.548 0.513 0.168 0.363 0.422 0.466 0.420 0.557 0.553 trec5 0.311 0.329 0.357 0.116 0.190 0.236 0.238 0.244 0.266 0.269 robust04 0.418 0.398 0.373 0.256 0.304 0.278 0.403 0.373 0.402 0.442 terabyte04 0.139 0.150 0.454 0.059 0.045 0.292 0.076 0.293 0.289 0.284 terabyte05 0.171 0.208 0.383 0.022 0.072 0.193 0.120 0.225 0.218 0.257 Table 1: Comparison to Robustness and Clarity measures for language model scores.",
                "Evaluation replicates experiments from [19].",
                "We present correlations between the classic Clarity measure (DV KL), the ranking robustness measure (P), and autocorrelation (ρ(y, ˜y)) each with mean average precision in terms of Kendalls τ.",
                "The adjusted coefficient of determination is presented to measure the effectiveness of combining predictors.",
                "Measures in bold represent the strongest correlation for that test/collection pair. multiple run (a) (b) (c) τ τ adjusted R2 DKL ρ(y, ˜y) Dn KL ρ(y, yµ) ρ(˜y, yµ) Dn KL ρ(y, ˜y) ρ(y, yµ) ρ(˜y, yµ) β trec3 0.201 0.461 0.461 0.439 0.456 0.444 0.395 0.394 0.386 0.498 trec4 0.252 0.396 0.455 0.482 0.489 0.379 0.263 0.429 0.482 0.483 trec5 0.016 0.277 0.433 0.459 0.393 0.280 0.157 0.375 0.323 0.386 trec6 0.230 0.227 0.352 0.428 0.418 0.203 0.089 0.323 0.325 0.325 trec7 0.083 0.326 0.341 0.430 0.483 0.264 0.182 0.363 0.442 0.400 trec8 0.235 0.396 0.454 0.508 0.567 0.402 0.272 0.490 0.580 0.523 robust03 0.302 0.354 0.377 0.385 0.447 0.269 0.206 0.274 0.392 0.303 robust04 0.183 0.308 0.301 0.384 0.453 0.200 0.182 0.301 0.393 0.335 robust05 0.224 0.249 0.371 0.377 0.404 0.341 0.108 0.313 0.328 0.336 terabyte04 0.043 0.245 0.544 0.420 0.392 0.516 0.105 0.357 0.343 0.365 terabyte05 0.068 0.306 0.480 0.434 0.390 0.491 0.168 0.384 0.309 0.403 trec4-spanish 0.307 0.388 0.488 0.398 0.395 0.423 0.299 0.282 0.299 0.388 trec5-spanish 0.220 0.458 0.446 0.484 0.475 0.411 0.398 0.428 0.437 0.529 trec5-chinese 0.092 0.199 0.367 0.379 0.384 0.379 0.199 0.273 0.276 0.310 trec6-chinese 0.144 0.276 0.265 0.353 0.376 0.115 0.128 0.188 0.223 0.199 ent05 - 0.181 0.324 0.305 0.282 0.211 0.043 0.158 0.155 0.179 Table 2: Large scale prediction experiments.",
                "We predict the ranking of large sets of retrievals for various collections and retrieval systems.",
                "Kendalls τ correlations are computed between the predicted ranking and a ranking based on the retrievals average precision.",
                "In column (a), we have predictors which do not use information from other retrievals for the same query.",
                "In columns (b) and (c) we present performance for predictors which incorporate information from multiple retrievals.",
                "The adjusted coefficient of determination is computed to determine effectiveness of combining predictors.",
                "Measures in bold represent the strongest correlation for that test/collection pair.",
                "Finally, regularization-based re-ranking processes are also closely-related to our work [8].",
                "These techniques seek to maximize the agreement between scores of related documents by solving a constrained optimization problem.",
                "The maximization of consistency is equivalent to maximizing the Moran autocorrelation.",
                "Therefore, we believe that our work provides explanation for why regularization-based re-ranking works. 9.",
                "CONCLUSION We have presented a new method for predicting the performance of a retrieval ranking without any relevance judgments.",
                "We consider two cases.",
                "First, when making predictions in the absence of retrievals from other systems, our predictors demonstrate robust, strong correlations with average precision.",
                "This performance, combined with a simple implementation, makes our predictors, in particular, very attractive.",
                "We have demonstrated this improvement for many, diverse settings.",
                "To our knowledge, this is the first large scale examination of zero-judgment, single-retrieval performance prediction.",
                "Second, when provided retrievals from other systems, our extended methods demonstrate competitive performance with state of the art baselines.",
                "Our experiments also demonstrate the limits of the usefulness of our predictors when information from multiple runs is provided.",
                "Our results suggest two conclusions.",
                "First, our results could affect retrieval algorithm design.",
                "Retrieval algorithms designed to consider spatial autocorrelation will conform to the cluster hypothesis and improve performance.",
                "Second, our results could affect the design of minimal test collection algorithms.",
                "Much of the recent work in ranking systems sometimes ignores correlations between document labels and scores.",
                "We believe that these two directions could be rewarding given the theoretical and experimental evidence in this paper. 10.",
                "ACKNOWLEDGMENTS This work was supported in part by the Center for Intelligent Information Retrieval and in part by the Defense Advanced Research Projects Agency (DARPA) under contract number HR0011-06-C-0023.",
                "Any opinions, findings and conclusions or recommendations expressed in this material are the authors and do not necessarily reflect those of the sponsor.",
                "We thank Yun Zhou and Desislava Petkova for providing data and Andre Gauthier for technical assistance. 11.",
                "REFERENCES [1] J. Aslam and V. Pavlu.",
                "Query hardness estimation using jensen-shannon divergence among multiple scoring functions.",
                "In ECIR 2007: Proceedings of the 29th European Conference on Information Retrieval, 2007. [2] J.",
                "A. Aslam, V. Pavlu, and E. Yilmaz.",
                "A statistical method for system evaluation using incomplete judgments.",
                "In S. Dumais, E. N. Efthimiadis, D. Hawking, and K. Jarvelin, editors, Proceedings of the 29th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 541-548.",
                "ACM Press, August 2006. [3] D. Carmel, E. Yom-Tov, A. Darlow, and D. Pelleg.",
                "What makes a query difficult?",
                "In SIGIR 06: Proceedings of the 29th annual international ACM SIGIR conference on Research and development in information retrieval, pages 390-397, New York, NY, USA, 2006.",
                "ACM Press. [4] B. Carterette, J. Allan, and R. Sitaraman.",
                "Minimal test collections for retrieval evaluation.",
                "In SIGIR 06: Proceedings of the 29th annual international ACM SIGIR conference on Research and development in information retrieval, pages 268-275, New York, NY, USA, 2006.",
                "ACM Press. [5] A. D. Cliff and J. K. Ord.",
                "Spatial Autocorrelation.",
                "Pion Ltd., 1973. [6] M. Connell, A. Feng, G. Kumaran, H. Raghavan, C. Shah, and J. Allan.",
                "Umass at tdt 2004.",
                "Technical Report CIIR Technical Report IR - 357, Department of Computer Science, University of Massachusetts, 2004. [7] S. Cronen-Townsend, Y. Zhou, and W. B. Croft.",
                "Precision prediction based on ranked list coherence.",
                "Inf.",
                "Retr., 9(6):723-755, 2006. [8] F. Diaz.",
                "Regularizing ad-hoc retrieval scores.",
                "In CIKM 05: Proceedings of the 14th ACM international conference on Information and knowledge management, pages 672-679, New York, NY, USA, 2005.",
                "ACM Press. [9] F. Diaz and R. Jones.",
                "Using temporal profiles of queries for precision prediction.",
                "In SIGIR 04: Proceedings of the 27th annual international ACM SIGIR conference on Research and development in information retrieval, pages 18-24, New York, NY, USA, 2004.",
                "ACM Press. [10] D. A. Griffith.",
                "Spatial Autocorrelation and Spatial Filtering.",
                "Springer Verlag, 2003. [11] B.",
                "He and I. Ounis.",
                "Inferring Query Performance Using Pre-retrieval Predictors.",
                "In The Eleventh Symposium on String Processing and Information Retrieval (SPIRE), 2004. [12] N. Jardine and C. J. V. Rijsbergen.",
                "The use of hierarchic clustering in information retrieval.",
                "Information Storage and Retrieval, 7:217-240, 1971. [13] D. Jensen and J. Neville.",
                "Linkage and autocorrelation cause feature selection bias in relational learning.",
                "In ICML 02: Proceedings of the Nineteenth International Conference on Machine Learning, pages 259-266, San Francisco, CA, USA, 2002.",
                "Morgan Kaufmann Publishers Inc. [14] O. Kurland and L. Lee.",
                "Corpus structure, language models, and ad-hoc information retrieval.",
                "In SIGIR 04: Proceedings of the 27th annual international conference on Research and development in information retrieval, pages 194-201, New York, NY, USA, 2004.",
                "ACM Press. [15] M. Montague and J.",
                "A. Aslam.",
                "Relevance score normalization for metasearch.",
                "In CIKM 01: Proceedings of the tenth international conference on Information and knowledge management, pages 427-433, New York, NY, USA, 2001.",
                "ACM Press. [16] T. Qin, T.-Y.",
                "Liu, X.-D. Zhang, Z. Chen, and W.-Y.",
                "Ma.",
                "A study of relevance propagation for web search.",
                "In SIGIR 05: Proceedings of the 28th annual international ACM SIGIR conference on Research and development in information retrieval, pages 408-415, New York, NY, USA, 2005.",
                "ACM Press. [17] I. Soboroff, C. Nicholas, and P. Cahan.",
                "Ranking retrieval systems without relevance judgments.",
                "In SIGIR 01: Proceedings of the 24th annual international ACM SIGIR conference on Research and development in information retrieval, pages 66-73, New York, NY, USA, 2001.",
                "ACM Press. [18] V. Vinay, I. J. Cox, N. Milic-Frayling, and K. Wood.",
                "On ranking the effectiveness of searches.",
                "In SIGIR 06: Proceedings of the 29th annual international ACM SIGIR conference on Research and development in information retrieval, pages 398-404, New York, NY, USA, 2006.",
                "ACM Press. [19] Y. Zhou and W. B. Croft.",
                "Ranking robustness: a novel framework to predict query performance.",
                "In CIKM 06: Proceedings of the 15th ACM international conference on Information and knowledge management, pages 567-574, New York, NY, USA, 2006.",
                "ACM Press."
            ],
            "original_annotated_samples": [],
            "translated_annotated_samples": [],
            "translated_text": "",
            "candidates": [],
            "error": [
                []
            ]
        },
        "predictor relationship": {
            "translated_key": "relación predictiva",
            "is_in_text": false,
            "original_annotated_sentences": [
                "Performance Prediction Using Spatial Autocorrelation Fernando Diaz Center for Intelligent Information Retrieval Department of Computer Science University of Massachusetts Amherst, MA 01003 fdiaz@cs.umass.edu ABSTRACT Evaluation of information retrieval systems is one of the core tasks in information retrieval.",
                "Problems include the inability to exhaustively label all documents for a topic, nongeneralizability from a small number of topics, and incorporating the variability of retrieval systems.",
                "Previous work addresses the evaluation of systems, the ranking of queries by difficulty, and the ranking of individual retrievals by performance.",
                "Approaches exist for the case of few and even no relevance judgments.",
                "Our focus is on zero-judgment performance prediction of individual retrievals.",
                "One common shortcoming of previous techniques is the assumption of uncorrelated document scores and judgments.",
                "If documents are embedded in a high-dimensional space (as they often are), we can apply techniques from spatial data analysis to detect correlations between document scores.",
                "We find that the low correlation between scores of topically close documents often implies a poor retrieval performance.",
                "When compared to a state of the art baseline, we demonstrate that the spatial analysis of retrieval scores provides significantly better prediction performance.",
                "These new predictors can also be incorporated with classic predictors to improve performance further.",
                "We also describe the first large-scale experiment to evaluate zero-judgment performance prediction for a massive number of retrieval systems over a variety of collections in several languages.",
                "Categories and Subject Descriptors H.3.3 [Information Search and Retrieval]: Retrieval models; H.3.4 [Systems and Software]: Performance evaluation (efficiency and effectiveness) General Terms Performance, Design, Reliability, Experimentation 1.",
                "INTRODUCTION In information retrieval, a user poses a query to a system.",
                "The system retrieves n documents each receiving a realvalued score indicating the predicted degree of relevance.",
                "If we randomly select pairs of documents from this set, we expect some pairs to share the same topic and other pairs to not share the same topic.",
                "Take two topically-related documents from the set and call them a and b.",
                "If the scores of a and b are very different, we may be concerned about the performance of our system.",
                "That is, if a and b are both on the topic of the query, we would like them both to receive a high score; if a and b are not on the topic of the query, we would like them both to receive a low score.",
                "We might become more worried as we find more differences between scores of related documents.",
                "We would be more comfortable with a retrieval where scores are consistent between related documents.",
                "Our paper studies the quantification of this inconsistency in a retrieval from a spatial perspective.",
                "Spatial analysis is appropriate since many retrieval models embed documents in some vector space.",
                "If documents are embedded in a space, proximity correlates with topical relationships.",
                "Score consistency can be measured by the spatial version of autocorrelation known as the Moran coefficient or IM [5, 10].",
                "In this paper, we demonstrate a strong correlation between IM and retrieval performance.",
                "The discussion up to this point is reminiscent of the cluster hypothesis.",
                "The cluster hypothesis states: closely-related documents tend to be relevant to the same request [12].",
                "As we shall see, a retrieval functions spatial autocorrelation measures the degree to which closely-related documents receive similar scores.",
                "Because of this, we interpret autocorrelation as measuring the degree to which a retrieval function satisfies the clustering hypothesis.",
                "If this connection is reasonable, in Section 6, we present evidence that failure to satisfy the cluster hypothesis correlates strongly with poor performance.",
                "In this work, we provide the following contributions, 1.",
                "A general, robust method for predicting the performance of retrievals with zero relevance judgments (Section 3). 2.",
                "A theoretical treatment of the similarities and motivations behind several state-of-the-art performance prediction techniques (Section 4). 3.",
                "The first large-scale experiments of zero-judgment, single run performance prediction (Sections 5 and 6). 2.",
                "PROBLEM DEFINITION Given a query, an information retrieval system produces a ranking of documents in the collection encoded as a set of scores associated with documents.",
                "We refer to the set of scores for a particular query-system combination as a retrieval.",
                "We would like to predict the performance of this retrieval with respect to some evaluation measure (eg, mean average precision).",
                "In this paper, we present results for ranking retrievals from arbitrary systems.",
                "We would like this ranking to approximate the ranking of retrievals by the evaluation measure.",
                "This is different from ranking queries by the average performance on each query.",
                "It is also different from ranking systems by the average performance on a set of queries.",
                "Scores are often only computed for the top n documents from the collection.",
                "We place these scores in the length n vector, y, where yi refers to the score of the ith-ranked document.",
                "We adjust scores to have zero mean and unit variance.",
                "We use this method because of its simplicity and its success in previous work [15]. 3.",
                "SPATIAL CORRELATION In information retrieval, we often assume that the representations of documents exist in some high-dimensional vector space.",
                "For example, given a vocabulary, V, this vector space may be an arbitrary |V|-dimensional space with cosine inner-product or a multinomial simplex with a distributionbased distance measure.",
                "An embedding space is often selected to respect topical proximity; if two documents are near, they are more likely to share a topic.",
                "Because of the prevalence and success of spatial models of information retrieval, we believe that the application of spatial data analysis techniques are appropriate.",
                "Whereas in information retrieval, we are concerned with the score at a point in a space, in spatial data analysis, we are concerned with the value of a function at a point or location in a space.",
                "We use the term function here to mean a mapping from a location to a real value.",
                "For example, we might be interested in the prevalence of a disease in the neighborhood of some city.",
                "The function would map the location of a neighborhood to an infection rate.",
                "If we want to quantify the spatial dependencies of a function, we would employ a measure referred to as the spatial autocorrelation [5, 10].",
                "High spatial autocorrelation suggests that knowing the value of a function at location a will tell us a great deal about the value at a neighboring location b.",
                "There is a high spatial autocorrelation for a function representing the temperature of a location since knowing the temperature at a location a will tell us a lot about the temperature at a neighboring location b.",
                "Low spatial autocorrelation suggests that knowing the value of a function at location a tells us little about the value at a neighboring location b.",
                "There is low spatial autocorrelation in a function measuring the outcome of a coin toss at a and b.",
                "In this section, we will begin by describing what we mean by spatial proximity for documents and then define a measure of spatial autocorrelation.",
                "We conclude by extending this model to include information from multiple retrievals from multiple systems for a single query. 3.1 Spatial Representation of Documents Our work does not focus on improving a specific similarity measure or defining a novel vector space.",
                "Instead, we choose an inner product known to be effective at detecting interdocument topical relationships.",
                "Specifically, we adopt tf.idf document vectors, ˜di = di log „ (n + 0.5) − ci 0.5 + ci « (1) where d is a vector of term frequencies, c is the length-|V| document frequency vector.",
                "We use this weighting scheme due to its success for topical link detection in the context of Topic Detection and Tracking (TDT) evaluations [6].",
                "Assuming vectors are scaled by their L2 norm, we use the inner product, ˜di, ˜dj , to define similarity.",
                "Given documents and some similarity measure, we can construct a matrix which encodes the similarity between pairs of documents.",
                "Recall that we are given the top n documents retrieved in y.",
                "We can compute an n × n similarity matrix, W. An element of this matrix, Wij represents the similarity between documents ranked i and j.",
                "In practice, we only include the affinities for a documents k-nearest neighbors.",
                "In all of our experiments, we have fixed k to 5.",
                "We leave exploration of parameter sensitivity to future work.",
                "We also row normalize the matrix so that Pn j=1 Wij = 1 for all i. 3.2 Spatial Autocorrelation of a Retrieval Recall that we are interested in measuring the similarity between the scores of spatially-close documents.",
                "One such suitable measure is the Moran coefficient of spatial autocorrelation.",
                "Assuming the function y over n locations, this is defined as ˜IM = n eTWe P i,j Wijyiyj P i y2 i = n eTWe yT Wy yTy (2) where eT We = P ij Wij.",
                "We would like to compare autocorrelation values for different retrievals.",
                "Unfortunately, the bound for Equation 2 is not consistent for different W and y.",
                "Therefore, we use the Cauchy-Schwartz inequality to establish a bound, ˜IM ≤ n eTWe s yTWTWy yTy And we define the normalized spatial autocorrelation as IM = yT Wy p yTy × yTWTWy Notice that if we let ˜y = Wy, then we can write this formula as, IM = yT ˜y y 2 ˜y 2 (3) which can be interpreted as the correlation between the original retrieval scores and a set of retrieval scores diffused in the space.",
                "We present some examples of autocorrelations of functions on a grid in Figure 1. 3.3 Correlation with Other Retrievals Sometimes we are interested in the performance of a single retrieval but have access to scores from multiple systems for (a) IM = 0.006 (b) IM = 0.241 (c) IM = 0.487 Figure 1: The Moran coefficient, IM for a several binary functions on a grid.",
                "The Moran coefficient is a local measure of function consistency.",
                "From the perspective of information retrieval, each of these grid spaces would represent a document and documents would be organized so that they lay next to topically-related documents.",
                "Binary retrieval scores would define a pattern on this grid.",
                "Notice that, as the Moran coefficient increases, neighboring cells tend to have similar values. the same query.",
                "In this situation, we can use combined information from these scores to construct a surrogate for a high-quality ranking [17].",
                "We can treat the correlation between the retrieval we are interested in and the combined scores as a predictor of performance.",
                "Assume that we are given m score functions, yi, for the same n documents.",
                "We will represent the mean of these vectors as yµ = Pm i=1 yi.",
                "We use the mean vector as an approximation to relevance.",
                "Since we use zero mean and unit variance normalization, work in metasearch suggests that this assumption is justified [15].",
                "Because yµ represents a very good retrieval, we hypothesize that a strong similarity between yµ and y will correlate positively with system performance.",
                "We use Pearsons product-moment correlation to measure the similarity between these vectors, ρ(y, yµ) = yT yµ y 2 yµ 2 (4) We will comment on the similarity between Equation 3 and 4 in Section 7.",
                "Of course, we can combine ρ(y, ˜y) and ρ(y, yµ) if we assume that they capture different factors in the prediction.",
                "One way to accomplish this is to combine these predictors as independent variables in a linear regression.",
                "An alternative means of combination is suggested by the mathematical form of our predictors.",
                "Since ˜y encodes the spatial dependencies in y and yµ encodes the spatial properties of the multiple runs, we can compute a third correlation between these two vectors, ρ(˜y, yµ) = ˜yT yµ ˜y 2 yµ 2 (5) We can interpret Equation 5 as measuring the correlation between a high quality ranking (yµ) and a spatially smoothed version of the retrieval (˜y). 4.",
                "RELATIONSHIP WITH OTHER PREDICTORS One way to predict the effectiveness of a retrieval is to look at the shared vocabulary of the top n retrieved documents.",
                "If we computed the most frequent content words in this set, we would hope that they would be consistent with our topic.",
                "In fact, we might believe that a bad retrieval would include documents on many disparate topics, resulting in an overlap of terminological noise.",
                "The Clarity of a query attempts to quantify exactly this [7].",
                "Specifically, Clarity measures the similarity of the words most frequently used in retrieved documents to those most frequently used in the whole corpus.",
                "The conjecture is that a good retrieval will use language distinct from general text; the overlapping language in a bad retrieval will tend to be more similar to general text.",
                "Mathematically, we can compute a representation of the language used in the initial retrieval as a weighted combination of document language models, P(w|θQ) = nX i=1 P(w|θi) P(Q|θi) Z (6) where θi is the language model of the ith-ranked document, P(Q|θi) is the query likelihood score of the ith-ranked document and Z = Pn i=1 P(Q|θi) is a normalization constant.",
                "The similarity between the multinomial P(w|θQ) and a model of general text can be computed using the Kullback-Leibler divergence, DV KL(θQ θC ).",
                "Here, the distribution P(w|θC ) is our model of general text which can be computed using term frequencies in the corpus.",
                "In Figure 2a, we present Clarity as measuring the distance between the weighted center of mass of the retrieval (labeled y) and the unweighted center of mass of the collection (labeled O).",
                "Clarity reaches a minimum when a retrieval assigns every document the same score.",
                "Lets again assume we have a set of n documents retrieved for our query.",
                "Another way to quantify the dispersion of a set of documents is to look at how clustered they are.",
                "We may hypothesize that a good retrieval will return a single, tight cluster.",
                "A poorly performing retrieval will return a loosely related set of documents covering many topics.",
                "One proposed method of quantifying this dispersion is to measure the distance from a random document a to its nearest neighbor, b.",
                "A retrieval which is tightly clustered will, on average, have a low distance between a and b; a retrieval which is less tightly-closed will, on average have high distances between a and b.",
                "This average corresponds to using the Cox-Lewis statistic to measure the randomness of the top n documents retrieved from a system [18].",
                "In Figure 2a, this is roughly equivalent to measuring the area of the set n. Notice that we are throwing away information about the retrieval function y.",
                "Therefore the Cox-Lewis statistic is highly dependent on selecting the top n documents.1 Remember that we have n documents and a set of scores.",
                "Lets assume that we have access to the system which provided the original scores and that we can also request scores for new documents.",
                "This suggests a third method for predicting performance.",
                "Take some document, a, from the retrieved set and arbitrarily add or remove words at random to create a new document ˜a.",
                "Now, we can ask our system to score ˜a with respect to our query.",
                "If, on average over the n documents, the scores of a and ˜a tend to be very different, we might suspect that the system is failing on this query.",
                "So, an alternative approach is to measure the simi1 The authors have suggested coupling the query with the distance measure [18].",
                "The information introduced by the query, though, is retrieval-independent so that, if two retrievals return the same set of documents, the approximate Cox-Lewis statistic will be the same regardless of the retrieval scores. yOy (a) Global Divergence µ(y)˜y y (b) Score Perturbation µ(y) y (c) Multirun Averaging Figure 2: Representation of several performance predictors on a grid.",
                "In Figure 2a, we depict predictors which measure the divergence between the center of mass of a retrieval and the center of the embedding space.",
                "In Figure 2b, we depict predictors which compare the original retrieval, y, to a perturbed version of the retrieval, ˜y.",
                "Our approach uses a particular type of perturbation based on score diffusion.",
                "Finally, in Figure 2c, we depict prediction when given retrievals from several other systems on the same query.",
                "Here, we can consider the fusion of these retrieval as a surrogate for relevance. larity between the retrieval and a perturbed version of that retrieval [18, 19].",
                "This can be accomplished by either perturbing the documents or queries.",
                "The similarity between the two retrievals can be measured using some correlation measure.",
                "This is depicted in Figure 2b.",
                "The upper grid represents the original retrieval, y, while the lower grid represents the function after having been perturbed, ˜y.",
                "The nature of the perturbation process requires additional scorings or retrievals.",
                "Our predictor does not require access to the original scoring function or additional retrievals.",
                "So, although our method is similar to other perturbation methods in spirit, it can be applied in situations when the retrieval system is inaccessible or costly to access.",
                "Finally, assume that we have, in addition to the retrieval we want to evaluate, m retrievals from a variety of different systems.",
                "In this case, we might take a document a, compare its rank in the retrieval to its average rank in the m retrievals.",
                "If we believe that the m retrievals provide a satisfactory approximation to relevance, then a very large difference in rank would suggest that our retrieval is misranking a.",
                "If this difference is large on average over all n documents, then we might predict that the retrieval is bad.",
                "If, on the other hand, the retrieval is very consistent with the m retrievals, then we might predict that the retrieval is good.",
                "The similarity between the retrieval and the combined retrieval may be computed using some correlation measure.",
                "This is depicted in Figure 2c.",
                "In previous work, the Kullback-Leibler divergence between the normalized scores of the retrieval and the normalized scores of the combined retrieval provides the similarity [1]. 5.",
                "EXPERIMENTS Our experiments focus on testing the predictive power of each of our predictors: ρ(y, ˜y), ρ(y, yµ), and ρ(˜y, yµ).",
                "As stated in Section 2, we are interested in predicting the performance of the retrieval generated by an arbitrary system.",
                "Our methodology is consistent with previous research in that we predict the relative performance of a retrieval by comparing a ranking based on our predictor to a ranking based on average precision.",
                "We present results for two sets of experiments.",
                "The first set of experiments presents detailed comparisons of our predictors to previously-proposed predictors using identical data sets.",
                "Our second set of experiments demonstrates the generalizability of our approach to arbitrary retrieval methods, corpus types, and corpus languages. 5.1 Detailed Experiments In these experiments, we will predict the performance of language modeling scores using our autocorrelation predictor, ρ(y, ˜y); we do not consider ρ(y, yµ) or ρ(˜y, yµ) because, in these detailed experiments, we focus on ranking the retrievals from a single system.",
                "We use retrievals, values for baseline predictors, and evaluation measures reported in previous work [19]. 5.1.1 Topics and Collections These performance prediction experiments use language model retrievals performed for queries associated with collections in the TREC corpora.",
                "Using TREC collections allows us to confidently associate an average precision with a retrieval.",
                "In these experiments, we use the following topic collections: TREC 4 ad-hoc, TREC 5 ad-hoc, Robust 2004, Terabyte 2004, and Terabyte 2005. 5.1.2 Baselines We provide two baselines.",
                "Our first baseline is the classic Clarity predictor presented in Equation 6.",
                "Clarity is designed to be used with language modeling systems.",
                "Our second baseline is Zhou and Crofts ranking robustness predictor.",
                "This predictor corrupts the top k documents from retrieval and re-computes the language model scores for these corrupted documents.",
                "The value of the predictor is the Spearman rank correlation between the original ranking and the corrupted ranking.",
                "In our tables, we will label results for Clarity using DV KL and the ranking robustness predictor using P. 5.2 Generalizability Experiments Our predictors do not require a particular baseline retrieval system; the predictors can be computed for an arbitrary retrieval, regardless of how scores were generated.",
                "We believe that that is one of the most attractive aspects of our algorithm.",
                "Therefore, in a second set of experiments, we demonstrate the ability of our techniques to generalize to a variety of collections, topics, and retrieval systems. 5.2.1 Topics and Collections We gathered a diverse set of collections from all possible TREC corpora.",
                "We cast a wide net in order to locate collections where our predictors might fail.",
                "Our hypothesis is that documents with high topical similarity should have correlated scores.",
                "Therefore, we avoided collections where scores were unlikely to be correlated (eg, question-answering) or were likely to be negatively correlated (eg, novelty).",
                "Nevertheless, our collections include corpora where correlations are weakly justified (eg, non-English corpora) or not justified at all (eg, expert search).",
                "We use the ad-hoc tracks from TREC3-8, TREC Robust 2003-2005, TREC Terabyte 20042005, TREC4-5 Spanish, TREC5-6 Chinese, and TREC Enterprise Expert Search 2005.",
                "In all cases, we use only the automatic runs for ad-hoc tracks submitted to NIST.",
                "For all English and Spanish corpora, we construct the matrix W according to the process described in Section 3.1.",
                "For Chinese corpora, we use na¨ıve character-based tf.idf vectors.",
                "For entities, entries in W are proportional to the number of documents in which two entities cooccur. 5.2.2 Baselines In our detailed experiments, we used the Clarity measure as a baseline.",
                "Since we are predicting the performance of retrievals which are not based on language modeling, we use a version of Clarity referred to as ranked-list Clarity [7].",
                "Ranked-list clarity converts document ranks to P(Q|θi) values.",
                "This conversion begins by replacing all of the scores in y with the respective ranks.",
                "Our estimation of P(Q|θi) from the ranks, then is, P(Q|θi) = ( 2(c+1−yi) c(c+1) if yi ≤ c 0 otherwise (7) where c is a cutoff parameter.",
                "As suggested by the authors, we fix the algorithm parameters c and λ2 so that c = 60 and λ2 = 0.10.",
                "We use Equation 6 to estimate P(w|θQ) and DV KL(θQ θC ) to compute the value of the predictor.",
                "We will refer to this predictor as DV KL, superscripted by V to indicate that the Kullback-Leibler divergence is with respect to the term embedding space.",
                "When information from multiple runs on the same query is available, we use Aslam and Pavlus document-space multinomial divergence as a baseline [1].",
                "This rank-based method first normalizes the scores in a retrieval as an n-dimensional multinomial.",
                "As with ranked-list Clarity, we begin by replacing all of the scores in y with their respective ranks.",
                "Then, we adjust the elements of y in the following way, ˆyi = 1 2n 0 @1 + nX k=yi 1 k 1 A (8) In our multirun experiments, we only use the top 75 documents from each retrieval (n = 75); this is within the range of parameter values suggested by the authors.",
                "However, we admit not tuning this parameter for either our system or the baseline.",
                "The predictor is the divergence between the candidate distribution, y, and the mean distribution, yµ .",
                "With the uniform linear combination of these m retrievals represented as yµ, we can compute the divergence as Dn KL(ˆy ˆyµ) where we use the superscript n to indicate that the summation is over the set of n documents.",
                "This baseline was developed in the context of predicting query difficulty but we adopt it as a reasonable baseline for predicting retrieval performance. 5.2.3 Parameter Settings When given multiple retrievals, we use documents in the union of the top k = 75 documents from each of the m retrievals for that query.",
                "If the size of this union is ˜n, then yµ and each yi is of length ˜n.",
                "In some cases, a system did not score a document in the union.",
                "Since we are making a Gaussian assumption about our scores, we can sample scores for these unseen documents from the negative tail of the distribution.",
                "Specifically, we sample from the part of the distribution lower than the minimum value of in the normalized retrieval.",
                "This introduces randomness into our algorithm but we believe it is more appropriate than assigning an arbitrary fixed value.",
                "We optimized the linear regression using the square root of each predictor.",
                "We found that this substantially improved fits for all predictors, including the baselines.",
                "We considered linear combinations of pairs of predictors (labeled by the components) and all predictors (labeled as β). 5.3 Evaluation Given a set of retrievals, potentially from a combination of queries and systems, we measure the correlation of the rank ordering of this set by the predictor and by the performance metric.",
                "In order to ensure comparability with previous results, we present Kendalls τ correlation between the predictors ranking and ranking based on average precision of the retrieval.",
                "Unless explicitly noted, all correlations are significant with p < 0.05.",
                "Predictors can sometimes perform better when linearly combined [9, 11].",
                "Although previous work has presented the coefficient of determination (R2 ) to measure the quality of the regression, this measure cannot be reliably used when comparing slight improvements from combining predictors.",
                "Therefore, we adopt the adjusted coefficient of determination which penalizes models with more variables.",
                "The adjusted R2 allows us to evaluate the improvement in prediction achieved by adding a parameter but loses the statistical interpretation of R2 .",
                "We will use Kendalls τ to evaluate the magnitude of the correlation and the adjusted R2 to evaluate the combination of variables. 6.",
                "RESULTS We present results for our detailed experiments comparing the prediction of language model scores in Table 1.",
                "Although the Clarity measure is theoretically designed for language model scores, it consistently underperforms our system-agnostic predictor.",
                "Ranking robustness was presented as an improvement to Clarity for web collections (represented in our experiments by the terabyte04 and terabyte05 collections), shifting the τ correlation from 0.139 to 0.150 for terabyte04 and 0.171 to 0.208 for terabyte05.",
                "However, these improvements are slight compared to the performance of autocorrelation on these collections.",
                "Our predictor achieves a τ correlation of 0.454 for terabyte04 and 0.383 for terabyte05.",
                "Though not always the strongest, autocorrelation achieves correlations competitive with baseline predictors.",
                "When examining the performance of linear combinations of predictors, we note that in every case, autocorrelation factors as a necessary component of a strong predictor.",
                "We also note that the adjusted R2 for individual baselines are always significantly improved by incorporating autocorrelation.",
                "We present our generalizability results in Table 2.",
                "We begin by examining the situation in column (a) where we are presented with a single retrieval and no information from additional retrievals.",
                "For every collection except one, we achieve significantly better correlations than ranked-list Clarity.",
                "Surprisingly, we achieve relatively strong correlations for Spanish and Chinese collections despite our na¨ıve processing.",
                "We do not have a ranked-list clarity correlation for ent05 because entity modeling is itself an open research question.",
                "However, our autocorrelation measure does not achieve high correlations perhaps because relevance for entity retrieval does not propagate according to the cooccurrence links we use.",
                "As noted above, the poor Clarity performance on web data is consistent with our findings in the detailed experiments.",
                "Clarity also notably underperforms for several news corpora (trec5, trec7, and robust04).",
                "On the other hand, autocorrelation seems robust to the changes between different corpora.",
                "Next, we turn to the introduction of information from multiple retrievals.",
                "We compare the correlations between those predictors which do not use this information in column (a) and those which do in column (b).",
                "For every collection, the predictors in column (b) outperform the predictors in column (a), indicating that the information from additional runs can be critical to making good predictions.",
                "Inspecting the predictors in column (b), we only draw weak conclusions.",
                "Our new predictors tend to perform better on news corpora.",
                "And between our new predictors, the hybrid ρ(˜y, yµ) predictor tends to perform better.",
                "Recall that our ρ(˜y, yµ) measure incorporates both spatial and multiple retrieval information.",
                "Therefore, we believe that the improvement in correlation is the result of incorporating information from spatial behavior.",
                "In column (c), we can investigate the utility of incorporating spatial information with information from multiple retrievals.",
                "Notice that in the cases where autocorrelation, ρ(y, ˜y), alone performs well (trec3, trec5-spanish, and trec6-chinese), it is substantially improved by incorporating multiple-retrieval information from ρ(y, yµ) in the linear regression, β.",
                "In the cases where ρ(y, yµ) performs well, incorporating autocorrelation rarely results in a significant improvement in performance.",
                "In fact, in every case where our predictor outperforms the baseline, it includes information from multiple runs. 7.",
                "DISCUSSION The most important result from our experiments involves prediction when no information is available from multiple runs (Tables 1 and 2a).",
                "This situation arises often in system design.",
                "For example, a system may need to, at retrieval time, assess its performance before deciding to conduct more intensive processing such as pseudo-relevance feedback or interaction.",
                "Assuming the presence of multiple retrievals is unrealistic in this case.",
                "We believe that autocorrelation is, like multiple-retrieval algorithms, approximating a good ranking; in this case by diffusing scores.",
                "Why is ˜y a reasonable surrogate?",
                "We know that diffusion of scores on the web graph and language model graphs improves performance [14, 16].",
                "Therefore, if score diffusion tends to, in general, improve performance, then diffused scores will, in general, provide a good surrogate for relevance.",
                "Our results demonstrate that this approximation is not as powerful as information from multiple retrievals.",
                "Nevertheless, in situations where this information is lacking, autocorrelation provides substantial information.",
                "The success of autocorrelation as a predictor may also have roots in the clustering hypothesis.",
                "Recall that we regard autocorrelation as the degree to which a retrieval satisfies the clustering hypothesis.",
                "Our experiments, then, demonstrate that a failure to respect the clustering hypothesis correlates with poor performance.",
                "Why might systems fail to conform to the cluster hypothesis?",
                "Query-based information retrieval systems often score documents independently.",
                "The score of document a may be computed by examining query term or phrase matches, the document length, and perhaps global collection statistics.",
                "Once computed, a system rarely compares the score of a to the score of a topically-related document b.",
                "With some exceptions, the correlation of document scores has largely been ignored.",
                "We should make it clear that we have selected tasks where topical autocorrelation is appropriate.",
                "There are certainly cases where there is no reason to believe that retrieval scores will have topical autocorrelation.",
                "For example, ranked lists which incorporate document novelty should not exhibit spatial autocorrelation; if anything autocorrelation should be negative for this task.",
                "Similarly, answer candidates in a question-answering task may or may not exhibit autocorrelation; in this case, the semantics of links is questionable too.",
                "It is important before applying this measure to confirm that, given the semantics for some link between two retrieved items, we should expect a correlation between scores. 8.",
                "RELATED WORK In this section we draw more general comparisons to other work in performance prediction and spatial data analysis.",
                "There is a growing body of work which attempts to predict the performance of individual retrievals [7, 3, 11, 9, 19].",
                "We have attempted to place our work in the context of much of this work in Section 4.",
                "However, a complete comparison is beyond the scope of this paper.",
                "We note, though, that our experiments cover a larger and more diverse set of retrievals, collections, and topics than previously examined.",
                "Much previous work-particularly in the context of TRECfocuses on predicting the performance of systems.",
                "Here, each system generates k retrievals.",
                "The task is, given these retrievals, to predict the ranking of systems according to some performance measure.",
                "Several papers attempt to address this task under the constraint of few judgments [2, 4].",
                "Some work even attempts to use zero judgments by leveraging multiple retrievals for the same query [17].",
                "Our task differs because we focus on ranking retrievals independent of the generating system.",
                "The task here is not to test the hypothesis system A is superior to system B but to test the hypothesis retrieval A is superior to retrieval B. Autocorrelation manifests itself in many classification tasks.",
                "Neville and Jensen define relational autocorrelation for relational learning problems and demonstrate that many classification tasks manifest autocorrelation [13].",
                "Temporal autocorrelation of initial retrievals has also been used to predict performance [9].",
                "However, temporal autocorrelation is performed by projecting the retrieval function into the temporal embedding space.",
                "In our work, we focus on the behavior of the function over the relationships between documents. τ adjusted R2 DV KL P ρ(y, ˜y) DV KL P ρ(y, ˜y) DV KL, P DV KL, ρ(y, ˜y) Pρ(y, ˜y) β trec4 0.353 0.548 0.513 0.168 0.363 0.422 0.466 0.420 0.557 0.553 trec5 0.311 0.329 0.357 0.116 0.190 0.236 0.238 0.244 0.266 0.269 robust04 0.418 0.398 0.373 0.256 0.304 0.278 0.403 0.373 0.402 0.442 terabyte04 0.139 0.150 0.454 0.059 0.045 0.292 0.076 0.293 0.289 0.284 terabyte05 0.171 0.208 0.383 0.022 0.072 0.193 0.120 0.225 0.218 0.257 Table 1: Comparison to Robustness and Clarity measures for language model scores.",
                "Evaluation replicates experiments from [19].",
                "We present correlations between the classic Clarity measure (DV KL), the ranking robustness measure (P), and autocorrelation (ρ(y, ˜y)) each with mean average precision in terms of Kendalls τ.",
                "The adjusted coefficient of determination is presented to measure the effectiveness of combining predictors.",
                "Measures in bold represent the strongest correlation for that test/collection pair. multiple run (a) (b) (c) τ τ adjusted R2 DKL ρ(y, ˜y) Dn KL ρ(y, yµ) ρ(˜y, yµ) Dn KL ρ(y, ˜y) ρ(y, yµ) ρ(˜y, yµ) β trec3 0.201 0.461 0.461 0.439 0.456 0.444 0.395 0.394 0.386 0.498 trec4 0.252 0.396 0.455 0.482 0.489 0.379 0.263 0.429 0.482 0.483 trec5 0.016 0.277 0.433 0.459 0.393 0.280 0.157 0.375 0.323 0.386 trec6 0.230 0.227 0.352 0.428 0.418 0.203 0.089 0.323 0.325 0.325 trec7 0.083 0.326 0.341 0.430 0.483 0.264 0.182 0.363 0.442 0.400 trec8 0.235 0.396 0.454 0.508 0.567 0.402 0.272 0.490 0.580 0.523 robust03 0.302 0.354 0.377 0.385 0.447 0.269 0.206 0.274 0.392 0.303 robust04 0.183 0.308 0.301 0.384 0.453 0.200 0.182 0.301 0.393 0.335 robust05 0.224 0.249 0.371 0.377 0.404 0.341 0.108 0.313 0.328 0.336 terabyte04 0.043 0.245 0.544 0.420 0.392 0.516 0.105 0.357 0.343 0.365 terabyte05 0.068 0.306 0.480 0.434 0.390 0.491 0.168 0.384 0.309 0.403 trec4-spanish 0.307 0.388 0.488 0.398 0.395 0.423 0.299 0.282 0.299 0.388 trec5-spanish 0.220 0.458 0.446 0.484 0.475 0.411 0.398 0.428 0.437 0.529 trec5-chinese 0.092 0.199 0.367 0.379 0.384 0.379 0.199 0.273 0.276 0.310 trec6-chinese 0.144 0.276 0.265 0.353 0.376 0.115 0.128 0.188 0.223 0.199 ent05 - 0.181 0.324 0.305 0.282 0.211 0.043 0.158 0.155 0.179 Table 2: Large scale prediction experiments.",
                "We predict the ranking of large sets of retrievals for various collections and retrieval systems.",
                "Kendalls τ correlations are computed between the predicted ranking and a ranking based on the retrievals average precision.",
                "In column (a), we have predictors which do not use information from other retrievals for the same query.",
                "In columns (b) and (c) we present performance for predictors which incorporate information from multiple retrievals.",
                "The adjusted coefficient of determination is computed to determine effectiveness of combining predictors.",
                "Measures in bold represent the strongest correlation for that test/collection pair.",
                "Finally, regularization-based re-ranking processes are also closely-related to our work [8].",
                "These techniques seek to maximize the agreement between scores of related documents by solving a constrained optimization problem.",
                "The maximization of consistency is equivalent to maximizing the Moran autocorrelation.",
                "Therefore, we believe that our work provides explanation for why regularization-based re-ranking works. 9.",
                "CONCLUSION We have presented a new method for predicting the performance of a retrieval ranking without any relevance judgments.",
                "We consider two cases.",
                "First, when making predictions in the absence of retrievals from other systems, our predictors demonstrate robust, strong correlations with average precision.",
                "This performance, combined with a simple implementation, makes our predictors, in particular, very attractive.",
                "We have demonstrated this improvement for many, diverse settings.",
                "To our knowledge, this is the first large scale examination of zero-judgment, single-retrieval performance prediction.",
                "Second, when provided retrievals from other systems, our extended methods demonstrate competitive performance with state of the art baselines.",
                "Our experiments also demonstrate the limits of the usefulness of our predictors when information from multiple runs is provided.",
                "Our results suggest two conclusions.",
                "First, our results could affect retrieval algorithm design.",
                "Retrieval algorithms designed to consider spatial autocorrelation will conform to the cluster hypothesis and improve performance.",
                "Second, our results could affect the design of minimal test collection algorithms.",
                "Much of the recent work in ranking systems sometimes ignores correlations between document labels and scores.",
                "We believe that these two directions could be rewarding given the theoretical and experimental evidence in this paper. 10.",
                "ACKNOWLEDGMENTS This work was supported in part by the Center for Intelligent Information Retrieval and in part by the Defense Advanced Research Projects Agency (DARPA) under contract number HR0011-06-C-0023.",
                "Any opinions, findings and conclusions or recommendations expressed in this material are the authors and do not necessarily reflect those of the sponsor.",
                "We thank Yun Zhou and Desislava Petkova for providing data and Andre Gauthier for technical assistance. 11.",
                "REFERENCES [1] J. Aslam and V. Pavlu.",
                "Query hardness estimation using jensen-shannon divergence among multiple scoring functions.",
                "In ECIR 2007: Proceedings of the 29th European Conference on Information Retrieval, 2007. [2] J.",
                "A. Aslam, V. Pavlu, and E. Yilmaz.",
                "A statistical method for system evaluation using incomplete judgments.",
                "In S. Dumais, E. N. Efthimiadis, D. Hawking, and K. Jarvelin, editors, Proceedings of the 29th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 541-548.",
                "ACM Press, August 2006. [3] D. Carmel, E. Yom-Tov, A. Darlow, and D. Pelleg.",
                "What makes a query difficult?",
                "In SIGIR 06: Proceedings of the 29th annual international ACM SIGIR conference on Research and development in information retrieval, pages 390-397, New York, NY, USA, 2006.",
                "ACM Press. [4] B. Carterette, J. Allan, and R. Sitaraman.",
                "Minimal test collections for retrieval evaluation.",
                "In SIGIR 06: Proceedings of the 29th annual international ACM SIGIR conference on Research and development in information retrieval, pages 268-275, New York, NY, USA, 2006.",
                "ACM Press. [5] A. D. Cliff and J. K. Ord.",
                "Spatial Autocorrelation.",
                "Pion Ltd., 1973. [6] M. Connell, A. Feng, G. Kumaran, H. Raghavan, C. Shah, and J. Allan.",
                "Umass at tdt 2004.",
                "Technical Report CIIR Technical Report IR - 357, Department of Computer Science, University of Massachusetts, 2004. [7] S. Cronen-Townsend, Y. Zhou, and W. B. Croft.",
                "Precision prediction based on ranked list coherence.",
                "Inf.",
                "Retr., 9(6):723-755, 2006. [8] F. Diaz.",
                "Regularizing ad-hoc retrieval scores.",
                "In CIKM 05: Proceedings of the 14th ACM international conference on Information and knowledge management, pages 672-679, New York, NY, USA, 2005.",
                "ACM Press. [9] F. Diaz and R. Jones.",
                "Using temporal profiles of queries for precision prediction.",
                "In SIGIR 04: Proceedings of the 27th annual international ACM SIGIR conference on Research and development in information retrieval, pages 18-24, New York, NY, USA, 2004.",
                "ACM Press. [10] D. A. Griffith.",
                "Spatial Autocorrelation and Spatial Filtering.",
                "Springer Verlag, 2003. [11] B.",
                "He and I. Ounis.",
                "Inferring Query Performance Using Pre-retrieval Predictors.",
                "In The Eleventh Symposium on String Processing and Information Retrieval (SPIRE), 2004. [12] N. Jardine and C. J. V. Rijsbergen.",
                "The use of hierarchic clustering in information retrieval.",
                "Information Storage and Retrieval, 7:217-240, 1971. [13] D. Jensen and J. Neville.",
                "Linkage and autocorrelation cause feature selection bias in relational learning.",
                "In ICML 02: Proceedings of the Nineteenth International Conference on Machine Learning, pages 259-266, San Francisco, CA, USA, 2002.",
                "Morgan Kaufmann Publishers Inc. [14] O. Kurland and L. Lee.",
                "Corpus structure, language models, and ad-hoc information retrieval.",
                "In SIGIR 04: Proceedings of the 27th annual international conference on Research and development in information retrieval, pages 194-201, New York, NY, USA, 2004.",
                "ACM Press. [15] M. Montague and J.",
                "A. Aslam.",
                "Relevance score normalization for metasearch.",
                "In CIKM 01: Proceedings of the tenth international conference on Information and knowledge management, pages 427-433, New York, NY, USA, 2001.",
                "ACM Press. [16] T. Qin, T.-Y.",
                "Liu, X.-D. Zhang, Z. Chen, and W.-Y.",
                "Ma.",
                "A study of relevance propagation for web search.",
                "In SIGIR 05: Proceedings of the 28th annual international ACM SIGIR conference on Research and development in information retrieval, pages 408-415, New York, NY, USA, 2005.",
                "ACM Press. [17] I. Soboroff, C. Nicholas, and P. Cahan.",
                "Ranking retrieval systems without relevance judgments.",
                "In SIGIR 01: Proceedings of the 24th annual international ACM SIGIR conference on Research and development in information retrieval, pages 66-73, New York, NY, USA, 2001.",
                "ACM Press. [18] V. Vinay, I. J. Cox, N. Milic-Frayling, and K. Wood.",
                "On ranking the effectiveness of searches.",
                "In SIGIR 06: Proceedings of the 29th annual international ACM SIGIR conference on Research and development in information retrieval, pages 398-404, New York, NY, USA, 2006.",
                "ACM Press. [19] Y. Zhou and W. B. Croft.",
                "Ranking robustness: a novel framework to predict query performance.",
                "In CIKM 06: Proceedings of the 15th ACM international conference on Information and knowledge management, pages 567-574, New York, NY, USA, 2006.",
                "ACM Press."
            ],
            "original_annotated_samples": [],
            "translated_annotated_samples": [],
            "translated_text": "",
            "candidates": [],
            "error": [
                []
            ]
        },
        "predictive power of predictor": {
            "translated_key": "poder predictivo del predictor",
            "is_in_text": false,
            "original_annotated_sentences": [
                "Performance Prediction Using Spatial Autocorrelation Fernando Diaz Center for Intelligent Information Retrieval Department of Computer Science University of Massachusetts Amherst, MA 01003 fdiaz@cs.umass.edu ABSTRACT Evaluation of information retrieval systems is one of the core tasks in information retrieval.",
                "Problems include the inability to exhaustively label all documents for a topic, nongeneralizability from a small number of topics, and incorporating the variability of retrieval systems.",
                "Previous work addresses the evaluation of systems, the ranking of queries by difficulty, and the ranking of individual retrievals by performance.",
                "Approaches exist for the case of few and even no relevance judgments.",
                "Our focus is on zero-judgment performance prediction of individual retrievals.",
                "One common shortcoming of previous techniques is the assumption of uncorrelated document scores and judgments.",
                "If documents are embedded in a high-dimensional space (as they often are), we can apply techniques from spatial data analysis to detect correlations between document scores.",
                "We find that the low correlation between scores of topically close documents often implies a poor retrieval performance.",
                "When compared to a state of the art baseline, we demonstrate that the spatial analysis of retrieval scores provides significantly better prediction performance.",
                "These new predictors can also be incorporated with classic predictors to improve performance further.",
                "We also describe the first large-scale experiment to evaluate zero-judgment performance prediction for a massive number of retrieval systems over a variety of collections in several languages.",
                "Categories and Subject Descriptors H.3.3 [Information Search and Retrieval]: Retrieval models; H.3.4 [Systems and Software]: Performance evaluation (efficiency and effectiveness) General Terms Performance, Design, Reliability, Experimentation 1.",
                "INTRODUCTION In information retrieval, a user poses a query to a system.",
                "The system retrieves n documents each receiving a realvalued score indicating the predicted degree of relevance.",
                "If we randomly select pairs of documents from this set, we expect some pairs to share the same topic and other pairs to not share the same topic.",
                "Take two topically-related documents from the set and call them a and b.",
                "If the scores of a and b are very different, we may be concerned about the performance of our system.",
                "That is, if a and b are both on the topic of the query, we would like them both to receive a high score; if a and b are not on the topic of the query, we would like them both to receive a low score.",
                "We might become more worried as we find more differences between scores of related documents.",
                "We would be more comfortable with a retrieval where scores are consistent between related documents.",
                "Our paper studies the quantification of this inconsistency in a retrieval from a spatial perspective.",
                "Spatial analysis is appropriate since many retrieval models embed documents in some vector space.",
                "If documents are embedded in a space, proximity correlates with topical relationships.",
                "Score consistency can be measured by the spatial version of autocorrelation known as the Moran coefficient or IM [5, 10].",
                "In this paper, we demonstrate a strong correlation between IM and retrieval performance.",
                "The discussion up to this point is reminiscent of the cluster hypothesis.",
                "The cluster hypothesis states: closely-related documents tend to be relevant to the same request [12].",
                "As we shall see, a retrieval functions spatial autocorrelation measures the degree to which closely-related documents receive similar scores.",
                "Because of this, we interpret autocorrelation as measuring the degree to which a retrieval function satisfies the clustering hypothesis.",
                "If this connection is reasonable, in Section 6, we present evidence that failure to satisfy the cluster hypothesis correlates strongly with poor performance.",
                "In this work, we provide the following contributions, 1.",
                "A general, robust method for predicting the performance of retrievals with zero relevance judgments (Section 3). 2.",
                "A theoretical treatment of the similarities and motivations behind several state-of-the-art performance prediction techniques (Section 4). 3.",
                "The first large-scale experiments of zero-judgment, single run performance prediction (Sections 5 and 6). 2.",
                "PROBLEM DEFINITION Given a query, an information retrieval system produces a ranking of documents in the collection encoded as a set of scores associated with documents.",
                "We refer to the set of scores for a particular query-system combination as a retrieval.",
                "We would like to predict the performance of this retrieval with respect to some evaluation measure (eg, mean average precision).",
                "In this paper, we present results for ranking retrievals from arbitrary systems.",
                "We would like this ranking to approximate the ranking of retrievals by the evaluation measure.",
                "This is different from ranking queries by the average performance on each query.",
                "It is also different from ranking systems by the average performance on a set of queries.",
                "Scores are often only computed for the top n documents from the collection.",
                "We place these scores in the length n vector, y, where yi refers to the score of the ith-ranked document.",
                "We adjust scores to have zero mean and unit variance.",
                "We use this method because of its simplicity and its success in previous work [15]. 3.",
                "SPATIAL CORRELATION In information retrieval, we often assume that the representations of documents exist in some high-dimensional vector space.",
                "For example, given a vocabulary, V, this vector space may be an arbitrary |V|-dimensional space with cosine inner-product or a multinomial simplex with a distributionbased distance measure.",
                "An embedding space is often selected to respect topical proximity; if two documents are near, they are more likely to share a topic.",
                "Because of the prevalence and success of spatial models of information retrieval, we believe that the application of spatial data analysis techniques are appropriate.",
                "Whereas in information retrieval, we are concerned with the score at a point in a space, in spatial data analysis, we are concerned with the value of a function at a point or location in a space.",
                "We use the term function here to mean a mapping from a location to a real value.",
                "For example, we might be interested in the prevalence of a disease in the neighborhood of some city.",
                "The function would map the location of a neighborhood to an infection rate.",
                "If we want to quantify the spatial dependencies of a function, we would employ a measure referred to as the spatial autocorrelation [5, 10].",
                "High spatial autocorrelation suggests that knowing the value of a function at location a will tell us a great deal about the value at a neighboring location b.",
                "There is a high spatial autocorrelation for a function representing the temperature of a location since knowing the temperature at a location a will tell us a lot about the temperature at a neighboring location b.",
                "Low spatial autocorrelation suggests that knowing the value of a function at location a tells us little about the value at a neighboring location b.",
                "There is low spatial autocorrelation in a function measuring the outcome of a coin toss at a and b.",
                "In this section, we will begin by describing what we mean by spatial proximity for documents and then define a measure of spatial autocorrelation.",
                "We conclude by extending this model to include information from multiple retrievals from multiple systems for a single query. 3.1 Spatial Representation of Documents Our work does not focus on improving a specific similarity measure or defining a novel vector space.",
                "Instead, we choose an inner product known to be effective at detecting interdocument topical relationships.",
                "Specifically, we adopt tf.idf document vectors, ˜di = di log „ (n + 0.5) − ci 0.5 + ci « (1) where d is a vector of term frequencies, c is the length-|V| document frequency vector.",
                "We use this weighting scheme due to its success for topical link detection in the context of Topic Detection and Tracking (TDT) evaluations [6].",
                "Assuming vectors are scaled by their L2 norm, we use the inner product, ˜di, ˜dj , to define similarity.",
                "Given documents and some similarity measure, we can construct a matrix which encodes the similarity between pairs of documents.",
                "Recall that we are given the top n documents retrieved in y.",
                "We can compute an n × n similarity matrix, W. An element of this matrix, Wij represents the similarity between documents ranked i and j.",
                "In practice, we only include the affinities for a documents k-nearest neighbors.",
                "In all of our experiments, we have fixed k to 5.",
                "We leave exploration of parameter sensitivity to future work.",
                "We also row normalize the matrix so that Pn j=1 Wij = 1 for all i. 3.2 Spatial Autocorrelation of a Retrieval Recall that we are interested in measuring the similarity between the scores of spatially-close documents.",
                "One such suitable measure is the Moran coefficient of spatial autocorrelation.",
                "Assuming the function y over n locations, this is defined as ˜IM = n eTWe P i,j Wijyiyj P i y2 i = n eTWe yT Wy yTy (2) where eT We = P ij Wij.",
                "We would like to compare autocorrelation values for different retrievals.",
                "Unfortunately, the bound for Equation 2 is not consistent for different W and y.",
                "Therefore, we use the Cauchy-Schwartz inequality to establish a bound, ˜IM ≤ n eTWe s yTWTWy yTy And we define the normalized spatial autocorrelation as IM = yT Wy p yTy × yTWTWy Notice that if we let ˜y = Wy, then we can write this formula as, IM = yT ˜y y 2 ˜y 2 (3) which can be interpreted as the correlation between the original retrieval scores and a set of retrieval scores diffused in the space.",
                "We present some examples of autocorrelations of functions on a grid in Figure 1. 3.3 Correlation with Other Retrievals Sometimes we are interested in the performance of a single retrieval but have access to scores from multiple systems for (a) IM = 0.006 (b) IM = 0.241 (c) IM = 0.487 Figure 1: The Moran coefficient, IM for a several binary functions on a grid.",
                "The Moran coefficient is a local measure of function consistency.",
                "From the perspective of information retrieval, each of these grid spaces would represent a document and documents would be organized so that they lay next to topically-related documents.",
                "Binary retrieval scores would define a pattern on this grid.",
                "Notice that, as the Moran coefficient increases, neighboring cells tend to have similar values. the same query.",
                "In this situation, we can use combined information from these scores to construct a surrogate for a high-quality ranking [17].",
                "We can treat the correlation between the retrieval we are interested in and the combined scores as a predictor of performance.",
                "Assume that we are given m score functions, yi, for the same n documents.",
                "We will represent the mean of these vectors as yµ = Pm i=1 yi.",
                "We use the mean vector as an approximation to relevance.",
                "Since we use zero mean and unit variance normalization, work in metasearch suggests that this assumption is justified [15].",
                "Because yµ represents a very good retrieval, we hypothesize that a strong similarity between yµ and y will correlate positively with system performance.",
                "We use Pearsons product-moment correlation to measure the similarity between these vectors, ρ(y, yµ) = yT yµ y 2 yµ 2 (4) We will comment on the similarity between Equation 3 and 4 in Section 7.",
                "Of course, we can combine ρ(y, ˜y) and ρ(y, yµ) if we assume that they capture different factors in the prediction.",
                "One way to accomplish this is to combine these predictors as independent variables in a linear regression.",
                "An alternative means of combination is suggested by the mathematical form of our predictors.",
                "Since ˜y encodes the spatial dependencies in y and yµ encodes the spatial properties of the multiple runs, we can compute a third correlation between these two vectors, ρ(˜y, yµ) = ˜yT yµ ˜y 2 yµ 2 (5) We can interpret Equation 5 as measuring the correlation between a high quality ranking (yµ) and a spatially smoothed version of the retrieval (˜y). 4.",
                "RELATIONSHIP WITH OTHER PREDICTORS One way to predict the effectiveness of a retrieval is to look at the shared vocabulary of the top n retrieved documents.",
                "If we computed the most frequent content words in this set, we would hope that they would be consistent with our topic.",
                "In fact, we might believe that a bad retrieval would include documents on many disparate topics, resulting in an overlap of terminological noise.",
                "The Clarity of a query attempts to quantify exactly this [7].",
                "Specifically, Clarity measures the similarity of the words most frequently used in retrieved documents to those most frequently used in the whole corpus.",
                "The conjecture is that a good retrieval will use language distinct from general text; the overlapping language in a bad retrieval will tend to be more similar to general text.",
                "Mathematically, we can compute a representation of the language used in the initial retrieval as a weighted combination of document language models, P(w|θQ) = nX i=1 P(w|θi) P(Q|θi) Z (6) where θi is the language model of the ith-ranked document, P(Q|θi) is the query likelihood score of the ith-ranked document and Z = Pn i=1 P(Q|θi) is a normalization constant.",
                "The similarity between the multinomial P(w|θQ) and a model of general text can be computed using the Kullback-Leibler divergence, DV KL(θQ θC ).",
                "Here, the distribution P(w|θC ) is our model of general text which can be computed using term frequencies in the corpus.",
                "In Figure 2a, we present Clarity as measuring the distance between the weighted center of mass of the retrieval (labeled y) and the unweighted center of mass of the collection (labeled O).",
                "Clarity reaches a minimum when a retrieval assigns every document the same score.",
                "Lets again assume we have a set of n documents retrieved for our query.",
                "Another way to quantify the dispersion of a set of documents is to look at how clustered they are.",
                "We may hypothesize that a good retrieval will return a single, tight cluster.",
                "A poorly performing retrieval will return a loosely related set of documents covering many topics.",
                "One proposed method of quantifying this dispersion is to measure the distance from a random document a to its nearest neighbor, b.",
                "A retrieval which is tightly clustered will, on average, have a low distance between a and b; a retrieval which is less tightly-closed will, on average have high distances between a and b.",
                "This average corresponds to using the Cox-Lewis statistic to measure the randomness of the top n documents retrieved from a system [18].",
                "In Figure 2a, this is roughly equivalent to measuring the area of the set n. Notice that we are throwing away information about the retrieval function y.",
                "Therefore the Cox-Lewis statistic is highly dependent on selecting the top n documents.1 Remember that we have n documents and a set of scores.",
                "Lets assume that we have access to the system which provided the original scores and that we can also request scores for new documents.",
                "This suggests a third method for predicting performance.",
                "Take some document, a, from the retrieved set and arbitrarily add or remove words at random to create a new document ˜a.",
                "Now, we can ask our system to score ˜a with respect to our query.",
                "If, on average over the n documents, the scores of a and ˜a tend to be very different, we might suspect that the system is failing on this query.",
                "So, an alternative approach is to measure the simi1 The authors have suggested coupling the query with the distance measure [18].",
                "The information introduced by the query, though, is retrieval-independent so that, if two retrievals return the same set of documents, the approximate Cox-Lewis statistic will be the same regardless of the retrieval scores. yOy (a) Global Divergence µ(y)˜y y (b) Score Perturbation µ(y) y (c) Multirun Averaging Figure 2: Representation of several performance predictors on a grid.",
                "In Figure 2a, we depict predictors which measure the divergence between the center of mass of a retrieval and the center of the embedding space.",
                "In Figure 2b, we depict predictors which compare the original retrieval, y, to a perturbed version of the retrieval, ˜y.",
                "Our approach uses a particular type of perturbation based on score diffusion.",
                "Finally, in Figure 2c, we depict prediction when given retrievals from several other systems on the same query.",
                "Here, we can consider the fusion of these retrieval as a surrogate for relevance. larity between the retrieval and a perturbed version of that retrieval [18, 19].",
                "This can be accomplished by either perturbing the documents or queries.",
                "The similarity between the two retrievals can be measured using some correlation measure.",
                "This is depicted in Figure 2b.",
                "The upper grid represents the original retrieval, y, while the lower grid represents the function after having been perturbed, ˜y.",
                "The nature of the perturbation process requires additional scorings or retrievals.",
                "Our predictor does not require access to the original scoring function or additional retrievals.",
                "So, although our method is similar to other perturbation methods in spirit, it can be applied in situations when the retrieval system is inaccessible or costly to access.",
                "Finally, assume that we have, in addition to the retrieval we want to evaluate, m retrievals from a variety of different systems.",
                "In this case, we might take a document a, compare its rank in the retrieval to its average rank in the m retrievals.",
                "If we believe that the m retrievals provide a satisfactory approximation to relevance, then a very large difference in rank would suggest that our retrieval is misranking a.",
                "If this difference is large on average over all n documents, then we might predict that the retrieval is bad.",
                "If, on the other hand, the retrieval is very consistent with the m retrievals, then we might predict that the retrieval is good.",
                "The similarity between the retrieval and the combined retrieval may be computed using some correlation measure.",
                "This is depicted in Figure 2c.",
                "In previous work, the Kullback-Leibler divergence between the normalized scores of the retrieval and the normalized scores of the combined retrieval provides the similarity [1]. 5.",
                "EXPERIMENTS Our experiments focus on testing the predictive power of each of our predictors: ρ(y, ˜y), ρ(y, yµ), and ρ(˜y, yµ).",
                "As stated in Section 2, we are interested in predicting the performance of the retrieval generated by an arbitrary system.",
                "Our methodology is consistent with previous research in that we predict the relative performance of a retrieval by comparing a ranking based on our predictor to a ranking based on average precision.",
                "We present results for two sets of experiments.",
                "The first set of experiments presents detailed comparisons of our predictors to previously-proposed predictors using identical data sets.",
                "Our second set of experiments demonstrates the generalizability of our approach to arbitrary retrieval methods, corpus types, and corpus languages. 5.1 Detailed Experiments In these experiments, we will predict the performance of language modeling scores using our autocorrelation predictor, ρ(y, ˜y); we do not consider ρ(y, yµ) or ρ(˜y, yµ) because, in these detailed experiments, we focus on ranking the retrievals from a single system.",
                "We use retrievals, values for baseline predictors, and evaluation measures reported in previous work [19]. 5.1.1 Topics and Collections These performance prediction experiments use language model retrievals performed for queries associated with collections in the TREC corpora.",
                "Using TREC collections allows us to confidently associate an average precision with a retrieval.",
                "In these experiments, we use the following topic collections: TREC 4 ad-hoc, TREC 5 ad-hoc, Robust 2004, Terabyte 2004, and Terabyte 2005. 5.1.2 Baselines We provide two baselines.",
                "Our first baseline is the classic Clarity predictor presented in Equation 6.",
                "Clarity is designed to be used with language modeling systems.",
                "Our second baseline is Zhou and Crofts ranking robustness predictor.",
                "This predictor corrupts the top k documents from retrieval and re-computes the language model scores for these corrupted documents.",
                "The value of the predictor is the Spearman rank correlation between the original ranking and the corrupted ranking.",
                "In our tables, we will label results for Clarity using DV KL and the ranking robustness predictor using P. 5.2 Generalizability Experiments Our predictors do not require a particular baseline retrieval system; the predictors can be computed for an arbitrary retrieval, regardless of how scores were generated.",
                "We believe that that is one of the most attractive aspects of our algorithm.",
                "Therefore, in a second set of experiments, we demonstrate the ability of our techniques to generalize to a variety of collections, topics, and retrieval systems. 5.2.1 Topics and Collections We gathered a diverse set of collections from all possible TREC corpora.",
                "We cast a wide net in order to locate collections where our predictors might fail.",
                "Our hypothesis is that documents with high topical similarity should have correlated scores.",
                "Therefore, we avoided collections where scores were unlikely to be correlated (eg, question-answering) or were likely to be negatively correlated (eg, novelty).",
                "Nevertheless, our collections include corpora where correlations are weakly justified (eg, non-English corpora) or not justified at all (eg, expert search).",
                "We use the ad-hoc tracks from TREC3-8, TREC Robust 2003-2005, TREC Terabyte 20042005, TREC4-5 Spanish, TREC5-6 Chinese, and TREC Enterprise Expert Search 2005.",
                "In all cases, we use only the automatic runs for ad-hoc tracks submitted to NIST.",
                "For all English and Spanish corpora, we construct the matrix W according to the process described in Section 3.1.",
                "For Chinese corpora, we use na¨ıve character-based tf.idf vectors.",
                "For entities, entries in W are proportional to the number of documents in which two entities cooccur. 5.2.2 Baselines In our detailed experiments, we used the Clarity measure as a baseline.",
                "Since we are predicting the performance of retrievals which are not based on language modeling, we use a version of Clarity referred to as ranked-list Clarity [7].",
                "Ranked-list clarity converts document ranks to P(Q|θi) values.",
                "This conversion begins by replacing all of the scores in y with the respective ranks.",
                "Our estimation of P(Q|θi) from the ranks, then is, P(Q|θi) = ( 2(c+1−yi) c(c+1) if yi ≤ c 0 otherwise (7) where c is a cutoff parameter.",
                "As suggested by the authors, we fix the algorithm parameters c and λ2 so that c = 60 and λ2 = 0.10.",
                "We use Equation 6 to estimate P(w|θQ) and DV KL(θQ θC ) to compute the value of the predictor.",
                "We will refer to this predictor as DV KL, superscripted by V to indicate that the Kullback-Leibler divergence is with respect to the term embedding space.",
                "When information from multiple runs on the same query is available, we use Aslam and Pavlus document-space multinomial divergence as a baseline [1].",
                "This rank-based method first normalizes the scores in a retrieval as an n-dimensional multinomial.",
                "As with ranked-list Clarity, we begin by replacing all of the scores in y with their respective ranks.",
                "Then, we adjust the elements of y in the following way, ˆyi = 1 2n 0 @1 + nX k=yi 1 k 1 A (8) In our multirun experiments, we only use the top 75 documents from each retrieval (n = 75); this is within the range of parameter values suggested by the authors.",
                "However, we admit not tuning this parameter for either our system or the baseline.",
                "The predictor is the divergence between the candidate distribution, y, and the mean distribution, yµ .",
                "With the uniform linear combination of these m retrievals represented as yµ, we can compute the divergence as Dn KL(ˆy ˆyµ) where we use the superscript n to indicate that the summation is over the set of n documents.",
                "This baseline was developed in the context of predicting query difficulty but we adopt it as a reasonable baseline for predicting retrieval performance. 5.2.3 Parameter Settings When given multiple retrievals, we use documents in the union of the top k = 75 documents from each of the m retrievals for that query.",
                "If the size of this union is ˜n, then yµ and each yi is of length ˜n.",
                "In some cases, a system did not score a document in the union.",
                "Since we are making a Gaussian assumption about our scores, we can sample scores for these unseen documents from the negative tail of the distribution.",
                "Specifically, we sample from the part of the distribution lower than the minimum value of in the normalized retrieval.",
                "This introduces randomness into our algorithm but we believe it is more appropriate than assigning an arbitrary fixed value.",
                "We optimized the linear regression using the square root of each predictor.",
                "We found that this substantially improved fits for all predictors, including the baselines.",
                "We considered linear combinations of pairs of predictors (labeled by the components) and all predictors (labeled as β). 5.3 Evaluation Given a set of retrievals, potentially from a combination of queries and systems, we measure the correlation of the rank ordering of this set by the predictor and by the performance metric.",
                "In order to ensure comparability with previous results, we present Kendalls τ correlation between the predictors ranking and ranking based on average precision of the retrieval.",
                "Unless explicitly noted, all correlations are significant with p < 0.05.",
                "Predictors can sometimes perform better when linearly combined [9, 11].",
                "Although previous work has presented the coefficient of determination (R2 ) to measure the quality of the regression, this measure cannot be reliably used when comparing slight improvements from combining predictors.",
                "Therefore, we adopt the adjusted coefficient of determination which penalizes models with more variables.",
                "The adjusted R2 allows us to evaluate the improvement in prediction achieved by adding a parameter but loses the statistical interpretation of R2 .",
                "We will use Kendalls τ to evaluate the magnitude of the correlation and the adjusted R2 to evaluate the combination of variables. 6.",
                "RESULTS We present results for our detailed experiments comparing the prediction of language model scores in Table 1.",
                "Although the Clarity measure is theoretically designed for language model scores, it consistently underperforms our system-agnostic predictor.",
                "Ranking robustness was presented as an improvement to Clarity for web collections (represented in our experiments by the terabyte04 and terabyte05 collections), shifting the τ correlation from 0.139 to 0.150 for terabyte04 and 0.171 to 0.208 for terabyte05.",
                "However, these improvements are slight compared to the performance of autocorrelation on these collections.",
                "Our predictor achieves a τ correlation of 0.454 for terabyte04 and 0.383 for terabyte05.",
                "Though not always the strongest, autocorrelation achieves correlations competitive with baseline predictors.",
                "When examining the performance of linear combinations of predictors, we note that in every case, autocorrelation factors as a necessary component of a strong predictor.",
                "We also note that the adjusted R2 for individual baselines are always significantly improved by incorporating autocorrelation.",
                "We present our generalizability results in Table 2.",
                "We begin by examining the situation in column (a) where we are presented with a single retrieval and no information from additional retrievals.",
                "For every collection except one, we achieve significantly better correlations than ranked-list Clarity.",
                "Surprisingly, we achieve relatively strong correlations for Spanish and Chinese collections despite our na¨ıve processing.",
                "We do not have a ranked-list clarity correlation for ent05 because entity modeling is itself an open research question.",
                "However, our autocorrelation measure does not achieve high correlations perhaps because relevance for entity retrieval does not propagate according to the cooccurrence links we use.",
                "As noted above, the poor Clarity performance on web data is consistent with our findings in the detailed experiments.",
                "Clarity also notably underperforms for several news corpora (trec5, trec7, and robust04).",
                "On the other hand, autocorrelation seems robust to the changes between different corpora.",
                "Next, we turn to the introduction of information from multiple retrievals.",
                "We compare the correlations between those predictors which do not use this information in column (a) and those which do in column (b).",
                "For every collection, the predictors in column (b) outperform the predictors in column (a), indicating that the information from additional runs can be critical to making good predictions.",
                "Inspecting the predictors in column (b), we only draw weak conclusions.",
                "Our new predictors tend to perform better on news corpora.",
                "And between our new predictors, the hybrid ρ(˜y, yµ) predictor tends to perform better.",
                "Recall that our ρ(˜y, yµ) measure incorporates both spatial and multiple retrieval information.",
                "Therefore, we believe that the improvement in correlation is the result of incorporating information from spatial behavior.",
                "In column (c), we can investigate the utility of incorporating spatial information with information from multiple retrievals.",
                "Notice that in the cases where autocorrelation, ρ(y, ˜y), alone performs well (trec3, trec5-spanish, and trec6-chinese), it is substantially improved by incorporating multiple-retrieval information from ρ(y, yµ) in the linear regression, β.",
                "In the cases where ρ(y, yµ) performs well, incorporating autocorrelation rarely results in a significant improvement in performance.",
                "In fact, in every case where our predictor outperforms the baseline, it includes information from multiple runs. 7.",
                "DISCUSSION The most important result from our experiments involves prediction when no information is available from multiple runs (Tables 1 and 2a).",
                "This situation arises often in system design.",
                "For example, a system may need to, at retrieval time, assess its performance before deciding to conduct more intensive processing such as pseudo-relevance feedback or interaction.",
                "Assuming the presence of multiple retrievals is unrealistic in this case.",
                "We believe that autocorrelation is, like multiple-retrieval algorithms, approximating a good ranking; in this case by diffusing scores.",
                "Why is ˜y a reasonable surrogate?",
                "We know that diffusion of scores on the web graph and language model graphs improves performance [14, 16].",
                "Therefore, if score diffusion tends to, in general, improve performance, then diffused scores will, in general, provide a good surrogate for relevance.",
                "Our results demonstrate that this approximation is not as powerful as information from multiple retrievals.",
                "Nevertheless, in situations where this information is lacking, autocorrelation provides substantial information.",
                "The success of autocorrelation as a predictor may also have roots in the clustering hypothesis.",
                "Recall that we regard autocorrelation as the degree to which a retrieval satisfies the clustering hypothesis.",
                "Our experiments, then, demonstrate that a failure to respect the clustering hypothesis correlates with poor performance.",
                "Why might systems fail to conform to the cluster hypothesis?",
                "Query-based information retrieval systems often score documents independently.",
                "The score of document a may be computed by examining query term or phrase matches, the document length, and perhaps global collection statistics.",
                "Once computed, a system rarely compares the score of a to the score of a topically-related document b.",
                "With some exceptions, the correlation of document scores has largely been ignored.",
                "We should make it clear that we have selected tasks where topical autocorrelation is appropriate.",
                "There are certainly cases where there is no reason to believe that retrieval scores will have topical autocorrelation.",
                "For example, ranked lists which incorporate document novelty should not exhibit spatial autocorrelation; if anything autocorrelation should be negative for this task.",
                "Similarly, answer candidates in a question-answering task may or may not exhibit autocorrelation; in this case, the semantics of links is questionable too.",
                "It is important before applying this measure to confirm that, given the semantics for some link between two retrieved items, we should expect a correlation between scores. 8.",
                "RELATED WORK In this section we draw more general comparisons to other work in performance prediction and spatial data analysis.",
                "There is a growing body of work which attempts to predict the performance of individual retrievals [7, 3, 11, 9, 19].",
                "We have attempted to place our work in the context of much of this work in Section 4.",
                "However, a complete comparison is beyond the scope of this paper.",
                "We note, though, that our experiments cover a larger and more diverse set of retrievals, collections, and topics than previously examined.",
                "Much previous work-particularly in the context of TRECfocuses on predicting the performance of systems.",
                "Here, each system generates k retrievals.",
                "The task is, given these retrievals, to predict the ranking of systems according to some performance measure.",
                "Several papers attempt to address this task under the constraint of few judgments [2, 4].",
                "Some work even attempts to use zero judgments by leveraging multiple retrievals for the same query [17].",
                "Our task differs because we focus on ranking retrievals independent of the generating system.",
                "The task here is not to test the hypothesis system A is superior to system B but to test the hypothesis retrieval A is superior to retrieval B. Autocorrelation manifests itself in many classification tasks.",
                "Neville and Jensen define relational autocorrelation for relational learning problems and demonstrate that many classification tasks manifest autocorrelation [13].",
                "Temporal autocorrelation of initial retrievals has also been used to predict performance [9].",
                "However, temporal autocorrelation is performed by projecting the retrieval function into the temporal embedding space.",
                "In our work, we focus on the behavior of the function over the relationships between documents. τ adjusted R2 DV KL P ρ(y, ˜y) DV KL P ρ(y, ˜y) DV KL, P DV KL, ρ(y, ˜y) Pρ(y, ˜y) β trec4 0.353 0.548 0.513 0.168 0.363 0.422 0.466 0.420 0.557 0.553 trec5 0.311 0.329 0.357 0.116 0.190 0.236 0.238 0.244 0.266 0.269 robust04 0.418 0.398 0.373 0.256 0.304 0.278 0.403 0.373 0.402 0.442 terabyte04 0.139 0.150 0.454 0.059 0.045 0.292 0.076 0.293 0.289 0.284 terabyte05 0.171 0.208 0.383 0.022 0.072 0.193 0.120 0.225 0.218 0.257 Table 1: Comparison to Robustness and Clarity measures for language model scores.",
                "Evaluation replicates experiments from [19].",
                "We present correlations between the classic Clarity measure (DV KL), the ranking robustness measure (P), and autocorrelation (ρ(y, ˜y)) each with mean average precision in terms of Kendalls τ.",
                "The adjusted coefficient of determination is presented to measure the effectiveness of combining predictors.",
                "Measures in bold represent the strongest correlation for that test/collection pair. multiple run (a) (b) (c) τ τ adjusted R2 DKL ρ(y, ˜y) Dn KL ρ(y, yµ) ρ(˜y, yµ) Dn KL ρ(y, ˜y) ρ(y, yµ) ρ(˜y, yµ) β trec3 0.201 0.461 0.461 0.439 0.456 0.444 0.395 0.394 0.386 0.498 trec4 0.252 0.396 0.455 0.482 0.489 0.379 0.263 0.429 0.482 0.483 trec5 0.016 0.277 0.433 0.459 0.393 0.280 0.157 0.375 0.323 0.386 trec6 0.230 0.227 0.352 0.428 0.418 0.203 0.089 0.323 0.325 0.325 trec7 0.083 0.326 0.341 0.430 0.483 0.264 0.182 0.363 0.442 0.400 trec8 0.235 0.396 0.454 0.508 0.567 0.402 0.272 0.490 0.580 0.523 robust03 0.302 0.354 0.377 0.385 0.447 0.269 0.206 0.274 0.392 0.303 robust04 0.183 0.308 0.301 0.384 0.453 0.200 0.182 0.301 0.393 0.335 robust05 0.224 0.249 0.371 0.377 0.404 0.341 0.108 0.313 0.328 0.336 terabyte04 0.043 0.245 0.544 0.420 0.392 0.516 0.105 0.357 0.343 0.365 terabyte05 0.068 0.306 0.480 0.434 0.390 0.491 0.168 0.384 0.309 0.403 trec4-spanish 0.307 0.388 0.488 0.398 0.395 0.423 0.299 0.282 0.299 0.388 trec5-spanish 0.220 0.458 0.446 0.484 0.475 0.411 0.398 0.428 0.437 0.529 trec5-chinese 0.092 0.199 0.367 0.379 0.384 0.379 0.199 0.273 0.276 0.310 trec6-chinese 0.144 0.276 0.265 0.353 0.376 0.115 0.128 0.188 0.223 0.199 ent05 - 0.181 0.324 0.305 0.282 0.211 0.043 0.158 0.155 0.179 Table 2: Large scale prediction experiments.",
                "We predict the ranking of large sets of retrievals for various collections and retrieval systems.",
                "Kendalls τ correlations are computed between the predicted ranking and a ranking based on the retrievals average precision.",
                "In column (a), we have predictors which do not use information from other retrievals for the same query.",
                "In columns (b) and (c) we present performance for predictors which incorporate information from multiple retrievals.",
                "The adjusted coefficient of determination is computed to determine effectiveness of combining predictors.",
                "Measures in bold represent the strongest correlation for that test/collection pair.",
                "Finally, regularization-based re-ranking processes are also closely-related to our work [8].",
                "These techniques seek to maximize the agreement between scores of related documents by solving a constrained optimization problem.",
                "The maximization of consistency is equivalent to maximizing the Moran autocorrelation.",
                "Therefore, we believe that our work provides explanation for why regularization-based re-ranking works. 9.",
                "CONCLUSION We have presented a new method for predicting the performance of a retrieval ranking without any relevance judgments.",
                "We consider two cases.",
                "First, when making predictions in the absence of retrievals from other systems, our predictors demonstrate robust, strong correlations with average precision.",
                "This performance, combined with a simple implementation, makes our predictors, in particular, very attractive.",
                "We have demonstrated this improvement for many, diverse settings.",
                "To our knowledge, this is the first large scale examination of zero-judgment, single-retrieval performance prediction.",
                "Second, when provided retrievals from other systems, our extended methods demonstrate competitive performance with state of the art baselines.",
                "Our experiments also demonstrate the limits of the usefulness of our predictors when information from multiple runs is provided.",
                "Our results suggest two conclusions.",
                "First, our results could affect retrieval algorithm design.",
                "Retrieval algorithms designed to consider spatial autocorrelation will conform to the cluster hypothesis and improve performance.",
                "Second, our results could affect the design of minimal test collection algorithms.",
                "Much of the recent work in ranking systems sometimes ignores correlations between document labels and scores.",
                "We believe that these two directions could be rewarding given the theoretical and experimental evidence in this paper. 10.",
                "ACKNOWLEDGMENTS This work was supported in part by the Center for Intelligent Information Retrieval and in part by the Defense Advanced Research Projects Agency (DARPA) under contract number HR0011-06-C-0023.",
                "Any opinions, findings and conclusions or recommendations expressed in this material are the authors and do not necessarily reflect those of the sponsor.",
                "We thank Yun Zhou and Desislava Petkova for providing data and Andre Gauthier for technical assistance. 11.",
                "REFERENCES [1] J. Aslam and V. Pavlu.",
                "Query hardness estimation using jensen-shannon divergence among multiple scoring functions.",
                "In ECIR 2007: Proceedings of the 29th European Conference on Information Retrieval, 2007. [2] J.",
                "A. Aslam, V. Pavlu, and E. Yilmaz.",
                "A statistical method for system evaluation using incomplete judgments.",
                "In S. Dumais, E. N. Efthimiadis, D. Hawking, and K. Jarvelin, editors, Proceedings of the 29th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 541-548.",
                "ACM Press, August 2006. [3] D. Carmel, E. Yom-Tov, A. Darlow, and D. Pelleg.",
                "What makes a query difficult?",
                "In SIGIR 06: Proceedings of the 29th annual international ACM SIGIR conference on Research and development in information retrieval, pages 390-397, New York, NY, USA, 2006.",
                "ACM Press. [4] B. Carterette, J. Allan, and R. Sitaraman.",
                "Minimal test collections for retrieval evaluation.",
                "In SIGIR 06: Proceedings of the 29th annual international ACM SIGIR conference on Research and development in information retrieval, pages 268-275, New York, NY, USA, 2006.",
                "ACM Press. [5] A. D. Cliff and J. K. Ord.",
                "Spatial Autocorrelation.",
                "Pion Ltd., 1973. [6] M. Connell, A. Feng, G. Kumaran, H. Raghavan, C. Shah, and J. Allan.",
                "Umass at tdt 2004.",
                "Technical Report CIIR Technical Report IR - 357, Department of Computer Science, University of Massachusetts, 2004. [7] S. Cronen-Townsend, Y. Zhou, and W. B. Croft.",
                "Precision prediction based on ranked list coherence.",
                "Inf.",
                "Retr., 9(6):723-755, 2006. [8] F. Diaz.",
                "Regularizing ad-hoc retrieval scores.",
                "In CIKM 05: Proceedings of the 14th ACM international conference on Information and knowledge management, pages 672-679, New York, NY, USA, 2005.",
                "ACM Press. [9] F. Diaz and R. Jones.",
                "Using temporal profiles of queries for precision prediction.",
                "In SIGIR 04: Proceedings of the 27th annual international ACM SIGIR conference on Research and development in information retrieval, pages 18-24, New York, NY, USA, 2004.",
                "ACM Press. [10] D. A. Griffith.",
                "Spatial Autocorrelation and Spatial Filtering.",
                "Springer Verlag, 2003. [11] B.",
                "He and I. Ounis.",
                "Inferring Query Performance Using Pre-retrieval Predictors.",
                "In The Eleventh Symposium on String Processing and Information Retrieval (SPIRE), 2004. [12] N. Jardine and C. J. V. Rijsbergen.",
                "The use of hierarchic clustering in information retrieval.",
                "Information Storage and Retrieval, 7:217-240, 1971. [13] D. Jensen and J. Neville.",
                "Linkage and autocorrelation cause feature selection bias in relational learning.",
                "In ICML 02: Proceedings of the Nineteenth International Conference on Machine Learning, pages 259-266, San Francisco, CA, USA, 2002.",
                "Morgan Kaufmann Publishers Inc. [14] O. Kurland and L. Lee.",
                "Corpus structure, language models, and ad-hoc information retrieval.",
                "In SIGIR 04: Proceedings of the 27th annual international conference on Research and development in information retrieval, pages 194-201, New York, NY, USA, 2004.",
                "ACM Press. [15] M. Montague and J.",
                "A. Aslam.",
                "Relevance score normalization for metasearch.",
                "In CIKM 01: Proceedings of the tenth international conference on Information and knowledge management, pages 427-433, New York, NY, USA, 2001.",
                "ACM Press. [16] T. Qin, T.-Y.",
                "Liu, X.-D. Zhang, Z. Chen, and W.-Y.",
                "Ma.",
                "A study of relevance propagation for web search.",
                "In SIGIR 05: Proceedings of the 28th annual international ACM SIGIR conference on Research and development in information retrieval, pages 408-415, New York, NY, USA, 2005.",
                "ACM Press. [17] I. Soboroff, C. Nicholas, and P. Cahan.",
                "Ranking retrieval systems without relevance judgments.",
                "In SIGIR 01: Proceedings of the 24th annual international ACM SIGIR conference on Research and development in information retrieval, pages 66-73, New York, NY, USA, 2001.",
                "ACM Press. [18] V. Vinay, I. J. Cox, N. Milic-Frayling, and K. Wood.",
                "On ranking the effectiveness of searches.",
                "In SIGIR 06: Proceedings of the 29th annual international ACM SIGIR conference on Research and development in information retrieval, pages 398-404, New York, NY, USA, 2006.",
                "ACM Press. [19] Y. Zhou and W. B. Croft.",
                "Ranking robustness: a novel framework to predict query performance.",
                "In CIKM 06: Proceedings of the 15th ACM international conference on Information and knowledge management, pages 567-574, New York, NY, USA, 2006.",
                "ACM Press."
            ],
            "original_annotated_samples": [],
            "translated_annotated_samples": [],
            "translated_text": "",
            "candidates": [],
            "error": [
                []
            ]
        },
        "predictor predictive power": {
            "translated_key": "poder predictivo del predictor",
            "is_in_text": false,
            "original_annotated_sentences": [
                "Performance Prediction Using Spatial Autocorrelation Fernando Diaz Center for Intelligent Information Retrieval Department of Computer Science University of Massachusetts Amherst, MA 01003 fdiaz@cs.umass.edu ABSTRACT Evaluation of information retrieval systems is one of the core tasks in information retrieval.",
                "Problems include the inability to exhaustively label all documents for a topic, nongeneralizability from a small number of topics, and incorporating the variability of retrieval systems.",
                "Previous work addresses the evaluation of systems, the ranking of queries by difficulty, and the ranking of individual retrievals by performance.",
                "Approaches exist for the case of few and even no relevance judgments.",
                "Our focus is on zero-judgment performance prediction of individual retrievals.",
                "One common shortcoming of previous techniques is the assumption of uncorrelated document scores and judgments.",
                "If documents are embedded in a high-dimensional space (as they often are), we can apply techniques from spatial data analysis to detect correlations between document scores.",
                "We find that the low correlation between scores of topically close documents often implies a poor retrieval performance.",
                "When compared to a state of the art baseline, we demonstrate that the spatial analysis of retrieval scores provides significantly better prediction performance.",
                "These new predictors can also be incorporated with classic predictors to improve performance further.",
                "We also describe the first large-scale experiment to evaluate zero-judgment performance prediction for a massive number of retrieval systems over a variety of collections in several languages.",
                "Categories and Subject Descriptors H.3.3 [Information Search and Retrieval]: Retrieval models; H.3.4 [Systems and Software]: Performance evaluation (efficiency and effectiveness) General Terms Performance, Design, Reliability, Experimentation 1.",
                "INTRODUCTION In information retrieval, a user poses a query to a system.",
                "The system retrieves n documents each receiving a realvalued score indicating the predicted degree of relevance.",
                "If we randomly select pairs of documents from this set, we expect some pairs to share the same topic and other pairs to not share the same topic.",
                "Take two topically-related documents from the set and call them a and b.",
                "If the scores of a and b are very different, we may be concerned about the performance of our system.",
                "That is, if a and b are both on the topic of the query, we would like them both to receive a high score; if a and b are not on the topic of the query, we would like them both to receive a low score.",
                "We might become more worried as we find more differences between scores of related documents.",
                "We would be more comfortable with a retrieval where scores are consistent between related documents.",
                "Our paper studies the quantification of this inconsistency in a retrieval from a spatial perspective.",
                "Spatial analysis is appropriate since many retrieval models embed documents in some vector space.",
                "If documents are embedded in a space, proximity correlates with topical relationships.",
                "Score consistency can be measured by the spatial version of autocorrelation known as the Moran coefficient or IM [5, 10].",
                "In this paper, we demonstrate a strong correlation between IM and retrieval performance.",
                "The discussion up to this point is reminiscent of the cluster hypothesis.",
                "The cluster hypothesis states: closely-related documents tend to be relevant to the same request [12].",
                "As we shall see, a retrieval functions spatial autocorrelation measures the degree to which closely-related documents receive similar scores.",
                "Because of this, we interpret autocorrelation as measuring the degree to which a retrieval function satisfies the clustering hypothesis.",
                "If this connection is reasonable, in Section 6, we present evidence that failure to satisfy the cluster hypothesis correlates strongly with poor performance.",
                "In this work, we provide the following contributions, 1.",
                "A general, robust method for predicting the performance of retrievals with zero relevance judgments (Section 3). 2.",
                "A theoretical treatment of the similarities and motivations behind several state-of-the-art performance prediction techniques (Section 4). 3.",
                "The first large-scale experiments of zero-judgment, single run performance prediction (Sections 5 and 6). 2.",
                "PROBLEM DEFINITION Given a query, an information retrieval system produces a ranking of documents in the collection encoded as a set of scores associated with documents.",
                "We refer to the set of scores for a particular query-system combination as a retrieval.",
                "We would like to predict the performance of this retrieval with respect to some evaluation measure (eg, mean average precision).",
                "In this paper, we present results for ranking retrievals from arbitrary systems.",
                "We would like this ranking to approximate the ranking of retrievals by the evaluation measure.",
                "This is different from ranking queries by the average performance on each query.",
                "It is also different from ranking systems by the average performance on a set of queries.",
                "Scores are often only computed for the top n documents from the collection.",
                "We place these scores in the length n vector, y, where yi refers to the score of the ith-ranked document.",
                "We adjust scores to have zero mean and unit variance.",
                "We use this method because of its simplicity and its success in previous work [15]. 3.",
                "SPATIAL CORRELATION In information retrieval, we often assume that the representations of documents exist in some high-dimensional vector space.",
                "For example, given a vocabulary, V, this vector space may be an arbitrary |V|-dimensional space with cosine inner-product or a multinomial simplex with a distributionbased distance measure.",
                "An embedding space is often selected to respect topical proximity; if two documents are near, they are more likely to share a topic.",
                "Because of the prevalence and success of spatial models of information retrieval, we believe that the application of spatial data analysis techniques are appropriate.",
                "Whereas in information retrieval, we are concerned with the score at a point in a space, in spatial data analysis, we are concerned with the value of a function at a point or location in a space.",
                "We use the term function here to mean a mapping from a location to a real value.",
                "For example, we might be interested in the prevalence of a disease in the neighborhood of some city.",
                "The function would map the location of a neighborhood to an infection rate.",
                "If we want to quantify the spatial dependencies of a function, we would employ a measure referred to as the spatial autocorrelation [5, 10].",
                "High spatial autocorrelation suggests that knowing the value of a function at location a will tell us a great deal about the value at a neighboring location b.",
                "There is a high spatial autocorrelation for a function representing the temperature of a location since knowing the temperature at a location a will tell us a lot about the temperature at a neighboring location b.",
                "Low spatial autocorrelation suggests that knowing the value of a function at location a tells us little about the value at a neighboring location b.",
                "There is low spatial autocorrelation in a function measuring the outcome of a coin toss at a and b.",
                "In this section, we will begin by describing what we mean by spatial proximity for documents and then define a measure of spatial autocorrelation.",
                "We conclude by extending this model to include information from multiple retrievals from multiple systems for a single query. 3.1 Spatial Representation of Documents Our work does not focus on improving a specific similarity measure or defining a novel vector space.",
                "Instead, we choose an inner product known to be effective at detecting interdocument topical relationships.",
                "Specifically, we adopt tf.idf document vectors, ˜di = di log „ (n + 0.5) − ci 0.5 + ci « (1) where d is a vector of term frequencies, c is the length-|V| document frequency vector.",
                "We use this weighting scheme due to its success for topical link detection in the context of Topic Detection and Tracking (TDT) evaluations [6].",
                "Assuming vectors are scaled by their L2 norm, we use the inner product, ˜di, ˜dj , to define similarity.",
                "Given documents and some similarity measure, we can construct a matrix which encodes the similarity between pairs of documents.",
                "Recall that we are given the top n documents retrieved in y.",
                "We can compute an n × n similarity matrix, W. An element of this matrix, Wij represents the similarity between documents ranked i and j.",
                "In practice, we only include the affinities for a documents k-nearest neighbors.",
                "In all of our experiments, we have fixed k to 5.",
                "We leave exploration of parameter sensitivity to future work.",
                "We also row normalize the matrix so that Pn j=1 Wij = 1 for all i. 3.2 Spatial Autocorrelation of a Retrieval Recall that we are interested in measuring the similarity between the scores of spatially-close documents.",
                "One such suitable measure is the Moran coefficient of spatial autocorrelation.",
                "Assuming the function y over n locations, this is defined as ˜IM = n eTWe P i,j Wijyiyj P i y2 i = n eTWe yT Wy yTy (2) where eT We = P ij Wij.",
                "We would like to compare autocorrelation values for different retrievals.",
                "Unfortunately, the bound for Equation 2 is not consistent for different W and y.",
                "Therefore, we use the Cauchy-Schwartz inequality to establish a bound, ˜IM ≤ n eTWe s yTWTWy yTy And we define the normalized spatial autocorrelation as IM = yT Wy p yTy × yTWTWy Notice that if we let ˜y = Wy, then we can write this formula as, IM = yT ˜y y 2 ˜y 2 (3) which can be interpreted as the correlation between the original retrieval scores and a set of retrieval scores diffused in the space.",
                "We present some examples of autocorrelations of functions on a grid in Figure 1. 3.3 Correlation with Other Retrievals Sometimes we are interested in the performance of a single retrieval but have access to scores from multiple systems for (a) IM = 0.006 (b) IM = 0.241 (c) IM = 0.487 Figure 1: The Moran coefficient, IM for a several binary functions on a grid.",
                "The Moran coefficient is a local measure of function consistency.",
                "From the perspective of information retrieval, each of these grid spaces would represent a document and documents would be organized so that they lay next to topically-related documents.",
                "Binary retrieval scores would define a pattern on this grid.",
                "Notice that, as the Moran coefficient increases, neighboring cells tend to have similar values. the same query.",
                "In this situation, we can use combined information from these scores to construct a surrogate for a high-quality ranking [17].",
                "We can treat the correlation between the retrieval we are interested in and the combined scores as a predictor of performance.",
                "Assume that we are given m score functions, yi, for the same n documents.",
                "We will represent the mean of these vectors as yµ = Pm i=1 yi.",
                "We use the mean vector as an approximation to relevance.",
                "Since we use zero mean and unit variance normalization, work in metasearch suggests that this assumption is justified [15].",
                "Because yµ represents a very good retrieval, we hypothesize that a strong similarity between yµ and y will correlate positively with system performance.",
                "We use Pearsons product-moment correlation to measure the similarity between these vectors, ρ(y, yµ) = yT yµ y 2 yµ 2 (4) We will comment on the similarity between Equation 3 and 4 in Section 7.",
                "Of course, we can combine ρ(y, ˜y) and ρ(y, yµ) if we assume that they capture different factors in the prediction.",
                "One way to accomplish this is to combine these predictors as independent variables in a linear regression.",
                "An alternative means of combination is suggested by the mathematical form of our predictors.",
                "Since ˜y encodes the spatial dependencies in y and yµ encodes the spatial properties of the multiple runs, we can compute a third correlation between these two vectors, ρ(˜y, yµ) = ˜yT yµ ˜y 2 yµ 2 (5) We can interpret Equation 5 as measuring the correlation between a high quality ranking (yµ) and a spatially smoothed version of the retrieval (˜y). 4.",
                "RELATIONSHIP WITH OTHER PREDICTORS One way to predict the effectiveness of a retrieval is to look at the shared vocabulary of the top n retrieved documents.",
                "If we computed the most frequent content words in this set, we would hope that they would be consistent with our topic.",
                "In fact, we might believe that a bad retrieval would include documents on many disparate topics, resulting in an overlap of terminological noise.",
                "The Clarity of a query attempts to quantify exactly this [7].",
                "Specifically, Clarity measures the similarity of the words most frequently used in retrieved documents to those most frequently used in the whole corpus.",
                "The conjecture is that a good retrieval will use language distinct from general text; the overlapping language in a bad retrieval will tend to be more similar to general text.",
                "Mathematically, we can compute a representation of the language used in the initial retrieval as a weighted combination of document language models, P(w|θQ) = nX i=1 P(w|θi) P(Q|θi) Z (6) where θi is the language model of the ith-ranked document, P(Q|θi) is the query likelihood score of the ith-ranked document and Z = Pn i=1 P(Q|θi) is a normalization constant.",
                "The similarity between the multinomial P(w|θQ) and a model of general text can be computed using the Kullback-Leibler divergence, DV KL(θQ θC ).",
                "Here, the distribution P(w|θC ) is our model of general text which can be computed using term frequencies in the corpus.",
                "In Figure 2a, we present Clarity as measuring the distance between the weighted center of mass of the retrieval (labeled y) and the unweighted center of mass of the collection (labeled O).",
                "Clarity reaches a minimum when a retrieval assigns every document the same score.",
                "Lets again assume we have a set of n documents retrieved for our query.",
                "Another way to quantify the dispersion of a set of documents is to look at how clustered they are.",
                "We may hypothesize that a good retrieval will return a single, tight cluster.",
                "A poorly performing retrieval will return a loosely related set of documents covering many topics.",
                "One proposed method of quantifying this dispersion is to measure the distance from a random document a to its nearest neighbor, b.",
                "A retrieval which is tightly clustered will, on average, have a low distance between a and b; a retrieval which is less tightly-closed will, on average have high distances between a and b.",
                "This average corresponds to using the Cox-Lewis statistic to measure the randomness of the top n documents retrieved from a system [18].",
                "In Figure 2a, this is roughly equivalent to measuring the area of the set n. Notice that we are throwing away information about the retrieval function y.",
                "Therefore the Cox-Lewis statistic is highly dependent on selecting the top n documents.1 Remember that we have n documents and a set of scores.",
                "Lets assume that we have access to the system which provided the original scores and that we can also request scores for new documents.",
                "This suggests a third method for predicting performance.",
                "Take some document, a, from the retrieved set and arbitrarily add or remove words at random to create a new document ˜a.",
                "Now, we can ask our system to score ˜a with respect to our query.",
                "If, on average over the n documents, the scores of a and ˜a tend to be very different, we might suspect that the system is failing on this query.",
                "So, an alternative approach is to measure the simi1 The authors have suggested coupling the query with the distance measure [18].",
                "The information introduced by the query, though, is retrieval-independent so that, if two retrievals return the same set of documents, the approximate Cox-Lewis statistic will be the same regardless of the retrieval scores. yOy (a) Global Divergence µ(y)˜y y (b) Score Perturbation µ(y) y (c) Multirun Averaging Figure 2: Representation of several performance predictors on a grid.",
                "In Figure 2a, we depict predictors which measure the divergence between the center of mass of a retrieval and the center of the embedding space.",
                "In Figure 2b, we depict predictors which compare the original retrieval, y, to a perturbed version of the retrieval, ˜y.",
                "Our approach uses a particular type of perturbation based on score diffusion.",
                "Finally, in Figure 2c, we depict prediction when given retrievals from several other systems on the same query.",
                "Here, we can consider the fusion of these retrieval as a surrogate for relevance. larity between the retrieval and a perturbed version of that retrieval [18, 19].",
                "This can be accomplished by either perturbing the documents or queries.",
                "The similarity between the two retrievals can be measured using some correlation measure.",
                "This is depicted in Figure 2b.",
                "The upper grid represents the original retrieval, y, while the lower grid represents the function after having been perturbed, ˜y.",
                "The nature of the perturbation process requires additional scorings or retrievals.",
                "Our predictor does not require access to the original scoring function or additional retrievals.",
                "So, although our method is similar to other perturbation methods in spirit, it can be applied in situations when the retrieval system is inaccessible or costly to access.",
                "Finally, assume that we have, in addition to the retrieval we want to evaluate, m retrievals from a variety of different systems.",
                "In this case, we might take a document a, compare its rank in the retrieval to its average rank in the m retrievals.",
                "If we believe that the m retrievals provide a satisfactory approximation to relevance, then a very large difference in rank would suggest that our retrieval is misranking a.",
                "If this difference is large on average over all n documents, then we might predict that the retrieval is bad.",
                "If, on the other hand, the retrieval is very consistent with the m retrievals, then we might predict that the retrieval is good.",
                "The similarity between the retrieval and the combined retrieval may be computed using some correlation measure.",
                "This is depicted in Figure 2c.",
                "In previous work, the Kullback-Leibler divergence between the normalized scores of the retrieval and the normalized scores of the combined retrieval provides the similarity [1]. 5.",
                "EXPERIMENTS Our experiments focus on testing the predictive power of each of our predictors: ρ(y, ˜y), ρ(y, yµ), and ρ(˜y, yµ).",
                "As stated in Section 2, we are interested in predicting the performance of the retrieval generated by an arbitrary system.",
                "Our methodology is consistent with previous research in that we predict the relative performance of a retrieval by comparing a ranking based on our predictor to a ranking based on average precision.",
                "We present results for two sets of experiments.",
                "The first set of experiments presents detailed comparisons of our predictors to previously-proposed predictors using identical data sets.",
                "Our second set of experiments demonstrates the generalizability of our approach to arbitrary retrieval methods, corpus types, and corpus languages. 5.1 Detailed Experiments In these experiments, we will predict the performance of language modeling scores using our autocorrelation predictor, ρ(y, ˜y); we do not consider ρ(y, yµ) or ρ(˜y, yµ) because, in these detailed experiments, we focus on ranking the retrievals from a single system.",
                "We use retrievals, values for baseline predictors, and evaluation measures reported in previous work [19]. 5.1.1 Topics and Collections These performance prediction experiments use language model retrievals performed for queries associated with collections in the TREC corpora.",
                "Using TREC collections allows us to confidently associate an average precision with a retrieval.",
                "In these experiments, we use the following topic collections: TREC 4 ad-hoc, TREC 5 ad-hoc, Robust 2004, Terabyte 2004, and Terabyte 2005. 5.1.2 Baselines We provide two baselines.",
                "Our first baseline is the classic Clarity predictor presented in Equation 6.",
                "Clarity is designed to be used with language modeling systems.",
                "Our second baseline is Zhou and Crofts ranking robustness predictor.",
                "This predictor corrupts the top k documents from retrieval and re-computes the language model scores for these corrupted documents.",
                "The value of the predictor is the Spearman rank correlation between the original ranking and the corrupted ranking.",
                "In our tables, we will label results for Clarity using DV KL and the ranking robustness predictor using P. 5.2 Generalizability Experiments Our predictors do not require a particular baseline retrieval system; the predictors can be computed for an arbitrary retrieval, regardless of how scores were generated.",
                "We believe that that is one of the most attractive aspects of our algorithm.",
                "Therefore, in a second set of experiments, we demonstrate the ability of our techniques to generalize to a variety of collections, topics, and retrieval systems. 5.2.1 Topics and Collections We gathered a diverse set of collections from all possible TREC corpora.",
                "We cast a wide net in order to locate collections where our predictors might fail.",
                "Our hypothesis is that documents with high topical similarity should have correlated scores.",
                "Therefore, we avoided collections where scores were unlikely to be correlated (eg, question-answering) or were likely to be negatively correlated (eg, novelty).",
                "Nevertheless, our collections include corpora where correlations are weakly justified (eg, non-English corpora) or not justified at all (eg, expert search).",
                "We use the ad-hoc tracks from TREC3-8, TREC Robust 2003-2005, TREC Terabyte 20042005, TREC4-5 Spanish, TREC5-6 Chinese, and TREC Enterprise Expert Search 2005.",
                "In all cases, we use only the automatic runs for ad-hoc tracks submitted to NIST.",
                "For all English and Spanish corpora, we construct the matrix W according to the process described in Section 3.1.",
                "For Chinese corpora, we use na¨ıve character-based tf.idf vectors.",
                "For entities, entries in W are proportional to the number of documents in which two entities cooccur. 5.2.2 Baselines In our detailed experiments, we used the Clarity measure as a baseline.",
                "Since we are predicting the performance of retrievals which are not based on language modeling, we use a version of Clarity referred to as ranked-list Clarity [7].",
                "Ranked-list clarity converts document ranks to P(Q|θi) values.",
                "This conversion begins by replacing all of the scores in y with the respective ranks.",
                "Our estimation of P(Q|θi) from the ranks, then is, P(Q|θi) = ( 2(c+1−yi) c(c+1) if yi ≤ c 0 otherwise (7) where c is a cutoff parameter.",
                "As suggested by the authors, we fix the algorithm parameters c and λ2 so that c = 60 and λ2 = 0.10.",
                "We use Equation 6 to estimate P(w|θQ) and DV KL(θQ θC ) to compute the value of the predictor.",
                "We will refer to this predictor as DV KL, superscripted by V to indicate that the Kullback-Leibler divergence is with respect to the term embedding space.",
                "When information from multiple runs on the same query is available, we use Aslam and Pavlus document-space multinomial divergence as a baseline [1].",
                "This rank-based method first normalizes the scores in a retrieval as an n-dimensional multinomial.",
                "As with ranked-list Clarity, we begin by replacing all of the scores in y with their respective ranks.",
                "Then, we adjust the elements of y in the following way, ˆyi = 1 2n 0 @1 + nX k=yi 1 k 1 A (8) In our multirun experiments, we only use the top 75 documents from each retrieval (n = 75); this is within the range of parameter values suggested by the authors.",
                "However, we admit not tuning this parameter for either our system or the baseline.",
                "The predictor is the divergence between the candidate distribution, y, and the mean distribution, yµ .",
                "With the uniform linear combination of these m retrievals represented as yµ, we can compute the divergence as Dn KL(ˆy ˆyµ) where we use the superscript n to indicate that the summation is over the set of n documents.",
                "This baseline was developed in the context of predicting query difficulty but we adopt it as a reasonable baseline for predicting retrieval performance. 5.2.3 Parameter Settings When given multiple retrievals, we use documents in the union of the top k = 75 documents from each of the m retrievals for that query.",
                "If the size of this union is ˜n, then yµ and each yi is of length ˜n.",
                "In some cases, a system did not score a document in the union.",
                "Since we are making a Gaussian assumption about our scores, we can sample scores for these unseen documents from the negative tail of the distribution.",
                "Specifically, we sample from the part of the distribution lower than the minimum value of in the normalized retrieval.",
                "This introduces randomness into our algorithm but we believe it is more appropriate than assigning an arbitrary fixed value.",
                "We optimized the linear regression using the square root of each predictor.",
                "We found that this substantially improved fits for all predictors, including the baselines.",
                "We considered linear combinations of pairs of predictors (labeled by the components) and all predictors (labeled as β). 5.3 Evaluation Given a set of retrievals, potentially from a combination of queries and systems, we measure the correlation of the rank ordering of this set by the predictor and by the performance metric.",
                "In order to ensure comparability with previous results, we present Kendalls τ correlation between the predictors ranking and ranking based on average precision of the retrieval.",
                "Unless explicitly noted, all correlations are significant with p < 0.05.",
                "Predictors can sometimes perform better when linearly combined [9, 11].",
                "Although previous work has presented the coefficient of determination (R2 ) to measure the quality of the regression, this measure cannot be reliably used when comparing slight improvements from combining predictors.",
                "Therefore, we adopt the adjusted coefficient of determination which penalizes models with more variables.",
                "The adjusted R2 allows us to evaluate the improvement in prediction achieved by adding a parameter but loses the statistical interpretation of R2 .",
                "We will use Kendalls τ to evaluate the magnitude of the correlation and the adjusted R2 to evaluate the combination of variables. 6.",
                "RESULTS We present results for our detailed experiments comparing the prediction of language model scores in Table 1.",
                "Although the Clarity measure is theoretically designed for language model scores, it consistently underperforms our system-agnostic predictor.",
                "Ranking robustness was presented as an improvement to Clarity for web collections (represented in our experiments by the terabyte04 and terabyte05 collections), shifting the τ correlation from 0.139 to 0.150 for terabyte04 and 0.171 to 0.208 for terabyte05.",
                "However, these improvements are slight compared to the performance of autocorrelation on these collections.",
                "Our predictor achieves a τ correlation of 0.454 for terabyte04 and 0.383 for terabyte05.",
                "Though not always the strongest, autocorrelation achieves correlations competitive with baseline predictors.",
                "When examining the performance of linear combinations of predictors, we note that in every case, autocorrelation factors as a necessary component of a strong predictor.",
                "We also note that the adjusted R2 for individual baselines are always significantly improved by incorporating autocorrelation.",
                "We present our generalizability results in Table 2.",
                "We begin by examining the situation in column (a) where we are presented with a single retrieval and no information from additional retrievals.",
                "For every collection except one, we achieve significantly better correlations than ranked-list Clarity.",
                "Surprisingly, we achieve relatively strong correlations for Spanish and Chinese collections despite our na¨ıve processing.",
                "We do not have a ranked-list clarity correlation for ent05 because entity modeling is itself an open research question.",
                "However, our autocorrelation measure does not achieve high correlations perhaps because relevance for entity retrieval does not propagate according to the cooccurrence links we use.",
                "As noted above, the poor Clarity performance on web data is consistent with our findings in the detailed experiments.",
                "Clarity also notably underperforms for several news corpora (trec5, trec7, and robust04).",
                "On the other hand, autocorrelation seems robust to the changes between different corpora.",
                "Next, we turn to the introduction of information from multiple retrievals.",
                "We compare the correlations between those predictors which do not use this information in column (a) and those which do in column (b).",
                "For every collection, the predictors in column (b) outperform the predictors in column (a), indicating that the information from additional runs can be critical to making good predictions.",
                "Inspecting the predictors in column (b), we only draw weak conclusions.",
                "Our new predictors tend to perform better on news corpora.",
                "And between our new predictors, the hybrid ρ(˜y, yµ) predictor tends to perform better.",
                "Recall that our ρ(˜y, yµ) measure incorporates both spatial and multiple retrieval information.",
                "Therefore, we believe that the improvement in correlation is the result of incorporating information from spatial behavior.",
                "In column (c), we can investigate the utility of incorporating spatial information with information from multiple retrievals.",
                "Notice that in the cases where autocorrelation, ρ(y, ˜y), alone performs well (trec3, trec5-spanish, and trec6-chinese), it is substantially improved by incorporating multiple-retrieval information from ρ(y, yµ) in the linear regression, β.",
                "In the cases where ρ(y, yµ) performs well, incorporating autocorrelation rarely results in a significant improvement in performance.",
                "In fact, in every case where our predictor outperforms the baseline, it includes information from multiple runs. 7.",
                "DISCUSSION The most important result from our experiments involves prediction when no information is available from multiple runs (Tables 1 and 2a).",
                "This situation arises often in system design.",
                "For example, a system may need to, at retrieval time, assess its performance before deciding to conduct more intensive processing such as pseudo-relevance feedback or interaction.",
                "Assuming the presence of multiple retrievals is unrealistic in this case.",
                "We believe that autocorrelation is, like multiple-retrieval algorithms, approximating a good ranking; in this case by diffusing scores.",
                "Why is ˜y a reasonable surrogate?",
                "We know that diffusion of scores on the web graph and language model graphs improves performance [14, 16].",
                "Therefore, if score diffusion tends to, in general, improve performance, then diffused scores will, in general, provide a good surrogate for relevance.",
                "Our results demonstrate that this approximation is not as powerful as information from multiple retrievals.",
                "Nevertheless, in situations where this information is lacking, autocorrelation provides substantial information.",
                "The success of autocorrelation as a predictor may also have roots in the clustering hypothesis.",
                "Recall that we regard autocorrelation as the degree to which a retrieval satisfies the clustering hypothesis.",
                "Our experiments, then, demonstrate that a failure to respect the clustering hypothesis correlates with poor performance.",
                "Why might systems fail to conform to the cluster hypothesis?",
                "Query-based information retrieval systems often score documents independently.",
                "The score of document a may be computed by examining query term or phrase matches, the document length, and perhaps global collection statistics.",
                "Once computed, a system rarely compares the score of a to the score of a topically-related document b.",
                "With some exceptions, the correlation of document scores has largely been ignored.",
                "We should make it clear that we have selected tasks where topical autocorrelation is appropriate.",
                "There are certainly cases where there is no reason to believe that retrieval scores will have topical autocorrelation.",
                "For example, ranked lists which incorporate document novelty should not exhibit spatial autocorrelation; if anything autocorrelation should be negative for this task.",
                "Similarly, answer candidates in a question-answering task may or may not exhibit autocorrelation; in this case, the semantics of links is questionable too.",
                "It is important before applying this measure to confirm that, given the semantics for some link between two retrieved items, we should expect a correlation between scores. 8.",
                "RELATED WORK In this section we draw more general comparisons to other work in performance prediction and spatial data analysis.",
                "There is a growing body of work which attempts to predict the performance of individual retrievals [7, 3, 11, 9, 19].",
                "We have attempted to place our work in the context of much of this work in Section 4.",
                "However, a complete comparison is beyond the scope of this paper.",
                "We note, though, that our experiments cover a larger and more diverse set of retrievals, collections, and topics than previously examined.",
                "Much previous work-particularly in the context of TRECfocuses on predicting the performance of systems.",
                "Here, each system generates k retrievals.",
                "The task is, given these retrievals, to predict the ranking of systems according to some performance measure.",
                "Several papers attempt to address this task under the constraint of few judgments [2, 4].",
                "Some work even attempts to use zero judgments by leveraging multiple retrievals for the same query [17].",
                "Our task differs because we focus on ranking retrievals independent of the generating system.",
                "The task here is not to test the hypothesis system A is superior to system B but to test the hypothesis retrieval A is superior to retrieval B. Autocorrelation manifests itself in many classification tasks.",
                "Neville and Jensen define relational autocorrelation for relational learning problems and demonstrate that many classification tasks manifest autocorrelation [13].",
                "Temporal autocorrelation of initial retrievals has also been used to predict performance [9].",
                "However, temporal autocorrelation is performed by projecting the retrieval function into the temporal embedding space.",
                "In our work, we focus on the behavior of the function over the relationships between documents. τ adjusted R2 DV KL P ρ(y, ˜y) DV KL P ρ(y, ˜y) DV KL, P DV KL, ρ(y, ˜y) Pρ(y, ˜y) β trec4 0.353 0.548 0.513 0.168 0.363 0.422 0.466 0.420 0.557 0.553 trec5 0.311 0.329 0.357 0.116 0.190 0.236 0.238 0.244 0.266 0.269 robust04 0.418 0.398 0.373 0.256 0.304 0.278 0.403 0.373 0.402 0.442 terabyte04 0.139 0.150 0.454 0.059 0.045 0.292 0.076 0.293 0.289 0.284 terabyte05 0.171 0.208 0.383 0.022 0.072 0.193 0.120 0.225 0.218 0.257 Table 1: Comparison to Robustness and Clarity measures for language model scores.",
                "Evaluation replicates experiments from [19].",
                "We present correlations between the classic Clarity measure (DV KL), the ranking robustness measure (P), and autocorrelation (ρ(y, ˜y)) each with mean average precision in terms of Kendalls τ.",
                "The adjusted coefficient of determination is presented to measure the effectiveness of combining predictors.",
                "Measures in bold represent the strongest correlation for that test/collection pair. multiple run (a) (b) (c) τ τ adjusted R2 DKL ρ(y, ˜y) Dn KL ρ(y, yµ) ρ(˜y, yµ) Dn KL ρ(y, ˜y) ρ(y, yµ) ρ(˜y, yµ) β trec3 0.201 0.461 0.461 0.439 0.456 0.444 0.395 0.394 0.386 0.498 trec4 0.252 0.396 0.455 0.482 0.489 0.379 0.263 0.429 0.482 0.483 trec5 0.016 0.277 0.433 0.459 0.393 0.280 0.157 0.375 0.323 0.386 trec6 0.230 0.227 0.352 0.428 0.418 0.203 0.089 0.323 0.325 0.325 trec7 0.083 0.326 0.341 0.430 0.483 0.264 0.182 0.363 0.442 0.400 trec8 0.235 0.396 0.454 0.508 0.567 0.402 0.272 0.490 0.580 0.523 robust03 0.302 0.354 0.377 0.385 0.447 0.269 0.206 0.274 0.392 0.303 robust04 0.183 0.308 0.301 0.384 0.453 0.200 0.182 0.301 0.393 0.335 robust05 0.224 0.249 0.371 0.377 0.404 0.341 0.108 0.313 0.328 0.336 terabyte04 0.043 0.245 0.544 0.420 0.392 0.516 0.105 0.357 0.343 0.365 terabyte05 0.068 0.306 0.480 0.434 0.390 0.491 0.168 0.384 0.309 0.403 trec4-spanish 0.307 0.388 0.488 0.398 0.395 0.423 0.299 0.282 0.299 0.388 trec5-spanish 0.220 0.458 0.446 0.484 0.475 0.411 0.398 0.428 0.437 0.529 trec5-chinese 0.092 0.199 0.367 0.379 0.384 0.379 0.199 0.273 0.276 0.310 trec6-chinese 0.144 0.276 0.265 0.353 0.376 0.115 0.128 0.188 0.223 0.199 ent05 - 0.181 0.324 0.305 0.282 0.211 0.043 0.158 0.155 0.179 Table 2: Large scale prediction experiments.",
                "We predict the ranking of large sets of retrievals for various collections and retrieval systems.",
                "Kendalls τ correlations are computed between the predicted ranking and a ranking based on the retrievals average precision.",
                "In column (a), we have predictors which do not use information from other retrievals for the same query.",
                "In columns (b) and (c) we present performance for predictors which incorporate information from multiple retrievals.",
                "The adjusted coefficient of determination is computed to determine effectiveness of combining predictors.",
                "Measures in bold represent the strongest correlation for that test/collection pair.",
                "Finally, regularization-based re-ranking processes are also closely-related to our work [8].",
                "These techniques seek to maximize the agreement between scores of related documents by solving a constrained optimization problem.",
                "The maximization of consistency is equivalent to maximizing the Moran autocorrelation.",
                "Therefore, we believe that our work provides explanation for why regularization-based re-ranking works. 9.",
                "CONCLUSION We have presented a new method for predicting the performance of a retrieval ranking without any relevance judgments.",
                "We consider two cases.",
                "First, when making predictions in the absence of retrievals from other systems, our predictors demonstrate robust, strong correlations with average precision.",
                "This performance, combined with a simple implementation, makes our predictors, in particular, very attractive.",
                "We have demonstrated this improvement for many, diverse settings.",
                "To our knowledge, this is the first large scale examination of zero-judgment, single-retrieval performance prediction.",
                "Second, when provided retrievals from other systems, our extended methods demonstrate competitive performance with state of the art baselines.",
                "Our experiments also demonstrate the limits of the usefulness of our predictors when information from multiple runs is provided.",
                "Our results suggest two conclusions.",
                "First, our results could affect retrieval algorithm design.",
                "Retrieval algorithms designed to consider spatial autocorrelation will conform to the cluster hypothesis and improve performance.",
                "Second, our results could affect the design of minimal test collection algorithms.",
                "Much of the recent work in ranking systems sometimes ignores correlations between document labels and scores.",
                "We believe that these two directions could be rewarding given the theoretical and experimental evidence in this paper. 10.",
                "ACKNOWLEDGMENTS This work was supported in part by the Center for Intelligent Information Retrieval and in part by the Defense Advanced Research Projects Agency (DARPA) under contract number HR0011-06-C-0023.",
                "Any opinions, findings and conclusions or recommendations expressed in this material are the authors and do not necessarily reflect those of the sponsor.",
                "We thank Yun Zhou and Desislava Petkova for providing data and Andre Gauthier for technical assistance. 11.",
                "REFERENCES [1] J. Aslam and V. Pavlu.",
                "Query hardness estimation using jensen-shannon divergence among multiple scoring functions.",
                "In ECIR 2007: Proceedings of the 29th European Conference on Information Retrieval, 2007. [2] J.",
                "A. Aslam, V. Pavlu, and E. Yilmaz.",
                "A statistical method for system evaluation using incomplete judgments.",
                "In S. Dumais, E. N. Efthimiadis, D. Hawking, and K. Jarvelin, editors, Proceedings of the 29th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 541-548.",
                "ACM Press, August 2006. [3] D. Carmel, E. Yom-Tov, A. Darlow, and D. Pelleg.",
                "What makes a query difficult?",
                "In SIGIR 06: Proceedings of the 29th annual international ACM SIGIR conference on Research and development in information retrieval, pages 390-397, New York, NY, USA, 2006.",
                "ACM Press. [4] B. Carterette, J. Allan, and R. Sitaraman.",
                "Minimal test collections for retrieval evaluation.",
                "In SIGIR 06: Proceedings of the 29th annual international ACM SIGIR conference on Research and development in information retrieval, pages 268-275, New York, NY, USA, 2006.",
                "ACM Press. [5] A. D. Cliff and J. K. Ord.",
                "Spatial Autocorrelation.",
                "Pion Ltd., 1973. [6] M. Connell, A. Feng, G. Kumaran, H. Raghavan, C. Shah, and J. Allan.",
                "Umass at tdt 2004.",
                "Technical Report CIIR Technical Report IR - 357, Department of Computer Science, University of Massachusetts, 2004. [7] S. Cronen-Townsend, Y. Zhou, and W. B. Croft.",
                "Precision prediction based on ranked list coherence.",
                "Inf.",
                "Retr., 9(6):723-755, 2006. [8] F. Diaz.",
                "Regularizing ad-hoc retrieval scores.",
                "In CIKM 05: Proceedings of the 14th ACM international conference on Information and knowledge management, pages 672-679, New York, NY, USA, 2005.",
                "ACM Press. [9] F. Diaz and R. Jones.",
                "Using temporal profiles of queries for precision prediction.",
                "In SIGIR 04: Proceedings of the 27th annual international ACM SIGIR conference on Research and development in information retrieval, pages 18-24, New York, NY, USA, 2004.",
                "ACM Press. [10] D. A. Griffith.",
                "Spatial Autocorrelation and Spatial Filtering.",
                "Springer Verlag, 2003. [11] B.",
                "He and I. Ounis.",
                "Inferring Query Performance Using Pre-retrieval Predictors.",
                "In The Eleventh Symposium on String Processing and Information Retrieval (SPIRE), 2004. [12] N. Jardine and C. J. V. Rijsbergen.",
                "The use of hierarchic clustering in information retrieval.",
                "Information Storage and Retrieval, 7:217-240, 1971. [13] D. Jensen and J. Neville.",
                "Linkage and autocorrelation cause feature selection bias in relational learning.",
                "In ICML 02: Proceedings of the Nineteenth International Conference on Machine Learning, pages 259-266, San Francisco, CA, USA, 2002.",
                "Morgan Kaufmann Publishers Inc. [14] O. Kurland and L. Lee.",
                "Corpus structure, language models, and ad-hoc information retrieval.",
                "In SIGIR 04: Proceedings of the 27th annual international conference on Research and development in information retrieval, pages 194-201, New York, NY, USA, 2004.",
                "ACM Press. [15] M. Montague and J.",
                "A. Aslam.",
                "Relevance score normalization for metasearch.",
                "In CIKM 01: Proceedings of the tenth international conference on Information and knowledge management, pages 427-433, New York, NY, USA, 2001.",
                "ACM Press. [16] T. Qin, T.-Y.",
                "Liu, X.-D. Zhang, Z. Chen, and W.-Y.",
                "Ma.",
                "A study of relevance propagation for web search.",
                "In SIGIR 05: Proceedings of the 28th annual international ACM SIGIR conference on Research and development in information retrieval, pages 408-415, New York, NY, USA, 2005.",
                "ACM Press. [17] I. Soboroff, C. Nicholas, and P. Cahan.",
                "Ranking retrieval systems without relevance judgments.",
                "In SIGIR 01: Proceedings of the 24th annual international ACM SIGIR conference on Research and development in information retrieval, pages 66-73, New York, NY, USA, 2001.",
                "ACM Press. [18] V. Vinay, I. J. Cox, N. Milic-Frayling, and K. Wood.",
                "On ranking the effectiveness of searches.",
                "In SIGIR 06: Proceedings of the 29th annual international ACM SIGIR conference on Research and development in information retrieval, pages 398-404, New York, NY, USA, 2006.",
                "ACM Press. [19] Y. Zhou and W. B. Croft.",
                "Ranking robustness: a novel framework to predict query performance.",
                "In CIKM 06: Proceedings of the 15th ACM international conference on Information and knowledge management, pages 567-574, New York, NY, USA, 2006.",
                "ACM Press."
            ],
            "original_annotated_samples": [],
            "translated_annotated_samples": [],
            "translated_text": "",
            "candidates": [],
            "error": [
                []
            ]
        },
        "language model score": {
            "translated_key": "puntuaciones de modelos de lenguaje",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Performance Prediction Using Spatial Autocorrelation Fernando Diaz Center for Intelligent Information Retrieval Department of Computer Science University of Massachusetts Amherst, MA 01003 fdiaz@cs.umass.edu ABSTRACT Evaluation of information retrieval systems is one of the core tasks in information retrieval.",
                "Problems include the inability to exhaustively label all documents for a topic, nongeneralizability from a small number of topics, and incorporating the variability of retrieval systems.",
                "Previous work addresses the evaluation of systems, the ranking of queries by difficulty, and the ranking of individual retrievals by performance.",
                "Approaches exist for the case of few and even no relevance judgments.",
                "Our focus is on zero-judgment performance prediction of individual retrievals.",
                "One common shortcoming of previous techniques is the assumption of uncorrelated document scores and judgments.",
                "If documents are embedded in a high-dimensional space (as they often are), we can apply techniques from spatial data analysis to detect correlations between document scores.",
                "We find that the low correlation between scores of topically close documents often implies a poor retrieval performance.",
                "When compared to a state of the art baseline, we demonstrate that the spatial analysis of retrieval scores provides significantly better prediction performance.",
                "These new predictors can also be incorporated with classic predictors to improve performance further.",
                "We also describe the first large-scale experiment to evaluate zero-judgment performance prediction for a massive number of retrieval systems over a variety of collections in several languages.",
                "Categories and Subject Descriptors H.3.3 [Information Search and Retrieval]: Retrieval models; H.3.4 [Systems and Software]: Performance evaluation (efficiency and effectiveness) General Terms Performance, Design, Reliability, Experimentation 1.",
                "INTRODUCTION In information retrieval, a user poses a query to a system.",
                "The system retrieves n documents each receiving a realvalued score indicating the predicted degree of relevance.",
                "If we randomly select pairs of documents from this set, we expect some pairs to share the same topic and other pairs to not share the same topic.",
                "Take two topically-related documents from the set and call them a and b.",
                "If the scores of a and b are very different, we may be concerned about the performance of our system.",
                "That is, if a and b are both on the topic of the query, we would like them both to receive a high score; if a and b are not on the topic of the query, we would like them both to receive a low score.",
                "We might become more worried as we find more differences between scores of related documents.",
                "We would be more comfortable with a retrieval where scores are consistent between related documents.",
                "Our paper studies the quantification of this inconsistency in a retrieval from a spatial perspective.",
                "Spatial analysis is appropriate since many retrieval models embed documents in some vector space.",
                "If documents are embedded in a space, proximity correlates with topical relationships.",
                "Score consistency can be measured by the spatial version of autocorrelation known as the Moran coefficient or IM [5, 10].",
                "In this paper, we demonstrate a strong correlation between IM and retrieval performance.",
                "The discussion up to this point is reminiscent of the cluster hypothesis.",
                "The cluster hypothesis states: closely-related documents tend to be relevant to the same request [12].",
                "As we shall see, a retrieval functions spatial autocorrelation measures the degree to which closely-related documents receive similar scores.",
                "Because of this, we interpret autocorrelation as measuring the degree to which a retrieval function satisfies the clustering hypothesis.",
                "If this connection is reasonable, in Section 6, we present evidence that failure to satisfy the cluster hypothesis correlates strongly with poor performance.",
                "In this work, we provide the following contributions, 1.",
                "A general, robust method for predicting the performance of retrievals with zero relevance judgments (Section 3). 2.",
                "A theoretical treatment of the similarities and motivations behind several state-of-the-art performance prediction techniques (Section 4). 3.",
                "The first large-scale experiments of zero-judgment, single run performance prediction (Sections 5 and 6). 2.",
                "PROBLEM DEFINITION Given a query, an information retrieval system produces a ranking of documents in the collection encoded as a set of scores associated with documents.",
                "We refer to the set of scores for a particular query-system combination as a retrieval.",
                "We would like to predict the performance of this retrieval with respect to some evaluation measure (eg, mean average precision).",
                "In this paper, we present results for ranking retrievals from arbitrary systems.",
                "We would like this ranking to approximate the ranking of retrievals by the evaluation measure.",
                "This is different from ranking queries by the average performance on each query.",
                "It is also different from ranking systems by the average performance on a set of queries.",
                "Scores are often only computed for the top n documents from the collection.",
                "We place these scores in the length n vector, y, where yi refers to the score of the ith-ranked document.",
                "We adjust scores to have zero mean and unit variance.",
                "We use this method because of its simplicity and its success in previous work [15]. 3.",
                "SPATIAL CORRELATION In information retrieval, we often assume that the representations of documents exist in some high-dimensional vector space.",
                "For example, given a vocabulary, V, this vector space may be an arbitrary |V|-dimensional space with cosine inner-product or a multinomial simplex with a distributionbased distance measure.",
                "An embedding space is often selected to respect topical proximity; if two documents are near, they are more likely to share a topic.",
                "Because of the prevalence and success of spatial models of information retrieval, we believe that the application of spatial data analysis techniques are appropriate.",
                "Whereas in information retrieval, we are concerned with the score at a point in a space, in spatial data analysis, we are concerned with the value of a function at a point or location in a space.",
                "We use the term function here to mean a mapping from a location to a real value.",
                "For example, we might be interested in the prevalence of a disease in the neighborhood of some city.",
                "The function would map the location of a neighborhood to an infection rate.",
                "If we want to quantify the spatial dependencies of a function, we would employ a measure referred to as the spatial autocorrelation [5, 10].",
                "High spatial autocorrelation suggests that knowing the value of a function at location a will tell us a great deal about the value at a neighboring location b.",
                "There is a high spatial autocorrelation for a function representing the temperature of a location since knowing the temperature at a location a will tell us a lot about the temperature at a neighboring location b.",
                "Low spatial autocorrelation suggests that knowing the value of a function at location a tells us little about the value at a neighboring location b.",
                "There is low spatial autocorrelation in a function measuring the outcome of a coin toss at a and b.",
                "In this section, we will begin by describing what we mean by spatial proximity for documents and then define a measure of spatial autocorrelation.",
                "We conclude by extending this model to include information from multiple retrievals from multiple systems for a single query. 3.1 Spatial Representation of Documents Our work does not focus on improving a specific similarity measure or defining a novel vector space.",
                "Instead, we choose an inner product known to be effective at detecting interdocument topical relationships.",
                "Specifically, we adopt tf.idf document vectors, ˜di = di log „ (n + 0.5) − ci 0.5 + ci « (1) where d is a vector of term frequencies, c is the length-|V| document frequency vector.",
                "We use this weighting scheme due to its success for topical link detection in the context of Topic Detection and Tracking (TDT) evaluations [6].",
                "Assuming vectors are scaled by their L2 norm, we use the inner product, ˜di, ˜dj , to define similarity.",
                "Given documents and some similarity measure, we can construct a matrix which encodes the similarity between pairs of documents.",
                "Recall that we are given the top n documents retrieved in y.",
                "We can compute an n × n similarity matrix, W. An element of this matrix, Wij represents the similarity between documents ranked i and j.",
                "In practice, we only include the affinities for a documents k-nearest neighbors.",
                "In all of our experiments, we have fixed k to 5.",
                "We leave exploration of parameter sensitivity to future work.",
                "We also row normalize the matrix so that Pn j=1 Wij = 1 for all i. 3.2 Spatial Autocorrelation of a Retrieval Recall that we are interested in measuring the similarity between the scores of spatially-close documents.",
                "One such suitable measure is the Moran coefficient of spatial autocorrelation.",
                "Assuming the function y over n locations, this is defined as ˜IM = n eTWe P i,j Wijyiyj P i y2 i = n eTWe yT Wy yTy (2) where eT We = P ij Wij.",
                "We would like to compare autocorrelation values for different retrievals.",
                "Unfortunately, the bound for Equation 2 is not consistent for different W and y.",
                "Therefore, we use the Cauchy-Schwartz inequality to establish a bound, ˜IM ≤ n eTWe s yTWTWy yTy And we define the normalized spatial autocorrelation as IM = yT Wy p yTy × yTWTWy Notice that if we let ˜y = Wy, then we can write this formula as, IM = yT ˜y y 2 ˜y 2 (3) which can be interpreted as the correlation between the original retrieval scores and a set of retrieval scores diffused in the space.",
                "We present some examples of autocorrelations of functions on a grid in Figure 1. 3.3 Correlation with Other Retrievals Sometimes we are interested in the performance of a single retrieval but have access to scores from multiple systems for (a) IM = 0.006 (b) IM = 0.241 (c) IM = 0.487 Figure 1: The Moran coefficient, IM for a several binary functions on a grid.",
                "The Moran coefficient is a local measure of function consistency.",
                "From the perspective of information retrieval, each of these grid spaces would represent a document and documents would be organized so that they lay next to topically-related documents.",
                "Binary retrieval scores would define a pattern on this grid.",
                "Notice that, as the Moran coefficient increases, neighboring cells tend to have similar values. the same query.",
                "In this situation, we can use combined information from these scores to construct a surrogate for a high-quality ranking [17].",
                "We can treat the correlation between the retrieval we are interested in and the combined scores as a predictor of performance.",
                "Assume that we are given m score functions, yi, for the same n documents.",
                "We will represent the mean of these vectors as yµ = Pm i=1 yi.",
                "We use the mean vector as an approximation to relevance.",
                "Since we use zero mean and unit variance normalization, work in metasearch suggests that this assumption is justified [15].",
                "Because yµ represents a very good retrieval, we hypothesize that a strong similarity between yµ and y will correlate positively with system performance.",
                "We use Pearsons product-moment correlation to measure the similarity between these vectors, ρ(y, yµ) = yT yµ y 2 yµ 2 (4) We will comment on the similarity between Equation 3 and 4 in Section 7.",
                "Of course, we can combine ρ(y, ˜y) and ρ(y, yµ) if we assume that they capture different factors in the prediction.",
                "One way to accomplish this is to combine these predictors as independent variables in a linear regression.",
                "An alternative means of combination is suggested by the mathematical form of our predictors.",
                "Since ˜y encodes the spatial dependencies in y and yµ encodes the spatial properties of the multiple runs, we can compute a third correlation between these two vectors, ρ(˜y, yµ) = ˜yT yµ ˜y 2 yµ 2 (5) We can interpret Equation 5 as measuring the correlation between a high quality ranking (yµ) and a spatially smoothed version of the retrieval (˜y). 4.",
                "RELATIONSHIP WITH OTHER PREDICTORS One way to predict the effectiveness of a retrieval is to look at the shared vocabulary of the top n retrieved documents.",
                "If we computed the most frequent content words in this set, we would hope that they would be consistent with our topic.",
                "In fact, we might believe that a bad retrieval would include documents on many disparate topics, resulting in an overlap of terminological noise.",
                "The Clarity of a query attempts to quantify exactly this [7].",
                "Specifically, Clarity measures the similarity of the words most frequently used in retrieved documents to those most frequently used in the whole corpus.",
                "The conjecture is that a good retrieval will use language distinct from general text; the overlapping language in a bad retrieval will tend to be more similar to general text.",
                "Mathematically, we can compute a representation of the language used in the initial retrieval as a weighted combination of document language models, P(w|θQ) = nX i=1 P(w|θi) P(Q|θi) Z (6) where θi is the language model of the ith-ranked document, P(Q|θi) is the query likelihood score of the ith-ranked document and Z = Pn i=1 P(Q|θi) is a normalization constant.",
                "The similarity between the multinomial P(w|θQ) and a model of general text can be computed using the Kullback-Leibler divergence, DV KL(θQ θC ).",
                "Here, the distribution P(w|θC ) is our model of general text which can be computed using term frequencies in the corpus.",
                "In Figure 2a, we present Clarity as measuring the distance between the weighted center of mass of the retrieval (labeled y) and the unweighted center of mass of the collection (labeled O).",
                "Clarity reaches a minimum when a retrieval assigns every document the same score.",
                "Lets again assume we have a set of n documents retrieved for our query.",
                "Another way to quantify the dispersion of a set of documents is to look at how clustered they are.",
                "We may hypothesize that a good retrieval will return a single, tight cluster.",
                "A poorly performing retrieval will return a loosely related set of documents covering many topics.",
                "One proposed method of quantifying this dispersion is to measure the distance from a random document a to its nearest neighbor, b.",
                "A retrieval which is tightly clustered will, on average, have a low distance between a and b; a retrieval which is less tightly-closed will, on average have high distances between a and b.",
                "This average corresponds to using the Cox-Lewis statistic to measure the randomness of the top n documents retrieved from a system [18].",
                "In Figure 2a, this is roughly equivalent to measuring the area of the set n. Notice that we are throwing away information about the retrieval function y.",
                "Therefore the Cox-Lewis statistic is highly dependent on selecting the top n documents.1 Remember that we have n documents and a set of scores.",
                "Lets assume that we have access to the system which provided the original scores and that we can also request scores for new documents.",
                "This suggests a third method for predicting performance.",
                "Take some document, a, from the retrieved set and arbitrarily add or remove words at random to create a new document ˜a.",
                "Now, we can ask our system to score ˜a with respect to our query.",
                "If, on average over the n documents, the scores of a and ˜a tend to be very different, we might suspect that the system is failing on this query.",
                "So, an alternative approach is to measure the simi1 The authors have suggested coupling the query with the distance measure [18].",
                "The information introduced by the query, though, is retrieval-independent so that, if two retrievals return the same set of documents, the approximate Cox-Lewis statistic will be the same regardless of the retrieval scores. yOy (a) Global Divergence µ(y)˜y y (b) Score Perturbation µ(y) y (c) Multirun Averaging Figure 2: Representation of several performance predictors on a grid.",
                "In Figure 2a, we depict predictors which measure the divergence between the center of mass of a retrieval and the center of the embedding space.",
                "In Figure 2b, we depict predictors which compare the original retrieval, y, to a perturbed version of the retrieval, ˜y.",
                "Our approach uses a particular type of perturbation based on score diffusion.",
                "Finally, in Figure 2c, we depict prediction when given retrievals from several other systems on the same query.",
                "Here, we can consider the fusion of these retrieval as a surrogate for relevance. larity between the retrieval and a perturbed version of that retrieval [18, 19].",
                "This can be accomplished by either perturbing the documents or queries.",
                "The similarity between the two retrievals can be measured using some correlation measure.",
                "This is depicted in Figure 2b.",
                "The upper grid represents the original retrieval, y, while the lower grid represents the function after having been perturbed, ˜y.",
                "The nature of the perturbation process requires additional scorings or retrievals.",
                "Our predictor does not require access to the original scoring function or additional retrievals.",
                "So, although our method is similar to other perturbation methods in spirit, it can be applied in situations when the retrieval system is inaccessible or costly to access.",
                "Finally, assume that we have, in addition to the retrieval we want to evaluate, m retrievals from a variety of different systems.",
                "In this case, we might take a document a, compare its rank in the retrieval to its average rank in the m retrievals.",
                "If we believe that the m retrievals provide a satisfactory approximation to relevance, then a very large difference in rank would suggest that our retrieval is misranking a.",
                "If this difference is large on average over all n documents, then we might predict that the retrieval is bad.",
                "If, on the other hand, the retrieval is very consistent with the m retrievals, then we might predict that the retrieval is good.",
                "The similarity between the retrieval and the combined retrieval may be computed using some correlation measure.",
                "This is depicted in Figure 2c.",
                "In previous work, the Kullback-Leibler divergence between the normalized scores of the retrieval and the normalized scores of the combined retrieval provides the similarity [1]. 5.",
                "EXPERIMENTS Our experiments focus on testing the predictive power of each of our predictors: ρ(y, ˜y), ρ(y, yµ), and ρ(˜y, yµ).",
                "As stated in Section 2, we are interested in predicting the performance of the retrieval generated by an arbitrary system.",
                "Our methodology is consistent with previous research in that we predict the relative performance of a retrieval by comparing a ranking based on our predictor to a ranking based on average precision.",
                "We present results for two sets of experiments.",
                "The first set of experiments presents detailed comparisons of our predictors to previously-proposed predictors using identical data sets.",
                "Our second set of experiments demonstrates the generalizability of our approach to arbitrary retrieval methods, corpus types, and corpus languages. 5.1 Detailed Experiments In these experiments, we will predict the performance of language modeling scores using our autocorrelation predictor, ρ(y, ˜y); we do not consider ρ(y, yµ) or ρ(˜y, yµ) because, in these detailed experiments, we focus on ranking the retrievals from a single system.",
                "We use retrievals, values for baseline predictors, and evaluation measures reported in previous work [19]. 5.1.1 Topics and Collections These performance prediction experiments use language model retrievals performed for queries associated with collections in the TREC corpora.",
                "Using TREC collections allows us to confidently associate an average precision with a retrieval.",
                "In these experiments, we use the following topic collections: TREC 4 ad-hoc, TREC 5 ad-hoc, Robust 2004, Terabyte 2004, and Terabyte 2005. 5.1.2 Baselines We provide two baselines.",
                "Our first baseline is the classic Clarity predictor presented in Equation 6.",
                "Clarity is designed to be used with language modeling systems.",
                "Our second baseline is Zhou and Crofts ranking robustness predictor.",
                "This predictor corrupts the top k documents from retrieval and re-computes the <br>language model score</br>s for these corrupted documents.",
                "The value of the predictor is the Spearman rank correlation between the original ranking and the corrupted ranking.",
                "In our tables, we will label results for Clarity using DV KL and the ranking robustness predictor using P. 5.2 Generalizability Experiments Our predictors do not require a particular baseline retrieval system; the predictors can be computed for an arbitrary retrieval, regardless of how scores were generated.",
                "We believe that that is one of the most attractive aspects of our algorithm.",
                "Therefore, in a second set of experiments, we demonstrate the ability of our techniques to generalize to a variety of collections, topics, and retrieval systems. 5.2.1 Topics and Collections We gathered a diverse set of collections from all possible TREC corpora.",
                "We cast a wide net in order to locate collections where our predictors might fail.",
                "Our hypothesis is that documents with high topical similarity should have correlated scores.",
                "Therefore, we avoided collections where scores were unlikely to be correlated (eg, question-answering) or were likely to be negatively correlated (eg, novelty).",
                "Nevertheless, our collections include corpora where correlations are weakly justified (eg, non-English corpora) or not justified at all (eg, expert search).",
                "We use the ad-hoc tracks from TREC3-8, TREC Robust 2003-2005, TREC Terabyte 20042005, TREC4-5 Spanish, TREC5-6 Chinese, and TREC Enterprise Expert Search 2005.",
                "In all cases, we use only the automatic runs for ad-hoc tracks submitted to NIST.",
                "For all English and Spanish corpora, we construct the matrix W according to the process described in Section 3.1.",
                "For Chinese corpora, we use na¨ıve character-based tf.idf vectors.",
                "For entities, entries in W are proportional to the number of documents in which two entities cooccur. 5.2.2 Baselines In our detailed experiments, we used the Clarity measure as a baseline.",
                "Since we are predicting the performance of retrievals which are not based on language modeling, we use a version of Clarity referred to as ranked-list Clarity [7].",
                "Ranked-list clarity converts document ranks to P(Q|θi) values.",
                "This conversion begins by replacing all of the scores in y with the respective ranks.",
                "Our estimation of P(Q|θi) from the ranks, then is, P(Q|θi) = ( 2(c+1−yi) c(c+1) if yi ≤ c 0 otherwise (7) where c is a cutoff parameter.",
                "As suggested by the authors, we fix the algorithm parameters c and λ2 so that c = 60 and λ2 = 0.10.",
                "We use Equation 6 to estimate P(w|θQ) and DV KL(θQ θC ) to compute the value of the predictor.",
                "We will refer to this predictor as DV KL, superscripted by V to indicate that the Kullback-Leibler divergence is with respect to the term embedding space.",
                "When information from multiple runs on the same query is available, we use Aslam and Pavlus document-space multinomial divergence as a baseline [1].",
                "This rank-based method first normalizes the scores in a retrieval as an n-dimensional multinomial.",
                "As with ranked-list Clarity, we begin by replacing all of the scores in y with their respective ranks.",
                "Then, we adjust the elements of y in the following way, ˆyi = 1 2n 0 @1 + nX k=yi 1 k 1 A (8) In our multirun experiments, we only use the top 75 documents from each retrieval (n = 75); this is within the range of parameter values suggested by the authors.",
                "However, we admit not tuning this parameter for either our system or the baseline.",
                "The predictor is the divergence between the candidate distribution, y, and the mean distribution, yµ .",
                "With the uniform linear combination of these m retrievals represented as yµ, we can compute the divergence as Dn KL(ˆy ˆyµ) where we use the superscript n to indicate that the summation is over the set of n documents.",
                "This baseline was developed in the context of predicting query difficulty but we adopt it as a reasonable baseline for predicting retrieval performance. 5.2.3 Parameter Settings When given multiple retrievals, we use documents in the union of the top k = 75 documents from each of the m retrievals for that query.",
                "If the size of this union is ˜n, then yµ and each yi is of length ˜n.",
                "In some cases, a system did not score a document in the union.",
                "Since we are making a Gaussian assumption about our scores, we can sample scores for these unseen documents from the negative tail of the distribution.",
                "Specifically, we sample from the part of the distribution lower than the minimum value of in the normalized retrieval.",
                "This introduces randomness into our algorithm but we believe it is more appropriate than assigning an arbitrary fixed value.",
                "We optimized the linear regression using the square root of each predictor.",
                "We found that this substantially improved fits for all predictors, including the baselines.",
                "We considered linear combinations of pairs of predictors (labeled by the components) and all predictors (labeled as β). 5.3 Evaluation Given a set of retrievals, potentially from a combination of queries and systems, we measure the correlation of the rank ordering of this set by the predictor and by the performance metric.",
                "In order to ensure comparability with previous results, we present Kendalls τ correlation between the predictors ranking and ranking based on average precision of the retrieval.",
                "Unless explicitly noted, all correlations are significant with p < 0.05.",
                "Predictors can sometimes perform better when linearly combined [9, 11].",
                "Although previous work has presented the coefficient of determination (R2 ) to measure the quality of the regression, this measure cannot be reliably used when comparing slight improvements from combining predictors.",
                "Therefore, we adopt the adjusted coefficient of determination which penalizes models with more variables.",
                "The adjusted R2 allows us to evaluate the improvement in prediction achieved by adding a parameter but loses the statistical interpretation of R2 .",
                "We will use Kendalls τ to evaluate the magnitude of the correlation and the adjusted R2 to evaluate the combination of variables. 6.",
                "RESULTS We present results for our detailed experiments comparing the prediction of <br>language model score</br>s in Table 1.",
                "Although the Clarity measure is theoretically designed for <br>language model score</br>s, it consistently underperforms our system-agnostic predictor.",
                "Ranking robustness was presented as an improvement to Clarity for web collections (represented in our experiments by the terabyte04 and terabyte05 collections), shifting the τ correlation from 0.139 to 0.150 for terabyte04 and 0.171 to 0.208 for terabyte05.",
                "However, these improvements are slight compared to the performance of autocorrelation on these collections.",
                "Our predictor achieves a τ correlation of 0.454 for terabyte04 and 0.383 for terabyte05.",
                "Though not always the strongest, autocorrelation achieves correlations competitive with baseline predictors.",
                "When examining the performance of linear combinations of predictors, we note that in every case, autocorrelation factors as a necessary component of a strong predictor.",
                "We also note that the adjusted R2 for individual baselines are always significantly improved by incorporating autocorrelation.",
                "We present our generalizability results in Table 2.",
                "We begin by examining the situation in column (a) where we are presented with a single retrieval and no information from additional retrievals.",
                "For every collection except one, we achieve significantly better correlations than ranked-list Clarity.",
                "Surprisingly, we achieve relatively strong correlations for Spanish and Chinese collections despite our na¨ıve processing.",
                "We do not have a ranked-list clarity correlation for ent05 because entity modeling is itself an open research question.",
                "However, our autocorrelation measure does not achieve high correlations perhaps because relevance for entity retrieval does not propagate according to the cooccurrence links we use.",
                "As noted above, the poor Clarity performance on web data is consistent with our findings in the detailed experiments.",
                "Clarity also notably underperforms for several news corpora (trec5, trec7, and robust04).",
                "On the other hand, autocorrelation seems robust to the changes between different corpora.",
                "Next, we turn to the introduction of information from multiple retrievals.",
                "We compare the correlations between those predictors which do not use this information in column (a) and those which do in column (b).",
                "For every collection, the predictors in column (b) outperform the predictors in column (a), indicating that the information from additional runs can be critical to making good predictions.",
                "Inspecting the predictors in column (b), we only draw weak conclusions.",
                "Our new predictors tend to perform better on news corpora.",
                "And between our new predictors, the hybrid ρ(˜y, yµ) predictor tends to perform better.",
                "Recall that our ρ(˜y, yµ) measure incorporates both spatial and multiple retrieval information.",
                "Therefore, we believe that the improvement in correlation is the result of incorporating information from spatial behavior.",
                "In column (c), we can investigate the utility of incorporating spatial information with information from multiple retrievals.",
                "Notice that in the cases where autocorrelation, ρ(y, ˜y), alone performs well (trec3, trec5-spanish, and trec6-chinese), it is substantially improved by incorporating multiple-retrieval information from ρ(y, yµ) in the linear regression, β.",
                "In the cases where ρ(y, yµ) performs well, incorporating autocorrelation rarely results in a significant improvement in performance.",
                "In fact, in every case where our predictor outperforms the baseline, it includes information from multiple runs. 7.",
                "DISCUSSION The most important result from our experiments involves prediction when no information is available from multiple runs (Tables 1 and 2a).",
                "This situation arises often in system design.",
                "For example, a system may need to, at retrieval time, assess its performance before deciding to conduct more intensive processing such as pseudo-relevance feedback or interaction.",
                "Assuming the presence of multiple retrievals is unrealistic in this case.",
                "We believe that autocorrelation is, like multiple-retrieval algorithms, approximating a good ranking; in this case by diffusing scores.",
                "Why is ˜y a reasonable surrogate?",
                "We know that diffusion of scores on the web graph and language model graphs improves performance [14, 16].",
                "Therefore, if score diffusion tends to, in general, improve performance, then diffused scores will, in general, provide a good surrogate for relevance.",
                "Our results demonstrate that this approximation is not as powerful as information from multiple retrievals.",
                "Nevertheless, in situations where this information is lacking, autocorrelation provides substantial information.",
                "The success of autocorrelation as a predictor may also have roots in the clustering hypothesis.",
                "Recall that we regard autocorrelation as the degree to which a retrieval satisfies the clustering hypothesis.",
                "Our experiments, then, demonstrate that a failure to respect the clustering hypothesis correlates with poor performance.",
                "Why might systems fail to conform to the cluster hypothesis?",
                "Query-based information retrieval systems often score documents independently.",
                "The score of document a may be computed by examining query term or phrase matches, the document length, and perhaps global collection statistics.",
                "Once computed, a system rarely compares the score of a to the score of a topically-related document b.",
                "With some exceptions, the correlation of document scores has largely been ignored.",
                "We should make it clear that we have selected tasks where topical autocorrelation is appropriate.",
                "There are certainly cases where there is no reason to believe that retrieval scores will have topical autocorrelation.",
                "For example, ranked lists which incorporate document novelty should not exhibit spatial autocorrelation; if anything autocorrelation should be negative for this task.",
                "Similarly, answer candidates in a question-answering task may or may not exhibit autocorrelation; in this case, the semantics of links is questionable too.",
                "It is important before applying this measure to confirm that, given the semantics for some link between two retrieved items, we should expect a correlation between scores. 8.",
                "RELATED WORK In this section we draw more general comparisons to other work in performance prediction and spatial data analysis.",
                "There is a growing body of work which attempts to predict the performance of individual retrievals [7, 3, 11, 9, 19].",
                "We have attempted to place our work in the context of much of this work in Section 4.",
                "However, a complete comparison is beyond the scope of this paper.",
                "We note, though, that our experiments cover a larger and more diverse set of retrievals, collections, and topics than previously examined.",
                "Much previous work-particularly in the context of TRECfocuses on predicting the performance of systems.",
                "Here, each system generates k retrievals.",
                "The task is, given these retrievals, to predict the ranking of systems according to some performance measure.",
                "Several papers attempt to address this task under the constraint of few judgments [2, 4].",
                "Some work even attempts to use zero judgments by leveraging multiple retrievals for the same query [17].",
                "Our task differs because we focus on ranking retrievals independent of the generating system.",
                "The task here is not to test the hypothesis system A is superior to system B but to test the hypothesis retrieval A is superior to retrieval B. Autocorrelation manifests itself in many classification tasks.",
                "Neville and Jensen define relational autocorrelation for relational learning problems and demonstrate that many classification tasks manifest autocorrelation [13].",
                "Temporal autocorrelation of initial retrievals has also been used to predict performance [9].",
                "However, temporal autocorrelation is performed by projecting the retrieval function into the temporal embedding space.",
                "In our work, we focus on the behavior of the function over the relationships between documents. τ adjusted R2 DV KL P ρ(y, ˜y) DV KL P ρ(y, ˜y) DV KL, P DV KL, ρ(y, ˜y) Pρ(y, ˜y) β trec4 0.353 0.548 0.513 0.168 0.363 0.422 0.466 0.420 0.557 0.553 trec5 0.311 0.329 0.357 0.116 0.190 0.236 0.238 0.244 0.266 0.269 robust04 0.418 0.398 0.373 0.256 0.304 0.278 0.403 0.373 0.402 0.442 terabyte04 0.139 0.150 0.454 0.059 0.045 0.292 0.076 0.293 0.289 0.284 terabyte05 0.171 0.208 0.383 0.022 0.072 0.193 0.120 0.225 0.218 0.257 Table 1: Comparison to Robustness and Clarity measures for <br>language model score</br>s.",
                "Evaluation replicates experiments from [19].",
                "We present correlations between the classic Clarity measure (DV KL), the ranking robustness measure (P), and autocorrelation (ρ(y, ˜y)) each with mean average precision in terms of Kendalls τ.",
                "The adjusted coefficient of determination is presented to measure the effectiveness of combining predictors.",
                "Measures in bold represent the strongest correlation for that test/collection pair. multiple run (a) (b) (c) τ τ adjusted R2 DKL ρ(y, ˜y) Dn KL ρ(y, yµ) ρ(˜y, yµ) Dn KL ρ(y, ˜y) ρ(y, yµ) ρ(˜y, yµ) β trec3 0.201 0.461 0.461 0.439 0.456 0.444 0.395 0.394 0.386 0.498 trec4 0.252 0.396 0.455 0.482 0.489 0.379 0.263 0.429 0.482 0.483 trec5 0.016 0.277 0.433 0.459 0.393 0.280 0.157 0.375 0.323 0.386 trec6 0.230 0.227 0.352 0.428 0.418 0.203 0.089 0.323 0.325 0.325 trec7 0.083 0.326 0.341 0.430 0.483 0.264 0.182 0.363 0.442 0.400 trec8 0.235 0.396 0.454 0.508 0.567 0.402 0.272 0.490 0.580 0.523 robust03 0.302 0.354 0.377 0.385 0.447 0.269 0.206 0.274 0.392 0.303 robust04 0.183 0.308 0.301 0.384 0.453 0.200 0.182 0.301 0.393 0.335 robust05 0.224 0.249 0.371 0.377 0.404 0.341 0.108 0.313 0.328 0.336 terabyte04 0.043 0.245 0.544 0.420 0.392 0.516 0.105 0.357 0.343 0.365 terabyte05 0.068 0.306 0.480 0.434 0.390 0.491 0.168 0.384 0.309 0.403 trec4-spanish 0.307 0.388 0.488 0.398 0.395 0.423 0.299 0.282 0.299 0.388 trec5-spanish 0.220 0.458 0.446 0.484 0.475 0.411 0.398 0.428 0.437 0.529 trec5-chinese 0.092 0.199 0.367 0.379 0.384 0.379 0.199 0.273 0.276 0.310 trec6-chinese 0.144 0.276 0.265 0.353 0.376 0.115 0.128 0.188 0.223 0.199 ent05 - 0.181 0.324 0.305 0.282 0.211 0.043 0.158 0.155 0.179 Table 2: Large scale prediction experiments.",
                "We predict the ranking of large sets of retrievals for various collections and retrieval systems.",
                "Kendalls τ correlations are computed between the predicted ranking and a ranking based on the retrievals average precision.",
                "In column (a), we have predictors which do not use information from other retrievals for the same query.",
                "In columns (b) and (c) we present performance for predictors which incorporate information from multiple retrievals.",
                "The adjusted coefficient of determination is computed to determine effectiveness of combining predictors.",
                "Measures in bold represent the strongest correlation for that test/collection pair.",
                "Finally, regularization-based re-ranking processes are also closely-related to our work [8].",
                "These techniques seek to maximize the agreement between scores of related documents by solving a constrained optimization problem.",
                "The maximization of consistency is equivalent to maximizing the Moran autocorrelation.",
                "Therefore, we believe that our work provides explanation for why regularization-based re-ranking works. 9.",
                "CONCLUSION We have presented a new method for predicting the performance of a retrieval ranking without any relevance judgments.",
                "We consider two cases.",
                "First, when making predictions in the absence of retrievals from other systems, our predictors demonstrate robust, strong correlations with average precision.",
                "This performance, combined with a simple implementation, makes our predictors, in particular, very attractive.",
                "We have demonstrated this improvement for many, diverse settings.",
                "To our knowledge, this is the first large scale examination of zero-judgment, single-retrieval performance prediction.",
                "Second, when provided retrievals from other systems, our extended methods demonstrate competitive performance with state of the art baselines.",
                "Our experiments also demonstrate the limits of the usefulness of our predictors when information from multiple runs is provided.",
                "Our results suggest two conclusions.",
                "First, our results could affect retrieval algorithm design.",
                "Retrieval algorithms designed to consider spatial autocorrelation will conform to the cluster hypothesis and improve performance.",
                "Second, our results could affect the design of minimal test collection algorithms.",
                "Much of the recent work in ranking systems sometimes ignores correlations between document labels and scores.",
                "We believe that these two directions could be rewarding given the theoretical and experimental evidence in this paper. 10.",
                "ACKNOWLEDGMENTS This work was supported in part by the Center for Intelligent Information Retrieval and in part by the Defense Advanced Research Projects Agency (DARPA) under contract number HR0011-06-C-0023.",
                "Any opinions, findings and conclusions or recommendations expressed in this material are the authors and do not necessarily reflect those of the sponsor.",
                "We thank Yun Zhou and Desislava Petkova for providing data and Andre Gauthier for technical assistance. 11.",
                "REFERENCES [1] J. Aslam and V. Pavlu.",
                "Query hardness estimation using jensen-shannon divergence among multiple scoring functions.",
                "In ECIR 2007: Proceedings of the 29th European Conference on Information Retrieval, 2007. [2] J.",
                "A. Aslam, V. Pavlu, and E. Yilmaz.",
                "A statistical method for system evaluation using incomplete judgments.",
                "In S. Dumais, E. N. Efthimiadis, D. Hawking, and K. Jarvelin, editors, Proceedings of the 29th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 541-548.",
                "ACM Press, August 2006. [3] D. Carmel, E. Yom-Tov, A. Darlow, and D. Pelleg.",
                "What makes a query difficult?",
                "In SIGIR 06: Proceedings of the 29th annual international ACM SIGIR conference on Research and development in information retrieval, pages 390-397, New York, NY, USA, 2006.",
                "ACM Press. [4] B. Carterette, J. Allan, and R. Sitaraman.",
                "Minimal test collections for retrieval evaluation.",
                "In SIGIR 06: Proceedings of the 29th annual international ACM SIGIR conference on Research and development in information retrieval, pages 268-275, New York, NY, USA, 2006.",
                "ACM Press. [5] A. D. Cliff and J. K. Ord.",
                "Spatial Autocorrelation.",
                "Pion Ltd., 1973. [6] M. Connell, A. Feng, G. Kumaran, H. Raghavan, C. Shah, and J. Allan.",
                "Umass at tdt 2004.",
                "Technical Report CIIR Technical Report IR - 357, Department of Computer Science, University of Massachusetts, 2004. [7] S. Cronen-Townsend, Y. Zhou, and W. B. Croft.",
                "Precision prediction based on ranked list coherence.",
                "Inf.",
                "Retr., 9(6):723-755, 2006. [8] F. Diaz.",
                "Regularizing ad-hoc retrieval scores.",
                "In CIKM 05: Proceedings of the 14th ACM international conference on Information and knowledge management, pages 672-679, New York, NY, USA, 2005.",
                "ACM Press. [9] F. Diaz and R. Jones.",
                "Using temporal profiles of queries for precision prediction.",
                "In SIGIR 04: Proceedings of the 27th annual international ACM SIGIR conference on Research and development in information retrieval, pages 18-24, New York, NY, USA, 2004.",
                "ACM Press. [10] D. A. Griffith.",
                "Spatial Autocorrelation and Spatial Filtering.",
                "Springer Verlag, 2003. [11] B.",
                "He and I. Ounis.",
                "Inferring Query Performance Using Pre-retrieval Predictors.",
                "In The Eleventh Symposium on String Processing and Information Retrieval (SPIRE), 2004. [12] N. Jardine and C. J. V. Rijsbergen.",
                "The use of hierarchic clustering in information retrieval.",
                "Information Storage and Retrieval, 7:217-240, 1971. [13] D. Jensen and J. Neville.",
                "Linkage and autocorrelation cause feature selection bias in relational learning.",
                "In ICML 02: Proceedings of the Nineteenth International Conference on Machine Learning, pages 259-266, San Francisco, CA, USA, 2002.",
                "Morgan Kaufmann Publishers Inc. [14] O. Kurland and L. Lee.",
                "Corpus structure, language models, and ad-hoc information retrieval.",
                "In SIGIR 04: Proceedings of the 27th annual international conference on Research and development in information retrieval, pages 194-201, New York, NY, USA, 2004.",
                "ACM Press. [15] M. Montague and J.",
                "A. Aslam.",
                "Relevance score normalization for metasearch.",
                "In CIKM 01: Proceedings of the tenth international conference on Information and knowledge management, pages 427-433, New York, NY, USA, 2001.",
                "ACM Press. [16] T. Qin, T.-Y.",
                "Liu, X.-D. Zhang, Z. Chen, and W.-Y.",
                "Ma.",
                "A study of relevance propagation for web search.",
                "In SIGIR 05: Proceedings of the 28th annual international ACM SIGIR conference on Research and development in information retrieval, pages 408-415, New York, NY, USA, 2005.",
                "ACM Press. [17] I. Soboroff, C. Nicholas, and P. Cahan.",
                "Ranking retrieval systems without relevance judgments.",
                "In SIGIR 01: Proceedings of the 24th annual international ACM SIGIR conference on Research and development in information retrieval, pages 66-73, New York, NY, USA, 2001.",
                "ACM Press. [18] V. Vinay, I. J. Cox, N. Milic-Frayling, and K. Wood.",
                "On ranking the effectiveness of searches.",
                "In SIGIR 06: Proceedings of the 29th annual international ACM SIGIR conference on Research and development in information retrieval, pages 398-404, New York, NY, USA, 2006.",
                "ACM Press. [19] Y. Zhou and W. B. Croft.",
                "Ranking robustness: a novel framework to predict query performance.",
                "In CIKM 06: Proceedings of the 15th ACM international conference on Information and knowledge management, pages 567-574, New York, NY, USA, 2006.",
                "ACM Press."
            ],
            "original_annotated_samples": [
                "This predictor corrupts the top k documents from retrieval and re-computes the <br>language model score</br>s for these corrupted documents.",
                "RESULTS We present results for our detailed experiments comparing the prediction of <br>language model score</br>s in Table 1.",
                "Although the Clarity measure is theoretically designed for <br>language model score</br>s, it consistently underperforms our system-agnostic predictor.",
                "In our work, we focus on the behavior of the function over the relationships between documents. τ adjusted R2 DV KL P ρ(y, ˜y) DV KL P ρ(y, ˜y) DV KL, P DV KL, ρ(y, ˜y) Pρ(y, ˜y) β trec4 0.353 0.548 0.513 0.168 0.363 0.422 0.466 0.420 0.557 0.553 trec5 0.311 0.329 0.357 0.116 0.190 0.236 0.238 0.244 0.266 0.269 robust04 0.418 0.398 0.373 0.256 0.304 0.278 0.403 0.373 0.402 0.442 terabyte04 0.139 0.150 0.454 0.059 0.045 0.292 0.076 0.293 0.289 0.284 terabyte05 0.171 0.208 0.383 0.022 0.072 0.193 0.120 0.225 0.218 0.257 Table 1: Comparison to Robustness and Clarity measures for <br>language model score</br>s."
            ],
            "translated_annotated_samples": [
                "Este predictor corrompe los k documentos principales de la recuperación y vuelve a calcular las <br>puntuaciones del modelo de lenguaje</br> para estos documentos corruptos.",
                "RESULTADOS Presentamos los resultados de nuestros experimentos detallados comparando la predicción de <br>puntuaciones de modelos de lenguaje</br> en la Tabla 1.",
                "Aunque la medida de Claridad está teóricamente diseñada para <br>puntuaciones de modelos de lenguaje</br>, consistentemente tiene un rendimiento inferior a nuestro predictor independiente del sistema.",
                "En nuestro trabajo, nos enfocamos en el comportamiento de la función sobre las relaciones entre documentos. τ ajustado R2 DV KL P ρ(y, ˜y) DV KL P ρ(y, ˜y) DV KL, P DV KL, ρ(y, ˜y) Pρ(y, ˜y) β trec4 0.353 0.548 0.513 0.168 0.363 0.422 0.466 0.420 0.557 0.553 trec5 0.311 0.329 0.357 0.116 0.190 0.236 0.238 0.244 0.266 0.269 robust04 0.418 0.398 0.373 0.256 0.304 0.278 0.403 0.373 0.402 0.442 terabyte04 0.139 0.150 0.454 0.059 0.045 0.292 0.076 0.293 0.289 0.284 terabyte05 0.171 0.208 0.383 0.022 0.072 0.193 0.120 0.225 0.218 0.257 Tabla 1: Comparación de medidas de robustez y claridad para <br>puntuaciones de modelos de lenguaje</br>."
            ],
            "translated_text": "Predicción del rendimiento utilizando autocorrelación espacial. Fernando Díaz. Centro de Recuperación de Información Inteligente. Departamento de Ciencias de la Computación. Universidad de Massachusetts Amherst, MA 01003. fdiaz@cs.umass.edu. RESUMEN La evaluación de sistemas de recuperación de información es una de las tareas fundamentales en la recuperación de información. Los problemas incluyen la incapacidad de etiquetar exhaustivamente todos los documentos sobre un tema, la falta de generalización a partir de un pequeño número de temas e incorporar la variabilidad de los sistemas de recuperación. Trabajos anteriores abordan la evaluación de sistemas, la clasificación de consultas por dificultad y la clasificación de recuperaciones individuales por rendimiento. Existen enfoques para el caso de pocos e incluso ningún juicio de relevancia. Nuestro enfoque está en la predicción del rendimiento sin juicios de las recuperaciones individuales. Una deficiencia común de las técnicas anteriores es la suposición de que las puntuaciones de los documentos y los juicios no están correlacionados. Si los documentos están incrustados en un espacio de alta dimensión (como a menudo lo están), podemos aplicar técnicas de análisis de datos espaciales para detectar correlaciones entre las puntuaciones de los documentos. Observamos que la baja correlación entre las puntuaciones de documentos temáticamente cercanos a menudo implica un bajo rendimiento en la recuperación. Cuando se compara con una línea base de última generación, demostramos que el análisis espacial de las puntuaciones de recuperación ofrece un rendimiento predictivo significativamente mejor. Estos nuevos predictores también pueden ser incorporados con predictores clásicos para mejorar aún más el rendimiento. También describimos el primer experimento a gran escala para evaluar la predicción de rendimiento sin juicio para un gran número de sistemas de recuperación en una variedad de colecciones en varios idiomas. Categorías y Descriptores de Asignaturas H.3.3 [Búsqueda y Recuperación de Información]: Modelos de recuperación; H.3.4 [Sistemas y Software]: Evaluación del rendimiento (eficiencia y efectividad) Términos Generales Rendimiento, Diseño, Confiabilidad, Experimentación 1. En la recuperación de información, un usuario plantea una consulta a un sistema. El sistema recupera n documentos, cada uno recibiendo una puntuación de valor real que indica el grado de relevancia predicho. Si seleccionamos aleatoriamente pares de documentos de este conjunto, esperamos que algunos pares compartan el mismo tema y otros pares no compartan el mismo tema. Toma dos documentos relacionados entre sí del conjunto y llámalos a y b. Si las puntuaciones de a y b son muy diferentes, podríamos estar preocupados por el rendimiento de nuestro sistema. Es decir, si tanto a como b están relacionados con el tema de la consulta, nos gustaría que ambos reciban una puntuación alta; si a y b no están relacionados con el tema de la consulta, nos gustaría que ambos reciban una puntuación baja. Podríamos preocuparnos más a medida que encontramos más diferencias entre las puntuaciones de documentos relacionados. Estaríamos más cómodos con una recuperación en la que las puntuaciones sean consistentes entre documentos relacionados. Nuestro artículo estudia la cuantificación de esta inconsistencia en una recuperación desde una perspectiva espacial. El análisis espacial es apropiado ya que muchos modelos de recuperación incrustan documentos en algún espacio vectorial. Si los documentos están incrustados en un espacio, la proximidad se correlaciona con las relaciones temáticas. La consistencia de la puntuación puede medirse mediante la versión espacial de la autocorrelación conocida como el coeficiente de Moran o IM [5, 10]. En este artículo, demostramos una fuerte correlación entre IM y el rendimiento de recuperación. La discusión hasta este punto recuerda a la hipótesis del cúmulo. La hipótesis del clúster establece que los documentos estrechamente relacionados tienden a ser relevantes para la misma solicitud [12]. Como veremos, una función de recuperación de medidas de autocorrelación espacial mide el grado en que los documentos relacionados reciben puntuaciones similares. Debido a esto, interpretamos la autocorrelación como la medida del grado en que una función de recuperación satisface la hipótesis de agrupamiento. Si esta conexión es razonable, en la Sección 6 presentamos evidencia de que la falta de cumplimiento de la hipótesis de agrupamiento se correlaciona fuertemente con un bajo rendimiento. En este trabajo, proporcionamos las siguientes contribuciones: 1. Un método general y robusto para predecir el rendimiento de recuperaciones sin juicios de relevancia (Sección 3). 2. Un tratamiento teórico de las similitudes y motivaciones detrás de varias técnicas de predicción de rendimiento de vanguardia (Sección 4). 3. Las primeras experimentaciones a gran escala de predicción de rendimiento de una sola ejecución sin juicio (Secciones 5 y 6). 2. Dada una consulta, un sistema de recuperación de información produce una clasificación de documentos en la colección codificada como un conjunto de puntuaciones asociadas con los documentos. Nos referimos al conjunto de puntuaciones para una combinación particular de consulta-sistema como una recuperación. Nos gustaría predecir el rendimiento de esta recuperación con respecto a alguna medida de evaluación (por ejemplo, precisión promedio). En este artículo, presentamos resultados para clasificar recuperaciones de sistemas arbitrarios. Nos gustaría que este ranking se aproximara al ranking de recuperaciones según la medida de evaluación. Esto es diferente de clasificar las consultas por el rendimiento promedio en cada consulta. También es diferente de los sistemas de clasificación por el rendimiento promedio en un conjunto de consultas. Las puntuaciones a menudo solo se calculan para los primeros n documentos de la colección. Colocamos estos puntajes en el vector de longitud n, y, donde yi se refiere al puntaje del documento clasificado en la posición i. Ajustamos las puntuaciones para que tengan una media de cero y una varianza unitaria. Utilizamos este método debido a su simplicidad y su éxito en trabajos anteriores [15]. CORRELACIÓN ESPACIAL En la recuperación de información, a menudo asumimos que las representaciones de los documentos existen en algún espacio vectorial de alta dimensión. Por ejemplo, dado un vocabulario, V, este espacio vectorial puede ser un espacio arbitrario de dimensión |V| con producto interno de coseno o un simplejo multinomial con una medida de distancia basada en distribución. Un espacio de incrustación suele ser seleccionado para respetar la proximidad temática; si dos documentos están cerca, es más probable que compartan un tema. Debido a la prevalencia y éxito de los modelos espaciales de recuperación de información, creemos que la aplicación de técnicas de análisis de datos espaciales es apropiada. Mientras que en la recuperación de información nos preocupa la puntuación en un punto en el espacio, en el análisis de datos espaciales nos preocupa el valor de una función en un punto o ubicación en el espacio. Utilizamos el término función aquí para referirnos a una asignación de una ubicación a un valor real. Por ejemplo, podríamos estar interesados en la prevalencia de una enfermedad en el vecindario de alguna ciudad. La función asignaría la ubicación de un vecindario a una tasa de infección. Si queremos cuantificar las dependencias espaciales de una función, emplearíamos una medida conocida como la autocorrelación espacial [5, 10]. Una alta autocorrelación espacial sugiere que conocer el valor de una función en la ubicación a nos dirá mucho sobre el valor en una ubicación vecina b. Existe una alta autocorrelación espacial para una función que representa la temperatura de una ubicación, ya que saber la temperatura en una ubicación a nos dirá mucho sobre la temperatura en una ubicación vecina b. La baja autocorrelación espacial sugiere que conocer el valor de una función en la ubicación a nos dice poco sobre el valor en una ubicación vecina b. Hay una baja autocorrelación espacial en una función que mide el resultado de lanzar una moneda en a y b. En esta sección, comenzaremos describiendo lo que entendemos por proximidad espacial para documentos y luego definiremos una medida de autocorrelación espacial. Concluimos extendiendo este modelo para incluir información de múltiples recuperaciones de múltiples sistemas para una sola consulta. 3.1 Representación Espacial de Documentos Nuestro trabajo no se centra en mejorar una medida de similitud específica o definir un espacio vectorial novedoso. En cambio, elegimos un producto interno conocido por ser efectivo en la detección de relaciones temáticas entre documentos. Específicamente, adoptamos vectores de documentos tf.idf, ˜di = di log „ (n + 0.5) − ci 0.5 + ci « (1) donde d es un vector de frecuencias de términos, c es el vector de frecuencia de documentos de longitud |V|. Utilizamos este esquema de ponderación debido a su éxito en la detección de enlaces temáticos en el contexto de las evaluaciones de Detección y Seguimiento de Temas (TDT) [6]. Suponiendo que los vectores están escalados por su norma L2, usamos el producto interno, ˜di, ˜dj, para definir la similitud. Dado un conjunto de documentos y alguna medida de similitud, podemos construir una matriz que codifica la similitud entre pares de documentos. Recuerde que se nos dan los primeros n documentos recuperados en y. Podemos calcular una matriz de similitud n × n, W. Un elemento de esta matriz, Wij, representa la similitud entre los documentos clasificados i y j. En la práctica, solo incluimos las afinidades para los k vecinos más cercanos de un documento. En todos nuestros experimentos, hemos fijado k en 5. Dejamos la exploración de la sensibilidad de los parámetros para trabajos futuros. También normalizamos por filas la matriz para que Pn j=1 Wij = 1 para todos los i. 3.2 Autocorrelación Espacial de una Recuperación Recuerde que estamos interesados en medir la similitud entre las puntuaciones de documentos cercanos espacialmente. Una medida adecuada es el coeficiente de Moran de autocorrelación espacial. Suponiendo la función y sobre n ubicaciones, esto se define como ˜IM = n eTWe P i,j Wijyiyj P i y2 i = n eTWe yT Wy yTy (2) donde eT We = P ij Wij. Nos gustaría comparar los valores de autocorrelación para diferentes recuperaciones. Desafortunadamente, el límite para la Ecuación 2 no es consistente para diferentes valores de W y y. Por lo tanto, utilizamos la desigualdad de Cauchy-Schwartz para establecer un límite, ˜IM ≤ n eTWe s yTWTWy yTy Y definimos la autocorrelación espacial normalizada como IM = yT Wy p yTy × yTWTWy. Nótese que si dejamos ˜y = Wy, entonces podemos escribir esta fórmula como, IM = yT ˜y y 2 ˜y 2 (3) lo cual puede interpretarse como la correlación entre las puntuaciones originales de recuperación y un conjunto de puntuaciones de recuperación difundidas en el espacio. Presentamos algunos ejemplos de autocorrelaciones de funciones en una cuadrícula en la Figura 1. 3.3 Correlación con Otros Recuperos A veces estamos interesados en el rendimiento de un solo recuperación pero tenemos acceso a puntajes de múltiples sistemas para (a) IM = 0.006 (b) IM = 0.241 (c) IM = 0.487 Figura 1: El coeficiente de Moran, IM para varias funciones binarias en una cuadrícula. El coeficiente de Moran es una medida local de consistencia de la función. Desde la perspectiva de la recuperación de información, cada uno de estos espacios de la cuadrícula representaría un documento y los documentos estarían organizados de manera que se encuentren junto a documentos relacionados temáticamente. Las puntuaciones de recuperación binaria definirían un patrón en esta cuadrícula. Ten en cuenta que, a medida que el coeficiente de Moran aumenta, las celdas vecinas tienden a tener valores similares. En esta situación, podemos utilizar la información combinada de estas puntuaciones para construir un sustituto de una clasificación de alta calidad [17]. Podemos tratar la correlación entre la recuperación que nos interesa y las puntuaciones combinadas como un predictor del rendimiento. Supongamos que se nos dan m funciones de puntuación, yi, para los mismos n documentos. Representaremos la media de estos vectores como yµ = Σm i=1 yi. Utilizamos el vector medio como una aproximación a la relevancia. Dado que utilizamos normalización de media cero y varianza unitaria, el trabajo en metabusqueda sugiere que esta suposición está justificada [15]. Dado que yµ representa una recuperación muy buena, hipotetizamos que una similitud fuerte entre yµ e y correlacionará positivamente con el rendimiento del sistema. Utilizamos la correlación de Pearson para medir la similitud entre estos vectores, ρ(y, yµ) = yT yµ y 2 yµ 2 (4). Comentaremos sobre la similitud entre la Ecuación 3 y 4 en la Sección 7. Por supuesto, podemos combinar ρ(y, ˜y) y ρ(y, yµ) si asumimos que capturan diferentes factores en la predicción. Una forma de lograr esto es combinar estos predictores como variables independientes en una regresión lineal. Se sugiere un medio alternativo de combinación basado en la forma matemática de nuestros predictores. Dado que ˜y codifica las dependencias espaciales en y y yµ codifica las propiedades espaciales de las múltiples ejecuciones, podemos calcular una tercera correlación entre estos dos vectores, ρ(˜y, yµ) = ˜yT yµ ˜y 2 yµ 2 (5). Podemos interpretar la Ecuación 5 como la medición de la correlación entre un ranking de alta calidad (yµ) y una versión suavizada espacialmente de la recuperación (˜y). 4. RELACIÓN CON OTROS PREDICTORES Una forma de predecir la efectividad de una recuperación es observar el vocabulario compartido de los n documentos principales recuperados. Si calculáramos las palabras de contenido más frecuentes en este conjunto, esperaríamos que fueran coherentes con nuestro tema. De hecho, podríamos creer que una mala recuperación incluiría documentos sobre muchos temas dispares, lo que resultaría en una superposición de ruido terminológico. La claridad de una consulta intenta cuantificar exactamente esto [7]. Específicamente, la Claridad mide la similitud de las palabras más frecuentemente utilizadas en los documentos recuperados con aquellas más frecuentemente utilizadas en todo el corpus. La conjetura es que una buena recuperación utilizará un lenguaje distinto al del texto general; el lenguaje superpuesto en una mala recuperación tenderá a ser más similar al texto general. Matemáticamente, podemos calcular una representación del lenguaje utilizado en la recuperación inicial como una combinación ponderada de modelos de lenguaje de documentos, P(w|θQ) = Σ i=1 P(w|θi) P(Q|θi) Z (6) donde θi es el modelo de lenguaje del documento clasificado en la posición i, P(Q|θi) es la puntuación de probabilidad de la consulta del documento clasificado en la posición i y Z = Σ i=1 P(Q|θi) es una constante de normalización. La similitud entre el multinomial P(w|θQ) y un modelo de texto general se puede calcular utilizando la divergencia de Kullback-Leibler, DV KL(θQ θC). Aquí, la distribución P(w|θC) es nuestro modelo de texto general que puede ser calculado utilizando las frecuencias de términos en el corpus. En la Figura 2a, presentamos la Claridad como la medida de la distancia entre el centro de masa ponderado de la recuperación (etiquetado como y) y el centro de masa no ponderado de la colección (etiquetado como O). La claridad alcanza un mínimo cuando una recuperación asigna a cada documento la misma puntuación. Volvamos a asumir que tenemos un conjunto de n documentos recuperados para nuestra consulta. Otra forma de cuantificar la dispersión de un conjunto de documentos es observar qué tan agrupados están. Podemos hipotetizar que una buena recuperación devolverá un único y compacto grupo. Una recuperación de bajo rendimiento devolverá un conjunto de documentos poco relacionados que abarcan muchos temas. Un método propuesto para cuantificar esta dispersión es medir la distancia desde un documento aleatorio a su vecino más cercano, b. Una recuperación que esté estrechamente agrupada, en promedio, tendrá una distancia baja entre a y b; una recuperación que esté menos cerrada tendrá, en promedio, distancias altas entre a y b. Este promedio corresponde al uso de la estadística de Cox-Lewis para medir la aleatoriedad de los primeros n documentos recuperados de un sistema [18]. En la Figura 2a, esto es aproximadamente equivalente a medir el área del conjunto n. Observa que estamos descartando información sobre la función de recuperación y. Por lo tanto, la estadística de Cox-Lewis depende en gran medida de la selección de los primeros n documentos. Recuerda que tenemos n documentos y un conjunto de puntuaciones. Supongamos que tenemos acceso al sistema que proporcionó las puntuaciones originales y que también podemos solicitar puntuaciones para nuevos documentos. Esto sugiere un tercer método para predecir el rendimiento. Toma algún documento, a, del conjunto recuperado y agrega o elimina palabras al azar de forma arbitraria para crear un nuevo documento ˜a. Ahora, podemos pedirle a nuestro sistema que puntúe ˜a con respecto a nuestra consulta. Si, en promedio, a lo largo de los n documentos, las puntuaciones de a y ˜a tienden a ser muy diferentes, podríamos sospechar que el sistema está fallando en esta consulta. Los autores han sugerido acoplar la consulta con la medida de distancia [18]. La información introducida por la consulta, sin embargo, es independiente de la recuperación, de modo que, si dos recuperaciones devuelven el mismo conjunto de documentos, la estadística aproximada de Cox-Lewis será la misma independientemente de las puntuaciones de recuperación. yOy (a) Divergencia Global µ(y)˜y y (b) Perturbación de Puntuación µ(y) y (c) Promedio de Múltiples Ejecuciones Figura 2: Representación de varios predictores de rendimiento en una cuadrícula. En la Figura 2a, representamos los predictores que miden la divergencia entre el centro de masa de una recuperación y el centro del espacio de incrustación. En la Figura 2b, representamos los predictores que comparan la recuperación original, y, con una versión perturbada de la recuperación, ˜y. Nuestro enfoque utiliza un tipo particular de perturbación basado en la difusión de puntajes. Finalmente, en la Figura 2c, representamos la predicción cuando se proporcionan recuperaciones de varios otros sistemas en la misma consulta. Aquí, podemos considerar la fusión de estas recuperaciones como un sustituto de la relevancia. Esto se puede lograr ya sea perturbando los documentos o las consultas. La similitud entre los dos recuperos se puede medir utilizando alguna medida de correlación. Esto se muestra en la Figura 2b. La cuadrícula superior representa la recuperación original, y, mientras que la cuadrícula inferior representa la función después de haber sido perturbada, ˜y. La naturaleza del proceso de perturbación requiere puntuaciones o recuperaciones adicionales. Nuestro predictor no requiere acceso a la función de puntuación original ni a recuperaciones adicionales. Por lo tanto, aunque nuestro método es similar a otros métodos de perturbación en espíritu, se puede aplicar en situaciones en las que el sistema de recuperación es inaccesible o costoso de acceder. Finalmente, supongamos que tenemos, además de la recuperación que queremos evaluar, m recuperaciones de una variedad de sistemas diferentes. En este caso, podríamos tomar un documento a, comparar su rango en la recuperación con su rango promedio en los m recuperos. Si creemos que las m recuperaciones proporcionan una aproximación satisfactoria a la relevancia, entonces una diferencia muy grande en el rango sugeriría que nuestra recuperación está clasificando incorrectamente a. Si esta diferencia es grande en promedio en todos los n documentos, entonces podríamos predecir que la recuperación es mala. Si, por otro lado, la recuperación es muy consistente con las m recuperaciones, entonces podríamos predecir que la recuperación es buena. La similitud entre la recuperación y la recuperación combinada puede calcularse utilizando alguna medida de correlación. Esto se muestra en la Figura 2c. En trabajos anteriores, la divergencia de Kullback-Leibler entre las puntuaciones normalizadas de la recuperación y las puntuaciones normalizadas de la recuperación combinada proporciona la similitud [1]. 5. Nuestros experimentos se centran en probar el poder predictivo de cada uno de nuestros predictores: ρ(y, ˜y), ρ(y, yµ) y ρ(˜y, yµ). Como se indica en la Sección 2, estamos interesados en predecir el rendimiento de la recuperación generada por un sistema arbitrario. Nuestra metodología es consistente con investigaciones previas en el sentido de que predecimos el rendimiento relativo de una recuperación al comparar una clasificación basada en nuestro predictor con una clasificación basada en la precisión promedio. Presentamos los resultados de dos conjuntos de experimentos. El primer conjunto de experimentos presenta comparaciones detalladas de nuestros predictores con predictores previamente propuestos utilizando conjuntos de datos idénticos. Nuestro segundo conjunto de experimentos demuestra la generalizabilidad de nuestro enfoque a métodos de recuperación arbitrarios, tipos de corpus y lenguajes de corpus. 5.1 Experimentos Detallados En estos experimentos, predeciremos el rendimiento de los puntajes de modelado de lenguaje utilizando nuestro predictor de autocorrelación, ρ(y, ˜y); no consideramos ρ(y, yµ) o ρ(˜y, yµ) porque, en estos experimentos detallados, nos enfocamos en clasificar las recuperaciones de un solo sistema. Utilizamos recuperaciones, valores de predictores de referencia y medidas de evaluación reportadas en trabajos anteriores [19]. 5.1.1 Temas y Colecciones Estos experimentos de predicción de rendimiento utilizan recuperaciones de modelos de lenguaje realizadas para consultas asociadas con colecciones en las corpora de TREC. El uso de las colecciones TREC nos permite asociar con confianza una precisión promedio con una recuperación. En estos experimentos, utilizamos las siguientes colecciones de temas: TREC 4 ad-hoc, TREC 5 ad-hoc, Robust 2004, Terabyte 2004 y Terabyte 2005. 5.1.2 Baselines Proporcionamos dos líneas base. Nuestro primer punto de referencia es el predictor clásico de Claridad presentado en la Ecuación 6. La claridad está diseñada para ser utilizada con sistemas de modelado de lenguaje. Nuestro segundo punto de referencia es el predictor de robustez de clasificación de Zhou y Crofts. Este predictor corrompe los k documentos principales de la recuperación y vuelve a calcular las <br>puntuaciones del modelo de lenguaje</br> para estos documentos corruptos. El valor del predictor es la correlación de rangos de Spearman entre la clasificación original y la clasificación corrupta. En nuestras tablas, etiquetaremos los resultados para Claridad utilizando DV KL y el predictor de robustez de clasificación utilizando P. 5.2 Experimentos de Generalizabilidad Nuestros predictores no requieren un sistema de recuperación base particular; los predictores pueden calcularse para una recuperación arbitraria, independientemente de cómo se generaron los puntajes. Creemos que ese es uno de los aspectos más atractivos de nuestro algoritmo. Por lo tanto, en un segundo conjunto de experimentos, demostramos la capacidad de nuestras técnicas para generalizar a una variedad de colecciones, temas y sistemas de recuperación. 5.2.1 Temas y Colecciones Recopilamos un conjunto diverso de colecciones de todos los corpus posibles de TREC. Lanzamos una red amplia para localizar colecciones donde nuestros predictores podrían fallar. Nuestra hipótesis es que los documentos con alta similitud temática deberían tener puntuaciones correlacionadas. Por lo tanto, evitamos las colecciones donde las puntuaciones eran poco probables de estar correlacionadas (por ejemplo, preguntas y respuestas) o donde probablemente estuvieran negativamente correlacionadas (por ejemplo, novedad). Sin embargo, nuestras colecciones incluyen corpus donde las correlaciones están débilmente justificadas (por ejemplo, corpus no en inglés) o no justificadas en absoluto (por ejemplo, búsqueda de expertos). Utilizamos las pistas ad-hoc de TREC3-8, TREC Robust 2003-2005, TREC Terabyte 2004-2005, TREC4-5 en español, TREC5-6 en chino y TREC Enterprise Expert Search 2005. En todos los casos, solo utilizamos las ejecuciones automáticas para las pistas ad-hoc enviadas a NIST. Para todos los corpus en inglés y español, construimos la matriz W de acuerdo con el proceso descrito en la Sección 3.1. Para los corpus chinos, utilizamos vectores tf.idf basados en caracteres ingenuos. Para las entidades, las entradas en W son proporcionales al número de documentos en los que dos entidades coocurren. 5.2.2 Baselines En nuestros experimentos detallados, utilizamos la medida de Claridad como referencia. Dado que estamos prediciendo el rendimiento de recuperaciones que no se basan en modelado de lenguaje, utilizamos una versión de Claridad conocida como Claridad de lista clasificada [7]. La claridad de la lista clasificada convierte las clasificaciones de documentos en valores P(Q|θi). Esta conversión comienza reemplazando todas las puntuaciones en y con los rangos respectivos. Nuestra estimación de P(Q|θi) a partir de los rangos, entonces es, P(Q|θi) = ( 2(c+1−yi) c(c+1) si yi ≤ c 0 en otro caso donde c es un parámetro de corte. Como sugieren los autores, fijamos los parámetros del algoritmo c y λ2 de manera que c = 60 y λ2 = 0.10. Utilizamos la Ecuación 6 para estimar P(w|θQ) y DV KL(θQ θC) para calcular el valor del predictor. Nos referiremos a este predictor como DV KL, con superíndice V para indicar que la divergencia de Kullback-Leibler es con respecto al espacio de incrustación de términos. Cuando la información de múltiples ejecuciones de la misma consulta está disponible, utilizamos la divergencia multinomial en el espacio de documentos de Aslam y Pavlus como referencia [1]. Este método basado en rangos primero normaliza las puntuaciones en una recuperación como un multinomial n-dimensional. Al igual que con la Claridad de la lista clasificada, comenzamos reemplazando todas las puntuaciones en y con sus respectivas posiciones. Luego, ajustamos los elementos de y de la siguiente manera, ˆyi = 1 2n 0 @1 + nX k=yi 1 k 1 A (8) En nuestros experimentos de múltiples ejecuciones, solo utilizamos los 75 documentos principales de cada recuperación (n = 75); esto está dentro del rango de valores de parámetros sugeridos por los autores. Sin embargo, admitimos no haber ajustado este parámetro ni para nuestro sistema ni para la línea base. El predictor es la divergencia entre la distribución candidata, y, y la distribución media, yµ. Con la combinación lineal uniforme de estos m recuperaciones representadas como yµ, podemos calcular la divergencia como Dn KL(ˆy ˆyµ) donde usamos el superíndice n para indicar que la suma es sobre el conjunto de n documentos. Este punto de referencia fue desarrollado en el contexto de predecir la dificultad de la consulta, pero lo adoptamos como un punto de referencia razonable para predecir el rendimiento de la recuperación. 5.2.3 Configuración de parámetros Cuando se proporcionan múltiples recuperaciones, utilizamos documentos en la unión de los mejores k = 75 documentos de cada una de las m recuperaciones para esa consulta. Si el tamaño de esta unión es ˜n, entonces yµ y cada yi tiene una longitud de ˜n. En algunos casos, un sistema no puntuó un documento en la unión. Dado que estamos haciendo una suposición gaussiana sobre nuestras puntuaciones, podemos muestrear puntuaciones para estos documentos no vistos de la cola negativa de la distribución. Específicamente, muestreamos de la parte de la distribución inferior al valor mínimo en la recuperación normalizada. Esto introduce aleatoriedad en nuestro algoritmo, pero creemos que es más apropiado que asignar un valor fijo arbitrario. Optimizamos la regresión lineal utilizando la raíz cuadrada de cada predictor. Encontramos que esto mejoró sustancialmente los ajustes para todos los predictores, incluidos los basales. Consideramos combinaciones lineales de pares de predictores (etiquetados por los componentes) y todos los predictores (etiquetados como β). 5.3 Evaluación Dado un conjunto de recuperaciones, potencialmente de una combinación de consultas y sistemas, medimos la correlación del ordenamiento de rango de este conjunto por el predictor y por la métrica de rendimiento. Para garantizar la comparabilidad con los resultados anteriores, presentamos la correlación de Kendalls τ entre la clasificación de los predictores y la clasificación basada en la precisión promedio de la recuperación. A menos que se indique explícitamente, todas las correlaciones son significativas con p < 0.05. Los predictores a veces pueden tener un mejor rendimiento cuando se combinan linealmente [9, 11]. Aunque trabajos anteriores han presentado el coeficiente de determinación (R2) para medir la calidad de la regresión, esta medida no puede ser utilizada de manera confiable al comparar pequeñas mejoras al combinar predictores. Por lo tanto, adoptamos el coeficiente de determinación ajustado que penaliza los modelos con más variables. El R2 ajustado nos permite evaluar la mejora en la predicción lograda al agregar un parámetro pero pierde la interpretación estadística del R2. Utilizaremos τ de Kendall para evaluar la magnitud de la correlación y R2 ajustado para evaluar la combinación de variables. RESULTADOS Presentamos los resultados de nuestros experimentos detallados comparando la predicción de <br>puntuaciones de modelos de lenguaje</br> en la Tabla 1. Aunque la medida de Claridad está teóricamente diseñada para <br>puntuaciones de modelos de lenguaje</br>, consistentemente tiene un rendimiento inferior a nuestro predictor independiente del sistema. La robustez del ranking se presentó como una mejora a la Claridad para colecciones web (representadas en nuestros experimentos por las colecciones terabyte04 y terabyte05), desplazando la correlación τ de 0.139 a 0.150 para terabyte04 y de 0.171 a 0.208 para terabyte05. Sin embargo, estas mejoras son leves en comparación con el rendimiento de la autocorrelación en estas colecciones. Nuestro predictor logra una correlación τ de 0.454 para terabyte04 y 0.383 para terabyte05. Aunque no siempre es la más fuerte, la autocorrelación logra correlaciones competitivas con los predictores de referencia. Al examinar el rendimiento de las combinaciones lineales de predictores, observamos que en cada caso, los factores de autocorrelación son un componente necesario de un predictor sólido. También observamos que el R2 ajustado para las líneas de base individuales siempre mejora significativamente al incorporar la autocorrelación. Presentamos nuestros resultados de generalizabilidad en la Tabla 2. Comenzamos examinando la situación en la columna (a) donde se nos presenta una sola recuperación y ninguna información de recuperaciones adicionales. Para cada colección excepto una, logramos correlaciones significativamente mejores que la claridad de la lista clasificada. Sorprendentemente, logramos correlaciones relativamente fuertes para las colecciones en español y chino a pesar de nuestro procesamiento ingenuo. No tenemos una correlación de claridad de lista clasificada para ent05 porque la modelización de entidades es en sí misma una pregunta de investigación abierta. Sin embargo, nuestra medida de autocorrelación no logra altas correlaciones, quizás porque la relevancia para la recuperación de entidades no se propaga de acuerdo con los enlaces de coocurrencia que utilizamos. Como se señaló anteriormente, el bajo rendimiento de Claridad en datos web es consistente con nuestros hallazgos en los experimentos detallados. La claridad también tiene un rendimiento notablemente inferior en varios corpus de noticias (trec5, trec7 y robust04). Por otro lado, la autocorrelación parece ser robusta a los cambios entre diferentes corpora. A continuación, pasamos a la introducción de información de múltiples recuperaciones. Comparamos las correlaciones entre aquellos predictores que no utilizan esta información en la columna (a) y aquellos que sí lo hacen en la columna (b). Para cada colección, los predictores en la columna (b) superan a los predictores en la columna (a), lo que indica que la información de ejecuciones adicionales puede ser crítica para hacer buenas predicciones. Inspeccionando los predictores en la columna (b), solo podemos sacar conclusiones débiles. Nuestros nuevos predictores tienden a tener un mejor rendimiento en corpora de noticias. Y entre nuestros nuevos predictores, el predictor híbrido ρ(˜y, yµ) tiende a tener un mejor rendimiento. Recuerde que nuestra medida ρ(˜y, yµ) incorpora tanto información espacial como de múltiples recuperaciones. Por lo tanto, creemos que la mejora en la correlación es el resultado de incorporar información del comportamiento espacial. En la columna (c), podemos investigar la utilidad de incorporar información espacial con información de múltiples recuperaciones. Observa que en los casos donde la autocorrelación, ρ(y, ˜y), por sí sola funciona bien (trec3, trec5-spanish y trec6-chinese), se mejora sustancialmente al incorporar información de múltiples recuperaciones de ρ(y, yµ) en la regresión lineal, β. En los casos en los que ρ(y, yµ) funciona bien, la incorporación de la autocorrelación rara vez resulta en una mejora significativa en el rendimiento. De hecho, en cada caso en el que nuestro predictor supera al valor de referencia, incluye información de múltiples ejecuciones. 7. DISCUSIÓN El resultado más importante de nuestros experimentos implica la predicción cuando no hay información disponible de múltiples ejecuciones (Tablas 1 y 2a). Esta situación surge a menudo en el diseño de sistemas. Por ejemplo, un sistema puede necesitar, en el momento de la recuperación, evaluar su rendimiento antes de decidir llevar a cabo un procesamiento más intensivo como la retroalimentación de pseudo relevancia o la interacción. Suponiendo que la presencia de múltiples recuperaciones es irrealista en este caso. Creemos que la autocorrelación, al igual que los algoritmos de recuperación múltiple, aproxima un buen ranking; en este caso mediante la difusión de puntajes. ¿Por qué es ˜y un sustituto razonable? Sabemos que la difusión de puntuaciones en el grafo web y en los grafos de modelos de lenguaje mejora el rendimiento [14, 16]. Por lo tanto, si la difusión de puntuaciones tiende, en general, a mejorar el rendimiento, entonces las puntuaciones difusas proporcionarán, en general, un buen sustituto de la relevancia. Nuestros resultados demuestran que esta aproximación no es tan potente como la información de múltiples recuperaciones. Sin embargo, en situaciones donde esta información falta, la autocorrelación proporciona información sustancial. El éxito de la autocorrelación como predictor también puede tener sus raíces en la hipótesis de agrupamiento. Recuerde que consideramos la autocorrelación como el grado en que una recuperación satisface la hipótesis de agrupamiento. Nuestros experimentos, entonces, demuestran que una falta de respeto a la hipótesis de agrupamiento se correlaciona con un bajo rendimiento. ¿Por qué los sistemas podrían no cumplir con la hipótesis del clúster? Los sistemas de recuperación de información basados en consultas a menudo puntúan los documentos de forma independiente. El puntaje del documento a puede ser calculado examinando las coincidencias de términos o frases de la consulta, la longitud del documento y quizás las estadísticas globales de la colección. Una vez calculado, un sistema rara vez compara la puntuación de un documento a con la puntuación de un documento relacionado temáticamente b. Con algunas excepciones, la correlación de las puntuaciones de los documentos ha sido ampliamente ignorada. Debemos dejar claro que hemos seleccionado tareas donde la autocorrelación temática es apropiada. Ciertamente hay casos en los que no hay motivo para creer que las puntuaciones de recuperación tendrán autocorrelación temática. Por ejemplo, las listas clasificadas que incorporan novedad de documentos no deben mostrar autocorrelación espacial; si acaso, la autocorrelación debería ser negativa para esta tarea. Del mismo modo, los candidatos de respuestas en una tarea de pregunta-respuesta pueden o no mostrar autocorrelación; en este caso, la semántica de los enlaces también es cuestionable. Es importante antes de aplicar esta medida confirmar que, dada la semántica para algún enlace entre dos elementos recuperados, deberíamos esperar una correlación entre las puntuaciones. 8. TRABAJO RELACIONADO En esta sección realizamos comparaciones más generales con otros trabajos en predicción de rendimiento y análisis de datos espaciales. Existe un creciente cuerpo de trabajo que intenta predecir el rendimiento de recuperaciones individuales [7, 3, 11, 9, 19]. Hemos intentado situar nuestro trabajo en el contexto de gran parte de este trabajo en la Sección 4. Sin embargo, una comparación completa está fuera del alcance de este documento. Sin embargo, cabe destacar que nuestros experimentos abarcan un conjunto más amplio y diverso de recuperaciones, colecciones y temas que los examinados previamente. Gran parte del trabajo previo, especialmente en el contexto de TREC, se centra en predecir el rendimiento de los sistemas. Aquí, cada sistema genera k recuperaciones. La tarea consiste en, dadas estas recuperaciones, predecir la clasificación de los sistemas según alguna medida de rendimiento. Varios artículos intentan abordar esta tarea bajo la restricción de pocas evaluaciones [2, 4]. Algunos trabajos incluso intentan utilizar cero juicios aprovechando múltiples recuperaciones para la misma consulta [17]. Nuestra tarea difiere porque nos enfocamos en clasificar recuperaciones independientemente del sistema generador. La tarea aquí no es probar que el sistema A es superior al sistema B, sino probar que la recuperación A es superior a la recuperación B. La autocorrelación se manifiesta en muchas tareas de clasificación. Neville y Jensen definen la autocorrelación relacional para problemas de aprendizaje relacional y demuestran que muchas tareas de clasificación manifiestan autocorrelación [13]. La autocorrelación temporal de las recuperaciones iniciales también se ha utilizado para predecir el rendimiento [9]. Sin embargo, la autocorrelación temporal se realiza proyectando la función de recuperación en el espacio de incrustación temporal. En nuestro trabajo, nos enfocamos en el comportamiento de la función sobre las relaciones entre documentos. τ ajustado R2 DV KL P ρ(y, ˜y) DV KL P ρ(y, ˜y) DV KL, P DV KL, ρ(y, ˜y) Pρ(y, ˜y) β trec4 0.353 0.548 0.513 0.168 0.363 0.422 0.466 0.420 0.557 0.553 trec5 0.311 0.329 0.357 0.116 0.190 0.236 0.238 0.244 0.266 0.269 robust04 0.418 0.398 0.373 0.256 0.304 0.278 0.403 0.373 0.402 0.442 terabyte04 0.139 0.150 0.454 0.059 0.045 0.292 0.076 0.293 0.289 0.284 terabyte05 0.171 0.208 0.383 0.022 0.072 0.193 0.120 0.225 0.218 0.257 Tabla 1: Comparación de medidas de robustez y claridad para <br>puntuaciones de modelos de lenguaje</br>. La evaluación replica experimentos de [19]. Presentamos las correlaciones entre la medida clásica de Claridad (DV KL), la medida de robustez de clasificación (P) y la autocorrelación (ρ(y, ˜y)) cada una con la precisión media promedio en términos de τ de Kendall. El coeficiente de determinación ajustado se presenta para medir la efectividad de combinar predictores. Las medidas en negrita representan la correlación más fuerte para ese par de prueba/colección. múltiples ejecuciones (a) (b) (c) τ τ ajustado R2 DKL ρ(y, ˜y) Dn KL ρ(y, yµ) ρ(˜y, yµ) Dn KL ρ(y, ˜y) ρ(y, yµ) ρ(˜y, yµ) β trec3 0.201 0.461 0.461 0.439 0.456 0.444 0.395 0.394 0.386 0.498 trec4 0.252 0.396 0.455 0.482 0.489 0.379 0.263 0.429 0.482 0.483 trec5 0.016 0.277 0.433 0.459 0.393 0.280 0.157 0.375 0.323 0.386 trec6 0.230 0.227 0.352 0.428 0.418 0.203 0.089 0.323 0.325 0.325 trec7 0.083 0.326 0.341 0.430 0.483 0.264 0.182 0.363 0.442 0.400 trec8 0.235 0.396 0.454 0.508 0.567 0.402 0.272 0.490 0.580 0.523 robust03 0.302 0.354 0.377 0.385 0.447 0.269 0.206 0.274 0.392 0.303 robust04 0.183 0.308 0.301 0.384 0.453 0.200 0.182 0.301 0.393 0.335 robust05 0.224 0.249 0.371 0.377 0.404 0.341 0.108 0.313 0.328 0.336 terabyte04 0.043 0.245 0.544 0.420 0.392 0.516 0.105 0.357 0.343 0.365 terabyte05 0.068 0.306 0.480 0.434 0.390 0.491 0.168 0.384 0.309 0.403 trec4-spanish 0.307 0.388 0.488 0.398 0.395 0.423 0.299 0.282 0.299 0.388 trec5-spanish 0.220 0.458 0.446 0.484 0.475 0.411 0.398 0.428 0.437 0.529 trec5-chinese 0.092 0.199 0.367 0.379 0.384 0.379 0.199 0.273 0.276 0.310 trec6-chinese 0.144 0.276 0.265 0.353 0.376 0.115 0.128 0.188 0.223 0.199 ent05 - 0.181 0.324 0.305 0.282 0.211 0.043 0.158 0.155 0.179 Tabla 2: Experimentos de predicción a gran escala. Predecimos la clasificación de grandes conjuntos de recuperaciones para varias colecciones y sistemas de recuperación. Las correlaciones de τ de Kendall se calculan entre la clasificación predicha y una clasificación basada en la precisión promedio de las recuperaciones. En la columna (a), tenemos predictores que no utilizan información de otras recuperaciones para la misma consulta. En las columnas (b) y (c) presentamos el rendimiento de los predictores que incorporan información de múltiples recuperaciones. El coeficiente de determinación ajustado se calcula para determinar la efectividad de combinar predictores. Las medidas en negrita representan la correlación más fuerte para ese par de prueba/colección. Finalmente, los procesos de reordenamiento basados en regularización también están estrechamente relacionados con nuestro trabajo [8]. Estas técnicas buscan maximizar el acuerdo entre las puntuaciones de documentos relacionados al resolver un problema de optimización restringida. La maximización de la consistencia es equivalente a maximizar la autocorrelación de Moran. Por lo tanto, creemos que nuestro trabajo proporciona una explicación de por qué funciona el reordenamiento basado en regularización. 9. CONCLUSIÓN Hemos presentado un nuevo método para predecir el rendimiento de un ranking de recuperación sin necesidad de juicios de relevancia. Consideramos dos casos. Primero, al hacer predicciones en ausencia de recuperaciones de otros sistemas, nuestros predictores muestran correlaciones sólidas y robustas con la precisión promedio. Esta actuación, combinada con una implementación sencilla, hace que nuestros predictores, en particular, sean muy atractivos. Hemos demostrado esta mejora en muchos entornos diversos. Según nuestro conocimiento, esta es la primera evaluación a gran escala de la predicción del rendimiento de una sola recuperación sin juicio. Segundo, cuando se proporcionan recuperaciones de otros sistemas, nuestros métodos ampliados demuestran un rendimiento competitivo con las líneas de base de vanguardia. Nuestros experimentos también demuestran los límites de la utilidad de nuestros predictores cuando se proporciona información de múltiples ejecuciones. Nuestros resultados sugieren dos conclusiones. Primero, nuestros resultados podrían afectar el diseño de algoritmos de recuperación. Los algoritmos de recuperación diseñados para considerar la autocorrelación espacial se ajustarán a la hipótesis de agrupamiento y mejorarán el rendimiento. Segundo, nuestros resultados podrían afectar el diseño de algoritmos de colección de pruebas mínimas. Gran parte del trabajo reciente en sistemas de clasificación a veces ignora las correlaciones entre las etiquetas de los documentos y las puntuaciones. Creemos que estas dos direcciones podrían ser gratificantes dadas las pruebas teóricas y experimentales en este documento. 10. AGRADECIMIENTOS Este trabajo fue apoyado en parte por el Centro de Recuperación de Información Inteligente y en parte por la Agencia de Proyectos de Investigación Avanzada de Defensa (DARPA) bajo el número de contrato HR0011-06-C-0023. Cualquier opinión, hallazgo y conclusión o recomendación expresada en este material son del autor y no necesariamente reflejan las del patrocinador. Agradecemos a Yun Zhou y Desislava Petkova por proporcionar los datos y a Andre Gauthier por la asistencia técnica. 11. REFERENCIAS [1] J. Aslam y V. Pavlu. Estimación de la dificultad de la consulta utilizando la divergencia de Jensen-Shannon entre múltiples funciones de puntuación. En ECIR 2007: Actas de la 29ª Conferencia Europea sobre Recuperación de Información, 2007. [2] J. A. Aslam, V. Pavlu y E. Yilmaz. Un método estadístico para la evaluación de sistemas utilizando juicios incompletos. En S. Dumais, E. N. Efthimiadis, D. Hawking y K. Jarvelin, editores, Actas de la 29ª Conferencia Internacional Anual de ACM SIGIR sobre Investigación y Desarrollo en Recuperación de Información, páginas 541-548. ACM Press, agosto de 2006. [3] D. Carmel, E. Yom-Tov, A. Darlow y D. Pelleg. ¿Qué hace que una consulta sea difícil? En SIGIR 06: Actas de la 29ª conferencia internacional anual de ACM SIGIR sobre investigación y desarrollo en recuperación de información, páginas 390-397, Nueva York, NY, EE. UU., 2006. ACM Press. [4] B. Carterette, J. Allan y R. Sitaraman. Colecciones de prueba mínimas para evaluación de recuperación. En SIGIR 06: Actas de la 29ª conferencia internacional anual de ACM SIGIR sobre investigación y desarrollo en recuperación de información, páginas 268-275, Nueva York, NY, EE. UU., 2006. ACM Press. [5] A. D. Cliff y J. K. Ord. Autocorrelación espacial. Pion Ltd., 1973. [6] M. Connell, A. Feng, G. Kumaran, H. Raghavan, C. Shah y J. Allan. Umass en tdt 2004. Informe técnico CIIR Informe técnico IR - 357, Departamento de Ciencias de la Computación, Universidad de Massachusetts, 2004. [7] S. Cronen-Townsend, Y. Zhou y W. B. Croft. Predicción de precisión basada en la coherencia de la lista clasificada. I'm sorry, but the sentence \"Inf.\" is not a complete sentence. Could you please provide more context or a full sentence for me to translate to Spanish? Rev., 9(6):723-755, 2006. [8] F. Diaz. Normalizando las puntuaciones de recuperación ad-hoc. En CIKM 05: Actas de la 14ª conferencia internacional de ACM sobre gestión de la información y el conocimiento, páginas 672-679, Nueva York, NY, EE. UU., 2005. ACM Press. [9] F. Diaz y R. Jones. Utilizando perfiles temporales de consultas para predecir la precisión. En SIGIR 04: Actas de la 27ª conferencia internacional anual de ACM SIGIR sobre investigación y desarrollo en recuperación de información, páginas 18-24, Nueva York, NY, EE. UU., 2004. ACM Press. [10] D. A. Griffith. \n\nACM Press. [10] D. A. Griffith. Autocorrelación espacial y filtrado espacial. Springer Verlag, 2003. [11] B. \n\nSpringer Verlag, 2003. [11] B. Él y yo. Ounis. Inferir el rendimiento de la consulta utilizando predictores previos a la recuperación. En el Undécimo Simposio sobre Procesamiento de Cadenas y Recuperación de Información (SPIRE), 2004. [12] N. Jardine y C. J. V. Rijsbergen. El uso de agrupamiento jerárquico en la recuperación de información. Almacenamiento y recuperación de información, 7:217-240, 1971. [13] D. Jensen y J. Neville. El enlace y la autocorrelación causan sesgo en la selección de características en el aprendizaje relacional. En ICML 02: Actas de la Decimonovena Conferencia Internacional sobre Aprendizaje Automático, páginas 259-266, San Francisco, CA, EE. UU., 2002. Morgan Kaufmann Publishers Inc. [14] O. Kurland y L. Lee. Estructura del corpus, modelos de lenguaje y recuperación de información ad-hoc. En SIGIR 04: Actas de la 27ª conferencia internacional anual sobre investigación y desarrollo en recuperación de información, páginas 194-201, Nueva York, NY, EE. UU., 2004. ACM Press. [15] M. Montague y J. A. Aslam. Normalización de la puntuación de relevancia para metabusqueda. En CIKM 01: Actas de la décima conferencia internacional sobre gestión de la información y el conocimiento, páginas 427-433, Nueva York, NY, EE. UU., 2001. ACM Press. [16] T. Qin, T.-Y. Liu, X.-D. Zhang, Z. Chen y W.-Y. I'm sorry, but \"Ma.\" is not a complete sentence. Could you please provide more context or a complete sentence for me to translate into Spanish? Un estudio de propagación de relevancia para la búsqueda en la web. En SIGIR 05: Actas de la 28ª conferencia internacional anual de ACM SIGIR sobre investigación y desarrollo en recuperación de información, páginas 408-415, Nueva York, NY, EE. UU., 2005. ACM Press. [17] I. Soboroff, C. Nicholas y P. Cahan. Sistemas de recuperación de clasificación sin juicios de relevancia. En SIGIR 01: Actas de la 24ª conferencia internacional anual de ACM SIGIR sobre investigación y desarrollo en recuperación de información, páginas 66-73, Nueva York, NY, EE. UU., 2001. ACM Press. [18] V. Vinay, I. J. Cox, N. Milic-Frayling y K. Wood. Sobre la clasificación de la efectividad de las búsquedas. En SIGIR 06: Actas de la 29ª conferencia internacional anual de ACM SIGIR sobre investigación y desarrollo en recuperación de información, páginas 398-404, Nueva York, NY, EE. UU., 2006. ACM Press. [19] Y. Zhou y W. B. Croft. Robustez del ranking: un nuevo marco para predecir el rendimiento de la consulta. En CIKM 06: Actas de la 15ª conferencia internacional de ACM sobre gestión de la información y el conocimiento, páginas 567-574, Nueva York, NY, EE. UU., 2006. ACM Press. ",
            "candidates": [],
            "error": [
                [
                    "puntuaciones del modelo de lenguaje",
                    "puntuaciones de modelos de lenguaje",
                    "puntuaciones de modelos de lenguaje",
                    "puntuaciones de modelos de lenguaje"
                ]
            ]
        },
        "ranking of queries": {
            "translated_key": "clasificación de consultas",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Performance Prediction Using Spatial Autocorrelation Fernando Diaz Center for Intelligent Information Retrieval Department of Computer Science University of Massachusetts Amherst, MA 01003 fdiaz@cs.umass.edu ABSTRACT Evaluation of information retrieval systems is one of the core tasks in information retrieval.",
                "Problems include the inability to exhaustively label all documents for a topic, nongeneralizability from a small number of topics, and incorporating the variability of retrieval systems.",
                "Previous work addresses the evaluation of systems, the <br>ranking of queries</br> by difficulty, and the ranking of individual retrievals by performance.",
                "Approaches exist for the case of few and even no relevance judgments.",
                "Our focus is on zero-judgment performance prediction of individual retrievals.",
                "One common shortcoming of previous techniques is the assumption of uncorrelated document scores and judgments.",
                "If documents are embedded in a high-dimensional space (as they often are), we can apply techniques from spatial data analysis to detect correlations between document scores.",
                "We find that the low correlation between scores of topically close documents often implies a poor retrieval performance.",
                "When compared to a state of the art baseline, we demonstrate that the spatial analysis of retrieval scores provides significantly better prediction performance.",
                "These new predictors can also be incorporated with classic predictors to improve performance further.",
                "We also describe the first large-scale experiment to evaluate zero-judgment performance prediction for a massive number of retrieval systems over a variety of collections in several languages.",
                "Categories and Subject Descriptors H.3.3 [Information Search and Retrieval]: Retrieval models; H.3.4 [Systems and Software]: Performance evaluation (efficiency and effectiveness) General Terms Performance, Design, Reliability, Experimentation 1.",
                "INTRODUCTION In information retrieval, a user poses a query to a system.",
                "The system retrieves n documents each receiving a realvalued score indicating the predicted degree of relevance.",
                "If we randomly select pairs of documents from this set, we expect some pairs to share the same topic and other pairs to not share the same topic.",
                "Take two topically-related documents from the set and call them a and b.",
                "If the scores of a and b are very different, we may be concerned about the performance of our system.",
                "That is, if a and b are both on the topic of the query, we would like them both to receive a high score; if a and b are not on the topic of the query, we would like them both to receive a low score.",
                "We might become more worried as we find more differences between scores of related documents.",
                "We would be more comfortable with a retrieval where scores are consistent between related documents.",
                "Our paper studies the quantification of this inconsistency in a retrieval from a spatial perspective.",
                "Spatial analysis is appropriate since many retrieval models embed documents in some vector space.",
                "If documents are embedded in a space, proximity correlates with topical relationships.",
                "Score consistency can be measured by the spatial version of autocorrelation known as the Moran coefficient or IM [5, 10].",
                "In this paper, we demonstrate a strong correlation between IM and retrieval performance.",
                "The discussion up to this point is reminiscent of the cluster hypothesis.",
                "The cluster hypothesis states: closely-related documents tend to be relevant to the same request [12].",
                "As we shall see, a retrieval functions spatial autocorrelation measures the degree to which closely-related documents receive similar scores.",
                "Because of this, we interpret autocorrelation as measuring the degree to which a retrieval function satisfies the clustering hypothesis.",
                "If this connection is reasonable, in Section 6, we present evidence that failure to satisfy the cluster hypothesis correlates strongly with poor performance.",
                "In this work, we provide the following contributions, 1.",
                "A general, robust method for predicting the performance of retrievals with zero relevance judgments (Section 3). 2.",
                "A theoretical treatment of the similarities and motivations behind several state-of-the-art performance prediction techniques (Section 4). 3.",
                "The first large-scale experiments of zero-judgment, single run performance prediction (Sections 5 and 6). 2.",
                "PROBLEM DEFINITION Given a query, an information retrieval system produces a ranking of documents in the collection encoded as a set of scores associated with documents.",
                "We refer to the set of scores for a particular query-system combination as a retrieval.",
                "We would like to predict the performance of this retrieval with respect to some evaluation measure (eg, mean average precision).",
                "In this paper, we present results for ranking retrievals from arbitrary systems.",
                "We would like this ranking to approximate the ranking of retrievals by the evaluation measure.",
                "This is different from ranking queries by the average performance on each query.",
                "It is also different from ranking systems by the average performance on a set of queries.",
                "Scores are often only computed for the top n documents from the collection.",
                "We place these scores in the length n vector, y, where yi refers to the score of the ith-ranked document.",
                "We adjust scores to have zero mean and unit variance.",
                "We use this method because of its simplicity and its success in previous work [15]. 3.",
                "SPATIAL CORRELATION In information retrieval, we often assume that the representations of documents exist in some high-dimensional vector space.",
                "For example, given a vocabulary, V, this vector space may be an arbitrary |V|-dimensional space with cosine inner-product or a multinomial simplex with a distributionbased distance measure.",
                "An embedding space is often selected to respect topical proximity; if two documents are near, they are more likely to share a topic.",
                "Because of the prevalence and success of spatial models of information retrieval, we believe that the application of spatial data analysis techniques are appropriate.",
                "Whereas in information retrieval, we are concerned with the score at a point in a space, in spatial data analysis, we are concerned with the value of a function at a point or location in a space.",
                "We use the term function here to mean a mapping from a location to a real value.",
                "For example, we might be interested in the prevalence of a disease in the neighborhood of some city.",
                "The function would map the location of a neighborhood to an infection rate.",
                "If we want to quantify the spatial dependencies of a function, we would employ a measure referred to as the spatial autocorrelation [5, 10].",
                "High spatial autocorrelation suggests that knowing the value of a function at location a will tell us a great deal about the value at a neighboring location b.",
                "There is a high spatial autocorrelation for a function representing the temperature of a location since knowing the temperature at a location a will tell us a lot about the temperature at a neighboring location b.",
                "Low spatial autocorrelation suggests that knowing the value of a function at location a tells us little about the value at a neighboring location b.",
                "There is low spatial autocorrelation in a function measuring the outcome of a coin toss at a and b.",
                "In this section, we will begin by describing what we mean by spatial proximity for documents and then define a measure of spatial autocorrelation.",
                "We conclude by extending this model to include information from multiple retrievals from multiple systems for a single query. 3.1 Spatial Representation of Documents Our work does not focus on improving a specific similarity measure or defining a novel vector space.",
                "Instead, we choose an inner product known to be effective at detecting interdocument topical relationships.",
                "Specifically, we adopt tf.idf document vectors, ˜di = di log „ (n + 0.5) − ci 0.5 + ci « (1) where d is a vector of term frequencies, c is the length-|V| document frequency vector.",
                "We use this weighting scheme due to its success for topical link detection in the context of Topic Detection and Tracking (TDT) evaluations [6].",
                "Assuming vectors are scaled by their L2 norm, we use the inner product, ˜di, ˜dj , to define similarity.",
                "Given documents and some similarity measure, we can construct a matrix which encodes the similarity between pairs of documents.",
                "Recall that we are given the top n documents retrieved in y.",
                "We can compute an n × n similarity matrix, W. An element of this matrix, Wij represents the similarity between documents ranked i and j.",
                "In practice, we only include the affinities for a documents k-nearest neighbors.",
                "In all of our experiments, we have fixed k to 5.",
                "We leave exploration of parameter sensitivity to future work.",
                "We also row normalize the matrix so that Pn j=1 Wij = 1 for all i. 3.2 Spatial Autocorrelation of a Retrieval Recall that we are interested in measuring the similarity between the scores of spatially-close documents.",
                "One such suitable measure is the Moran coefficient of spatial autocorrelation.",
                "Assuming the function y over n locations, this is defined as ˜IM = n eTWe P i,j Wijyiyj P i y2 i = n eTWe yT Wy yTy (2) where eT We = P ij Wij.",
                "We would like to compare autocorrelation values for different retrievals.",
                "Unfortunately, the bound for Equation 2 is not consistent for different W and y.",
                "Therefore, we use the Cauchy-Schwartz inequality to establish a bound, ˜IM ≤ n eTWe s yTWTWy yTy And we define the normalized spatial autocorrelation as IM = yT Wy p yTy × yTWTWy Notice that if we let ˜y = Wy, then we can write this formula as, IM = yT ˜y y 2 ˜y 2 (3) which can be interpreted as the correlation between the original retrieval scores and a set of retrieval scores diffused in the space.",
                "We present some examples of autocorrelations of functions on a grid in Figure 1. 3.3 Correlation with Other Retrievals Sometimes we are interested in the performance of a single retrieval but have access to scores from multiple systems for (a) IM = 0.006 (b) IM = 0.241 (c) IM = 0.487 Figure 1: The Moran coefficient, IM for a several binary functions on a grid.",
                "The Moran coefficient is a local measure of function consistency.",
                "From the perspective of information retrieval, each of these grid spaces would represent a document and documents would be organized so that they lay next to topically-related documents.",
                "Binary retrieval scores would define a pattern on this grid.",
                "Notice that, as the Moran coefficient increases, neighboring cells tend to have similar values. the same query.",
                "In this situation, we can use combined information from these scores to construct a surrogate for a high-quality ranking [17].",
                "We can treat the correlation between the retrieval we are interested in and the combined scores as a predictor of performance.",
                "Assume that we are given m score functions, yi, for the same n documents.",
                "We will represent the mean of these vectors as yµ = Pm i=1 yi.",
                "We use the mean vector as an approximation to relevance.",
                "Since we use zero mean and unit variance normalization, work in metasearch suggests that this assumption is justified [15].",
                "Because yµ represents a very good retrieval, we hypothesize that a strong similarity between yµ and y will correlate positively with system performance.",
                "We use Pearsons product-moment correlation to measure the similarity between these vectors, ρ(y, yµ) = yT yµ y 2 yµ 2 (4) We will comment on the similarity between Equation 3 and 4 in Section 7.",
                "Of course, we can combine ρ(y, ˜y) and ρ(y, yµ) if we assume that they capture different factors in the prediction.",
                "One way to accomplish this is to combine these predictors as independent variables in a linear regression.",
                "An alternative means of combination is suggested by the mathematical form of our predictors.",
                "Since ˜y encodes the spatial dependencies in y and yµ encodes the spatial properties of the multiple runs, we can compute a third correlation between these two vectors, ρ(˜y, yµ) = ˜yT yµ ˜y 2 yµ 2 (5) We can interpret Equation 5 as measuring the correlation between a high quality ranking (yµ) and a spatially smoothed version of the retrieval (˜y). 4.",
                "RELATIONSHIP WITH OTHER PREDICTORS One way to predict the effectiveness of a retrieval is to look at the shared vocabulary of the top n retrieved documents.",
                "If we computed the most frequent content words in this set, we would hope that they would be consistent with our topic.",
                "In fact, we might believe that a bad retrieval would include documents on many disparate topics, resulting in an overlap of terminological noise.",
                "The Clarity of a query attempts to quantify exactly this [7].",
                "Specifically, Clarity measures the similarity of the words most frequently used in retrieved documents to those most frequently used in the whole corpus.",
                "The conjecture is that a good retrieval will use language distinct from general text; the overlapping language in a bad retrieval will tend to be more similar to general text.",
                "Mathematically, we can compute a representation of the language used in the initial retrieval as a weighted combination of document language models, P(w|θQ) = nX i=1 P(w|θi) P(Q|θi) Z (6) where θi is the language model of the ith-ranked document, P(Q|θi) is the query likelihood score of the ith-ranked document and Z = Pn i=1 P(Q|θi) is a normalization constant.",
                "The similarity between the multinomial P(w|θQ) and a model of general text can be computed using the Kullback-Leibler divergence, DV KL(θQ θC ).",
                "Here, the distribution P(w|θC ) is our model of general text which can be computed using term frequencies in the corpus.",
                "In Figure 2a, we present Clarity as measuring the distance between the weighted center of mass of the retrieval (labeled y) and the unweighted center of mass of the collection (labeled O).",
                "Clarity reaches a minimum when a retrieval assigns every document the same score.",
                "Lets again assume we have a set of n documents retrieved for our query.",
                "Another way to quantify the dispersion of a set of documents is to look at how clustered they are.",
                "We may hypothesize that a good retrieval will return a single, tight cluster.",
                "A poorly performing retrieval will return a loosely related set of documents covering many topics.",
                "One proposed method of quantifying this dispersion is to measure the distance from a random document a to its nearest neighbor, b.",
                "A retrieval which is tightly clustered will, on average, have a low distance between a and b; a retrieval which is less tightly-closed will, on average have high distances between a and b.",
                "This average corresponds to using the Cox-Lewis statistic to measure the randomness of the top n documents retrieved from a system [18].",
                "In Figure 2a, this is roughly equivalent to measuring the area of the set n. Notice that we are throwing away information about the retrieval function y.",
                "Therefore the Cox-Lewis statistic is highly dependent on selecting the top n documents.1 Remember that we have n documents and a set of scores.",
                "Lets assume that we have access to the system which provided the original scores and that we can also request scores for new documents.",
                "This suggests a third method for predicting performance.",
                "Take some document, a, from the retrieved set and arbitrarily add or remove words at random to create a new document ˜a.",
                "Now, we can ask our system to score ˜a with respect to our query.",
                "If, on average over the n documents, the scores of a and ˜a tend to be very different, we might suspect that the system is failing on this query.",
                "So, an alternative approach is to measure the simi1 The authors have suggested coupling the query with the distance measure [18].",
                "The information introduced by the query, though, is retrieval-independent so that, if two retrievals return the same set of documents, the approximate Cox-Lewis statistic will be the same regardless of the retrieval scores. yOy (a) Global Divergence µ(y)˜y y (b) Score Perturbation µ(y) y (c) Multirun Averaging Figure 2: Representation of several performance predictors on a grid.",
                "In Figure 2a, we depict predictors which measure the divergence between the center of mass of a retrieval and the center of the embedding space.",
                "In Figure 2b, we depict predictors which compare the original retrieval, y, to a perturbed version of the retrieval, ˜y.",
                "Our approach uses a particular type of perturbation based on score diffusion.",
                "Finally, in Figure 2c, we depict prediction when given retrievals from several other systems on the same query.",
                "Here, we can consider the fusion of these retrieval as a surrogate for relevance. larity between the retrieval and a perturbed version of that retrieval [18, 19].",
                "This can be accomplished by either perturbing the documents or queries.",
                "The similarity between the two retrievals can be measured using some correlation measure.",
                "This is depicted in Figure 2b.",
                "The upper grid represents the original retrieval, y, while the lower grid represents the function after having been perturbed, ˜y.",
                "The nature of the perturbation process requires additional scorings or retrievals.",
                "Our predictor does not require access to the original scoring function or additional retrievals.",
                "So, although our method is similar to other perturbation methods in spirit, it can be applied in situations when the retrieval system is inaccessible or costly to access.",
                "Finally, assume that we have, in addition to the retrieval we want to evaluate, m retrievals from a variety of different systems.",
                "In this case, we might take a document a, compare its rank in the retrieval to its average rank in the m retrievals.",
                "If we believe that the m retrievals provide a satisfactory approximation to relevance, then a very large difference in rank would suggest that our retrieval is misranking a.",
                "If this difference is large on average over all n documents, then we might predict that the retrieval is bad.",
                "If, on the other hand, the retrieval is very consistent with the m retrievals, then we might predict that the retrieval is good.",
                "The similarity between the retrieval and the combined retrieval may be computed using some correlation measure.",
                "This is depicted in Figure 2c.",
                "In previous work, the Kullback-Leibler divergence between the normalized scores of the retrieval and the normalized scores of the combined retrieval provides the similarity [1]. 5.",
                "EXPERIMENTS Our experiments focus on testing the predictive power of each of our predictors: ρ(y, ˜y), ρ(y, yµ), and ρ(˜y, yµ).",
                "As stated in Section 2, we are interested in predicting the performance of the retrieval generated by an arbitrary system.",
                "Our methodology is consistent with previous research in that we predict the relative performance of a retrieval by comparing a ranking based on our predictor to a ranking based on average precision.",
                "We present results for two sets of experiments.",
                "The first set of experiments presents detailed comparisons of our predictors to previously-proposed predictors using identical data sets.",
                "Our second set of experiments demonstrates the generalizability of our approach to arbitrary retrieval methods, corpus types, and corpus languages. 5.1 Detailed Experiments In these experiments, we will predict the performance of language modeling scores using our autocorrelation predictor, ρ(y, ˜y); we do not consider ρ(y, yµ) or ρ(˜y, yµ) because, in these detailed experiments, we focus on ranking the retrievals from a single system.",
                "We use retrievals, values for baseline predictors, and evaluation measures reported in previous work [19]. 5.1.1 Topics and Collections These performance prediction experiments use language model retrievals performed for queries associated with collections in the TREC corpora.",
                "Using TREC collections allows us to confidently associate an average precision with a retrieval.",
                "In these experiments, we use the following topic collections: TREC 4 ad-hoc, TREC 5 ad-hoc, Robust 2004, Terabyte 2004, and Terabyte 2005. 5.1.2 Baselines We provide two baselines.",
                "Our first baseline is the classic Clarity predictor presented in Equation 6.",
                "Clarity is designed to be used with language modeling systems.",
                "Our second baseline is Zhou and Crofts ranking robustness predictor.",
                "This predictor corrupts the top k documents from retrieval and re-computes the language model scores for these corrupted documents.",
                "The value of the predictor is the Spearman rank correlation between the original ranking and the corrupted ranking.",
                "In our tables, we will label results for Clarity using DV KL and the ranking robustness predictor using P. 5.2 Generalizability Experiments Our predictors do not require a particular baseline retrieval system; the predictors can be computed for an arbitrary retrieval, regardless of how scores were generated.",
                "We believe that that is one of the most attractive aspects of our algorithm.",
                "Therefore, in a second set of experiments, we demonstrate the ability of our techniques to generalize to a variety of collections, topics, and retrieval systems. 5.2.1 Topics and Collections We gathered a diverse set of collections from all possible TREC corpora.",
                "We cast a wide net in order to locate collections where our predictors might fail.",
                "Our hypothesis is that documents with high topical similarity should have correlated scores.",
                "Therefore, we avoided collections where scores were unlikely to be correlated (eg, question-answering) or were likely to be negatively correlated (eg, novelty).",
                "Nevertheless, our collections include corpora where correlations are weakly justified (eg, non-English corpora) or not justified at all (eg, expert search).",
                "We use the ad-hoc tracks from TREC3-8, TREC Robust 2003-2005, TREC Terabyte 20042005, TREC4-5 Spanish, TREC5-6 Chinese, and TREC Enterprise Expert Search 2005.",
                "In all cases, we use only the automatic runs for ad-hoc tracks submitted to NIST.",
                "For all English and Spanish corpora, we construct the matrix W according to the process described in Section 3.1.",
                "For Chinese corpora, we use na¨ıve character-based tf.idf vectors.",
                "For entities, entries in W are proportional to the number of documents in which two entities cooccur. 5.2.2 Baselines In our detailed experiments, we used the Clarity measure as a baseline.",
                "Since we are predicting the performance of retrievals which are not based on language modeling, we use a version of Clarity referred to as ranked-list Clarity [7].",
                "Ranked-list clarity converts document ranks to P(Q|θi) values.",
                "This conversion begins by replacing all of the scores in y with the respective ranks.",
                "Our estimation of P(Q|θi) from the ranks, then is, P(Q|θi) = ( 2(c+1−yi) c(c+1) if yi ≤ c 0 otherwise (7) where c is a cutoff parameter.",
                "As suggested by the authors, we fix the algorithm parameters c and λ2 so that c = 60 and λ2 = 0.10.",
                "We use Equation 6 to estimate P(w|θQ) and DV KL(θQ θC ) to compute the value of the predictor.",
                "We will refer to this predictor as DV KL, superscripted by V to indicate that the Kullback-Leibler divergence is with respect to the term embedding space.",
                "When information from multiple runs on the same query is available, we use Aslam and Pavlus document-space multinomial divergence as a baseline [1].",
                "This rank-based method first normalizes the scores in a retrieval as an n-dimensional multinomial.",
                "As with ranked-list Clarity, we begin by replacing all of the scores in y with their respective ranks.",
                "Then, we adjust the elements of y in the following way, ˆyi = 1 2n 0 @1 + nX k=yi 1 k 1 A (8) In our multirun experiments, we only use the top 75 documents from each retrieval (n = 75); this is within the range of parameter values suggested by the authors.",
                "However, we admit not tuning this parameter for either our system or the baseline.",
                "The predictor is the divergence between the candidate distribution, y, and the mean distribution, yµ .",
                "With the uniform linear combination of these m retrievals represented as yµ, we can compute the divergence as Dn KL(ˆy ˆyµ) where we use the superscript n to indicate that the summation is over the set of n documents.",
                "This baseline was developed in the context of predicting query difficulty but we adopt it as a reasonable baseline for predicting retrieval performance. 5.2.3 Parameter Settings When given multiple retrievals, we use documents in the union of the top k = 75 documents from each of the m retrievals for that query.",
                "If the size of this union is ˜n, then yµ and each yi is of length ˜n.",
                "In some cases, a system did not score a document in the union.",
                "Since we are making a Gaussian assumption about our scores, we can sample scores for these unseen documents from the negative tail of the distribution.",
                "Specifically, we sample from the part of the distribution lower than the minimum value of in the normalized retrieval.",
                "This introduces randomness into our algorithm but we believe it is more appropriate than assigning an arbitrary fixed value.",
                "We optimized the linear regression using the square root of each predictor.",
                "We found that this substantially improved fits for all predictors, including the baselines.",
                "We considered linear combinations of pairs of predictors (labeled by the components) and all predictors (labeled as β). 5.3 Evaluation Given a set of retrievals, potentially from a combination of queries and systems, we measure the correlation of the rank ordering of this set by the predictor and by the performance metric.",
                "In order to ensure comparability with previous results, we present Kendalls τ correlation between the predictors ranking and ranking based on average precision of the retrieval.",
                "Unless explicitly noted, all correlations are significant with p < 0.05.",
                "Predictors can sometimes perform better when linearly combined [9, 11].",
                "Although previous work has presented the coefficient of determination (R2 ) to measure the quality of the regression, this measure cannot be reliably used when comparing slight improvements from combining predictors.",
                "Therefore, we adopt the adjusted coefficient of determination which penalizes models with more variables.",
                "The adjusted R2 allows us to evaluate the improvement in prediction achieved by adding a parameter but loses the statistical interpretation of R2 .",
                "We will use Kendalls τ to evaluate the magnitude of the correlation and the adjusted R2 to evaluate the combination of variables. 6.",
                "RESULTS We present results for our detailed experiments comparing the prediction of language model scores in Table 1.",
                "Although the Clarity measure is theoretically designed for language model scores, it consistently underperforms our system-agnostic predictor.",
                "Ranking robustness was presented as an improvement to Clarity for web collections (represented in our experiments by the terabyte04 and terabyte05 collections), shifting the τ correlation from 0.139 to 0.150 for terabyte04 and 0.171 to 0.208 for terabyte05.",
                "However, these improvements are slight compared to the performance of autocorrelation on these collections.",
                "Our predictor achieves a τ correlation of 0.454 for terabyte04 and 0.383 for terabyte05.",
                "Though not always the strongest, autocorrelation achieves correlations competitive with baseline predictors.",
                "When examining the performance of linear combinations of predictors, we note that in every case, autocorrelation factors as a necessary component of a strong predictor.",
                "We also note that the adjusted R2 for individual baselines are always significantly improved by incorporating autocorrelation.",
                "We present our generalizability results in Table 2.",
                "We begin by examining the situation in column (a) where we are presented with a single retrieval and no information from additional retrievals.",
                "For every collection except one, we achieve significantly better correlations than ranked-list Clarity.",
                "Surprisingly, we achieve relatively strong correlations for Spanish and Chinese collections despite our na¨ıve processing.",
                "We do not have a ranked-list clarity correlation for ent05 because entity modeling is itself an open research question.",
                "However, our autocorrelation measure does not achieve high correlations perhaps because relevance for entity retrieval does not propagate according to the cooccurrence links we use.",
                "As noted above, the poor Clarity performance on web data is consistent with our findings in the detailed experiments.",
                "Clarity also notably underperforms for several news corpora (trec5, trec7, and robust04).",
                "On the other hand, autocorrelation seems robust to the changes between different corpora.",
                "Next, we turn to the introduction of information from multiple retrievals.",
                "We compare the correlations between those predictors which do not use this information in column (a) and those which do in column (b).",
                "For every collection, the predictors in column (b) outperform the predictors in column (a), indicating that the information from additional runs can be critical to making good predictions.",
                "Inspecting the predictors in column (b), we only draw weak conclusions.",
                "Our new predictors tend to perform better on news corpora.",
                "And between our new predictors, the hybrid ρ(˜y, yµ) predictor tends to perform better.",
                "Recall that our ρ(˜y, yµ) measure incorporates both spatial and multiple retrieval information.",
                "Therefore, we believe that the improvement in correlation is the result of incorporating information from spatial behavior.",
                "In column (c), we can investigate the utility of incorporating spatial information with information from multiple retrievals.",
                "Notice that in the cases where autocorrelation, ρ(y, ˜y), alone performs well (trec3, trec5-spanish, and trec6-chinese), it is substantially improved by incorporating multiple-retrieval information from ρ(y, yµ) in the linear regression, β.",
                "In the cases where ρ(y, yµ) performs well, incorporating autocorrelation rarely results in a significant improvement in performance.",
                "In fact, in every case where our predictor outperforms the baseline, it includes information from multiple runs. 7.",
                "DISCUSSION The most important result from our experiments involves prediction when no information is available from multiple runs (Tables 1 and 2a).",
                "This situation arises often in system design.",
                "For example, a system may need to, at retrieval time, assess its performance before deciding to conduct more intensive processing such as pseudo-relevance feedback or interaction.",
                "Assuming the presence of multiple retrievals is unrealistic in this case.",
                "We believe that autocorrelation is, like multiple-retrieval algorithms, approximating a good ranking; in this case by diffusing scores.",
                "Why is ˜y a reasonable surrogate?",
                "We know that diffusion of scores on the web graph and language model graphs improves performance [14, 16].",
                "Therefore, if score diffusion tends to, in general, improve performance, then diffused scores will, in general, provide a good surrogate for relevance.",
                "Our results demonstrate that this approximation is not as powerful as information from multiple retrievals.",
                "Nevertheless, in situations where this information is lacking, autocorrelation provides substantial information.",
                "The success of autocorrelation as a predictor may also have roots in the clustering hypothesis.",
                "Recall that we regard autocorrelation as the degree to which a retrieval satisfies the clustering hypothesis.",
                "Our experiments, then, demonstrate that a failure to respect the clustering hypothesis correlates with poor performance.",
                "Why might systems fail to conform to the cluster hypothesis?",
                "Query-based information retrieval systems often score documents independently.",
                "The score of document a may be computed by examining query term or phrase matches, the document length, and perhaps global collection statistics.",
                "Once computed, a system rarely compares the score of a to the score of a topically-related document b.",
                "With some exceptions, the correlation of document scores has largely been ignored.",
                "We should make it clear that we have selected tasks where topical autocorrelation is appropriate.",
                "There are certainly cases where there is no reason to believe that retrieval scores will have topical autocorrelation.",
                "For example, ranked lists which incorporate document novelty should not exhibit spatial autocorrelation; if anything autocorrelation should be negative for this task.",
                "Similarly, answer candidates in a question-answering task may or may not exhibit autocorrelation; in this case, the semantics of links is questionable too.",
                "It is important before applying this measure to confirm that, given the semantics for some link between two retrieved items, we should expect a correlation between scores. 8.",
                "RELATED WORK In this section we draw more general comparisons to other work in performance prediction and spatial data analysis.",
                "There is a growing body of work which attempts to predict the performance of individual retrievals [7, 3, 11, 9, 19].",
                "We have attempted to place our work in the context of much of this work in Section 4.",
                "However, a complete comparison is beyond the scope of this paper.",
                "We note, though, that our experiments cover a larger and more diverse set of retrievals, collections, and topics than previously examined.",
                "Much previous work-particularly in the context of TRECfocuses on predicting the performance of systems.",
                "Here, each system generates k retrievals.",
                "The task is, given these retrievals, to predict the ranking of systems according to some performance measure.",
                "Several papers attempt to address this task under the constraint of few judgments [2, 4].",
                "Some work even attempts to use zero judgments by leveraging multiple retrievals for the same query [17].",
                "Our task differs because we focus on ranking retrievals independent of the generating system.",
                "The task here is not to test the hypothesis system A is superior to system B but to test the hypothesis retrieval A is superior to retrieval B. Autocorrelation manifests itself in many classification tasks.",
                "Neville and Jensen define relational autocorrelation for relational learning problems and demonstrate that many classification tasks manifest autocorrelation [13].",
                "Temporal autocorrelation of initial retrievals has also been used to predict performance [9].",
                "However, temporal autocorrelation is performed by projecting the retrieval function into the temporal embedding space.",
                "In our work, we focus on the behavior of the function over the relationships between documents. τ adjusted R2 DV KL P ρ(y, ˜y) DV KL P ρ(y, ˜y) DV KL, P DV KL, ρ(y, ˜y) Pρ(y, ˜y) β trec4 0.353 0.548 0.513 0.168 0.363 0.422 0.466 0.420 0.557 0.553 trec5 0.311 0.329 0.357 0.116 0.190 0.236 0.238 0.244 0.266 0.269 robust04 0.418 0.398 0.373 0.256 0.304 0.278 0.403 0.373 0.402 0.442 terabyte04 0.139 0.150 0.454 0.059 0.045 0.292 0.076 0.293 0.289 0.284 terabyte05 0.171 0.208 0.383 0.022 0.072 0.193 0.120 0.225 0.218 0.257 Table 1: Comparison to Robustness and Clarity measures for language model scores.",
                "Evaluation replicates experiments from [19].",
                "We present correlations between the classic Clarity measure (DV KL), the ranking robustness measure (P), and autocorrelation (ρ(y, ˜y)) each with mean average precision in terms of Kendalls τ.",
                "The adjusted coefficient of determination is presented to measure the effectiveness of combining predictors.",
                "Measures in bold represent the strongest correlation for that test/collection pair. multiple run (a) (b) (c) τ τ adjusted R2 DKL ρ(y, ˜y) Dn KL ρ(y, yµ) ρ(˜y, yµ) Dn KL ρ(y, ˜y) ρ(y, yµ) ρ(˜y, yµ) β trec3 0.201 0.461 0.461 0.439 0.456 0.444 0.395 0.394 0.386 0.498 trec4 0.252 0.396 0.455 0.482 0.489 0.379 0.263 0.429 0.482 0.483 trec5 0.016 0.277 0.433 0.459 0.393 0.280 0.157 0.375 0.323 0.386 trec6 0.230 0.227 0.352 0.428 0.418 0.203 0.089 0.323 0.325 0.325 trec7 0.083 0.326 0.341 0.430 0.483 0.264 0.182 0.363 0.442 0.400 trec8 0.235 0.396 0.454 0.508 0.567 0.402 0.272 0.490 0.580 0.523 robust03 0.302 0.354 0.377 0.385 0.447 0.269 0.206 0.274 0.392 0.303 robust04 0.183 0.308 0.301 0.384 0.453 0.200 0.182 0.301 0.393 0.335 robust05 0.224 0.249 0.371 0.377 0.404 0.341 0.108 0.313 0.328 0.336 terabyte04 0.043 0.245 0.544 0.420 0.392 0.516 0.105 0.357 0.343 0.365 terabyte05 0.068 0.306 0.480 0.434 0.390 0.491 0.168 0.384 0.309 0.403 trec4-spanish 0.307 0.388 0.488 0.398 0.395 0.423 0.299 0.282 0.299 0.388 trec5-spanish 0.220 0.458 0.446 0.484 0.475 0.411 0.398 0.428 0.437 0.529 trec5-chinese 0.092 0.199 0.367 0.379 0.384 0.379 0.199 0.273 0.276 0.310 trec6-chinese 0.144 0.276 0.265 0.353 0.376 0.115 0.128 0.188 0.223 0.199 ent05 - 0.181 0.324 0.305 0.282 0.211 0.043 0.158 0.155 0.179 Table 2: Large scale prediction experiments.",
                "We predict the ranking of large sets of retrievals for various collections and retrieval systems.",
                "Kendalls τ correlations are computed between the predicted ranking and a ranking based on the retrievals average precision.",
                "In column (a), we have predictors which do not use information from other retrievals for the same query.",
                "In columns (b) and (c) we present performance for predictors which incorporate information from multiple retrievals.",
                "The adjusted coefficient of determination is computed to determine effectiveness of combining predictors.",
                "Measures in bold represent the strongest correlation for that test/collection pair.",
                "Finally, regularization-based re-ranking processes are also closely-related to our work [8].",
                "These techniques seek to maximize the agreement between scores of related documents by solving a constrained optimization problem.",
                "The maximization of consistency is equivalent to maximizing the Moran autocorrelation.",
                "Therefore, we believe that our work provides explanation for why regularization-based re-ranking works. 9.",
                "CONCLUSION We have presented a new method for predicting the performance of a retrieval ranking without any relevance judgments.",
                "We consider two cases.",
                "First, when making predictions in the absence of retrievals from other systems, our predictors demonstrate robust, strong correlations with average precision.",
                "This performance, combined with a simple implementation, makes our predictors, in particular, very attractive.",
                "We have demonstrated this improvement for many, diverse settings.",
                "To our knowledge, this is the first large scale examination of zero-judgment, single-retrieval performance prediction.",
                "Second, when provided retrievals from other systems, our extended methods demonstrate competitive performance with state of the art baselines.",
                "Our experiments also demonstrate the limits of the usefulness of our predictors when information from multiple runs is provided.",
                "Our results suggest two conclusions.",
                "First, our results could affect retrieval algorithm design.",
                "Retrieval algorithms designed to consider spatial autocorrelation will conform to the cluster hypothesis and improve performance.",
                "Second, our results could affect the design of minimal test collection algorithms.",
                "Much of the recent work in ranking systems sometimes ignores correlations between document labels and scores.",
                "We believe that these two directions could be rewarding given the theoretical and experimental evidence in this paper. 10.",
                "ACKNOWLEDGMENTS This work was supported in part by the Center for Intelligent Information Retrieval and in part by the Defense Advanced Research Projects Agency (DARPA) under contract number HR0011-06-C-0023.",
                "Any opinions, findings and conclusions or recommendations expressed in this material are the authors and do not necessarily reflect those of the sponsor.",
                "We thank Yun Zhou and Desislava Petkova for providing data and Andre Gauthier for technical assistance. 11.",
                "REFERENCES [1] J. Aslam and V. Pavlu.",
                "Query hardness estimation using jensen-shannon divergence among multiple scoring functions.",
                "In ECIR 2007: Proceedings of the 29th European Conference on Information Retrieval, 2007. [2] J.",
                "A. Aslam, V. Pavlu, and E. Yilmaz.",
                "A statistical method for system evaluation using incomplete judgments.",
                "In S. Dumais, E. N. Efthimiadis, D. Hawking, and K. Jarvelin, editors, Proceedings of the 29th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 541-548.",
                "ACM Press, August 2006. [3] D. Carmel, E. Yom-Tov, A. Darlow, and D. Pelleg.",
                "What makes a query difficult?",
                "In SIGIR 06: Proceedings of the 29th annual international ACM SIGIR conference on Research and development in information retrieval, pages 390-397, New York, NY, USA, 2006.",
                "ACM Press. [4] B. Carterette, J. Allan, and R. Sitaraman.",
                "Minimal test collections for retrieval evaluation.",
                "In SIGIR 06: Proceedings of the 29th annual international ACM SIGIR conference on Research and development in information retrieval, pages 268-275, New York, NY, USA, 2006.",
                "ACM Press. [5] A. D. Cliff and J. K. Ord.",
                "Spatial Autocorrelation.",
                "Pion Ltd., 1973. [6] M. Connell, A. Feng, G. Kumaran, H. Raghavan, C. Shah, and J. Allan.",
                "Umass at tdt 2004.",
                "Technical Report CIIR Technical Report IR - 357, Department of Computer Science, University of Massachusetts, 2004. [7] S. Cronen-Townsend, Y. Zhou, and W. B. Croft.",
                "Precision prediction based on ranked list coherence.",
                "Inf.",
                "Retr., 9(6):723-755, 2006. [8] F. Diaz.",
                "Regularizing ad-hoc retrieval scores.",
                "In CIKM 05: Proceedings of the 14th ACM international conference on Information and knowledge management, pages 672-679, New York, NY, USA, 2005.",
                "ACM Press. [9] F. Diaz and R. Jones.",
                "Using temporal profiles of queries for precision prediction.",
                "In SIGIR 04: Proceedings of the 27th annual international ACM SIGIR conference on Research and development in information retrieval, pages 18-24, New York, NY, USA, 2004.",
                "ACM Press. [10] D. A. Griffith.",
                "Spatial Autocorrelation and Spatial Filtering.",
                "Springer Verlag, 2003. [11] B.",
                "He and I. Ounis.",
                "Inferring Query Performance Using Pre-retrieval Predictors.",
                "In The Eleventh Symposium on String Processing and Information Retrieval (SPIRE), 2004. [12] N. Jardine and C. J. V. Rijsbergen.",
                "The use of hierarchic clustering in information retrieval.",
                "Information Storage and Retrieval, 7:217-240, 1971. [13] D. Jensen and J. Neville.",
                "Linkage and autocorrelation cause feature selection bias in relational learning.",
                "In ICML 02: Proceedings of the Nineteenth International Conference on Machine Learning, pages 259-266, San Francisco, CA, USA, 2002.",
                "Morgan Kaufmann Publishers Inc. [14] O. Kurland and L. Lee.",
                "Corpus structure, language models, and ad-hoc information retrieval.",
                "In SIGIR 04: Proceedings of the 27th annual international conference on Research and development in information retrieval, pages 194-201, New York, NY, USA, 2004.",
                "ACM Press. [15] M. Montague and J.",
                "A. Aslam.",
                "Relevance score normalization for metasearch.",
                "In CIKM 01: Proceedings of the tenth international conference on Information and knowledge management, pages 427-433, New York, NY, USA, 2001.",
                "ACM Press. [16] T. Qin, T.-Y.",
                "Liu, X.-D. Zhang, Z. Chen, and W.-Y.",
                "Ma.",
                "A study of relevance propagation for web search.",
                "In SIGIR 05: Proceedings of the 28th annual international ACM SIGIR conference on Research and development in information retrieval, pages 408-415, New York, NY, USA, 2005.",
                "ACM Press. [17] I. Soboroff, C. Nicholas, and P. Cahan.",
                "Ranking retrieval systems without relevance judgments.",
                "In SIGIR 01: Proceedings of the 24th annual international ACM SIGIR conference on Research and development in information retrieval, pages 66-73, New York, NY, USA, 2001.",
                "ACM Press. [18] V. Vinay, I. J. Cox, N. Milic-Frayling, and K. Wood.",
                "On ranking the effectiveness of searches.",
                "In SIGIR 06: Proceedings of the 29th annual international ACM SIGIR conference on Research and development in information retrieval, pages 398-404, New York, NY, USA, 2006.",
                "ACM Press. [19] Y. Zhou and W. B. Croft.",
                "Ranking robustness: a novel framework to predict query performance.",
                "In CIKM 06: Proceedings of the 15th ACM international conference on Information and knowledge management, pages 567-574, New York, NY, USA, 2006.",
                "ACM Press."
            ],
            "original_annotated_samples": [
                "Previous work addresses the evaluation of systems, the <br>ranking of queries</br> by difficulty, and the ranking of individual retrievals by performance."
            ],
            "translated_annotated_samples": [
                "Trabajos anteriores abordan la evaluación de sistemas, la <br>clasificación de consultas</br> por dificultad y la clasificación de recuperaciones individuales por rendimiento."
            ],
            "translated_text": "Predicción del rendimiento utilizando autocorrelación espacial. Fernando Díaz. Centro de Recuperación de Información Inteligente. Departamento de Ciencias de la Computación. Universidad de Massachusetts Amherst, MA 01003. fdiaz@cs.umass.edu. RESUMEN La evaluación de sistemas de recuperación de información es una de las tareas fundamentales en la recuperación de información. Los problemas incluyen la incapacidad de etiquetar exhaustivamente todos los documentos sobre un tema, la falta de generalización a partir de un pequeño número de temas e incorporar la variabilidad de los sistemas de recuperación. Trabajos anteriores abordan la evaluación de sistemas, la <br>clasificación de consultas</br> por dificultad y la clasificación de recuperaciones individuales por rendimiento. Existen enfoques para el caso de pocos e incluso ningún juicio de relevancia. Nuestro enfoque está en la predicción del rendimiento sin juicios de las recuperaciones individuales. Una deficiencia común de las técnicas anteriores es la suposición de que las puntuaciones de los documentos y los juicios no están correlacionados. Si los documentos están incrustados en un espacio de alta dimensión (como a menudo lo están), podemos aplicar técnicas de análisis de datos espaciales para detectar correlaciones entre las puntuaciones de los documentos. Observamos que la baja correlación entre las puntuaciones de documentos temáticamente cercanos a menudo implica un bajo rendimiento en la recuperación. Cuando se compara con una línea base de última generación, demostramos que el análisis espacial de las puntuaciones de recuperación ofrece un rendimiento predictivo significativamente mejor. Estos nuevos predictores también pueden ser incorporados con predictores clásicos para mejorar aún más el rendimiento. También describimos el primer experimento a gran escala para evaluar la predicción de rendimiento sin juicio para un gran número de sistemas de recuperación en una variedad de colecciones en varios idiomas. Categorías y Descriptores de Asignaturas H.3.3 [Búsqueda y Recuperación de Información]: Modelos de recuperación; H.3.4 [Sistemas y Software]: Evaluación del rendimiento (eficiencia y efectividad) Términos Generales Rendimiento, Diseño, Confiabilidad, Experimentación 1. En la recuperación de información, un usuario plantea una consulta a un sistema. El sistema recupera n documentos, cada uno recibiendo una puntuación de valor real que indica el grado de relevancia predicho. Si seleccionamos aleatoriamente pares de documentos de este conjunto, esperamos que algunos pares compartan el mismo tema y otros pares no compartan el mismo tema. Toma dos documentos relacionados entre sí del conjunto y llámalos a y b. Si las puntuaciones de a y b son muy diferentes, podríamos estar preocupados por el rendimiento de nuestro sistema. Es decir, si tanto a como b están relacionados con el tema de la consulta, nos gustaría que ambos reciban una puntuación alta; si a y b no están relacionados con el tema de la consulta, nos gustaría que ambos reciban una puntuación baja. Podríamos preocuparnos más a medida que encontramos más diferencias entre las puntuaciones de documentos relacionados. Estaríamos más cómodos con una recuperación en la que las puntuaciones sean consistentes entre documentos relacionados. Nuestro artículo estudia la cuantificación de esta inconsistencia en una recuperación desde una perspectiva espacial. El análisis espacial es apropiado ya que muchos modelos de recuperación incrustan documentos en algún espacio vectorial. Si los documentos están incrustados en un espacio, la proximidad se correlaciona con las relaciones temáticas. La consistencia de la puntuación puede medirse mediante la versión espacial de la autocorrelación conocida como el coeficiente de Moran o IM [5, 10]. En este artículo, demostramos una fuerte correlación entre IM y el rendimiento de recuperación. La discusión hasta este punto recuerda a la hipótesis del cúmulo. La hipótesis del clúster establece que los documentos estrechamente relacionados tienden a ser relevantes para la misma solicitud [12]. Como veremos, una función de recuperación de medidas de autocorrelación espacial mide el grado en que los documentos relacionados reciben puntuaciones similares. Debido a esto, interpretamos la autocorrelación como la medida del grado en que una función de recuperación satisface la hipótesis de agrupamiento. Si esta conexión es razonable, en la Sección 6 presentamos evidencia de que la falta de cumplimiento de la hipótesis de agrupamiento se correlaciona fuertemente con un bajo rendimiento. En este trabajo, proporcionamos las siguientes contribuciones: 1. Un método general y robusto para predecir el rendimiento de recuperaciones sin juicios de relevancia (Sección 3). 2. Un tratamiento teórico de las similitudes y motivaciones detrás de varias técnicas de predicción de rendimiento de vanguardia (Sección 4). 3. Las primeras experimentaciones a gran escala de predicción de rendimiento de una sola ejecución sin juicio (Secciones 5 y 6). 2. Dada una consulta, un sistema de recuperación de información produce una clasificación de documentos en la colección codificada como un conjunto de puntuaciones asociadas con los documentos. Nos referimos al conjunto de puntuaciones para una combinación particular de consulta-sistema como una recuperación. Nos gustaría predecir el rendimiento de esta recuperación con respecto a alguna medida de evaluación (por ejemplo, precisión promedio). En este artículo, presentamos resultados para clasificar recuperaciones de sistemas arbitrarios. Nos gustaría que este ranking se aproximara al ranking de recuperaciones según la medida de evaluación. Esto es diferente de clasificar las consultas por el rendimiento promedio en cada consulta. También es diferente de los sistemas de clasificación por el rendimiento promedio en un conjunto de consultas. Las puntuaciones a menudo solo se calculan para los primeros n documentos de la colección. Colocamos estos puntajes en el vector de longitud n, y, donde yi se refiere al puntaje del documento clasificado en la posición i. Ajustamos las puntuaciones para que tengan una media de cero y una varianza unitaria. Utilizamos este método debido a su simplicidad y su éxito en trabajos anteriores [15]. CORRELACIÓN ESPACIAL En la recuperación de información, a menudo asumimos que las representaciones de los documentos existen en algún espacio vectorial de alta dimensión. Por ejemplo, dado un vocabulario, V, este espacio vectorial puede ser un espacio arbitrario de dimensión |V| con producto interno de coseno o un simplejo multinomial con una medida de distancia basada en distribución. Un espacio de incrustación suele ser seleccionado para respetar la proximidad temática; si dos documentos están cerca, es más probable que compartan un tema. Debido a la prevalencia y éxito de los modelos espaciales de recuperación de información, creemos que la aplicación de técnicas de análisis de datos espaciales es apropiada. Mientras que en la recuperación de información nos preocupa la puntuación en un punto en el espacio, en el análisis de datos espaciales nos preocupa el valor de una función en un punto o ubicación en el espacio. Utilizamos el término función aquí para referirnos a una asignación de una ubicación a un valor real. Por ejemplo, podríamos estar interesados en la prevalencia de una enfermedad en el vecindario de alguna ciudad. La función asignaría la ubicación de un vecindario a una tasa de infección. Si queremos cuantificar las dependencias espaciales de una función, emplearíamos una medida conocida como la autocorrelación espacial [5, 10]. Una alta autocorrelación espacial sugiere que conocer el valor de una función en la ubicación a nos dirá mucho sobre el valor en una ubicación vecina b. Existe una alta autocorrelación espacial para una función que representa la temperatura de una ubicación, ya que saber la temperatura en una ubicación a nos dirá mucho sobre la temperatura en una ubicación vecina b. La baja autocorrelación espacial sugiere que conocer el valor de una función en la ubicación a nos dice poco sobre el valor en una ubicación vecina b. Hay una baja autocorrelación espacial en una función que mide el resultado de lanzar una moneda en a y b. En esta sección, comenzaremos describiendo lo que entendemos por proximidad espacial para documentos y luego definiremos una medida de autocorrelación espacial. Concluimos extendiendo este modelo para incluir información de múltiples recuperaciones de múltiples sistemas para una sola consulta. 3.1 Representación Espacial de Documentos Nuestro trabajo no se centra en mejorar una medida de similitud específica o definir un espacio vectorial novedoso. En cambio, elegimos un producto interno conocido por ser efectivo en la detección de relaciones temáticas entre documentos. Específicamente, adoptamos vectores de documentos tf.idf, ˜di = di log „ (n + 0.5) − ci 0.5 + ci « (1) donde d es un vector de frecuencias de términos, c es el vector de frecuencia de documentos de longitud |V|. Utilizamos este esquema de ponderación debido a su éxito en la detección de enlaces temáticos en el contexto de las evaluaciones de Detección y Seguimiento de Temas (TDT) [6]. Suponiendo que los vectores están escalados por su norma L2, usamos el producto interno, ˜di, ˜dj, para definir la similitud. Dado un conjunto de documentos y alguna medida de similitud, podemos construir una matriz que codifica la similitud entre pares de documentos. Recuerde que se nos dan los primeros n documentos recuperados en y. Podemos calcular una matriz de similitud n × n, W. Un elemento de esta matriz, Wij, representa la similitud entre los documentos clasificados i y j. En la práctica, solo incluimos las afinidades para los k vecinos más cercanos de un documento. En todos nuestros experimentos, hemos fijado k en 5. Dejamos la exploración de la sensibilidad de los parámetros para trabajos futuros. También normalizamos por filas la matriz para que Pn j=1 Wij = 1 para todos los i. 3.2 Autocorrelación Espacial de una Recuperación Recuerde que estamos interesados en medir la similitud entre las puntuaciones de documentos cercanos espacialmente. Una medida adecuada es el coeficiente de Moran de autocorrelación espacial. Suponiendo la función y sobre n ubicaciones, esto se define como ˜IM = n eTWe P i,j Wijyiyj P i y2 i = n eTWe yT Wy yTy (2) donde eT We = P ij Wij. Nos gustaría comparar los valores de autocorrelación para diferentes recuperaciones. Desafortunadamente, el límite para la Ecuación 2 no es consistente para diferentes valores de W y y. Por lo tanto, utilizamos la desigualdad de Cauchy-Schwartz para establecer un límite, ˜IM ≤ n eTWe s yTWTWy yTy Y definimos la autocorrelación espacial normalizada como IM = yT Wy p yTy × yTWTWy. Nótese que si dejamos ˜y = Wy, entonces podemos escribir esta fórmula como, IM = yT ˜y y 2 ˜y 2 (3) lo cual puede interpretarse como la correlación entre las puntuaciones originales de recuperación y un conjunto de puntuaciones de recuperación difundidas en el espacio. Presentamos algunos ejemplos de autocorrelaciones de funciones en una cuadrícula en la Figura 1. 3.3 Correlación con Otros Recuperos A veces estamos interesados en el rendimiento de un solo recuperación pero tenemos acceso a puntajes de múltiples sistemas para (a) IM = 0.006 (b) IM = 0.241 (c) IM = 0.487 Figura 1: El coeficiente de Moran, IM para varias funciones binarias en una cuadrícula. El coeficiente de Moran es una medida local de consistencia de la función. Desde la perspectiva de la recuperación de información, cada uno de estos espacios de la cuadrícula representaría un documento y los documentos estarían organizados de manera que se encuentren junto a documentos relacionados temáticamente. Las puntuaciones de recuperación binaria definirían un patrón en esta cuadrícula. Ten en cuenta que, a medida que el coeficiente de Moran aumenta, las celdas vecinas tienden a tener valores similares. En esta situación, podemos utilizar la información combinada de estas puntuaciones para construir un sustituto de una clasificación de alta calidad [17]. Podemos tratar la correlación entre la recuperación que nos interesa y las puntuaciones combinadas como un predictor del rendimiento. Supongamos que se nos dan m funciones de puntuación, yi, para los mismos n documentos. Representaremos la media de estos vectores como yµ = Σm i=1 yi. Utilizamos el vector medio como una aproximación a la relevancia. Dado que utilizamos normalización de media cero y varianza unitaria, el trabajo en metabusqueda sugiere que esta suposición está justificada [15]. Dado que yµ representa una recuperación muy buena, hipotetizamos que una similitud fuerte entre yµ e y correlacionará positivamente con el rendimiento del sistema. Utilizamos la correlación de Pearson para medir la similitud entre estos vectores, ρ(y, yµ) = yT yµ y 2 yµ 2 (4). Comentaremos sobre la similitud entre la Ecuación 3 y 4 en la Sección 7. Por supuesto, podemos combinar ρ(y, ˜y) y ρ(y, yµ) si asumimos que capturan diferentes factores en la predicción. Una forma de lograr esto es combinar estos predictores como variables independientes en una regresión lineal. Se sugiere un medio alternativo de combinación basado en la forma matemática de nuestros predictores. Dado que ˜y codifica las dependencias espaciales en y y yµ codifica las propiedades espaciales de las múltiples ejecuciones, podemos calcular una tercera correlación entre estos dos vectores, ρ(˜y, yµ) = ˜yT yµ ˜y 2 yµ 2 (5). Podemos interpretar la Ecuación 5 como la medición de la correlación entre un ranking de alta calidad (yµ) y una versión suavizada espacialmente de la recuperación (˜y). 4. RELACIÓN CON OTROS PREDICTORES Una forma de predecir la efectividad de una recuperación es observar el vocabulario compartido de los n documentos principales recuperados. Si calculáramos las palabras de contenido más frecuentes en este conjunto, esperaríamos que fueran coherentes con nuestro tema. De hecho, podríamos creer que una mala recuperación incluiría documentos sobre muchos temas dispares, lo que resultaría en una superposición de ruido terminológico. La claridad de una consulta intenta cuantificar exactamente esto [7]. Específicamente, la Claridad mide la similitud de las palabras más frecuentemente utilizadas en los documentos recuperados con aquellas más frecuentemente utilizadas en todo el corpus. La conjetura es que una buena recuperación utilizará un lenguaje distinto al del texto general; el lenguaje superpuesto en una mala recuperación tenderá a ser más similar al texto general. Matemáticamente, podemos calcular una representación del lenguaje utilizado en la recuperación inicial como una combinación ponderada de modelos de lenguaje de documentos, P(w|θQ) = Σ i=1 P(w|θi) P(Q|θi) Z (6) donde θi es el modelo de lenguaje del documento clasificado en la posición i, P(Q|θi) es la puntuación de probabilidad de la consulta del documento clasificado en la posición i y Z = Σ i=1 P(Q|θi) es una constante de normalización. La similitud entre el multinomial P(w|θQ) y un modelo de texto general se puede calcular utilizando la divergencia de Kullback-Leibler, DV KL(θQ θC). Aquí, la distribución P(w|θC) es nuestro modelo de texto general que puede ser calculado utilizando las frecuencias de términos en el corpus. En la Figura 2a, presentamos la Claridad como la medida de la distancia entre el centro de masa ponderado de la recuperación (etiquetado como y) y el centro de masa no ponderado de la colección (etiquetado como O). La claridad alcanza un mínimo cuando una recuperación asigna a cada documento la misma puntuación. Volvamos a asumir que tenemos un conjunto de n documentos recuperados para nuestra consulta. Otra forma de cuantificar la dispersión de un conjunto de documentos es observar qué tan agrupados están. Podemos hipotetizar que una buena recuperación devolverá un único y compacto grupo. Una recuperación de bajo rendimiento devolverá un conjunto de documentos poco relacionados que abarcan muchos temas. Un método propuesto para cuantificar esta dispersión es medir la distancia desde un documento aleatorio a su vecino más cercano, b. Una recuperación que esté estrechamente agrupada, en promedio, tendrá una distancia baja entre a y b; una recuperación que esté menos cerrada tendrá, en promedio, distancias altas entre a y b. Este promedio corresponde al uso de la estadística de Cox-Lewis para medir la aleatoriedad de los primeros n documentos recuperados de un sistema [18]. En la Figura 2a, esto es aproximadamente equivalente a medir el área del conjunto n. Observa que estamos descartando información sobre la función de recuperación y. Por lo tanto, la estadística de Cox-Lewis depende en gran medida de la selección de los primeros n documentos. Recuerda que tenemos n documentos y un conjunto de puntuaciones. Supongamos que tenemos acceso al sistema que proporcionó las puntuaciones originales y que también podemos solicitar puntuaciones para nuevos documentos. Esto sugiere un tercer método para predecir el rendimiento. Toma algún documento, a, del conjunto recuperado y agrega o elimina palabras al azar de forma arbitraria para crear un nuevo documento ˜a. Ahora, podemos pedirle a nuestro sistema que puntúe ˜a con respecto a nuestra consulta. Si, en promedio, a lo largo de los n documentos, las puntuaciones de a y ˜a tienden a ser muy diferentes, podríamos sospechar que el sistema está fallando en esta consulta. Los autores han sugerido acoplar la consulta con la medida de distancia [18]. La información introducida por la consulta, sin embargo, es independiente de la recuperación, de modo que, si dos recuperaciones devuelven el mismo conjunto de documentos, la estadística aproximada de Cox-Lewis será la misma independientemente de las puntuaciones de recuperación. yOy (a) Divergencia Global µ(y)˜y y (b) Perturbación de Puntuación µ(y) y (c) Promedio de Múltiples Ejecuciones Figura 2: Representación de varios predictores de rendimiento en una cuadrícula. En la Figura 2a, representamos los predictores que miden la divergencia entre el centro de masa de una recuperación y el centro del espacio de incrustación. En la Figura 2b, representamos los predictores que comparan la recuperación original, y, con una versión perturbada de la recuperación, ˜y. Nuestro enfoque utiliza un tipo particular de perturbación basado en la difusión de puntajes. Finalmente, en la Figura 2c, representamos la predicción cuando se proporcionan recuperaciones de varios otros sistemas en la misma consulta. Aquí, podemos considerar la fusión de estas recuperaciones como un sustituto de la relevancia. Esto se puede lograr ya sea perturbando los documentos o las consultas. La similitud entre los dos recuperos se puede medir utilizando alguna medida de correlación. Esto se muestra en la Figura 2b. La cuadrícula superior representa la recuperación original, y, mientras que la cuadrícula inferior representa la función después de haber sido perturbada, ˜y. La naturaleza del proceso de perturbación requiere puntuaciones o recuperaciones adicionales. Nuestro predictor no requiere acceso a la función de puntuación original ni a recuperaciones adicionales. Por lo tanto, aunque nuestro método es similar a otros métodos de perturbación en espíritu, se puede aplicar en situaciones en las que el sistema de recuperación es inaccesible o costoso de acceder. Finalmente, supongamos que tenemos, además de la recuperación que queremos evaluar, m recuperaciones de una variedad de sistemas diferentes. En este caso, podríamos tomar un documento a, comparar su rango en la recuperación con su rango promedio en los m recuperos. Si creemos que las m recuperaciones proporcionan una aproximación satisfactoria a la relevancia, entonces una diferencia muy grande en el rango sugeriría que nuestra recuperación está clasificando incorrectamente a. Si esta diferencia es grande en promedio en todos los n documentos, entonces podríamos predecir que la recuperación es mala. Si, por otro lado, la recuperación es muy consistente con las m recuperaciones, entonces podríamos predecir que la recuperación es buena. La similitud entre la recuperación y la recuperación combinada puede calcularse utilizando alguna medida de correlación. Esto se muestra en la Figura 2c. En trabajos anteriores, la divergencia de Kullback-Leibler entre las puntuaciones normalizadas de la recuperación y las puntuaciones normalizadas de la recuperación combinada proporciona la similitud [1]. 5. Nuestros experimentos se centran en probar el poder predictivo de cada uno de nuestros predictores: ρ(y, ˜y), ρ(y, yµ) y ρ(˜y, yµ). Como se indica en la Sección 2, estamos interesados en predecir el rendimiento de la recuperación generada por un sistema arbitrario. Nuestra metodología es consistente con investigaciones previas en el sentido de que predecimos el rendimiento relativo de una recuperación al comparar una clasificación basada en nuestro predictor con una clasificación basada en la precisión promedio. Presentamos los resultados de dos conjuntos de experimentos. El primer conjunto de experimentos presenta comparaciones detalladas de nuestros predictores con predictores previamente propuestos utilizando conjuntos de datos idénticos. Nuestro segundo conjunto de experimentos demuestra la generalizabilidad de nuestro enfoque a métodos de recuperación arbitrarios, tipos de corpus y lenguajes de corpus. 5.1 Experimentos Detallados En estos experimentos, predeciremos el rendimiento de los puntajes de modelado de lenguaje utilizando nuestro predictor de autocorrelación, ρ(y, ˜y); no consideramos ρ(y, yµ) o ρ(˜y, yµ) porque, en estos experimentos detallados, nos enfocamos en clasificar las recuperaciones de un solo sistema. Utilizamos recuperaciones, valores de predictores de referencia y medidas de evaluación reportadas en trabajos anteriores [19]. 5.1.1 Temas y Colecciones Estos experimentos de predicción de rendimiento utilizan recuperaciones de modelos de lenguaje realizadas para consultas asociadas con colecciones en las corpora de TREC. El uso de las colecciones TREC nos permite asociar con confianza una precisión promedio con una recuperación. En estos experimentos, utilizamos las siguientes colecciones de temas: TREC 4 ad-hoc, TREC 5 ad-hoc, Robust 2004, Terabyte 2004 y Terabyte 2005. 5.1.2 Baselines Proporcionamos dos líneas base. Nuestro primer punto de referencia es el predictor clásico de Claridad presentado en la Ecuación 6. La claridad está diseñada para ser utilizada con sistemas de modelado de lenguaje. Nuestro segundo punto de referencia es el predictor de robustez de clasificación de Zhou y Crofts. Este predictor corrompe los k documentos principales de la recuperación y vuelve a calcular las puntuaciones del modelo de lenguaje para estos documentos corruptos. El valor del predictor es la correlación de rangos de Spearman entre la clasificación original y la clasificación corrupta. En nuestras tablas, etiquetaremos los resultados para Claridad utilizando DV KL y el predictor de robustez de clasificación utilizando P. 5.2 Experimentos de Generalizabilidad Nuestros predictores no requieren un sistema de recuperación base particular; los predictores pueden calcularse para una recuperación arbitraria, independientemente de cómo se generaron los puntajes. Creemos que ese es uno de los aspectos más atractivos de nuestro algoritmo. Por lo tanto, en un segundo conjunto de experimentos, demostramos la capacidad de nuestras técnicas para generalizar a una variedad de colecciones, temas y sistemas de recuperación. 5.2.1 Temas y Colecciones Recopilamos un conjunto diverso de colecciones de todos los corpus posibles de TREC. Lanzamos una red amplia para localizar colecciones donde nuestros predictores podrían fallar. Nuestra hipótesis es que los documentos con alta similitud temática deberían tener puntuaciones correlacionadas. Por lo tanto, evitamos las colecciones donde las puntuaciones eran poco probables de estar correlacionadas (por ejemplo, preguntas y respuestas) o donde probablemente estuvieran negativamente correlacionadas (por ejemplo, novedad). Sin embargo, nuestras colecciones incluyen corpus donde las correlaciones están débilmente justificadas (por ejemplo, corpus no en inglés) o no justificadas en absoluto (por ejemplo, búsqueda de expertos). Utilizamos las pistas ad-hoc de TREC3-8, TREC Robust 2003-2005, TREC Terabyte 2004-2005, TREC4-5 en español, TREC5-6 en chino y TREC Enterprise Expert Search 2005. En todos los casos, solo utilizamos las ejecuciones automáticas para las pistas ad-hoc enviadas a NIST. Para todos los corpus en inglés y español, construimos la matriz W de acuerdo con el proceso descrito en la Sección 3.1. Para los corpus chinos, utilizamos vectores tf.idf basados en caracteres ingenuos. Para las entidades, las entradas en W son proporcionales al número de documentos en los que dos entidades coocurren. 5.2.2 Baselines En nuestros experimentos detallados, utilizamos la medida de Claridad como referencia. Dado que estamos prediciendo el rendimiento de recuperaciones que no se basan en modelado de lenguaje, utilizamos una versión de Claridad conocida como Claridad de lista clasificada [7]. La claridad de la lista clasificada convierte las clasificaciones de documentos en valores P(Q|θi). Esta conversión comienza reemplazando todas las puntuaciones en y con los rangos respectivos. Nuestra estimación de P(Q|θi) a partir de los rangos, entonces es, P(Q|θi) = ( 2(c+1−yi) c(c+1) si yi ≤ c 0 en otro caso donde c es un parámetro de corte. Como sugieren los autores, fijamos los parámetros del algoritmo c y λ2 de manera que c = 60 y λ2 = 0.10. Utilizamos la Ecuación 6 para estimar P(w|θQ) y DV KL(θQ θC) para calcular el valor del predictor. Nos referiremos a este predictor como DV KL, con superíndice V para indicar que la divergencia de Kullback-Leibler es con respecto al espacio de incrustación de términos. Cuando la información de múltiples ejecuciones de la misma consulta está disponible, utilizamos la divergencia multinomial en el espacio de documentos de Aslam y Pavlus como referencia [1]. Este método basado en rangos primero normaliza las puntuaciones en una recuperación como un multinomial n-dimensional. Al igual que con la Claridad de la lista clasificada, comenzamos reemplazando todas las puntuaciones en y con sus respectivas posiciones. Luego, ajustamos los elementos de y de la siguiente manera, ˆyi = 1 2n 0 @1 + nX k=yi 1 k 1 A (8) En nuestros experimentos de múltiples ejecuciones, solo utilizamos los 75 documentos principales de cada recuperación (n = 75); esto está dentro del rango de valores de parámetros sugeridos por los autores. Sin embargo, admitimos no haber ajustado este parámetro ni para nuestro sistema ni para la línea base. El predictor es la divergencia entre la distribución candidata, y, y la distribución media, yµ. Con la combinación lineal uniforme de estos m recuperaciones representadas como yµ, podemos calcular la divergencia como Dn KL(ˆy ˆyµ) donde usamos el superíndice n para indicar que la suma es sobre el conjunto de n documentos. Este punto de referencia fue desarrollado en el contexto de predecir la dificultad de la consulta, pero lo adoptamos como un punto de referencia razonable para predecir el rendimiento de la recuperación. 5.2.3 Configuración de parámetros Cuando se proporcionan múltiples recuperaciones, utilizamos documentos en la unión de los mejores k = 75 documentos de cada una de las m recuperaciones para esa consulta. Si el tamaño de esta unión es ˜n, entonces yµ y cada yi tiene una longitud de ˜n. En algunos casos, un sistema no puntuó un documento en la unión. Dado que estamos haciendo una suposición gaussiana sobre nuestras puntuaciones, podemos muestrear puntuaciones para estos documentos no vistos de la cola negativa de la distribución. Específicamente, muestreamos de la parte de la distribución inferior al valor mínimo en la recuperación normalizada. Esto introduce aleatoriedad en nuestro algoritmo, pero creemos que es más apropiado que asignar un valor fijo arbitrario. Optimizamos la regresión lineal utilizando la raíz cuadrada de cada predictor. Encontramos que esto mejoró sustancialmente los ajustes para todos los predictores, incluidos los basales. Consideramos combinaciones lineales de pares de predictores (etiquetados por los componentes) y todos los predictores (etiquetados como β). 5.3 Evaluación Dado un conjunto de recuperaciones, potencialmente de una combinación de consultas y sistemas, medimos la correlación del ordenamiento de rango de este conjunto por el predictor y por la métrica de rendimiento. Para garantizar la comparabilidad con los resultados anteriores, presentamos la correlación de Kendalls τ entre la clasificación de los predictores y la clasificación basada en la precisión promedio de la recuperación. A menos que se indique explícitamente, todas las correlaciones son significativas con p < 0.05. Los predictores a veces pueden tener un mejor rendimiento cuando se combinan linealmente [9, 11]. Aunque trabajos anteriores han presentado el coeficiente de determinación (R2) para medir la calidad de la regresión, esta medida no puede ser utilizada de manera confiable al comparar pequeñas mejoras al combinar predictores. Por lo tanto, adoptamos el coeficiente de determinación ajustado que penaliza los modelos con más variables. El R2 ajustado nos permite evaluar la mejora en la predicción lograda al agregar un parámetro pero pierde la interpretación estadística del R2. Utilizaremos τ de Kendall para evaluar la magnitud de la correlación y R2 ajustado para evaluar la combinación de variables. RESULTADOS Presentamos los resultados de nuestros experimentos detallados comparando la predicción de puntuaciones de modelos de lenguaje en la Tabla 1. Aunque la medida de Claridad está teóricamente diseñada para puntuaciones de modelos de lenguaje, consistentemente tiene un rendimiento inferior a nuestro predictor independiente del sistema. La robustez del ranking se presentó como una mejora a la Claridad para colecciones web (representadas en nuestros experimentos por las colecciones terabyte04 y terabyte05), desplazando la correlación τ de 0.139 a 0.150 para terabyte04 y de 0.171 a 0.208 para terabyte05. Sin embargo, estas mejoras son leves en comparación con el rendimiento de la autocorrelación en estas colecciones. Nuestro predictor logra una correlación τ de 0.454 para terabyte04 y 0.383 para terabyte05. Aunque no siempre es la más fuerte, la autocorrelación logra correlaciones competitivas con los predictores de referencia. Al examinar el rendimiento de las combinaciones lineales de predictores, observamos que en cada caso, los factores de autocorrelación son un componente necesario de un predictor sólido. También observamos que el R2 ajustado para las líneas de base individuales siempre mejora significativamente al incorporar la autocorrelación. Presentamos nuestros resultados de generalizabilidad en la Tabla 2. Comenzamos examinando la situación en la columna (a) donde se nos presenta una sola recuperación y ninguna información de recuperaciones adicionales. Para cada colección excepto una, logramos correlaciones significativamente mejores que la claridad de la lista clasificada. Sorprendentemente, logramos correlaciones relativamente fuertes para las colecciones en español y chino a pesar de nuestro procesamiento ingenuo. No tenemos una correlación de claridad de lista clasificada para ent05 porque la modelización de entidades es en sí misma una pregunta de investigación abierta. Sin embargo, nuestra medida de autocorrelación no logra altas correlaciones, quizás porque la relevancia para la recuperación de entidades no se propaga de acuerdo con los enlaces de coocurrencia que utilizamos. Como se señaló anteriormente, el bajo rendimiento de Claridad en datos web es consistente con nuestros hallazgos en los experimentos detallados. La claridad también tiene un rendimiento notablemente inferior en varios corpus de noticias (trec5, trec7 y robust04). Por otro lado, la autocorrelación parece ser robusta a los cambios entre diferentes corpora. A continuación, pasamos a la introducción de información de múltiples recuperaciones. Comparamos las correlaciones entre aquellos predictores que no utilizan esta información en la columna (a) y aquellos que sí lo hacen en la columna (b). Para cada colección, los predictores en la columna (b) superan a los predictores en la columna (a), lo que indica que la información de ejecuciones adicionales puede ser crítica para hacer buenas predicciones. Inspeccionando los predictores en la columna (b), solo podemos sacar conclusiones débiles. Nuestros nuevos predictores tienden a tener un mejor rendimiento en corpora de noticias. Y entre nuestros nuevos predictores, el predictor híbrido ρ(˜y, yµ) tiende a tener un mejor rendimiento. Recuerde que nuestra medida ρ(˜y, yµ) incorpora tanto información espacial como de múltiples recuperaciones. Por lo tanto, creemos que la mejora en la correlación es el resultado de incorporar información del comportamiento espacial. En la columna (c), podemos investigar la utilidad de incorporar información espacial con información de múltiples recuperaciones. Observa que en los casos donde la autocorrelación, ρ(y, ˜y), por sí sola funciona bien (trec3, trec5-spanish y trec6-chinese), se mejora sustancialmente al incorporar información de múltiples recuperaciones de ρ(y, yµ) en la regresión lineal, β. En los casos en los que ρ(y, yµ) funciona bien, la incorporación de la autocorrelación rara vez resulta en una mejora significativa en el rendimiento. De hecho, en cada caso en el que nuestro predictor supera al valor de referencia, incluye información de múltiples ejecuciones. 7. DISCUSIÓN El resultado más importante de nuestros experimentos implica la predicción cuando no hay información disponible de múltiples ejecuciones (Tablas 1 y 2a). Esta situación surge a menudo en el diseño de sistemas. Por ejemplo, un sistema puede necesitar, en el momento de la recuperación, evaluar su rendimiento antes de decidir llevar a cabo un procesamiento más intensivo como la retroalimentación de pseudo relevancia o la interacción. Suponiendo que la presencia de múltiples recuperaciones es irrealista en este caso. Creemos que la autocorrelación, al igual que los algoritmos de recuperación múltiple, aproxima un buen ranking; en este caso mediante la difusión de puntajes. ¿Por qué es ˜y un sustituto razonable? Sabemos que la difusión de puntuaciones en el grafo web y en los grafos de modelos de lenguaje mejora el rendimiento [14, 16]. Por lo tanto, si la difusión de puntuaciones tiende, en general, a mejorar el rendimiento, entonces las puntuaciones difusas proporcionarán, en general, un buen sustituto de la relevancia. Nuestros resultados demuestran que esta aproximación no es tan potente como la información de múltiples recuperaciones. Sin embargo, en situaciones donde esta información falta, la autocorrelación proporciona información sustancial. El éxito de la autocorrelación como predictor también puede tener sus raíces en la hipótesis de agrupamiento. Recuerde que consideramos la autocorrelación como el grado en que una recuperación satisface la hipótesis de agrupamiento. Nuestros experimentos, entonces, demuestran que una falta de respeto a la hipótesis de agrupamiento se correlaciona con un bajo rendimiento. ¿Por qué los sistemas podrían no cumplir con la hipótesis del clúster? Los sistemas de recuperación de información basados en consultas a menudo puntúan los documentos de forma independiente. El puntaje del documento a puede ser calculado examinando las coincidencias de términos o frases de la consulta, la longitud del documento y quizás las estadísticas globales de la colección. Una vez calculado, un sistema rara vez compara la puntuación de un documento a con la puntuación de un documento relacionado temáticamente b. Con algunas excepciones, la correlación de las puntuaciones de los documentos ha sido ampliamente ignorada. Debemos dejar claro que hemos seleccionado tareas donde la autocorrelación temática es apropiada. Ciertamente hay casos en los que no hay motivo para creer que las puntuaciones de recuperación tendrán autocorrelación temática. Por ejemplo, las listas clasificadas que incorporan novedad de documentos no deben mostrar autocorrelación espacial; si acaso, la autocorrelación debería ser negativa para esta tarea. Del mismo modo, los candidatos de respuestas en una tarea de pregunta-respuesta pueden o no mostrar autocorrelación; en este caso, la semántica de los enlaces también es cuestionable. Es importante antes de aplicar esta medida confirmar que, dada la semántica para algún enlace entre dos elementos recuperados, deberíamos esperar una correlación entre las puntuaciones. 8. TRABAJO RELACIONADO En esta sección realizamos comparaciones más generales con otros trabajos en predicción de rendimiento y análisis de datos espaciales. Existe un creciente cuerpo de trabajo que intenta predecir el rendimiento de recuperaciones individuales [7, 3, 11, 9, 19]. Hemos intentado situar nuestro trabajo en el contexto de gran parte de este trabajo en la Sección 4. Sin embargo, una comparación completa está fuera del alcance de este documento. Sin embargo, cabe destacar que nuestros experimentos abarcan un conjunto más amplio y diverso de recuperaciones, colecciones y temas que los examinados previamente. Gran parte del trabajo previo, especialmente en el contexto de TREC, se centra en predecir el rendimiento de los sistemas. Aquí, cada sistema genera k recuperaciones. La tarea consiste en, dadas estas recuperaciones, predecir la clasificación de los sistemas según alguna medida de rendimiento. Varios artículos intentan abordar esta tarea bajo la restricción de pocas evaluaciones [2, 4]. Algunos trabajos incluso intentan utilizar cero juicios aprovechando múltiples recuperaciones para la misma consulta [17]. Nuestra tarea difiere porque nos enfocamos en clasificar recuperaciones independientemente del sistema generador. La tarea aquí no es probar que el sistema A es superior al sistema B, sino probar que la recuperación A es superior a la recuperación B. La autocorrelación se manifiesta en muchas tareas de clasificación. Neville y Jensen definen la autocorrelación relacional para problemas de aprendizaje relacional y demuestran que muchas tareas de clasificación manifiestan autocorrelación [13]. La autocorrelación temporal de las recuperaciones iniciales también se ha utilizado para predecir el rendimiento [9]. Sin embargo, la autocorrelación temporal se realiza proyectando la función de recuperación en el espacio de incrustación temporal. En nuestro trabajo, nos enfocamos en el comportamiento de la función sobre las relaciones entre documentos. τ ajustado R2 DV KL P ρ(y, ˜y) DV KL P ρ(y, ˜y) DV KL, P DV KL, ρ(y, ˜y) Pρ(y, ˜y) β trec4 0.353 0.548 0.513 0.168 0.363 0.422 0.466 0.420 0.557 0.553 trec5 0.311 0.329 0.357 0.116 0.190 0.236 0.238 0.244 0.266 0.269 robust04 0.418 0.398 0.373 0.256 0.304 0.278 0.403 0.373 0.402 0.442 terabyte04 0.139 0.150 0.454 0.059 0.045 0.292 0.076 0.293 0.289 0.284 terabyte05 0.171 0.208 0.383 0.022 0.072 0.193 0.120 0.225 0.218 0.257 Tabla 1: Comparación de medidas de robustez y claridad para puntuaciones de modelos de lenguaje. La evaluación replica experimentos de [19]. Presentamos las correlaciones entre la medida clásica de Claridad (DV KL), la medida de robustez de clasificación (P) y la autocorrelación (ρ(y, ˜y)) cada una con la precisión media promedio en términos de τ de Kendall. El coeficiente de determinación ajustado se presenta para medir la efectividad de combinar predictores. Las medidas en negrita representan la correlación más fuerte para ese par de prueba/colección. múltiples ejecuciones (a) (b) (c) τ τ ajustado R2 DKL ρ(y, ˜y) Dn KL ρ(y, yµ) ρ(˜y, yµ) Dn KL ρ(y, ˜y) ρ(y, yµ) ρ(˜y, yµ) β trec3 0.201 0.461 0.461 0.439 0.456 0.444 0.395 0.394 0.386 0.498 trec4 0.252 0.396 0.455 0.482 0.489 0.379 0.263 0.429 0.482 0.483 trec5 0.016 0.277 0.433 0.459 0.393 0.280 0.157 0.375 0.323 0.386 trec6 0.230 0.227 0.352 0.428 0.418 0.203 0.089 0.323 0.325 0.325 trec7 0.083 0.326 0.341 0.430 0.483 0.264 0.182 0.363 0.442 0.400 trec8 0.235 0.396 0.454 0.508 0.567 0.402 0.272 0.490 0.580 0.523 robust03 0.302 0.354 0.377 0.385 0.447 0.269 0.206 0.274 0.392 0.303 robust04 0.183 0.308 0.301 0.384 0.453 0.200 0.182 0.301 0.393 0.335 robust05 0.224 0.249 0.371 0.377 0.404 0.341 0.108 0.313 0.328 0.336 terabyte04 0.043 0.245 0.544 0.420 0.392 0.516 0.105 0.357 0.343 0.365 terabyte05 0.068 0.306 0.480 0.434 0.390 0.491 0.168 0.384 0.309 0.403 trec4-spanish 0.307 0.388 0.488 0.398 0.395 0.423 0.299 0.282 0.299 0.388 trec5-spanish 0.220 0.458 0.446 0.484 0.475 0.411 0.398 0.428 0.437 0.529 trec5-chinese 0.092 0.199 0.367 0.379 0.384 0.379 0.199 0.273 0.276 0.310 trec6-chinese 0.144 0.276 0.265 0.353 0.376 0.115 0.128 0.188 0.223 0.199 ent05 - 0.181 0.324 0.305 0.282 0.211 0.043 0.158 0.155 0.179 Tabla 2: Experimentos de predicción a gran escala. Predecimos la clasificación de grandes conjuntos de recuperaciones para varias colecciones y sistemas de recuperación. Las correlaciones de τ de Kendall se calculan entre la clasificación predicha y una clasificación basada en la precisión promedio de las recuperaciones. En la columna (a), tenemos predictores que no utilizan información de otras recuperaciones para la misma consulta. En las columnas (b) y (c) presentamos el rendimiento de los predictores que incorporan información de múltiples recuperaciones. El coeficiente de determinación ajustado se calcula para determinar la efectividad de combinar predictores. Las medidas en negrita representan la correlación más fuerte para ese par de prueba/colección. Finalmente, los procesos de reordenamiento basados en regularización también están estrechamente relacionados con nuestro trabajo [8]. Estas técnicas buscan maximizar el acuerdo entre las puntuaciones de documentos relacionados al resolver un problema de optimización restringida. La maximización de la consistencia es equivalente a maximizar la autocorrelación de Moran. Por lo tanto, creemos que nuestro trabajo proporciona una explicación de por qué funciona el reordenamiento basado en regularización. 9. CONCLUSIÓN Hemos presentado un nuevo método para predecir el rendimiento de un ranking de recuperación sin necesidad de juicios de relevancia. Consideramos dos casos. Primero, al hacer predicciones en ausencia de recuperaciones de otros sistemas, nuestros predictores muestran correlaciones sólidas y robustas con la precisión promedio. Esta actuación, combinada con una implementación sencilla, hace que nuestros predictores, en particular, sean muy atractivos. Hemos demostrado esta mejora en muchos entornos diversos. Según nuestro conocimiento, esta es la primera evaluación a gran escala de la predicción del rendimiento de una sola recuperación sin juicio. Segundo, cuando se proporcionan recuperaciones de otros sistemas, nuestros métodos ampliados demuestran un rendimiento competitivo con las líneas de base de vanguardia. Nuestros experimentos también demuestran los límites de la utilidad de nuestros predictores cuando se proporciona información de múltiples ejecuciones. Nuestros resultados sugieren dos conclusiones. Primero, nuestros resultados podrían afectar el diseño de algoritmos de recuperación. Los algoritmos de recuperación diseñados para considerar la autocorrelación espacial se ajustarán a la hipótesis de agrupamiento y mejorarán el rendimiento. Segundo, nuestros resultados podrían afectar el diseño de algoritmos de colección de pruebas mínimas. Gran parte del trabajo reciente en sistemas de clasificación a veces ignora las correlaciones entre las etiquetas de los documentos y las puntuaciones. Creemos que estas dos direcciones podrían ser gratificantes dadas las pruebas teóricas y experimentales en este documento. 10. AGRADECIMIENTOS Este trabajo fue apoyado en parte por el Centro de Recuperación de Información Inteligente y en parte por la Agencia de Proyectos de Investigación Avanzada de Defensa (DARPA) bajo el número de contrato HR0011-06-C-0023. Cualquier opinión, hallazgo y conclusión o recomendación expresada en este material son del autor y no necesariamente reflejan las del patrocinador. Agradecemos a Yun Zhou y Desislava Petkova por proporcionar los datos y a Andre Gauthier por la asistencia técnica. 11. REFERENCIAS [1] J. Aslam y V. Pavlu. Estimación de la dificultad de la consulta utilizando la divergencia de Jensen-Shannon entre múltiples funciones de puntuación. En ECIR 2007: Actas de la 29ª Conferencia Europea sobre Recuperación de Información, 2007. [2] J. A. Aslam, V. Pavlu y E. Yilmaz. Un método estadístico para la evaluación de sistemas utilizando juicios incompletos. En S. Dumais, E. N. Efthimiadis, D. Hawking y K. Jarvelin, editores, Actas de la 29ª Conferencia Internacional Anual de ACM SIGIR sobre Investigación y Desarrollo en Recuperación de Información, páginas 541-548. ACM Press, agosto de 2006. [3] D. Carmel, E. Yom-Tov, A. Darlow y D. Pelleg. ¿Qué hace que una consulta sea difícil? En SIGIR 06: Actas de la 29ª conferencia internacional anual de ACM SIGIR sobre investigación y desarrollo en recuperación de información, páginas 390-397, Nueva York, NY, EE. UU., 2006. ACM Press. [4] B. Carterette, J. Allan y R. Sitaraman. Colecciones de prueba mínimas para evaluación de recuperación. En SIGIR 06: Actas de la 29ª conferencia internacional anual de ACM SIGIR sobre investigación y desarrollo en recuperación de información, páginas 268-275, Nueva York, NY, EE. UU., 2006. ACM Press. [5] A. D. Cliff y J. K. Ord. Autocorrelación espacial. Pion Ltd., 1973. [6] M. Connell, A. Feng, G. Kumaran, H. Raghavan, C. Shah y J. Allan. Umass en tdt 2004. Informe técnico CIIR Informe técnico IR - 357, Departamento de Ciencias de la Computación, Universidad de Massachusetts, 2004. [7] S. Cronen-Townsend, Y. Zhou y W. B. Croft. Predicción de precisión basada en la coherencia de la lista clasificada. I'm sorry, but the sentence \"Inf.\" is not a complete sentence. Could you please provide more context or a full sentence for me to translate to Spanish? Rev., 9(6):723-755, 2006. [8] F. Diaz. Normalizando las puntuaciones de recuperación ad-hoc. En CIKM 05: Actas de la 14ª conferencia internacional de ACM sobre gestión de la información y el conocimiento, páginas 672-679, Nueva York, NY, EE. UU., 2005. ACM Press. [9] F. Diaz y R. Jones. Utilizando perfiles temporales de consultas para predecir la precisión. En SIGIR 04: Actas de la 27ª conferencia internacional anual de ACM SIGIR sobre investigación y desarrollo en recuperación de información, páginas 18-24, Nueva York, NY, EE. UU., 2004. ACM Press. [10] D. A. Griffith. \n\nACM Press. [10] D. A. Griffith. Autocorrelación espacial y filtrado espacial. Springer Verlag, 2003. [11] B. \n\nSpringer Verlag, 2003. [11] B. Él y yo. Ounis. Inferir el rendimiento de la consulta utilizando predictores previos a la recuperación. En el Undécimo Simposio sobre Procesamiento de Cadenas y Recuperación de Información (SPIRE), 2004. [12] N. Jardine y C. J. V. Rijsbergen. El uso de agrupamiento jerárquico en la recuperación de información. Almacenamiento y recuperación de información, 7:217-240, 1971. [13] D. Jensen y J. Neville. El enlace y la autocorrelación causan sesgo en la selección de características en el aprendizaje relacional. En ICML 02: Actas de la Decimonovena Conferencia Internacional sobre Aprendizaje Automático, páginas 259-266, San Francisco, CA, EE. UU., 2002. Morgan Kaufmann Publishers Inc. [14] O. Kurland y L. Lee. Estructura del corpus, modelos de lenguaje y recuperación de información ad-hoc. En SIGIR 04: Actas de la 27ª conferencia internacional anual sobre investigación y desarrollo en recuperación de información, páginas 194-201, Nueva York, NY, EE. UU., 2004. ACM Press. [15] M. Montague y J. A. Aslam. Normalización de la puntuación de relevancia para metabusqueda. En CIKM 01: Actas de la décima conferencia internacional sobre gestión de la información y el conocimiento, páginas 427-433, Nueva York, NY, EE. UU., 2001. ACM Press. [16] T. Qin, T.-Y. Liu, X.-D. Zhang, Z. Chen y W.-Y. I'm sorry, but \"Ma.\" is not a complete sentence. Could you please provide more context or a complete sentence for me to translate into Spanish? Un estudio de propagación de relevancia para la búsqueda en la web. En SIGIR 05: Actas de la 28ª conferencia internacional anual de ACM SIGIR sobre investigación y desarrollo en recuperación de información, páginas 408-415, Nueva York, NY, EE. UU., 2005. ACM Press. [17] I. Soboroff, C. Nicholas y P. Cahan. Sistemas de recuperación de clasificación sin juicios de relevancia. En SIGIR 01: Actas de la 24ª conferencia internacional anual de ACM SIGIR sobre investigación y desarrollo en recuperación de información, páginas 66-73, Nueva York, NY, EE. UU., 2001. ACM Press. [18] V. Vinay, I. J. Cox, N. Milic-Frayling y K. Wood. Sobre la clasificación de la efectividad de las búsquedas. En SIGIR 06: Actas de la 29ª conferencia internacional anual de ACM SIGIR sobre investigación y desarrollo en recuperación de información, páginas 398-404, Nueva York, NY, EE. UU., 2006. ACM Press. [19] Y. Zhou y W. B. Croft. Robustez del ranking: un nuevo marco para predecir el rendimiento de la consulta. En CIKM 06: Actas de la 15ª conferencia internacional de ACM sobre gestión de la información y el conocimiento, páginas 567-574, Nueva York, NY, EE. UU., 2006. ACM Press. ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "query ranking": {
            "translated_key": "Clasificación de consultas",
            "is_in_text": false,
            "original_annotated_sentences": [
                "Performance Prediction Using Spatial Autocorrelation Fernando Diaz Center for Intelligent Information Retrieval Department of Computer Science University of Massachusetts Amherst, MA 01003 fdiaz@cs.umass.edu ABSTRACT Evaluation of information retrieval systems is one of the core tasks in information retrieval.",
                "Problems include the inability to exhaustively label all documents for a topic, nongeneralizability from a small number of topics, and incorporating the variability of retrieval systems.",
                "Previous work addresses the evaluation of systems, the ranking of queries by difficulty, and the ranking of individual retrievals by performance.",
                "Approaches exist for the case of few and even no relevance judgments.",
                "Our focus is on zero-judgment performance prediction of individual retrievals.",
                "One common shortcoming of previous techniques is the assumption of uncorrelated document scores and judgments.",
                "If documents are embedded in a high-dimensional space (as they often are), we can apply techniques from spatial data analysis to detect correlations between document scores.",
                "We find that the low correlation between scores of topically close documents often implies a poor retrieval performance.",
                "When compared to a state of the art baseline, we demonstrate that the spatial analysis of retrieval scores provides significantly better prediction performance.",
                "These new predictors can also be incorporated with classic predictors to improve performance further.",
                "We also describe the first large-scale experiment to evaluate zero-judgment performance prediction for a massive number of retrieval systems over a variety of collections in several languages.",
                "Categories and Subject Descriptors H.3.3 [Information Search and Retrieval]: Retrieval models; H.3.4 [Systems and Software]: Performance evaluation (efficiency and effectiveness) General Terms Performance, Design, Reliability, Experimentation 1.",
                "INTRODUCTION In information retrieval, a user poses a query to a system.",
                "The system retrieves n documents each receiving a realvalued score indicating the predicted degree of relevance.",
                "If we randomly select pairs of documents from this set, we expect some pairs to share the same topic and other pairs to not share the same topic.",
                "Take two topically-related documents from the set and call them a and b.",
                "If the scores of a and b are very different, we may be concerned about the performance of our system.",
                "That is, if a and b are both on the topic of the query, we would like them both to receive a high score; if a and b are not on the topic of the query, we would like them both to receive a low score.",
                "We might become more worried as we find more differences between scores of related documents.",
                "We would be more comfortable with a retrieval where scores are consistent between related documents.",
                "Our paper studies the quantification of this inconsistency in a retrieval from a spatial perspective.",
                "Spatial analysis is appropriate since many retrieval models embed documents in some vector space.",
                "If documents are embedded in a space, proximity correlates with topical relationships.",
                "Score consistency can be measured by the spatial version of autocorrelation known as the Moran coefficient or IM [5, 10].",
                "In this paper, we demonstrate a strong correlation between IM and retrieval performance.",
                "The discussion up to this point is reminiscent of the cluster hypothesis.",
                "The cluster hypothesis states: closely-related documents tend to be relevant to the same request [12].",
                "As we shall see, a retrieval functions spatial autocorrelation measures the degree to which closely-related documents receive similar scores.",
                "Because of this, we interpret autocorrelation as measuring the degree to which a retrieval function satisfies the clustering hypothesis.",
                "If this connection is reasonable, in Section 6, we present evidence that failure to satisfy the cluster hypothesis correlates strongly with poor performance.",
                "In this work, we provide the following contributions, 1.",
                "A general, robust method for predicting the performance of retrievals with zero relevance judgments (Section 3). 2.",
                "A theoretical treatment of the similarities and motivations behind several state-of-the-art performance prediction techniques (Section 4). 3.",
                "The first large-scale experiments of zero-judgment, single run performance prediction (Sections 5 and 6). 2.",
                "PROBLEM DEFINITION Given a query, an information retrieval system produces a ranking of documents in the collection encoded as a set of scores associated with documents.",
                "We refer to the set of scores for a particular query-system combination as a retrieval.",
                "We would like to predict the performance of this retrieval with respect to some evaluation measure (eg, mean average precision).",
                "In this paper, we present results for ranking retrievals from arbitrary systems.",
                "We would like this ranking to approximate the ranking of retrievals by the evaluation measure.",
                "This is different from ranking queries by the average performance on each query.",
                "It is also different from ranking systems by the average performance on a set of queries.",
                "Scores are often only computed for the top n documents from the collection.",
                "We place these scores in the length n vector, y, where yi refers to the score of the ith-ranked document.",
                "We adjust scores to have zero mean and unit variance.",
                "We use this method because of its simplicity and its success in previous work [15]. 3.",
                "SPATIAL CORRELATION In information retrieval, we often assume that the representations of documents exist in some high-dimensional vector space.",
                "For example, given a vocabulary, V, this vector space may be an arbitrary |V|-dimensional space with cosine inner-product or a multinomial simplex with a distributionbased distance measure.",
                "An embedding space is often selected to respect topical proximity; if two documents are near, they are more likely to share a topic.",
                "Because of the prevalence and success of spatial models of information retrieval, we believe that the application of spatial data analysis techniques are appropriate.",
                "Whereas in information retrieval, we are concerned with the score at a point in a space, in spatial data analysis, we are concerned with the value of a function at a point or location in a space.",
                "We use the term function here to mean a mapping from a location to a real value.",
                "For example, we might be interested in the prevalence of a disease in the neighborhood of some city.",
                "The function would map the location of a neighborhood to an infection rate.",
                "If we want to quantify the spatial dependencies of a function, we would employ a measure referred to as the spatial autocorrelation [5, 10].",
                "High spatial autocorrelation suggests that knowing the value of a function at location a will tell us a great deal about the value at a neighboring location b.",
                "There is a high spatial autocorrelation for a function representing the temperature of a location since knowing the temperature at a location a will tell us a lot about the temperature at a neighboring location b.",
                "Low spatial autocorrelation suggests that knowing the value of a function at location a tells us little about the value at a neighboring location b.",
                "There is low spatial autocorrelation in a function measuring the outcome of a coin toss at a and b.",
                "In this section, we will begin by describing what we mean by spatial proximity for documents and then define a measure of spatial autocorrelation.",
                "We conclude by extending this model to include information from multiple retrievals from multiple systems for a single query. 3.1 Spatial Representation of Documents Our work does not focus on improving a specific similarity measure or defining a novel vector space.",
                "Instead, we choose an inner product known to be effective at detecting interdocument topical relationships.",
                "Specifically, we adopt tf.idf document vectors, ˜di = di log „ (n + 0.5) − ci 0.5 + ci « (1) where d is a vector of term frequencies, c is the length-|V| document frequency vector.",
                "We use this weighting scheme due to its success for topical link detection in the context of Topic Detection and Tracking (TDT) evaluations [6].",
                "Assuming vectors are scaled by their L2 norm, we use the inner product, ˜di, ˜dj , to define similarity.",
                "Given documents and some similarity measure, we can construct a matrix which encodes the similarity between pairs of documents.",
                "Recall that we are given the top n documents retrieved in y.",
                "We can compute an n × n similarity matrix, W. An element of this matrix, Wij represents the similarity between documents ranked i and j.",
                "In practice, we only include the affinities for a documents k-nearest neighbors.",
                "In all of our experiments, we have fixed k to 5.",
                "We leave exploration of parameter sensitivity to future work.",
                "We also row normalize the matrix so that Pn j=1 Wij = 1 for all i. 3.2 Spatial Autocorrelation of a Retrieval Recall that we are interested in measuring the similarity between the scores of spatially-close documents.",
                "One such suitable measure is the Moran coefficient of spatial autocorrelation.",
                "Assuming the function y over n locations, this is defined as ˜IM = n eTWe P i,j Wijyiyj P i y2 i = n eTWe yT Wy yTy (2) where eT We = P ij Wij.",
                "We would like to compare autocorrelation values for different retrievals.",
                "Unfortunately, the bound for Equation 2 is not consistent for different W and y.",
                "Therefore, we use the Cauchy-Schwartz inequality to establish a bound, ˜IM ≤ n eTWe s yTWTWy yTy And we define the normalized spatial autocorrelation as IM = yT Wy p yTy × yTWTWy Notice that if we let ˜y = Wy, then we can write this formula as, IM = yT ˜y y 2 ˜y 2 (3) which can be interpreted as the correlation between the original retrieval scores and a set of retrieval scores diffused in the space.",
                "We present some examples of autocorrelations of functions on a grid in Figure 1. 3.3 Correlation with Other Retrievals Sometimes we are interested in the performance of a single retrieval but have access to scores from multiple systems for (a) IM = 0.006 (b) IM = 0.241 (c) IM = 0.487 Figure 1: The Moran coefficient, IM for a several binary functions on a grid.",
                "The Moran coefficient is a local measure of function consistency.",
                "From the perspective of information retrieval, each of these grid spaces would represent a document and documents would be organized so that they lay next to topically-related documents.",
                "Binary retrieval scores would define a pattern on this grid.",
                "Notice that, as the Moran coefficient increases, neighboring cells tend to have similar values. the same query.",
                "In this situation, we can use combined information from these scores to construct a surrogate for a high-quality ranking [17].",
                "We can treat the correlation between the retrieval we are interested in and the combined scores as a predictor of performance.",
                "Assume that we are given m score functions, yi, for the same n documents.",
                "We will represent the mean of these vectors as yµ = Pm i=1 yi.",
                "We use the mean vector as an approximation to relevance.",
                "Since we use zero mean and unit variance normalization, work in metasearch suggests that this assumption is justified [15].",
                "Because yµ represents a very good retrieval, we hypothesize that a strong similarity between yµ and y will correlate positively with system performance.",
                "We use Pearsons product-moment correlation to measure the similarity between these vectors, ρ(y, yµ) = yT yµ y 2 yµ 2 (4) We will comment on the similarity between Equation 3 and 4 in Section 7.",
                "Of course, we can combine ρ(y, ˜y) and ρ(y, yµ) if we assume that they capture different factors in the prediction.",
                "One way to accomplish this is to combine these predictors as independent variables in a linear regression.",
                "An alternative means of combination is suggested by the mathematical form of our predictors.",
                "Since ˜y encodes the spatial dependencies in y and yµ encodes the spatial properties of the multiple runs, we can compute a third correlation between these two vectors, ρ(˜y, yµ) = ˜yT yµ ˜y 2 yµ 2 (5) We can interpret Equation 5 as measuring the correlation between a high quality ranking (yµ) and a spatially smoothed version of the retrieval (˜y). 4.",
                "RELATIONSHIP WITH OTHER PREDICTORS One way to predict the effectiveness of a retrieval is to look at the shared vocabulary of the top n retrieved documents.",
                "If we computed the most frequent content words in this set, we would hope that they would be consistent with our topic.",
                "In fact, we might believe that a bad retrieval would include documents on many disparate topics, resulting in an overlap of terminological noise.",
                "The Clarity of a query attempts to quantify exactly this [7].",
                "Specifically, Clarity measures the similarity of the words most frequently used in retrieved documents to those most frequently used in the whole corpus.",
                "The conjecture is that a good retrieval will use language distinct from general text; the overlapping language in a bad retrieval will tend to be more similar to general text.",
                "Mathematically, we can compute a representation of the language used in the initial retrieval as a weighted combination of document language models, P(w|θQ) = nX i=1 P(w|θi) P(Q|θi) Z (6) where θi is the language model of the ith-ranked document, P(Q|θi) is the query likelihood score of the ith-ranked document and Z = Pn i=1 P(Q|θi) is a normalization constant.",
                "The similarity between the multinomial P(w|θQ) and a model of general text can be computed using the Kullback-Leibler divergence, DV KL(θQ θC ).",
                "Here, the distribution P(w|θC ) is our model of general text which can be computed using term frequencies in the corpus.",
                "In Figure 2a, we present Clarity as measuring the distance between the weighted center of mass of the retrieval (labeled y) and the unweighted center of mass of the collection (labeled O).",
                "Clarity reaches a minimum when a retrieval assigns every document the same score.",
                "Lets again assume we have a set of n documents retrieved for our query.",
                "Another way to quantify the dispersion of a set of documents is to look at how clustered they are.",
                "We may hypothesize that a good retrieval will return a single, tight cluster.",
                "A poorly performing retrieval will return a loosely related set of documents covering many topics.",
                "One proposed method of quantifying this dispersion is to measure the distance from a random document a to its nearest neighbor, b.",
                "A retrieval which is tightly clustered will, on average, have a low distance between a and b; a retrieval which is less tightly-closed will, on average have high distances between a and b.",
                "This average corresponds to using the Cox-Lewis statistic to measure the randomness of the top n documents retrieved from a system [18].",
                "In Figure 2a, this is roughly equivalent to measuring the area of the set n. Notice that we are throwing away information about the retrieval function y.",
                "Therefore the Cox-Lewis statistic is highly dependent on selecting the top n documents.1 Remember that we have n documents and a set of scores.",
                "Lets assume that we have access to the system which provided the original scores and that we can also request scores for new documents.",
                "This suggests a third method for predicting performance.",
                "Take some document, a, from the retrieved set and arbitrarily add or remove words at random to create a new document ˜a.",
                "Now, we can ask our system to score ˜a with respect to our query.",
                "If, on average over the n documents, the scores of a and ˜a tend to be very different, we might suspect that the system is failing on this query.",
                "So, an alternative approach is to measure the simi1 The authors have suggested coupling the query with the distance measure [18].",
                "The information introduced by the query, though, is retrieval-independent so that, if two retrievals return the same set of documents, the approximate Cox-Lewis statistic will be the same regardless of the retrieval scores. yOy (a) Global Divergence µ(y)˜y y (b) Score Perturbation µ(y) y (c) Multirun Averaging Figure 2: Representation of several performance predictors on a grid.",
                "In Figure 2a, we depict predictors which measure the divergence between the center of mass of a retrieval and the center of the embedding space.",
                "In Figure 2b, we depict predictors which compare the original retrieval, y, to a perturbed version of the retrieval, ˜y.",
                "Our approach uses a particular type of perturbation based on score diffusion.",
                "Finally, in Figure 2c, we depict prediction when given retrievals from several other systems on the same query.",
                "Here, we can consider the fusion of these retrieval as a surrogate for relevance. larity between the retrieval and a perturbed version of that retrieval [18, 19].",
                "This can be accomplished by either perturbing the documents or queries.",
                "The similarity between the two retrievals can be measured using some correlation measure.",
                "This is depicted in Figure 2b.",
                "The upper grid represents the original retrieval, y, while the lower grid represents the function after having been perturbed, ˜y.",
                "The nature of the perturbation process requires additional scorings or retrievals.",
                "Our predictor does not require access to the original scoring function or additional retrievals.",
                "So, although our method is similar to other perturbation methods in spirit, it can be applied in situations when the retrieval system is inaccessible or costly to access.",
                "Finally, assume that we have, in addition to the retrieval we want to evaluate, m retrievals from a variety of different systems.",
                "In this case, we might take a document a, compare its rank in the retrieval to its average rank in the m retrievals.",
                "If we believe that the m retrievals provide a satisfactory approximation to relevance, then a very large difference in rank would suggest that our retrieval is misranking a.",
                "If this difference is large on average over all n documents, then we might predict that the retrieval is bad.",
                "If, on the other hand, the retrieval is very consistent with the m retrievals, then we might predict that the retrieval is good.",
                "The similarity between the retrieval and the combined retrieval may be computed using some correlation measure.",
                "This is depicted in Figure 2c.",
                "In previous work, the Kullback-Leibler divergence between the normalized scores of the retrieval and the normalized scores of the combined retrieval provides the similarity [1]. 5.",
                "EXPERIMENTS Our experiments focus on testing the predictive power of each of our predictors: ρ(y, ˜y), ρ(y, yµ), and ρ(˜y, yµ).",
                "As stated in Section 2, we are interested in predicting the performance of the retrieval generated by an arbitrary system.",
                "Our methodology is consistent with previous research in that we predict the relative performance of a retrieval by comparing a ranking based on our predictor to a ranking based on average precision.",
                "We present results for two sets of experiments.",
                "The first set of experiments presents detailed comparisons of our predictors to previously-proposed predictors using identical data sets.",
                "Our second set of experiments demonstrates the generalizability of our approach to arbitrary retrieval methods, corpus types, and corpus languages. 5.1 Detailed Experiments In these experiments, we will predict the performance of language modeling scores using our autocorrelation predictor, ρ(y, ˜y); we do not consider ρ(y, yµ) or ρ(˜y, yµ) because, in these detailed experiments, we focus on ranking the retrievals from a single system.",
                "We use retrievals, values for baseline predictors, and evaluation measures reported in previous work [19]. 5.1.1 Topics and Collections These performance prediction experiments use language model retrievals performed for queries associated with collections in the TREC corpora.",
                "Using TREC collections allows us to confidently associate an average precision with a retrieval.",
                "In these experiments, we use the following topic collections: TREC 4 ad-hoc, TREC 5 ad-hoc, Robust 2004, Terabyte 2004, and Terabyte 2005. 5.1.2 Baselines We provide two baselines.",
                "Our first baseline is the classic Clarity predictor presented in Equation 6.",
                "Clarity is designed to be used with language modeling systems.",
                "Our second baseline is Zhou and Crofts ranking robustness predictor.",
                "This predictor corrupts the top k documents from retrieval and re-computes the language model scores for these corrupted documents.",
                "The value of the predictor is the Spearman rank correlation between the original ranking and the corrupted ranking.",
                "In our tables, we will label results for Clarity using DV KL and the ranking robustness predictor using P. 5.2 Generalizability Experiments Our predictors do not require a particular baseline retrieval system; the predictors can be computed for an arbitrary retrieval, regardless of how scores were generated.",
                "We believe that that is one of the most attractive aspects of our algorithm.",
                "Therefore, in a second set of experiments, we demonstrate the ability of our techniques to generalize to a variety of collections, topics, and retrieval systems. 5.2.1 Topics and Collections We gathered a diverse set of collections from all possible TREC corpora.",
                "We cast a wide net in order to locate collections where our predictors might fail.",
                "Our hypothesis is that documents with high topical similarity should have correlated scores.",
                "Therefore, we avoided collections where scores were unlikely to be correlated (eg, question-answering) or were likely to be negatively correlated (eg, novelty).",
                "Nevertheless, our collections include corpora where correlations are weakly justified (eg, non-English corpora) or not justified at all (eg, expert search).",
                "We use the ad-hoc tracks from TREC3-8, TREC Robust 2003-2005, TREC Terabyte 20042005, TREC4-5 Spanish, TREC5-6 Chinese, and TREC Enterprise Expert Search 2005.",
                "In all cases, we use only the automatic runs for ad-hoc tracks submitted to NIST.",
                "For all English and Spanish corpora, we construct the matrix W according to the process described in Section 3.1.",
                "For Chinese corpora, we use na¨ıve character-based tf.idf vectors.",
                "For entities, entries in W are proportional to the number of documents in which two entities cooccur. 5.2.2 Baselines In our detailed experiments, we used the Clarity measure as a baseline.",
                "Since we are predicting the performance of retrievals which are not based on language modeling, we use a version of Clarity referred to as ranked-list Clarity [7].",
                "Ranked-list clarity converts document ranks to P(Q|θi) values.",
                "This conversion begins by replacing all of the scores in y with the respective ranks.",
                "Our estimation of P(Q|θi) from the ranks, then is, P(Q|θi) = ( 2(c+1−yi) c(c+1) if yi ≤ c 0 otherwise (7) where c is a cutoff parameter.",
                "As suggested by the authors, we fix the algorithm parameters c and λ2 so that c = 60 and λ2 = 0.10.",
                "We use Equation 6 to estimate P(w|θQ) and DV KL(θQ θC ) to compute the value of the predictor.",
                "We will refer to this predictor as DV KL, superscripted by V to indicate that the Kullback-Leibler divergence is with respect to the term embedding space.",
                "When information from multiple runs on the same query is available, we use Aslam and Pavlus document-space multinomial divergence as a baseline [1].",
                "This rank-based method first normalizes the scores in a retrieval as an n-dimensional multinomial.",
                "As with ranked-list Clarity, we begin by replacing all of the scores in y with their respective ranks.",
                "Then, we adjust the elements of y in the following way, ˆyi = 1 2n 0 @1 + nX k=yi 1 k 1 A (8) In our multirun experiments, we only use the top 75 documents from each retrieval (n = 75); this is within the range of parameter values suggested by the authors.",
                "However, we admit not tuning this parameter for either our system or the baseline.",
                "The predictor is the divergence between the candidate distribution, y, and the mean distribution, yµ .",
                "With the uniform linear combination of these m retrievals represented as yµ, we can compute the divergence as Dn KL(ˆy ˆyµ) where we use the superscript n to indicate that the summation is over the set of n documents.",
                "This baseline was developed in the context of predicting query difficulty but we adopt it as a reasonable baseline for predicting retrieval performance. 5.2.3 Parameter Settings When given multiple retrievals, we use documents in the union of the top k = 75 documents from each of the m retrievals for that query.",
                "If the size of this union is ˜n, then yµ and each yi is of length ˜n.",
                "In some cases, a system did not score a document in the union.",
                "Since we are making a Gaussian assumption about our scores, we can sample scores for these unseen documents from the negative tail of the distribution.",
                "Specifically, we sample from the part of the distribution lower than the minimum value of in the normalized retrieval.",
                "This introduces randomness into our algorithm but we believe it is more appropriate than assigning an arbitrary fixed value.",
                "We optimized the linear regression using the square root of each predictor.",
                "We found that this substantially improved fits for all predictors, including the baselines.",
                "We considered linear combinations of pairs of predictors (labeled by the components) and all predictors (labeled as β). 5.3 Evaluation Given a set of retrievals, potentially from a combination of queries and systems, we measure the correlation of the rank ordering of this set by the predictor and by the performance metric.",
                "In order to ensure comparability with previous results, we present Kendalls τ correlation between the predictors ranking and ranking based on average precision of the retrieval.",
                "Unless explicitly noted, all correlations are significant with p < 0.05.",
                "Predictors can sometimes perform better when linearly combined [9, 11].",
                "Although previous work has presented the coefficient of determination (R2 ) to measure the quality of the regression, this measure cannot be reliably used when comparing slight improvements from combining predictors.",
                "Therefore, we adopt the adjusted coefficient of determination which penalizes models with more variables.",
                "The adjusted R2 allows us to evaluate the improvement in prediction achieved by adding a parameter but loses the statistical interpretation of R2 .",
                "We will use Kendalls τ to evaluate the magnitude of the correlation and the adjusted R2 to evaluate the combination of variables. 6.",
                "RESULTS We present results for our detailed experiments comparing the prediction of language model scores in Table 1.",
                "Although the Clarity measure is theoretically designed for language model scores, it consistently underperforms our system-agnostic predictor.",
                "Ranking robustness was presented as an improvement to Clarity for web collections (represented in our experiments by the terabyte04 and terabyte05 collections), shifting the τ correlation from 0.139 to 0.150 for terabyte04 and 0.171 to 0.208 for terabyte05.",
                "However, these improvements are slight compared to the performance of autocorrelation on these collections.",
                "Our predictor achieves a τ correlation of 0.454 for terabyte04 and 0.383 for terabyte05.",
                "Though not always the strongest, autocorrelation achieves correlations competitive with baseline predictors.",
                "When examining the performance of linear combinations of predictors, we note that in every case, autocorrelation factors as a necessary component of a strong predictor.",
                "We also note that the adjusted R2 for individual baselines are always significantly improved by incorporating autocorrelation.",
                "We present our generalizability results in Table 2.",
                "We begin by examining the situation in column (a) where we are presented with a single retrieval and no information from additional retrievals.",
                "For every collection except one, we achieve significantly better correlations than ranked-list Clarity.",
                "Surprisingly, we achieve relatively strong correlations for Spanish and Chinese collections despite our na¨ıve processing.",
                "We do not have a ranked-list clarity correlation for ent05 because entity modeling is itself an open research question.",
                "However, our autocorrelation measure does not achieve high correlations perhaps because relevance for entity retrieval does not propagate according to the cooccurrence links we use.",
                "As noted above, the poor Clarity performance on web data is consistent with our findings in the detailed experiments.",
                "Clarity also notably underperforms for several news corpora (trec5, trec7, and robust04).",
                "On the other hand, autocorrelation seems robust to the changes between different corpora.",
                "Next, we turn to the introduction of information from multiple retrievals.",
                "We compare the correlations between those predictors which do not use this information in column (a) and those which do in column (b).",
                "For every collection, the predictors in column (b) outperform the predictors in column (a), indicating that the information from additional runs can be critical to making good predictions.",
                "Inspecting the predictors in column (b), we only draw weak conclusions.",
                "Our new predictors tend to perform better on news corpora.",
                "And between our new predictors, the hybrid ρ(˜y, yµ) predictor tends to perform better.",
                "Recall that our ρ(˜y, yµ) measure incorporates both spatial and multiple retrieval information.",
                "Therefore, we believe that the improvement in correlation is the result of incorporating information from spatial behavior.",
                "In column (c), we can investigate the utility of incorporating spatial information with information from multiple retrievals.",
                "Notice that in the cases where autocorrelation, ρ(y, ˜y), alone performs well (trec3, trec5-spanish, and trec6-chinese), it is substantially improved by incorporating multiple-retrieval information from ρ(y, yµ) in the linear regression, β.",
                "In the cases where ρ(y, yµ) performs well, incorporating autocorrelation rarely results in a significant improvement in performance.",
                "In fact, in every case where our predictor outperforms the baseline, it includes information from multiple runs. 7.",
                "DISCUSSION The most important result from our experiments involves prediction when no information is available from multiple runs (Tables 1 and 2a).",
                "This situation arises often in system design.",
                "For example, a system may need to, at retrieval time, assess its performance before deciding to conduct more intensive processing such as pseudo-relevance feedback or interaction.",
                "Assuming the presence of multiple retrievals is unrealistic in this case.",
                "We believe that autocorrelation is, like multiple-retrieval algorithms, approximating a good ranking; in this case by diffusing scores.",
                "Why is ˜y a reasonable surrogate?",
                "We know that diffusion of scores on the web graph and language model graphs improves performance [14, 16].",
                "Therefore, if score diffusion tends to, in general, improve performance, then diffused scores will, in general, provide a good surrogate for relevance.",
                "Our results demonstrate that this approximation is not as powerful as information from multiple retrievals.",
                "Nevertheless, in situations where this information is lacking, autocorrelation provides substantial information.",
                "The success of autocorrelation as a predictor may also have roots in the clustering hypothesis.",
                "Recall that we regard autocorrelation as the degree to which a retrieval satisfies the clustering hypothesis.",
                "Our experiments, then, demonstrate that a failure to respect the clustering hypothesis correlates with poor performance.",
                "Why might systems fail to conform to the cluster hypothesis?",
                "Query-based information retrieval systems often score documents independently.",
                "The score of document a may be computed by examining query term or phrase matches, the document length, and perhaps global collection statistics.",
                "Once computed, a system rarely compares the score of a to the score of a topically-related document b.",
                "With some exceptions, the correlation of document scores has largely been ignored.",
                "We should make it clear that we have selected tasks where topical autocorrelation is appropriate.",
                "There are certainly cases where there is no reason to believe that retrieval scores will have topical autocorrelation.",
                "For example, ranked lists which incorporate document novelty should not exhibit spatial autocorrelation; if anything autocorrelation should be negative for this task.",
                "Similarly, answer candidates in a question-answering task may or may not exhibit autocorrelation; in this case, the semantics of links is questionable too.",
                "It is important before applying this measure to confirm that, given the semantics for some link between two retrieved items, we should expect a correlation between scores. 8.",
                "RELATED WORK In this section we draw more general comparisons to other work in performance prediction and spatial data analysis.",
                "There is a growing body of work which attempts to predict the performance of individual retrievals [7, 3, 11, 9, 19].",
                "We have attempted to place our work in the context of much of this work in Section 4.",
                "However, a complete comparison is beyond the scope of this paper.",
                "We note, though, that our experiments cover a larger and more diverse set of retrievals, collections, and topics than previously examined.",
                "Much previous work-particularly in the context of TRECfocuses on predicting the performance of systems.",
                "Here, each system generates k retrievals.",
                "The task is, given these retrievals, to predict the ranking of systems according to some performance measure.",
                "Several papers attempt to address this task under the constraint of few judgments [2, 4].",
                "Some work even attempts to use zero judgments by leveraging multiple retrievals for the same query [17].",
                "Our task differs because we focus on ranking retrievals independent of the generating system.",
                "The task here is not to test the hypothesis system A is superior to system B but to test the hypothesis retrieval A is superior to retrieval B. Autocorrelation manifests itself in many classification tasks.",
                "Neville and Jensen define relational autocorrelation for relational learning problems and demonstrate that many classification tasks manifest autocorrelation [13].",
                "Temporal autocorrelation of initial retrievals has also been used to predict performance [9].",
                "However, temporal autocorrelation is performed by projecting the retrieval function into the temporal embedding space.",
                "In our work, we focus on the behavior of the function over the relationships between documents. τ adjusted R2 DV KL P ρ(y, ˜y) DV KL P ρ(y, ˜y) DV KL, P DV KL, ρ(y, ˜y) Pρ(y, ˜y) β trec4 0.353 0.548 0.513 0.168 0.363 0.422 0.466 0.420 0.557 0.553 trec5 0.311 0.329 0.357 0.116 0.190 0.236 0.238 0.244 0.266 0.269 robust04 0.418 0.398 0.373 0.256 0.304 0.278 0.403 0.373 0.402 0.442 terabyte04 0.139 0.150 0.454 0.059 0.045 0.292 0.076 0.293 0.289 0.284 terabyte05 0.171 0.208 0.383 0.022 0.072 0.193 0.120 0.225 0.218 0.257 Table 1: Comparison to Robustness and Clarity measures for language model scores.",
                "Evaluation replicates experiments from [19].",
                "We present correlations between the classic Clarity measure (DV KL), the ranking robustness measure (P), and autocorrelation (ρ(y, ˜y)) each with mean average precision in terms of Kendalls τ.",
                "The adjusted coefficient of determination is presented to measure the effectiveness of combining predictors.",
                "Measures in bold represent the strongest correlation for that test/collection pair. multiple run (a) (b) (c) τ τ adjusted R2 DKL ρ(y, ˜y) Dn KL ρ(y, yµ) ρ(˜y, yµ) Dn KL ρ(y, ˜y) ρ(y, yµ) ρ(˜y, yµ) β trec3 0.201 0.461 0.461 0.439 0.456 0.444 0.395 0.394 0.386 0.498 trec4 0.252 0.396 0.455 0.482 0.489 0.379 0.263 0.429 0.482 0.483 trec5 0.016 0.277 0.433 0.459 0.393 0.280 0.157 0.375 0.323 0.386 trec6 0.230 0.227 0.352 0.428 0.418 0.203 0.089 0.323 0.325 0.325 trec7 0.083 0.326 0.341 0.430 0.483 0.264 0.182 0.363 0.442 0.400 trec8 0.235 0.396 0.454 0.508 0.567 0.402 0.272 0.490 0.580 0.523 robust03 0.302 0.354 0.377 0.385 0.447 0.269 0.206 0.274 0.392 0.303 robust04 0.183 0.308 0.301 0.384 0.453 0.200 0.182 0.301 0.393 0.335 robust05 0.224 0.249 0.371 0.377 0.404 0.341 0.108 0.313 0.328 0.336 terabyte04 0.043 0.245 0.544 0.420 0.392 0.516 0.105 0.357 0.343 0.365 terabyte05 0.068 0.306 0.480 0.434 0.390 0.491 0.168 0.384 0.309 0.403 trec4-spanish 0.307 0.388 0.488 0.398 0.395 0.423 0.299 0.282 0.299 0.388 trec5-spanish 0.220 0.458 0.446 0.484 0.475 0.411 0.398 0.428 0.437 0.529 trec5-chinese 0.092 0.199 0.367 0.379 0.384 0.379 0.199 0.273 0.276 0.310 trec6-chinese 0.144 0.276 0.265 0.353 0.376 0.115 0.128 0.188 0.223 0.199 ent05 - 0.181 0.324 0.305 0.282 0.211 0.043 0.158 0.155 0.179 Table 2: Large scale prediction experiments.",
                "We predict the ranking of large sets of retrievals for various collections and retrieval systems.",
                "Kendalls τ correlations are computed between the predicted ranking and a ranking based on the retrievals average precision.",
                "In column (a), we have predictors which do not use information from other retrievals for the same query.",
                "In columns (b) and (c) we present performance for predictors which incorporate information from multiple retrievals.",
                "The adjusted coefficient of determination is computed to determine effectiveness of combining predictors.",
                "Measures in bold represent the strongest correlation for that test/collection pair.",
                "Finally, regularization-based re-ranking processes are also closely-related to our work [8].",
                "These techniques seek to maximize the agreement between scores of related documents by solving a constrained optimization problem.",
                "The maximization of consistency is equivalent to maximizing the Moran autocorrelation.",
                "Therefore, we believe that our work provides explanation for why regularization-based re-ranking works. 9.",
                "CONCLUSION We have presented a new method for predicting the performance of a retrieval ranking without any relevance judgments.",
                "We consider two cases.",
                "First, when making predictions in the absence of retrievals from other systems, our predictors demonstrate robust, strong correlations with average precision.",
                "This performance, combined with a simple implementation, makes our predictors, in particular, very attractive.",
                "We have demonstrated this improvement for many, diverse settings.",
                "To our knowledge, this is the first large scale examination of zero-judgment, single-retrieval performance prediction.",
                "Second, when provided retrievals from other systems, our extended methods demonstrate competitive performance with state of the art baselines.",
                "Our experiments also demonstrate the limits of the usefulness of our predictors when information from multiple runs is provided.",
                "Our results suggest two conclusions.",
                "First, our results could affect retrieval algorithm design.",
                "Retrieval algorithms designed to consider spatial autocorrelation will conform to the cluster hypothesis and improve performance.",
                "Second, our results could affect the design of minimal test collection algorithms.",
                "Much of the recent work in ranking systems sometimes ignores correlations between document labels and scores.",
                "We believe that these two directions could be rewarding given the theoretical and experimental evidence in this paper. 10.",
                "ACKNOWLEDGMENTS This work was supported in part by the Center for Intelligent Information Retrieval and in part by the Defense Advanced Research Projects Agency (DARPA) under contract number HR0011-06-C-0023.",
                "Any opinions, findings and conclusions or recommendations expressed in this material are the authors and do not necessarily reflect those of the sponsor.",
                "We thank Yun Zhou and Desislava Petkova for providing data and Andre Gauthier for technical assistance. 11.",
                "REFERENCES [1] J. Aslam and V. Pavlu.",
                "Query hardness estimation using jensen-shannon divergence among multiple scoring functions.",
                "In ECIR 2007: Proceedings of the 29th European Conference on Information Retrieval, 2007. [2] J.",
                "A. Aslam, V. Pavlu, and E. Yilmaz.",
                "A statistical method for system evaluation using incomplete judgments.",
                "In S. Dumais, E. N. Efthimiadis, D. Hawking, and K. Jarvelin, editors, Proceedings of the 29th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 541-548.",
                "ACM Press, August 2006. [3] D. Carmel, E. Yom-Tov, A. Darlow, and D. Pelleg.",
                "What makes a query difficult?",
                "In SIGIR 06: Proceedings of the 29th annual international ACM SIGIR conference on Research and development in information retrieval, pages 390-397, New York, NY, USA, 2006.",
                "ACM Press. [4] B. Carterette, J. Allan, and R. Sitaraman.",
                "Minimal test collections for retrieval evaluation.",
                "In SIGIR 06: Proceedings of the 29th annual international ACM SIGIR conference on Research and development in information retrieval, pages 268-275, New York, NY, USA, 2006.",
                "ACM Press. [5] A. D. Cliff and J. K. Ord.",
                "Spatial Autocorrelation.",
                "Pion Ltd., 1973. [6] M. Connell, A. Feng, G. Kumaran, H. Raghavan, C. Shah, and J. Allan.",
                "Umass at tdt 2004.",
                "Technical Report CIIR Technical Report IR - 357, Department of Computer Science, University of Massachusetts, 2004. [7] S. Cronen-Townsend, Y. Zhou, and W. B. Croft.",
                "Precision prediction based on ranked list coherence.",
                "Inf.",
                "Retr., 9(6):723-755, 2006. [8] F. Diaz.",
                "Regularizing ad-hoc retrieval scores.",
                "In CIKM 05: Proceedings of the 14th ACM international conference on Information and knowledge management, pages 672-679, New York, NY, USA, 2005.",
                "ACM Press. [9] F. Diaz and R. Jones.",
                "Using temporal profiles of queries for precision prediction.",
                "In SIGIR 04: Proceedings of the 27th annual international ACM SIGIR conference on Research and development in information retrieval, pages 18-24, New York, NY, USA, 2004.",
                "ACM Press. [10] D. A. Griffith.",
                "Spatial Autocorrelation and Spatial Filtering.",
                "Springer Verlag, 2003. [11] B.",
                "He and I. Ounis.",
                "Inferring Query Performance Using Pre-retrieval Predictors.",
                "In The Eleventh Symposium on String Processing and Information Retrieval (SPIRE), 2004. [12] N. Jardine and C. J. V. Rijsbergen.",
                "The use of hierarchic clustering in information retrieval.",
                "Information Storage and Retrieval, 7:217-240, 1971. [13] D. Jensen and J. Neville.",
                "Linkage and autocorrelation cause feature selection bias in relational learning.",
                "In ICML 02: Proceedings of the Nineteenth International Conference on Machine Learning, pages 259-266, San Francisco, CA, USA, 2002.",
                "Morgan Kaufmann Publishers Inc. [14] O. Kurland and L. Lee.",
                "Corpus structure, language models, and ad-hoc information retrieval.",
                "In SIGIR 04: Proceedings of the 27th annual international conference on Research and development in information retrieval, pages 194-201, New York, NY, USA, 2004.",
                "ACM Press. [15] M. Montague and J.",
                "A. Aslam.",
                "Relevance score normalization for metasearch.",
                "In CIKM 01: Proceedings of the tenth international conference on Information and knowledge management, pages 427-433, New York, NY, USA, 2001.",
                "ACM Press. [16] T. Qin, T.-Y.",
                "Liu, X.-D. Zhang, Z. Chen, and W.-Y.",
                "Ma.",
                "A study of relevance propagation for web search.",
                "In SIGIR 05: Proceedings of the 28th annual international ACM SIGIR conference on Research and development in information retrieval, pages 408-415, New York, NY, USA, 2005.",
                "ACM Press. [17] I. Soboroff, C. Nicholas, and P. Cahan.",
                "Ranking retrieval systems without relevance judgments.",
                "In SIGIR 01: Proceedings of the 24th annual international ACM SIGIR conference on Research and development in information retrieval, pages 66-73, New York, NY, USA, 2001.",
                "ACM Press. [18] V. Vinay, I. J. Cox, N. Milic-Frayling, and K. Wood.",
                "On ranking the effectiveness of searches.",
                "In SIGIR 06: Proceedings of the 29th annual international ACM SIGIR conference on Research and development in information retrieval, pages 398-404, New York, NY, USA, 2006.",
                "ACM Press. [19] Y. Zhou and W. B. Croft.",
                "Ranking robustness: a novel framework to predict query performance.",
                "In CIKM 06: Proceedings of the 15th ACM international conference on Information and knowledge management, pages 567-574, New York, NY, USA, 2006.",
                "ACM Press."
            ],
            "original_annotated_samples": [],
            "translated_annotated_samples": [],
            "translated_text": "",
            "candidates": [],
            "error": [
                []
            ]
        },
        "regularization": {
            "translated_key": "regularización",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Performance Prediction Using Spatial Autocorrelation Fernando Diaz Center for Intelligent Information Retrieval Department of Computer Science University of Massachusetts Amherst, MA 01003 fdiaz@cs.umass.edu ABSTRACT Evaluation of information retrieval systems is one of the core tasks in information retrieval.",
                "Problems include the inability to exhaustively label all documents for a topic, nongeneralizability from a small number of topics, and incorporating the variability of retrieval systems.",
                "Previous work addresses the evaluation of systems, the ranking of queries by difficulty, and the ranking of individual retrievals by performance.",
                "Approaches exist for the case of few and even no relevance judgments.",
                "Our focus is on zero-judgment performance prediction of individual retrievals.",
                "One common shortcoming of previous techniques is the assumption of uncorrelated document scores and judgments.",
                "If documents are embedded in a high-dimensional space (as they often are), we can apply techniques from spatial data analysis to detect correlations between document scores.",
                "We find that the low correlation between scores of topically close documents often implies a poor retrieval performance.",
                "When compared to a state of the art baseline, we demonstrate that the spatial analysis of retrieval scores provides significantly better prediction performance.",
                "These new predictors can also be incorporated with classic predictors to improve performance further.",
                "We also describe the first large-scale experiment to evaluate zero-judgment performance prediction for a massive number of retrieval systems over a variety of collections in several languages.",
                "Categories and Subject Descriptors H.3.3 [Information Search and Retrieval]: Retrieval models; H.3.4 [Systems and Software]: Performance evaluation (efficiency and effectiveness) General Terms Performance, Design, Reliability, Experimentation 1.",
                "INTRODUCTION In information retrieval, a user poses a query to a system.",
                "The system retrieves n documents each receiving a realvalued score indicating the predicted degree of relevance.",
                "If we randomly select pairs of documents from this set, we expect some pairs to share the same topic and other pairs to not share the same topic.",
                "Take two topically-related documents from the set and call them a and b.",
                "If the scores of a and b are very different, we may be concerned about the performance of our system.",
                "That is, if a and b are both on the topic of the query, we would like them both to receive a high score; if a and b are not on the topic of the query, we would like them both to receive a low score.",
                "We might become more worried as we find more differences between scores of related documents.",
                "We would be more comfortable with a retrieval where scores are consistent between related documents.",
                "Our paper studies the quantification of this inconsistency in a retrieval from a spatial perspective.",
                "Spatial analysis is appropriate since many retrieval models embed documents in some vector space.",
                "If documents are embedded in a space, proximity correlates with topical relationships.",
                "Score consistency can be measured by the spatial version of autocorrelation known as the Moran coefficient or IM [5, 10].",
                "In this paper, we demonstrate a strong correlation between IM and retrieval performance.",
                "The discussion up to this point is reminiscent of the cluster hypothesis.",
                "The cluster hypothesis states: closely-related documents tend to be relevant to the same request [12].",
                "As we shall see, a retrieval functions spatial autocorrelation measures the degree to which closely-related documents receive similar scores.",
                "Because of this, we interpret autocorrelation as measuring the degree to which a retrieval function satisfies the clustering hypothesis.",
                "If this connection is reasonable, in Section 6, we present evidence that failure to satisfy the cluster hypothesis correlates strongly with poor performance.",
                "In this work, we provide the following contributions, 1.",
                "A general, robust method for predicting the performance of retrievals with zero relevance judgments (Section 3). 2.",
                "A theoretical treatment of the similarities and motivations behind several state-of-the-art performance prediction techniques (Section 4). 3.",
                "The first large-scale experiments of zero-judgment, single run performance prediction (Sections 5 and 6). 2.",
                "PROBLEM DEFINITION Given a query, an information retrieval system produces a ranking of documents in the collection encoded as a set of scores associated with documents.",
                "We refer to the set of scores for a particular query-system combination as a retrieval.",
                "We would like to predict the performance of this retrieval with respect to some evaluation measure (eg, mean average precision).",
                "In this paper, we present results for ranking retrievals from arbitrary systems.",
                "We would like this ranking to approximate the ranking of retrievals by the evaluation measure.",
                "This is different from ranking queries by the average performance on each query.",
                "It is also different from ranking systems by the average performance on a set of queries.",
                "Scores are often only computed for the top n documents from the collection.",
                "We place these scores in the length n vector, y, where yi refers to the score of the ith-ranked document.",
                "We adjust scores to have zero mean and unit variance.",
                "We use this method because of its simplicity and its success in previous work [15]. 3.",
                "SPATIAL CORRELATION In information retrieval, we often assume that the representations of documents exist in some high-dimensional vector space.",
                "For example, given a vocabulary, V, this vector space may be an arbitrary |V|-dimensional space with cosine inner-product or a multinomial simplex with a distributionbased distance measure.",
                "An embedding space is often selected to respect topical proximity; if two documents are near, they are more likely to share a topic.",
                "Because of the prevalence and success of spatial models of information retrieval, we believe that the application of spatial data analysis techniques are appropriate.",
                "Whereas in information retrieval, we are concerned with the score at a point in a space, in spatial data analysis, we are concerned with the value of a function at a point or location in a space.",
                "We use the term function here to mean a mapping from a location to a real value.",
                "For example, we might be interested in the prevalence of a disease in the neighborhood of some city.",
                "The function would map the location of a neighborhood to an infection rate.",
                "If we want to quantify the spatial dependencies of a function, we would employ a measure referred to as the spatial autocorrelation [5, 10].",
                "High spatial autocorrelation suggests that knowing the value of a function at location a will tell us a great deal about the value at a neighboring location b.",
                "There is a high spatial autocorrelation for a function representing the temperature of a location since knowing the temperature at a location a will tell us a lot about the temperature at a neighboring location b.",
                "Low spatial autocorrelation suggests that knowing the value of a function at location a tells us little about the value at a neighboring location b.",
                "There is low spatial autocorrelation in a function measuring the outcome of a coin toss at a and b.",
                "In this section, we will begin by describing what we mean by spatial proximity for documents and then define a measure of spatial autocorrelation.",
                "We conclude by extending this model to include information from multiple retrievals from multiple systems for a single query. 3.1 Spatial Representation of Documents Our work does not focus on improving a specific similarity measure or defining a novel vector space.",
                "Instead, we choose an inner product known to be effective at detecting interdocument topical relationships.",
                "Specifically, we adopt tf.idf document vectors, ˜di = di log „ (n + 0.5) − ci 0.5 + ci « (1) where d is a vector of term frequencies, c is the length-|V| document frequency vector.",
                "We use this weighting scheme due to its success for topical link detection in the context of Topic Detection and Tracking (TDT) evaluations [6].",
                "Assuming vectors are scaled by their L2 norm, we use the inner product, ˜di, ˜dj , to define similarity.",
                "Given documents and some similarity measure, we can construct a matrix which encodes the similarity between pairs of documents.",
                "Recall that we are given the top n documents retrieved in y.",
                "We can compute an n × n similarity matrix, W. An element of this matrix, Wij represents the similarity between documents ranked i and j.",
                "In practice, we only include the affinities for a documents k-nearest neighbors.",
                "In all of our experiments, we have fixed k to 5.",
                "We leave exploration of parameter sensitivity to future work.",
                "We also row normalize the matrix so that Pn j=1 Wij = 1 for all i. 3.2 Spatial Autocorrelation of a Retrieval Recall that we are interested in measuring the similarity between the scores of spatially-close documents.",
                "One such suitable measure is the Moran coefficient of spatial autocorrelation.",
                "Assuming the function y over n locations, this is defined as ˜IM = n eTWe P i,j Wijyiyj P i y2 i = n eTWe yT Wy yTy (2) where eT We = P ij Wij.",
                "We would like to compare autocorrelation values for different retrievals.",
                "Unfortunately, the bound for Equation 2 is not consistent for different W and y.",
                "Therefore, we use the Cauchy-Schwartz inequality to establish a bound, ˜IM ≤ n eTWe s yTWTWy yTy And we define the normalized spatial autocorrelation as IM = yT Wy p yTy × yTWTWy Notice that if we let ˜y = Wy, then we can write this formula as, IM = yT ˜y y 2 ˜y 2 (3) which can be interpreted as the correlation between the original retrieval scores and a set of retrieval scores diffused in the space.",
                "We present some examples of autocorrelations of functions on a grid in Figure 1. 3.3 Correlation with Other Retrievals Sometimes we are interested in the performance of a single retrieval but have access to scores from multiple systems for (a) IM = 0.006 (b) IM = 0.241 (c) IM = 0.487 Figure 1: The Moran coefficient, IM for a several binary functions on a grid.",
                "The Moran coefficient is a local measure of function consistency.",
                "From the perspective of information retrieval, each of these grid spaces would represent a document and documents would be organized so that they lay next to topically-related documents.",
                "Binary retrieval scores would define a pattern on this grid.",
                "Notice that, as the Moran coefficient increases, neighboring cells tend to have similar values. the same query.",
                "In this situation, we can use combined information from these scores to construct a surrogate for a high-quality ranking [17].",
                "We can treat the correlation between the retrieval we are interested in and the combined scores as a predictor of performance.",
                "Assume that we are given m score functions, yi, for the same n documents.",
                "We will represent the mean of these vectors as yµ = Pm i=1 yi.",
                "We use the mean vector as an approximation to relevance.",
                "Since we use zero mean and unit variance normalization, work in metasearch suggests that this assumption is justified [15].",
                "Because yµ represents a very good retrieval, we hypothesize that a strong similarity between yµ and y will correlate positively with system performance.",
                "We use Pearsons product-moment correlation to measure the similarity between these vectors, ρ(y, yµ) = yT yµ y 2 yµ 2 (4) We will comment on the similarity between Equation 3 and 4 in Section 7.",
                "Of course, we can combine ρ(y, ˜y) and ρ(y, yµ) if we assume that they capture different factors in the prediction.",
                "One way to accomplish this is to combine these predictors as independent variables in a linear regression.",
                "An alternative means of combination is suggested by the mathematical form of our predictors.",
                "Since ˜y encodes the spatial dependencies in y and yµ encodes the spatial properties of the multiple runs, we can compute a third correlation between these two vectors, ρ(˜y, yµ) = ˜yT yµ ˜y 2 yµ 2 (5) We can interpret Equation 5 as measuring the correlation between a high quality ranking (yµ) and a spatially smoothed version of the retrieval (˜y). 4.",
                "RELATIONSHIP WITH OTHER PREDICTORS One way to predict the effectiveness of a retrieval is to look at the shared vocabulary of the top n retrieved documents.",
                "If we computed the most frequent content words in this set, we would hope that they would be consistent with our topic.",
                "In fact, we might believe that a bad retrieval would include documents on many disparate topics, resulting in an overlap of terminological noise.",
                "The Clarity of a query attempts to quantify exactly this [7].",
                "Specifically, Clarity measures the similarity of the words most frequently used in retrieved documents to those most frequently used in the whole corpus.",
                "The conjecture is that a good retrieval will use language distinct from general text; the overlapping language in a bad retrieval will tend to be more similar to general text.",
                "Mathematically, we can compute a representation of the language used in the initial retrieval as a weighted combination of document language models, P(w|θQ) = nX i=1 P(w|θi) P(Q|θi) Z (6) where θi is the language model of the ith-ranked document, P(Q|θi) is the query likelihood score of the ith-ranked document and Z = Pn i=1 P(Q|θi) is a normalization constant.",
                "The similarity between the multinomial P(w|θQ) and a model of general text can be computed using the Kullback-Leibler divergence, DV KL(θQ θC ).",
                "Here, the distribution P(w|θC ) is our model of general text which can be computed using term frequencies in the corpus.",
                "In Figure 2a, we present Clarity as measuring the distance between the weighted center of mass of the retrieval (labeled y) and the unweighted center of mass of the collection (labeled O).",
                "Clarity reaches a minimum when a retrieval assigns every document the same score.",
                "Lets again assume we have a set of n documents retrieved for our query.",
                "Another way to quantify the dispersion of a set of documents is to look at how clustered they are.",
                "We may hypothesize that a good retrieval will return a single, tight cluster.",
                "A poorly performing retrieval will return a loosely related set of documents covering many topics.",
                "One proposed method of quantifying this dispersion is to measure the distance from a random document a to its nearest neighbor, b.",
                "A retrieval which is tightly clustered will, on average, have a low distance between a and b; a retrieval which is less tightly-closed will, on average have high distances between a and b.",
                "This average corresponds to using the Cox-Lewis statistic to measure the randomness of the top n documents retrieved from a system [18].",
                "In Figure 2a, this is roughly equivalent to measuring the area of the set n. Notice that we are throwing away information about the retrieval function y.",
                "Therefore the Cox-Lewis statistic is highly dependent on selecting the top n documents.1 Remember that we have n documents and a set of scores.",
                "Lets assume that we have access to the system which provided the original scores and that we can also request scores for new documents.",
                "This suggests a third method for predicting performance.",
                "Take some document, a, from the retrieved set and arbitrarily add or remove words at random to create a new document ˜a.",
                "Now, we can ask our system to score ˜a with respect to our query.",
                "If, on average over the n documents, the scores of a and ˜a tend to be very different, we might suspect that the system is failing on this query.",
                "So, an alternative approach is to measure the simi1 The authors have suggested coupling the query with the distance measure [18].",
                "The information introduced by the query, though, is retrieval-independent so that, if two retrievals return the same set of documents, the approximate Cox-Lewis statistic will be the same regardless of the retrieval scores. yOy (a) Global Divergence µ(y)˜y y (b) Score Perturbation µ(y) y (c) Multirun Averaging Figure 2: Representation of several performance predictors on a grid.",
                "In Figure 2a, we depict predictors which measure the divergence between the center of mass of a retrieval and the center of the embedding space.",
                "In Figure 2b, we depict predictors which compare the original retrieval, y, to a perturbed version of the retrieval, ˜y.",
                "Our approach uses a particular type of perturbation based on score diffusion.",
                "Finally, in Figure 2c, we depict prediction when given retrievals from several other systems on the same query.",
                "Here, we can consider the fusion of these retrieval as a surrogate for relevance. larity between the retrieval and a perturbed version of that retrieval [18, 19].",
                "This can be accomplished by either perturbing the documents or queries.",
                "The similarity between the two retrievals can be measured using some correlation measure.",
                "This is depicted in Figure 2b.",
                "The upper grid represents the original retrieval, y, while the lower grid represents the function after having been perturbed, ˜y.",
                "The nature of the perturbation process requires additional scorings or retrievals.",
                "Our predictor does not require access to the original scoring function or additional retrievals.",
                "So, although our method is similar to other perturbation methods in spirit, it can be applied in situations when the retrieval system is inaccessible or costly to access.",
                "Finally, assume that we have, in addition to the retrieval we want to evaluate, m retrievals from a variety of different systems.",
                "In this case, we might take a document a, compare its rank in the retrieval to its average rank in the m retrievals.",
                "If we believe that the m retrievals provide a satisfactory approximation to relevance, then a very large difference in rank would suggest that our retrieval is misranking a.",
                "If this difference is large on average over all n documents, then we might predict that the retrieval is bad.",
                "If, on the other hand, the retrieval is very consistent with the m retrievals, then we might predict that the retrieval is good.",
                "The similarity between the retrieval and the combined retrieval may be computed using some correlation measure.",
                "This is depicted in Figure 2c.",
                "In previous work, the Kullback-Leibler divergence between the normalized scores of the retrieval and the normalized scores of the combined retrieval provides the similarity [1]. 5.",
                "EXPERIMENTS Our experiments focus on testing the predictive power of each of our predictors: ρ(y, ˜y), ρ(y, yµ), and ρ(˜y, yµ).",
                "As stated in Section 2, we are interested in predicting the performance of the retrieval generated by an arbitrary system.",
                "Our methodology is consistent with previous research in that we predict the relative performance of a retrieval by comparing a ranking based on our predictor to a ranking based on average precision.",
                "We present results for two sets of experiments.",
                "The first set of experiments presents detailed comparisons of our predictors to previously-proposed predictors using identical data sets.",
                "Our second set of experiments demonstrates the generalizability of our approach to arbitrary retrieval methods, corpus types, and corpus languages. 5.1 Detailed Experiments In these experiments, we will predict the performance of language modeling scores using our autocorrelation predictor, ρ(y, ˜y); we do not consider ρ(y, yµ) or ρ(˜y, yµ) because, in these detailed experiments, we focus on ranking the retrievals from a single system.",
                "We use retrievals, values for baseline predictors, and evaluation measures reported in previous work [19]. 5.1.1 Topics and Collections These performance prediction experiments use language model retrievals performed for queries associated with collections in the TREC corpora.",
                "Using TREC collections allows us to confidently associate an average precision with a retrieval.",
                "In these experiments, we use the following topic collections: TREC 4 ad-hoc, TREC 5 ad-hoc, Robust 2004, Terabyte 2004, and Terabyte 2005. 5.1.2 Baselines We provide two baselines.",
                "Our first baseline is the classic Clarity predictor presented in Equation 6.",
                "Clarity is designed to be used with language modeling systems.",
                "Our second baseline is Zhou and Crofts ranking robustness predictor.",
                "This predictor corrupts the top k documents from retrieval and re-computes the language model scores for these corrupted documents.",
                "The value of the predictor is the Spearman rank correlation between the original ranking and the corrupted ranking.",
                "In our tables, we will label results for Clarity using DV KL and the ranking robustness predictor using P. 5.2 Generalizability Experiments Our predictors do not require a particular baseline retrieval system; the predictors can be computed for an arbitrary retrieval, regardless of how scores were generated.",
                "We believe that that is one of the most attractive aspects of our algorithm.",
                "Therefore, in a second set of experiments, we demonstrate the ability of our techniques to generalize to a variety of collections, topics, and retrieval systems. 5.2.1 Topics and Collections We gathered a diverse set of collections from all possible TREC corpora.",
                "We cast a wide net in order to locate collections where our predictors might fail.",
                "Our hypothesis is that documents with high topical similarity should have correlated scores.",
                "Therefore, we avoided collections where scores were unlikely to be correlated (eg, question-answering) or were likely to be negatively correlated (eg, novelty).",
                "Nevertheless, our collections include corpora where correlations are weakly justified (eg, non-English corpora) or not justified at all (eg, expert search).",
                "We use the ad-hoc tracks from TREC3-8, TREC Robust 2003-2005, TREC Terabyte 20042005, TREC4-5 Spanish, TREC5-6 Chinese, and TREC Enterprise Expert Search 2005.",
                "In all cases, we use only the automatic runs for ad-hoc tracks submitted to NIST.",
                "For all English and Spanish corpora, we construct the matrix W according to the process described in Section 3.1.",
                "For Chinese corpora, we use na¨ıve character-based tf.idf vectors.",
                "For entities, entries in W are proportional to the number of documents in which two entities cooccur. 5.2.2 Baselines In our detailed experiments, we used the Clarity measure as a baseline.",
                "Since we are predicting the performance of retrievals which are not based on language modeling, we use a version of Clarity referred to as ranked-list Clarity [7].",
                "Ranked-list clarity converts document ranks to P(Q|θi) values.",
                "This conversion begins by replacing all of the scores in y with the respective ranks.",
                "Our estimation of P(Q|θi) from the ranks, then is, P(Q|θi) = ( 2(c+1−yi) c(c+1) if yi ≤ c 0 otherwise (7) where c is a cutoff parameter.",
                "As suggested by the authors, we fix the algorithm parameters c and λ2 so that c = 60 and λ2 = 0.10.",
                "We use Equation 6 to estimate P(w|θQ) and DV KL(θQ θC ) to compute the value of the predictor.",
                "We will refer to this predictor as DV KL, superscripted by V to indicate that the Kullback-Leibler divergence is with respect to the term embedding space.",
                "When information from multiple runs on the same query is available, we use Aslam and Pavlus document-space multinomial divergence as a baseline [1].",
                "This rank-based method first normalizes the scores in a retrieval as an n-dimensional multinomial.",
                "As with ranked-list Clarity, we begin by replacing all of the scores in y with their respective ranks.",
                "Then, we adjust the elements of y in the following way, ˆyi = 1 2n 0 @1 + nX k=yi 1 k 1 A (8) In our multirun experiments, we only use the top 75 documents from each retrieval (n = 75); this is within the range of parameter values suggested by the authors.",
                "However, we admit not tuning this parameter for either our system or the baseline.",
                "The predictor is the divergence between the candidate distribution, y, and the mean distribution, yµ .",
                "With the uniform linear combination of these m retrievals represented as yµ, we can compute the divergence as Dn KL(ˆy ˆyµ) where we use the superscript n to indicate that the summation is over the set of n documents.",
                "This baseline was developed in the context of predicting query difficulty but we adopt it as a reasonable baseline for predicting retrieval performance. 5.2.3 Parameter Settings When given multiple retrievals, we use documents in the union of the top k = 75 documents from each of the m retrievals for that query.",
                "If the size of this union is ˜n, then yµ and each yi is of length ˜n.",
                "In some cases, a system did not score a document in the union.",
                "Since we are making a Gaussian assumption about our scores, we can sample scores for these unseen documents from the negative tail of the distribution.",
                "Specifically, we sample from the part of the distribution lower than the minimum value of in the normalized retrieval.",
                "This introduces randomness into our algorithm but we believe it is more appropriate than assigning an arbitrary fixed value.",
                "We optimized the linear regression using the square root of each predictor.",
                "We found that this substantially improved fits for all predictors, including the baselines.",
                "We considered linear combinations of pairs of predictors (labeled by the components) and all predictors (labeled as β). 5.3 Evaluation Given a set of retrievals, potentially from a combination of queries and systems, we measure the correlation of the rank ordering of this set by the predictor and by the performance metric.",
                "In order to ensure comparability with previous results, we present Kendalls τ correlation between the predictors ranking and ranking based on average precision of the retrieval.",
                "Unless explicitly noted, all correlations are significant with p < 0.05.",
                "Predictors can sometimes perform better when linearly combined [9, 11].",
                "Although previous work has presented the coefficient of determination (R2 ) to measure the quality of the regression, this measure cannot be reliably used when comparing slight improvements from combining predictors.",
                "Therefore, we adopt the adjusted coefficient of determination which penalizes models with more variables.",
                "The adjusted R2 allows us to evaluate the improvement in prediction achieved by adding a parameter but loses the statistical interpretation of R2 .",
                "We will use Kendalls τ to evaluate the magnitude of the correlation and the adjusted R2 to evaluate the combination of variables. 6.",
                "RESULTS We present results for our detailed experiments comparing the prediction of language model scores in Table 1.",
                "Although the Clarity measure is theoretically designed for language model scores, it consistently underperforms our system-agnostic predictor.",
                "Ranking robustness was presented as an improvement to Clarity for web collections (represented in our experiments by the terabyte04 and terabyte05 collections), shifting the τ correlation from 0.139 to 0.150 for terabyte04 and 0.171 to 0.208 for terabyte05.",
                "However, these improvements are slight compared to the performance of autocorrelation on these collections.",
                "Our predictor achieves a τ correlation of 0.454 for terabyte04 and 0.383 for terabyte05.",
                "Though not always the strongest, autocorrelation achieves correlations competitive with baseline predictors.",
                "When examining the performance of linear combinations of predictors, we note that in every case, autocorrelation factors as a necessary component of a strong predictor.",
                "We also note that the adjusted R2 for individual baselines are always significantly improved by incorporating autocorrelation.",
                "We present our generalizability results in Table 2.",
                "We begin by examining the situation in column (a) where we are presented with a single retrieval and no information from additional retrievals.",
                "For every collection except one, we achieve significantly better correlations than ranked-list Clarity.",
                "Surprisingly, we achieve relatively strong correlations for Spanish and Chinese collections despite our na¨ıve processing.",
                "We do not have a ranked-list clarity correlation for ent05 because entity modeling is itself an open research question.",
                "However, our autocorrelation measure does not achieve high correlations perhaps because relevance for entity retrieval does not propagate according to the cooccurrence links we use.",
                "As noted above, the poor Clarity performance on web data is consistent with our findings in the detailed experiments.",
                "Clarity also notably underperforms for several news corpora (trec5, trec7, and robust04).",
                "On the other hand, autocorrelation seems robust to the changes between different corpora.",
                "Next, we turn to the introduction of information from multiple retrievals.",
                "We compare the correlations between those predictors which do not use this information in column (a) and those which do in column (b).",
                "For every collection, the predictors in column (b) outperform the predictors in column (a), indicating that the information from additional runs can be critical to making good predictions.",
                "Inspecting the predictors in column (b), we only draw weak conclusions.",
                "Our new predictors tend to perform better on news corpora.",
                "And between our new predictors, the hybrid ρ(˜y, yµ) predictor tends to perform better.",
                "Recall that our ρ(˜y, yµ) measure incorporates both spatial and multiple retrieval information.",
                "Therefore, we believe that the improvement in correlation is the result of incorporating information from spatial behavior.",
                "In column (c), we can investigate the utility of incorporating spatial information with information from multiple retrievals.",
                "Notice that in the cases where autocorrelation, ρ(y, ˜y), alone performs well (trec3, trec5-spanish, and trec6-chinese), it is substantially improved by incorporating multiple-retrieval information from ρ(y, yµ) in the linear regression, β.",
                "In the cases where ρ(y, yµ) performs well, incorporating autocorrelation rarely results in a significant improvement in performance.",
                "In fact, in every case where our predictor outperforms the baseline, it includes information from multiple runs. 7.",
                "DISCUSSION The most important result from our experiments involves prediction when no information is available from multiple runs (Tables 1 and 2a).",
                "This situation arises often in system design.",
                "For example, a system may need to, at retrieval time, assess its performance before deciding to conduct more intensive processing such as pseudo-relevance feedback or interaction.",
                "Assuming the presence of multiple retrievals is unrealistic in this case.",
                "We believe that autocorrelation is, like multiple-retrieval algorithms, approximating a good ranking; in this case by diffusing scores.",
                "Why is ˜y a reasonable surrogate?",
                "We know that diffusion of scores on the web graph and language model graphs improves performance [14, 16].",
                "Therefore, if score diffusion tends to, in general, improve performance, then diffused scores will, in general, provide a good surrogate for relevance.",
                "Our results demonstrate that this approximation is not as powerful as information from multiple retrievals.",
                "Nevertheless, in situations where this information is lacking, autocorrelation provides substantial information.",
                "The success of autocorrelation as a predictor may also have roots in the clustering hypothesis.",
                "Recall that we regard autocorrelation as the degree to which a retrieval satisfies the clustering hypothesis.",
                "Our experiments, then, demonstrate that a failure to respect the clustering hypothesis correlates with poor performance.",
                "Why might systems fail to conform to the cluster hypothesis?",
                "Query-based information retrieval systems often score documents independently.",
                "The score of document a may be computed by examining query term or phrase matches, the document length, and perhaps global collection statistics.",
                "Once computed, a system rarely compares the score of a to the score of a topically-related document b.",
                "With some exceptions, the correlation of document scores has largely been ignored.",
                "We should make it clear that we have selected tasks where topical autocorrelation is appropriate.",
                "There are certainly cases where there is no reason to believe that retrieval scores will have topical autocorrelation.",
                "For example, ranked lists which incorporate document novelty should not exhibit spatial autocorrelation; if anything autocorrelation should be negative for this task.",
                "Similarly, answer candidates in a question-answering task may or may not exhibit autocorrelation; in this case, the semantics of links is questionable too.",
                "It is important before applying this measure to confirm that, given the semantics for some link between two retrieved items, we should expect a correlation between scores. 8.",
                "RELATED WORK In this section we draw more general comparisons to other work in performance prediction and spatial data analysis.",
                "There is a growing body of work which attempts to predict the performance of individual retrievals [7, 3, 11, 9, 19].",
                "We have attempted to place our work in the context of much of this work in Section 4.",
                "However, a complete comparison is beyond the scope of this paper.",
                "We note, though, that our experiments cover a larger and more diverse set of retrievals, collections, and topics than previously examined.",
                "Much previous work-particularly in the context of TRECfocuses on predicting the performance of systems.",
                "Here, each system generates k retrievals.",
                "The task is, given these retrievals, to predict the ranking of systems according to some performance measure.",
                "Several papers attempt to address this task under the constraint of few judgments [2, 4].",
                "Some work even attempts to use zero judgments by leveraging multiple retrievals for the same query [17].",
                "Our task differs because we focus on ranking retrievals independent of the generating system.",
                "The task here is not to test the hypothesis system A is superior to system B but to test the hypothesis retrieval A is superior to retrieval B. Autocorrelation manifests itself in many classification tasks.",
                "Neville and Jensen define relational autocorrelation for relational learning problems and demonstrate that many classification tasks manifest autocorrelation [13].",
                "Temporal autocorrelation of initial retrievals has also been used to predict performance [9].",
                "However, temporal autocorrelation is performed by projecting the retrieval function into the temporal embedding space.",
                "In our work, we focus on the behavior of the function over the relationships between documents. τ adjusted R2 DV KL P ρ(y, ˜y) DV KL P ρ(y, ˜y) DV KL, P DV KL, ρ(y, ˜y) Pρ(y, ˜y) β trec4 0.353 0.548 0.513 0.168 0.363 0.422 0.466 0.420 0.557 0.553 trec5 0.311 0.329 0.357 0.116 0.190 0.236 0.238 0.244 0.266 0.269 robust04 0.418 0.398 0.373 0.256 0.304 0.278 0.403 0.373 0.402 0.442 terabyte04 0.139 0.150 0.454 0.059 0.045 0.292 0.076 0.293 0.289 0.284 terabyte05 0.171 0.208 0.383 0.022 0.072 0.193 0.120 0.225 0.218 0.257 Table 1: Comparison to Robustness and Clarity measures for language model scores.",
                "Evaluation replicates experiments from [19].",
                "We present correlations between the classic Clarity measure (DV KL), the ranking robustness measure (P), and autocorrelation (ρ(y, ˜y)) each with mean average precision in terms of Kendalls τ.",
                "The adjusted coefficient of determination is presented to measure the effectiveness of combining predictors.",
                "Measures in bold represent the strongest correlation for that test/collection pair. multiple run (a) (b) (c) τ τ adjusted R2 DKL ρ(y, ˜y) Dn KL ρ(y, yµ) ρ(˜y, yµ) Dn KL ρ(y, ˜y) ρ(y, yµ) ρ(˜y, yµ) β trec3 0.201 0.461 0.461 0.439 0.456 0.444 0.395 0.394 0.386 0.498 trec4 0.252 0.396 0.455 0.482 0.489 0.379 0.263 0.429 0.482 0.483 trec5 0.016 0.277 0.433 0.459 0.393 0.280 0.157 0.375 0.323 0.386 trec6 0.230 0.227 0.352 0.428 0.418 0.203 0.089 0.323 0.325 0.325 trec7 0.083 0.326 0.341 0.430 0.483 0.264 0.182 0.363 0.442 0.400 trec8 0.235 0.396 0.454 0.508 0.567 0.402 0.272 0.490 0.580 0.523 robust03 0.302 0.354 0.377 0.385 0.447 0.269 0.206 0.274 0.392 0.303 robust04 0.183 0.308 0.301 0.384 0.453 0.200 0.182 0.301 0.393 0.335 robust05 0.224 0.249 0.371 0.377 0.404 0.341 0.108 0.313 0.328 0.336 terabyte04 0.043 0.245 0.544 0.420 0.392 0.516 0.105 0.357 0.343 0.365 terabyte05 0.068 0.306 0.480 0.434 0.390 0.491 0.168 0.384 0.309 0.403 trec4-spanish 0.307 0.388 0.488 0.398 0.395 0.423 0.299 0.282 0.299 0.388 trec5-spanish 0.220 0.458 0.446 0.484 0.475 0.411 0.398 0.428 0.437 0.529 trec5-chinese 0.092 0.199 0.367 0.379 0.384 0.379 0.199 0.273 0.276 0.310 trec6-chinese 0.144 0.276 0.265 0.353 0.376 0.115 0.128 0.188 0.223 0.199 ent05 - 0.181 0.324 0.305 0.282 0.211 0.043 0.158 0.155 0.179 Table 2: Large scale prediction experiments.",
                "We predict the ranking of large sets of retrievals for various collections and retrieval systems.",
                "Kendalls τ correlations are computed between the predicted ranking and a ranking based on the retrievals average precision.",
                "In column (a), we have predictors which do not use information from other retrievals for the same query.",
                "In columns (b) and (c) we present performance for predictors which incorporate information from multiple retrievals.",
                "The adjusted coefficient of determination is computed to determine effectiveness of combining predictors.",
                "Measures in bold represent the strongest correlation for that test/collection pair.",
                "Finally, <br>regularization</br>-based re-ranking processes are also closely-related to our work [8].",
                "These techniques seek to maximize the agreement between scores of related documents by solving a constrained optimization problem.",
                "The maximization of consistency is equivalent to maximizing the Moran autocorrelation.",
                "Therefore, we believe that our work provides explanation for why <br>regularization</br>-based re-ranking works. 9.",
                "CONCLUSION We have presented a new method for predicting the performance of a retrieval ranking without any relevance judgments.",
                "We consider two cases.",
                "First, when making predictions in the absence of retrievals from other systems, our predictors demonstrate robust, strong correlations with average precision.",
                "This performance, combined with a simple implementation, makes our predictors, in particular, very attractive.",
                "We have demonstrated this improvement for many, diverse settings.",
                "To our knowledge, this is the first large scale examination of zero-judgment, single-retrieval performance prediction.",
                "Second, when provided retrievals from other systems, our extended methods demonstrate competitive performance with state of the art baselines.",
                "Our experiments also demonstrate the limits of the usefulness of our predictors when information from multiple runs is provided.",
                "Our results suggest two conclusions.",
                "First, our results could affect retrieval algorithm design.",
                "Retrieval algorithms designed to consider spatial autocorrelation will conform to the cluster hypothesis and improve performance.",
                "Second, our results could affect the design of minimal test collection algorithms.",
                "Much of the recent work in ranking systems sometimes ignores correlations between document labels and scores.",
                "We believe that these two directions could be rewarding given the theoretical and experimental evidence in this paper. 10.",
                "ACKNOWLEDGMENTS This work was supported in part by the Center for Intelligent Information Retrieval and in part by the Defense Advanced Research Projects Agency (DARPA) under contract number HR0011-06-C-0023.",
                "Any opinions, findings and conclusions or recommendations expressed in this material are the authors and do not necessarily reflect those of the sponsor.",
                "We thank Yun Zhou and Desislava Petkova for providing data and Andre Gauthier for technical assistance. 11.",
                "REFERENCES [1] J. Aslam and V. Pavlu.",
                "Query hardness estimation using jensen-shannon divergence among multiple scoring functions.",
                "In ECIR 2007: Proceedings of the 29th European Conference on Information Retrieval, 2007. [2] J.",
                "A. Aslam, V. Pavlu, and E. Yilmaz.",
                "A statistical method for system evaluation using incomplete judgments.",
                "In S. Dumais, E. N. Efthimiadis, D. Hawking, and K. Jarvelin, editors, Proceedings of the 29th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, pages 541-548.",
                "ACM Press, August 2006. [3] D. Carmel, E. Yom-Tov, A. Darlow, and D. Pelleg.",
                "What makes a query difficult?",
                "In SIGIR 06: Proceedings of the 29th annual international ACM SIGIR conference on Research and development in information retrieval, pages 390-397, New York, NY, USA, 2006.",
                "ACM Press. [4] B. Carterette, J. Allan, and R. Sitaraman.",
                "Minimal test collections for retrieval evaluation.",
                "In SIGIR 06: Proceedings of the 29th annual international ACM SIGIR conference on Research and development in information retrieval, pages 268-275, New York, NY, USA, 2006.",
                "ACM Press. [5] A. D. Cliff and J. K. Ord.",
                "Spatial Autocorrelation.",
                "Pion Ltd., 1973. [6] M. Connell, A. Feng, G. Kumaran, H. Raghavan, C. Shah, and J. Allan.",
                "Umass at tdt 2004.",
                "Technical Report CIIR Technical Report IR - 357, Department of Computer Science, University of Massachusetts, 2004. [7] S. Cronen-Townsend, Y. Zhou, and W. B. Croft.",
                "Precision prediction based on ranked list coherence.",
                "Inf.",
                "Retr., 9(6):723-755, 2006. [8] F. Diaz.",
                "Regularizing ad-hoc retrieval scores.",
                "In CIKM 05: Proceedings of the 14th ACM international conference on Information and knowledge management, pages 672-679, New York, NY, USA, 2005.",
                "ACM Press. [9] F. Diaz and R. Jones.",
                "Using temporal profiles of queries for precision prediction.",
                "In SIGIR 04: Proceedings of the 27th annual international ACM SIGIR conference on Research and development in information retrieval, pages 18-24, New York, NY, USA, 2004.",
                "ACM Press. [10] D. A. Griffith.",
                "Spatial Autocorrelation and Spatial Filtering.",
                "Springer Verlag, 2003. [11] B.",
                "He and I. Ounis.",
                "Inferring Query Performance Using Pre-retrieval Predictors.",
                "In The Eleventh Symposium on String Processing and Information Retrieval (SPIRE), 2004. [12] N. Jardine and C. J. V. Rijsbergen.",
                "The use of hierarchic clustering in information retrieval.",
                "Information Storage and Retrieval, 7:217-240, 1971. [13] D. Jensen and J. Neville.",
                "Linkage and autocorrelation cause feature selection bias in relational learning.",
                "In ICML 02: Proceedings of the Nineteenth International Conference on Machine Learning, pages 259-266, San Francisco, CA, USA, 2002.",
                "Morgan Kaufmann Publishers Inc. [14] O. Kurland and L. Lee.",
                "Corpus structure, language models, and ad-hoc information retrieval.",
                "In SIGIR 04: Proceedings of the 27th annual international conference on Research and development in information retrieval, pages 194-201, New York, NY, USA, 2004.",
                "ACM Press. [15] M. Montague and J.",
                "A. Aslam.",
                "Relevance score normalization for metasearch.",
                "In CIKM 01: Proceedings of the tenth international conference on Information and knowledge management, pages 427-433, New York, NY, USA, 2001.",
                "ACM Press. [16] T. Qin, T.-Y.",
                "Liu, X.-D. Zhang, Z. Chen, and W.-Y.",
                "Ma.",
                "A study of relevance propagation for web search.",
                "In SIGIR 05: Proceedings of the 28th annual international ACM SIGIR conference on Research and development in information retrieval, pages 408-415, New York, NY, USA, 2005.",
                "ACM Press. [17] I. Soboroff, C. Nicholas, and P. Cahan.",
                "Ranking retrieval systems without relevance judgments.",
                "In SIGIR 01: Proceedings of the 24th annual international ACM SIGIR conference on Research and development in information retrieval, pages 66-73, New York, NY, USA, 2001.",
                "ACM Press. [18] V. Vinay, I. J. Cox, N. Milic-Frayling, and K. Wood.",
                "On ranking the effectiveness of searches.",
                "In SIGIR 06: Proceedings of the 29th annual international ACM SIGIR conference on Research and development in information retrieval, pages 398-404, New York, NY, USA, 2006.",
                "ACM Press. [19] Y. Zhou and W. B. Croft.",
                "Ranking robustness: a novel framework to predict query performance.",
                "In CIKM 06: Proceedings of the 15th ACM international conference on Information and knowledge management, pages 567-574, New York, NY, USA, 2006.",
                "ACM Press."
            ],
            "original_annotated_samples": [
                "Finally, <br>regularization</br>-based re-ranking processes are also closely-related to our work [8].",
                "Therefore, we believe that our work provides explanation for why <br>regularization</br>-based re-ranking works. 9."
            ],
            "translated_annotated_samples": [
                "Finalmente, los procesos de reordenamiento basados en <br>regularización</br> también están estrechamente relacionados con nuestro trabajo [8].",
                "Por lo tanto, creemos que nuestro trabajo proporciona una explicación de por qué funciona el reordenamiento basado en <br>regularización</br>. 9."
            ],
            "translated_text": "Predicción del rendimiento utilizando autocorrelación espacial. Fernando Díaz. Centro de Recuperación de Información Inteligente. Departamento de Ciencias de la Computación. Universidad de Massachusetts Amherst, MA 01003. fdiaz@cs.umass.edu. RESUMEN La evaluación de sistemas de recuperación de información es una de las tareas fundamentales en la recuperación de información. Los problemas incluyen la incapacidad de etiquetar exhaustivamente todos los documentos sobre un tema, la falta de generalización a partir de un pequeño número de temas e incorporar la variabilidad de los sistemas de recuperación. Trabajos anteriores abordan la evaluación de sistemas, la clasificación de consultas por dificultad y la clasificación de recuperaciones individuales por rendimiento. Existen enfoques para el caso de pocos e incluso ningún juicio de relevancia. Nuestro enfoque está en la predicción del rendimiento sin juicios de las recuperaciones individuales. Una deficiencia común de las técnicas anteriores es la suposición de que las puntuaciones de los documentos y los juicios no están correlacionados. Si los documentos están incrustados en un espacio de alta dimensión (como a menudo lo están), podemos aplicar técnicas de análisis de datos espaciales para detectar correlaciones entre las puntuaciones de los documentos. Observamos que la baja correlación entre las puntuaciones de documentos temáticamente cercanos a menudo implica un bajo rendimiento en la recuperación. Cuando se compara con una línea base de última generación, demostramos que el análisis espacial de las puntuaciones de recuperación ofrece un rendimiento predictivo significativamente mejor. Estos nuevos predictores también pueden ser incorporados con predictores clásicos para mejorar aún más el rendimiento. También describimos el primer experimento a gran escala para evaluar la predicción de rendimiento sin juicio para un gran número de sistemas de recuperación en una variedad de colecciones en varios idiomas. Categorías y Descriptores de Asignaturas H.3.3 [Búsqueda y Recuperación de Información]: Modelos de recuperación; H.3.4 [Sistemas y Software]: Evaluación del rendimiento (eficiencia y efectividad) Términos Generales Rendimiento, Diseño, Confiabilidad, Experimentación 1. En la recuperación de información, un usuario plantea una consulta a un sistema. El sistema recupera n documentos, cada uno recibiendo una puntuación de valor real que indica el grado de relevancia predicho. Si seleccionamos aleatoriamente pares de documentos de este conjunto, esperamos que algunos pares compartan el mismo tema y otros pares no compartan el mismo tema. Toma dos documentos relacionados entre sí del conjunto y llámalos a y b. Si las puntuaciones de a y b son muy diferentes, podríamos estar preocupados por el rendimiento de nuestro sistema. Es decir, si tanto a como b están relacionados con el tema de la consulta, nos gustaría que ambos reciban una puntuación alta; si a y b no están relacionados con el tema de la consulta, nos gustaría que ambos reciban una puntuación baja. Podríamos preocuparnos más a medida que encontramos más diferencias entre las puntuaciones de documentos relacionados. Estaríamos más cómodos con una recuperación en la que las puntuaciones sean consistentes entre documentos relacionados. Nuestro artículo estudia la cuantificación de esta inconsistencia en una recuperación desde una perspectiva espacial. El análisis espacial es apropiado ya que muchos modelos de recuperación incrustan documentos en algún espacio vectorial. Si los documentos están incrustados en un espacio, la proximidad se correlaciona con las relaciones temáticas. La consistencia de la puntuación puede medirse mediante la versión espacial de la autocorrelación conocida como el coeficiente de Moran o IM [5, 10]. En este artículo, demostramos una fuerte correlación entre IM y el rendimiento de recuperación. La discusión hasta este punto recuerda a la hipótesis del cúmulo. La hipótesis del clúster establece que los documentos estrechamente relacionados tienden a ser relevantes para la misma solicitud [12]. Como veremos, una función de recuperación de medidas de autocorrelación espacial mide el grado en que los documentos relacionados reciben puntuaciones similares. Debido a esto, interpretamos la autocorrelación como la medida del grado en que una función de recuperación satisface la hipótesis de agrupamiento. Si esta conexión es razonable, en la Sección 6 presentamos evidencia de que la falta de cumplimiento de la hipótesis de agrupamiento se correlaciona fuertemente con un bajo rendimiento. En este trabajo, proporcionamos las siguientes contribuciones: 1. Un método general y robusto para predecir el rendimiento de recuperaciones sin juicios de relevancia (Sección 3). 2. Un tratamiento teórico de las similitudes y motivaciones detrás de varias técnicas de predicción de rendimiento de vanguardia (Sección 4). 3. Las primeras experimentaciones a gran escala de predicción de rendimiento de una sola ejecución sin juicio (Secciones 5 y 6). 2. Dada una consulta, un sistema de recuperación de información produce una clasificación de documentos en la colección codificada como un conjunto de puntuaciones asociadas con los documentos. Nos referimos al conjunto de puntuaciones para una combinación particular de consulta-sistema como una recuperación. Nos gustaría predecir el rendimiento de esta recuperación con respecto a alguna medida de evaluación (por ejemplo, precisión promedio). En este artículo, presentamos resultados para clasificar recuperaciones de sistemas arbitrarios. Nos gustaría que este ranking se aproximara al ranking de recuperaciones según la medida de evaluación. Esto es diferente de clasificar las consultas por el rendimiento promedio en cada consulta. También es diferente de los sistemas de clasificación por el rendimiento promedio en un conjunto de consultas. Las puntuaciones a menudo solo se calculan para los primeros n documentos de la colección. Colocamos estos puntajes en el vector de longitud n, y, donde yi se refiere al puntaje del documento clasificado en la posición i. Ajustamos las puntuaciones para que tengan una media de cero y una varianza unitaria. Utilizamos este método debido a su simplicidad y su éxito en trabajos anteriores [15]. CORRELACIÓN ESPACIAL En la recuperación de información, a menudo asumimos que las representaciones de los documentos existen en algún espacio vectorial de alta dimensión. Por ejemplo, dado un vocabulario, V, este espacio vectorial puede ser un espacio arbitrario de dimensión |V| con producto interno de coseno o un simplejo multinomial con una medida de distancia basada en distribución. Un espacio de incrustación suele ser seleccionado para respetar la proximidad temática; si dos documentos están cerca, es más probable que compartan un tema. Debido a la prevalencia y éxito de los modelos espaciales de recuperación de información, creemos que la aplicación de técnicas de análisis de datos espaciales es apropiada. Mientras que en la recuperación de información nos preocupa la puntuación en un punto en el espacio, en el análisis de datos espaciales nos preocupa el valor de una función en un punto o ubicación en el espacio. Utilizamos el término función aquí para referirnos a una asignación de una ubicación a un valor real. Por ejemplo, podríamos estar interesados en la prevalencia de una enfermedad en el vecindario de alguna ciudad. La función asignaría la ubicación de un vecindario a una tasa de infección. Si queremos cuantificar las dependencias espaciales de una función, emplearíamos una medida conocida como la autocorrelación espacial [5, 10]. Una alta autocorrelación espacial sugiere que conocer el valor de una función en la ubicación a nos dirá mucho sobre el valor en una ubicación vecina b. Existe una alta autocorrelación espacial para una función que representa la temperatura de una ubicación, ya que saber la temperatura en una ubicación a nos dirá mucho sobre la temperatura en una ubicación vecina b. La baja autocorrelación espacial sugiere que conocer el valor de una función en la ubicación a nos dice poco sobre el valor en una ubicación vecina b. Hay una baja autocorrelación espacial en una función que mide el resultado de lanzar una moneda en a y b. En esta sección, comenzaremos describiendo lo que entendemos por proximidad espacial para documentos y luego definiremos una medida de autocorrelación espacial. Concluimos extendiendo este modelo para incluir información de múltiples recuperaciones de múltiples sistemas para una sola consulta. 3.1 Representación Espacial de Documentos Nuestro trabajo no se centra en mejorar una medida de similitud específica o definir un espacio vectorial novedoso. En cambio, elegimos un producto interno conocido por ser efectivo en la detección de relaciones temáticas entre documentos. Específicamente, adoptamos vectores de documentos tf.idf, ˜di = di log „ (n + 0.5) − ci 0.5 + ci « (1) donde d es un vector de frecuencias de términos, c es el vector de frecuencia de documentos de longitud |V|. Utilizamos este esquema de ponderación debido a su éxito en la detección de enlaces temáticos en el contexto de las evaluaciones de Detección y Seguimiento de Temas (TDT) [6]. Suponiendo que los vectores están escalados por su norma L2, usamos el producto interno, ˜di, ˜dj, para definir la similitud. Dado un conjunto de documentos y alguna medida de similitud, podemos construir una matriz que codifica la similitud entre pares de documentos. Recuerde que se nos dan los primeros n documentos recuperados en y. Podemos calcular una matriz de similitud n × n, W. Un elemento de esta matriz, Wij, representa la similitud entre los documentos clasificados i y j. En la práctica, solo incluimos las afinidades para los k vecinos más cercanos de un documento. En todos nuestros experimentos, hemos fijado k en 5. Dejamos la exploración de la sensibilidad de los parámetros para trabajos futuros. También normalizamos por filas la matriz para que Pn j=1 Wij = 1 para todos los i. 3.2 Autocorrelación Espacial de una Recuperación Recuerde que estamos interesados en medir la similitud entre las puntuaciones de documentos cercanos espacialmente. Una medida adecuada es el coeficiente de Moran de autocorrelación espacial. Suponiendo la función y sobre n ubicaciones, esto se define como ˜IM = n eTWe P i,j Wijyiyj P i y2 i = n eTWe yT Wy yTy (2) donde eT We = P ij Wij. Nos gustaría comparar los valores de autocorrelación para diferentes recuperaciones. Desafortunadamente, el límite para la Ecuación 2 no es consistente para diferentes valores de W y y. Por lo tanto, utilizamos la desigualdad de Cauchy-Schwartz para establecer un límite, ˜IM ≤ n eTWe s yTWTWy yTy Y definimos la autocorrelación espacial normalizada como IM = yT Wy p yTy × yTWTWy. Nótese que si dejamos ˜y = Wy, entonces podemos escribir esta fórmula como, IM = yT ˜y y 2 ˜y 2 (3) lo cual puede interpretarse como la correlación entre las puntuaciones originales de recuperación y un conjunto de puntuaciones de recuperación difundidas en el espacio. Presentamos algunos ejemplos de autocorrelaciones de funciones en una cuadrícula en la Figura 1. 3.3 Correlación con Otros Recuperos A veces estamos interesados en el rendimiento de un solo recuperación pero tenemos acceso a puntajes de múltiples sistemas para (a) IM = 0.006 (b) IM = 0.241 (c) IM = 0.487 Figura 1: El coeficiente de Moran, IM para varias funciones binarias en una cuadrícula. El coeficiente de Moran es una medida local de consistencia de la función. Desde la perspectiva de la recuperación de información, cada uno de estos espacios de la cuadrícula representaría un documento y los documentos estarían organizados de manera que se encuentren junto a documentos relacionados temáticamente. Las puntuaciones de recuperación binaria definirían un patrón en esta cuadrícula. Ten en cuenta que, a medida que el coeficiente de Moran aumenta, las celdas vecinas tienden a tener valores similares. En esta situación, podemos utilizar la información combinada de estas puntuaciones para construir un sustituto de una clasificación de alta calidad [17]. Podemos tratar la correlación entre la recuperación que nos interesa y las puntuaciones combinadas como un predictor del rendimiento. Supongamos que se nos dan m funciones de puntuación, yi, para los mismos n documentos. Representaremos la media de estos vectores como yµ = Σm i=1 yi. Utilizamos el vector medio como una aproximación a la relevancia. Dado que utilizamos normalización de media cero y varianza unitaria, el trabajo en metabusqueda sugiere que esta suposición está justificada [15]. Dado que yµ representa una recuperación muy buena, hipotetizamos que una similitud fuerte entre yµ e y correlacionará positivamente con el rendimiento del sistema. Utilizamos la correlación de Pearson para medir la similitud entre estos vectores, ρ(y, yµ) = yT yµ y 2 yµ 2 (4). Comentaremos sobre la similitud entre la Ecuación 3 y 4 en la Sección 7. Por supuesto, podemos combinar ρ(y, ˜y) y ρ(y, yµ) si asumimos que capturan diferentes factores en la predicción. Una forma de lograr esto es combinar estos predictores como variables independientes en una regresión lineal. Se sugiere un medio alternativo de combinación basado en la forma matemática de nuestros predictores. Dado que ˜y codifica las dependencias espaciales en y y yµ codifica las propiedades espaciales de las múltiples ejecuciones, podemos calcular una tercera correlación entre estos dos vectores, ρ(˜y, yµ) = ˜yT yµ ˜y 2 yµ 2 (5). Podemos interpretar la Ecuación 5 como la medición de la correlación entre un ranking de alta calidad (yµ) y una versión suavizada espacialmente de la recuperación (˜y). 4. RELACIÓN CON OTROS PREDICTORES Una forma de predecir la efectividad de una recuperación es observar el vocabulario compartido de los n documentos principales recuperados. Si calculáramos las palabras de contenido más frecuentes en este conjunto, esperaríamos que fueran coherentes con nuestro tema. De hecho, podríamos creer que una mala recuperación incluiría documentos sobre muchos temas dispares, lo que resultaría en una superposición de ruido terminológico. La claridad de una consulta intenta cuantificar exactamente esto [7]. Específicamente, la Claridad mide la similitud de las palabras más frecuentemente utilizadas en los documentos recuperados con aquellas más frecuentemente utilizadas en todo el corpus. La conjetura es que una buena recuperación utilizará un lenguaje distinto al del texto general; el lenguaje superpuesto en una mala recuperación tenderá a ser más similar al texto general. Matemáticamente, podemos calcular una representación del lenguaje utilizado en la recuperación inicial como una combinación ponderada de modelos de lenguaje de documentos, P(w|θQ) = Σ i=1 P(w|θi) P(Q|θi) Z (6) donde θi es el modelo de lenguaje del documento clasificado en la posición i, P(Q|θi) es la puntuación de probabilidad de la consulta del documento clasificado en la posición i y Z = Σ i=1 P(Q|θi) es una constante de normalización. La similitud entre el multinomial P(w|θQ) y un modelo de texto general se puede calcular utilizando la divergencia de Kullback-Leibler, DV KL(θQ θC). Aquí, la distribución P(w|θC) es nuestro modelo de texto general que puede ser calculado utilizando las frecuencias de términos en el corpus. En la Figura 2a, presentamos la Claridad como la medida de la distancia entre el centro de masa ponderado de la recuperación (etiquetado como y) y el centro de masa no ponderado de la colección (etiquetado como O). La claridad alcanza un mínimo cuando una recuperación asigna a cada documento la misma puntuación. Volvamos a asumir que tenemos un conjunto de n documentos recuperados para nuestra consulta. Otra forma de cuantificar la dispersión de un conjunto de documentos es observar qué tan agrupados están. Podemos hipotetizar que una buena recuperación devolverá un único y compacto grupo. Una recuperación de bajo rendimiento devolverá un conjunto de documentos poco relacionados que abarcan muchos temas. Un método propuesto para cuantificar esta dispersión es medir la distancia desde un documento aleatorio a su vecino más cercano, b. Una recuperación que esté estrechamente agrupada, en promedio, tendrá una distancia baja entre a y b; una recuperación que esté menos cerrada tendrá, en promedio, distancias altas entre a y b. Este promedio corresponde al uso de la estadística de Cox-Lewis para medir la aleatoriedad de los primeros n documentos recuperados de un sistema [18]. En la Figura 2a, esto es aproximadamente equivalente a medir el área del conjunto n. Observa que estamos descartando información sobre la función de recuperación y. Por lo tanto, la estadística de Cox-Lewis depende en gran medida de la selección de los primeros n documentos. Recuerda que tenemos n documentos y un conjunto de puntuaciones. Supongamos que tenemos acceso al sistema que proporcionó las puntuaciones originales y que también podemos solicitar puntuaciones para nuevos documentos. Esto sugiere un tercer método para predecir el rendimiento. Toma algún documento, a, del conjunto recuperado y agrega o elimina palabras al azar de forma arbitraria para crear un nuevo documento ˜a. Ahora, podemos pedirle a nuestro sistema que puntúe ˜a con respecto a nuestra consulta. Si, en promedio, a lo largo de los n documentos, las puntuaciones de a y ˜a tienden a ser muy diferentes, podríamos sospechar que el sistema está fallando en esta consulta. Los autores han sugerido acoplar la consulta con la medida de distancia [18]. La información introducida por la consulta, sin embargo, es independiente de la recuperación, de modo que, si dos recuperaciones devuelven el mismo conjunto de documentos, la estadística aproximada de Cox-Lewis será la misma independientemente de las puntuaciones de recuperación. yOy (a) Divergencia Global µ(y)˜y y (b) Perturbación de Puntuación µ(y) y (c) Promedio de Múltiples Ejecuciones Figura 2: Representación de varios predictores de rendimiento en una cuadrícula. En la Figura 2a, representamos los predictores que miden la divergencia entre el centro de masa de una recuperación y el centro del espacio de incrustación. En la Figura 2b, representamos los predictores que comparan la recuperación original, y, con una versión perturbada de la recuperación, ˜y. Nuestro enfoque utiliza un tipo particular de perturbación basado en la difusión de puntajes. Finalmente, en la Figura 2c, representamos la predicción cuando se proporcionan recuperaciones de varios otros sistemas en la misma consulta. Aquí, podemos considerar la fusión de estas recuperaciones como un sustituto de la relevancia. Esto se puede lograr ya sea perturbando los documentos o las consultas. La similitud entre los dos recuperos se puede medir utilizando alguna medida de correlación. Esto se muestra en la Figura 2b. La cuadrícula superior representa la recuperación original, y, mientras que la cuadrícula inferior representa la función después de haber sido perturbada, ˜y. La naturaleza del proceso de perturbación requiere puntuaciones o recuperaciones adicionales. Nuestro predictor no requiere acceso a la función de puntuación original ni a recuperaciones adicionales. Por lo tanto, aunque nuestro método es similar a otros métodos de perturbación en espíritu, se puede aplicar en situaciones en las que el sistema de recuperación es inaccesible o costoso de acceder. Finalmente, supongamos que tenemos, además de la recuperación que queremos evaluar, m recuperaciones de una variedad de sistemas diferentes. En este caso, podríamos tomar un documento a, comparar su rango en la recuperación con su rango promedio en los m recuperos. Si creemos que las m recuperaciones proporcionan una aproximación satisfactoria a la relevancia, entonces una diferencia muy grande en el rango sugeriría que nuestra recuperación está clasificando incorrectamente a. Si esta diferencia es grande en promedio en todos los n documentos, entonces podríamos predecir que la recuperación es mala. Si, por otro lado, la recuperación es muy consistente con las m recuperaciones, entonces podríamos predecir que la recuperación es buena. La similitud entre la recuperación y la recuperación combinada puede calcularse utilizando alguna medida de correlación. Esto se muestra en la Figura 2c. En trabajos anteriores, la divergencia de Kullback-Leibler entre las puntuaciones normalizadas de la recuperación y las puntuaciones normalizadas de la recuperación combinada proporciona la similitud [1]. 5. Nuestros experimentos se centran en probar el poder predictivo de cada uno de nuestros predictores: ρ(y, ˜y), ρ(y, yµ) y ρ(˜y, yµ). Como se indica en la Sección 2, estamos interesados en predecir el rendimiento de la recuperación generada por un sistema arbitrario. Nuestra metodología es consistente con investigaciones previas en el sentido de que predecimos el rendimiento relativo de una recuperación al comparar una clasificación basada en nuestro predictor con una clasificación basada en la precisión promedio. Presentamos los resultados de dos conjuntos de experimentos. El primer conjunto de experimentos presenta comparaciones detalladas de nuestros predictores con predictores previamente propuestos utilizando conjuntos de datos idénticos. Nuestro segundo conjunto de experimentos demuestra la generalizabilidad de nuestro enfoque a métodos de recuperación arbitrarios, tipos de corpus y lenguajes de corpus. 5.1 Experimentos Detallados En estos experimentos, predeciremos el rendimiento de los puntajes de modelado de lenguaje utilizando nuestro predictor de autocorrelación, ρ(y, ˜y); no consideramos ρ(y, yµ) o ρ(˜y, yµ) porque, en estos experimentos detallados, nos enfocamos en clasificar las recuperaciones de un solo sistema. Utilizamos recuperaciones, valores de predictores de referencia y medidas de evaluación reportadas en trabajos anteriores [19]. 5.1.1 Temas y Colecciones Estos experimentos de predicción de rendimiento utilizan recuperaciones de modelos de lenguaje realizadas para consultas asociadas con colecciones en las corpora de TREC. El uso de las colecciones TREC nos permite asociar con confianza una precisión promedio con una recuperación. En estos experimentos, utilizamos las siguientes colecciones de temas: TREC 4 ad-hoc, TREC 5 ad-hoc, Robust 2004, Terabyte 2004 y Terabyte 2005. 5.1.2 Baselines Proporcionamos dos líneas base. Nuestro primer punto de referencia es el predictor clásico de Claridad presentado en la Ecuación 6. La claridad está diseñada para ser utilizada con sistemas de modelado de lenguaje. Nuestro segundo punto de referencia es el predictor de robustez de clasificación de Zhou y Crofts. Este predictor corrompe los k documentos principales de la recuperación y vuelve a calcular las puntuaciones del modelo de lenguaje para estos documentos corruptos. El valor del predictor es la correlación de rangos de Spearman entre la clasificación original y la clasificación corrupta. En nuestras tablas, etiquetaremos los resultados para Claridad utilizando DV KL y el predictor de robustez de clasificación utilizando P. 5.2 Experimentos de Generalizabilidad Nuestros predictores no requieren un sistema de recuperación base particular; los predictores pueden calcularse para una recuperación arbitraria, independientemente de cómo se generaron los puntajes. Creemos que ese es uno de los aspectos más atractivos de nuestro algoritmo. Por lo tanto, en un segundo conjunto de experimentos, demostramos la capacidad de nuestras técnicas para generalizar a una variedad de colecciones, temas y sistemas de recuperación. 5.2.1 Temas y Colecciones Recopilamos un conjunto diverso de colecciones de todos los corpus posibles de TREC. Lanzamos una red amplia para localizar colecciones donde nuestros predictores podrían fallar. Nuestra hipótesis es que los documentos con alta similitud temática deberían tener puntuaciones correlacionadas. Por lo tanto, evitamos las colecciones donde las puntuaciones eran poco probables de estar correlacionadas (por ejemplo, preguntas y respuestas) o donde probablemente estuvieran negativamente correlacionadas (por ejemplo, novedad). Sin embargo, nuestras colecciones incluyen corpus donde las correlaciones están débilmente justificadas (por ejemplo, corpus no en inglés) o no justificadas en absoluto (por ejemplo, búsqueda de expertos). Utilizamos las pistas ad-hoc de TREC3-8, TREC Robust 2003-2005, TREC Terabyte 2004-2005, TREC4-5 en español, TREC5-6 en chino y TREC Enterprise Expert Search 2005. En todos los casos, solo utilizamos las ejecuciones automáticas para las pistas ad-hoc enviadas a NIST. Para todos los corpus en inglés y español, construimos la matriz W de acuerdo con el proceso descrito en la Sección 3.1. Para los corpus chinos, utilizamos vectores tf.idf basados en caracteres ingenuos. Para las entidades, las entradas en W son proporcionales al número de documentos en los que dos entidades coocurren. 5.2.2 Baselines En nuestros experimentos detallados, utilizamos la medida de Claridad como referencia. Dado que estamos prediciendo el rendimiento de recuperaciones que no se basan en modelado de lenguaje, utilizamos una versión de Claridad conocida como Claridad de lista clasificada [7]. La claridad de la lista clasificada convierte las clasificaciones de documentos en valores P(Q|θi). Esta conversión comienza reemplazando todas las puntuaciones en y con los rangos respectivos. Nuestra estimación de P(Q|θi) a partir de los rangos, entonces es, P(Q|θi) = ( 2(c+1−yi) c(c+1) si yi ≤ c 0 en otro caso donde c es un parámetro de corte. Como sugieren los autores, fijamos los parámetros del algoritmo c y λ2 de manera que c = 60 y λ2 = 0.10. Utilizamos la Ecuación 6 para estimar P(w|θQ) y DV KL(θQ θC) para calcular el valor del predictor. Nos referiremos a este predictor como DV KL, con superíndice V para indicar que la divergencia de Kullback-Leibler es con respecto al espacio de incrustación de términos. Cuando la información de múltiples ejecuciones de la misma consulta está disponible, utilizamos la divergencia multinomial en el espacio de documentos de Aslam y Pavlus como referencia [1]. Este método basado en rangos primero normaliza las puntuaciones en una recuperación como un multinomial n-dimensional. Al igual que con la Claridad de la lista clasificada, comenzamos reemplazando todas las puntuaciones en y con sus respectivas posiciones. Luego, ajustamos los elementos de y de la siguiente manera, ˆyi = 1 2n 0 @1 + nX k=yi 1 k 1 A (8) En nuestros experimentos de múltiples ejecuciones, solo utilizamos los 75 documentos principales de cada recuperación (n = 75); esto está dentro del rango de valores de parámetros sugeridos por los autores. Sin embargo, admitimos no haber ajustado este parámetro ni para nuestro sistema ni para la línea base. El predictor es la divergencia entre la distribución candidata, y, y la distribución media, yµ. Con la combinación lineal uniforme de estos m recuperaciones representadas como yµ, podemos calcular la divergencia como Dn KL(ˆy ˆyµ) donde usamos el superíndice n para indicar que la suma es sobre el conjunto de n documentos. Este punto de referencia fue desarrollado en el contexto de predecir la dificultad de la consulta, pero lo adoptamos como un punto de referencia razonable para predecir el rendimiento de la recuperación. 5.2.3 Configuración de parámetros Cuando se proporcionan múltiples recuperaciones, utilizamos documentos en la unión de los mejores k = 75 documentos de cada una de las m recuperaciones para esa consulta. Si el tamaño de esta unión es ˜n, entonces yµ y cada yi tiene una longitud de ˜n. En algunos casos, un sistema no puntuó un documento en la unión. Dado que estamos haciendo una suposición gaussiana sobre nuestras puntuaciones, podemos muestrear puntuaciones para estos documentos no vistos de la cola negativa de la distribución. Específicamente, muestreamos de la parte de la distribución inferior al valor mínimo en la recuperación normalizada. Esto introduce aleatoriedad en nuestro algoritmo, pero creemos que es más apropiado que asignar un valor fijo arbitrario. Optimizamos la regresión lineal utilizando la raíz cuadrada de cada predictor. Encontramos que esto mejoró sustancialmente los ajustes para todos los predictores, incluidos los basales. Consideramos combinaciones lineales de pares de predictores (etiquetados por los componentes) y todos los predictores (etiquetados como β). 5.3 Evaluación Dado un conjunto de recuperaciones, potencialmente de una combinación de consultas y sistemas, medimos la correlación del ordenamiento de rango de este conjunto por el predictor y por la métrica de rendimiento. Para garantizar la comparabilidad con los resultados anteriores, presentamos la correlación de Kendalls τ entre la clasificación de los predictores y la clasificación basada en la precisión promedio de la recuperación. A menos que se indique explícitamente, todas las correlaciones son significativas con p < 0.05. Los predictores a veces pueden tener un mejor rendimiento cuando se combinan linealmente [9, 11]. Aunque trabajos anteriores han presentado el coeficiente de determinación (R2) para medir la calidad de la regresión, esta medida no puede ser utilizada de manera confiable al comparar pequeñas mejoras al combinar predictores. Por lo tanto, adoptamos el coeficiente de determinación ajustado que penaliza los modelos con más variables. El R2 ajustado nos permite evaluar la mejora en la predicción lograda al agregar un parámetro pero pierde la interpretación estadística del R2. Utilizaremos τ de Kendall para evaluar la magnitud de la correlación y R2 ajustado para evaluar la combinación de variables. RESULTADOS Presentamos los resultados de nuestros experimentos detallados comparando la predicción de puntuaciones de modelos de lenguaje en la Tabla 1. Aunque la medida de Claridad está teóricamente diseñada para puntuaciones de modelos de lenguaje, consistentemente tiene un rendimiento inferior a nuestro predictor independiente del sistema. La robustez del ranking se presentó como una mejora a la Claridad para colecciones web (representadas en nuestros experimentos por las colecciones terabyte04 y terabyte05), desplazando la correlación τ de 0.139 a 0.150 para terabyte04 y de 0.171 a 0.208 para terabyte05. Sin embargo, estas mejoras son leves en comparación con el rendimiento de la autocorrelación en estas colecciones. Nuestro predictor logra una correlación τ de 0.454 para terabyte04 y 0.383 para terabyte05. Aunque no siempre es la más fuerte, la autocorrelación logra correlaciones competitivas con los predictores de referencia. Al examinar el rendimiento de las combinaciones lineales de predictores, observamos que en cada caso, los factores de autocorrelación son un componente necesario de un predictor sólido. También observamos que el R2 ajustado para las líneas de base individuales siempre mejora significativamente al incorporar la autocorrelación. Presentamos nuestros resultados de generalizabilidad en la Tabla 2. Comenzamos examinando la situación en la columna (a) donde se nos presenta una sola recuperación y ninguna información de recuperaciones adicionales. Para cada colección excepto una, logramos correlaciones significativamente mejores que la claridad de la lista clasificada. Sorprendentemente, logramos correlaciones relativamente fuertes para las colecciones en español y chino a pesar de nuestro procesamiento ingenuo. No tenemos una correlación de claridad de lista clasificada para ent05 porque la modelización de entidades es en sí misma una pregunta de investigación abierta. Sin embargo, nuestra medida de autocorrelación no logra altas correlaciones, quizás porque la relevancia para la recuperación de entidades no se propaga de acuerdo con los enlaces de coocurrencia que utilizamos. Como se señaló anteriormente, el bajo rendimiento de Claridad en datos web es consistente con nuestros hallazgos en los experimentos detallados. La claridad también tiene un rendimiento notablemente inferior en varios corpus de noticias (trec5, trec7 y robust04). Por otro lado, la autocorrelación parece ser robusta a los cambios entre diferentes corpora. A continuación, pasamos a la introducción de información de múltiples recuperaciones. Comparamos las correlaciones entre aquellos predictores que no utilizan esta información en la columna (a) y aquellos que sí lo hacen en la columna (b). Para cada colección, los predictores en la columna (b) superan a los predictores en la columna (a), lo que indica que la información de ejecuciones adicionales puede ser crítica para hacer buenas predicciones. Inspeccionando los predictores en la columna (b), solo podemos sacar conclusiones débiles. Nuestros nuevos predictores tienden a tener un mejor rendimiento en corpora de noticias. Y entre nuestros nuevos predictores, el predictor híbrido ρ(˜y, yµ) tiende a tener un mejor rendimiento. Recuerde que nuestra medida ρ(˜y, yµ) incorpora tanto información espacial como de múltiples recuperaciones. Por lo tanto, creemos que la mejora en la correlación es el resultado de incorporar información del comportamiento espacial. En la columna (c), podemos investigar la utilidad de incorporar información espacial con información de múltiples recuperaciones. Observa que en los casos donde la autocorrelación, ρ(y, ˜y), por sí sola funciona bien (trec3, trec5-spanish y trec6-chinese), se mejora sustancialmente al incorporar información de múltiples recuperaciones de ρ(y, yµ) en la regresión lineal, β. En los casos en los que ρ(y, yµ) funciona bien, la incorporación de la autocorrelación rara vez resulta en una mejora significativa en el rendimiento. De hecho, en cada caso en el que nuestro predictor supera al valor de referencia, incluye información de múltiples ejecuciones. 7. DISCUSIÓN El resultado más importante de nuestros experimentos implica la predicción cuando no hay información disponible de múltiples ejecuciones (Tablas 1 y 2a). Esta situación surge a menudo en el diseño de sistemas. Por ejemplo, un sistema puede necesitar, en el momento de la recuperación, evaluar su rendimiento antes de decidir llevar a cabo un procesamiento más intensivo como la retroalimentación de pseudo relevancia o la interacción. Suponiendo que la presencia de múltiples recuperaciones es irrealista en este caso. Creemos que la autocorrelación, al igual que los algoritmos de recuperación múltiple, aproxima un buen ranking; en este caso mediante la difusión de puntajes. ¿Por qué es ˜y un sustituto razonable? Sabemos que la difusión de puntuaciones en el grafo web y en los grafos de modelos de lenguaje mejora el rendimiento [14, 16]. Por lo tanto, si la difusión de puntuaciones tiende, en general, a mejorar el rendimiento, entonces las puntuaciones difusas proporcionarán, en general, un buen sustituto de la relevancia. Nuestros resultados demuestran que esta aproximación no es tan potente como la información de múltiples recuperaciones. Sin embargo, en situaciones donde esta información falta, la autocorrelación proporciona información sustancial. El éxito de la autocorrelación como predictor también puede tener sus raíces en la hipótesis de agrupamiento. Recuerde que consideramos la autocorrelación como el grado en que una recuperación satisface la hipótesis de agrupamiento. Nuestros experimentos, entonces, demuestran que una falta de respeto a la hipótesis de agrupamiento se correlaciona con un bajo rendimiento. ¿Por qué los sistemas podrían no cumplir con la hipótesis del clúster? Los sistemas de recuperación de información basados en consultas a menudo puntúan los documentos de forma independiente. El puntaje del documento a puede ser calculado examinando las coincidencias de términos o frases de la consulta, la longitud del documento y quizás las estadísticas globales de la colección. Una vez calculado, un sistema rara vez compara la puntuación de un documento a con la puntuación de un documento relacionado temáticamente b. Con algunas excepciones, la correlación de las puntuaciones de los documentos ha sido ampliamente ignorada. Debemos dejar claro que hemos seleccionado tareas donde la autocorrelación temática es apropiada. Ciertamente hay casos en los que no hay motivo para creer que las puntuaciones de recuperación tendrán autocorrelación temática. Por ejemplo, las listas clasificadas que incorporan novedad de documentos no deben mostrar autocorrelación espacial; si acaso, la autocorrelación debería ser negativa para esta tarea. Del mismo modo, los candidatos de respuestas en una tarea de pregunta-respuesta pueden o no mostrar autocorrelación; en este caso, la semántica de los enlaces también es cuestionable. Es importante antes de aplicar esta medida confirmar que, dada la semántica para algún enlace entre dos elementos recuperados, deberíamos esperar una correlación entre las puntuaciones. 8. TRABAJO RELACIONADO En esta sección realizamos comparaciones más generales con otros trabajos en predicción de rendimiento y análisis de datos espaciales. Existe un creciente cuerpo de trabajo que intenta predecir el rendimiento de recuperaciones individuales [7, 3, 11, 9, 19]. Hemos intentado situar nuestro trabajo en el contexto de gran parte de este trabajo en la Sección 4. Sin embargo, una comparación completa está fuera del alcance de este documento. Sin embargo, cabe destacar que nuestros experimentos abarcan un conjunto más amplio y diverso de recuperaciones, colecciones y temas que los examinados previamente. Gran parte del trabajo previo, especialmente en el contexto de TREC, se centra en predecir el rendimiento de los sistemas. Aquí, cada sistema genera k recuperaciones. La tarea consiste en, dadas estas recuperaciones, predecir la clasificación de los sistemas según alguna medida de rendimiento. Varios artículos intentan abordar esta tarea bajo la restricción de pocas evaluaciones [2, 4]. Algunos trabajos incluso intentan utilizar cero juicios aprovechando múltiples recuperaciones para la misma consulta [17]. Nuestra tarea difiere porque nos enfocamos en clasificar recuperaciones independientemente del sistema generador. La tarea aquí no es probar que el sistema A es superior al sistema B, sino probar que la recuperación A es superior a la recuperación B. La autocorrelación se manifiesta en muchas tareas de clasificación. Neville y Jensen definen la autocorrelación relacional para problemas de aprendizaje relacional y demuestran que muchas tareas de clasificación manifiestan autocorrelación [13]. La autocorrelación temporal de las recuperaciones iniciales también se ha utilizado para predecir el rendimiento [9]. Sin embargo, la autocorrelación temporal se realiza proyectando la función de recuperación en el espacio de incrustación temporal. En nuestro trabajo, nos enfocamos en el comportamiento de la función sobre las relaciones entre documentos. τ ajustado R2 DV KL P ρ(y, ˜y) DV KL P ρ(y, ˜y) DV KL, P DV KL, ρ(y, ˜y) Pρ(y, ˜y) β trec4 0.353 0.548 0.513 0.168 0.363 0.422 0.466 0.420 0.557 0.553 trec5 0.311 0.329 0.357 0.116 0.190 0.236 0.238 0.244 0.266 0.269 robust04 0.418 0.398 0.373 0.256 0.304 0.278 0.403 0.373 0.402 0.442 terabyte04 0.139 0.150 0.454 0.059 0.045 0.292 0.076 0.293 0.289 0.284 terabyte05 0.171 0.208 0.383 0.022 0.072 0.193 0.120 0.225 0.218 0.257 Tabla 1: Comparación de medidas de robustez y claridad para puntuaciones de modelos de lenguaje. La evaluación replica experimentos de [19]. Presentamos las correlaciones entre la medida clásica de Claridad (DV KL), la medida de robustez de clasificación (P) y la autocorrelación (ρ(y, ˜y)) cada una con la precisión media promedio en términos de τ de Kendall. El coeficiente de determinación ajustado se presenta para medir la efectividad de combinar predictores. Las medidas en negrita representan la correlación más fuerte para ese par de prueba/colección. múltiples ejecuciones (a) (b) (c) τ τ ajustado R2 DKL ρ(y, ˜y) Dn KL ρ(y, yµ) ρ(˜y, yµ) Dn KL ρ(y, ˜y) ρ(y, yµ) ρ(˜y, yµ) β trec3 0.201 0.461 0.461 0.439 0.456 0.444 0.395 0.394 0.386 0.498 trec4 0.252 0.396 0.455 0.482 0.489 0.379 0.263 0.429 0.482 0.483 trec5 0.016 0.277 0.433 0.459 0.393 0.280 0.157 0.375 0.323 0.386 trec6 0.230 0.227 0.352 0.428 0.418 0.203 0.089 0.323 0.325 0.325 trec7 0.083 0.326 0.341 0.430 0.483 0.264 0.182 0.363 0.442 0.400 trec8 0.235 0.396 0.454 0.508 0.567 0.402 0.272 0.490 0.580 0.523 robust03 0.302 0.354 0.377 0.385 0.447 0.269 0.206 0.274 0.392 0.303 robust04 0.183 0.308 0.301 0.384 0.453 0.200 0.182 0.301 0.393 0.335 robust05 0.224 0.249 0.371 0.377 0.404 0.341 0.108 0.313 0.328 0.336 terabyte04 0.043 0.245 0.544 0.420 0.392 0.516 0.105 0.357 0.343 0.365 terabyte05 0.068 0.306 0.480 0.434 0.390 0.491 0.168 0.384 0.309 0.403 trec4-spanish 0.307 0.388 0.488 0.398 0.395 0.423 0.299 0.282 0.299 0.388 trec5-spanish 0.220 0.458 0.446 0.484 0.475 0.411 0.398 0.428 0.437 0.529 trec5-chinese 0.092 0.199 0.367 0.379 0.384 0.379 0.199 0.273 0.276 0.310 trec6-chinese 0.144 0.276 0.265 0.353 0.376 0.115 0.128 0.188 0.223 0.199 ent05 - 0.181 0.324 0.305 0.282 0.211 0.043 0.158 0.155 0.179 Tabla 2: Experimentos de predicción a gran escala. Predecimos la clasificación de grandes conjuntos de recuperaciones para varias colecciones y sistemas de recuperación. Las correlaciones de τ de Kendall se calculan entre la clasificación predicha y una clasificación basada en la precisión promedio de las recuperaciones. En la columna (a), tenemos predictores que no utilizan información de otras recuperaciones para la misma consulta. En las columnas (b) y (c) presentamos el rendimiento de los predictores que incorporan información de múltiples recuperaciones. El coeficiente de determinación ajustado se calcula para determinar la efectividad de combinar predictores. Las medidas en negrita representan la correlación más fuerte para ese par de prueba/colección. Finalmente, los procesos de reordenamiento basados en <br>regularización</br> también están estrechamente relacionados con nuestro trabajo [8]. Estas técnicas buscan maximizar el acuerdo entre las puntuaciones de documentos relacionados al resolver un problema de optimización restringida. La maximización de la consistencia es equivalente a maximizar la autocorrelación de Moran. Por lo tanto, creemos que nuestro trabajo proporciona una explicación de por qué funciona el reordenamiento basado en <br>regularización</br>. 9. CONCLUSIÓN Hemos presentado un nuevo método para predecir el rendimiento de un ranking de recuperación sin necesidad de juicios de relevancia. Consideramos dos casos. Primero, al hacer predicciones en ausencia de recuperaciones de otros sistemas, nuestros predictores muestran correlaciones sólidas y robustas con la precisión promedio. Esta actuación, combinada con una implementación sencilla, hace que nuestros predictores, en particular, sean muy atractivos. Hemos demostrado esta mejora en muchos entornos diversos. Según nuestro conocimiento, esta es la primera evaluación a gran escala de la predicción del rendimiento de una sola recuperación sin juicio. Segundo, cuando se proporcionan recuperaciones de otros sistemas, nuestros métodos ampliados demuestran un rendimiento competitivo con las líneas de base de vanguardia. Nuestros experimentos también demuestran los límites de la utilidad de nuestros predictores cuando se proporciona información de múltiples ejecuciones. Nuestros resultados sugieren dos conclusiones. Primero, nuestros resultados podrían afectar el diseño de algoritmos de recuperación. Los algoritmos de recuperación diseñados para considerar la autocorrelación espacial se ajustarán a la hipótesis de agrupamiento y mejorarán el rendimiento. Segundo, nuestros resultados podrían afectar el diseño de algoritmos de colección de pruebas mínimas. Gran parte del trabajo reciente en sistemas de clasificación a veces ignora las correlaciones entre las etiquetas de los documentos y las puntuaciones. Creemos que estas dos direcciones podrían ser gratificantes dadas las pruebas teóricas y experimentales en este documento. 10. AGRADECIMIENTOS Este trabajo fue apoyado en parte por el Centro de Recuperación de Información Inteligente y en parte por la Agencia de Proyectos de Investigación Avanzada de Defensa (DARPA) bajo el número de contrato HR0011-06-C-0023. Cualquier opinión, hallazgo y conclusión o recomendación expresada en este material son del autor y no necesariamente reflejan las del patrocinador. Agradecemos a Yun Zhou y Desislava Petkova por proporcionar los datos y a Andre Gauthier por la asistencia técnica. 11. REFERENCIAS [1] J. Aslam y V. Pavlu. Estimación de la dificultad de la consulta utilizando la divergencia de Jensen-Shannon entre múltiples funciones de puntuación. En ECIR 2007: Actas de la 29ª Conferencia Europea sobre Recuperación de Información, 2007. [2] J. A. Aslam, V. Pavlu y E. Yilmaz. Un método estadístico para la evaluación de sistemas utilizando juicios incompletos. En S. Dumais, E. N. Efthimiadis, D. Hawking y K. Jarvelin, editores, Actas de la 29ª Conferencia Internacional Anual de ACM SIGIR sobre Investigación y Desarrollo en Recuperación de Información, páginas 541-548. ACM Press, agosto de 2006. [3] D. Carmel, E. Yom-Tov, A. Darlow y D. Pelleg. ¿Qué hace que una consulta sea difícil? En SIGIR 06: Actas de la 29ª conferencia internacional anual de ACM SIGIR sobre investigación y desarrollo en recuperación de información, páginas 390-397, Nueva York, NY, EE. UU., 2006. ACM Press. [4] B. Carterette, J. Allan y R. Sitaraman. Colecciones de prueba mínimas para evaluación de recuperación. En SIGIR 06: Actas de la 29ª conferencia internacional anual de ACM SIGIR sobre investigación y desarrollo en recuperación de información, páginas 268-275, Nueva York, NY, EE. UU., 2006. ACM Press. [5] A. D. Cliff y J. K. Ord. Autocorrelación espacial. Pion Ltd., 1973. [6] M. Connell, A. Feng, G. Kumaran, H. Raghavan, C. Shah y J. Allan. Umass en tdt 2004. Informe técnico CIIR Informe técnico IR - 357, Departamento de Ciencias de la Computación, Universidad de Massachusetts, 2004. [7] S. Cronen-Townsend, Y. Zhou y W. B. Croft. Predicción de precisión basada en la coherencia de la lista clasificada. I'm sorry, but the sentence \"Inf.\" is not a complete sentence. Could you please provide more context or a full sentence for me to translate to Spanish? Rev., 9(6):723-755, 2006. [8] F. Diaz. Normalizando las puntuaciones de recuperación ad-hoc. En CIKM 05: Actas de la 14ª conferencia internacional de ACM sobre gestión de la información y el conocimiento, páginas 672-679, Nueva York, NY, EE. UU., 2005. ACM Press. [9] F. Diaz y R. Jones. Utilizando perfiles temporales de consultas para predecir la precisión. En SIGIR 04: Actas de la 27ª conferencia internacional anual de ACM SIGIR sobre investigación y desarrollo en recuperación de información, páginas 18-24, Nueva York, NY, EE. UU., 2004. ACM Press. [10] D. A. Griffith. \n\nACM Press. [10] D. A. Griffith. Autocorrelación espacial y filtrado espacial. Springer Verlag, 2003. [11] B. \n\nSpringer Verlag, 2003. [11] B. Él y yo. Ounis. Inferir el rendimiento de la consulta utilizando predictores previos a la recuperación. En el Undécimo Simposio sobre Procesamiento de Cadenas y Recuperación de Información (SPIRE), 2004. [12] N. Jardine y C. J. V. Rijsbergen. El uso de agrupamiento jerárquico en la recuperación de información. Almacenamiento y recuperación de información, 7:217-240, 1971. [13] D. Jensen y J. Neville. El enlace y la autocorrelación causan sesgo en la selección de características en el aprendizaje relacional. En ICML 02: Actas de la Decimonovena Conferencia Internacional sobre Aprendizaje Automático, páginas 259-266, San Francisco, CA, EE. UU., 2002. Morgan Kaufmann Publishers Inc. [14] O. Kurland y L. Lee. Estructura del corpus, modelos de lenguaje y recuperación de información ad-hoc. En SIGIR 04: Actas de la 27ª conferencia internacional anual sobre investigación y desarrollo en recuperación de información, páginas 194-201, Nueva York, NY, EE. UU., 2004. ACM Press. [15] M. Montague y J. A. Aslam. Normalización de la puntuación de relevancia para metabusqueda. En CIKM 01: Actas de la décima conferencia internacional sobre gestión de la información y el conocimiento, páginas 427-433, Nueva York, NY, EE. UU., 2001. ACM Press. [16] T. Qin, T.-Y. Liu, X.-D. Zhang, Z. Chen y W.-Y. I'm sorry, but \"Ma.\" is not a complete sentence. Could you please provide more context or a complete sentence for me to translate into Spanish? Un estudio de propagación de relevancia para la búsqueda en la web. En SIGIR 05: Actas de la 28ª conferencia internacional anual de ACM SIGIR sobre investigación y desarrollo en recuperación de información, páginas 408-415, Nueva York, NY, EE. UU., 2005. ACM Press. [17] I. Soboroff, C. Nicholas y P. Cahan. Sistemas de recuperación de clasificación sin juicios de relevancia. En SIGIR 01: Actas de la 24ª conferencia internacional anual de ACM SIGIR sobre investigación y desarrollo en recuperación de información, páginas 66-73, Nueva York, NY, EE. UU., 2001. ACM Press. [18] V. Vinay, I. J. Cox, N. Milic-Frayling y K. Wood. Sobre la clasificación de la efectividad de las búsquedas. En SIGIR 06: Actas de la 29ª conferencia internacional anual de ACM SIGIR sobre investigación y desarrollo en recuperación de información, páginas 398-404, Nueva York, NY, EE. UU., 2006. ACM Press. [19] Y. Zhou y W. B. Croft. Robustez del ranking: un nuevo marco para predecir el rendimiento de la consulta. En CIKM 06: Actas de la 15ª conferencia internacional de ACM sobre gestión de la información y el conocimiento, páginas 567-574, Nueva York, NY, EE. UU., 2006. ACM Press. ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        }
    }
}