{
    "id": "C-80",
    "original_text": "Consistency-preserving Caching of Dynamic Database Content∗ Niraj Tolia and M. Satyanarayanan Carnegie Mellon University {ntolia,satya}@cs.cmu.edu ABSTRACT With the growing use of dynamic web content generated from relational databases, traditional caching solutions for throughput and latency improvements are ineffective. We describe a middleware layer called Ganesh that reduces the volume of data transmitted without semantic interpretation of queries or results. It achieves this reduction through the use of cryptographic hashing to detect similarities with previous results. These benefits do not require any compromise of the strict consistency semantics provided by the back-end database. Further, Ganesh does not require modifications to applications, web servers, or database servers, and works with closed-source applications and databases. Using two benchmarks representative of dynamic web sites, measurements of our prototype show that it can increase end-to-end throughput by as much as twofold for non-data intensive applications and by as much as tenfold for data intensive ones. Categories and Subject Descriptors C.2.4 [Computer-Communication Networks]: Distributed Systems; H.2.4 [Database Management]: Systems General Terms Design, Performance 1. INTRODUCTION An increasing fraction of web content is dynamically generated from back-end relational databases. Even when database content remains unchanged, temporal locality of access cannot be exploited because dynamic content is not cacheable by web browsers or by intermediate caching servers such as Akamai mirrors. In a multitiered architecture, each web request can stress the WAN link between the web server and the database. This causes user experience to be highly variable because there is no caching to insulate the client from bursty loads. Previous attempts in caching dynamic database content have generally weakened transactional semantics [3, 4] or required application modifications [15, 34]. We report on a new solution that takes the form of a databaseagnostic middleware layer called Ganesh. Ganesh makes no effort to semantically interpret the contents of queries or their results. Instead, it relies exclusively on cryptographic hashing to detect similarities with previous results. Hash-based similarity detection has seen increasing use in distributed file systems [26, 36, 37] for improving performance on low-bandwidth networks. However, these techniques have not been used for relational databases. Unlike previous approaches that use generic methods to detect similarity, Ganesh exploits the structure of relational database results to yield superior performance improvement. One faces at least three challenges in applying hash-based similarity detection to back-end databases. First, previous work in this space has traditionally viewed storage content as uninterpreted bags of bits with no internal structure. This allows hash-based techniques to operate on long, contiguous runs of data for maximum effectiveness. In contrast, relational databases have rich internal structure that may not be as amenable to hash-based similarity detection. Second, relational databases have very tight integrity and consistency constraints that must not be compromised by the use of hash-based techniques. Third, the source code of commercial databases is typically not available. This is in contrast to previous work which presumed availability of source code. Our experiments show that Ganesh, while conceptually simple, can improve performance significantly at bandwidths representative of todays commercial Internet. On benchmarks modeling multitiered web applications, the throughput improvement was as high as tenfold for data-intensive workloads. For workloads that were not data-intensive, throughput improvements of up to twofold were observed. Even when bandwidth was not a constraint, Ganesh had low overhead and did not hurt performance. Our experiments also confirm that exploiting the structure present in database results is crucial to this performance improvement. 2. BACKGROUND 2.1 Dynamic Content Generation As the World Wide Web has grown, many web sites have decentralized their data and functionality by pushing them to the edges of the Internet. Today, eBusiness systems often use a three-tiered architecture consisting of a front-end web server, an application server, and a back-end database server. Figure 1 illustrates this architecture. The first two tiers can be replicated close to a concentration of clients at the edge of the Internet. This improves user experience by lowering end-to-end latency and reducing exposure WWW 2007 / Track: Performance and Scalability Session: Scalable Systems for Dynamic Content 311 Back-End Database Server Front-End Web and Application Servers Figure 1: Multi-Tier Architecture to backbone traffic congestion. It can also increase the availability and scalability of web services. Content that is generated dynamically from the back-end database cannot be cached in the first two tiers. While databases can be easily replicated in a LAN, this is infeasible in a WAN because of the difficult task of simultaneously providing strong consistency, availability, and tolerance to network partitions [7]. As a result, databases tend to be centralized to meet the strong consistency requirements of many eBusiness applications such as banking, finance, and online retailing [38]. Thus, the back-end database is usually located far from many sets of first and second-tier nodes [2]. In the absence of both caching and replication, WAN bandwidth can easily become a limiting factor in the performance and scalability of data-intensive applications. 2.2 Hash-Based Systems Ganeshs focus is on efficient transmission of results by discovering similarities with the results of previous queries. As SQL queries can generate large results, hash-based techniques lend themselves well to the problem of efficiently transferring these large results across bandwidth constrained links. The use of hash-based techniques to reduce the volume of data transmitted has emerged as a common theme of many recent storage systems, as discussed in Section 8.2. These techniques rely on some basic assumptions. Cryptographic hash functions are assumed to be collision-resistant. In other words, it is computationally intractable to find two inputs that hash to the same output. The functions are also assumed to be one-way; that is, finding an input that results in a specific output is computationally infeasible. Menezes et al. [23] provide more details about these assumptions. The above assumptions allow hash-based systems to assume that collisions do not occur. Hence, they are able to treat the hash of a data item as its unique identifier. A collection of data items effectively becomes content-addressable, allowing a small hash to serve as a codeword for a much larger data item in permanent storage or network transmission. The assumption that collisions are so rare as to be effectively non-existent has recently come under fire [17]. However, as explained by Black [5], we believe that these issues do not form a concern for Ganesh. All communication is between trusted parts of the system and an adversary has no way to force Ganesh to accept invalid data. Further, Ganesh does not depend critically on any specific hash function. While we currently use SHA-1, replacing it with a different hash function would be simple. There would be no impact on performance as stronger hash functions (e.g. SHA256) only add a few extra bytes and the generated hashes are still orders of magnitude smaller than the data items they represent. No re-hashing of permanent storage is required since Ganesh only uses hashing on volatile data. 3. DESIGN AND IMPLEMENTATION Ganesh exploits redundancy in the result stream to avoid transmitting result fragments that are already present at the query site. Redundancy can arise naturally in many different ways. For example, a query repeated after a certain interval may return a different result because of updates to the database; however, there may be significant commonality between the two results. As another example, a user who is refining a search may generate a sequence of queries with overlapping results. When Ganesh detects redundancy, it suppresses transmission of the corresponding result fragments. Instead, it transmits a much smaller digest of those fragments and lets the query site reconstruct the result through hash lookup in a cache of previous results. In effect, Ganesh uses computation at the edges to reduce Internet communication. Our description of Ganesh focuses on four aspects. We first explain our approach to detecting similarity in query results. Next, we discuss how the Ganesh architecture is completely invisible to all components of a multi-tier system. We then describe Ganeshs proxy-based approach and the dataflow for detecting similarity. 3.1 Detecting Similarity One of the key design decisions in Ganesh is how similarity is detected. There are many potential ways to decompose a result into fragments. The optimal way is, of course, the one that results in the smallest possible object for transmission for a given querys results. Finding this optimal decomposition is a difficult problem because of the large space of possibilities and because the optimal choice depends on many factors such as the contents of the querys result, the history of recent results, and the cache management algorithm. When an object is opaque, the use of Rabin fingerprints [8, 30] to detect common data between two objects has been successfully shown in the past by systems such as LBFS [26] and CASPER [37]. Rabin fingerprinting uses a sliding window over the data to compute a rolling hash. Assuming that the hash function is uniformly distributed, a chunk boundary is defined whenever the lower order bits of the hash value equal some predetermined value. The number of lower order bits used defines the average chunk size. These sub-divided chunks of the object become the unit of comparison for detecting similarity between different objects. As the locations of boundaries found by using Rabin fingerprints is stochastically determined, they usually fail to align with any structural properties of the underlying data. The algorithm therefore deals well with in-place updates, insertions and deletions. However, it performs poorly in the presence of any reordering of data. Figure 2 shows an example where two results, A and B, consisting of three rows, have the same data but have different sort attributes. In the extreme case, Rabin fingerprinting might be unable to find any similar data due to the way it detects chunk boundaries. Fortunately, Ganesh can use domain specific knowledge for more precise boundary detection. The information we exploit is that a querys result reflects the structure of a relational database where all data is organized as tables and rows. It is therefore simple to check for similarity with previous results at two granularities: first the entire result, and then individual rows. The end of a row in a result serves as a natural chunk boundary. It is important to note that using the tabular structure in results only involves shallow interpretation of the data. Ganesh does not perform any deeper semantic interpretation such as understanding data types, result schema, or integrity constraints. Tuning Rabin fingerprinting for a workload can also be difficult. If the average chunk size is too large, chunks can span multiple result rows. However, selecting a smaller average chunk size increases the amount of metadata required to the describe the results. WWW 2007 / Track: Performance and Scalability Session: Scalable Systems for Dynamic Content 312 Figure 2: Rabin Fingerprinting vs. Ganeshs Chunking This, in turn, would decrease the savings obtained via its use. Rabin fingerprinting also needs two computationally-expensive passes over the data: once to determine chunk boundaries and one again to generate cryptographic hashes for the chunks. Ganesh only needs a single pass for hash generation as the chunk boundaries are provided by the datas natural structure. The performance comparison in Section 6 shows that Ganeshs row-based algorithm outperforms Rabin fingerprinting. Given that previous work has already shown that Rabin fingerprinting performs better than gzip [26], we do not compare Ganesh to compression algorithms in this paper. 3.2 Transparency The key factor influencing our design was the need for Ganesh to be completely transparent to all components of a typical eBusiness system: web servers, application servers, and database servers. Without this, Ganesh stands little chance of having a significant real-world impact. Requiring modifications to any of the above components would raise the barrier for entry of Ganesh into an existing system, and thus reduce its chances of adoption. Preserving transparency is simplified by the fact that Ganesh is purely a performance enhancement, not a functionality or usability enhancement. We chose agent interposition as the architectural approach to realizing our goal. This approach relies on the existence of a compact programming interface that is already widely used by target software. It also relies on a mechanism to easily add new code without disrupting existing module structure. These conditions are easily met in our context because of the popularity of Java as the programming language for eBusiness systems. The Java Database Connectivity (JDBC) API [32] allows Java applications to access a wide variety of databases and even other tabular data repositories such as flat files. Access to these data sources is provided by JDBC drivers that translate between the JDBC API and the database communication mechanism. Figure 3(a) shows how JDBC is typically used in an application. As the JDBC interface is standardized, one can substitute one JDBC driver for another without application modifications. The JDBC driver thus becomes the natural module to exploit for code interposition. As shown in Figure 3(b), the native JDBC driver is replaced with a Ganesh JDBC driver that presents the same standardized interface. The Ganesh driver maintains an in-memory cache of result fragments from previous queries and performs reassembly of results. At the database, we add a new process called the Ganesh proxy. This proxy, which can be shared by multiple front-end nodes, consists of two parts: code to detect similarity in result fragments and the original native JDBC driver that communicates with the database. The use of a proxy at the database makes Ganesh database-agnostic and simplifies prototyping and experimentation. Ganesh is thus able to work with a wide range of databases and applications, requiring no modifications to either. 3.3 Proxy-Based Caching The native JDBC driver shown in Figure 3(a) is a lightweight code component supplied by the database vendor. Its main funcClient Database Web and Application Server Native JDBC Driver WAN (a) Native Architecture Client Database Ganesh Proxy Native JDBC Driver WAN Web and Application Server Ganesh JDBC Driver (b) Ganeshs Interposition-based Architecture Figure 3: Native vs. Ganesh Architecture tion is to mediate communication between the application and the remote database. It forwards queries, buffers entire results, and responds to application requests to view parts of results. The Ganesh JDBC driver shown in Figure 3(b) presents the application with an interface identical to that provided by the native driver. It provides the ability to reconstruct results from compact hash-based descriptions sent by the proxy. To perform this reconstruction, the driver maintains an in-memory cache of recentlyreceived results. This cache is only used as a source of result fragments in reconstructing results. No attempt is made by the Ganesh driver or proxy to track database updates. The lack of cache consistency does not hurt correctness as a description of the results is always fetched from the proxy - at worst, there will be no performance benefit from using Ganesh. Stale data will simply be paged out of the cache over time. The Ganesh proxy accesses the database via the native JDBC driver, which remains unchanged between Figures 3(a) and (b). The database is thus completely unaware of the existence of the proxy. The proxy does not examine any queries received from the Ganesh driver but passes them to the native driver. Instead, the proxy is responsible for inspecting database output received from the native driver, detecting similar results, and generating hash-based encodings of these results whenever enough similarity is found. While this architecture does not decrease the load on a database, as mentioned earlier in Section 2.1, it is much easier to replicate databases for scalability in a LAN than in a WAN. To generate a hash-based encoding, the proxy must be aware of what result fragments are available in the Ganesh drivers cache. One approach is to be optimistic, and to assume that all result fragments are available. This will result in the smallest possible initial transmission of a result. However, in cases where there is little overlap with previous results, the Ganesh driver will have to make many calls to the proxy during reconstruction to fetch missing result fragments. To avoid this situation, the proxy loosely tracks the state of the Ganesh drivers cache. Since both components are under our control, it is relatively simple to do this without resorting to gray-box techniques or explicit communication for maintaining cache coherence. Instead, the proxy simulates the Ganesh drivers cache management algorithm and uses this to maintain a list of hashes for which the Ganesh driver is likely to possess the result fragments. In case of mistracking, there will be no loss of correctness but there will be extra round-trip delays to fetch the missing fragments. If the client detects loss of synchronization with the proxy, it can ask the proxy to reset the state shared between them. Also note that the proxy does not need to keep the result fragments themselves, only their hashes. This allows the proxy to remain scalable even when it is shared by many front-end nodes. WWW 2007 / Track: Performance and Scalability Session: Scalable Systems for Dynamic Content 313 Object Output Stream Convert ResultSet Object Input Stream Convert ResultSet All Data Recipe ResultSet All Data ResultSet Network Ganesh Proxy Ganesh JDBC Driver Result Set Recipe Result Set Yes Yes No No GaneshInputStream GaneshOutputStream Figure 4: Dataflow for Result Handling 3.4 Encoding and Decoding Results The Ganesh proxy receives database output as Java objects from the native JDBC driver. It examines this output to see if a Java object of type ResultSet is present. The JDBC interface uses this data type to store results of database queries. If a ResultSet object is found, it is shrunk as discussed below. All other Java objects are passed through unmodified. As discussed in Section 3.1, the proxy uses the row boundaries defined in the ResultSet to partition it into fragments consisting of single result rows. All ResultSet objects are converted into objects of a new type called RecipeResultSet. We use the term recipe for this compact description of a database result because of its similarity to a file recipe in the CASPER file system [37]. The conversion replaces each result fragment that is likely to be present in the Ganesh drivers cache by a SHA-1 hash of that fragment. Previously unseen result fragments are retained verbatim. The proxy also retains hashes for the new result fragments as they will be present in the drivers cache in the future. Note that the proxy only caches hashes for result fragments and does not cache recipes. The proxy constructs a RecipeResultSet by checking for similarity at the entire result and then the row level. If the entire result is predicted to be present in the Ganesh drivers cache, the RecipeResultSet is simply a single hash of the entire result. Otherwise, it contains hashes for those rows predicted to be present in that cache; all other rows are retained verbatim. If the proxy estimates an overall space savings, it will transmit the RecipeResultSet. Otherwise the original ResultSet is transmitted. The RecipeResultSet objects are transformed back into ResultSet objects by the Ganesh driver. Figure 4 illustrates ResultSet handling at both ends. Each SHA-1 hash found in a RecipeResultSet is looked up in the local cache of result fragments. On a hit, the hash is replaced by the corresponding fragment. On a miss, the driver contacts the Ganesh proxy to fetch the fragment. All previously unseen result fragments that were retained verbatim by the proxy are hashed and added to the result cache. There should be very few misses if the proxy has accurately tracked the Ganesh drivers cache state. A future optimization would be to batch the fetch of missing fragments. This would be valuable when there are many small missing fragments in a high-latency WAN. Once the transformation is complete, the fully reconstructed ResultSet object is passed up to the application. 4. EXPERIMENTAL VALIDATION Three questions follow from the goals and design of Ganesh: • First, can performance can be improved significantly by exploiting similarity across database results? Benchmark Dataset Details 500,000 Users, 12,000 Stories BBOARD 2.0 GB 3,298,000 Comments AUCTION 1.3 GB 1,000,000 Users, 34,000 Items Table 1: Benchmark Dataset Details • Second, how important is Ganeshs structural similarity detection relative to Rabin fingerprintings similarity detection? • Third, is the overhead of the proxy-based design acceptable? Our evaluation answers these question through controlled experiments with the Ganesh prototype. This section describes the benchmarks used, our evaluation procedure, and the experimental setup. Results of the experiments are presented in Sections 5, 6, and 7. 4.1 Benchmarks Our evaluation is based on two benchmarks [18] that have been widely used by other researchers to evaluate various aspects of multi-tier [27] and eBusiness architectures [9]. The first benchmark, BBOARD, is modeled after Slashdot, a technology-oriented news site. The second benchmark, AUCTION, is modeled after eBay, an online auction site. In both benchmarks, most content is dynamically generated from information stored in a database. Details of the datasets used can be found in Table 1. 4.1.1 The BBOARD Benchmark The BBOARD benchmark, also known as RUBBoS [18], models Slashdot, a popular technology-oriented web site. Slashdot aggregates links to news stories and other topics of interest found elsewhere on the web. The site also serves as a bulletin board by allowing users to comment on the posted stories in a threaded conversation form. It is not uncommon for a story to gather hundreds of comments in a matter of hours. The BBOARD benchmark is similar to the site and models the activities of a user, including readonly operations such as browsing the stories of the day, browsing story categories, and viewing comments as well as write operations such as new user registration, adding and moderating comments, and story submission. The benchmark consists of three different phases: a short warmup phase, a runtime phase representing the main body of the workload, and a short cool-down phase. In this paper we only report results from the runtime phase. The warm-up phase is important in establishing dynamic system state, but measurements from that phase are not significant for our evaluation. The cool-down phase is solely for allowing the benchmark to shut down. The warm-up, runtime, and cool-down phases are 2, 15, and 2 minutes respectively. The number of simulated clients were 400, 800, 1200, and 1600. The benchmark is available in a Java Servlets and PHP version and has different datasets; we evaluated Ganesh using the Java Servlets version and the Expanded dataset. The BBOARD benchmark defines two different workloads. The first, the Authoring mix, consists of 70% read-only operations and 30% read-write operations. The second, the Browsing mix, contains only read-only operations and does not update the database. 4.1.2 The AUCTION Benchmark The AUCTION benchmark, also known as RUBiS [18], models eBay, the online auction site. The eBay web site is used to buy and sell items via an auction format. The main activities of a user include browsing, selling, or bidding for items. Modeling the activities on this site, this benchmark includes read-only activities such as browsing items by category and by region, as well as read-write WWW 2007 / Track: Performance and Scalability Session: Scalable Systems for Dynamic Content 314 NetEm Router Ganesh Proxy Clients Web and Application Server Database Server Figure 5: Experimental Setup activities such as bidding for items, buying and selling items, and leaving feedback. As with BBOARD, the benchmark consists of three different phases. The warm-up, runtime, and cool-down phases for this experiment are 1.5, 15, and 1 minutes respectively. We tested Ganesh with four client configurations where the number of test clients was set to 400, 800, 1200, and 1600. The benchmark is available in a Enterprise Java Bean (EJB), Java Servlets, and PHP version and has different datasets; we evaluated Ganesh with the Java Servlets version and the Expanded dataset. The AUCTION benchmark defines two different workloads. The first, the Bidding mix, consists of 70% read-only operations and 30% read-write operations. The second, the Browsing mix, contains only read-only operations and does not update the database. 4.2 Experimental Procedure Both benchmarks involve a synthetic workload of clients accessing a web server. The number of clients emulated is an experimental parameter. Each emulated client runs an instance of the benchmark in its own thread, using a matrix to transition between different benchmark states. The matrix defines a stochastic model with probabilities of transitioning between the different states that represent typical user actions. An example transition is a user logging into the AUCTION system and then deciding on whether to post an item for sale or bid on active auctions. Each client also models user think time between requests. The think time is modeled as an exponential distribution with a mean of 7 seconds. We evaluate Ganesh along two axes: number of clients and WAN bandwidth. Higher loads are especially useful in understanding Ganeshs performance when the CPU or disk of the database server or proxy is the limiting factor. A previous study has shown that approximately 50% of the wide-area Internet bottlenecks observed had an available bandwidth under 10 Mb/s [1]. Based on this work, we focus our evaluation on the WAN bandwidth of 5 Mb/s with 66 ms of round-trip latency, representative of severely constrained network paths, and 20 Mb/s with 33 ms of round-trip latency, representative of a moderately constrained network path. We also report Ganeshs performance at 100 Mb/s with no added round-trip latency. This bandwidth, representative of an unconstrained network, is especially useful in revealing any potential overhead of Ganesh in situations where WAN bandwidth is not the limiting factor. For each combination of number of clients and WAN bandwidth, we measured results from the two configurations listed below: • Native: This configuration corresponds to Figure 3(a). Native avoids Ganeshs overhead in using a proxy and performing Java object serialization. • Ganesh: This configuration corresponds to Figure 3(b). For a given number of clients and WAN bandwidth, comparing these results to the corresponding Native results gives the performance benefit due to the Ganesh middleware system. The metric used to quantify the improvement in throughput is the number of client requests that can be serviced per second. The metric used to quantify Ganeshs overhead is the average response time for a client request. For all of the experiments, the Ganesh driver used by the application server used a cache size of 100,000 items1 . The proxy was effective in tracking the Ganesh drivers cache state; for all of our experiments the miss rate on the driver never exceeded 0.7%. 4.3 Experimental Setup The experimental setup used for the benchmarks can be seen in Figure 5. All machines were 3.2 GHz Pentium 4s (with HyperThreading enabled.) With the exception of the database server, all machines had 2 GB of SDRAM and ran the Fedora Core Linux distribution. The database server had 4 GB of SDRAM. We used Apaches Tomcat as both the application server that hosted the Java Servlets and the web server. Both benchmarks used Java Servlets to generate the dynamic content. The database server used the open source MySQL database. For the native JDBC drivers, we used the Connector/J drivers provided by MySQL. The application server used Suns Java Virtual Machine as the runtime environment for the Java Servlets. The sysstat tool was used to monitor the CPU, network, disk, and memory utilization on all machines. The machines were connected by a switched gigabit Ethernet network. As shown in Figure 5, the front-end web and application server was separated from the proxy and database server by a NetEm router [16]. This router allowed us to control the bandwidth and latency settings on the network. The NetEm router is a standard PC with two network cards running the Linux Traffic Control and Network Emulation software. The bandwidth and latency constraints were only applied to the link between the application server and the database for the native case and between the application server and the proxy for the Ganesh case. There is no communication between the application server and the database with Ganesh as all data flows through the proxy. As our focus was on the WAN link between the application server and the database, there were no constraints on the link between the simulated test clients and the web server. 5. THROUGHPUT AND RESPONSE TIME In this section, we address the first question raised in Section 4: Can performance can be improved significantly by exploiting similarity across database results? To answer this question, we use results from the BBOARD and AUCTION benchmarks. We use two metrics to quantify the performance improvement obtainable through the use of Ganesh: throughput, from the perspective of the web server, and average response time, from the perspective of the client. Throughput is measured in terms of the number of client requests that can be serviced per second. 5.1 BBOARD Results and Analysis 5.1.1 Authoring Mix Figures 6 (a) and (b) present the average number of requests serviced per second and the average response time for these requests as perceived by the clients for BBOARDs Authoring Mix. As Figure 6 (a) shows, Native easily saturates the 5 Mb/s link. At 400 clients, the Native solution delivers 29 requests/sec with an average response time of 8.3 seconds. Natives throughput drops with an increase in test clients as clients timeout due to congestion at the application server. Usability studies have shown that response times above 10 seconds cause the user to move on to 1 As Java lacks a sizeof() operator, Java caches therefore limit their size based on the number of objects. The size of cache dumps taken at the end of the experiments never exceeded 212 MB. WWW 2007 / Track: Performance and Scalability Session: Scalable Systems for Dynamic Content 315 0 50 100 150 200 250 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Test Clients Requests/sec Native Ganesh 0.001 0.01 0.1 1 10 100 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Test Clients Avg.Resp.Time(sec) Native Ganesh Note Logscale (a) Throughput: Authoring Mix (b) Response Time: Authoring Mix 0 50 100 150 200 250 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Test Clients Requests/sec Native Ganesh 0.001 0.01 0.1 1 10 100 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Test Clients Avg.Resp.Time(sec) Native Ganesh Note Logscale (c) Throughput: Browsing Mix (d) Response Time: Browsing Mix Mean of three trials. The maximum standard deviation for throughput and response time was 9.8% and 11.9% of the corresponding mean. Figure 6: BBOARD Benchmark - Throughput and Average Response Time other tasks [24]. Based on these numbers, increasing the number of test clients makes the Native system unusable. Ganesh at 5 Mb/s, however, delivers a twofold improvement with 400 test clients and a fivefold improvement at 1200 clients. Ganeshs performance drops slightly at 1200 and 1600 clients as the network is saturated. Compared to Native, Figure 6 (b) shows that Ganeshs response times are substantially lower with sub-second response times at 400 clients. Figure 6 (a) also shows that for 400 and 800 test clients Ganesh at 5 Mb/s has the same throughput and average response time as Native at 20 Mb/s. Only at 1200 and 1600 clients does Native at 20 Mb/s deliver higher throughput than Ganesh at 5 Mb/s. Comparing both Ganesh and Native at 20 Mb/s, we see that Ganesh is no longer bandwidth constrained and delivers up to a twofold improvement over Native at 1600 test clients. As Ganesh does not saturate the network with higher test client configurations, at 1600 test clients, its average response time is 0.1 seconds rather than Natives 7.7 seconds. As expected, there are no visible gains from Ganesh at the higher bandwidth of 100 Mb/s where the network is no longer the bottleneck. Ganesh, however, still tracks Native in terms of throughput. 5.1.2 Browsing Mix Figures 6 (c) and (d) present the average number of requests serviced per second and the average response time for these requests as perceived by the clients for BBOARDs Browsing Mix. Regardless of the test client configuration, Figure 6 (c) shows that Natives throughput at 5 Mb/s is limited to 10 reqs/sec. Ganesh at 5 Mb/s with 400 test clients, delivers more than a sixfold increase in throughput. The improvement increases to over a elevenfold increase at 800 test clients before Ganesh saturates the network. Further, Figure 6 (d) shows that Natives average response time of 35 seconds at 400 test clients make the system unusable. These high response times further increase with the addition of test clients. Even with the 1600 test client configuration Ganesh delivers an acceptable average response time of 8.2 seconds. Due to the data-intensive nature of the Browsing mix, Ganesh at 5 Mb/s surprisingly performs much better than Native at 20 Mb/s. Further, as shown in Figure 6 (d), while the average response time for Native at 20 Mb/s is acceptable at 400 test clients, it is unusable with 800 test clients with an average response time of 15.8 seconds. Like the 5 Mb/s case, this response time increases with the addition of extra test clients. Ganesh at 20 Mb/s and both Native and Ganesh at 100 Mb/s are not bandwidth limited. However, performance plateaus out after 1200 test clients due to the database CPU being saturated. 5.1.3 Filter Variant We were surprised by the Native performance from the BBOARD benchmark. At the bandwidth of 5 Mb/s, Native performance was lower than what we had expected. It turned out the benchmark code that displays stories read all the comments associated with the particular story from the database and only then did some postprocessing to select the comments to be displayed. While this is exactly the behavior of SlashCode, the code base behind the Slashdot web site, we decided to modify the benchmark to perform some pre-filtering at the database. This modified benchmark, named the Filter Variant, models a developer who applies optimizations at the SQL level to transfer less data. In the interests of brevity, we only briefly summarize the results from the Authoring mix. For the Authoring mix, at 800 test clients at 5 Mb/s, Figure 7 (a) shows that Natives throughput increase by 85% when compared to the original benchmark while Ganeshs improvement is smaller at 15%. Natives performance drops above 800 clients as the test clients time out due to high response times. The most significant gain for Native is seen at 20 Mb/s. At 1600 test clients, when compared to the original benchmark, Native sees a 73% improvement in throughput and a 77% reduction in average response time. While WWW 2007 / Track: Performance and Scalability Session: Scalable Systems for Dynamic Content 316 0 50 100 150 200 250 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Test Clients Requests/sec Native Ganesh 0.001 0.01 0.1 1 10 100 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Test Clients Avg.Resp.Time(sec) Native Ganesh Note Logscale (a) Throughput: Authoring Mix (b) Response Time: Authoring Mix Mean of three trials. The maximum standard deviation for throughput and response time was 7.2% and 11.5% of the corresponding mean. Figure 7: BBOARD Benchmark - Filter Variant - Throughput and Average Response Time Ganesh sees no improvement when compared to the original, it still processes 19% more requests/sec than Native. Thus, while the optimizations were more helpful to Native, Ganesh still delivers an improvement in performance. 5.2 AUCTION Results and Analysis 5.2.1 Bidding Mix Figures 8 (a) and (b) present the average number of requests serviced per second and the average response time for these requests as perceived by the clients for AUCTIONs Bidding Mix. As mentioned earlier, the Bidding mix consists of a mixture of read and write operations. The AUCTION benchmark is not as data intensive as BBOARD. Therefore, most of the gains are observed at the lower bandwidth of 5 Mb/s. Figure 8 (a) shows that the increase in throughput due to Ganesh ranges from 8% at 400 test clients to 18% with 1600 test clients. As seen in Figure 8 (b), the average response times for Ganesh are significantly lower than Native ranging from a decrease of 84% at 800 test clients to 88% at 1600 test clients. Figure 8 (a) also shows that with a fourfold increase of bandwidth from 5 Mb/s to 20 Mb/s, Native is no longer bandwidth constrained and there is no performance difference between Ganesh and Native. With the higher test client configurations, we did observe that the bandwidth used by Ganesh was lower than Native. Ganesh might still be useful in these non-constrained scenarios if bandwidth is purchased on a metered basis. Similar results are seen for the 100 Mb/s scenario. 5.2.2 Browsing Mix For AUCTIONs Browsing Mix, Figures 8 (c) and (d) present the average number of requests serviced per second and the average response time for these requests as perceived by the clients. Again, most of the gains are observed at lower bandwidths. At 5 Mb/s, Native and Ganesh deliver similar throughput and response times with 400 test clients. While the throughput for both remains the same at 800 test clients, Figure 8 (d) shows that Ganeshs average response time is 62% lower than Native. Native saturates the link at 800 clients and adding extra test clients only increases the average response time. Ganesh, regardless of the test client configuration, is not bandwidth constrained and maintains the same response time. At 1600 test clients, Figure 8 (c) shows that Ganeshs throughput is almost twice that of Native. At the higher bandwidths of 20 and 100 Mb/s, neither Ganesh nor Native is bandwidth limited and deliver equivalent throughput and response times. Benchmark Orig. Size Ganesh Size Rabin Size SelectSort1 223.6 MB 5.4 MB 219.3 MB SelectSort2 223.6 MB 5.4 MB 223.6 MB Table 2: Similarity Microbenchmarks 6. STRUCTURAL VS. RABIN SIMILARITY In this section, we address the second question raised in Section 4: How important is Ganeshs structural similarity detection relative to Rabin fingerprinting-based similarity detecting? To answer this question, we used microbenchmarks and the BBOARD and AUCTION benchmarks. As Ganesh always performed better than Rabin fingerprinting, we only present a subset of the results here in the interests of brevity. 6.1 Microbenchmarks Two microbenchmarks show an example of the effects of data reordering on Rabin fingerprinting algorithm. In the first microbenchmark, SelectSort1, a query with a specified sort order selects 223.6 MB of data spread over approximately 280 K rows. The query is then repeated with a different sort attribute. While the same number of rows and the same data is returned, the order of rows is different. In such a scenario, one would expect a large amount of similarity to be detected between both results. As Table 2 shows, Ganeshs row-based algorithm achieves a 97.6% reduction while the Rabin fingerprinting algorithm, with the average chunk size parameter set to 4 KB, only achieves a 1% reduction. The reason, as shown earlier in Figure 2, is that with Rabin fingerprinting, the spans of data between two consecutive boundaries usually cross row boundaries. With the order of the rows changing in the second result and the Rabin fingerprints now spanning different rows, the algorithm is unable to detect significant similarity. The small gain seen is mostly for those single rows that are large enough to be broken into multiple chunks. SelectSort2, another micro-benchmark executed the same queries but increased the minimum chunk size of the Rabin fingerprinting algorithm. As can be seen in Table 2, even the small gain from the previous microbenchmark disappears as the minimum chunk size was greater than the average row size. While one can partially address these problems by dynamically varying the parameters of the Rabin fingerprinting algorithm, this can be computationally expensive, especially in the presence of changing workloads. 6.2 Application Benchmarks We ran the BBOARD benchmark described in Section 4.1.1 on two versions of Ganesh: the first with Rabin fingerprinting used as WWW 2007 / Track: Performance and Scalability Session: Scalable Systems for Dynamic Content 317 0 50 100 150 200 250 300 350 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Test Clients Requests/sec Native Ganesh 0.001 0.01 0.1 1 10 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Test Clients Avg.Resp.Time(sec) Native Ganesh Note Logscale (a) Throughput: Bidding Mix (b) Response Time: Bidding Mix 0 50 100 150 200 250 300 350 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Test Clients Requests/sec Native Ganesh 0.001 0.01 0.1 1 10 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Test Clients Avg.Resp.Time(sec) Native Ganesh Note Logscale (c) Throughput: Browsing Mix (d) Response Time: Browsing Mix Mean of three trials. The maximum standard deviation for throughput and response time was 2.2% and 11.8% of the corresponding mean. Figure 8: AUCTION Benchmark - Throughput and Average Response Time the chunking algorithm and the second with Ganeshs row-based algorithm. Rabins results for the Browsing Mix are normalized to Ganeshs results and presented in Figure 9. As Figure 9 (a) shows, at 5 Mb/s, independent of the test client configuration, Rabin significantly underperforms Ganesh. This happens because of a combination of two reasons. First, as outlined in Section 3.1, Rabin finds less similarity as it does not exploit the results structural information. Second, this benchmark contained some queries that generated large results. In this case, Rabin, with a small average chunk size, generated a large number of objects that evicted other useful data from the cache. In contrast, Ganesh was able to detect these large rows and correspondingly increase the size of the chunks. This was confirmed as cache statistics showed that Ganeshs hit ratio was roughly three time that of Rabin. Throughput measurements at 20 Mb/s were similar with the exception of Rabins performance with 400 test clients. In this case, Ganesh was not network limited and, in fact, the throughput was the same as 400 clients at 5 Mb/s. Rabin, however, took advantage of the bandwidth increase from 5 to 20 Mb/s to deliver a slightly better performance. At 100 Mb/s, Rabins throughput was almost similar to Ganesh as bandwidth was no longer a bottleneck. The normalized response time, presented in Figure 9 (b), shows similar trends. At 5 and 20 Mb/s, the addition of test clients decreases the normalized response time as Ganeshs average response time increases faster than Rabins. However, at no point does Rabin outperform Ganesh. Note that at 400 and 800 clients at 100 Mb/s, Rabin does have a higher overhead even when it is not bandwidth constrained. As mentioned in Section 3.1, this is due to the fact that Rabin has to hash each ResultSet twice. The overhead disappears with 1200 and 1600 clients as the database CPU is saturated and limits the performance of both Ganesh and Rabin. 7. PROXY OVERHEAD In this section, we address the third question raised in Section 4: Is the overhead of Ganeshs proxy-based design acceptable? To answer this question, we concentrate on its performance at the higher bandwidths. Our evaluation in Section 5 showed that Ganesh, when compared to Native, can deliver a substantial throughput improvement at lower bandwidths. It is only at higher bandwidths that latency, measured by the average response time for a client request, and throughput, measured by the number of client requests that can be serviced per second, overheads would be visible. Looking at the Authoring mix of the original BBOARD benchmark, there are no visible gains from Ganesh at 100 Mb/s. Ganesh, however, still tracks Native in terms of throughput. While the average response time is higher for Ganesh, the absolute difference is in between 0.01 and 0.04 seconds and would be imperceptible to the end-user. The Browsing mix shows an even smaller difference in average response times. The results from the filter variant of the BBOARD benchmarks are similar. Even for the AUCTION benchmark, the difference between Native and Ganeshs response time at 100 Mb/s was never greater than 0.02 seconds. The only exception to the above results was seen in the filter variant of the BBOARD benchmark where Ganesh at 1600 test clients added 0.85 seconds to the average response time. Thus, even for much faster networks where the WAN link is not the bottleneck, Ganesh always delivers throughput equivalent to Native. While some extra latency is added by the proxy-based design, it is usually imperceptible. 8. RELATED WORK To the best of our knowledge, Ganesh is the first system that combines the use of hash-based techniques with caching of database results to improve throughput and response times for applications with dynamic content. We also believe that it is also the first system to demonstrate the benefits of using structural information for WWW 2007 / Track: Performance and Scalability Session: Scalable Systems for Dynamic Content 318 0.0 0.2 0.4 0.6 0.8 1.0 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Test Clients Norm.Throughput 31.8 3.8 2.8 2.3 23.8 32.8 5.8 3.6 1.8 2.1 1.1 1.0 0 5 10 15 20 25 30 35 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Test Clients Norm.ResponseTime (a) Normalized Throughput: Higher is better (b) Normalized Response Time: Higher is worse For throughput, a normalized result greater than 1 implies that Rabin is better, For response time, a normalized result greater than 1 implies that Ganesh is better. Mean of three trials. The maximum standard deviation for throughput and response time was 9.1% and 13.9% of the corresponding mean. Figure 9: Normalized Comparison of Ganesh vs. Rabin - BBOARD Browsing Mix detecting similarity. In this section, we first discuss alternative approaches to caching dynamic content and then examine other uses of hash-based primitives in distributed systems. 8.1 Caching Dynamic Content At the database layer, a number of systems have advocated middletier caching where parts of the database are replicated at the edge or server [3, 4, 20]. These systems either cache entire tables in what is essentially a replicated database or use materialized views from previous query replies [19]. They require tight integration with the back-end database to ensure a time bound on the propagation of updates. These systems are also usually targeted towards workloads that do not require strict consistency and can tolerate stale data. Further, unlike Ganesh, some of these mid-tier caching solutions [2, 3], suffer from the complexity of having to participate in query planing and distributed query processing. Gao et al. [15] propose using a distributed object replication architecture where the data stores consistency requirements are adapted on a per-application basis. These solutions require substantial developer resources and detailed understanding of the application being modified. While systems that attempt to automate the partitioning and replication of an applications database exist [34], they do not provide full transaction semantics. In comparison, Ganesh does not weaken any of the semantics provided by the underlying database. Recent work in the evaluation of edge caching options for dynamic web sites [38] has suggested that, without careful planning, employing complex offloading strategies can hurt performance. Instead, the work advocates for an architecture in which all tiers except the database should be offloaded to the edge. Our evaluation of Ganesh has shown that it would benefit these scenarios. To improve database scalability, C-JDBC [10], SSS [22], and Ganymed [28] also advocate the use of an interposition-based architecture to transparently cluster and replicate databases at the middleware level. The approaches of these architectures and Ganesh are complementary and they would benefit each other. Moving up to the presentation layer, there has been widespread adoption of fragment-based caching [14], which improves cache utilization by separately caching different parts of generated web pages. While fragment-based caching works at the edge, a recent proposal has proposed moving web page assembly to the clients to optimize content delivery [31]. While Ganesh is not used at the presentation layer, the same principles have been applied in Duplicate Transfer Detection [25] to increase web cache efficiency as well as for web access across bandwidth limited links [33]. 8.2 Hash-based Systems The past few years have seen the emergence of many systems that exploit hash-based techniques. At the heart of all these systems is the idea of detecting similarity in data without requiring interpretation of that data. This simple yet elegant idea relies on cryptographic hashing, as discussed earlier in Section 2. Successful applications of this idea span a wide range of storage systems. Examples include peer-to-peer backup of personal computing files [11], storage-efficient archiving of data [29], and finding similar files [21]. Spring and Wetherall [35] apply similar principles at the network level. Using synchronized caches at both ends of a network link, duplicated data is replaced by smaller tokens for transmission and then restored at the remote end. This and other hash-based systems such as the CASPER [37] and LBFS [26] filesystems, and Layer-2 bandwidth optimizers such as Riverbed and Peribit use Rabin fingerprinting [30] to discover spans of commonality in data. This approach is especially useful when data items are modified in-place through insertions, deletions, and updates. However, as Section 6 shows, the performance of this technique can show a dramatic drop in the presence of data reordering. Ganesh instead uses row boundaries as dividers for detecting similarity. The most aggressive use of hash-based techniques is by systems that use hashes as the primary identifiers for objects in persistent storage. Storage systems such as CFS [12] and PAST [13] that have been built using distributed hash tables fall into this category. Single Instance Storage [6] and Venti [29] are other examples of such systems. As discussed in Section 2.2, the use of cryptographic hashes for addressing persistent data represents a deeper level of faith in their collision-resistance than that assumed by Ganesh. If time reveals shortcomings in the hash algorithm, the effort involved in correcting the flaw is much greater. In Ganesh, it is merely a matter of replacing the hash algorithm. 9. CONCLUSION The growing use of dynamic web content generated from relational databases places increased demands on WAN bandwidth. Traditional caching solutions for bandwidth and latency reduction are often ineffective for such content. This paper shows that the impact of WAN accesses to databases can be substantially reduced through the Ganesh architecture without any compromise of the databases strict consistency semantics. The essence of the Ganesh architecture is the use of computation at the edges to reduce communication through the Internet. Ganesh is able to use cryptographic hashes to detect similarity with previous results and send WWW 2007 / Track: Performance and Scalability Session: Scalable Systems for Dynamic Content 319 compact recipes of results rather than full results. Our design uses interposition to achieve complete transparency: clients, application servers, and database servers are all unaware of Ganeshs presence and require no modification. Our experimental evaluation confirms that Ganesh, while conceptually simple, can be highly effective in improving throughput and response time. Our results also confirm that exploiting the structure present in database results to detect similarity is crucial to this performance improvement. 10. REFERENCES [1] AKELLA, A., SESHAN, S., AND SHAIKH, A. An empirical evaluation of wide-area internet bottlenecks. In Proc. 3rd ACM SIGCOMM Conference on Internet Measurement (Miami Beach, FL, USA, Oct. 2003), pp. 101-114. [2] ALTINEL, M., BORNH ¨OVD, C., KRISHNAMURTHY, S., MOHAN, C., PIRAHESH, H., AND REINWALD, B. Cache tables: Paving the way for an adaptive database cache. In Proc. of 29th VLDB (Berlin, Germany, 2003), pp. 718-729. [3] ALTINEL, M., LUO, Q., KRISHNAMURTHY, S., MOHAN, C., PIRAHESH, H., LINDSAY, B. G., WOO, H., AND BROWN, L. Dbcache: Database caching for web application servers. In Proc. 2002 ACM SIGMOD (2002), pp. 612-612. [4] AMIRI, K., PARK, S., TEWARI, R., AND PADMANABHAN, S. Dbproxy: A dynamic data cache for web applications. In Proc. IEEE International Conference on Data Engineering (ICDE) (Mar. 2003). [5] BLACK, J. Compare-by-hash: A reasoned analysis. In Proc. 2006 USENIX Annual Technical Conference (Boston, MA, May 2006), pp. 85-90. [6] BOLOSKY, W. J., CORBIN, S., GOEBEL, D., , AND DOUCEUR, J. R. Single instance storage in windows 2000. In Proc. 4th USENIX Windows Systems Symposium (Seattle, WA, Aug. 2000), pp. 13-24. [7] BREWER, E. A. Lessons from giant-scale services. IEEE Internet Computing 5, 4 (2001), 46-55. [8] BRODER, A., GLASSMAN, S., MANASSE, M., AND ZWEIG, G. Syntactic clustering of the web. In Proc. 6th International WWW Conference (1997). [9] CECCHET, E., CHANDA, A., ELNIKETY, S., MARGUERITE, J., AND ZWAENEPOEL, W. Performance comparison of middleware architectures for generating dynamic web content. In Proc. Fourth ACM/IFIP/USENIX International Middleware Conference (Rio de Janeiro, Brazil, June 2003). [10] CECCHET, E., MARGUERITE, J., AND ZWAENEPOEL, W. C-JDBC: Flexible database clustering middleware. In Proc. 2004 USENIX Annual Technical Conference (Boston, MA, June 2004). [11] COX, L. P., MURRAY, C. D., AND NOBLE, B. D. Pastiche: Making backup cheap and easy. In OSDI: Symposium on Operating Systems Design and Implementation (2002). [12] DABEK, F., KAASHOEK, M. F., KARGER, D., MORRIS, R., AND STOICA, I. Wide-area cooperative storage with CFS. In 18th ACM Symposium on Operating Systems Principles (Banff, Canada, Oct. 2001). [13] DRUSCHEL, P., AND ROWSTRON, A. PAST: A large-scale, persistent peer-to-peer storage utility. In HotOS VIII (Schloss Elmau, Germany, May 2001), pp. 75-80. [14] Edge side includes. http://www.esi.org. [15] GAO, L., DAHLIN, M., NAYATE, A., ZHENG, J., AND IYENGAR, A. Application specific data replication for edge services. In WWW 03: Proc. Twelfth International Conference on World Wide Web (2003), pp. 449-460. [16] HEMMINGER, S. Netem - emulating real networks in the lab. In Proc. 2005 Linux Conference Australia (Canberra, Australia, Apr. 2005). [17] HENSON, V. An analysis of compare-by-hash. In Proc. 9th Workshop on Hot Topics in Operating Systems (HotOS IX) (May 2003), pp. 13-18. [18] Jmob benchmarks. http://jmob.objectweb.org/. [19] LABRINIDIS, A., AND ROUSSOPOULOS, N. Balancing performance and data freshness in web database servers. In Proc. 29th VLDB Conference (Sept. 2003). [20] LARSON, P.-A., GOLDSTEIN, J., AND ZHOU, J. Transparent mid-tier database caching in sql server. In Proc. 2003 ACM SIGMOD (2003), pp. 661-661. [21] MANBER, U. Finding similar files in a large file system. In Proc. USENIX Winter 1994 Technical Conference (San Fransisco, CA, 17-21 1994), pp. 1-10. [22] MANJHI, A., AILAMAKI, A., MAGGS, B. M., MOWRY, T. C., OLSTON, C., AND TOMASIC, A. Simultaneous scalability and security for data-intensive web applications. In Proc. 2006 ACM SIGMOD (June 2006), pp. 241-252. [23] MENEZES, A. J., VANSTONE, S. A., AND OORSCHOT, P. C. V. Handbook of Applied Cryptography. CRC Press, 1996. [24] MILLER, R. B. Response time in man-computer conversational transactions. In Proc. AFIPS Fall Joint Computer Conference (1968), pp. 267-277. [25] MOGUL, J. C., CHAN, Y. M., AND KELLY, T. Design, implementation, and evaluation of duplicate transfer detection in http. In Proc. First Symposium on Networked Systems Design and Implementation (San Francisco, CA, Mar. 2004). [26] MUTHITACHAROEN, A., CHEN, B., AND MAZIERES, D. A low-bandwidth network file system. In Proc. 18th ACM Symposium on Operating Systems Principles (Banff, Canada, Oct. 2001). [27] PFEIFER, D., AND JAKSCHITSCH, H. Method-based caching in multi-tiered server applications. In Proc. Fifth International Symposium on Distributed Objects and Applications (Catania, Sicily, Italy, Nov. 2003). [28] PLATTNER, C., AND ALONSO, G. Ganymed: Scalable replication for transactional web applications. In Proc. 5th ACM/IFIP/USENIX International Conference on Middleware (2004), pp. 155-174. [29] QUINLAN, S., AND DORWARD, S. Venti: A new approach to archival storage. In Proc. FAST 2002 Conference on File and Storage Technologies (2002). [30] RABIN, M. Fingerprinting by random polynomials. In Harvard University Center for Research in Computing Technology Technical Report TR-15-81 (1981). [31] RABINOVICH, M., XIAO, Z., DOUGLIS, F., AND KALMANEK, C. Moving edge side includes to the real edge - the clients. In Proc. 4th USENIX Symposium on Internet Technologies and Systems (Seattle, WA, Mar. 2003). [32] REESE, G. Database Programming with JDBC and Java, 1st ed. OReilly, June 1997. [33] RHEA, S., LIANG, K., AND BREWER, E. Value-based web caching. In Proc. Twelfth International World Wide Web Conference (May 2003). [34] SIVASUBRAMANIAN, S., ALONSO, G., PIERRE, G., AND VAN STEEN, M. Globedb: Autonomic data replication for web applications. In WWW 05: Proc. 14th International World-Wide Web conference (May 2005). [35] SPRING, N. T., AND WETHERALL, D. A protocol-independent technique for eliminating redundant network traffic. In Proc. of ACM SIGCOMM (Aug. 2000). [36] TOLIA, N., HARKES, J., KOZUCH, M., AND SATYANARAYANAN, M. Integrating portable and distributed storage. In Proc. 3rd USENIX Conference on File and Storage Technologies (San Francisco, CA, Mar. 2004). [37] TOLIA, N., KOZUCH, M., SATYANARAYANAN, M., KARP, B., PERRIG, A., AND BRESSOUD, T. Opportunistic use of content addressable storage for distributed file systems. In Proc. 2003 USENIX Annual Technical Conference (San Antonio, TX, June 2003), pp. 127-140. [38] YUAN, C., CHEN, Y., AND ZHANG, Z. Evaluation of edge caching/offloading for dynamic content delivery. In WWW 03: Proc. Twelfth International Conference on World Wide Web (2003), pp. 461-471. WWW 2007 / Track: Performance and Scalability Session: Scalable Systems for Dynamic Content 320",
    "original_translation": "Conservación de la consistencia en el almacenamiento en caché de contenido dinámico de bases de datos∗ Niraj Tolia y M. Satyanarayanan Universidad Carnegie Mellon {ntolia,satya}@cs.cmu.edu RESUMEN Con el creciente uso de contenido web dinámico generado a partir de bases de datos relacionales, las soluciones de almacenamiento en caché tradicionales para mejorar el rendimiento y la latencia son ineficaces. Describimos una capa de middleware llamada Ganesh que reduce el volumen de datos transmitidos sin interpretación semántica de consultas o resultados. Se logra esta reducción mediante el uso de hash criptográficos para detectar similitudes con resultados anteriores. Estos beneficios no requieren ningún compromiso con la semántica de consistencia estricta proporcionada por la base de datos del servidor. Además, Ganesh no requiere modificaciones en aplicaciones, servidores web o servidores de bases de datos, y funciona con aplicaciones y bases de datos de código cerrado. Usando dos puntos de referencia representativos de sitios web dinámicos, las mediciones de nuestro prototipo muestran que puede aumentar el rendimiento de extremo a extremo hasta en un factor de dos para aplicaciones no intensivas en datos y hasta en un factor de diez para las intensivas en datos. Categorías y Descriptores de Asignaturas C.2.4 [Redes de Computadoras-Comunicación]: Sistemas Distribuidos; H.2.4 [Gestión de Bases de Datos]: Términos Generales de Sistemas de Diseño, Rendimiento 1. INTRODUCCIÓN Una fracción creciente del contenido web se genera dinámicamente a partir de bases de datos relacionales en el backend. Incluso cuando el contenido de la base de datos permanece sin cambios, la localidad temporal de acceso no puede ser explotada porque el contenido dinámico no es almacenable en caché por los navegadores web o por servidores de almacenamiento en caché intermedios como los espejos de Akamai. En una arquitectura multinivel, cada solicitud web puede tensionar el enlace WAN entre el servidor web y la base de datos. Esto provoca que la experiencia del usuario sea altamente variable porque no hay almacenamiento en caché para aislar al cliente de cargas repentinas. Los intentos previos de almacenar en caché contenido dinámico de bases de datos generalmente han debilitado la semántica transaccional [3, 4] o han requerido modificaciones en la aplicación [15, 34]. Informamos sobre una nueva solución que toma la forma de una capa intermedia de middleware independiente de la base de datos llamada Ganesh. Ganesh no hace ningún esfuerzo por interpretar semánticamente el contenido de las consultas o sus resultados. En cambio, se basa exclusivamente en el hash criptográfico para detectar similitudes con resultados anteriores. La detección de similitud basada en hash ha sido cada vez más utilizada en sistemas de archivos distribuidos [26, 36, 37] para mejorar el rendimiento en redes de baja capacidad de ancho de banda. Sin embargo, estas técnicas no se han utilizado para bases de datos relacionales. A diferencia de enfoques anteriores que utilizan métodos genéricos para detectar similitud, Ganesh explota la estructura de los resultados de la base de datos relacional para lograr una mejora superior en el rendimiento. Uno se enfrenta al menos a tres desafíos al aplicar la detección de similitud basada en hash a las bases de datos de back-end. Primero, el trabajo previo en este ámbito ha considerado tradicionalmente el contenido de almacenamiento como bolsas de bits no interpretadas y sin estructura interna. Esto permite que las técnicas basadas en hash operen en largas y contiguas secuencias de datos para lograr la máxima efectividad. Por el contrario, las bases de datos relacionales tienen una estructura interna compleja que puede no ser tan propicia para la detección de similitudes basada en hash. Segundo, las bases de datos relacionales tienen restricciones de integridad y consistencia muy estrictas que no deben comprometerse por el uso de técnicas basadas en hash. Tercero, el código fuente de las bases de datos comerciales generalmente no está disponible. Esto contrasta con trabajos anteriores que presumían la disponibilidad del código fuente. Nuestros experimentos muestran que Ganesh, aunque conceptualmente simple, puede mejorar significativamente el rendimiento en anchos de banda representativos del Internet comercial actual. En los modelos de referencia de aplicaciones web multinivel, la mejora en el rendimiento fue de hasta diez veces para cargas de trabajo intensivas en datos. Para cargas de trabajo que no eran intensivas en datos, se observaron mejoras en el rendimiento de hasta el doble. Incluso cuando el ancho de banda no era una limitación, Ganesh tenía un bajo sobrecosto y no afectaba el rendimiento. Nuestros experimentos también confirman que aprovechar la estructura presente en los resultados de la base de datos es crucial para esta mejora en el rendimiento. Antecedentes 2.1 Generación de Contenido Dinámico A medida que la World Wide Web ha crecido, muchos sitios web han descentralizado sus datos y funcionalidades al llevarlos a los extremos de Internet. Hoy en día, los sistemas de comercio electrónico a menudo utilizan una arquitectura de tres niveles que consta de un servidor web de front-end, un servidor de aplicaciones y un servidor de base de datos de back-end. La Figura 1 ilustra esta arquitectura. Los dos primeros niveles se pueden replicar cerca de una concentración de clientes en el borde de Internet. Esto mejora la experiencia del usuario al reducir la latencia de extremo a extremo y disminuir la exposición al congestionamiento del tráfico de la columna vertebral. También puede aumentar la disponibilidad y escalabilidad de los servicios web. El contenido que se genera dinámicamente desde la base de datos del servidor no puede ser almacenado en caché en los dos primeros niveles. Si bien las bases de datos pueden replicarse fácilmente en una LAN, esto es inviable en una WAN debido a la difícil tarea de proporcionar simultáneamente una consistencia sólida, disponibilidad y tolerancia a particiones de red [7]. Como resultado, las bases de datos tienden a ser centralizadas para cumplir con los fuertes requisitos de consistencia de muchas aplicaciones de comercio electrónico como la banca, las finanzas y la venta al por menor en línea [38]. Por lo tanto, la base de datos del back-end suele estar ubicada lejos de muchos conjuntos de nodos de primer y segundo nivel [2]. En ausencia de almacenamiento en caché y replicación, el ancho de banda de la WAN puede convertirse fácilmente en un factor limitante en el rendimiento y la escalabilidad de aplicaciones intensivas en datos. El enfoque de Ganesh en los sistemas basados en hash es la transmisión eficiente de resultados al descubrir similitudes con los resultados de consultas anteriores. Dado que las consultas SQL pueden generar resultados grandes, las técnicas basadas en hash se prestan bien al problema de transferir eficientemente estos grandes resultados a través de enlaces con ancho de banda limitado. El uso de técnicas basadas en hash para reducir el volumen de datos transmitidos ha surgido como un tema común en muchos sistemas de almacenamiento recientes, como se discute en la Sección 8.2. Estas técnicas se basan en algunas suposiciones básicas. Se asume que las funciones hash criptográficas son resistentes a colisiones. En otras palabras, es computacionalmente intratable encontrar dos entradas que se hash a la misma salida. Las funciones también se asumen como unidireccionales; es decir, encontrar una entrada que resulte en una salida específica es computacionalmente inviable. Menezes et al. [23] proporcionan más detalles sobre estas suposiciones. Las suposiciones anteriores permiten a los sistemas basados en hash asumir que no se producen colisiones. Por lo tanto, pueden tratar el hash de un elemento de datos como su identificador único. Una colección de elementos de datos se convierte efectivamente en direccionable por contenido, permitiendo que un hash pequeño funcione como una palabra de código para un elemento de datos mucho más grande en almacenamiento permanente o transmisión en red. La suposición de que las colisiones son tan raras que prácticamente no existen ha sido cuestionada recientemente [17]. Sin embargo, como explicó Black [5], creemos que estos problemas no son una preocupación para Ganesh. Toda comunicación es entre partes confiables del sistema y un adversario no tiene forma de obligar a Ganesh a aceptar datos inválidos. Además, Ganesh no depende críticamente de ninguna función hash específica. Si bien actualmente usamos SHA-1, reemplazarlo con una función hash diferente sería sencillo. No habría impacto en el rendimiento con funciones hash más fuertes (por ejemplo, SHA256) solo añade unos pocos bytes adicionales y los hashes generados siguen siendo órdenes de magnitud más pequeños que los elementos de datos que representan. No es necesario volver a almacenar permanentemente ya que Ganesh solo utiliza el hash en datos volátiles. 3. DISEÑO E IMPLEMENTACIÓN Ganesh explota la redundancia en el flujo de resultados para evitar transmitir fragmentos de resultados que ya están presentes en el sitio de la consulta. La redundancia puede surgir de forma natural de muchas maneras diferentes. Por ejemplo, una consulta repetida después de un cierto intervalo puede devolver un resultado diferente debido a actualizaciones en la base de datos; sin embargo, puede haber una significativa similitud entre los dos resultados. Como otro ejemplo, un usuario que está refinando una búsqueda puede generar una secuencia de consultas con resultados superpuestos. Cuando Ganesh detecta redundancia, suprime la transmisión de los fragmentos de resultado correspondientes. En cambio, transmite un resumen mucho más pequeño de esos fragmentos y permite que el sitio de consulta reconstruya el resultado a través de la búsqueda de hash en una caché de resultados anteriores. De hecho, Ganesh utiliza la computación en los bordes para reducir la comunicación por Internet. Nuestra descripción de Ganesh se centra en cuatro aspectos. Primero explicamos nuestro enfoque para detectar similitud en los resultados de la consulta. A continuación, discutimos cómo la arquitectura Ganesh es completamente invisible para todos los componentes de un sistema de múltiples niveles. Luego describimos el enfoque basado en proxy de Ganesh y el flujo de datos para detectar similitudes. 3.1 Detectar similitud Una de las decisiones clave de diseño en Ganesh es cómo se detecta la similitud. Hay muchas formas potenciales de descomponer un resultado en fragmentos.  I the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the thees I,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,, Encontrar esta descomposición óptima es un problema difícil debido al amplio espacio de posibilidades y porque la elección óptima depende de muchos factores, como el contenido del resultado de las consultas, el historial de resultados recientes y el algoritmo de gestión de caché. Cuando un objeto es opaco, el uso de huellas digitales de Rabin [8, 30] para detectar datos comunes entre dos objetos ha sido demostrado con éxito en el pasado por sistemas como LBFS [26] y CASPER [37]. El fingerprinting de Rabin utiliza una ventana deslizante sobre los datos para calcular un hash rodante. Suponiendo que la función hash está distribuida uniformemente, un límite de fragmento se define cuando los bits de orden inferior del valor hash son iguales a algún valor predeterminado. El número de bits de orden inferior utilizados define el tamaño promedio del fragmento. Estos fragmentos subdivididos del objeto se convierten en la unidad de comparación para detectar similitudes entre diferentes objetos. Dado que las ubicaciones de los límites encontrados mediante el uso de las huellas de Rabin están determinadas de manera estocástica, generalmente no logran alinearse con ninguna propiedad estructural de los datos subyacentes. Por lo tanto, el algoritmo maneja bien las actualizaciones en su lugar, inserciones y eliminaciones. Sin embargo, tiene un rendimiento deficiente en presencia de cualquier reordenamiento de datos. La Figura 2 muestra un ejemplo donde dos resultados, A y B, que constan de tres filas, tienen los mismos datos pero diferentes atributos de ordenamiento. En el caso extremo, la huella digital de Rabin podría no ser capaz de encontrar datos similares debido a la forma en que detecta los límites de los fragmentos. Afortunadamente, Ganesh puede utilizar conocimientos específicos del dominio para una detección de límites más precisa. La información que explotamos es que el resultado de una consulta refleja la estructura de una base de datos relacional donde todos los datos están organizados en tablas y filas. Por lo tanto, es sencillo verificar la similitud con resultados anteriores en dos niveles de granularidad: primero el resultado completo y luego las filas individuales. El final de una fila en un resultado sirve como un límite natural de fragmento. Es importante tener en cuenta que el uso de la estructura tabular en los resultados solo implica una interpretación superficial de los datos. Ganesh no realiza ninguna interpretación semántica más profunda, como comprender tipos de datos, esquemas de resultados o restricciones de integridad. Ajustar la huella digital de Rabin para una carga de trabajo también puede ser difícil. Si el tamaño promedio de los fragmentos es demasiado grande, los fragmentos pueden abarcar varias filas de resultados. Sin embargo, seleccionar un tamaño de fragmento promedio más pequeño aumenta la cantidad de metadatos necesarios para describir los resultados. Esto, a su vez, disminuiría los ahorros obtenidos mediante su uso. El fingerprinting de Rabin también requiere dos pasadas computacionalmente costosas sobre los datos: una vez para determinar los límites de los fragmentos y otra vez para generar hashes criptográficos para los fragmentos. Ganesh solo necesita un único pase para la generación de hash, ya que los límites de los fragmentos son proporcionados por la estructura natural de los datos. La comparación de rendimiento en la Sección 6 muestra que el algoritmo basado en filas de Ganesh supera al fingerprinting de Rabin. Dado que trabajos anteriores ya han demostrado que la huella digital de Rabin funciona mejor que gzip [26], no comparamos a Ganesh con algoritmos de compresión en este artículo. 3.2 Transparencia El factor clave que influyó en nuestro diseño fue la necesidad de que Ganesh fuera completamente transparente para todos los componentes de un sistema típico de comercio electrónico: servidores web, servidores de aplicaciones y servidores de bases de datos. Sin esto, Ganesh tiene pocas posibilidades de tener un impacto significativo en el mundo real. Requerir modificaciones en cualquiera de los componentes mencionados aumentaría la barrera de entrada de Ganesh en un sistema existente, y por lo tanto reduciría sus posibilidades de adopción. Preservar la transparencia se simplifica por el hecho de que Ganesh es simplemente una mejora de rendimiento, no una mejora de funcionalidad o usabilidad. Elegimos la interposición de agentes como enfoque arquitectónico para lograr nuestro objetivo. Este enfoque se basa en la existencia de una interfaz de programación compacta que ya es ampliamente utilizada por el software objetivo. También se basa en un mecanismo para agregar fácilmente nuevo código sin interrumpir la estructura de módulos existente. Estas condiciones se cumplen fácilmente en nuestro contexto debido a la popularidad de Java como el lenguaje de programación para sistemas de comercio electrónico. La API de Conectividad de Base de Datos de Java (JDBC) [32] permite a las aplicaciones de Java acceder a una amplia variedad de bases de datos e incluso a otros repositorios de datos tabulares como archivos planos. El acceso a estas fuentes de datos es proporcionado por controladores JDBC que traducen entre la API JDBC y el mecanismo de comunicación de la base de datos. La figura 3(a) muestra cómo se utiliza típicamente JDBC en una aplicación. Dado que la interfaz JDBC está estandarizada, se puede sustituir un controlador JDBC por otro sin necesidad de de modificar la aplicación. El controlador JDBC se convierte así en el módulo natural para aprovechar la interposición de código. Como se muestra en la Figura 3(b), el controlador JDBC nativo es reemplazado por un controlador JDBC Ganesh que presenta la misma interfaz estandarizada. El controlador Ganesh mantiene una caché en memoria de fragmentos de resultados de consultas anteriores y realiza el reensamblaje de resultados. En la base de datos, agregamos un nuevo proceso llamado el proxy Ganesh. Este proxy, que puede ser compartido por múltiples nodos front-end, consta de dos partes: código para detectar similitud en fragmentos de resultados y el controlador JDBC nativo original que se comunica con la base de datos. El uso de un proxy en la base de datos hace que Ganesh sea independiente de la base de datos y simplifica la creación de prototipos y experimentación. Ganesh es capaz de trabajar con una amplia gama de bases de datos y aplicaciones, sin necesidad de realizar modificaciones en ninguna de ellas. 3.3 Caché basada en proxy El controlador JDBC nativo mostrado en la Figura 3(a) es un componente de código ligero suministrado por el proveedor de la base de datos. Su función principal es mediar la comunicación entre la aplicación y la base de datos remota. Reenvía consultas, almacena resultados completos y responde a solicitudes de la aplicación para ver partes de los resultados. El controlador JDBC de Ganesh mostrado en la Figura 3(b) presenta a la aplicación una interfaz idéntica a la proporcionada por el controlador nativo. Proporciona la capacidad de reconstruir resultados a partir de descripciones compactas basadas en hash enviadas por el proxy. Para realizar esta reconstrucción, el controlador mantiene una caché en memoria de los resultados recibidos recientemente. Esta caché solo se utiliza como fuente de fragmentos de resultados en la reconstrucción de resultados. El conductor Ganesh o el proxy no intentan rastrear las actualizaciones de la base de datos. La falta de consistencia en la caché no afecta a la corrección, ya que la descripción de los resultados siempre se obtiene del proxy; en el peor de los casos, no habrá beneficio de rendimiento al usar Ganesh. Los datos obsoletos simplemente se eliminarán de la caché con el tiempo. El proxy de Ganesh accede a la base de datos a través del controlador JDBC nativo, que permanece sin cambios entre las Figuras 3(a) y (b). La base de datos está completamente ajena a la existencia del proxy. El proxy no examina ninguna consulta recibida del controlador Ganesh, sino que las pasa al controlador nativo. En cambio, el proxy es responsable de inspeccionar la salida de la base de datos recibida del controlador nativo, detectar resultados similares y generar codificaciones basadas en hash de estos resultados siempre que se encuentre suficiente similitud. Si bien esta arquitectura no disminuye la carga en una base de datos, como se mencionó anteriormente en la Sección 2.1, es mucho más fácil replicar bases de datos para escalabilidad en una LAN que en una WAN. Para generar una codificación basada en hash, el proxy debe estar al tanto de qué fragmentos de resultados están disponibles en la caché de controladores de Ganesh. Un enfoque es ser optimista y asumir que todos los fragmentos de resultados están disponibles. Esto resultará en la transmisión inicial más pequeña posible de un resultado. Sin embargo, en casos donde hay poca superposición con resultados anteriores, el controlador Ganesh tendrá que realizar muchas llamadas al proxy durante la reconstrucción para recuperar fragmentos de resultados faltantes. Para evitar esta situación, el proxy sigue de manera flexible el estado de la caché de controladores de Ganesh. Dado que ambos componentes están bajo nuestro control, es relativamente sencillo hacer esto sin recurrir a técnicas de caja gris o comunicación explícita para mantener la coherencia de la caché. En cambio, el proxy simula el algoritmo de gestión de caché de controladores de Ganesh y lo utiliza para mantener una lista de hashes para los cuales es probable que el controlador de Ganesh posea los fragmentos de resultado. En caso de desviación de seguimiento, no habrá pérdida de corrección, pero habrá retrasos adicionales en el viaje de ida y vuelta para recuperar los fragmentos faltantes. Si el cliente detecta la pérdida de sincronización con el proxy, puede pedirle al proxy que restablezca el estado compartido entre ellos. También hay que tener en cuenta que el proxy no necesita guardar los fragmentos de resultado en sí, solo sus hashes. Esto permite que el proxy siga siendo escalable incluso cuando es compartido por muchos nodos front-end. El proxy Ganesh recibe la salida de la base de datos como objetos Java del controlador JDBC nativo. Examina esta salida para ver si está presente un objeto Java del tipo ResultSet. La interfaz JDBC utiliza este tipo de dato para almacenar los resultados de las consultas a la base de datos. Si se encuentra un objeto ResultSet, se reduce como se discute a continuación. Todos los demás objetos de Java se pasan sin modificar. Como se discute en la Sección 3.1, el proxy utiliza los límites de fila definidos en el ResultSet para dividirlo en fragmentos que consisten en filas de resultado individuales. Todos los objetos ResultSet se convierten en objetos de un nuevo tipo llamado RecipeResultSet. Utilizamos el término receta para esta descripción compacta de un resultado de base de datos debido a su similitud con una receta de archivo en el sistema de archivos CASPER [37]. La conversión reemplaza cada fragmento de resultado que probablemente esté presente en la caché de controladores de Ganesh por un hash SHA-1 de ese fragmento. Los fragmentos de resultados previamente no vistos se conservan textualmente. El proxy también retiene los hashes de los nuevos fragmentos de resultados, ya que estarán presentes en la caché de los controladores en el futuro. Ten en cuenta que el proxy solo almacena en caché los hashes de los fragmentos de resultados y no almacena en caché las recetas. El proxy construye un RecipeResultSet verificando la similitud en todo el resultado y luego a nivel de fila. Si se predice que todo el resultado estará presente en la caché de los controladores de Ganesh, el RecipeResultSet será simplemente un único hash de todo el resultado. De lo contrario, contiene hashes para aquellas filas que se predice que están presentes en esa caché; todas las demás filas se conservan textualmente. Si el proxy estima un ahorro de espacio general, transmitirá el RecipeResultSet. De lo contrario, se transmite el ResultSet original. Los objetos RecipeResultSet son transformados de vuelta en objetos ResultSet por el controlador Ganesh. La Figura 4 ilustra el manejo de ResultSet en ambos extremos. Cada hash SHA-1 encontrado en un RecipeResultSet se busca en la caché local de fragmentos de resultados. En caso de acierto, el hash es reemplazado por el fragmento correspondiente. En caso de error, el conductor contacta al proxy de Ganesh para recuperar el fragmento. Todos los fragmentos de resultados previamente no vistos que fueron retenidos textualmente por el proxy se hasheado y se han añadido a la caché de resultados. Debería haber muy pocos fallos si el proxy ha seguido con precisión el estado de la caché de controladores de Ganesh. Una optimización futura sería agrupar la obtención de fragmentos faltantes. Esto sería valioso cuando hay muchos pequeños fragmentos faltantes en una WAN de alta latencia. Una vez que la transformación esté completa, el objeto ResultSet completamente reconstruido se pasa a la aplicación. 4. VALIDACIÓN EXPERIMENTAL Tres preguntas surgen de los objetivos y diseño de Ganesh: • Primero, ¿se puede mejorar significativamente el rendimiento al explotar la similitud entre los resultados de la base de datos? Detalles del conjunto de datos de referencia 500,000 usuarios, 12,000 historias BBOARD 2.0 GB 3,298,000 comentarios SUBASTA 1.3 GB 1,000,000 usuarios, 34,000 elementos Tabla 1: Detalles del conjunto de datos de referencia • En segundo lugar, ¿qué tan importante es la detección de similitud estructural de Ganesh en comparación con la detección de similitud de la huella digital de Rabin? • En tercer lugar, ¿es aceptable la sobrecarga del diseño basado en proxy? Nuestra evaluación responde a estas preguntas a través de experimentos controlados con el prototipo Ganesh. Esta sección describe los puntos de referencia utilizados, nuestro procedimiento de evaluación y la configuración experimental. Los resultados de los experimentos se presentan en las Secciones 5, 6 y 7. 4.1 Puntos de referencia Nuestra evaluación se basa en dos puntos de referencia [18] que han sido ampliamente utilizados por otros investigadores para evaluar varios aspectos de arquitecturas multi-tier [27] y de comercio electrónico [9]. El primer punto de referencia, BBOARD, está modelado según Slashdot, un sitio de noticias orientado a la tecnología. El segundo punto de referencia, AUCTION, está modelado según eBay, un sitio de subastas en línea. En ambos puntos de referencia, la mayoría del contenido se genera dinámicamente a partir de la información almacenada en una base de datos. Los detalles de los conjuntos de datos utilizados se pueden encontrar en la Tabla 1. 4.1.1 El Benchmark BBOARD El benchmark BBOARD, también conocido como RUBBoS [18], modela Slashdot, un popular sitio web orientado a la tecnología. Slashdot recopila enlaces a noticias y otros temas de interés encontrados en otros lugares de la web. El sitio también funciona como un tablón de anuncios al permitir a los usuarios comentar en las historias publicadas en forma de conversación en hilos. No es raro que una historia recopile cientos de comentarios en cuestión de horas. El benchmark BBOARD es similar al sitio y modela las actividades de un usuario, incluyendo operaciones de solo lectura como navegar por las historias del día, explorar categorías de historias y ver comentarios, así como operaciones de escritura como registro de nuevos usuarios, agregar y moderar comentarios, y enviar historias. El benchmark consiste en tres fases diferentes: una fase de calentamiento corta, una fase de ejecución que representa el cuerpo principal de la carga de trabajo, y una fase de enfriamiento corta. En este documento solo informamos sobre los resultados de la fase de ejecución. La fase de calentamiento es importante para establecer el estado del sistema dinámico, pero las mediciones de esa fase no son significativas para nuestra evaluación. La fase de enfriamiento es únicamente para permitir que el punto de referencia se apague. Las fases de calentamiento, ejercicio y enfriamiento son de 2, 15 y 2 minutos respectivamente. El número de clientes simulados fue de 400, 800, 1200 y 1600. El punto de referencia está disponible en una versión de Java Servlets y PHP y tiene diferentes conjuntos de datos; evaluamos a Ganesh utilizando la versión de Java Servlets y el conjunto de datos Expandido. El benchmark BBOARD define dos cargas de trabajo diferentes. El primero, la mezcla de Autoría, consiste en un 70% de operaciones de solo lectura y un 30% de operaciones de lectura y escritura. El segundo, la mezcla de navegación, contiene solo operaciones de solo lectura y no actualiza la base de datos. 4.1.2 El Benchmark de SUBASTA El benchmark de SUBASTA, también conocido como RUBiS [18], modela eBay, el sitio de subastas en línea. El sitio web de eBay se utiliza para comprar y vender artículos a través de un formato de subasta. Las principales actividades de un usuario incluyen navegar, vender o pujar por artículos. Modelando las actividades en este sitio, este punto de referencia incluye actividades de solo lectura como navegar por artículos por categoría y por región, así como actividades de lectura-escritura como pujar por artículos, comprar y vender artículos, y dejar comentarios. Al igual que con BBOARD, el benchmark consiste en tres fases diferentes. Las fases de calentamiento, ejecución y enfriamiento para este experimento son de 1.5, 15 y 1 minutos respectivamente. Probamos Ganesh con cuatro configuraciones de clientes donde el número de clientes de prueba se estableció en 400, 800, 1200 y 1600. El punto de referencia está disponible en una versión de Enterprise Java Bean (EJB), Java Servlets y PHP y tiene diferentes conjuntos de datos; evaluamos Ganesh con la versión de Java Servlets y el conjunto de datos Expandido. El benchmark de SUBASTA define dos cargas de trabajo diferentes. El primero, la mezcla de Ofertas, consiste en un 70% de operaciones de solo lectura y un 30% de operaciones de lectura-escritura. El segundo, la mezcla de navegación, contiene solo operaciones de solo lectura y no actualiza la base de datos. 4.2 Procedimiento Experimental Ambos benchmarks involucran una carga de trabajo sintética de clientes accediendo a un servidor web. El número de clientes emulados es un parámetro experimental. Cada cliente emulado ejecuta una instancia del benchmark en su propio hilo, utilizando una matriz para hacer la transición entre diferentes estados del benchmark. La matriz define un modelo estocástico con probabilidades de transición entre los diferentes estados que representan las acciones típicas de los usuarios. Un ejemplo de transición es un usuario iniciando sesión en el sistema de SUBASTA y luego decidiendo si publicar un artículo en venta o pujar en subastas activas. Cada cliente también modela el tiempo de pensamiento del usuario entre las solicitudes. El tiempo de pensamiento se modela como una distribución exponencial con una media de 7 segundos. Evaluamos a Ganesh a lo largo de dos ejes: número de clientes y ancho de banda de la WAN. Las cargas más altas son especialmente útiles para comprender el rendimiento de Ganesh cuando la CPU o el disco del servidor de base de datos o del proxy son el factor limitante. Un estudio previo ha demostrado que aproximadamente el 50% de los cuellos de botella de Internet de gran área observados tenían un ancho de banda disponible inferior a 10 Mb/s [1]. Basándonos en este trabajo, enfocamos nuestra evaluación en el ancho de banda de la WAN de 5 Mb/s con una latencia de ida y vuelta de 66 ms, representativa de rutas de red severamente restringidas, y 20 Mb/s con una latencia de ida y vuelta de 33 ms, representativa de una ruta de red moderadamente restringida. También informamos sobre el rendimiento de Ganesh a 100 Mb/s sin agregar latencia de ida y vuelta. Este ancho de banda, representativo de una red sin restricciones, es especialmente útil para revelar cualquier sobrecarga potencial de Ganesh en situaciones donde el ancho de banda de la WAN no es el factor limitante. Para cada combinación de número de clientes y ancho de banda de WAN, medimos los resultados de las dos configuraciones enumeradas a continuación: • Nativa: Esta configuración corresponde a la Figura 3(a). El nativo evita la sobrecarga de Ganesh al usar un proxy y realizar la serialización de objetos Java. • Ganesh: Esta configuración corresponde a la Figura 3(b). Para un número dado de clientes y ancho de banda de WAN, comparar estos resultados con los resultados nativos correspondientes proporciona el beneficio de rendimiento debido al sistema de middleware Ganesh. La métrica utilizada para cuantificar la mejora en el rendimiento es el número de solicitudes de clientes que pueden ser atendidas por segundo. La métrica utilizada para cuantificar el rendimiento de Ganesh es el tiempo promedio de respuesta para una solicitud de cliente. Para todos los experimentos, el controlador Ganesh utilizado por el servidor de aplicaciones usó un tamaño de caché de 100,000 elementos. El proxy fue efectivo en rastrear el estado de la caché de los controladores Ganesh; para todos nuestros experimentos, la tasa de fallos en el controlador nunca superó el 0.7%. 4.3 Configuración Experimental La configuración experimental utilizada para las pruebas se puede ver en la Figura 5. Todas las máquinas eran Pentium 4 de 3.2 GHz (con HyperThreading habilitado). Con la excepción del servidor de base de datos, todas las máquinas tenían 2 GB de SDRAM y ejecutaban la distribución de Linux Fedora Core. El servidor de la base de datos tenía 4 GB de SDRAM. Utilizamos Apache Tomcat como tanto el servidor de aplicaciones que alojaba los Servlets de Java como el servidor web. Ambos benchmarks utilizaron Java Servlets para generar el contenido dinámico. El servidor de la base de datos utilizó la base de datos de código abierto MySQL. Para los controladores JDBC nativos, utilizamos los controladores Connector/J proporcionados por MySQL. El servidor de aplicaciones utilizaba la Máquina Virtual de Java de Sun como entorno de ejecución para los Servlets de Java. La herramienta sysstat se utilizó para monitorear la utilización de la CPU, red, disco y memoria en todas las máquinas. Las máquinas estaban conectadas por una red Ethernet gigabit conmutada. Como se muestra en la Figura 5, el servidor web y de aplicación de front-end fue separado del servidor de proxy y base de datos por un enrutador NetEm [16]. Este enrutador nos permitió controlar la configuración de ancho de banda y latencia en la red. El enrutador NetEm es un PC estándar con dos tarjetas de red que ejecuta el software de Control de Tráfico de Linux y Emulación de Red. Las restricciones de ancho de banda y latencia solo se aplicaron al enlace entre el servidor de aplicaciones y la base de datos para el caso nativo y entre el servidor de aplicaciones y el proxy para el caso de Ganesh. No hay comunicación entre el servidor de aplicaciones y la base de datos con Ganesh, ya que todos los datos fluyen a través del proxy. Como nuestro enfoque estaba en el enlace WAN entre el servidor de aplicaciones y la base de datos, no hubo restricciones en el enlace entre los clientes de prueba simulados y el servidor web. 5. DESEMPEÑO Y TIEMPO DE RESPUESTA En esta sección, abordamos la primera pregunta planteada en la Sección 4: ¿Se puede mejorar significativamente el rendimiento explotando la similitud entre los resultados de la base de datos? Para responder a esta pregunta, utilizamos los resultados de los benchmarks BBOARD y AUCTION. Utilizamos dos métricas para cuantificar la mejora en el rendimiento obtenible a través del uso de Ganesh: el throughput, desde la perspectiva del servidor web, y el tiempo de respuesta promedio, desde la perspectiva del cliente. El rendimiento se mide en términos del número de solicitudes de clientes que pueden ser atendidas por segundo. Los resultados y análisis de BBOARD 5.1 Figuras 6 (a) y (b) presentan el número promedio de solicitudes atendidas por segundo y el tiempo de respuesta promedio para estas solicitudes tal como lo perciben los clientes para la Mezcla de Autoría de BBOARD. Como muestra la Figura 6 (a), Native satura fácilmente el enlace de 5 Mb/s. Con 400 clientes, la solución nativa entrega 29 solicitudes/segundo con un tiempo de respuesta promedio de 8.3 segundos. La capacidad de procesamiento de los clientes disminuye con un aumento en los clientes de prueba, ya que los clientes se agotan debido a la congestión en el servidor de aplicaciones. Los estudios de usabilidad han demostrado que los tiempos de respuesta superiores a 10 segundos hacen que el usuario pase a 1. Dado que Java carece de un operador sizeof(), los cachés de Java limitan su tamaño en función del número de objetos. El tamaño de los volcados de caché tomados al final de los experimentos nunca superó los 212 MB. WWW 2007 / Pista: Rendimiento y Escalabilidad Sesión: Sistemas Escalables para Contenido Dinámico 315 0 50 100 150 200 250 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Solicitudes de Clientes de Prueba por Segundo Nativo Ganesh 0.001 0.01 0.1 1 10 100 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Tiempo Promedio de Respuesta de Clientes de Prueba Nativo Ganesh Nota Escala Logarítmica (a) Rendimiento: Mezcla de Autoría (b) Tiempo de Respuesta: Mezcla de Autoría 0 50 100 150 200 250 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Solicitudes de Clientes de Prueba por Segundo Nativo Ganesh 0.001 0.01 0.1 1 10 100 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Tiempo Promedio de Respuesta de Clientes de Prueba Nativo Ganesh Nota Escala Logarítmica (c) Rendimiento: Mezcla de Navegación (d) Tiempo de Respuesta: Mezcla de Navegación Promedio de tres pruebas. La desviación estándar máxima para el rendimiento y el tiempo de respuesta fue del 9.8% y 11.9% de la media correspondiente. Figura 6: BBOARD Benchmark - Rendimiento y Tiempo de Respuesta Promedio de otras tareas [24]. Basándose en estos números, aumentar el número de clientes de prueba hace que el sistema Nativo sea inutilizable. Ganesh a 5 Mb/s, sin embargo, ofrece una mejora doble con 400 clientes de prueba y una mejora quintuple con 1200 clientes. El rendimiento de Ganesh disminuye ligeramente a 1200 y 1600 clientes debido a que la red está saturada. En comparación con Native, la Figura 6 (b) muestra que los tiempos de respuesta de Ganesh son considerablemente más bajos con tiempos de respuesta de menos de un segundo con 400 clientes. La Figura 6 (a) también muestra que para 400 y 800 clientes de prueba, Ganesh a 5 Mb/s tiene el mismo rendimiento y tiempo de respuesta promedio que Native a 20 Mb/s. Solo con 1200 y 1600 clientes, Native a 20 Mb/s ofrece un rendimiento mayor que Ganesh a 5 Mb/s. Al comparar tanto a Ganesh como a Native a 20 Mb/s, vemos que Ganesh ya no está limitado por el ancho de banda y ofrece hasta una mejora del doble sobre Native con 1600 clientes de prueba. Como Ganesh no satura la red con configuraciones de cliente de prueba más altas, con 1600 clientes de prueba, su tiempo de respuesta promedio es de 0.1 segundos en lugar de los 7.7 segundos de Natives. Como era de esperar, no hay ganancias visibles de Ganesh en el ancho de banda más alto de 100 Mb/s donde la red ya no es el cuello de botella. Sin embargo, Ganesh sigue monitoreando a Native en cuanto a rendimiento. Las Figuras 6 (c) y (d) presentan el número promedio de solicitudes atendidas por segundo y el tiempo de respuesta promedio para estas solicitudes tal como lo perciben los clientes para la Mezcla de Navegación de BBOARDs. Independientemente de la configuración del cliente de prueba, la Figura 6 (c) muestra que el rendimiento de los Nativos a 5 Mb/s está limitado a 10 reqs/seg. Ganesh a 5 Mb/s con 400 clientes de prueba, ofrece un aumento de más de seis veces en el rendimiento. La mejora aumenta a más de once veces a 800 clientes de prueba antes de que Ganesh sature la red. Además, la Figura 6 (d) muestra que el tiempo de respuesta promedio de los Nativos de 35 segundos con 400 clientes de prueba hace que el sistema sea inutilizable. Estos altos tiempos de respuesta aumentan aún más con la adición de clientes de prueba. Incluso con la configuración del cliente de prueba de 1600, Ganesh ofrece un tiempo de respuesta promedio aceptable de 8.2 segundos. Debido a la naturaleza intensiva en datos de la mezcla de navegación, Ganesh a 5 Mb/s sorprendentemente tiene un rendimiento mucho mejor que Native a 20 Mb/s. Además, como se muestra en la Figura 6 (d), si bien el tiempo de respuesta promedio para Native a 20 Mb/s es aceptable con 400 clientes de prueba, resulta inutilizable con 800 clientes de prueba, con un tiempo de respuesta promedio de 15.8 segundos. Al igual que en el caso de 5 Mb/s, este tiempo de respuesta aumenta con la adición de clientes de prueba adicionales. Ganesh a 20 Mb/s y tanto Native como Ganesh a 100 Mb/s no tienen limitaciones de ancho de banda. Sin embargo, el rendimiento se estanca después de 1200 clientes de prueba debido a que la CPU de la base de datos está saturada. 5.1.3 Variante de filtro Nos sorprendió el rendimiento nativo del benchmark BBOARD. A una velocidad de banda ancha de 5 Mb/s, el rendimiento nativo fue más bajo de lo que esperábamos. Resultó que el código de referencia que muestra historias leía todos los comentarios asociados con la historia en particular de la base de datos y solo entonces realizaba un postprocesamiento para seleccionar los comentarios que se mostrarían. Si bien este es exactamente el comportamiento de SlashCode, la base de código detrás del sitio web de Slashdot, decidimos modificar la prueba de rendimiento para realizar cierto prefiltrado en la base de datos. Este benchmark modificado, llamado el Filtro de Variantes, modela a un desarrollador que aplica optimizaciones a nivel de SQL para transferir menos datos. En aras de la brevedad, solo resumimos brevemente los resultados de la mezcla de autores. Para la mezcla de Autoría, con 800 clientes de prueba a 5 Mb/s, la Figura 7 (a) muestra que el rendimiento de Natives aumenta un 85% en comparación con el punto de referencia original, mientras que la mejora de Ganesh es menor, del 15%. El rendimiento de los servidores disminuye por encima de los 800 clientes, ya que los clientes de prueba se agotan debido a los altos tiempos de respuesta. La ganancia más significativa para Native se observa a 20 Mb/s. En 1600 clientes de prueba, en comparación con el punto de referencia original, Native experimenta una mejora del 73% en el rendimiento y una reducción del 77% en el tiempo de respuesta promedio. Mientras WWW 2007 / Pista: Rendimiento y Escalabilidad Sesión: Sistemas Escalables para Contenido Dinámico 316 0 50 100 150 200 250 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Clientes de Prueba Solicitudes/seg Nativo Ganesh 0.001 0.01 0.1 1 10 100 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Clientes de Prueba Tiempo de Resp. Promedio (seg) Nativo Ganesh Nota Escala Logarítmica (a) Rendimiento: Mezcla de Autoría (b) Tiempo de Respuesta: Mezcla de Autoría Promedio de tres pruebas. La desviación estándar máxima para el rendimiento y el tiempo de respuesta fue del 7.2% y del 11.5% de la media correspondiente. Figura 7: BBOARD Benchmark - Variante de filtro - Rendimiento y Tiempo de Respuesta Promedio Ganesh no observa ninguna mejora en comparación con el original, aún procesa un 19% más de solicitudes/seg que Native. Por lo tanto, aunque las optimizaciones fueron más útiles para Native, Ganesh todavía ofrece una mejora en el rendimiento. 5.2 Resultados y Análisis de la SUBASTA 5.2.1 Figuras de la Mezcla de Ofertas Los gráficos 8 (a) y (b) presentan el número promedio de solicitudes atendidas por segundo y el tiempo de respuesta promedio para estas solicitudes tal como son percibidas por los clientes para la Mezcla de Ofertas de las SUBASTAS. Como se mencionó anteriormente, la mezcla de ofertas consiste en una combinación de operaciones de lectura y escritura. El benchmark AUCTION no es tan intensivo en datos como BBOARD. Por lo tanto, la mayoría de las ganancias se observan en el ancho de banda más bajo de 5 Mb/s. La figura 8 (a) muestra que el aumento en el rendimiento debido a Ganesh varía desde un 8% con 400 clientes de prueba hasta un 18% con 1600 clientes de prueba. Como se observa en la Figura 8 (b), los tiempos de respuesta promedio para Ganesh son significativamente más bajos que los de Native, con una disminución del 84% a 800 clientes de prueba y del 88% a 1600 clientes de prueba. La Figura 8 (a) también muestra que con un aumento cuádruple del ancho de banda de 5 Mb/s a 20 Mb/s, Native ya no está limitado por el ancho de banda y no hay diferencia de rendimiento entre Ganesh y Native. Con las configuraciones de cliente de prueba más altas, observamos que el ancho de banda utilizado por Ganesh era menor que el de Nativo. Ganesh podría seguir siendo útil en estos escenarios no restringidos si se compra ancho de banda de forma medible. Se observan resultados similares para el escenario de 100 Mb/s. 5.2.2 Mezcla de Navegación Para la Mezcla de Navegación de SUBASTAS, las Figuras 8 (c) y (d) presentan el número promedio de solicitudes atendidas por segundo y el tiempo promedio de respuesta para estas solicitudes tal como lo perciben los clientes. Una vez más, la mayoría de las ganancias se observan en anchos de banda más bajos. A 5 Mb/s, Native y Ganesh ofrecen un rendimiento y tiempos de respuesta similares con 400 clientes de prueba. Mientras que el rendimiento para ambos permanece igual en 800 clientes de prueba, la Figura 8 (d) muestra que el tiempo de respuesta promedio de Ganesh es un 62% menor que el de Native. El servidor satura el enlace con 800 clientes y agregar clientes de prueba adicionales solo aumenta el tiempo promedio de respuesta. Ganesh, independientemente de la configuración del cliente de prueba, no tiene restricciones de ancho de banda y mantiene el mismo tiempo de respuesta. A 1600 clientes de prueba, la Figura 8 (c) muestra que el rendimiento de Ganesh es casi el doble que el de Nativo. En los anchos de banda más altos de 20 y 100 Mb/s, ni Ganesh ni Native tienen limitaciones de ancho de banda y ofrecen un rendimiento y tiempos de respuesta equivalentes. Referencia original. Tamaño Ganesh Tamaño Rabin Tamaño SelectSort1 223.6 MB 5.4 MB 219.3 MB SelectSort2 223.6 MB 5.4 MB 223.6 MB Tabla 2: Microbenchmarks de similitud 6. SIMILITUD ESTRUCTURAL VS. SIMILITUD DE RABIN En esta sección, abordamos la segunda pregunta planteada en la Sección 4: ¿Qué tan importante es la detección de similitud estructural de Ganesh en comparación con la detección de similitud basada en la huella digital de Rabin? Para responder a esta pregunta, utilizamos microbenchmarks y los benchmarks BBOARD y AUCTION. Dado que Ganesh siempre tuvo un mejor rendimiento que Rabin en la huella dactilar, aquí presentamos solo un subconjunto de los resultados en aras de la brevedad. 6.1 Microbenchmarks Dos microbenchmarks muestran un ejemplo de los efectos de la reordenación de datos en el algoritmo de huella dactilar de Rabin. En el primer microbenchmark, SelectSort1, una consulta con un orden de clasificación especificado selecciona 223.6 MB de datos distribuidos en aproximadamente 280 K filas. La consulta se repite entonces con un atributo de ordenación diferente. Si bien se devuelve el mismo número de filas y los mismos datos, el orden de las filas es diferente. En un escenario así, se esperaría detectar una gran cantidad de similitud entre ambos resultados. Como muestra la Tabla 2, el algoritmo basado en filas de Ganesh logra una reducción del 97.6%, mientras que el algoritmo de huella digital de Rabin, con el parámetro de tamaño de fragmento promedio establecido en 4 KB, solo logra una reducción del 1%. La razón, como se muestra anteriormente en la Figura 2, es que con la huella digital de Rabin, los tramos de datos entre dos límites consecutivos suelen cruzar los límites de fila. Con el cambio en el orden de las filas en el segundo resultado y los fingerprints de Rabin ahora abarcando diferentes filas, el algoritmo no puede detectar similitud significativa. La pequeña ganancia observada se debe principalmente a aquellas filas individuales que son lo suficientemente grandes como para dividirse en múltiples fragmentos. SelectSort2, otro micro-benchmark ejecutó las mismas consultas pero aumentó el tamaño mínimo del fragmento del algoritmo de huella digital de Rabin. Como se puede ver en la Tabla 2, incluso la pequeña ganancia del microbenchmark anterior desaparece cuando el tamaño mínimo de fragmento fue mayor que el tamaño promedio de fila. Si bien se pueden abordar parcialmente estos problemas variando dinámicamente los parámetros del algoritmo de huella digital de Rabin, esto puede resultar computacionalmente costoso, especialmente en presencia de cargas de trabajo cambiantes. 6.2 Benchmarks de Aplicación Ejecutamos el benchmark BBOARD descrito en la Sección 4.1.1 en dos versiones de Ganesh: la primera con la huella digital de Rabin utilizada como WWW 2007 / Track: Sesión de Rendimiento y Escalabilidad: Sistemas Escalables para Contenido Dinámico 317 0 50 100 150 200 250 300 350 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Clientes de Prueba Solicitudes/seg Ganesh Nativo 0.001 0.01 0.1 1 10 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Clientes de Prueba Tiempo de Respuesta Promedio (seg) Ganesh Nativo Nota Escala Logarítmica (a) Rendimiento: Mezcla de Ofertas (b) Tiempo de Respuesta: Mezcla de Ofertas 0 50 100 150 200 250 300 350 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Clientes de Prueba Solicitudes/seg Ganesh Nativo 0.001 0.01 0.1 1 10 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Clientes de Prueba Tiempo de Respuesta Promedio (seg) Ganesh Nativo Nota Escala Logarítmica (c) Rendimiento: Mezcla de Navegación (d) Tiempo de Respuesta: Mezcla de Navegación Promedio de tres pruebas. La desviación estándar máxima para el rendimiento y el tiempo de respuesta fue del 2.2% y del 11.8% de la media correspondiente. Figura 8: Referencia de la subasta AUCTION - Rendimiento y Tiempo de Respuesta Promedio del algoritmo de fragmentación y el segundo con el algoritmo basado en filas de Ganesh. Los resultados de Rabins para la Mezcla de Navegación se normalizan con los resultados de Ganesh y se presentan en la Figura 9. Como muestra la Figura 9 (a), a 5 Mb/s, independientemente de la configuración del cliente de prueba, Rabin tiene un rendimiento significativamente inferior a Ganesh. Esto sucede debido a una combinación de dos razones. Primero, como se describe en la Sección 3.1, Rabin encuentra menos similitud ya que no explota la información estructural de los resultados. Segundo, este punto de referencia contenía algunas consultas que generaron resultados grandes. En este caso, Rabin, con un tamaño de fragmento promedio pequeño, generó una gran cantidad de objetos que desplazaron otros datos útiles de la caché. Por el contrario, Ganesh pudo detectar estas filas grandes y aumentar correspondientemente el tamaño de los bloques. Esto fue confirmado ya que las estadísticas de caché mostraron que la proporción de aciertos de Ganesh era aproximadamente tres veces mayor que la de Rabin. Las mediciones de rendimiento a 20 Mb/s fueron similares, con la excepción del rendimiento de Rabins con 400 clientes de prueba. En este caso, Ganesh no estaba limitado por la red y, de hecho, el rendimiento era el mismo que el de 400 clientes a 5 Mb/s. Rabin, sin embargo, aprovechó el aumento del ancho de banda de 5 a 20 Mb/s para ofrecer un rendimiento ligeramente mejor. A 100 Mb/s, el rendimiento de Rabin era casi similar al de Ganesh ya que el ancho de banda ya no era un cuello de botella. El tiempo de respuesta normalizado, presentado en la Figura 9 (b), muestra tendencias similares. A 5 y 20 Mb/s, la adición de clientes de prueba disminuye el tiempo de respuesta normalizado, ya que el tiempo de respuesta promedio de Ganesh aumenta más rápido que el de Rabin. Sin embargo, en ningún momento Rabin supera a Ganesh. Ten en cuenta que con 400 y 800 clientes a 100 Mb/s, Rabin tiene un mayor sobrecosto incluso cuando no está limitado por el ancho de banda. Como se menciona en la Sección 3.1, esto se debe a que Rabin tiene que hashear cada ResultSet dos veces. La sobrecarga desaparece con 1200 y 1600 clientes, ya que la CPU de la base de datos está saturada y limita el rendimiento tanto de Ganesh como de Rabin. 7. SUPERPOSICIÓN DE PROXY En esta sección, abordamos la tercera pregunta planteada en la Sección 4: ¿Es aceptable la superposición del diseño basado en proxy de Ganesh? Para responder a esta pregunta, nos concentramos en su rendimiento en las bandas de mayor ancho de banda. Nuestra evaluación en la Sección 5 mostró que Ganesh, en comparación con Native, puede ofrecer una mejora sustancial en el rendimiento a anchos de banda más bajos. Solo en anchos de banda más altos serían visibles los costos adicionales de latencia, medidos por el tiempo promedio de respuesta para una solicitud de cliente, y de rendimiento, medidos por la cantidad de solicitudes de cliente que pueden ser atendidas por segundo. Al observar la combinación de autoría del benchmark original de BBOARD, no se aprecian ganancias visibles de Ganesh a 100 Mb/s. Sin embargo, Ganesh sigue rastreando a Native en cuanto a rendimiento. Si bien el tiempo promedio de respuesta es mayor para Ganesh, la diferencia absoluta está entre 0.01 y 0.04 segundos y sería imperceptible para el usuario final. La mezcla de navegación muestra una diferencia aún menor en los tiempos de respuesta promedio. Los resultados de la variante del filtro de los benchmarks de BBOARD son similares. Incluso para el benchmark de SUBASTA, la diferencia entre el tiempo de respuesta de Nativo y Ganesh a 100 Mb/s nunca fue mayor a 0.02 segundos. La única excepción a los resultados anteriores se observó en la variante de filtro del benchmark BBOARD, donde Ganesh con 1600 clientes de prueba añadió 0.85 segundos al tiempo de respuesta promedio. Por lo tanto, incluso para redes mucho más rápidas donde el enlace WAN no es el cuello de botella, Ganesh siempre ofrece un rendimiento equivalente al Nativo. Si bien se agrega algo de latencia adicional debido al diseño basado en proxy, generalmente es imperceptible. TRABAJO RELACIONADO Hasta donde sabemos, Ganesh es el primer sistema que combina el uso de técnicas basadas en hash con el almacenamiento en caché de resultados de base de datos para mejorar el rendimiento y los tiempos de respuesta de aplicaciones con contenido dinámico. También creemos que es el primer sistema en demostrar los beneficios de utilizar información estructural para WWW 2007 / Track: Rendimiento y Escalabilidad Sesión: Sistemas Escalables para Contenido Dinámico 318 0.0 0.2 0.4 0.6 0.8 1.0 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Clientes de Prueba Rendimiento Normalizado 31.8 3.8 2.8 2.3 23.8 32.8 5.8 3.6 1.8 2.1 1.1 1.0 0 5 10 15 20 25 30 35 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Clientes de Prueba Tiempo de Respuesta Normalizado (a) Rendimiento Normalizado: Mayor es mejor (b) Tiempo de Respuesta Normalizado: Mayor es peor Para el rendimiento, un resultado normalizado mayor que 1 implica que Rabin es mejor. Para el tiempo de respuesta, un resultado normalizado mayor que 1 implica que Ganesh es mejor. Media de tres pruebas. La desviación estándar máxima para el rendimiento y el tiempo de respuesta fue del 9.1% y del 13.9% de la media correspondiente. Figura 9: Comparación normalizada de Ganesh vs. Rabin - Mezcla de navegación BBOARD detectando similitud. En esta sección, primero discutimos enfoques alternativos para almacenar en caché contenido dinámico y luego examinamos otros usos de primitivas basadas en hash en sistemas distribuidos. 8.1 Almacenamiento en Caché de Contenido Dinámico En la capa de base de datos, varios sistemas han abogado por la caché de nivel intermedio donde partes de la base de datos se replican en el borde o servidor [3, 4, 20]. Estos sistemas almacenan en caché tablas completas en lo que es esencialmente una base de datos replicada o utilizan vistas materializadas de respuestas de consultas anteriores [19]. Requieren una integración estrecha con la base de datos del sistema para garantizar un límite de tiempo en la propagación de actualizaciones. Estos sistemas suelen estar dirigidos a cargas de trabajo que no requieren una consistencia estricta y pueden tolerar datos obsoletos. Además, a diferencia de Ganesh, algunas de estas soluciones de almacenamiento en caché de nivel medio [2, 3], sufren de la complejidad de tener que participar en la planificación de consultas y el procesamiento de consultas distribuidas. Gao et al. [15] proponen utilizar una arquitectura de replicación de objetos distribuidos donde los requisitos de consistencia de las tiendas de datos se adaptan según la aplicación. Estas soluciones requieren recursos sustanciales de desarrollo y un entendimiento detallado de la aplicación que se está modificando. Si bien existen sistemas que intentan automatizar la partición y replicación de la base de datos de una aplicación [34], no proporcionan semántica de transacciones completa. En comparación, Ganesh no debilita ninguna de las semánticas proporcionadas por la base de datos subyacente. El trabajo reciente en la evaluación de opciones de almacenamiento en caché de borde para sitios web dinámicos [38] ha sugerido que, sin una planificación cuidadosa, el empleo de estrategias complejas de descarga puede perjudicar el rendimiento. En cambio, el trabajo aboga por una arquitectura en la que todos los niveles, excepto la base de datos, deberían ser trasladados al borde. Nuestra evaluación de Ganesh ha demostrado que sería beneficioso para estos escenarios. Para mejorar la escalabilidad de la base de datos, C-JDBC [10], SSS [22] y Ganymed [28] también abogan por el uso de una arquitectura basada en interposición para clusterizar y replicar bases de datos de forma transparente a nivel de middleware. Los enfoques de estas arquitecturas y Ganesh son complementarios y se beneficiarían mutuamente. Avanzando hacia la capa de presentación, se ha producido una amplia adopción de la caché basada en fragmentos [14], la cual mejora la utilización de la caché al almacenar por separado diferentes partes de las páginas web generadas. Si bien el almacenamiento en caché basado en fragmentos funciona en el borde, una propuesta reciente ha propuesto trasladar el ensamblaje de páginas web a los clientes para optimizar la entrega de contenido [31]. Si bien Ganesh no se utiliza en la capa de presentación, los mismos principios se han aplicado en la Detección de Transferencias Duplicadas [25] para aumentar la eficiencia de la caché web, así como para el acceso web a través de enlaces con ancho de banda limitado [33]. 8.2 Sistemas basados en hash En los últimos años han surgido muchos sistemas que explotan técnicas basadas en hash. En el centro de todos estos sistemas se encuentra la idea de detectar similitudes en los datos sin necesidad de interpretar esos datos. Esta idea simple pero elegante se basa en el hash criptográfico, como se discutió anteriormente en la Sección 2. Las aplicaciones exitosas de esta idea abarcan una amplia gama de sistemas de almacenamiento. Los ejemplos incluyen la copia de seguridad entre pares de archivos informáticos personales [11], el archivado eficiente de datos [29] y la búsqueda de archivos similares [21]. Spring y Wetherall [35] aplican principios similares a nivel de red. Utilizando cachés sincronizadas en ambos extremos de un enlace de red, los datos duplicados son reemplazados por tokens más pequeños para su transmisión y luego restaurados en el extremo remoto. Este y otros sistemas basados en hash como los sistemas de archivos CASPER [37] y LBFS [26], y optimizadores de ancho de banda de Capa-2 como Riverbed y Peribit utilizan la huella digital de Rabin [30] para descubrir tramos de similitud en los datos. Este enfoque es especialmente útil cuando los elementos de datos son modificados en su lugar a través de inserciones, eliminaciones y actualizaciones. Sin embargo, como se muestra en la Sección 6, el rendimiento de esta técnica puede experimentar una caída dramática en presencia de reordenamiento de datos. Ganesh en cambio utiliza los límites de fila como divisores para detectar similitudes. El uso más agresivo de técnicas basadas en hash es por sistemas que utilizan hashes como identificadores principales para objetos en almacenamiento persistente. Los sistemas de almacenamiento como CFS [12] y PAST [13] que han sido construidos utilizando tablas hash distribuidas entran en esta categoría. Single Instance Storage [6] y Venti [29] son otros ejemplos de tales sistemas. Como se discute en la Sección 2.2, el uso de hashes criptográficos para abordar datos persistentes representa un nivel más profundo de confianza en su resistencia a colisiones que la asumida por Ganesh. Si el tiempo revela deficiencias en el algoritmo hash, el esfuerzo necesario para corregir la falla es mucho mayor. En Ganesh, simplemente se trata de reemplazar el algoritmo hash. 9. CONCLUSIÓN El creciente uso de contenido web dinámico generado a partir de bases de datos relacionales aumenta las demandas de ancho de banda de la WAN. Las soluciones de almacenamiento en caché tradicionales para reducir el ancho de banda y la latencia suelen ser ineficaces para este tipo de contenido. Este documento muestra que el impacto de los accesos a bases de datos a través de WAN puede reducirse sustancialmente mediante la arquitectura Ganesh sin comprometer la estricta semántica de consistencia de las bases de datos. La esencia de la arquitectura Ganesh es el uso de la computación en los bordes para reducir la comunicación a través de Internet. Ganesh es capaz de utilizar hashes criptográficos para detectar similitud con resultados anteriores y enviar recetas compactas de resultados en lugar de resultados completos en la sesión de Sistemas Escalables para Contenido Dinámico 319 de WWW 2007 / Track: Rendimiento y Escalabilidad. Nuestro diseño utiliza la interposición para lograr una transparencia completa: los clientes, los servidores de aplicaciones y los servidores de bases de datos no son conscientes de la presencia de Ganesh y no requieren ninguna modificación. Nuestra evaluación experimental confirma que Ganesh, aunque conceptualmente simple, puede ser altamente efectivo en mejorar el rendimiento y el tiempo de respuesta. Nuestros resultados también confirman que aprovechar la estructura presente en los resultados de la base de datos para detectar similitudes es crucial para esta mejora en el rendimiento. REFERENCIAS [1] AKELLA, A., SESHAN, S., Y SHAIKH, A. Una evaluación empírica de los cuellos de botella en Internet de área amplia. En Proc. 3ª Conferencia ACM SIGCOMM sobre Medición de Internet (Miami Beach, FL, EE. UU., Oct. 2003), pp. 101-114. [2] ALTINEL, M., BORNH ¨OVD, C., KRISHNAMURTHY, S., MOHAN, C., PIRAHESH, H., Y REINWALD, B. Tablas de caché: allanando el camino para una caché de base de datos adaptativa. En Proc. del 29º VLDB (Berlín, Alemania, 2003), pp. 718-729. [3] ALTINEL, M., LUO, Q., KRISHNAMURTHY, S., MOHAN, C., PIRAHESH, H., LINDSAY, B. G., WOO, H., Y BROWN, L. Dbcache: Caché de base de datos para servidores de aplicaciones web. En Proc. 2002 ACM SIGMOD (2002), pp. 612-612. [4] AMIRI, K., PARK, S., TEWARI, R., Y PADMANABHAN, S. Dbproxy: una caché de datos dinámica para aplicaciones web. En Proc. Conferencia Internacional de Ingeniería de Datos de IEEE (ICDE) (Mar. 2003). [5] BLACK, J. Compare-by-hash: Un análisis razonado. En Proc. Conferencia Técnica Anual USENIX 2006 (Boston, MA, mayo de 2006), pp. 85-90. [6] BOLOSKY, W. J., CORBIN, S., GOEBEL, D., y DOUCEUR, J. R. Almacenamiento de instancia única en Windows 2000. En Proc. 4to Simposio de Sistemas Windows de USENIX (Seattle, WA, ago. 2000), pp. 13-24. [7] BREWER, E. A. Lecciones de servicios a gran escala. IEEE Internet Computing 5, 4 (2001), 46-55. [8] BRODER, A., GLASSMAN, S., MANASSE, M., AND ZWEIG, G. Agrupamiento sintáctico de la web. En Proc. 6ta Conferencia Internacional WWW (1997). [9] CECCHET, E., CHANDA, A., ELNIKETY, S., MARGUERITE, J., Y ZWAENEPOEL, W. Comparación de rendimiento de arquitecturas de middleware para generar contenido web dinámico. En Proc. Cuarta Conferencia Internacional de Middleware ACM/IFIP/USENIX (Río de Janeiro, Brasil, junio de 2003). [10] CECCHET, E., MARGUERITE, J., Y ZWAENEPOEL, W. C-JDBC: Middleware flexible de agrupación de bases de datos. En Proc. Conferencia Técnica Anual USENIX 2004 (Boston, MA, junio de 2004). [11] COX, L. P., MURRAY, C. D., Y NOBLE, B. D. Pastiche: Haciendo que la copia de seguridad sea barata y fácil. En OSDI: Simposio sobre Diseño e Implementación de Sistemas Operativos (2002). [12] DABEK, F., KAASHOEK, M. F., KARGER, D., MORRIS, R., Y STOICA, I. Almacenamiento cooperativo de amplia área con CFS. En el 18º Simposio ACM sobre Principios de Sistemas Operativos (Banff, Canadá, octubre de 2001). [13] DRUSCHEL, P., Y ROWSTRON, A. PASADO: Una utilidad de almacenamiento entre pares a gran escala y persistente. En HotOS VIII (Schloss Elmau, Alemania, mayo de 2001), pp. 75-80. [14] Incluye el lado del borde. http://www.esi.org. [15] GAO, L., DAHLIN, M., NAYATE, A., ZHENG, J., Y IYENGAR, A. Replicación de datos específica de la aplicación para servicios en el borde. En WWW 03: Proc. Duodécima Conferencia Internacional sobre la World Wide Web (2003), pp. 449-460. [16] HEMMINGER, S. Netem - emulando redes reales en el laboratorio. En Proc. 2005 Linux Conference Australia (Canberra, Australia, Abr. 2005). [17] HENSON, V. Un análisis de compare-by-hash. En Proc. 9º Taller sobre Temas Candentes en Sistemas Operativos (HotOS IX) (mayo de 2003), pp. 13-18. [18] Benchmarks de Jmob. http://jmob.objectweb.org/. [19] LABRINIDIS, A., Y ROUSSOPOULOS, N. Equilibrando el rendimiento y la frescura de los datos en servidores de bases de datos web. En Proc. 29ª Conferencia VLDB (Sept. 2003). [20] LARSON, P.-A., GOLDSTEIN, J., Y ZHOU, J. Caché transparente de bases de datos en el nivel intermedio en SQL Server. En Proc. 2003 ACM SIGMOD (2003), pp. 661-661. [21] MANBER, U. Encontrar archivos similares en un sistema de archivos grande. En Proc. Conferencia Técnica de Invierno de USENIX 1994 (San Francisco, CA, 17-21 de 1994), pp. 1-10. [22] MANJHI, A., AILAMAKI, A., MAGGS, B. M., MOWRY, T. C., OLSTON, C., Y TOMASIC, A. Escalabilidad y seguridad simultáneas para aplicaciones web intensivas en datos. En Proc. 2006 ACM SIGMOD (junio de 2006), pp. 241-252. [23] MENEZES, A. J., VANSTONE, S. A., Y OORSCHOT, P. C. V. Manual de Criptografía Aplicada. CRC Press, 1996. [24] MILLER, R. B. \n\nCRC Press, 1996. [24] MILLER, R. B. Tiempo de respuesta en transacciones conversacionales entre humanos y computadoras. En Proc. Conferencia Conjunta de Computación de Otoño de AFIPS (1968), pp. 267-277. [25] MOGUL, J. C., CHAN, Y. M., Y KELLY, T. Diseño, implementación y evaluación de la detección de transferencias duplicadas en http. En Proc. Primer Simposio sobre Diseño e Implementación de Sistemas en Red (San Francisco, CA, Mar. 2004). [26] MUTHITACHAROEN, A., CHEN, B., Y MAZIERES, D. Un sistema de archivos en red de bajo ancho de banda. En Proc. 18º Simposio de la ACM sobre Principios de Sistemas Operativos (Banff, Canadá, Oct. 2001). [27] PFEIFER, D., Y JAKSCHITSCH, H. Caché basada en métodos en aplicaciones de servidores multinivel. En Proc. Quinto Simposio Internacional sobre Objetos y Aplicaciones Distribuidas (Catania, Sicilia, Italia, noviembre de 2003). [28] PLATTNER, C., Y ALONSO, G. Ganymed: Replicación escalable para aplicaciones web transaccionales. En Proc. 5ta Conferencia Internacional de Middleware ACM/IFIP/USENIX (2004), pp. 155-174. [29] QUINLAN, S., Y DORWARD, S. Venti: Un nuevo enfoque para el almacenamiento de archivos. En Proc. Conferencia FAST 2002 sobre Tecnologías de Archivo y Almacenamiento (2002). [30] RABIN, M. Huellas dactilares mediante polinomios aleatorios. En el Informe Técnico TR-15-81 (1981) del Centro de Investigación en Tecnología Informática de la Universidad de Harvard. [31] RABINOVICH, M., XIAO, Z., DOUGLIS, F., Y KALMANEK, C. Mover los lados de los bordes incluye a los clientes reales en el borde. En Proc. 4to Simposio USENIX sobre Tecnologías y Sistemas de Internet (Seattle, WA, Mar. 2003). [32] REESE, G. Programación de bases de datos con JDBC y Java, 1ra ed. OReilly, junio de 1997. [33] RHEA, S., LIANG, K., Y BREWER, E. Caché web basada en valores. En Proc. Duodécima Conferencia Internacional de la World Wide Web (mayo de 2003). [34] SIVASUBRAMANIAN, S., ALONSO, G., PIERRE, G., Y VAN STEEN, M. Globedb: Replicación autónoma de datos para aplicaciones web. En WWW 05: Actas de la 14ª Conferencia Internacional de la World-Wide Web (mayo de 2005). [35] SPRING, N. T., Y WETHERALL, D. Una técnica independiente de protocolo para eliminar el tráfico de red redundante. En Proc. de ACM SIGCOMM (Ago. 2000). [36] TOLIA, N., HARKES, J., KOZUCH, M., Y SATYANARAYANAN, M. Integrando almacenamiento portátil y distribuido. En Proc. 3ra Conferencia USENIX sobre Tecnologías de Archivos y Almacenamiento (San Francisco, CA, Mar. 2004). [37] TOLIA, N., KOZUCH, M., SATYANARAYANAN, M., KARP, B., PERRIG, A., Y BRESSOUD, T. Uso oportunista del almacenamiento direccionable por contenido para sistemas de archivos distribuidos. En Proc. Conferencia Técnica Anual USENIX 2003 (San Antonio, TX, junio de 2003), pp. 127-140. [38] YUAN, C., CHEN, Y., Y ZHANG, Z. Evaluación de almacenamiento en caché/descarga en el borde para la entrega de contenido dinámico. En WWW 03: Proc. Duodécima Conferencia Internacional sobre la World Wide Web (2003), pp. 461-471. WWW 2007 / Pista: Rendimiento y Escalabilidad Sesión: Sistemas Escalables para Contenido Dinámico 320",
    "original_sentences": [
        "Consistency-preserving Caching of Dynamic Database Content∗ Niraj Tolia and M. Satyanarayanan Carnegie Mellon University {ntolia,satya}@cs.cmu.edu ABSTRACT With the growing use of dynamic web content generated from relational databases, traditional caching solutions for throughput and latency improvements are ineffective.",
        "We describe a middleware layer called Ganesh that reduces the volume of data transmitted without semantic interpretation of queries or results.",
        "It achieves this reduction through the use of cryptographic hashing to detect similarities with previous results.",
        "These benefits do not require any compromise of the strict consistency semantics provided by the back-end database.",
        "Further, Ganesh does not require modifications to applications, web servers, or database servers, and works with closed-source applications and databases.",
        "Using two benchmarks representative of dynamic web sites, measurements of our prototype show that it can increase end-to-end throughput by as much as twofold for non-data intensive applications and by as much as tenfold for data intensive ones.",
        "Categories and Subject Descriptors C.2.4 [Computer-Communication Networks]: Distributed Systems; H.2.4 [Database Management]: Systems General Terms Design, Performance 1.",
        "INTRODUCTION An increasing fraction of web content is dynamically generated from back-end relational databases.",
        "Even when database content remains unchanged, temporal locality of access cannot be exploited because dynamic content is not cacheable by web browsers or by intermediate caching servers such as Akamai mirrors.",
        "In a multitiered architecture, each web request can stress the WAN link between the web server and the database.",
        "This causes user experience to be highly variable because there is no caching to insulate the client from bursty loads.",
        "Previous attempts in caching dynamic database content have generally weakened transactional semantics [3, 4] or required application modifications [15, 34].",
        "We report on a new solution that takes the form of a databaseagnostic middleware layer called Ganesh.",
        "Ganesh makes no effort to semantically interpret the contents of queries or their results.",
        "Instead, it relies exclusively on cryptographic hashing to detect similarities with previous results.",
        "Hash-based similarity detection has seen increasing use in distributed file systems [26, 36, 37] for improving performance on low-bandwidth networks.",
        "However, these techniques have not been used for relational databases.",
        "Unlike previous approaches that use generic methods to detect similarity, Ganesh exploits the structure of relational database results to yield superior performance improvement.",
        "One faces at least three challenges in applying hash-based similarity detection to back-end databases.",
        "First, previous work in this space has traditionally viewed storage content as uninterpreted bags of bits with no internal structure.",
        "This allows hash-based techniques to operate on long, contiguous runs of data for maximum effectiveness.",
        "In contrast, relational databases have rich internal structure that may not be as amenable to hash-based similarity detection.",
        "Second, relational databases have very tight integrity and consistency constraints that must not be compromised by the use of hash-based techniques.",
        "Third, the source code of commercial databases is typically not available.",
        "This is in contrast to previous work which presumed availability of source code.",
        "Our experiments show that Ganesh, while conceptually simple, can improve performance significantly at bandwidths representative of todays commercial Internet.",
        "On benchmarks modeling multitiered web applications, the throughput improvement was as high as tenfold for data-intensive workloads.",
        "For workloads that were not data-intensive, throughput improvements of up to twofold were observed.",
        "Even when bandwidth was not a constraint, Ganesh had low overhead and did not hurt performance.",
        "Our experiments also confirm that exploiting the structure present in database results is crucial to this performance improvement. 2.",
        "BACKGROUND 2.1 Dynamic Content Generation As the World Wide Web has grown, many web sites have decentralized their data and functionality by pushing them to the edges of the Internet.",
        "Today, eBusiness systems often use a three-tiered architecture consisting of a front-end web server, an application server, and a back-end database server.",
        "Figure 1 illustrates this architecture.",
        "The first two tiers can be replicated close to a concentration of clients at the edge of the Internet.",
        "This improves user experience by lowering end-to-end latency and reducing exposure WWW 2007 / Track: Performance and Scalability Session: Scalable Systems for Dynamic Content 311 Back-End Database Server Front-End Web and Application Servers Figure 1: Multi-Tier Architecture to backbone traffic congestion.",
        "It can also increase the availability and scalability of web services.",
        "Content that is generated dynamically from the back-end database cannot be cached in the first two tiers.",
        "While databases can be easily replicated in a LAN, this is infeasible in a WAN because of the difficult task of simultaneously providing strong consistency, availability, and tolerance to network partitions [7].",
        "As a result, databases tend to be centralized to meet the strong consistency requirements of many eBusiness applications such as banking, finance, and online retailing [38].",
        "Thus, the back-end database is usually located far from many sets of first and second-tier nodes [2].",
        "In the absence of both caching and replication, WAN bandwidth can easily become a limiting factor in the performance and scalability of data-intensive applications. 2.2 Hash-Based Systems Ganeshs focus is on efficient transmission of results by discovering similarities with the results of previous queries.",
        "As SQL queries can generate large results, hash-based techniques lend themselves well to the problem of efficiently transferring these large results across bandwidth constrained links.",
        "The use of hash-based techniques to reduce the volume of data transmitted has emerged as a common theme of many recent storage systems, as discussed in Section 8.2.",
        "These techniques rely on some basic assumptions.",
        "Cryptographic hash functions are assumed to be collision-resistant.",
        "In other words, it is computationally intractable to find two inputs that hash to the same output.",
        "The functions are also assumed to be one-way; that is, finding an input that results in a specific output is computationally infeasible.",
        "Menezes et al. [23] provide more details about these assumptions.",
        "The above assumptions allow hash-based systems to assume that collisions do not occur.",
        "Hence, they are able to treat the hash of a data item as its unique identifier.",
        "A collection of data items effectively becomes content-addressable, allowing a small hash to serve as a codeword for a much larger data item in permanent storage or network transmission.",
        "The assumption that collisions are so rare as to be effectively non-existent has recently come under fire [17].",
        "However, as explained by Black [5], we believe that these issues do not form a concern for Ganesh.",
        "All communication is between trusted parts of the system and an adversary has no way to force Ganesh to accept invalid data.",
        "Further, Ganesh does not depend critically on any specific hash function.",
        "While we currently use SHA-1, replacing it with a different hash function would be simple.",
        "There would be no impact on performance as stronger hash functions (e.g.",
        "SHA256) only add a few extra bytes and the generated hashes are still orders of magnitude smaller than the data items they represent.",
        "No re-hashing of permanent storage is required since Ganesh only uses hashing on volatile data. 3.",
        "DESIGN AND IMPLEMENTATION Ganesh exploits redundancy in the result stream to avoid transmitting result fragments that are already present at the query site.",
        "Redundancy can arise naturally in many different ways.",
        "For example, a query repeated after a certain interval may return a different result because of updates to the database; however, there may be significant commonality between the two results.",
        "As another example, a user who is refining a search may generate a sequence of queries with overlapping results.",
        "When Ganesh detects redundancy, it suppresses transmission of the corresponding result fragments.",
        "Instead, it transmits a much smaller digest of those fragments and lets the query site reconstruct the result through hash lookup in a cache of previous results.",
        "In effect, Ganesh uses computation at the edges to reduce Internet communication.",
        "Our description of Ganesh focuses on four aspects.",
        "We first explain our approach to detecting similarity in query results.",
        "Next, we discuss how the Ganesh architecture is completely invisible to all components of a multi-tier system.",
        "We then describe Ganeshs proxy-based approach and the dataflow for detecting similarity. 3.1 Detecting Similarity One of the key design decisions in Ganesh is how similarity is detected.",
        "There are many potential ways to decompose a result into fragments.",
        "The optimal way is, of course, the one that results in the smallest possible object for transmission for a given querys results.",
        "Finding this optimal decomposition is a difficult problem because of the large space of possibilities and because the optimal choice depends on many factors such as the contents of the querys result, the history of recent results, and the cache management algorithm.",
        "When an object is opaque, the use of Rabin fingerprints [8, 30] to detect common data between two objects has been successfully shown in the past by systems such as LBFS [26] and CASPER [37].",
        "Rabin fingerprinting uses a sliding window over the data to compute a rolling hash.",
        "Assuming that the hash function is uniformly distributed, a chunk boundary is defined whenever the lower order bits of the hash value equal some predetermined value.",
        "The number of lower order bits used defines the average chunk size.",
        "These sub-divided chunks of the object become the unit of comparison for detecting similarity between different objects.",
        "As the locations of boundaries found by using Rabin fingerprints is stochastically determined, they usually fail to align with any structural properties of the underlying data.",
        "The algorithm therefore deals well with in-place updates, insertions and deletions.",
        "However, it performs poorly in the presence of any reordering of data.",
        "Figure 2 shows an example where two results, A and B, consisting of three rows, have the same data but have different sort attributes.",
        "In the extreme case, Rabin fingerprinting might be unable to find any similar data due to the way it detects chunk boundaries.",
        "Fortunately, Ganesh can use domain specific knowledge for more precise boundary detection.",
        "The information we exploit is that a querys result reflects the structure of a relational database where all data is organized as tables and rows.",
        "It is therefore simple to check for similarity with previous results at two granularities: first the entire result, and then individual rows.",
        "The end of a row in a result serves as a natural chunk boundary.",
        "It is important to note that using the tabular structure in results only involves shallow interpretation of the data.",
        "Ganesh does not perform any deeper semantic interpretation such as understanding data types, result schema, or integrity constraints.",
        "Tuning Rabin fingerprinting for a workload can also be difficult.",
        "If the average chunk size is too large, chunks can span multiple result rows.",
        "However, selecting a smaller average chunk size increases the amount of metadata required to the describe the results.",
        "WWW 2007 / Track: Performance and Scalability Session: Scalable Systems for Dynamic Content 312 Figure 2: Rabin Fingerprinting vs. Ganeshs Chunking This, in turn, would decrease the savings obtained via its use.",
        "Rabin fingerprinting also needs two computationally-expensive passes over the data: once to determine chunk boundaries and one again to generate cryptographic hashes for the chunks.",
        "Ganesh only needs a single pass for hash generation as the chunk boundaries are provided by the datas natural structure.",
        "The performance comparison in Section 6 shows that Ganeshs row-based algorithm outperforms Rabin fingerprinting.",
        "Given that previous work has already shown that Rabin fingerprinting performs better than gzip [26], we do not compare Ganesh to compression algorithms in this paper. 3.2 Transparency The key factor influencing our design was the need for Ganesh to be completely transparent to all components of a typical eBusiness system: web servers, application servers, and database servers.",
        "Without this, Ganesh stands little chance of having a significant real-world impact.",
        "Requiring modifications to any of the above components would raise the barrier for entry of Ganesh into an existing system, and thus reduce its chances of adoption.",
        "Preserving transparency is simplified by the fact that Ganesh is purely a performance enhancement, not a functionality or usability enhancement.",
        "We chose agent interposition as the architectural approach to realizing our goal.",
        "This approach relies on the existence of a compact programming interface that is already widely used by target software.",
        "It also relies on a mechanism to easily add new code without disrupting existing module structure.",
        "These conditions are easily met in our context because of the popularity of Java as the programming language for eBusiness systems.",
        "The Java Database Connectivity (JDBC) API [32] allows Java applications to access a wide variety of databases and even other tabular data repositories such as flat files.",
        "Access to these data sources is provided by JDBC drivers that translate between the JDBC API and the database communication mechanism.",
        "Figure 3(a) shows how JDBC is typically used in an application.",
        "As the JDBC interface is standardized, one can substitute one JDBC driver for another without application modifications.",
        "The JDBC driver thus becomes the natural module to exploit for code interposition.",
        "As shown in Figure 3(b), the native JDBC driver is replaced with a Ganesh JDBC driver that presents the same standardized interface.",
        "The Ganesh driver maintains an in-memory cache of result fragments from previous queries and performs reassembly of results.",
        "At the database, we add a new process called the Ganesh proxy.",
        "This proxy, which can be shared by multiple front-end nodes, consists of two parts: code to detect similarity in result fragments and the original native JDBC driver that communicates with the database.",
        "The use of a proxy at the database makes Ganesh database-agnostic and simplifies prototyping and experimentation.",
        "Ganesh is thus able to work with a wide range of databases and applications, requiring no modifications to either. 3.3 Proxy-Based Caching The native JDBC driver shown in Figure 3(a) is a lightweight code component supplied by the database vendor.",
        "Its main funcClient Database Web and Application Server Native JDBC Driver WAN (a) Native Architecture Client Database Ganesh Proxy Native JDBC Driver WAN Web and Application Server Ganesh JDBC Driver (b) Ganeshs Interposition-based Architecture Figure 3: Native vs. Ganesh Architecture tion is to mediate communication between the application and the remote database.",
        "It forwards queries, buffers entire results, and responds to application requests to view parts of results.",
        "The Ganesh JDBC driver shown in Figure 3(b) presents the application with an interface identical to that provided by the native driver.",
        "It provides the ability to reconstruct results from compact hash-based descriptions sent by the proxy.",
        "To perform this reconstruction, the driver maintains an in-memory cache of recentlyreceived results.",
        "This cache is only used as a source of result fragments in reconstructing results.",
        "No attempt is made by the Ganesh driver or proxy to track database updates.",
        "The lack of cache consistency does not hurt correctness as a description of the results is always fetched from the proxy - at worst, there will be no performance benefit from using Ganesh.",
        "Stale data will simply be paged out of the cache over time.",
        "The Ganesh proxy accesses the database via the native JDBC driver, which remains unchanged between Figures 3(a) and (b).",
        "The database is thus completely unaware of the existence of the proxy.",
        "The proxy does not examine any queries received from the Ganesh driver but passes them to the native driver.",
        "Instead, the proxy is responsible for inspecting database output received from the native driver, detecting similar results, and generating hash-based encodings of these results whenever enough similarity is found.",
        "While this architecture does not decrease the load on a database, as mentioned earlier in Section 2.1, it is much easier to replicate databases for scalability in a LAN than in a WAN.",
        "To generate a hash-based encoding, the proxy must be aware of what result fragments are available in the Ganesh drivers cache.",
        "One approach is to be optimistic, and to assume that all result fragments are available.",
        "This will result in the smallest possible initial transmission of a result.",
        "However, in cases where there is little overlap with previous results, the Ganesh driver will have to make many calls to the proxy during reconstruction to fetch missing result fragments.",
        "To avoid this situation, the proxy loosely tracks the state of the Ganesh drivers cache.",
        "Since both components are under our control, it is relatively simple to do this without resorting to gray-box techniques or explicit communication for maintaining cache coherence.",
        "Instead, the proxy simulates the Ganesh drivers cache management algorithm and uses this to maintain a list of hashes for which the Ganesh driver is likely to possess the result fragments.",
        "In case of mistracking, there will be no loss of correctness but there will be extra round-trip delays to fetch the missing fragments.",
        "If the client detects loss of synchronization with the proxy, it can ask the proxy to reset the state shared between them.",
        "Also note that the proxy does not need to keep the result fragments themselves, only their hashes.",
        "This allows the proxy to remain scalable even when it is shared by many front-end nodes.",
        "WWW 2007 / Track: Performance and Scalability Session: Scalable Systems for Dynamic Content 313 Object Output Stream Convert ResultSet Object Input Stream Convert ResultSet All Data Recipe ResultSet All Data ResultSet Network Ganesh Proxy Ganesh JDBC Driver Result Set Recipe Result Set Yes Yes No No GaneshInputStream GaneshOutputStream Figure 4: Dataflow for Result Handling 3.4 Encoding and Decoding Results The Ganesh proxy receives database output as Java objects from the native JDBC driver.",
        "It examines this output to see if a Java object of type ResultSet is present.",
        "The JDBC interface uses this data type to store results of database queries.",
        "If a ResultSet object is found, it is shrunk as discussed below.",
        "All other Java objects are passed through unmodified.",
        "As discussed in Section 3.1, the proxy uses the row boundaries defined in the ResultSet to partition it into fragments consisting of single result rows.",
        "All ResultSet objects are converted into objects of a new type called RecipeResultSet.",
        "We use the term recipe for this compact description of a database result because of its similarity to a file recipe in the CASPER file system [37].",
        "The conversion replaces each result fragment that is likely to be present in the Ganesh drivers cache by a SHA-1 hash of that fragment.",
        "Previously unseen result fragments are retained verbatim.",
        "The proxy also retains hashes for the new result fragments as they will be present in the drivers cache in the future.",
        "Note that the proxy only caches hashes for result fragments and does not cache recipes.",
        "The proxy constructs a RecipeResultSet by checking for similarity at the entire result and then the row level.",
        "If the entire result is predicted to be present in the Ganesh drivers cache, the RecipeResultSet is simply a single hash of the entire result.",
        "Otherwise, it contains hashes for those rows predicted to be present in that cache; all other rows are retained verbatim.",
        "If the proxy estimates an overall space savings, it will transmit the RecipeResultSet.",
        "Otherwise the original ResultSet is transmitted.",
        "The RecipeResultSet objects are transformed back into ResultSet objects by the Ganesh driver.",
        "Figure 4 illustrates ResultSet handling at both ends.",
        "Each SHA-1 hash found in a RecipeResultSet is looked up in the local cache of result fragments.",
        "On a hit, the hash is replaced by the corresponding fragment.",
        "On a miss, the driver contacts the Ganesh proxy to fetch the fragment.",
        "All previously unseen result fragments that were retained verbatim by the proxy are hashed and added to the result cache.",
        "There should be very few misses if the proxy has accurately tracked the Ganesh drivers cache state.",
        "A future optimization would be to batch the fetch of missing fragments.",
        "This would be valuable when there are many small missing fragments in a high-latency WAN.",
        "Once the transformation is complete, the fully reconstructed ResultSet object is passed up to the application. 4.",
        "EXPERIMENTAL VALIDATION Three questions follow from the goals and design of Ganesh: • First, can performance can be improved significantly by exploiting similarity across database results?",
        "Benchmark Dataset Details 500,000 Users, 12,000 Stories BBOARD 2.0 GB 3,298,000 Comments AUCTION 1.3 GB 1,000,000 Users, 34,000 Items Table 1: Benchmark Dataset Details • Second, how important is Ganeshs structural similarity detection relative to Rabin fingerprintings similarity detection? • Third, is the overhead of the proxy-based design acceptable?",
        "Our evaluation answers these question through controlled experiments with the Ganesh prototype.",
        "This section describes the benchmarks used, our evaluation procedure, and the experimental setup.",
        "Results of the experiments are presented in Sections 5, 6, and 7. 4.1 Benchmarks Our evaluation is based on two benchmarks [18] that have been widely used by other researchers to evaluate various aspects of multi-tier [27] and eBusiness architectures [9].",
        "The first benchmark, BBOARD, is modeled after Slashdot, a technology-oriented news site.",
        "The second benchmark, AUCTION, is modeled after eBay, an online auction site.",
        "In both benchmarks, most content is dynamically generated from information stored in a database.",
        "Details of the datasets used can be found in Table 1. 4.1.1 The BBOARD Benchmark The BBOARD benchmark, also known as RUBBoS [18], models Slashdot, a popular technology-oriented web site.",
        "Slashdot aggregates links to news stories and other topics of interest found elsewhere on the web.",
        "The site also serves as a bulletin board by allowing users to comment on the posted stories in a threaded conversation form.",
        "It is not uncommon for a story to gather hundreds of comments in a matter of hours.",
        "The BBOARD benchmark is similar to the site and models the activities of a user, including readonly operations such as browsing the stories of the day, browsing story categories, and viewing comments as well as write operations such as new user registration, adding and moderating comments, and story submission.",
        "The benchmark consists of three different phases: a short warmup phase, a runtime phase representing the main body of the workload, and a short cool-down phase.",
        "In this paper we only report results from the runtime phase.",
        "The warm-up phase is important in establishing dynamic system state, but measurements from that phase are not significant for our evaluation.",
        "The cool-down phase is solely for allowing the benchmark to shut down.",
        "The warm-up, runtime, and cool-down phases are 2, 15, and 2 minutes respectively.",
        "The number of simulated clients were 400, 800, 1200, and 1600.",
        "The benchmark is available in a Java Servlets and PHP version and has different datasets; we evaluated Ganesh using the Java Servlets version and the Expanded dataset.",
        "The BBOARD benchmark defines two different workloads.",
        "The first, the Authoring mix, consists of 70% read-only operations and 30% read-write operations.",
        "The second, the Browsing mix, contains only read-only operations and does not update the database. 4.1.2 The AUCTION Benchmark The AUCTION benchmark, also known as RUBiS [18], models eBay, the online auction site.",
        "The eBay web site is used to buy and sell items via an auction format.",
        "The main activities of a user include browsing, selling, or bidding for items.",
        "Modeling the activities on this site, this benchmark includes read-only activities such as browsing items by category and by region, as well as read-write WWW 2007 / Track: Performance and Scalability Session: Scalable Systems for Dynamic Content 314 NetEm Router Ganesh Proxy Clients Web and Application Server Database Server Figure 5: Experimental Setup activities such as bidding for items, buying and selling items, and leaving feedback.",
        "As with BBOARD, the benchmark consists of three different phases.",
        "The warm-up, runtime, and cool-down phases for this experiment are 1.5, 15, and 1 minutes respectively.",
        "We tested Ganesh with four client configurations where the number of test clients was set to 400, 800, 1200, and 1600.",
        "The benchmark is available in a Enterprise Java Bean (EJB), Java Servlets, and PHP version and has different datasets; we evaluated Ganesh with the Java Servlets version and the Expanded dataset.",
        "The AUCTION benchmark defines two different workloads.",
        "The first, the Bidding mix, consists of 70% read-only operations and 30% read-write operations.",
        "The second, the Browsing mix, contains only read-only operations and does not update the database. 4.2 Experimental Procedure Both benchmarks involve a synthetic workload of clients accessing a web server.",
        "The number of clients emulated is an experimental parameter.",
        "Each emulated client runs an instance of the benchmark in its own thread, using a matrix to transition between different benchmark states.",
        "The matrix defines a stochastic model with probabilities of transitioning between the different states that represent typical user actions.",
        "An example transition is a user logging into the AUCTION system and then deciding on whether to post an item for sale or bid on active auctions.",
        "Each client also models user think time between requests.",
        "The think time is modeled as an exponential distribution with a mean of 7 seconds.",
        "We evaluate Ganesh along two axes: number of clients and WAN bandwidth.",
        "Higher loads are especially useful in understanding Ganeshs performance when the CPU or disk of the database server or proxy is the limiting factor.",
        "A previous study has shown that approximately 50% of the wide-area Internet bottlenecks observed had an available bandwidth under 10 Mb/s [1].",
        "Based on this work, we focus our evaluation on the WAN bandwidth of 5 Mb/s with 66 ms of round-trip latency, representative of severely constrained network paths, and 20 Mb/s with 33 ms of round-trip latency, representative of a moderately constrained network path.",
        "We also report Ganeshs performance at 100 Mb/s with no added round-trip latency.",
        "This bandwidth, representative of an unconstrained network, is especially useful in revealing any potential overhead of Ganesh in situations where WAN bandwidth is not the limiting factor.",
        "For each combination of number of clients and WAN bandwidth, we measured results from the two configurations listed below: • Native: This configuration corresponds to Figure 3(a).",
        "Native avoids Ganeshs overhead in using a proxy and performing Java object serialization. • Ganesh: This configuration corresponds to Figure 3(b).",
        "For a given number of clients and WAN bandwidth, comparing these results to the corresponding Native results gives the performance benefit due to the Ganesh middleware system.",
        "The metric used to quantify the improvement in throughput is the number of client requests that can be serviced per second.",
        "The metric used to quantify Ganeshs overhead is the average response time for a client request.",
        "For all of the experiments, the Ganesh driver used by the application server used a cache size of 100,000 items1 .",
        "The proxy was effective in tracking the Ganesh drivers cache state; for all of our experiments the miss rate on the driver never exceeded 0.7%. 4.3 Experimental Setup The experimental setup used for the benchmarks can be seen in Figure 5.",
        "All machines were 3.2 GHz Pentium 4s (with HyperThreading enabled.)",
        "With the exception of the database server, all machines had 2 GB of SDRAM and ran the Fedora Core Linux distribution.",
        "The database server had 4 GB of SDRAM.",
        "We used Apaches Tomcat as both the application server that hosted the Java Servlets and the web server.",
        "Both benchmarks used Java Servlets to generate the dynamic content.",
        "The database server used the open source MySQL database.",
        "For the native JDBC drivers, we used the Connector/J drivers provided by MySQL.",
        "The application server used Suns Java Virtual Machine as the runtime environment for the Java Servlets.",
        "The sysstat tool was used to monitor the CPU, network, disk, and memory utilization on all machines.",
        "The machines were connected by a switched gigabit Ethernet network.",
        "As shown in Figure 5, the front-end web and application server was separated from the proxy and database server by a NetEm router [16].",
        "This router allowed us to control the bandwidth and latency settings on the network.",
        "The NetEm router is a standard PC with two network cards running the Linux Traffic Control and Network Emulation software.",
        "The bandwidth and latency constraints were only applied to the link between the application server and the database for the native case and between the application server and the proxy for the Ganesh case.",
        "There is no communication between the application server and the database with Ganesh as all data flows through the proxy.",
        "As our focus was on the WAN link between the application server and the database, there were no constraints on the link between the simulated test clients and the web server. 5.",
        "THROUGHPUT AND RESPONSE TIME In this section, we address the first question raised in Section 4: Can performance can be improved significantly by exploiting similarity across database results?",
        "To answer this question, we use results from the BBOARD and AUCTION benchmarks.",
        "We use two metrics to quantify the performance improvement obtainable through the use of Ganesh: throughput, from the perspective of the web server, and average response time, from the perspective of the client.",
        "Throughput is measured in terms of the number of client requests that can be serviced per second. 5.1 BBOARD Results and Analysis 5.1.1 Authoring Mix Figures 6 (a) and (b) present the average number of requests serviced per second and the average response time for these requests as perceived by the clients for BBOARDs Authoring Mix.",
        "As Figure 6 (a) shows, Native easily saturates the 5 Mb/s link.",
        "At 400 clients, the Native solution delivers 29 requests/sec with an average response time of 8.3 seconds.",
        "Natives throughput drops with an increase in test clients as clients timeout due to congestion at the application server.",
        "Usability studies have shown that response times above 10 seconds cause the user to move on to 1 As Java lacks a sizeof() operator, Java caches therefore limit their size based on the number of objects.",
        "The size of cache dumps taken at the end of the experiments never exceeded 212 MB.",
        "WWW 2007 / Track: Performance and Scalability Session: Scalable Systems for Dynamic Content 315 0 50 100 150 200 250 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Test Clients Requests/sec Native Ganesh 0.001 0.01 0.1 1 10 100 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Test Clients Avg.Resp.Time(sec) Native Ganesh Note Logscale (a) Throughput: Authoring Mix (b) Response Time: Authoring Mix 0 50 100 150 200 250 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Test Clients Requests/sec Native Ganesh 0.001 0.01 0.1 1 10 100 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Test Clients Avg.Resp.Time(sec) Native Ganesh Note Logscale (c) Throughput: Browsing Mix (d) Response Time: Browsing Mix Mean of three trials.",
        "The maximum standard deviation for throughput and response time was 9.8% and 11.9% of the corresponding mean.",
        "Figure 6: BBOARD Benchmark - Throughput and Average Response Time other tasks [24].",
        "Based on these numbers, increasing the number of test clients makes the Native system unusable.",
        "Ganesh at 5 Mb/s, however, delivers a twofold improvement with 400 test clients and a fivefold improvement at 1200 clients.",
        "Ganeshs performance drops slightly at 1200 and 1600 clients as the network is saturated.",
        "Compared to Native, Figure 6 (b) shows that Ganeshs response times are substantially lower with sub-second response times at 400 clients.",
        "Figure 6 (a) also shows that for 400 and 800 test clients Ganesh at 5 Mb/s has the same throughput and average response time as Native at 20 Mb/s.",
        "Only at 1200 and 1600 clients does Native at 20 Mb/s deliver higher throughput than Ganesh at 5 Mb/s.",
        "Comparing both Ganesh and Native at 20 Mb/s, we see that Ganesh is no longer bandwidth constrained and delivers up to a twofold improvement over Native at 1600 test clients.",
        "As Ganesh does not saturate the network with higher test client configurations, at 1600 test clients, its average response time is 0.1 seconds rather than Natives 7.7 seconds.",
        "As expected, there are no visible gains from Ganesh at the higher bandwidth of 100 Mb/s where the network is no longer the bottleneck.",
        "Ganesh, however, still tracks Native in terms of throughput. 5.1.2 Browsing Mix Figures 6 (c) and (d) present the average number of requests serviced per second and the average response time for these requests as perceived by the clients for BBOARDs Browsing Mix.",
        "Regardless of the test client configuration, Figure 6 (c) shows that Natives throughput at 5 Mb/s is limited to 10 reqs/sec.",
        "Ganesh at 5 Mb/s with 400 test clients, delivers more than a sixfold increase in throughput.",
        "The improvement increases to over a elevenfold increase at 800 test clients before Ganesh saturates the network.",
        "Further, Figure 6 (d) shows that Natives average response time of 35 seconds at 400 test clients make the system unusable.",
        "These high response times further increase with the addition of test clients.",
        "Even with the 1600 test client configuration Ganesh delivers an acceptable average response time of 8.2 seconds.",
        "Due to the data-intensive nature of the Browsing mix, Ganesh at 5 Mb/s surprisingly performs much better than Native at 20 Mb/s.",
        "Further, as shown in Figure 6 (d), while the average response time for Native at 20 Mb/s is acceptable at 400 test clients, it is unusable with 800 test clients with an average response time of 15.8 seconds.",
        "Like the 5 Mb/s case, this response time increases with the addition of extra test clients.",
        "Ganesh at 20 Mb/s and both Native and Ganesh at 100 Mb/s are not bandwidth limited.",
        "However, performance plateaus out after 1200 test clients due to the database CPU being saturated. 5.1.3 Filter Variant We were surprised by the Native performance from the BBOARD benchmark.",
        "At the bandwidth of 5 Mb/s, Native performance was lower than what we had expected.",
        "It turned out the benchmark code that displays stories read all the comments associated with the particular story from the database and only then did some postprocessing to select the comments to be displayed.",
        "While this is exactly the behavior of SlashCode, the code base behind the Slashdot web site, we decided to modify the benchmark to perform some pre-filtering at the database.",
        "This modified benchmark, named the Filter Variant, models a developer who applies optimizations at the SQL level to transfer less data.",
        "In the interests of brevity, we only briefly summarize the results from the Authoring mix.",
        "For the Authoring mix, at 800 test clients at 5 Mb/s, Figure 7 (a) shows that Natives throughput increase by 85% when compared to the original benchmark while Ganeshs improvement is smaller at 15%.",
        "Natives performance drops above 800 clients as the test clients time out due to high response times.",
        "The most significant gain for Native is seen at 20 Mb/s.",
        "At 1600 test clients, when compared to the original benchmark, Native sees a 73% improvement in throughput and a 77% reduction in average response time.",
        "While WWW 2007 / Track: Performance and Scalability Session: Scalable Systems for Dynamic Content 316 0 50 100 150 200 250 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Test Clients Requests/sec Native Ganesh 0.001 0.01 0.1 1 10 100 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Test Clients Avg.Resp.Time(sec) Native Ganesh Note Logscale (a) Throughput: Authoring Mix (b) Response Time: Authoring Mix Mean of three trials.",
        "The maximum standard deviation for throughput and response time was 7.2% and 11.5% of the corresponding mean.",
        "Figure 7: BBOARD Benchmark - Filter Variant - Throughput and Average Response Time Ganesh sees no improvement when compared to the original, it still processes 19% more requests/sec than Native.",
        "Thus, while the optimizations were more helpful to Native, Ganesh still delivers an improvement in performance. 5.2 AUCTION Results and Analysis 5.2.1 Bidding Mix Figures 8 (a) and (b) present the average number of requests serviced per second and the average response time for these requests as perceived by the clients for AUCTIONs Bidding Mix.",
        "As mentioned earlier, the Bidding mix consists of a mixture of read and write operations.",
        "The AUCTION benchmark is not as data intensive as BBOARD.",
        "Therefore, most of the gains are observed at the lower bandwidth of 5 Mb/s.",
        "Figure 8 (a) shows that the increase in throughput due to Ganesh ranges from 8% at 400 test clients to 18% with 1600 test clients.",
        "As seen in Figure 8 (b), the average response times for Ganesh are significantly lower than Native ranging from a decrease of 84% at 800 test clients to 88% at 1600 test clients.",
        "Figure 8 (a) also shows that with a fourfold increase of bandwidth from 5 Mb/s to 20 Mb/s, Native is no longer bandwidth constrained and there is no performance difference between Ganesh and Native.",
        "With the higher test client configurations, we did observe that the bandwidth used by Ganesh was lower than Native.",
        "Ganesh might still be useful in these non-constrained scenarios if bandwidth is purchased on a metered basis.",
        "Similar results are seen for the 100 Mb/s scenario. 5.2.2 Browsing Mix For AUCTIONs Browsing Mix, Figures 8 (c) and (d) present the average number of requests serviced per second and the average response time for these requests as perceived by the clients.",
        "Again, most of the gains are observed at lower bandwidths.",
        "At 5 Mb/s, Native and Ganesh deliver similar throughput and response times with 400 test clients.",
        "While the throughput for both remains the same at 800 test clients, Figure 8 (d) shows that Ganeshs average response time is 62% lower than Native.",
        "Native saturates the link at 800 clients and adding extra test clients only increases the average response time.",
        "Ganesh, regardless of the test client configuration, is not bandwidth constrained and maintains the same response time.",
        "At 1600 test clients, Figure 8 (c) shows that Ganeshs throughput is almost twice that of Native.",
        "At the higher bandwidths of 20 and 100 Mb/s, neither Ganesh nor Native is bandwidth limited and deliver equivalent throughput and response times.",
        "Benchmark Orig.",
        "Size Ganesh Size Rabin Size SelectSort1 223.6 MB 5.4 MB 219.3 MB SelectSort2 223.6 MB 5.4 MB 223.6 MB Table 2: Similarity Microbenchmarks 6.",
        "STRUCTURAL VS. RABIN SIMILARITY In this section, we address the second question raised in Section 4: How important is Ganeshs structural similarity detection relative to Rabin fingerprinting-based similarity detecting?",
        "To answer this question, we used microbenchmarks and the BBOARD and AUCTION benchmarks.",
        "As Ganesh always performed better than Rabin fingerprinting, we only present a subset of the results here in the interests of brevity. 6.1 Microbenchmarks Two microbenchmarks show an example of the effects of data reordering on Rabin fingerprinting algorithm.",
        "In the first microbenchmark, SelectSort1, a query with a specified sort order selects 223.6 MB of data spread over approximately 280 K rows.",
        "The query is then repeated with a different sort attribute.",
        "While the same number of rows and the same data is returned, the order of rows is different.",
        "In such a scenario, one would expect a large amount of similarity to be detected between both results.",
        "As Table 2 shows, Ganeshs row-based algorithm achieves a 97.6% reduction while the Rabin fingerprinting algorithm, with the average chunk size parameter set to 4 KB, only achieves a 1% reduction.",
        "The reason, as shown earlier in Figure 2, is that with Rabin fingerprinting, the spans of data between two consecutive boundaries usually cross row boundaries.",
        "With the order of the rows changing in the second result and the Rabin fingerprints now spanning different rows, the algorithm is unable to detect significant similarity.",
        "The small gain seen is mostly for those single rows that are large enough to be broken into multiple chunks.",
        "SelectSort2, another micro-benchmark executed the same queries but increased the minimum chunk size of the Rabin fingerprinting algorithm.",
        "As can be seen in Table 2, even the small gain from the previous microbenchmark disappears as the minimum chunk size was greater than the average row size.",
        "While one can partially address these problems by dynamically varying the parameters of the Rabin fingerprinting algorithm, this can be computationally expensive, especially in the presence of changing workloads. 6.2 Application Benchmarks We ran the BBOARD benchmark described in Section 4.1.1 on two versions of Ganesh: the first with Rabin fingerprinting used as WWW 2007 / Track: Performance and Scalability Session: Scalable Systems for Dynamic Content 317 0 50 100 150 200 250 300 350 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Test Clients Requests/sec Native Ganesh 0.001 0.01 0.1 1 10 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Test Clients Avg.Resp.Time(sec) Native Ganesh Note Logscale (a) Throughput: Bidding Mix (b) Response Time: Bidding Mix 0 50 100 150 200 250 300 350 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Test Clients Requests/sec Native Ganesh 0.001 0.01 0.1 1 10 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Test Clients Avg.Resp.Time(sec) Native Ganesh Note Logscale (c) Throughput: Browsing Mix (d) Response Time: Browsing Mix Mean of three trials.",
        "The maximum standard deviation for throughput and response time was 2.2% and 11.8% of the corresponding mean.",
        "Figure 8: AUCTION Benchmark - Throughput and Average Response Time the chunking algorithm and the second with Ganeshs row-based algorithm.",
        "Rabins results for the Browsing Mix are normalized to Ganeshs results and presented in Figure 9.",
        "As Figure 9 (a) shows, at 5 Mb/s, independent of the test client configuration, Rabin significantly underperforms Ganesh.",
        "This happens because of a combination of two reasons.",
        "First, as outlined in Section 3.1, Rabin finds less similarity as it does not exploit the results structural information.",
        "Second, this benchmark contained some queries that generated large results.",
        "In this case, Rabin, with a small average chunk size, generated a large number of objects that evicted other useful data from the cache.",
        "In contrast, Ganesh was able to detect these large rows and correspondingly increase the size of the chunks.",
        "This was confirmed as cache statistics showed that Ganeshs hit ratio was roughly three time that of Rabin.",
        "Throughput measurements at 20 Mb/s were similar with the exception of Rabins performance with 400 test clients.",
        "In this case, Ganesh was not network limited and, in fact, the throughput was the same as 400 clients at 5 Mb/s.",
        "Rabin, however, took advantage of the bandwidth increase from 5 to 20 Mb/s to deliver a slightly better performance.",
        "At 100 Mb/s, Rabins throughput was almost similar to Ganesh as bandwidth was no longer a bottleneck.",
        "The normalized response time, presented in Figure 9 (b), shows similar trends.",
        "At 5 and 20 Mb/s, the addition of test clients decreases the normalized response time as Ganeshs average response time increases faster than Rabins.",
        "However, at no point does Rabin outperform Ganesh.",
        "Note that at 400 and 800 clients at 100 Mb/s, Rabin does have a higher overhead even when it is not bandwidth constrained.",
        "As mentioned in Section 3.1, this is due to the fact that Rabin has to hash each ResultSet twice.",
        "The overhead disappears with 1200 and 1600 clients as the database CPU is saturated and limits the performance of both Ganesh and Rabin. 7.",
        "PROXY OVERHEAD In this section, we address the third question raised in Section 4: Is the overhead of Ganeshs proxy-based design acceptable?",
        "To answer this question, we concentrate on its performance at the higher bandwidths.",
        "Our evaluation in Section 5 showed that Ganesh, when compared to Native, can deliver a substantial throughput improvement at lower bandwidths.",
        "It is only at higher bandwidths that latency, measured by the average response time for a client request, and throughput, measured by the number of client requests that can be serviced per second, overheads would be visible.",
        "Looking at the Authoring mix of the original BBOARD benchmark, there are no visible gains from Ganesh at 100 Mb/s.",
        "Ganesh, however, still tracks Native in terms of throughput.",
        "While the average response time is higher for Ganesh, the absolute difference is in between 0.01 and 0.04 seconds and would be imperceptible to the end-user.",
        "The Browsing mix shows an even smaller difference in average response times.",
        "The results from the filter variant of the BBOARD benchmarks are similar.",
        "Even for the AUCTION benchmark, the difference between Native and Ganeshs response time at 100 Mb/s was never greater than 0.02 seconds.",
        "The only exception to the above results was seen in the filter variant of the BBOARD benchmark where Ganesh at 1600 test clients added 0.85 seconds to the average response time.",
        "Thus, even for much faster networks where the WAN link is not the bottleneck, Ganesh always delivers throughput equivalent to Native.",
        "While some extra latency is added by the proxy-based design, it is usually imperceptible. 8.",
        "RELATED WORK To the best of our knowledge, Ganesh is the first system that combines the use of hash-based techniques with caching of database results to improve throughput and response times for applications with dynamic content.",
        "We also believe that it is also the first system to demonstrate the benefits of using structural information for WWW 2007 / Track: Performance and Scalability Session: Scalable Systems for Dynamic Content 318 0.0 0.2 0.4 0.6 0.8 1.0 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Test Clients Norm.Throughput 31.8 3.8 2.8 2.3 23.8 32.8 5.8 3.6 1.8 2.1 1.1 1.0 0 5 10 15 20 25 30 35 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Test Clients Norm.ResponseTime (a) Normalized Throughput: Higher is better (b) Normalized Response Time: Higher is worse For throughput, a normalized result greater than 1 implies that Rabin is better, For response time, a normalized result greater than 1 implies that Ganesh is better.",
        "Mean of three trials.",
        "The maximum standard deviation for throughput and response time was 9.1% and 13.9% of the corresponding mean.",
        "Figure 9: Normalized Comparison of Ganesh vs. Rabin - BBOARD Browsing Mix detecting similarity.",
        "In this section, we first discuss alternative approaches to caching dynamic content and then examine other uses of hash-based primitives in distributed systems. 8.1 Caching Dynamic Content At the database layer, a number of systems have advocated middletier caching where parts of the database are replicated at the edge or server [3, 4, 20].",
        "These systems either cache entire tables in what is essentially a replicated database or use materialized views from previous query replies [19].",
        "They require tight integration with the back-end database to ensure a time bound on the propagation of updates.",
        "These systems are also usually targeted towards workloads that do not require strict consistency and can tolerate stale data.",
        "Further, unlike Ganesh, some of these mid-tier caching solutions [2, 3], suffer from the complexity of having to participate in query planing and distributed query processing.",
        "Gao et al. [15] propose using a distributed object replication architecture where the data stores consistency requirements are adapted on a per-application basis.",
        "These solutions require substantial developer resources and detailed understanding of the application being modified.",
        "While systems that attempt to automate the partitioning and replication of an applications database exist [34], they do not provide full transaction semantics.",
        "In comparison, Ganesh does not weaken any of the semantics provided by the underlying database.",
        "Recent work in the evaluation of edge caching options for dynamic web sites [38] has suggested that, without careful planning, employing complex offloading strategies can hurt performance.",
        "Instead, the work advocates for an architecture in which all tiers except the database should be offloaded to the edge.",
        "Our evaluation of Ganesh has shown that it would benefit these scenarios.",
        "To improve database scalability, C-JDBC [10], SSS [22], and Ganymed [28] also advocate the use of an interposition-based architecture to transparently cluster and replicate databases at the middleware level.",
        "The approaches of these architectures and Ganesh are complementary and they would benefit each other.",
        "Moving up to the presentation layer, there has been widespread adoption of fragment-based caching [14], which improves cache utilization by separately caching different parts of generated web pages.",
        "While fragment-based caching works at the edge, a recent proposal has proposed moving web page assembly to the clients to optimize content delivery [31].",
        "While Ganesh is not used at the presentation layer, the same principles have been applied in Duplicate Transfer Detection [25] to increase web cache efficiency as well as for web access across bandwidth limited links [33]. 8.2 Hash-based Systems The past few years have seen the emergence of many systems that exploit hash-based techniques.",
        "At the heart of all these systems is the idea of detecting similarity in data without requiring interpretation of that data.",
        "This simple yet elegant idea relies on cryptographic hashing, as discussed earlier in Section 2.",
        "Successful applications of this idea span a wide range of storage systems.",
        "Examples include peer-to-peer backup of personal computing files [11], storage-efficient archiving of data [29], and finding similar files [21].",
        "Spring and Wetherall [35] apply similar principles at the network level.",
        "Using synchronized caches at both ends of a network link, duplicated data is replaced by smaller tokens for transmission and then restored at the remote end.",
        "This and other hash-based systems such as the CASPER [37] and LBFS [26] filesystems, and Layer-2 bandwidth optimizers such as Riverbed and Peribit use Rabin fingerprinting [30] to discover spans of commonality in data.",
        "This approach is especially useful when data items are modified in-place through insertions, deletions, and updates.",
        "However, as Section 6 shows, the performance of this technique can show a dramatic drop in the presence of data reordering.",
        "Ganesh instead uses row boundaries as dividers for detecting similarity.",
        "The most aggressive use of hash-based techniques is by systems that use hashes as the primary identifiers for objects in persistent storage.",
        "Storage systems such as CFS [12] and PAST [13] that have been built using distributed hash tables fall into this category.",
        "Single Instance Storage [6] and Venti [29] are other examples of such systems.",
        "As discussed in Section 2.2, the use of cryptographic hashes for addressing persistent data represents a deeper level of faith in their collision-resistance than that assumed by Ganesh.",
        "If time reveals shortcomings in the hash algorithm, the effort involved in correcting the flaw is much greater.",
        "In Ganesh, it is merely a matter of replacing the hash algorithm. 9.",
        "CONCLUSION The growing use of dynamic web content generated from relational databases places increased demands on WAN bandwidth.",
        "Traditional caching solutions for bandwidth and latency reduction are often ineffective for such content.",
        "This paper shows that the impact of WAN accesses to databases can be substantially reduced through the Ganesh architecture without any compromise of the databases strict consistency semantics.",
        "The essence of the Ganesh architecture is the use of computation at the edges to reduce communication through the Internet.",
        "Ganesh is able to use cryptographic hashes to detect similarity with previous results and send WWW 2007 / Track: Performance and Scalability Session: Scalable Systems for Dynamic Content 319 compact recipes of results rather than full results.",
        "Our design uses interposition to achieve complete transparency: clients, application servers, and database servers are all unaware of Ganeshs presence and require no modification.",
        "Our experimental evaluation confirms that Ganesh, while conceptually simple, can be highly effective in improving throughput and response time.",
        "Our results also confirm that exploiting the structure present in database results to detect similarity is crucial to this performance improvement. 10.",
        "REFERENCES [1] AKELLA, A., SESHAN, S., AND SHAIKH, A.",
        "An empirical evaluation of wide-area internet bottlenecks.",
        "In Proc. 3rd ACM SIGCOMM Conference on Internet Measurement (Miami Beach, FL, USA, Oct. 2003), pp. 101-114. [2] ALTINEL, M., BORNH ¨OVD, C., KRISHNAMURTHY, S., MOHAN, C., PIRAHESH, H., AND REINWALD, B. Cache tables: Paving the way for an adaptive database cache.",
        "In Proc. of 29th VLDB (Berlin, Germany, 2003), pp. 718-729. [3] ALTINEL, M., LUO, Q., KRISHNAMURTHY, S., MOHAN, C., PIRAHESH, H., LINDSAY, B. G., WOO, H., AND BROWN, L. Dbcache: Database caching for web application servers.",
        "In Proc. 2002 ACM SIGMOD (2002), pp. 612-612. [4] AMIRI, K., PARK, S., TEWARI, R., AND PADMANABHAN, S. Dbproxy: A dynamic data cache for web applications.",
        "In Proc.",
        "IEEE International Conference on Data Engineering (ICDE) (Mar. 2003). [5] BLACK, J. Compare-by-hash: A reasoned analysis.",
        "In Proc. 2006 USENIX Annual Technical Conference (Boston, MA, May 2006), pp. 85-90. [6] BOLOSKY, W. J., CORBIN, S., GOEBEL, D., , AND DOUCEUR, J. R. Single instance storage in windows 2000.",
        "In Proc. 4th USENIX Windows Systems Symposium (Seattle, WA, Aug. 2000), pp. 13-24. [7] BREWER, E. A.",
        "Lessons from giant-scale services.",
        "IEEE Internet Computing 5, 4 (2001), 46-55. [8] BRODER, A., GLASSMAN, S., MANASSE, M., AND ZWEIG, G. Syntactic clustering of the web.",
        "In Proc. 6th International WWW Conference (1997). [9] CECCHET, E., CHANDA, A., ELNIKETY, S., MARGUERITE, J., AND ZWAENEPOEL, W. Performance comparison of middleware architectures for generating dynamic web content.",
        "In Proc.",
        "Fourth ACM/IFIP/USENIX International Middleware Conference (Rio de Janeiro, Brazil, June 2003). [10] CECCHET, E., MARGUERITE, J., AND ZWAENEPOEL, W. C-JDBC: Flexible database clustering middleware.",
        "In Proc. 2004 USENIX Annual Technical Conference (Boston, MA, June 2004). [11] COX, L. P., MURRAY, C. D., AND NOBLE, B. D. Pastiche: Making backup cheap and easy.",
        "In OSDI: Symposium on Operating Systems Design and Implementation (2002). [12] DABEK, F., KAASHOEK, M. F., KARGER, D., MORRIS, R., AND STOICA, I. Wide-area cooperative storage with CFS.",
        "In 18th ACM Symposium on Operating Systems Principles (Banff, Canada, Oct. 2001). [13] DRUSCHEL, P., AND ROWSTRON, A.",
        "PAST: A large-scale, persistent peer-to-peer storage utility.",
        "In HotOS VIII (Schloss Elmau, Germany, May 2001), pp. 75-80. [14] Edge side includes. http://www.esi.org. [15] GAO, L., DAHLIN, M., NAYATE, A., ZHENG, J., AND IYENGAR, A.",
        "Application specific data replication for edge services.",
        "In WWW 03: Proc.",
        "Twelfth International Conference on World Wide Web (2003), pp. 449-460. [16] HEMMINGER, S. Netem - emulating real networks in the lab.",
        "In Proc. 2005 Linux Conference Australia (Canberra, Australia, Apr. 2005). [17] HENSON, V. An analysis of compare-by-hash.",
        "In Proc. 9th Workshop on Hot Topics in Operating Systems (HotOS IX) (May 2003), pp. 13-18. [18] Jmob benchmarks. http://jmob.objectweb.org/. [19] LABRINIDIS, A., AND ROUSSOPOULOS, N. Balancing performance and data freshness in web database servers.",
        "In Proc. 29th VLDB Conference (Sept. 2003). [20] LARSON, P.-A., GOLDSTEIN, J., AND ZHOU, J. Transparent mid-tier database caching in sql server.",
        "In Proc. 2003 ACM SIGMOD (2003), pp. 661-661. [21] MANBER, U.",
        "Finding similar files in a large file system.",
        "In Proc.",
        "USENIX Winter 1994 Technical Conference (San Fransisco, CA, 17-21 1994), pp. 1-10. [22] MANJHI, A., AILAMAKI, A., MAGGS, B. M., MOWRY, T. C., OLSTON, C., AND TOMASIC, A.",
        "Simultaneous scalability and security for data-intensive web applications.",
        "In Proc. 2006 ACM SIGMOD (June 2006), pp. 241-252. [23] MENEZES, A. J., VANSTONE, S. A., AND OORSCHOT, P. C. V. Handbook of Applied Cryptography.",
        "CRC Press, 1996. [24] MILLER, R. B.",
        "Response time in man-computer conversational transactions.",
        "In Proc.",
        "AFIPS Fall Joint Computer Conference (1968), pp. 267-277. [25] MOGUL, J. C., CHAN, Y. M., AND KELLY, T. Design, implementation, and evaluation of duplicate transfer detection in http.",
        "In Proc.",
        "First Symposium on Networked Systems Design and Implementation (San Francisco, CA, Mar. 2004). [26] MUTHITACHAROEN, A., CHEN, B., AND MAZIERES, D. A low-bandwidth network file system.",
        "In Proc. 18th ACM Symposium on Operating Systems Principles (Banff, Canada, Oct. 2001). [27] PFEIFER, D., AND JAKSCHITSCH, H. Method-based caching in multi-tiered server applications.",
        "In Proc.",
        "Fifth International Symposium on Distributed Objects and Applications (Catania, Sicily, Italy, Nov. 2003). [28] PLATTNER, C., AND ALONSO, G. Ganymed: Scalable replication for transactional web applications.",
        "In Proc. 5th ACM/IFIP/USENIX International Conference on Middleware (2004), pp. 155-174. [29] QUINLAN, S., AND DORWARD, S. Venti: A new approach to archival storage.",
        "In Proc.",
        "FAST 2002 Conference on File and Storage Technologies (2002). [30] RABIN, M. Fingerprinting by random polynomials.",
        "In Harvard University Center for Research in Computing Technology Technical Report TR-15-81 (1981). [31] RABINOVICH, M., XIAO, Z., DOUGLIS, F., AND KALMANEK, C. Moving edge side includes to the real edge - the clients.",
        "In Proc. 4th USENIX Symposium on Internet Technologies and Systems (Seattle, WA, Mar. 2003). [32] REESE, G. Database Programming with JDBC and Java, 1st ed.",
        "OReilly, June 1997. [33] RHEA, S., LIANG, K., AND BREWER, E. Value-based web caching.",
        "In Proc.",
        "Twelfth International World Wide Web Conference (May 2003). [34] SIVASUBRAMANIAN, S., ALONSO, G., PIERRE, G., AND VAN STEEN, M. Globedb: Autonomic data replication for web applications.",
        "In WWW 05: Proc. 14th International World-Wide Web conference (May 2005). [35] SPRING, N. T., AND WETHERALL, D. A protocol-independent technique for eliminating redundant network traffic.",
        "In Proc. of ACM SIGCOMM (Aug. 2000). [36] TOLIA, N., HARKES, J., KOZUCH, M., AND SATYANARAYANAN, M. Integrating portable and distributed storage.",
        "In Proc. 3rd USENIX Conference on File and Storage Technologies (San Francisco, CA, Mar. 2004). [37] TOLIA, N., KOZUCH, M., SATYANARAYANAN, M., KARP, B., PERRIG, A., AND BRESSOUD, T. Opportunistic use of content addressable storage for distributed file systems.",
        "In Proc. 2003 USENIX Annual Technical Conference (San Antonio, TX, June 2003), pp. 127-140. [38] YUAN, C., CHEN, Y., AND ZHANG, Z.",
        "Evaluation of edge caching/offloading for dynamic content delivery.",
        "In WWW 03: Proc.",
        "Twelfth International Conference on World Wide Web (2003), pp. 461-471.",
        "WWW 2007 / Track: Performance and Scalability Session: Scalable Systems for Dynamic Content 320"
    ],
    "translated_text_sentences": [
        "Conservación de la consistencia en el almacenamiento en caché de contenido dinámico de bases de datos∗ Niraj Tolia y M. Satyanarayanan Universidad Carnegie Mellon {ntolia,satya}@cs.cmu.edu RESUMEN Con el creciente uso de contenido web dinámico generado a partir de bases de datos relacionales, las soluciones de almacenamiento en caché tradicionales para mejorar el rendimiento y la latencia son ineficaces.",
        "Describimos una capa de middleware llamada Ganesh que reduce el volumen de datos transmitidos sin interpretación semántica de consultas o resultados.",
        "Se logra esta reducción mediante el uso de hash criptográficos para detectar similitudes con resultados anteriores.",
        "Estos beneficios no requieren ningún compromiso con la semántica de consistencia estricta proporcionada por la base de datos del servidor.",
        "Además, Ganesh no requiere modificaciones en aplicaciones, servidores web o servidores de bases de datos, y funciona con aplicaciones y bases de datos de código cerrado.",
        "Usando dos puntos de referencia representativos de sitios web dinámicos, las mediciones de nuestro prototipo muestran que puede aumentar el rendimiento de extremo a extremo hasta en un factor de dos para aplicaciones no intensivas en datos y hasta en un factor de diez para las intensivas en datos.",
        "Categorías y Descriptores de Asignaturas C.2.4 [Redes de Computadoras-Comunicación]: Sistemas Distribuidos; H.2.4 [Gestión de Bases de Datos]: Términos Generales de Sistemas de Diseño, Rendimiento 1.",
        "INTRODUCCIÓN Una fracción creciente del contenido web se genera dinámicamente a partir de bases de datos relacionales en el backend.",
        "Incluso cuando el contenido de la base de datos permanece sin cambios, la localidad temporal de acceso no puede ser explotada porque el contenido dinámico no es almacenable en caché por los navegadores web o por servidores de almacenamiento en caché intermedios como los espejos de Akamai.",
        "En una arquitectura multinivel, cada solicitud web puede tensionar el enlace WAN entre el servidor web y la base de datos.",
        "Esto provoca que la experiencia del usuario sea altamente variable porque no hay almacenamiento en caché para aislar al cliente de cargas repentinas.",
        "Los intentos previos de almacenar en caché contenido dinámico de bases de datos generalmente han debilitado la semántica transaccional [3, 4] o han requerido modificaciones en la aplicación [15, 34].",
        "Informamos sobre una nueva solución que toma la forma de una capa intermedia de middleware independiente de la base de datos llamada Ganesh.",
        "Ganesh no hace ningún esfuerzo por interpretar semánticamente el contenido de las consultas o sus resultados.",
        "En cambio, se basa exclusivamente en el hash criptográfico para detectar similitudes con resultados anteriores.",
        "La detección de similitud basada en hash ha sido cada vez más utilizada en sistemas de archivos distribuidos [26, 36, 37] para mejorar el rendimiento en redes de baja capacidad de ancho de banda.",
        "Sin embargo, estas técnicas no se han utilizado para bases de datos relacionales.",
        "A diferencia de enfoques anteriores que utilizan métodos genéricos para detectar similitud, Ganesh explota la estructura de los resultados de la base de datos relacional para lograr una mejora superior en el rendimiento.",
        "Uno se enfrenta al menos a tres desafíos al aplicar la detección de similitud basada en hash a las bases de datos de back-end.",
        "Primero, el trabajo previo en este ámbito ha considerado tradicionalmente el contenido de almacenamiento como bolsas de bits no interpretadas y sin estructura interna.",
        "Esto permite que las técnicas basadas en hash operen en largas y contiguas secuencias de datos para lograr la máxima efectividad.",
        "Por el contrario, las bases de datos relacionales tienen una estructura interna compleja que puede no ser tan propicia para la detección de similitudes basada en hash.",
        "Segundo, las bases de datos relacionales tienen restricciones de integridad y consistencia muy estrictas que no deben comprometerse por el uso de técnicas basadas en hash.",
        "Tercero, el código fuente de las bases de datos comerciales generalmente no está disponible.",
        "Esto contrasta con trabajos anteriores que presumían la disponibilidad del código fuente.",
        "Nuestros experimentos muestran que Ganesh, aunque conceptualmente simple, puede mejorar significativamente el rendimiento en anchos de banda representativos del Internet comercial actual.",
        "En los modelos de referencia de aplicaciones web multinivel, la mejora en el rendimiento fue de hasta diez veces para cargas de trabajo intensivas en datos.",
        "Para cargas de trabajo que no eran intensivas en datos, se observaron mejoras en el rendimiento de hasta el doble.",
        "Incluso cuando el ancho de banda no era una limitación, Ganesh tenía un bajo sobrecosto y no afectaba el rendimiento.",
        "Nuestros experimentos también confirman que aprovechar la estructura presente en los resultados de la base de datos es crucial para esta mejora en el rendimiento.",
        "Antecedentes 2.1 Generación de Contenido Dinámico A medida que la World Wide Web ha crecido, muchos sitios web han descentralizado sus datos y funcionalidades al llevarlos a los extremos de Internet.",
        "Hoy en día, los sistemas de comercio electrónico a menudo utilizan una arquitectura de tres niveles que consta de un servidor web de front-end, un servidor de aplicaciones y un servidor de base de datos de back-end.",
        "La Figura 1 ilustra esta arquitectura.",
        "Los dos primeros niveles se pueden replicar cerca de una concentración de clientes en el borde de Internet.",
        "Esto mejora la experiencia del usuario al reducir la latencia de extremo a extremo y disminuir la exposición al congestionamiento del tráfico de la columna vertebral.",
        "También puede aumentar la disponibilidad y escalabilidad de los servicios web.",
        "El contenido que se genera dinámicamente desde la base de datos del servidor no puede ser almacenado en caché en los dos primeros niveles.",
        "Si bien las bases de datos pueden replicarse fácilmente en una LAN, esto es inviable en una WAN debido a la difícil tarea de proporcionar simultáneamente una consistencia sólida, disponibilidad y tolerancia a particiones de red [7].",
        "Como resultado, las bases de datos tienden a ser centralizadas para cumplir con los fuertes requisitos de consistencia de muchas aplicaciones de comercio electrónico como la banca, las finanzas y la venta al por menor en línea [38].",
        "Por lo tanto, la base de datos del back-end suele estar ubicada lejos de muchos conjuntos de nodos de primer y segundo nivel [2].",
        "En ausencia de almacenamiento en caché y replicación, el ancho de banda de la WAN puede convertirse fácilmente en un factor limitante en el rendimiento y la escalabilidad de aplicaciones intensivas en datos. El enfoque de Ganesh en los sistemas basados en hash es la transmisión eficiente de resultados al descubrir similitudes con los resultados de consultas anteriores.",
        "Dado que las consultas SQL pueden generar resultados grandes, las técnicas basadas en hash se prestan bien al problema de transferir eficientemente estos grandes resultados a través de enlaces con ancho de banda limitado.",
        "El uso de técnicas basadas en hash para reducir el volumen de datos transmitidos ha surgido como un tema común en muchos sistemas de almacenamiento recientes, como se discute en la Sección 8.2.",
        "Estas técnicas se basan en algunas suposiciones básicas.",
        "Se asume que las funciones hash criptográficas son resistentes a colisiones.",
        "En otras palabras, es computacionalmente intratable encontrar dos entradas que se hash a la misma salida.",
        "Las funciones también se asumen como unidireccionales; es decir, encontrar una entrada que resulte en una salida específica es computacionalmente inviable.",
        "Menezes et al. [23] proporcionan más detalles sobre estas suposiciones.",
        "Las suposiciones anteriores permiten a los sistemas basados en hash asumir que no se producen colisiones.",
        "Por lo tanto, pueden tratar el hash de un elemento de datos como su identificador único.",
        "Una colección de elementos de datos se convierte efectivamente en direccionable por contenido, permitiendo que un hash pequeño funcione como una palabra de código para un elemento de datos mucho más grande en almacenamiento permanente o transmisión en red.",
        "La suposición de que las colisiones son tan raras que prácticamente no existen ha sido cuestionada recientemente [17].",
        "Sin embargo, como explicó Black [5], creemos que estos problemas no son una preocupación para Ganesh.",
        "Toda comunicación es entre partes confiables del sistema y un adversario no tiene forma de obligar a Ganesh a aceptar datos inválidos.",
        "Además, Ganesh no depende críticamente de ninguna función hash específica.",
        "Si bien actualmente usamos SHA-1, reemplazarlo con una función hash diferente sería sencillo.",
        "No habría impacto en el rendimiento con funciones hash más fuertes (por ejemplo,",
        "SHA256) solo añade unos pocos bytes adicionales y los hashes generados siguen siendo órdenes de magnitud más pequeños que los elementos de datos que representan.",
        "No es necesario volver a almacenar permanentemente ya que Ganesh solo utiliza el hash en datos volátiles. 3.",
        "DISEÑO E IMPLEMENTACIÓN Ganesh explota la redundancia en el flujo de resultados para evitar transmitir fragmentos de resultados que ya están presentes en el sitio de la consulta.",
        "La redundancia puede surgir de forma natural de muchas maneras diferentes.",
        "Por ejemplo, una consulta repetida después de un cierto intervalo puede devolver un resultado diferente debido a actualizaciones en la base de datos; sin embargo, puede haber una significativa similitud entre los dos resultados.",
        "Como otro ejemplo, un usuario que está refinando una búsqueda puede generar una secuencia de consultas con resultados superpuestos.",
        "Cuando Ganesh detecta redundancia, suprime la transmisión de los fragmentos de resultado correspondientes.",
        "En cambio, transmite un resumen mucho más pequeño de esos fragmentos y permite que el sitio de consulta reconstruya el resultado a través de la búsqueda de hash en una caché de resultados anteriores.",
        "De hecho, Ganesh utiliza la computación en los bordes para reducir la comunicación por Internet.",
        "Nuestra descripción de Ganesh se centra en cuatro aspectos.",
        "Primero explicamos nuestro enfoque para detectar similitud en los resultados de la consulta.",
        "A continuación, discutimos cómo la arquitectura Ganesh es completamente invisible para todos los componentes de un sistema de múltiples niveles.",
        "Luego describimos el enfoque basado en proxy de Ganesh y el flujo de datos para detectar similitudes. 3.1 Detectar similitud Una de las decisiones clave de diseño en Ganesh es cómo se detecta la similitud.",
        "Hay muchas formas potenciales de descomponer un resultado en fragmentos.",
        " I the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the thees I,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,",
        "Encontrar esta descomposición óptima es un problema difícil debido al amplio espacio de posibilidades y porque la elección óptima depende de muchos factores, como el contenido del resultado de las consultas, el historial de resultados recientes y el algoritmo de gestión de caché.",
        "Cuando un objeto es opaco, el uso de huellas digitales de Rabin [8, 30] para detectar datos comunes entre dos objetos ha sido demostrado con éxito en el pasado por sistemas como LBFS [26] y CASPER [37].",
        "El fingerprinting de Rabin utiliza una ventana deslizante sobre los datos para calcular un hash rodante.",
        "Suponiendo que la función hash está distribuida uniformemente, un límite de fragmento se define cuando los bits de orden inferior del valor hash son iguales a algún valor predeterminado.",
        "El número de bits de orden inferior utilizados define el tamaño promedio del fragmento.",
        "Estos fragmentos subdivididos del objeto se convierten en la unidad de comparación para detectar similitudes entre diferentes objetos.",
        "Dado que las ubicaciones de los límites encontrados mediante el uso de las huellas de Rabin están determinadas de manera estocástica, generalmente no logran alinearse con ninguna propiedad estructural de los datos subyacentes.",
        "Por lo tanto, el algoritmo maneja bien las actualizaciones en su lugar, inserciones y eliminaciones.",
        "Sin embargo, tiene un rendimiento deficiente en presencia de cualquier reordenamiento de datos.",
        "La Figura 2 muestra un ejemplo donde dos resultados, A y B, que constan de tres filas, tienen los mismos datos pero diferentes atributos de ordenamiento.",
        "En el caso extremo, la huella digital de Rabin podría no ser capaz de encontrar datos similares debido a la forma en que detecta los límites de los fragmentos.",
        "Afortunadamente, Ganesh puede utilizar conocimientos específicos del dominio para una detección de límites más precisa.",
        "La información que explotamos es que el resultado de una consulta refleja la estructura de una base de datos relacional donde todos los datos están organizados en tablas y filas.",
        "Por lo tanto, es sencillo verificar la similitud con resultados anteriores en dos niveles de granularidad: primero el resultado completo y luego las filas individuales.",
        "El final de una fila en un resultado sirve como un límite natural de fragmento.",
        "Es importante tener en cuenta que el uso de la estructura tabular en los resultados solo implica una interpretación superficial de los datos.",
        "Ganesh no realiza ninguna interpretación semántica más profunda, como comprender tipos de datos, esquemas de resultados o restricciones de integridad.",
        "Ajustar la huella digital de Rabin para una carga de trabajo también puede ser difícil.",
        "Si el tamaño promedio de los fragmentos es demasiado grande, los fragmentos pueden abarcar varias filas de resultados.",
        "Sin embargo, seleccionar un tamaño de fragmento promedio más pequeño aumenta la cantidad de metadatos necesarios para describir los resultados.",
        "Esto, a su vez, disminuiría los ahorros obtenidos mediante su uso.",
        "El fingerprinting de Rabin también requiere dos pasadas computacionalmente costosas sobre los datos: una vez para determinar los límites de los fragmentos y otra vez para generar hashes criptográficos para los fragmentos.",
        "Ganesh solo necesita un único pase para la generación de hash, ya que los límites de los fragmentos son proporcionados por la estructura natural de los datos.",
        "La comparación de rendimiento en la Sección 6 muestra que el algoritmo basado en filas de Ganesh supera al fingerprinting de Rabin.",
        "Dado que trabajos anteriores ya han demostrado que la huella digital de Rabin funciona mejor que gzip [26], no comparamos a Ganesh con algoritmos de compresión en este artículo. 3.2 Transparencia El factor clave que influyó en nuestro diseño fue la necesidad de que Ganesh fuera completamente transparente para todos los componentes de un sistema típico de comercio electrónico: servidores web, servidores de aplicaciones y servidores de bases de datos.",
        "Sin esto, Ganesh tiene pocas posibilidades de tener un impacto significativo en el mundo real.",
        "Requerir modificaciones en cualquiera de los componentes mencionados aumentaría la barrera de entrada de Ganesh en un sistema existente, y por lo tanto reduciría sus posibilidades de adopción.",
        "Preservar la transparencia se simplifica por el hecho de que Ganesh es simplemente una mejora de rendimiento, no una mejora de funcionalidad o usabilidad.",
        "Elegimos la interposición de agentes como enfoque arquitectónico para lograr nuestro objetivo.",
        "Este enfoque se basa en la existencia de una interfaz de programación compacta que ya es ampliamente utilizada por el software objetivo.",
        "También se basa en un mecanismo para agregar fácilmente nuevo código sin interrumpir la estructura de módulos existente.",
        "Estas condiciones se cumplen fácilmente en nuestro contexto debido a la popularidad de Java como el lenguaje de programación para sistemas de comercio electrónico.",
        "La API de Conectividad de Base de Datos de Java (JDBC) [32] permite a las aplicaciones de Java acceder a una amplia variedad de bases de datos e incluso a otros repositorios de datos tabulares como archivos planos.",
        "El acceso a estas fuentes de datos es proporcionado por controladores JDBC que traducen entre la API JDBC y el mecanismo de comunicación de la base de datos.",
        "La figura 3(a) muestra cómo se utiliza típicamente JDBC en una aplicación.",
        "Dado que la interfaz JDBC está estandarizada, se puede sustituir un controlador JDBC por otro sin necesidad de de modificar la aplicación.",
        "El controlador JDBC se convierte así en el módulo natural para aprovechar la interposición de código.",
        "Como se muestra en la Figura 3(b), el controlador JDBC nativo es reemplazado por un controlador JDBC Ganesh que presenta la misma interfaz estandarizada.",
        "El controlador Ganesh mantiene una caché en memoria de fragmentos de resultados de consultas anteriores y realiza el reensamblaje de resultados.",
        "En la base de datos, agregamos un nuevo proceso llamado el proxy Ganesh.",
        "Este proxy, que puede ser compartido por múltiples nodos front-end, consta de dos partes: código para detectar similitud en fragmentos de resultados y el controlador JDBC nativo original que se comunica con la base de datos.",
        "El uso de un proxy en la base de datos hace que Ganesh sea independiente de la base de datos y simplifica la creación de prototipos y experimentación.",
        "Ganesh es capaz de trabajar con una amplia gama de bases de datos y aplicaciones, sin necesidad de realizar modificaciones en ninguna de ellas. 3.3 Caché basada en proxy El controlador JDBC nativo mostrado en la Figura 3(a) es un componente de código ligero suministrado por el proveedor de la base de datos.",
        "Su función principal es mediar la comunicación entre la aplicación y la base de datos remota.",
        "Reenvía consultas, almacena resultados completos y responde a solicitudes de la aplicación para ver partes de los resultados.",
        "El controlador JDBC de Ganesh mostrado en la Figura 3(b) presenta a la aplicación una interfaz idéntica a la proporcionada por el controlador nativo.",
        "Proporciona la capacidad de reconstruir resultados a partir de descripciones compactas basadas en hash enviadas por el proxy.",
        "Para realizar esta reconstrucción, el controlador mantiene una caché en memoria de los resultados recibidos recientemente.",
        "Esta caché solo se utiliza como fuente de fragmentos de resultados en la reconstrucción de resultados.",
        "El conductor Ganesh o el proxy no intentan rastrear las actualizaciones de la base de datos.",
        "La falta de consistencia en la caché no afecta a la corrección, ya que la descripción de los resultados siempre se obtiene del proxy; en el peor de los casos, no habrá beneficio de rendimiento al usar Ganesh.",
        "Los datos obsoletos simplemente se eliminarán de la caché con el tiempo.",
        "El proxy de Ganesh accede a la base de datos a través del controlador JDBC nativo, que permanece sin cambios entre las Figuras 3(a) y (b).",
        "La base de datos está completamente ajena a la existencia del proxy.",
        "El proxy no examina ninguna consulta recibida del controlador Ganesh, sino que las pasa al controlador nativo.",
        "En cambio, el proxy es responsable de inspeccionar la salida de la base de datos recibida del controlador nativo, detectar resultados similares y generar codificaciones basadas en hash de estos resultados siempre que se encuentre suficiente similitud.",
        "Si bien esta arquitectura no disminuye la carga en una base de datos, como se mencionó anteriormente en la Sección 2.1, es mucho más fácil replicar bases de datos para escalabilidad en una LAN que en una WAN.",
        "Para generar una codificación basada en hash, el proxy debe estar al tanto de qué fragmentos de resultados están disponibles en la caché de controladores de Ganesh.",
        "Un enfoque es ser optimista y asumir que todos los fragmentos de resultados están disponibles.",
        "Esto resultará en la transmisión inicial más pequeña posible de un resultado.",
        "Sin embargo, en casos donde hay poca superposición con resultados anteriores, el controlador Ganesh tendrá que realizar muchas llamadas al proxy durante la reconstrucción para recuperar fragmentos de resultados faltantes.",
        "Para evitar esta situación, el proxy sigue de manera flexible el estado de la caché de controladores de Ganesh.",
        "Dado que ambos componentes están bajo nuestro control, es relativamente sencillo hacer esto sin recurrir a técnicas de caja gris o comunicación explícita para mantener la coherencia de la caché.",
        "En cambio, el proxy simula el algoritmo de gestión de caché de controladores de Ganesh y lo utiliza para mantener una lista de hashes para los cuales es probable que el controlador de Ganesh posea los fragmentos de resultado.",
        "En caso de desviación de seguimiento, no habrá pérdida de corrección, pero habrá retrasos adicionales en el viaje de ida y vuelta para recuperar los fragmentos faltantes.",
        "Si el cliente detecta la pérdida de sincronización con el proxy, puede pedirle al proxy que restablezca el estado compartido entre ellos.",
        "También hay que tener en cuenta que el proxy no necesita guardar los fragmentos de resultado en sí, solo sus hashes.",
        "Esto permite que el proxy siga siendo escalable incluso cuando es compartido por muchos nodos front-end.",
        "El proxy Ganesh recibe la salida de la base de datos como objetos Java del controlador JDBC nativo.",
        "Examina esta salida para ver si está presente un objeto Java del tipo ResultSet.",
        "La interfaz JDBC utiliza este tipo de dato para almacenar los resultados de las consultas a la base de datos.",
        "Si se encuentra un objeto ResultSet, se reduce como se discute a continuación.",
        "Todos los demás objetos de Java se pasan sin modificar.",
        "Como se discute en la Sección 3.1, el proxy utiliza los límites de fila definidos en el ResultSet para dividirlo en fragmentos que consisten en filas de resultado individuales.",
        "Todos los objetos ResultSet se convierten en objetos de un nuevo tipo llamado RecipeResultSet.",
        "Utilizamos el término receta para esta descripción compacta de un resultado de base de datos debido a su similitud con una receta de archivo en el sistema de archivos CASPER [37].",
        "La conversión reemplaza cada fragmento de resultado que probablemente esté presente en la caché de controladores de Ganesh por un hash SHA-1 de ese fragmento.",
        "Los fragmentos de resultados previamente no vistos se conservan textualmente.",
        "El proxy también retiene los hashes de los nuevos fragmentos de resultados, ya que estarán presentes en la caché de los controladores en el futuro.",
        "Ten en cuenta que el proxy solo almacena en caché los hashes de los fragmentos de resultados y no almacena en caché las recetas.",
        "El proxy construye un RecipeResultSet verificando la similitud en todo el resultado y luego a nivel de fila.",
        "Si se predice que todo el resultado estará presente en la caché de los controladores de Ganesh, el RecipeResultSet será simplemente un único hash de todo el resultado.",
        "De lo contrario, contiene hashes para aquellas filas que se predice que están presentes en esa caché; todas las demás filas se conservan textualmente.",
        "Si el proxy estima un ahorro de espacio general, transmitirá el RecipeResultSet.",
        "De lo contrario, se transmite el ResultSet original.",
        "Los objetos RecipeResultSet son transformados de vuelta en objetos ResultSet por el controlador Ganesh.",
        "La Figura 4 ilustra el manejo de ResultSet en ambos extremos.",
        "Cada hash SHA-1 encontrado en un RecipeResultSet se busca en la caché local de fragmentos de resultados.",
        "En caso de acierto, el hash es reemplazado por el fragmento correspondiente.",
        "En caso de error, el conductor contacta al proxy de Ganesh para recuperar el fragmento.",
        "Todos los fragmentos de resultados previamente no vistos que fueron retenidos textualmente por el proxy se hasheado y se han añadido a la caché de resultados.",
        "Debería haber muy pocos fallos si el proxy ha seguido con precisión el estado de la caché de controladores de Ganesh.",
        "Una optimización futura sería agrupar la obtención de fragmentos faltantes.",
        "Esto sería valioso cuando hay muchos pequeños fragmentos faltantes en una WAN de alta latencia.",
        "Una vez que la transformación esté completa, el objeto ResultSet completamente reconstruido se pasa a la aplicación. 4.",
        "VALIDACIÓN EXPERIMENTAL Tres preguntas surgen de los objetivos y diseño de Ganesh: • Primero, ¿se puede mejorar significativamente el rendimiento al explotar la similitud entre los resultados de la base de datos?",
        "Detalles del conjunto de datos de referencia 500,000 usuarios, 12,000 historias BBOARD 2.0 GB 3,298,000 comentarios SUBASTA 1.3 GB 1,000,000 usuarios, 34,000 elementos Tabla 1: Detalles del conjunto de datos de referencia • En segundo lugar, ¿qué tan importante es la detección de similitud estructural de Ganesh en comparación con la detección de similitud de la huella digital de Rabin? • En tercer lugar, ¿es aceptable la sobrecarga del diseño basado en proxy?",
        "Nuestra evaluación responde a estas preguntas a través de experimentos controlados con el prototipo Ganesh.",
        "Esta sección describe los puntos de referencia utilizados, nuestro procedimiento de evaluación y la configuración experimental.",
        "Los resultados de los experimentos se presentan en las Secciones 5, 6 y 7. 4.1 Puntos de referencia Nuestra evaluación se basa en dos puntos de referencia [18] que han sido ampliamente utilizados por otros investigadores para evaluar varios aspectos de arquitecturas multi-tier [27] y de comercio electrónico [9].",
        "El primer punto de referencia, BBOARD, está modelado según Slashdot, un sitio de noticias orientado a la tecnología.",
        "El segundo punto de referencia, AUCTION, está modelado según eBay, un sitio de subastas en línea.",
        "En ambos puntos de referencia, la mayoría del contenido se genera dinámicamente a partir de la información almacenada en una base de datos.",
        "Los detalles de los conjuntos de datos utilizados se pueden encontrar en la Tabla 1. 4.1.1 El Benchmark BBOARD El benchmark BBOARD, también conocido como RUBBoS [18], modela Slashdot, un popular sitio web orientado a la tecnología.",
        "Slashdot recopila enlaces a noticias y otros temas de interés encontrados en otros lugares de la web.",
        "El sitio también funciona como un tablón de anuncios al permitir a los usuarios comentar en las historias publicadas en forma de conversación en hilos.",
        "No es raro que una historia recopile cientos de comentarios en cuestión de horas.",
        "El benchmark BBOARD es similar al sitio y modela las actividades de un usuario, incluyendo operaciones de solo lectura como navegar por las historias del día, explorar categorías de historias y ver comentarios, así como operaciones de escritura como registro de nuevos usuarios, agregar y moderar comentarios, y enviar historias.",
        "El benchmark consiste en tres fases diferentes: una fase de calentamiento corta, una fase de ejecución que representa el cuerpo principal de la carga de trabajo, y una fase de enfriamiento corta.",
        "En este documento solo informamos sobre los resultados de la fase de ejecución.",
        "La fase de calentamiento es importante para establecer el estado del sistema dinámico, pero las mediciones de esa fase no son significativas para nuestra evaluación.",
        "La fase de enfriamiento es únicamente para permitir que el punto de referencia se apague.",
        "Las fases de calentamiento, ejercicio y enfriamiento son de 2, 15 y 2 minutos respectivamente.",
        "El número de clientes simulados fue de 400, 800, 1200 y 1600.",
        "El punto de referencia está disponible en una versión de Java Servlets y PHP y tiene diferentes conjuntos de datos; evaluamos a Ganesh utilizando la versión de Java Servlets y el conjunto de datos Expandido.",
        "El benchmark BBOARD define dos cargas de trabajo diferentes.",
        "El primero, la mezcla de Autoría, consiste en un 70% de operaciones de solo lectura y un 30% de operaciones de lectura y escritura.",
        "El segundo, la mezcla de navegación, contiene solo operaciones de solo lectura y no actualiza la base de datos. 4.1.2 El Benchmark de SUBASTA El benchmark de SUBASTA, también conocido como RUBiS [18], modela eBay, el sitio de subastas en línea.",
        "El sitio web de eBay se utiliza para comprar y vender artículos a través de un formato de subasta.",
        "Las principales actividades de un usuario incluyen navegar, vender o pujar por artículos.",
        "Modelando las actividades en este sitio, este punto de referencia incluye actividades de solo lectura como navegar por artículos por categoría y por región, así como actividades de lectura-escritura como pujar por artículos, comprar y vender artículos, y dejar comentarios.",
        "Al igual que con BBOARD, el benchmark consiste en tres fases diferentes.",
        "Las fases de calentamiento, ejecución y enfriamiento para este experimento son de 1.5, 15 y 1 minutos respectivamente.",
        "Probamos Ganesh con cuatro configuraciones de clientes donde el número de clientes de prueba se estableció en 400, 800, 1200 y 1600.",
        "El punto de referencia está disponible en una versión de Enterprise Java Bean (EJB), Java Servlets y PHP y tiene diferentes conjuntos de datos; evaluamos Ganesh con la versión de Java Servlets y el conjunto de datos Expandido.",
        "El benchmark de SUBASTA define dos cargas de trabajo diferentes.",
        "El primero, la mezcla de Ofertas, consiste en un 70% de operaciones de solo lectura y un 30% de operaciones de lectura-escritura.",
        "El segundo, la mezcla de navegación, contiene solo operaciones de solo lectura y no actualiza la base de datos. 4.2 Procedimiento Experimental Ambos benchmarks involucran una carga de trabajo sintética de clientes accediendo a un servidor web.",
        "El número de clientes emulados es un parámetro experimental.",
        "Cada cliente emulado ejecuta una instancia del benchmark en su propio hilo, utilizando una matriz para hacer la transición entre diferentes estados del benchmark.",
        "La matriz define un modelo estocástico con probabilidades de transición entre los diferentes estados que representan las acciones típicas de los usuarios.",
        "Un ejemplo de transición es un usuario iniciando sesión en el sistema de SUBASTA y luego decidiendo si publicar un artículo en venta o pujar en subastas activas.",
        "Cada cliente también modela el tiempo de pensamiento del usuario entre las solicitudes.",
        "El tiempo de pensamiento se modela como una distribución exponencial con una media de 7 segundos.",
        "Evaluamos a Ganesh a lo largo de dos ejes: número de clientes y ancho de banda de la WAN.",
        "Las cargas más altas son especialmente útiles para comprender el rendimiento de Ganesh cuando la CPU o el disco del servidor de base de datos o del proxy son el factor limitante.",
        "Un estudio previo ha demostrado que aproximadamente el 50% de los cuellos de botella de Internet de gran área observados tenían un ancho de banda disponible inferior a 10 Mb/s [1].",
        "Basándonos en este trabajo, enfocamos nuestra evaluación en el ancho de banda de la WAN de 5 Mb/s con una latencia de ida y vuelta de 66 ms, representativa de rutas de red severamente restringidas, y 20 Mb/s con una latencia de ida y vuelta de 33 ms, representativa de una ruta de red moderadamente restringida.",
        "También informamos sobre el rendimiento de Ganesh a 100 Mb/s sin agregar latencia de ida y vuelta.",
        "Este ancho de banda, representativo de una red sin restricciones, es especialmente útil para revelar cualquier sobrecarga potencial de Ganesh en situaciones donde el ancho de banda de la WAN no es el factor limitante.",
        "Para cada combinación de número de clientes y ancho de banda de WAN, medimos los resultados de las dos configuraciones enumeradas a continuación: • Nativa: Esta configuración corresponde a la Figura 3(a).",
        "El nativo evita la sobrecarga de Ganesh al usar un proxy y realizar la serialización de objetos Java. • Ganesh: Esta configuración corresponde a la Figura 3(b).",
        "Para un número dado de clientes y ancho de banda de WAN, comparar estos resultados con los resultados nativos correspondientes proporciona el beneficio de rendimiento debido al sistema de middleware Ganesh.",
        "La métrica utilizada para cuantificar la mejora en el rendimiento es el número de solicitudes de clientes que pueden ser atendidas por segundo.",
        "La métrica utilizada para cuantificar el rendimiento de Ganesh es el tiempo promedio de respuesta para una solicitud de cliente.",
        "Para todos los experimentos, el controlador Ganesh utilizado por el servidor de aplicaciones usó un tamaño de caché de 100,000 elementos.",
        "El proxy fue efectivo en rastrear el estado de la caché de los controladores Ganesh; para todos nuestros experimentos, la tasa de fallos en el controlador nunca superó el 0.7%. 4.3 Configuración Experimental La configuración experimental utilizada para las pruebas se puede ver en la Figura 5.",
        "Todas las máquinas eran Pentium 4 de 3.2 GHz (con HyperThreading habilitado).",
        "Con la excepción del servidor de base de datos, todas las máquinas tenían 2 GB de SDRAM y ejecutaban la distribución de Linux Fedora Core.",
        "El servidor de la base de datos tenía 4 GB de SDRAM.",
        "Utilizamos Apache Tomcat como tanto el servidor de aplicaciones que alojaba los Servlets de Java como el servidor web.",
        "Ambos benchmarks utilizaron Java Servlets para generar el contenido dinámico.",
        "El servidor de la base de datos utilizó la base de datos de código abierto MySQL.",
        "Para los controladores JDBC nativos, utilizamos los controladores Connector/J proporcionados por MySQL.",
        "El servidor de aplicaciones utilizaba la Máquina Virtual de Java de Sun como entorno de ejecución para los Servlets de Java.",
        "La herramienta sysstat se utilizó para monitorear la utilización de la CPU, red, disco y memoria en todas las máquinas.",
        "Las máquinas estaban conectadas por una red Ethernet gigabit conmutada.",
        "Como se muestra en la Figura 5, el servidor web y de aplicación de front-end fue separado del servidor de proxy y base de datos por un enrutador NetEm [16].",
        "Este enrutador nos permitió controlar la configuración de ancho de banda y latencia en la red.",
        "El enrutador NetEm es un PC estándar con dos tarjetas de red que ejecuta el software de Control de Tráfico de Linux y Emulación de Red.",
        "Las restricciones de ancho de banda y latencia solo se aplicaron al enlace entre el servidor de aplicaciones y la base de datos para el caso nativo y entre el servidor de aplicaciones y el proxy para el caso de Ganesh.",
        "No hay comunicación entre el servidor de aplicaciones y la base de datos con Ganesh, ya que todos los datos fluyen a través del proxy.",
        "Como nuestro enfoque estaba en el enlace WAN entre el servidor de aplicaciones y la base de datos, no hubo restricciones en el enlace entre los clientes de prueba simulados y el servidor web. 5.",
        "DESEMPEÑO Y TIEMPO DE RESPUESTA En esta sección, abordamos la primera pregunta planteada en la Sección 4: ¿Se puede mejorar significativamente el rendimiento explotando la similitud entre los resultados de la base de datos?",
        "Para responder a esta pregunta, utilizamos los resultados de los benchmarks BBOARD y AUCTION.",
        "Utilizamos dos métricas para cuantificar la mejora en el rendimiento obtenible a través del uso de Ganesh: el throughput, desde la perspectiva del servidor web, y el tiempo de respuesta promedio, desde la perspectiva del cliente.",
        "El rendimiento se mide en términos del número de solicitudes de clientes que pueden ser atendidas por segundo. Los resultados y análisis de BBOARD 5.1 Figuras 6 (a) y (b) presentan el número promedio de solicitudes atendidas por segundo y el tiempo de respuesta promedio para estas solicitudes tal como lo perciben los clientes para la Mezcla de Autoría de BBOARD.",
        "Como muestra la Figura 6 (a), Native satura fácilmente el enlace de 5 Mb/s.",
        "Con 400 clientes, la solución nativa entrega 29 solicitudes/segundo con un tiempo de respuesta promedio de 8.3 segundos.",
        "La capacidad de procesamiento de los clientes disminuye con un aumento en los clientes de prueba, ya que los clientes se agotan debido a la congestión en el servidor de aplicaciones.",
        "Los estudios de usabilidad han demostrado que los tiempos de respuesta superiores a 10 segundos hacen que el usuario pase a 1. Dado que Java carece de un operador sizeof(), los cachés de Java limitan su tamaño en función del número de objetos.",
        "El tamaño de los volcados de caché tomados al final de los experimentos nunca superó los 212 MB.",
        "WWW 2007 / Pista: Rendimiento y Escalabilidad Sesión: Sistemas Escalables para Contenido Dinámico 315 0 50 100 150 200 250 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Solicitudes de Clientes de Prueba por Segundo Nativo Ganesh 0.001 0.01 0.1 1 10 100 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Tiempo Promedio de Respuesta de Clientes de Prueba Nativo Ganesh Nota Escala Logarítmica (a) Rendimiento: Mezcla de Autoría (b) Tiempo de Respuesta: Mezcla de Autoría 0 50 100 150 200 250 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Solicitudes de Clientes de Prueba por Segundo Nativo Ganesh 0.001 0.01 0.1 1 10 100 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Tiempo Promedio de Respuesta de Clientes de Prueba Nativo Ganesh Nota Escala Logarítmica (c) Rendimiento: Mezcla de Navegación (d) Tiempo de Respuesta: Mezcla de Navegación Promedio de tres pruebas.",
        "La desviación estándar máxima para el rendimiento y el tiempo de respuesta fue del 9.8% y 11.9% de la media correspondiente.",
        "Figura 6: BBOARD Benchmark - Rendimiento y Tiempo de Respuesta Promedio de otras tareas [24].",
        "Basándose en estos números, aumentar el número de clientes de prueba hace que el sistema Nativo sea inutilizable.",
        "Ganesh a 5 Mb/s, sin embargo, ofrece una mejora doble con 400 clientes de prueba y una mejora quintuple con 1200 clientes.",
        "El rendimiento de Ganesh disminuye ligeramente a 1200 y 1600 clientes debido a que la red está saturada.",
        "En comparación con Native, la Figura 6 (b) muestra que los tiempos de respuesta de Ganesh son considerablemente más bajos con tiempos de respuesta de menos de un segundo con 400 clientes.",
        "La Figura 6 (a) también muestra que para 400 y 800 clientes de prueba, Ganesh a 5 Mb/s tiene el mismo rendimiento y tiempo de respuesta promedio que Native a 20 Mb/s.",
        "Solo con 1200 y 1600 clientes, Native a 20 Mb/s ofrece un rendimiento mayor que Ganesh a 5 Mb/s.",
        "Al comparar tanto a Ganesh como a Native a 20 Mb/s, vemos que Ganesh ya no está limitado por el ancho de banda y ofrece hasta una mejora del doble sobre Native con 1600 clientes de prueba.",
        "Como Ganesh no satura la red con configuraciones de cliente de prueba más altas, con 1600 clientes de prueba, su tiempo de respuesta promedio es de 0.1 segundos en lugar de los 7.7 segundos de Natives.",
        "Como era de esperar, no hay ganancias visibles de Ganesh en el ancho de banda más alto de 100 Mb/s donde la red ya no es el cuello de botella.",
        "Sin embargo, Ganesh sigue monitoreando a Native en cuanto a rendimiento. Las Figuras 6 (c) y (d) presentan el número promedio de solicitudes atendidas por segundo y el tiempo de respuesta promedio para estas solicitudes tal como lo perciben los clientes para la Mezcla de Navegación de BBOARDs.",
        "Independientemente de la configuración del cliente de prueba, la Figura 6 (c) muestra que el rendimiento de los Nativos a 5 Mb/s está limitado a 10 reqs/seg.",
        "Ganesh a 5 Mb/s con 400 clientes de prueba, ofrece un aumento de más de seis veces en el rendimiento.",
        "La mejora aumenta a más de once veces a 800 clientes de prueba antes de que Ganesh sature la red.",
        "Además, la Figura 6 (d) muestra que el tiempo de respuesta promedio de los Nativos de 35 segundos con 400 clientes de prueba hace que el sistema sea inutilizable.",
        "Estos altos tiempos de respuesta aumentan aún más con la adición de clientes de prueba.",
        "Incluso con la configuración del cliente de prueba de 1600, Ganesh ofrece un tiempo de respuesta promedio aceptable de 8.2 segundos.",
        "Debido a la naturaleza intensiva en datos de la mezcla de navegación, Ganesh a 5 Mb/s sorprendentemente tiene un rendimiento mucho mejor que Native a 20 Mb/s.",
        "Además, como se muestra en la Figura 6 (d), si bien el tiempo de respuesta promedio para Native a 20 Mb/s es aceptable con 400 clientes de prueba, resulta inutilizable con 800 clientes de prueba, con un tiempo de respuesta promedio de 15.8 segundos.",
        "Al igual que en el caso de 5 Mb/s, este tiempo de respuesta aumenta con la adición de clientes de prueba adicionales.",
        "Ganesh a 20 Mb/s y tanto Native como Ganesh a 100 Mb/s no tienen limitaciones de ancho de banda.",
        "Sin embargo, el rendimiento se estanca después de 1200 clientes de prueba debido a que la CPU de la base de datos está saturada. 5.1.3 Variante de filtro Nos sorprendió el rendimiento nativo del benchmark BBOARD.",
        "A una velocidad de banda ancha de 5 Mb/s, el rendimiento nativo fue más bajo de lo que esperábamos.",
        "Resultó que el código de referencia que muestra historias leía todos los comentarios asociados con la historia en particular de la base de datos y solo entonces realizaba un postprocesamiento para seleccionar los comentarios que se mostrarían.",
        "Si bien este es exactamente el comportamiento de SlashCode, la base de código detrás del sitio web de Slashdot, decidimos modificar la prueba de rendimiento para realizar cierto prefiltrado en la base de datos.",
        "Este benchmark modificado, llamado el Filtro de Variantes, modela a un desarrollador que aplica optimizaciones a nivel de SQL para transferir menos datos.",
        "En aras de la brevedad, solo resumimos brevemente los resultados de la mezcla de autores.",
        "Para la mezcla de Autoría, con 800 clientes de prueba a 5 Mb/s, la Figura 7 (a) muestra que el rendimiento de Natives aumenta un 85% en comparación con el punto de referencia original, mientras que la mejora de Ganesh es menor, del 15%.",
        "El rendimiento de los servidores disminuye por encima de los 800 clientes, ya que los clientes de prueba se agotan debido a los altos tiempos de respuesta.",
        "La ganancia más significativa para Native se observa a 20 Mb/s.",
        "En 1600 clientes de prueba, en comparación con el punto de referencia original, Native experimenta una mejora del 73% en el rendimiento y una reducción del 77% en el tiempo de respuesta promedio.",
        "Mientras WWW 2007 / Pista: Rendimiento y Escalabilidad Sesión: Sistemas Escalables para Contenido Dinámico 316 0 50 100 150 200 250 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Clientes de Prueba Solicitudes/seg Nativo Ganesh 0.001 0.01 0.1 1 10 100 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Clientes de Prueba Tiempo de Resp. Promedio (seg) Nativo Ganesh Nota Escala Logarítmica (a) Rendimiento: Mezcla de Autoría (b) Tiempo de Respuesta: Mezcla de Autoría Promedio de tres pruebas.",
        "La desviación estándar máxima para el rendimiento y el tiempo de respuesta fue del 7.2% y del 11.5% de la media correspondiente.",
        "Figura 7: BBOARD Benchmark - Variante de filtro - Rendimiento y Tiempo de Respuesta Promedio Ganesh no observa ninguna mejora en comparación con el original, aún procesa un 19% más de solicitudes/seg que Native.",
        "Por lo tanto, aunque las optimizaciones fueron más útiles para Native, Ganesh todavía ofrece una mejora en el rendimiento. 5.2 Resultados y Análisis de la SUBASTA 5.2.1 Figuras de la Mezcla de Ofertas Los gráficos 8 (a) y (b) presentan el número promedio de solicitudes atendidas por segundo y el tiempo de respuesta promedio para estas solicitudes tal como son percibidas por los clientes para la Mezcla de Ofertas de las SUBASTAS.",
        "Como se mencionó anteriormente, la mezcla de ofertas consiste en una combinación de operaciones de lectura y escritura.",
        "El benchmark AUCTION no es tan intensivo en datos como BBOARD.",
        "Por lo tanto, la mayoría de las ganancias se observan en el ancho de banda más bajo de 5 Mb/s.",
        "La figura 8 (a) muestra que el aumento en el rendimiento debido a Ganesh varía desde un 8% con 400 clientes de prueba hasta un 18% con 1600 clientes de prueba.",
        "Como se observa en la Figura 8 (b), los tiempos de respuesta promedio para Ganesh son significativamente más bajos que los de Native, con una disminución del 84% a 800 clientes de prueba y del 88% a 1600 clientes de prueba.",
        "La Figura 8 (a) también muestra que con un aumento cuádruple del ancho de banda de 5 Mb/s a 20 Mb/s, Native ya no está limitado por el ancho de banda y no hay diferencia de rendimiento entre Ganesh y Native.",
        "Con las configuraciones de cliente de prueba más altas, observamos que el ancho de banda utilizado por Ganesh era menor que el de Nativo.",
        "Ganesh podría seguir siendo útil en estos escenarios no restringidos si se compra ancho de banda de forma medible.",
        "Se observan resultados similares para el escenario de 100 Mb/s. 5.2.2 Mezcla de Navegación Para la Mezcla de Navegación de SUBASTAS, las Figuras 8 (c) y (d) presentan el número promedio de solicitudes atendidas por segundo y el tiempo promedio de respuesta para estas solicitudes tal como lo perciben los clientes.",
        "Una vez más, la mayoría de las ganancias se observan en anchos de banda más bajos.",
        "A 5 Mb/s, Native y Ganesh ofrecen un rendimiento y tiempos de respuesta similares con 400 clientes de prueba.",
        "Mientras que el rendimiento para ambos permanece igual en 800 clientes de prueba, la Figura 8 (d) muestra que el tiempo de respuesta promedio de Ganesh es un 62% menor que el de Native.",
        "El servidor satura el enlace con 800 clientes y agregar clientes de prueba adicionales solo aumenta el tiempo promedio de respuesta.",
        "Ganesh, independientemente de la configuración del cliente de prueba, no tiene restricciones de ancho de banda y mantiene el mismo tiempo de respuesta.",
        "A 1600 clientes de prueba, la Figura 8 (c) muestra que el rendimiento de Ganesh es casi el doble que el de Nativo.",
        "En los anchos de banda más altos de 20 y 100 Mb/s, ni Ganesh ni Native tienen limitaciones de ancho de banda y ofrecen un rendimiento y tiempos de respuesta equivalentes.",
        "Referencia original.",
        "Tamaño Ganesh Tamaño Rabin Tamaño SelectSort1 223.6 MB 5.4 MB 219.3 MB SelectSort2 223.6 MB 5.4 MB 223.6 MB Tabla 2: Microbenchmarks de similitud 6.",
        "SIMILITUD ESTRUCTURAL VS. SIMILITUD DE RABIN En esta sección, abordamos la segunda pregunta planteada en la Sección 4: ¿Qué tan importante es la detección de similitud estructural de Ganesh en comparación con la detección de similitud basada en la huella digital de Rabin?",
        "Para responder a esta pregunta, utilizamos microbenchmarks y los benchmarks BBOARD y AUCTION.",
        "Dado que Ganesh siempre tuvo un mejor rendimiento que Rabin en la huella dactilar, aquí presentamos solo un subconjunto de los resultados en aras de la brevedad. 6.1 Microbenchmarks Dos microbenchmarks muestran un ejemplo de los efectos de la reordenación de datos en el algoritmo de huella dactilar de Rabin.",
        "En el primer microbenchmark, SelectSort1, una consulta con un orden de clasificación especificado selecciona 223.6 MB de datos distribuidos en aproximadamente 280 K filas.",
        "La consulta se repite entonces con un atributo de ordenación diferente.",
        "Si bien se devuelve el mismo número de filas y los mismos datos, el orden de las filas es diferente.",
        "En un escenario así, se esperaría detectar una gran cantidad de similitud entre ambos resultados.",
        "Como muestra la Tabla 2, el algoritmo basado en filas de Ganesh logra una reducción del 97.6%, mientras que el algoritmo de huella digital de Rabin, con el parámetro de tamaño de fragmento promedio establecido en 4 KB, solo logra una reducción del 1%.",
        "La razón, como se muestra anteriormente en la Figura 2, es que con la huella digital de Rabin, los tramos de datos entre dos límites consecutivos suelen cruzar los límites de fila.",
        "Con el cambio en el orden de las filas en el segundo resultado y los fingerprints de Rabin ahora abarcando diferentes filas, el algoritmo no puede detectar similitud significativa.",
        "La pequeña ganancia observada se debe principalmente a aquellas filas individuales que son lo suficientemente grandes como para dividirse en múltiples fragmentos.",
        "SelectSort2, otro micro-benchmark ejecutó las mismas consultas pero aumentó el tamaño mínimo del fragmento del algoritmo de huella digital de Rabin.",
        "Como se puede ver en la Tabla 2, incluso la pequeña ganancia del microbenchmark anterior desaparece cuando el tamaño mínimo de fragmento fue mayor que el tamaño promedio de fila.",
        "Si bien se pueden abordar parcialmente estos problemas variando dinámicamente los parámetros del algoritmo de huella digital de Rabin, esto puede resultar computacionalmente costoso, especialmente en presencia de cargas de trabajo cambiantes. 6.2 Benchmarks de Aplicación Ejecutamos el benchmark BBOARD descrito en la Sección 4.1.1 en dos versiones de Ganesh: la primera con la huella digital de Rabin utilizada como WWW 2007 / Track: Sesión de Rendimiento y Escalabilidad: Sistemas Escalables para Contenido Dinámico 317 0 50 100 150 200 250 300 350 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Clientes de Prueba Solicitudes/seg Ganesh Nativo 0.001 0.01 0.1 1 10 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Clientes de Prueba Tiempo de Respuesta Promedio (seg) Ganesh Nativo Nota Escala Logarítmica (a) Rendimiento: Mezcla de Ofertas (b) Tiempo de Respuesta: Mezcla de Ofertas 0 50 100 150 200 250 300 350 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Clientes de Prueba Solicitudes/seg Ganesh Nativo 0.001 0.01 0.1 1 10 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Clientes de Prueba Tiempo de Respuesta Promedio (seg) Ganesh Nativo Nota Escala Logarítmica (c) Rendimiento: Mezcla de Navegación (d) Tiempo de Respuesta: Mezcla de Navegación Promedio de tres pruebas.",
        "La desviación estándar máxima para el rendimiento y el tiempo de respuesta fue del 2.2% y del 11.8% de la media correspondiente.",
        "Figura 8: Referencia de la subasta AUCTION - Rendimiento y Tiempo de Respuesta Promedio del algoritmo de fragmentación y el segundo con el algoritmo basado en filas de Ganesh.",
        "Los resultados de Rabins para la Mezcla de Navegación se normalizan con los resultados de Ganesh y se presentan en la Figura 9.",
        "Como muestra la Figura 9 (a), a 5 Mb/s, independientemente de la configuración del cliente de prueba, Rabin tiene un rendimiento significativamente inferior a Ganesh.",
        "Esto sucede debido a una combinación de dos razones.",
        "Primero, como se describe en la Sección 3.1, Rabin encuentra menos similitud ya que no explota la información estructural de los resultados.",
        "Segundo, este punto de referencia contenía algunas consultas que generaron resultados grandes.",
        "En este caso, Rabin, con un tamaño de fragmento promedio pequeño, generó una gran cantidad de objetos que desplazaron otros datos útiles de la caché.",
        "Por el contrario, Ganesh pudo detectar estas filas grandes y aumentar correspondientemente el tamaño de los bloques.",
        "Esto fue confirmado ya que las estadísticas de caché mostraron que la proporción de aciertos de Ganesh era aproximadamente tres veces mayor que la de Rabin.",
        "Las mediciones de rendimiento a 20 Mb/s fueron similares, con la excepción del rendimiento de Rabins con 400 clientes de prueba.",
        "En este caso, Ganesh no estaba limitado por la red y, de hecho, el rendimiento era el mismo que el de 400 clientes a 5 Mb/s.",
        "Rabin, sin embargo, aprovechó el aumento del ancho de banda de 5 a 20 Mb/s para ofrecer un rendimiento ligeramente mejor.",
        "A 100 Mb/s, el rendimiento de Rabin era casi similar al de Ganesh ya que el ancho de banda ya no era un cuello de botella.",
        "El tiempo de respuesta normalizado, presentado en la Figura 9 (b), muestra tendencias similares.",
        "A 5 y 20 Mb/s, la adición de clientes de prueba disminuye el tiempo de respuesta normalizado, ya que el tiempo de respuesta promedio de Ganesh aumenta más rápido que el de Rabin.",
        "Sin embargo, en ningún momento Rabin supera a Ganesh.",
        "Ten en cuenta que con 400 y 800 clientes a 100 Mb/s, Rabin tiene un mayor sobrecosto incluso cuando no está limitado por el ancho de banda.",
        "Como se menciona en la Sección 3.1, esto se debe a que Rabin tiene que hashear cada ResultSet dos veces.",
        "La sobrecarga desaparece con 1200 y 1600 clientes, ya que la CPU de la base de datos está saturada y limita el rendimiento tanto de Ganesh como de Rabin. 7.",
        "SUPERPOSICIÓN DE PROXY En esta sección, abordamos la tercera pregunta planteada en la Sección 4: ¿Es aceptable la superposición del diseño basado en proxy de Ganesh?",
        "Para responder a esta pregunta, nos concentramos en su rendimiento en las bandas de mayor ancho de banda.",
        "Nuestra evaluación en la Sección 5 mostró que Ganesh, en comparación con Native, puede ofrecer una mejora sustancial en el rendimiento a anchos de banda más bajos.",
        "Solo en anchos de banda más altos serían visibles los costos adicionales de latencia, medidos por el tiempo promedio de respuesta para una solicitud de cliente, y de rendimiento, medidos por la cantidad de solicitudes de cliente que pueden ser atendidas por segundo.",
        "Al observar la combinación de autoría del benchmark original de BBOARD, no se aprecian ganancias visibles de Ganesh a 100 Mb/s.",
        "Sin embargo, Ganesh sigue rastreando a Native en cuanto a rendimiento.",
        "Si bien el tiempo promedio de respuesta es mayor para Ganesh, la diferencia absoluta está entre 0.01 y 0.04 segundos y sería imperceptible para el usuario final.",
        "La mezcla de navegación muestra una diferencia aún menor en los tiempos de respuesta promedio.",
        "Los resultados de la variante del filtro de los benchmarks de BBOARD son similares.",
        "Incluso para el benchmark de SUBASTA, la diferencia entre el tiempo de respuesta de Nativo y Ganesh a 100 Mb/s nunca fue mayor a 0.02 segundos.",
        "La única excepción a los resultados anteriores se observó en la variante de filtro del benchmark BBOARD, donde Ganesh con 1600 clientes de prueba añadió 0.85 segundos al tiempo de respuesta promedio.",
        "Por lo tanto, incluso para redes mucho más rápidas donde el enlace WAN no es el cuello de botella, Ganesh siempre ofrece un rendimiento equivalente al Nativo.",
        "Si bien se agrega algo de latencia adicional debido al diseño basado en proxy, generalmente es imperceptible.",
        "TRABAJO RELACIONADO Hasta donde sabemos, Ganesh es el primer sistema que combina el uso de técnicas basadas en hash con el almacenamiento en caché de resultados de base de datos para mejorar el rendimiento y los tiempos de respuesta de aplicaciones con contenido dinámico.",
        "También creemos que es el primer sistema en demostrar los beneficios de utilizar información estructural para WWW 2007 / Track: Rendimiento y Escalabilidad Sesión: Sistemas Escalables para Contenido Dinámico 318 0.0 0.2 0.4 0.6 0.8 1.0 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Clientes de Prueba Rendimiento Normalizado 31.8 3.8 2.8 2.3 23.8 32.8 5.8 3.6 1.8 2.1 1.1 1.0 0 5 10 15 20 25 30 35 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Clientes de Prueba Tiempo de Respuesta Normalizado (a) Rendimiento Normalizado: Mayor es mejor (b) Tiempo de Respuesta Normalizado: Mayor es peor Para el rendimiento, un resultado normalizado mayor que 1 implica que Rabin es mejor. Para el tiempo de respuesta, un resultado normalizado mayor que 1 implica que Ganesh es mejor.",
        "Media de tres pruebas.",
        "La desviación estándar máxima para el rendimiento y el tiempo de respuesta fue del 9.1% y del 13.9% de la media correspondiente.",
        "Figura 9: Comparación normalizada de Ganesh vs. Rabin - Mezcla de navegación BBOARD detectando similitud.",
        "En esta sección, primero discutimos enfoques alternativos para almacenar en caché contenido dinámico y luego examinamos otros usos de primitivas basadas en hash en sistemas distribuidos. 8.1 Almacenamiento en Caché de Contenido Dinámico En la capa de base de datos, varios sistemas han abogado por la caché de nivel intermedio donde partes de la base de datos se replican en el borde o servidor [3, 4, 20].",
        "Estos sistemas almacenan en caché tablas completas en lo que es esencialmente una base de datos replicada o utilizan vistas materializadas de respuestas de consultas anteriores [19].",
        "Requieren una integración estrecha con la base de datos del sistema para garantizar un límite de tiempo en la propagación de actualizaciones.",
        "Estos sistemas suelen estar dirigidos a cargas de trabajo que no requieren una consistencia estricta y pueden tolerar datos obsoletos.",
        "Además, a diferencia de Ganesh, algunas de estas soluciones de almacenamiento en caché de nivel medio [2, 3], sufren de la complejidad de tener que participar en la planificación de consultas y el procesamiento de consultas distribuidas.",
        "Gao et al. [15] proponen utilizar una arquitectura de replicación de objetos distribuidos donde los requisitos de consistencia de las tiendas de datos se adaptan según la aplicación.",
        "Estas soluciones requieren recursos sustanciales de desarrollo y un entendimiento detallado de la aplicación que se está modificando.",
        "Si bien existen sistemas que intentan automatizar la partición y replicación de la base de datos de una aplicación [34], no proporcionan semántica de transacciones completa.",
        "En comparación, Ganesh no debilita ninguna de las semánticas proporcionadas por la base de datos subyacente.",
        "El trabajo reciente en la evaluación de opciones de almacenamiento en caché de borde para sitios web dinámicos [38] ha sugerido que, sin una planificación cuidadosa, el empleo de estrategias complejas de descarga puede perjudicar el rendimiento.",
        "En cambio, el trabajo aboga por una arquitectura en la que todos los niveles, excepto la base de datos, deberían ser trasladados al borde.",
        "Nuestra evaluación de Ganesh ha demostrado que sería beneficioso para estos escenarios.",
        "Para mejorar la escalabilidad de la base de datos, C-JDBC [10], SSS [22] y Ganymed [28] también abogan por el uso de una arquitectura basada en interposición para clusterizar y replicar bases de datos de forma transparente a nivel de middleware.",
        "Los enfoques de estas arquitecturas y Ganesh son complementarios y se beneficiarían mutuamente.",
        "Avanzando hacia la capa de presentación, se ha producido una amplia adopción de la caché basada en fragmentos [14], la cual mejora la utilización de la caché al almacenar por separado diferentes partes de las páginas web generadas.",
        "Si bien el almacenamiento en caché basado en fragmentos funciona en el borde, una propuesta reciente ha propuesto trasladar el ensamblaje de páginas web a los clientes para optimizar la entrega de contenido [31].",
        "Si bien Ganesh no se utiliza en la capa de presentación, los mismos principios se han aplicado en la Detección de Transferencias Duplicadas [25] para aumentar la eficiencia de la caché web, así como para el acceso web a través de enlaces con ancho de banda limitado [33]. 8.2 Sistemas basados en hash En los últimos años han surgido muchos sistemas que explotan técnicas basadas en hash.",
        "En el centro de todos estos sistemas se encuentra la idea de detectar similitudes en los datos sin necesidad de interpretar esos datos.",
        "Esta idea simple pero elegante se basa en el hash criptográfico, como se discutió anteriormente en la Sección 2.",
        "Las aplicaciones exitosas de esta idea abarcan una amplia gama de sistemas de almacenamiento.",
        "Los ejemplos incluyen la copia de seguridad entre pares de archivos informáticos personales [11], el archivado eficiente de datos [29] y la búsqueda de archivos similares [21].",
        "Spring y Wetherall [35] aplican principios similares a nivel de red.",
        "Utilizando cachés sincronizadas en ambos extremos de un enlace de red, los datos duplicados son reemplazados por tokens más pequeños para su transmisión y luego restaurados en el extremo remoto.",
        "Este y otros sistemas basados en hash como los sistemas de archivos CASPER [37] y LBFS [26], y optimizadores de ancho de banda de Capa-2 como Riverbed y Peribit utilizan la huella digital de Rabin [30] para descubrir tramos de similitud en los datos.",
        "Este enfoque es especialmente útil cuando los elementos de datos son modificados en su lugar a través de inserciones, eliminaciones y actualizaciones.",
        "Sin embargo, como se muestra en la Sección 6, el rendimiento de esta técnica puede experimentar una caída dramática en presencia de reordenamiento de datos.",
        "Ganesh en cambio utiliza los límites de fila como divisores para detectar similitudes.",
        "El uso más agresivo de técnicas basadas en hash es por sistemas que utilizan hashes como identificadores principales para objetos en almacenamiento persistente.",
        "Los sistemas de almacenamiento como CFS [12] y PAST [13] que han sido construidos utilizando tablas hash distribuidas entran en esta categoría.",
        "Single Instance Storage [6] y Venti [29] son otros ejemplos de tales sistemas.",
        "Como se discute en la Sección 2.2, el uso de hashes criptográficos para abordar datos persistentes representa un nivel más profundo de confianza en su resistencia a colisiones que la asumida por Ganesh.",
        "Si el tiempo revela deficiencias en el algoritmo hash, el esfuerzo necesario para corregir la falla es mucho mayor.",
        "En Ganesh, simplemente se trata de reemplazar el algoritmo hash. 9.",
        "CONCLUSIÓN El creciente uso de contenido web dinámico generado a partir de bases de datos relacionales aumenta las demandas de ancho de banda de la WAN.",
        "Las soluciones de almacenamiento en caché tradicionales para reducir el ancho de banda y la latencia suelen ser ineficaces para este tipo de contenido.",
        "Este documento muestra que el impacto de los accesos a bases de datos a través de WAN puede reducirse sustancialmente mediante la arquitectura Ganesh sin comprometer la estricta semántica de consistencia de las bases de datos.",
        "La esencia de la arquitectura Ganesh es el uso de la computación en los bordes para reducir la comunicación a través de Internet.",
        "Ganesh es capaz de utilizar hashes criptográficos para detectar similitud con resultados anteriores y enviar recetas compactas de resultados en lugar de resultados completos en la sesión de Sistemas Escalables para Contenido Dinámico 319 de WWW 2007 / Track: Rendimiento y Escalabilidad.",
        "Nuestro diseño utiliza la interposición para lograr una transparencia completa: los clientes, los servidores de aplicaciones y los servidores de bases de datos no son conscientes de la presencia de Ganesh y no requieren ninguna modificación.",
        "Nuestra evaluación experimental confirma que Ganesh, aunque conceptualmente simple, puede ser altamente efectivo en mejorar el rendimiento y el tiempo de respuesta.",
        "Nuestros resultados también confirman que aprovechar la estructura presente en los resultados de la base de datos para detectar similitudes es crucial para esta mejora en el rendimiento.",
        "REFERENCIAS [1] AKELLA, A., SESHAN, S., Y SHAIKH, A.",
        "Una evaluación empírica de los cuellos de botella en Internet de área amplia.",
        "En Proc. 3ª Conferencia ACM SIGCOMM sobre Medición de Internet (Miami Beach, FL, EE. UU., Oct. 2003), pp. 101-114. [2] ALTINEL, M., BORNH ¨OVD, C., KRISHNAMURTHY, S., MOHAN, C., PIRAHESH, H., Y REINWALD, B. Tablas de caché: allanando el camino para una caché de base de datos adaptativa.",
        "En Proc. del 29º VLDB (Berlín, Alemania, 2003), pp. 718-729. [3] ALTINEL, M., LUO, Q., KRISHNAMURTHY, S., MOHAN, C., PIRAHESH, H., LINDSAY, B. G., WOO, H., Y BROWN, L. Dbcache: Caché de base de datos para servidores de aplicaciones web.",
        "En Proc. 2002 ACM SIGMOD (2002), pp. 612-612. [4] AMIRI, K., PARK, S., TEWARI, R., Y PADMANABHAN, S. Dbproxy: una caché de datos dinámica para aplicaciones web.",
        "En Proc.",
        "Conferencia Internacional de Ingeniería de Datos de IEEE (ICDE) (Mar. 2003). [5] BLACK, J. Compare-by-hash: Un análisis razonado.",
        "En Proc. Conferencia Técnica Anual USENIX 2006 (Boston, MA, mayo de 2006), pp. 85-90. [6] BOLOSKY, W. J., CORBIN, S., GOEBEL, D., y DOUCEUR, J. R. Almacenamiento de instancia única en Windows 2000.",
        "En Proc. 4to Simposio de Sistemas Windows de USENIX (Seattle, WA, ago. 2000), pp. 13-24. [7] BREWER, E. A.",
        "Lecciones de servicios a gran escala.",
        "IEEE Internet Computing 5, 4 (2001), 46-55. [8] BRODER, A., GLASSMAN, S., MANASSE, M., AND ZWEIG, G. Agrupamiento sintáctico de la web.",
        "En Proc. 6ta Conferencia Internacional WWW (1997). [9] CECCHET, E., CHANDA, A., ELNIKETY, S., MARGUERITE, J., Y ZWAENEPOEL, W. Comparación de rendimiento de arquitecturas de middleware para generar contenido web dinámico.",
        "En Proc.",
        "Cuarta Conferencia Internacional de Middleware ACM/IFIP/USENIX (Río de Janeiro, Brasil, junio de 2003). [10] CECCHET, E., MARGUERITE, J., Y ZWAENEPOEL, W. C-JDBC: Middleware flexible de agrupación de bases de datos.",
        "En Proc. Conferencia Técnica Anual USENIX 2004 (Boston, MA, junio de 2004). [11] COX, L. P., MURRAY, C. D., Y NOBLE, B. D. Pastiche: Haciendo que la copia de seguridad sea barata y fácil.",
        "En OSDI: Simposio sobre Diseño e Implementación de Sistemas Operativos (2002). [12] DABEK, F., KAASHOEK, M. F., KARGER, D., MORRIS, R., Y STOICA, I. Almacenamiento cooperativo de amplia área con CFS.",
        "En el 18º Simposio ACM sobre Principios de Sistemas Operativos (Banff, Canadá, octubre de 2001). [13] DRUSCHEL, P., Y ROWSTRON, A.",
        "PASADO: Una utilidad de almacenamiento entre pares a gran escala y persistente.",
        "En HotOS VIII (Schloss Elmau, Alemania, mayo de 2001), pp. 75-80. [14] Incluye el lado del borde. http://www.esi.org. [15] GAO, L., DAHLIN, M., NAYATE, A., ZHENG, J., Y IYENGAR, A.",
        "Replicación de datos específica de la aplicación para servicios en el borde.",
        "En WWW 03: Proc.",
        "Duodécima Conferencia Internacional sobre la World Wide Web (2003), pp. 449-460. [16] HEMMINGER, S. Netem - emulando redes reales en el laboratorio.",
        "En Proc. 2005 Linux Conference Australia (Canberra, Australia, Abr. 2005). [17] HENSON, V. Un análisis de compare-by-hash.",
        "En Proc. 9º Taller sobre Temas Candentes en Sistemas Operativos (HotOS IX) (mayo de 2003), pp. 13-18. [18] Benchmarks de Jmob. http://jmob.objectweb.org/. [19] LABRINIDIS, A., Y ROUSSOPOULOS, N. Equilibrando el rendimiento y la frescura de los datos en servidores de bases de datos web.",
        "En Proc. 29ª Conferencia VLDB (Sept. 2003). [20] LARSON, P.-A., GOLDSTEIN, J., Y ZHOU, J. Caché transparente de bases de datos en el nivel intermedio en SQL Server.",
        "En Proc. 2003 ACM SIGMOD (2003), pp. 661-661. [21] MANBER, U.",
        "Encontrar archivos similares en un sistema de archivos grande.",
        "En Proc.",
        "Conferencia Técnica de Invierno de USENIX 1994 (San Francisco, CA, 17-21 de 1994), pp. 1-10. [22] MANJHI, A., AILAMAKI, A., MAGGS, B. M., MOWRY, T. C., OLSTON, C., Y TOMASIC, A.",
        "Escalabilidad y seguridad simultáneas para aplicaciones web intensivas en datos.",
        "En Proc. 2006 ACM SIGMOD (junio de 2006), pp. 241-252. [23] MENEZES, A. J., VANSTONE, S. A., Y OORSCHOT, P. C. V. Manual de Criptografía Aplicada.",
        "CRC Press, 1996. [24] MILLER, R. B. \n\nCRC Press, 1996. [24] MILLER, R. B.",
        "Tiempo de respuesta en transacciones conversacionales entre humanos y computadoras.",
        "En Proc.",
        "Conferencia Conjunta de Computación de Otoño de AFIPS (1968), pp. 267-277. [25] MOGUL, J. C., CHAN, Y. M., Y KELLY, T. Diseño, implementación y evaluación de la detección de transferencias duplicadas en http.",
        "En Proc.",
        "Primer Simposio sobre Diseño e Implementación de Sistemas en Red (San Francisco, CA, Mar. 2004). [26] MUTHITACHAROEN, A., CHEN, B., Y MAZIERES, D. Un sistema de archivos en red de bajo ancho de banda.",
        "En Proc. 18º Simposio de la ACM sobre Principios de Sistemas Operativos (Banff, Canadá, Oct. 2001). [27] PFEIFER, D., Y JAKSCHITSCH, H. Caché basada en métodos en aplicaciones de servidores multinivel.",
        "En Proc.",
        "Quinto Simposio Internacional sobre Objetos y Aplicaciones Distribuidas (Catania, Sicilia, Italia, noviembre de 2003). [28] PLATTNER, C., Y ALONSO, G. Ganymed: Replicación escalable para aplicaciones web transaccionales.",
        "En Proc. 5ta Conferencia Internacional de Middleware ACM/IFIP/USENIX (2004), pp. 155-174. [29] QUINLAN, S., Y DORWARD, S. Venti: Un nuevo enfoque para el almacenamiento de archivos.",
        "En Proc.",
        "Conferencia FAST 2002 sobre Tecnologías de Archivo y Almacenamiento (2002). [30] RABIN, M. Huellas dactilares mediante polinomios aleatorios.",
        "En el Informe Técnico TR-15-81 (1981) del Centro de Investigación en Tecnología Informática de la Universidad de Harvard. [31] RABINOVICH, M., XIAO, Z., DOUGLIS, F., Y KALMANEK, C. Mover los lados de los bordes incluye a los clientes reales en el borde.",
        "En Proc. 4to Simposio USENIX sobre Tecnologías y Sistemas de Internet (Seattle, WA, Mar. 2003). [32] REESE, G. Programación de bases de datos con JDBC y Java, 1ra ed.",
        "OReilly, junio de 1997. [33] RHEA, S., LIANG, K., Y BREWER, E. Caché web basada en valores.",
        "En Proc.",
        "Duodécima Conferencia Internacional de la World Wide Web (mayo de 2003). [34] SIVASUBRAMANIAN, S., ALONSO, G., PIERRE, G., Y VAN STEEN, M. Globedb: Replicación autónoma de datos para aplicaciones web.",
        "En WWW 05: Actas de la 14ª Conferencia Internacional de la World-Wide Web (mayo de 2005). [35] SPRING, N. T., Y WETHERALL, D. Una técnica independiente de protocolo para eliminar el tráfico de red redundante.",
        "En Proc. de ACM SIGCOMM (Ago. 2000). [36] TOLIA, N., HARKES, J., KOZUCH, M., Y SATYANARAYANAN, M. Integrando almacenamiento portátil y distribuido.",
        "En Proc. 3ra Conferencia USENIX sobre Tecnologías de Archivos y Almacenamiento (San Francisco, CA, Mar. 2004). [37] TOLIA, N., KOZUCH, M., SATYANARAYANAN, M., KARP, B., PERRIG, A., Y BRESSOUD, T. Uso oportunista del almacenamiento direccionable por contenido para sistemas de archivos distribuidos.",
        "En Proc. Conferencia Técnica Anual USENIX 2003 (San Antonio, TX, junio de 2003), pp. 127-140. [38] YUAN, C., CHEN, Y., Y ZHANG, Z.",
        "Evaluación de almacenamiento en caché/descarga en el borde para la entrega de contenido dinámico.",
        "En WWW 03: Proc.",
        "Duodécima Conferencia Internacional sobre la World Wide Web (2003), pp. 461-471.",
        "WWW 2007 / Pista: Rendimiento y Escalabilidad Sesión: Sistemas Escalables para Contenido Dinámico 320"
    ],
    "error_count": 3,
    "keys": {
        "relational database": {
            "translated_key": "base de datos relacional",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Consistency-preserving Caching of Dynamic Database Content∗ Niraj Tolia and M. Satyanarayanan Carnegie Mellon University {ntolia,satya}@cs.cmu.edu ABSTRACT With the growing use of dynamic web content generated from relational databases, traditional caching solutions for throughput and latency improvements are ineffective.",
                "We describe a middleware layer called Ganesh that reduces the volume of data transmitted without semantic interpretation of queries or results.",
                "It achieves this reduction through the use of cryptographic hashing to detect similarities with previous results.",
                "These benefits do not require any compromise of the strict consistency semantics provided by the back-end database.",
                "Further, Ganesh does not require modifications to applications, web servers, or database servers, and works with closed-source applications and databases.",
                "Using two benchmarks representative of dynamic web sites, measurements of our prototype show that it can increase end-to-end throughput by as much as twofold for non-data intensive applications and by as much as tenfold for data intensive ones.",
                "Categories and Subject Descriptors C.2.4 [Computer-Communication Networks]: Distributed Systems; H.2.4 [Database Management]: Systems General Terms Design, Performance 1.",
                "INTRODUCTION An increasing fraction of web content is dynamically generated from back-end relational databases.",
                "Even when database content remains unchanged, temporal locality of access cannot be exploited because dynamic content is not cacheable by web browsers or by intermediate caching servers such as Akamai mirrors.",
                "In a multitiered architecture, each web request can stress the WAN link between the web server and the database.",
                "This causes user experience to be highly variable because there is no caching to insulate the client from bursty loads.",
                "Previous attempts in caching dynamic database content have generally weakened transactional semantics [3, 4] or required application modifications [15, 34].",
                "We report on a new solution that takes the form of a databaseagnostic middleware layer called Ganesh.",
                "Ganesh makes no effort to semantically interpret the contents of queries or their results.",
                "Instead, it relies exclusively on cryptographic hashing to detect similarities with previous results.",
                "Hash-based similarity detection has seen increasing use in distributed file systems [26, 36, 37] for improving performance on low-bandwidth networks.",
                "However, these techniques have not been used for relational databases.",
                "Unlike previous approaches that use generic methods to detect similarity, Ganesh exploits the structure of <br>relational database</br> results to yield superior performance improvement.",
                "One faces at least three challenges in applying hash-based similarity detection to back-end databases.",
                "First, previous work in this space has traditionally viewed storage content as uninterpreted bags of bits with no internal structure.",
                "This allows hash-based techniques to operate on long, contiguous runs of data for maximum effectiveness.",
                "In contrast, relational databases have rich internal structure that may not be as amenable to hash-based similarity detection.",
                "Second, relational databases have very tight integrity and consistency constraints that must not be compromised by the use of hash-based techniques.",
                "Third, the source code of commercial databases is typically not available.",
                "This is in contrast to previous work which presumed availability of source code.",
                "Our experiments show that Ganesh, while conceptually simple, can improve performance significantly at bandwidths representative of todays commercial Internet.",
                "On benchmarks modeling multitiered web applications, the throughput improvement was as high as tenfold for data-intensive workloads.",
                "For workloads that were not data-intensive, throughput improvements of up to twofold were observed.",
                "Even when bandwidth was not a constraint, Ganesh had low overhead and did not hurt performance.",
                "Our experiments also confirm that exploiting the structure present in database results is crucial to this performance improvement. 2.",
                "BACKGROUND 2.1 Dynamic Content Generation As the World Wide Web has grown, many web sites have decentralized their data and functionality by pushing them to the edges of the Internet.",
                "Today, eBusiness systems often use a three-tiered architecture consisting of a front-end web server, an application server, and a back-end database server.",
                "Figure 1 illustrates this architecture.",
                "The first two tiers can be replicated close to a concentration of clients at the edge of the Internet.",
                "This improves user experience by lowering end-to-end latency and reducing exposure WWW 2007 / Track: Performance and Scalability Session: Scalable Systems for Dynamic Content 311 Back-End Database Server Front-End Web and Application Servers Figure 1: Multi-Tier Architecture to backbone traffic congestion.",
                "It can also increase the availability and scalability of web services.",
                "Content that is generated dynamically from the back-end database cannot be cached in the first two tiers.",
                "While databases can be easily replicated in a LAN, this is infeasible in a WAN because of the difficult task of simultaneously providing strong consistency, availability, and tolerance to network partitions [7].",
                "As a result, databases tend to be centralized to meet the strong consistency requirements of many eBusiness applications such as banking, finance, and online retailing [38].",
                "Thus, the back-end database is usually located far from many sets of first and second-tier nodes [2].",
                "In the absence of both caching and replication, WAN bandwidth can easily become a limiting factor in the performance and scalability of data-intensive applications. 2.2 Hash-Based Systems Ganeshs focus is on efficient transmission of results by discovering similarities with the results of previous queries.",
                "As SQL queries can generate large results, hash-based techniques lend themselves well to the problem of efficiently transferring these large results across bandwidth constrained links.",
                "The use of hash-based techniques to reduce the volume of data transmitted has emerged as a common theme of many recent storage systems, as discussed in Section 8.2.",
                "These techniques rely on some basic assumptions.",
                "Cryptographic hash functions are assumed to be collision-resistant.",
                "In other words, it is computationally intractable to find two inputs that hash to the same output.",
                "The functions are also assumed to be one-way; that is, finding an input that results in a specific output is computationally infeasible.",
                "Menezes et al. [23] provide more details about these assumptions.",
                "The above assumptions allow hash-based systems to assume that collisions do not occur.",
                "Hence, they are able to treat the hash of a data item as its unique identifier.",
                "A collection of data items effectively becomes content-addressable, allowing a small hash to serve as a codeword for a much larger data item in permanent storage or network transmission.",
                "The assumption that collisions are so rare as to be effectively non-existent has recently come under fire [17].",
                "However, as explained by Black [5], we believe that these issues do not form a concern for Ganesh.",
                "All communication is between trusted parts of the system and an adversary has no way to force Ganesh to accept invalid data.",
                "Further, Ganesh does not depend critically on any specific hash function.",
                "While we currently use SHA-1, replacing it with a different hash function would be simple.",
                "There would be no impact on performance as stronger hash functions (e.g.",
                "SHA256) only add a few extra bytes and the generated hashes are still orders of magnitude smaller than the data items they represent.",
                "No re-hashing of permanent storage is required since Ganesh only uses hashing on volatile data. 3.",
                "DESIGN AND IMPLEMENTATION Ganesh exploits redundancy in the result stream to avoid transmitting result fragments that are already present at the query site.",
                "Redundancy can arise naturally in many different ways.",
                "For example, a query repeated after a certain interval may return a different result because of updates to the database; however, there may be significant commonality between the two results.",
                "As another example, a user who is refining a search may generate a sequence of queries with overlapping results.",
                "When Ganesh detects redundancy, it suppresses transmission of the corresponding result fragments.",
                "Instead, it transmits a much smaller digest of those fragments and lets the query site reconstruct the result through hash lookup in a cache of previous results.",
                "In effect, Ganesh uses computation at the edges to reduce Internet communication.",
                "Our description of Ganesh focuses on four aspects.",
                "We first explain our approach to detecting similarity in query results.",
                "Next, we discuss how the Ganesh architecture is completely invisible to all components of a multi-tier system.",
                "We then describe Ganeshs proxy-based approach and the dataflow for detecting similarity. 3.1 Detecting Similarity One of the key design decisions in Ganesh is how similarity is detected.",
                "There are many potential ways to decompose a result into fragments.",
                "The optimal way is, of course, the one that results in the smallest possible object for transmission for a given querys results.",
                "Finding this optimal decomposition is a difficult problem because of the large space of possibilities and because the optimal choice depends on many factors such as the contents of the querys result, the history of recent results, and the cache management algorithm.",
                "When an object is opaque, the use of Rabin fingerprints [8, 30] to detect common data between two objects has been successfully shown in the past by systems such as LBFS [26] and CASPER [37].",
                "Rabin fingerprinting uses a sliding window over the data to compute a rolling hash.",
                "Assuming that the hash function is uniformly distributed, a chunk boundary is defined whenever the lower order bits of the hash value equal some predetermined value.",
                "The number of lower order bits used defines the average chunk size.",
                "These sub-divided chunks of the object become the unit of comparison for detecting similarity between different objects.",
                "As the locations of boundaries found by using Rabin fingerprints is stochastically determined, they usually fail to align with any structural properties of the underlying data.",
                "The algorithm therefore deals well with in-place updates, insertions and deletions.",
                "However, it performs poorly in the presence of any reordering of data.",
                "Figure 2 shows an example where two results, A and B, consisting of three rows, have the same data but have different sort attributes.",
                "In the extreme case, Rabin fingerprinting might be unable to find any similar data due to the way it detects chunk boundaries.",
                "Fortunately, Ganesh can use domain specific knowledge for more precise boundary detection.",
                "The information we exploit is that a querys result reflects the structure of a <br>relational database</br> where all data is organized as tables and rows.",
                "It is therefore simple to check for similarity with previous results at two granularities: first the entire result, and then individual rows.",
                "The end of a row in a result serves as a natural chunk boundary.",
                "It is important to note that using the tabular structure in results only involves shallow interpretation of the data.",
                "Ganesh does not perform any deeper semantic interpretation such as understanding data types, result schema, or integrity constraints.",
                "Tuning Rabin fingerprinting for a workload can also be difficult.",
                "If the average chunk size is too large, chunks can span multiple result rows.",
                "However, selecting a smaller average chunk size increases the amount of metadata required to the describe the results.",
                "WWW 2007 / Track: Performance and Scalability Session: Scalable Systems for Dynamic Content 312 Figure 2: Rabin Fingerprinting vs. Ganeshs Chunking This, in turn, would decrease the savings obtained via its use.",
                "Rabin fingerprinting also needs two computationally-expensive passes over the data: once to determine chunk boundaries and one again to generate cryptographic hashes for the chunks.",
                "Ganesh only needs a single pass for hash generation as the chunk boundaries are provided by the datas natural structure.",
                "The performance comparison in Section 6 shows that Ganeshs row-based algorithm outperforms Rabin fingerprinting.",
                "Given that previous work has already shown that Rabin fingerprinting performs better than gzip [26], we do not compare Ganesh to compression algorithms in this paper. 3.2 Transparency The key factor influencing our design was the need for Ganesh to be completely transparent to all components of a typical eBusiness system: web servers, application servers, and database servers.",
                "Without this, Ganesh stands little chance of having a significant real-world impact.",
                "Requiring modifications to any of the above components would raise the barrier for entry of Ganesh into an existing system, and thus reduce its chances of adoption.",
                "Preserving transparency is simplified by the fact that Ganesh is purely a performance enhancement, not a functionality or usability enhancement.",
                "We chose agent interposition as the architectural approach to realizing our goal.",
                "This approach relies on the existence of a compact programming interface that is already widely used by target software.",
                "It also relies on a mechanism to easily add new code without disrupting existing module structure.",
                "These conditions are easily met in our context because of the popularity of Java as the programming language for eBusiness systems.",
                "The Java Database Connectivity (JDBC) API [32] allows Java applications to access a wide variety of databases and even other tabular data repositories such as flat files.",
                "Access to these data sources is provided by JDBC drivers that translate between the JDBC API and the database communication mechanism.",
                "Figure 3(a) shows how JDBC is typically used in an application.",
                "As the JDBC interface is standardized, one can substitute one JDBC driver for another without application modifications.",
                "The JDBC driver thus becomes the natural module to exploit for code interposition.",
                "As shown in Figure 3(b), the native JDBC driver is replaced with a Ganesh JDBC driver that presents the same standardized interface.",
                "The Ganesh driver maintains an in-memory cache of result fragments from previous queries and performs reassembly of results.",
                "At the database, we add a new process called the Ganesh proxy.",
                "This proxy, which can be shared by multiple front-end nodes, consists of two parts: code to detect similarity in result fragments and the original native JDBC driver that communicates with the database.",
                "The use of a proxy at the database makes Ganesh database-agnostic and simplifies prototyping and experimentation.",
                "Ganesh is thus able to work with a wide range of databases and applications, requiring no modifications to either. 3.3 Proxy-Based Caching The native JDBC driver shown in Figure 3(a) is a lightweight code component supplied by the database vendor.",
                "Its main funcClient Database Web and Application Server Native JDBC Driver WAN (a) Native Architecture Client Database Ganesh Proxy Native JDBC Driver WAN Web and Application Server Ganesh JDBC Driver (b) Ganeshs Interposition-based Architecture Figure 3: Native vs. Ganesh Architecture tion is to mediate communication between the application and the remote database.",
                "It forwards queries, buffers entire results, and responds to application requests to view parts of results.",
                "The Ganesh JDBC driver shown in Figure 3(b) presents the application with an interface identical to that provided by the native driver.",
                "It provides the ability to reconstruct results from compact hash-based descriptions sent by the proxy.",
                "To perform this reconstruction, the driver maintains an in-memory cache of recentlyreceived results.",
                "This cache is only used as a source of result fragments in reconstructing results.",
                "No attempt is made by the Ganesh driver or proxy to track database updates.",
                "The lack of cache consistency does not hurt correctness as a description of the results is always fetched from the proxy - at worst, there will be no performance benefit from using Ganesh.",
                "Stale data will simply be paged out of the cache over time.",
                "The Ganesh proxy accesses the database via the native JDBC driver, which remains unchanged between Figures 3(a) and (b).",
                "The database is thus completely unaware of the existence of the proxy.",
                "The proxy does not examine any queries received from the Ganesh driver but passes them to the native driver.",
                "Instead, the proxy is responsible for inspecting database output received from the native driver, detecting similar results, and generating hash-based encodings of these results whenever enough similarity is found.",
                "While this architecture does not decrease the load on a database, as mentioned earlier in Section 2.1, it is much easier to replicate databases for scalability in a LAN than in a WAN.",
                "To generate a hash-based encoding, the proxy must be aware of what result fragments are available in the Ganesh drivers cache.",
                "One approach is to be optimistic, and to assume that all result fragments are available.",
                "This will result in the smallest possible initial transmission of a result.",
                "However, in cases where there is little overlap with previous results, the Ganesh driver will have to make many calls to the proxy during reconstruction to fetch missing result fragments.",
                "To avoid this situation, the proxy loosely tracks the state of the Ganesh drivers cache.",
                "Since both components are under our control, it is relatively simple to do this without resorting to gray-box techniques or explicit communication for maintaining cache coherence.",
                "Instead, the proxy simulates the Ganesh drivers cache management algorithm and uses this to maintain a list of hashes for which the Ganesh driver is likely to possess the result fragments.",
                "In case of mistracking, there will be no loss of correctness but there will be extra round-trip delays to fetch the missing fragments.",
                "If the client detects loss of synchronization with the proxy, it can ask the proxy to reset the state shared between them.",
                "Also note that the proxy does not need to keep the result fragments themselves, only their hashes.",
                "This allows the proxy to remain scalable even when it is shared by many front-end nodes.",
                "WWW 2007 / Track: Performance and Scalability Session: Scalable Systems for Dynamic Content 313 Object Output Stream Convert ResultSet Object Input Stream Convert ResultSet All Data Recipe ResultSet All Data ResultSet Network Ganesh Proxy Ganesh JDBC Driver Result Set Recipe Result Set Yes Yes No No GaneshInputStream GaneshOutputStream Figure 4: Dataflow for Result Handling 3.4 Encoding and Decoding Results The Ganesh proxy receives database output as Java objects from the native JDBC driver.",
                "It examines this output to see if a Java object of type ResultSet is present.",
                "The JDBC interface uses this data type to store results of database queries.",
                "If a ResultSet object is found, it is shrunk as discussed below.",
                "All other Java objects are passed through unmodified.",
                "As discussed in Section 3.1, the proxy uses the row boundaries defined in the ResultSet to partition it into fragments consisting of single result rows.",
                "All ResultSet objects are converted into objects of a new type called RecipeResultSet.",
                "We use the term recipe for this compact description of a database result because of its similarity to a file recipe in the CASPER file system [37].",
                "The conversion replaces each result fragment that is likely to be present in the Ganesh drivers cache by a SHA-1 hash of that fragment.",
                "Previously unseen result fragments are retained verbatim.",
                "The proxy also retains hashes for the new result fragments as they will be present in the drivers cache in the future.",
                "Note that the proxy only caches hashes for result fragments and does not cache recipes.",
                "The proxy constructs a RecipeResultSet by checking for similarity at the entire result and then the row level.",
                "If the entire result is predicted to be present in the Ganesh drivers cache, the RecipeResultSet is simply a single hash of the entire result.",
                "Otherwise, it contains hashes for those rows predicted to be present in that cache; all other rows are retained verbatim.",
                "If the proxy estimates an overall space savings, it will transmit the RecipeResultSet.",
                "Otherwise the original ResultSet is transmitted.",
                "The RecipeResultSet objects are transformed back into ResultSet objects by the Ganesh driver.",
                "Figure 4 illustrates ResultSet handling at both ends.",
                "Each SHA-1 hash found in a RecipeResultSet is looked up in the local cache of result fragments.",
                "On a hit, the hash is replaced by the corresponding fragment.",
                "On a miss, the driver contacts the Ganesh proxy to fetch the fragment.",
                "All previously unseen result fragments that were retained verbatim by the proxy are hashed and added to the result cache.",
                "There should be very few misses if the proxy has accurately tracked the Ganesh drivers cache state.",
                "A future optimization would be to batch the fetch of missing fragments.",
                "This would be valuable when there are many small missing fragments in a high-latency WAN.",
                "Once the transformation is complete, the fully reconstructed ResultSet object is passed up to the application. 4.",
                "EXPERIMENTAL VALIDATION Three questions follow from the goals and design of Ganesh: • First, can performance can be improved significantly by exploiting similarity across database results?",
                "Benchmark Dataset Details 500,000 Users, 12,000 Stories BBOARD 2.0 GB 3,298,000 Comments AUCTION 1.3 GB 1,000,000 Users, 34,000 Items Table 1: Benchmark Dataset Details • Second, how important is Ganeshs structural similarity detection relative to Rabin fingerprintings similarity detection? • Third, is the overhead of the proxy-based design acceptable?",
                "Our evaluation answers these question through controlled experiments with the Ganesh prototype.",
                "This section describes the benchmarks used, our evaluation procedure, and the experimental setup.",
                "Results of the experiments are presented in Sections 5, 6, and 7. 4.1 Benchmarks Our evaluation is based on two benchmarks [18] that have been widely used by other researchers to evaluate various aspects of multi-tier [27] and eBusiness architectures [9].",
                "The first benchmark, BBOARD, is modeled after Slashdot, a technology-oriented news site.",
                "The second benchmark, AUCTION, is modeled after eBay, an online auction site.",
                "In both benchmarks, most content is dynamically generated from information stored in a database.",
                "Details of the datasets used can be found in Table 1. 4.1.1 The BBOARD Benchmark The BBOARD benchmark, also known as RUBBoS [18], models Slashdot, a popular technology-oriented web site.",
                "Slashdot aggregates links to news stories and other topics of interest found elsewhere on the web.",
                "The site also serves as a bulletin board by allowing users to comment on the posted stories in a threaded conversation form.",
                "It is not uncommon for a story to gather hundreds of comments in a matter of hours.",
                "The BBOARD benchmark is similar to the site and models the activities of a user, including readonly operations such as browsing the stories of the day, browsing story categories, and viewing comments as well as write operations such as new user registration, adding and moderating comments, and story submission.",
                "The benchmark consists of three different phases: a short warmup phase, a runtime phase representing the main body of the workload, and a short cool-down phase.",
                "In this paper we only report results from the runtime phase.",
                "The warm-up phase is important in establishing dynamic system state, but measurements from that phase are not significant for our evaluation.",
                "The cool-down phase is solely for allowing the benchmark to shut down.",
                "The warm-up, runtime, and cool-down phases are 2, 15, and 2 minutes respectively.",
                "The number of simulated clients were 400, 800, 1200, and 1600.",
                "The benchmark is available in a Java Servlets and PHP version and has different datasets; we evaluated Ganesh using the Java Servlets version and the Expanded dataset.",
                "The BBOARD benchmark defines two different workloads.",
                "The first, the Authoring mix, consists of 70% read-only operations and 30% read-write operations.",
                "The second, the Browsing mix, contains only read-only operations and does not update the database. 4.1.2 The AUCTION Benchmark The AUCTION benchmark, also known as RUBiS [18], models eBay, the online auction site.",
                "The eBay web site is used to buy and sell items via an auction format.",
                "The main activities of a user include browsing, selling, or bidding for items.",
                "Modeling the activities on this site, this benchmark includes read-only activities such as browsing items by category and by region, as well as read-write WWW 2007 / Track: Performance and Scalability Session: Scalable Systems for Dynamic Content 314 NetEm Router Ganesh Proxy Clients Web and Application Server Database Server Figure 5: Experimental Setup activities such as bidding for items, buying and selling items, and leaving feedback.",
                "As with BBOARD, the benchmark consists of three different phases.",
                "The warm-up, runtime, and cool-down phases for this experiment are 1.5, 15, and 1 minutes respectively.",
                "We tested Ganesh with four client configurations where the number of test clients was set to 400, 800, 1200, and 1600.",
                "The benchmark is available in a Enterprise Java Bean (EJB), Java Servlets, and PHP version and has different datasets; we evaluated Ganesh with the Java Servlets version and the Expanded dataset.",
                "The AUCTION benchmark defines two different workloads.",
                "The first, the Bidding mix, consists of 70% read-only operations and 30% read-write operations.",
                "The second, the Browsing mix, contains only read-only operations and does not update the database. 4.2 Experimental Procedure Both benchmarks involve a synthetic workload of clients accessing a web server.",
                "The number of clients emulated is an experimental parameter.",
                "Each emulated client runs an instance of the benchmark in its own thread, using a matrix to transition between different benchmark states.",
                "The matrix defines a stochastic model with probabilities of transitioning between the different states that represent typical user actions.",
                "An example transition is a user logging into the AUCTION system and then deciding on whether to post an item for sale or bid on active auctions.",
                "Each client also models user think time between requests.",
                "The think time is modeled as an exponential distribution with a mean of 7 seconds.",
                "We evaluate Ganesh along two axes: number of clients and WAN bandwidth.",
                "Higher loads are especially useful in understanding Ganeshs performance when the CPU or disk of the database server or proxy is the limiting factor.",
                "A previous study has shown that approximately 50% of the wide-area Internet bottlenecks observed had an available bandwidth under 10 Mb/s [1].",
                "Based on this work, we focus our evaluation on the WAN bandwidth of 5 Mb/s with 66 ms of round-trip latency, representative of severely constrained network paths, and 20 Mb/s with 33 ms of round-trip latency, representative of a moderately constrained network path.",
                "We also report Ganeshs performance at 100 Mb/s with no added round-trip latency.",
                "This bandwidth, representative of an unconstrained network, is especially useful in revealing any potential overhead of Ganesh in situations where WAN bandwidth is not the limiting factor.",
                "For each combination of number of clients and WAN bandwidth, we measured results from the two configurations listed below: • Native: This configuration corresponds to Figure 3(a).",
                "Native avoids Ganeshs overhead in using a proxy and performing Java object serialization. • Ganesh: This configuration corresponds to Figure 3(b).",
                "For a given number of clients and WAN bandwidth, comparing these results to the corresponding Native results gives the performance benefit due to the Ganesh middleware system.",
                "The metric used to quantify the improvement in throughput is the number of client requests that can be serviced per second.",
                "The metric used to quantify Ganeshs overhead is the average response time for a client request.",
                "For all of the experiments, the Ganesh driver used by the application server used a cache size of 100,000 items1 .",
                "The proxy was effective in tracking the Ganesh drivers cache state; for all of our experiments the miss rate on the driver never exceeded 0.7%. 4.3 Experimental Setup The experimental setup used for the benchmarks can be seen in Figure 5.",
                "All machines were 3.2 GHz Pentium 4s (with HyperThreading enabled.)",
                "With the exception of the database server, all machines had 2 GB of SDRAM and ran the Fedora Core Linux distribution.",
                "The database server had 4 GB of SDRAM.",
                "We used Apaches Tomcat as both the application server that hosted the Java Servlets and the web server.",
                "Both benchmarks used Java Servlets to generate the dynamic content.",
                "The database server used the open source MySQL database.",
                "For the native JDBC drivers, we used the Connector/J drivers provided by MySQL.",
                "The application server used Suns Java Virtual Machine as the runtime environment for the Java Servlets.",
                "The sysstat tool was used to monitor the CPU, network, disk, and memory utilization on all machines.",
                "The machines were connected by a switched gigabit Ethernet network.",
                "As shown in Figure 5, the front-end web and application server was separated from the proxy and database server by a NetEm router [16].",
                "This router allowed us to control the bandwidth and latency settings on the network.",
                "The NetEm router is a standard PC with two network cards running the Linux Traffic Control and Network Emulation software.",
                "The bandwidth and latency constraints were only applied to the link between the application server and the database for the native case and between the application server and the proxy for the Ganesh case.",
                "There is no communication between the application server and the database with Ganesh as all data flows through the proxy.",
                "As our focus was on the WAN link between the application server and the database, there were no constraints on the link between the simulated test clients and the web server. 5.",
                "THROUGHPUT AND RESPONSE TIME In this section, we address the first question raised in Section 4: Can performance can be improved significantly by exploiting similarity across database results?",
                "To answer this question, we use results from the BBOARD and AUCTION benchmarks.",
                "We use two metrics to quantify the performance improvement obtainable through the use of Ganesh: throughput, from the perspective of the web server, and average response time, from the perspective of the client.",
                "Throughput is measured in terms of the number of client requests that can be serviced per second. 5.1 BBOARD Results and Analysis 5.1.1 Authoring Mix Figures 6 (a) and (b) present the average number of requests serviced per second and the average response time for these requests as perceived by the clients for BBOARDs Authoring Mix.",
                "As Figure 6 (a) shows, Native easily saturates the 5 Mb/s link.",
                "At 400 clients, the Native solution delivers 29 requests/sec with an average response time of 8.3 seconds.",
                "Natives throughput drops with an increase in test clients as clients timeout due to congestion at the application server.",
                "Usability studies have shown that response times above 10 seconds cause the user to move on to 1 As Java lacks a sizeof() operator, Java caches therefore limit their size based on the number of objects.",
                "The size of cache dumps taken at the end of the experiments never exceeded 212 MB.",
                "WWW 2007 / Track: Performance and Scalability Session: Scalable Systems for Dynamic Content 315 0 50 100 150 200 250 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Test Clients Requests/sec Native Ganesh 0.001 0.01 0.1 1 10 100 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Test Clients Avg.Resp.Time(sec) Native Ganesh Note Logscale (a) Throughput: Authoring Mix (b) Response Time: Authoring Mix 0 50 100 150 200 250 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Test Clients Requests/sec Native Ganesh 0.001 0.01 0.1 1 10 100 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Test Clients Avg.Resp.Time(sec) Native Ganesh Note Logscale (c) Throughput: Browsing Mix (d) Response Time: Browsing Mix Mean of three trials.",
                "The maximum standard deviation for throughput and response time was 9.8% and 11.9% of the corresponding mean.",
                "Figure 6: BBOARD Benchmark - Throughput and Average Response Time other tasks [24].",
                "Based on these numbers, increasing the number of test clients makes the Native system unusable.",
                "Ganesh at 5 Mb/s, however, delivers a twofold improvement with 400 test clients and a fivefold improvement at 1200 clients.",
                "Ganeshs performance drops slightly at 1200 and 1600 clients as the network is saturated.",
                "Compared to Native, Figure 6 (b) shows that Ganeshs response times are substantially lower with sub-second response times at 400 clients.",
                "Figure 6 (a) also shows that for 400 and 800 test clients Ganesh at 5 Mb/s has the same throughput and average response time as Native at 20 Mb/s.",
                "Only at 1200 and 1600 clients does Native at 20 Mb/s deliver higher throughput than Ganesh at 5 Mb/s.",
                "Comparing both Ganesh and Native at 20 Mb/s, we see that Ganesh is no longer bandwidth constrained and delivers up to a twofold improvement over Native at 1600 test clients.",
                "As Ganesh does not saturate the network with higher test client configurations, at 1600 test clients, its average response time is 0.1 seconds rather than Natives 7.7 seconds.",
                "As expected, there are no visible gains from Ganesh at the higher bandwidth of 100 Mb/s where the network is no longer the bottleneck.",
                "Ganesh, however, still tracks Native in terms of throughput. 5.1.2 Browsing Mix Figures 6 (c) and (d) present the average number of requests serviced per second and the average response time for these requests as perceived by the clients for BBOARDs Browsing Mix.",
                "Regardless of the test client configuration, Figure 6 (c) shows that Natives throughput at 5 Mb/s is limited to 10 reqs/sec.",
                "Ganesh at 5 Mb/s with 400 test clients, delivers more than a sixfold increase in throughput.",
                "The improvement increases to over a elevenfold increase at 800 test clients before Ganesh saturates the network.",
                "Further, Figure 6 (d) shows that Natives average response time of 35 seconds at 400 test clients make the system unusable.",
                "These high response times further increase with the addition of test clients.",
                "Even with the 1600 test client configuration Ganesh delivers an acceptable average response time of 8.2 seconds.",
                "Due to the data-intensive nature of the Browsing mix, Ganesh at 5 Mb/s surprisingly performs much better than Native at 20 Mb/s.",
                "Further, as shown in Figure 6 (d), while the average response time for Native at 20 Mb/s is acceptable at 400 test clients, it is unusable with 800 test clients with an average response time of 15.8 seconds.",
                "Like the 5 Mb/s case, this response time increases with the addition of extra test clients.",
                "Ganesh at 20 Mb/s and both Native and Ganesh at 100 Mb/s are not bandwidth limited.",
                "However, performance plateaus out after 1200 test clients due to the database CPU being saturated. 5.1.3 Filter Variant We were surprised by the Native performance from the BBOARD benchmark.",
                "At the bandwidth of 5 Mb/s, Native performance was lower than what we had expected.",
                "It turned out the benchmark code that displays stories read all the comments associated with the particular story from the database and only then did some postprocessing to select the comments to be displayed.",
                "While this is exactly the behavior of SlashCode, the code base behind the Slashdot web site, we decided to modify the benchmark to perform some pre-filtering at the database.",
                "This modified benchmark, named the Filter Variant, models a developer who applies optimizations at the SQL level to transfer less data.",
                "In the interests of brevity, we only briefly summarize the results from the Authoring mix.",
                "For the Authoring mix, at 800 test clients at 5 Mb/s, Figure 7 (a) shows that Natives throughput increase by 85% when compared to the original benchmark while Ganeshs improvement is smaller at 15%.",
                "Natives performance drops above 800 clients as the test clients time out due to high response times.",
                "The most significant gain for Native is seen at 20 Mb/s.",
                "At 1600 test clients, when compared to the original benchmark, Native sees a 73% improvement in throughput and a 77% reduction in average response time.",
                "While WWW 2007 / Track: Performance and Scalability Session: Scalable Systems for Dynamic Content 316 0 50 100 150 200 250 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Test Clients Requests/sec Native Ganesh 0.001 0.01 0.1 1 10 100 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Test Clients Avg.Resp.Time(sec) Native Ganesh Note Logscale (a) Throughput: Authoring Mix (b) Response Time: Authoring Mix Mean of three trials.",
                "The maximum standard deviation for throughput and response time was 7.2% and 11.5% of the corresponding mean.",
                "Figure 7: BBOARD Benchmark - Filter Variant - Throughput and Average Response Time Ganesh sees no improvement when compared to the original, it still processes 19% more requests/sec than Native.",
                "Thus, while the optimizations were more helpful to Native, Ganesh still delivers an improvement in performance. 5.2 AUCTION Results and Analysis 5.2.1 Bidding Mix Figures 8 (a) and (b) present the average number of requests serviced per second and the average response time for these requests as perceived by the clients for AUCTIONs Bidding Mix.",
                "As mentioned earlier, the Bidding mix consists of a mixture of read and write operations.",
                "The AUCTION benchmark is not as data intensive as BBOARD.",
                "Therefore, most of the gains are observed at the lower bandwidth of 5 Mb/s.",
                "Figure 8 (a) shows that the increase in throughput due to Ganesh ranges from 8% at 400 test clients to 18% with 1600 test clients.",
                "As seen in Figure 8 (b), the average response times for Ganesh are significantly lower than Native ranging from a decrease of 84% at 800 test clients to 88% at 1600 test clients.",
                "Figure 8 (a) also shows that with a fourfold increase of bandwidth from 5 Mb/s to 20 Mb/s, Native is no longer bandwidth constrained and there is no performance difference between Ganesh and Native.",
                "With the higher test client configurations, we did observe that the bandwidth used by Ganesh was lower than Native.",
                "Ganesh might still be useful in these non-constrained scenarios if bandwidth is purchased on a metered basis.",
                "Similar results are seen for the 100 Mb/s scenario. 5.2.2 Browsing Mix For AUCTIONs Browsing Mix, Figures 8 (c) and (d) present the average number of requests serviced per second and the average response time for these requests as perceived by the clients.",
                "Again, most of the gains are observed at lower bandwidths.",
                "At 5 Mb/s, Native and Ganesh deliver similar throughput and response times with 400 test clients.",
                "While the throughput for both remains the same at 800 test clients, Figure 8 (d) shows that Ganeshs average response time is 62% lower than Native.",
                "Native saturates the link at 800 clients and adding extra test clients only increases the average response time.",
                "Ganesh, regardless of the test client configuration, is not bandwidth constrained and maintains the same response time.",
                "At 1600 test clients, Figure 8 (c) shows that Ganeshs throughput is almost twice that of Native.",
                "At the higher bandwidths of 20 and 100 Mb/s, neither Ganesh nor Native is bandwidth limited and deliver equivalent throughput and response times.",
                "Benchmark Orig.",
                "Size Ganesh Size Rabin Size SelectSort1 223.6 MB 5.4 MB 219.3 MB SelectSort2 223.6 MB 5.4 MB 223.6 MB Table 2: Similarity Microbenchmarks 6.",
                "STRUCTURAL VS. RABIN SIMILARITY In this section, we address the second question raised in Section 4: How important is Ganeshs structural similarity detection relative to Rabin fingerprinting-based similarity detecting?",
                "To answer this question, we used microbenchmarks and the BBOARD and AUCTION benchmarks.",
                "As Ganesh always performed better than Rabin fingerprinting, we only present a subset of the results here in the interests of brevity. 6.1 Microbenchmarks Two microbenchmarks show an example of the effects of data reordering on Rabin fingerprinting algorithm.",
                "In the first microbenchmark, SelectSort1, a query with a specified sort order selects 223.6 MB of data spread over approximately 280 K rows.",
                "The query is then repeated with a different sort attribute.",
                "While the same number of rows and the same data is returned, the order of rows is different.",
                "In such a scenario, one would expect a large amount of similarity to be detected between both results.",
                "As Table 2 shows, Ganeshs row-based algorithm achieves a 97.6% reduction while the Rabin fingerprinting algorithm, with the average chunk size parameter set to 4 KB, only achieves a 1% reduction.",
                "The reason, as shown earlier in Figure 2, is that with Rabin fingerprinting, the spans of data between two consecutive boundaries usually cross row boundaries.",
                "With the order of the rows changing in the second result and the Rabin fingerprints now spanning different rows, the algorithm is unable to detect significant similarity.",
                "The small gain seen is mostly for those single rows that are large enough to be broken into multiple chunks.",
                "SelectSort2, another micro-benchmark executed the same queries but increased the minimum chunk size of the Rabin fingerprinting algorithm.",
                "As can be seen in Table 2, even the small gain from the previous microbenchmark disappears as the minimum chunk size was greater than the average row size.",
                "While one can partially address these problems by dynamically varying the parameters of the Rabin fingerprinting algorithm, this can be computationally expensive, especially in the presence of changing workloads. 6.2 Application Benchmarks We ran the BBOARD benchmark described in Section 4.1.1 on two versions of Ganesh: the first with Rabin fingerprinting used as WWW 2007 / Track: Performance and Scalability Session: Scalable Systems for Dynamic Content 317 0 50 100 150 200 250 300 350 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Test Clients Requests/sec Native Ganesh 0.001 0.01 0.1 1 10 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Test Clients Avg.Resp.Time(sec) Native Ganesh Note Logscale (a) Throughput: Bidding Mix (b) Response Time: Bidding Mix 0 50 100 150 200 250 300 350 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Test Clients Requests/sec Native Ganesh 0.001 0.01 0.1 1 10 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Test Clients Avg.Resp.Time(sec) Native Ganesh Note Logscale (c) Throughput: Browsing Mix (d) Response Time: Browsing Mix Mean of three trials.",
                "The maximum standard deviation for throughput and response time was 2.2% and 11.8% of the corresponding mean.",
                "Figure 8: AUCTION Benchmark - Throughput and Average Response Time the chunking algorithm and the second with Ganeshs row-based algorithm.",
                "Rabins results for the Browsing Mix are normalized to Ganeshs results and presented in Figure 9.",
                "As Figure 9 (a) shows, at 5 Mb/s, independent of the test client configuration, Rabin significantly underperforms Ganesh.",
                "This happens because of a combination of two reasons.",
                "First, as outlined in Section 3.1, Rabin finds less similarity as it does not exploit the results structural information.",
                "Second, this benchmark contained some queries that generated large results.",
                "In this case, Rabin, with a small average chunk size, generated a large number of objects that evicted other useful data from the cache.",
                "In contrast, Ganesh was able to detect these large rows and correspondingly increase the size of the chunks.",
                "This was confirmed as cache statistics showed that Ganeshs hit ratio was roughly three time that of Rabin.",
                "Throughput measurements at 20 Mb/s were similar with the exception of Rabins performance with 400 test clients.",
                "In this case, Ganesh was not network limited and, in fact, the throughput was the same as 400 clients at 5 Mb/s.",
                "Rabin, however, took advantage of the bandwidth increase from 5 to 20 Mb/s to deliver a slightly better performance.",
                "At 100 Mb/s, Rabins throughput was almost similar to Ganesh as bandwidth was no longer a bottleneck.",
                "The normalized response time, presented in Figure 9 (b), shows similar trends.",
                "At 5 and 20 Mb/s, the addition of test clients decreases the normalized response time as Ganeshs average response time increases faster than Rabins.",
                "However, at no point does Rabin outperform Ganesh.",
                "Note that at 400 and 800 clients at 100 Mb/s, Rabin does have a higher overhead even when it is not bandwidth constrained.",
                "As mentioned in Section 3.1, this is due to the fact that Rabin has to hash each ResultSet twice.",
                "The overhead disappears with 1200 and 1600 clients as the database CPU is saturated and limits the performance of both Ganesh and Rabin. 7.",
                "PROXY OVERHEAD In this section, we address the third question raised in Section 4: Is the overhead of Ganeshs proxy-based design acceptable?",
                "To answer this question, we concentrate on its performance at the higher bandwidths.",
                "Our evaluation in Section 5 showed that Ganesh, when compared to Native, can deliver a substantial throughput improvement at lower bandwidths.",
                "It is only at higher bandwidths that latency, measured by the average response time for a client request, and throughput, measured by the number of client requests that can be serviced per second, overheads would be visible.",
                "Looking at the Authoring mix of the original BBOARD benchmark, there are no visible gains from Ganesh at 100 Mb/s.",
                "Ganesh, however, still tracks Native in terms of throughput.",
                "While the average response time is higher for Ganesh, the absolute difference is in between 0.01 and 0.04 seconds and would be imperceptible to the end-user.",
                "The Browsing mix shows an even smaller difference in average response times.",
                "The results from the filter variant of the BBOARD benchmarks are similar.",
                "Even for the AUCTION benchmark, the difference between Native and Ganeshs response time at 100 Mb/s was never greater than 0.02 seconds.",
                "The only exception to the above results was seen in the filter variant of the BBOARD benchmark where Ganesh at 1600 test clients added 0.85 seconds to the average response time.",
                "Thus, even for much faster networks where the WAN link is not the bottleneck, Ganesh always delivers throughput equivalent to Native.",
                "While some extra latency is added by the proxy-based design, it is usually imperceptible. 8.",
                "RELATED WORK To the best of our knowledge, Ganesh is the first system that combines the use of hash-based techniques with caching of database results to improve throughput and response times for applications with dynamic content.",
                "We also believe that it is also the first system to demonstrate the benefits of using structural information for WWW 2007 / Track: Performance and Scalability Session: Scalable Systems for Dynamic Content 318 0.0 0.2 0.4 0.6 0.8 1.0 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Test Clients Norm.Throughput 31.8 3.8 2.8 2.3 23.8 32.8 5.8 3.6 1.8 2.1 1.1 1.0 0 5 10 15 20 25 30 35 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Test Clients Norm.ResponseTime (a) Normalized Throughput: Higher is better (b) Normalized Response Time: Higher is worse For throughput, a normalized result greater than 1 implies that Rabin is better, For response time, a normalized result greater than 1 implies that Ganesh is better.",
                "Mean of three trials.",
                "The maximum standard deviation for throughput and response time was 9.1% and 13.9% of the corresponding mean.",
                "Figure 9: Normalized Comparison of Ganesh vs. Rabin - BBOARD Browsing Mix detecting similarity.",
                "In this section, we first discuss alternative approaches to caching dynamic content and then examine other uses of hash-based primitives in distributed systems. 8.1 Caching Dynamic Content At the database layer, a number of systems have advocated middletier caching where parts of the database are replicated at the edge or server [3, 4, 20].",
                "These systems either cache entire tables in what is essentially a replicated database or use materialized views from previous query replies [19].",
                "They require tight integration with the back-end database to ensure a time bound on the propagation of updates.",
                "These systems are also usually targeted towards workloads that do not require strict consistency and can tolerate stale data.",
                "Further, unlike Ganesh, some of these mid-tier caching solutions [2, 3], suffer from the complexity of having to participate in query planing and distributed query processing.",
                "Gao et al. [15] propose using a distributed object replication architecture where the data stores consistency requirements are adapted on a per-application basis.",
                "These solutions require substantial developer resources and detailed understanding of the application being modified.",
                "While systems that attempt to automate the partitioning and replication of an applications database exist [34], they do not provide full transaction semantics.",
                "In comparison, Ganesh does not weaken any of the semantics provided by the underlying database.",
                "Recent work in the evaluation of edge caching options for dynamic web sites [38] has suggested that, without careful planning, employing complex offloading strategies can hurt performance.",
                "Instead, the work advocates for an architecture in which all tiers except the database should be offloaded to the edge.",
                "Our evaluation of Ganesh has shown that it would benefit these scenarios.",
                "To improve database scalability, C-JDBC [10], SSS [22], and Ganymed [28] also advocate the use of an interposition-based architecture to transparently cluster and replicate databases at the middleware level.",
                "The approaches of these architectures and Ganesh are complementary and they would benefit each other.",
                "Moving up to the presentation layer, there has been widespread adoption of fragment-based caching [14], which improves cache utilization by separately caching different parts of generated web pages.",
                "While fragment-based caching works at the edge, a recent proposal has proposed moving web page assembly to the clients to optimize content delivery [31].",
                "While Ganesh is not used at the presentation layer, the same principles have been applied in Duplicate Transfer Detection [25] to increase web cache efficiency as well as for web access across bandwidth limited links [33]. 8.2 Hash-based Systems The past few years have seen the emergence of many systems that exploit hash-based techniques.",
                "At the heart of all these systems is the idea of detecting similarity in data without requiring interpretation of that data.",
                "This simple yet elegant idea relies on cryptographic hashing, as discussed earlier in Section 2.",
                "Successful applications of this idea span a wide range of storage systems.",
                "Examples include peer-to-peer backup of personal computing files [11], storage-efficient archiving of data [29], and finding similar files [21].",
                "Spring and Wetherall [35] apply similar principles at the network level.",
                "Using synchronized caches at both ends of a network link, duplicated data is replaced by smaller tokens for transmission and then restored at the remote end.",
                "This and other hash-based systems such as the CASPER [37] and LBFS [26] filesystems, and Layer-2 bandwidth optimizers such as Riverbed and Peribit use Rabin fingerprinting [30] to discover spans of commonality in data.",
                "This approach is especially useful when data items are modified in-place through insertions, deletions, and updates.",
                "However, as Section 6 shows, the performance of this technique can show a dramatic drop in the presence of data reordering.",
                "Ganesh instead uses row boundaries as dividers for detecting similarity.",
                "The most aggressive use of hash-based techniques is by systems that use hashes as the primary identifiers for objects in persistent storage.",
                "Storage systems such as CFS [12] and PAST [13] that have been built using distributed hash tables fall into this category.",
                "Single Instance Storage [6] and Venti [29] are other examples of such systems.",
                "As discussed in Section 2.2, the use of cryptographic hashes for addressing persistent data represents a deeper level of faith in their collision-resistance than that assumed by Ganesh.",
                "If time reveals shortcomings in the hash algorithm, the effort involved in correcting the flaw is much greater.",
                "In Ganesh, it is merely a matter of replacing the hash algorithm. 9.",
                "CONCLUSION The growing use of dynamic web content generated from relational databases places increased demands on WAN bandwidth.",
                "Traditional caching solutions for bandwidth and latency reduction are often ineffective for such content.",
                "This paper shows that the impact of WAN accesses to databases can be substantially reduced through the Ganesh architecture without any compromise of the databases strict consistency semantics.",
                "The essence of the Ganesh architecture is the use of computation at the edges to reduce communication through the Internet.",
                "Ganesh is able to use cryptographic hashes to detect similarity with previous results and send WWW 2007 / Track: Performance and Scalability Session: Scalable Systems for Dynamic Content 319 compact recipes of results rather than full results.",
                "Our design uses interposition to achieve complete transparency: clients, application servers, and database servers are all unaware of Ganeshs presence and require no modification.",
                "Our experimental evaluation confirms that Ganesh, while conceptually simple, can be highly effective in improving throughput and response time.",
                "Our results also confirm that exploiting the structure present in database results to detect similarity is crucial to this performance improvement. 10.",
                "REFERENCES [1] AKELLA, A., SESHAN, S., AND SHAIKH, A.",
                "An empirical evaluation of wide-area internet bottlenecks.",
                "In Proc. 3rd ACM SIGCOMM Conference on Internet Measurement (Miami Beach, FL, USA, Oct. 2003), pp. 101-114. [2] ALTINEL, M., BORNH ¨OVD, C., KRISHNAMURTHY, S., MOHAN, C., PIRAHESH, H., AND REINWALD, B. Cache tables: Paving the way for an adaptive database cache.",
                "In Proc. of 29th VLDB (Berlin, Germany, 2003), pp. 718-729. [3] ALTINEL, M., LUO, Q., KRISHNAMURTHY, S., MOHAN, C., PIRAHESH, H., LINDSAY, B. G., WOO, H., AND BROWN, L. Dbcache: Database caching for web application servers.",
                "In Proc. 2002 ACM SIGMOD (2002), pp. 612-612. [4] AMIRI, K., PARK, S., TEWARI, R., AND PADMANABHAN, S. Dbproxy: A dynamic data cache for web applications.",
                "In Proc.",
                "IEEE International Conference on Data Engineering (ICDE) (Mar. 2003). [5] BLACK, J. Compare-by-hash: A reasoned analysis.",
                "In Proc. 2006 USENIX Annual Technical Conference (Boston, MA, May 2006), pp. 85-90. [6] BOLOSKY, W. J., CORBIN, S., GOEBEL, D., , AND DOUCEUR, J. R. Single instance storage in windows 2000.",
                "In Proc. 4th USENIX Windows Systems Symposium (Seattle, WA, Aug. 2000), pp. 13-24. [7] BREWER, E. A.",
                "Lessons from giant-scale services.",
                "IEEE Internet Computing 5, 4 (2001), 46-55. [8] BRODER, A., GLASSMAN, S., MANASSE, M., AND ZWEIG, G. Syntactic clustering of the web.",
                "In Proc. 6th International WWW Conference (1997). [9] CECCHET, E., CHANDA, A., ELNIKETY, S., MARGUERITE, J., AND ZWAENEPOEL, W. Performance comparison of middleware architectures for generating dynamic web content.",
                "In Proc.",
                "Fourth ACM/IFIP/USENIX International Middleware Conference (Rio de Janeiro, Brazil, June 2003). [10] CECCHET, E., MARGUERITE, J., AND ZWAENEPOEL, W. C-JDBC: Flexible database clustering middleware.",
                "In Proc. 2004 USENIX Annual Technical Conference (Boston, MA, June 2004). [11] COX, L. P., MURRAY, C. D., AND NOBLE, B. D. Pastiche: Making backup cheap and easy.",
                "In OSDI: Symposium on Operating Systems Design and Implementation (2002). [12] DABEK, F., KAASHOEK, M. F., KARGER, D., MORRIS, R., AND STOICA, I. Wide-area cooperative storage with CFS.",
                "In 18th ACM Symposium on Operating Systems Principles (Banff, Canada, Oct. 2001). [13] DRUSCHEL, P., AND ROWSTRON, A.",
                "PAST: A large-scale, persistent peer-to-peer storage utility.",
                "In HotOS VIII (Schloss Elmau, Germany, May 2001), pp. 75-80. [14] Edge side includes. http://www.esi.org. [15] GAO, L., DAHLIN, M., NAYATE, A., ZHENG, J., AND IYENGAR, A.",
                "Application specific data replication for edge services.",
                "In WWW 03: Proc.",
                "Twelfth International Conference on World Wide Web (2003), pp. 449-460. [16] HEMMINGER, S. Netem - emulating real networks in the lab.",
                "In Proc. 2005 Linux Conference Australia (Canberra, Australia, Apr. 2005). [17] HENSON, V. An analysis of compare-by-hash.",
                "In Proc. 9th Workshop on Hot Topics in Operating Systems (HotOS IX) (May 2003), pp. 13-18. [18] Jmob benchmarks. http://jmob.objectweb.org/. [19] LABRINIDIS, A., AND ROUSSOPOULOS, N. Balancing performance and data freshness in web database servers.",
                "In Proc. 29th VLDB Conference (Sept. 2003). [20] LARSON, P.-A., GOLDSTEIN, J., AND ZHOU, J. Transparent mid-tier database caching in sql server.",
                "In Proc. 2003 ACM SIGMOD (2003), pp. 661-661. [21] MANBER, U.",
                "Finding similar files in a large file system.",
                "In Proc.",
                "USENIX Winter 1994 Technical Conference (San Fransisco, CA, 17-21 1994), pp. 1-10. [22] MANJHI, A., AILAMAKI, A., MAGGS, B. M., MOWRY, T. C., OLSTON, C., AND TOMASIC, A.",
                "Simultaneous scalability and security for data-intensive web applications.",
                "In Proc. 2006 ACM SIGMOD (June 2006), pp. 241-252. [23] MENEZES, A. J., VANSTONE, S. A., AND OORSCHOT, P. C. V. Handbook of Applied Cryptography.",
                "CRC Press, 1996. [24] MILLER, R. B.",
                "Response time in man-computer conversational transactions.",
                "In Proc.",
                "AFIPS Fall Joint Computer Conference (1968), pp. 267-277. [25] MOGUL, J. C., CHAN, Y. M., AND KELLY, T. Design, implementation, and evaluation of duplicate transfer detection in http.",
                "In Proc.",
                "First Symposium on Networked Systems Design and Implementation (San Francisco, CA, Mar. 2004). [26] MUTHITACHAROEN, A., CHEN, B., AND MAZIERES, D. A low-bandwidth network file system.",
                "In Proc. 18th ACM Symposium on Operating Systems Principles (Banff, Canada, Oct. 2001). [27] PFEIFER, D., AND JAKSCHITSCH, H. Method-based caching in multi-tiered server applications.",
                "In Proc.",
                "Fifth International Symposium on Distributed Objects and Applications (Catania, Sicily, Italy, Nov. 2003). [28] PLATTNER, C., AND ALONSO, G. Ganymed: Scalable replication for transactional web applications.",
                "In Proc. 5th ACM/IFIP/USENIX International Conference on Middleware (2004), pp. 155-174. [29] QUINLAN, S., AND DORWARD, S. Venti: A new approach to archival storage.",
                "In Proc.",
                "FAST 2002 Conference on File and Storage Technologies (2002). [30] RABIN, M. Fingerprinting by random polynomials.",
                "In Harvard University Center for Research in Computing Technology Technical Report TR-15-81 (1981). [31] RABINOVICH, M., XIAO, Z., DOUGLIS, F., AND KALMANEK, C. Moving edge side includes to the real edge - the clients.",
                "In Proc. 4th USENIX Symposium on Internet Technologies and Systems (Seattle, WA, Mar. 2003). [32] REESE, G. Database Programming with JDBC and Java, 1st ed.",
                "OReilly, June 1997. [33] RHEA, S., LIANG, K., AND BREWER, E. Value-based web caching.",
                "In Proc.",
                "Twelfth International World Wide Web Conference (May 2003). [34] SIVASUBRAMANIAN, S., ALONSO, G., PIERRE, G., AND VAN STEEN, M. Globedb: Autonomic data replication for web applications.",
                "In WWW 05: Proc. 14th International World-Wide Web conference (May 2005). [35] SPRING, N. T., AND WETHERALL, D. A protocol-independent technique for eliminating redundant network traffic.",
                "In Proc. of ACM SIGCOMM (Aug. 2000). [36] TOLIA, N., HARKES, J., KOZUCH, M., AND SATYANARAYANAN, M. Integrating portable and distributed storage.",
                "In Proc. 3rd USENIX Conference on File and Storage Technologies (San Francisco, CA, Mar. 2004). [37] TOLIA, N., KOZUCH, M., SATYANARAYANAN, M., KARP, B., PERRIG, A., AND BRESSOUD, T. Opportunistic use of content addressable storage for distributed file systems.",
                "In Proc. 2003 USENIX Annual Technical Conference (San Antonio, TX, June 2003), pp. 127-140. [38] YUAN, C., CHEN, Y., AND ZHANG, Z.",
                "Evaluation of edge caching/offloading for dynamic content delivery.",
                "In WWW 03: Proc.",
                "Twelfth International Conference on World Wide Web (2003), pp. 461-471.",
                "WWW 2007 / Track: Performance and Scalability Session: Scalable Systems for Dynamic Content 320"
            ],
            "original_annotated_samples": [
                "Unlike previous approaches that use generic methods to detect similarity, Ganesh exploits the structure of <br>relational database</br> results to yield superior performance improvement.",
                "The information we exploit is that a querys result reflects the structure of a <br>relational database</br> where all data is organized as tables and rows."
            ],
            "translated_annotated_samples": [
                "A diferencia de enfoques anteriores que utilizan métodos genéricos para detectar similitud, Ganesh explota la estructura de los resultados de la <br>base de datos relacional</br> para lograr una mejora superior en el rendimiento.",
                "La información que explotamos es que el resultado de una consulta refleja la estructura de una <br>base de datos relacional</br> donde todos los datos están organizados en tablas y filas."
            ],
            "translated_text": "Conservación de la consistencia en el almacenamiento en caché de contenido dinámico de bases de datos∗ Niraj Tolia y M. Satyanarayanan Universidad Carnegie Mellon {ntolia,satya}@cs.cmu.edu RESUMEN Con el creciente uso de contenido web dinámico generado a partir de bases de datos relacionales, las soluciones de almacenamiento en caché tradicionales para mejorar el rendimiento y la latencia son ineficaces. Describimos una capa de middleware llamada Ganesh que reduce el volumen de datos transmitidos sin interpretación semántica de consultas o resultados. Se logra esta reducción mediante el uso de hash criptográficos para detectar similitudes con resultados anteriores. Estos beneficios no requieren ningún compromiso con la semántica de consistencia estricta proporcionada por la base de datos del servidor. Además, Ganesh no requiere modificaciones en aplicaciones, servidores web o servidores de bases de datos, y funciona con aplicaciones y bases de datos de código cerrado. Usando dos puntos de referencia representativos de sitios web dinámicos, las mediciones de nuestro prototipo muestran que puede aumentar el rendimiento de extremo a extremo hasta en un factor de dos para aplicaciones no intensivas en datos y hasta en un factor de diez para las intensivas en datos. Categorías y Descriptores de Asignaturas C.2.4 [Redes de Computadoras-Comunicación]: Sistemas Distribuidos; H.2.4 [Gestión de Bases de Datos]: Términos Generales de Sistemas de Diseño, Rendimiento 1. INTRODUCCIÓN Una fracción creciente del contenido web se genera dinámicamente a partir de bases de datos relacionales en el backend. Incluso cuando el contenido de la base de datos permanece sin cambios, la localidad temporal de acceso no puede ser explotada porque el contenido dinámico no es almacenable en caché por los navegadores web o por servidores de almacenamiento en caché intermedios como los espejos de Akamai. En una arquitectura multinivel, cada solicitud web puede tensionar el enlace WAN entre el servidor web y la base de datos. Esto provoca que la experiencia del usuario sea altamente variable porque no hay almacenamiento en caché para aislar al cliente de cargas repentinas. Los intentos previos de almacenar en caché contenido dinámico de bases de datos generalmente han debilitado la semántica transaccional [3, 4] o han requerido modificaciones en la aplicación [15, 34]. Informamos sobre una nueva solución que toma la forma de una capa intermedia de middleware independiente de la base de datos llamada Ganesh. Ganesh no hace ningún esfuerzo por interpretar semánticamente el contenido de las consultas o sus resultados. En cambio, se basa exclusivamente en el hash criptográfico para detectar similitudes con resultados anteriores. La detección de similitud basada en hash ha sido cada vez más utilizada en sistemas de archivos distribuidos [26, 36, 37] para mejorar el rendimiento en redes de baja capacidad de ancho de banda. Sin embargo, estas técnicas no se han utilizado para bases de datos relacionales. A diferencia de enfoques anteriores que utilizan métodos genéricos para detectar similitud, Ganesh explota la estructura de los resultados de la <br>base de datos relacional</br> para lograr una mejora superior en el rendimiento. Uno se enfrenta al menos a tres desafíos al aplicar la detección de similitud basada en hash a las bases de datos de back-end. Primero, el trabajo previo en este ámbito ha considerado tradicionalmente el contenido de almacenamiento como bolsas de bits no interpretadas y sin estructura interna. Esto permite que las técnicas basadas en hash operen en largas y contiguas secuencias de datos para lograr la máxima efectividad. Por el contrario, las bases de datos relacionales tienen una estructura interna compleja que puede no ser tan propicia para la detección de similitudes basada en hash. Segundo, las bases de datos relacionales tienen restricciones de integridad y consistencia muy estrictas que no deben comprometerse por el uso de técnicas basadas en hash. Tercero, el código fuente de las bases de datos comerciales generalmente no está disponible. Esto contrasta con trabajos anteriores que presumían la disponibilidad del código fuente. Nuestros experimentos muestran que Ganesh, aunque conceptualmente simple, puede mejorar significativamente el rendimiento en anchos de banda representativos del Internet comercial actual. En los modelos de referencia de aplicaciones web multinivel, la mejora en el rendimiento fue de hasta diez veces para cargas de trabajo intensivas en datos. Para cargas de trabajo que no eran intensivas en datos, se observaron mejoras en el rendimiento de hasta el doble. Incluso cuando el ancho de banda no era una limitación, Ganesh tenía un bajo sobrecosto y no afectaba el rendimiento. Nuestros experimentos también confirman que aprovechar la estructura presente en los resultados de la base de datos es crucial para esta mejora en el rendimiento. Antecedentes 2.1 Generación de Contenido Dinámico A medida que la World Wide Web ha crecido, muchos sitios web han descentralizado sus datos y funcionalidades al llevarlos a los extremos de Internet. Hoy en día, los sistemas de comercio electrónico a menudo utilizan una arquitectura de tres niveles que consta de un servidor web de front-end, un servidor de aplicaciones y un servidor de base de datos de back-end. La Figura 1 ilustra esta arquitectura. Los dos primeros niveles se pueden replicar cerca de una concentración de clientes en el borde de Internet. Esto mejora la experiencia del usuario al reducir la latencia de extremo a extremo y disminuir la exposición al congestionamiento del tráfico de la columna vertebral. También puede aumentar la disponibilidad y escalabilidad de los servicios web. El contenido que se genera dinámicamente desde la base de datos del servidor no puede ser almacenado en caché en los dos primeros niveles. Si bien las bases de datos pueden replicarse fácilmente en una LAN, esto es inviable en una WAN debido a la difícil tarea de proporcionar simultáneamente una consistencia sólida, disponibilidad y tolerancia a particiones de red [7]. Como resultado, las bases de datos tienden a ser centralizadas para cumplir con los fuertes requisitos de consistencia de muchas aplicaciones de comercio electrónico como la banca, las finanzas y la venta al por menor en línea [38]. Por lo tanto, la base de datos del back-end suele estar ubicada lejos de muchos conjuntos de nodos de primer y segundo nivel [2]. En ausencia de almacenamiento en caché y replicación, el ancho de banda de la WAN puede convertirse fácilmente en un factor limitante en el rendimiento y la escalabilidad de aplicaciones intensivas en datos. El enfoque de Ganesh en los sistemas basados en hash es la transmisión eficiente de resultados al descubrir similitudes con los resultados de consultas anteriores. Dado que las consultas SQL pueden generar resultados grandes, las técnicas basadas en hash se prestan bien al problema de transferir eficientemente estos grandes resultados a través de enlaces con ancho de banda limitado. El uso de técnicas basadas en hash para reducir el volumen de datos transmitidos ha surgido como un tema común en muchos sistemas de almacenamiento recientes, como se discute en la Sección 8.2. Estas técnicas se basan en algunas suposiciones básicas. Se asume que las funciones hash criptográficas son resistentes a colisiones. En otras palabras, es computacionalmente intratable encontrar dos entradas que se hash a la misma salida. Las funciones también se asumen como unidireccionales; es decir, encontrar una entrada que resulte en una salida específica es computacionalmente inviable. Menezes et al. [23] proporcionan más detalles sobre estas suposiciones. Las suposiciones anteriores permiten a los sistemas basados en hash asumir que no se producen colisiones. Por lo tanto, pueden tratar el hash de un elemento de datos como su identificador único. Una colección de elementos de datos se convierte efectivamente en direccionable por contenido, permitiendo que un hash pequeño funcione como una palabra de código para un elemento de datos mucho más grande en almacenamiento permanente o transmisión en red. La suposición de que las colisiones son tan raras que prácticamente no existen ha sido cuestionada recientemente [17]. Sin embargo, como explicó Black [5], creemos que estos problemas no son una preocupación para Ganesh. Toda comunicación es entre partes confiables del sistema y un adversario no tiene forma de obligar a Ganesh a aceptar datos inválidos. Además, Ganesh no depende críticamente de ninguna función hash específica. Si bien actualmente usamos SHA-1, reemplazarlo con una función hash diferente sería sencillo. No habría impacto en el rendimiento con funciones hash más fuertes (por ejemplo, SHA256) solo añade unos pocos bytes adicionales y los hashes generados siguen siendo órdenes de magnitud más pequeños que los elementos de datos que representan. No es necesario volver a almacenar permanentemente ya que Ganesh solo utiliza el hash en datos volátiles. 3. DISEÑO E IMPLEMENTACIÓN Ganesh explota la redundancia en el flujo de resultados para evitar transmitir fragmentos de resultados que ya están presentes en el sitio de la consulta. La redundancia puede surgir de forma natural de muchas maneras diferentes. Por ejemplo, una consulta repetida después de un cierto intervalo puede devolver un resultado diferente debido a actualizaciones en la base de datos; sin embargo, puede haber una significativa similitud entre los dos resultados. Como otro ejemplo, un usuario que está refinando una búsqueda puede generar una secuencia de consultas con resultados superpuestos. Cuando Ganesh detecta redundancia, suprime la transmisión de los fragmentos de resultado correspondientes. En cambio, transmite un resumen mucho más pequeño de esos fragmentos y permite que el sitio de consulta reconstruya el resultado a través de la búsqueda de hash en una caché de resultados anteriores. De hecho, Ganesh utiliza la computación en los bordes para reducir la comunicación por Internet. Nuestra descripción de Ganesh se centra en cuatro aspectos. Primero explicamos nuestro enfoque para detectar similitud en los resultados de la consulta. A continuación, discutimos cómo la arquitectura Ganesh es completamente invisible para todos los componentes de un sistema de múltiples niveles. Luego describimos el enfoque basado en proxy de Ganesh y el flujo de datos para detectar similitudes. 3.1 Detectar similitud Una de las decisiones clave de diseño en Ganesh es cómo se detecta la similitud. Hay muchas formas potenciales de descomponer un resultado en fragmentos.  I the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the thees I,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,, Encontrar esta descomposición óptima es un problema difícil debido al amplio espacio de posibilidades y porque la elección óptima depende de muchos factores, como el contenido del resultado de las consultas, el historial de resultados recientes y el algoritmo de gestión de caché. Cuando un objeto es opaco, el uso de huellas digitales de Rabin [8, 30] para detectar datos comunes entre dos objetos ha sido demostrado con éxito en el pasado por sistemas como LBFS [26] y CASPER [37]. El fingerprinting de Rabin utiliza una ventana deslizante sobre los datos para calcular un hash rodante. Suponiendo que la función hash está distribuida uniformemente, un límite de fragmento se define cuando los bits de orden inferior del valor hash son iguales a algún valor predeterminado. El número de bits de orden inferior utilizados define el tamaño promedio del fragmento. Estos fragmentos subdivididos del objeto se convierten en la unidad de comparación para detectar similitudes entre diferentes objetos. Dado que las ubicaciones de los límites encontrados mediante el uso de las huellas de Rabin están determinadas de manera estocástica, generalmente no logran alinearse con ninguna propiedad estructural de los datos subyacentes. Por lo tanto, el algoritmo maneja bien las actualizaciones en su lugar, inserciones y eliminaciones. Sin embargo, tiene un rendimiento deficiente en presencia de cualquier reordenamiento de datos. La Figura 2 muestra un ejemplo donde dos resultados, A y B, que constan de tres filas, tienen los mismos datos pero diferentes atributos de ordenamiento. En el caso extremo, la huella digital de Rabin podría no ser capaz de encontrar datos similares debido a la forma en que detecta los límites de los fragmentos. Afortunadamente, Ganesh puede utilizar conocimientos específicos del dominio para una detección de límites más precisa. La información que explotamos es que el resultado de una consulta refleja la estructura de una <br>base de datos relacional</br> donde todos los datos están organizados en tablas y filas. Por lo tanto, es sencillo verificar la similitud con resultados anteriores en dos niveles de granularidad: primero el resultado completo y luego las filas individuales. El final de una fila en un resultado sirve como un límite natural de fragmento. Es importante tener en cuenta que el uso de la estructura tabular en los resultados solo implica una interpretación superficial de los datos. Ganesh no realiza ninguna interpretación semántica más profunda, como comprender tipos de datos, esquemas de resultados o restricciones de integridad. Ajustar la huella digital de Rabin para una carga de trabajo también puede ser difícil. Si el tamaño promedio de los fragmentos es demasiado grande, los fragmentos pueden abarcar varias filas de resultados. Sin embargo, seleccionar un tamaño de fragmento promedio más pequeño aumenta la cantidad de metadatos necesarios para describir los resultados. Esto, a su vez, disminuiría los ahorros obtenidos mediante su uso. El fingerprinting de Rabin también requiere dos pasadas computacionalmente costosas sobre los datos: una vez para determinar los límites de los fragmentos y otra vez para generar hashes criptográficos para los fragmentos. Ganesh solo necesita un único pase para la generación de hash, ya que los límites de los fragmentos son proporcionados por la estructura natural de los datos. La comparación de rendimiento en la Sección 6 muestra que el algoritmo basado en filas de Ganesh supera al fingerprinting de Rabin. Dado que trabajos anteriores ya han demostrado que la huella digital de Rabin funciona mejor que gzip [26], no comparamos a Ganesh con algoritmos de compresión en este artículo. 3.2 Transparencia El factor clave que influyó en nuestro diseño fue la necesidad de que Ganesh fuera completamente transparente para todos los componentes de un sistema típico de comercio electrónico: servidores web, servidores de aplicaciones y servidores de bases de datos. Sin esto, Ganesh tiene pocas posibilidades de tener un impacto significativo en el mundo real. Requerir modificaciones en cualquiera de los componentes mencionados aumentaría la barrera de entrada de Ganesh en un sistema existente, y por lo tanto reduciría sus posibilidades de adopción. Preservar la transparencia se simplifica por el hecho de que Ganesh es simplemente una mejora de rendimiento, no una mejora de funcionalidad o usabilidad. Elegimos la interposición de agentes como enfoque arquitectónico para lograr nuestro objetivo. Este enfoque se basa en la existencia de una interfaz de programación compacta que ya es ampliamente utilizada por el software objetivo. También se basa en un mecanismo para agregar fácilmente nuevo código sin interrumpir la estructura de módulos existente. Estas condiciones se cumplen fácilmente en nuestro contexto debido a la popularidad de Java como el lenguaje de programación para sistemas de comercio electrónico. La API de Conectividad de Base de Datos de Java (JDBC) [32] permite a las aplicaciones de Java acceder a una amplia variedad de bases de datos e incluso a otros repositorios de datos tabulares como archivos planos. El acceso a estas fuentes de datos es proporcionado por controladores JDBC que traducen entre la API JDBC y el mecanismo de comunicación de la base de datos. La figura 3(a) muestra cómo se utiliza típicamente JDBC en una aplicación. Dado que la interfaz JDBC está estandarizada, se puede sustituir un controlador JDBC por otro sin necesidad de de modificar la aplicación. El controlador JDBC se convierte así en el módulo natural para aprovechar la interposición de código. Como se muestra en la Figura 3(b), el controlador JDBC nativo es reemplazado por un controlador JDBC Ganesh que presenta la misma interfaz estandarizada. El controlador Ganesh mantiene una caché en memoria de fragmentos de resultados de consultas anteriores y realiza el reensamblaje de resultados. En la base de datos, agregamos un nuevo proceso llamado el proxy Ganesh. Este proxy, que puede ser compartido por múltiples nodos front-end, consta de dos partes: código para detectar similitud en fragmentos de resultados y el controlador JDBC nativo original que se comunica con la base de datos. El uso de un proxy en la base de datos hace que Ganesh sea independiente de la base de datos y simplifica la creación de prototipos y experimentación. Ganesh es capaz de trabajar con una amplia gama de bases de datos y aplicaciones, sin necesidad de realizar modificaciones en ninguna de ellas. 3.3 Caché basada en proxy El controlador JDBC nativo mostrado en la Figura 3(a) es un componente de código ligero suministrado por el proveedor de la base de datos. Su función principal es mediar la comunicación entre la aplicación y la base de datos remota. Reenvía consultas, almacena resultados completos y responde a solicitudes de la aplicación para ver partes de los resultados. El controlador JDBC de Ganesh mostrado en la Figura 3(b) presenta a la aplicación una interfaz idéntica a la proporcionada por el controlador nativo. Proporciona la capacidad de reconstruir resultados a partir de descripciones compactas basadas en hash enviadas por el proxy. Para realizar esta reconstrucción, el controlador mantiene una caché en memoria de los resultados recibidos recientemente. Esta caché solo se utiliza como fuente de fragmentos de resultados en la reconstrucción de resultados. El conductor Ganesh o el proxy no intentan rastrear las actualizaciones de la base de datos. La falta de consistencia en la caché no afecta a la corrección, ya que la descripción de los resultados siempre se obtiene del proxy; en el peor de los casos, no habrá beneficio de rendimiento al usar Ganesh. Los datos obsoletos simplemente se eliminarán de la caché con el tiempo. El proxy de Ganesh accede a la base de datos a través del controlador JDBC nativo, que permanece sin cambios entre las Figuras 3(a) y (b). La base de datos está completamente ajena a la existencia del proxy. El proxy no examina ninguna consulta recibida del controlador Ganesh, sino que las pasa al controlador nativo. En cambio, el proxy es responsable de inspeccionar la salida de la base de datos recibida del controlador nativo, detectar resultados similares y generar codificaciones basadas en hash de estos resultados siempre que se encuentre suficiente similitud. Si bien esta arquitectura no disminuye la carga en una base de datos, como se mencionó anteriormente en la Sección 2.1, es mucho más fácil replicar bases de datos para escalabilidad en una LAN que en una WAN. Para generar una codificación basada en hash, el proxy debe estar al tanto de qué fragmentos de resultados están disponibles en la caché de controladores de Ganesh. Un enfoque es ser optimista y asumir que todos los fragmentos de resultados están disponibles. Esto resultará en la transmisión inicial más pequeña posible de un resultado. Sin embargo, en casos donde hay poca superposición con resultados anteriores, el controlador Ganesh tendrá que realizar muchas llamadas al proxy durante la reconstrucción para recuperar fragmentos de resultados faltantes. Para evitar esta situación, el proxy sigue de manera flexible el estado de la caché de controladores de Ganesh. Dado que ambos componentes están bajo nuestro control, es relativamente sencillo hacer esto sin recurrir a técnicas de caja gris o comunicación explícita para mantener la coherencia de la caché. En cambio, el proxy simula el algoritmo de gestión de caché de controladores de Ganesh y lo utiliza para mantener una lista de hashes para los cuales es probable que el controlador de Ganesh posea los fragmentos de resultado. En caso de desviación de seguimiento, no habrá pérdida de corrección, pero habrá retrasos adicionales en el viaje de ida y vuelta para recuperar los fragmentos faltantes. Si el cliente detecta la pérdida de sincronización con el proxy, puede pedirle al proxy que restablezca el estado compartido entre ellos. También hay que tener en cuenta que el proxy no necesita guardar los fragmentos de resultado en sí, solo sus hashes. Esto permite que el proxy siga siendo escalable incluso cuando es compartido por muchos nodos front-end. El proxy Ganesh recibe la salida de la base de datos como objetos Java del controlador JDBC nativo. Examina esta salida para ver si está presente un objeto Java del tipo ResultSet. La interfaz JDBC utiliza este tipo de dato para almacenar los resultados de las consultas a la base de datos. Si se encuentra un objeto ResultSet, se reduce como se discute a continuación. Todos los demás objetos de Java se pasan sin modificar. Como se discute en la Sección 3.1, el proxy utiliza los límites de fila definidos en el ResultSet para dividirlo en fragmentos que consisten en filas de resultado individuales. Todos los objetos ResultSet se convierten en objetos de un nuevo tipo llamado RecipeResultSet. Utilizamos el término receta para esta descripción compacta de un resultado de base de datos debido a su similitud con una receta de archivo en el sistema de archivos CASPER [37]. La conversión reemplaza cada fragmento de resultado que probablemente esté presente en la caché de controladores de Ganesh por un hash SHA-1 de ese fragmento. Los fragmentos de resultados previamente no vistos se conservan textualmente. El proxy también retiene los hashes de los nuevos fragmentos de resultados, ya que estarán presentes en la caché de los controladores en el futuro. Ten en cuenta que el proxy solo almacena en caché los hashes de los fragmentos de resultados y no almacena en caché las recetas. El proxy construye un RecipeResultSet verificando la similitud en todo el resultado y luego a nivel de fila. Si se predice que todo el resultado estará presente en la caché de los controladores de Ganesh, el RecipeResultSet será simplemente un único hash de todo el resultado. De lo contrario, contiene hashes para aquellas filas que se predice que están presentes en esa caché; todas las demás filas se conservan textualmente. Si el proxy estima un ahorro de espacio general, transmitirá el RecipeResultSet. De lo contrario, se transmite el ResultSet original. Los objetos RecipeResultSet son transformados de vuelta en objetos ResultSet por el controlador Ganesh. La Figura 4 ilustra el manejo de ResultSet en ambos extremos. Cada hash SHA-1 encontrado en un RecipeResultSet se busca en la caché local de fragmentos de resultados. En caso de acierto, el hash es reemplazado por el fragmento correspondiente. En caso de error, el conductor contacta al proxy de Ganesh para recuperar el fragmento. Todos los fragmentos de resultados previamente no vistos que fueron retenidos textualmente por el proxy se hasheado y se han añadido a la caché de resultados. Debería haber muy pocos fallos si el proxy ha seguido con precisión el estado de la caché de controladores de Ganesh. Una optimización futura sería agrupar la obtención de fragmentos faltantes. Esto sería valioso cuando hay muchos pequeños fragmentos faltantes en una WAN de alta latencia. Una vez que la transformación esté completa, el objeto ResultSet completamente reconstruido se pasa a la aplicación. 4. VALIDACIÓN EXPERIMENTAL Tres preguntas surgen de los objetivos y diseño de Ganesh: • Primero, ¿se puede mejorar significativamente el rendimiento al explotar la similitud entre los resultados de la base de datos? Detalles del conjunto de datos de referencia 500,000 usuarios, 12,000 historias BBOARD 2.0 GB 3,298,000 comentarios SUBASTA 1.3 GB 1,000,000 usuarios, 34,000 elementos Tabla 1: Detalles del conjunto de datos de referencia • En segundo lugar, ¿qué tan importante es la detección de similitud estructural de Ganesh en comparación con la detección de similitud de la huella digital de Rabin? • En tercer lugar, ¿es aceptable la sobrecarga del diseño basado en proxy? Nuestra evaluación responde a estas preguntas a través de experimentos controlados con el prototipo Ganesh. Esta sección describe los puntos de referencia utilizados, nuestro procedimiento de evaluación y la configuración experimental. Los resultados de los experimentos se presentan en las Secciones 5, 6 y 7. 4.1 Puntos de referencia Nuestra evaluación se basa en dos puntos de referencia [18] que han sido ampliamente utilizados por otros investigadores para evaluar varios aspectos de arquitecturas multi-tier [27] y de comercio electrónico [9]. El primer punto de referencia, BBOARD, está modelado según Slashdot, un sitio de noticias orientado a la tecnología. El segundo punto de referencia, AUCTION, está modelado según eBay, un sitio de subastas en línea. En ambos puntos de referencia, la mayoría del contenido se genera dinámicamente a partir de la información almacenada en una base de datos. Los detalles de los conjuntos de datos utilizados se pueden encontrar en la Tabla 1. 4.1.1 El Benchmark BBOARD El benchmark BBOARD, también conocido como RUBBoS [18], modela Slashdot, un popular sitio web orientado a la tecnología. Slashdot recopila enlaces a noticias y otros temas de interés encontrados en otros lugares de la web. El sitio también funciona como un tablón de anuncios al permitir a los usuarios comentar en las historias publicadas en forma de conversación en hilos. No es raro que una historia recopile cientos de comentarios en cuestión de horas. El benchmark BBOARD es similar al sitio y modela las actividades de un usuario, incluyendo operaciones de solo lectura como navegar por las historias del día, explorar categorías de historias y ver comentarios, así como operaciones de escritura como registro de nuevos usuarios, agregar y moderar comentarios, y enviar historias. El benchmark consiste en tres fases diferentes: una fase de calentamiento corta, una fase de ejecución que representa el cuerpo principal de la carga de trabajo, y una fase de enfriamiento corta. En este documento solo informamos sobre los resultados de la fase de ejecución. La fase de calentamiento es importante para establecer el estado del sistema dinámico, pero las mediciones de esa fase no son significativas para nuestra evaluación. La fase de enfriamiento es únicamente para permitir que el punto de referencia se apague. Las fases de calentamiento, ejercicio y enfriamiento son de 2, 15 y 2 minutos respectivamente. El número de clientes simulados fue de 400, 800, 1200 y 1600. El punto de referencia está disponible en una versión de Java Servlets y PHP y tiene diferentes conjuntos de datos; evaluamos a Ganesh utilizando la versión de Java Servlets y el conjunto de datos Expandido. El benchmark BBOARD define dos cargas de trabajo diferentes. El primero, la mezcla de Autoría, consiste en un 70% de operaciones de solo lectura y un 30% de operaciones de lectura y escritura. El segundo, la mezcla de navegación, contiene solo operaciones de solo lectura y no actualiza la base de datos. 4.1.2 El Benchmark de SUBASTA El benchmark de SUBASTA, también conocido como RUBiS [18], modela eBay, el sitio de subastas en línea. El sitio web de eBay se utiliza para comprar y vender artículos a través de un formato de subasta. Las principales actividades de un usuario incluyen navegar, vender o pujar por artículos. Modelando las actividades en este sitio, este punto de referencia incluye actividades de solo lectura como navegar por artículos por categoría y por región, así como actividades de lectura-escritura como pujar por artículos, comprar y vender artículos, y dejar comentarios. Al igual que con BBOARD, el benchmark consiste en tres fases diferentes. Las fases de calentamiento, ejecución y enfriamiento para este experimento son de 1.5, 15 y 1 minutos respectivamente. Probamos Ganesh con cuatro configuraciones de clientes donde el número de clientes de prueba se estableció en 400, 800, 1200 y 1600. El punto de referencia está disponible en una versión de Enterprise Java Bean (EJB), Java Servlets y PHP y tiene diferentes conjuntos de datos; evaluamos Ganesh con la versión de Java Servlets y el conjunto de datos Expandido. El benchmark de SUBASTA define dos cargas de trabajo diferentes. El primero, la mezcla de Ofertas, consiste en un 70% de operaciones de solo lectura y un 30% de operaciones de lectura-escritura. El segundo, la mezcla de navegación, contiene solo operaciones de solo lectura y no actualiza la base de datos. 4.2 Procedimiento Experimental Ambos benchmarks involucran una carga de trabajo sintética de clientes accediendo a un servidor web. El número de clientes emulados es un parámetro experimental. Cada cliente emulado ejecuta una instancia del benchmark en su propio hilo, utilizando una matriz para hacer la transición entre diferentes estados del benchmark. La matriz define un modelo estocástico con probabilidades de transición entre los diferentes estados que representan las acciones típicas de los usuarios. Un ejemplo de transición es un usuario iniciando sesión en el sistema de SUBASTA y luego decidiendo si publicar un artículo en venta o pujar en subastas activas. Cada cliente también modela el tiempo de pensamiento del usuario entre las solicitudes. El tiempo de pensamiento se modela como una distribución exponencial con una media de 7 segundos. Evaluamos a Ganesh a lo largo de dos ejes: número de clientes y ancho de banda de la WAN. Las cargas más altas son especialmente útiles para comprender el rendimiento de Ganesh cuando la CPU o el disco del servidor de base de datos o del proxy son el factor limitante. Un estudio previo ha demostrado que aproximadamente el 50% de los cuellos de botella de Internet de gran área observados tenían un ancho de banda disponible inferior a 10 Mb/s [1]. Basándonos en este trabajo, enfocamos nuestra evaluación en el ancho de banda de la WAN de 5 Mb/s con una latencia de ida y vuelta de 66 ms, representativa de rutas de red severamente restringidas, y 20 Mb/s con una latencia de ida y vuelta de 33 ms, representativa de una ruta de red moderadamente restringida. También informamos sobre el rendimiento de Ganesh a 100 Mb/s sin agregar latencia de ida y vuelta. Este ancho de banda, representativo de una red sin restricciones, es especialmente útil para revelar cualquier sobrecarga potencial de Ganesh en situaciones donde el ancho de banda de la WAN no es el factor limitante. Para cada combinación de número de clientes y ancho de banda de WAN, medimos los resultados de las dos configuraciones enumeradas a continuación: • Nativa: Esta configuración corresponde a la Figura 3(a). El nativo evita la sobrecarga de Ganesh al usar un proxy y realizar la serialización de objetos Java. • Ganesh: Esta configuración corresponde a la Figura 3(b). Para un número dado de clientes y ancho de banda de WAN, comparar estos resultados con los resultados nativos correspondientes proporciona el beneficio de rendimiento debido al sistema de middleware Ganesh. La métrica utilizada para cuantificar la mejora en el rendimiento es el número de solicitudes de clientes que pueden ser atendidas por segundo. La métrica utilizada para cuantificar el rendimiento de Ganesh es el tiempo promedio de respuesta para una solicitud de cliente. Para todos los experimentos, el controlador Ganesh utilizado por el servidor de aplicaciones usó un tamaño de caché de 100,000 elementos. El proxy fue efectivo en rastrear el estado de la caché de los controladores Ganesh; para todos nuestros experimentos, la tasa de fallos en el controlador nunca superó el 0.7%. 4.3 Configuración Experimental La configuración experimental utilizada para las pruebas se puede ver en la Figura 5. Todas las máquinas eran Pentium 4 de 3.2 GHz (con HyperThreading habilitado). Con la excepción del servidor de base de datos, todas las máquinas tenían 2 GB de SDRAM y ejecutaban la distribución de Linux Fedora Core. El servidor de la base de datos tenía 4 GB de SDRAM. Utilizamos Apache Tomcat como tanto el servidor de aplicaciones que alojaba los Servlets de Java como el servidor web. Ambos benchmarks utilizaron Java Servlets para generar el contenido dinámico. El servidor de la base de datos utilizó la base de datos de código abierto MySQL. Para los controladores JDBC nativos, utilizamos los controladores Connector/J proporcionados por MySQL. El servidor de aplicaciones utilizaba la Máquina Virtual de Java de Sun como entorno de ejecución para los Servlets de Java. La herramienta sysstat se utilizó para monitorear la utilización de la CPU, red, disco y memoria en todas las máquinas. Las máquinas estaban conectadas por una red Ethernet gigabit conmutada. Como se muestra en la Figura 5, el servidor web y de aplicación de front-end fue separado del servidor de proxy y base de datos por un enrutador NetEm [16]. Este enrutador nos permitió controlar la configuración de ancho de banda y latencia en la red. El enrutador NetEm es un PC estándar con dos tarjetas de red que ejecuta el software de Control de Tráfico de Linux y Emulación de Red. Las restricciones de ancho de banda y latencia solo se aplicaron al enlace entre el servidor de aplicaciones y la base de datos para el caso nativo y entre el servidor de aplicaciones y el proxy para el caso de Ganesh. No hay comunicación entre el servidor de aplicaciones y la base de datos con Ganesh, ya que todos los datos fluyen a través del proxy. Como nuestro enfoque estaba en el enlace WAN entre el servidor de aplicaciones y la base de datos, no hubo restricciones en el enlace entre los clientes de prueba simulados y el servidor web. 5. DESEMPEÑO Y TIEMPO DE RESPUESTA En esta sección, abordamos la primera pregunta planteada en la Sección 4: ¿Se puede mejorar significativamente el rendimiento explotando la similitud entre los resultados de la base de datos? Para responder a esta pregunta, utilizamos los resultados de los benchmarks BBOARD y AUCTION. Utilizamos dos métricas para cuantificar la mejora en el rendimiento obtenible a través del uso de Ganesh: el throughput, desde la perspectiva del servidor web, y el tiempo de respuesta promedio, desde la perspectiva del cliente. El rendimiento se mide en términos del número de solicitudes de clientes que pueden ser atendidas por segundo. Los resultados y análisis de BBOARD 5.1 Figuras 6 (a) y (b) presentan el número promedio de solicitudes atendidas por segundo y el tiempo de respuesta promedio para estas solicitudes tal como lo perciben los clientes para la Mezcla de Autoría de BBOARD. Como muestra la Figura 6 (a), Native satura fácilmente el enlace de 5 Mb/s. Con 400 clientes, la solución nativa entrega 29 solicitudes/segundo con un tiempo de respuesta promedio de 8.3 segundos. La capacidad de procesamiento de los clientes disminuye con un aumento en los clientes de prueba, ya que los clientes se agotan debido a la congestión en el servidor de aplicaciones. Los estudios de usabilidad han demostrado que los tiempos de respuesta superiores a 10 segundos hacen que el usuario pase a 1. Dado que Java carece de un operador sizeof(), los cachés de Java limitan su tamaño en función del número de objetos. El tamaño de los volcados de caché tomados al final de los experimentos nunca superó los 212 MB. WWW 2007 / Pista: Rendimiento y Escalabilidad Sesión: Sistemas Escalables para Contenido Dinámico 315 0 50 100 150 200 250 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Solicitudes de Clientes de Prueba por Segundo Nativo Ganesh 0.001 0.01 0.1 1 10 100 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Tiempo Promedio de Respuesta de Clientes de Prueba Nativo Ganesh Nota Escala Logarítmica (a) Rendimiento: Mezcla de Autoría (b) Tiempo de Respuesta: Mezcla de Autoría 0 50 100 150 200 250 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Solicitudes de Clientes de Prueba por Segundo Nativo Ganesh 0.001 0.01 0.1 1 10 100 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Tiempo Promedio de Respuesta de Clientes de Prueba Nativo Ganesh Nota Escala Logarítmica (c) Rendimiento: Mezcla de Navegación (d) Tiempo de Respuesta: Mezcla de Navegación Promedio de tres pruebas. La desviación estándar máxima para el rendimiento y el tiempo de respuesta fue del 9.8% y 11.9% de la media correspondiente. Figura 6: BBOARD Benchmark - Rendimiento y Tiempo de Respuesta Promedio de otras tareas [24]. Basándose en estos números, aumentar el número de clientes de prueba hace que el sistema Nativo sea inutilizable. Ganesh a 5 Mb/s, sin embargo, ofrece una mejora doble con 400 clientes de prueba y una mejora quintuple con 1200 clientes. El rendimiento de Ganesh disminuye ligeramente a 1200 y 1600 clientes debido a que la red está saturada. En comparación con Native, la Figura 6 (b) muestra que los tiempos de respuesta de Ganesh son considerablemente más bajos con tiempos de respuesta de menos de un segundo con 400 clientes. La Figura 6 (a) también muestra que para 400 y 800 clientes de prueba, Ganesh a 5 Mb/s tiene el mismo rendimiento y tiempo de respuesta promedio que Native a 20 Mb/s. Solo con 1200 y 1600 clientes, Native a 20 Mb/s ofrece un rendimiento mayor que Ganesh a 5 Mb/s. Al comparar tanto a Ganesh como a Native a 20 Mb/s, vemos que Ganesh ya no está limitado por el ancho de banda y ofrece hasta una mejora del doble sobre Native con 1600 clientes de prueba. Como Ganesh no satura la red con configuraciones de cliente de prueba más altas, con 1600 clientes de prueba, su tiempo de respuesta promedio es de 0.1 segundos en lugar de los 7.7 segundos de Natives. Como era de esperar, no hay ganancias visibles de Ganesh en el ancho de banda más alto de 100 Mb/s donde la red ya no es el cuello de botella. Sin embargo, Ganesh sigue monitoreando a Native en cuanto a rendimiento. Las Figuras 6 (c) y (d) presentan el número promedio de solicitudes atendidas por segundo y el tiempo de respuesta promedio para estas solicitudes tal como lo perciben los clientes para la Mezcla de Navegación de BBOARDs. Independientemente de la configuración del cliente de prueba, la Figura 6 (c) muestra que el rendimiento de los Nativos a 5 Mb/s está limitado a 10 reqs/seg. Ganesh a 5 Mb/s con 400 clientes de prueba, ofrece un aumento de más de seis veces en el rendimiento. La mejora aumenta a más de once veces a 800 clientes de prueba antes de que Ganesh sature la red. Además, la Figura 6 (d) muestra que el tiempo de respuesta promedio de los Nativos de 35 segundos con 400 clientes de prueba hace que el sistema sea inutilizable. Estos altos tiempos de respuesta aumentan aún más con la adición de clientes de prueba. Incluso con la configuración del cliente de prueba de 1600, Ganesh ofrece un tiempo de respuesta promedio aceptable de 8.2 segundos. Debido a la naturaleza intensiva en datos de la mezcla de navegación, Ganesh a 5 Mb/s sorprendentemente tiene un rendimiento mucho mejor que Native a 20 Mb/s. Además, como se muestra en la Figura 6 (d), si bien el tiempo de respuesta promedio para Native a 20 Mb/s es aceptable con 400 clientes de prueba, resulta inutilizable con 800 clientes de prueba, con un tiempo de respuesta promedio de 15.8 segundos. Al igual que en el caso de 5 Mb/s, este tiempo de respuesta aumenta con la adición de clientes de prueba adicionales. Ganesh a 20 Mb/s y tanto Native como Ganesh a 100 Mb/s no tienen limitaciones de ancho de banda. Sin embargo, el rendimiento se estanca después de 1200 clientes de prueba debido a que la CPU de la base de datos está saturada. 5.1.3 Variante de filtro Nos sorprendió el rendimiento nativo del benchmark BBOARD. A una velocidad de banda ancha de 5 Mb/s, el rendimiento nativo fue más bajo de lo que esperábamos. Resultó que el código de referencia que muestra historias leía todos los comentarios asociados con la historia en particular de la base de datos y solo entonces realizaba un postprocesamiento para seleccionar los comentarios que se mostrarían. Si bien este es exactamente el comportamiento de SlashCode, la base de código detrás del sitio web de Slashdot, decidimos modificar la prueba de rendimiento para realizar cierto prefiltrado en la base de datos. Este benchmark modificado, llamado el Filtro de Variantes, modela a un desarrollador que aplica optimizaciones a nivel de SQL para transferir menos datos. En aras de la brevedad, solo resumimos brevemente los resultados de la mezcla de autores. Para la mezcla de Autoría, con 800 clientes de prueba a 5 Mb/s, la Figura 7 (a) muestra que el rendimiento de Natives aumenta un 85% en comparación con el punto de referencia original, mientras que la mejora de Ganesh es menor, del 15%. El rendimiento de los servidores disminuye por encima de los 800 clientes, ya que los clientes de prueba se agotan debido a los altos tiempos de respuesta. La ganancia más significativa para Native se observa a 20 Mb/s. En 1600 clientes de prueba, en comparación con el punto de referencia original, Native experimenta una mejora del 73% en el rendimiento y una reducción del 77% en el tiempo de respuesta promedio. Mientras WWW 2007 / Pista: Rendimiento y Escalabilidad Sesión: Sistemas Escalables para Contenido Dinámico 316 0 50 100 150 200 250 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Clientes de Prueba Solicitudes/seg Nativo Ganesh 0.001 0.01 0.1 1 10 100 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Clientes de Prueba Tiempo de Resp. Promedio (seg) Nativo Ganesh Nota Escala Logarítmica (a) Rendimiento: Mezcla de Autoría (b) Tiempo de Respuesta: Mezcla de Autoría Promedio de tres pruebas. La desviación estándar máxima para el rendimiento y el tiempo de respuesta fue del 7.2% y del 11.5% de la media correspondiente. Figura 7: BBOARD Benchmark - Variante de filtro - Rendimiento y Tiempo de Respuesta Promedio Ganesh no observa ninguna mejora en comparación con el original, aún procesa un 19% más de solicitudes/seg que Native. Por lo tanto, aunque las optimizaciones fueron más útiles para Native, Ganesh todavía ofrece una mejora en el rendimiento. 5.2 Resultados y Análisis de la SUBASTA 5.2.1 Figuras de la Mezcla de Ofertas Los gráficos 8 (a) y (b) presentan el número promedio de solicitudes atendidas por segundo y el tiempo de respuesta promedio para estas solicitudes tal como son percibidas por los clientes para la Mezcla de Ofertas de las SUBASTAS. Como se mencionó anteriormente, la mezcla de ofertas consiste en una combinación de operaciones de lectura y escritura. El benchmark AUCTION no es tan intensivo en datos como BBOARD. Por lo tanto, la mayoría de las ganancias se observan en el ancho de banda más bajo de 5 Mb/s. La figura 8 (a) muestra que el aumento en el rendimiento debido a Ganesh varía desde un 8% con 400 clientes de prueba hasta un 18% con 1600 clientes de prueba. Como se observa en la Figura 8 (b), los tiempos de respuesta promedio para Ganesh son significativamente más bajos que los de Native, con una disminución del 84% a 800 clientes de prueba y del 88% a 1600 clientes de prueba. La Figura 8 (a) también muestra que con un aumento cuádruple del ancho de banda de 5 Mb/s a 20 Mb/s, Native ya no está limitado por el ancho de banda y no hay diferencia de rendimiento entre Ganesh y Native. Con las configuraciones de cliente de prueba más altas, observamos que el ancho de banda utilizado por Ganesh era menor que el de Nativo. Ganesh podría seguir siendo útil en estos escenarios no restringidos si se compra ancho de banda de forma medible. Se observan resultados similares para el escenario de 100 Mb/s. 5.2.2 Mezcla de Navegación Para la Mezcla de Navegación de SUBASTAS, las Figuras 8 (c) y (d) presentan el número promedio de solicitudes atendidas por segundo y el tiempo promedio de respuesta para estas solicitudes tal como lo perciben los clientes. Una vez más, la mayoría de las ganancias se observan en anchos de banda más bajos. A 5 Mb/s, Native y Ganesh ofrecen un rendimiento y tiempos de respuesta similares con 400 clientes de prueba. Mientras que el rendimiento para ambos permanece igual en 800 clientes de prueba, la Figura 8 (d) muestra que el tiempo de respuesta promedio de Ganesh es un 62% menor que el de Native. El servidor satura el enlace con 800 clientes y agregar clientes de prueba adicionales solo aumenta el tiempo promedio de respuesta. Ganesh, independientemente de la configuración del cliente de prueba, no tiene restricciones de ancho de banda y mantiene el mismo tiempo de respuesta. A 1600 clientes de prueba, la Figura 8 (c) muestra que el rendimiento de Ganesh es casi el doble que el de Nativo. En los anchos de banda más altos de 20 y 100 Mb/s, ni Ganesh ni Native tienen limitaciones de ancho de banda y ofrecen un rendimiento y tiempos de respuesta equivalentes. Referencia original. Tamaño Ganesh Tamaño Rabin Tamaño SelectSort1 223.6 MB 5.4 MB 219.3 MB SelectSort2 223.6 MB 5.4 MB 223.6 MB Tabla 2: Microbenchmarks de similitud 6. SIMILITUD ESTRUCTURAL VS. SIMILITUD DE RABIN En esta sección, abordamos la segunda pregunta planteada en la Sección 4: ¿Qué tan importante es la detección de similitud estructural de Ganesh en comparación con la detección de similitud basada en la huella digital de Rabin? Para responder a esta pregunta, utilizamos microbenchmarks y los benchmarks BBOARD y AUCTION. Dado que Ganesh siempre tuvo un mejor rendimiento que Rabin en la huella dactilar, aquí presentamos solo un subconjunto de los resultados en aras de la brevedad. 6.1 Microbenchmarks Dos microbenchmarks muestran un ejemplo de los efectos de la reordenación de datos en el algoritmo de huella dactilar de Rabin. En el primer microbenchmark, SelectSort1, una consulta con un orden de clasificación especificado selecciona 223.6 MB de datos distribuidos en aproximadamente 280 K filas. La consulta se repite entonces con un atributo de ordenación diferente. Si bien se devuelve el mismo número de filas y los mismos datos, el orden de las filas es diferente. En un escenario así, se esperaría detectar una gran cantidad de similitud entre ambos resultados. Como muestra la Tabla 2, el algoritmo basado en filas de Ganesh logra una reducción del 97.6%, mientras que el algoritmo de huella digital de Rabin, con el parámetro de tamaño de fragmento promedio establecido en 4 KB, solo logra una reducción del 1%. La razón, como se muestra anteriormente en la Figura 2, es que con la huella digital de Rabin, los tramos de datos entre dos límites consecutivos suelen cruzar los límites de fila. Con el cambio en el orden de las filas en el segundo resultado y los fingerprints de Rabin ahora abarcando diferentes filas, el algoritmo no puede detectar similitud significativa. La pequeña ganancia observada se debe principalmente a aquellas filas individuales que son lo suficientemente grandes como para dividirse en múltiples fragmentos. SelectSort2, otro micro-benchmark ejecutó las mismas consultas pero aumentó el tamaño mínimo del fragmento del algoritmo de huella digital de Rabin. Como se puede ver en la Tabla 2, incluso la pequeña ganancia del microbenchmark anterior desaparece cuando el tamaño mínimo de fragmento fue mayor que el tamaño promedio de fila. Si bien se pueden abordar parcialmente estos problemas variando dinámicamente los parámetros del algoritmo de huella digital de Rabin, esto puede resultar computacionalmente costoso, especialmente en presencia de cargas de trabajo cambiantes. 6.2 Benchmarks de Aplicación Ejecutamos el benchmark BBOARD descrito en la Sección 4.1.1 en dos versiones de Ganesh: la primera con la huella digital de Rabin utilizada como WWW 2007 / Track: Sesión de Rendimiento y Escalabilidad: Sistemas Escalables para Contenido Dinámico 317 0 50 100 150 200 250 300 350 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Clientes de Prueba Solicitudes/seg Ganesh Nativo 0.001 0.01 0.1 1 10 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Clientes de Prueba Tiempo de Respuesta Promedio (seg) Ganesh Nativo Nota Escala Logarítmica (a) Rendimiento: Mezcla de Ofertas (b) Tiempo de Respuesta: Mezcla de Ofertas 0 50 100 150 200 250 300 350 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Clientes de Prueba Solicitudes/seg Ganesh Nativo 0.001 0.01 0.1 1 10 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Clientes de Prueba Tiempo de Respuesta Promedio (seg) Ganesh Nativo Nota Escala Logarítmica (c) Rendimiento: Mezcla de Navegación (d) Tiempo de Respuesta: Mezcla de Navegación Promedio de tres pruebas. La desviación estándar máxima para el rendimiento y el tiempo de respuesta fue del 2.2% y del 11.8% de la media correspondiente. Figura 8: Referencia de la subasta AUCTION - Rendimiento y Tiempo de Respuesta Promedio del algoritmo de fragmentación y el segundo con el algoritmo basado en filas de Ganesh. Los resultados de Rabins para la Mezcla de Navegación se normalizan con los resultados de Ganesh y se presentan en la Figura 9. Como muestra la Figura 9 (a), a 5 Mb/s, independientemente de la configuración del cliente de prueba, Rabin tiene un rendimiento significativamente inferior a Ganesh. Esto sucede debido a una combinación de dos razones. Primero, como se describe en la Sección 3.1, Rabin encuentra menos similitud ya que no explota la información estructural de los resultados. Segundo, este punto de referencia contenía algunas consultas que generaron resultados grandes. En este caso, Rabin, con un tamaño de fragmento promedio pequeño, generó una gran cantidad de objetos que desplazaron otros datos útiles de la caché. Por el contrario, Ganesh pudo detectar estas filas grandes y aumentar correspondientemente el tamaño de los bloques. Esto fue confirmado ya que las estadísticas de caché mostraron que la proporción de aciertos de Ganesh era aproximadamente tres veces mayor que la de Rabin. Las mediciones de rendimiento a 20 Mb/s fueron similares, con la excepción del rendimiento de Rabins con 400 clientes de prueba. En este caso, Ganesh no estaba limitado por la red y, de hecho, el rendimiento era el mismo que el de 400 clientes a 5 Mb/s. Rabin, sin embargo, aprovechó el aumento del ancho de banda de 5 a 20 Mb/s para ofrecer un rendimiento ligeramente mejor. A 100 Mb/s, el rendimiento de Rabin era casi similar al de Ganesh ya que el ancho de banda ya no era un cuello de botella. El tiempo de respuesta normalizado, presentado en la Figura 9 (b), muestra tendencias similares. A 5 y 20 Mb/s, la adición de clientes de prueba disminuye el tiempo de respuesta normalizado, ya que el tiempo de respuesta promedio de Ganesh aumenta más rápido que el de Rabin. Sin embargo, en ningún momento Rabin supera a Ganesh. Ten en cuenta que con 400 y 800 clientes a 100 Mb/s, Rabin tiene un mayor sobrecosto incluso cuando no está limitado por el ancho de banda. Como se menciona en la Sección 3.1, esto se debe a que Rabin tiene que hashear cada ResultSet dos veces. La sobrecarga desaparece con 1200 y 1600 clientes, ya que la CPU de la base de datos está saturada y limita el rendimiento tanto de Ganesh como de Rabin. 7. SUPERPOSICIÓN DE PROXY En esta sección, abordamos la tercera pregunta planteada en la Sección 4: ¿Es aceptable la superposición del diseño basado en proxy de Ganesh? Para responder a esta pregunta, nos concentramos en su rendimiento en las bandas de mayor ancho de banda. Nuestra evaluación en la Sección 5 mostró que Ganesh, en comparación con Native, puede ofrecer una mejora sustancial en el rendimiento a anchos de banda más bajos. Solo en anchos de banda más altos serían visibles los costos adicionales de latencia, medidos por el tiempo promedio de respuesta para una solicitud de cliente, y de rendimiento, medidos por la cantidad de solicitudes de cliente que pueden ser atendidas por segundo. Al observar la combinación de autoría del benchmark original de BBOARD, no se aprecian ganancias visibles de Ganesh a 100 Mb/s. Sin embargo, Ganesh sigue rastreando a Native en cuanto a rendimiento. Si bien el tiempo promedio de respuesta es mayor para Ganesh, la diferencia absoluta está entre 0.01 y 0.04 segundos y sería imperceptible para el usuario final. La mezcla de navegación muestra una diferencia aún menor en los tiempos de respuesta promedio. Los resultados de la variante del filtro de los benchmarks de BBOARD son similares. Incluso para el benchmark de SUBASTA, la diferencia entre el tiempo de respuesta de Nativo y Ganesh a 100 Mb/s nunca fue mayor a 0.02 segundos. La única excepción a los resultados anteriores se observó en la variante de filtro del benchmark BBOARD, donde Ganesh con 1600 clientes de prueba añadió 0.85 segundos al tiempo de respuesta promedio. Por lo tanto, incluso para redes mucho más rápidas donde el enlace WAN no es el cuello de botella, Ganesh siempre ofrece un rendimiento equivalente al Nativo. Si bien se agrega algo de latencia adicional debido al diseño basado en proxy, generalmente es imperceptible. TRABAJO RELACIONADO Hasta donde sabemos, Ganesh es el primer sistema que combina el uso de técnicas basadas en hash con el almacenamiento en caché de resultados de base de datos para mejorar el rendimiento y los tiempos de respuesta de aplicaciones con contenido dinámico. También creemos que es el primer sistema en demostrar los beneficios de utilizar información estructural para WWW 2007 / Track: Rendimiento y Escalabilidad Sesión: Sistemas Escalables para Contenido Dinámico 318 0.0 0.2 0.4 0.6 0.8 1.0 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Clientes de Prueba Rendimiento Normalizado 31.8 3.8 2.8 2.3 23.8 32.8 5.8 3.6 1.8 2.1 1.1 1.0 0 5 10 15 20 25 30 35 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Clientes de Prueba Tiempo de Respuesta Normalizado (a) Rendimiento Normalizado: Mayor es mejor (b) Tiempo de Respuesta Normalizado: Mayor es peor Para el rendimiento, un resultado normalizado mayor que 1 implica que Rabin es mejor. Para el tiempo de respuesta, un resultado normalizado mayor que 1 implica que Ganesh es mejor. Media de tres pruebas. La desviación estándar máxima para el rendimiento y el tiempo de respuesta fue del 9.1% y del 13.9% de la media correspondiente. Figura 9: Comparación normalizada de Ganesh vs. Rabin - Mezcla de navegación BBOARD detectando similitud. En esta sección, primero discutimos enfoques alternativos para almacenar en caché contenido dinámico y luego examinamos otros usos de primitivas basadas en hash en sistemas distribuidos. 8.1 Almacenamiento en Caché de Contenido Dinámico En la capa de base de datos, varios sistemas han abogado por la caché de nivel intermedio donde partes de la base de datos se replican en el borde o servidor [3, 4, 20]. Estos sistemas almacenan en caché tablas completas en lo que es esencialmente una base de datos replicada o utilizan vistas materializadas de respuestas de consultas anteriores [19]. Requieren una integración estrecha con la base de datos del sistema para garantizar un límite de tiempo en la propagación de actualizaciones. Estos sistemas suelen estar dirigidos a cargas de trabajo que no requieren una consistencia estricta y pueden tolerar datos obsoletos. Además, a diferencia de Ganesh, algunas de estas soluciones de almacenamiento en caché de nivel medio [2, 3], sufren de la complejidad de tener que participar en la planificación de consultas y el procesamiento de consultas distribuidas. Gao et al. [15] proponen utilizar una arquitectura de replicación de objetos distribuidos donde los requisitos de consistencia de las tiendas de datos se adaptan según la aplicación. Estas soluciones requieren recursos sustanciales de desarrollo y un entendimiento detallado de la aplicación que se está modificando. Si bien existen sistemas que intentan automatizar la partición y replicación de la base de datos de una aplicación [34], no proporcionan semántica de transacciones completa. En comparación, Ganesh no debilita ninguna de las semánticas proporcionadas por la base de datos subyacente. El trabajo reciente en la evaluación de opciones de almacenamiento en caché de borde para sitios web dinámicos [38] ha sugerido que, sin una planificación cuidadosa, el empleo de estrategias complejas de descarga puede perjudicar el rendimiento. En cambio, el trabajo aboga por una arquitectura en la que todos los niveles, excepto la base de datos, deberían ser trasladados al borde. Nuestra evaluación de Ganesh ha demostrado que sería beneficioso para estos escenarios. Para mejorar la escalabilidad de la base de datos, C-JDBC [10], SSS [22] y Ganymed [28] también abogan por el uso de una arquitectura basada en interposición para clusterizar y replicar bases de datos de forma transparente a nivel de middleware. Los enfoques de estas arquitecturas y Ganesh son complementarios y se beneficiarían mutuamente. Avanzando hacia la capa de presentación, se ha producido una amplia adopción de la caché basada en fragmentos [14], la cual mejora la utilización de la caché al almacenar por separado diferentes partes de las páginas web generadas. Si bien el almacenamiento en caché basado en fragmentos funciona en el borde, una propuesta reciente ha propuesto trasladar el ensamblaje de páginas web a los clientes para optimizar la entrega de contenido [31]. Si bien Ganesh no se utiliza en la capa de presentación, los mismos principios se han aplicado en la Detección de Transferencias Duplicadas [25] para aumentar la eficiencia de la caché web, así como para el acceso web a través de enlaces con ancho de banda limitado [33]. 8.2 Sistemas basados en hash En los últimos años han surgido muchos sistemas que explotan técnicas basadas en hash. En el centro de todos estos sistemas se encuentra la idea de detectar similitudes en los datos sin necesidad de interpretar esos datos. Esta idea simple pero elegante se basa en el hash criptográfico, como se discutió anteriormente en la Sección 2. Las aplicaciones exitosas de esta idea abarcan una amplia gama de sistemas de almacenamiento. Los ejemplos incluyen la copia de seguridad entre pares de archivos informáticos personales [11], el archivado eficiente de datos [29] y la búsqueda de archivos similares [21]. Spring y Wetherall [35] aplican principios similares a nivel de red. Utilizando cachés sincronizadas en ambos extremos de un enlace de red, los datos duplicados son reemplazados por tokens más pequeños para su transmisión y luego restaurados en el extremo remoto. Este y otros sistemas basados en hash como los sistemas de archivos CASPER [37] y LBFS [26], y optimizadores de ancho de banda de Capa-2 como Riverbed y Peribit utilizan la huella digital de Rabin [30] para descubrir tramos de similitud en los datos. Este enfoque es especialmente útil cuando los elementos de datos son modificados en su lugar a través de inserciones, eliminaciones y actualizaciones. Sin embargo, como se muestra en la Sección 6, el rendimiento de esta técnica puede experimentar una caída dramática en presencia de reordenamiento de datos. Ganesh en cambio utiliza los límites de fila como divisores para detectar similitudes. El uso más agresivo de técnicas basadas en hash es por sistemas que utilizan hashes como identificadores principales para objetos en almacenamiento persistente. Los sistemas de almacenamiento como CFS [12] y PAST [13] que han sido construidos utilizando tablas hash distribuidas entran en esta categoría. Single Instance Storage [6] y Venti [29] son otros ejemplos de tales sistemas. Como se discute en la Sección 2.2, el uso de hashes criptográficos para abordar datos persistentes representa un nivel más profundo de confianza en su resistencia a colisiones que la asumida por Ganesh. Si el tiempo revela deficiencias en el algoritmo hash, el esfuerzo necesario para corregir la falla es mucho mayor. En Ganesh, simplemente se trata de reemplazar el algoritmo hash. 9. CONCLUSIÓN El creciente uso de contenido web dinámico generado a partir de bases de datos relacionales aumenta las demandas de ancho de banda de la WAN. Las soluciones de almacenamiento en caché tradicionales para reducir el ancho de banda y la latencia suelen ser ineficaces para este tipo de contenido. Este documento muestra que el impacto de los accesos a bases de datos a través de WAN puede reducirse sustancialmente mediante la arquitectura Ganesh sin comprometer la estricta semántica de consistencia de las bases de datos. La esencia de la arquitectura Ganesh es el uso de la computación en los bordes para reducir la comunicación a través de Internet. Ganesh es capaz de utilizar hashes criptográficos para detectar similitud con resultados anteriores y enviar recetas compactas de resultados en lugar de resultados completos en la sesión de Sistemas Escalables para Contenido Dinámico 319 de WWW 2007 / Track: Rendimiento y Escalabilidad. Nuestro diseño utiliza la interposición para lograr una transparencia completa: los clientes, los servidores de aplicaciones y los servidores de bases de datos no son conscientes de la presencia de Ganesh y no requieren ninguna modificación. Nuestra evaluación experimental confirma que Ganesh, aunque conceptualmente simple, puede ser altamente efectivo en mejorar el rendimiento y el tiempo de respuesta. Nuestros resultados también confirman que aprovechar la estructura presente en los resultados de la base de datos para detectar similitudes es crucial para esta mejora en el rendimiento. REFERENCIAS [1] AKELLA, A., SESHAN, S., Y SHAIKH, A. Una evaluación empírica de los cuellos de botella en Internet de área amplia. En Proc. 3ª Conferencia ACM SIGCOMM sobre Medición de Internet (Miami Beach, FL, EE. UU., Oct. 2003), pp. 101-114. [2] ALTINEL, M., BORNH ¨OVD, C., KRISHNAMURTHY, S., MOHAN, C., PIRAHESH, H., Y REINWALD, B. Tablas de caché: allanando el camino para una caché de base de datos adaptativa. En Proc. del 29º VLDB (Berlín, Alemania, 2003), pp. 718-729. [3] ALTINEL, M., LUO, Q., KRISHNAMURTHY, S., MOHAN, C., PIRAHESH, H., LINDSAY, B. G., WOO, H., Y BROWN, L. Dbcache: Caché de base de datos para servidores de aplicaciones web. En Proc. 2002 ACM SIGMOD (2002), pp. 612-612. [4] AMIRI, K., PARK, S., TEWARI, R., Y PADMANABHAN, S. Dbproxy: una caché de datos dinámica para aplicaciones web. En Proc. Conferencia Internacional de Ingeniería de Datos de IEEE (ICDE) (Mar. 2003). [5] BLACK, J. Compare-by-hash: Un análisis razonado. En Proc. Conferencia Técnica Anual USENIX 2006 (Boston, MA, mayo de 2006), pp. 85-90. [6] BOLOSKY, W. J., CORBIN, S., GOEBEL, D., y DOUCEUR, J. R. Almacenamiento de instancia única en Windows 2000. En Proc. 4to Simposio de Sistemas Windows de USENIX (Seattle, WA, ago. 2000), pp. 13-24. [7] BREWER, E. A. Lecciones de servicios a gran escala. IEEE Internet Computing 5, 4 (2001), 46-55. [8] BRODER, A., GLASSMAN, S., MANASSE, M., AND ZWEIG, G. Agrupamiento sintáctico de la web. En Proc. 6ta Conferencia Internacional WWW (1997). [9] CECCHET, E., CHANDA, A., ELNIKETY, S., MARGUERITE, J., Y ZWAENEPOEL, W. Comparación de rendimiento de arquitecturas de middleware para generar contenido web dinámico. En Proc. Cuarta Conferencia Internacional de Middleware ACM/IFIP/USENIX (Río de Janeiro, Brasil, junio de 2003). [10] CECCHET, E., MARGUERITE, J., Y ZWAENEPOEL, W. C-JDBC: Middleware flexible de agrupación de bases de datos. En Proc. Conferencia Técnica Anual USENIX 2004 (Boston, MA, junio de 2004). [11] COX, L. P., MURRAY, C. D., Y NOBLE, B. D. Pastiche: Haciendo que la copia de seguridad sea barata y fácil. En OSDI: Simposio sobre Diseño e Implementación de Sistemas Operativos (2002). [12] DABEK, F., KAASHOEK, M. F., KARGER, D., MORRIS, R., Y STOICA, I. Almacenamiento cooperativo de amplia área con CFS. En el 18º Simposio ACM sobre Principios de Sistemas Operativos (Banff, Canadá, octubre de 2001). [13] DRUSCHEL, P., Y ROWSTRON, A. PASADO: Una utilidad de almacenamiento entre pares a gran escala y persistente. En HotOS VIII (Schloss Elmau, Alemania, mayo de 2001), pp. 75-80. [14] Incluye el lado del borde. http://www.esi.org. [15] GAO, L., DAHLIN, M., NAYATE, A., ZHENG, J., Y IYENGAR, A. Replicación de datos específica de la aplicación para servicios en el borde. En WWW 03: Proc. Duodécima Conferencia Internacional sobre la World Wide Web (2003), pp. 449-460. [16] HEMMINGER, S. Netem - emulando redes reales en el laboratorio. En Proc. 2005 Linux Conference Australia (Canberra, Australia, Abr. 2005). [17] HENSON, V. Un análisis de compare-by-hash. En Proc. 9º Taller sobre Temas Candentes en Sistemas Operativos (HotOS IX) (mayo de 2003), pp. 13-18. [18] Benchmarks de Jmob. http://jmob.objectweb.org/. [19] LABRINIDIS, A., Y ROUSSOPOULOS, N. Equilibrando el rendimiento y la frescura de los datos en servidores de bases de datos web. En Proc. 29ª Conferencia VLDB (Sept. 2003). [20] LARSON, P.-A., GOLDSTEIN, J., Y ZHOU, J. Caché transparente de bases de datos en el nivel intermedio en SQL Server. En Proc. 2003 ACM SIGMOD (2003), pp. 661-661. [21] MANBER, U. Encontrar archivos similares en un sistema de archivos grande. En Proc. Conferencia Técnica de Invierno de USENIX 1994 (San Francisco, CA, 17-21 de 1994), pp. 1-10. [22] MANJHI, A., AILAMAKI, A., MAGGS, B. M., MOWRY, T. C., OLSTON, C., Y TOMASIC, A. Escalabilidad y seguridad simultáneas para aplicaciones web intensivas en datos. En Proc. 2006 ACM SIGMOD (junio de 2006), pp. 241-252. [23] MENEZES, A. J., VANSTONE, S. A., Y OORSCHOT, P. C. V. Manual de Criptografía Aplicada. CRC Press, 1996. [24] MILLER, R. B. \n\nCRC Press, 1996. [24] MILLER, R. B. Tiempo de respuesta en transacciones conversacionales entre humanos y computadoras. En Proc. Conferencia Conjunta de Computación de Otoño de AFIPS (1968), pp. 267-277. [25] MOGUL, J. C., CHAN, Y. M., Y KELLY, T. Diseño, implementación y evaluación de la detección de transferencias duplicadas en http. En Proc. Primer Simposio sobre Diseño e Implementación de Sistemas en Red (San Francisco, CA, Mar. 2004). [26] MUTHITACHAROEN, A., CHEN, B., Y MAZIERES, D. Un sistema de archivos en red de bajo ancho de banda. En Proc. 18º Simposio de la ACM sobre Principios de Sistemas Operativos (Banff, Canadá, Oct. 2001). [27] PFEIFER, D., Y JAKSCHITSCH, H. Caché basada en métodos en aplicaciones de servidores multinivel. En Proc. Quinto Simposio Internacional sobre Objetos y Aplicaciones Distribuidas (Catania, Sicilia, Italia, noviembre de 2003). [28] PLATTNER, C., Y ALONSO, G. Ganymed: Replicación escalable para aplicaciones web transaccionales. En Proc. 5ta Conferencia Internacional de Middleware ACM/IFIP/USENIX (2004), pp. 155-174. [29] QUINLAN, S., Y DORWARD, S. Venti: Un nuevo enfoque para el almacenamiento de archivos. En Proc. Conferencia FAST 2002 sobre Tecnologías de Archivo y Almacenamiento (2002). [30] RABIN, M. Huellas dactilares mediante polinomios aleatorios. En el Informe Técnico TR-15-81 (1981) del Centro de Investigación en Tecnología Informática de la Universidad de Harvard. [31] RABINOVICH, M., XIAO, Z., DOUGLIS, F., Y KALMANEK, C. Mover los lados de los bordes incluye a los clientes reales en el borde. En Proc. 4to Simposio USENIX sobre Tecnologías y Sistemas de Internet (Seattle, WA, Mar. 2003). [32] REESE, G. Programación de bases de datos con JDBC y Java, 1ra ed. OReilly, junio de 1997. [33] RHEA, S., LIANG, K., Y BREWER, E. Caché web basada en valores. En Proc. Duodécima Conferencia Internacional de la World Wide Web (mayo de 2003). [34] SIVASUBRAMANIAN, S., ALONSO, G., PIERRE, G., Y VAN STEEN, M. Globedb: Replicación autónoma de datos para aplicaciones web. En WWW 05: Actas de la 14ª Conferencia Internacional de la World-Wide Web (mayo de 2005). [35] SPRING, N. T., Y WETHERALL, D. Una técnica independiente de protocolo para eliminar el tráfico de red redundante. En Proc. de ACM SIGCOMM (Ago. 2000). [36] TOLIA, N., HARKES, J., KOZUCH, M., Y SATYANARAYANAN, M. Integrando almacenamiento portátil y distribuido. En Proc. 3ra Conferencia USENIX sobre Tecnologías de Archivos y Almacenamiento (San Francisco, CA, Mar. 2004). [37] TOLIA, N., KOZUCH, M., SATYANARAYANAN, M., KARP, B., PERRIG, A., Y BRESSOUD, T. Uso oportunista del almacenamiento direccionable por contenido para sistemas de archivos distribuidos. En Proc. Conferencia Técnica Anual USENIX 2003 (San Antonio, TX, junio de 2003), pp. 127-140. [38] YUAN, C., CHEN, Y., Y ZHANG, Z. Evaluación de almacenamiento en caché/descarga en el borde para la entrega de contenido dinámico. En WWW 03: Proc. Duodécima Conferencia Internacional sobre la World Wide Web (2003), pp. 461-471. WWW 2007 / Pista: Rendimiento y Escalabilidad Sesión: Sistemas Escalables para Contenido Dinámico 320 ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "temporal locality": {
            "translated_key": "localidad temporal",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Consistency-preserving Caching of Dynamic Database Content∗ Niraj Tolia and M. Satyanarayanan Carnegie Mellon University {ntolia,satya}@cs.cmu.edu ABSTRACT With the growing use of dynamic web content generated from relational databases, traditional caching solutions for throughput and latency improvements are ineffective.",
                "We describe a middleware layer called Ganesh that reduces the volume of data transmitted without semantic interpretation of queries or results.",
                "It achieves this reduction through the use of cryptographic hashing to detect similarities with previous results.",
                "These benefits do not require any compromise of the strict consistency semantics provided by the back-end database.",
                "Further, Ganesh does not require modifications to applications, web servers, or database servers, and works with closed-source applications and databases.",
                "Using two benchmarks representative of dynamic web sites, measurements of our prototype show that it can increase end-to-end throughput by as much as twofold for non-data intensive applications and by as much as tenfold for data intensive ones.",
                "Categories and Subject Descriptors C.2.4 [Computer-Communication Networks]: Distributed Systems; H.2.4 [Database Management]: Systems General Terms Design, Performance 1.",
                "INTRODUCTION An increasing fraction of web content is dynamically generated from back-end relational databases.",
                "Even when database content remains unchanged, <br>temporal locality</br> of access cannot be exploited because dynamic content is not cacheable by web browsers or by intermediate caching servers such as Akamai mirrors.",
                "In a multitiered architecture, each web request can stress the WAN link between the web server and the database.",
                "This causes user experience to be highly variable because there is no caching to insulate the client from bursty loads.",
                "Previous attempts in caching dynamic database content have generally weakened transactional semantics [3, 4] or required application modifications [15, 34].",
                "We report on a new solution that takes the form of a databaseagnostic middleware layer called Ganesh.",
                "Ganesh makes no effort to semantically interpret the contents of queries or their results.",
                "Instead, it relies exclusively on cryptographic hashing to detect similarities with previous results.",
                "Hash-based similarity detection has seen increasing use in distributed file systems [26, 36, 37] for improving performance on low-bandwidth networks.",
                "However, these techniques have not been used for relational databases.",
                "Unlike previous approaches that use generic methods to detect similarity, Ganesh exploits the structure of relational database results to yield superior performance improvement.",
                "One faces at least three challenges in applying hash-based similarity detection to back-end databases.",
                "First, previous work in this space has traditionally viewed storage content as uninterpreted bags of bits with no internal structure.",
                "This allows hash-based techniques to operate on long, contiguous runs of data for maximum effectiveness.",
                "In contrast, relational databases have rich internal structure that may not be as amenable to hash-based similarity detection.",
                "Second, relational databases have very tight integrity and consistency constraints that must not be compromised by the use of hash-based techniques.",
                "Third, the source code of commercial databases is typically not available.",
                "This is in contrast to previous work which presumed availability of source code.",
                "Our experiments show that Ganesh, while conceptually simple, can improve performance significantly at bandwidths representative of todays commercial Internet.",
                "On benchmarks modeling multitiered web applications, the throughput improvement was as high as tenfold for data-intensive workloads.",
                "For workloads that were not data-intensive, throughput improvements of up to twofold were observed.",
                "Even when bandwidth was not a constraint, Ganesh had low overhead and did not hurt performance.",
                "Our experiments also confirm that exploiting the structure present in database results is crucial to this performance improvement. 2.",
                "BACKGROUND 2.1 Dynamic Content Generation As the World Wide Web has grown, many web sites have decentralized their data and functionality by pushing them to the edges of the Internet.",
                "Today, eBusiness systems often use a three-tiered architecture consisting of a front-end web server, an application server, and a back-end database server.",
                "Figure 1 illustrates this architecture.",
                "The first two tiers can be replicated close to a concentration of clients at the edge of the Internet.",
                "This improves user experience by lowering end-to-end latency and reducing exposure WWW 2007 / Track: Performance and Scalability Session: Scalable Systems for Dynamic Content 311 Back-End Database Server Front-End Web and Application Servers Figure 1: Multi-Tier Architecture to backbone traffic congestion.",
                "It can also increase the availability and scalability of web services.",
                "Content that is generated dynamically from the back-end database cannot be cached in the first two tiers.",
                "While databases can be easily replicated in a LAN, this is infeasible in a WAN because of the difficult task of simultaneously providing strong consistency, availability, and tolerance to network partitions [7].",
                "As a result, databases tend to be centralized to meet the strong consistency requirements of many eBusiness applications such as banking, finance, and online retailing [38].",
                "Thus, the back-end database is usually located far from many sets of first and second-tier nodes [2].",
                "In the absence of both caching and replication, WAN bandwidth can easily become a limiting factor in the performance and scalability of data-intensive applications. 2.2 Hash-Based Systems Ganeshs focus is on efficient transmission of results by discovering similarities with the results of previous queries.",
                "As SQL queries can generate large results, hash-based techniques lend themselves well to the problem of efficiently transferring these large results across bandwidth constrained links.",
                "The use of hash-based techniques to reduce the volume of data transmitted has emerged as a common theme of many recent storage systems, as discussed in Section 8.2.",
                "These techniques rely on some basic assumptions.",
                "Cryptographic hash functions are assumed to be collision-resistant.",
                "In other words, it is computationally intractable to find two inputs that hash to the same output.",
                "The functions are also assumed to be one-way; that is, finding an input that results in a specific output is computationally infeasible.",
                "Menezes et al. [23] provide more details about these assumptions.",
                "The above assumptions allow hash-based systems to assume that collisions do not occur.",
                "Hence, they are able to treat the hash of a data item as its unique identifier.",
                "A collection of data items effectively becomes content-addressable, allowing a small hash to serve as a codeword for a much larger data item in permanent storage or network transmission.",
                "The assumption that collisions are so rare as to be effectively non-existent has recently come under fire [17].",
                "However, as explained by Black [5], we believe that these issues do not form a concern for Ganesh.",
                "All communication is between trusted parts of the system and an adversary has no way to force Ganesh to accept invalid data.",
                "Further, Ganesh does not depend critically on any specific hash function.",
                "While we currently use SHA-1, replacing it with a different hash function would be simple.",
                "There would be no impact on performance as stronger hash functions (e.g.",
                "SHA256) only add a few extra bytes and the generated hashes are still orders of magnitude smaller than the data items they represent.",
                "No re-hashing of permanent storage is required since Ganesh only uses hashing on volatile data. 3.",
                "DESIGN AND IMPLEMENTATION Ganesh exploits redundancy in the result stream to avoid transmitting result fragments that are already present at the query site.",
                "Redundancy can arise naturally in many different ways.",
                "For example, a query repeated after a certain interval may return a different result because of updates to the database; however, there may be significant commonality between the two results.",
                "As another example, a user who is refining a search may generate a sequence of queries with overlapping results.",
                "When Ganesh detects redundancy, it suppresses transmission of the corresponding result fragments.",
                "Instead, it transmits a much smaller digest of those fragments and lets the query site reconstruct the result through hash lookup in a cache of previous results.",
                "In effect, Ganesh uses computation at the edges to reduce Internet communication.",
                "Our description of Ganesh focuses on four aspects.",
                "We first explain our approach to detecting similarity in query results.",
                "Next, we discuss how the Ganesh architecture is completely invisible to all components of a multi-tier system.",
                "We then describe Ganeshs proxy-based approach and the dataflow for detecting similarity. 3.1 Detecting Similarity One of the key design decisions in Ganesh is how similarity is detected.",
                "There are many potential ways to decompose a result into fragments.",
                "The optimal way is, of course, the one that results in the smallest possible object for transmission for a given querys results.",
                "Finding this optimal decomposition is a difficult problem because of the large space of possibilities and because the optimal choice depends on many factors such as the contents of the querys result, the history of recent results, and the cache management algorithm.",
                "When an object is opaque, the use of Rabin fingerprints [8, 30] to detect common data between two objects has been successfully shown in the past by systems such as LBFS [26] and CASPER [37].",
                "Rabin fingerprinting uses a sliding window over the data to compute a rolling hash.",
                "Assuming that the hash function is uniformly distributed, a chunk boundary is defined whenever the lower order bits of the hash value equal some predetermined value.",
                "The number of lower order bits used defines the average chunk size.",
                "These sub-divided chunks of the object become the unit of comparison for detecting similarity between different objects.",
                "As the locations of boundaries found by using Rabin fingerprints is stochastically determined, they usually fail to align with any structural properties of the underlying data.",
                "The algorithm therefore deals well with in-place updates, insertions and deletions.",
                "However, it performs poorly in the presence of any reordering of data.",
                "Figure 2 shows an example where two results, A and B, consisting of three rows, have the same data but have different sort attributes.",
                "In the extreme case, Rabin fingerprinting might be unable to find any similar data due to the way it detects chunk boundaries.",
                "Fortunately, Ganesh can use domain specific knowledge for more precise boundary detection.",
                "The information we exploit is that a querys result reflects the structure of a relational database where all data is organized as tables and rows.",
                "It is therefore simple to check for similarity with previous results at two granularities: first the entire result, and then individual rows.",
                "The end of a row in a result serves as a natural chunk boundary.",
                "It is important to note that using the tabular structure in results only involves shallow interpretation of the data.",
                "Ganesh does not perform any deeper semantic interpretation such as understanding data types, result schema, or integrity constraints.",
                "Tuning Rabin fingerprinting for a workload can also be difficult.",
                "If the average chunk size is too large, chunks can span multiple result rows.",
                "However, selecting a smaller average chunk size increases the amount of metadata required to the describe the results.",
                "WWW 2007 / Track: Performance and Scalability Session: Scalable Systems for Dynamic Content 312 Figure 2: Rabin Fingerprinting vs. Ganeshs Chunking This, in turn, would decrease the savings obtained via its use.",
                "Rabin fingerprinting also needs two computationally-expensive passes over the data: once to determine chunk boundaries and one again to generate cryptographic hashes for the chunks.",
                "Ganesh only needs a single pass for hash generation as the chunk boundaries are provided by the datas natural structure.",
                "The performance comparison in Section 6 shows that Ganeshs row-based algorithm outperforms Rabin fingerprinting.",
                "Given that previous work has already shown that Rabin fingerprinting performs better than gzip [26], we do not compare Ganesh to compression algorithms in this paper. 3.2 Transparency The key factor influencing our design was the need for Ganesh to be completely transparent to all components of a typical eBusiness system: web servers, application servers, and database servers.",
                "Without this, Ganesh stands little chance of having a significant real-world impact.",
                "Requiring modifications to any of the above components would raise the barrier for entry of Ganesh into an existing system, and thus reduce its chances of adoption.",
                "Preserving transparency is simplified by the fact that Ganesh is purely a performance enhancement, not a functionality or usability enhancement.",
                "We chose agent interposition as the architectural approach to realizing our goal.",
                "This approach relies on the existence of a compact programming interface that is already widely used by target software.",
                "It also relies on a mechanism to easily add new code without disrupting existing module structure.",
                "These conditions are easily met in our context because of the popularity of Java as the programming language for eBusiness systems.",
                "The Java Database Connectivity (JDBC) API [32] allows Java applications to access a wide variety of databases and even other tabular data repositories such as flat files.",
                "Access to these data sources is provided by JDBC drivers that translate between the JDBC API and the database communication mechanism.",
                "Figure 3(a) shows how JDBC is typically used in an application.",
                "As the JDBC interface is standardized, one can substitute one JDBC driver for another without application modifications.",
                "The JDBC driver thus becomes the natural module to exploit for code interposition.",
                "As shown in Figure 3(b), the native JDBC driver is replaced with a Ganesh JDBC driver that presents the same standardized interface.",
                "The Ganesh driver maintains an in-memory cache of result fragments from previous queries and performs reassembly of results.",
                "At the database, we add a new process called the Ganesh proxy.",
                "This proxy, which can be shared by multiple front-end nodes, consists of two parts: code to detect similarity in result fragments and the original native JDBC driver that communicates with the database.",
                "The use of a proxy at the database makes Ganesh database-agnostic and simplifies prototyping and experimentation.",
                "Ganesh is thus able to work with a wide range of databases and applications, requiring no modifications to either. 3.3 Proxy-Based Caching The native JDBC driver shown in Figure 3(a) is a lightweight code component supplied by the database vendor.",
                "Its main funcClient Database Web and Application Server Native JDBC Driver WAN (a) Native Architecture Client Database Ganesh Proxy Native JDBC Driver WAN Web and Application Server Ganesh JDBC Driver (b) Ganeshs Interposition-based Architecture Figure 3: Native vs. Ganesh Architecture tion is to mediate communication between the application and the remote database.",
                "It forwards queries, buffers entire results, and responds to application requests to view parts of results.",
                "The Ganesh JDBC driver shown in Figure 3(b) presents the application with an interface identical to that provided by the native driver.",
                "It provides the ability to reconstruct results from compact hash-based descriptions sent by the proxy.",
                "To perform this reconstruction, the driver maintains an in-memory cache of recentlyreceived results.",
                "This cache is only used as a source of result fragments in reconstructing results.",
                "No attempt is made by the Ganesh driver or proxy to track database updates.",
                "The lack of cache consistency does not hurt correctness as a description of the results is always fetched from the proxy - at worst, there will be no performance benefit from using Ganesh.",
                "Stale data will simply be paged out of the cache over time.",
                "The Ganesh proxy accesses the database via the native JDBC driver, which remains unchanged between Figures 3(a) and (b).",
                "The database is thus completely unaware of the existence of the proxy.",
                "The proxy does not examine any queries received from the Ganesh driver but passes them to the native driver.",
                "Instead, the proxy is responsible for inspecting database output received from the native driver, detecting similar results, and generating hash-based encodings of these results whenever enough similarity is found.",
                "While this architecture does not decrease the load on a database, as mentioned earlier in Section 2.1, it is much easier to replicate databases for scalability in a LAN than in a WAN.",
                "To generate a hash-based encoding, the proxy must be aware of what result fragments are available in the Ganesh drivers cache.",
                "One approach is to be optimistic, and to assume that all result fragments are available.",
                "This will result in the smallest possible initial transmission of a result.",
                "However, in cases where there is little overlap with previous results, the Ganesh driver will have to make many calls to the proxy during reconstruction to fetch missing result fragments.",
                "To avoid this situation, the proxy loosely tracks the state of the Ganesh drivers cache.",
                "Since both components are under our control, it is relatively simple to do this without resorting to gray-box techniques or explicit communication for maintaining cache coherence.",
                "Instead, the proxy simulates the Ganesh drivers cache management algorithm and uses this to maintain a list of hashes for which the Ganesh driver is likely to possess the result fragments.",
                "In case of mistracking, there will be no loss of correctness but there will be extra round-trip delays to fetch the missing fragments.",
                "If the client detects loss of synchronization with the proxy, it can ask the proxy to reset the state shared between them.",
                "Also note that the proxy does not need to keep the result fragments themselves, only their hashes.",
                "This allows the proxy to remain scalable even when it is shared by many front-end nodes.",
                "WWW 2007 / Track: Performance and Scalability Session: Scalable Systems for Dynamic Content 313 Object Output Stream Convert ResultSet Object Input Stream Convert ResultSet All Data Recipe ResultSet All Data ResultSet Network Ganesh Proxy Ganesh JDBC Driver Result Set Recipe Result Set Yes Yes No No GaneshInputStream GaneshOutputStream Figure 4: Dataflow for Result Handling 3.4 Encoding and Decoding Results The Ganesh proxy receives database output as Java objects from the native JDBC driver.",
                "It examines this output to see if a Java object of type ResultSet is present.",
                "The JDBC interface uses this data type to store results of database queries.",
                "If a ResultSet object is found, it is shrunk as discussed below.",
                "All other Java objects are passed through unmodified.",
                "As discussed in Section 3.1, the proxy uses the row boundaries defined in the ResultSet to partition it into fragments consisting of single result rows.",
                "All ResultSet objects are converted into objects of a new type called RecipeResultSet.",
                "We use the term recipe for this compact description of a database result because of its similarity to a file recipe in the CASPER file system [37].",
                "The conversion replaces each result fragment that is likely to be present in the Ganesh drivers cache by a SHA-1 hash of that fragment.",
                "Previously unseen result fragments are retained verbatim.",
                "The proxy also retains hashes for the new result fragments as they will be present in the drivers cache in the future.",
                "Note that the proxy only caches hashes for result fragments and does not cache recipes.",
                "The proxy constructs a RecipeResultSet by checking for similarity at the entire result and then the row level.",
                "If the entire result is predicted to be present in the Ganesh drivers cache, the RecipeResultSet is simply a single hash of the entire result.",
                "Otherwise, it contains hashes for those rows predicted to be present in that cache; all other rows are retained verbatim.",
                "If the proxy estimates an overall space savings, it will transmit the RecipeResultSet.",
                "Otherwise the original ResultSet is transmitted.",
                "The RecipeResultSet objects are transformed back into ResultSet objects by the Ganesh driver.",
                "Figure 4 illustrates ResultSet handling at both ends.",
                "Each SHA-1 hash found in a RecipeResultSet is looked up in the local cache of result fragments.",
                "On a hit, the hash is replaced by the corresponding fragment.",
                "On a miss, the driver contacts the Ganesh proxy to fetch the fragment.",
                "All previously unseen result fragments that were retained verbatim by the proxy are hashed and added to the result cache.",
                "There should be very few misses if the proxy has accurately tracked the Ganesh drivers cache state.",
                "A future optimization would be to batch the fetch of missing fragments.",
                "This would be valuable when there are many small missing fragments in a high-latency WAN.",
                "Once the transformation is complete, the fully reconstructed ResultSet object is passed up to the application. 4.",
                "EXPERIMENTAL VALIDATION Three questions follow from the goals and design of Ganesh: • First, can performance can be improved significantly by exploiting similarity across database results?",
                "Benchmark Dataset Details 500,000 Users, 12,000 Stories BBOARD 2.0 GB 3,298,000 Comments AUCTION 1.3 GB 1,000,000 Users, 34,000 Items Table 1: Benchmark Dataset Details • Second, how important is Ganeshs structural similarity detection relative to Rabin fingerprintings similarity detection? • Third, is the overhead of the proxy-based design acceptable?",
                "Our evaluation answers these question through controlled experiments with the Ganesh prototype.",
                "This section describes the benchmarks used, our evaluation procedure, and the experimental setup.",
                "Results of the experiments are presented in Sections 5, 6, and 7. 4.1 Benchmarks Our evaluation is based on two benchmarks [18] that have been widely used by other researchers to evaluate various aspects of multi-tier [27] and eBusiness architectures [9].",
                "The first benchmark, BBOARD, is modeled after Slashdot, a technology-oriented news site.",
                "The second benchmark, AUCTION, is modeled after eBay, an online auction site.",
                "In both benchmarks, most content is dynamically generated from information stored in a database.",
                "Details of the datasets used can be found in Table 1. 4.1.1 The BBOARD Benchmark The BBOARD benchmark, also known as RUBBoS [18], models Slashdot, a popular technology-oriented web site.",
                "Slashdot aggregates links to news stories and other topics of interest found elsewhere on the web.",
                "The site also serves as a bulletin board by allowing users to comment on the posted stories in a threaded conversation form.",
                "It is not uncommon for a story to gather hundreds of comments in a matter of hours.",
                "The BBOARD benchmark is similar to the site and models the activities of a user, including readonly operations such as browsing the stories of the day, browsing story categories, and viewing comments as well as write operations such as new user registration, adding and moderating comments, and story submission.",
                "The benchmark consists of three different phases: a short warmup phase, a runtime phase representing the main body of the workload, and a short cool-down phase.",
                "In this paper we only report results from the runtime phase.",
                "The warm-up phase is important in establishing dynamic system state, but measurements from that phase are not significant for our evaluation.",
                "The cool-down phase is solely for allowing the benchmark to shut down.",
                "The warm-up, runtime, and cool-down phases are 2, 15, and 2 minutes respectively.",
                "The number of simulated clients were 400, 800, 1200, and 1600.",
                "The benchmark is available in a Java Servlets and PHP version and has different datasets; we evaluated Ganesh using the Java Servlets version and the Expanded dataset.",
                "The BBOARD benchmark defines two different workloads.",
                "The first, the Authoring mix, consists of 70% read-only operations and 30% read-write operations.",
                "The second, the Browsing mix, contains only read-only operations and does not update the database. 4.1.2 The AUCTION Benchmark The AUCTION benchmark, also known as RUBiS [18], models eBay, the online auction site.",
                "The eBay web site is used to buy and sell items via an auction format.",
                "The main activities of a user include browsing, selling, or bidding for items.",
                "Modeling the activities on this site, this benchmark includes read-only activities such as browsing items by category and by region, as well as read-write WWW 2007 / Track: Performance and Scalability Session: Scalable Systems for Dynamic Content 314 NetEm Router Ganesh Proxy Clients Web and Application Server Database Server Figure 5: Experimental Setup activities such as bidding for items, buying and selling items, and leaving feedback.",
                "As with BBOARD, the benchmark consists of three different phases.",
                "The warm-up, runtime, and cool-down phases for this experiment are 1.5, 15, and 1 minutes respectively.",
                "We tested Ganesh with four client configurations where the number of test clients was set to 400, 800, 1200, and 1600.",
                "The benchmark is available in a Enterprise Java Bean (EJB), Java Servlets, and PHP version and has different datasets; we evaluated Ganesh with the Java Servlets version and the Expanded dataset.",
                "The AUCTION benchmark defines two different workloads.",
                "The first, the Bidding mix, consists of 70% read-only operations and 30% read-write operations.",
                "The second, the Browsing mix, contains only read-only operations and does not update the database. 4.2 Experimental Procedure Both benchmarks involve a synthetic workload of clients accessing a web server.",
                "The number of clients emulated is an experimental parameter.",
                "Each emulated client runs an instance of the benchmark in its own thread, using a matrix to transition between different benchmark states.",
                "The matrix defines a stochastic model with probabilities of transitioning between the different states that represent typical user actions.",
                "An example transition is a user logging into the AUCTION system and then deciding on whether to post an item for sale or bid on active auctions.",
                "Each client also models user think time between requests.",
                "The think time is modeled as an exponential distribution with a mean of 7 seconds.",
                "We evaluate Ganesh along two axes: number of clients and WAN bandwidth.",
                "Higher loads are especially useful in understanding Ganeshs performance when the CPU or disk of the database server or proxy is the limiting factor.",
                "A previous study has shown that approximately 50% of the wide-area Internet bottlenecks observed had an available bandwidth under 10 Mb/s [1].",
                "Based on this work, we focus our evaluation on the WAN bandwidth of 5 Mb/s with 66 ms of round-trip latency, representative of severely constrained network paths, and 20 Mb/s with 33 ms of round-trip latency, representative of a moderately constrained network path.",
                "We also report Ganeshs performance at 100 Mb/s with no added round-trip latency.",
                "This bandwidth, representative of an unconstrained network, is especially useful in revealing any potential overhead of Ganesh in situations where WAN bandwidth is not the limiting factor.",
                "For each combination of number of clients and WAN bandwidth, we measured results from the two configurations listed below: • Native: This configuration corresponds to Figure 3(a).",
                "Native avoids Ganeshs overhead in using a proxy and performing Java object serialization. • Ganesh: This configuration corresponds to Figure 3(b).",
                "For a given number of clients and WAN bandwidth, comparing these results to the corresponding Native results gives the performance benefit due to the Ganesh middleware system.",
                "The metric used to quantify the improvement in throughput is the number of client requests that can be serviced per second.",
                "The metric used to quantify Ganeshs overhead is the average response time for a client request.",
                "For all of the experiments, the Ganesh driver used by the application server used a cache size of 100,000 items1 .",
                "The proxy was effective in tracking the Ganesh drivers cache state; for all of our experiments the miss rate on the driver never exceeded 0.7%. 4.3 Experimental Setup The experimental setup used for the benchmarks can be seen in Figure 5.",
                "All machines were 3.2 GHz Pentium 4s (with HyperThreading enabled.)",
                "With the exception of the database server, all machines had 2 GB of SDRAM and ran the Fedora Core Linux distribution.",
                "The database server had 4 GB of SDRAM.",
                "We used Apaches Tomcat as both the application server that hosted the Java Servlets and the web server.",
                "Both benchmarks used Java Servlets to generate the dynamic content.",
                "The database server used the open source MySQL database.",
                "For the native JDBC drivers, we used the Connector/J drivers provided by MySQL.",
                "The application server used Suns Java Virtual Machine as the runtime environment for the Java Servlets.",
                "The sysstat tool was used to monitor the CPU, network, disk, and memory utilization on all machines.",
                "The machines were connected by a switched gigabit Ethernet network.",
                "As shown in Figure 5, the front-end web and application server was separated from the proxy and database server by a NetEm router [16].",
                "This router allowed us to control the bandwidth and latency settings on the network.",
                "The NetEm router is a standard PC with two network cards running the Linux Traffic Control and Network Emulation software.",
                "The bandwidth and latency constraints were only applied to the link between the application server and the database for the native case and between the application server and the proxy for the Ganesh case.",
                "There is no communication between the application server and the database with Ganesh as all data flows through the proxy.",
                "As our focus was on the WAN link between the application server and the database, there were no constraints on the link between the simulated test clients and the web server. 5.",
                "THROUGHPUT AND RESPONSE TIME In this section, we address the first question raised in Section 4: Can performance can be improved significantly by exploiting similarity across database results?",
                "To answer this question, we use results from the BBOARD and AUCTION benchmarks.",
                "We use two metrics to quantify the performance improvement obtainable through the use of Ganesh: throughput, from the perspective of the web server, and average response time, from the perspective of the client.",
                "Throughput is measured in terms of the number of client requests that can be serviced per second. 5.1 BBOARD Results and Analysis 5.1.1 Authoring Mix Figures 6 (a) and (b) present the average number of requests serviced per second and the average response time for these requests as perceived by the clients for BBOARDs Authoring Mix.",
                "As Figure 6 (a) shows, Native easily saturates the 5 Mb/s link.",
                "At 400 clients, the Native solution delivers 29 requests/sec with an average response time of 8.3 seconds.",
                "Natives throughput drops with an increase in test clients as clients timeout due to congestion at the application server.",
                "Usability studies have shown that response times above 10 seconds cause the user to move on to 1 As Java lacks a sizeof() operator, Java caches therefore limit their size based on the number of objects.",
                "The size of cache dumps taken at the end of the experiments never exceeded 212 MB.",
                "WWW 2007 / Track: Performance and Scalability Session: Scalable Systems for Dynamic Content 315 0 50 100 150 200 250 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Test Clients Requests/sec Native Ganesh 0.001 0.01 0.1 1 10 100 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Test Clients Avg.Resp.Time(sec) Native Ganesh Note Logscale (a) Throughput: Authoring Mix (b) Response Time: Authoring Mix 0 50 100 150 200 250 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Test Clients Requests/sec Native Ganesh 0.001 0.01 0.1 1 10 100 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Test Clients Avg.Resp.Time(sec) Native Ganesh Note Logscale (c) Throughput: Browsing Mix (d) Response Time: Browsing Mix Mean of three trials.",
                "The maximum standard deviation for throughput and response time was 9.8% and 11.9% of the corresponding mean.",
                "Figure 6: BBOARD Benchmark - Throughput and Average Response Time other tasks [24].",
                "Based on these numbers, increasing the number of test clients makes the Native system unusable.",
                "Ganesh at 5 Mb/s, however, delivers a twofold improvement with 400 test clients and a fivefold improvement at 1200 clients.",
                "Ganeshs performance drops slightly at 1200 and 1600 clients as the network is saturated.",
                "Compared to Native, Figure 6 (b) shows that Ganeshs response times are substantially lower with sub-second response times at 400 clients.",
                "Figure 6 (a) also shows that for 400 and 800 test clients Ganesh at 5 Mb/s has the same throughput and average response time as Native at 20 Mb/s.",
                "Only at 1200 and 1600 clients does Native at 20 Mb/s deliver higher throughput than Ganesh at 5 Mb/s.",
                "Comparing both Ganesh and Native at 20 Mb/s, we see that Ganesh is no longer bandwidth constrained and delivers up to a twofold improvement over Native at 1600 test clients.",
                "As Ganesh does not saturate the network with higher test client configurations, at 1600 test clients, its average response time is 0.1 seconds rather than Natives 7.7 seconds.",
                "As expected, there are no visible gains from Ganesh at the higher bandwidth of 100 Mb/s where the network is no longer the bottleneck.",
                "Ganesh, however, still tracks Native in terms of throughput. 5.1.2 Browsing Mix Figures 6 (c) and (d) present the average number of requests serviced per second and the average response time for these requests as perceived by the clients for BBOARDs Browsing Mix.",
                "Regardless of the test client configuration, Figure 6 (c) shows that Natives throughput at 5 Mb/s is limited to 10 reqs/sec.",
                "Ganesh at 5 Mb/s with 400 test clients, delivers more than a sixfold increase in throughput.",
                "The improvement increases to over a elevenfold increase at 800 test clients before Ganesh saturates the network.",
                "Further, Figure 6 (d) shows that Natives average response time of 35 seconds at 400 test clients make the system unusable.",
                "These high response times further increase with the addition of test clients.",
                "Even with the 1600 test client configuration Ganesh delivers an acceptable average response time of 8.2 seconds.",
                "Due to the data-intensive nature of the Browsing mix, Ganesh at 5 Mb/s surprisingly performs much better than Native at 20 Mb/s.",
                "Further, as shown in Figure 6 (d), while the average response time for Native at 20 Mb/s is acceptable at 400 test clients, it is unusable with 800 test clients with an average response time of 15.8 seconds.",
                "Like the 5 Mb/s case, this response time increases with the addition of extra test clients.",
                "Ganesh at 20 Mb/s and both Native and Ganesh at 100 Mb/s are not bandwidth limited.",
                "However, performance plateaus out after 1200 test clients due to the database CPU being saturated. 5.1.3 Filter Variant We were surprised by the Native performance from the BBOARD benchmark.",
                "At the bandwidth of 5 Mb/s, Native performance was lower than what we had expected.",
                "It turned out the benchmark code that displays stories read all the comments associated with the particular story from the database and only then did some postprocessing to select the comments to be displayed.",
                "While this is exactly the behavior of SlashCode, the code base behind the Slashdot web site, we decided to modify the benchmark to perform some pre-filtering at the database.",
                "This modified benchmark, named the Filter Variant, models a developer who applies optimizations at the SQL level to transfer less data.",
                "In the interests of brevity, we only briefly summarize the results from the Authoring mix.",
                "For the Authoring mix, at 800 test clients at 5 Mb/s, Figure 7 (a) shows that Natives throughput increase by 85% when compared to the original benchmark while Ganeshs improvement is smaller at 15%.",
                "Natives performance drops above 800 clients as the test clients time out due to high response times.",
                "The most significant gain for Native is seen at 20 Mb/s.",
                "At 1600 test clients, when compared to the original benchmark, Native sees a 73% improvement in throughput and a 77% reduction in average response time.",
                "While WWW 2007 / Track: Performance and Scalability Session: Scalable Systems for Dynamic Content 316 0 50 100 150 200 250 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Test Clients Requests/sec Native Ganesh 0.001 0.01 0.1 1 10 100 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Test Clients Avg.Resp.Time(sec) Native Ganesh Note Logscale (a) Throughput: Authoring Mix (b) Response Time: Authoring Mix Mean of three trials.",
                "The maximum standard deviation for throughput and response time was 7.2% and 11.5% of the corresponding mean.",
                "Figure 7: BBOARD Benchmark - Filter Variant - Throughput and Average Response Time Ganesh sees no improvement when compared to the original, it still processes 19% more requests/sec than Native.",
                "Thus, while the optimizations were more helpful to Native, Ganesh still delivers an improvement in performance. 5.2 AUCTION Results and Analysis 5.2.1 Bidding Mix Figures 8 (a) and (b) present the average number of requests serviced per second and the average response time for these requests as perceived by the clients for AUCTIONs Bidding Mix.",
                "As mentioned earlier, the Bidding mix consists of a mixture of read and write operations.",
                "The AUCTION benchmark is not as data intensive as BBOARD.",
                "Therefore, most of the gains are observed at the lower bandwidth of 5 Mb/s.",
                "Figure 8 (a) shows that the increase in throughput due to Ganesh ranges from 8% at 400 test clients to 18% with 1600 test clients.",
                "As seen in Figure 8 (b), the average response times for Ganesh are significantly lower than Native ranging from a decrease of 84% at 800 test clients to 88% at 1600 test clients.",
                "Figure 8 (a) also shows that with a fourfold increase of bandwidth from 5 Mb/s to 20 Mb/s, Native is no longer bandwidth constrained and there is no performance difference between Ganesh and Native.",
                "With the higher test client configurations, we did observe that the bandwidth used by Ganesh was lower than Native.",
                "Ganesh might still be useful in these non-constrained scenarios if bandwidth is purchased on a metered basis.",
                "Similar results are seen for the 100 Mb/s scenario. 5.2.2 Browsing Mix For AUCTIONs Browsing Mix, Figures 8 (c) and (d) present the average number of requests serviced per second and the average response time for these requests as perceived by the clients.",
                "Again, most of the gains are observed at lower bandwidths.",
                "At 5 Mb/s, Native and Ganesh deliver similar throughput and response times with 400 test clients.",
                "While the throughput for both remains the same at 800 test clients, Figure 8 (d) shows that Ganeshs average response time is 62% lower than Native.",
                "Native saturates the link at 800 clients and adding extra test clients only increases the average response time.",
                "Ganesh, regardless of the test client configuration, is not bandwidth constrained and maintains the same response time.",
                "At 1600 test clients, Figure 8 (c) shows that Ganeshs throughput is almost twice that of Native.",
                "At the higher bandwidths of 20 and 100 Mb/s, neither Ganesh nor Native is bandwidth limited and deliver equivalent throughput and response times.",
                "Benchmark Orig.",
                "Size Ganesh Size Rabin Size SelectSort1 223.6 MB 5.4 MB 219.3 MB SelectSort2 223.6 MB 5.4 MB 223.6 MB Table 2: Similarity Microbenchmarks 6.",
                "STRUCTURAL VS. RABIN SIMILARITY In this section, we address the second question raised in Section 4: How important is Ganeshs structural similarity detection relative to Rabin fingerprinting-based similarity detecting?",
                "To answer this question, we used microbenchmarks and the BBOARD and AUCTION benchmarks.",
                "As Ganesh always performed better than Rabin fingerprinting, we only present a subset of the results here in the interests of brevity. 6.1 Microbenchmarks Two microbenchmarks show an example of the effects of data reordering on Rabin fingerprinting algorithm.",
                "In the first microbenchmark, SelectSort1, a query with a specified sort order selects 223.6 MB of data spread over approximately 280 K rows.",
                "The query is then repeated with a different sort attribute.",
                "While the same number of rows and the same data is returned, the order of rows is different.",
                "In such a scenario, one would expect a large amount of similarity to be detected between both results.",
                "As Table 2 shows, Ganeshs row-based algorithm achieves a 97.6% reduction while the Rabin fingerprinting algorithm, with the average chunk size parameter set to 4 KB, only achieves a 1% reduction.",
                "The reason, as shown earlier in Figure 2, is that with Rabin fingerprinting, the spans of data between two consecutive boundaries usually cross row boundaries.",
                "With the order of the rows changing in the second result and the Rabin fingerprints now spanning different rows, the algorithm is unable to detect significant similarity.",
                "The small gain seen is mostly for those single rows that are large enough to be broken into multiple chunks.",
                "SelectSort2, another micro-benchmark executed the same queries but increased the minimum chunk size of the Rabin fingerprinting algorithm.",
                "As can be seen in Table 2, even the small gain from the previous microbenchmark disappears as the minimum chunk size was greater than the average row size.",
                "While one can partially address these problems by dynamically varying the parameters of the Rabin fingerprinting algorithm, this can be computationally expensive, especially in the presence of changing workloads. 6.2 Application Benchmarks We ran the BBOARD benchmark described in Section 4.1.1 on two versions of Ganesh: the first with Rabin fingerprinting used as WWW 2007 / Track: Performance and Scalability Session: Scalable Systems for Dynamic Content 317 0 50 100 150 200 250 300 350 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Test Clients Requests/sec Native Ganesh 0.001 0.01 0.1 1 10 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Test Clients Avg.Resp.Time(sec) Native Ganesh Note Logscale (a) Throughput: Bidding Mix (b) Response Time: Bidding Mix 0 50 100 150 200 250 300 350 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Test Clients Requests/sec Native Ganesh 0.001 0.01 0.1 1 10 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Test Clients Avg.Resp.Time(sec) Native Ganesh Note Logscale (c) Throughput: Browsing Mix (d) Response Time: Browsing Mix Mean of three trials.",
                "The maximum standard deviation for throughput and response time was 2.2% and 11.8% of the corresponding mean.",
                "Figure 8: AUCTION Benchmark - Throughput and Average Response Time the chunking algorithm and the second with Ganeshs row-based algorithm.",
                "Rabins results for the Browsing Mix are normalized to Ganeshs results and presented in Figure 9.",
                "As Figure 9 (a) shows, at 5 Mb/s, independent of the test client configuration, Rabin significantly underperforms Ganesh.",
                "This happens because of a combination of two reasons.",
                "First, as outlined in Section 3.1, Rabin finds less similarity as it does not exploit the results structural information.",
                "Second, this benchmark contained some queries that generated large results.",
                "In this case, Rabin, with a small average chunk size, generated a large number of objects that evicted other useful data from the cache.",
                "In contrast, Ganesh was able to detect these large rows and correspondingly increase the size of the chunks.",
                "This was confirmed as cache statistics showed that Ganeshs hit ratio was roughly three time that of Rabin.",
                "Throughput measurements at 20 Mb/s were similar with the exception of Rabins performance with 400 test clients.",
                "In this case, Ganesh was not network limited and, in fact, the throughput was the same as 400 clients at 5 Mb/s.",
                "Rabin, however, took advantage of the bandwidth increase from 5 to 20 Mb/s to deliver a slightly better performance.",
                "At 100 Mb/s, Rabins throughput was almost similar to Ganesh as bandwidth was no longer a bottleneck.",
                "The normalized response time, presented in Figure 9 (b), shows similar trends.",
                "At 5 and 20 Mb/s, the addition of test clients decreases the normalized response time as Ganeshs average response time increases faster than Rabins.",
                "However, at no point does Rabin outperform Ganesh.",
                "Note that at 400 and 800 clients at 100 Mb/s, Rabin does have a higher overhead even when it is not bandwidth constrained.",
                "As mentioned in Section 3.1, this is due to the fact that Rabin has to hash each ResultSet twice.",
                "The overhead disappears with 1200 and 1600 clients as the database CPU is saturated and limits the performance of both Ganesh and Rabin. 7.",
                "PROXY OVERHEAD In this section, we address the third question raised in Section 4: Is the overhead of Ganeshs proxy-based design acceptable?",
                "To answer this question, we concentrate on its performance at the higher bandwidths.",
                "Our evaluation in Section 5 showed that Ganesh, when compared to Native, can deliver a substantial throughput improvement at lower bandwidths.",
                "It is only at higher bandwidths that latency, measured by the average response time for a client request, and throughput, measured by the number of client requests that can be serviced per second, overheads would be visible.",
                "Looking at the Authoring mix of the original BBOARD benchmark, there are no visible gains from Ganesh at 100 Mb/s.",
                "Ganesh, however, still tracks Native in terms of throughput.",
                "While the average response time is higher for Ganesh, the absolute difference is in between 0.01 and 0.04 seconds and would be imperceptible to the end-user.",
                "The Browsing mix shows an even smaller difference in average response times.",
                "The results from the filter variant of the BBOARD benchmarks are similar.",
                "Even for the AUCTION benchmark, the difference between Native and Ganeshs response time at 100 Mb/s was never greater than 0.02 seconds.",
                "The only exception to the above results was seen in the filter variant of the BBOARD benchmark where Ganesh at 1600 test clients added 0.85 seconds to the average response time.",
                "Thus, even for much faster networks where the WAN link is not the bottleneck, Ganesh always delivers throughput equivalent to Native.",
                "While some extra latency is added by the proxy-based design, it is usually imperceptible. 8.",
                "RELATED WORK To the best of our knowledge, Ganesh is the first system that combines the use of hash-based techniques with caching of database results to improve throughput and response times for applications with dynamic content.",
                "We also believe that it is also the first system to demonstrate the benefits of using structural information for WWW 2007 / Track: Performance and Scalability Session: Scalable Systems for Dynamic Content 318 0.0 0.2 0.4 0.6 0.8 1.0 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Test Clients Norm.Throughput 31.8 3.8 2.8 2.3 23.8 32.8 5.8 3.6 1.8 2.1 1.1 1.0 0 5 10 15 20 25 30 35 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Test Clients Norm.ResponseTime (a) Normalized Throughput: Higher is better (b) Normalized Response Time: Higher is worse For throughput, a normalized result greater than 1 implies that Rabin is better, For response time, a normalized result greater than 1 implies that Ganesh is better.",
                "Mean of three trials.",
                "The maximum standard deviation for throughput and response time was 9.1% and 13.9% of the corresponding mean.",
                "Figure 9: Normalized Comparison of Ganesh vs. Rabin - BBOARD Browsing Mix detecting similarity.",
                "In this section, we first discuss alternative approaches to caching dynamic content and then examine other uses of hash-based primitives in distributed systems. 8.1 Caching Dynamic Content At the database layer, a number of systems have advocated middletier caching where parts of the database are replicated at the edge or server [3, 4, 20].",
                "These systems either cache entire tables in what is essentially a replicated database or use materialized views from previous query replies [19].",
                "They require tight integration with the back-end database to ensure a time bound on the propagation of updates.",
                "These systems are also usually targeted towards workloads that do not require strict consistency and can tolerate stale data.",
                "Further, unlike Ganesh, some of these mid-tier caching solutions [2, 3], suffer from the complexity of having to participate in query planing and distributed query processing.",
                "Gao et al. [15] propose using a distributed object replication architecture where the data stores consistency requirements are adapted on a per-application basis.",
                "These solutions require substantial developer resources and detailed understanding of the application being modified.",
                "While systems that attempt to automate the partitioning and replication of an applications database exist [34], they do not provide full transaction semantics.",
                "In comparison, Ganesh does not weaken any of the semantics provided by the underlying database.",
                "Recent work in the evaluation of edge caching options for dynamic web sites [38] has suggested that, without careful planning, employing complex offloading strategies can hurt performance.",
                "Instead, the work advocates for an architecture in which all tiers except the database should be offloaded to the edge.",
                "Our evaluation of Ganesh has shown that it would benefit these scenarios.",
                "To improve database scalability, C-JDBC [10], SSS [22], and Ganymed [28] also advocate the use of an interposition-based architecture to transparently cluster and replicate databases at the middleware level.",
                "The approaches of these architectures and Ganesh are complementary and they would benefit each other.",
                "Moving up to the presentation layer, there has been widespread adoption of fragment-based caching [14], which improves cache utilization by separately caching different parts of generated web pages.",
                "While fragment-based caching works at the edge, a recent proposal has proposed moving web page assembly to the clients to optimize content delivery [31].",
                "While Ganesh is not used at the presentation layer, the same principles have been applied in Duplicate Transfer Detection [25] to increase web cache efficiency as well as for web access across bandwidth limited links [33]. 8.2 Hash-based Systems The past few years have seen the emergence of many systems that exploit hash-based techniques.",
                "At the heart of all these systems is the idea of detecting similarity in data without requiring interpretation of that data.",
                "This simple yet elegant idea relies on cryptographic hashing, as discussed earlier in Section 2.",
                "Successful applications of this idea span a wide range of storage systems.",
                "Examples include peer-to-peer backup of personal computing files [11], storage-efficient archiving of data [29], and finding similar files [21].",
                "Spring and Wetherall [35] apply similar principles at the network level.",
                "Using synchronized caches at both ends of a network link, duplicated data is replaced by smaller tokens for transmission and then restored at the remote end.",
                "This and other hash-based systems such as the CASPER [37] and LBFS [26] filesystems, and Layer-2 bandwidth optimizers such as Riverbed and Peribit use Rabin fingerprinting [30] to discover spans of commonality in data.",
                "This approach is especially useful when data items are modified in-place through insertions, deletions, and updates.",
                "However, as Section 6 shows, the performance of this technique can show a dramatic drop in the presence of data reordering.",
                "Ganesh instead uses row boundaries as dividers for detecting similarity.",
                "The most aggressive use of hash-based techniques is by systems that use hashes as the primary identifiers for objects in persistent storage.",
                "Storage systems such as CFS [12] and PAST [13] that have been built using distributed hash tables fall into this category.",
                "Single Instance Storage [6] and Venti [29] are other examples of such systems.",
                "As discussed in Section 2.2, the use of cryptographic hashes for addressing persistent data represents a deeper level of faith in their collision-resistance than that assumed by Ganesh.",
                "If time reveals shortcomings in the hash algorithm, the effort involved in correcting the flaw is much greater.",
                "In Ganesh, it is merely a matter of replacing the hash algorithm. 9.",
                "CONCLUSION The growing use of dynamic web content generated from relational databases places increased demands on WAN bandwidth.",
                "Traditional caching solutions for bandwidth and latency reduction are often ineffective for such content.",
                "This paper shows that the impact of WAN accesses to databases can be substantially reduced through the Ganesh architecture without any compromise of the databases strict consistency semantics.",
                "The essence of the Ganesh architecture is the use of computation at the edges to reduce communication through the Internet.",
                "Ganesh is able to use cryptographic hashes to detect similarity with previous results and send WWW 2007 / Track: Performance and Scalability Session: Scalable Systems for Dynamic Content 319 compact recipes of results rather than full results.",
                "Our design uses interposition to achieve complete transparency: clients, application servers, and database servers are all unaware of Ganeshs presence and require no modification.",
                "Our experimental evaluation confirms that Ganesh, while conceptually simple, can be highly effective in improving throughput and response time.",
                "Our results also confirm that exploiting the structure present in database results to detect similarity is crucial to this performance improvement. 10.",
                "REFERENCES [1] AKELLA, A., SESHAN, S., AND SHAIKH, A.",
                "An empirical evaluation of wide-area internet bottlenecks.",
                "In Proc. 3rd ACM SIGCOMM Conference on Internet Measurement (Miami Beach, FL, USA, Oct. 2003), pp. 101-114. [2] ALTINEL, M., BORNH ¨OVD, C., KRISHNAMURTHY, S., MOHAN, C., PIRAHESH, H., AND REINWALD, B. Cache tables: Paving the way for an adaptive database cache.",
                "In Proc. of 29th VLDB (Berlin, Germany, 2003), pp. 718-729. [3] ALTINEL, M., LUO, Q., KRISHNAMURTHY, S., MOHAN, C., PIRAHESH, H., LINDSAY, B. G., WOO, H., AND BROWN, L. Dbcache: Database caching for web application servers.",
                "In Proc. 2002 ACM SIGMOD (2002), pp. 612-612. [4] AMIRI, K., PARK, S., TEWARI, R., AND PADMANABHAN, S. Dbproxy: A dynamic data cache for web applications.",
                "In Proc.",
                "IEEE International Conference on Data Engineering (ICDE) (Mar. 2003). [5] BLACK, J. Compare-by-hash: A reasoned analysis.",
                "In Proc. 2006 USENIX Annual Technical Conference (Boston, MA, May 2006), pp. 85-90. [6] BOLOSKY, W. J., CORBIN, S., GOEBEL, D., , AND DOUCEUR, J. R. Single instance storage in windows 2000.",
                "In Proc. 4th USENIX Windows Systems Symposium (Seattle, WA, Aug. 2000), pp. 13-24. [7] BREWER, E. A.",
                "Lessons from giant-scale services.",
                "IEEE Internet Computing 5, 4 (2001), 46-55. [8] BRODER, A., GLASSMAN, S., MANASSE, M., AND ZWEIG, G. Syntactic clustering of the web.",
                "In Proc. 6th International WWW Conference (1997). [9] CECCHET, E., CHANDA, A., ELNIKETY, S., MARGUERITE, J., AND ZWAENEPOEL, W. Performance comparison of middleware architectures for generating dynamic web content.",
                "In Proc.",
                "Fourth ACM/IFIP/USENIX International Middleware Conference (Rio de Janeiro, Brazil, June 2003). [10] CECCHET, E., MARGUERITE, J., AND ZWAENEPOEL, W. C-JDBC: Flexible database clustering middleware.",
                "In Proc. 2004 USENIX Annual Technical Conference (Boston, MA, June 2004). [11] COX, L. P., MURRAY, C. D., AND NOBLE, B. D. Pastiche: Making backup cheap and easy.",
                "In OSDI: Symposium on Operating Systems Design and Implementation (2002). [12] DABEK, F., KAASHOEK, M. F., KARGER, D., MORRIS, R., AND STOICA, I. Wide-area cooperative storage with CFS.",
                "In 18th ACM Symposium on Operating Systems Principles (Banff, Canada, Oct. 2001). [13] DRUSCHEL, P., AND ROWSTRON, A.",
                "PAST: A large-scale, persistent peer-to-peer storage utility.",
                "In HotOS VIII (Schloss Elmau, Germany, May 2001), pp. 75-80. [14] Edge side includes. http://www.esi.org. [15] GAO, L., DAHLIN, M., NAYATE, A., ZHENG, J., AND IYENGAR, A.",
                "Application specific data replication for edge services.",
                "In WWW 03: Proc.",
                "Twelfth International Conference on World Wide Web (2003), pp. 449-460. [16] HEMMINGER, S. Netem - emulating real networks in the lab.",
                "In Proc. 2005 Linux Conference Australia (Canberra, Australia, Apr. 2005). [17] HENSON, V. An analysis of compare-by-hash.",
                "In Proc. 9th Workshop on Hot Topics in Operating Systems (HotOS IX) (May 2003), pp. 13-18. [18] Jmob benchmarks. http://jmob.objectweb.org/. [19] LABRINIDIS, A., AND ROUSSOPOULOS, N. Balancing performance and data freshness in web database servers.",
                "In Proc. 29th VLDB Conference (Sept. 2003). [20] LARSON, P.-A., GOLDSTEIN, J., AND ZHOU, J. Transparent mid-tier database caching in sql server.",
                "In Proc. 2003 ACM SIGMOD (2003), pp. 661-661. [21] MANBER, U.",
                "Finding similar files in a large file system.",
                "In Proc.",
                "USENIX Winter 1994 Technical Conference (San Fransisco, CA, 17-21 1994), pp. 1-10. [22] MANJHI, A., AILAMAKI, A., MAGGS, B. M., MOWRY, T. C., OLSTON, C., AND TOMASIC, A.",
                "Simultaneous scalability and security for data-intensive web applications.",
                "In Proc. 2006 ACM SIGMOD (June 2006), pp. 241-252. [23] MENEZES, A. J., VANSTONE, S. A., AND OORSCHOT, P. C. V. Handbook of Applied Cryptography.",
                "CRC Press, 1996. [24] MILLER, R. B.",
                "Response time in man-computer conversational transactions.",
                "In Proc.",
                "AFIPS Fall Joint Computer Conference (1968), pp. 267-277. [25] MOGUL, J. C., CHAN, Y. M., AND KELLY, T. Design, implementation, and evaluation of duplicate transfer detection in http.",
                "In Proc.",
                "First Symposium on Networked Systems Design and Implementation (San Francisco, CA, Mar. 2004). [26] MUTHITACHAROEN, A., CHEN, B., AND MAZIERES, D. A low-bandwidth network file system.",
                "In Proc. 18th ACM Symposium on Operating Systems Principles (Banff, Canada, Oct. 2001). [27] PFEIFER, D., AND JAKSCHITSCH, H. Method-based caching in multi-tiered server applications.",
                "In Proc.",
                "Fifth International Symposium on Distributed Objects and Applications (Catania, Sicily, Italy, Nov. 2003). [28] PLATTNER, C., AND ALONSO, G. Ganymed: Scalable replication for transactional web applications.",
                "In Proc. 5th ACM/IFIP/USENIX International Conference on Middleware (2004), pp. 155-174. [29] QUINLAN, S., AND DORWARD, S. Venti: A new approach to archival storage.",
                "In Proc.",
                "FAST 2002 Conference on File and Storage Technologies (2002). [30] RABIN, M. Fingerprinting by random polynomials.",
                "In Harvard University Center for Research in Computing Technology Technical Report TR-15-81 (1981). [31] RABINOVICH, M., XIAO, Z., DOUGLIS, F., AND KALMANEK, C. Moving edge side includes to the real edge - the clients.",
                "In Proc. 4th USENIX Symposium on Internet Technologies and Systems (Seattle, WA, Mar. 2003). [32] REESE, G. Database Programming with JDBC and Java, 1st ed.",
                "OReilly, June 1997. [33] RHEA, S., LIANG, K., AND BREWER, E. Value-based web caching.",
                "In Proc.",
                "Twelfth International World Wide Web Conference (May 2003). [34] SIVASUBRAMANIAN, S., ALONSO, G., PIERRE, G., AND VAN STEEN, M. Globedb: Autonomic data replication for web applications.",
                "In WWW 05: Proc. 14th International World-Wide Web conference (May 2005). [35] SPRING, N. T., AND WETHERALL, D. A protocol-independent technique for eliminating redundant network traffic.",
                "In Proc. of ACM SIGCOMM (Aug. 2000). [36] TOLIA, N., HARKES, J., KOZUCH, M., AND SATYANARAYANAN, M. Integrating portable and distributed storage.",
                "In Proc. 3rd USENIX Conference on File and Storage Technologies (San Francisco, CA, Mar. 2004). [37] TOLIA, N., KOZUCH, M., SATYANARAYANAN, M., KARP, B., PERRIG, A., AND BRESSOUD, T. Opportunistic use of content addressable storage for distributed file systems.",
                "In Proc. 2003 USENIX Annual Technical Conference (San Antonio, TX, June 2003), pp. 127-140. [38] YUAN, C., CHEN, Y., AND ZHANG, Z.",
                "Evaluation of edge caching/offloading for dynamic content delivery.",
                "In WWW 03: Proc.",
                "Twelfth International Conference on World Wide Web (2003), pp. 461-471.",
                "WWW 2007 / Track: Performance and Scalability Session: Scalable Systems for Dynamic Content 320"
            ],
            "original_annotated_samples": [
                "Even when database content remains unchanged, <br>temporal locality</br> of access cannot be exploited because dynamic content is not cacheable by web browsers or by intermediate caching servers such as Akamai mirrors."
            ],
            "translated_annotated_samples": [
                "Incluso cuando el contenido de la base de datos permanece sin cambios, la <br>localidad temporal</br> de acceso no puede ser explotada porque el contenido dinámico no es almacenable en caché por los navegadores web o por servidores de almacenamiento en caché intermedios como los espejos de Akamai."
            ],
            "translated_text": "Conservación de la consistencia en el almacenamiento en caché de contenido dinámico de bases de datos∗ Niraj Tolia y M. Satyanarayanan Universidad Carnegie Mellon {ntolia,satya}@cs.cmu.edu RESUMEN Con el creciente uso de contenido web dinámico generado a partir de bases de datos relacionales, las soluciones de almacenamiento en caché tradicionales para mejorar el rendimiento y la latencia son ineficaces. Describimos una capa de middleware llamada Ganesh que reduce el volumen de datos transmitidos sin interpretación semántica de consultas o resultados. Se logra esta reducción mediante el uso de hash criptográficos para detectar similitudes con resultados anteriores. Estos beneficios no requieren ningún compromiso con la semántica de consistencia estricta proporcionada por la base de datos del servidor. Además, Ganesh no requiere modificaciones en aplicaciones, servidores web o servidores de bases de datos, y funciona con aplicaciones y bases de datos de código cerrado. Usando dos puntos de referencia representativos de sitios web dinámicos, las mediciones de nuestro prototipo muestran que puede aumentar el rendimiento de extremo a extremo hasta en un factor de dos para aplicaciones no intensivas en datos y hasta en un factor de diez para las intensivas en datos. Categorías y Descriptores de Asignaturas C.2.4 [Redes de Computadoras-Comunicación]: Sistemas Distribuidos; H.2.4 [Gestión de Bases de Datos]: Términos Generales de Sistemas de Diseño, Rendimiento 1. INTRODUCCIÓN Una fracción creciente del contenido web se genera dinámicamente a partir de bases de datos relacionales en el backend. Incluso cuando el contenido de la base de datos permanece sin cambios, la <br>localidad temporal</br> de acceso no puede ser explotada porque el contenido dinámico no es almacenable en caché por los navegadores web o por servidores de almacenamiento en caché intermedios como los espejos de Akamai. En una arquitectura multinivel, cada solicitud web puede tensionar el enlace WAN entre el servidor web y la base de datos. Esto provoca que la experiencia del usuario sea altamente variable porque no hay almacenamiento en caché para aislar al cliente de cargas repentinas. Los intentos previos de almacenar en caché contenido dinámico de bases de datos generalmente han debilitado la semántica transaccional [3, 4] o han requerido modificaciones en la aplicación [15, 34]. Informamos sobre una nueva solución que toma la forma de una capa intermedia de middleware independiente de la base de datos llamada Ganesh. Ganesh no hace ningún esfuerzo por interpretar semánticamente el contenido de las consultas o sus resultados. En cambio, se basa exclusivamente en el hash criptográfico para detectar similitudes con resultados anteriores. La detección de similitud basada en hash ha sido cada vez más utilizada en sistemas de archivos distribuidos [26, 36, 37] para mejorar el rendimiento en redes de baja capacidad de ancho de banda. Sin embargo, estas técnicas no se han utilizado para bases de datos relacionales. A diferencia de enfoques anteriores que utilizan métodos genéricos para detectar similitud, Ganesh explota la estructura de los resultados de la base de datos relacional para lograr una mejora superior en el rendimiento. Uno se enfrenta al menos a tres desafíos al aplicar la detección de similitud basada en hash a las bases de datos de back-end. Primero, el trabajo previo en este ámbito ha considerado tradicionalmente el contenido de almacenamiento como bolsas de bits no interpretadas y sin estructura interna. Esto permite que las técnicas basadas en hash operen en largas y contiguas secuencias de datos para lograr la máxima efectividad. Por el contrario, las bases de datos relacionales tienen una estructura interna compleja que puede no ser tan propicia para la detección de similitudes basada en hash. Segundo, las bases de datos relacionales tienen restricciones de integridad y consistencia muy estrictas que no deben comprometerse por el uso de técnicas basadas en hash. Tercero, el código fuente de las bases de datos comerciales generalmente no está disponible. Esto contrasta con trabajos anteriores que presumían la disponibilidad del código fuente. Nuestros experimentos muestran que Ganesh, aunque conceptualmente simple, puede mejorar significativamente el rendimiento en anchos de banda representativos del Internet comercial actual. En los modelos de referencia de aplicaciones web multinivel, la mejora en el rendimiento fue de hasta diez veces para cargas de trabajo intensivas en datos. Para cargas de trabajo que no eran intensivas en datos, se observaron mejoras en el rendimiento de hasta el doble. Incluso cuando el ancho de banda no era una limitación, Ganesh tenía un bajo sobrecosto y no afectaba el rendimiento. Nuestros experimentos también confirman que aprovechar la estructura presente en los resultados de la base de datos es crucial para esta mejora en el rendimiento. Antecedentes 2.1 Generación de Contenido Dinámico A medida que la World Wide Web ha crecido, muchos sitios web han descentralizado sus datos y funcionalidades al llevarlos a los extremos de Internet. Hoy en día, los sistemas de comercio electrónico a menudo utilizan una arquitectura de tres niveles que consta de un servidor web de front-end, un servidor de aplicaciones y un servidor de base de datos de back-end. La Figura 1 ilustra esta arquitectura. Los dos primeros niveles se pueden replicar cerca de una concentración de clientes en el borde de Internet. Esto mejora la experiencia del usuario al reducir la latencia de extremo a extremo y disminuir la exposición al congestionamiento del tráfico de la columna vertebral. También puede aumentar la disponibilidad y escalabilidad de los servicios web. El contenido que se genera dinámicamente desde la base de datos del servidor no puede ser almacenado en caché en los dos primeros niveles. Si bien las bases de datos pueden replicarse fácilmente en una LAN, esto es inviable en una WAN debido a la difícil tarea de proporcionar simultáneamente una consistencia sólida, disponibilidad y tolerancia a particiones de red [7]. Como resultado, las bases de datos tienden a ser centralizadas para cumplir con los fuertes requisitos de consistencia de muchas aplicaciones de comercio electrónico como la banca, las finanzas y la venta al por menor en línea [38]. Por lo tanto, la base de datos del back-end suele estar ubicada lejos de muchos conjuntos de nodos de primer y segundo nivel [2]. En ausencia de almacenamiento en caché y replicación, el ancho de banda de la WAN puede convertirse fácilmente en un factor limitante en el rendimiento y la escalabilidad de aplicaciones intensivas en datos. El enfoque de Ganesh en los sistemas basados en hash es la transmisión eficiente de resultados al descubrir similitudes con los resultados de consultas anteriores. Dado que las consultas SQL pueden generar resultados grandes, las técnicas basadas en hash se prestan bien al problema de transferir eficientemente estos grandes resultados a través de enlaces con ancho de banda limitado. El uso de técnicas basadas en hash para reducir el volumen de datos transmitidos ha surgido como un tema común en muchos sistemas de almacenamiento recientes, como se discute en la Sección 8.2. Estas técnicas se basan en algunas suposiciones básicas. Se asume que las funciones hash criptográficas son resistentes a colisiones. En otras palabras, es computacionalmente intratable encontrar dos entradas que se hash a la misma salida. Las funciones también se asumen como unidireccionales; es decir, encontrar una entrada que resulte en una salida específica es computacionalmente inviable. Menezes et al. [23] proporcionan más detalles sobre estas suposiciones. Las suposiciones anteriores permiten a los sistemas basados en hash asumir que no se producen colisiones. Por lo tanto, pueden tratar el hash de un elemento de datos como su identificador único. Una colección de elementos de datos se convierte efectivamente en direccionable por contenido, permitiendo que un hash pequeño funcione como una palabra de código para un elemento de datos mucho más grande en almacenamiento permanente o transmisión en red. La suposición de que las colisiones son tan raras que prácticamente no existen ha sido cuestionada recientemente [17]. Sin embargo, como explicó Black [5], creemos que estos problemas no son una preocupación para Ganesh. Toda comunicación es entre partes confiables del sistema y un adversario no tiene forma de obligar a Ganesh a aceptar datos inválidos. Además, Ganesh no depende críticamente de ninguna función hash específica. Si bien actualmente usamos SHA-1, reemplazarlo con una función hash diferente sería sencillo. No habría impacto en el rendimiento con funciones hash más fuertes (por ejemplo, SHA256) solo añade unos pocos bytes adicionales y los hashes generados siguen siendo órdenes de magnitud más pequeños que los elementos de datos que representan. No es necesario volver a almacenar permanentemente ya que Ganesh solo utiliza el hash en datos volátiles. 3. DISEÑO E IMPLEMENTACIÓN Ganesh explota la redundancia en el flujo de resultados para evitar transmitir fragmentos de resultados que ya están presentes en el sitio de la consulta. La redundancia puede surgir de forma natural de muchas maneras diferentes. Por ejemplo, una consulta repetida después de un cierto intervalo puede devolver un resultado diferente debido a actualizaciones en la base de datos; sin embargo, puede haber una significativa similitud entre los dos resultados. Como otro ejemplo, un usuario que está refinando una búsqueda puede generar una secuencia de consultas con resultados superpuestos. Cuando Ganesh detecta redundancia, suprime la transmisión de los fragmentos de resultado correspondientes. En cambio, transmite un resumen mucho más pequeño de esos fragmentos y permite que el sitio de consulta reconstruya el resultado a través de la búsqueda de hash en una caché de resultados anteriores. De hecho, Ganesh utiliza la computación en los bordes para reducir la comunicación por Internet. Nuestra descripción de Ganesh se centra en cuatro aspectos. Primero explicamos nuestro enfoque para detectar similitud en los resultados de la consulta. A continuación, discutimos cómo la arquitectura Ganesh es completamente invisible para todos los componentes de un sistema de múltiples niveles. Luego describimos el enfoque basado en proxy de Ganesh y el flujo de datos para detectar similitudes. 3.1 Detectar similitud Una de las decisiones clave de diseño en Ganesh es cómo se detecta la similitud. Hay muchas formas potenciales de descomponer un resultado en fragmentos.  I the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the thees I,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,, Encontrar esta descomposición óptima es un problema difícil debido al amplio espacio de posibilidades y porque la elección óptima depende de muchos factores, como el contenido del resultado de las consultas, el historial de resultados recientes y el algoritmo de gestión de caché. Cuando un objeto es opaco, el uso de huellas digitales de Rabin [8, 30] para detectar datos comunes entre dos objetos ha sido demostrado con éxito en el pasado por sistemas como LBFS [26] y CASPER [37]. El fingerprinting de Rabin utiliza una ventana deslizante sobre los datos para calcular un hash rodante. Suponiendo que la función hash está distribuida uniformemente, un límite de fragmento se define cuando los bits de orden inferior del valor hash son iguales a algún valor predeterminado. El número de bits de orden inferior utilizados define el tamaño promedio del fragmento. Estos fragmentos subdivididos del objeto se convierten en la unidad de comparación para detectar similitudes entre diferentes objetos. Dado que las ubicaciones de los límites encontrados mediante el uso de las huellas de Rabin están determinadas de manera estocástica, generalmente no logran alinearse con ninguna propiedad estructural de los datos subyacentes. Por lo tanto, el algoritmo maneja bien las actualizaciones en su lugar, inserciones y eliminaciones. Sin embargo, tiene un rendimiento deficiente en presencia de cualquier reordenamiento de datos. La Figura 2 muestra un ejemplo donde dos resultados, A y B, que constan de tres filas, tienen los mismos datos pero diferentes atributos de ordenamiento. En el caso extremo, la huella digital de Rabin podría no ser capaz de encontrar datos similares debido a la forma en que detecta los límites de los fragmentos. Afortunadamente, Ganesh puede utilizar conocimientos específicos del dominio para una detección de límites más precisa. La información que explotamos es que el resultado de una consulta refleja la estructura de una base de datos relacional donde todos los datos están organizados en tablas y filas. Por lo tanto, es sencillo verificar la similitud con resultados anteriores en dos niveles de granularidad: primero el resultado completo y luego las filas individuales. El final de una fila en un resultado sirve como un límite natural de fragmento. Es importante tener en cuenta que el uso de la estructura tabular en los resultados solo implica una interpretación superficial de los datos. Ganesh no realiza ninguna interpretación semántica más profunda, como comprender tipos de datos, esquemas de resultados o restricciones de integridad. Ajustar la huella digital de Rabin para una carga de trabajo también puede ser difícil. Si el tamaño promedio de los fragmentos es demasiado grande, los fragmentos pueden abarcar varias filas de resultados. Sin embargo, seleccionar un tamaño de fragmento promedio más pequeño aumenta la cantidad de metadatos necesarios para describir los resultados. Esto, a su vez, disminuiría los ahorros obtenidos mediante su uso. El fingerprinting de Rabin también requiere dos pasadas computacionalmente costosas sobre los datos: una vez para determinar los límites de los fragmentos y otra vez para generar hashes criptográficos para los fragmentos. Ganesh solo necesita un único pase para la generación de hash, ya que los límites de los fragmentos son proporcionados por la estructura natural de los datos. La comparación de rendimiento en la Sección 6 muestra que el algoritmo basado en filas de Ganesh supera al fingerprinting de Rabin. Dado que trabajos anteriores ya han demostrado que la huella digital de Rabin funciona mejor que gzip [26], no comparamos a Ganesh con algoritmos de compresión en este artículo. 3.2 Transparencia El factor clave que influyó en nuestro diseño fue la necesidad de que Ganesh fuera completamente transparente para todos los componentes de un sistema típico de comercio electrónico: servidores web, servidores de aplicaciones y servidores de bases de datos. Sin esto, Ganesh tiene pocas posibilidades de tener un impacto significativo en el mundo real. Requerir modificaciones en cualquiera de los componentes mencionados aumentaría la barrera de entrada de Ganesh en un sistema existente, y por lo tanto reduciría sus posibilidades de adopción. Preservar la transparencia se simplifica por el hecho de que Ganesh es simplemente una mejora de rendimiento, no una mejora de funcionalidad o usabilidad. Elegimos la interposición de agentes como enfoque arquitectónico para lograr nuestro objetivo. Este enfoque se basa en la existencia de una interfaz de programación compacta que ya es ampliamente utilizada por el software objetivo. También se basa en un mecanismo para agregar fácilmente nuevo código sin interrumpir la estructura de módulos existente. Estas condiciones se cumplen fácilmente en nuestro contexto debido a la popularidad de Java como el lenguaje de programación para sistemas de comercio electrónico. La API de Conectividad de Base de Datos de Java (JDBC) [32] permite a las aplicaciones de Java acceder a una amplia variedad de bases de datos e incluso a otros repositorios de datos tabulares como archivos planos. El acceso a estas fuentes de datos es proporcionado por controladores JDBC que traducen entre la API JDBC y el mecanismo de comunicación de la base de datos. La figura 3(a) muestra cómo se utiliza típicamente JDBC en una aplicación. Dado que la interfaz JDBC está estandarizada, se puede sustituir un controlador JDBC por otro sin necesidad de de modificar la aplicación. El controlador JDBC se convierte así en el módulo natural para aprovechar la interposición de código. Como se muestra en la Figura 3(b), el controlador JDBC nativo es reemplazado por un controlador JDBC Ganesh que presenta la misma interfaz estandarizada. El controlador Ganesh mantiene una caché en memoria de fragmentos de resultados de consultas anteriores y realiza el reensamblaje de resultados. En la base de datos, agregamos un nuevo proceso llamado el proxy Ganesh. Este proxy, que puede ser compartido por múltiples nodos front-end, consta de dos partes: código para detectar similitud en fragmentos de resultados y el controlador JDBC nativo original que se comunica con la base de datos. El uso de un proxy en la base de datos hace que Ganesh sea independiente de la base de datos y simplifica la creación de prototipos y experimentación. Ganesh es capaz de trabajar con una amplia gama de bases de datos y aplicaciones, sin necesidad de realizar modificaciones en ninguna de ellas. 3.3 Caché basada en proxy El controlador JDBC nativo mostrado en la Figura 3(a) es un componente de código ligero suministrado por el proveedor de la base de datos. Su función principal es mediar la comunicación entre la aplicación y la base de datos remota. Reenvía consultas, almacena resultados completos y responde a solicitudes de la aplicación para ver partes de los resultados. El controlador JDBC de Ganesh mostrado en la Figura 3(b) presenta a la aplicación una interfaz idéntica a la proporcionada por el controlador nativo. Proporciona la capacidad de reconstruir resultados a partir de descripciones compactas basadas en hash enviadas por el proxy. Para realizar esta reconstrucción, el controlador mantiene una caché en memoria de los resultados recibidos recientemente. Esta caché solo se utiliza como fuente de fragmentos de resultados en la reconstrucción de resultados. El conductor Ganesh o el proxy no intentan rastrear las actualizaciones de la base de datos. La falta de consistencia en la caché no afecta a la corrección, ya que la descripción de los resultados siempre se obtiene del proxy; en el peor de los casos, no habrá beneficio de rendimiento al usar Ganesh. Los datos obsoletos simplemente se eliminarán de la caché con el tiempo. El proxy de Ganesh accede a la base de datos a través del controlador JDBC nativo, que permanece sin cambios entre las Figuras 3(a) y (b). La base de datos está completamente ajena a la existencia del proxy. El proxy no examina ninguna consulta recibida del controlador Ganesh, sino que las pasa al controlador nativo. En cambio, el proxy es responsable de inspeccionar la salida de la base de datos recibida del controlador nativo, detectar resultados similares y generar codificaciones basadas en hash de estos resultados siempre que se encuentre suficiente similitud. Si bien esta arquitectura no disminuye la carga en una base de datos, como se mencionó anteriormente en la Sección 2.1, es mucho más fácil replicar bases de datos para escalabilidad en una LAN que en una WAN. Para generar una codificación basada en hash, el proxy debe estar al tanto de qué fragmentos de resultados están disponibles en la caché de controladores de Ganesh. Un enfoque es ser optimista y asumir que todos los fragmentos de resultados están disponibles. Esto resultará en la transmisión inicial más pequeña posible de un resultado. Sin embargo, en casos donde hay poca superposición con resultados anteriores, el controlador Ganesh tendrá que realizar muchas llamadas al proxy durante la reconstrucción para recuperar fragmentos de resultados faltantes. Para evitar esta situación, el proxy sigue de manera flexible el estado de la caché de controladores de Ganesh. Dado que ambos componentes están bajo nuestro control, es relativamente sencillo hacer esto sin recurrir a técnicas de caja gris o comunicación explícita para mantener la coherencia de la caché. En cambio, el proxy simula el algoritmo de gestión de caché de controladores de Ganesh y lo utiliza para mantener una lista de hashes para los cuales es probable que el controlador de Ganesh posea los fragmentos de resultado. En caso de desviación de seguimiento, no habrá pérdida de corrección, pero habrá retrasos adicionales en el viaje de ida y vuelta para recuperar los fragmentos faltantes. Si el cliente detecta la pérdida de sincronización con el proxy, puede pedirle al proxy que restablezca el estado compartido entre ellos. También hay que tener en cuenta que el proxy no necesita guardar los fragmentos de resultado en sí, solo sus hashes. Esto permite que el proxy siga siendo escalable incluso cuando es compartido por muchos nodos front-end. El proxy Ganesh recibe la salida de la base de datos como objetos Java del controlador JDBC nativo. Examina esta salida para ver si está presente un objeto Java del tipo ResultSet. La interfaz JDBC utiliza este tipo de dato para almacenar los resultados de las consultas a la base de datos. Si se encuentra un objeto ResultSet, se reduce como se discute a continuación. Todos los demás objetos de Java se pasan sin modificar. Como se discute en la Sección 3.1, el proxy utiliza los límites de fila definidos en el ResultSet para dividirlo en fragmentos que consisten en filas de resultado individuales. Todos los objetos ResultSet se convierten en objetos de un nuevo tipo llamado RecipeResultSet. Utilizamos el término receta para esta descripción compacta de un resultado de base de datos debido a su similitud con una receta de archivo en el sistema de archivos CASPER [37]. La conversión reemplaza cada fragmento de resultado que probablemente esté presente en la caché de controladores de Ganesh por un hash SHA-1 de ese fragmento. Los fragmentos de resultados previamente no vistos se conservan textualmente. El proxy también retiene los hashes de los nuevos fragmentos de resultados, ya que estarán presentes en la caché de los controladores en el futuro. Ten en cuenta que el proxy solo almacena en caché los hashes de los fragmentos de resultados y no almacena en caché las recetas. El proxy construye un RecipeResultSet verificando la similitud en todo el resultado y luego a nivel de fila. Si se predice que todo el resultado estará presente en la caché de los controladores de Ganesh, el RecipeResultSet será simplemente un único hash de todo el resultado. De lo contrario, contiene hashes para aquellas filas que se predice que están presentes en esa caché; todas las demás filas se conservan textualmente. Si el proxy estima un ahorro de espacio general, transmitirá el RecipeResultSet. De lo contrario, se transmite el ResultSet original. Los objetos RecipeResultSet son transformados de vuelta en objetos ResultSet por el controlador Ganesh. La Figura 4 ilustra el manejo de ResultSet en ambos extremos. Cada hash SHA-1 encontrado en un RecipeResultSet se busca en la caché local de fragmentos de resultados. En caso de acierto, el hash es reemplazado por el fragmento correspondiente. En caso de error, el conductor contacta al proxy de Ganesh para recuperar el fragmento. Todos los fragmentos de resultados previamente no vistos que fueron retenidos textualmente por el proxy se hasheado y se han añadido a la caché de resultados. Debería haber muy pocos fallos si el proxy ha seguido con precisión el estado de la caché de controladores de Ganesh. Una optimización futura sería agrupar la obtención de fragmentos faltantes. Esto sería valioso cuando hay muchos pequeños fragmentos faltantes en una WAN de alta latencia. Una vez que la transformación esté completa, el objeto ResultSet completamente reconstruido se pasa a la aplicación. 4. VALIDACIÓN EXPERIMENTAL Tres preguntas surgen de los objetivos y diseño de Ganesh: • Primero, ¿se puede mejorar significativamente el rendimiento al explotar la similitud entre los resultados de la base de datos? Detalles del conjunto de datos de referencia 500,000 usuarios, 12,000 historias BBOARD 2.0 GB 3,298,000 comentarios SUBASTA 1.3 GB 1,000,000 usuarios, 34,000 elementos Tabla 1: Detalles del conjunto de datos de referencia • En segundo lugar, ¿qué tan importante es la detección de similitud estructural de Ganesh en comparación con la detección de similitud de la huella digital de Rabin? • En tercer lugar, ¿es aceptable la sobrecarga del diseño basado en proxy? Nuestra evaluación responde a estas preguntas a través de experimentos controlados con el prototipo Ganesh. Esta sección describe los puntos de referencia utilizados, nuestro procedimiento de evaluación y la configuración experimental. Los resultados de los experimentos se presentan en las Secciones 5, 6 y 7. 4.1 Puntos de referencia Nuestra evaluación se basa en dos puntos de referencia [18] que han sido ampliamente utilizados por otros investigadores para evaluar varios aspectos de arquitecturas multi-tier [27] y de comercio electrónico [9]. El primer punto de referencia, BBOARD, está modelado según Slashdot, un sitio de noticias orientado a la tecnología. El segundo punto de referencia, AUCTION, está modelado según eBay, un sitio de subastas en línea. En ambos puntos de referencia, la mayoría del contenido se genera dinámicamente a partir de la información almacenada en una base de datos. Los detalles de los conjuntos de datos utilizados se pueden encontrar en la Tabla 1. 4.1.1 El Benchmark BBOARD El benchmark BBOARD, también conocido como RUBBoS [18], modela Slashdot, un popular sitio web orientado a la tecnología. Slashdot recopila enlaces a noticias y otros temas de interés encontrados en otros lugares de la web. El sitio también funciona como un tablón de anuncios al permitir a los usuarios comentar en las historias publicadas en forma de conversación en hilos. No es raro que una historia recopile cientos de comentarios en cuestión de horas. El benchmark BBOARD es similar al sitio y modela las actividades de un usuario, incluyendo operaciones de solo lectura como navegar por las historias del día, explorar categorías de historias y ver comentarios, así como operaciones de escritura como registro de nuevos usuarios, agregar y moderar comentarios, y enviar historias. El benchmark consiste en tres fases diferentes: una fase de calentamiento corta, una fase de ejecución que representa el cuerpo principal de la carga de trabajo, y una fase de enfriamiento corta. En este documento solo informamos sobre los resultados de la fase de ejecución. La fase de calentamiento es importante para establecer el estado del sistema dinámico, pero las mediciones de esa fase no son significativas para nuestra evaluación. La fase de enfriamiento es únicamente para permitir que el punto de referencia se apague. Las fases de calentamiento, ejercicio y enfriamiento son de 2, 15 y 2 minutos respectivamente. El número de clientes simulados fue de 400, 800, 1200 y 1600. El punto de referencia está disponible en una versión de Java Servlets y PHP y tiene diferentes conjuntos de datos; evaluamos a Ganesh utilizando la versión de Java Servlets y el conjunto de datos Expandido. El benchmark BBOARD define dos cargas de trabajo diferentes. El primero, la mezcla de Autoría, consiste en un 70% de operaciones de solo lectura y un 30% de operaciones de lectura y escritura. El segundo, la mezcla de navegación, contiene solo operaciones de solo lectura y no actualiza la base de datos. 4.1.2 El Benchmark de SUBASTA El benchmark de SUBASTA, también conocido como RUBiS [18], modela eBay, el sitio de subastas en línea. El sitio web de eBay se utiliza para comprar y vender artículos a través de un formato de subasta. Las principales actividades de un usuario incluyen navegar, vender o pujar por artículos. Modelando las actividades en este sitio, este punto de referencia incluye actividades de solo lectura como navegar por artículos por categoría y por región, así como actividades de lectura-escritura como pujar por artículos, comprar y vender artículos, y dejar comentarios. Al igual que con BBOARD, el benchmark consiste en tres fases diferentes. Las fases de calentamiento, ejecución y enfriamiento para este experimento son de 1.5, 15 y 1 minutos respectivamente. Probamos Ganesh con cuatro configuraciones de clientes donde el número de clientes de prueba se estableció en 400, 800, 1200 y 1600. El punto de referencia está disponible en una versión de Enterprise Java Bean (EJB), Java Servlets y PHP y tiene diferentes conjuntos de datos; evaluamos Ganesh con la versión de Java Servlets y el conjunto de datos Expandido. El benchmark de SUBASTA define dos cargas de trabajo diferentes. El primero, la mezcla de Ofertas, consiste en un 70% de operaciones de solo lectura y un 30% de operaciones de lectura-escritura. El segundo, la mezcla de navegación, contiene solo operaciones de solo lectura y no actualiza la base de datos. 4.2 Procedimiento Experimental Ambos benchmarks involucran una carga de trabajo sintética de clientes accediendo a un servidor web. El número de clientes emulados es un parámetro experimental. Cada cliente emulado ejecuta una instancia del benchmark en su propio hilo, utilizando una matriz para hacer la transición entre diferentes estados del benchmark. La matriz define un modelo estocástico con probabilidades de transición entre los diferentes estados que representan las acciones típicas de los usuarios. Un ejemplo de transición es un usuario iniciando sesión en el sistema de SUBASTA y luego decidiendo si publicar un artículo en venta o pujar en subastas activas. Cada cliente también modela el tiempo de pensamiento del usuario entre las solicitudes. El tiempo de pensamiento se modela como una distribución exponencial con una media de 7 segundos. Evaluamos a Ganesh a lo largo de dos ejes: número de clientes y ancho de banda de la WAN. Las cargas más altas son especialmente útiles para comprender el rendimiento de Ganesh cuando la CPU o el disco del servidor de base de datos o del proxy son el factor limitante. Un estudio previo ha demostrado que aproximadamente el 50% de los cuellos de botella de Internet de gran área observados tenían un ancho de banda disponible inferior a 10 Mb/s [1]. Basándonos en este trabajo, enfocamos nuestra evaluación en el ancho de banda de la WAN de 5 Mb/s con una latencia de ida y vuelta de 66 ms, representativa de rutas de red severamente restringidas, y 20 Mb/s con una latencia de ida y vuelta de 33 ms, representativa de una ruta de red moderadamente restringida. También informamos sobre el rendimiento de Ganesh a 100 Mb/s sin agregar latencia de ida y vuelta. Este ancho de banda, representativo de una red sin restricciones, es especialmente útil para revelar cualquier sobrecarga potencial de Ganesh en situaciones donde el ancho de banda de la WAN no es el factor limitante. Para cada combinación de número de clientes y ancho de banda de WAN, medimos los resultados de las dos configuraciones enumeradas a continuación: • Nativa: Esta configuración corresponde a la Figura 3(a). El nativo evita la sobrecarga de Ganesh al usar un proxy y realizar la serialización de objetos Java. • Ganesh: Esta configuración corresponde a la Figura 3(b). Para un número dado de clientes y ancho de banda de WAN, comparar estos resultados con los resultados nativos correspondientes proporciona el beneficio de rendimiento debido al sistema de middleware Ganesh. La métrica utilizada para cuantificar la mejora en el rendimiento es el número de solicitudes de clientes que pueden ser atendidas por segundo. La métrica utilizada para cuantificar el rendimiento de Ganesh es el tiempo promedio de respuesta para una solicitud de cliente. Para todos los experimentos, el controlador Ganesh utilizado por el servidor de aplicaciones usó un tamaño de caché de 100,000 elementos. El proxy fue efectivo en rastrear el estado de la caché de los controladores Ganesh; para todos nuestros experimentos, la tasa de fallos en el controlador nunca superó el 0.7%. 4.3 Configuración Experimental La configuración experimental utilizada para las pruebas se puede ver en la Figura 5. Todas las máquinas eran Pentium 4 de 3.2 GHz (con HyperThreading habilitado). Con la excepción del servidor de base de datos, todas las máquinas tenían 2 GB de SDRAM y ejecutaban la distribución de Linux Fedora Core. El servidor de la base de datos tenía 4 GB de SDRAM. Utilizamos Apache Tomcat como tanto el servidor de aplicaciones que alojaba los Servlets de Java como el servidor web. Ambos benchmarks utilizaron Java Servlets para generar el contenido dinámico. El servidor de la base de datos utilizó la base de datos de código abierto MySQL. Para los controladores JDBC nativos, utilizamos los controladores Connector/J proporcionados por MySQL. El servidor de aplicaciones utilizaba la Máquina Virtual de Java de Sun como entorno de ejecución para los Servlets de Java. La herramienta sysstat se utilizó para monitorear la utilización de la CPU, red, disco y memoria en todas las máquinas. Las máquinas estaban conectadas por una red Ethernet gigabit conmutada. Como se muestra en la Figura 5, el servidor web y de aplicación de front-end fue separado del servidor de proxy y base de datos por un enrutador NetEm [16]. Este enrutador nos permitió controlar la configuración de ancho de banda y latencia en la red. El enrutador NetEm es un PC estándar con dos tarjetas de red que ejecuta el software de Control de Tráfico de Linux y Emulación de Red. Las restricciones de ancho de banda y latencia solo se aplicaron al enlace entre el servidor de aplicaciones y la base de datos para el caso nativo y entre el servidor de aplicaciones y el proxy para el caso de Ganesh. No hay comunicación entre el servidor de aplicaciones y la base de datos con Ganesh, ya que todos los datos fluyen a través del proxy. Como nuestro enfoque estaba en el enlace WAN entre el servidor de aplicaciones y la base de datos, no hubo restricciones en el enlace entre los clientes de prueba simulados y el servidor web. 5. DESEMPEÑO Y TIEMPO DE RESPUESTA En esta sección, abordamos la primera pregunta planteada en la Sección 4: ¿Se puede mejorar significativamente el rendimiento explotando la similitud entre los resultados de la base de datos? Para responder a esta pregunta, utilizamos los resultados de los benchmarks BBOARD y AUCTION. Utilizamos dos métricas para cuantificar la mejora en el rendimiento obtenible a través del uso de Ganesh: el throughput, desde la perspectiva del servidor web, y el tiempo de respuesta promedio, desde la perspectiva del cliente. El rendimiento se mide en términos del número de solicitudes de clientes que pueden ser atendidas por segundo. Los resultados y análisis de BBOARD 5.1 Figuras 6 (a) y (b) presentan el número promedio de solicitudes atendidas por segundo y el tiempo de respuesta promedio para estas solicitudes tal como lo perciben los clientes para la Mezcla de Autoría de BBOARD. Como muestra la Figura 6 (a), Native satura fácilmente el enlace de 5 Mb/s. Con 400 clientes, la solución nativa entrega 29 solicitudes/segundo con un tiempo de respuesta promedio de 8.3 segundos. La capacidad de procesamiento de los clientes disminuye con un aumento en los clientes de prueba, ya que los clientes se agotan debido a la congestión en el servidor de aplicaciones. Los estudios de usabilidad han demostrado que los tiempos de respuesta superiores a 10 segundos hacen que el usuario pase a 1. Dado que Java carece de un operador sizeof(), los cachés de Java limitan su tamaño en función del número de objetos. El tamaño de los volcados de caché tomados al final de los experimentos nunca superó los 212 MB. WWW 2007 / Pista: Rendimiento y Escalabilidad Sesión: Sistemas Escalables para Contenido Dinámico 315 0 50 100 150 200 250 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Solicitudes de Clientes de Prueba por Segundo Nativo Ganesh 0.001 0.01 0.1 1 10 100 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Tiempo Promedio de Respuesta de Clientes de Prueba Nativo Ganesh Nota Escala Logarítmica (a) Rendimiento: Mezcla de Autoría (b) Tiempo de Respuesta: Mezcla de Autoría 0 50 100 150 200 250 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Solicitudes de Clientes de Prueba por Segundo Nativo Ganesh 0.001 0.01 0.1 1 10 100 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Tiempo Promedio de Respuesta de Clientes de Prueba Nativo Ganesh Nota Escala Logarítmica (c) Rendimiento: Mezcla de Navegación (d) Tiempo de Respuesta: Mezcla de Navegación Promedio de tres pruebas. La desviación estándar máxima para el rendimiento y el tiempo de respuesta fue del 9.8% y 11.9% de la media correspondiente. Figura 6: BBOARD Benchmark - Rendimiento y Tiempo de Respuesta Promedio de otras tareas [24]. Basándose en estos números, aumentar el número de clientes de prueba hace que el sistema Nativo sea inutilizable. Ganesh a 5 Mb/s, sin embargo, ofrece una mejora doble con 400 clientes de prueba y una mejora quintuple con 1200 clientes. El rendimiento de Ganesh disminuye ligeramente a 1200 y 1600 clientes debido a que la red está saturada. En comparación con Native, la Figura 6 (b) muestra que los tiempos de respuesta de Ganesh son considerablemente más bajos con tiempos de respuesta de menos de un segundo con 400 clientes. La Figura 6 (a) también muestra que para 400 y 800 clientes de prueba, Ganesh a 5 Mb/s tiene el mismo rendimiento y tiempo de respuesta promedio que Native a 20 Mb/s. Solo con 1200 y 1600 clientes, Native a 20 Mb/s ofrece un rendimiento mayor que Ganesh a 5 Mb/s. Al comparar tanto a Ganesh como a Native a 20 Mb/s, vemos que Ganesh ya no está limitado por el ancho de banda y ofrece hasta una mejora del doble sobre Native con 1600 clientes de prueba. Como Ganesh no satura la red con configuraciones de cliente de prueba más altas, con 1600 clientes de prueba, su tiempo de respuesta promedio es de 0.1 segundos en lugar de los 7.7 segundos de Natives. Como era de esperar, no hay ganancias visibles de Ganesh en el ancho de banda más alto de 100 Mb/s donde la red ya no es el cuello de botella. Sin embargo, Ganesh sigue monitoreando a Native en cuanto a rendimiento. Las Figuras 6 (c) y (d) presentan el número promedio de solicitudes atendidas por segundo y el tiempo de respuesta promedio para estas solicitudes tal como lo perciben los clientes para la Mezcla de Navegación de BBOARDs. Independientemente de la configuración del cliente de prueba, la Figura 6 (c) muestra que el rendimiento de los Nativos a 5 Mb/s está limitado a 10 reqs/seg. Ganesh a 5 Mb/s con 400 clientes de prueba, ofrece un aumento de más de seis veces en el rendimiento. La mejora aumenta a más de once veces a 800 clientes de prueba antes de que Ganesh sature la red. Además, la Figura 6 (d) muestra que el tiempo de respuesta promedio de los Nativos de 35 segundos con 400 clientes de prueba hace que el sistema sea inutilizable. Estos altos tiempos de respuesta aumentan aún más con la adición de clientes de prueba. Incluso con la configuración del cliente de prueba de 1600, Ganesh ofrece un tiempo de respuesta promedio aceptable de 8.2 segundos. Debido a la naturaleza intensiva en datos de la mezcla de navegación, Ganesh a 5 Mb/s sorprendentemente tiene un rendimiento mucho mejor que Native a 20 Mb/s. Además, como se muestra en la Figura 6 (d), si bien el tiempo de respuesta promedio para Native a 20 Mb/s es aceptable con 400 clientes de prueba, resulta inutilizable con 800 clientes de prueba, con un tiempo de respuesta promedio de 15.8 segundos. Al igual que en el caso de 5 Mb/s, este tiempo de respuesta aumenta con la adición de clientes de prueba adicionales. Ganesh a 20 Mb/s y tanto Native como Ganesh a 100 Mb/s no tienen limitaciones de ancho de banda. Sin embargo, el rendimiento se estanca después de 1200 clientes de prueba debido a que la CPU de la base de datos está saturada. 5.1.3 Variante de filtro Nos sorprendió el rendimiento nativo del benchmark BBOARD. A una velocidad de banda ancha de 5 Mb/s, el rendimiento nativo fue más bajo de lo que esperábamos. Resultó que el código de referencia que muestra historias leía todos los comentarios asociados con la historia en particular de la base de datos y solo entonces realizaba un postprocesamiento para seleccionar los comentarios que se mostrarían. Si bien este es exactamente el comportamiento de SlashCode, la base de código detrás del sitio web de Slashdot, decidimos modificar la prueba de rendimiento para realizar cierto prefiltrado en la base de datos. Este benchmark modificado, llamado el Filtro de Variantes, modela a un desarrollador que aplica optimizaciones a nivel de SQL para transferir menos datos. En aras de la brevedad, solo resumimos brevemente los resultados de la mezcla de autores. Para la mezcla de Autoría, con 800 clientes de prueba a 5 Mb/s, la Figura 7 (a) muestra que el rendimiento de Natives aumenta un 85% en comparación con el punto de referencia original, mientras que la mejora de Ganesh es menor, del 15%. El rendimiento de los servidores disminuye por encima de los 800 clientes, ya que los clientes de prueba se agotan debido a los altos tiempos de respuesta. La ganancia más significativa para Native se observa a 20 Mb/s. En 1600 clientes de prueba, en comparación con el punto de referencia original, Native experimenta una mejora del 73% en el rendimiento y una reducción del 77% en el tiempo de respuesta promedio. Mientras WWW 2007 / Pista: Rendimiento y Escalabilidad Sesión: Sistemas Escalables para Contenido Dinámico 316 0 50 100 150 200 250 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Clientes de Prueba Solicitudes/seg Nativo Ganesh 0.001 0.01 0.1 1 10 100 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Clientes de Prueba Tiempo de Resp. Promedio (seg) Nativo Ganesh Nota Escala Logarítmica (a) Rendimiento: Mezcla de Autoría (b) Tiempo de Respuesta: Mezcla de Autoría Promedio de tres pruebas. La desviación estándar máxima para el rendimiento y el tiempo de respuesta fue del 7.2% y del 11.5% de la media correspondiente. Figura 7: BBOARD Benchmark - Variante de filtro - Rendimiento y Tiempo de Respuesta Promedio Ganesh no observa ninguna mejora en comparación con el original, aún procesa un 19% más de solicitudes/seg que Native. Por lo tanto, aunque las optimizaciones fueron más útiles para Native, Ganesh todavía ofrece una mejora en el rendimiento. 5.2 Resultados y Análisis de la SUBASTA 5.2.1 Figuras de la Mezcla de Ofertas Los gráficos 8 (a) y (b) presentan el número promedio de solicitudes atendidas por segundo y el tiempo de respuesta promedio para estas solicitudes tal como son percibidas por los clientes para la Mezcla de Ofertas de las SUBASTAS. Como se mencionó anteriormente, la mezcla de ofertas consiste en una combinación de operaciones de lectura y escritura. El benchmark AUCTION no es tan intensivo en datos como BBOARD. Por lo tanto, la mayoría de las ganancias se observan en el ancho de banda más bajo de 5 Mb/s. La figura 8 (a) muestra que el aumento en el rendimiento debido a Ganesh varía desde un 8% con 400 clientes de prueba hasta un 18% con 1600 clientes de prueba. Como se observa en la Figura 8 (b), los tiempos de respuesta promedio para Ganesh son significativamente más bajos que los de Native, con una disminución del 84% a 800 clientes de prueba y del 88% a 1600 clientes de prueba. La Figura 8 (a) también muestra que con un aumento cuádruple del ancho de banda de 5 Mb/s a 20 Mb/s, Native ya no está limitado por el ancho de banda y no hay diferencia de rendimiento entre Ganesh y Native. Con las configuraciones de cliente de prueba más altas, observamos que el ancho de banda utilizado por Ganesh era menor que el de Nativo. Ganesh podría seguir siendo útil en estos escenarios no restringidos si se compra ancho de banda de forma medible. Se observan resultados similares para el escenario de 100 Mb/s. 5.2.2 Mezcla de Navegación Para la Mezcla de Navegación de SUBASTAS, las Figuras 8 (c) y (d) presentan el número promedio de solicitudes atendidas por segundo y el tiempo promedio de respuesta para estas solicitudes tal como lo perciben los clientes. Una vez más, la mayoría de las ganancias se observan en anchos de banda más bajos. A 5 Mb/s, Native y Ganesh ofrecen un rendimiento y tiempos de respuesta similares con 400 clientes de prueba. Mientras que el rendimiento para ambos permanece igual en 800 clientes de prueba, la Figura 8 (d) muestra que el tiempo de respuesta promedio de Ganesh es un 62% menor que el de Native. El servidor satura el enlace con 800 clientes y agregar clientes de prueba adicionales solo aumenta el tiempo promedio de respuesta. Ganesh, independientemente de la configuración del cliente de prueba, no tiene restricciones de ancho de banda y mantiene el mismo tiempo de respuesta. A 1600 clientes de prueba, la Figura 8 (c) muestra que el rendimiento de Ganesh es casi el doble que el de Nativo. En los anchos de banda más altos de 20 y 100 Mb/s, ni Ganesh ni Native tienen limitaciones de ancho de banda y ofrecen un rendimiento y tiempos de respuesta equivalentes. Referencia original. Tamaño Ganesh Tamaño Rabin Tamaño SelectSort1 223.6 MB 5.4 MB 219.3 MB SelectSort2 223.6 MB 5.4 MB 223.6 MB Tabla 2: Microbenchmarks de similitud 6. SIMILITUD ESTRUCTURAL VS. SIMILITUD DE RABIN En esta sección, abordamos la segunda pregunta planteada en la Sección 4: ¿Qué tan importante es la detección de similitud estructural de Ganesh en comparación con la detección de similitud basada en la huella digital de Rabin? Para responder a esta pregunta, utilizamos microbenchmarks y los benchmarks BBOARD y AUCTION. Dado que Ganesh siempre tuvo un mejor rendimiento que Rabin en la huella dactilar, aquí presentamos solo un subconjunto de los resultados en aras de la brevedad. 6.1 Microbenchmarks Dos microbenchmarks muestran un ejemplo de los efectos de la reordenación de datos en el algoritmo de huella dactilar de Rabin. En el primer microbenchmark, SelectSort1, una consulta con un orden de clasificación especificado selecciona 223.6 MB de datos distribuidos en aproximadamente 280 K filas. La consulta se repite entonces con un atributo de ordenación diferente. Si bien se devuelve el mismo número de filas y los mismos datos, el orden de las filas es diferente. En un escenario así, se esperaría detectar una gran cantidad de similitud entre ambos resultados. Como muestra la Tabla 2, el algoritmo basado en filas de Ganesh logra una reducción del 97.6%, mientras que el algoritmo de huella digital de Rabin, con el parámetro de tamaño de fragmento promedio establecido en 4 KB, solo logra una reducción del 1%. La razón, como se muestra anteriormente en la Figura 2, es que con la huella digital de Rabin, los tramos de datos entre dos límites consecutivos suelen cruzar los límites de fila. Con el cambio en el orden de las filas en el segundo resultado y los fingerprints de Rabin ahora abarcando diferentes filas, el algoritmo no puede detectar similitud significativa. La pequeña ganancia observada se debe principalmente a aquellas filas individuales que son lo suficientemente grandes como para dividirse en múltiples fragmentos. SelectSort2, otro micro-benchmark ejecutó las mismas consultas pero aumentó el tamaño mínimo del fragmento del algoritmo de huella digital de Rabin. Como se puede ver en la Tabla 2, incluso la pequeña ganancia del microbenchmark anterior desaparece cuando el tamaño mínimo de fragmento fue mayor que el tamaño promedio de fila. Si bien se pueden abordar parcialmente estos problemas variando dinámicamente los parámetros del algoritmo de huella digital de Rabin, esto puede resultar computacionalmente costoso, especialmente en presencia de cargas de trabajo cambiantes. 6.2 Benchmarks de Aplicación Ejecutamos el benchmark BBOARD descrito en la Sección 4.1.1 en dos versiones de Ganesh: la primera con la huella digital de Rabin utilizada como WWW 2007 / Track: Sesión de Rendimiento y Escalabilidad: Sistemas Escalables para Contenido Dinámico 317 0 50 100 150 200 250 300 350 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Clientes de Prueba Solicitudes/seg Ganesh Nativo 0.001 0.01 0.1 1 10 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Clientes de Prueba Tiempo de Respuesta Promedio (seg) Ganesh Nativo Nota Escala Logarítmica (a) Rendimiento: Mezcla de Ofertas (b) Tiempo de Respuesta: Mezcla de Ofertas 0 50 100 150 200 250 300 350 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Clientes de Prueba Solicitudes/seg Ganesh Nativo 0.001 0.01 0.1 1 10 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Clientes de Prueba Tiempo de Respuesta Promedio (seg) Ganesh Nativo Nota Escala Logarítmica (c) Rendimiento: Mezcla de Navegación (d) Tiempo de Respuesta: Mezcla de Navegación Promedio de tres pruebas. La desviación estándar máxima para el rendimiento y el tiempo de respuesta fue del 2.2% y del 11.8% de la media correspondiente. Figura 8: Referencia de la subasta AUCTION - Rendimiento y Tiempo de Respuesta Promedio del algoritmo de fragmentación y el segundo con el algoritmo basado en filas de Ganesh. Los resultados de Rabins para la Mezcla de Navegación se normalizan con los resultados de Ganesh y se presentan en la Figura 9. Como muestra la Figura 9 (a), a 5 Mb/s, independientemente de la configuración del cliente de prueba, Rabin tiene un rendimiento significativamente inferior a Ganesh. Esto sucede debido a una combinación de dos razones. Primero, como se describe en la Sección 3.1, Rabin encuentra menos similitud ya que no explota la información estructural de los resultados. Segundo, este punto de referencia contenía algunas consultas que generaron resultados grandes. En este caso, Rabin, con un tamaño de fragmento promedio pequeño, generó una gran cantidad de objetos que desplazaron otros datos útiles de la caché. Por el contrario, Ganesh pudo detectar estas filas grandes y aumentar correspondientemente el tamaño de los bloques. Esto fue confirmado ya que las estadísticas de caché mostraron que la proporción de aciertos de Ganesh era aproximadamente tres veces mayor que la de Rabin. Las mediciones de rendimiento a 20 Mb/s fueron similares, con la excepción del rendimiento de Rabins con 400 clientes de prueba. En este caso, Ganesh no estaba limitado por la red y, de hecho, el rendimiento era el mismo que el de 400 clientes a 5 Mb/s. Rabin, sin embargo, aprovechó el aumento del ancho de banda de 5 a 20 Mb/s para ofrecer un rendimiento ligeramente mejor. A 100 Mb/s, el rendimiento de Rabin era casi similar al de Ganesh ya que el ancho de banda ya no era un cuello de botella. El tiempo de respuesta normalizado, presentado en la Figura 9 (b), muestra tendencias similares. A 5 y 20 Mb/s, la adición de clientes de prueba disminuye el tiempo de respuesta normalizado, ya que el tiempo de respuesta promedio de Ganesh aumenta más rápido que el de Rabin. Sin embargo, en ningún momento Rabin supera a Ganesh. Ten en cuenta que con 400 y 800 clientes a 100 Mb/s, Rabin tiene un mayor sobrecosto incluso cuando no está limitado por el ancho de banda. Como se menciona en la Sección 3.1, esto se debe a que Rabin tiene que hashear cada ResultSet dos veces. La sobrecarga desaparece con 1200 y 1600 clientes, ya que la CPU de la base de datos está saturada y limita el rendimiento tanto de Ganesh como de Rabin. 7. SUPERPOSICIÓN DE PROXY En esta sección, abordamos la tercera pregunta planteada en la Sección 4: ¿Es aceptable la superposición del diseño basado en proxy de Ganesh? Para responder a esta pregunta, nos concentramos en su rendimiento en las bandas de mayor ancho de banda. Nuestra evaluación en la Sección 5 mostró que Ganesh, en comparación con Native, puede ofrecer una mejora sustancial en el rendimiento a anchos de banda más bajos. Solo en anchos de banda más altos serían visibles los costos adicionales de latencia, medidos por el tiempo promedio de respuesta para una solicitud de cliente, y de rendimiento, medidos por la cantidad de solicitudes de cliente que pueden ser atendidas por segundo. Al observar la combinación de autoría del benchmark original de BBOARD, no se aprecian ganancias visibles de Ganesh a 100 Mb/s. Sin embargo, Ganesh sigue rastreando a Native en cuanto a rendimiento. Si bien el tiempo promedio de respuesta es mayor para Ganesh, la diferencia absoluta está entre 0.01 y 0.04 segundos y sería imperceptible para el usuario final. La mezcla de navegación muestra una diferencia aún menor en los tiempos de respuesta promedio. Los resultados de la variante del filtro de los benchmarks de BBOARD son similares. Incluso para el benchmark de SUBASTA, la diferencia entre el tiempo de respuesta de Nativo y Ganesh a 100 Mb/s nunca fue mayor a 0.02 segundos. La única excepción a los resultados anteriores se observó en la variante de filtro del benchmark BBOARD, donde Ganesh con 1600 clientes de prueba añadió 0.85 segundos al tiempo de respuesta promedio. Por lo tanto, incluso para redes mucho más rápidas donde el enlace WAN no es el cuello de botella, Ganesh siempre ofrece un rendimiento equivalente al Nativo. Si bien se agrega algo de latencia adicional debido al diseño basado en proxy, generalmente es imperceptible. TRABAJO RELACIONADO Hasta donde sabemos, Ganesh es el primer sistema que combina el uso de técnicas basadas en hash con el almacenamiento en caché de resultados de base de datos para mejorar el rendimiento y los tiempos de respuesta de aplicaciones con contenido dinámico. También creemos que es el primer sistema en demostrar los beneficios de utilizar información estructural para WWW 2007 / Track: Rendimiento y Escalabilidad Sesión: Sistemas Escalables para Contenido Dinámico 318 0.0 0.2 0.4 0.6 0.8 1.0 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Clientes de Prueba Rendimiento Normalizado 31.8 3.8 2.8 2.3 23.8 32.8 5.8 3.6 1.8 2.1 1.1 1.0 0 5 10 15 20 25 30 35 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Clientes de Prueba Tiempo de Respuesta Normalizado (a) Rendimiento Normalizado: Mayor es mejor (b) Tiempo de Respuesta Normalizado: Mayor es peor Para el rendimiento, un resultado normalizado mayor que 1 implica que Rabin es mejor. Para el tiempo de respuesta, un resultado normalizado mayor que 1 implica que Ganesh es mejor. Media de tres pruebas. La desviación estándar máxima para el rendimiento y el tiempo de respuesta fue del 9.1% y del 13.9% de la media correspondiente. Figura 9: Comparación normalizada de Ganesh vs. Rabin - Mezcla de navegación BBOARD detectando similitud. En esta sección, primero discutimos enfoques alternativos para almacenar en caché contenido dinámico y luego examinamos otros usos de primitivas basadas en hash en sistemas distribuidos. 8.1 Almacenamiento en Caché de Contenido Dinámico En la capa de base de datos, varios sistemas han abogado por la caché de nivel intermedio donde partes de la base de datos se replican en el borde o servidor [3, 4, 20]. Estos sistemas almacenan en caché tablas completas en lo que es esencialmente una base de datos replicada o utilizan vistas materializadas de respuestas de consultas anteriores [19]. Requieren una integración estrecha con la base de datos del sistema para garantizar un límite de tiempo en la propagación de actualizaciones. Estos sistemas suelen estar dirigidos a cargas de trabajo que no requieren una consistencia estricta y pueden tolerar datos obsoletos. Además, a diferencia de Ganesh, algunas de estas soluciones de almacenamiento en caché de nivel medio [2, 3], sufren de la complejidad de tener que participar en la planificación de consultas y el procesamiento de consultas distribuidas. Gao et al. [15] proponen utilizar una arquitectura de replicación de objetos distribuidos donde los requisitos de consistencia de las tiendas de datos se adaptan según la aplicación. Estas soluciones requieren recursos sustanciales de desarrollo y un entendimiento detallado de la aplicación que se está modificando. Si bien existen sistemas que intentan automatizar la partición y replicación de la base de datos de una aplicación [34], no proporcionan semántica de transacciones completa. En comparación, Ganesh no debilita ninguna de las semánticas proporcionadas por la base de datos subyacente. El trabajo reciente en la evaluación de opciones de almacenamiento en caché de borde para sitios web dinámicos [38] ha sugerido que, sin una planificación cuidadosa, el empleo de estrategias complejas de descarga puede perjudicar el rendimiento. En cambio, el trabajo aboga por una arquitectura en la que todos los niveles, excepto la base de datos, deberían ser trasladados al borde. Nuestra evaluación de Ganesh ha demostrado que sería beneficioso para estos escenarios. Para mejorar la escalabilidad de la base de datos, C-JDBC [10], SSS [22] y Ganymed [28] también abogan por el uso de una arquitectura basada en interposición para clusterizar y replicar bases de datos de forma transparente a nivel de middleware. Los enfoques de estas arquitecturas y Ganesh son complementarios y se beneficiarían mutuamente. Avanzando hacia la capa de presentación, se ha producido una amplia adopción de la caché basada en fragmentos [14], la cual mejora la utilización de la caché al almacenar por separado diferentes partes de las páginas web generadas. Si bien el almacenamiento en caché basado en fragmentos funciona en el borde, una propuesta reciente ha propuesto trasladar el ensamblaje de páginas web a los clientes para optimizar la entrega de contenido [31]. Si bien Ganesh no se utiliza en la capa de presentación, los mismos principios se han aplicado en la Detección de Transferencias Duplicadas [25] para aumentar la eficiencia de la caché web, así como para el acceso web a través de enlaces con ancho de banda limitado [33]. 8.2 Sistemas basados en hash En los últimos años han surgido muchos sistemas que explotan técnicas basadas en hash. En el centro de todos estos sistemas se encuentra la idea de detectar similitudes en los datos sin necesidad de interpretar esos datos. Esta idea simple pero elegante se basa en el hash criptográfico, como se discutió anteriormente en la Sección 2. Las aplicaciones exitosas de esta idea abarcan una amplia gama de sistemas de almacenamiento. Los ejemplos incluyen la copia de seguridad entre pares de archivos informáticos personales [11], el archivado eficiente de datos [29] y la búsqueda de archivos similares [21]. Spring y Wetherall [35] aplican principios similares a nivel de red. Utilizando cachés sincronizadas en ambos extremos de un enlace de red, los datos duplicados son reemplazados por tokens más pequeños para su transmisión y luego restaurados en el extremo remoto. Este y otros sistemas basados en hash como los sistemas de archivos CASPER [37] y LBFS [26], y optimizadores de ancho de banda de Capa-2 como Riverbed y Peribit utilizan la huella digital de Rabin [30] para descubrir tramos de similitud en los datos. Este enfoque es especialmente útil cuando los elementos de datos son modificados en su lugar a través de inserciones, eliminaciones y actualizaciones. Sin embargo, como se muestra en la Sección 6, el rendimiento de esta técnica puede experimentar una caída dramática en presencia de reordenamiento de datos. Ganesh en cambio utiliza los límites de fila como divisores para detectar similitudes. El uso más agresivo de técnicas basadas en hash es por sistemas que utilizan hashes como identificadores principales para objetos en almacenamiento persistente. Los sistemas de almacenamiento como CFS [12] y PAST [13] que han sido construidos utilizando tablas hash distribuidas entran en esta categoría. Single Instance Storage [6] y Venti [29] son otros ejemplos de tales sistemas. Como se discute en la Sección 2.2, el uso de hashes criptográficos para abordar datos persistentes representa un nivel más profundo de confianza en su resistencia a colisiones que la asumida por Ganesh. Si el tiempo revela deficiencias en el algoritmo hash, el esfuerzo necesario para corregir la falla es mucho mayor. En Ganesh, simplemente se trata de reemplazar el algoritmo hash. 9. CONCLUSIÓN El creciente uso de contenido web dinámico generado a partir de bases de datos relacionales aumenta las demandas de ancho de banda de la WAN. Las soluciones de almacenamiento en caché tradicionales para reducir el ancho de banda y la latencia suelen ser ineficaces para este tipo de contenido. Este documento muestra que el impacto de los accesos a bases de datos a través de WAN puede reducirse sustancialmente mediante la arquitectura Ganesh sin comprometer la estricta semántica de consistencia de las bases de datos. La esencia de la arquitectura Ganesh es el uso de la computación en los bordes para reducir la comunicación a través de Internet. Ganesh es capaz de utilizar hashes criptográficos para detectar similitud con resultados anteriores y enviar recetas compactas de resultados en lugar de resultados completos en la sesión de Sistemas Escalables para Contenido Dinámico 319 de WWW 2007 / Track: Rendimiento y Escalabilidad. Nuestro diseño utiliza la interposición para lograr una transparencia completa: los clientes, los servidores de aplicaciones y los servidores de bases de datos no son conscientes de la presencia de Ganesh y no requieren ninguna modificación. Nuestra evaluación experimental confirma que Ganesh, aunque conceptualmente simple, puede ser altamente efectivo en mejorar el rendimiento y el tiempo de respuesta. Nuestros resultados también confirman que aprovechar la estructura presente en los resultados de la base de datos para detectar similitudes es crucial para esta mejora en el rendimiento. REFERENCIAS [1] AKELLA, A., SESHAN, S., Y SHAIKH, A. Una evaluación empírica de los cuellos de botella en Internet de área amplia. En Proc. 3ª Conferencia ACM SIGCOMM sobre Medición de Internet (Miami Beach, FL, EE. UU., Oct. 2003), pp. 101-114. [2] ALTINEL, M., BORNH ¨OVD, C., KRISHNAMURTHY, S., MOHAN, C., PIRAHESH, H., Y REINWALD, B. Tablas de caché: allanando el camino para una caché de base de datos adaptativa. En Proc. del 29º VLDB (Berlín, Alemania, 2003), pp. 718-729. [3] ALTINEL, M., LUO, Q., KRISHNAMURTHY, S., MOHAN, C., PIRAHESH, H., LINDSAY, B. G., WOO, H., Y BROWN, L. Dbcache: Caché de base de datos para servidores de aplicaciones web. En Proc. 2002 ACM SIGMOD (2002), pp. 612-612. [4] AMIRI, K., PARK, S., TEWARI, R., Y PADMANABHAN, S. Dbproxy: una caché de datos dinámica para aplicaciones web. En Proc. Conferencia Internacional de Ingeniería de Datos de IEEE (ICDE) (Mar. 2003). [5] BLACK, J. Compare-by-hash: Un análisis razonado. En Proc. Conferencia Técnica Anual USENIX 2006 (Boston, MA, mayo de 2006), pp. 85-90. [6] BOLOSKY, W. J., CORBIN, S., GOEBEL, D., y DOUCEUR, J. R. Almacenamiento de instancia única en Windows 2000. En Proc. 4to Simposio de Sistemas Windows de USENIX (Seattle, WA, ago. 2000), pp. 13-24. [7] BREWER, E. A. Lecciones de servicios a gran escala. IEEE Internet Computing 5, 4 (2001), 46-55. [8] BRODER, A., GLASSMAN, S., MANASSE, M., AND ZWEIG, G. Agrupamiento sintáctico de la web. En Proc. 6ta Conferencia Internacional WWW (1997). [9] CECCHET, E., CHANDA, A., ELNIKETY, S., MARGUERITE, J., Y ZWAENEPOEL, W. Comparación de rendimiento de arquitecturas de middleware para generar contenido web dinámico. En Proc. Cuarta Conferencia Internacional de Middleware ACM/IFIP/USENIX (Río de Janeiro, Brasil, junio de 2003). [10] CECCHET, E., MARGUERITE, J., Y ZWAENEPOEL, W. C-JDBC: Middleware flexible de agrupación de bases de datos. En Proc. Conferencia Técnica Anual USENIX 2004 (Boston, MA, junio de 2004). [11] COX, L. P., MURRAY, C. D., Y NOBLE, B. D. Pastiche: Haciendo que la copia de seguridad sea barata y fácil. En OSDI: Simposio sobre Diseño e Implementación de Sistemas Operativos (2002). [12] DABEK, F., KAASHOEK, M. F., KARGER, D., MORRIS, R., Y STOICA, I. Almacenamiento cooperativo de amplia área con CFS. En el 18º Simposio ACM sobre Principios de Sistemas Operativos (Banff, Canadá, octubre de 2001). [13] DRUSCHEL, P., Y ROWSTRON, A. PASADO: Una utilidad de almacenamiento entre pares a gran escala y persistente. En HotOS VIII (Schloss Elmau, Alemania, mayo de 2001), pp. 75-80. [14] Incluye el lado del borde. http://www.esi.org. [15] GAO, L., DAHLIN, M., NAYATE, A., ZHENG, J., Y IYENGAR, A. Replicación de datos específica de la aplicación para servicios en el borde. En WWW 03: Proc. Duodécima Conferencia Internacional sobre la World Wide Web (2003), pp. 449-460. [16] HEMMINGER, S. Netem - emulando redes reales en el laboratorio. En Proc. 2005 Linux Conference Australia (Canberra, Australia, Abr. 2005). [17] HENSON, V. Un análisis de compare-by-hash. En Proc. 9º Taller sobre Temas Candentes en Sistemas Operativos (HotOS IX) (mayo de 2003), pp. 13-18. [18] Benchmarks de Jmob. http://jmob.objectweb.org/. [19] LABRINIDIS, A., Y ROUSSOPOULOS, N. Equilibrando el rendimiento y la frescura de los datos en servidores de bases de datos web. En Proc. 29ª Conferencia VLDB (Sept. 2003). [20] LARSON, P.-A., GOLDSTEIN, J., Y ZHOU, J. Caché transparente de bases de datos en el nivel intermedio en SQL Server. En Proc. 2003 ACM SIGMOD (2003), pp. 661-661. [21] MANBER, U. Encontrar archivos similares en un sistema de archivos grande. En Proc. Conferencia Técnica de Invierno de USENIX 1994 (San Francisco, CA, 17-21 de 1994), pp. 1-10. [22] MANJHI, A., AILAMAKI, A., MAGGS, B. M., MOWRY, T. C., OLSTON, C., Y TOMASIC, A. Escalabilidad y seguridad simultáneas para aplicaciones web intensivas en datos. En Proc. 2006 ACM SIGMOD (junio de 2006), pp. 241-252. [23] MENEZES, A. J., VANSTONE, S. A., Y OORSCHOT, P. C. V. Manual de Criptografía Aplicada. CRC Press, 1996. [24] MILLER, R. B. \n\nCRC Press, 1996. [24] MILLER, R. B. Tiempo de respuesta en transacciones conversacionales entre humanos y computadoras. En Proc. Conferencia Conjunta de Computación de Otoño de AFIPS (1968), pp. 267-277. [25] MOGUL, J. C., CHAN, Y. M., Y KELLY, T. Diseño, implementación y evaluación de la detección de transferencias duplicadas en http. En Proc. Primer Simposio sobre Diseño e Implementación de Sistemas en Red (San Francisco, CA, Mar. 2004). [26] MUTHITACHAROEN, A., CHEN, B., Y MAZIERES, D. Un sistema de archivos en red de bajo ancho de banda. En Proc. 18º Simposio de la ACM sobre Principios de Sistemas Operativos (Banff, Canadá, Oct. 2001). [27] PFEIFER, D., Y JAKSCHITSCH, H. Caché basada en métodos en aplicaciones de servidores multinivel. En Proc. Quinto Simposio Internacional sobre Objetos y Aplicaciones Distribuidas (Catania, Sicilia, Italia, noviembre de 2003). [28] PLATTNER, C., Y ALONSO, G. Ganymed: Replicación escalable para aplicaciones web transaccionales. En Proc. 5ta Conferencia Internacional de Middleware ACM/IFIP/USENIX (2004), pp. 155-174. [29] QUINLAN, S., Y DORWARD, S. Venti: Un nuevo enfoque para el almacenamiento de archivos. En Proc. Conferencia FAST 2002 sobre Tecnologías de Archivo y Almacenamiento (2002). [30] RABIN, M. Huellas dactilares mediante polinomios aleatorios. En el Informe Técnico TR-15-81 (1981) del Centro de Investigación en Tecnología Informática de la Universidad de Harvard. [31] RABINOVICH, M., XIAO, Z., DOUGLIS, F., Y KALMANEK, C. Mover los lados de los bordes incluye a los clientes reales en el borde. En Proc. 4to Simposio USENIX sobre Tecnologías y Sistemas de Internet (Seattle, WA, Mar. 2003). [32] REESE, G. Programación de bases de datos con JDBC y Java, 1ra ed. OReilly, junio de 1997. [33] RHEA, S., LIANG, K., Y BREWER, E. Caché web basada en valores. En Proc. Duodécima Conferencia Internacional de la World Wide Web (mayo de 2003). [34] SIVASUBRAMANIAN, S., ALONSO, G., PIERRE, G., Y VAN STEEN, M. Globedb: Replicación autónoma de datos para aplicaciones web. En WWW 05: Actas de la 14ª Conferencia Internacional de la World-Wide Web (mayo de 2005). [35] SPRING, N. T., Y WETHERALL, D. Una técnica independiente de protocolo para eliminar el tráfico de red redundante. En Proc. de ACM SIGCOMM (Ago. 2000). [36] TOLIA, N., HARKES, J., KOZUCH, M., Y SATYANARAYANAN, M. Integrando almacenamiento portátil y distribuido. En Proc. 3ra Conferencia USENIX sobre Tecnologías de Archivos y Almacenamiento (San Francisco, CA, Mar. 2004). [37] TOLIA, N., KOZUCH, M., SATYANARAYANAN, M., KARP, B., PERRIG, A., Y BRESSOUD, T. Uso oportunista del almacenamiento direccionable por contenido para sistemas de archivos distribuidos. En Proc. Conferencia Técnica Anual USENIX 2003 (San Antonio, TX, junio de 2003), pp. 127-140. [38] YUAN, C., CHEN, Y., Y ZHANG, Z. Evaluación de almacenamiento en caché/descarga en el borde para la entrega de contenido dinámico. En WWW 03: Proc. Duodécima Conferencia Internacional sobre la World Wide Web (2003), pp. 461-471. WWW 2007 / Pista: Rendimiento y Escalabilidad Sesión: Sistemas Escalables para Contenido Dinámico 320 ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "database content": {
            "translated_key": "contenido de la base de datos",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Consistency-preserving Caching of Dynamic <br>database content</br>∗ Niraj Tolia and M. Satyanarayanan Carnegie Mellon University {ntolia,satya}@cs.cmu.edu ABSTRACT With the growing use of dynamic web content generated from relational databases, traditional caching solutions for throughput and latency improvements are ineffective.",
                "We describe a middleware layer called Ganesh that reduces the volume of data transmitted without semantic interpretation of queries or results.",
                "It achieves this reduction through the use of cryptographic hashing to detect similarities with previous results.",
                "These benefits do not require any compromise of the strict consistency semantics provided by the back-end database.",
                "Further, Ganesh does not require modifications to applications, web servers, or database servers, and works with closed-source applications and databases.",
                "Using two benchmarks representative of dynamic web sites, measurements of our prototype show that it can increase end-to-end throughput by as much as twofold for non-data intensive applications and by as much as tenfold for data intensive ones.",
                "Categories and Subject Descriptors C.2.4 [Computer-Communication Networks]: Distributed Systems; H.2.4 [Database Management]: Systems General Terms Design, Performance 1.",
                "INTRODUCTION An increasing fraction of web content is dynamically generated from back-end relational databases.",
                "Even when <br>database content</br> remains unchanged, temporal locality of access cannot be exploited because dynamic content is not cacheable by web browsers or by intermediate caching servers such as Akamai mirrors.",
                "In a multitiered architecture, each web request can stress the WAN link between the web server and the database.",
                "This causes user experience to be highly variable because there is no caching to insulate the client from bursty loads.",
                "Previous attempts in caching dynamic <br>database content</br> have generally weakened transactional semantics [3, 4] or required application modifications [15, 34].",
                "We report on a new solution that takes the form of a databaseagnostic middleware layer called Ganesh.",
                "Ganesh makes no effort to semantically interpret the contents of queries or their results.",
                "Instead, it relies exclusively on cryptographic hashing to detect similarities with previous results.",
                "Hash-based similarity detection has seen increasing use in distributed file systems [26, 36, 37] for improving performance on low-bandwidth networks.",
                "However, these techniques have not been used for relational databases.",
                "Unlike previous approaches that use generic methods to detect similarity, Ganesh exploits the structure of relational database results to yield superior performance improvement.",
                "One faces at least three challenges in applying hash-based similarity detection to back-end databases.",
                "First, previous work in this space has traditionally viewed storage content as uninterpreted bags of bits with no internal structure.",
                "This allows hash-based techniques to operate on long, contiguous runs of data for maximum effectiveness.",
                "In contrast, relational databases have rich internal structure that may not be as amenable to hash-based similarity detection.",
                "Second, relational databases have very tight integrity and consistency constraints that must not be compromised by the use of hash-based techniques.",
                "Third, the source code of commercial databases is typically not available.",
                "This is in contrast to previous work which presumed availability of source code.",
                "Our experiments show that Ganesh, while conceptually simple, can improve performance significantly at bandwidths representative of todays commercial Internet.",
                "On benchmarks modeling multitiered web applications, the throughput improvement was as high as tenfold for data-intensive workloads.",
                "For workloads that were not data-intensive, throughput improvements of up to twofold were observed.",
                "Even when bandwidth was not a constraint, Ganesh had low overhead and did not hurt performance.",
                "Our experiments also confirm that exploiting the structure present in database results is crucial to this performance improvement. 2.",
                "BACKGROUND 2.1 Dynamic Content Generation As the World Wide Web has grown, many web sites have decentralized their data and functionality by pushing them to the edges of the Internet.",
                "Today, eBusiness systems often use a three-tiered architecture consisting of a front-end web server, an application server, and a back-end database server.",
                "Figure 1 illustrates this architecture.",
                "The first two tiers can be replicated close to a concentration of clients at the edge of the Internet.",
                "This improves user experience by lowering end-to-end latency and reducing exposure WWW 2007 / Track: Performance and Scalability Session: Scalable Systems for Dynamic Content 311 Back-End Database Server Front-End Web and Application Servers Figure 1: Multi-Tier Architecture to backbone traffic congestion.",
                "It can also increase the availability and scalability of web services.",
                "Content that is generated dynamically from the back-end database cannot be cached in the first two tiers.",
                "While databases can be easily replicated in a LAN, this is infeasible in a WAN because of the difficult task of simultaneously providing strong consistency, availability, and tolerance to network partitions [7].",
                "As a result, databases tend to be centralized to meet the strong consistency requirements of many eBusiness applications such as banking, finance, and online retailing [38].",
                "Thus, the back-end database is usually located far from many sets of first and second-tier nodes [2].",
                "In the absence of both caching and replication, WAN bandwidth can easily become a limiting factor in the performance and scalability of data-intensive applications. 2.2 Hash-Based Systems Ganeshs focus is on efficient transmission of results by discovering similarities with the results of previous queries.",
                "As SQL queries can generate large results, hash-based techniques lend themselves well to the problem of efficiently transferring these large results across bandwidth constrained links.",
                "The use of hash-based techniques to reduce the volume of data transmitted has emerged as a common theme of many recent storage systems, as discussed in Section 8.2.",
                "These techniques rely on some basic assumptions.",
                "Cryptographic hash functions are assumed to be collision-resistant.",
                "In other words, it is computationally intractable to find two inputs that hash to the same output.",
                "The functions are also assumed to be one-way; that is, finding an input that results in a specific output is computationally infeasible.",
                "Menezes et al. [23] provide more details about these assumptions.",
                "The above assumptions allow hash-based systems to assume that collisions do not occur.",
                "Hence, they are able to treat the hash of a data item as its unique identifier.",
                "A collection of data items effectively becomes content-addressable, allowing a small hash to serve as a codeword for a much larger data item in permanent storage or network transmission.",
                "The assumption that collisions are so rare as to be effectively non-existent has recently come under fire [17].",
                "However, as explained by Black [5], we believe that these issues do not form a concern for Ganesh.",
                "All communication is between trusted parts of the system and an adversary has no way to force Ganesh to accept invalid data.",
                "Further, Ganesh does not depend critically on any specific hash function.",
                "While we currently use SHA-1, replacing it with a different hash function would be simple.",
                "There would be no impact on performance as stronger hash functions (e.g.",
                "SHA256) only add a few extra bytes and the generated hashes are still orders of magnitude smaller than the data items they represent.",
                "No re-hashing of permanent storage is required since Ganesh only uses hashing on volatile data. 3.",
                "DESIGN AND IMPLEMENTATION Ganesh exploits redundancy in the result stream to avoid transmitting result fragments that are already present at the query site.",
                "Redundancy can arise naturally in many different ways.",
                "For example, a query repeated after a certain interval may return a different result because of updates to the database; however, there may be significant commonality between the two results.",
                "As another example, a user who is refining a search may generate a sequence of queries with overlapping results.",
                "When Ganesh detects redundancy, it suppresses transmission of the corresponding result fragments.",
                "Instead, it transmits a much smaller digest of those fragments and lets the query site reconstruct the result through hash lookup in a cache of previous results.",
                "In effect, Ganesh uses computation at the edges to reduce Internet communication.",
                "Our description of Ganesh focuses on four aspects.",
                "We first explain our approach to detecting similarity in query results.",
                "Next, we discuss how the Ganesh architecture is completely invisible to all components of a multi-tier system.",
                "We then describe Ganeshs proxy-based approach and the dataflow for detecting similarity. 3.1 Detecting Similarity One of the key design decisions in Ganesh is how similarity is detected.",
                "There are many potential ways to decompose a result into fragments.",
                "The optimal way is, of course, the one that results in the smallest possible object for transmission for a given querys results.",
                "Finding this optimal decomposition is a difficult problem because of the large space of possibilities and because the optimal choice depends on many factors such as the contents of the querys result, the history of recent results, and the cache management algorithm.",
                "When an object is opaque, the use of Rabin fingerprints [8, 30] to detect common data between two objects has been successfully shown in the past by systems such as LBFS [26] and CASPER [37].",
                "Rabin fingerprinting uses a sliding window over the data to compute a rolling hash.",
                "Assuming that the hash function is uniformly distributed, a chunk boundary is defined whenever the lower order bits of the hash value equal some predetermined value.",
                "The number of lower order bits used defines the average chunk size.",
                "These sub-divided chunks of the object become the unit of comparison for detecting similarity between different objects.",
                "As the locations of boundaries found by using Rabin fingerprints is stochastically determined, they usually fail to align with any structural properties of the underlying data.",
                "The algorithm therefore deals well with in-place updates, insertions and deletions.",
                "However, it performs poorly in the presence of any reordering of data.",
                "Figure 2 shows an example where two results, A and B, consisting of three rows, have the same data but have different sort attributes.",
                "In the extreme case, Rabin fingerprinting might be unable to find any similar data due to the way it detects chunk boundaries.",
                "Fortunately, Ganesh can use domain specific knowledge for more precise boundary detection.",
                "The information we exploit is that a querys result reflects the structure of a relational database where all data is organized as tables and rows.",
                "It is therefore simple to check for similarity with previous results at two granularities: first the entire result, and then individual rows.",
                "The end of a row in a result serves as a natural chunk boundary.",
                "It is important to note that using the tabular structure in results only involves shallow interpretation of the data.",
                "Ganesh does not perform any deeper semantic interpretation such as understanding data types, result schema, or integrity constraints.",
                "Tuning Rabin fingerprinting for a workload can also be difficult.",
                "If the average chunk size is too large, chunks can span multiple result rows.",
                "However, selecting a smaller average chunk size increases the amount of metadata required to the describe the results.",
                "WWW 2007 / Track: Performance and Scalability Session: Scalable Systems for Dynamic Content 312 Figure 2: Rabin Fingerprinting vs. Ganeshs Chunking This, in turn, would decrease the savings obtained via its use.",
                "Rabin fingerprinting also needs two computationally-expensive passes over the data: once to determine chunk boundaries and one again to generate cryptographic hashes for the chunks.",
                "Ganesh only needs a single pass for hash generation as the chunk boundaries are provided by the datas natural structure.",
                "The performance comparison in Section 6 shows that Ganeshs row-based algorithm outperforms Rabin fingerprinting.",
                "Given that previous work has already shown that Rabin fingerprinting performs better than gzip [26], we do not compare Ganesh to compression algorithms in this paper. 3.2 Transparency The key factor influencing our design was the need for Ganesh to be completely transparent to all components of a typical eBusiness system: web servers, application servers, and database servers.",
                "Without this, Ganesh stands little chance of having a significant real-world impact.",
                "Requiring modifications to any of the above components would raise the barrier for entry of Ganesh into an existing system, and thus reduce its chances of adoption.",
                "Preserving transparency is simplified by the fact that Ganesh is purely a performance enhancement, not a functionality or usability enhancement.",
                "We chose agent interposition as the architectural approach to realizing our goal.",
                "This approach relies on the existence of a compact programming interface that is already widely used by target software.",
                "It also relies on a mechanism to easily add new code without disrupting existing module structure.",
                "These conditions are easily met in our context because of the popularity of Java as the programming language for eBusiness systems.",
                "The Java Database Connectivity (JDBC) API [32] allows Java applications to access a wide variety of databases and even other tabular data repositories such as flat files.",
                "Access to these data sources is provided by JDBC drivers that translate between the JDBC API and the database communication mechanism.",
                "Figure 3(a) shows how JDBC is typically used in an application.",
                "As the JDBC interface is standardized, one can substitute one JDBC driver for another without application modifications.",
                "The JDBC driver thus becomes the natural module to exploit for code interposition.",
                "As shown in Figure 3(b), the native JDBC driver is replaced with a Ganesh JDBC driver that presents the same standardized interface.",
                "The Ganesh driver maintains an in-memory cache of result fragments from previous queries and performs reassembly of results.",
                "At the database, we add a new process called the Ganesh proxy.",
                "This proxy, which can be shared by multiple front-end nodes, consists of two parts: code to detect similarity in result fragments and the original native JDBC driver that communicates with the database.",
                "The use of a proxy at the database makes Ganesh database-agnostic and simplifies prototyping and experimentation.",
                "Ganesh is thus able to work with a wide range of databases and applications, requiring no modifications to either. 3.3 Proxy-Based Caching The native JDBC driver shown in Figure 3(a) is a lightweight code component supplied by the database vendor.",
                "Its main funcClient Database Web and Application Server Native JDBC Driver WAN (a) Native Architecture Client Database Ganesh Proxy Native JDBC Driver WAN Web and Application Server Ganesh JDBC Driver (b) Ganeshs Interposition-based Architecture Figure 3: Native vs. Ganesh Architecture tion is to mediate communication between the application and the remote database.",
                "It forwards queries, buffers entire results, and responds to application requests to view parts of results.",
                "The Ganesh JDBC driver shown in Figure 3(b) presents the application with an interface identical to that provided by the native driver.",
                "It provides the ability to reconstruct results from compact hash-based descriptions sent by the proxy.",
                "To perform this reconstruction, the driver maintains an in-memory cache of recentlyreceived results.",
                "This cache is only used as a source of result fragments in reconstructing results.",
                "No attempt is made by the Ganesh driver or proxy to track database updates.",
                "The lack of cache consistency does not hurt correctness as a description of the results is always fetched from the proxy - at worst, there will be no performance benefit from using Ganesh.",
                "Stale data will simply be paged out of the cache over time.",
                "The Ganesh proxy accesses the database via the native JDBC driver, which remains unchanged between Figures 3(a) and (b).",
                "The database is thus completely unaware of the existence of the proxy.",
                "The proxy does not examine any queries received from the Ganesh driver but passes them to the native driver.",
                "Instead, the proxy is responsible for inspecting database output received from the native driver, detecting similar results, and generating hash-based encodings of these results whenever enough similarity is found.",
                "While this architecture does not decrease the load on a database, as mentioned earlier in Section 2.1, it is much easier to replicate databases for scalability in a LAN than in a WAN.",
                "To generate a hash-based encoding, the proxy must be aware of what result fragments are available in the Ganesh drivers cache.",
                "One approach is to be optimistic, and to assume that all result fragments are available.",
                "This will result in the smallest possible initial transmission of a result.",
                "However, in cases where there is little overlap with previous results, the Ganesh driver will have to make many calls to the proxy during reconstruction to fetch missing result fragments.",
                "To avoid this situation, the proxy loosely tracks the state of the Ganesh drivers cache.",
                "Since both components are under our control, it is relatively simple to do this without resorting to gray-box techniques or explicit communication for maintaining cache coherence.",
                "Instead, the proxy simulates the Ganesh drivers cache management algorithm and uses this to maintain a list of hashes for which the Ganesh driver is likely to possess the result fragments.",
                "In case of mistracking, there will be no loss of correctness but there will be extra round-trip delays to fetch the missing fragments.",
                "If the client detects loss of synchronization with the proxy, it can ask the proxy to reset the state shared between them.",
                "Also note that the proxy does not need to keep the result fragments themselves, only their hashes.",
                "This allows the proxy to remain scalable even when it is shared by many front-end nodes.",
                "WWW 2007 / Track: Performance and Scalability Session: Scalable Systems for Dynamic Content 313 Object Output Stream Convert ResultSet Object Input Stream Convert ResultSet All Data Recipe ResultSet All Data ResultSet Network Ganesh Proxy Ganesh JDBC Driver Result Set Recipe Result Set Yes Yes No No GaneshInputStream GaneshOutputStream Figure 4: Dataflow for Result Handling 3.4 Encoding and Decoding Results The Ganesh proxy receives database output as Java objects from the native JDBC driver.",
                "It examines this output to see if a Java object of type ResultSet is present.",
                "The JDBC interface uses this data type to store results of database queries.",
                "If a ResultSet object is found, it is shrunk as discussed below.",
                "All other Java objects are passed through unmodified.",
                "As discussed in Section 3.1, the proxy uses the row boundaries defined in the ResultSet to partition it into fragments consisting of single result rows.",
                "All ResultSet objects are converted into objects of a new type called RecipeResultSet.",
                "We use the term recipe for this compact description of a database result because of its similarity to a file recipe in the CASPER file system [37].",
                "The conversion replaces each result fragment that is likely to be present in the Ganesh drivers cache by a SHA-1 hash of that fragment.",
                "Previously unseen result fragments are retained verbatim.",
                "The proxy also retains hashes for the new result fragments as they will be present in the drivers cache in the future.",
                "Note that the proxy only caches hashes for result fragments and does not cache recipes.",
                "The proxy constructs a RecipeResultSet by checking for similarity at the entire result and then the row level.",
                "If the entire result is predicted to be present in the Ganesh drivers cache, the RecipeResultSet is simply a single hash of the entire result.",
                "Otherwise, it contains hashes for those rows predicted to be present in that cache; all other rows are retained verbatim.",
                "If the proxy estimates an overall space savings, it will transmit the RecipeResultSet.",
                "Otherwise the original ResultSet is transmitted.",
                "The RecipeResultSet objects are transformed back into ResultSet objects by the Ganesh driver.",
                "Figure 4 illustrates ResultSet handling at both ends.",
                "Each SHA-1 hash found in a RecipeResultSet is looked up in the local cache of result fragments.",
                "On a hit, the hash is replaced by the corresponding fragment.",
                "On a miss, the driver contacts the Ganesh proxy to fetch the fragment.",
                "All previously unseen result fragments that were retained verbatim by the proxy are hashed and added to the result cache.",
                "There should be very few misses if the proxy has accurately tracked the Ganesh drivers cache state.",
                "A future optimization would be to batch the fetch of missing fragments.",
                "This would be valuable when there are many small missing fragments in a high-latency WAN.",
                "Once the transformation is complete, the fully reconstructed ResultSet object is passed up to the application. 4.",
                "EXPERIMENTAL VALIDATION Three questions follow from the goals and design of Ganesh: • First, can performance can be improved significantly by exploiting similarity across database results?",
                "Benchmark Dataset Details 500,000 Users, 12,000 Stories BBOARD 2.0 GB 3,298,000 Comments AUCTION 1.3 GB 1,000,000 Users, 34,000 Items Table 1: Benchmark Dataset Details • Second, how important is Ganeshs structural similarity detection relative to Rabin fingerprintings similarity detection? • Third, is the overhead of the proxy-based design acceptable?",
                "Our evaluation answers these question through controlled experiments with the Ganesh prototype.",
                "This section describes the benchmarks used, our evaluation procedure, and the experimental setup.",
                "Results of the experiments are presented in Sections 5, 6, and 7. 4.1 Benchmarks Our evaluation is based on two benchmarks [18] that have been widely used by other researchers to evaluate various aspects of multi-tier [27] and eBusiness architectures [9].",
                "The first benchmark, BBOARD, is modeled after Slashdot, a technology-oriented news site.",
                "The second benchmark, AUCTION, is modeled after eBay, an online auction site.",
                "In both benchmarks, most content is dynamically generated from information stored in a database.",
                "Details of the datasets used can be found in Table 1. 4.1.1 The BBOARD Benchmark The BBOARD benchmark, also known as RUBBoS [18], models Slashdot, a popular technology-oriented web site.",
                "Slashdot aggregates links to news stories and other topics of interest found elsewhere on the web.",
                "The site also serves as a bulletin board by allowing users to comment on the posted stories in a threaded conversation form.",
                "It is not uncommon for a story to gather hundreds of comments in a matter of hours.",
                "The BBOARD benchmark is similar to the site and models the activities of a user, including readonly operations such as browsing the stories of the day, browsing story categories, and viewing comments as well as write operations such as new user registration, adding and moderating comments, and story submission.",
                "The benchmark consists of three different phases: a short warmup phase, a runtime phase representing the main body of the workload, and a short cool-down phase.",
                "In this paper we only report results from the runtime phase.",
                "The warm-up phase is important in establishing dynamic system state, but measurements from that phase are not significant for our evaluation.",
                "The cool-down phase is solely for allowing the benchmark to shut down.",
                "The warm-up, runtime, and cool-down phases are 2, 15, and 2 minutes respectively.",
                "The number of simulated clients were 400, 800, 1200, and 1600.",
                "The benchmark is available in a Java Servlets and PHP version and has different datasets; we evaluated Ganesh using the Java Servlets version and the Expanded dataset.",
                "The BBOARD benchmark defines two different workloads.",
                "The first, the Authoring mix, consists of 70% read-only operations and 30% read-write operations.",
                "The second, the Browsing mix, contains only read-only operations and does not update the database. 4.1.2 The AUCTION Benchmark The AUCTION benchmark, also known as RUBiS [18], models eBay, the online auction site.",
                "The eBay web site is used to buy and sell items via an auction format.",
                "The main activities of a user include browsing, selling, or bidding for items.",
                "Modeling the activities on this site, this benchmark includes read-only activities such as browsing items by category and by region, as well as read-write WWW 2007 / Track: Performance and Scalability Session: Scalable Systems for Dynamic Content 314 NetEm Router Ganesh Proxy Clients Web and Application Server Database Server Figure 5: Experimental Setup activities such as bidding for items, buying and selling items, and leaving feedback.",
                "As with BBOARD, the benchmark consists of three different phases.",
                "The warm-up, runtime, and cool-down phases for this experiment are 1.5, 15, and 1 minutes respectively.",
                "We tested Ganesh with four client configurations where the number of test clients was set to 400, 800, 1200, and 1600.",
                "The benchmark is available in a Enterprise Java Bean (EJB), Java Servlets, and PHP version and has different datasets; we evaluated Ganesh with the Java Servlets version and the Expanded dataset.",
                "The AUCTION benchmark defines two different workloads.",
                "The first, the Bidding mix, consists of 70% read-only operations and 30% read-write operations.",
                "The second, the Browsing mix, contains only read-only operations and does not update the database. 4.2 Experimental Procedure Both benchmarks involve a synthetic workload of clients accessing a web server.",
                "The number of clients emulated is an experimental parameter.",
                "Each emulated client runs an instance of the benchmark in its own thread, using a matrix to transition between different benchmark states.",
                "The matrix defines a stochastic model with probabilities of transitioning between the different states that represent typical user actions.",
                "An example transition is a user logging into the AUCTION system and then deciding on whether to post an item for sale or bid on active auctions.",
                "Each client also models user think time between requests.",
                "The think time is modeled as an exponential distribution with a mean of 7 seconds.",
                "We evaluate Ganesh along two axes: number of clients and WAN bandwidth.",
                "Higher loads are especially useful in understanding Ganeshs performance when the CPU or disk of the database server or proxy is the limiting factor.",
                "A previous study has shown that approximately 50% of the wide-area Internet bottlenecks observed had an available bandwidth under 10 Mb/s [1].",
                "Based on this work, we focus our evaluation on the WAN bandwidth of 5 Mb/s with 66 ms of round-trip latency, representative of severely constrained network paths, and 20 Mb/s with 33 ms of round-trip latency, representative of a moderately constrained network path.",
                "We also report Ganeshs performance at 100 Mb/s with no added round-trip latency.",
                "This bandwidth, representative of an unconstrained network, is especially useful in revealing any potential overhead of Ganesh in situations where WAN bandwidth is not the limiting factor.",
                "For each combination of number of clients and WAN bandwidth, we measured results from the two configurations listed below: • Native: This configuration corresponds to Figure 3(a).",
                "Native avoids Ganeshs overhead in using a proxy and performing Java object serialization. • Ganesh: This configuration corresponds to Figure 3(b).",
                "For a given number of clients and WAN bandwidth, comparing these results to the corresponding Native results gives the performance benefit due to the Ganesh middleware system.",
                "The metric used to quantify the improvement in throughput is the number of client requests that can be serviced per second.",
                "The metric used to quantify Ganeshs overhead is the average response time for a client request.",
                "For all of the experiments, the Ganesh driver used by the application server used a cache size of 100,000 items1 .",
                "The proxy was effective in tracking the Ganesh drivers cache state; for all of our experiments the miss rate on the driver never exceeded 0.7%. 4.3 Experimental Setup The experimental setup used for the benchmarks can be seen in Figure 5.",
                "All machines were 3.2 GHz Pentium 4s (with HyperThreading enabled.)",
                "With the exception of the database server, all machines had 2 GB of SDRAM and ran the Fedora Core Linux distribution.",
                "The database server had 4 GB of SDRAM.",
                "We used Apaches Tomcat as both the application server that hosted the Java Servlets and the web server.",
                "Both benchmarks used Java Servlets to generate the dynamic content.",
                "The database server used the open source MySQL database.",
                "For the native JDBC drivers, we used the Connector/J drivers provided by MySQL.",
                "The application server used Suns Java Virtual Machine as the runtime environment for the Java Servlets.",
                "The sysstat tool was used to monitor the CPU, network, disk, and memory utilization on all machines.",
                "The machines were connected by a switched gigabit Ethernet network.",
                "As shown in Figure 5, the front-end web and application server was separated from the proxy and database server by a NetEm router [16].",
                "This router allowed us to control the bandwidth and latency settings on the network.",
                "The NetEm router is a standard PC with two network cards running the Linux Traffic Control and Network Emulation software.",
                "The bandwidth and latency constraints were only applied to the link between the application server and the database for the native case and between the application server and the proxy for the Ganesh case.",
                "There is no communication between the application server and the database with Ganesh as all data flows through the proxy.",
                "As our focus was on the WAN link between the application server and the database, there were no constraints on the link between the simulated test clients and the web server. 5.",
                "THROUGHPUT AND RESPONSE TIME In this section, we address the first question raised in Section 4: Can performance can be improved significantly by exploiting similarity across database results?",
                "To answer this question, we use results from the BBOARD and AUCTION benchmarks.",
                "We use two metrics to quantify the performance improvement obtainable through the use of Ganesh: throughput, from the perspective of the web server, and average response time, from the perspective of the client.",
                "Throughput is measured in terms of the number of client requests that can be serviced per second. 5.1 BBOARD Results and Analysis 5.1.1 Authoring Mix Figures 6 (a) and (b) present the average number of requests serviced per second and the average response time for these requests as perceived by the clients for BBOARDs Authoring Mix.",
                "As Figure 6 (a) shows, Native easily saturates the 5 Mb/s link.",
                "At 400 clients, the Native solution delivers 29 requests/sec with an average response time of 8.3 seconds.",
                "Natives throughput drops with an increase in test clients as clients timeout due to congestion at the application server.",
                "Usability studies have shown that response times above 10 seconds cause the user to move on to 1 As Java lacks a sizeof() operator, Java caches therefore limit their size based on the number of objects.",
                "The size of cache dumps taken at the end of the experiments never exceeded 212 MB.",
                "WWW 2007 / Track: Performance and Scalability Session: Scalable Systems for Dynamic Content 315 0 50 100 150 200 250 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Test Clients Requests/sec Native Ganesh 0.001 0.01 0.1 1 10 100 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Test Clients Avg.Resp.Time(sec) Native Ganesh Note Logscale (a) Throughput: Authoring Mix (b) Response Time: Authoring Mix 0 50 100 150 200 250 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Test Clients Requests/sec Native Ganesh 0.001 0.01 0.1 1 10 100 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Test Clients Avg.Resp.Time(sec) Native Ganesh Note Logscale (c) Throughput: Browsing Mix (d) Response Time: Browsing Mix Mean of three trials.",
                "The maximum standard deviation for throughput and response time was 9.8% and 11.9% of the corresponding mean.",
                "Figure 6: BBOARD Benchmark - Throughput and Average Response Time other tasks [24].",
                "Based on these numbers, increasing the number of test clients makes the Native system unusable.",
                "Ganesh at 5 Mb/s, however, delivers a twofold improvement with 400 test clients and a fivefold improvement at 1200 clients.",
                "Ganeshs performance drops slightly at 1200 and 1600 clients as the network is saturated.",
                "Compared to Native, Figure 6 (b) shows that Ganeshs response times are substantially lower with sub-second response times at 400 clients.",
                "Figure 6 (a) also shows that for 400 and 800 test clients Ganesh at 5 Mb/s has the same throughput and average response time as Native at 20 Mb/s.",
                "Only at 1200 and 1600 clients does Native at 20 Mb/s deliver higher throughput than Ganesh at 5 Mb/s.",
                "Comparing both Ganesh and Native at 20 Mb/s, we see that Ganesh is no longer bandwidth constrained and delivers up to a twofold improvement over Native at 1600 test clients.",
                "As Ganesh does not saturate the network with higher test client configurations, at 1600 test clients, its average response time is 0.1 seconds rather than Natives 7.7 seconds.",
                "As expected, there are no visible gains from Ganesh at the higher bandwidth of 100 Mb/s where the network is no longer the bottleneck.",
                "Ganesh, however, still tracks Native in terms of throughput. 5.1.2 Browsing Mix Figures 6 (c) and (d) present the average number of requests serviced per second and the average response time for these requests as perceived by the clients for BBOARDs Browsing Mix.",
                "Regardless of the test client configuration, Figure 6 (c) shows that Natives throughput at 5 Mb/s is limited to 10 reqs/sec.",
                "Ganesh at 5 Mb/s with 400 test clients, delivers more than a sixfold increase in throughput.",
                "The improvement increases to over a elevenfold increase at 800 test clients before Ganesh saturates the network.",
                "Further, Figure 6 (d) shows that Natives average response time of 35 seconds at 400 test clients make the system unusable.",
                "These high response times further increase with the addition of test clients.",
                "Even with the 1600 test client configuration Ganesh delivers an acceptable average response time of 8.2 seconds.",
                "Due to the data-intensive nature of the Browsing mix, Ganesh at 5 Mb/s surprisingly performs much better than Native at 20 Mb/s.",
                "Further, as shown in Figure 6 (d), while the average response time for Native at 20 Mb/s is acceptable at 400 test clients, it is unusable with 800 test clients with an average response time of 15.8 seconds.",
                "Like the 5 Mb/s case, this response time increases with the addition of extra test clients.",
                "Ganesh at 20 Mb/s and both Native and Ganesh at 100 Mb/s are not bandwidth limited.",
                "However, performance plateaus out after 1200 test clients due to the database CPU being saturated. 5.1.3 Filter Variant We were surprised by the Native performance from the BBOARD benchmark.",
                "At the bandwidth of 5 Mb/s, Native performance was lower than what we had expected.",
                "It turned out the benchmark code that displays stories read all the comments associated with the particular story from the database and only then did some postprocessing to select the comments to be displayed.",
                "While this is exactly the behavior of SlashCode, the code base behind the Slashdot web site, we decided to modify the benchmark to perform some pre-filtering at the database.",
                "This modified benchmark, named the Filter Variant, models a developer who applies optimizations at the SQL level to transfer less data.",
                "In the interests of brevity, we only briefly summarize the results from the Authoring mix.",
                "For the Authoring mix, at 800 test clients at 5 Mb/s, Figure 7 (a) shows that Natives throughput increase by 85% when compared to the original benchmark while Ganeshs improvement is smaller at 15%.",
                "Natives performance drops above 800 clients as the test clients time out due to high response times.",
                "The most significant gain for Native is seen at 20 Mb/s.",
                "At 1600 test clients, when compared to the original benchmark, Native sees a 73% improvement in throughput and a 77% reduction in average response time.",
                "While WWW 2007 / Track: Performance and Scalability Session: Scalable Systems for Dynamic Content 316 0 50 100 150 200 250 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Test Clients Requests/sec Native Ganesh 0.001 0.01 0.1 1 10 100 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Test Clients Avg.Resp.Time(sec) Native Ganesh Note Logscale (a) Throughput: Authoring Mix (b) Response Time: Authoring Mix Mean of three trials.",
                "The maximum standard deviation for throughput and response time was 7.2% and 11.5% of the corresponding mean.",
                "Figure 7: BBOARD Benchmark - Filter Variant - Throughput and Average Response Time Ganesh sees no improvement when compared to the original, it still processes 19% more requests/sec than Native.",
                "Thus, while the optimizations were more helpful to Native, Ganesh still delivers an improvement in performance. 5.2 AUCTION Results and Analysis 5.2.1 Bidding Mix Figures 8 (a) and (b) present the average number of requests serviced per second and the average response time for these requests as perceived by the clients for AUCTIONs Bidding Mix.",
                "As mentioned earlier, the Bidding mix consists of a mixture of read and write operations.",
                "The AUCTION benchmark is not as data intensive as BBOARD.",
                "Therefore, most of the gains are observed at the lower bandwidth of 5 Mb/s.",
                "Figure 8 (a) shows that the increase in throughput due to Ganesh ranges from 8% at 400 test clients to 18% with 1600 test clients.",
                "As seen in Figure 8 (b), the average response times for Ganesh are significantly lower than Native ranging from a decrease of 84% at 800 test clients to 88% at 1600 test clients.",
                "Figure 8 (a) also shows that with a fourfold increase of bandwidth from 5 Mb/s to 20 Mb/s, Native is no longer bandwidth constrained and there is no performance difference between Ganesh and Native.",
                "With the higher test client configurations, we did observe that the bandwidth used by Ganesh was lower than Native.",
                "Ganesh might still be useful in these non-constrained scenarios if bandwidth is purchased on a metered basis.",
                "Similar results are seen for the 100 Mb/s scenario. 5.2.2 Browsing Mix For AUCTIONs Browsing Mix, Figures 8 (c) and (d) present the average number of requests serviced per second and the average response time for these requests as perceived by the clients.",
                "Again, most of the gains are observed at lower bandwidths.",
                "At 5 Mb/s, Native and Ganesh deliver similar throughput and response times with 400 test clients.",
                "While the throughput for both remains the same at 800 test clients, Figure 8 (d) shows that Ganeshs average response time is 62% lower than Native.",
                "Native saturates the link at 800 clients and adding extra test clients only increases the average response time.",
                "Ganesh, regardless of the test client configuration, is not bandwidth constrained and maintains the same response time.",
                "At 1600 test clients, Figure 8 (c) shows that Ganeshs throughput is almost twice that of Native.",
                "At the higher bandwidths of 20 and 100 Mb/s, neither Ganesh nor Native is bandwidth limited and deliver equivalent throughput and response times.",
                "Benchmark Orig.",
                "Size Ganesh Size Rabin Size SelectSort1 223.6 MB 5.4 MB 219.3 MB SelectSort2 223.6 MB 5.4 MB 223.6 MB Table 2: Similarity Microbenchmarks 6.",
                "STRUCTURAL VS. RABIN SIMILARITY In this section, we address the second question raised in Section 4: How important is Ganeshs structural similarity detection relative to Rabin fingerprinting-based similarity detecting?",
                "To answer this question, we used microbenchmarks and the BBOARD and AUCTION benchmarks.",
                "As Ganesh always performed better than Rabin fingerprinting, we only present a subset of the results here in the interests of brevity. 6.1 Microbenchmarks Two microbenchmarks show an example of the effects of data reordering on Rabin fingerprinting algorithm.",
                "In the first microbenchmark, SelectSort1, a query with a specified sort order selects 223.6 MB of data spread over approximately 280 K rows.",
                "The query is then repeated with a different sort attribute.",
                "While the same number of rows and the same data is returned, the order of rows is different.",
                "In such a scenario, one would expect a large amount of similarity to be detected between both results.",
                "As Table 2 shows, Ganeshs row-based algorithm achieves a 97.6% reduction while the Rabin fingerprinting algorithm, with the average chunk size parameter set to 4 KB, only achieves a 1% reduction.",
                "The reason, as shown earlier in Figure 2, is that with Rabin fingerprinting, the spans of data between two consecutive boundaries usually cross row boundaries.",
                "With the order of the rows changing in the second result and the Rabin fingerprints now spanning different rows, the algorithm is unable to detect significant similarity.",
                "The small gain seen is mostly for those single rows that are large enough to be broken into multiple chunks.",
                "SelectSort2, another micro-benchmark executed the same queries but increased the minimum chunk size of the Rabin fingerprinting algorithm.",
                "As can be seen in Table 2, even the small gain from the previous microbenchmark disappears as the minimum chunk size was greater than the average row size.",
                "While one can partially address these problems by dynamically varying the parameters of the Rabin fingerprinting algorithm, this can be computationally expensive, especially in the presence of changing workloads. 6.2 Application Benchmarks We ran the BBOARD benchmark described in Section 4.1.1 on two versions of Ganesh: the first with Rabin fingerprinting used as WWW 2007 / Track: Performance and Scalability Session: Scalable Systems for Dynamic Content 317 0 50 100 150 200 250 300 350 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Test Clients Requests/sec Native Ganesh 0.001 0.01 0.1 1 10 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Test Clients Avg.Resp.Time(sec) Native Ganesh Note Logscale (a) Throughput: Bidding Mix (b) Response Time: Bidding Mix 0 50 100 150 200 250 300 350 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Test Clients Requests/sec Native Ganesh 0.001 0.01 0.1 1 10 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Test Clients Avg.Resp.Time(sec) Native Ganesh Note Logscale (c) Throughput: Browsing Mix (d) Response Time: Browsing Mix Mean of three trials.",
                "The maximum standard deviation for throughput and response time was 2.2% and 11.8% of the corresponding mean.",
                "Figure 8: AUCTION Benchmark - Throughput and Average Response Time the chunking algorithm and the second with Ganeshs row-based algorithm.",
                "Rabins results for the Browsing Mix are normalized to Ganeshs results and presented in Figure 9.",
                "As Figure 9 (a) shows, at 5 Mb/s, independent of the test client configuration, Rabin significantly underperforms Ganesh.",
                "This happens because of a combination of two reasons.",
                "First, as outlined in Section 3.1, Rabin finds less similarity as it does not exploit the results structural information.",
                "Second, this benchmark contained some queries that generated large results.",
                "In this case, Rabin, with a small average chunk size, generated a large number of objects that evicted other useful data from the cache.",
                "In contrast, Ganesh was able to detect these large rows and correspondingly increase the size of the chunks.",
                "This was confirmed as cache statistics showed that Ganeshs hit ratio was roughly three time that of Rabin.",
                "Throughput measurements at 20 Mb/s were similar with the exception of Rabins performance with 400 test clients.",
                "In this case, Ganesh was not network limited and, in fact, the throughput was the same as 400 clients at 5 Mb/s.",
                "Rabin, however, took advantage of the bandwidth increase from 5 to 20 Mb/s to deliver a slightly better performance.",
                "At 100 Mb/s, Rabins throughput was almost similar to Ganesh as bandwidth was no longer a bottleneck.",
                "The normalized response time, presented in Figure 9 (b), shows similar trends.",
                "At 5 and 20 Mb/s, the addition of test clients decreases the normalized response time as Ganeshs average response time increases faster than Rabins.",
                "However, at no point does Rabin outperform Ganesh.",
                "Note that at 400 and 800 clients at 100 Mb/s, Rabin does have a higher overhead even when it is not bandwidth constrained.",
                "As mentioned in Section 3.1, this is due to the fact that Rabin has to hash each ResultSet twice.",
                "The overhead disappears with 1200 and 1600 clients as the database CPU is saturated and limits the performance of both Ganesh and Rabin. 7.",
                "PROXY OVERHEAD In this section, we address the third question raised in Section 4: Is the overhead of Ganeshs proxy-based design acceptable?",
                "To answer this question, we concentrate on its performance at the higher bandwidths.",
                "Our evaluation in Section 5 showed that Ganesh, when compared to Native, can deliver a substantial throughput improvement at lower bandwidths.",
                "It is only at higher bandwidths that latency, measured by the average response time for a client request, and throughput, measured by the number of client requests that can be serviced per second, overheads would be visible.",
                "Looking at the Authoring mix of the original BBOARD benchmark, there are no visible gains from Ganesh at 100 Mb/s.",
                "Ganesh, however, still tracks Native in terms of throughput.",
                "While the average response time is higher for Ganesh, the absolute difference is in between 0.01 and 0.04 seconds and would be imperceptible to the end-user.",
                "The Browsing mix shows an even smaller difference in average response times.",
                "The results from the filter variant of the BBOARD benchmarks are similar.",
                "Even for the AUCTION benchmark, the difference between Native and Ganeshs response time at 100 Mb/s was never greater than 0.02 seconds.",
                "The only exception to the above results was seen in the filter variant of the BBOARD benchmark where Ganesh at 1600 test clients added 0.85 seconds to the average response time.",
                "Thus, even for much faster networks where the WAN link is not the bottleneck, Ganesh always delivers throughput equivalent to Native.",
                "While some extra latency is added by the proxy-based design, it is usually imperceptible. 8.",
                "RELATED WORK To the best of our knowledge, Ganesh is the first system that combines the use of hash-based techniques with caching of database results to improve throughput and response times for applications with dynamic content.",
                "We also believe that it is also the first system to demonstrate the benefits of using structural information for WWW 2007 / Track: Performance and Scalability Session: Scalable Systems for Dynamic Content 318 0.0 0.2 0.4 0.6 0.8 1.0 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Test Clients Norm.Throughput 31.8 3.8 2.8 2.3 23.8 32.8 5.8 3.6 1.8 2.1 1.1 1.0 0 5 10 15 20 25 30 35 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Test Clients Norm.ResponseTime (a) Normalized Throughput: Higher is better (b) Normalized Response Time: Higher is worse For throughput, a normalized result greater than 1 implies that Rabin is better, For response time, a normalized result greater than 1 implies that Ganesh is better.",
                "Mean of three trials.",
                "The maximum standard deviation for throughput and response time was 9.1% and 13.9% of the corresponding mean.",
                "Figure 9: Normalized Comparison of Ganesh vs. Rabin - BBOARD Browsing Mix detecting similarity.",
                "In this section, we first discuss alternative approaches to caching dynamic content and then examine other uses of hash-based primitives in distributed systems. 8.1 Caching Dynamic Content At the database layer, a number of systems have advocated middletier caching where parts of the database are replicated at the edge or server [3, 4, 20].",
                "These systems either cache entire tables in what is essentially a replicated database or use materialized views from previous query replies [19].",
                "They require tight integration with the back-end database to ensure a time bound on the propagation of updates.",
                "These systems are also usually targeted towards workloads that do not require strict consistency and can tolerate stale data.",
                "Further, unlike Ganesh, some of these mid-tier caching solutions [2, 3], suffer from the complexity of having to participate in query planing and distributed query processing.",
                "Gao et al. [15] propose using a distributed object replication architecture where the data stores consistency requirements are adapted on a per-application basis.",
                "These solutions require substantial developer resources and detailed understanding of the application being modified.",
                "While systems that attempt to automate the partitioning and replication of an applications database exist [34], they do not provide full transaction semantics.",
                "In comparison, Ganesh does not weaken any of the semantics provided by the underlying database.",
                "Recent work in the evaluation of edge caching options for dynamic web sites [38] has suggested that, without careful planning, employing complex offloading strategies can hurt performance.",
                "Instead, the work advocates for an architecture in which all tiers except the database should be offloaded to the edge.",
                "Our evaluation of Ganesh has shown that it would benefit these scenarios.",
                "To improve database scalability, C-JDBC [10], SSS [22], and Ganymed [28] also advocate the use of an interposition-based architecture to transparently cluster and replicate databases at the middleware level.",
                "The approaches of these architectures and Ganesh are complementary and they would benefit each other.",
                "Moving up to the presentation layer, there has been widespread adoption of fragment-based caching [14], which improves cache utilization by separately caching different parts of generated web pages.",
                "While fragment-based caching works at the edge, a recent proposal has proposed moving web page assembly to the clients to optimize content delivery [31].",
                "While Ganesh is not used at the presentation layer, the same principles have been applied in Duplicate Transfer Detection [25] to increase web cache efficiency as well as for web access across bandwidth limited links [33]. 8.2 Hash-based Systems The past few years have seen the emergence of many systems that exploit hash-based techniques.",
                "At the heart of all these systems is the idea of detecting similarity in data without requiring interpretation of that data.",
                "This simple yet elegant idea relies on cryptographic hashing, as discussed earlier in Section 2.",
                "Successful applications of this idea span a wide range of storage systems.",
                "Examples include peer-to-peer backup of personal computing files [11], storage-efficient archiving of data [29], and finding similar files [21].",
                "Spring and Wetherall [35] apply similar principles at the network level.",
                "Using synchronized caches at both ends of a network link, duplicated data is replaced by smaller tokens for transmission and then restored at the remote end.",
                "This and other hash-based systems such as the CASPER [37] and LBFS [26] filesystems, and Layer-2 bandwidth optimizers such as Riverbed and Peribit use Rabin fingerprinting [30] to discover spans of commonality in data.",
                "This approach is especially useful when data items are modified in-place through insertions, deletions, and updates.",
                "However, as Section 6 shows, the performance of this technique can show a dramatic drop in the presence of data reordering.",
                "Ganesh instead uses row boundaries as dividers for detecting similarity.",
                "The most aggressive use of hash-based techniques is by systems that use hashes as the primary identifiers for objects in persistent storage.",
                "Storage systems such as CFS [12] and PAST [13] that have been built using distributed hash tables fall into this category.",
                "Single Instance Storage [6] and Venti [29] are other examples of such systems.",
                "As discussed in Section 2.2, the use of cryptographic hashes for addressing persistent data represents a deeper level of faith in their collision-resistance than that assumed by Ganesh.",
                "If time reveals shortcomings in the hash algorithm, the effort involved in correcting the flaw is much greater.",
                "In Ganesh, it is merely a matter of replacing the hash algorithm. 9.",
                "CONCLUSION The growing use of dynamic web content generated from relational databases places increased demands on WAN bandwidth.",
                "Traditional caching solutions for bandwidth and latency reduction are often ineffective for such content.",
                "This paper shows that the impact of WAN accesses to databases can be substantially reduced through the Ganesh architecture without any compromise of the databases strict consistency semantics.",
                "The essence of the Ganesh architecture is the use of computation at the edges to reduce communication through the Internet.",
                "Ganesh is able to use cryptographic hashes to detect similarity with previous results and send WWW 2007 / Track: Performance and Scalability Session: Scalable Systems for Dynamic Content 319 compact recipes of results rather than full results.",
                "Our design uses interposition to achieve complete transparency: clients, application servers, and database servers are all unaware of Ganeshs presence and require no modification.",
                "Our experimental evaluation confirms that Ganesh, while conceptually simple, can be highly effective in improving throughput and response time.",
                "Our results also confirm that exploiting the structure present in database results to detect similarity is crucial to this performance improvement. 10.",
                "REFERENCES [1] AKELLA, A., SESHAN, S., AND SHAIKH, A.",
                "An empirical evaluation of wide-area internet bottlenecks.",
                "In Proc. 3rd ACM SIGCOMM Conference on Internet Measurement (Miami Beach, FL, USA, Oct. 2003), pp. 101-114. [2] ALTINEL, M., BORNH ¨OVD, C., KRISHNAMURTHY, S., MOHAN, C., PIRAHESH, H., AND REINWALD, B. Cache tables: Paving the way for an adaptive database cache.",
                "In Proc. of 29th VLDB (Berlin, Germany, 2003), pp. 718-729. [3] ALTINEL, M., LUO, Q., KRISHNAMURTHY, S., MOHAN, C., PIRAHESH, H., LINDSAY, B. G., WOO, H., AND BROWN, L. Dbcache: Database caching for web application servers.",
                "In Proc. 2002 ACM SIGMOD (2002), pp. 612-612. [4] AMIRI, K., PARK, S., TEWARI, R., AND PADMANABHAN, S. Dbproxy: A dynamic data cache for web applications.",
                "In Proc.",
                "IEEE International Conference on Data Engineering (ICDE) (Mar. 2003). [5] BLACK, J. Compare-by-hash: A reasoned analysis.",
                "In Proc. 2006 USENIX Annual Technical Conference (Boston, MA, May 2006), pp. 85-90. [6] BOLOSKY, W. J., CORBIN, S., GOEBEL, D., , AND DOUCEUR, J. R. Single instance storage in windows 2000.",
                "In Proc. 4th USENIX Windows Systems Symposium (Seattle, WA, Aug. 2000), pp. 13-24. [7] BREWER, E. A.",
                "Lessons from giant-scale services.",
                "IEEE Internet Computing 5, 4 (2001), 46-55. [8] BRODER, A., GLASSMAN, S., MANASSE, M., AND ZWEIG, G. Syntactic clustering of the web.",
                "In Proc. 6th International WWW Conference (1997). [9] CECCHET, E., CHANDA, A., ELNIKETY, S., MARGUERITE, J., AND ZWAENEPOEL, W. Performance comparison of middleware architectures for generating dynamic web content.",
                "In Proc.",
                "Fourth ACM/IFIP/USENIX International Middleware Conference (Rio de Janeiro, Brazil, June 2003). [10] CECCHET, E., MARGUERITE, J., AND ZWAENEPOEL, W. C-JDBC: Flexible database clustering middleware.",
                "In Proc. 2004 USENIX Annual Technical Conference (Boston, MA, June 2004). [11] COX, L. P., MURRAY, C. D., AND NOBLE, B. D. Pastiche: Making backup cheap and easy.",
                "In OSDI: Symposium on Operating Systems Design and Implementation (2002). [12] DABEK, F., KAASHOEK, M. F., KARGER, D., MORRIS, R., AND STOICA, I. Wide-area cooperative storage with CFS.",
                "In 18th ACM Symposium on Operating Systems Principles (Banff, Canada, Oct. 2001). [13] DRUSCHEL, P., AND ROWSTRON, A.",
                "PAST: A large-scale, persistent peer-to-peer storage utility.",
                "In HotOS VIII (Schloss Elmau, Germany, May 2001), pp. 75-80. [14] Edge side includes. http://www.esi.org. [15] GAO, L., DAHLIN, M., NAYATE, A., ZHENG, J., AND IYENGAR, A.",
                "Application specific data replication for edge services.",
                "In WWW 03: Proc.",
                "Twelfth International Conference on World Wide Web (2003), pp. 449-460. [16] HEMMINGER, S. Netem - emulating real networks in the lab.",
                "In Proc. 2005 Linux Conference Australia (Canberra, Australia, Apr. 2005). [17] HENSON, V. An analysis of compare-by-hash.",
                "In Proc. 9th Workshop on Hot Topics in Operating Systems (HotOS IX) (May 2003), pp. 13-18. [18] Jmob benchmarks. http://jmob.objectweb.org/. [19] LABRINIDIS, A., AND ROUSSOPOULOS, N. Balancing performance and data freshness in web database servers.",
                "In Proc. 29th VLDB Conference (Sept. 2003). [20] LARSON, P.-A., GOLDSTEIN, J., AND ZHOU, J. Transparent mid-tier database caching in sql server.",
                "In Proc. 2003 ACM SIGMOD (2003), pp. 661-661. [21] MANBER, U.",
                "Finding similar files in a large file system.",
                "In Proc.",
                "USENIX Winter 1994 Technical Conference (San Fransisco, CA, 17-21 1994), pp. 1-10. [22] MANJHI, A., AILAMAKI, A., MAGGS, B. M., MOWRY, T. C., OLSTON, C., AND TOMASIC, A.",
                "Simultaneous scalability and security for data-intensive web applications.",
                "In Proc. 2006 ACM SIGMOD (June 2006), pp. 241-252. [23] MENEZES, A. J., VANSTONE, S. A., AND OORSCHOT, P. C. V. Handbook of Applied Cryptography.",
                "CRC Press, 1996. [24] MILLER, R. B.",
                "Response time in man-computer conversational transactions.",
                "In Proc.",
                "AFIPS Fall Joint Computer Conference (1968), pp. 267-277. [25] MOGUL, J. C., CHAN, Y. M., AND KELLY, T. Design, implementation, and evaluation of duplicate transfer detection in http.",
                "In Proc.",
                "First Symposium on Networked Systems Design and Implementation (San Francisco, CA, Mar. 2004). [26] MUTHITACHAROEN, A., CHEN, B., AND MAZIERES, D. A low-bandwidth network file system.",
                "In Proc. 18th ACM Symposium on Operating Systems Principles (Banff, Canada, Oct. 2001). [27] PFEIFER, D., AND JAKSCHITSCH, H. Method-based caching in multi-tiered server applications.",
                "In Proc.",
                "Fifth International Symposium on Distributed Objects and Applications (Catania, Sicily, Italy, Nov. 2003). [28] PLATTNER, C., AND ALONSO, G. Ganymed: Scalable replication for transactional web applications.",
                "In Proc. 5th ACM/IFIP/USENIX International Conference on Middleware (2004), pp. 155-174. [29] QUINLAN, S., AND DORWARD, S. Venti: A new approach to archival storage.",
                "In Proc.",
                "FAST 2002 Conference on File and Storage Technologies (2002). [30] RABIN, M. Fingerprinting by random polynomials.",
                "In Harvard University Center for Research in Computing Technology Technical Report TR-15-81 (1981). [31] RABINOVICH, M., XIAO, Z., DOUGLIS, F., AND KALMANEK, C. Moving edge side includes to the real edge - the clients.",
                "In Proc. 4th USENIX Symposium on Internet Technologies and Systems (Seattle, WA, Mar. 2003). [32] REESE, G. Database Programming with JDBC and Java, 1st ed.",
                "OReilly, June 1997. [33] RHEA, S., LIANG, K., AND BREWER, E. Value-based web caching.",
                "In Proc.",
                "Twelfth International World Wide Web Conference (May 2003). [34] SIVASUBRAMANIAN, S., ALONSO, G., PIERRE, G., AND VAN STEEN, M. Globedb: Autonomic data replication for web applications.",
                "In WWW 05: Proc. 14th International World-Wide Web conference (May 2005). [35] SPRING, N. T., AND WETHERALL, D. A protocol-independent technique for eliminating redundant network traffic.",
                "In Proc. of ACM SIGCOMM (Aug. 2000). [36] TOLIA, N., HARKES, J., KOZUCH, M., AND SATYANARAYANAN, M. Integrating portable and distributed storage.",
                "In Proc. 3rd USENIX Conference on File and Storage Technologies (San Francisco, CA, Mar. 2004). [37] TOLIA, N., KOZUCH, M., SATYANARAYANAN, M., KARP, B., PERRIG, A., AND BRESSOUD, T. Opportunistic use of content addressable storage for distributed file systems.",
                "In Proc. 2003 USENIX Annual Technical Conference (San Antonio, TX, June 2003), pp. 127-140. [38] YUAN, C., CHEN, Y., AND ZHANG, Z.",
                "Evaluation of edge caching/offloading for dynamic content delivery.",
                "In WWW 03: Proc.",
                "Twelfth International Conference on World Wide Web (2003), pp. 461-471.",
                "WWW 2007 / Track: Performance and Scalability Session: Scalable Systems for Dynamic Content 320"
            ],
            "original_annotated_samples": [
                "Consistency-preserving Caching of Dynamic <br>database content</br>∗ Niraj Tolia and M. Satyanarayanan Carnegie Mellon University {ntolia,satya}@cs.cmu.edu ABSTRACT With the growing use of dynamic web content generated from relational databases, traditional caching solutions for throughput and latency improvements are ineffective.",
                "Even when <br>database content</br> remains unchanged, temporal locality of access cannot be exploited because dynamic content is not cacheable by web browsers or by intermediate caching servers such as Akamai mirrors.",
                "Previous attempts in caching dynamic <br>database content</br> have generally weakened transactional semantics [3, 4] or required application modifications [15, 34]."
            ],
            "translated_annotated_samples": [
                "Conservación de la consistencia en el almacenamiento en caché de contenido dinámico de bases de datos∗ Niraj Tolia y M. Satyanarayanan Universidad Carnegie Mellon {ntolia,satya}@cs.cmu.edu RESUMEN Con el creciente uso de contenido web dinámico generado a partir de bases de datos relacionales, las soluciones de almacenamiento en caché tradicionales para mejorar el rendimiento y la latencia son ineficaces.",
                "Incluso cuando el <br>contenido de la base de datos</br> permanece sin cambios, la localidad temporal de acceso no puede ser explotada porque el contenido dinámico no es almacenable en caché por los navegadores web o por servidores de almacenamiento en caché intermedios como los espejos de Akamai.",
                "Los intentos previos de almacenar en caché <br>contenido dinámico de bases de datos</br> generalmente han debilitado la semántica transaccional [3, 4] o han requerido modificaciones en la aplicación [15, 34]."
            ],
            "translated_text": "Conservación de la consistencia en el almacenamiento en caché de contenido dinámico de bases de datos∗ Niraj Tolia y M. Satyanarayanan Universidad Carnegie Mellon {ntolia,satya}@cs.cmu.edu RESUMEN Con el creciente uso de contenido web dinámico generado a partir de bases de datos relacionales, las soluciones de almacenamiento en caché tradicionales para mejorar el rendimiento y la latencia son ineficaces. Describimos una capa de middleware llamada Ganesh que reduce el volumen de datos transmitidos sin interpretación semántica de consultas o resultados. Se logra esta reducción mediante el uso de hash criptográficos para detectar similitudes con resultados anteriores. Estos beneficios no requieren ningún compromiso con la semántica de consistencia estricta proporcionada por la base de datos del servidor. Además, Ganesh no requiere modificaciones en aplicaciones, servidores web o servidores de bases de datos, y funciona con aplicaciones y bases de datos de código cerrado. Usando dos puntos de referencia representativos de sitios web dinámicos, las mediciones de nuestro prototipo muestran que puede aumentar el rendimiento de extremo a extremo hasta en un factor de dos para aplicaciones no intensivas en datos y hasta en un factor de diez para las intensivas en datos. Categorías y Descriptores de Asignaturas C.2.4 [Redes de Computadoras-Comunicación]: Sistemas Distribuidos; H.2.4 [Gestión de Bases de Datos]: Términos Generales de Sistemas de Diseño, Rendimiento 1. INTRODUCCIÓN Una fracción creciente del contenido web se genera dinámicamente a partir de bases de datos relacionales en el backend. Incluso cuando el <br>contenido de la base de datos</br> permanece sin cambios, la localidad temporal de acceso no puede ser explotada porque el contenido dinámico no es almacenable en caché por los navegadores web o por servidores de almacenamiento en caché intermedios como los espejos de Akamai. En una arquitectura multinivel, cada solicitud web puede tensionar el enlace WAN entre el servidor web y la base de datos. Esto provoca que la experiencia del usuario sea altamente variable porque no hay almacenamiento en caché para aislar al cliente de cargas repentinas. Los intentos previos de almacenar en caché <br>contenido dinámico de bases de datos</br> generalmente han debilitado la semántica transaccional [3, 4] o han requerido modificaciones en la aplicación [15, 34]. Informamos sobre una nueva solución que toma la forma de una capa intermedia de middleware independiente de la base de datos llamada Ganesh. Ganesh no hace ningún esfuerzo por interpretar semánticamente el contenido de las consultas o sus resultados. En cambio, se basa exclusivamente en el hash criptográfico para detectar similitudes con resultados anteriores. La detección de similitud basada en hash ha sido cada vez más utilizada en sistemas de archivos distribuidos [26, 36, 37] para mejorar el rendimiento en redes de baja capacidad de ancho de banda. Sin embargo, estas técnicas no se han utilizado para bases de datos relacionales. A diferencia de enfoques anteriores que utilizan métodos genéricos para detectar similitud, Ganesh explota la estructura de los resultados de la base de datos relacional para lograr una mejora superior en el rendimiento. Uno se enfrenta al menos a tres desafíos al aplicar la detección de similitud basada en hash a las bases de datos de back-end. Primero, el trabajo previo en este ámbito ha considerado tradicionalmente el contenido de almacenamiento como bolsas de bits no interpretadas y sin estructura interna. Esto permite que las técnicas basadas en hash operen en largas y contiguas secuencias de datos para lograr la máxima efectividad. Por el contrario, las bases de datos relacionales tienen una estructura interna compleja que puede no ser tan propicia para la detección de similitudes basada en hash. Segundo, las bases de datos relacionales tienen restricciones de integridad y consistencia muy estrictas que no deben comprometerse por el uso de técnicas basadas en hash. Tercero, el código fuente de las bases de datos comerciales generalmente no está disponible. Esto contrasta con trabajos anteriores que presumían la disponibilidad del código fuente. Nuestros experimentos muestran que Ganesh, aunque conceptualmente simple, puede mejorar significativamente el rendimiento en anchos de banda representativos del Internet comercial actual. En los modelos de referencia de aplicaciones web multinivel, la mejora en el rendimiento fue de hasta diez veces para cargas de trabajo intensivas en datos. Para cargas de trabajo que no eran intensivas en datos, se observaron mejoras en el rendimiento de hasta el doble. Incluso cuando el ancho de banda no era una limitación, Ganesh tenía un bajo sobrecosto y no afectaba el rendimiento. Nuestros experimentos también confirman que aprovechar la estructura presente en los resultados de la base de datos es crucial para esta mejora en el rendimiento. Antecedentes 2.1 Generación de Contenido Dinámico A medida que la World Wide Web ha crecido, muchos sitios web han descentralizado sus datos y funcionalidades al llevarlos a los extremos de Internet. Hoy en día, los sistemas de comercio electrónico a menudo utilizan una arquitectura de tres niveles que consta de un servidor web de front-end, un servidor de aplicaciones y un servidor de base de datos de back-end. La Figura 1 ilustra esta arquitectura. Los dos primeros niveles se pueden replicar cerca de una concentración de clientes en el borde de Internet. Esto mejora la experiencia del usuario al reducir la latencia de extremo a extremo y disminuir la exposición al congestionamiento del tráfico de la columna vertebral. También puede aumentar la disponibilidad y escalabilidad de los servicios web. El contenido que se genera dinámicamente desde la base de datos del servidor no puede ser almacenado en caché en los dos primeros niveles. Si bien las bases de datos pueden replicarse fácilmente en una LAN, esto es inviable en una WAN debido a la difícil tarea de proporcionar simultáneamente una consistencia sólida, disponibilidad y tolerancia a particiones de red [7]. Como resultado, las bases de datos tienden a ser centralizadas para cumplir con los fuertes requisitos de consistencia de muchas aplicaciones de comercio electrónico como la banca, las finanzas y la venta al por menor en línea [38]. Por lo tanto, la base de datos del back-end suele estar ubicada lejos de muchos conjuntos de nodos de primer y segundo nivel [2]. En ausencia de almacenamiento en caché y replicación, el ancho de banda de la WAN puede convertirse fácilmente en un factor limitante en el rendimiento y la escalabilidad de aplicaciones intensivas en datos. El enfoque de Ganesh en los sistemas basados en hash es la transmisión eficiente de resultados al descubrir similitudes con los resultados de consultas anteriores. Dado que las consultas SQL pueden generar resultados grandes, las técnicas basadas en hash se prestan bien al problema de transferir eficientemente estos grandes resultados a través de enlaces con ancho de banda limitado. El uso de técnicas basadas en hash para reducir el volumen de datos transmitidos ha surgido como un tema común en muchos sistemas de almacenamiento recientes, como se discute en la Sección 8.2. Estas técnicas se basan en algunas suposiciones básicas. Se asume que las funciones hash criptográficas son resistentes a colisiones. En otras palabras, es computacionalmente intratable encontrar dos entradas que se hash a la misma salida. Las funciones también se asumen como unidireccionales; es decir, encontrar una entrada que resulte en una salida específica es computacionalmente inviable. Menezes et al. [23] proporcionan más detalles sobre estas suposiciones. Las suposiciones anteriores permiten a los sistemas basados en hash asumir que no se producen colisiones. Por lo tanto, pueden tratar el hash de un elemento de datos como su identificador único. Una colección de elementos de datos se convierte efectivamente en direccionable por contenido, permitiendo que un hash pequeño funcione como una palabra de código para un elemento de datos mucho más grande en almacenamiento permanente o transmisión en red. La suposición de que las colisiones son tan raras que prácticamente no existen ha sido cuestionada recientemente [17]. Sin embargo, como explicó Black [5], creemos que estos problemas no son una preocupación para Ganesh. Toda comunicación es entre partes confiables del sistema y un adversario no tiene forma de obligar a Ganesh a aceptar datos inválidos. Además, Ganesh no depende críticamente de ninguna función hash específica. Si bien actualmente usamos SHA-1, reemplazarlo con una función hash diferente sería sencillo. No habría impacto en el rendimiento con funciones hash más fuertes (por ejemplo, SHA256) solo añade unos pocos bytes adicionales y los hashes generados siguen siendo órdenes de magnitud más pequeños que los elementos de datos que representan. No es necesario volver a almacenar permanentemente ya que Ganesh solo utiliza el hash en datos volátiles. 3. DISEÑO E IMPLEMENTACIÓN Ganesh explota la redundancia en el flujo de resultados para evitar transmitir fragmentos de resultados que ya están presentes en el sitio de la consulta. La redundancia puede surgir de forma natural de muchas maneras diferentes. Por ejemplo, una consulta repetida después de un cierto intervalo puede devolver un resultado diferente debido a actualizaciones en la base de datos; sin embargo, puede haber una significativa similitud entre los dos resultados. Como otro ejemplo, un usuario que está refinando una búsqueda puede generar una secuencia de consultas con resultados superpuestos. Cuando Ganesh detecta redundancia, suprime la transmisión de los fragmentos de resultado correspondientes. En cambio, transmite un resumen mucho más pequeño de esos fragmentos y permite que el sitio de consulta reconstruya el resultado a través de la búsqueda de hash en una caché de resultados anteriores. De hecho, Ganesh utiliza la computación en los bordes para reducir la comunicación por Internet. Nuestra descripción de Ganesh se centra en cuatro aspectos. Primero explicamos nuestro enfoque para detectar similitud en los resultados de la consulta. A continuación, discutimos cómo la arquitectura Ganesh es completamente invisible para todos los componentes de un sistema de múltiples niveles. Luego describimos el enfoque basado en proxy de Ganesh y el flujo de datos para detectar similitudes. 3.1 Detectar similitud Una de las decisiones clave de diseño en Ganesh es cómo se detecta la similitud. Hay muchas formas potenciales de descomponer un resultado en fragmentos.  I the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the thees I,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,, Encontrar esta descomposición óptima es un problema difícil debido al amplio espacio de posibilidades y porque la elección óptima depende de muchos factores, como el contenido del resultado de las consultas, el historial de resultados recientes y el algoritmo de gestión de caché. Cuando un objeto es opaco, el uso de huellas digitales de Rabin [8, 30] para detectar datos comunes entre dos objetos ha sido demostrado con éxito en el pasado por sistemas como LBFS [26] y CASPER [37]. El fingerprinting de Rabin utiliza una ventana deslizante sobre los datos para calcular un hash rodante. Suponiendo que la función hash está distribuida uniformemente, un límite de fragmento se define cuando los bits de orden inferior del valor hash son iguales a algún valor predeterminado. El número de bits de orden inferior utilizados define el tamaño promedio del fragmento. Estos fragmentos subdivididos del objeto se convierten en la unidad de comparación para detectar similitudes entre diferentes objetos. Dado que las ubicaciones de los límites encontrados mediante el uso de las huellas de Rabin están determinadas de manera estocástica, generalmente no logran alinearse con ninguna propiedad estructural de los datos subyacentes. Por lo tanto, el algoritmo maneja bien las actualizaciones en su lugar, inserciones y eliminaciones. Sin embargo, tiene un rendimiento deficiente en presencia de cualquier reordenamiento de datos. La Figura 2 muestra un ejemplo donde dos resultados, A y B, que constan de tres filas, tienen los mismos datos pero diferentes atributos de ordenamiento. En el caso extremo, la huella digital de Rabin podría no ser capaz de encontrar datos similares debido a la forma en que detecta los límites de los fragmentos. Afortunadamente, Ganesh puede utilizar conocimientos específicos del dominio para una detección de límites más precisa. La información que explotamos es que el resultado de una consulta refleja la estructura de una base de datos relacional donde todos los datos están organizados en tablas y filas. Por lo tanto, es sencillo verificar la similitud con resultados anteriores en dos niveles de granularidad: primero el resultado completo y luego las filas individuales. El final de una fila en un resultado sirve como un límite natural de fragmento. Es importante tener en cuenta que el uso de la estructura tabular en los resultados solo implica una interpretación superficial de los datos. Ganesh no realiza ninguna interpretación semántica más profunda, como comprender tipos de datos, esquemas de resultados o restricciones de integridad. Ajustar la huella digital de Rabin para una carga de trabajo también puede ser difícil. Si el tamaño promedio de los fragmentos es demasiado grande, los fragmentos pueden abarcar varias filas de resultados. Sin embargo, seleccionar un tamaño de fragmento promedio más pequeño aumenta la cantidad de metadatos necesarios para describir los resultados. Esto, a su vez, disminuiría los ahorros obtenidos mediante su uso. El fingerprinting de Rabin también requiere dos pasadas computacionalmente costosas sobre los datos: una vez para determinar los límites de los fragmentos y otra vez para generar hashes criptográficos para los fragmentos. Ganesh solo necesita un único pase para la generación de hash, ya que los límites de los fragmentos son proporcionados por la estructura natural de los datos. La comparación de rendimiento en la Sección 6 muestra que el algoritmo basado en filas de Ganesh supera al fingerprinting de Rabin. Dado que trabajos anteriores ya han demostrado que la huella digital de Rabin funciona mejor que gzip [26], no comparamos a Ganesh con algoritmos de compresión en este artículo. 3.2 Transparencia El factor clave que influyó en nuestro diseño fue la necesidad de que Ganesh fuera completamente transparente para todos los componentes de un sistema típico de comercio electrónico: servidores web, servidores de aplicaciones y servidores de bases de datos. Sin esto, Ganesh tiene pocas posibilidades de tener un impacto significativo en el mundo real. Requerir modificaciones en cualquiera de los componentes mencionados aumentaría la barrera de entrada de Ganesh en un sistema existente, y por lo tanto reduciría sus posibilidades de adopción. Preservar la transparencia se simplifica por el hecho de que Ganesh es simplemente una mejora de rendimiento, no una mejora de funcionalidad o usabilidad. Elegimos la interposición de agentes como enfoque arquitectónico para lograr nuestro objetivo. Este enfoque se basa en la existencia de una interfaz de programación compacta que ya es ampliamente utilizada por el software objetivo. También se basa en un mecanismo para agregar fácilmente nuevo código sin interrumpir la estructura de módulos existente. Estas condiciones se cumplen fácilmente en nuestro contexto debido a la popularidad de Java como el lenguaje de programación para sistemas de comercio electrónico. La API de Conectividad de Base de Datos de Java (JDBC) [32] permite a las aplicaciones de Java acceder a una amplia variedad de bases de datos e incluso a otros repositorios de datos tabulares como archivos planos. El acceso a estas fuentes de datos es proporcionado por controladores JDBC que traducen entre la API JDBC y el mecanismo de comunicación de la base de datos. La figura 3(a) muestra cómo se utiliza típicamente JDBC en una aplicación. Dado que la interfaz JDBC está estandarizada, se puede sustituir un controlador JDBC por otro sin necesidad de de modificar la aplicación. El controlador JDBC se convierte así en el módulo natural para aprovechar la interposición de código. Como se muestra en la Figura 3(b), el controlador JDBC nativo es reemplazado por un controlador JDBC Ganesh que presenta la misma interfaz estandarizada. El controlador Ganesh mantiene una caché en memoria de fragmentos de resultados de consultas anteriores y realiza el reensamblaje de resultados. En la base de datos, agregamos un nuevo proceso llamado el proxy Ganesh. Este proxy, que puede ser compartido por múltiples nodos front-end, consta de dos partes: código para detectar similitud en fragmentos de resultados y el controlador JDBC nativo original que se comunica con la base de datos. El uso de un proxy en la base de datos hace que Ganesh sea independiente de la base de datos y simplifica la creación de prototipos y experimentación. Ganesh es capaz de trabajar con una amplia gama de bases de datos y aplicaciones, sin necesidad de realizar modificaciones en ninguna de ellas. 3.3 Caché basada en proxy El controlador JDBC nativo mostrado en la Figura 3(a) es un componente de código ligero suministrado por el proveedor de la base de datos. Su función principal es mediar la comunicación entre la aplicación y la base de datos remota. Reenvía consultas, almacena resultados completos y responde a solicitudes de la aplicación para ver partes de los resultados. El controlador JDBC de Ganesh mostrado en la Figura 3(b) presenta a la aplicación una interfaz idéntica a la proporcionada por el controlador nativo. Proporciona la capacidad de reconstruir resultados a partir de descripciones compactas basadas en hash enviadas por el proxy. Para realizar esta reconstrucción, el controlador mantiene una caché en memoria de los resultados recibidos recientemente. Esta caché solo se utiliza como fuente de fragmentos de resultados en la reconstrucción de resultados. El conductor Ganesh o el proxy no intentan rastrear las actualizaciones de la base de datos. La falta de consistencia en la caché no afecta a la corrección, ya que la descripción de los resultados siempre se obtiene del proxy; en el peor de los casos, no habrá beneficio de rendimiento al usar Ganesh. Los datos obsoletos simplemente se eliminarán de la caché con el tiempo. El proxy de Ganesh accede a la base de datos a través del controlador JDBC nativo, que permanece sin cambios entre las Figuras 3(a) y (b). La base de datos está completamente ajena a la existencia del proxy. El proxy no examina ninguna consulta recibida del controlador Ganesh, sino que las pasa al controlador nativo. En cambio, el proxy es responsable de inspeccionar la salida de la base de datos recibida del controlador nativo, detectar resultados similares y generar codificaciones basadas en hash de estos resultados siempre que se encuentre suficiente similitud. Si bien esta arquitectura no disminuye la carga en una base de datos, como se mencionó anteriormente en la Sección 2.1, es mucho más fácil replicar bases de datos para escalabilidad en una LAN que en una WAN. Para generar una codificación basada en hash, el proxy debe estar al tanto de qué fragmentos de resultados están disponibles en la caché de controladores de Ganesh. Un enfoque es ser optimista y asumir que todos los fragmentos de resultados están disponibles. Esto resultará en la transmisión inicial más pequeña posible de un resultado. Sin embargo, en casos donde hay poca superposición con resultados anteriores, el controlador Ganesh tendrá que realizar muchas llamadas al proxy durante la reconstrucción para recuperar fragmentos de resultados faltantes. Para evitar esta situación, el proxy sigue de manera flexible el estado de la caché de controladores de Ganesh. Dado que ambos componentes están bajo nuestro control, es relativamente sencillo hacer esto sin recurrir a técnicas de caja gris o comunicación explícita para mantener la coherencia de la caché. En cambio, el proxy simula el algoritmo de gestión de caché de controladores de Ganesh y lo utiliza para mantener una lista de hashes para los cuales es probable que el controlador de Ganesh posea los fragmentos de resultado. En caso de desviación de seguimiento, no habrá pérdida de corrección, pero habrá retrasos adicionales en el viaje de ida y vuelta para recuperar los fragmentos faltantes. Si el cliente detecta la pérdida de sincronización con el proxy, puede pedirle al proxy que restablezca el estado compartido entre ellos. También hay que tener en cuenta que el proxy no necesita guardar los fragmentos de resultado en sí, solo sus hashes. Esto permite que el proxy siga siendo escalable incluso cuando es compartido por muchos nodos front-end. El proxy Ganesh recibe la salida de la base de datos como objetos Java del controlador JDBC nativo. Examina esta salida para ver si está presente un objeto Java del tipo ResultSet. La interfaz JDBC utiliza este tipo de dato para almacenar los resultados de las consultas a la base de datos. Si se encuentra un objeto ResultSet, se reduce como se discute a continuación. Todos los demás objetos de Java se pasan sin modificar. Como se discute en la Sección 3.1, el proxy utiliza los límites de fila definidos en el ResultSet para dividirlo en fragmentos que consisten en filas de resultado individuales. Todos los objetos ResultSet se convierten en objetos de un nuevo tipo llamado RecipeResultSet. Utilizamos el término receta para esta descripción compacta de un resultado de base de datos debido a su similitud con una receta de archivo en el sistema de archivos CASPER [37]. La conversión reemplaza cada fragmento de resultado que probablemente esté presente en la caché de controladores de Ganesh por un hash SHA-1 de ese fragmento. Los fragmentos de resultados previamente no vistos se conservan textualmente. El proxy también retiene los hashes de los nuevos fragmentos de resultados, ya que estarán presentes en la caché de los controladores en el futuro. Ten en cuenta que el proxy solo almacena en caché los hashes de los fragmentos de resultados y no almacena en caché las recetas. El proxy construye un RecipeResultSet verificando la similitud en todo el resultado y luego a nivel de fila. Si se predice que todo el resultado estará presente en la caché de los controladores de Ganesh, el RecipeResultSet será simplemente un único hash de todo el resultado. De lo contrario, contiene hashes para aquellas filas que se predice que están presentes en esa caché; todas las demás filas se conservan textualmente. Si el proxy estima un ahorro de espacio general, transmitirá el RecipeResultSet. De lo contrario, se transmite el ResultSet original. Los objetos RecipeResultSet son transformados de vuelta en objetos ResultSet por el controlador Ganesh. La Figura 4 ilustra el manejo de ResultSet en ambos extremos. Cada hash SHA-1 encontrado en un RecipeResultSet se busca en la caché local de fragmentos de resultados. En caso de acierto, el hash es reemplazado por el fragmento correspondiente. En caso de error, el conductor contacta al proxy de Ganesh para recuperar el fragmento. Todos los fragmentos de resultados previamente no vistos que fueron retenidos textualmente por el proxy se hasheado y se han añadido a la caché de resultados. Debería haber muy pocos fallos si el proxy ha seguido con precisión el estado de la caché de controladores de Ganesh. Una optimización futura sería agrupar la obtención de fragmentos faltantes. Esto sería valioso cuando hay muchos pequeños fragmentos faltantes en una WAN de alta latencia. Una vez que la transformación esté completa, el objeto ResultSet completamente reconstruido se pasa a la aplicación. 4. VALIDACIÓN EXPERIMENTAL Tres preguntas surgen de los objetivos y diseño de Ganesh: • Primero, ¿se puede mejorar significativamente el rendimiento al explotar la similitud entre los resultados de la base de datos? Detalles del conjunto de datos de referencia 500,000 usuarios, 12,000 historias BBOARD 2.0 GB 3,298,000 comentarios SUBASTA 1.3 GB 1,000,000 usuarios, 34,000 elementos Tabla 1: Detalles del conjunto de datos de referencia • En segundo lugar, ¿qué tan importante es la detección de similitud estructural de Ganesh en comparación con la detección de similitud de la huella digital de Rabin? • En tercer lugar, ¿es aceptable la sobrecarga del diseño basado en proxy? Nuestra evaluación responde a estas preguntas a través de experimentos controlados con el prototipo Ganesh. Esta sección describe los puntos de referencia utilizados, nuestro procedimiento de evaluación y la configuración experimental. Los resultados de los experimentos se presentan en las Secciones 5, 6 y 7. 4.1 Puntos de referencia Nuestra evaluación se basa en dos puntos de referencia [18] que han sido ampliamente utilizados por otros investigadores para evaluar varios aspectos de arquitecturas multi-tier [27] y de comercio electrónico [9]. El primer punto de referencia, BBOARD, está modelado según Slashdot, un sitio de noticias orientado a la tecnología. El segundo punto de referencia, AUCTION, está modelado según eBay, un sitio de subastas en línea. En ambos puntos de referencia, la mayoría del contenido se genera dinámicamente a partir de la información almacenada en una base de datos. Los detalles de los conjuntos de datos utilizados se pueden encontrar en la Tabla 1. 4.1.1 El Benchmark BBOARD El benchmark BBOARD, también conocido como RUBBoS [18], modela Slashdot, un popular sitio web orientado a la tecnología. Slashdot recopila enlaces a noticias y otros temas de interés encontrados en otros lugares de la web. El sitio también funciona como un tablón de anuncios al permitir a los usuarios comentar en las historias publicadas en forma de conversación en hilos. No es raro que una historia recopile cientos de comentarios en cuestión de horas. El benchmark BBOARD es similar al sitio y modela las actividades de un usuario, incluyendo operaciones de solo lectura como navegar por las historias del día, explorar categorías de historias y ver comentarios, así como operaciones de escritura como registro de nuevos usuarios, agregar y moderar comentarios, y enviar historias. El benchmark consiste en tres fases diferentes: una fase de calentamiento corta, una fase de ejecución que representa el cuerpo principal de la carga de trabajo, y una fase de enfriamiento corta. En este documento solo informamos sobre los resultados de la fase de ejecución. La fase de calentamiento es importante para establecer el estado del sistema dinámico, pero las mediciones de esa fase no son significativas para nuestra evaluación. La fase de enfriamiento es únicamente para permitir que el punto de referencia se apague. Las fases de calentamiento, ejercicio y enfriamiento son de 2, 15 y 2 minutos respectivamente. El número de clientes simulados fue de 400, 800, 1200 y 1600. El punto de referencia está disponible en una versión de Java Servlets y PHP y tiene diferentes conjuntos de datos; evaluamos a Ganesh utilizando la versión de Java Servlets y el conjunto de datos Expandido. El benchmark BBOARD define dos cargas de trabajo diferentes. El primero, la mezcla de Autoría, consiste en un 70% de operaciones de solo lectura y un 30% de operaciones de lectura y escritura. El segundo, la mezcla de navegación, contiene solo operaciones de solo lectura y no actualiza la base de datos. 4.1.2 El Benchmark de SUBASTA El benchmark de SUBASTA, también conocido como RUBiS [18], modela eBay, el sitio de subastas en línea. El sitio web de eBay se utiliza para comprar y vender artículos a través de un formato de subasta. Las principales actividades de un usuario incluyen navegar, vender o pujar por artículos. Modelando las actividades en este sitio, este punto de referencia incluye actividades de solo lectura como navegar por artículos por categoría y por región, así como actividades de lectura-escritura como pujar por artículos, comprar y vender artículos, y dejar comentarios. Al igual que con BBOARD, el benchmark consiste en tres fases diferentes. Las fases de calentamiento, ejecución y enfriamiento para este experimento son de 1.5, 15 y 1 minutos respectivamente. Probamos Ganesh con cuatro configuraciones de clientes donde el número de clientes de prueba se estableció en 400, 800, 1200 y 1600. El punto de referencia está disponible en una versión de Enterprise Java Bean (EJB), Java Servlets y PHP y tiene diferentes conjuntos de datos; evaluamos Ganesh con la versión de Java Servlets y el conjunto de datos Expandido. El benchmark de SUBASTA define dos cargas de trabajo diferentes. El primero, la mezcla de Ofertas, consiste en un 70% de operaciones de solo lectura y un 30% de operaciones de lectura-escritura. El segundo, la mezcla de navegación, contiene solo operaciones de solo lectura y no actualiza la base de datos. 4.2 Procedimiento Experimental Ambos benchmarks involucran una carga de trabajo sintética de clientes accediendo a un servidor web. El número de clientes emulados es un parámetro experimental. Cada cliente emulado ejecuta una instancia del benchmark en su propio hilo, utilizando una matriz para hacer la transición entre diferentes estados del benchmark. La matriz define un modelo estocástico con probabilidades de transición entre los diferentes estados que representan las acciones típicas de los usuarios. Un ejemplo de transición es un usuario iniciando sesión en el sistema de SUBASTA y luego decidiendo si publicar un artículo en venta o pujar en subastas activas. Cada cliente también modela el tiempo de pensamiento del usuario entre las solicitudes. El tiempo de pensamiento se modela como una distribución exponencial con una media de 7 segundos. Evaluamos a Ganesh a lo largo de dos ejes: número de clientes y ancho de banda de la WAN. Las cargas más altas son especialmente útiles para comprender el rendimiento de Ganesh cuando la CPU o el disco del servidor de base de datos o del proxy son el factor limitante. Un estudio previo ha demostrado que aproximadamente el 50% de los cuellos de botella de Internet de gran área observados tenían un ancho de banda disponible inferior a 10 Mb/s [1]. Basándonos en este trabajo, enfocamos nuestra evaluación en el ancho de banda de la WAN de 5 Mb/s con una latencia de ida y vuelta de 66 ms, representativa de rutas de red severamente restringidas, y 20 Mb/s con una latencia de ida y vuelta de 33 ms, representativa de una ruta de red moderadamente restringida. También informamos sobre el rendimiento de Ganesh a 100 Mb/s sin agregar latencia de ida y vuelta. Este ancho de banda, representativo de una red sin restricciones, es especialmente útil para revelar cualquier sobrecarga potencial de Ganesh en situaciones donde el ancho de banda de la WAN no es el factor limitante. Para cada combinación de número de clientes y ancho de banda de WAN, medimos los resultados de las dos configuraciones enumeradas a continuación: • Nativa: Esta configuración corresponde a la Figura 3(a). El nativo evita la sobrecarga de Ganesh al usar un proxy y realizar la serialización de objetos Java. • Ganesh: Esta configuración corresponde a la Figura 3(b). Para un número dado de clientes y ancho de banda de WAN, comparar estos resultados con los resultados nativos correspondientes proporciona el beneficio de rendimiento debido al sistema de middleware Ganesh. La métrica utilizada para cuantificar la mejora en el rendimiento es el número de solicitudes de clientes que pueden ser atendidas por segundo. La métrica utilizada para cuantificar el rendimiento de Ganesh es el tiempo promedio de respuesta para una solicitud de cliente. Para todos los experimentos, el controlador Ganesh utilizado por el servidor de aplicaciones usó un tamaño de caché de 100,000 elementos. El proxy fue efectivo en rastrear el estado de la caché de los controladores Ganesh; para todos nuestros experimentos, la tasa de fallos en el controlador nunca superó el 0.7%. 4.3 Configuración Experimental La configuración experimental utilizada para las pruebas se puede ver en la Figura 5. Todas las máquinas eran Pentium 4 de 3.2 GHz (con HyperThreading habilitado). Con la excepción del servidor de base de datos, todas las máquinas tenían 2 GB de SDRAM y ejecutaban la distribución de Linux Fedora Core. El servidor de la base de datos tenía 4 GB de SDRAM. Utilizamos Apache Tomcat como tanto el servidor de aplicaciones que alojaba los Servlets de Java como el servidor web. Ambos benchmarks utilizaron Java Servlets para generar el contenido dinámico. El servidor de la base de datos utilizó la base de datos de código abierto MySQL. Para los controladores JDBC nativos, utilizamos los controladores Connector/J proporcionados por MySQL. El servidor de aplicaciones utilizaba la Máquina Virtual de Java de Sun como entorno de ejecución para los Servlets de Java. La herramienta sysstat se utilizó para monitorear la utilización de la CPU, red, disco y memoria en todas las máquinas. Las máquinas estaban conectadas por una red Ethernet gigabit conmutada. Como se muestra en la Figura 5, el servidor web y de aplicación de front-end fue separado del servidor de proxy y base de datos por un enrutador NetEm [16]. Este enrutador nos permitió controlar la configuración de ancho de banda y latencia en la red. El enrutador NetEm es un PC estándar con dos tarjetas de red que ejecuta el software de Control de Tráfico de Linux y Emulación de Red. Las restricciones de ancho de banda y latencia solo se aplicaron al enlace entre el servidor de aplicaciones y la base de datos para el caso nativo y entre el servidor de aplicaciones y el proxy para el caso de Ganesh. No hay comunicación entre el servidor de aplicaciones y la base de datos con Ganesh, ya que todos los datos fluyen a través del proxy. Como nuestro enfoque estaba en el enlace WAN entre el servidor de aplicaciones y la base de datos, no hubo restricciones en el enlace entre los clientes de prueba simulados y el servidor web. 5. DESEMPEÑO Y TIEMPO DE RESPUESTA En esta sección, abordamos la primera pregunta planteada en la Sección 4: ¿Se puede mejorar significativamente el rendimiento explotando la similitud entre los resultados de la base de datos? Para responder a esta pregunta, utilizamos los resultados de los benchmarks BBOARD y AUCTION. Utilizamos dos métricas para cuantificar la mejora en el rendimiento obtenible a través del uso de Ganesh: el throughput, desde la perspectiva del servidor web, y el tiempo de respuesta promedio, desde la perspectiva del cliente. El rendimiento se mide en términos del número de solicitudes de clientes que pueden ser atendidas por segundo. Los resultados y análisis de BBOARD 5.1 Figuras 6 (a) y (b) presentan el número promedio de solicitudes atendidas por segundo y el tiempo de respuesta promedio para estas solicitudes tal como lo perciben los clientes para la Mezcla de Autoría de BBOARD. Como muestra la Figura 6 (a), Native satura fácilmente el enlace de 5 Mb/s. Con 400 clientes, la solución nativa entrega 29 solicitudes/segundo con un tiempo de respuesta promedio de 8.3 segundos. La capacidad de procesamiento de los clientes disminuye con un aumento en los clientes de prueba, ya que los clientes se agotan debido a la congestión en el servidor de aplicaciones. Los estudios de usabilidad han demostrado que los tiempos de respuesta superiores a 10 segundos hacen que el usuario pase a 1. Dado que Java carece de un operador sizeof(), los cachés de Java limitan su tamaño en función del número de objetos. El tamaño de los volcados de caché tomados al final de los experimentos nunca superó los 212 MB. WWW 2007 / Pista: Rendimiento y Escalabilidad Sesión: Sistemas Escalables para Contenido Dinámico 315 0 50 100 150 200 250 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Solicitudes de Clientes de Prueba por Segundo Nativo Ganesh 0.001 0.01 0.1 1 10 100 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Tiempo Promedio de Respuesta de Clientes de Prueba Nativo Ganesh Nota Escala Logarítmica (a) Rendimiento: Mezcla de Autoría (b) Tiempo de Respuesta: Mezcla de Autoría 0 50 100 150 200 250 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Solicitudes de Clientes de Prueba por Segundo Nativo Ganesh 0.001 0.01 0.1 1 10 100 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Tiempo Promedio de Respuesta de Clientes de Prueba Nativo Ganesh Nota Escala Logarítmica (c) Rendimiento: Mezcla de Navegación (d) Tiempo de Respuesta: Mezcla de Navegación Promedio de tres pruebas. La desviación estándar máxima para el rendimiento y el tiempo de respuesta fue del 9.8% y 11.9% de la media correspondiente. Figura 6: BBOARD Benchmark - Rendimiento y Tiempo de Respuesta Promedio de otras tareas [24]. Basándose en estos números, aumentar el número de clientes de prueba hace que el sistema Nativo sea inutilizable. Ganesh a 5 Mb/s, sin embargo, ofrece una mejora doble con 400 clientes de prueba y una mejora quintuple con 1200 clientes. El rendimiento de Ganesh disminuye ligeramente a 1200 y 1600 clientes debido a que la red está saturada. En comparación con Native, la Figura 6 (b) muestra que los tiempos de respuesta de Ganesh son considerablemente más bajos con tiempos de respuesta de menos de un segundo con 400 clientes. La Figura 6 (a) también muestra que para 400 y 800 clientes de prueba, Ganesh a 5 Mb/s tiene el mismo rendimiento y tiempo de respuesta promedio que Native a 20 Mb/s. Solo con 1200 y 1600 clientes, Native a 20 Mb/s ofrece un rendimiento mayor que Ganesh a 5 Mb/s. Al comparar tanto a Ganesh como a Native a 20 Mb/s, vemos que Ganesh ya no está limitado por el ancho de banda y ofrece hasta una mejora del doble sobre Native con 1600 clientes de prueba. Como Ganesh no satura la red con configuraciones de cliente de prueba más altas, con 1600 clientes de prueba, su tiempo de respuesta promedio es de 0.1 segundos en lugar de los 7.7 segundos de Natives. Como era de esperar, no hay ganancias visibles de Ganesh en el ancho de banda más alto de 100 Mb/s donde la red ya no es el cuello de botella. Sin embargo, Ganesh sigue monitoreando a Native en cuanto a rendimiento. Las Figuras 6 (c) y (d) presentan el número promedio de solicitudes atendidas por segundo y el tiempo de respuesta promedio para estas solicitudes tal como lo perciben los clientes para la Mezcla de Navegación de BBOARDs. Independientemente de la configuración del cliente de prueba, la Figura 6 (c) muestra que el rendimiento de los Nativos a 5 Mb/s está limitado a 10 reqs/seg. Ganesh a 5 Mb/s con 400 clientes de prueba, ofrece un aumento de más de seis veces en el rendimiento. La mejora aumenta a más de once veces a 800 clientes de prueba antes de que Ganesh sature la red. Además, la Figura 6 (d) muestra que el tiempo de respuesta promedio de los Nativos de 35 segundos con 400 clientes de prueba hace que el sistema sea inutilizable. Estos altos tiempos de respuesta aumentan aún más con la adición de clientes de prueba. Incluso con la configuración del cliente de prueba de 1600, Ganesh ofrece un tiempo de respuesta promedio aceptable de 8.2 segundos. Debido a la naturaleza intensiva en datos de la mezcla de navegación, Ganesh a 5 Mb/s sorprendentemente tiene un rendimiento mucho mejor que Native a 20 Mb/s. Además, como se muestra en la Figura 6 (d), si bien el tiempo de respuesta promedio para Native a 20 Mb/s es aceptable con 400 clientes de prueba, resulta inutilizable con 800 clientes de prueba, con un tiempo de respuesta promedio de 15.8 segundos. Al igual que en el caso de 5 Mb/s, este tiempo de respuesta aumenta con la adición de clientes de prueba adicionales. Ganesh a 20 Mb/s y tanto Native como Ganesh a 100 Mb/s no tienen limitaciones de ancho de banda. Sin embargo, el rendimiento se estanca después de 1200 clientes de prueba debido a que la CPU de la base de datos está saturada. 5.1.3 Variante de filtro Nos sorprendió el rendimiento nativo del benchmark BBOARD. A una velocidad de banda ancha de 5 Mb/s, el rendimiento nativo fue más bajo de lo que esperábamos. Resultó que el código de referencia que muestra historias leía todos los comentarios asociados con la historia en particular de la base de datos y solo entonces realizaba un postprocesamiento para seleccionar los comentarios que se mostrarían. Si bien este es exactamente el comportamiento de SlashCode, la base de código detrás del sitio web de Slashdot, decidimos modificar la prueba de rendimiento para realizar cierto prefiltrado en la base de datos. Este benchmark modificado, llamado el Filtro de Variantes, modela a un desarrollador que aplica optimizaciones a nivel de SQL para transferir menos datos. En aras de la brevedad, solo resumimos brevemente los resultados de la mezcla de autores. Para la mezcla de Autoría, con 800 clientes de prueba a 5 Mb/s, la Figura 7 (a) muestra que el rendimiento de Natives aumenta un 85% en comparación con el punto de referencia original, mientras que la mejora de Ganesh es menor, del 15%. El rendimiento de los servidores disminuye por encima de los 800 clientes, ya que los clientes de prueba se agotan debido a los altos tiempos de respuesta. La ganancia más significativa para Native se observa a 20 Mb/s. En 1600 clientes de prueba, en comparación con el punto de referencia original, Native experimenta una mejora del 73% en el rendimiento y una reducción del 77% en el tiempo de respuesta promedio. Mientras WWW 2007 / Pista: Rendimiento y Escalabilidad Sesión: Sistemas Escalables para Contenido Dinámico 316 0 50 100 150 200 250 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Clientes de Prueba Solicitudes/seg Nativo Ganesh 0.001 0.01 0.1 1 10 100 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Clientes de Prueba Tiempo de Resp. Promedio (seg) Nativo Ganesh Nota Escala Logarítmica (a) Rendimiento: Mezcla de Autoría (b) Tiempo de Respuesta: Mezcla de Autoría Promedio de tres pruebas. La desviación estándar máxima para el rendimiento y el tiempo de respuesta fue del 7.2% y del 11.5% de la media correspondiente. Figura 7: BBOARD Benchmark - Variante de filtro - Rendimiento y Tiempo de Respuesta Promedio Ganesh no observa ninguna mejora en comparación con el original, aún procesa un 19% más de solicitudes/seg que Native. Por lo tanto, aunque las optimizaciones fueron más útiles para Native, Ganesh todavía ofrece una mejora en el rendimiento. 5.2 Resultados y Análisis de la SUBASTA 5.2.1 Figuras de la Mezcla de Ofertas Los gráficos 8 (a) y (b) presentan el número promedio de solicitudes atendidas por segundo y el tiempo de respuesta promedio para estas solicitudes tal como son percibidas por los clientes para la Mezcla de Ofertas de las SUBASTAS. Como se mencionó anteriormente, la mezcla de ofertas consiste en una combinación de operaciones de lectura y escritura. El benchmark AUCTION no es tan intensivo en datos como BBOARD. Por lo tanto, la mayoría de las ganancias se observan en el ancho de banda más bajo de 5 Mb/s. La figura 8 (a) muestra que el aumento en el rendimiento debido a Ganesh varía desde un 8% con 400 clientes de prueba hasta un 18% con 1600 clientes de prueba. Como se observa en la Figura 8 (b), los tiempos de respuesta promedio para Ganesh son significativamente más bajos que los de Native, con una disminución del 84% a 800 clientes de prueba y del 88% a 1600 clientes de prueba. La Figura 8 (a) también muestra que con un aumento cuádruple del ancho de banda de 5 Mb/s a 20 Mb/s, Native ya no está limitado por el ancho de banda y no hay diferencia de rendimiento entre Ganesh y Native. Con las configuraciones de cliente de prueba más altas, observamos que el ancho de banda utilizado por Ganesh era menor que el de Nativo. Ganesh podría seguir siendo útil en estos escenarios no restringidos si se compra ancho de banda de forma medible. Se observan resultados similares para el escenario de 100 Mb/s. 5.2.2 Mezcla de Navegación Para la Mezcla de Navegación de SUBASTAS, las Figuras 8 (c) y (d) presentan el número promedio de solicitudes atendidas por segundo y el tiempo promedio de respuesta para estas solicitudes tal como lo perciben los clientes. Una vez más, la mayoría de las ganancias se observan en anchos de banda más bajos. A 5 Mb/s, Native y Ganesh ofrecen un rendimiento y tiempos de respuesta similares con 400 clientes de prueba. Mientras que el rendimiento para ambos permanece igual en 800 clientes de prueba, la Figura 8 (d) muestra que el tiempo de respuesta promedio de Ganesh es un 62% menor que el de Native. El servidor satura el enlace con 800 clientes y agregar clientes de prueba adicionales solo aumenta el tiempo promedio de respuesta. Ganesh, independientemente de la configuración del cliente de prueba, no tiene restricciones de ancho de banda y mantiene el mismo tiempo de respuesta. A 1600 clientes de prueba, la Figura 8 (c) muestra que el rendimiento de Ganesh es casi el doble que el de Nativo. En los anchos de banda más altos de 20 y 100 Mb/s, ni Ganesh ni Native tienen limitaciones de ancho de banda y ofrecen un rendimiento y tiempos de respuesta equivalentes. Referencia original. Tamaño Ganesh Tamaño Rabin Tamaño SelectSort1 223.6 MB 5.4 MB 219.3 MB SelectSort2 223.6 MB 5.4 MB 223.6 MB Tabla 2: Microbenchmarks de similitud 6. SIMILITUD ESTRUCTURAL VS. SIMILITUD DE RABIN En esta sección, abordamos la segunda pregunta planteada en la Sección 4: ¿Qué tan importante es la detección de similitud estructural de Ganesh en comparación con la detección de similitud basada en la huella digital de Rabin? Para responder a esta pregunta, utilizamos microbenchmarks y los benchmarks BBOARD y AUCTION. Dado que Ganesh siempre tuvo un mejor rendimiento que Rabin en la huella dactilar, aquí presentamos solo un subconjunto de los resultados en aras de la brevedad. 6.1 Microbenchmarks Dos microbenchmarks muestran un ejemplo de los efectos de la reordenación de datos en el algoritmo de huella dactilar de Rabin. En el primer microbenchmark, SelectSort1, una consulta con un orden de clasificación especificado selecciona 223.6 MB de datos distribuidos en aproximadamente 280 K filas. La consulta se repite entonces con un atributo de ordenación diferente. Si bien se devuelve el mismo número de filas y los mismos datos, el orden de las filas es diferente. En un escenario así, se esperaría detectar una gran cantidad de similitud entre ambos resultados. Como muestra la Tabla 2, el algoritmo basado en filas de Ganesh logra una reducción del 97.6%, mientras que el algoritmo de huella digital de Rabin, con el parámetro de tamaño de fragmento promedio establecido en 4 KB, solo logra una reducción del 1%. La razón, como se muestra anteriormente en la Figura 2, es que con la huella digital de Rabin, los tramos de datos entre dos límites consecutivos suelen cruzar los límites de fila. Con el cambio en el orden de las filas en el segundo resultado y los fingerprints de Rabin ahora abarcando diferentes filas, el algoritmo no puede detectar similitud significativa. La pequeña ganancia observada se debe principalmente a aquellas filas individuales que son lo suficientemente grandes como para dividirse en múltiples fragmentos. SelectSort2, otro micro-benchmark ejecutó las mismas consultas pero aumentó el tamaño mínimo del fragmento del algoritmo de huella digital de Rabin. Como se puede ver en la Tabla 2, incluso la pequeña ganancia del microbenchmark anterior desaparece cuando el tamaño mínimo de fragmento fue mayor que el tamaño promedio de fila. Si bien se pueden abordar parcialmente estos problemas variando dinámicamente los parámetros del algoritmo de huella digital de Rabin, esto puede resultar computacionalmente costoso, especialmente en presencia de cargas de trabajo cambiantes. 6.2 Benchmarks de Aplicación Ejecutamos el benchmark BBOARD descrito en la Sección 4.1.1 en dos versiones de Ganesh: la primera con la huella digital de Rabin utilizada como WWW 2007 / Track: Sesión de Rendimiento y Escalabilidad: Sistemas Escalables para Contenido Dinámico 317 0 50 100 150 200 250 300 350 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Clientes de Prueba Solicitudes/seg Ganesh Nativo 0.001 0.01 0.1 1 10 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Clientes de Prueba Tiempo de Respuesta Promedio (seg) Ganesh Nativo Nota Escala Logarítmica (a) Rendimiento: Mezcla de Ofertas (b) Tiempo de Respuesta: Mezcla de Ofertas 0 50 100 150 200 250 300 350 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Clientes de Prueba Solicitudes/seg Ganesh Nativo 0.001 0.01 0.1 1 10 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Clientes de Prueba Tiempo de Respuesta Promedio (seg) Ganesh Nativo Nota Escala Logarítmica (c) Rendimiento: Mezcla de Navegación (d) Tiempo de Respuesta: Mezcla de Navegación Promedio de tres pruebas. La desviación estándar máxima para el rendimiento y el tiempo de respuesta fue del 2.2% y del 11.8% de la media correspondiente. Figura 8: Referencia de la subasta AUCTION - Rendimiento y Tiempo de Respuesta Promedio del algoritmo de fragmentación y el segundo con el algoritmo basado en filas de Ganesh. Los resultados de Rabins para la Mezcla de Navegación se normalizan con los resultados de Ganesh y se presentan en la Figura 9. Como muestra la Figura 9 (a), a 5 Mb/s, independientemente de la configuración del cliente de prueba, Rabin tiene un rendimiento significativamente inferior a Ganesh. Esto sucede debido a una combinación de dos razones. Primero, como se describe en la Sección 3.1, Rabin encuentra menos similitud ya que no explota la información estructural de los resultados. Segundo, este punto de referencia contenía algunas consultas que generaron resultados grandes. En este caso, Rabin, con un tamaño de fragmento promedio pequeño, generó una gran cantidad de objetos que desplazaron otros datos útiles de la caché. Por el contrario, Ganesh pudo detectar estas filas grandes y aumentar correspondientemente el tamaño de los bloques. Esto fue confirmado ya que las estadísticas de caché mostraron que la proporción de aciertos de Ganesh era aproximadamente tres veces mayor que la de Rabin. Las mediciones de rendimiento a 20 Mb/s fueron similares, con la excepción del rendimiento de Rabins con 400 clientes de prueba. En este caso, Ganesh no estaba limitado por la red y, de hecho, el rendimiento era el mismo que el de 400 clientes a 5 Mb/s. Rabin, sin embargo, aprovechó el aumento del ancho de banda de 5 a 20 Mb/s para ofrecer un rendimiento ligeramente mejor. A 100 Mb/s, el rendimiento de Rabin era casi similar al de Ganesh ya que el ancho de banda ya no era un cuello de botella. El tiempo de respuesta normalizado, presentado en la Figura 9 (b), muestra tendencias similares. A 5 y 20 Mb/s, la adición de clientes de prueba disminuye el tiempo de respuesta normalizado, ya que el tiempo de respuesta promedio de Ganesh aumenta más rápido que el de Rabin. Sin embargo, en ningún momento Rabin supera a Ganesh. Ten en cuenta que con 400 y 800 clientes a 100 Mb/s, Rabin tiene un mayor sobrecosto incluso cuando no está limitado por el ancho de banda. Como se menciona en la Sección 3.1, esto se debe a que Rabin tiene que hashear cada ResultSet dos veces. La sobrecarga desaparece con 1200 y 1600 clientes, ya que la CPU de la base de datos está saturada y limita el rendimiento tanto de Ganesh como de Rabin. 7. SUPERPOSICIÓN DE PROXY En esta sección, abordamos la tercera pregunta planteada en la Sección 4: ¿Es aceptable la superposición del diseño basado en proxy de Ganesh? Para responder a esta pregunta, nos concentramos en su rendimiento en las bandas de mayor ancho de banda. Nuestra evaluación en la Sección 5 mostró que Ganesh, en comparación con Native, puede ofrecer una mejora sustancial en el rendimiento a anchos de banda más bajos. Solo en anchos de banda más altos serían visibles los costos adicionales de latencia, medidos por el tiempo promedio de respuesta para una solicitud de cliente, y de rendimiento, medidos por la cantidad de solicitudes de cliente que pueden ser atendidas por segundo. Al observar la combinación de autoría del benchmark original de BBOARD, no se aprecian ganancias visibles de Ganesh a 100 Mb/s. Sin embargo, Ganesh sigue rastreando a Native en cuanto a rendimiento. Si bien el tiempo promedio de respuesta es mayor para Ganesh, la diferencia absoluta está entre 0.01 y 0.04 segundos y sería imperceptible para el usuario final. La mezcla de navegación muestra una diferencia aún menor en los tiempos de respuesta promedio. Los resultados de la variante del filtro de los benchmarks de BBOARD son similares. Incluso para el benchmark de SUBASTA, la diferencia entre el tiempo de respuesta de Nativo y Ganesh a 100 Mb/s nunca fue mayor a 0.02 segundos. La única excepción a los resultados anteriores se observó en la variante de filtro del benchmark BBOARD, donde Ganesh con 1600 clientes de prueba añadió 0.85 segundos al tiempo de respuesta promedio. Por lo tanto, incluso para redes mucho más rápidas donde el enlace WAN no es el cuello de botella, Ganesh siempre ofrece un rendimiento equivalente al Nativo. Si bien se agrega algo de latencia adicional debido al diseño basado en proxy, generalmente es imperceptible. TRABAJO RELACIONADO Hasta donde sabemos, Ganesh es el primer sistema que combina el uso de técnicas basadas en hash con el almacenamiento en caché de resultados de base de datos para mejorar el rendimiento y los tiempos de respuesta de aplicaciones con contenido dinámico. También creemos que es el primer sistema en demostrar los beneficios de utilizar información estructural para WWW 2007 / Track: Rendimiento y Escalabilidad Sesión: Sistemas Escalables para Contenido Dinámico 318 0.0 0.2 0.4 0.6 0.8 1.0 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Clientes de Prueba Rendimiento Normalizado 31.8 3.8 2.8 2.3 23.8 32.8 5.8 3.6 1.8 2.1 1.1 1.0 0 5 10 15 20 25 30 35 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Clientes de Prueba Tiempo de Respuesta Normalizado (a) Rendimiento Normalizado: Mayor es mejor (b) Tiempo de Respuesta Normalizado: Mayor es peor Para el rendimiento, un resultado normalizado mayor que 1 implica que Rabin es mejor. Para el tiempo de respuesta, un resultado normalizado mayor que 1 implica que Ganesh es mejor. Media de tres pruebas. La desviación estándar máxima para el rendimiento y el tiempo de respuesta fue del 9.1% y del 13.9% de la media correspondiente. Figura 9: Comparación normalizada de Ganesh vs. Rabin - Mezcla de navegación BBOARD detectando similitud. En esta sección, primero discutimos enfoques alternativos para almacenar en caché contenido dinámico y luego examinamos otros usos de primitivas basadas en hash en sistemas distribuidos. 8.1 Almacenamiento en Caché de Contenido Dinámico En la capa de base de datos, varios sistemas han abogado por la caché de nivel intermedio donde partes de la base de datos se replican en el borde o servidor [3, 4, 20]. Estos sistemas almacenan en caché tablas completas en lo que es esencialmente una base de datos replicada o utilizan vistas materializadas de respuestas de consultas anteriores [19]. Requieren una integración estrecha con la base de datos del sistema para garantizar un límite de tiempo en la propagación de actualizaciones. Estos sistemas suelen estar dirigidos a cargas de trabajo que no requieren una consistencia estricta y pueden tolerar datos obsoletos. Además, a diferencia de Ganesh, algunas de estas soluciones de almacenamiento en caché de nivel medio [2, 3], sufren de la complejidad de tener que participar en la planificación de consultas y el procesamiento de consultas distribuidas. Gao et al. [15] proponen utilizar una arquitectura de replicación de objetos distribuidos donde los requisitos de consistencia de las tiendas de datos se adaptan según la aplicación. Estas soluciones requieren recursos sustanciales de desarrollo y un entendimiento detallado de la aplicación que se está modificando. Si bien existen sistemas que intentan automatizar la partición y replicación de la base de datos de una aplicación [34], no proporcionan semántica de transacciones completa. En comparación, Ganesh no debilita ninguna de las semánticas proporcionadas por la base de datos subyacente. El trabajo reciente en la evaluación de opciones de almacenamiento en caché de borde para sitios web dinámicos [38] ha sugerido que, sin una planificación cuidadosa, el empleo de estrategias complejas de descarga puede perjudicar el rendimiento. En cambio, el trabajo aboga por una arquitectura en la que todos los niveles, excepto la base de datos, deberían ser trasladados al borde. Nuestra evaluación de Ganesh ha demostrado que sería beneficioso para estos escenarios. Para mejorar la escalabilidad de la base de datos, C-JDBC [10], SSS [22] y Ganymed [28] también abogan por el uso de una arquitectura basada en interposición para clusterizar y replicar bases de datos de forma transparente a nivel de middleware. Los enfoques de estas arquitecturas y Ganesh son complementarios y se beneficiarían mutuamente. Avanzando hacia la capa de presentación, se ha producido una amplia adopción de la caché basada en fragmentos [14], la cual mejora la utilización de la caché al almacenar por separado diferentes partes de las páginas web generadas. Si bien el almacenamiento en caché basado en fragmentos funciona en el borde, una propuesta reciente ha propuesto trasladar el ensamblaje de páginas web a los clientes para optimizar la entrega de contenido [31]. Si bien Ganesh no se utiliza en la capa de presentación, los mismos principios se han aplicado en la Detección de Transferencias Duplicadas [25] para aumentar la eficiencia de la caché web, así como para el acceso web a través de enlaces con ancho de banda limitado [33]. 8.2 Sistemas basados en hash En los últimos años han surgido muchos sistemas que explotan técnicas basadas en hash. En el centro de todos estos sistemas se encuentra la idea de detectar similitudes en los datos sin necesidad de interpretar esos datos. Esta idea simple pero elegante se basa en el hash criptográfico, como se discutió anteriormente en la Sección 2. Las aplicaciones exitosas de esta idea abarcan una amplia gama de sistemas de almacenamiento. Los ejemplos incluyen la copia de seguridad entre pares de archivos informáticos personales [11], el archivado eficiente de datos [29] y la búsqueda de archivos similares [21]. Spring y Wetherall [35] aplican principios similares a nivel de red. Utilizando cachés sincronizadas en ambos extremos de un enlace de red, los datos duplicados son reemplazados por tokens más pequeños para su transmisión y luego restaurados en el extremo remoto. Este y otros sistemas basados en hash como los sistemas de archivos CASPER [37] y LBFS [26], y optimizadores de ancho de banda de Capa-2 como Riverbed y Peribit utilizan la huella digital de Rabin [30] para descubrir tramos de similitud en los datos. Este enfoque es especialmente útil cuando los elementos de datos son modificados en su lugar a través de inserciones, eliminaciones y actualizaciones. Sin embargo, como se muestra en la Sección 6, el rendimiento de esta técnica puede experimentar una caída dramática en presencia de reordenamiento de datos. Ganesh en cambio utiliza los límites de fila como divisores para detectar similitudes. El uso más agresivo de técnicas basadas en hash es por sistemas que utilizan hashes como identificadores principales para objetos en almacenamiento persistente. Los sistemas de almacenamiento como CFS [12] y PAST [13] que han sido construidos utilizando tablas hash distribuidas entran en esta categoría. Single Instance Storage [6] y Venti [29] son otros ejemplos de tales sistemas. Como se discute en la Sección 2.2, el uso de hashes criptográficos para abordar datos persistentes representa un nivel más profundo de confianza en su resistencia a colisiones que la asumida por Ganesh. Si el tiempo revela deficiencias en el algoritmo hash, el esfuerzo necesario para corregir la falla es mucho mayor. En Ganesh, simplemente se trata de reemplazar el algoritmo hash. 9. CONCLUSIÓN El creciente uso de contenido web dinámico generado a partir de bases de datos relacionales aumenta las demandas de ancho de banda de la WAN. Las soluciones de almacenamiento en caché tradicionales para reducir el ancho de banda y la latencia suelen ser ineficaces para este tipo de contenido. Este documento muestra que el impacto de los accesos a bases de datos a través de WAN puede reducirse sustancialmente mediante la arquitectura Ganesh sin comprometer la estricta semántica de consistencia de las bases de datos. La esencia de la arquitectura Ganesh es el uso de la computación en los bordes para reducir la comunicación a través de Internet. Ganesh es capaz de utilizar hashes criptográficos para detectar similitud con resultados anteriores y enviar recetas compactas de resultados en lugar de resultados completos en la sesión de Sistemas Escalables para Contenido Dinámico 319 de WWW 2007 / Track: Rendimiento y Escalabilidad. Nuestro diseño utiliza la interposición para lograr una transparencia completa: los clientes, los servidores de aplicaciones y los servidores de bases de datos no son conscientes de la presencia de Ganesh y no requieren ninguna modificación. Nuestra evaluación experimental confirma que Ganesh, aunque conceptualmente simple, puede ser altamente efectivo en mejorar el rendimiento y el tiempo de respuesta. Nuestros resultados también confirman que aprovechar la estructura presente en los resultados de la base de datos para detectar similitudes es crucial para esta mejora en el rendimiento. REFERENCIAS [1] AKELLA, A., SESHAN, S., Y SHAIKH, A. Una evaluación empírica de los cuellos de botella en Internet de área amplia. En Proc. 3ª Conferencia ACM SIGCOMM sobre Medición de Internet (Miami Beach, FL, EE. UU., Oct. 2003), pp. 101-114. [2] ALTINEL, M., BORNH ¨OVD, C., KRISHNAMURTHY, S., MOHAN, C., PIRAHESH, H., Y REINWALD, B. Tablas de caché: allanando el camino para una caché de base de datos adaptativa. En Proc. del 29º VLDB (Berlín, Alemania, 2003), pp. 718-729. [3] ALTINEL, M., LUO, Q., KRISHNAMURTHY, S., MOHAN, C., PIRAHESH, H., LINDSAY, B. G., WOO, H., Y BROWN, L. Dbcache: Caché de base de datos para servidores de aplicaciones web. En Proc. 2002 ACM SIGMOD (2002), pp. 612-612. [4] AMIRI, K., PARK, S., TEWARI, R., Y PADMANABHAN, S. Dbproxy: una caché de datos dinámica para aplicaciones web. En Proc. Conferencia Internacional de Ingeniería de Datos de IEEE (ICDE) (Mar. 2003). [5] BLACK, J. Compare-by-hash: Un análisis razonado. En Proc. Conferencia Técnica Anual USENIX 2006 (Boston, MA, mayo de 2006), pp. 85-90. [6] BOLOSKY, W. J., CORBIN, S., GOEBEL, D., y DOUCEUR, J. R. Almacenamiento de instancia única en Windows 2000. En Proc. 4to Simposio de Sistemas Windows de USENIX (Seattle, WA, ago. 2000), pp. 13-24. [7] BREWER, E. A. Lecciones de servicios a gran escala. IEEE Internet Computing 5, 4 (2001), 46-55. [8] BRODER, A., GLASSMAN, S., MANASSE, M., AND ZWEIG, G. Agrupamiento sintáctico de la web. En Proc. 6ta Conferencia Internacional WWW (1997). [9] CECCHET, E., CHANDA, A., ELNIKETY, S., MARGUERITE, J., Y ZWAENEPOEL, W. Comparación de rendimiento de arquitecturas de middleware para generar contenido web dinámico. En Proc. Cuarta Conferencia Internacional de Middleware ACM/IFIP/USENIX (Río de Janeiro, Brasil, junio de 2003). [10] CECCHET, E., MARGUERITE, J., Y ZWAENEPOEL, W. C-JDBC: Middleware flexible de agrupación de bases de datos. En Proc. Conferencia Técnica Anual USENIX 2004 (Boston, MA, junio de 2004). [11] COX, L. P., MURRAY, C. D., Y NOBLE, B. D. Pastiche: Haciendo que la copia de seguridad sea barata y fácil. En OSDI: Simposio sobre Diseño e Implementación de Sistemas Operativos (2002). [12] DABEK, F., KAASHOEK, M. F., KARGER, D., MORRIS, R., Y STOICA, I. Almacenamiento cooperativo de amplia área con CFS. En el 18º Simposio ACM sobre Principios de Sistemas Operativos (Banff, Canadá, octubre de 2001). [13] DRUSCHEL, P., Y ROWSTRON, A. PASADO: Una utilidad de almacenamiento entre pares a gran escala y persistente. En HotOS VIII (Schloss Elmau, Alemania, mayo de 2001), pp. 75-80. [14] Incluye el lado del borde. http://www.esi.org. [15] GAO, L., DAHLIN, M., NAYATE, A., ZHENG, J., Y IYENGAR, A. Replicación de datos específica de la aplicación para servicios en el borde. En WWW 03: Proc. Duodécima Conferencia Internacional sobre la World Wide Web (2003), pp. 449-460. [16] HEMMINGER, S. Netem - emulando redes reales en el laboratorio. En Proc. 2005 Linux Conference Australia (Canberra, Australia, Abr. 2005). [17] HENSON, V. Un análisis de compare-by-hash. En Proc. 9º Taller sobre Temas Candentes en Sistemas Operativos (HotOS IX) (mayo de 2003), pp. 13-18. [18] Benchmarks de Jmob. http://jmob.objectweb.org/. [19] LABRINIDIS, A., Y ROUSSOPOULOS, N. Equilibrando el rendimiento y la frescura de los datos en servidores de bases de datos web. En Proc. 29ª Conferencia VLDB (Sept. 2003). [20] LARSON, P.-A., GOLDSTEIN, J., Y ZHOU, J. Caché transparente de bases de datos en el nivel intermedio en SQL Server. En Proc. 2003 ACM SIGMOD (2003), pp. 661-661. [21] MANBER, U. Encontrar archivos similares en un sistema de archivos grande. En Proc. Conferencia Técnica de Invierno de USENIX 1994 (San Francisco, CA, 17-21 de 1994), pp. 1-10. [22] MANJHI, A., AILAMAKI, A., MAGGS, B. M., MOWRY, T. C., OLSTON, C., Y TOMASIC, A. Escalabilidad y seguridad simultáneas para aplicaciones web intensivas en datos. En Proc. 2006 ACM SIGMOD (junio de 2006), pp. 241-252. [23] MENEZES, A. J., VANSTONE, S. A., Y OORSCHOT, P. C. V. Manual de Criptografía Aplicada. CRC Press, 1996. [24] MILLER, R. B. \n\nCRC Press, 1996. [24] MILLER, R. B. Tiempo de respuesta en transacciones conversacionales entre humanos y computadoras. En Proc. Conferencia Conjunta de Computación de Otoño de AFIPS (1968), pp. 267-277. [25] MOGUL, J. C., CHAN, Y. M., Y KELLY, T. Diseño, implementación y evaluación de la detección de transferencias duplicadas en http. En Proc. Primer Simposio sobre Diseño e Implementación de Sistemas en Red (San Francisco, CA, Mar. 2004). [26] MUTHITACHAROEN, A., CHEN, B., Y MAZIERES, D. Un sistema de archivos en red de bajo ancho de banda. En Proc. 18º Simposio de la ACM sobre Principios de Sistemas Operativos (Banff, Canadá, Oct. 2001). [27] PFEIFER, D., Y JAKSCHITSCH, H. Caché basada en métodos en aplicaciones de servidores multinivel. En Proc. Quinto Simposio Internacional sobre Objetos y Aplicaciones Distribuidas (Catania, Sicilia, Italia, noviembre de 2003). [28] PLATTNER, C., Y ALONSO, G. Ganymed: Replicación escalable para aplicaciones web transaccionales. En Proc. 5ta Conferencia Internacional de Middleware ACM/IFIP/USENIX (2004), pp. 155-174. [29] QUINLAN, S., Y DORWARD, S. Venti: Un nuevo enfoque para el almacenamiento de archivos. En Proc. Conferencia FAST 2002 sobre Tecnologías de Archivo y Almacenamiento (2002). [30] RABIN, M. Huellas dactilares mediante polinomios aleatorios. En el Informe Técnico TR-15-81 (1981) del Centro de Investigación en Tecnología Informática de la Universidad de Harvard. [31] RABINOVICH, M., XIAO, Z., DOUGLIS, F., Y KALMANEK, C. Mover los lados de los bordes incluye a los clientes reales en el borde. En Proc. 4to Simposio USENIX sobre Tecnologías y Sistemas de Internet (Seattle, WA, Mar. 2003). [32] REESE, G. Programación de bases de datos con JDBC y Java, 1ra ed. OReilly, junio de 1997. [33] RHEA, S., LIANG, K., Y BREWER, E. Caché web basada en valores. En Proc. Duodécima Conferencia Internacional de la World Wide Web (mayo de 2003). [34] SIVASUBRAMANIAN, S., ALONSO, G., PIERRE, G., Y VAN STEEN, M. Globedb: Replicación autónoma de datos para aplicaciones web. En WWW 05: Actas de la 14ª Conferencia Internacional de la World-Wide Web (mayo de 2005). [35] SPRING, N. T., Y WETHERALL, D. Una técnica independiente de protocolo para eliminar el tráfico de red redundante. En Proc. de ACM SIGCOMM (Ago. 2000). [36] TOLIA, N., HARKES, J., KOZUCH, M., Y SATYANARAYANAN, M. Integrando almacenamiento portátil y distribuido. En Proc. 3ra Conferencia USENIX sobre Tecnologías de Archivos y Almacenamiento (San Francisco, CA, Mar. 2004). [37] TOLIA, N., KOZUCH, M., SATYANARAYANAN, M., KARP, B., PERRIG, A., Y BRESSOUD, T. Uso oportunista del almacenamiento direccionable por contenido para sistemas de archivos distribuidos. En Proc. Conferencia Técnica Anual USENIX 2003 (San Antonio, TX, junio de 2003), pp. 127-140. [38] YUAN, C., CHEN, Y., Y ZHANG, Z. Evaluación de almacenamiento en caché/descarga en el borde para la entrega de contenido dinámico. En WWW 03: Proc. Duodécima Conferencia Internacional sobre la World Wide Web (2003), pp. 461-471. WWW 2007 / Pista: Rendimiento y Escalabilidad Sesión: Sistemas Escalables para Contenido Dinámico 320 ",
            "candidates": [],
            "error": [
                [
                    "contenido de la base de datos",
                    "contenido dinámico de bases de datos"
                ]
            ]
        },
        "caching dynamic database content": {
            "translated_key": "contenido dinámico de bases de datos",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Consistency-preserving Caching of Dynamic Database Content∗ Niraj Tolia and M. Satyanarayanan Carnegie Mellon University {ntolia,satya}@cs.cmu.edu ABSTRACT With the growing use of dynamic web content generated from relational databases, traditional caching solutions for throughput and latency improvements are ineffective.",
                "We describe a middleware layer called Ganesh that reduces the volume of data transmitted without semantic interpretation of queries or results.",
                "It achieves this reduction through the use of cryptographic hashing to detect similarities with previous results.",
                "These benefits do not require any compromise of the strict consistency semantics provided by the back-end database.",
                "Further, Ganesh does not require modifications to applications, web servers, or database servers, and works with closed-source applications and databases.",
                "Using two benchmarks representative of dynamic web sites, measurements of our prototype show that it can increase end-to-end throughput by as much as twofold for non-data intensive applications and by as much as tenfold for data intensive ones.",
                "Categories and Subject Descriptors C.2.4 [Computer-Communication Networks]: Distributed Systems; H.2.4 [Database Management]: Systems General Terms Design, Performance 1.",
                "INTRODUCTION An increasing fraction of web content is dynamically generated from back-end relational databases.",
                "Even when database content remains unchanged, temporal locality of access cannot be exploited because dynamic content is not cacheable by web browsers or by intermediate caching servers such as Akamai mirrors.",
                "In a multitiered architecture, each web request can stress the WAN link between the web server and the database.",
                "This causes user experience to be highly variable because there is no caching to insulate the client from bursty loads.",
                "Previous attempts in <br>caching dynamic database content</br> have generally weakened transactional semantics [3, 4] or required application modifications [15, 34].",
                "We report on a new solution that takes the form of a databaseagnostic middleware layer called Ganesh.",
                "Ganesh makes no effort to semantically interpret the contents of queries or their results.",
                "Instead, it relies exclusively on cryptographic hashing to detect similarities with previous results.",
                "Hash-based similarity detection has seen increasing use in distributed file systems [26, 36, 37] for improving performance on low-bandwidth networks.",
                "However, these techniques have not been used for relational databases.",
                "Unlike previous approaches that use generic methods to detect similarity, Ganesh exploits the structure of relational database results to yield superior performance improvement.",
                "One faces at least three challenges in applying hash-based similarity detection to back-end databases.",
                "First, previous work in this space has traditionally viewed storage content as uninterpreted bags of bits with no internal structure.",
                "This allows hash-based techniques to operate on long, contiguous runs of data for maximum effectiveness.",
                "In contrast, relational databases have rich internal structure that may not be as amenable to hash-based similarity detection.",
                "Second, relational databases have very tight integrity and consistency constraints that must not be compromised by the use of hash-based techniques.",
                "Third, the source code of commercial databases is typically not available.",
                "This is in contrast to previous work which presumed availability of source code.",
                "Our experiments show that Ganesh, while conceptually simple, can improve performance significantly at bandwidths representative of todays commercial Internet.",
                "On benchmarks modeling multitiered web applications, the throughput improvement was as high as tenfold for data-intensive workloads.",
                "For workloads that were not data-intensive, throughput improvements of up to twofold were observed.",
                "Even when bandwidth was not a constraint, Ganesh had low overhead and did not hurt performance.",
                "Our experiments also confirm that exploiting the structure present in database results is crucial to this performance improvement. 2.",
                "BACKGROUND 2.1 Dynamic Content Generation As the World Wide Web has grown, many web sites have decentralized their data and functionality by pushing them to the edges of the Internet.",
                "Today, eBusiness systems often use a three-tiered architecture consisting of a front-end web server, an application server, and a back-end database server.",
                "Figure 1 illustrates this architecture.",
                "The first two tiers can be replicated close to a concentration of clients at the edge of the Internet.",
                "This improves user experience by lowering end-to-end latency and reducing exposure WWW 2007 / Track: Performance and Scalability Session: Scalable Systems for Dynamic Content 311 Back-End Database Server Front-End Web and Application Servers Figure 1: Multi-Tier Architecture to backbone traffic congestion.",
                "It can also increase the availability and scalability of web services.",
                "Content that is generated dynamically from the back-end database cannot be cached in the first two tiers.",
                "While databases can be easily replicated in a LAN, this is infeasible in a WAN because of the difficult task of simultaneously providing strong consistency, availability, and tolerance to network partitions [7].",
                "As a result, databases tend to be centralized to meet the strong consistency requirements of many eBusiness applications such as banking, finance, and online retailing [38].",
                "Thus, the back-end database is usually located far from many sets of first and second-tier nodes [2].",
                "In the absence of both caching and replication, WAN bandwidth can easily become a limiting factor in the performance and scalability of data-intensive applications. 2.2 Hash-Based Systems Ganeshs focus is on efficient transmission of results by discovering similarities with the results of previous queries.",
                "As SQL queries can generate large results, hash-based techniques lend themselves well to the problem of efficiently transferring these large results across bandwidth constrained links.",
                "The use of hash-based techniques to reduce the volume of data transmitted has emerged as a common theme of many recent storage systems, as discussed in Section 8.2.",
                "These techniques rely on some basic assumptions.",
                "Cryptographic hash functions are assumed to be collision-resistant.",
                "In other words, it is computationally intractable to find two inputs that hash to the same output.",
                "The functions are also assumed to be one-way; that is, finding an input that results in a specific output is computationally infeasible.",
                "Menezes et al. [23] provide more details about these assumptions.",
                "The above assumptions allow hash-based systems to assume that collisions do not occur.",
                "Hence, they are able to treat the hash of a data item as its unique identifier.",
                "A collection of data items effectively becomes content-addressable, allowing a small hash to serve as a codeword for a much larger data item in permanent storage or network transmission.",
                "The assumption that collisions are so rare as to be effectively non-existent has recently come under fire [17].",
                "However, as explained by Black [5], we believe that these issues do not form a concern for Ganesh.",
                "All communication is between trusted parts of the system and an adversary has no way to force Ganesh to accept invalid data.",
                "Further, Ganesh does not depend critically on any specific hash function.",
                "While we currently use SHA-1, replacing it with a different hash function would be simple.",
                "There would be no impact on performance as stronger hash functions (e.g.",
                "SHA256) only add a few extra bytes and the generated hashes are still orders of magnitude smaller than the data items they represent.",
                "No re-hashing of permanent storage is required since Ganesh only uses hashing on volatile data. 3.",
                "DESIGN AND IMPLEMENTATION Ganesh exploits redundancy in the result stream to avoid transmitting result fragments that are already present at the query site.",
                "Redundancy can arise naturally in many different ways.",
                "For example, a query repeated after a certain interval may return a different result because of updates to the database; however, there may be significant commonality between the two results.",
                "As another example, a user who is refining a search may generate a sequence of queries with overlapping results.",
                "When Ganesh detects redundancy, it suppresses transmission of the corresponding result fragments.",
                "Instead, it transmits a much smaller digest of those fragments and lets the query site reconstruct the result through hash lookup in a cache of previous results.",
                "In effect, Ganesh uses computation at the edges to reduce Internet communication.",
                "Our description of Ganesh focuses on four aspects.",
                "We first explain our approach to detecting similarity in query results.",
                "Next, we discuss how the Ganesh architecture is completely invisible to all components of a multi-tier system.",
                "We then describe Ganeshs proxy-based approach and the dataflow for detecting similarity. 3.1 Detecting Similarity One of the key design decisions in Ganesh is how similarity is detected.",
                "There are many potential ways to decompose a result into fragments.",
                "The optimal way is, of course, the one that results in the smallest possible object for transmission for a given querys results.",
                "Finding this optimal decomposition is a difficult problem because of the large space of possibilities and because the optimal choice depends on many factors such as the contents of the querys result, the history of recent results, and the cache management algorithm.",
                "When an object is opaque, the use of Rabin fingerprints [8, 30] to detect common data between two objects has been successfully shown in the past by systems such as LBFS [26] and CASPER [37].",
                "Rabin fingerprinting uses a sliding window over the data to compute a rolling hash.",
                "Assuming that the hash function is uniformly distributed, a chunk boundary is defined whenever the lower order bits of the hash value equal some predetermined value.",
                "The number of lower order bits used defines the average chunk size.",
                "These sub-divided chunks of the object become the unit of comparison for detecting similarity between different objects.",
                "As the locations of boundaries found by using Rabin fingerprints is stochastically determined, they usually fail to align with any structural properties of the underlying data.",
                "The algorithm therefore deals well with in-place updates, insertions and deletions.",
                "However, it performs poorly in the presence of any reordering of data.",
                "Figure 2 shows an example where two results, A and B, consisting of three rows, have the same data but have different sort attributes.",
                "In the extreme case, Rabin fingerprinting might be unable to find any similar data due to the way it detects chunk boundaries.",
                "Fortunately, Ganesh can use domain specific knowledge for more precise boundary detection.",
                "The information we exploit is that a querys result reflects the structure of a relational database where all data is organized as tables and rows.",
                "It is therefore simple to check for similarity with previous results at two granularities: first the entire result, and then individual rows.",
                "The end of a row in a result serves as a natural chunk boundary.",
                "It is important to note that using the tabular structure in results only involves shallow interpretation of the data.",
                "Ganesh does not perform any deeper semantic interpretation such as understanding data types, result schema, or integrity constraints.",
                "Tuning Rabin fingerprinting for a workload can also be difficult.",
                "If the average chunk size is too large, chunks can span multiple result rows.",
                "However, selecting a smaller average chunk size increases the amount of metadata required to the describe the results.",
                "WWW 2007 / Track: Performance and Scalability Session: Scalable Systems for Dynamic Content 312 Figure 2: Rabin Fingerprinting vs. Ganeshs Chunking This, in turn, would decrease the savings obtained via its use.",
                "Rabin fingerprinting also needs two computationally-expensive passes over the data: once to determine chunk boundaries and one again to generate cryptographic hashes for the chunks.",
                "Ganesh only needs a single pass for hash generation as the chunk boundaries are provided by the datas natural structure.",
                "The performance comparison in Section 6 shows that Ganeshs row-based algorithm outperforms Rabin fingerprinting.",
                "Given that previous work has already shown that Rabin fingerprinting performs better than gzip [26], we do not compare Ganesh to compression algorithms in this paper. 3.2 Transparency The key factor influencing our design was the need for Ganesh to be completely transparent to all components of a typical eBusiness system: web servers, application servers, and database servers.",
                "Without this, Ganesh stands little chance of having a significant real-world impact.",
                "Requiring modifications to any of the above components would raise the barrier for entry of Ganesh into an existing system, and thus reduce its chances of adoption.",
                "Preserving transparency is simplified by the fact that Ganesh is purely a performance enhancement, not a functionality or usability enhancement.",
                "We chose agent interposition as the architectural approach to realizing our goal.",
                "This approach relies on the existence of a compact programming interface that is already widely used by target software.",
                "It also relies on a mechanism to easily add new code without disrupting existing module structure.",
                "These conditions are easily met in our context because of the popularity of Java as the programming language for eBusiness systems.",
                "The Java Database Connectivity (JDBC) API [32] allows Java applications to access a wide variety of databases and even other tabular data repositories such as flat files.",
                "Access to these data sources is provided by JDBC drivers that translate between the JDBC API and the database communication mechanism.",
                "Figure 3(a) shows how JDBC is typically used in an application.",
                "As the JDBC interface is standardized, one can substitute one JDBC driver for another without application modifications.",
                "The JDBC driver thus becomes the natural module to exploit for code interposition.",
                "As shown in Figure 3(b), the native JDBC driver is replaced with a Ganesh JDBC driver that presents the same standardized interface.",
                "The Ganesh driver maintains an in-memory cache of result fragments from previous queries and performs reassembly of results.",
                "At the database, we add a new process called the Ganesh proxy.",
                "This proxy, which can be shared by multiple front-end nodes, consists of two parts: code to detect similarity in result fragments and the original native JDBC driver that communicates with the database.",
                "The use of a proxy at the database makes Ganesh database-agnostic and simplifies prototyping and experimentation.",
                "Ganesh is thus able to work with a wide range of databases and applications, requiring no modifications to either. 3.3 Proxy-Based Caching The native JDBC driver shown in Figure 3(a) is a lightweight code component supplied by the database vendor.",
                "Its main funcClient Database Web and Application Server Native JDBC Driver WAN (a) Native Architecture Client Database Ganesh Proxy Native JDBC Driver WAN Web and Application Server Ganesh JDBC Driver (b) Ganeshs Interposition-based Architecture Figure 3: Native vs. Ganesh Architecture tion is to mediate communication between the application and the remote database.",
                "It forwards queries, buffers entire results, and responds to application requests to view parts of results.",
                "The Ganesh JDBC driver shown in Figure 3(b) presents the application with an interface identical to that provided by the native driver.",
                "It provides the ability to reconstruct results from compact hash-based descriptions sent by the proxy.",
                "To perform this reconstruction, the driver maintains an in-memory cache of recentlyreceived results.",
                "This cache is only used as a source of result fragments in reconstructing results.",
                "No attempt is made by the Ganesh driver or proxy to track database updates.",
                "The lack of cache consistency does not hurt correctness as a description of the results is always fetched from the proxy - at worst, there will be no performance benefit from using Ganesh.",
                "Stale data will simply be paged out of the cache over time.",
                "The Ganesh proxy accesses the database via the native JDBC driver, which remains unchanged between Figures 3(a) and (b).",
                "The database is thus completely unaware of the existence of the proxy.",
                "The proxy does not examine any queries received from the Ganesh driver but passes them to the native driver.",
                "Instead, the proxy is responsible for inspecting database output received from the native driver, detecting similar results, and generating hash-based encodings of these results whenever enough similarity is found.",
                "While this architecture does not decrease the load on a database, as mentioned earlier in Section 2.1, it is much easier to replicate databases for scalability in a LAN than in a WAN.",
                "To generate a hash-based encoding, the proxy must be aware of what result fragments are available in the Ganesh drivers cache.",
                "One approach is to be optimistic, and to assume that all result fragments are available.",
                "This will result in the smallest possible initial transmission of a result.",
                "However, in cases where there is little overlap with previous results, the Ganesh driver will have to make many calls to the proxy during reconstruction to fetch missing result fragments.",
                "To avoid this situation, the proxy loosely tracks the state of the Ganesh drivers cache.",
                "Since both components are under our control, it is relatively simple to do this without resorting to gray-box techniques or explicit communication for maintaining cache coherence.",
                "Instead, the proxy simulates the Ganesh drivers cache management algorithm and uses this to maintain a list of hashes for which the Ganesh driver is likely to possess the result fragments.",
                "In case of mistracking, there will be no loss of correctness but there will be extra round-trip delays to fetch the missing fragments.",
                "If the client detects loss of synchronization with the proxy, it can ask the proxy to reset the state shared between them.",
                "Also note that the proxy does not need to keep the result fragments themselves, only their hashes.",
                "This allows the proxy to remain scalable even when it is shared by many front-end nodes.",
                "WWW 2007 / Track: Performance and Scalability Session: Scalable Systems for Dynamic Content 313 Object Output Stream Convert ResultSet Object Input Stream Convert ResultSet All Data Recipe ResultSet All Data ResultSet Network Ganesh Proxy Ganesh JDBC Driver Result Set Recipe Result Set Yes Yes No No GaneshInputStream GaneshOutputStream Figure 4: Dataflow for Result Handling 3.4 Encoding and Decoding Results The Ganesh proxy receives database output as Java objects from the native JDBC driver.",
                "It examines this output to see if a Java object of type ResultSet is present.",
                "The JDBC interface uses this data type to store results of database queries.",
                "If a ResultSet object is found, it is shrunk as discussed below.",
                "All other Java objects are passed through unmodified.",
                "As discussed in Section 3.1, the proxy uses the row boundaries defined in the ResultSet to partition it into fragments consisting of single result rows.",
                "All ResultSet objects are converted into objects of a new type called RecipeResultSet.",
                "We use the term recipe for this compact description of a database result because of its similarity to a file recipe in the CASPER file system [37].",
                "The conversion replaces each result fragment that is likely to be present in the Ganesh drivers cache by a SHA-1 hash of that fragment.",
                "Previously unseen result fragments are retained verbatim.",
                "The proxy also retains hashes for the new result fragments as they will be present in the drivers cache in the future.",
                "Note that the proxy only caches hashes for result fragments and does not cache recipes.",
                "The proxy constructs a RecipeResultSet by checking for similarity at the entire result and then the row level.",
                "If the entire result is predicted to be present in the Ganesh drivers cache, the RecipeResultSet is simply a single hash of the entire result.",
                "Otherwise, it contains hashes for those rows predicted to be present in that cache; all other rows are retained verbatim.",
                "If the proxy estimates an overall space savings, it will transmit the RecipeResultSet.",
                "Otherwise the original ResultSet is transmitted.",
                "The RecipeResultSet objects are transformed back into ResultSet objects by the Ganesh driver.",
                "Figure 4 illustrates ResultSet handling at both ends.",
                "Each SHA-1 hash found in a RecipeResultSet is looked up in the local cache of result fragments.",
                "On a hit, the hash is replaced by the corresponding fragment.",
                "On a miss, the driver contacts the Ganesh proxy to fetch the fragment.",
                "All previously unseen result fragments that were retained verbatim by the proxy are hashed and added to the result cache.",
                "There should be very few misses if the proxy has accurately tracked the Ganesh drivers cache state.",
                "A future optimization would be to batch the fetch of missing fragments.",
                "This would be valuable when there are many small missing fragments in a high-latency WAN.",
                "Once the transformation is complete, the fully reconstructed ResultSet object is passed up to the application. 4.",
                "EXPERIMENTAL VALIDATION Three questions follow from the goals and design of Ganesh: • First, can performance can be improved significantly by exploiting similarity across database results?",
                "Benchmark Dataset Details 500,000 Users, 12,000 Stories BBOARD 2.0 GB 3,298,000 Comments AUCTION 1.3 GB 1,000,000 Users, 34,000 Items Table 1: Benchmark Dataset Details • Second, how important is Ganeshs structural similarity detection relative to Rabin fingerprintings similarity detection? • Third, is the overhead of the proxy-based design acceptable?",
                "Our evaluation answers these question through controlled experiments with the Ganesh prototype.",
                "This section describes the benchmarks used, our evaluation procedure, and the experimental setup.",
                "Results of the experiments are presented in Sections 5, 6, and 7. 4.1 Benchmarks Our evaluation is based on two benchmarks [18] that have been widely used by other researchers to evaluate various aspects of multi-tier [27] and eBusiness architectures [9].",
                "The first benchmark, BBOARD, is modeled after Slashdot, a technology-oriented news site.",
                "The second benchmark, AUCTION, is modeled after eBay, an online auction site.",
                "In both benchmarks, most content is dynamically generated from information stored in a database.",
                "Details of the datasets used can be found in Table 1. 4.1.1 The BBOARD Benchmark The BBOARD benchmark, also known as RUBBoS [18], models Slashdot, a popular technology-oriented web site.",
                "Slashdot aggregates links to news stories and other topics of interest found elsewhere on the web.",
                "The site also serves as a bulletin board by allowing users to comment on the posted stories in a threaded conversation form.",
                "It is not uncommon for a story to gather hundreds of comments in a matter of hours.",
                "The BBOARD benchmark is similar to the site and models the activities of a user, including readonly operations such as browsing the stories of the day, browsing story categories, and viewing comments as well as write operations such as new user registration, adding and moderating comments, and story submission.",
                "The benchmark consists of three different phases: a short warmup phase, a runtime phase representing the main body of the workload, and a short cool-down phase.",
                "In this paper we only report results from the runtime phase.",
                "The warm-up phase is important in establishing dynamic system state, but measurements from that phase are not significant for our evaluation.",
                "The cool-down phase is solely for allowing the benchmark to shut down.",
                "The warm-up, runtime, and cool-down phases are 2, 15, and 2 minutes respectively.",
                "The number of simulated clients were 400, 800, 1200, and 1600.",
                "The benchmark is available in a Java Servlets and PHP version and has different datasets; we evaluated Ganesh using the Java Servlets version and the Expanded dataset.",
                "The BBOARD benchmark defines two different workloads.",
                "The first, the Authoring mix, consists of 70% read-only operations and 30% read-write operations.",
                "The second, the Browsing mix, contains only read-only operations and does not update the database. 4.1.2 The AUCTION Benchmark The AUCTION benchmark, also known as RUBiS [18], models eBay, the online auction site.",
                "The eBay web site is used to buy and sell items via an auction format.",
                "The main activities of a user include browsing, selling, or bidding for items.",
                "Modeling the activities on this site, this benchmark includes read-only activities such as browsing items by category and by region, as well as read-write WWW 2007 / Track: Performance and Scalability Session: Scalable Systems for Dynamic Content 314 NetEm Router Ganesh Proxy Clients Web and Application Server Database Server Figure 5: Experimental Setup activities such as bidding for items, buying and selling items, and leaving feedback.",
                "As with BBOARD, the benchmark consists of three different phases.",
                "The warm-up, runtime, and cool-down phases for this experiment are 1.5, 15, and 1 minutes respectively.",
                "We tested Ganesh with four client configurations where the number of test clients was set to 400, 800, 1200, and 1600.",
                "The benchmark is available in a Enterprise Java Bean (EJB), Java Servlets, and PHP version and has different datasets; we evaluated Ganesh with the Java Servlets version and the Expanded dataset.",
                "The AUCTION benchmark defines two different workloads.",
                "The first, the Bidding mix, consists of 70% read-only operations and 30% read-write operations.",
                "The second, the Browsing mix, contains only read-only operations and does not update the database. 4.2 Experimental Procedure Both benchmarks involve a synthetic workload of clients accessing a web server.",
                "The number of clients emulated is an experimental parameter.",
                "Each emulated client runs an instance of the benchmark in its own thread, using a matrix to transition between different benchmark states.",
                "The matrix defines a stochastic model with probabilities of transitioning between the different states that represent typical user actions.",
                "An example transition is a user logging into the AUCTION system and then deciding on whether to post an item for sale or bid on active auctions.",
                "Each client also models user think time between requests.",
                "The think time is modeled as an exponential distribution with a mean of 7 seconds.",
                "We evaluate Ganesh along two axes: number of clients and WAN bandwidth.",
                "Higher loads are especially useful in understanding Ganeshs performance when the CPU or disk of the database server or proxy is the limiting factor.",
                "A previous study has shown that approximately 50% of the wide-area Internet bottlenecks observed had an available bandwidth under 10 Mb/s [1].",
                "Based on this work, we focus our evaluation on the WAN bandwidth of 5 Mb/s with 66 ms of round-trip latency, representative of severely constrained network paths, and 20 Mb/s with 33 ms of round-trip latency, representative of a moderately constrained network path.",
                "We also report Ganeshs performance at 100 Mb/s with no added round-trip latency.",
                "This bandwidth, representative of an unconstrained network, is especially useful in revealing any potential overhead of Ganesh in situations where WAN bandwidth is not the limiting factor.",
                "For each combination of number of clients and WAN bandwidth, we measured results from the two configurations listed below: • Native: This configuration corresponds to Figure 3(a).",
                "Native avoids Ganeshs overhead in using a proxy and performing Java object serialization. • Ganesh: This configuration corresponds to Figure 3(b).",
                "For a given number of clients and WAN bandwidth, comparing these results to the corresponding Native results gives the performance benefit due to the Ganesh middleware system.",
                "The metric used to quantify the improvement in throughput is the number of client requests that can be serviced per second.",
                "The metric used to quantify Ganeshs overhead is the average response time for a client request.",
                "For all of the experiments, the Ganesh driver used by the application server used a cache size of 100,000 items1 .",
                "The proxy was effective in tracking the Ganesh drivers cache state; for all of our experiments the miss rate on the driver never exceeded 0.7%. 4.3 Experimental Setup The experimental setup used for the benchmarks can be seen in Figure 5.",
                "All machines were 3.2 GHz Pentium 4s (with HyperThreading enabled.)",
                "With the exception of the database server, all machines had 2 GB of SDRAM and ran the Fedora Core Linux distribution.",
                "The database server had 4 GB of SDRAM.",
                "We used Apaches Tomcat as both the application server that hosted the Java Servlets and the web server.",
                "Both benchmarks used Java Servlets to generate the dynamic content.",
                "The database server used the open source MySQL database.",
                "For the native JDBC drivers, we used the Connector/J drivers provided by MySQL.",
                "The application server used Suns Java Virtual Machine as the runtime environment for the Java Servlets.",
                "The sysstat tool was used to monitor the CPU, network, disk, and memory utilization on all machines.",
                "The machines were connected by a switched gigabit Ethernet network.",
                "As shown in Figure 5, the front-end web and application server was separated from the proxy and database server by a NetEm router [16].",
                "This router allowed us to control the bandwidth and latency settings on the network.",
                "The NetEm router is a standard PC with two network cards running the Linux Traffic Control and Network Emulation software.",
                "The bandwidth and latency constraints were only applied to the link between the application server and the database for the native case and between the application server and the proxy for the Ganesh case.",
                "There is no communication between the application server and the database with Ganesh as all data flows through the proxy.",
                "As our focus was on the WAN link between the application server and the database, there were no constraints on the link between the simulated test clients and the web server. 5.",
                "THROUGHPUT AND RESPONSE TIME In this section, we address the first question raised in Section 4: Can performance can be improved significantly by exploiting similarity across database results?",
                "To answer this question, we use results from the BBOARD and AUCTION benchmarks.",
                "We use two metrics to quantify the performance improvement obtainable through the use of Ganesh: throughput, from the perspective of the web server, and average response time, from the perspective of the client.",
                "Throughput is measured in terms of the number of client requests that can be serviced per second. 5.1 BBOARD Results and Analysis 5.1.1 Authoring Mix Figures 6 (a) and (b) present the average number of requests serviced per second and the average response time for these requests as perceived by the clients for BBOARDs Authoring Mix.",
                "As Figure 6 (a) shows, Native easily saturates the 5 Mb/s link.",
                "At 400 clients, the Native solution delivers 29 requests/sec with an average response time of 8.3 seconds.",
                "Natives throughput drops with an increase in test clients as clients timeout due to congestion at the application server.",
                "Usability studies have shown that response times above 10 seconds cause the user to move on to 1 As Java lacks a sizeof() operator, Java caches therefore limit their size based on the number of objects.",
                "The size of cache dumps taken at the end of the experiments never exceeded 212 MB.",
                "WWW 2007 / Track: Performance and Scalability Session: Scalable Systems for Dynamic Content 315 0 50 100 150 200 250 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Test Clients Requests/sec Native Ganesh 0.001 0.01 0.1 1 10 100 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Test Clients Avg.Resp.Time(sec) Native Ganesh Note Logscale (a) Throughput: Authoring Mix (b) Response Time: Authoring Mix 0 50 100 150 200 250 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Test Clients Requests/sec Native Ganesh 0.001 0.01 0.1 1 10 100 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Test Clients Avg.Resp.Time(sec) Native Ganesh Note Logscale (c) Throughput: Browsing Mix (d) Response Time: Browsing Mix Mean of three trials.",
                "The maximum standard deviation for throughput and response time was 9.8% and 11.9% of the corresponding mean.",
                "Figure 6: BBOARD Benchmark - Throughput and Average Response Time other tasks [24].",
                "Based on these numbers, increasing the number of test clients makes the Native system unusable.",
                "Ganesh at 5 Mb/s, however, delivers a twofold improvement with 400 test clients and a fivefold improvement at 1200 clients.",
                "Ganeshs performance drops slightly at 1200 and 1600 clients as the network is saturated.",
                "Compared to Native, Figure 6 (b) shows that Ganeshs response times are substantially lower with sub-second response times at 400 clients.",
                "Figure 6 (a) also shows that for 400 and 800 test clients Ganesh at 5 Mb/s has the same throughput and average response time as Native at 20 Mb/s.",
                "Only at 1200 and 1600 clients does Native at 20 Mb/s deliver higher throughput than Ganesh at 5 Mb/s.",
                "Comparing both Ganesh and Native at 20 Mb/s, we see that Ganesh is no longer bandwidth constrained and delivers up to a twofold improvement over Native at 1600 test clients.",
                "As Ganesh does not saturate the network with higher test client configurations, at 1600 test clients, its average response time is 0.1 seconds rather than Natives 7.7 seconds.",
                "As expected, there are no visible gains from Ganesh at the higher bandwidth of 100 Mb/s where the network is no longer the bottleneck.",
                "Ganesh, however, still tracks Native in terms of throughput. 5.1.2 Browsing Mix Figures 6 (c) and (d) present the average number of requests serviced per second and the average response time for these requests as perceived by the clients for BBOARDs Browsing Mix.",
                "Regardless of the test client configuration, Figure 6 (c) shows that Natives throughput at 5 Mb/s is limited to 10 reqs/sec.",
                "Ganesh at 5 Mb/s with 400 test clients, delivers more than a sixfold increase in throughput.",
                "The improvement increases to over a elevenfold increase at 800 test clients before Ganesh saturates the network.",
                "Further, Figure 6 (d) shows that Natives average response time of 35 seconds at 400 test clients make the system unusable.",
                "These high response times further increase with the addition of test clients.",
                "Even with the 1600 test client configuration Ganesh delivers an acceptable average response time of 8.2 seconds.",
                "Due to the data-intensive nature of the Browsing mix, Ganesh at 5 Mb/s surprisingly performs much better than Native at 20 Mb/s.",
                "Further, as shown in Figure 6 (d), while the average response time for Native at 20 Mb/s is acceptable at 400 test clients, it is unusable with 800 test clients with an average response time of 15.8 seconds.",
                "Like the 5 Mb/s case, this response time increases with the addition of extra test clients.",
                "Ganesh at 20 Mb/s and both Native and Ganesh at 100 Mb/s are not bandwidth limited.",
                "However, performance plateaus out after 1200 test clients due to the database CPU being saturated. 5.1.3 Filter Variant We were surprised by the Native performance from the BBOARD benchmark.",
                "At the bandwidth of 5 Mb/s, Native performance was lower than what we had expected.",
                "It turned out the benchmark code that displays stories read all the comments associated with the particular story from the database and only then did some postprocessing to select the comments to be displayed.",
                "While this is exactly the behavior of SlashCode, the code base behind the Slashdot web site, we decided to modify the benchmark to perform some pre-filtering at the database.",
                "This modified benchmark, named the Filter Variant, models a developer who applies optimizations at the SQL level to transfer less data.",
                "In the interests of brevity, we only briefly summarize the results from the Authoring mix.",
                "For the Authoring mix, at 800 test clients at 5 Mb/s, Figure 7 (a) shows that Natives throughput increase by 85% when compared to the original benchmark while Ganeshs improvement is smaller at 15%.",
                "Natives performance drops above 800 clients as the test clients time out due to high response times.",
                "The most significant gain for Native is seen at 20 Mb/s.",
                "At 1600 test clients, when compared to the original benchmark, Native sees a 73% improvement in throughput and a 77% reduction in average response time.",
                "While WWW 2007 / Track: Performance and Scalability Session: Scalable Systems for Dynamic Content 316 0 50 100 150 200 250 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Test Clients Requests/sec Native Ganesh 0.001 0.01 0.1 1 10 100 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Test Clients Avg.Resp.Time(sec) Native Ganesh Note Logscale (a) Throughput: Authoring Mix (b) Response Time: Authoring Mix Mean of three trials.",
                "The maximum standard deviation for throughput and response time was 7.2% and 11.5% of the corresponding mean.",
                "Figure 7: BBOARD Benchmark - Filter Variant - Throughput and Average Response Time Ganesh sees no improvement when compared to the original, it still processes 19% more requests/sec than Native.",
                "Thus, while the optimizations were more helpful to Native, Ganesh still delivers an improvement in performance. 5.2 AUCTION Results and Analysis 5.2.1 Bidding Mix Figures 8 (a) and (b) present the average number of requests serviced per second and the average response time for these requests as perceived by the clients for AUCTIONs Bidding Mix.",
                "As mentioned earlier, the Bidding mix consists of a mixture of read and write operations.",
                "The AUCTION benchmark is not as data intensive as BBOARD.",
                "Therefore, most of the gains are observed at the lower bandwidth of 5 Mb/s.",
                "Figure 8 (a) shows that the increase in throughput due to Ganesh ranges from 8% at 400 test clients to 18% with 1600 test clients.",
                "As seen in Figure 8 (b), the average response times for Ganesh are significantly lower than Native ranging from a decrease of 84% at 800 test clients to 88% at 1600 test clients.",
                "Figure 8 (a) also shows that with a fourfold increase of bandwidth from 5 Mb/s to 20 Mb/s, Native is no longer bandwidth constrained and there is no performance difference between Ganesh and Native.",
                "With the higher test client configurations, we did observe that the bandwidth used by Ganesh was lower than Native.",
                "Ganesh might still be useful in these non-constrained scenarios if bandwidth is purchased on a metered basis.",
                "Similar results are seen for the 100 Mb/s scenario. 5.2.2 Browsing Mix For AUCTIONs Browsing Mix, Figures 8 (c) and (d) present the average number of requests serviced per second and the average response time for these requests as perceived by the clients.",
                "Again, most of the gains are observed at lower bandwidths.",
                "At 5 Mb/s, Native and Ganesh deliver similar throughput and response times with 400 test clients.",
                "While the throughput for both remains the same at 800 test clients, Figure 8 (d) shows that Ganeshs average response time is 62% lower than Native.",
                "Native saturates the link at 800 clients and adding extra test clients only increases the average response time.",
                "Ganesh, regardless of the test client configuration, is not bandwidth constrained and maintains the same response time.",
                "At 1600 test clients, Figure 8 (c) shows that Ganeshs throughput is almost twice that of Native.",
                "At the higher bandwidths of 20 and 100 Mb/s, neither Ganesh nor Native is bandwidth limited and deliver equivalent throughput and response times.",
                "Benchmark Orig.",
                "Size Ganesh Size Rabin Size SelectSort1 223.6 MB 5.4 MB 219.3 MB SelectSort2 223.6 MB 5.4 MB 223.6 MB Table 2: Similarity Microbenchmarks 6.",
                "STRUCTURAL VS. RABIN SIMILARITY In this section, we address the second question raised in Section 4: How important is Ganeshs structural similarity detection relative to Rabin fingerprinting-based similarity detecting?",
                "To answer this question, we used microbenchmarks and the BBOARD and AUCTION benchmarks.",
                "As Ganesh always performed better than Rabin fingerprinting, we only present a subset of the results here in the interests of brevity. 6.1 Microbenchmarks Two microbenchmarks show an example of the effects of data reordering on Rabin fingerprinting algorithm.",
                "In the first microbenchmark, SelectSort1, a query with a specified sort order selects 223.6 MB of data spread over approximately 280 K rows.",
                "The query is then repeated with a different sort attribute.",
                "While the same number of rows and the same data is returned, the order of rows is different.",
                "In such a scenario, one would expect a large amount of similarity to be detected between both results.",
                "As Table 2 shows, Ganeshs row-based algorithm achieves a 97.6% reduction while the Rabin fingerprinting algorithm, with the average chunk size parameter set to 4 KB, only achieves a 1% reduction.",
                "The reason, as shown earlier in Figure 2, is that with Rabin fingerprinting, the spans of data between two consecutive boundaries usually cross row boundaries.",
                "With the order of the rows changing in the second result and the Rabin fingerprints now spanning different rows, the algorithm is unable to detect significant similarity.",
                "The small gain seen is mostly for those single rows that are large enough to be broken into multiple chunks.",
                "SelectSort2, another micro-benchmark executed the same queries but increased the minimum chunk size of the Rabin fingerprinting algorithm.",
                "As can be seen in Table 2, even the small gain from the previous microbenchmark disappears as the minimum chunk size was greater than the average row size.",
                "While one can partially address these problems by dynamically varying the parameters of the Rabin fingerprinting algorithm, this can be computationally expensive, especially in the presence of changing workloads. 6.2 Application Benchmarks We ran the BBOARD benchmark described in Section 4.1.1 on two versions of Ganesh: the first with Rabin fingerprinting used as WWW 2007 / Track: Performance and Scalability Session: Scalable Systems for Dynamic Content 317 0 50 100 150 200 250 300 350 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Test Clients Requests/sec Native Ganesh 0.001 0.01 0.1 1 10 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Test Clients Avg.Resp.Time(sec) Native Ganesh Note Logscale (a) Throughput: Bidding Mix (b) Response Time: Bidding Mix 0 50 100 150 200 250 300 350 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Test Clients Requests/sec Native Ganesh 0.001 0.01 0.1 1 10 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Test Clients Avg.Resp.Time(sec) Native Ganesh Note Logscale (c) Throughput: Browsing Mix (d) Response Time: Browsing Mix Mean of three trials.",
                "The maximum standard deviation for throughput and response time was 2.2% and 11.8% of the corresponding mean.",
                "Figure 8: AUCTION Benchmark - Throughput and Average Response Time the chunking algorithm and the second with Ganeshs row-based algorithm.",
                "Rabins results for the Browsing Mix are normalized to Ganeshs results and presented in Figure 9.",
                "As Figure 9 (a) shows, at 5 Mb/s, independent of the test client configuration, Rabin significantly underperforms Ganesh.",
                "This happens because of a combination of two reasons.",
                "First, as outlined in Section 3.1, Rabin finds less similarity as it does not exploit the results structural information.",
                "Second, this benchmark contained some queries that generated large results.",
                "In this case, Rabin, with a small average chunk size, generated a large number of objects that evicted other useful data from the cache.",
                "In contrast, Ganesh was able to detect these large rows and correspondingly increase the size of the chunks.",
                "This was confirmed as cache statistics showed that Ganeshs hit ratio was roughly three time that of Rabin.",
                "Throughput measurements at 20 Mb/s were similar with the exception of Rabins performance with 400 test clients.",
                "In this case, Ganesh was not network limited and, in fact, the throughput was the same as 400 clients at 5 Mb/s.",
                "Rabin, however, took advantage of the bandwidth increase from 5 to 20 Mb/s to deliver a slightly better performance.",
                "At 100 Mb/s, Rabins throughput was almost similar to Ganesh as bandwidth was no longer a bottleneck.",
                "The normalized response time, presented in Figure 9 (b), shows similar trends.",
                "At 5 and 20 Mb/s, the addition of test clients decreases the normalized response time as Ganeshs average response time increases faster than Rabins.",
                "However, at no point does Rabin outperform Ganesh.",
                "Note that at 400 and 800 clients at 100 Mb/s, Rabin does have a higher overhead even when it is not bandwidth constrained.",
                "As mentioned in Section 3.1, this is due to the fact that Rabin has to hash each ResultSet twice.",
                "The overhead disappears with 1200 and 1600 clients as the database CPU is saturated and limits the performance of both Ganesh and Rabin. 7.",
                "PROXY OVERHEAD In this section, we address the third question raised in Section 4: Is the overhead of Ganeshs proxy-based design acceptable?",
                "To answer this question, we concentrate on its performance at the higher bandwidths.",
                "Our evaluation in Section 5 showed that Ganesh, when compared to Native, can deliver a substantial throughput improvement at lower bandwidths.",
                "It is only at higher bandwidths that latency, measured by the average response time for a client request, and throughput, measured by the number of client requests that can be serviced per second, overheads would be visible.",
                "Looking at the Authoring mix of the original BBOARD benchmark, there are no visible gains from Ganesh at 100 Mb/s.",
                "Ganesh, however, still tracks Native in terms of throughput.",
                "While the average response time is higher for Ganesh, the absolute difference is in between 0.01 and 0.04 seconds and would be imperceptible to the end-user.",
                "The Browsing mix shows an even smaller difference in average response times.",
                "The results from the filter variant of the BBOARD benchmarks are similar.",
                "Even for the AUCTION benchmark, the difference between Native and Ganeshs response time at 100 Mb/s was never greater than 0.02 seconds.",
                "The only exception to the above results was seen in the filter variant of the BBOARD benchmark where Ganesh at 1600 test clients added 0.85 seconds to the average response time.",
                "Thus, even for much faster networks where the WAN link is not the bottleneck, Ganesh always delivers throughput equivalent to Native.",
                "While some extra latency is added by the proxy-based design, it is usually imperceptible. 8.",
                "RELATED WORK To the best of our knowledge, Ganesh is the first system that combines the use of hash-based techniques with caching of database results to improve throughput and response times for applications with dynamic content.",
                "We also believe that it is also the first system to demonstrate the benefits of using structural information for WWW 2007 / Track: Performance and Scalability Session: Scalable Systems for Dynamic Content 318 0.0 0.2 0.4 0.6 0.8 1.0 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Test Clients Norm.Throughput 31.8 3.8 2.8 2.3 23.8 32.8 5.8 3.6 1.8 2.1 1.1 1.0 0 5 10 15 20 25 30 35 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Test Clients Norm.ResponseTime (a) Normalized Throughput: Higher is better (b) Normalized Response Time: Higher is worse For throughput, a normalized result greater than 1 implies that Rabin is better, For response time, a normalized result greater than 1 implies that Ganesh is better.",
                "Mean of three trials.",
                "The maximum standard deviation for throughput and response time was 9.1% and 13.9% of the corresponding mean.",
                "Figure 9: Normalized Comparison of Ganesh vs. Rabin - BBOARD Browsing Mix detecting similarity.",
                "In this section, we first discuss alternative approaches to caching dynamic content and then examine other uses of hash-based primitives in distributed systems. 8.1 Caching Dynamic Content At the database layer, a number of systems have advocated middletier caching where parts of the database are replicated at the edge or server [3, 4, 20].",
                "These systems either cache entire tables in what is essentially a replicated database or use materialized views from previous query replies [19].",
                "They require tight integration with the back-end database to ensure a time bound on the propagation of updates.",
                "These systems are also usually targeted towards workloads that do not require strict consistency and can tolerate stale data.",
                "Further, unlike Ganesh, some of these mid-tier caching solutions [2, 3], suffer from the complexity of having to participate in query planing and distributed query processing.",
                "Gao et al. [15] propose using a distributed object replication architecture where the data stores consistency requirements are adapted on a per-application basis.",
                "These solutions require substantial developer resources and detailed understanding of the application being modified.",
                "While systems that attempt to automate the partitioning and replication of an applications database exist [34], they do not provide full transaction semantics.",
                "In comparison, Ganesh does not weaken any of the semantics provided by the underlying database.",
                "Recent work in the evaluation of edge caching options for dynamic web sites [38] has suggested that, without careful planning, employing complex offloading strategies can hurt performance.",
                "Instead, the work advocates for an architecture in which all tiers except the database should be offloaded to the edge.",
                "Our evaluation of Ganesh has shown that it would benefit these scenarios.",
                "To improve database scalability, C-JDBC [10], SSS [22], and Ganymed [28] also advocate the use of an interposition-based architecture to transparently cluster and replicate databases at the middleware level.",
                "The approaches of these architectures and Ganesh are complementary and they would benefit each other.",
                "Moving up to the presentation layer, there has been widespread adoption of fragment-based caching [14], which improves cache utilization by separately caching different parts of generated web pages.",
                "While fragment-based caching works at the edge, a recent proposal has proposed moving web page assembly to the clients to optimize content delivery [31].",
                "While Ganesh is not used at the presentation layer, the same principles have been applied in Duplicate Transfer Detection [25] to increase web cache efficiency as well as for web access across bandwidth limited links [33]. 8.2 Hash-based Systems The past few years have seen the emergence of many systems that exploit hash-based techniques.",
                "At the heart of all these systems is the idea of detecting similarity in data without requiring interpretation of that data.",
                "This simple yet elegant idea relies on cryptographic hashing, as discussed earlier in Section 2.",
                "Successful applications of this idea span a wide range of storage systems.",
                "Examples include peer-to-peer backup of personal computing files [11], storage-efficient archiving of data [29], and finding similar files [21].",
                "Spring and Wetherall [35] apply similar principles at the network level.",
                "Using synchronized caches at both ends of a network link, duplicated data is replaced by smaller tokens for transmission and then restored at the remote end.",
                "This and other hash-based systems such as the CASPER [37] and LBFS [26] filesystems, and Layer-2 bandwidth optimizers such as Riverbed and Peribit use Rabin fingerprinting [30] to discover spans of commonality in data.",
                "This approach is especially useful when data items are modified in-place through insertions, deletions, and updates.",
                "However, as Section 6 shows, the performance of this technique can show a dramatic drop in the presence of data reordering.",
                "Ganesh instead uses row boundaries as dividers for detecting similarity.",
                "The most aggressive use of hash-based techniques is by systems that use hashes as the primary identifiers for objects in persistent storage.",
                "Storage systems such as CFS [12] and PAST [13] that have been built using distributed hash tables fall into this category.",
                "Single Instance Storage [6] and Venti [29] are other examples of such systems.",
                "As discussed in Section 2.2, the use of cryptographic hashes for addressing persistent data represents a deeper level of faith in their collision-resistance than that assumed by Ganesh.",
                "If time reveals shortcomings in the hash algorithm, the effort involved in correcting the flaw is much greater.",
                "In Ganesh, it is merely a matter of replacing the hash algorithm. 9.",
                "CONCLUSION The growing use of dynamic web content generated from relational databases places increased demands on WAN bandwidth.",
                "Traditional caching solutions for bandwidth and latency reduction are often ineffective for such content.",
                "This paper shows that the impact of WAN accesses to databases can be substantially reduced through the Ganesh architecture without any compromise of the databases strict consistency semantics.",
                "The essence of the Ganesh architecture is the use of computation at the edges to reduce communication through the Internet.",
                "Ganesh is able to use cryptographic hashes to detect similarity with previous results and send WWW 2007 / Track: Performance and Scalability Session: Scalable Systems for Dynamic Content 319 compact recipes of results rather than full results.",
                "Our design uses interposition to achieve complete transparency: clients, application servers, and database servers are all unaware of Ganeshs presence and require no modification.",
                "Our experimental evaluation confirms that Ganesh, while conceptually simple, can be highly effective in improving throughput and response time.",
                "Our results also confirm that exploiting the structure present in database results to detect similarity is crucial to this performance improvement. 10.",
                "REFERENCES [1] AKELLA, A., SESHAN, S., AND SHAIKH, A.",
                "An empirical evaluation of wide-area internet bottlenecks.",
                "In Proc. 3rd ACM SIGCOMM Conference on Internet Measurement (Miami Beach, FL, USA, Oct. 2003), pp. 101-114. [2] ALTINEL, M., BORNH ¨OVD, C., KRISHNAMURTHY, S., MOHAN, C., PIRAHESH, H., AND REINWALD, B. Cache tables: Paving the way for an adaptive database cache.",
                "In Proc. of 29th VLDB (Berlin, Germany, 2003), pp. 718-729. [3] ALTINEL, M., LUO, Q., KRISHNAMURTHY, S., MOHAN, C., PIRAHESH, H., LINDSAY, B. G., WOO, H., AND BROWN, L. Dbcache: Database caching for web application servers.",
                "In Proc. 2002 ACM SIGMOD (2002), pp. 612-612. [4] AMIRI, K., PARK, S., TEWARI, R., AND PADMANABHAN, S. Dbproxy: A dynamic data cache for web applications.",
                "In Proc.",
                "IEEE International Conference on Data Engineering (ICDE) (Mar. 2003). [5] BLACK, J. Compare-by-hash: A reasoned analysis.",
                "In Proc. 2006 USENIX Annual Technical Conference (Boston, MA, May 2006), pp. 85-90. [6] BOLOSKY, W. J., CORBIN, S., GOEBEL, D., , AND DOUCEUR, J. R. Single instance storage in windows 2000.",
                "In Proc. 4th USENIX Windows Systems Symposium (Seattle, WA, Aug. 2000), pp. 13-24. [7] BREWER, E. A.",
                "Lessons from giant-scale services.",
                "IEEE Internet Computing 5, 4 (2001), 46-55. [8] BRODER, A., GLASSMAN, S., MANASSE, M., AND ZWEIG, G. Syntactic clustering of the web.",
                "In Proc. 6th International WWW Conference (1997). [9] CECCHET, E., CHANDA, A., ELNIKETY, S., MARGUERITE, J., AND ZWAENEPOEL, W. Performance comparison of middleware architectures for generating dynamic web content.",
                "In Proc.",
                "Fourth ACM/IFIP/USENIX International Middleware Conference (Rio de Janeiro, Brazil, June 2003). [10] CECCHET, E., MARGUERITE, J., AND ZWAENEPOEL, W. C-JDBC: Flexible database clustering middleware.",
                "In Proc. 2004 USENIX Annual Technical Conference (Boston, MA, June 2004). [11] COX, L. P., MURRAY, C. D., AND NOBLE, B. D. Pastiche: Making backup cheap and easy.",
                "In OSDI: Symposium on Operating Systems Design and Implementation (2002). [12] DABEK, F., KAASHOEK, M. F., KARGER, D., MORRIS, R., AND STOICA, I. Wide-area cooperative storage with CFS.",
                "In 18th ACM Symposium on Operating Systems Principles (Banff, Canada, Oct. 2001). [13] DRUSCHEL, P., AND ROWSTRON, A.",
                "PAST: A large-scale, persistent peer-to-peer storage utility.",
                "In HotOS VIII (Schloss Elmau, Germany, May 2001), pp. 75-80. [14] Edge side includes. http://www.esi.org. [15] GAO, L., DAHLIN, M., NAYATE, A., ZHENG, J., AND IYENGAR, A.",
                "Application specific data replication for edge services.",
                "In WWW 03: Proc.",
                "Twelfth International Conference on World Wide Web (2003), pp. 449-460. [16] HEMMINGER, S. Netem - emulating real networks in the lab.",
                "In Proc. 2005 Linux Conference Australia (Canberra, Australia, Apr. 2005). [17] HENSON, V. An analysis of compare-by-hash.",
                "In Proc. 9th Workshop on Hot Topics in Operating Systems (HotOS IX) (May 2003), pp. 13-18. [18] Jmob benchmarks. http://jmob.objectweb.org/. [19] LABRINIDIS, A., AND ROUSSOPOULOS, N. Balancing performance and data freshness in web database servers.",
                "In Proc. 29th VLDB Conference (Sept. 2003). [20] LARSON, P.-A., GOLDSTEIN, J., AND ZHOU, J. Transparent mid-tier database caching in sql server.",
                "In Proc. 2003 ACM SIGMOD (2003), pp. 661-661. [21] MANBER, U.",
                "Finding similar files in a large file system.",
                "In Proc.",
                "USENIX Winter 1994 Technical Conference (San Fransisco, CA, 17-21 1994), pp. 1-10. [22] MANJHI, A., AILAMAKI, A., MAGGS, B. M., MOWRY, T. C., OLSTON, C., AND TOMASIC, A.",
                "Simultaneous scalability and security for data-intensive web applications.",
                "In Proc. 2006 ACM SIGMOD (June 2006), pp. 241-252. [23] MENEZES, A. J., VANSTONE, S. A., AND OORSCHOT, P. C. V. Handbook of Applied Cryptography.",
                "CRC Press, 1996. [24] MILLER, R. B.",
                "Response time in man-computer conversational transactions.",
                "In Proc.",
                "AFIPS Fall Joint Computer Conference (1968), pp. 267-277. [25] MOGUL, J. C., CHAN, Y. M., AND KELLY, T. Design, implementation, and evaluation of duplicate transfer detection in http.",
                "In Proc.",
                "First Symposium on Networked Systems Design and Implementation (San Francisco, CA, Mar. 2004). [26] MUTHITACHAROEN, A., CHEN, B., AND MAZIERES, D. A low-bandwidth network file system.",
                "In Proc. 18th ACM Symposium on Operating Systems Principles (Banff, Canada, Oct. 2001). [27] PFEIFER, D., AND JAKSCHITSCH, H. Method-based caching in multi-tiered server applications.",
                "In Proc.",
                "Fifth International Symposium on Distributed Objects and Applications (Catania, Sicily, Italy, Nov. 2003). [28] PLATTNER, C., AND ALONSO, G. Ganymed: Scalable replication for transactional web applications.",
                "In Proc. 5th ACM/IFIP/USENIX International Conference on Middleware (2004), pp. 155-174. [29] QUINLAN, S., AND DORWARD, S. Venti: A new approach to archival storage.",
                "In Proc.",
                "FAST 2002 Conference on File and Storage Technologies (2002). [30] RABIN, M. Fingerprinting by random polynomials.",
                "In Harvard University Center for Research in Computing Technology Technical Report TR-15-81 (1981). [31] RABINOVICH, M., XIAO, Z., DOUGLIS, F., AND KALMANEK, C. Moving edge side includes to the real edge - the clients.",
                "In Proc. 4th USENIX Symposium on Internet Technologies and Systems (Seattle, WA, Mar. 2003). [32] REESE, G. Database Programming with JDBC and Java, 1st ed.",
                "OReilly, June 1997. [33] RHEA, S., LIANG, K., AND BREWER, E. Value-based web caching.",
                "In Proc.",
                "Twelfth International World Wide Web Conference (May 2003). [34] SIVASUBRAMANIAN, S., ALONSO, G., PIERRE, G., AND VAN STEEN, M. Globedb: Autonomic data replication for web applications.",
                "In WWW 05: Proc. 14th International World-Wide Web conference (May 2005). [35] SPRING, N. T., AND WETHERALL, D. A protocol-independent technique for eliminating redundant network traffic.",
                "In Proc. of ACM SIGCOMM (Aug. 2000). [36] TOLIA, N., HARKES, J., KOZUCH, M., AND SATYANARAYANAN, M. Integrating portable and distributed storage.",
                "In Proc. 3rd USENIX Conference on File and Storage Technologies (San Francisco, CA, Mar. 2004). [37] TOLIA, N., KOZUCH, M., SATYANARAYANAN, M., KARP, B., PERRIG, A., AND BRESSOUD, T. Opportunistic use of content addressable storage for distributed file systems.",
                "In Proc. 2003 USENIX Annual Technical Conference (San Antonio, TX, June 2003), pp. 127-140. [38] YUAN, C., CHEN, Y., AND ZHANG, Z.",
                "Evaluation of edge caching/offloading for dynamic content delivery.",
                "In WWW 03: Proc.",
                "Twelfth International Conference on World Wide Web (2003), pp. 461-471.",
                "WWW 2007 / Track: Performance and Scalability Session: Scalable Systems for Dynamic Content 320"
            ],
            "original_annotated_samples": [
                "Previous attempts in <br>caching dynamic database content</br> have generally weakened transactional semantics [3, 4] or required application modifications [15, 34]."
            ],
            "translated_annotated_samples": [
                "Los intentos previos de almacenar en caché <br>contenido dinámico de bases de datos</br> generalmente han debilitado la semántica transaccional [3, 4] o han requerido modificaciones en la aplicación [15, 34]."
            ],
            "translated_text": "Conservación de la consistencia en el almacenamiento en caché de contenido dinámico de bases de datos∗ Niraj Tolia y M. Satyanarayanan Universidad Carnegie Mellon {ntolia,satya}@cs.cmu.edu RESUMEN Con el creciente uso de contenido web dinámico generado a partir de bases de datos relacionales, las soluciones de almacenamiento en caché tradicionales para mejorar el rendimiento y la latencia son ineficaces. Describimos una capa de middleware llamada Ganesh que reduce el volumen de datos transmitidos sin interpretación semántica de consultas o resultados. Se logra esta reducción mediante el uso de hash criptográficos para detectar similitudes con resultados anteriores. Estos beneficios no requieren ningún compromiso con la semántica de consistencia estricta proporcionada por la base de datos del servidor. Además, Ganesh no requiere modificaciones en aplicaciones, servidores web o servidores de bases de datos, y funciona con aplicaciones y bases de datos de código cerrado. Usando dos puntos de referencia representativos de sitios web dinámicos, las mediciones de nuestro prototipo muestran que puede aumentar el rendimiento de extremo a extremo hasta en un factor de dos para aplicaciones no intensivas en datos y hasta en un factor de diez para las intensivas en datos. Categorías y Descriptores de Asignaturas C.2.4 [Redes de Computadoras-Comunicación]: Sistemas Distribuidos; H.2.4 [Gestión de Bases de Datos]: Términos Generales de Sistemas de Diseño, Rendimiento 1. INTRODUCCIÓN Una fracción creciente del contenido web se genera dinámicamente a partir de bases de datos relacionales en el backend. Incluso cuando el contenido de la base de datos permanece sin cambios, la localidad temporal de acceso no puede ser explotada porque el contenido dinámico no es almacenable en caché por los navegadores web o por servidores de almacenamiento en caché intermedios como los espejos de Akamai. En una arquitectura multinivel, cada solicitud web puede tensionar el enlace WAN entre el servidor web y la base de datos. Esto provoca que la experiencia del usuario sea altamente variable porque no hay almacenamiento en caché para aislar al cliente de cargas repentinas. Los intentos previos de almacenar en caché <br>contenido dinámico de bases de datos</br> generalmente han debilitado la semántica transaccional [3, 4] o han requerido modificaciones en la aplicación [15, 34]. Informamos sobre una nueva solución que toma la forma de una capa intermedia de middleware independiente de la base de datos llamada Ganesh. Ganesh no hace ningún esfuerzo por interpretar semánticamente el contenido de las consultas o sus resultados. En cambio, se basa exclusivamente en el hash criptográfico para detectar similitudes con resultados anteriores. La detección de similitud basada en hash ha sido cada vez más utilizada en sistemas de archivos distribuidos [26, 36, 37] para mejorar el rendimiento en redes de baja capacidad de ancho de banda. Sin embargo, estas técnicas no se han utilizado para bases de datos relacionales. A diferencia de enfoques anteriores que utilizan métodos genéricos para detectar similitud, Ganesh explota la estructura de los resultados de la base de datos relacional para lograr una mejora superior en el rendimiento. Uno se enfrenta al menos a tres desafíos al aplicar la detección de similitud basada en hash a las bases de datos de back-end. Primero, el trabajo previo en este ámbito ha considerado tradicionalmente el contenido de almacenamiento como bolsas de bits no interpretadas y sin estructura interna. Esto permite que las técnicas basadas en hash operen en largas y contiguas secuencias de datos para lograr la máxima efectividad. Por el contrario, las bases de datos relacionales tienen una estructura interna compleja que puede no ser tan propicia para la detección de similitudes basada en hash. Segundo, las bases de datos relacionales tienen restricciones de integridad y consistencia muy estrictas que no deben comprometerse por el uso de técnicas basadas en hash. Tercero, el código fuente de las bases de datos comerciales generalmente no está disponible. Esto contrasta con trabajos anteriores que presumían la disponibilidad del código fuente. Nuestros experimentos muestran que Ganesh, aunque conceptualmente simple, puede mejorar significativamente el rendimiento en anchos de banda representativos del Internet comercial actual. En los modelos de referencia de aplicaciones web multinivel, la mejora en el rendimiento fue de hasta diez veces para cargas de trabajo intensivas en datos. Para cargas de trabajo que no eran intensivas en datos, se observaron mejoras en el rendimiento de hasta el doble. Incluso cuando el ancho de banda no era una limitación, Ganesh tenía un bajo sobrecosto y no afectaba el rendimiento. Nuestros experimentos también confirman que aprovechar la estructura presente en los resultados de la base de datos es crucial para esta mejora en el rendimiento. Antecedentes 2.1 Generación de Contenido Dinámico A medida que la World Wide Web ha crecido, muchos sitios web han descentralizado sus datos y funcionalidades al llevarlos a los extremos de Internet. Hoy en día, los sistemas de comercio electrónico a menudo utilizan una arquitectura de tres niveles que consta de un servidor web de front-end, un servidor de aplicaciones y un servidor de base de datos de back-end. La Figura 1 ilustra esta arquitectura. Los dos primeros niveles se pueden replicar cerca de una concentración de clientes en el borde de Internet. Esto mejora la experiencia del usuario al reducir la latencia de extremo a extremo y disminuir la exposición al congestionamiento del tráfico de la columna vertebral. También puede aumentar la disponibilidad y escalabilidad de los servicios web. El contenido que se genera dinámicamente desde la base de datos del servidor no puede ser almacenado en caché en los dos primeros niveles. Si bien las bases de datos pueden replicarse fácilmente en una LAN, esto es inviable en una WAN debido a la difícil tarea de proporcionar simultáneamente una consistencia sólida, disponibilidad y tolerancia a particiones de red [7]. Como resultado, las bases de datos tienden a ser centralizadas para cumplir con los fuertes requisitos de consistencia de muchas aplicaciones de comercio electrónico como la banca, las finanzas y la venta al por menor en línea [38]. Por lo tanto, la base de datos del back-end suele estar ubicada lejos de muchos conjuntos de nodos de primer y segundo nivel [2]. En ausencia de almacenamiento en caché y replicación, el ancho de banda de la WAN puede convertirse fácilmente en un factor limitante en el rendimiento y la escalabilidad de aplicaciones intensivas en datos. El enfoque de Ganesh en los sistemas basados en hash es la transmisión eficiente de resultados al descubrir similitudes con los resultados de consultas anteriores. Dado que las consultas SQL pueden generar resultados grandes, las técnicas basadas en hash se prestan bien al problema de transferir eficientemente estos grandes resultados a través de enlaces con ancho de banda limitado. El uso de técnicas basadas en hash para reducir el volumen de datos transmitidos ha surgido como un tema común en muchos sistemas de almacenamiento recientes, como se discute en la Sección 8.2. Estas técnicas se basan en algunas suposiciones básicas. Se asume que las funciones hash criptográficas son resistentes a colisiones. En otras palabras, es computacionalmente intratable encontrar dos entradas que se hash a la misma salida. Las funciones también se asumen como unidireccionales; es decir, encontrar una entrada que resulte en una salida específica es computacionalmente inviable. Menezes et al. [23] proporcionan más detalles sobre estas suposiciones. Las suposiciones anteriores permiten a los sistemas basados en hash asumir que no se producen colisiones. Por lo tanto, pueden tratar el hash de un elemento de datos como su identificador único. Una colección de elementos de datos se convierte efectivamente en direccionable por contenido, permitiendo que un hash pequeño funcione como una palabra de código para un elemento de datos mucho más grande en almacenamiento permanente o transmisión en red. La suposición de que las colisiones son tan raras que prácticamente no existen ha sido cuestionada recientemente [17]. Sin embargo, como explicó Black [5], creemos que estos problemas no son una preocupación para Ganesh. Toda comunicación es entre partes confiables del sistema y un adversario no tiene forma de obligar a Ganesh a aceptar datos inválidos. Además, Ganesh no depende críticamente de ninguna función hash específica. Si bien actualmente usamos SHA-1, reemplazarlo con una función hash diferente sería sencillo. No habría impacto en el rendimiento con funciones hash más fuertes (por ejemplo, SHA256) solo añade unos pocos bytes adicionales y los hashes generados siguen siendo órdenes de magnitud más pequeños que los elementos de datos que representan. No es necesario volver a almacenar permanentemente ya que Ganesh solo utiliza el hash en datos volátiles. 3. DISEÑO E IMPLEMENTACIÓN Ganesh explota la redundancia en el flujo de resultados para evitar transmitir fragmentos de resultados que ya están presentes en el sitio de la consulta. La redundancia puede surgir de forma natural de muchas maneras diferentes. Por ejemplo, una consulta repetida después de un cierto intervalo puede devolver un resultado diferente debido a actualizaciones en la base de datos; sin embargo, puede haber una significativa similitud entre los dos resultados. Como otro ejemplo, un usuario que está refinando una búsqueda puede generar una secuencia de consultas con resultados superpuestos. Cuando Ganesh detecta redundancia, suprime la transmisión de los fragmentos de resultado correspondientes. En cambio, transmite un resumen mucho más pequeño de esos fragmentos y permite que el sitio de consulta reconstruya el resultado a través de la búsqueda de hash en una caché de resultados anteriores. De hecho, Ganesh utiliza la computación en los bordes para reducir la comunicación por Internet. Nuestra descripción de Ganesh se centra en cuatro aspectos. Primero explicamos nuestro enfoque para detectar similitud en los resultados de la consulta. A continuación, discutimos cómo la arquitectura Ganesh es completamente invisible para todos los componentes de un sistema de múltiples niveles. Luego describimos el enfoque basado en proxy de Ganesh y el flujo de datos para detectar similitudes. 3.1 Detectar similitud Una de las decisiones clave de diseño en Ganesh es cómo se detecta la similitud. Hay muchas formas potenciales de descomponer un resultado en fragmentos.  I the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the thees I,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,, Encontrar esta descomposición óptima es un problema difícil debido al amplio espacio de posibilidades y porque la elección óptima depende de muchos factores, como el contenido del resultado de las consultas, el historial de resultados recientes y el algoritmo de gestión de caché. Cuando un objeto es opaco, el uso de huellas digitales de Rabin [8, 30] para detectar datos comunes entre dos objetos ha sido demostrado con éxito en el pasado por sistemas como LBFS [26] y CASPER [37]. El fingerprinting de Rabin utiliza una ventana deslizante sobre los datos para calcular un hash rodante. Suponiendo que la función hash está distribuida uniformemente, un límite de fragmento se define cuando los bits de orden inferior del valor hash son iguales a algún valor predeterminado. El número de bits de orden inferior utilizados define el tamaño promedio del fragmento. Estos fragmentos subdivididos del objeto se convierten en la unidad de comparación para detectar similitudes entre diferentes objetos. Dado que las ubicaciones de los límites encontrados mediante el uso de las huellas de Rabin están determinadas de manera estocástica, generalmente no logran alinearse con ninguna propiedad estructural de los datos subyacentes. Por lo tanto, el algoritmo maneja bien las actualizaciones en su lugar, inserciones y eliminaciones. Sin embargo, tiene un rendimiento deficiente en presencia de cualquier reordenamiento de datos. La Figura 2 muestra un ejemplo donde dos resultados, A y B, que constan de tres filas, tienen los mismos datos pero diferentes atributos de ordenamiento. En el caso extremo, la huella digital de Rabin podría no ser capaz de encontrar datos similares debido a la forma en que detecta los límites de los fragmentos. Afortunadamente, Ganesh puede utilizar conocimientos específicos del dominio para una detección de límites más precisa. La información que explotamos es que el resultado de una consulta refleja la estructura de una base de datos relacional donde todos los datos están organizados en tablas y filas. Por lo tanto, es sencillo verificar la similitud con resultados anteriores en dos niveles de granularidad: primero el resultado completo y luego las filas individuales. El final de una fila en un resultado sirve como un límite natural de fragmento. Es importante tener en cuenta que el uso de la estructura tabular en los resultados solo implica una interpretación superficial de los datos. Ganesh no realiza ninguna interpretación semántica más profunda, como comprender tipos de datos, esquemas de resultados o restricciones de integridad. Ajustar la huella digital de Rabin para una carga de trabajo también puede ser difícil. Si el tamaño promedio de los fragmentos es demasiado grande, los fragmentos pueden abarcar varias filas de resultados. Sin embargo, seleccionar un tamaño de fragmento promedio más pequeño aumenta la cantidad de metadatos necesarios para describir los resultados. Esto, a su vez, disminuiría los ahorros obtenidos mediante su uso. El fingerprinting de Rabin también requiere dos pasadas computacionalmente costosas sobre los datos: una vez para determinar los límites de los fragmentos y otra vez para generar hashes criptográficos para los fragmentos. Ganesh solo necesita un único pase para la generación de hash, ya que los límites de los fragmentos son proporcionados por la estructura natural de los datos. La comparación de rendimiento en la Sección 6 muestra que el algoritmo basado en filas de Ganesh supera al fingerprinting de Rabin. Dado que trabajos anteriores ya han demostrado que la huella digital de Rabin funciona mejor que gzip [26], no comparamos a Ganesh con algoritmos de compresión en este artículo. 3.2 Transparencia El factor clave que influyó en nuestro diseño fue la necesidad de que Ganesh fuera completamente transparente para todos los componentes de un sistema típico de comercio electrónico: servidores web, servidores de aplicaciones y servidores de bases de datos. Sin esto, Ganesh tiene pocas posibilidades de tener un impacto significativo en el mundo real. Requerir modificaciones en cualquiera de los componentes mencionados aumentaría la barrera de entrada de Ganesh en un sistema existente, y por lo tanto reduciría sus posibilidades de adopción. Preservar la transparencia se simplifica por el hecho de que Ganesh es simplemente una mejora de rendimiento, no una mejora de funcionalidad o usabilidad. Elegimos la interposición de agentes como enfoque arquitectónico para lograr nuestro objetivo. Este enfoque se basa en la existencia de una interfaz de programación compacta que ya es ampliamente utilizada por el software objetivo. También se basa en un mecanismo para agregar fácilmente nuevo código sin interrumpir la estructura de módulos existente. Estas condiciones se cumplen fácilmente en nuestro contexto debido a la popularidad de Java como el lenguaje de programación para sistemas de comercio electrónico. La API de Conectividad de Base de Datos de Java (JDBC) [32] permite a las aplicaciones de Java acceder a una amplia variedad de bases de datos e incluso a otros repositorios de datos tabulares como archivos planos. El acceso a estas fuentes de datos es proporcionado por controladores JDBC que traducen entre la API JDBC y el mecanismo de comunicación de la base de datos. La figura 3(a) muestra cómo se utiliza típicamente JDBC en una aplicación. Dado que la interfaz JDBC está estandarizada, se puede sustituir un controlador JDBC por otro sin necesidad de de modificar la aplicación. El controlador JDBC se convierte así en el módulo natural para aprovechar la interposición de código. Como se muestra en la Figura 3(b), el controlador JDBC nativo es reemplazado por un controlador JDBC Ganesh que presenta la misma interfaz estandarizada. El controlador Ganesh mantiene una caché en memoria de fragmentos de resultados de consultas anteriores y realiza el reensamblaje de resultados. En la base de datos, agregamos un nuevo proceso llamado el proxy Ganesh. Este proxy, que puede ser compartido por múltiples nodos front-end, consta de dos partes: código para detectar similitud en fragmentos de resultados y el controlador JDBC nativo original que se comunica con la base de datos. El uso de un proxy en la base de datos hace que Ganesh sea independiente de la base de datos y simplifica la creación de prototipos y experimentación. Ganesh es capaz de trabajar con una amplia gama de bases de datos y aplicaciones, sin necesidad de realizar modificaciones en ninguna de ellas. 3.3 Caché basada en proxy El controlador JDBC nativo mostrado en la Figura 3(a) es un componente de código ligero suministrado por el proveedor de la base de datos. Su función principal es mediar la comunicación entre la aplicación y la base de datos remota. Reenvía consultas, almacena resultados completos y responde a solicitudes de la aplicación para ver partes de los resultados. El controlador JDBC de Ganesh mostrado en la Figura 3(b) presenta a la aplicación una interfaz idéntica a la proporcionada por el controlador nativo. Proporciona la capacidad de reconstruir resultados a partir de descripciones compactas basadas en hash enviadas por el proxy. Para realizar esta reconstrucción, el controlador mantiene una caché en memoria de los resultados recibidos recientemente. Esta caché solo se utiliza como fuente de fragmentos de resultados en la reconstrucción de resultados. El conductor Ganesh o el proxy no intentan rastrear las actualizaciones de la base de datos. La falta de consistencia en la caché no afecta a la corrección, ya que la descripción de los resultados siempre se obtiene del proxy; en el peor de los casos, no habrá beneficio de rendimiento al usar Ganesh. Los datos obsoletos simplemente se eliminarán de la caché con el tiempo. El proxy de Ganesh accede a la base de datos a través del controlador JDBC nativo, que permanece sin cambios entre las Figuras 3(a) y (b). La base de datos está completamente ajena a la existencia del proxy. El proxy no examina ninguna consulta recibida del controlador Ganesh, sino que las pasa al controlador nativo. En cambio, el proxy es responsable de inspeccionar la salida de la base de datos recibida del controlador nativo, detectar resultados similares y generar codificaciones basadas en hash de estos resultados siempre que se encuentre suficiente similitud. Si bien esta arquitectura no disminuye la carga en una base de datos, como se mencionó anteriormente en la Sección 2.1, es mucho más fácil replicar bases de datos para escalabilidad en una LAN que en una WAN. Para generar una codificación basada en hash, el proxy debe estar al tanto de qué fragmentos de resultados están disponibles en la caché de controladores de Ganesh. Un enfoque es ser optimista y asumir que todos los fragmentos de resultados están disponibles. Esto resultará en la transmisión inicial más pequeña posible de un resultado. Sin embargo, en casos donde hay poca superposición con resultados anteriores, el controlador Ganesh tendrá que realizar muchas llamadas al proxy durante la reconstrucción para recuperar fragmentos de resultados faltantes. Para evitar esta situación, el proxy sigue de manera flexible el estado de la caché de controladores de Ganesh. Dado que ambos componentes están bajo nuestro control, es relativamente sencillo hacer esto sin recurrir a técnicas de caja gris o comunicación explícita para mantener la coherencia de la caché. En cambio, el proxy simula el algoritmo de gestión de caché de controladores de Ganesh y lo utiliza para mantener una lista de hashes para los cuales es probable que el controlador de Ganesh posea los fragmentos de resultado. En caso de desviación de seguimiento, no habrá pérdida de corrección, pero habrá retrasos adicionales en el viaje de ida y vuelta para recuperar los fragmentos faltantes. Si el cliente detecta la pérdida de sincronización con el proxy, puede pedirle al proxy que restablezca el estado compartido entre ellos. También hay que tener en cuenta que el proxy no necesita guardar los fragmentos de resultado en sí, solo sus hashes. Esto permite que el proxy siga siendo escalable incluso cuando es compartido por muchos nodos front-end. El proxy Ganesh recibe la salida de la base de datos como objetos Java del controlador JDBC nativo. Examina esta salida para ver si está presente un objeto Java del tipo ResultSet. La interfaz JDBC utiliza este tipo de dato para almacenar los resultados de las consultas a la base de datos. Si se encuentra un objeto ResultSet, se reduce como se discute a continuación. Todos los demás objetos de Java se pasan sin modificar. Como se discute en la Sección 3.1, el proxy utiliza los límites de fila definidos en el ResultSet para dividirlo en fragmentos que consisten en filas de resultado individuales. Todos los objetos ResultSet se convierten en objetos de un nuevo tipo llamado RecipeResultSet. Utilizamos el término receta para esta descripción compacta de un resultado de base de datos debido a su similitud con una receta de archivo en el sistema de archivos CASPER [37]. La conversión reemplaza cada fragmento de resultado que probablemente esté presente en la caché de controladores de Ganesh por un hash SHA-1 de ese fragmento. Los fragmentos de resultados previamente no vistos se conservan textualmente. El proxy también retiene los hashes de los nuevos fragmentos de resultados, ya que estarán presentes en la caché de los controladores en el futuro. Ten en cuenta que el proxy solo almacena en caché los hashes de los fragmentos de resultados y no almacena en caché las recetas. El proxy construye un RecipeResultSet verificando la similitud en todo el resultado y luego a nivel de fila. Si se predice que todo el resultado estará presente en la caché de los controladores de Ganesh, el RecipeResultSet será simplemente un único hash de todo el resultado. De lo contrario, contiene hashes para aquellas filas que se predice que están presentes en esa caché; todas las demás filas se conservan textualmente. Si el proxy estima un ahorro de espacio general, transmitirá el RecipeResultSet. De lo contrario, se transmite el ResultSet original. Los objetos RecipeResultSet son transformados de vuelta en objetos ResultSet por el controlador Ganesh. La Figura 4 ilustra el manejo de ResultSet en ambos extremos. Cada hash SHA-1 encontrado en un RecipeResultSet se busca en la caché local de fragmentos de resultados. En caso de acierto, el hash es reemplazado por el fragmento correspondiente. En caso de error, el conductor contacta al proxy de Ganesh para recuperar el fragmento. Todos los fragmentos de resultados previamente no vistos que fueron retenidos textualmente por el proxy se hasheado y se han añadido a la caché de resultados. Debería haber muy pocos fallos si el proxy ha seguido con precisión el estado de la caché de controladores de Ganesh. Una optimización futura sería agrupar la obtención de fragmentos faltantes. Esto sería valioso cuando hay muchos pequeños fragmentos faltantes en una WAN de alta latencia. Una vez que la transformación esté completa, el objeto ResultSet completamente reconstruido se pasa a la aplicación. 4. VALIDACIÓN EXPERIMENTAL Tres preguntas surgen de los objetivos y diseño de Ganesh: • Primero, ¿se puede mejorar significativamente el rendimiento al explotar la similitud entre los resultados de la base de datos? Detalles del conjunto de datos de referencia 500,000 usuarios, 12,000 historias BBOARD 2.0 GB 3,298,000 comentarios SUBASTA 1.3 GB 1,000,000 usuarios, 34,000 elementos Tabla 1: Detalles del conjunto de datos de referencia • En segundo lugar, ¿qué tan importante es la detección de similitud estructural de Ganesh en comparación con la detección de similitud de la huella digital de Rabin? • En tercer lugar, ¿es aceptable la sobrecarga del diseño basado en proxy? Nuestra evaluación responde a estas preguntas a través de experimentos controlados con el prototipo Ganesh. Esta sección describe los puntos de referencia utilizados, nuestro procedimiento de evaluación y la configuración experimental. Los resultados de los experimentos se presentan en las Secciones 5, 6 y 7. 4.1 Puntos de referencia Nuestra evaluación se basa en dos puntos de referencia [18] que han sido ampliamente utilizados por otros investigadores para evaluar varios aspectos de arquitecturas multi-tier [27] y de comercio electrónico [9]. El primer punto de referencia, BBOARD, está modelado según Slashdot, un sitio de noticias orientado a la tecnología. El segundo punto de referencia, AUCTION, está modelado según eBay, un sitio de subastas en línea. En ambos puntos de referencia, la mayoría del contenido se genera dinámicamente a partir de la información almacenada en una base de datos. Los detalles de los conjuntos de datos utilizados se pueden encontrar en la Tabla 1. 4.1.1 El Benchmark BBOARD El benchmark BBOARD, también conocido como RUBBoS [18], modela Slashdot, un popular sitio web orientado a la tecnología. Slashdot recopila enlaces a noticias y otros temas de interés encontrados en otros lugares de la web. El sitio también funciona como un tablón de anuncios al permitir a los usuarios comentar en las historias publicadas en forma de conversación en hilos. No es raro que una historia recopile cientos de comentarios en cuestión de horas. El benchmark BBOARD es similar al sitio y modela las actividades de un usuario, incluyendo operaciones de solo lectura como navegar por las historias del día, explorar categorías de historias y ver comentarios, así como operaciones de escritura como registro de nuevos usuarios, agregar y moderar comentarios, y enviar historias. El benchmark consiste en tres fases diferentes: una fase de calentamiento corta, una fase de ejecución que representa el cuerpo principal de la carga de trabajo, y una fase de enfriamiento corta. En este documento solo informamos sobre los resultados de la fase de ejecución. La fase de calentamiento es importante para establecer el estado del sistema dinámico, pero las mediciones de esa fase no son significativas para nuestra evaluación. La fase de enfriamiento es únicamente para permitir que el punto de referencia se apague. Las fases de calentamiento, ejercicio y enfriamiento son de 2, 15 y 2 minutos respectivamente. El número de clientes simulados fue de 400, 800, 1200 y 1600. El punto de referencia está disponible en una versión de Java Servlets y PHP y tiene diferentes conjuntos de datos; evaluamos a Ganesh utilizando la versión de Java Servlets y el conjunto de datos Expandido. El benchmark BBOARD define dos cargas de trabajo diferentes. El primero, la mezcla de Autoría, consiste en un 70% de operaciones de solo lectura y un 30% de operaciones de lectura y escritura. El segundo, la mezcla de navegación, contiene solo operaciones de solo lectura y no actualiza la base de datos. 4.1.2 El Benchmark de SUBASTA El benchmark de SUBASTA, también conocido como RUBiS [18], modela eBay, el sitio de subastas en línea. El sitio web de eBay se utiliza para comprar y vender artículos a través de un formato de subasta. Las principales actividades de un usuario incluyen navegar, vender o pujar por artículos. Modelando las actividades en este sitio, este punto de referencia incluye actividades de solo lectura como navegar por artículos por categoría y por región, así como actividades de lectura-escritura como pujar por artículos, comprar y vender artículos, y dejar comentarios. Al igual que con BBOARD, el benchmark consiste en tres fases diferentes. Las fases de calentamiento, ejecución y enfriamiento para este experimento son de 1.5, 15 y 1 minutos respectivamente. Probamos Ganesh con cuatro configuraciones de clientes donde el número de clientes de prueba se estableció en 400, 800, 1200 y 1600. El punto de referencia está disponible en una versión de Enterprise Java Bean (EJB), Java Servlets y PHP y tiene diferentes conjuntos de datos; evaluamos Ganesh con la versión de Java Servlets y el conjunto de datos Expandido. El benchmark de SUBASTA define dos cargas de trabajo diferentes. El primero, la mezcla de Ofertas, consiste en un 70% de operaciones de solo lectura y un 30% de operaciones de lectura-escritura. El segundo, la mezcla de navegación, contiene solo operaciones de solo lectura y no actualiza la base de datos. 4.2 Procedimiento Experimental Ambos benchmarks involucran una carga de trabajo sintética de clientes accediendo a un servidor web. El número de clientes emulados es un parámetro experimental. Cada cliente emulado ejecuta una instancia del benchmark en su propio hilo, utilizando una matriz para hacer la transición entre diferentes estados del benchmark. La matriz define un modelo estocástico con probabilidades de transición entre los diferentes estados que representan las acciones típicas de los usuarios. Un ejemplo de transición es un usuario iniciando sesión en el sistema de SUBASTA y luego decidiendo si publicar un artículo en venta o pujar en subastas activas. Cada cliente también modela el tiempo de pensamiento del usuario entre las solicitudes. El tiempo de pensamiento se modela como una distribución exponencial con una media de 7 segundos. Evaluamos a Ganesh a lo largo de dos ejes: número de clientes y ancho de banda de la WAN. Las cargas más altas son especialmente útiles para comprender el rendimiento de Ganesh cuando la CPU o el disco del servidor de base de datos o del proxy son el factor limitante. Un estudio previo ha demostrado que aproximadamente el 50% de los cuellos de botella de Internet de gran área observados tenían un ancho de banda disponible inferior a 10 Mb/s [1]. Basándonos en este trabajo, enfocamos nuestra evaluación en el ancho de banda de la WAN de 5 Mb/s con una latencia de ida y vuelta de 66 ms, representativa de rutas de red severamente restringidas, y 20 Mb/s con una latencia de ida y vuelta de 33 ms, representativa de una ruta de red moderadamente restringida. También informamos sobre el rendimiento de Ganesh a 100 Mb/s sin agregar latencia de ida y vuelta. Este ancho de banda, representativo de una red sin restricciones, es especialmente útil para revelar cualquier sobrecarga potencial de Ganesh en situaciones donde el ancho de banda de la WAN no es el factor limitante. Para cada combinación de número de clientes y ancho de banda de WAN, medimos los resultados de las dos configuraciones enumeradas a continuación: • Nativa: Esta configuración corresponde a la Figura 3(a). El nativo evita la sobrecarga de Ganesh al usar un proxy y realizar la serialización de objetos Java. • Ganesh: Esta configuración corresponde a la Figura 3(b). Para un número dado de clientes y ancho de banda de WAN, comparar estos resultados con los resultados nativos correspondientes proporciona el beneficio de rendimiento debido al sistema de middleware Ganesh. La métrica utilizada para cuantificar la mejora en el rendimiento es el número de solicitudes de clientes que pueden ser atendidas por segundo. La métrica utilizada para cuantificar el rendimiento de Ganesh es el tiempo promedio de respuesta para una solicitud de cliente. Para todos los experimentos, el controlador Ganesh utilizado por el servidor de aplicaciones usó un tamaño de caché de 100,000 elementos. El proxy fue efectivo en rastrear el estado de la caché de los controladores Ganesh; para todos nuestros experimentos, la tasa de fallos en el controlador nunca superó el 0.7%. 4.3 Configuración Experimental La configuración experimental utilizada para las pruebas se puede ver en la Figura 5. Todas las máquinas eran Pentium 4 de 3.2 GHz (con HyperThreading habilitado). Con la excepción del servidor de base de datos, todas las máquinas tenían 2 GB de SDRAM y ejecutaban la distribución de Linux Fedora Core. El servidor de la base de datos tenía 4 GB de SDRAM. Utilizamos Apache Tomcat como tanto el servidor de aplicaciones que alojaba los Servlets de Java como el servidor web. Ambos benchmarks utilizaron Java Servlets para generar el contenido dinámico. El servidor de la base de datos utilizó la base de datos de código abierto MySQL. Para los controladores JDBC nativos, utilizamos los controladores Connector/J proporcionados por MySQL. El servidor de aplicaciones utilizaba la Máquina Virtual de Java de Sun como entorno de ejecución para los Servlets de Java. La herramienta sysstat se utilizó para monitorear la utilización de la CPU, red, disco y memoria en todas las máquinas. Las máquinas estaban conectadas por una red Ethernet gigabit conmutada. Como se muestra en la Figura 5, el servidor web y de aplicación de front-end fue separado del servidor de proxy y base de datos por un enrutador NetEm [16]. Este enrutador nos permitió controlar la configuración de ancho de banda y latencia en la red. El enrutador NetEm es un PC estándar con dos tarjetas de red que ejecuta el software de Control de Tráfico de Linux y Emulación de Red. Las restricciones de ancho de banda y latencia solo se aplicaron al enlace entre el servidor de aplicaciones y la base de datos para el caso nativo y entre el servidor de aplicaciones y el proxy para el caso de Ganesh. No hay comunicación entre el servidor de aplicaciones y la base de datos con Ganesh, ya que todos los datos fluyen a través del proxy. Como nuestro enfoque estaba en el enlace WAN entre el servidor de aplicaciones y la base de datos, no hubo restricciones en el enlace entre los clientes de prueba simulados y el servidor web. 5. DESEMPEÑO Y TIEMPO DE RESPUESTA En esta sección, abordamos la primera pregunta planteada en la Sección 4: ¿Se puede mejorar significativamente el rendimiento explotando la similitud entre los resultados de la base de datos? Para responder a esta pregunta, utilizamos los resultados de los benchmarks BBOARD y AUCTION. Utilizamos dos métricas para cuantificar la mejora en el rendimiento obtenible a través del uso de Ganesh: el throughput, desde la perspectiva del servidor web, y el tiempo de respuesta promedio, desde la perspectiva del cliente. El rendimiento se mide en términos del número de solicitudes de clientes que pueden ser atendidas por segundo. Los resultados y análisis de BBOARD 5.1 Figuras 6 (a) y (b) presentan el número promedio de solicitudes atendidas por segundo y el tiempo de respuesta promedio para estas solicitudes tal como lo perciben los clientes para la Mezcla de Autoría de BBOARD. Como muestra la Figura 6 (a), Native satura fácilmente el enlace de 5 Mb/s. Con 400 clientes, la solución nativa entrega 29 solicitudes/segundo con un tiempo de respuesta promedio de 8.3 segundos. La capacidad de procesamiento de los clientes disminuye con un aumento en los clientes de prueba, ya que los clientes se agotan debido a la congestión en el servidor de aplicaciones. Los estudios de usabilidad han demostrado que los tiempos de respuesta superiores a 10 segundos hacen que el usuario pase a 1. Dado que Java carece de un operador sizeof(), los cachés de Java limitan su tamaño en función del número de objetos. El tamaño de los volcados de caché tomados al final de los experimentos nunca superó los 212 MB. WWW 2007 / Pista: Rendimiento y Escalabilidad Sesión: Sistemas Escalables para Contenido Dinámico 315 0 50 100 150 200 250 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Solicitudes de Clientes de Prueba por Segundo Nativo Ganesh 0.001 0.01 0.1 1 10 100 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Tiempo Promedio de Respuesta de Clientes de Prueba Nativo Ganesh Nota Escala Logarítmica (a) Rendimiento: Mezcla de Autoría (b) Tiempo de Respuesta: Mezcla de Autoría 0 50 100 150 200 250 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Solicitudes de Clientes de Prueba por Segundo Nativo Ganesh 0.001 0.01 0.1 1 10 100 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Tiempo Promedio de Respuesta de Clientes de Prueba Nativo Ganesh Nota Escala Logarítmica (c) Rendimiento: Mezcla de Navegación (d) Tiempo de Respuesta: Mezcla de Navegación Promedio de tres pruebas. La desviación estándar máxima para el rendimiento y el tiempo de respuesta fue del 9.8% y 11.9% de la media correspondiente. Figura 6: BBOARD Benchmark - Rendimiento y Tiempo de Respuesta Promedio de otras tareas [24]. Basándose en estos números, aumentar el número de clientes de prueba hace que el sistema Nativo sea inutilizable. Ganesh a 5 Mb/s, sin embargo, ofrece una mejora doble con 400 clientes de prueba y una mejora quintuple con 1200 clientes. El rendimiento de Ganesh disminuye ligeramente a 1200 y 1600 clientes debido a que la red está saturada. En comparación con Native, la Figura 6 (b) muestra que los tiempos de respuesta de Ganesh son considerablemente más bajos con tiempos de respuesta de menos de un segundo con 400 clientes. La Figura 6 (a) también muestra que para 400 y 800 clientes de prueba, Ganesh a 5 Mb/s tiene el mismo rendimiento y tiempo de respuesta promedio que Native a 20 Mb/s. Solo con 1200 y 1600 clientes, Native a 20 Mb/s ofrece un rendimiento mayor que Ganesh a 5 Mb/s. Al comparar tanto a Ganesh como a Native a 20 Mb/s, vemos que Ganesh ya no está limitado por el ancho de banda y ofrece hasta una mejora del doble sobre Native con 1600 clientes de prueba. Como Ganesh no satura la red con configuraciones de cliente de prueba más altas, con 1600 clientes de prueba, su tiempo de respuesta promedio es de 0.1 segundos en lugar de los 7.7 segundos de Natives. Como era de esperar, no hay ganancias visibles de Ganesh en el ancho de banda más alto de 100 Mb/s donde la red ya no es el cuello de botella. Sin embargo, Ganesh sigue monitoreando a Native en cuanto a rendimiento. Las Figuras 6 (c) y (d) presentan el número promedio de solicitudes atendidas por segundo y el tiempo de respuesta promedio para estas solicitudes tal como lo perciben los clientes para la Mezcla de Navegación de BBOARDs. Independientemente de la configuración del cliente de prueba, la Figura 6 (c) muestra que el rendimiento de los Nativos a 5 Mb/s está limitado a 10 reqs/seg. Ganesh a 5 Mb/s con 400 clientes de prueba, ofrece un aumento de más de seis veces en el rendimiento. La mejora aumenta a más de once veces a 800 clientes de prueba antes de que Ganesh sature la red. Además, la Figura 6 (d) muestra que el tiempo de respuesta promedio de los Nativos de 35 segundos con 400 clientes de prueba hace que el sistema sea inutilizable. Estos altos tiempos de respuesta aumentan aún más con la adición de clientes de prueba. Incluso con la configuración del cliente de prueba de 1600, Ganesh ofrece un tiempo de respuesta promedio aceptable de 8.2 segundos. Debido a la naturaleza intensiva en datos de la mezcla de navegación, Ganesh a 5 Mb/s sorprendentemente tiene un rendimiento mucho mejor que Native a 20 Mb/s. Además, como se muestra en la Figura 6 (d), si bien el tiempo de respuesta promedio para Native a 20 Mb/s es aceptable con 400 clientes de prueba, resulta inutilizable con 800 clientes de prueba, con un tiempo de respuesta promedio de 15.8 segundos. Al igual que en el caso de 5 Mb/s, este tiempo de respuesta aumenta con la adición de clientes de prueba adicionales. Ganesh a 20 Mb/s y tanto Native como Ganesh a 100 Mb/s no tienen limitaciones de ancho de banda. Sin embargo, el rendimiento se estanca después de 1200 clientes de prueba debido a que la CPU de la base de datos está saturada. 5.1.3 Variante de filtro Nos sorprendió el rendimiento nativo del benchmark BBOARD. A una velocidad de banda ancha de 5 Mb/s, el rendimiento nativo fue más bajo de lo que esperábamos. Resultó que el código de referencia que muestra historias leía todos los comentarios asociados con la historia en particular de la base de datos y solo entonces realizaba un postprocesamiento para seleccionar los comentarios que se mostrarían. Si bien este es exactamente el comportamiento de SlashCode, la base de código detrás del sitio web de Slashdot, decidimos modificar la prueba de rendimiento para realizar cierto prefiltrado en la base de datos. Este benchmark modificado, llamado el Filtro de Variantes, modela a un desarrollador que aplica optimizaciones a nivel de SQL para transferir menos datos. En aras de la brevedad, solo resumimos brevemente los resultados de la mezcla de autores. Para la mezcla de Autoría, con 800 clientes de prueba a 5 Mb/s, la Figura 7 (a) muestra que el rendimiento de Natives aumenta un 85% en comparación con el punto de referencia original, mientras que la mejora de Ganesh es menor, del 15%. El rendimiento de los servidores disminuye por encima de los 800 clientes, ya que los clientes de prueba se agotan debido a los altos tiempos de respuesta. La ganancia más significativa para Native se observa a 20 Mb/s. En 1600 clientes de prueba, en comparación con el punto de referencia original, Native experimenta una mejora del 73% en el rendimiento y una reducción del 77% en el tiempo de respuesta promedio. Mientras WWW 2007 / Pista: Rendimiento y Escalabilidad Sesión: Sistemas Escalables para Contenido Dinámico 316 0 50 100 150 200 250 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Clientes de Prueba Solicitudes/seg Nativo Ganesh 0.001 0.01 0.1 1 10 100 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Clientes de Prueba Tiempo de Resp. Promedio (seg) Nativo Ganesh Nota Escala Logarítmica (a) Rendimiento: Mezcla de Autoría (b) Tiempo de Respuesta: Mezcla de Autoría Promedio de tres pruebas. La desviación estándar máxima para el rendimiento y el tiempo de respuesta fue del 7.2% y del 11.5% de la media correspondiente. Figura 7: BBOARD Benchmark - Variante de filtro - Rendimiento y Tiempo de Respuesta Promedio Ganesh no observa ninguna mejora en comparación con el original, aún procesa un 19% más de solicitudes/seg que Native. Por lo tanto, aunque las optimizaciones fueron más útiles para Native, Ganesh todavía ofrece una mejora en el rendimiento. 5.2 Resultados y Análisis de la SUBASTA 5.2.1 Figuras de la Mezcla de Ofertas Los gráficos 8 (a) y (b) presentan el número promedio de solicitudes atendidas por segundo y el tiempo de respuesta promedio para estas solicitudes tal como son percibidas por los clientes para la Mezcla de Ofertas de las SUBASTAS. Como se mencionó anteriormente, la mezcla de ofertas consiste en una combinación de operaciones de lectura y escritura. El benchmark AUCTION no es tan intensivo en datos como BBOARD. Por lo tanto, la mayoría de las ganancias se observan en el ancho de banda más bajo de 5 Mb/s. La figura 8 (a) muestra que el aumento en el rendimiento debido a Ganesh varía desde un 8% con 400 clientes de prueba hasta un 18% con 1600 clientes de prueba. Como se observa en la Figura 8 (b), los tiempos de respuesta promedio para Ganesh son significativamente más bajos que los de Native, con una disminución del 84% a 800 clientes de prueba y del 88% a 1600 clientes de prueba. La Figura 8 (a) también muestra que con un aumento cuádruple del ancho de banda de 5 Mb/s a 20 Mb/s, Native ya no está limitado por el ancho de banda y no hay diferencia de rendimiento entre Ganesh y Native. Con las configuraciones de cliente de prueba más altas, observamos que el ancho de banda utilizado por Ganesh era menor que el de Nativo. Ganesh podría seguir siendo útil en estos escenarios no restringidos si se compra ancho de banda de forma medible. Se observan resultados similares para el escenario de 100 Mb/s. 5.2.2 Mezcla de Navegación Para la Mezcla de Navegación de SUBASTAS, las Figuras 8 (c) y (d) presentan el número promedio de solicitudes atendidas por segundo y el tiempo promedio de respuesta para estas solicitudes tal como lo perciben los clientes. Una vez más, la mayoría de las ganancias se observan en anchos de banda más bajos. A 5 Mb/s, Native y Ganesh ofrecen un rendimiento y tiempos de respuesta similares con 400 clientes de prueba. Mientras que el rendimiento para ambos permanece igual en 800 clientes de prueba, la Figura 8 (d) muestra que el tiempo de respuesta promedio de Ganesh es un 62% menor que el de Native. El servidor satura el enlace con 800 clientes y agregar clientes de prueba adicionales solo aumenta el tiempo promedio de respuesta. Ganesh, independientemente de la configuración del cliente de prueba, no tiene restricciones de ancho de banda y mantiene el mismo tiempo de respuesta. A 1600 clientes de prueba, la Figura 8 (c) muestra que el rendimiento de Ganesh es casi el doble que el de Nativo. En los anchos de banda más altos de 20 y 100 Mb/s, ni Ganesh ni Native tienen limitaciones de ancho de banda y ofrecen un rendimiento y tiempos de respuesta equivalentes. Referencia original. Tamaño Ganesh Tamaño Rabin Tamaño SelectSort1 223.6 MB 5.4 MB 219.3 MB SelectSort2 223.6 MB 5.4 MB 223.6 MB Tabla 2: Microbenchmarks de similitud 6. SIMILITUD ESTRUCTURAL VS. SIMILITUD DE RABIN En esta sección, abordamos la segunda pregunta planteada en la Sección 4: ¿Qué tan importante es la detección de similitud estructural de Ganesh en comparación con la detección de similitud basada en la huella digital de Rabin? Para responder a esta pregunta, utilizamos microbenchmarks y los benchmarks BBOARD y AUCTION. Dado que Ganesh siempre tuvo un mejor rendimiento que Rabin en la huella dactilar, aquí presentamos solo un subconjunto de los resultados en aras de la brevedad. 6.1 Microbenchmarks Dos microbenchmarks muestran un ejemplo de los efectos de la reordenación de datos en el algoritmo de huella dactilar de Rabin. En el primer microbenchmark, SelectSort1, una consulta con un orden de clasificación especificado selecciona 223.6 MB de datos distribuidos en aproximadamente 280 K filas. La consulta se repite entonces con un atributo de ordenación diferente. Si bien se devuelve el mismo número de filas y los mismos datos, el orden de las filas es diferente. En un escenario así, se esperaría detectar una gran cantidad de similitud entre ambos resultados. Como muestra la Tabla 2, el algoritmo basado en filas de Ganesh logra una reducción del 97.6%, mientras que el algoritmo de huella digital de Rabin, con el parámetro de tamaño de fragmento promedio establecido en 4 KB, solo logra una reducción del 1%. La razón, como se muestra anteriormente en la Figura 2, es que con la huella digital de Rabin, los tramos de datos entre dos límites consecutivos suelen cruzar los límites de fila. Con el cambio en el orden de las filas en el segundo resultado y los fingerprints de Rabin ahora abarcando diferentes filas, el algoritmo no puede detectar similitud significativa. La pequeña ganancia observada se debe principalmente a aquellas filas individuales que son lo suficientemente grandes como para dividirse en múltiples fragmentos. SelectSort2, otro micro-benchmark ejecutó las mismas consultas pero aumentó el tamaño mínimo del fragmento del algoritmo de huella digital de Rabin. Como se puede ver en la Tabla 2, incluso la pequeña ganancia del microbenchmark anterior desaparece cuando el tamaño mínimo de fragmento fue mayor que el tamaño promedio de fila. Si bien se pueden abordar parcialmente estos problemas variando dinámicamente los parámetros del algoritmo de huella digital de Rabin, esto puede resultar computacionalmente costoso, especialmente en presencia de cargas de trabajo cambiantes. 6.2 Benchmarks de Aplicación Ejecutamos el benchmark BBOARD descrito en la Sección 4.1.1 en dos versiones de Ganesh: la primera con la huella digital de Rabin utilizada como WWW 2007 / Track: Sesión de Rendimiento y Escalabilidad: Sistemas Escalables para Contenido Dinámico 317 0 50 100 150 200 250 300 350 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Clientes de Prueba Solicitudes/seg Ganesh Nativo 0.001 0.01 0.1 1 10 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Clientes de Prueba Tiempo de Respuesta Promedio (seg) Ganesh Nativo Nota Escala Logarítmica (a) Rendimiento: Mezcla de Ofertas (b) Tiempo de Respuesta: Mezcla de Ofertas 0 50 100 150 200 250 300 350 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Clientes de Prueba Solicitudes/seg Ganesh Nativo 0.001 0.01 0.1 1 10 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Clientes de Prueba Tiempo de Respuesta Promedio (seg) Ganesh Nativo Nota Escala Logarítmica (c) Rendimiento: Mezcla de Navegación (d) Tiempo de Respuesta: Mezcla de Navegación Promedio de tres pruebas. La desviación estándar máxima para el rendimiento y el tiempo de respuesta fue del 2.2% y del 11.8% de la media correspondiente. Figura 8: Referencia de la subasta AUCTION - Rendimiento y Tiempo de Respuesta Promedio del algoritmo de fragmentación y el segundo con el algoritmo basado en filas de Ganesh. Los resultados de Rabins para la Mezcla de Navegación se normalizan con los resultados de Ganesh y se presentan en la Figura 9. Como muestra la Figura 9 (a), a 5 Mb/s, independientemente de la configuración del cliente de prueba, Rabin tiene un rendimiento significativamente inferior a Ganesh. Esto sucede debido a una combinación de dos razones. Primero, como se describe en la Sección 3.1, Rabin encuentra menos similitud ya que no explota la información estructural de los resultados. Segundo, este punto de referencia contenía algunas consultas que generaron resultados grandes. En este caso, Rabin, con un tamaño de fragmento promedio pequeño, generó una gran cantidad de objetos que desplazaron otros datos útiles de la caché. Por el contrario, Ganesh pudo detectar estas filas grandes y aumentar correspondientemente el tamaño de los bloques. Esto fue confirmado ya que las estadísticas de caché mostraron que la proporción de aciertos de Ganesh era aproximadamente tres veces mayor que la de Rabin. Las mediciones de rendimiento a 20 Mb/s fueron similares, con la excepción del rendimiento de Rabins con 400 clientes de prueba. En este caso, Ganesh no estaba limitado por la red y, de hecho, el rendimiento era el mismo que el de 400 clientes a 5 Mb/s. Rabin, sin embargo, aprovechó el aumento del ancho de banda de 5 a 20 Mb/s para ofrecer un rendimiento ligeramente mejor. A 100 Mb/s, el rendimiento de Rabin era casi similar al de Ganesh ya que el ancho de banda ya no era un cuello de botella. El tiempo de respuesta normalizado, presentado en la Figura 9 (b), muestra tendencias similares. A 5 y 20 Mb/s, la adición de clientes de prueba disminuye el tiempo de respuesta normalizado, ya que el tiempo de respuesta promedio de Ganesh aumenta más rápido que el de Rabin. Sin embargo, en ningún momento Rabin supera a Ganesh. Ten en cuenta que con 400 y 800 clientes a 100 Mb/s, Rabin tiene un mayor sobrecosto incluso cuando no está limitado por el ancho de banda. Como se menciona en la Sección 3.1, esto se debe a que Rabin tiene que hashear cada ResultSet dos veces. La sobrecarga desaparece con 1200 y 1600 clientes, ya que la CPU de la base de datos está saturada y limita el rendimiento tanto de Ganesh como de Rabin. 7. SUPERPOSICIÓN DE PROXY En esta sección, abordamos la tercera pregunta planteada en la Sección 4: ¿Es aceptable la superposición del diseño basado en proxy de Ganesh? Para responder a esta pregunta, nos concentramos en su rendimiento en las bandas de mayor ancho de banda. Nuestra evaluación en la Sección 5 mostró que Ganesh, en comparación con Native, puede ofrecer una mejora sustancial en el rendimiento a anchos de banda más bajos. Solo en anchos de banda más altos serían visibles los costos adicionales de latencia, medidos por el tiempo promedio de respuesta para una solicitud de cliente, y de rendimiento, medidos por la cantidad de solicitudes de cliente que pueden ser atendidas por segundo. Al observar la combinación de autoría del benchmark original de BBOARD, no se aprecian ganancias visibles de Ganesh a 100 Mb/s. Sin embargo, Ganesh sigue rastreando a Native en cuanto a rendimiento. Si bien el tiempo promedio de respuesta es mayor para Ganesh, la diferencia absoluta está entre 0.01 y 0.04 segundos y sería imperceptible para el usuario final. La mezcla de navegación muestra una diferencia aún menor en los tiempos de respuesta promedio. Los resultados de la variante del filtro de los benchmarks de BBOARD son similares. Incluso para el benchmark de SUBASTA, la diferencia entre el tiempo de respuesta de Nativo y Ganesh a 100 Mb/s nunca fue mayor a 0.02 segundos. La única excepción a los resultados anteriores se observó en la variante de filtro del benchmark BBOARD, donde Ganesh con 1600 clientes de prueba añadió 0.85 segundos al tiempo de respuesta promedio. Por lo tanto, incluso para redes mucho más rápidas donde el enlace WAN no es el cuello de botella, Ganesh siempre ofrece un rendimiento equivalente al Nativo. Si bien se agrega algo de latencia adicional debido al diseño basado en proxy, generalmente es imperceptible. TRABAJO RELACIONADO Hasta donde sabemos, Ganesh es el primer sistema que combina el uso de técnicas basadas en hash con el almacenamiento en caché de resultados de base de datos para mejorar el rendimiento y los tiempos de respuesta de aplicaciones con contenido dinámico. También creemos que es el primer sistema en demostrar los beneficios de utilizar información estructural para WWW 2007 / Track: Rendimiento y Escalabilidad Sesión: Sistemas Escalables para Contenido Dinámico 318 0.0 0.2 0.4 0.6 0.8 1.0 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Clientes de Prueba Rendimiento Normalizado 31.8 3.8 2.8 2.3 23.8 32.8 5.8 3.6 1.8 2.1 1.1 1.0 0 5 10 15 20 25 30 35 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Clientes de Prueba Tiempo de Respuesta Normalizado (a) Rendimiento Normalizado: Mayor es mejor (b) Tiempo de Respuesta Normalizado: Mayor es peor Para el rendimiento, un resultado normalizado mayor que 1 implica que Rabin es mejor. Para el tiempo de respuesta, un resultado normalizado mayor que 1 implica que Ganesh es mejor. Media de tres pruebas. La desviación estándar máxima para el rendimiento y el tiempo de respuesta fue del 9.1% y del 13.9% de la media correspondiente. Figura 9: Comparación normalizada de Ganesh vs. Rabin - Mezcla de navegación BBOARD detectando similitud. En esta sección, primero discutimos enfoques alternativos para almacenar en caché contenido dinámico y luego examinamos otros usos de primitivas basadas en hash en sistemas distribuidos. 8.1 Almacenamiento en Caché de Contenido Dinámico En la capa de base de datos, varios sistemas han abogado por la caché de nivel intermedio donde partes de la base de datos se replican en el borde o servidor [3, 4, 20]. Estos sistemas almacenan en caché tablas completas en lo que es esencialmente una base de datos replicada o utilizan vistas materializadas de respuestas de consultas anteriores [19]. Requieren una integración estrecha con la base de datos del sistema para garantizar un límite de tiempo en la propagación de actualizaciones. Estos sistemas suelen estar dirigidos a cargas de trabajo que no requieren una consistencia estricta y pueden tolerar datos obsoletos. Además, a diferencia de Ganesh, algunas de estas soluciones de almacenamiento en caché de nivel medio [2, 3], sufren de la complejidad de tener que participar en la planificación de consultas y el procesamiento de consultas distribuidas. Gao et al. [15] proponen utilizar una arquitectura de replicación de objetos distribuidos donde los requisitos de consistencia de las tiendas de datos se adaptan según la aplicación. Estas soluciones requieren recursos sustanciales de desarrollo y un entendimiento detallado de la aplicación que se está modificando. Si bien existen sistemas que intentan automatizar la partición y replicación de la base de datos de una aplicación [34], no proporcionan semántica de transacciones completa. En comparación, Ganesh no debilita ninguna de las semánticas proporcionadas por la base de datos subyacente. El trabajo reciente en la evaluación de opciones de almacenamiento en caché de borde para sitios web dinámicos [38] ha sugerido que, sin una planificación cuidadosa, el empleo de estrategias complejas de descarga puede perjudicar el rendimiento. En cambio, el trabajo aboga por una arquitectura en la que todos los niveles, excepto la base de datos, deberían ser trasladados al borde. Nuestra evaluación de Ganesh ha demostrado que sería beneficioso para estos escenarios. Para mejorar la escalabilidad de la base de datos, C-JDBC [10], SSS [22] y Ganymed [28] también abogan por el uso de una arquitectura basada en interposición para clusterizar y replicar bases de datos de forma transparente a nivel de middleware. Los enfoques de estas arquitecturas y Ganesh son complementarios y se beneficiarían mutuamente. Avanzando hacia la capa de presentación, se ha producido una amplia adopción de la caché basada en fragmentos [14], la cual mejora la utilización de la caché al almacenar por separado diferentes partes de las páginas web generadas. Si bien el almacenamiento en caché basado en fragmentos funciona en el borde, una propuesta reciente ha propuesto trasladar el ensamblaje de páginas web a los clientes para optimizar la entrega de contenido [31]. Si bien Ganesh no se utiliza en la capa de presentación, los mismos principios se han aplicado en la Detección de Transferencias Duplicadas [25] para aumentar la eficiencia de la caché web, así como para el acceso web a través de enlaces con ancho de banda limitado [33]. 8.2 Sistemas basados en hash En los últimos años han surgido muchos sistemas que explotan técnicas basadas en hash. En el centro de todos estos sistemas se encuentra la idea de detectar similitudes en los datos sin necesidad de interpretar esos datos. Esta idea simple pero elegante se basa en el hash criptográfico, como se discutió anteriormente en la Sección 2. Las aplicaciones exitosas de esta idea abarcan una amplia gama de sistemas de almacenamiento. Los ejemplos incluyen la copia de seguridad entre pares de archivos informáticos personales [11], el archivado eficiente de datos [29] y la búsqueda de archivos similares [21]. Spring y Wetherall [35] aplican principios similares a nivel de red. Utilizando cachés sincronizadas en ambos extremos de un enlace de red, los datos duplicados son reemplazados por tokens más pequeños para su transmisión y luego restaurados en el extremo remoto. Este y otros sistemas basados en hash como los sistemas de archivos CASPER [37] y LBFS [26], y optimizadores de ancho de banda de Capa-2 como Riverbed y Peribit utilizan la huella digital de Rabin [30] para descubrir tramos de similitud en los datos. Este enfoque es especialmente útil cuando los elementos de datos son modificados en su lugar a través de inserciones, eliminaciones y actualizaciones. Sin embargo, como se muestra en la Sección 6, el rendimiento de esta técnica puede experimentar una caída dramática en presencia de reordenamiento de datos. Ganesh en cambio utiliza los límites de fila como divisores para detectar similitudes. El uso más agresivo de técnicas basadas en hash es por sistemas que utilizan hashes como identificadores principales para objetos en almacenamiento persistente. Los sistemas de almacenamiento como CFS [12] y PAST [13] que han sido construidos utilizando tablas hash distribuidas entran en esta categoría. Single Instance Storage [6] y Venti [29] son otros ejemplos de tales sistemas. Como se discute en la Sección 2.2, el uso de hashes criptográficos para abordar datos persistentes representa un nivel más profundo de confianza en su resistencia a colisiones que la asumida por Ganesh. Si el tiempo revela deficiencias en el algoritmo hash, el esfuerzo necesario para corregir la falla es mucho mayor. En Ganesh, simplemente se trata de reemplazar el algoritmo hash. 9. CONCLUSIÓN El creciente uso de contenido web dinámico generado a partir de bases de datos relacionales aumenta las demandas de ancho de banda de la WAN. Las soluciones de almacenamiento en caché tradicionales para reducir el ancho de banda y la latencia suelen ser ineficaces para este tipo de contenido. Este documento muestra que el impacto de los accesos a bases de datos a través de WAN puede reducirse sustancialmente mediante la arquitectura Ganesh sin comprometer la estricta semántica de consistencia de las bases de datos. La esencia de la arquitectura Ganesh es el uso de la computación en los bordes para reducir la comunicación a través de Internet. Ganesh es capaz de utilizar hashes criptográficos para detectar similitud con resultados anteriores y enviar recetas compactas de resultados en lugar de resultados completos en la sesión de Sistemas Escalables para Contenido Dinámico 319 de WWW 2007 / Track: Rendimiento y Escalabilidad. Nuestro diseño utiliza la interposición para lograr una transparencia completa: los clientes, los servidores de aplicaciones y los servidores de bases de datos no son conscientes de la presencia de Ganesh y no requieren ninguna modificación. Nuestra evaluación experimental confirma que Ganesh, aunque conceptualmente simple, puede ser altamente efectivo en mejorar el rendimiento y el tiempo de respuesta. Nuestros resultados también confirman que aprovechar la estructura presente en los resultados de la base de datos para detectar similitudes es crucial para esta mejora en el rendimiento. REFERENCIAS [1] AKELLA, A., SESHAN, S., Y SHAIKH, A. Una evaluación empírica de los cuellos de botella en Internet de área amplia. En Proc. 3ª Conferencia ACM SIGCOMM sobre Medición de Internet (Miami Beach, FL, EE. UU., Oct. 2003), pp. 101-114. [2] ALTINEL, M., BORNH ¨OVD, C., KRISHNAMURTHY, S., MOHAN, C., PIRAHESH, H., Y REINWALD, B. Tablas de caché: allanando el camino para una caché de base de datos adaptativa. En Proc. del 29º VLDB (Berlín, Alemania, 2003), pp. 718-729. [3] ALTINEL, M., LUO, Q., KRISHNAMURTHY, S., MOHAN, C., PIRAHESH, H., LINDSAY, B. G., WOO, H., Y BROWN, L. Dbcache: Caché de base de datos para servidores de aplicaciones web. En Proc. 2002 ACM SIGMOD (2002), pp. 612-612. [4] AMIRI, K., PARK, S., TEWARI, R., Y PADMANABHAN, S. Dbproxy: una caché de datos dinámica para aplicaciones web. En Proc. Conferencia Internacional de Ingeniería de Datos de IEEE (ICDE) (Mar. 2003). [5] BLACK, J. Compare-by-hash: Un análisis razonado. En Proc. Conferencia Técnica Anual USENIX 2006 (Boston, MA, mayo de 2006), pp. 85-90. [6] BOLOSKY, W. J., CORBIN, S., GOEBEL, D., y DOUCEUR, J. R. Almacenamiento de instancia única en Windows 2000. En Proc. 4to Simposio de Sistemas Windows de USENIX (Seattle, WA, ago. 2000), pp. 13-24. [7] BREWER, E. A. Lecciones de servicios a gran escala. IEEE Internet Computing 5, 4 (2001), 46-55. [8] BRODER, A., GLASSMAN, S., MANASSE, M., AND ZWEIG, G. Agrupamiento sintáctico de la web. En Proc. 6ta Conferencia Internacional WWW (1997). [9] CECCHET, E., CHANDA, A., ELNIKETY, S., MARGUERITE, J., Y ZWAENEPOEL, W. Comparación de rendimiento de arquitecturas de middleware para generar contenido web dinámico. En Proc. Cuarta Conferencia Internacional de Middleware ACM/IFIP/USENIX (Río de Janeiro, Brasil, junio de 2003). [10] CECCHET, E., MARGUERITE, J., Y ZWAENEPOEL, W. C-JDBC: Middleware flexible de agrupación de bases de datos. En Proc. Conferencia Técnica Anual USENIX 2004 (Boston, MA, junio de 2004). [11] COX, L. P., MURRAY, C. D., Y NOBLE, B. D. Pastiche: Haciendo que la copia de seguridad sea barata y fácil. En OSDI: Simposio sobre Diseño e Implementación de Sistemas Operativos (2002). [12] DABEK, F., KAASHOEK, M. F., KARGER, D., MORRIS, R., Y STOICA, I. Almacenamiento cooperativo de amplia área con CFS. En el 18º Simposio ACM sobre Principios de Sistemas Operativos (Banff, Canadá, octubre de 2001). [13] DRUSCHEL, P., Y ROWSTRON, A. PASADO: Una utilidad de almacenamiento entre pares a gran escala y persistente. En HotOS VIII (Schloss Elmau, Alemania, mayo de 2001), pp. 75-80. [14] Incluye el lado del borde. http://www.esi.org. [15] GAO, L., DAHLIN, M., NAYATE, A., ZHENG, J., Y IYENGAR, A. Replicación de datos específica de la aplicación para servicios en el borde. En WWW 03: Proc. Duodécima Conferencia Internacional sobre la World Wide Web (2003), pp. 449-460. [16] HEMMINGER, S. Netem - emulando redes reales en el laboratorio. En Proc. 2005 Linux Conference Australia (Canberra, Australia, Abr. 2005). [17] HENSON, V. Un análisis de compare-by-hash. En Proc. 9º Taller sobre Temas Candentes en Sistemas Operativos (HotOS IX) (mayo de 2003), pp. 13-18. [18] Benchmarks de Jmob. http://jmob.objectweb.org/. [19] LABRINIDIS, A., Y ROUSSOPOULOS, N. Equilibrando el rendimiento y la frescura de los datos en servidores de bases de datos web. En Proc. 29ª Conferencia VLDB (Sept. 2003). [20] LARSON, P.-A., GOLDSTEIN, J., Y ZHOU, J. Caché transparente de bases de datos en el nivel intermedio en SQL Server. En Proc. 2003 ACM SIGMOD (2003), pp. 661-661. [21] MANBER, U. Encontrar archivos similares en un sistema de archivos grande. En Proc. Conferencia Técnica de Invierno de USENIX 1994 (San Francisco, CA, 17-21 de 1994), pp. 1-10. [22] MANJHI, A., AILAMAKI, A., MAGGS, B. M., MOWRY, T. C., OLSTON, C., Y TOMASIC, A. Escalabilidad y seguridad simultáneas para aplicaciones web intensivas en datos. En Proc. 2006 ACM SIGMOD (junio de 2006), pp. 241-252. [23] MENEZES, A. J., VANSTONE, S. A., Y OORSCHOT, P. C. V. Manual de Criptografía Aplicada. CRC Press, 1996. [24] MILLER, R. B. \n\nCRC Press, 1996. [24] MILLER, R. B. Tiempo de respuesta en transacciones conversacionales entre humanos y computadoras. En Proc. Conferencia Conjunta de Computación de Otoño de AFIPS (1968), pp. 267-277. [25] MOGUL, J. C., CHAN, Y. M., Y KELLY, T. Diseño, implementación y evaluación de la detección de transferencias duplicadas en http. En Proc. Primer Simposio sobre Diseño e Implementación de Sistemas en Red (San Francisco, CA, Mar. 2004). [26] MUTHITACHAROEN, A., CHEN, B., Y MAZIERES, D. Un sistema de archivos en red de bajo ancho de banda. En Proc. 18º Simposio de la ACM sobre Principios de Sistemas Operativos (Banff, Canadá, Oct. 2001). [27] PFEIFER, D., Y JAKSCHITSCH, H. Caché basada en métodos en aplicaciones de servidores multinivel. En Proc. Quinto Simposio Internacional sobre Objetos y Aplicaciones Distribuidas (Catania, Sicilia, Italia, noviembre de 2003). [28] PLATTNER, C., Y ALONSO, G. Ganymed: Replicación escalable para aplicaciones web transaccionales. En Proc. 5ta Conferencia Internacional de Middleware ACM/IFIP/USENIX (2004), pp. 155-174. [29] QUINLAN, S., Y DORWARD, S. Venti: Un nuevo enfoque para el almacenamiento de archivos. En Proc. Conferencia FAST 2002 sobre Tecnologías de Archivo y Almacenamiento (2002). [30] RABIN, M. Huellas dactilares mediante polinomios aleatorios. En el Informe Técnico TR-15-81 (1981) del Centro de Investigación en Tecnología Informática de la Universidad de Harvard. [31] RABINOVICH, M., XIAO, Z., DOUGLIS, F., Y KALMANEK, C. Mover los lados de los bordes incluye a los clientes reales en el borde. En Proc. 4to Simposio USENIX sobre Tecnologías y Sistemas de Internet (Seattle, WA, Mar. 2003). [32] REESE, G. Programación de bases de datos con JDBC y Java, 1ra ed. OReilly, junio de 1997. [33] RHEA, S., LIANG, K., Y BREWER, E. Caché web basada en valores. En Proc. Duodécima Conferencia Internacional de la World Wide Web (mayo de 2003). [34] SIVASUBRAMANIAN, S., ALONSO, G., PIERRE, G., Y VAN STEEN, M. Globedb: Replicación autónoma de datos para aplicaciones web. En WWW 05: Actas de la 14ª Conferencia Internacional de la World-Wide Web (mayo de 2005). [35] SPRING, N. T., Y WETHERALL, D. Una técnica independiente de protocolo para eliminar el tráfico de red redundante. En Proc. de ACM SIGCOMM (Ago. 2000). [36] TOLIA, N., HARKES, J., KOZUCH, M., Y SATYANARAYANAN, M. Integrando almacenamiento portátil y distribuido. En Proc. 3ra Conferencia USENIX sobre Tecnologías de Archivos y Almacenamiento (San Francisco, CA, Mar. 2004). [37] TOLIA, N., KOZUCH, M., SATYANARAYANAN, M., KARP, B., PERRIG, A., Y BRESSOUD, T. Uso oportunista del almacenamiento direccionable por contenido para sistemas de archivos distribuidos. En Proc. Conferencia Técnica Anual USENIX 2003 (San Antonio, TX, junio de 2003), pp. 127-140. [38] YUAN, C., CHEN, Y., Y ZHANG, Z. Evaluación de almacenamiento en caché/descarga en el borde para la entrega de contenido dinámico. En WWW 03: Proc. Duodécima Conferencia Internacional sobre la World Wide Web (2003), pp. 461-471. WWW 2007 / Pista: Rendimiento y Escalabilidad Sesión: Sistemas Escalables para Contenido Dinámico 320 ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "hash-based technique": {
            "translated_key": "técnicas basadas en hash",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Consistency-preserving Caching of Dynamic Database Content∗ Niraj Tolia and M. Satyanarayanan Carnegie Mellon University {ntolia,satya}@cs.cmu.edu ABSTRACT With the growing use of dynamic web content generated from relational databases, traditional caching solutions for throughput and latency improvements are ineffective.",
                "We describe a middleware layer called Ganesh that reduces the volume of data transmitted without semantic interpretation of queries or results.",
                "It achieves this reduction through the use of cryptographic hashing to detect similarities with previous results.",
                "These benefits do not require any compromise of the strict consistency semantics provided by the back-end database.",
                "Further, Ganesh does not require modifications to applications, web servers, or database servers, and works with closed-source applications and databases.",
                "Using two benchmarks representative of dynamic web sites, measurements of our prototype show that it can increase end-to-end throughput by as much as twofold for non-data intensive applications and by as much as tenfold for data intensive ones.",
                "Categories and Subject Descriptors C.2.4 [Computer-Communication Networks]: Distributed Systems; H.2.4 [Database Management]: Systems General Terms Design, Performance 1.",
                "INTRODUCTION An increasing fraction of web content is dynamically generated from back-end relational databases.",
                "Even when database content remains unchanged, temporal locality of access cannot be exploited because dynamic content is not cacheable by web browsers or by intermediate caching servers such as Akamai mirrors.",
                "In a multitiered architecture, each web request can stress the WAN link between the web server and the database.",
                "This causes user experience to be highly variable because there is no caching to insulate the client from bursty loads.",
                "Previous attempts in caching dynamic database content have generally weakened transactional semantics [3, 4] or required application modifications [15, 34].",
                "We report on a new solution that takes the form of a databaseagnostic middleware layer called Ganesh.",
                "Ganesh makes no effort to semantically interpret the contents of queries or their results.",
                "Instead, it relies exclusively on cryptographic hashing to detect similarities with previous results.",
                "Hash-based similarity detection has seen increasing use in distributed file systems [26, 36, 37] for improving performance on low-bandwidth networks.",
                "However, these techniques have not been used for relational databases.",
                "Unlike previous approaches that use generic methods to detect similarity, Ganesh exploits the structure of relational database results to yield superior performance improvement.",
                "One faces at least three challenges in applying hash-based similarity detection to back-end databases.",
                "First, previous work in this space has traditionally viewed storage content as uninterpreted bags of bits with no internal structure.",
                "This allows <br>hash-based technique</br>s to operate on long, contiguous runs of data for maximum effectiveness.",
                "In contrast, relational databases have rich internal structure that may not be as amenable to hash-based similarity detection.",
                "Second, relational databases have very tight integrity and consistency constraints that must not be compromised by the use of <br>hash-based technique</br>s.",
                "Third, the source code of commercial databases is typically not available.",
                "This is in contrast to previous work which presumed availability of source code.",
                "Our experiments show that Ganesh, while conceptually simple, can improve performance significantly at bandwidths representative of todays commercial Internet.",
                "On benchmarks modeling multitiered web applications, the throughput improvement was as high as tenfold for data-intensive workloads.",
                "For workloads that were not data-intensive, throughput improvements of up to twofold were observed.",
                "Even when bandwidth was not a constraint, Ganesh had low overhead and did not hurt performance.",
                "Our experiments also confirm that exploiting the structure present in database results is crucial to this performance improvement. 2.",
                "BACKGROUND 2.1 Dynamic Content Generation As the World Wide Web has grown, many web sites have decentralized their data and functionality by pushing them to the edges of the Internet.",
                "Today, eBusiness systems often use a three-tiered architecture consisting of a front-end web server, an application server, and a back-end database server.",
                "Figure 1 illustrates this architecture.",
                "The first two tiers can be replicated close to a concentration of clients at the edge of the Internet.",
                "This improves user experience by lowering end-to-end latency and reducing exposure WWW 2007 / Track: Performance and Scalability Session: Scalable Systems for Dynamic Content 311 Back-End Database Server Front-End Web and Application Servers Figure 1: Multi-Tier Architecture to backbone traffic congestion.",
                "It can also increase the availability and scalability of web services.",
                "Content that is generated dynamically from the back-end database cannot be cached in the first two tiers.",
                "While databases can be easily replicated in a LAN, this is infeasible in a WAN because of the difficult task of simultaneously providing strong consistency, availability, and tolerance to network partitions [7].",
                "As a result, databases tend to be centralized to meet the strong consistency requirements of many eBusiness applications such as banking, finance, and online retailing [38].",
                "Thus, the back-end database is usually located far from many sets of first and second-tier nodes [2].",
                "In the absence of both caching and replication, WAN bandwidth can easily become a limiting factor in the performance and scalability of data-intensive applications. 2.2 Hash-Based Systems Ganeshs focus is on efficient transmission of results by discovering similarities with the results of previous queries.",
                "As SQL queries can generate large results, <br>hash-based technique</br>s lend themselves well to the problem of efficiently transferring these large results across bandwidth constrained links.",
                "The use of <br>hash-based technique</br>s to reduce the volume of data transmitted has emerged as a common theme of many recent storage systems, as discussed in Section 8.2.",
                "These techniques rely on some basic assumptions.",
                "Cryptographic hash functions are assumed to be collision-resistant.",
                "In other words, it is computationally intractable to find two inputs that hash to the same output.",
                "The functions are also assumed to be one-way; that is, finding an input that results in a specific output is computationally infeasible.",
                "Menezes et al. [23] provide more details about these assumptions.",
                "The above assumptions allow hash-based systems to assume that collisions do not occur.",
                "Hence, they are able to treat the hash of a data item as its unique identifier.",
                "A collection of data items effectively becomes content-addressable, allowing a small hash to serve as a codeword for a much larger data item in permanent storage or network transmission.",
                "The assumption that collisions are so rare as to be effectively non-existent has recently come under fire [17].",
                "However, as explained by Black [5], we believe that these issues do not form a concern for Ganesh.",
                "All communication is between trusted parts of the system and an adversary has no way to force Ganesh to accept invalid data.",
                "Further, Ganesh does not depend critically on any specific hash function.",
                "While we currently use SHA-1, replacing it with a different hash function would be simple.",
                "There would be no impact on performance as stronger hash functions (e.g.",
                "SHA256) only add a few extra bytes and the generated hashes are still orders of magnitude smaller than the data items they represent.",
                "No re-hashing of permanent storage is required since Ganesh only uses hashing on volatile data. 3.",
                "DESIGN AND IMPLEMENTATION Ganesh exploits redundancy in the result stream to avoid transmitting result fragments that are already present at the query site.",
                "Redundancy can arise naturally in many different ways.",
                "For example, a query repeated after a certain interval may return a different result because of updates to the database; however, there may be significant commonality between the two results.",
                "As another example, a user who is refining a search may generate a sequence of queries with overlapping results.",
                "When Ganesh detects redundancy, it suppresses transmission of the corresponding result fragments.",
                "Instead, it transmits a much smaller digest of those fragments and lets the query site reconstruct the result through hash lookup in a cache of previous results.",
                "In effect, Ganesh uses computation at the edges to reduce Internet communication.",
                "Our description of Ganesh focuses on four aspects.",
                "We first explain our approach to detecting similarity in query results.",
                "Next, we discuss how the Ganesh architecture is completely invisible to all components of a multi-tier system.",
                "We then describe Ganeshs proxy-based approach and the dataflow for detecting similarity. 3.1 Detecting Similarity One of the key design decisions in Ganesh is how similarity is detected.",
                "There are many potential ways to decompose a result into fragments.",
                "The optimal way is, of course, the one that results in the smallest possible object for transmission for a given querys results.",
                "Finding this optimal decomposition is a difficult problem because of the large space of possibilities and because the optimal choice depends on many factors such as the contents of the querys result, the history of recent results, and the cache management algorithm.",
                "When an object is opaque, the use of Rabin fingerprints [8, 30] to detect common data between two objects has been successfully shown in the past by systems such as LBFS [26] and CASPER [37].",
                "Rabin fingerprinting uses a sliding window over the data to compute a rolling hash.",
                "Assuming that the hash function is uniformly distributed, a chunk boundary is defined whenever the lower order bits of the hash value equal some predetermined value.",
                "The number of lower order bits used defines the average chunk size.",
                "These sub-divided chunks of the object become the unit of comparison for detecting similarity between different objects.",
                "As the locations of boundaries found by using Rabin fingerprints is stochastically determined, they usually fail to align with any structural properties of the underlying data.",
                "The algorithm therefore deals well with in-place updates, insertions and deletions.",
                "However, it performs poorly in the presence of any reordering of data.",
                "Figure 2 shows an example where two results, A and B, consisting of three rows, have the same data but have different sort attributes.",
                "In the extreme case, Rabin fingerprinting might be unable to find any similar data due to the way it detects chunk boundaries.",
                "Fortunately, Ganesh can use domain specific knowledge for more precise boundary detection.",
                "The information we exploit is that a querys result reflects the structure of a relational database where all data is organized as tables and rows.",
                "It is therefore simple to check for similarity with previous results at two granularities: first the entire result, and then individual rows.",
                "The end of a row in a result serves as a natural chunk boundary.",
                "It is important to note that using the tabular structure in results only involves shallow interpretation of the data.",
                "Ganesh does not perform any deeper semantic interpretation such as understanding data types, result schema, or integrity constraints.",
                "Tuning Rabin fingerprinting for a workload can also be difficult.",
                "If the average chunk size is too large, chunks can span multiple result rows.",
                "However, selecting a smaller average chunk size increases the amount of metadata required to the describe the results.",
                "WWW 2007 / Track: Performance and Scalability Session: Scalable Systems for Dynamic Content 312 Figure 2: Rabin Fingerprinting vs. Ganeshs Chunking This, in turn, would decrease the savings obtained via its use.",
                "Rabin fingerprinting also needs two computationally-expensive passes over the data: once to determine chunk boundaries and one again to generate cryptographic hashes for the chunks.",
                "Ganesh only needs a single pass for hash generation as the chunk boundaries are provided by the datas natural structure.",
                "The performance comparison in Section 6 shows that Ganeshs row-based algorithm outperforms Rabin fingerprinting.",
                "Given that previous work has already shown that Rabin fingerprinting performs better than gzip [26], we do not compare Ganesh to compression algorithms in this paper. 3.2 Transparency The key factor influencing our design was the need for Ganesh to be completely transparent to all components of a typical eBusiness system: web servers, application servers, and database servers.",
                "Without this, Ganesh stands little chance of having a significant real-world impact.",
                "Requiring modifications to any of the above components would raise the barrier for entry of Ganesh into an existing system, and thus reduce its chances of adoption.",
                "Preserving transparency is simplified by the fact that Ganesh is purely a performance enhancement, not a functionality or usability enhancement.",
                "We chose agent interposition as the architectural approach to realizing our goal.",
                "This approach relies on the existence of a compact programming interface that is already widely used by target software.",
                "It also relies on a mechanism to easily add new code without disrupting existing module structure.",
                "These conditions are easily met in our context because of the popularity of Java as the programming language for eBusiness systems.",
                "The Java Database Connectivity (JDBC) API [32] allows Java applications to access a wide variety of databases and even other tabular data repositories such as flat files.",
                "Access to these data sources is provided by JDBC drivers that translate between the JDBC API and the database communication mechanism.",
                "Figure 3(a) shows how JDBC is typically used in an application.",
                "As the JDBC interface is standardized, one can substitute one JDBC driver for another without application modifications.",
                "The JDBC driver thus becomes the natural module to exploit for code interposition.",
                "As shown in Figure 3(b), the native JDBC driver is replaced with a Ganesh JDBC driver that presents the same standardized interface.",
                "The Ganesh driver maintains an in-memory cache of result fragments from previous queries and performs reassembly of results.",
                "At the database, we add a new process called the Ganesh proxy.",
                "This proxy, which can be shared by multiple front-end nodes, consists of two parts: code to detect similarity in result fragments and the original native JDBC driver that communicates with the database.",
                "The use of a proxy at the database makes Ganesh database-agnostic and simplifies prototyping and experimentation.",
                "Ganesh is thus able to work with a wide range of databases and applications, requiring no modifications to either. 3.3 Proxy-Based Caching The native JDBC driver shown in Figure 3(a) is a lightweight code component supplied by the database vendor.",
                "Its main funcClient Database Web and Application Server Native JDBC Driver WAN (a) Native Architecture Client Database Ganesh Proxy Native JDBC Driver WAN Web and Application Server Ganesh JDBC Driver (b) Ganeshs Interposition-based Architecture Figure 3: Native vs. Ganesh Architecture tion is to mediate communication between the application and the remote database.",
                "It forwards queries, buffers entire results, and responds to application requests to view parts of results.",
                "The Ganesh JDBC driver shown in Figure 3(b) presents the application with an interface identical to that provided by the native driver.",
                "It provides the ability to reconstruct results from compact hash-based descriptions sent by the proxy.",
                "To perform this reconstruction, the driver maintains an in-memory cache of recentlyreceived results.",
                "This cache is only used as a source of result fragments in reconstructing results.",
                "No attempt is made by the Ganesh driver or proxy to track database updates.",
                "The lack of cache consistency does not hurt correctness as a description of the results is always fetched from the proxy - at worst, there will be no performance benefit from using Ganesh.",
                "Stale data will simply be paged out of the cache over time.",
                "The Ganesh proxy accesses the database via the native JDBC driver, which remains unchanged between Figures 3(a) and (b).",
                "The database is thus completely unaware of the existence of the proxy.",
                "The proxy does not examine any queries received from the Ganesh driver but passes them to the native driver.",
                "Instead, the proxy is responsible for inspecting database output received from the native driver, detecting similar results, and generating hash-based encodings of these results whenever enough similarity is found.",
                "While this architecture does not decrease the load on a database, as mentioned earlier in Section 2.1, it is much easier to replicate databases for scalability in a LAN than in a WAN.",
                "To generate a hash-based encoding, the proxy must be aware of what result fragments are available in the Ganesh drivers cache.",
                "One approach is to be optimistic, and to assume that all result fragments are available.",
                "This will result in the smallest possible initial transmission of a result.",
                "However, in cases where there is little overlap with previous results, the Ganesh driver will have to make many calls to the proxy during reconstruction to fetch missing result fragments.",
                "To avoid this situation, the proxy loosely tracks the state of the Ganesh drivers cache.",
                "Since both components are under our control, it is relatively simple to do this without resorting to gray-box techniques or explicit communication for maintaining cache coherence.",
                "Instead, the proxy simulates the Ganesh drivers cache management algorithm and uses this to maintain a list of hashes for which the Ganesh driver is likely to possess the result fragments.",
                "In case of mistracking, there will be no loss of correctness but there will be extra round-trip delays to fetch the missing fragments.",
                "If the client detects loss of synchronization with the proxy, it can ask the proxy to reset the state shared between them.",
                "Also note that the proxy does not need to keep the result fragments themselves, only their hashes.",
                "This allows the proxy to remain scalable even when it is shared by many front-end nodes.",
                "WWW 2007 / Track: Performance and Scalability Session: Scalable Systems for Dynamic Content 313 Object Output Stream Convert ResultSet Object Input Stream Convert ResultSet All Data Recipe ResultSet All Data ResultSet Network Ganesh Proxy Ganesh JDBC Driver Result Set Recipe Result Set Yes Yes No No GaneshInputStream GaneshOutputStream Figure 4: Dataflow for Result Handling 3.4 Encoding and Decoding Results The Ganesh proxy receives database output as Java objects from the native JDBC driver.",
                "It examines this output to see if a Java object of type ResultSet is present.",
                "The JDBC interface uses this data type to store results of database queries.",
                "If a ResultSet object is found, it is shrunk as discussed below.",
                "All other Java objects are passed through unmodified.",
                "As discussed in Section 3.1, the proxy uses the row boundaries defined in the ResultSet to partition it into fragments consisting of single result rows.",
                "All ResultSet objects are converted into objects of a new type called RecipeResultSet.",
                "We use the term recipe for this compact description of a database result because of its similarity to a file recipe in the CASPER file system [37].",
                "The conversion replaces each result fragment that is likely to be present in the Ganesh drivers cache by a SHA-1 hash of that fragment.",
                "Previously unseen result fragments are retained verbatim.",
                "The proxy also retains hashes for the new result fragments as they will be present in the drivers cache in the future.",
                "Note that the proxy only caches hashes for result fragments and does not cache recipes.",
                "The proxy constructs a RecipeResultSet by checking for similarity at the entire result and then the row level.",
                "If the entire result is predicted to be present in the Ganesh drivers cache, the RecipeResultSet is simply a single hash of the entire result.",
                "Otherwise, it contains hashes for those rows predicted to be present in that cache; all other rows are retained verbatim.",
                "If the proxy estimates an overall space savings, it will transmit the RecipeResultSet.",
                "Otherwise the original ResultSet is transmitted.",
                "The RecipeResultSet objects are transformed back into ResultSet objects by the Ganesh driver.",
                "Figure 4 illustrates ResultSet handling at both ends.",
                "Each SHA-1 hash found in a RecipeResultSet is looked up in the local cache of result fragments.",
                "On a hit, the hash is replaced by the corresponding fragment.",
                "On a miss, the driver contacts the Ganesh proxy to fetch the fragment.",
                "All previously unseen result fragments that were retained verbatim by the proxy are hashed and added to the result cache.",
                "There should be very few misses if the proxy has accurately tracked the Ganesh drivers cache state.",
                "A future optimization would be to batch the fetch of missing fragments.",
                "This would be valuable when there are many small missing fragments in a high-latency WAN.",
                "Once the transformation is complete, the fully reconstructed ResultSet object is passed up to the application. 4.",
                "EXPERIMENTAL VALIDATION Three questions follow from the goals and design of Ganesh: • First, can performance can be improved significantly by exploiting similarity across database results?",
                "Benchmark Dataset Details 500,000 Users, 12,000 Stories BBOARD 2.0 GB 3,298,000 Comments AUCTION 1.3 GB 1,000,000 Users, 34,000 Items Table 1: Benchmark Dataset Details • Second, how important is Ganeshs structural similarity detection relative to Rabin fingerprintings similarity detection? • Third, is the overhead of the proxy-based design acceptable?",
                "Our evaluation answers these question through controlled experiments with the Ganesh prototype.",
                "This section describes the benchmarks used, our evaluation procedure, and the experimental setup.",
                "Results of the experiments are presented in Sections 5, 6, and 7. 4.1 Benchmarks Our evaluation is based on two benchmarks [18] that have been widely used by other researchers to evaluate various aspects of multi-tier [27] and eBusiness architectures [9].",
                "The first benchmark, BBOARD, is modeled after Slashdot, a technology-oriented news site.",
                "The second benchmark, AUCTION, is modeled after eBay, an online auction site.",
                "In both benchmarks, most content is dynamically generated from information stored in a database.",
                "Details of the datasets used can be found in Table 1. 4.1.1 The BBOARD Benchmark The BBOARD benchmark, also known as RUBBoS [18], models Slashdot, a popular technology-oriented web site.",
                "Slashdot aggregates links to news stories and other topics of interest found elsewhere on the web.",
                "The site also serves as a bulletin board by allowing users to comment on the posted stories in a threaded conversation form.",
                "It is not uncommon for a story to gather hundreds of comments in a matter of hours.",
                "The BBOARD benchmark is similar to the site and models the activities of a user, including readonly operations such as browsing the stories of the day, browsing story categories, and viewing comments as well as write operations such as new user registration, adding and moderating comments, and story submission.",
                "The benchmark consists of three different phases: a short warmup phase, a runtime phase representing the main body of the workload, and a short cool-down phase.",
                "In this paper we only report results from the runtime phase.",
                "The warm-up phase is important in establishing dynamic system state, but measurements from that phase are not significant for our evaluation.",
                "The cool-down phase is solely for allowing the benchmark to shut down.",
                "The warm-up, runtime, and cool-down phases are 2, 15, and 2 minutes respectively.",
                "The number of simulated clients were 400, 800, 1200, and 1600.",
                "The benchmark is available in a Java Servlets and PHP version and has different datasets; we evaluated Ganesh using the Java Servlets version and the Expanded dataset.",
                "The BBOARD benchmark defines two different workloads.",
                "The first, the Authoring mix, consists of 70% read-only operations and 30% read-write operations.",
                "The second, the Browsing mix, contains only read-only operations and does not update the database. 4.1.2 The AUCTION Benchmark The AUCTION benchmark, also known as RUBiS [18], models eBay, the online auction site.",
                "The eBay web site is used to buy and sell items via an auction format.",
                "The main activities of a user include browsing, selling, or bidding for items.",
                "Modeling the activities on this site, this benchmark includes read-only activities such as browsing items by category and by region, as well as read-write WWW 2007 / Track: Performance and Scalability Session: Scalable Systems for Dynamic Content 314 NetEm Router Ganesh Proxy Clients Web and Application Server Database Server Figure 5: Experimental Setup activities such as bidding for items, buying and selling items, and leaving feedback.",
                "As with BBOARD, the benchmark consists of three different phases.",
                "The warm-up, runtime, and cool-down phases for this experiment are 1.5, 15, and 1 minutes respectively.",
                "We tested Ganesh with four client configurations where the number of test clients was set to 400, 800, 1200, and 1600.",
                "The benchmark is available in a Enterprise Java Bean (EJB), Java Servlets, and PHP version and has different datasets; we evaluated Ganesh with the Java Servlets version and the Expanded dataset.",
                "The AUCTION benchmark defines two different workloads.",
                "The first, the Bidding mix, consists of 70% read-only operations and 30% read-write operations.",
                "The second, the Browsing mix, contains only read-only operations and does not update the database. 4.2 Experimental Procedure Both benchmarks involve a synthetic workload of clients accessing a web server.",
                "The number of clients emulated is an experimental parameter.",
                "Each emulated client runs an instance of the benchmark in its own thread, using a matrix to transition between different benchmark states.",
                "The matrix defines a stochastic model with probabilities of transitioning between the different states that represent typical user actions.",
                "An example transition is a user logging into the AUCTION system and then deciding on whether to post an item for sale or bid on active auctions.",
                "Each client also models user think time between requests.",
                "The think time is modeled as an exponential distribution with a mean of 7 seconds.",
                "We evaluate Ganesh along two axes: number of clients and WAN bandwidth.",
                "Higher loads are especially useful in understanding Ganeshs performance when the CPU or disk of the database server or proxy is the limiting factor.",
                "A previous study has shown that approximately 50% of the wide-area Internet bottlenecks observed had an available bandwidth under 10 Mb/s [1].",
                "Based on this work, we focus our evaluation on the WAN bandwidth of 5 Mb/s with 66 ms of round-trip latency, representative of severely constrained network paths, and 20 Mb/s with 33 ms of round-trip latency, representative of a moderately constrained network path.",
                "We also report Ganeshs performance at 100 Mb/s with no added round-trip latency.",
                "This bandwidth, representative of an unconstrained network, is especially useful in revealing any potential overhead of Ganesh in situations where WAN bandwidth is not the limiting factor.",
                "For each combination of number of clients and WAN bandwidth, we measured results from the two configurations listed below: • Native: This configuration corresponds to Figure 3(a).",
                "Native avoids Ganeshs overhead in using a proxy and performing Java object serialization. • Ganesh: This configuration corresponds to Figure 3(b).",
                "For a given number of clients and WAN bandwidth, comparing these results to the corresponding Native results gives the performance benefit due to the Ganesh middleware system.",
                "The metric used to quantify the improvement in throughput is the number of client requests that can be serviced per second.",
                "The metric used to quantify Ganeshs overhead is the average response time for a client request.",
                "For all of the experiments, the Ganesh driver used by the application server used a cache size of 100,000 items1 .",
                "The proxy was effective in tracking the Ganesh drivers cache state; for all of our experiments the miss rate on the driver never exceeded 0.7%. 4.3 Experimental Setup The experimental setup used for the benchmarks can be seen in Figure 5.",
                "All machines were 3.2 GHz Pentium 4s (with HyperThreading enabled.)",
                "With the exception of the database server, all machines had 2 GB of SDRAM and ran the Fedora Core Linux distribution.",
                "The database server had 4 GB of SDRAM.",
                "We used Apaches Tomcat as both the application server that hosted the Java Servlets and the web server.",
                "Both benchmarks used Java Servlets to generate the dynamic content.",
                "The database server used the open source MySQL database.",
                "For the native JDBC drivers, we used the Connector/J drivers provided by MySQL.",
                "The application server used Suns Java Virtual Machine as the runtime environment for the Java Servlets.",
                "The sysstat tool was used to monitor the CPU, network, disk, and memory utilization on all machines.",
                "The machines were connected by a switched gigabit Ethernet network.",
                "As shown in Figure 5, the front-end web and application server was separated from the proxy and database server by a NetEm router [16].",
                "This router allowed us to control the bandwidth and latency settings on the network.",
                "The NetEm router is a standard PC with two network cards running the Linux Traffic Control and Network Emulation software.",
                "The bandwidth and latency constraints were only applied to the link between the application server and the database for the native case and between the application server and the proxy for the Ganesh case.",
                "There is no communication between the application server and the database with Ganesh as all data flows through the proxy.",
                "As our focus was on the WAN link between the application server and the database, there were no constraints on the link between the simulated test clients and the web server. 5.",
                "THROUGHPUT AND RESPONSE TIME In this section, we address the first question raised in Section 4: Can performance can be improved significantly by exploiting similarity across database results?",
                "To answer this question, we use results from the BBOARD and AUCTION benchmarks.",
                "We use two metrics to quantify the performance improvement obtainable through the use of Ganesh: throughput, from the perspective of the web server, and average response time, from the perspective of the client.",
                "Throughput is measured in terms of the number of client requests that can be serviced per second. 5.1 BBOARD Results and Analysis 5.1.1 Authoring Mix Figures 6 (a) and (b) present the average number of requests serviced per second and the average response time for these requests as perceived by the clients for BBOARDs Authoring Mix.",
                "As Figure 6 (a) shows, Native easily saturates the 5 Mb/s link.",
                "At 400 clients, the Native solution delivers 29 requests/sec with an average response time of 8.3 seconds.",
                "Natives throughput drops with an increase in test clients as clients timeout due to congestion at the application server.",
                "Usability studies have shown that response times above 10 seconds cause the user to move on to 1 As Java lacks a sizeof() operator, Java caches therefore limit their size based on the number of objects.",
                "The size of cache dumps taken at the end of the experiments never exceeded 212 MB.",
                "WWW 2007 / Track: Performance and Scalability Session: Scalable Systems for Dynamic Content 315 0 50 100 150 200 250 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Test Clients Requests/sec Native Ganesh 0.001 0.01 0.1 1 10 100 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Test Clients Avg.Resp.Time(sec) Native Ganesh Note Logscale (a) Throughput: Authoring Mix (b) Response Time: Authoring Mix 0 50 100 150 200 250 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Test Clients Requests/sec Native Ganesh 0.001 0.01 0.1 1 10 100 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Test Clients Avg.Resp.Time(sec) Native Ganesh Note Logscale (c) Throughput: Browsing Mix (d) Response Time: Browsing Mix Mean of three trials.",
                "The maximum standard deviation for throughput and response time was 9.8% and 11.9% of the corresponding mean.",
                "Figure 6: BBOARD Benchmark - Throughput and Average Response Time other tasks [24].",
                "Based on these numbers, increasing the number of test clients makes the Native system unusable.",
                "Ganesh at 5 Mb/s, however, delivers a twofold improvement with 400 test clients and a fivefold improvement at 1200 clients.",
                "Ganeshs performance drops slightly at 1200 and 1600 clients as the network is saturated.",
                "Compared to Native, Figure 6 (b) shows that Ganeshs response times are substantially lower with sub-second response times at 400 clients.",
                "Figure 6 (a) also shows that for 400 and 800 test clients Ganesh at 5 Mb/s has the same throughput and average response time as Native at 20 Mb/s.",
                "Only at 1200 and 1600 clients does Native at 20 Mb/s deliver higher throughput than Ganesh at 5 Mb/s.",
                "Comparing both Ganesh and Native at 20 Mb/s, we see that Ganesh is no longer bandwidth constrained and delivers up to a twofold improvement over Native at 1600 test clients.",
                "As Ganesh does not saturate the network with higher test client configurations, at 1600 test clients, its average response time is 0.1 seconds rather than Natives 7.7 seconds.",
                "As expected, there are no visible gains from Ganesh at the higher bandwidth of 100 Mb/s where the network is no longer the bottleneck.",
                "Ganesh, however, still tracks Native in terms of throughput. 5.1.2 Browsing Mix Figures 6 (c) and (d) present the average number of requests serviced per second and the average response time for these requests as perceived by the clients for BBOARDs Browsing Mix.",
                "Regardless of the test client configuration, Figure 6 (c) shows that Natives throughput at 5 Mb/s is limited to 10 reqs/sec.",
                "Ganesh at 5 Mb/s with 400 test clients, delivers more than a sixfold increase in throughput.",
                "The improvement increases to over a elevenfold increase at 800 test clients before Ganesh saturates the network.",
                "Further, Figure 6 (d) shows that Natives average response time of 35 seconds at 400 test clients make the system unusable.",
                "These high response times further increase with the addition of test clients.",
                "Even with the 1600 test client configuration Ganesh delivers an acceptable average response time of 8.2 seconds.",
                "Due to the data-intensive nature of the Browsing mix, Ganesh at 5 Mb/s surprisingly performs much better than Native at 20 Mb/s.",
                "Further, as shown in Figure 6 (d), while the average response time for Native at 20 Mb/s is acceptable at 400 test clients, it is unusable with 800 test clients with an average response time of 15.8 seconds.",
                "Like the 5 Mb/s case, this response time increases with the addition of extra test clients.",
                "Ganesh at 20 Mb/s and both Native and Ganesh at 100 Mb/s are not bandwidth limited.",
                "However, performance plateaus out after 1200 test clients due to the database CPU being saturated. 5.1.3 Filter Variant We were surprised by the Native performance from the BBOARD benchmark.",
                "At the bandwidth of 5 Mb/s, Native performance was lower than what we had expected.",
                "It turned out the benchmark code that displays stories read all the comments associated with the particular story from the database and only then did some postprocessing to select the comments to be displayed.",
                "While this is exactly the behavior of SlashCode, the code base behind the Slashdot web site, we decided to modify the benchmark to perform some pre-filtering at the database.",
                "This modified benchmark, named the Filter Variant, models a developer who applies optimizations at the SQL level to transfer less data.",
                "In the interests of brevity, we only briefly summarize the results from the Authoring mix.",
                "For the Authoring mix, at 800 test clients at 5 Mb/s, Figure 7 (a) shows that Natives throughput increase by 85% when compared to the original benchmark while Ganeshs improvement is smaller at 15%.",
                "Natives performance drops above 800 clients as the test clients time out due to high response times.",
                "The most significant gain for Native is seen at 20 Mb/s.",
                "At 1600 test clients, when compared to the original benchmark, Native sees a 73% improvement in throughput and a 77% reduction in average response time.",
                "While WWW 2007 / Track: Performance and Scalability Session: Scalable Systems for Dynamic Content 316 0 50 100 150 200 250 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Test Clients Requests/sec Native Ganesh 0.001 0.01 0.1 1 10 100 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Test Clients Avg.Resp.Time(sec) Native Ganesh Note Logscale (a) Throughput: Authoring Mix (b) Response Time: Authoring Mix Mean of three trials.",
                "The maximum standard deviation for throughput and response time was 7.2% and 11.5% of the corresponding mean.",
                "Figure 7: BBOARD Benchmark - Filter Variant - Throughput and Average Response Time Ganesh sees no improvement when compared to the original, it still processes 19% more requests/sec than Native.",
                "Thus, while the optimizations were more helpful to Native, Ganesh still delivers an improvement in performance. 5.2 AUCTION Results and Analysis 5.2.1 Bidding Mix Figures 8 (a) and (b) present the average number of requests serviced per second and the average response time for these requests as perceived by the clients for AUCTIONs Bidding Mix.",
                "As mentioned earlier, the Bidding mix consists of a mixture of read and write operations.",
                "The AUCTION benchmark is not as data intensive as BBOARD.",
                "Therefore, most of the gains are observed at the lower bandwidth of 5 Mb/s.",
                "Figure 8 (a) shows that the increase in throughput due to Ganesh ranges from 8% at 400 test clients to 18% with 1600 test clients.",
                "As seen in Figure 8 (b), the average response times for Ganesh are significantly lower than Native ranging from a decrease of 84% at 800 test clients to 88% at 1600 test clients.",
                "Figure 8 (a) also shows that with a fourfold increase of bandwidth from 5 Mb/s to 20 Mb/s, Native is no longer bandwidth constrained and there is no performance difference between Ganesh and Native.",
                "With the higher test client configurations, we did observe that the bandwidth used by Ganesh was lower than Native.",
                "Ganesh might still be useful in these non-constrained scenarios if bandwidth is purchased on a metered basis.",
                "Similar results are seen for the 100 Mb/s scenario. 5.2.2 Browsing Mix For AUCTIONs Browsing Mix, Figures 8 (c) and (d) present the average number of requests serviced per second and the average response time for these requests as perceived by the clients.",
                "Again, most of the gains are observed at lower bandwidths.",
                "At 5 Mb/s, Native and Ganesh deliver similar throughput and response times with 400 test clients.",
                "While the throughput for both remains the same at 800 test clients, Figure 8 (d) shows that Ganeshs average response time is 62% lower than Native.",
                "Native saturates the link at 800 clients and adding extra test clients only increases the average response time.",
                "Ganesh, regardless of the test client configuration, is not bandwidth constrained and maintains the same response time.",
                "At 1600 test clients, Figure 8 (c) shows that Ganeshs throughput is almost twice that of Native.",
                "At the higher bandwidths of 20 and 100 Mb/s, neither Ganesh nor Native is bandwidth limited and deliver equivalent throughput and response times.",
                "Benchmark Orig.",
                "Size Ganesh Size Rabin Size SelectSort1 223.6 MB 5.4 MB 219.3 MB SelectSort2 223.6 MB 5.4 MB 223.6 MB Table 2: Similarity Microbenchmarks 6.",
                "STRUCTURAL VS. RABIN SIMILARITY In this section, we address the second question raised in Section 4: How important is Ganeshs structural similarity detection relative to Rabin fingerprinting-based similarity detecting?",
                "To answer this question, we used microbenchmarks and the BBOARD and AUCTION benchmarks.",
                "As Ganesh always performed better than Rabin fingerprinting, we only present a subset of the results here in the interests of brevity. 6.1 Microbenchmarks Two microbenchmarks show an example of the effects of data reordering on Rabin fingerprinting algorithm.",
                "In the first microbenchmark, SelectSort1, a query with a specified sort order selects 223.6 MB of data spread over approximately 280 K rows.",
                "The query is then repeated with a different sort attribute.",
                "While the same number of rows and the same data is returned, the order of rows is different.",
                "In such a scenario, one would expect a large amount of similarity to be detected between both results.",
                "As Table 2 shows, Ganeshs row-based algorithm achieves a 97.6% reduction while the Rabin fingerprinting algorithm, with the average chunk size parameter set to 4 KB, only achieves a 1% reduction.",
                "The reason, as shown earlier in Figure 2, is that with Rabin fingerprinting, the spans of data between two consecutive boundaries usually cross row boundaries.",
                "With the order of the rows changing in the second result and the Rabin fingerprints now spanning different rows, the algorithm is unable to detect significant similarity.",
                "The small gain seen is mostly for those single rows that are large enough to be broken into multiple chunks.",
                "SelectSort2, another micro-benchmark executed the same queries but increased the minimum chunk size of the Rabin fingerprinting algorithm.",
                "As can be seen in Table 2, even the small gain from the previous microbenchmark disappears as the minimum chunk size was greater than the average row size.",
                "While one can partially address these problems by dynamically varying the parameters of the Rabin fingerprinting algorithm, this can be computationally expensive, especially in the presence of changing workloads. 6.2 Application Benchmarks We ran the BBOARD benchmark described in Section 4.1.1 on two versions of Ganesh: the first with Rabin fingerprinting used as WWW 2007 / Track: Performance and Scalability Session: Scalable Systems for Dynamic Content 317 0 50 100 150 200 250 300 350 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Test Clients Requests/sec Native Ganesh 0.001 0.01 0.1 1 10 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Test Clients Avg.Resp.Time(sec) Native Ganesh Note Logscale (a) Throughput: Bidding Mix (b) Response Time: Bidding Mix 0 50 100 150 200 250 300 350 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Test Clients Requests/sec Native Ganesh 0.001 0.01 0.1 1 10 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Test Clients Avg.Resp.Time(sec) Native Ganesh Note Logscale (c) Throughput: Browsing Mix (d) Response Time: Browsing Mix Mean of three trials.",
                "The maximum standard deviation for throughput and response time was 2.2% and 11.8% of the corresponding mean.",
                "Figure 8: AUCTION Benchmark - Throughput and Average Response Time the chunking algorithm and the second with Ganeshs row-based algorithm.",
                "Rabins results for the Browsing Mix are normalized to Ganeshs results and presented in Figure 9.",
                "As Figure 9 (a) shows, at 5 Mb/s, independent of the test client configuration, Rabin significantly underperforms Ganesh.",
                "This happens because of a combination of two reasons.",
                "First, as outlined in Section 3.1, Rabin finds less similarity as it does not exploit the results structural information.",
                "Second, this benchmark contained some queries that generated large results.",
                "In this case, Rabin, with a small average chunk size, generated a large number of objects that evicted other useful data from the cache.",
                "In contrast, Ganesh was able to detect these large rows and correspondingly increase the size of the chunks.",
                "This was confirmed as cache statistics showed that Ganeshs hit ratio was roughly three time that of Rabin.",
                "Throughput measurements at 20 Mb/s were similar with the exception of Rabins performance with 400 test clients.",
                "In this case, Ganesh was not network limited and, in fact, the throughput was the same as 400 clients at 5 Mb/s.",
                "Rabin, however, took advantage of the bandwidth increase from 5 to 20 Mb/s to deliver a slightly better performance.",
                "At 100 Mb/s, Rabins throughput was almost similar to Ganesh as bandwidth was no longer a bottleneck.",
                "The normalized response time, presented in Figure 9 (b), shows similar trends.",
                "At 5 and 20 Mb/s, the addition of test clients decreases the normalized response time as Ganeshs average response time increases faster than Rabins.",
                "However, at no point does Rabin outperform Ganesh.",
                "Note that at 400 and 800 clients at 100 Mb/s, Rabin does have a higher overhead even when it is not bandwidth constrained.",
                "As mentioned in Section 3.1, this is due to the fact that Rabin has to hash each ResultSet twice.",
                "The overhead disappears with 1200 and 1600 clients as the database CPU is saturated and limits the performance of both Ganesh and Rabin. 7.",
                "PROXY OVERHEAD In this section, we address the third question raised in Section 4: Is the overhead of Ganeshs proxy-based design acceptable?",
                "To answer this question, we concentrate on its performance at the higher bandwidths.",
                "Our evaluation in Section 5 showed that Ganesh, when compared to Native, can deliver a substantial throughput improvement at lower bandwidths.",
                "It is only at higher bandwidths that latency, measured by the average response time for a client request, and throughput, measured by the number of client requests that can be serviced per second, overheads would be visible.",
                "Looking at the Authoring mix of the original BBOARD benchmark, there are no visible gains from Ganesh at 100 Mb/s.",
                "Ganesh, however, still tracks Native in terms of throughput.",
                "While the average response time is higher for Ganesh, the absolute difference is in between 0.01 and 0.04 seconds and would be imperceptible to the end-user.",
                "The Browsing mix shows an even smaller difference in average response times.",
                "The results from the filter variant of the BBOARD benchmarks are similar.",
                "Even for the AUCTION benchmark, the difference between Native and Ganeshs response time at 100 Mb/s was never greater than 0.02 seconds.",
                "The only exception to the above results was seen in the filter variant of the BBOARD benchmark where Ganesh at 1600 test clients added 0.85 seconds to the average response time.",
                "Thus, even for much faster networks where the WAN link is not the bottleneck, Ganesh always delivers throughput equivalent to Native.",
                "While some extra latency is added by the proxy-based design, it is usually imperceptible. 8.",
                "RELATED WORK To the best of our knowledge, Ganesh is the first system that combines the use of <br>hash-based technique</br>s with caching of database results to improve throughput and response times for applications with dynamic content.",
                "We also believe that it is also the first system to demonstrate the benefits of using structural information for WWW 2007 / Track: Performance and Scalability Session: Scalable Systems for Dynamic Content 318 0.0 0.2 0.4 0.6 0.8 1.0 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Test Clients Norm.Throughput 31.8 3.8 2.8 2.3 23.8 32.8 5.8 3.6 1.8 2.1 1.1 1.0 0 5 10 15 20 25 30 35 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Test Clients Norm.ResponseTime (a) Normalized Throughput: Higher is better (b) Normalized Response Time: Higher is worse For throughput, a normalized result greater than 1 implies that Rabin is better, For response time, a normalized result greater than 1 implies that Ganesh is better.",
                "Mean of three trials.",
                "The maximum standard deviation for throughput and response time was 9.1% and 13.9% of the corresponding mean.",
                "Figure 9: Normalized Comparison of Ganesh vs. Rabin - BBOARD Browsing Mix detecting similarity.",
                "In this section, we first discuss alternative approaches to caching dynamic content and then examine other uses of hash-based primitives in distributed systems. 8.1 Caching Dynamic Content At the database layer, a number of systems have advocated middletier caching where parts of the database are replicated at the edge or server [3, 4, 20].",
                "These systems either cache entire tables in what is essentially a replicated database or use materialized views from previous query replies [19].",
                "They require tight integration with the back-end database to ensure a time bound on the propagation of updates.",
                "These systems are also usually targeted towards workloads that do not require strict consistency and can tolerate stale data.",
                "Further, unlike Ganesh, some of these mid-tier caching solutions [2, 3], suffer from the complexity of having to participate in query planing and distributed query processing.",
                "Gao et al. [15] propose using a distributed object replication architecture where the data stores consistency requirements are adapted on a per-application basis.",
                "These solutions require substantial developer resources and detailed understanding of the application being modified.",
                "While systems that attempt to automate the partitioning and replication of an applications database exist [34], they do not provide full transaction semantics.",
                "In comparison, Ganesh does not weaken any of the semantics provided by the underlying database.",
                "Recent work in the evaluation of edge caching options for dynamic web sites [38] has suggested that, without careful planning, employing complex offloading strategies can hurt performance.",
                "Instead, the work advocates for an architecture in which all tiers except the database should be offloaded to the edge.",
                "Our evaluation of Ganesh has shown that it would benefit these scenarios.",
                "To improve database scalability, C-JDBC [10], SSS [22], and Ganymed [28] also advocate the use of an interposition-based architecture to transparently cluster and replicate databases at the middleware level.",
                "The approaches of these architectures and Ganesh are complementary and they would benefit each other.",
                "Moving up to the presentation layer, there has been widespread adoption of fragment-based caching [14], which improves cache utilization by separately caching different parts of generated web pages.",
                "While fragment-based caching works at the edge, a recent proposal has proposed moving web page assembly to the clients to optimize content delivery [31].",
                "While Ganesh is not used at the presentation layer, the same principles have been applied in Duplicate Transfer Detection [25] to increase web cache efficiency as well as for web access across bandwidth limited links [33]. 8.2 Hash-based Systems The past few years have seen the emergence of many systems that exploit <br>hash-based technique</br>s.",
                "At the heart of all these systems is the idea of detecting similarity in data without requiring interpretation of that data.",
                "This simple yet elegant idea relies on cryptographic hashing, as discussed earlier in Section 2.",
                "Successful applications of this idea span a wide range of storage systems.",
                "Examples include peer-to-peer backup of personal computing files [11], storage-efficient archiving of data [29], and finding similar files [21].",
                "Spring and Wetherall [35] apply similar principles at the network level.",
                "Using synchronized caches at both ends of a network link, duplicated data is replaced by smaller tokens for transmission and then restored at the remote end.",
                "This and other hash-based systems such as the CASPER [37] and LBFS [26] filesystems, and Layer-2 bandwidth optimizers such as Riverbed and Peribit use Rabin fingerprinting [30] to discover spans of commonality in data.",
                "This approach is especially useful when data items are modified in-place through insertions, deletions, and updates.",
                "However, as Section 6 shows, the performance of this technique can show a dramatic drop in the presence of data reordering.",
                "Ganesh instead uses row boundaries as dividers for detecting similarity.",
                "The most aggressive use of <br>hash-based technique</br>s is by systems that use hashes as the primary identifiers for objects in persistent storage.",
                "Storage systems such as CFS [12] and PAST [13] that have been built using distributed hash tables fall into this category.",
                "Single Instance Storage [6] and Venti [29] are other examples of such systems.",
                "As discussed in Section 2.2, the use of cryptographic hashes for addressing persistent data represents a deeper level of faith in their collision-resistance than that assumed by Ganesh.",
                "If time reveals shortcomings in the hash algorithm, the effort involved in correcting the flaw is much greater.",
                "In Ganesh, it is merely a matter of replacing the hash algorithm. 9.",
                "CONCLUSION The growing use of dynamic web content generated from relational databases places increased demands on WAN bandwidth.",
                "Traditional caching solutions for bandwidth and latency reduction are often ineffective for such content.",
                "This paper shows that the impact of WAN accesses to databases can be substantially reduced through the Ganesh architecture without any compromise of the databases strict consistency semantics.",
                "The essence of the Ganesh architecture is the use of computation at the edges to reduce communication through the Internet.",
                "Ganesh is able to use cryptographic hashes to detect similarity with previous results and send WWW 2007 / Track: Performance and Scalability Session: Scalable Systems for Dynamic Content 319 compact recipes of results rather than full results.",
                "Our design uses interposition to achieve complete transparency: clients, application servers, and database servers are all unaware of Ganeshs presence and require no modification.",
                "Our experimental evaluation confirms that Ganesh, while conceptually simple, can be highly effective in improving throughput and response time.",
                "Our results also confirm that exploiting the structure present in database results to detect similarity is crucial to this performance improvement. 10.",
                "REFERENCES [1] AKELLA, A., SESHAN, S., AND SHAIKH, A.",
                "An empirical evaluation of wide-area internet bottlenecks.",
                "In Proc. 3rd ACM SIGCOMM Conference on Internet Measurement (Miami Beach, FL, USA, Oct. 2003), pp. 101-114. [2] ALTINEL, M., BORNH ¨OVD, C., KRISHNAMURTHY, S., MOHAN, C., PIRAHESH, H., AND REINWALD, B. Cache tables: Paving the way for an adaptive database cache.",
                "In Proc. of 29th VLDB (Berlin, Germany, 2003), pp. 718-729. [3] ALTINEL, M., LUO, Q., KRISHNAMURTHY, S., MOHAN, C., PIRAHESH, H., LINDSAY, B. G., WOO, H., AND BROWN, L. Dbcache: Database caching for web application servers.",
                "In Proc. 2002 ACM SIGMOD (2002), pp. 612-612. [4] AMIRI, K., PARK, S., TEWARI, R., AND PADMANABHAN, S. Dbproxy: A dynamic data cache for web applications.",
                "In Proc.",
                "IEEE International Conference on Data Engineering (ICDE) (Mar. 2003). [5] BLACK, J. Compare-by-hash: A reasoned analysis.",
                "In Proc. 2006 USENIX Annual Technical Conference (Boston, MA, May 2006), pp. 85-90. [6] BOLOSKY, W. J., CORBIN, S., GOEBEL, D., , AND DOUCEUR, J. R. Single instance storage in windows 2000.",
                "In Proc. 4th USENIX Windows Systems Symposium (Seattle, WA, Aug. 2000), pp. 13-24. [7] BREWER, E. A.",
                "Lessons from giant-scale services.",
                "IEEE Internet Computing 5, 4 (2001), 46-55. [8] BRODER, A., GLASSMAN, S., MANASSE, M., AND ZWEIG, G. Syntactic clustering of the web.",
                "In Proc. 6th International WWW Conference (1997). [9] CECCHET, E., CHANDA, A., ELNIKETY, S., MARGUERITE, J., AND ZWAENEPOEL, W. Performance comparison of middleware architectures for generating dynamic web content.",
                "In Proc.",
                "Fourth ACM/IFIP/USENIX International Middleware Conference (Rio de Janeiro, Brazil, June 2003). [10] CECCHET, E., MARGUERITE, J., AND ZWAENEPOEL, W. C-JDBC: Flexible database clustering middleware.",
                "In Proc. 2004 USENIX Annual Technical Conference (Boston, MA, June 2004). [11] COX, L. P., MURRAY, C. D., AND NOBLE, B. D. Pastiche: Making backup cheap and easy.",
                "In OSDI: Symposium on Operating Systems Design and Implementation (2002). [12] DABEK, F., KAASHOEK, M. F., KARGER, D., MORRIS, R., AND STOICA, I. Wide-area cooperative storage with CFS.",
                "In 18th ACM Symposium on Operating Systems Principles (Banff, Canada, Oct. 2001). [13] DRUSCHEL, P., AND ROWSTRON, A.",
                "PAST: A large-scale, persistent peer-to-peer storage utility.",
                "In HotOS VIII (Schloss Elmau, Germany, May 2001), pp. 75-80. [14] Edge side includes. http://www.esi.org. [15] GAO, L., DAHLIN, M., NAYATE, A., ZHENG, J., AND IYENGAR, A.",
                "Application specific data replication for edge services.",
                "In WWW 03: Proc.",
                "Twelfth International Conference on World Wide Web (2003), pp. 449-460. [16] HEMMINGER, S. Netem - emulating real networks in the lab.",
                "In Proc. 2005 Linux Conference Australia (Canberra, Australia, Apr. 2005). [17] HENSON, V. An analysis of compare-by-hash.",
                "In Proc. 9th Workshop on Hot Topics in Operating Systems (HotOS IX) (May 2003), pp. 13-18. [18] Jmob benchmarks. http://jmob.objectweb.org/. [19] LABRINIDIS, A., AND ROUSSOPOULOS, N. Balancing performance and data freshness in web database servers.",
                "In Proc. 29th VLDB Conference (Sept. 2003). [20] LARSON, P.-A., GOLDSTEIN, J., AND ZHOU, J. Transparent mid-tier database caching in sql server.",
                "In Proc. 2003 ACM SIGMOD (2003), pp. 661-661. [21] MANBER, U.",
                "Finding similar files in a large file system.",
                "In Proc.",
                "USENIX Winter 1994 Technical Conference (San Fransisco, CA, 17-21 1994), pp. 1-10. [22] MANJHI, A., AILAMAKI, A., MAGGS, B. M., MOWRY, T. C., OLSTON, C., AND TOMASIC, A.",
                "Simultaneous scalability and security for data-intensive web applications.",
                "In Proc. 2006 ACM SIGMOD (June 2006), pp. 241-252. [23] MENEZES, A. J., VANSTONE, S. A., AND OORSCHOT, P. C. V. Handbook of Applied Cryptography.",
                "CRC Press, 1996. [24] MILLER, R. B.",
                "Response time in man-computer conversational transactions.",
                "In Proc.",
                "AFIPS Fall Joint Computer Conference (1968), pp. 267-277. [25] MOGUL, J. C., CHAN, Y. M., AND KELLY, T. Design, implementation, and evaluation of duplicate transfer detection in http.",
                "In Proc.",
                "First Symposium on Networked Systems Design and Implementation (San Francisco, CA, Mar. 2004). [26] MUTHITACHAROEN, A., CHEN, B., AND MAZIERES, D. A low-bandwidth network file system.",
                "In Proc. 18th ACM Symposium on Operating Systems Principles (Banff, Canada, Oct. 2001). [27] PFEIFER, D., AND JAKSCHITSCH, H. Method-based caching in multi-tiered server applications.",
                "In Proc.",
                "Fifth International Symposium on Distributed Objects and Applications (Catania, Sicily, Italy, Nov. 2003). [28] PLATTNER, C., AND ALONSO, G. Ganymed: Scalable replication for transactional web applications.",
                "In Proc. 5th ACM/IFIP/USENIX International Conference on Middleware (2004), pp. 155-174. [29] QUINLAN, S., AND DORWARD, S. Venti: A new approach to archival storage.",
                "In Proc.",
                "FAST 2002 Conference on File and Storage Technologies (2002). [30] RABIN, M. Fingerprinting by random polynomials.",
                "In Harvard University Center for Research in Computing Technology Technical Report TR-15-81 (1981). [31] RABINOVICH, M., XIAO, Z., DOUGLIS, F., AND KALMANEK, C. Moving edge side includes to the real edge - the clients.",
                "In Proc. 4th USENIX Symposium on Internet Technologies and Systems (Seattle, WA, Mar. 2003). [32] REESE, G. Database Programming with JDBC and Java, 1st ed.",
                "OReilly, June 1997. [33] RHEA, S., LIANG, K., AND BREWER, E. Value-based web caching.",
                "In Proc.",
                "Twelfth International World Wide Web Conference (May 2003). [34] SIVASUBRAMANIAN, S., ALONSO, G., PIERRE, G., AND VAN STEEN, M. Globedb: Autonomic data replication for web applications.",
                "In WWW 05: Proc. 14th International World-Wide Web conference (May 2005). [35] SPRING, N. T., AND WETHERALL, D. A protocol-independent technique for eliminating redundant network traffic.",
                "In Proc. of ACM SIGCOMM (Aug. 2000). [36] TOLIA, N., HARKES, J., KOZUCH, M., AND SATYANARAYANAN, M. Integrating portable and distributed storage.",
                "In Proc. 3rd USENIX Conference on File and Storage Technologies (San Francisco, CA, Mar. 2004). [37] TOLIA, N., KOZUCH, M., SATYANARAYANAN, M., KARP, B., PERRIG, A., AND BRESSOUD, T. Opportunistic use of content addressable storage for distributed file systems.",
                "In Proc. 2003 USENIX Annual Technical Conference (San Antonio, TX, June 2003), pp. 127-140. [38] YUAN, C., CHEN, Y., AND ZHANG, Z.",
                "Evaluation of edge caching/offloading for dynamic content delivery.",
                "In WWW 03: Proc.",
                "Twelfth International Conference on World Wide Web (2003), pp. 461-471.",
                "WWW 2007 / Track: Performance and Scalability Session: Scalable Systems for Dynamic Content 320"
            ],
            "original_annotated_samples": [
                "This allows <br>hash-based technique</br>s to operate on long, contiguous runs of data for maximum effectiveness.",
                "Second, relational databases have very tight integrity and consistency constraints that must not be compromised by the use of <br>hash-based technique</br>s.",
                "As SQL queries can generate large results, <br>hash-based technique</br>s lend themselves well to the problem of efficiently transferring these large results across bandwidth constrained links.",
                "The use of <br>hash-based technique</br>s to reduce the volume of data transmitted has emerged as a common theme of many recent storage systems, as discussed in Section 8.2.",
                "RELATED WORK To the best of our knowledge, Ganesh is the first system that combines the use of <br>hash-based technique</br>s with caching of database results to improve throughput and response times for applications with dynamic content."
            ],
            "translated_annotated_samples": [
                "Esto permite que las <br>técnicas basadas en hash</br> operen en largas y contiguas secuencias de datos para lograr la máxima efectividad.",
                "Segundo, las bases de datos relacionales tienen restricciones de integridad y consistencia muy estrictas que no deben comprometerse por el uso de <br>técnicas basadas en hash</br>.",
                "Dado que las consultas SQL pueden generar resultados grandes, las <br>técnicas basadas en hash</br> se prestan bien al problema de transferir eficientemente estos grandes resultados a través de enlaces con ancho de banda limitado.",
                "El uso de <br>técnicas basadas en hash</br> para reducir el volumen de datos transmitidos ha surgido como un tema común en muchos sistemas de almacenamiento recientes, como se discute en la Sección 8.2.",
                "TRABAJO RELACIONADO Hasta donde sabemos, Ganesh es el primer sistema que combina el uso de <br>técnicas basadas en hash</br> con el almacenamiento en caché de resultados de base de datos para mejorar el rendimiento y los tiempos de respuesta de aplicaciones con contenido dinámico."
            ],
            "translated_text": "Conservación de la consistencia en el almacenamiento en caché de contenido dinámico de bases de datos∗ Niraj Tolia y M. Satyanarayanan Universidad Carnegie Mellon {ntolia,satya}@cs.cmu.edu RESUMEN Con el creciente uso de contenido web dinámico generado a partir de bases de datos relacionales, las soluciones de almacenamiento en caché tradicionales para mejorar el rendimiento y la latencia son ineficaces. Describimos una capa de middleware llamada Ganesh que reduce el volumen de datos transmitidos sin interpretación semántica de consultas o resultados. Se logra esta reducción mediante el uso de hash criptográficos para detectar similitudes con resultados anteriores. Estos beneficios no requieren ningún compromiso con la semántica de consistencia estricta proporcionada por la base de datos del servidor. Además, Ganesh no requiere modificaciones en aplicaciones, servidores web o servidores de bases de datos, y funciona con aplicaciones y bases de datos de código cerrado. Usando dos puntos de referencia representativos de sitios web dinámicos, las mediciones de nuestro prototipo muestran que puede aumentar el rendimiento de extremo a extremo hasta en un factor de dos para aplicaciones no intensivas en datos y hasta en un factor de diez para las intensivas en datos. Categorías y Descriptores de Asignaturas C.2.4 [Redes de Computadoras-Comunicación]: Sistemas Distribuidos; H.2.4 [Gestión de Bases de Datos]: Términos Generales de Sistemas de Diseño, Rendimiento 1. INTRODUCCIÓN Una fracción creciente del contenido web se genera dinámicamente a partir de bases de datos relacionales en el backend. Incluso cuando el contenido de la base de datos permanece sin cambios, la localidad temporal de acceso no puede ser explotada porque el contenido dinámico no es almacenable en caché por los navegadores web o por servidores de almacenamiento en caché intermedios como los espejos de Akamai. En una arquitectura multinivel, cada solicitud web puede tensionar el enlace WAN entre el servidor web y la base de datos. Esto provoca que la experiencia del usuario sea altamente variable porque no hay almacenamiento en caché para aislar al cliente de cargas repentinas. Los intentos previos de almacenar en caché contenido dinámico de bases de datos generalmente han debilitado la semántica transaccional [3, 4] o han requerido modificaciones en la aplicación [15, 34]. Informamos sobre una nueva solución que toma la forma de una capa intermedia de middleware independiente de la base de datos llamada Ganesh. Ganesh no hace ningún esfuerzo por interpretar semánticamente el contenido de las consultas o sus resultados. En cambio, se basa exclusivamente en el hash criptográfico para detectar similitudes con resultados anteriores. La detección de similitud basada en hash ha sido cada vez más utilizada en sistemas de archivos distribuidos [26, 36, 37] para mejorar el rendimiento en redes de baja capacidad de ancho de banda. Sin embargo, estas técnicas no se han utilizado para bases de datos relacionales. A diferencia de enfoques anteriores que utilizan métodos genéricos para detectar similitud, Ganesh explota la estructura de los resultados de la base de datos relacional para lograr una mejora superior en el rendimiento. Uno se enfrenta al menos a tres desafíos al aplicar la detección de similitud basada en hash a las bases de datos de back-end. Primero, el trabajo previo en este ámbito ha considerado tradicionalmente el contenido de almacenamiento como bolsas de bits no interpretadas y sin estructura interna. Esto permite que las <br>técnicas basadas en hash</br> operen en largas y contiguas secuencias de datos para lograr la máxima efectividad. Por el contrario, las bases de datos relacionales tienen una estructura interna compleja que puede no ser tan propicia para la detección de similitudes basada en hash. Segundo, las bases de datos relacionales tienen restricciones de integridad y consistencia muy estrictas que no deben comprometerse por el uso de <br>técnicas basadas en hash</br>. Tercero, el código fuente de las bases de datos comerciales generalmente no está disponible. Esto contrasta con trabajos anteriores que presumían la disponibilidad del código fuente. Nuestros experimentos muestran que Ganesh, aunque conceptualmente simple, puede mejorar significativamente el rendimiento en anchos de banda representativos del Internet comercial actual. En los modelos de referencia de aplicaciones web multinivel, la mejora en el rendimiento fue de hasta diez veces para cargas de trabajo intensivas en datos. Para cargas de trabajo que no eran intensivas en datos, se observaron mejoras en el rendimiento de hasta el doble. Incluso cuando el ancho de banda no era una limitación, Ganesh tenía un bajo sobrecosto y no afectaba el rendimiento. Nuestros experimentos también confirman que aprovechar la estructura presente en los resultados de la base de datos es crucial para esta mejora en el rendimiento. Antecedentes 2.1 Generación de Contenido Dinámico A medida que la World Wide Web ha crecido, muchos sitios web han descentralizado sus datos y funcionalidades al llevarlos a los extremos de Internet. Hoy en día, los sistemas de comercio electrónico a menudo utilizan una arquitectura de tres niveles que consta de un servidor web de front-end, un servidor de aplicaciones y un servidor de base de datos de back-end. La Figura 1 ilustra esta arquitectura. Los dos primeros niveles se pueden replicar cerca de una concentración de clientes en el borde de Internet. Esto mejora la experiencia del usuario al reducir la latencia de extremo a extremo y disminuir la exposición al congestionamiento del tráfico de la columna vertebral. También puede aumentar la disponibilidad y escalabilidad de los servicios web. El contenido que se genera dinámicamente desde la base de datos del servidor no puede ser almacenado en caché en los dos primeros niveles. Si bien las bases de datos pueden replicarse fácilmente en una LAN, esto es inviable en una WAN debido a la difícil tarea de proporcionar simultáneamente una consistencia sólida, disponibilidad y tolerancia a particiones de red [7]. Como resultado, las bases de datos tienden a ser centralizadas para cumplir con los fuertes requisitos de consistencia de muchas aplicaciones de comercio electrónico como la banca, las finanzas y la venta al por menor en línea [38]. Por lo tanto, la base de datos del back-end suele estar ubicada lejos de muchos conjuntos de nodos de primer y segundo nivel [2]. En ausencia de almacenamiento en caché y replicación, el ancho de banda de la WAN puede convertirse fácilmente en un factor limitante en el rendimiento y la escalabilidad de aplicaciones intensivas en datos. El enfoque de Ganesh en los sistemas basados en hash es la transmisión eficiente de resultados al descubrir similitudes con los resultados de consultas anteriores. Dado que las consultas SQL pueden generar resultados grandes, las <br>técnicas basadas en hash</br> se prestan bien al problema de transferir eficientemente estos grandes resultados a través de enlaces con ancho de banda limitado. El uso de <br>técnicas basadas en hash</br> para reducir el volumen de datos transmitidos ha surgido como un tema común en muchos sistemas de almacenamiento recientes, como se discute en la Sección 8.2. Estas técnicas se basan en algunas suposiciones básicas. Se asume que las funciones hash criptográficas son resistentes a colisiones. En otras palabras, es computacionalmente intratable encontrar dos entradas que se hash a la misma salida. Las funciones también se asumen como unidireccionales; es decir, encontrar una entrada que resulte en una salida específica es computacionalmente inviable. Menezes et al. [23] proporcionan más detalles sobre estas suposiciones. Las suposiciones anteriores permiten a los sistemas basados en hash asumir que no se producen colisiones. Por lo tanto, pueden tratar el hash de un elemento de datos como su identificador único. Una colección de elementos de datos se convierte efectivamente en direccionable por contenido, permitiendo que un hash pequeño funcione como una palabra de código para un elemento de datos mucho más grande en almacenamiento permanente o transmisión en red. La suposición de que las colisiones son tan raras que prácticamente no existen ha sido cuestionada recientemente [17]. Sin embargo, como explicó Black [5], creemos que estos problemas no son una preocupación para Ganesh. Toda comunicación es entre partes confiables del sistema y un adversario no tiene forma de obligar a Ganesh a aceptar datos inválidos. Además, Ganesh no depende críticamente de ninguna función hash específica. Si bien actualmente usamos SHA-1, reemplazarlo con una función hash diferente sería sencillo. No habría impacto en el rendimiento con funciones hash más fuertes (por ejemplo, SHA256) solo añade unos pocos bytes adicionales y los hashes generados siguen siendo órdenes de magnitud más pequeños que los elementos de datos que representan. No es necesario volver a almacenar permanentemente ya que Ganesh solo utiliza el hash en datos volátiles. 3. DISEÑO E IMPLEMENTACIÓN Ganesh explota la redundancia en el flujo de resultados para evitar transmitir fragmentos de resultados que ya están presentes en el sitio de la consulta. La redundancia puede surgir de forma natural de muchas maneras diferentes. Por ejemplo, una consulta repetida después de un cierto intervalo puede devolver un resultado diferente debido a actualizaciones en la base de datos; sin embargo, puede haber una significativa similitud entre los dos resultados. Como otro ejemplo, un usuario que está refinando una búsqueda puede generar una secuencia de consultas con resultados superpuestos. Cuando Ganesh detecta redundancia, suprime la transmisión de los fragmentos de resultado correspondientes. En cambio, transmite un resumen mucho más pequeño de esos fragmentos y permite que el sitio de consulta reconstruya el resultado a través de la búsqueda de hash en una caché de resultados anteriores. De hecho, Ganesh utiliza la computación en los bordes para reducir la comunicación por Internet. Nuestra descripción de Ganesh se centra en cuatro aspectos. Primero explicamos nuestro enfoque para detectar similitud en los resultados de la consulta. A continuación, discutimos cómo la arquitectura Ganesh es completamente invisible para todos los componentes de un sistema de múltiples niveles. Luego describimos el enfoque basado en proxy de Ganesh y el flujo de datos para detectar similitudes. 3.1 Detectar similitud Una de las decisiones clave de diseño en Ganesh es cómo se detecta la similitud. Hay muchas formas potenciales de descomponer un resultado en fragmentos.  I the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the thees I,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,, Encontrar esta descomposición óptima es un problema difícil debido al amplio espacio de posibilidades y porque la elección óptima depende de muchos factores, como el contenido del resultado de las consultas, el historial de resultados recientes y el algoritmo de gestión de caché. Cuando un objeto es opaco, el uso de huellas digitales de Rabin [8, 30] para detectar datos comunes entre dos objetos ha sido demostrado con éxito en el pasado por sistemas como LBFS [26] y CASPER [37]. El fingerprinting de Rabin utiliza una ventana deslizante sobre los datos para calcular un hash rodante. Suponiendo que la función hash está distribuida uniformemente, un límite de fragmento se define cuando los bits de orden inferior del valor hash son iguales a algún valor predeterminado. El número de bits de orden inferior utilizados define el tamaño promedio del fragmento. Estos fragmentos subdivididos del objeto se convierten en la unidad de comparación para detectar similitudes entre diferentes objetos. Dado que las ubicaciones de los límites encontrados mediante el uso de las huellas de Rabin están determinadas de manera estocástica, generalmente no logran alinearse con ninguna propiedad estructural de los datos subyacentes. Por lo tanto, el algoritmo maneja bien las actualizaciones en su lugar, inserciones y eliminaciones. Sin embargo, tiene un rendimiento deficiente en presencia de cualquier reordenamiento de datos. La Figura 2 muestra un ejemplo donde dos resultados, A y B, que constan de tres filas, tienen los mismos datos pero diferentes atributos de ordenamiento. En el caso extremo, la huella digital de Rabin podría no ser capaz de encontrar datos similares debido a la forma en que detecta los límites de los fragmentos. Afortunadamente, Ganesh puede utilizar conocimientos específicos del dominio para una detección de límites más precisa. La información que explotamos es que el resultado de una consulta refleja la estructura de una base de datos relacional donde todos los datos están organizados en tablas y filas. Por lo tanto, es sencillo verificar la similitud con resultados anteriores en dos niveles de granularidad: primero el resultado completo y luego las filas individuales. El final de una fila en un resultado sirve como un límite natural de fragmento. Es importante tener en cuenta que el uso de la estructura tabular en los resultados solo implica una interpretación superficial de los datos. Ganesh no realiza ninguna interpretación semántica más profunda, como comprender tipos de datos, esquemas de resultados o restricciones de integridad. Ajustar la huella digital de Rabin para una carga de trabajo también puede ser difícil. Si el tamaño promedio de los fragmentos es demasiado grande, los fragmentos pueden abarcar varias filas de resultados. Sin embargo, seleccionar un tamaño de fragmento promedio más pequeño aumenta la cantidad de metadatos necesarios para describir los resultados. Esto, a su vez, disminuiría los ahorros obtenidos mediante su uso. El fingerprinting de Rabin también requiere dos pasadas computacionalmente costosas sobre los datos: una vez para determinar los límites de los fragmentos y otra vez para generar hashes criptográficos para los fragmentos. Ganesh solo necesita un único pase para la generación de hash, ya que los límites de los fragmentos son proporcionados por la estructura natural de los datos. La comparación de rendimiento en la Sección 6 muestra que el algoritmo basado en filas de Ganesh supera al fingerprinting de Rabin. Dado que trabajos anteriores ya han demostrado que la huella digital de Rabin funciona mejor que gzip [26], no comparamos a Ganesh con algoritmos de compresión en este artículo. 3.2 Transparencia El factor clave que influyó en nuestro diseño fue la necesidad de que Ganesh fuera completamente transparente para todos los componentes de un sistema típico de comercio electrónico: servidores web, servidores de aplicaciones y servidores de bases de datos. Sin esto, Ganesh tiene pocas posibilidades de tener un impacto significativo en el mundo real. Requerir modificaciones en cualquiera de los componentes mencionados aumentaría la barrera de entrada de Ganesh en un sistema existente, y por lo tanto reduciría sus posibilidades de adopción. Preservar la transparencia se simplifica por el hecho de que Ganesh es simplemente una mejora de rendimiento, no una mejora de funcionalidad o usabilidad. Elegimos la interposición de agentes como enfoque arquitectónico para lograr nuestro objetivo. Este enfoque se basa en la existencia de una interfaz de programación compacta que ya es ampliamente utilizada por el software objetivo. También se basa en un mecanismo para agregar fácilmente nuevo código sin interrumpir la estructura de módulos existente. Estas condiciones se cumplen fácilmente en nuestro contexto debido a la popularidad de Java como el lenguaje de programación para sistemas de comercio electrónico. La API de Conectividad de Base de Datos de Java (JDBC) [32] permite a las aplicaciones de Java acceder a una amplia variedad de bases de datos e incluso a otros repositorios de datos tabulares como archivos planos. El acceso a estas fuentes de datos es proporcionado por controladores JDBC que traducen entre la API JDBC y el mecanismo de comunicación de la base de datos. La figura 3(a) muestra cómo se utiliza típicamente JDBC en una aplicación. Dado que la interfaz JDBC está estandarizada, se puede sustituir un controlador JDBC por otro sin necesidad de de modificar la aplicación. El controlador JDBC se convierte así en el módulo natural para aprovechar la interposición de código. Como se muestra en la Figura 3(b), el controlador JDBC nativo es reemplazado por un controlador JDBC Ganesh que presenta la misma interfaz estandarizada. El controlador Ganesh mantiene una caché en memoria de fragmentos de resultados de consultas anteriores y realiza el reensamblaje de resultados. En la base de datos, agregamos un nuevo proceso llamado el proxy Ganesh. Este proxy, que puede ser compartido por múltiples nodos front-end, consta de dos partes: código para detectar similitud en fragmentos de resultados y el controlador JDBC nativo original que se comunica con la base de datos. El uso de un proxy en la base de datos hace que Ganesh sea independiente de la base de datos y simplifica la creación de prototipos y experimentación. Ganesh es capaz de trabajar con una amplia gama de bases de datos y aplicaciones, sin necesidad de realizar modificaciones en ninguna de ellas. 3.3 Caché basada en proxy El controlador JDBC nativo mostrado en la Figura 3(a) es un componente de código ligero suministrado por el proveedor de la base de datos. Su función principal es mediar la comunicación entre la aplicación y la base de datos remota. Reenvía consultas, almacena resultados completos y responde a solicitudes de la aplicación para ver partes de los resultados. El controlador JDBC de Ganesh mostrado en la Figura 3(b) presenta a la aplicación una interfaz idéntica a la proporcionada por el controlador nativo. Proporciona la capacidad de reconstruir resultados a partir de descripciones compactas basadas en hash enviadas por el proxy. Para realizar esta reconstrucción, el controlador mantiene una caché en memoria de los resultados recibidos recientemente. Esta caché solo se utiliza como fuente de fragmentos de resultados en la reconstrucción de resultados. El conductor Ganesh o el proxy no intentan rastrear las actualizaciones de la base de datos. La falta de consistencia en la caché no afecta a la corrección, ya que la descripción de los resultados siempre se obtiene del proxy; en el peor de los casos, no habrá beneficio de rendimiento al usar Ganesh. Los datos obsoletos simplemente se eliminarán de la caché con el tiempo. El proxy de Ganesh accede a la base de datos a través del controlador JDBC nativo, que permanece sin cambios entre las Figuras 3(a) y (b). La base de datos está completamente ajena a la existencia del proxy. El proxy no examina ninguna consulta recibida del controlador Ganesh, sino que las pasa al controlador nativo. En cambio, el proxy es responsable de inspeccionar la salida de la base de datos recibida del controlador nativo, detectar resultados similares y generar codificaciones basadas en hash de estos resultados siempre que se encuentre suficiente similitud. Si bien esta arquitectura no disminuye la carga en una base de datos, como se mencionó anteriormente en la Sección 2.1, es mucho más fácil replicar bases de datos para escalabilidad en una LAN que en una WAN. Para generar una codificación basada en hash, el proxy debe estar al tanto de qué fragmentos de resultados están disponibles en la caché de controladores de Ganesh. Un enfoque es ser optimista y asumir que todos los fragmentos de resultados están disponibles. Esto resultará en la transmisión inicial más pequeña posible de un resultado. Sin embargo, en casos donde hay poca superposición con resultados anteriores, el controlador Ganesh tendrá que realizar muchas llamadas al proxy durante la reconstrucción para recuperar fragmentos de resultados faltantes. Para evitar esta situación, el proxy sigue de manera flexible el estado de la caché de controladores de Ganesh. Dado que ambos componentes están bajo nuestro control, es relativamente sencillo hacer esto sin recurrir a técnicas de caja gris o comunicación explícita para mantener la coherencia de la caché. En cambio, el proxy simula el algoritmo de gestión de caché de controladores de Ganesh y lo utiliza para mantener una lista de hashes para los cuales es probable que el controlador de Ganesh posea los fragmentos de resultado. En caso de desviación de seguimiento, no habrá pérdida de corrección, pero habrá retrasos adicionales en el viaje de ida y vuelta para recuperar los fragmentos faltantes. Si el cliente detecta la pérdida de sincronización con el proxy, puede pedirle al proxy que restablezca el estado compartido entre ellos. También hay que tener en cuenta que el proxy no necesita guardar los fragmentos de resultado en sí, solo sus hashes. Esto permite que el proxy siga siendo escalable incluso cuando es compartido por muchos nodos front-end. El proxy Ganesh recibe la salida de la base de datos como objetos Java del controlador JDBC nativo. Examina esta salida para ver si está presente un objeto Java del tipo ResultSet. La interfaz JDBC utiliza este tipo de dato para almacenar los resultados de las consultas a la base de datos. Si se encuentra un objeto ResultSet, se reduce como se discute a continuación. Todos los demás objetos de Java se pasan sin modificar. Como se discute en la Sección 3.1, el proxy utiliza los límites de fila definidos en el ResultSet para dividirlo en fragmentos que consisten en filas de resultado individuales. Todos los objetos ResultSet se convierten en objetos de un nuevo tipo llamado RecipeResultSet. Utilizamos el término receta para esta descripción compacta de un resultado de base de datos debido a su similitud con una receta de archivo en el sistema de archivos CASPER [37]. La conversión reemplaza cada fragmento de resultado que probablemente esté presente en la caché de controladores de Ganesh por un hash SHA-1 de ese fragmento. Los fragmentos de resultados previamente no vistos se conservan textualmente. El proxy también retiene los hashes de los nuevos fragmentos de resultados, ya que estarán presentes en la caché de los controladores en el futuro. Ten en cuenta que el proxy solo almacena en caché los hashes de los fragmentos de resultados y no almacena en caché las recetas. El proxy construye un RecipeResultSet verificando la similitud en todo el resultado y luego a nivel de fila. Si se predice que todo el resultado estará presente en la caché de los controladores de Ganesh, el RecipeResultSet será simplemente un único hash de todo el resultado. De lo contrario, contiene hashes para aquellas filas que se predice que están presentes en esa caché; todas las demás filas se conservan textualmente. Si el proxy estima un ahorro de espacio general, transmitirá el RecipeResultSet. De lo contrario, se transmite el ResultSet original. Los objetos RecipeResultSet son transformados de vuelta en objetos ResultSet por el controlador Ganesh. La Figura 4 ilustra el manejo de ResultSet en ambos extremos. Cada hash SHA-1 encontrado en un RecipeResultSet se busca en la caché local de fragmentos de resultados. En caso de acierto, el hash es reemplazado por el fragmento correspondiente. En caso de error, el conductor contacta al proxy de Ganesh para recuperar el fragmento. Todos los fragmentos de resultados previamente no vistos que fueron retenidos textualmente por el proxy se hasheado y se han añadido a la caché de resultados. Debería haber muy pocos fallos si el proxy ha seguido con precisión el estado de la caché de controladores de Ganesh. Una optimización futura sería agrupar la obtención de fragmentos faltantes. Esto sería valioso cuando hay muchos pequeños fragmentos faltantes en una WAN de alta latencia. Una vez que la transformación esté completa, el objeto ResultSet completamente reconstruido se pasa a la aplicación. 4. VALIDACIÓN EXPERIMENTAL Tres preguntas surgen de los objetivos y diseño de Ganesh: • Primero, ¿se puede mejorar significativamente el rendimiento al explotar la similitud entre los resultados de la base de datos? Detalles del conjunto de datos de referencia 500,000 usuarios, 12,000 historias BBOARD 2.0 GB 3,298,000 comentarios SUBASTA 1.3 GB 1,000,000 usuarios, 34,000 elementos Tabla 1: Detalles del conjunto de datos de referencia • En segundo lugar, ¿qué tan importante es la detección de similitud estructural de Ganesh en comparación con la detección de similitud de la huella digital de Rabin? • En tercer lugar, ¿es aceptable la sobrecarga del diseño basado en proxy? Nuestra evaluación responde a estas preguntas a través de experimentos controlados con el prototipo Ganesh. Esta sección describe los puntos de referencia utilizados, nuestro procedimiento de evaluación y la configuración experimental. Los resultados de los experimentos se presentan en las Secciones 5, 6 y 7. 4.1 Puntos de referencia Nuestra evaluación se basa en dos puntos de referencia [18] que han sido ampliamente utilizados por otros investigadores para evaluar varios aspectos de arquitecturas multi-tier [27] y de comercio electrónico [9]. El primer punto de referencia, BBOARD, está modelado según Slashdot, un sitio de noticias orientado a la tecnología. El segundo punto de referencia, AUCTION, está modelado según eBay, un sitio de subastas en línea. En ambos puntos de referencia, la mayoría del contenido se genera dinámicamente a partir de la información almacenada en una base de datos. Los detalles de los conjuntos de datos utilizados se pueden encontrar en la Tabla 1. 4.1.1 El Benchmark BBOARD El benchmark BBOARD, también conocido como RUBBoS [18], modela Slashdot, un popular sitio web orientado a la tecnología. Slashdot recopila enlaces a noticias y otros temas de interés encontrados en otros lugares de la web. El sitio también funciona como un tablón de anuncios al permitir a los usuarios comentar en las historias publicadas en forma de conversación en hilos. No es raro que una historia recopile cientos de comentarios en cuestión de horas. El benchmark BBOARD es similar al sitio y modela las actividades de un usuario, incluyendo operaciones de solo lectura como navegar por las historias del día, explorar categorías de historias y ver comentarios, así como operaciones de escritura como registro de nuevos usuarios, agregar y moderar comentarios, y enviar historias. El benchmark consiste en tres fases diferentes: una fase de calentamiento corta, una fase de ejecución que representa el cuerpo principal de la carga de trabajo, y una fase de enfriamiento corta. En este documento solo informamos sobre los resultados de la fase de ejecución. La fase de calentamiento es importante para establecer el estado del sistema dinámico, pero las mediciones de esa fase no son significativas para nuestra evaluación. La fase de enfriamiento es únicamente para permitir que el punto de referencia se apague. Las fases de calentamiento, ejercicio y enfriamiento son de 2, 15 y 2 minutos respectivamente. El número de clientes simulados fue de 400, 800, 1200 y 1600. El punto de referencia está disponible en una versión de Java Servlets y PHP y tiene diferentes conjuntos de datos; evaluamos a Ganesh utilizando la versión de Java Servlets y el conjunto de datos Expandido. El benchmark BBOARD define dos cargas de trabajo diferentes. El primero, la mezcla de Autoría, consiste en un 70% de operaciones de solo lectura y un 30% de operaciones de lectura y escritura. El segundo, la mezcla de navegación, contiene solo operaciones de solo lectura y no actualiza la base de datos. 4.1.2 El Benchmark de SUBASTA El benchmark de SUBASTA, también conocido como RUBiS [18], modela eBay, el sitio de subastas en línea. El sitio web de eBay se utiliza para comprar y vender artículos a través de un formato de subasta. Las principales actividades de un usuario incluyen navegar, vender o pujar por artículos. Modelando las actividades en este sitio, este punto de referencia incluye actividades de solo lectura como navegar por artículos por categoría y por región, así como actividades de lectura-escritura como pujar por artículos, comprar y vender artículos, y dejar comentarios. Al igual que con BBOARD, el benchmark consiste en tres fases diferentes. Las fases de calentamiento, ejecución y enfriamiento para este experimento son de 1.5, 15 y 1 minutos respectivamente. Probamos Ganesh con cuatro configuraciones de clientes donde el número de clientes de prueba se estableció en 400, 800, 1200 y 1600. El punto de referencia está disponible en una versión de Enterprise Java Bean (EJB), Java Servlets y PHP y tiene diferentes conjuntos de datos; evaluamos Ganesh con la versión de Java Servlets y el conjunto de datos Expandido. El benchmark de SUBASTA define dos cargas de trabajo diferentes. El primero, la mezcla de Ofertas, consiste en un 70% de operaciones de solo lectura y un 30% de operaciones de lectura-escritura. El segundo, la mezcla de navegación, contiene solo operaciones de solo lectura y no actualiza la base de datos. 4.2 Procedimiento Experimental Ambos benchmarks involucran una carga de trabajo sintética de clientes accediendo a un servidor web. El número de clientes emulados es un parámetro experimental. Cada cliente emulado ejecuta una instancia del benchmark en su propio hilo, utilizando una matriz para hacer la transición entre diferentes estados del benchmark. La matriz define un modelo estocástico con probabilidades de transición entre los diferentes estados que representan las acciones típicas de los usuarios. Un ejemplo de transición es un usuario iniciando sesión en el sistema de SUBASTA y luego decidiendo si publicar un artículo en venta o pujar en subastas activas. Cada cliente también modela el tiempo de pensamiento del usuario entre las solicitudes. El tiempo de pensamiento se modela como una distribución exponencial con una media de 7 segundos. Evaluamos a Ganesh a lo largo de dos ejes: número de clientes y ancho de banda de la WAN. Las cargas más altas son especialmente útiles para comprender el rendimiento de Ganesh cuando la CPU o el disco del servidor de base de datos o del proxy son el factor limitante. Un estudio previo ha demostrado que aproximadamente el 50% de los cuellos de botella de Internet de gran área observados tenían un ancho de banda disponible inferior a 10 Mb/s [1]. Basándonos en este trabajo, enfocamos nuestra evaluación en el ancho de banda de la WAN de 5 Mb/s con una latencia de ida y vuelta de 66 ms, representativa de rutas de red severamente restringidas, y 20 Mb/s con una latencia de ida y vuelta de 33 ms, representativa de una ruta de red moderadamente restringida. También informamos sobre el rendimiento de Ganesh a 100 Mb/s sin agregar latencia de ida y vuelta. Este ancho de banda, representativo de una red sin restricciones, es especialmente útil para revelar cualquier sobrecarga potencial de Ganesh en situaciones donde el ancho de banda de la WAN no es el factor limitante. Para cada combinación de número de clientes y ancho de banda de WAN, medimos los resultados de las dos configuraciones enumeradas a continuación: • Nativa: Esta configuración corresponde a la Figura 3(a). El nativo evita la sobrecarga de Ganesh al usar un proxy y realizar la serialización de objetos Java. • Ganesh: Esta configuración corresponde a la Figura 3(b). Para un número dado de clientes y ancho de banda de WAN, comparar estos resultados con los resultados nativos correspondientes proporciona el beneficio de rendimiento debido al sistema de middleware Ganesh. La métrica utilizada para cuantificar la mejora en el rendimiento es el número de solicitudes de clientes que pueden ser atendidas por segundo. La métrica utilizada para cuantificar el rendimiento de Ganesh es el tiempo promedio de respuesta para una solicitud de cliente. Para todos los experimentos, el controlador Ganesh utilizado por el servidor de aplicaciones usó un tamaño de caché de 100,000 elementos. El proxy fue efectivo en rastrear el estado de la caché de los controladores Ganesh; para todos nuestros experimentos, la tasa de fallos en el controlador nunca superó el 0.7%. 4.3 Configuración Experimental La configuración experimental utilizada para las pruebas se puede ver en la Figura 5. Todas las máquinas eran Pentium 4 de 3.2 GHz (con HyperThreading habilitado). Con la excepción del servidor de base de datos, todas las máquinas tenían 2 GB de SDRAM y ejecutaban la distribución de Linux Fedora Core. El servidor de la base de datos tenía 4 GB de SDRAM. Utilizamos Apache Tomcat como tanto el servidor de aplicaciones que alojaba los Servlets de Java como el servidor web. Ambos benchmarks utilizaron Java Servlets para generar el contenido dinámico. El servidor de la base de datos utilizó la base de datos de código abierto MySQL. Para los controladores JDBC nativos, utilizamos los controladores Connector/J proporcionados por MySQL. El servidor de aplicaciones utilizaba la Máquina Virtual de Java de Sun como entorno de ejecución para los Servlets de Java. La herramienta sysstat se utilizó para monitorear la utilización de la CPU, red, disco y memoria en todas las máquinas. Las máquinas estaban conectadas por una red Ethernet gigabit conmutada. Como se muestra en la Figura 5, el servidor web y de aplicación de front-end fue separado del servidor de proxy y base de datos por un enrutador NetEm [16]. Este enrutador nos permitió controlar la configuración de ancho de banda y latencia en la red. El enrutador NetEm es un PC estándar con dos tarjetas de red que ejecuta el software de Control de Tráfico de Linux y Emulación de Red. Las restricciones de ancho de banda y latencia solo se aplicaron al enlace entre el servidor de aplicaciones y la base de datos para el caso nativo y entre el servidor de aplicaciones y el proxy para el caso de Ganesh. No hay comunicación entre el servidor de aplicaciones y la base de datos con Ganesh, ya que todos los datos fluyen a través del proxy. Como nuestro enfoque estaba en el enlace WAN entre el servidor de aplicaciones y la base de datos, no hubo restricciones en el enlace entre los clientes de prueba simulados y el servidor web. 5. DESEMPEÑO Y TIEMPO DE RESPUESTA En esta sección, abordamos la primera pregunta planteada en la Sección 4: ¿Se puede mejorar significativamente el rendimiento explotando la similitud entre los resultados de la base de datos? Para responder a esta pregunta, utilizamos los resultados de los benchmarks BBOARD y AUCTION. Utilizamos dos métricas para cuantificar la mejora en el rendimiento obtenible a través del uso de Ganesh: el throughput, desde la perspectiva del servidor web, y el tiempo de respuesta promedio, desde la perspectiva del cliente. El rendimiento se mide en términos del número de solicitudes de clientes que pueden ser atendidas por segundo. Los resultados y análisis de BBOARD 5.1 Figuras 6 (a) y (b) presentan el número promedio de solicitudes atendidas por segundo y el tiempo de respuesta promedio para estas solicitudes tal como lo perciben los clientes para la Mezcla de Autoría de BBOARD. Como muestra la Figura 6 (a), Native satura fácilmente el enlace de 5 Mb/s. Con 400 clientes, la solución nativa entrega 29 solicitudes/segundo con un tiempo de respuesta promedio de 8.3 segundos. La capacidad de procesamiento de los clientes disminuye con un aumento en los clientes de prueba, ya que los clientes se agotan debido a la congestión en el servidor de aplicaciones. Los estudios de usabilidad han demostrado que los tiempos de respuesta superiores a 10 segundos hacen que el usuario pase a 1. Dado que Java carece de un operador sizeof(), los cachés de Java limitan su tamaño en función del número de objetos. El tamaño de los volcados de caché tomados al final de los experimentos nunca superó los 212 MB. WWW 2007 / Pista: Rendimiento y Escalabilidad Sesión: Sistemas Escalables para Contenido Dinámico 315 0 50 100 150 200 250 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Solicitudes de Clientes de Prueba por Segundo Nativo Ganesh 0.001 0.01 0.1 1 10 100 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Tiempo Promedio de Respuesta de Clientes de Prueba Nativo Ganesh Nota Escala Logarítmica (a) Rendimiento: Mezcla de Autoría (b) Tiempo de Respuesta: Mezcla de Autoría 0 50 100 150 200 250 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Solicitudes de Clientes de Prueba por Segundo Nativo Ganesh 0.001 0.01 0.1 1 10 100 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Tiempo Promedio de Respuesta de Clientes de Prueba Nativo Ganesh Nota Escala Logarítmica (c) Rendimiento: Mezcla de Navegación (d) Tiempo de Respuesta: Mezcla de Navegación Promedio de tres pruebas. La desviación estándar máxima para el rendimiento y el tiempo de respuesta fue del 9.8% y 11.9% de la media correspondiente. Figura 6: BBOARD Benchmark - Rendimiento y Tiempo de Respuesta Promedio de otras tareas [24]. Basándose en estos números, aumentar el número de clientes de prueba hace que el sistema Nativo sea inutilizable. Ganesh a 5 Mb/s, sin embargo, ofrece una mejora doble con 400 clientes de prueba y una mejora quintuple con 1200 clientes. El rendimiento de Ganesh disminuye ligeramente a 1200 y 1600 clientes debido a que la red está saturada. En comparación con Native, la Figura 6 (b) muestra que los tiempos de respuesta de Ganesh son considerablemente más bajos con tiempos de respuesta de menos de un segundo con 400 clientes. La Figura 6 (a) también muestra que para 400 y 800 clientes de prueba, Ganesh a 5 Mb/s tiene el mismo rendimiento y tiempo de respuesta promedio que Native a 20 Mb/s. Solo con 1200 y 1600 clientes, Native a 20 Mb/s ofrece un rendimiento mayor que Ganesh a 5 Mb/s. Al comparar tanto a Ganesh como a Native a 20 Mb/s, vemos que Ganesh ya no está limitado por el ancho de banda y ofrece hasta una mejora del doble sobre Native con 1600 clientes de prueba. Como Ganesh no satura la red con configuraciones de cliente de prueba más altas, con 1600 clientes de prueba, su tiempo de respuesta promedio es de 0.1 segundos en lugar de los 7.7 segundos de Natives. Como era de esperar, no hay ganancias visibles de Ganesh en el ancho de banda más alto de 100 Mb/s donde la red ya no es el cuello de botella. Sin embargo, Ganesh sigue monitoreando a Native en cuanto a rendimiento. Las Figuras 6 (c) y (d) presentan el número promedio de solicitudes atendidas por segundo y el tiempo de respuesta promedio para estas solicitudes tal como lo perciben los clientes para la Mezcla de Navegación de BBOARDs. Independientemente de la configuración del cliente de prueba, la Figura 6 (c) muestra que el rendimiento de los Nativos a 5 Mb/s está limitado a 10 reqs/seg. Ganesh a 5 Mb/s con 400 clientes de prueba, ofrece un aumento de más de seis veces en el rendimiento. La mejora aumenta a más de once veces a 800 clientes de prueba antes de que Ganesh sature la red. Además, la Figura 6 (d) muestra que el tiempo de respuesta promedio de los Nativos de 35 segundos con 400 clientes de prueba hace que el sistema sea inutilizable. Estos altos tiempos de respuesta aumentan aún más con la adición de clientes de prueba. Incluso con la configuración del cliente de prueba de 1600, Ganesh ofrece un tiempo de respuesta promedio aceptable de 8.2 segundos. Debido a la naturaleza intensiva en datos de la mezcla de navegación, Ganesh a 5 Mb/s sorprendentemente tiene un rendimiento mucho mejor que Native a 20 Mb/s. Además, como se muestra en la Figura 6 (d), si bien el tiempo de respuesta promedio para Native a 20 Mb/s es aceptable con 400 clientes de prueba, resulta inutilizable con 800 clientes de prueba, con un tiempo de respuesta promedio de 15.8 segundos. Al igual que en el caso de 5 Mb/s, este tiempo de respuesta aumenta con la adición de clientes de prueba adicionales. Ganesh a 20 Mb/s y tanto Native como Ganesh a 100 Mb/s no tienen limitaciones de ancho de banda. Sin embargo, el rendimiento se estanca después de 1200 clientes de prueba debido a que la CPU de la base de datos está saturada. 5.1.3 Variante de filtro Nos sorprendió el rendimiento nativo del benchmark BBOARD. A una velocidad de banda ancha de 5 Mb/s, el rendimiento nativo fue más bajo de lo que esperábamos. Resultó que el código de referencia que muestra historias leía todos los comentarios asociados con la historia en particular de la base de datos y solo entonces realizaba un postprocesamiento para seleccionar los comentarios que se mostrarían. Si bien este es exactamente el comportamiento de SlashCode, la base de código detrás del sitio web de Slashdot, decidimos modificar la prueba de rendimiento para realizar cierto prefiltrado en la base de datos. Este benchmark modificado, llamado el Filtro de Variantes, modela a un desarrollador que aplica optimizaciones a nivel de SQL para transferir menos datos. En aras de la brevedad, solo resumimos brevemente los resultados de la mezcla de autores. Para la mezcla de Autoría, con 800 clientes de prueba a 5 Mb/s, la Figura 7 (a) muestra que el rendimiento de Natives aumenta un 85% en comparación con el punto de referencia original, mientras que la mejora de Ganesh es menor, del 15%. El rendimiento de los servidores disminuye por encima de los 800 clientes, ya que los clientes de prueba se agotan debido a los altos tiempos de respuesta. La ganancia más significativa para Native se observa a 20 Mb/s. En 1600 clientes de prueba, en comparación con el punto de referencia original, Native experimenta una mejora del 73% en el rendimiento y una reducción del 77% en el tiempo de respuesta promedio. Mientras WWW 2007 / Pista: Rendimiento y Escalabilidad Sesión: Sistemas Escalables para Contenido Dinámico 316 0 50 100 150 200 250 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Clientes de Prueba Solicitudes/seg Nativo Ganesh 0.001 0.01 0.1 1 10 100 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Clientes de Prueba Tiempo de Resp. Promedio (seg) Nativo Ganesh Nota Escala Logarítmica (a) Rendimiento: Mezcla de Autoría (b) Tiempo de Respuesta: Mezcla de Autoría Promedio de tres pruebas. La desviación estándar máxima para el rendimiento y el tiempo de respuesta fue del 7.2% y del 11.5% de la media correspondiente. Figura 7: BBOARD Benchmark - Variante de filtro - Rendimiento y Tiempo de Respuesta Promedio Ganesh no observa ninguna mejora en comparación con el original, aún procesa un 19% más de solicitudes/seg que Native. Por lo tanto, aunque las optimizaciones fueron más útiles para Native, Ganesh todavía ofrece una mejora en el rendimiento. 5.2 Resultados y Análisis de la SUBASTA 5.2.1 Figuras de la Mezcla de Ofertas Los gráficos 8 (a) y (b) presentan el número promedio de solicitudes atendidas por segundo y el tiempo de respuesta promedio para estas solicitudes tal como son percibidas por los clientes para la Mezcla de Ofertas de las SUBASTAS. Como se mencionó anteriormente, la mezcla de ofertas consiste en una combinación de operaciones de lectura y escritura. El benchmark AUCTION no es tan intensivo en datos como BBOARD. Por lo tanto, la mayoría de las ganancias se observan en el ancho de banda más bajo de 5 Mb/s. La figura 8 (a) muestra que el aumento en el rendimiento debido a Ganesh varía desde un 8% con 400 clientes de prueba hasta un 18% con 1600 clientes de prueba. Como se observa en la Figura 8 (b), los tiempos de respuesta promedio para Ganesh son significativamente más bajos que los de Native, con una disminución del 84% a 800 clientes de prueba y del 88% a 1600 clientes de prueba. La Figura 8 (a) también muestra que con un aumento cuádruple del ancho de banda de 5 Mb/s a 20 Mb/s, Native ya no está limitado por el ancho de banda y no hay diferencia de rendimiento entre Ganesh y Native. Con las configuraciones de cliente de prueba más altas, observamos que el ancho de banda utilizado por Ganesh era menor que el de Nativo. Ganesh podría seguir siendo útil en estos escenarios no restringidos si se compra ancho de banda de forma medible. Se observan resultados similares para el escenario de 100 Mb/s. 5.2.2 Mezcla de Navegación Para la Mezcla de Navegación de SUBASTAS, las Figuras 8 (c) y (d) presentan el número promedio de solicitudes atendidas por segundo y el tiempo promedio de respuesta para estas solicitudes tal como lo perciben los clientes. Una vez más, la mayoría de las ganancias se observan en anchos de banda más bajos. A 5 Mb/s, Native y Ganesh ofrecen un rendimiento y tiempos de respuesta similares con 400 clientes de prueba. Mientras que el rendimiento para ambos permanece igual en 800 clientes de prueba, la Figura 8 (d) muestra que el tiempo de respuesta promedio de Ganesh es un 62% menor que el de Native. El servidor satura el enlace con 800 clientes y agregar clientes de prueba adicionales solo aumenta el tiempo promedio de respuesta. Ganesh, independientemente de la configuración del cliente de prueba, no tiene restricciones de ancho de banda y mantiene el mismo tiempo de respuesta. A 1600 clientes de prueba, la Figura 8 (c) muestra que el rendimiento de Ganesh es casi el doble que el de Nativo. En los anchos de banda más altos de 20 y 100 Mb/s, ni Ganesh ni Native tienen limitaciones de ancho de banda y ofrecen un rendimiento y tiempos de respuesta equivalentes. Referencia original. Tamaño Ganesh Tamaño Rabin Tamaño SelectSort1 223.6 MB 5.4 MB 219.3 MB SelectSort2 223.6 MB 5.4 MB 223.6 MB Tabla 2: Microbenchmarks de similitud 6. SIMILITUD ESTRUCTURAL VS. SIMILITUD DE RABIN En esta sección, abordamos la segunda pregunta planteada en la Sección 4: ¿Qué tan importante es la detección de similitud estructural de Ganesh en comparación con la detección de similitud basada en la huella digital de Rabin? Para responder a esta pregunta, utilizamos microbenchmarks y los benchmarks BBOARD y AUCTION. Dado que Ganesh siempre tuvo un mejor rendimiento que Rabin en la huella dactilar, aquí presentamos solo un subconjunto de los resultados en aras de la brevedad. 6.1 Microbenchmarks Dos microbenchmarks muestran un ejemplo de los efectos de la reordenación de datos en el algoritmo de huella dactilar de Rabin. En el primer microbenchmark, SelectSort1, una consulta con un orden de clasificación especificado selecciona 223.6 MB de datos distribuidos en aproximadamente 280 K filas. La consulta se repite entonces con un atributo de ordenación diferente. Si bien se devuelve el mismo número de filas y los mismos datos, el orden de las filas es diferente. En un escenario así, se esperaría detectar una gran cantidad de similitud entre ambos resultados. Como muestra la Tabla 2, el algoritmo basado en filas de Ganesh logra una reducción del 97.6%, mientras que el algoritmo de huella digital de Rabin, con el parámetro de tamaño de fragmento promedio establecido en 4 KB, solo logra una reducción del 1%. La razón, como se muestra anteriormente en la Figura 2, es que con la huella digital de Rabin, los tramos de datos entre dos límites consecutivos suelen cruzar los límites de fila. Con el cambio en el orden de las filas en el segundo resultado y los fingerprints de Rabin ahora abarcando diferentes filas, el algoritmo no puede detectar similitud significativa. La pequeña ganancia observada se debe principalmente a aquellas filas individuales que son lo suficientemente grandes como para dividirse en múltiples fragmentos. SelectSort2, otro micro-benchmark ejecutó las mismas consultas pero aumentó el tamaño mínimo del fragmento del algoritmo de huella digital de Rabin. Como se puede ver en la Tabla 2, incluso la pequeña ganancia del microbenchmark anterior desaparece cuando el tamaño mínimo de fragmento fue mayor que el tamaño promedio de fila. Si bien se pueden abordar parcialmente estos problemas variando dinámicamente los parámetros del algoritmo de huella digital de Rabin, esto puede resultar computacionalmente costoso, especialmente en presencia de cargas de trabajo cambiantes. 6.2 Benchmarks de Aplicación Ejecutamos el benchmark BBOARD descrito en la Sección 4.1.1 en dos versiones de Ganesh: la primera con la huella digital de Rabin utilizada como WWW 2007 / Track: Sesión de Rendimiento y Escalabilidad: Sistemas Escalables para Contenido Dinámico 317 0 50 100 150 200 250 300 350 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Clientes de Prueba Solicitudes/seg Ganesh Nativo 0.001 0.01 0.1 1 10 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Clientes de Prueba Tiempo de Respuesta Promedio (seg) Ganesh Nativo Nota Escala Logarítmica (a) Rendimiento: Mezcla de Ofertas (b) Tiempo de Respuesta: Mezcla de Ofertas 0 50 100 150 200 250 300 350 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Clientes de Prueba Solicitudes/seg Ganesh Nativo 0.001 0.01 0.1 1 10 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Clientes de Prueba Tiempo de Respuesta Promedio (seg) Ganesh Nativo Nota Escala Logarítmica (c) Rendimiento: Mezcla de Navegación (d) Tiempo de Respuesta: Mezcla de Navegación Promedio de tres pruebas. La desviación estándar máxima para el rendimiento y el tiempo de respuesta fue del 2.2% y del 11.8% de la media correspondiente. Figura 8: Referencia de la subasta AUCTION - Rendimiento y Tiempo de Respuesta Promedio del algoritmo de fragmentación y el segundo con el algoritmo basado en filas de Ganesh. Los resultados de Rabins para la Mezcla de Navegación se normalizan con los resultados de Ganesh y se presentan en la Figura 9. Como muestra la Figura 9 (a), a 5 Mb/s, independientemente de la configuración del cliente de prueba, Rabin tiene un rendimiento significativamente inferior a Ganesh. Esto sucede debido a una combinación de dos razones. Primero, como se describe en la Sección 3.1, Rabin encuentra menos similitud ya que no explota la información estructural de los resultados. Segundo, este punto de referencia contenía algunas consultas que generaron resultados grandes. En este caso, Rabin, con un tamaño de fragmento promedio pequeño, generó una gran cantidad de objetos que desplazaron otros datos útiles de la caché. Por el contrario, Ganesh pudo detectar estas filas grandes y aumentar correspondientemente el tamaño de los bloques. Esto fue confirmado ya que las estadísticas de caché mostraron que la proporción de aciertos de Ganesh era aproximadamente tres veces mayor que la de Rabin. Las mediciones de rendimiento a 20 Mb/s fueron similares, con la excepción del rendimiento de Rabins con 400 clientes de prueba. En este caso, Ganesh no estaba limitado por la red y, de hecho, el rendimiento era el mismo que el de 400 clientes a 5 Mb/s. Rabin, sin embargo, aprovechó el aumento del ancho de banda de 5 a 20 Mb/s para ofrecer un rendimiento ligeramente mejor. A 100 Mb/s, el rendimiento de Rabin era casi similar al de Ganesh ya que el ancho de banda ya no era un cuello de botella. El tiempo de respuesta normalizado, presentado en la Figura 9 (b), muestra tendencias similares. A 5 y 20 Mb/s, la adición de clientes de prueba disminuye el tiempo de respuesta normalizado, ya que el tiempo de respuesta promedio de Ganesh aumenta más rápido que el de Rabin. Sin embargo, en ningún momento Rabin supera a Ganesh. Ten en cuenta que con 400 y 800 clientes a 100 Mb/s, Rabin tiene un mayor sobrecosto incluso cuando no está limitado por el ancho de banda. Como se menciona en la Sección 3.1, esto se debe a que Rabin tiene que hashear cada ResultSet dos veces. La sobrecarga desaparece con 1200 y 1600 clientes, ya que la CPU de la base de datos está saturada y limita el rendimiento tanto de Ganesh como de Rabin. 7. SUPERPOSICIÓN DE PROXY En esta sección, abordamos la tercera pregunta planteada en la Sección 4: ¿Es aceptable la superposición del diseño basado en proxy de Ganesh? Para responder a esta pregunta, nos concentramos en su rendimiento en las bandas de mayor ancho de banda. Nuestra evaluación en la Sección 5 mostró que Ganesh, en comparación con Native, puede ofrecer una mejora sustancial en el rendimiento a anchos de banda más bajos. Solo en anchos de banda más altos serían visibles los costos adicionales de latencia, medidos por el tiempo promedio de respuesta para una solicitud de cliente, y de rendimiento, medidos por la cantidad de solicitudes de cliente que pueden ser atendidas por segundo. Al observar la combinación de autoría del benchmark original de BBOARD, no se aprecian ganancias visibles de Ganesh a 100 Mb/s. Sin embargo, Ganesh sigue rastreando a Native en cuanto a rendimiento. Si bien el tiempo promedio de respuesta es mayor para Ganesh, la diferencia absoluta está entre 0.01 y 0.04 segundos y sería imperceptible para el usuario final. La mezcla de navegación muestra una diferencia aún menor en los tiempos de respuesta promedio. Los resultados de la variante del filtro de los benchmarks de BBOARD son similares. Incluso para el benchmark de SUBASTA, la diferencia entre el tiempo de respuesta de Nativo y Ganesh a 100 Mb/s nunca fue mayor a 0.02 segundos. La única excepción a los resultados anteriores se observó en la variante de filtro del benchmark BBOARD, donde Ganesh con 1600 clientes de prueba añadió 0.85 segundos al tiempo de respuesta promedio. Por lo tanto, incluso para redes mucho más rápidas donde el enlace WAN no es el cuello de botella, Ganesh siempre ofrece un rendimiento equivalente al Nativo. Si bien se agrega algo de latencia adicional debido al diseño basado en proxy, generalmente es imperceptible. TRABAJO RELACIONADO Hasta donde sabemos, Ganesh es el primer sistema que combina el uso de <br>técnicas basadas en hash</br> con el almacenamiento en caché de resultados de base de datos para mejorar el rendimiento y los tiempos de respuesta de aplicaciones con contenido dinámico. ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "redundancy": {
            "translated_key": "redundancia",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Consistency-preserving Caching of Dynamic Database Content∗ Niraj Tolia and M. Satyanarayanan Carnegie Mellon University {ntolia,satya}@cs.cmu.edu ABSTRACT With the growing use of dynamic web content generated from relational databases, traditional caching solutions for throughput and latency improvements are ineffective.",
                "We describe a middleware layer called Ganesh that reduces the volume of data transmitted without semantic interpretation of queries or results.",
                "It achieves this reduction through the use of cryptographic hashing to detect similarities with previous results.",
                "These benefits do not require any compromise of the strict consistency semantics provided by the back-end database.",
                "Further, Ganesh does not require modifications to applications, web servers, or database servers, and works with closed-source applications and databases.",
                "Using two benchmarks representative of dynamic web sites, measurements of our prototype show that it can increase end-to-end throughput by as much as twofold for non-data intensive applications and by as much as tenfold for data intensive ones.",
                "Categories and Subject Descriptors C.2.4 [Computer-Communication Networks]: Distributed Systems; H.2.4 [Database Management]: Systems General Terms Design, Performance 1.",
                "INTRODUCTION An increasing fraction of web content is dynamically generated from back-end relational databases.",
                "Even when database content remains unchanged, temporal locality of access cannot be exploited because dynamic content is not cacheable by web browsers or by intermediate caching servers such as Akamai mirrors.",
                "In a multitiered architecture, each web request can stress the WAN link between the web server and the database.",
                "This causes user experience to be highly variable because there is no caching to insulate the client from bursty loads.",
                "Previous attempts in caching dynamic database content have generally weakened transactional semantics [3, 4] or required application modifications [15, 34].",
                "We report on a new solution that takes the form of a databaseagnostic middleware layer called Ganesh.",
                "Ganesh makes no effort to semantically interpret the contents of queries or their results.",
                "Instead, it relies exclusively on cryptographic hashing to detect similarities with previous results.",
                "Hash-based similarity detection has seen increasing use in distributed file systems [26, 36, 37] for improving performance on low-bandwidth networks.",
                "However, these techniques have not been used for relational databases.",
                "Unlike previous approaches that use generic methods to detect similarity, Ganesh exploits the structure of relational database results to yield superior performance improvement.",
                "One faces at least three challenges in applying hash-based similarity detection to back-end databases.",
                "First, previous work in this space has traditionally viewed storage content as uninterpreted bags of bits with no internal structure.",
                "This allows hash-based techniques to operate on long, contiguous runs of data for maximum effectiveness.",
                "In contrast, relational databases have rich internal structure that may not be as amenable to hash-based similarity detection.",
                "Second, relational databases have very tight integrity and consistency constraints that must not be compromised by the use of hash-based techniques.",
                "Third, the source code of commercial databases is typically not available.",
                "This is in contrast to previous work which presumed availability of source code.",
                "Our experiments show that Ganesh, while conceptually simple, can improve performance significantly at bandwidths representative of todays commercial Internet.",
                "On benchmarks modeling multitiered web applications, the throughput improvement was as high as tenfold for data-intensive workloads.",
                "For workloads that were not data-intensive, throughput improvements of up to twofold were observed.",
                "Even when bandwidth was not a constraint, Ganesh had low overhead and did not hurt performance.",
                "Our experiments also confirm that exploiting the structure present in database results is crucial to this performance improvement. 2.",
                "BACKGROUND 2.1 Dynamic Content Generation As the World Wide Web has grown, many web sites have decentralized their data and functionality by pushing them to the edges of the Internet.",
                "Today, eBusiness systems often use a three-tiered architecture consisting of a front-end web server, an application server, and a back-end database server.",
                "Figure 1 illustrates this architecture.",
                "The first two tiers can be replicated close to a concentration of clients at the edge of the Internet.",
                "This improves user experience by lowering end-to-end latency and reducing exposure WWW 2007 / Track: Performance and Scalability Session: Scalable Systems for Dynamic Content 311 Back-End Database Server Front-End Web and Application Servers Figure 1: Multi-Tier Architecture to backbone traffic congestion.",
                "It can also increase the availability and scalability of web services.",
                "Content that is generated dynamically from the back-end database cannot be cached in the first two tiers.",
                "While databases can be easily replicated in a LAN, this is infeasible in a WAN because of the difficult task of simultaneously providing strong consistency, availability, and tolerance to network partitions [7].",
                "As a result, databases tend to be centralized to meet the strong consistency requirements of many eBusiness applications such as banking, finance, and online retailing [38].",
                "Thus, the back-end database is usually located far from many sets of first and second-tier nodes [2].",
                "In the absence of both caching and replication, WAN bandwidth can easily become a limiting factor in the performance and scalability of data-intensive applications. 2.2 Hash-Based Systems Ganeshs focus is on efficient transmission of results by discovering similarities with the results of previous queries.",
                "As SQL queries can generate large results, hash-based techniques lend themselves well to the problem of efficiently transferring these large results across bandwidth constrained links.",
                "The use of hash-based techniques to reduce the volume of data transmitted has emerged as a common theme of many recent storage systems, as discussed in Section 8.2.",
                "These techniques rely on some basic assumptions.",
                "Cryptographic hash functions are assumed to be collision-resistant.",
                "In other words, it is computationally intractable to find two inputs that hash to the same output.",
                "The functions are also assumed to be one-way; that is, finding an input that results in a specific output is computationally infeasible.",
                "Menezes et al. [23] provide more details about these assumptions.",
                "The above assumptions allow hash-based systems to assume that collisions do not occur.",
                "Hence, they are able to treat the hash of a data item as its unique identifier.",
                "A collection of data items effectively becomes content-addressable, allowing a small hash to serve as a codeword for a much larger data item in permanent storage or network transmission.",
                "The assumption that collisions are so rare as to be effectively non-existent has recently come under fire [17].",
                "However, as explained by Black [5], we believe that these issues do not form a concern for Ganesh.",
                "All communication is between trusted parts of the system and an adversary has no way to force Ganesh to accept invalid data.",
                "Further, Ganesh does not depend critically on any specific hash function.",
                "While we currently use SHA-1, replacing it with a different hash function would be simple.",
                "There would be no impact on performance as stronger hash functions (e.g.",
                "SHA256) only add a few extra bytes and the generated hashes are still orders of magnitude smaller than the data items they represent.",
                "No re-hashing of permanent storage is required since Ganesh only uses hashing on volatile data. 3.",
                "DESIGN AND IMPLEMENTATION Ganesh exploits <br>redundancy</br> in the result stream to avoid transmitting result fragments that are already present at the query site.",
                "<br>redundancy</br> can arise naturally in many different ways.",
                "For example, a query repeated after a certain interval may return a different result because of updates to the database; however, there may be significant commonality between the two results.",
                "As another example, a user who is refining a search may generate a sequence of queries with overlapping results.",
                "When Ganesh detects <br>redundancy</br>, it suppresses transmission of the corresponding result fragments.",
                "Instead, it transmits a much smaller digest of those fragments and lets the query site reconstruct the result through hash lookup in a cache of previous results.",
                "In effect, Ganesh uses computation at the edges to reduce Internet communication.",
                "Our description of Ganesh focuses on four aspects.",
                "We first explain our approach to detecting similarity in query results.",
                "Next, we discuss how the Ganesh architecture is completely invisible to all components of a multi-tier system.",
                "We then describe Ganeshs proxy-based approach and the dataflow for detecting similarity. 3.1 Detecting Similarity One of the key design decisions in Ganesh is how similarity is detected.",
                "There are many potential ways to decompose a result into fragments.",
                "The optimal way is, of course, the one that results in the smallest possible object for transmission for a given querys results.",
                "Finding this optimal decomposition is a difficult problem because of the large space of possibilities and because the optimal choice depends on many factors such as the contents of the querys result, the history of recent results, and the cache management algorithm.",
                "When an object is opaque, the use of Rabin fingerprints [8, 30] to detect common data between two objects has been successfully shown in the past by systems such as LBFS [26] and CASPER [37].",
                "Rabin fingerprinting uses a sliding window over the data to compute a rolling hash.",
                "Assuming that the hash function is uniformly distributed, a chunk boundary is defined whenever the lower order bits of the hash value equal some predetermined value.",
                "The number of lower order bits used defines the average chunk size.",
                "These sub-divided chunks of the object become the unit of comparison for detecting similarity between different objects.",
                "As the locations of boundaries found by using Rabin fingerprints is stochastically determined, they usually fail to align with any structural properties of the underlying data.",
                "The algorithm therefore deals well with in-place updates, insertions and deletions.",
                "However, it performs poorly in the presence of any reordering of data.",
                "Figure 2 shows an example where two results, A and B, consisting of three rows, have the same data but have different sort attributes.",
                "In the extreme case, Rabin fingerprinting might be unable to find any similar data due to the way it detects chunk boundaries.",
                "Fortunately, Ganesh can use domain specific knowledge for more precise boundary detection.",
                "The information we exploit is that a querys result reflects the structure of a relational database where all data is organized as tables and rows.",
                "It is therefore simple to check for similarity with previous results at two granularities: first the entire result, and then individual rows.",
                "The end of a row in a result serves as a natural chunk boundary.",
                "It is important to note that using the tabular structure in results only involves shallow interpretation of the data.",
                "Ganesh does not perform any deeper semantic interpretation such as understanding data types, result schema, or integrity constraints.",
                "Tuning Rabin fingerprinting for a workload can also be difficult.",
                "If the average chunk size is too large, chunks can span multiple result rows.",
                "However, selecting a smaller average chunk size increases the amount of metadata required to the describe the results.",
                "WWW 2007 / Track: Performance and Scalability Session: Scalable Systems for Dynamic Content 312 Figure 2: Rabin Fingerprinting vs. Ganeshs Chunking This, in turn, would decrease the savings obtained via its use.",
                "Rabin fingerprinting also needs two computationally-expensive passes over the data: once to determine chunk boundaries and one again to generate cryptographic hashes for the chunks.",
                "Ganesh only needs a single pass for hash generation as the chunk boundaries are provided by the datas natural structure.",
                "The performance comparison in Section 6 shows that Ganeshs row-based algorithm outperforms Rabin fingerprinting.",
                "Given that previous work has already shown that Rabin fingerprinting performs better than gzip [26], we do not compare Ganesh to compression algorithms in this paper. 3.2 Transparency The key factor influencing our design was the need for Ganesh to be completely transparent to all components of a typical eBusiness system: web servers, application servers, and database servers.",
                "Without this, Ganesh stands little chance of having a significant real-world impact.",
                "Requiring modifications to any of the above components would raise the barrier for entry of Ganesh into an existing system, and thus reduce its chances of adoption.",
                "Preserving transparency is simplified by the fact that Ganesh is purely a performance enhancement, not a functionality or usability enhancement.",
                "We chose agent interposition as the architectural approach to realizing our goal.",
                "This approach relies on the existence of a compact programming interface that is already widely used by target software.",
                "It also relies on a mechanism to easily add new code without disrupting existing module structure.",
                "These conditions are easily met in our context because of the popularity of Java as the programming language for eBusiness systems.",
                "The Java Database Connectivity (JDBC) API [32] allows Java applications to access a wide variety of databases and even other tabular data repositories such as flat files.",
                "Access to these data sources is provided by JDBC drivers that translate between the JDBC API and the database communication mechanism.",
                "Figure 3(a) shows how JDBC is typically used in an application.",
                "As the JDBC interface is standardized, one can substitute one JDBC driver for another without application modifications.",
                "The JDBC driver thus becomes the natural module to exploit for code interposition.",
                "As shown in Figure 3(b), the native JDBC driver is replaced with a Ganesh JDBC driver that presents the same standardized interface.",
                "The Ganesh driver maintains an in-memory cache of result fragments from previous queries and performs reassembly of results.",
                "At the database, we add a new process called the Ganesh proxy.",
                "This proxy, which can be shared by multiple front-end nodes, consists of two parts: code to detect similarity in result fragments and the original native JDBC driver that communicates with the database.",
                "The use of a proxy at the database makes Ganesh database-agnostic and simplifies prototyping and experimentation.",
                "Ganesh is thus able to work with a wide range of databases and applications, requiring no modifications to either. 3.3 Proxy-Based Caching The native JDBC driver shown in Figure 3(a) is a lightweight code component supplied by the database vendor.",
                "Its main funcClient Database Web and Application Server Native JDBC Driver WAN (a) Native Architecture Client Database Ganesh Proxy Native JDBC Driver WAN Web and Application Server Ganesh JDBC Driver (b) Ganeshs Interposition-based Architecture Figure 3: Native vs. Ganesh Architecture tion is to mediate communication between the application and the remote database.",
                "It forwards queries, buffers entire results, and responds to application requests to view parts of results.",
                "The Ganesh JDBC driver shown in Figure 3(b) presents the application with an interface identical to that provided by the native driver.",
                "It provides the ability to reconstruct results from compact hash-based descriptions sent by the proxy.",
                "To perform this reconstruction, the driver maintains an in-memory cache of recentlyreceived results.",
                "This cache is only used as a source of result fragments in reconstructing results.",
                "No attempt is made by the Ganesh driver or proxy to track database updates.",
                "The lack of cache consistency does not hurt correctness as a description of the results is always fetched from the proxy - at worst, there will be no performance benefit from using Ganesh.",
                "Stale data will simply be paged out of the cache over time.",
                "The Ganesh proxy accesses the database via the native JDBC driver, which remains unchanged between Figures 3(a) and (b).",
                "The database is thus completely unaware of the existence of the proxy.",
                "The proxy does not examine any queries received from the Ganesh driver but passes them to the native driver.",
                "Instead, the proxy is responsible for inspecting database output received from the native driver, detecting similar results, and generating hash-based encodings of these results whenever enough similarity is found.",
                "While this architecture does not decrease the load on a database, as mentioned earlier in Section 2.1, it is much easier to replicate databases for scalability in a LAN than in a WAN.",
                "To generate a hash-based encoding, the proxy must be aware of what result fragments are available in the Ganesh drivers cache.",
                "One approach is to be optimistic, and to assume that all result fragments are available.",
                "This will result in the smallest possible initial transmission of a result.",
                "However, in cases where there is little overlap with previous results, the Ganesh driver will have to make many calls to the proxy during reconstruction to fetch missing result fragments.",
                "To avoid this situation, the proxy loosely tracks the state of the Ganesh drivers cache.",
                "Since both components are under our control, it is relatively simple to do this without resorting to gray-box techniques or explicit communication for maintaining cache coherence.",
                "Instead, the proxy simulates the Ganesh drivers cache management algorithm and uses this to maintain a list of hashes for which the Ganesh driver is likely to possess the result fragments.",
                "In case of mistracking, there will be no loss of correctness but there will be extra round-trip delays to fetch the missing fragments.",
                "If the client detects loss of synchronization with the proxy, it can ask the proxy to reset the state shared between them.",
                "Also note that the proxy does not need to keep the result fragments themselves, only their hashes.",
                "This allows the proxy to remain scalable even when it is shared by many front-end nodes.",
                "WWW 2007 / Track: Performance and Scalability Session: Scalable Systems for Dynamic Content 313 Object Output Stream Convert ResultSet Object Input Stream Convert ResultSet All Data Recipe ResultSet All Data ResultSet Network Ganesh Proxy Ganesh JDBC Driver Result Set Recipe Result Set Yes Yes No No GaneshInputStream GaneshOutputStream Figure 4: Dataflow for Result Handling 3.4 Encoding and Decoding Results The Ganesh proxy receives database output as Java objects from the native JDBC driver.",
                "It examines this output to see if a Java object of type ResultSet is present.",
                "The JDBC interface uses this data type to store results of database queries.",
                "If a ResultSet object is found, it is shrunk as discussed below.",
                "All other Java objects are passed through unmodified.",
                "As discussed in Section 3.1, the proxy uses the row boundaries defined in the ResultSet to partition it into fragments consisting of single result rows.",
                "All ResultSet objects are converted into objects of a new type called RecipeResultSet.",
                "We use the term recipe for this compact description of a database result because of its similarity to a file recipe in the CASPER file system [37].",
                "The conversion replaces each result fragment that is likely to be present in the Ganesh drivers cache by a SHA-1 hash of that fragment.",
                "Previously unseen result fragments are retained verbatim.",
                "The proxy also retains hashes for the new result fragments as they will be present in the drivers cache in the future.",
                "Note that the proxy only caches hashes for result fragments and does not cache recipes.",
                "The proxy constructs a RecipeResultSet by checking for similarity at the entire result and then the row level.",
                "If the entire result is predicted to be present in the Ganesh drivers cache, the RecipeResultSet is simply a single hash of the entire result.",
                "Otherwise, it contains hashes for those rows predicted to be present in that cache; all other rows are retained verbatim.",
                "If the proxy estimates an overall space savings, it will transmit the RecipeResultSet.",
                "Otherwise the original ResultSet is transmitted.",
                "The RecipeResultSet objects are transformed back into ResultSet objects by the Ganesh driver.",
                "Figure 4 illustrates ResultSet handling at both ends.",
                "Each SHA-1 hash found in a RecipeResultSet is looked up in the local cache of result fragments.",
                "On a hit, the hash is replaced by the corresponding fragment.",
                "On a miss, the driver contacts the Ganesh proxy to fetch the fragment.",
                "All previously unseen result fragments that were retained verbatim by the proxy are hashed and added to the result cache.",
                "There should be very few misses if the proxy has accurately tracked the Ganesh drivers cache state.",
                "A future optimization would be to batch the fetch of missing fragments.",
                "This would be valuable when there are many small missing fragments in a high-latency WAN.",
                "Once the transformation is complete, the fully reconstructed ResultSet object is passed up to the application. 4.",
                "EXPERIMENTAL VALIDATION Three questions follow from the goals and design of Ganesh: • First, can performance can be improved significantly by exploiting similarity across database results?",
                "Benchmark Dataset Details 500,000 Users, 12,000 Stories BBOARD 2.0 GB 3,298,000 Comments AUCTION 1.3 GB 1,000,000 Users, 34,000 Items Table 1: Benchmark Dataset Details • Second, how important is Ganeshs structural similarity detection relative to Rabin fingerprintings similarity detection? • Third, is the overhead of the proxy-based design acceptable?",
                "Our evaluation answers these question through controlled experiments with the Ganesh prototype.",
                "This section describes the benchmarks used, our evaluation procedure, and the experimental setup.",
                "Results of the experiments are presented in Sections 5, 6, and 7. 4.1 Benchmarks Our evaluation is based on two benchmarks [18] that have been widely used by other researchers to evaluate various aspects of multi-tier [27] and eBusiness architectures [9].",
                "The first benchmark, BBOARD, is modeled after Slashdot, a technology-oriented news site.",
                "The second benchmark, AUCTION, is modeled after eBay, an online auction site.",
                "In both benchmarks, most content is dynamically generated from information stored in a database.",
                "Details of the datasets used can be found in Table 1. 4.1.1 The BBOARD Benchmark The BBOARD benchmark, also known as RUBBoS [18], models Slashdot, a popular technology-oriented web site.",
                "Slashdot aggregates links to news stories and other topics of interest found elsewhere on the web.",
                "The site also serves as a bulletin board by allowing users to comment on the posted stories in a threaded conversation form.",
                "It is not uncommon for a story to gather hundreds of comments in a matter of hours.",
                "The BBOARD benchmark is similar to the site and models the activities of a user, including readonly operations such as browsing the stories of the day, browsing story categories, and viewing comments as well as write operations such as new user registration, adding and moderating comments, and story submission.",
                "The benchmark consists of three different phases: a short warmup phase, a runtime phase representing the main body of the workload, and a short cool-down phase.",
                "In this paper we only report results from the runtime phase.",
                "The warm-up phase is important in establishing dynamic system state, but measurements from that phase are not significant for our evaluation.",
                "The cool-down phase is solely for allowing the benchmark to shut down.",
                "The warm-up, runtime, and cool-down phases are 2, 15, and 2 minutes respectively.",
                "The number of simulated clients were 400, 800, 1200, and 1600.",
                "The benchmark is available in a Java Servlets and PHP version and has different datasets; we evaluated Ganesh using the Java Servlets version and the Expanded dataset.",
                "The BBOARD benchmark defines two different workloads.",
                "The first, the Authoring mix, consists of 70% read-only operations and 30% read-write operations.",
                "The second, the Browsing mix, contains only read-only operations and does not update the database. 4.1.2 The AUCTION Benchmark The AUCTION benchmark, also known as RUBiS [18], models eBay, the online auction site.",
                "The eBay web site is used to buy and sell items via an auction format.",
                "The main activities of a user include browsing, selling, or bidding for items.",
                "Modeling the activities on this site, this benchmark includes read-only activities such as browsing items by category and by region, as well as read-write WWW 2007 / Track: Performance and Scalability Session: Scalable Systems for Dynamic Content 314 NetEm Router Ganesh Proxy Clients Web and Application Server Database Server Figure 5: Experimental Setup activities such as bidding for items, buying and selling items, and leaving feedback.",
                "As with BBOARD, the benchmark consists of three different phases.",
                "The warm-up, runtime, and cool-down phases for this experiment are 1.5, 15, and 1 minutes respectively.",
                "We tested Ganesh with four client configurations where the number of test clients was set to 400, 800, 1200, and 1600.",
                "The benchmark is available in a Enterprise Java Bean (EJB), Java Servlets, and PHP version and has different datasets; we evaluated Ganesh with the Java Servlets version and the Expanded dataset.",
                "The AUCTION benchmark defines two different workloads.",
                "The first, the Bidding mix, consists of 70% read-only operations and 30% read-write operations.",
                "The second, the Browsing mix, contains only read-only operations and does not update the database. 4.2 Experimental Procedure Both benchmarks involve a synthetic workload of clients accessing a web server.",
                "The number of clients emulated is an experimental parameter.",
                "Each emulated client runs an instance of the benchmark in its own thread, using a matrix to transition between different benchmark states.",
                "The matrix defines a stochastic model with probabilities of transitioning between the different states that represent typical user actions.",
                "An example transition is a user logging into the AUCTION system and then deciding on whether to post an item for sale or bid on active auctions.",
                "Each client also models user think time between requests.",
                "The think time is modeled as an exponential distribution with a mean of 7 seconds.",
                "We evaluate Ganesh along two axes: number of clients and WAN bandwidth.",
                "Higher loads are especially useful in understanding Ganeshs performance when the CPU or disk of the database server or proxy is the limiting factor.",
                "A previous study has shown that approximately 50% of the wide-area Internet bottlenecks observed had an available bandwidth under 10 Mb/s [1].",
                "Based on this work, we focus our evaluation on the WAN bandwidth of 5 Mb/s with 66 ms of round-trip latency, representative of severely constrained network paths, and 20 Mb/s with 33 ms of round-trip latency, representative of a moderately constrained network path.",
                "We also report Ganeshs performance at 100 Mb/s with no added round-trip latency.",
                "This bandwidth, representative of an unconstrained network, is especially useful in revealing any potential overhead of Ganesh in situations where WAN bandwidth is not the limiting factor.",
                "For each combination of number of clients and WAN bandwidth, we measured results from the two configurations listed below: • Native: This configuration corresponds to Figure 3(a).",
                "Native avoids Ganeshs overhead in using a proxy and performing Java object serialization. • Ganesh: This configuration corresponds to Figure 3(b).",
                "For a given number of clients and WAN bandwidth, comparing these results to the corresponding Native results gives the performance benefit due to the Ganesh middleware system.",
                "The metric used to quantify the improvement in throughput is the number of client requests that can be serviced per second.",
                "The metric used to quantify Ganeshs overhead is the average response time for a client request.",
                "For all of the experiments, the Ganesh driver used by the application server used a cache size of 100,000 items1 .",
                "The proxy was effective in tracking the Ganesh drivers cache state; for all of our experiments the miss rate on the driver never exceeded 0.7%. 4.3 Experimental Setup The experimental setup used for the benchmarks can be seen in Figure 5.",
                "All machines were 3.2 GHz Pentium 4s (with HyperThreading enabled.)",
                "With the exception of the database server, all machines had 2 GB of SDRAM and ran the Fedora Core Linux distribution.",
                "The database server had 4 GB of SDRAM.",
                "We used Apaches Tomcat as both the application server that hosted the Java Servlets and the web server.",
                "Both benchmarks used Java Servlets to generate the dynamic content.",
                "The database server used the open source MySQL database.",
                "For the native JDBC drivers, we used the Connector/J drivers provided by MySQL.",
                "The application server used Suns Java Virtual Machine as the runtime environment for the Java Servlets.",
                "The sysstat tool was used to monitor the CPU, network, disk, and memory utilization on all machines.",
                "The machines were connected by a switched gigabit Ethernet network.",
                "As shown in Figure 5, the front-end web and application server was separated from the proxy and database server by a NetEm router [16].",
                "This router allowed us to control the bandwidth and latency settings on the network.",
                "The NetEm router is a standard PC with two network cards running the Linux Traffic Control and Network Emulation software.",
                "The bandwidth and latency constraints were only applied to the link between the application server and the database for the native case and between the application server and the proxy for the Ganesh case.",
                "There is no communication between the application server and the database with Ganesh as all data flows through the proxy.",
                "As our focus was on the WAN link between the application server and the database, there were no constraints on the link between the simulated test clients and the web server. 5.",
                "THROUGHPUT AND RESPONSE TIME In this section, we address the first question raised in Section 4: Can performance can be improved significantly by exploiting similarity across database results?",
                "To answer this question, we use results from the BBOARD and AUCTION benchmarks.",
                "We use two metrics to quantify the performance improvement obtainable through the use of Ganesh: throughput, from the perspective of the web server, and average response time, from the perspective of the client.",
                "Throughput is measured in terms of the number of client requests that can be serviced per second. 5.1 BBOARD Results and Analysis 5.1.1 Authoring Mix Figures 6 (a) and (b) present the average number of requests serviced per second and the average response time for these requests as perceived by the clients for BBOARDs Authoring Mix.",
                "As Figure 6 (a) shows, Native easily saturates the 5 Mb/s link.",
                "At 400 clients, the Native solution delivers 29 requests/sec with an average response time of 8.3 seconds.",
                "Natives throughput drops with an increase in test clients as clients timeout due to congestion at the application server.",
                "Usability studies have shown that response times above 10 seconds cause the user to move on to 1 As Java lacks a sizeof() operator, Java caches therefore limit their size based on the number of objects.",
                "The size of cache dumps taken at the end of the experiments never exceeded 212 MB.",
                "WWW 2007 / Track: Performance and Scalability Session: Scalable Systems for Dynamic Content 315 0 50 100 150 200 250 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Test Clients Requests/sec Native Ganesh 0.001 0.01 0.1 1 10 100 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Test Clients Avg.Resp.Time(sec) Native Ganesh Note Logscale (a) Throughput: Authoring Mix (b) Response Time: Authoring Mix 0 50 100 150 200 250 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Test Clients Requests/sec Native Ganesh 0.001 0.01 0.1 1 10 100 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Test Clients Avg.Resp.Time(sec) Native Ganesh Note Logscale (c) Throughput: Browsing Mix (d) Response Time: Browsing Mix Mean of three trials.",
                "The maximum standard deviation for throughput and response time was 9.8% and 11.9% of the corresponding mean.",
                "Figure 6: BBOARD Benchmark - Throughput and Average Response Time other tasks [24].",
                "Based on these numbers, increasing the number of test clients makes the Native system unusable.",
                "Ganesh at 5 Mb/s, however, delivers a twofold improvement with 400 test clients and a fivefold improvement at 1200 clients.",
                "Ganeshs performance drops slightly at 1200 and 1600 clients as the network is saturated.",
                "Compared to Native, Figure 6 (b) shows that Ganeshs response times are substantially lower with sub-second response times at 400 clients.",
                "Figure 6 (a) also shows that for 400 and 800 test clients Ganesh at 5 Mb/s has the same throughput and average response time as Native at 20 Mb/s.",
                "Only at 1200 and 1600 clients does Native at 20 Mb/s deliver higher throughput than Ganesh at 5 Mb/s.",
                "Comparing both Ganesh and Native at 20 Mb/s, we see that Ganesh is no longer bandwidth constrained and delivers up to a twofold improvement over Native at 1600 test clients.",
                "As Ganesh does not saturate the network with higher test client configurations, at 1600 test clients, its average response time is 0.1 seconds rather than Natives 7.7 seconds.",
                "As expected, there are no visible gains from Ganesh at the higher bandwidth of 100 Mb/s where the network is no longer the bottleneck.",
                "Ganesh, however, still tracks Native in terms of throughput. 5.1.2 Browsing Mix Figures 6 (c) and (d) present the average number of requests serviced per second and the average response time for these requests as perceived by the clients for BBOARDs Browsing Mix.",
                "Regardless of the test client configuration, Figure 6 (c) shows that Natives throughput at 5 Mb/s is limited to 10 reqs/sec.",
                "Ganesh at 5 Mb/s with 400 test clients, delivers more than a sixfold increase in throughput.",
                "The improvement increases to over a elevenfold increase at 800 test clients before Ganesh saturates the network.",
                "Further, Figure 6 (d) shows that Natives average response time of 35 seconds at 400 test clients make the system unusable.",
                "These high response times further increase with the addition of test clients.",
                "Even with the 1600 test client configuration Ganesh delivers an acceptable average response time of 8.2 seconds.",
                "Due to the data-intensive nature of the Browsing mix, Ganesh at 5 Mb/s surprisingly performs much better than Native at 20 Mb/s.",
                "Further, as shown in Figure 6 (d), while the average response time for Native at 20 Mb/s is acceptable at 400 test clients, it is unusable with 800 test clients with an average response time of 15.8 seconds.",
                "Like the 5 Mb/s case, this response time increases with the addition of extra test clients.",
                "Ganesh at 20 Mb/s and both Native and Ganesh at 100 Mb/s are not bandwidth limited.",
                "However, performance plateaus out after 1200 test clients due to the database CPU being saturated. 5.1.3 Filter Variant We were surprised by the Native performance from the BBOARD benchmark.",
                "At the bandwidth of 5 Mb/s, Native performance was lower than what we had expected.",
                "It turned out the benchmark code that displays stories read all the comments associated with the particular story from the database and only then did some postprocessing to select the comments to be displayed.",
                "While this is exactly the behavior of SlashCode, the code base behind the Slashdot web site, we decided to modify the benchmark to perform some pre-filtering at the database.",
                "This modified benchmark, named the Filter Variant, models a developer who applies optimizations at the SQL level to transfer less data.",
                "In the interests of brevity, we only briefly summarize the results from the Authoring mix.",
                "For the Authoring mix, at 800 test clients at 5 Mb/s, Figure 7 (a) shows that Natives throughput increase by 85% when compared to the original benchmark while Ganeshs improvement is smaller at 15%.",
                "Natives performance drops above 800 clients as the test clients time out due to high response times.",
                "The most significant gain for Native is seen at 20 Mb/s.",
                "At 1600 test clients, when compared to the original benchmark, Native sees a 73% improvement in throughput and a 77% reduction in average response time.",
                "While WWW 2007 / Track: Performance and Scalability Session: Scalable Systems for Dynamic Content 316 0 50 100 150 200 250 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Test Clients Requests/sec Native Ganesh 0.001 0.01 0.1 1 10 100 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Test Clients Avg.Resp.Time(sec) Native Ganesh Note Logscale (a) Throughput: Authoring Mix (b) Response Time: Authoring Mix Mean of three trials.",
                "The maximum standard deviation for throughput and response time was 7.2% and 11.5% of the corresponding mean.",
                "Figure 7: BBOARD Benchmark - Filter Variant - Throughput and Average Response Time Ganesh sees no improvement when compared to the original, it still processes 19% more requests/sec than Native.",
                "Thus, while the optimizations were more helpful to Native, Ganesh still delivers an improvement in performance. 5.2 AUCTION Results and Analysis 5.2.1 Bidding Mix Figures 8 (a) and (b) present the average number of requests serviced per second and the average response time for these requests as perceived by the clients for AUCTIONs Bidding Mix.",
                "As mentioned earlier, the Bidding mix consists of a mixture of read and write operations.",
                "The AUCTION benchmark is not as data intensive as BBOARD.",
                "Therefore, most of the gains are observed at the lower bandwidth of 5 Mb/s.",
                "Figure 8 (a) shows that the increase in throughput due to Ganesh ranges from 8% at 400 test clients to 18% with 1600 test clients.",
                "As seen in Figure 8 (b), the average response times for Ganesh are significantly lower than Native ranging from a decrease of 84% at 800 test clients to 88% at 1600 test clients.",
                "Figure 8 (a) also shows that with a fourfold increase of bandwidth from 5 Mb/s to 20 Mb/s, Native is no longer bandwidth constrained and there is no performance difference between Ganesh and Native.",
                "With the higher test client configurations, we did observe that the bandwidth used by Ganesh was lower than Native.",
                "Ganesh might still be useful in these non-constrained scenarios if bandwidth is purchased on a metered basis.",
                "Similar results are seen for the 100 Mb/s scenario. 5.2.2 Browsing Mix For AUCTIONs Browsing Mix, Figures 8 (c) and (d) present the average number of requests serviced per second and the average response time for these requests as perceived by the clients.",
                "Again, most of the gains are observed at lower bandwidths.",
                "At 5 Mb/s, Native and Ganesh deliver similar throughput and response times with 400 test clients.",
                "While the throughput for both remains the same at 800 test clients, Figure 8 (d) shows that Ganeshs average response time is 62% lower than Native.",
                "Native saturates the link at 800 clients and adding extra test clients only increases the average response time.",
                "Ganesh, regardless of the test client configuration, is not bandwidth constrained and maintains the same response time.",
                "At 1600 test clients, Figure 8 (c) shows that Ganeshs throughput is almost twice that of Native.",
                "At the higher bandwidths of 20 and 100 Mb/s, neither Ganesh nor Native is bandwidth limited and deliver equivalent throughput and response times.",
                "Benchmark Orig.",
                "Size Ganesh Size Rabin Size SelectSort1 223.6 MB 5.4 MB 219.3 MB SelectSort2 223.6 MB 5.4 MB 223.6 MB Table 2: Similarity Microbenchmarks 6.",
                "STRUCTURAL VS. RABIN SIMILARITY In this section, we address the second question raised in Section 4: How important is Ganeshs structural similarity detection relative to Rabin fingerprinting-based similarity detecting?",
                "To answer this question, we used microbenchmarks and the BBOARD and AUCTION benchmarks.",
                "As Ganesh always performed better than Rabin fingerprinting, we only present a subset of the results here in the interests of brevity. 6.1 Microbenchmarks Two microbenchmarks show an example of the effects of data reordering on Rabin fingerprinting algorithm.",
                "In the first microbenchmark, SelectSort1, a query with a specified sort order selects 223.6 MB of data spread over approximately 280 K rows.",
                "The query is then repeated with a different sort attribute.",
                "While the same number of rows and the same data is returned, the order of rows is different.",
                "In such a scenario, one would expect a large amount of similarity to be detected between both results.",
                "As Table 2 shows, Ganeshs row-based algorithm achieves a 97.6% reduction while the Rabin fingerprinting algorithm, with the average chunk size parameter set to 4 KB, only achieves a 1% reduction.",
                "The reason, as shown earlier in Figure 2, is that with Rabin fingerprinting, the spans of data between two consecutive boundaries usually cross row boundaries.",
                "With the order of the rows changing in the second result and the Rabin fingerprints now spanning different rows, the algorithm is unable to detect significant similarity.",
                "The small gain seen is mostly for those single rows that are large enough to be broken into multiple chunks.",
                "SelectSort2, another micro-benchmark executed the same queries but increased the minimum chunk size of the Rabin fingerprinting algorithm.",
                "As can be seen in Table 2, even the small gain from the previous microbenchmark disappears as the minimum chunk size was greater than the average row size.",
                "While one can partially address these problems by dynamically varying the parameters of the Rabin fingerprinting algorithm, this can be computationally expensive, especially in the presence of changing workloads. 6.2 Application Benchmarks We ran the BBOARD benchmark described in Section 4.1.1 on two versions of Ganesh: the first with Rabin fingerprinting used as WWW 2007 / Track: Performance and Scalability Session: Scalable Systems for Dynamic Content 317 0 50 100 150 200 250 300 350 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Test Clients Requests/sec Native Ganesh 0.001 0.01 0.1 1 10 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Test Clients Avg.Resp.Time(sec) Native Ganesh Note Logscale (a) Throughput: Bidding Mix (b) Response Time: Bidding Mix 0 50 100 150 200 250 300 350 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Test Clients Requests/sec Native Ganesh 0.001 0.01 0.1 1 10 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Test Clients Avg.Resp.Time(sec) Native Ganesh Note Logscale (c) Throughput: Browsing Mix (d) Response Time: Browsing Mix Mean of three trials.",
                "The maximum standard deviation for throughput and response time was 2.2% and 11.8% of the corresponding mean.",
                "Figure 8: AUCTION Benchmark - Throughput and Average Response Time the chunking algorithm and the second with Ganeshs row-based algorithm.",
                "Rabins results for the Browsing Mix are normalized to Ganeshs results and presented in Figure 9.",
                "As Figure 9 (a) shows, at 5 Mb/s, independent of the test client configuration, Rabin significantly underperforms Ganesh.",
                "This happens because of a combination of two reasons.",
                "First, as outlined in Section 3.1, Rabin finds less similarity as it does not exploit the results structural information.",
                "Second, this benchmark contained some queries that generated large results.",
                "In this case, Rabin, with a small average chunk size, generated a large number of objects that evicted other useful data from the cache.",
                "In contrast, Ganesh was able to detect these large rows and correspondingly increase the size of the chunks.",
                "This was confirmed as cache statistics showed that Ganeshs hit ratio was roughly three time that of Rabin.",
                "Throughput measurements at 20 Mb/s were similar with the exception of Rabins performance with 400 test clients.",
                "In this case, Ganesh was not network limited and, in fact, the throughput was the same as 400 clients at 5 Mb/s.",
                "Rabin, however, took advantage of the bandwidth increase from 5 to 20 Mb/s to deliver a slightly better performance.",
                "At 100 Mb/s, Rabins throughput was almost similar to Ganesh as bandwidth was no longer a bottleneck.",
                "The normalized response time, presented in Figure 9 (b), shows similar trends.",
                "At 5 and 20 Mb/s, the addition of test clients decreases the normalized response time as Ganeshs average response time increases faster than Rabins.",
                "However, at no point does Rabin outperform Ganesh.",
                "Note that at 400 and 800 clients at 100 Mb/s, Rabin does have a higher overhead even when it is not bandwidth constrained.",
                "As mentioned in Section 3.1, this is due to the fact that Rabin has to hash each ResultSet twice.",
                "The overhead disappears with 1200 and 1600 clients as the database CPU is saturated and limits the performance of both Ganesh and Rabin. 7.",
                "PROXY OVERHEAD In this section, we address the third question raised in Section 4: Is the overhead of Ganeshs proxy-based design acceptable?",
                "To answer this question, we concentrate on its performance at the higher bandwidths.",
                "Our evaluation in Section 5 showed that Ganesh, when compared to Native, can deliver a substantial throughput improvement at lower bandwidths.",
                "It is only at higher bandwidths that latency, measured by the average response time for a client request, and throughput, measured by the number of client requests that can be serviced per second, overheads would be visible.",
                "Looking at the Authoring mix of the original BBOARD benchmark, there are no visible gains from Ganesh at 100 Mb/s.",
                "Ganesh, however, still tracks Native in terms of throughput.",
                "While the average response time is higher for Ganesh, the absolute difference is in between 0.01 and 0.04 seconds and would be imperceptible to the end-user.",
                "The Browsing mix shows an even smaller difference in average response times.",
                "The results from the filter variant of the BBOARD benchmarks are similar.",
                "Even for the AUCTION benchmark, the difference between Native and Ganeshs response time at 100 Mb/s was never greater than 0.02 seconds.",
                "The only exception to the above results was seen in the filter variant of the BBOARD benchmark where Ganesh at 1600 test clients added 0.85 seconds to the average response time.",
                "Thus, even for much faster networks where the WAN link is not the bottleneck, Ganesh always delivers throughput equivalent to Native.",
                "While some extra latency is added by the proxy-based design, it is usually imperceptible. 8.",
                "RELATED WORK To the best of our knowledge, Ganesh is the first system that combines the use of hash-based techniques with caching of database results to improve throughput and response times for applications with dynamic content.",
                "We also believe that it is also the first system to demonstrate the benefits of using structural information for WWW 2007 / Track: Performance and Scalability Session: Scalable Systems for Dynamic Content 318 0.0 0.2 0.4 0.6 0.8 1.0 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Test Clients Norm.Throughput 31.8 3.8 2.8 2.3 23.8 32.8 5.8 3.6 1.8 2.1 1.1 1.0 0 5 10 15 20 25 30 35 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Test Clients Norm.ResponseTime (a) Normalized Throughput: Higher is better (b) Normalized Response Time: Higher is worse For throughput, a normalized result greater than 1 implies that Rabin is better, For response time, a normalized result greater than 1 implies that Ganesh is better.",
                "Mean of three trials.",
                "The maximum standard deviation for throughput and response time was 9.1% and 13.9% of the corresponding mean.",
                "Figure 9: Normalized Comparison of Ganesh vs. Rabin - BBOARD Browsing Mix detecting similarity.",
                "In this section, we first discuss alternative approaches to caching dynamic content and then examine other uses of hash-based primitives in distributed systems. 8.1 Caching Dynamic Content At the database layer, a number of systems have advocated middletier caching where parts of the database are replicated at the edge or server [3, 4, 20].",
                "These systems either cache entire tables in what is essentially a replicated database or use materialized views from previous query replies [19].",
                "They require tight integration with the back-end database to ensure a time bound on the propagation of updates.",
                "These systems are also usually targeted towards workloads that do not require strict consistency and can tolerate stale data.",
                "Further, unlike Ganesh, some of these mid-tier caching solutions [2, 3], suffer from the complexity of having to participate in query planing and distributed query processing.",
                "Gao et al. [15] propose using a distributed object replication architecture where the data stores consistency requirements are adapted on a per-application basis.",
                "These solutions require substantial developer resources and detailed understanding of the application being modified.",
                "While systems that attempt to automate the partitioning and replication of an applications database exist [34], they do not provide full transaction semantics.",
                "In comparison, Ganesh does not weaken any of the semantics provided by the underlying database.",
                "Recent work in the evaluation of edge caching options for dynamic web sites [38] has suggested that, without careful planning, employing complex offloading strategies can hurt performance.",
                "Instead, the work advocates for an architecture in which all tiers except the database should be offloaded to the edge.",
                "Our evaluation of Ganesh has shown that it would benefit these scenarios.",
                "To improve database scalability, C-JDBC [10], SSS [22], and Ganymed [28] also advocate the use of an interposition-based architecture to transparently cluster and replicate databases at the middleware level.",
                "The approaches of these architectures and Ganesh are complementary and they would benefit each other.",
                "Moving up to the presentation layer, there has been widespread adoption of fragment-based caching [14], which improves cache utilization by separately caching different parts of generated web pages.",
                "While fragment-based caching works at the edge, a recent proposal has proposed moving web page assembly to the clients to optimize content delivery [31].",
                "While Ganesh is not used at the presentation layer, the same principles have been applied in Duplicate Transfer Detection [25] to increase web cache efficiency as well as for web access across bandwidth limited links [33]. 8.2 Hash-based Systems The past few years have seen the emergence of many systems that exploit hash-based techniques.",
                "At the heart of all these systems is the idea of detecting similarity in data without requiring interpretation of that data.",
                "This simple yet elegant idea relies on cryptographic hashing, as discussed earlier in Section 2.",
                "Successful applications of this idea span a wide range of storage systems.",
                "Examples include peer-to-peer backup of personal computing files [11], storage-efficient archiving of data [29], and finding similar files [21].",
                "Spring and Wetherall [35] apply similar principles at the network level.",
                "Using synchronized caches at both ends of a network link, duplicated data is replaced by smaller tokens for transmission and then restored at the remote end.",
                "This and other hash-based systems such as the CASPER [37] and LBFS [26] filesystems, and Layer-2 bandwidth optimizers such as Riverbed and Peribit use Rabin fingerprinting [30] to discover spans of commonality in data.",
                "This approach is especially useful when data items are modified in-place through insertions, deletions, and updates.",
                "However, as Section 6 shows, the performance of this technique can show a dramatic drop in the presence of data reordering.",
                "Ganesh instead uses row boundaries as dividers for detecting similarity.",
                "The most aggressive use of hash-based techniques is by systems that use hashes as the primary identifiers for objects in persistent storage.",
                "Storage systems such as CFS [12] and PAST [13] that have been built using distributed hash tables fall into this category.",
                "Single Instance Storage [6] and Venti [29] are other examples of such systems.",
                "As discussed in Section 2.2, the use of cryptographic hashes for addressing persistent data represents a deeper level of faith in their collision-resistance than that assumed by Ganesh.",
                "If time reveals shortcomings in the hash algorithm, the effort involved in correcting the flaw is much greater.",
                "In Ganesh, it is merely a matter of replacing the hash algorithm. 9.",
                "CONCLUSION The growing use of dynamic web content generated from relational databases places increased demands on WAN bandwidth.",
                "Traditional caching solutions for bandwidth and latency reduction are often ineffective for such content.",
                "This paper shows that the impact of WAN accesses to databases can be substantially reduced through the Ganesh architecture without any compromise of the databases strict consistency semantics.",
                "The essence of the Ganesh architecture is the use of computation at the edges to reduce communication through the Internet.",
                "Ganesh is able to use cryptographic hashes to detect similarity with previous results and send WWW 2007 / Track: Performance and Scalability Session: Scalable Systems for Dynamic Content 319 compact recipes of results rather than full results.",
                "Our design uses interposition to achieve complete transparency: clients, application servers, and database servers are all unaware of Ganeshs presence and require no modification.",
                "Our experimental evaluation confirms that Ganesh, while conceptually simple, can be highly effective in improving throughput and response time.",
                "Our results also confirm that exploiting the structure present in database results to detect similarity is crucial to this performance improvement. 10.",
                "REFERENCES [1] AKELLA, A., SESHAN, S., AND SHAIKH, A.",
                "An empirical evaluation of wide-area internet bottlenecks.",
                "In Proc. 3rd ACM SIGCOMM Conference on Internet Measurement (Miami Beach, FL, USA, Oct. 2003), pp. 101-114. [2] ALTINEL, M., BORNH ¨OVD, C., KRISHNAMURTHY, S., MOHAN, C., PIRAHESH, H., AND REINWALD, B. Cache tables: Paving the way for an adaptive database cache.",
                "In Proc. of 29th VLDB (Berlin, Germany, 2003), pp. 718-729. [3] ALTINEL, M., LUO, Q., KRISHNAMURTHY, S., MOHAN, C., PIRAHESH, H., LINDSAY, B. G., WOO, H., AND BROWN, L. Dbcache: Database caching for web application servers.",
                "In Proc. 2002 ACM SIGMOD (2002), pp. 612-612. [4] AMIRI, K., PARK, S., TEWARI, R., AND PADMANABHAN, S. Dbproxy: A dynamic data cache for web applications.",
                "In Proc.",
                "IEEE International Conference on Data Engineering (ICDE) (Mar. 2003). [5] BLACK, J. Compare-by-hash: A reasoned analysis.",
                "In Proc. 2006 USENIX Annual Technical Conference (Boston, MA, May 2006), pp. 85-90. [6] BOLOSKY, W. J., CORBIN, S., GOEBEL, D., , AND DOUCEUR, J. R. Single instance storage in windows 2000.",
                "In Proc. 4th USENIX Windows Systems Symposium (Seattle, WA, Aug. 2000), pp. 13-24. [7] BREWER, E. A.",
                "Lessons from giant-scale services.",
                "IEEE Internet Computing 5, 4 (2001), 46-55. [8] BRODER, A., GLASSMAN, S., MANASSE, M., AND ZWEIG, G. Syntactic clustering of the web.",
                "In Proc. 6th International WWW Conference (1997). [9] CECCHET, E., CHANDA, A., ELNIKETY, S., MARGUERITE, J., AND ZWAENEPOEL, W. Performance comparison of middleware architectures for generating dynamic web content.",
                "In Proc.",
                "Fourth ACM/IFIP/USENIX International Middleware Conference (Rio de Janeiro, Brazil, June 2003). [10] CECCHET, E., MARGUERITE, J., AND ZWAENEPOEL, W. C-JDBC: Flexible database clustering middleware.",
                "In Proc. 2004 USENIX Annual Technical Conference (Boston, MA, June 2004). [11] COX, L. P., MURRAY, C. D., AND NOBLE, B. D. Pastiche: Making backup cheap and easy.",
                "In OSDI: Symposium on Operating Systems Design and Implementation (2002). [12] DABEK, F., KAASHOEK, M. F., KARGER, D., MORRIS, R., AND STOICA, I. Wide-area cooperative storage with CFS.",
                "In 18th ACM Symposium on Operating Systems Principles (Banff, Canada, Oct. 2001). [13] DRUSCHEL, P., AND ROWSTRON, A.",
                "PAST: A large-scale, persistent peer-to-peer storage utility.",
                "In HotOS VIII (Schloss Elmau, Germany, May 2001), pp. 75-80. [14] Edge side includes. http://www.esi.org. [15] GAO, L., DAHLIN, M., NAYATE, A., ZHENG, J., AND IYENGAR, A.",
                "Application specific data replication for edge services.",
                "In WWW 03: Proc.",
                "Twelfth International Conference on World Wide Web (2003), pp. 449-460. [16] HEMMINGER, S. Netem - emulating real networks in the lab.",
                "In Proc. 2005 Linux Conference Australia (Canberra, Australia, Apr. 2005). [17] HENSON, V. An analysis of compare-by-hash.",
                "In Proc. 9th Workshop on Hot Topics in Operating Systems (HotOS IX) (May 2003), pp. 13-18. [18] Jmob benchmarks. http://jmob.objectweb.org/. [19] LABRINIDIS, A., AND ROUSSOPOULOS, N. Balancing performance and data freshness in web database servers.",
                "In Proc. 29th VLDB Conference (Sept. 2003). [20] LARSON, P.-A., GOLDSTEIN, J., AND ZHOU, J. Transparent mid-tier database caching in sql server.",
                "In Proc. 2003 ACM SIGMOD (2003), pp. 661-661. [21] MANBER, U.",
                "Finding similar files in a large file system.",
                "In Proc.",
                "USENIX Winter 1994 Technical Conference (San Fransisco, CA, 17-21 1994), pp. 1-10. [22] MANJHI, A., AILAMAKI, A., MAGGS, B. M., MOWRY, T. C., OLSTON, C., AND TOMASIC, A.",
                "Simultaneous scalability and security for data-intensive web applications.",
                "In Proc. 2006 ACM SIGMOD (June 2006), pp. 241-252. [23] MENEZES, A. J., VANSTONE, S. A., AND OORSCHOT, P. C. V. Handbook of Applied Cryptography.",
                "CRC Press, 1996. [24] MILLER, R. B.",
                "Response time in man-computer conversational transactions.",
                "In Proc.",
                "AFIPS Fall Joint Computer Conference (1968), pp. 267-277. [25] MOGUL, J. C., CHAN, Y. M., AND KELLY, T. Design, implementation, and evaluation of duplicate transfer detection in http.",
                "In Proc.",
                "First Symposium on Networked Systems Design and Implementation (San Francisco, CA, Mar. 2004). [26] MUTHITACHAROEN, A., CHEN, B., AND MAZIERES, D. A low-bandwidth network file system.",
                "In Proc. 18th ACM Symposium on Operating Systems Principles (Banff, Canada, Oct. 2001). [27] PFEIFER, D., AND JAKSCHITSCH, H. Method-based caching in multi-tiered server applications.",
                "In Proc.",
                "Fifth International Symposium on Distributed Objects and Applications (Catania, Sicily, Italy, Nov. 2003). [28] PLATTNER, C., AND ALONSO, G. Ganymed: Scalable replication for transactional web applications.",
                "In Proc. 5th ACM/IFIP/USENIX International Conference on Middleware (2004), pp. 155-174. [29] QUINLAN, S., AND DORWARD, S. Venti: A new approach to archival storage.",
                "In Proc.",
                "FAST 2002 Conference on File and Storage Technologies (2002). [30] RABIN, M. Fingerprinting by random polynomials.",
                "In Harvard University Center for Research in Computing Technology Technical Report TR-15-81 (1981). [31] RABINOVICH, M., XIAO, Z., DOUGLIS, F., AND KALMANEK, C. Moving edge side includes to the real edge - the clients.",
                "In Proc. 4th USENIX Symposium on Internet Technologies and Systems (Seattle, WA, Mar. 2003). [32] REESE, G. Database Programming with JDBC and Java, 1st ed.",
                "OReilly, June 1997. [33] RHEA, S., LIANG, K., AND BREWER, E. Value-based web caching.",
                "In Proc.",
                "Twelfth International World Wide Web Conference (May 2003). [34] SIVASUBRAMANIAN, S., ALONSO, G., PIERRE, G., AND VAN STEEN, M. Globedb: Autonomic data replication for web applications.",
                "In WWW 05: Proc. 14th International World-Wide Web conference (May 2005). [35] SPRING, N. T., AND WETHERALL, D. A protocol-independent technique for eliminating redundant network traffic.",
                "In Proc. of ACM SIGCOMM (Aug. 2000). [36] TOLIA, N., HARKES, J., KOZUCH, M., AND SATYANARAYANAN, M. Integrating portable and distributed storage.",
                "In Proc. 3rd USENIX Conference on File and Storage Technologies (San Francisco, CA, Mar. 2004). [37] TOLIA, N., KOZUCH, M., SATYANARAYANAN, M., KARP, B., PERRIG, A., AND BRESSOUD, T. Opportunistic use of content addressable storage for distributed file systems.",
                "In Proc. 2003 USENIX Annual Technical Conference (San Antonio, TX, June 2003), pp. 127-140. [38] YUAN, C., CHEN, Y., AND ZHANG, Z.",
                "Evaluation of edge caching/offloading for dynamic content delivery.",
                "In WWW 03: Proc.",
                "Twelfth International Conference on World Wide Web (2003), pp. 461-471.",
                "WWW 2007 / Track: Performance and Scalability Session: Scalable Systems for Dynamic Content 320"
            ],
            "original_annotated_samples": [
                "DESIGN AND IMPLEMENTATION Ganesh exploits <br>redundancy</br> in the result stream to avoid transmitting result fragments that are already present at the query site.",
                "<br>redundancy</br> can arise naturally in many different ways.",
                "When Ganesh detects <br>redundancy</br>, it suppresses transmission of the corresponding result fragments."
            ],
            "translated_annotated_samples": [
                "DISEÑO E IMPLEMENTACIÓN Ganesh explota la <br>redundancia</br> en el flujo de resultados para evitar transmitir fragmentos de resultados que ya están presentes en el sitio de la consulta.",
                "La <br>redundancia</br> puede surgir de forma natural de muchas maneras diferentes.",
                "Cuando Ganesh detecta <br>redundancia</br>, suprime la transmisión de los fragmentos de resultado correspondientes."
            ],
            "translated_text": "Conservación de la consistencia en el almacenamiento en caché de contenido dinámico de bases de datos∗ Niraj Tolia y M. Satyanarayanan Universidad Carnegie Mellon {ntolia,satya}@cs.cmu.edu RESUMEN Con el creciente uso de contenido web dinámico generado a partir de bases de datos relacionales, las soluciones de almacenamiento en caché tradicionales para mejorar el rendimiento y la latencia son ineficaces. Describimos una capa de middleware llamada Ganesh que reduce el volumen de datos transmitidos sin interpretación semántica de consultas o resultados. Se logra esta reducción mediante el uso de hash criptográficos para detectar similitudes con resultados anteriores. Estos beneficios no requieren ningún compromiso con la semántica de consistencia estricta proporcionada por la base de datos del servidor. Además, Ganesh no requiere modificaciones en aplicaciones, servidores web o servidores de bases de datos, y funciona con aplicaciones y bases de datos de código cerrado. Usando dos puntos de referencia representativos de sitios web dinámicos, las mediciones de nuestro prototipo muestran que puede aumentar el rendimiento de extremo a extremo hasta en un factor de dos para aplicaciones no intensivas en datos y hasta en un factor de diez para las intensivas en datos. Categorías y Descriptores de Asignaturas C.2.4 [Redes de Computadoras-Comunicación]: Sistemas Distribuidos; H.2.4 [Gestión de Bases de Datos]: Términos Generales de Sistemas de Diseño, Rendimiento 1. INTRODUCCIÓN Una fracción creciente del contenido web se genera dinámicamente a partir de bases de datos relacionales en el backend. Incluso cuando el contenido de la base de datos permanece sin cambios, la localidad temporal de acceso no puede ser explotada porque el contenido dinámico no es almacenable en caché por los navegadores web o por servidores de almacenamiento en caché intermedios como los espejos de Akamai. En una arquitectura multinivel, cada solicitud web puede tensionar el enlace WAN entre el servidor web y la base de datos. Esto provoca que la experiencia del usuario sea altamente variable porque no hay almacenamiento en caché para aislar al cliente de cargas repentinas. Los intentos previos de almacenar en caché contenido dinámico de bases de datos generalmente han debilitado la semántica transaccional [3, 4] o han requerido modificaciones en la aplicación [15, 34]. Informamos sobre una nueva solución que toma la forma de una capa intermedia de middleware independiente de la base de datos llamada Ganesh. Ganesh no hace ningún esfuerzo por interpretar semánticamente el contenido de las consultas o sus resultados. En cambio, se basa exclusivamente en el hash criptográfico para detectar similitudes con resultados anteriores. La detección de similitud basada en hash ha sido cada vez más utilizada en sistemas de archivos distribuidos [26, 36, 37] para mejorar el rendimiento en redes de baja capacidad de ancho de banda. Sin embargo, estas técnicas no se han utilizado para bases de datos relacionales. A diferencia de enfoques anteriores que utilizan métodos genéricos para detectar similitud, Ganesh explota la estructura de los resultados de la base de datos relacional para lograr una mejora superior en el rendimiento. Uno se enfrenta al menos a tres desafíos al aplicar la detección de similitud basada en hash a las bases de datos de back-end. Primero, el trabajo previo en este ámbito ha considerado tradicionalmente el contenido de almacenamiento como bolsas de bits no interpretadas y sin estructura interna. Esto permite que las técnicas basadas en hash operen en largas y contiguas secuencias de datos para lograr la máxima efectividad. Por el contrario, las bases de datos relacionales tienen una estructura interna compleja que puede no ser tan propicia para la detección de similitudes basada en hash. Segundo, las bases de datos relacionales tienen restricciones de integridad y consistencia muy estrictas que no deben comprometerse por el uso de técnicas basadas en hash. Tercero, el código fuente de las bases de datos comerciales generalmente no está disponible. Esto contrasta con trabajos anteriores que presumían la disponibilidad del código fuente. Nuestros experimentos muestran que Ganesh, aunque conceptualmente simple, puede mejorar significativamente el rendimiento en anchos de banda representativos del Internet comercial actual. En los modelos de referencia de aplicaciones web multinivel, la mejora en el rendimiento fue de hasta diez veces para cargas de trabajo intensivas en datos. Para cargas de trabajo que no eran intensivas en datos, se observaron mejoras en el rendimiento de hasta el doble. Incluso cuando el ancho de banda no era una limitación, Ganesh tenía un bajo sobrecosto y no afectaba el rendimiento. Nuestros experimentos también confirman que aprovechar la estructura presente en los resultados de la base de datos es crucial para esta mejora en el rendimiento. Antecedentes 2.1 Generación de Contenido Dinámico A medida que la World Wide Web ha crecido, muchos sitios web han descentralizado sus datos y funcionalidades al llevarlos a los extremos de Internet. Hoy en día, los sistemas de comercio electrónico a menudo utilizan una arquitectura de tres niveles que consta de un servidor web de front-end, un servidor de aplicaciones y un servidor de base de datos de back-end. La Figura 1 ilustra esta arquitectura. Los dos primeros niveles se pueden replicar cerca de una concentración de clientes en el borde de Internet. Esto mejora la experiencia del usuario al reducir la latencia de extremo a extremo y disminuir la exposición al congestionamiento del tráfico de la columna vertebral. También puede aumentar la disponibilidad y escalabilidad de los servicios web. El contenido que se genera dinámicamente desde la base de datos del servidor no puede ser almacenado en caché en los dos primeros niveles. Si bien las bases de datos pueden replicarse fácilmente en una LAN, esto es inviable en una WAN debido a la difícil tarea de proporcionar simultáneamente una consistencia sólida, disponibilidad y tolerancia a particiones de red [7]. Como resultado, las bases de datos tienden a ser centralizadas para cumplir con los fuertes requisitos de consistencia de muchas aplicaciones de comercio electrónico como la banca, las finanzas y la venta al por menor en línea [38]. Por lo tanto, la base de datos del back-end suele estar ubicada lejos de muchos conjuntos de nodos de primer y segundo nivel [2]. En ausencia de almacenamiento en caché y replicación, el ancho de banda de la WAN puede convertirse fácilmente en un factor limitante en el rendimiento y la escalabilidad de aplicaciones intensivas en datos. El enfoque de Ganesh en los sistemas basados en hash es la transmisión eficiente de resultados al descubrir similitudes con los resultados de consultas anteriores. Dado que las consultas SQL pueden generar resultados grandes, las técnicas basadas en hash se prestan bien al problema de transferir eficientemente estos grandes resultados a través de enlaces con ancho de banda limitado. El uso de técnicas basadas en hash para reducir el volumen de datos transmitidos ha surgido como un tema común en muchos sistemas de almacenamiento recientes, como se discute en la Sección 8.2. Estas técnicas se basan en algunas suposiciones básicas. Se asume que las funciones hash criptográficas son resistentes a colisiones. En otras palabras, es computacionalmente intratable encontrar dos entradas que se hash a la misma salida. Las funciones también se asumen como unidireccionales; es decir, encontrar una entrada que resulte en una salida específica es computacionalmente inviable. Menezes et al. [23] proporcionan más detalles sobre estas suposiciones. Las suposiciones anteriores permiten a los sistemas basados en hash asumir que no se producen colisiones. Por lo tanto, pueden tratar el hash de un elemento de datos como su identificador único. Una colección de elementos de datos se convierte efectivamente en direccionable por contenido, permitiendo que un hash pequeño funcione como una palabra de código para un elemento de datos mucho más grande en almacenamiento permanente o transmisión en red. La suposición de que las colisiones son tan raras que prácticamente no existen ha sido cuestionada recientemente [17]. Sin embargo, como explicó Black [5], creemos que estos problemas no son una preocupación para Ganesh. Toda comunicación es entre partes confiables del sistema y un adversario no tiene forma de obligar a Ganesh a aceptar datos inválidos. Además, Ganesh no depende críticamente de ninguna función hash específica. Si bien actualmente usamos SHA-1, reemplazarlo con una función hash diferente sería sencillo. No habría impacto en el rendimiento con funciones hash más fuertes (por ejemplo, SHA256) solo añade unos pocos bytes adicionales y los hashes generados siguen siendo órdenes de magnitud más pequeños que los elementos de datos que representan. No es necesario volver a almacenar permanentemente ya que Ganesh solo utiliza el hash en datos volátiles. 3. DISEÑO E IMPLEMENTACIÓN Ganesh explota la <br>redundancia</br> en el flujo de resultados para evitar transmitir fragmentos de resultados que ya están presentes en el sitio de la consulta. La <br>redundancia</br> puede surgir de forma natural de muchas maneras diferentes. Por ejemplo, una consulta repetida después de un cierto intervalo puede devolver un resultado diferente debido a actualizaciones en la base de datos; sin embargo, puede haber una significativa similitud entre los dos resultados. Como otro ejemplo, un usuario que está refinando una búsqueda puede generar una secuencia de consultas con resultados superpuestos. Cuando Ganesh detecta <br>redundancia</br>, suprime la transmisión de los fragmentos de resultado correspondientes. En cambio, transmite un resumen mucho más pequeño de esos fragmentos y permite que el sitio de consulta reconstruya el resultado a través de la búsqueda de hash en una caché de resultados anteriores. De hecho, Ganesh utiliza la computación en los bordes para reducir la comunicación por Internet. Nuestra descripción de Ganesh se centra en cuatro aspectos. Primero explicamos nuestro enfoque para detectar similitud en los resultados de la consulta. A continuación, discutimos cómo la arquitectura Ganesh es completamente invisible para todos los componentes de un sistema de múltiples niveles. Luego describimos el enfoque basado en proxy de Ganesh y el flujo de datos para detectar similitudes. 3.1 Detectar similitud Una de las decisiones clave de diseño en Ganesh es cómo se detecta la similitud. Hay muchas formas potenciales de descomponer un resultado en fragmentos.  I the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the thees I,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,, Encontrar esta descomposición óptima es un problema difícil debido al amplio espacio de posibilidades y porque la elección óptima depende de muchos factores, como el contenido del resultado de las consultas, el historial de resultados recientes y el algoritmo de gestión de caché. Cuando un objeto es opaco, el uso de huellas digitales de Rabin [8, 30] para detectar datos comunes entre dos objetos ha sido demostrado con éxito en el pasado por sistemas como LBFS [26] y CASPER [37]. El fingerprinting de Rabin utiliza una ventana deslizante sobre los datos para calcular un hash rodante. Suponiendo que la función hash está distribuida uniformemente, un límite de fragmento se define cuando los bits de orden inferior del valor hash son iguales a algún valor predeterminado. El número de bits de orden inferior utilizados define el tamaño promedio del fragmento. Estos fragmentos subdivididos del objeto se convierten en la unidad de comparación para detectar similitudes entre diferentes objetos. Dado que las ubicaciones de los límites encontrados mediante el uso de las huellas de Rabin están determinadas de manera estocástica, generalmente no logran alinearse con ninguna propiedad estructural de los datos subyacentes. Por lo tanto, el algoritmo maneja bien las actualizaciones en su lugar, inserciones y eliminaciones. Sin embargo, tiene un rendimiento deficiente en presencia de cualquier reordenamiento de datos. La Figura 2 muestra un ejemplo donde dos resultados, A y B, que constan de tres filas, tienen los mismos datos pero diferentes atributos de ordenamiento. En el caso extremo, la huella digital de Rabin podría no ser capaz de encontrar datos similares debido a la forma en que detecta los límites de los fragmentos. Afortunadamente, Ganesh puede utilizar conocimientos específicos del dominio para una detección de límites más precisa. La información que explotamos es que el resultado de una consulta refleja la estructura de una base de datos relacional donde todos los datos están organizados en tablas y filas. Por lo tanto, es sencillo verificar la similitud con resultados anteriores en dos niveles de granularidad: primero el resultado completo y luego las filas individuales. El final de una fila en un resultado sirve como un límite natural de fragmento. Es importante tener en cuenta que el uso de la estructura tabular en los resultados solo implica una interpretación superficial de los datos. Ganesh no realiza ninguna interpretación semántica más profunda, como comprender tipos de datos, esquemas de resultados o restricciones de integridad. Ajustar la huella digital de Rabin para una carga de trabajo también puede ser difícil. Si el tamaño promedio de los fragmentos es demasiado grande, los fragmentos pueden abarcar varias filas de resultados. Sin embargo, seleccionar un tamaño de fragmento promedio más pequeño aumenta la cantidad de metadatos necesarios para describir los resultados. Esto, a su vez, disminuiría los ahorros obtenidos mediante su uso. El fingerprinting de Rabin también requiere dos pasadas computacionalmente costosas sobre los datos: una vez para determinar los límites de los fragmentos y otra vez para generar hashes criptográficos para los fragmentos. Ganesh solo necesita un único pase para la generación de hash, ya que los límites de los fragmentos son proporcionados por la estructura natural de los datos. La comparación de rendimiento en la Sección 6 muestra que el algoritmo basado en filas de Ganesh supera al fingerprinting de Rabin. Dado que trabajos anteriores ya han demostrado que la huella digital de Rabin funciona mejor que gzip [26], no comparamos a Ganesh con algoritmos de compresión en este artículo. 3.2 Transparencia El factor clave que influyó en nuestro diseño fue la necesidad de que Ganesh fuera completamente transparente para todos los componentes de un sistema típico de comercio electrónico: servidores web, servidores de aplicaciones y servidores de bases de datos. Sin esto, Ganesh tiene pocas posibilidades de tener un impacto significativo en el mundo real. Requerir modificaciones en cualquiera de los componentes mencionados aumentaría la barrera de entrada de Ganesh en un sistema existente, y por lo tanto reduciría sus posibilidades de adopción. Preservar la transparencia se simplifica por el hecho de que Ganesh es simplemente una mejora de rendimiento, no una mejora de funcionalidad o usabilidad. Elegimos la interposición de agentes como enfoque arquitectónico para lograr nuestro objetivo. Este enfoque se basa en la existencia de una interfaz de programación compacta que ya es ampliamente utilizada por el software objetivo. También se basa en un mecanismo para agregar fácilmente nuevo código sin interrumpir la estructura de módulos existente. Estas condiciones se cumplen fácilmente en nuestro contexto debido a la popularidad de Java como el lenguaje de programación para sistemas de comercio electrónico. La API de Conectividad de Base de Datos de Java (JDBC) [32] permite a las aplicaciones de Java acceder a una amplia variedad de bases de datos e incluso a otros repositorios de datos tabulares como archivos planos. El acceso a estas fuentes de datos es proporcionado por controladores JDBC que traducen entre la API JDBC y el mecanismo de comunicación de la base de datos. La figura 3(a) muestra cómo se utiliza típicamente JDBC en una aplicación. Dado que la interfaz JDBC está estandarizada, se puede sustituir un controlador JDBC por otro sin necesidad de de modificar la aplicación. El controlador JDBC se convierte así en el módulo natural para aprovechar la interposición de código. Como se muestra en la Figura 3(b), el controlador JDBC nativo es reemplazado por un controlador JDBC Ganesh que presenta la misma interfaz estandarizada. El controlador Ganesh mantiene una caché en memoria de fragmentos de resultados de consultas anteriores y realiza el reensamblaje de resultados. En la base de datos, agregamos un nuevo proceso llamado el proxy Ganesh. Este proxy, que puede ser compartido por múltiples nodos front-end, consta de dos partes: código para detectar similitud en fragmentos de resultados y el controlador JDBC nativo original que se comunica con la base de datos. El uso de un proxy en la base de datos hace que Ganesh sea independiente de la base de datos y simplifica la creación de prototipos y experimentación. Ganesh es capaz de trabajar con una amplia gama de bases de datos y aplicaciones, sin necesidad de realizar modificaciones en ninguna de ellas. 3.3 Caché basada en proxy El controlador JDBC nativo mostrado en la Figura 3(a) es un componente de código ligero suministrado por el proveedor de la base de datos. Su función principal es mediar la comunicación entre la aplicación y la base de datos remota. Reenvía consultas, almacena resultados completos y responde a solicitudes de la aplicación para ver partes de los resultados. El controlador JDBC de Ganesh mostrado en la Figura 3(b) presenta a la aplicación una interfaz idéntica a la proporcionada por el controlador nativo. Proporciona la capacidad de reconstruir resultados a partir de descripciones compactas basadas en hash enviadas por el proxy. Para realizar esta reconstrucción, el controlador mantiene una caché en memoria de los resultados recibidos recientemente. Esta caché solo se utiliza como fuente de fragmentos de resultados en la reconstrucción de resultados. El conductor Ganesh o el proxy no intentan rastrear las actualizaciones de la base de datos. La falta de consistencia en la caché no afecta a la corrección, ya que la descripción de los resultados siempre se obtiene del proxy; en el peor de los casos, no habrá beneficio de rendimiento al usar Ganesh. Los datos obsoletos simplemente se eliminarán de la caché con el tiempo. El proxy de Ganesh accede a la base de datos a través del controlador JDBC nativo, que permanece sin cambios entre las Figuras 3(a) y (b). La base de datos está completamente ajena a la existencia del proxy. El proxy no examina ninguna consulta recibida del controlador Ganesh, sino que las pasa al controlador nativo. En cambio, el proxy es responsable de inspeccionar la salida de la base de datos recibida del controlador nativo, detectar resultados similares y generar codificaciones basadas en hash de estos resultados siempre que se encuentre suficiente similitud. Si bien esta arquitectura no disminuye la carga en una base de datos, como se mencionó anteriormente en la Sección 2.1, es mucho más fácil replicar bases de datos para escalabilidad en una LAN que en una WAN. Para generar una codificación basada en hash, el proxy debe estar al tanto de qué fragmentos de resultados están disponibles en la caché de controladores de Ganesh. Un enfoque es ser optimista y asumir que todos los fragmentos de resultados están disponibles. Esto resultará en la transmisión inicial más pequeña posible de un resultado. Sin embargo, en casos donde hay poca superposición con resultados anteriores, el controlador Ganesh tendrá que realizar muchas llamadas al proxy durante la reconstrucción para recuperar fragmentos de resultados faltantes. Para evitar esta situación, el proxy sigue de manera flexible el estado de la caché de controladores de Ganesh. Dado que ambos componentes están bajo nuestro control, es relativamente sencillo hacer esto sin recurrir a técnicas de caja gris o comunicación explícita para mantener la coherencia de la caché. En cambio, el proxy simula el algoritmo de gestión de caché de controladores de Ganesh y lo utiliza para mantener una lista de hashes para los cuales es probable que el controlador de Ganesh posea los fragmentos de resultado. En caso de desviación de seguimiento, no habrá pérdida de corrección, pero habrá retrasos adicionales en el viaje de ida y vuelta para recuperar los fragmentos faltantes. Si el cliente detecta la pérdida de sincronización con el proxy, puede pedirle al proxy que restablezca el estado compartido entre ellos. También hay que tener en cuenta que el proxy no necesita guardar los fragmentos de resultado en sí, solo sus hashes. Esto permite que el proxy siga siendo escalable incluso cuando es compartido por muchos nodos front-end. El proxy Ganesh recibe la salida de la base de datos como objetos Java del controlador JDBC nativo. Examina esta salida para ver si está presente un objeto Java del tipo ResultSet. La interfaz JDBC utiliza este tipo de dato para almacenar los resultados de las consultas a la base de datos. Si se encuentra un objeto ResultSet, se reduce como se discute a continuación. Todos los demás objetos de Java se pasan sin modificar. Como se discute en la Sección 3.1, el proxy utiliza los límites de fila definidos en el ResultSet para dividirlo en fragmentos que consisten en filas de resultado individuales. Todos los objetos ResultSet se convierten en objetos de un nuevo tipo llamado RecipeResultSet. Utilizamos el término receta para esta descripción compacta de un resultado de base de datos debido a su similitud con una receta de archivo en el sistema de archivos CASPER [37]. La conversión reemplaza cada fragmento de resultado que probablemente esté presente en la caché de controladores de Ganesh por un hash SHA-1 de ese fragmento. Los fragmentos de resultados previamente no vistos se conservan textualmente. El proxy también retiene los hashes de los nuevos fragmentos de resultados, ya que estarán presentes en la caché de los controladores en el futuro. Ten en cuenta que el proxy solo almacena en caché los hashes de los fragmentos de resultados y no almacena en caché las recetas. El proxy construye un RecipeResultSet verificando la similitud en todo el resultado y luego a nivel de fila. Si se predice que todo el resultado estará presente en la caché de los controladores de Ganesh, el RecipeResultSet será simplemente un único hash de todo el resultado. De lo contrario, contiene hashes para aquellas filas que se predice que están presentes en esa caché; todas las demás filas se conservan textualmente. Si el proxy estima un ahorro de espacio general, transmitirá el RecipeResultSet. De lo contrario, se transmite el ResultSet original. Los objetos RecipeResultSet son transformados de vuelta en objetos ResultSet por el controlador Ganesh. La Figura 4 ilustra el manejo de ResultSet en ambos extremos. Cada hash SHA-1 encontrado en un RecipeResultSet se busca en la caché local de fragmentos de resultados. En caso de acierto, el hash es reemplazado por el fragmento correspondiente. En caso de error, el conductor contacta al proxy de Ganesh para recuperar el fragmento. Todos los fragmentos de resultados previamente no vistos que fueron retenidos textualmente por el proxy se hasheado y se han añadido a la caché de resultados. Debería haber muy pocos fallos si el proxy ha seguido con precisión el estado de la caché de controladores de Ganesh. Una optimización futura sería agrupar la obtención de fragmentos faltantes. Esto sería valioso cuando hay muchos pequeños fragmentos faltantes en una WAN de alta latencia. Una vez que la transformación esté completa, el objeto ResultSet completamente reconstruido se pasa a la aplicación. 4. VALIDACIÓN EXPERIMENTAL Tres preguntas surgen de los objetivos y diseño de Ganesh: • Primero, ¿se puede mejorar significativamente el rendimiento al explotar la similitud entre los resultados de la base de datos? Detalles del conjunto de datos de referencia 500,000 usuarios, 12,000 historias BBOARD 2.0 GB 3,298,000 comentarios SUBASTA 1.3 GB 1,000,000 usuarios, 34,000 elementos Tabla 1: Detalles del conjunto de datos de referencia • En segundo lugar, ¿qué tan importante es la detección de similitud estructural de Ganesh en comparación con la detección de similitud de la huella digital de Rabin? • En tercer lugar, ¿es aceptable la sobrecarga del diseño basado en proxy? Nuestra evaluación responde a estas preguntas a través de experimentos controlados con el prototipo Ganesh. Esta sección describe los puntos de referencia utilizados, nuestro procedimiento de evaluación y la configuración experimental. Los resultados de los experimentos se presentan en las Secciones 5, 6 y 7. 4.1 Puntos de referencia Nuestra evaluación se basa en dos puntos de referencia [18] que han sido ampliamente utilizados por otros investigadores para evaluar varios aspectos de arquitecturas multi-tier [27] y de comercio electrónico [9]. El primer punto de referencia, BBOARD, está modelado según Slashdot, un sitio de noticias orientado a la tecnología. El segundo punto de referencia, AUCTION, está modelado según eBay, un sitio de subastas en línea. En ambos puntos de referencia, la mayoría del contenido se genera dinámicamente a partir de la información almacenada en una base de datos. Los detalles de los conjuntos de datos utilizados se pueden encontrar en la Tabla 1. 4.1.1 El Benchmark BBOARD El benchmark BBOARD, también conocido como RUBBoS [18], modela Slashdot, un popular sitio web orientado a la tecnología. Slashdot recopila enlaces a noticias y otros temas de interés encontrados en otros lugares de la web. El sitio también funciona como un tablón de anuncios al permitir a los usuarios comentar en las historias publicadas en forma de conversación en hilos. No es raro que una historia recopile cientos de comentarios en cuestión de horas. El benchmark BBOARD es similar al sitio y modela las actividades de un usuario, incluyendo operaciones de solo lectura como navegar por las historias del día, explorar categorías de historias y ver comentarios, así como operaciones de escritura como registro de nuevos usuarios, agregar y moderar comentarios, y enviar historias. El benchmark consiste en tres fases diferentes: una fase de calentamiento corta, una fase de ejecución que representa el cuerpo principal de la carga de trabajo, y una fase de enfriamiento corta. En este documento solo informamos sobre los resultados de la fase de ejecución. La fase de calentamiento es importante para establecer el estado del sistema dinámico, pero las mediciones de esa fase no son significativas para nuestra evaluación. La fase de enfriamiento es únicamente para permitir que el punto de referencia se apague. Las fases de calentamiento, ejercicio y enfriamiento son de 2, 15 y 2 minutos respectivamente. El número de clientes simulados fue de 400, 800, 1200 y 1600. El punto de referencia está disponible en una versión de Java Servlets y PHP y tiene diferentes conjuntos de datos; evaluamos a Ganesh utilizando la versión de Java Servlets y el conjunto de datos Expandido. El benchmark BBOARD define dos cargas de trabajo diferentes. El primero, la mezcla de Autoría, consiste en un 70% de operaciones de solo lectura y un 30% de operaciones de lectura y escritura. El segundo, la mezcla de navegación, contiene solo operaciones de solo lectura y no actualiza la base de datos. 4.1.2 El Benchmark de SUBASTA El benchmark de SUBASTA, también conocido como RUBiS [18], modela eBay, el sitio de subastas en línea. El sitio web de eBay se utiliza para comprar y vender artículos a través de un formato de subasta. Las principales actividades de un usuario incluyen navegar, vender o pujar por artículos. Modelando las actividades en este sitio, este punto de referencia incluye actividades de solo lectura como navegar por artículos por categoría y por región, así como actividades de lectura-escritura como pujar por artículos, comprar y vender artículos, y dejar comentarios. Al igual que con BBOARD, el benchmark consiste en tres fases diferentes. Las fases de calentamiento, ejecución y enfriamiento para este experimento son de 1.5, 15 y 1 minutos respectivamente. Probamos Ganesh con cuatro configuraciones de clientes donde el número de clientes de prueba se estableció en 400, 800, 1200 y 1600. El punto de referencia está disponible en una versión de Enterprise Java Bean (EJB), Java Servlets y PHP y tiene diferentes conjuntos de datos; evaluamos Ganesh con la versión de Java Servlets y el conjunto de datos Expandido. El benchmark de SUBASTA define dos cargas de trabajo diferentes. El primero, la mezcla de Ofertas, consiste en un 70% de operaciones de solo lectura y un 30% de operaciones de lectura-escritura. El segundo, la mezcla de navegación, contiene solo operaciones de solo lectura y no actualiza la base de datos. 4.2 Procedimiento Experimental Ambos benchmarks involucran una carga de trabajo sintética de clientes accediendo a un servidor web. El número de clientes emulados es un parámetro experimental. Cada cliente emulado ejecuta una instancia del benchmark en su propio hilo, utilizando una matriz para hacer la transición entre diferentes estados del benchmark. La matriz define un modelo estocástico con probabilidades de transición entre los diferentes estados que representan las acciones típicas de los usuarios. Un ejemplo de transición es un usuario iniciando sesión en el sistema de SUBASTA y luego decidiendo si publicar un artículo en venta o pujar en subastas activas. Cada cliente también modela el tiempo de pensamiento del usuario entre las solicitudes. El tiempo de pensamiento se modela como una distribución exponencial con una media de 7 segundos. Evaluamos a Ganesh a lo largo de dos ejes: número de clientes y ancho de banda de la WAN. Las cargas más altas son especialmente útiles para comprender el rendimiento de Ganesh cuando la CPU o el disco del servidor de base de datos o del proxy son el factor limitante. Un estudio previo ha demostrado que aproximadamente el 50% de los cuellos de botella de Internet de gran área observados tenían un ancho de banda disponible inferior a 10 Mb/s [1]. Basándonos en este trabajo, enfocamos nuestra evaluación en el ancho de banda de la WAN de 5 Mb/s con una latencia de ida y vuelta de 66 ms, representativa de rutas de red severamente restringidas, y 20 Mb/s con una latencia de ida y vuelta de 33 ms, representativa de una ruta de red moderadamente restringida. También informamos sobre el rendimiento de Ganesh a 100 Mb/s sin agregar latencia de ida y vuelta. Este ancho de banda, representativo de una red sin restricciones, es especialmente útil para revelar cualquier sobrecarga potencial de Ganesh en situaciones donde el ancho de banda de la WAN no es el factor limitante. Para cada combinación de número de clientes y ancho de banda de WAN, medimos los resultados de las dos configuraciones enumeradas a continuación: • Nativa: Esta configuración corresponde a la Figura 3(a). El nativo evita la sobrecarga de Ganesh al usar un proxy y realizar la serialización de objetos Java. • Ganesh: Esta configuración corresponde a la Figura 3(b). Para un número dado de clientes y ancho de banda de WAN, comparar estos resultados con los resultados nativos correspondientes proporciona el beneficio de rendimiento debido al sistema de middleware Ganesh. La métrica utilizada para cuantificar la mejora en el rendimiento es el número de solicitudes de clientes que pueden ser atendidas por segundo. La métrica utilizada para cuantificar el rendimiento de Ganesh es el tiempo promedio de respuesta para una solicitud de cliente. Para todos los experimentos, el controlador Ganesh utilizado por el servidor de aplicaciones usó un tamaño de caché de 100,000 elementos. El proxy fue efectivo en rastrear el estado de la caché de los controladores Ganesh; para todos nuestros experimentos, la tasa de fallos en el controlador nunca superó el 0.7%. 4.3 Configuración Experimental La configuración experimental utilizada para las pruebas se puede ver en la Figura 5. Todas las máquinas eran Pentium 4 de 3.2 GHz (con HyperThreading habilitado). Con la excepción del servidor de base de datos, todas las máquinas tenían 2 GB de SDRAM y ejecutaban la distribución de Linux Fedora Core. El servidor de la base de datos tenía 4 GB de SDRAM. Utilizamos Apache Tomcat como tanto el servidor de aplicaciones que alojaba los Servlets de Java como el servidor web. Ambos benchmarks utilizaron Java Servlets para generar el contenido dinámico. El servidor de la base de datos utilizó la base de datos de código abierto MySQL. Para los controladores JDBC nativos, utilizamos los controladores Connector/J proporcionados por MySQL. El servidor de aplicaciones utilizaba la Máquina Virtual de Java de Sun como entorno de ejecución para los Servlets de Java. La herramienta sysstat se utilizó para monitorear la utilización de la CPU, red, disco y memoria en todas las máquinas. Las máquinas estaban conectadas por una red Ethernet gigabit conmutada. Como se muestra en la Figura 5, el servidor web y de aplicación de front-end fue separado del servidor de proxy y base de datos por un enrutador NetEm [16]. Este enrutador nos permitió controlar la configuración de ancho de banda y latencia en la red. El enrutador NetEm es un PC estándar con dos tarjetas de red que ejecuta el software de Control de Tráfico de Linux y Emulación de Red. Las restricciones de ancho de banda y latencia solo se aplicaron al enlace entre el servidor de aplicaciones y la base de datos para el caso nativo y entre el servidor de aplicaciones y el proxy para el caso de Ganesh. No hay comunicación entre el servidor de aplicaciones y la base de datos con Ganesh, ya que todos los datos fluyen a través del proxy. Como nuestro enfoque estaba en el enlace WAN entre el servidor de aplicaciones y la base de datos, no hubo restricciones en el enlace entre los clientes de prueba simulados y el servidor web. 5. DESEMPEÑO Y TIEMPO DE RESPUESTA En esta sección, abordamos la primera pregunta planteada en la Sección 4: ¿Se puede mejorar significativamente el rendimiento explotando la similitud entre los resultados de la base de datos? Para responder a esta pregunta, utilizamos los resultados de los benchmarks BBOARD y AUCTION. Utilizamos dos métricas para cuantificar la mejora en el rendimiento obtenible a través del uso de Ganesh: el throughput, desde la perspectiva del servidor web, y el tiempo de respuesta promedio, desde la perspectiva del cliente. El rendimiento se mide en términos del número de solicitudes de clientes que pueden ser atendidas por segundo. Los resultados y análisis de BBOARD 5.1 Figuras 6 (a) y (b) presentan el número promedio de solicitudes atendidas por segundo y el tiempo de respuesta promedio para estas solicitudes tal como lo perciben los clientes para la Mezcla de Autoría de BBOARD. Como muestra la Figura 6 (a), Native satura fácilmente el enlace de 5 Mb/s. Con 400 clientes, la solución nativa entrega 29 solicitudes/segundo con un tiempo de respuesta promedio de 8.3 segundos. La capacidad de procesamiento de los clientes disminuye con un aumento en los clientes de prueba, ya que los clientes se agotan debido a la congestión en el servidor de aplicaciones. Los estudios de usabilidad han demostrado que los tiempos de respuesta superiores a 10 segundos hacen que el usuario pase a 1. Dado que Java carece de un operador sizeof(), los cachés de Java limitan su tamaño en función del número de objetos. El tamaño de los volcados de caché tomados al final de los experimentos nunca superó los 212 MB. WWW 2007 / Pista: Rendimiento y Escalabilidad Sesión: Sistemas Escalables para Contenido Dinámico 315 0 50 100 150 200 250 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Solicitudes de Clientes de Prueba por Segundo Nativo Ganesh 0.001 0.01 0.1 1 10 100 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Tiempo Promedio de Respuesta de Clientes de Prueba Nativo Ganesh Nota Escala Logarítmica (a) Rendimiento: Mezcla de Autoría (b) Tiempo de Respuesta: Mezcla de Autoría 0 50 100 150 200 250 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Solicitudes de Clientes de Prueba por Segundo Nativo Ganesh 0.001 0.01 0.1 1 10 100 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Tiempo Promedio de Respuesta de Clientes de Prueba Nativo Ganesh Nota Escala Logarítmica (c) Rendimiento: Mezcla de Navegación (d) Tiempo de Respuesta: Mezcla de Navegación Promedio de tres pruebas. La desviación estándar máxima para el rendimiento y el tiempo de respuesta fue del 9.8% y 11.9% de la media correspondiente. Figura 6: BBOARD Benchmark - Rendimiento y Tiempo de Respuesta Promedio de otras tareas [24]. Basándose en estos números, aumentar el número de clientes de prueba hace que el sistema Nativo sea inutilizable. Ganesh a 5 Mb/s, sin embargo, ofrece una mejora doble con 400 clientes de prueba y una mejora quintuple con 1200 clientes. El rendimiento de Ganesh disminuye ligeramente a 1200 y 1600 clientes debido a que la red está saturada. En comparación con Native, la Figura 6 (b) muestra que los tiempos de respuesta de Ganesh son considerablemente más bajos con tiempos de respuesta de menos de un segundo con 400 clientes. La Figura 6 (a) también muestra que para 400 y 800 clientes de prueba, Ganesh a 5 Mb/s tiene el mismo rendimiento y tiempo de respuesta promedio que Native a 20 Mb/s. Solo con 1200 y 1600 clientes, Native a 20 Mb/s ofrece un rendimiento mayor que Ganesh a 5 Mb/s. Al comparar tanto a Ganesh como a Native a 20 Mb/s, vemos que Ganesh ya no está limitado por el ancho de banda y ofrece hasta una mejora del doble sobre Native con 1600 clientes de prueba. Como Ganesh no satura la red con configuraciones de cliente de prueba más altas, con 1600 clientes de prueba, su tiempo de respuesta promedio es de 0.1 segundos en lugar de los 7.7 segundos de Natives. Como era de esperar, no hay ganancias visibles de Ganesh en el ancho de banda más alto de 100 Mb/s donde la red ya no es el cuello de botella. Sin embargo, Ganesh sigue monitoreando a Native en cuanto a rendimiento. Las Figuras 6 (c) y (d) presentan el número promedio de solicitudes atendidas por segundo y el tiempo de respuesta promedio para estas solicitudes tal como lo perciben los clientes para la Mezcla de Navegación de BBOARDs. Independientemente de la configuración del cliente de prueba, la Figura 6 (c) muestra que el rendimiento de los Nativos a 5 Mb/s está limitado a 10 reqs/seg. Ganesh a 5 Mb/s con 400 clientes de prueba, ofrece un aumento de más de seis veces en el rendimiento. La mejora aumenta a más de once veces a 800 clientes de prueba antes de que Ganesh sature la red. Además, la Figura 6 (d) muestra que el tiempo de respuesta promedio de los Nativos de 35 segundos con 400 clientes de prueba hace que el sistema sea inutilizable. Estos altos tiempos de respuesta aumentan aún más con la adición de clientes de prueba. Incluso con la configuración del cliente de prueba de 1600, Ganesh ofrece un tiempo de respuesta promedio aceptable de 8.2 segundos. Debido a la naturaleza intensiva en datos de la mezcla de navegación, Ganesh a 5 Mb/s sorprendentemente tiene un rendimiento mucho mejor que Native a 20 Mb/s. Además, como se muestra en la Figura 6 (d), si bien el tiempo de respuesta promedio para Native a 20 Mb/s es aceptable con 400 clientes de prueba, resulta inutilizable con 800 clientes de prueba, con un tiempo de respuesta promedio de 15.8 segundos. Al igual que en el caso de 5 Mb/s, este tiempo de respuesta aumenta con la adición de clientes de prueba adicionales. Ganesh a 20 Mb/s y tanto Native como Ganesh a 100 Mb/s no tienen limitaciones de ancho de banda. Sin embargo, el rendimiento se estanca después de 1200 clientes de prueba debido a que la CPU de la base de datos está saturada. 5.1.3 Variante de filtro Nos sorprendió el rendimiento nativo del benchmark BBOARD. A una velocidad de banda ancha de 5 Mb/s, el rendimiento nativo fue más bajo de lo que esperábamos. Resultó que el código de referencia que muestra historias leía todos los comentarios asociados con la historia en particular de la base de datos y solo entonces realizaba un postprocesamiento para seleccionar los comentarios que se mostrarían. Si bien este es exactamente el comportamiento de SlashCode, la base de código detrás del sitio web de Slashdot, decidimos modificar la prueba de rendimiento para realizar cierto prefiltrado en la base de datos. Este benchmark modificado, llamado el Filtro de Variantes, modela a un desarrollador que aplica optimizaciones a nivel de SQL para transferir menos datos. En aras de la brevedad, solo resumimos brevemente los resultados de la mezcla de autores. Para la mezcla de Autoría, con 800 clientes de prueba a 5 Mb/s, la Figura 7 (a) muestra que el rendimiento de Natives aumenta un 85% en comparación con el punto de referencia original, mientras que la mejora de Ganesh es menor, del 15%. El rendimiento de los servidores disminuye por encima de los 800 clientes, ya que los clientes de prueba se agotan debido a los altos tiempos de respuesta. La ganancia más significativa para Native se observa a 20 Mb/s. En 1600 clientes de prueba, en comparación con el punto de referencia original, Native experimenta una mejora del 73% en el rendimiento y una reducción del 77% en el tiempo de respuesta promedio. Mientras WWW 2007 / Pista: Rendimiento y Escalabilidad Sesión: Sistemas Escalables para Contenido Dinámico 316 0 50 100 150 200 250 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Clientes de Prueba Solicitudes/seg Nativo Ganesh 0.001 0.01 0.1 1 10 100 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Clientes de Prueba Tiempo de Resp. Promedio (seg) Nativo Ganesh Nota Escala Logarítmica (a) Rendimiento: Mezcla de Autoría (b) Tiempo de Respuesta: Mezcla de Autoría Promedio de tres pruebas. La desviación estándar máxima para el rendimiento y el tiempo de respuesta fue del 7.2% y del 11.5% de la media correspondiente. Figura 7: BBOARD Benchmark - Variante de filtro - Rendimiento y Tiempo de Respuesta Promedio Ganesh no observa ninguna mejora en comparación con el original, aún procesa un 19% más de solicitudes/seg que Native. Por lo tanto, aunque las optimizaciones fueron más útiles para Native, Ganesh todavía ofrece una mejora en el rendimiento. 5.2 Resultados y Análisis de la SUBASTA 5.2.1 Figuras de la Mezcla de Ofertas Los gráficos 8 (a) y (b) presentan el número promedio de solicitudes atendidas por segundo y el tiempo de respuesta promedio para estas solicitudes tal como son percibidas por los clientes para la Mezcla de Ofertas de las SUBASTAS. Como se mencionó anteriormente, la mezcla de ofertas consiste en una combinación de operaciones de lectura y escritura. El benchmark AUCTION no es tan intensivo en datos como BBOARD. Por lo tanto, la mayoría de las ganancias se observan en el ancho de banda más bajo de 5 Mb/s. La figura 8 (a) muestra que el aumento en el rendimiento debido a Ganesh varía desde un 8% con 400 clientes de prueba hasta un 18% con 1600 clientes de prueba. Como se observa en la Figura 8 (b), los tiempos de respuesta promedio para Ganesh son significativamente más bajos que los de Native, con una disminución del 84% a 800 clientes de prueba y del 88% a 1600 clientes de prueba. La Figura 8 (a) también muestra que con un aumento cuádruple del ancho de banda de 5 Mb/s a 20 Mb/s, Native ya no está limitado por el ancho de banda y no hay diferencia de rendimiento entre Ganesh y Native. Con las configuraciones de cliente de prueba más altas, observamos que el ancho de banda utilizado por Ganesh era menor que el de Nativo. Ganesh podría seguir siendo útil en estos escenarios no restringidos si se compra ancho de banda de forma medible. Se observan resultados similares para el escenario de 100 Mb/s. 5.2.2 Mezcla de Navegación Para la Mezcla de Navegación de SUBASTAS, las Figuras 8 (c) y (d) presentan el número promedio de solicitudes atendidas por segundo y el tiempo promedio de respuesta para estas solicitudes tal como lo perciben los clientes. Una vez más, la mayoría de las ganancias se observan en anchos de banda más bajos. A 5 Mb/s, Native y Ganesh ofrecen un rendimiento y tiempos de respuesta similares con 400 clientes de prueba. Mientras que el rendimiento para ambos permanece igual en 800 clientes de prueba, la Figura 8 (d) muestra que el tiempo de respuesta promedio de Ganesh es un 62% menor que el de Native. El servidor satura el enlace con 800 clientes y agregar clientes de prueba adicionales solo aumenta el tiempo promedio de respuesta. Ganesh, independientemente de la configuración del cliente de prueba, no tiene restricciones de ancho de banda y mantiene el mismo tiempo de respuesta. A 1600 clientes de prueba, la Figura 8 (c) muestra que el rendimiento de Ganesh es casi el doble que el de Nativo. En los anchos de banda más altos de 20 y 100 Mb/s, ni Ganesh ni Native tienen limitaciones de ancho de banda y ofrecen un rendimiento y tiempos de respuesta equivalentes. Referencia original. Tamaño Ganesh Tamaño Rabin Tamaño SelectSort1 223.6 MB 5.4 MB 219.3 MB SelectSort2 223.6 MB 5.4 MB 223.6 MB Tabla 2: Microbenchmarks de similitud 6. SIMILITUD ESTRUCTURAL VS. SIMILITUD DE RABIN En esta sección, abordamos la segunda pregunta planteada en la Sección 4: ¿Qué tan importante es la detección de similitud estructural de Ganesh en comparación con la detección de similitud basada en la huella digital de Rabin? Para responder a esta pregunta, utilizamos microbenchmarks y los benchmarks BBOARD y AUCTION. Dado que Ganesh siempre tuvo un mejor rendimiento que Rabin en la huella dactilar, aquí presentamos solo un subconjunto de los resultados en aras de la brevedad. 6.1 Microbenchmarks Dos microbenchmarks muestran un ejemplo de los efectos de la reordenación de datos en el algoritmo de huella dactilar de Rabin. En el primer microbenchmark, SelectSort1, una consulta con un orden de clasificación especificado selecciona 223.6 MB de datos distribuidos en aproximadamente 280 K filas. La consulta se repite entonces con un atributo de ordenación diferente. Si bien se devuelve el mismo número de filas y los mismos datos, el orden de las filas es diferente. En un escenario así, se esperaría detectar una gran cantidad de similitud entre ambos resultados. Como muestra la Tabla 2, el algoritmo basado en filas de Ganesh logra una reducción del 97.6%, mientras que el algoritmo de huella digital de Rabin, con el parámetro de tamaño de fragmento promedio establecido en 4 KB, solo logra una reducción del 1%. La razón, como se muestra anteriormente en la Figura 2, es que con la huella digital de Rabin, los tramos de datos entre dos límites consecutivos suelen cruzar los límites de fila. Con el cambio en el orden de las filas en el segundo resultado y los fingerprints de Rabin ahora abarcando diferentes filas, el algoritmo no puede detectar similitud significativa. La pequeña ganancia observada se debe principalmente a aquellas filas individuales que son lo suficientemente grandes como para dividirse en múltiples fragmentos. SelectSort2, otro micro-benchmark ejecutó las mismas consultas pero aumentó el tamaño mínimo del fragmento del algoritmo de huella digital de Rabin. Como se puede ver en la Tabla 2, incluso la pequeña ganancia del microbenchmark anterior desaparece cuando el tamaño mínimo de fragmento fue mayor que el tamaño promedio de fila. Si bien se pueden abordar parcialmente estos problemas variando dinámicamente los parámetros del algoritmo de huella digital de Rabin, esto puede resultar computacionalmente costoso, especialmente en presencia de cargas de trabajo cambiantes. 6.2 Benchmarks de Aplicación Ejecutamos el benchmark BBOARD descrito en la Sección 4.1.1 en dos versiones de Ganesh: la primera con la huella digital de Rabin utilizada como WWW 2007 / Track: Sesión de Rendimiento y Escalabilidad: Sistemas Escalables para Contenido Dinámico 317 0 50 100 150 200 250 300 350 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Clientes de Prueba Solicitudes/seg Ganesh Nativo 0.001 0.01 0.1 1 10 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Clientes de Prueba Tiempo de Respuesta Promedio (seg) Ganesh Nativo Nota Escala Logarítmica (a) Rendimiento: Mezcla de Ofertas (b) Tiempo de Respuesta: Mezcla de Ofertas 0 50 100 150 200 250 300 350 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Clientes de Prueba Solicitudes/seg Ganesh Nativo 0.001 0.01 0.1 1 10 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Clientes de Prueba Tiempo de Respuesta Promedio (seg) Ganesh Nativo Nota Escala Logarítmica (c) Rendimiento: Mezcla de Navegación (d) Tiempo de Respuesta: Mezcla de Navegación Promedio de tres pruebas. La desviación estándar máxima para el rendimiento y el tiempo de respuesta fue del 2.2% y del 11.8% de la media correspondiente. Figura 8: Referencia de la subasta AUCTION - Rendimiento y Tiempo de Respuesta Promedio del algoritmo de fragmentación y el segundo con el algoritmo basado en filas de Ganesh. Los resultados de Rabins para la Mezcla de Navegación se normalizan con los resultados de Ganesh y se presentan en la Figura 9. Como muestra la Figura 9 (a), a 5 Mb/s, independientemente de la configuración del cliente de prueba, Rabin tiene un rendimiento significativamente inferior a Ganesh. Esto sucede debido a una combinación de dos razones. Primero, como se describe en la Sección 3.1, Rabin encuentra menos similitud ya que no explota la información estructural de los resultados. Segundo, este punto de referencia contenía algunas consultas que generaron resultados grandes. En este caso, Rabin, con un tamaño de fragmento promedio pequeño, generó una gran cantidad de objetos que desplazaron otros datos útiles de la caché. Por el contrario, Ganesh pudo detectar estas filas grandes y aumentar correspondientemente el tamaño de los bloques. Esto fue confirmado ya que las estadísticas de caché mostraron que la proporción de aciertos de Ganesh era aproximadamente tres veces mayor que la de Rabin. Las mediciones de rendimiento a 20 Mb/s fueron similares, con la excepción del rendimiento de Rabins con 400 clientes de prueba. En este caso, Ganesh no estaba limitado por la red y, de hecho, el rendimiento era el mismo que el de 400 clientes a 5 Mb/s. Rabin, sin embargo, aprovechó el aumento del ancho de banda de 5 a 20 Mb/s para ofrecer un rendimiento ligeramente mejor. A 100 Mb/s, el rendimiento de Rabin era casi similar al de Ganesh ya que el ancho de banda ya no era un cuello de botella. El tiempo de respuesta normalizado, presentado en la Figura 9 (b), muestra tendencias similares. A 5 y 20 Mb/s, la adición de clientes de prueba disminuye el tiempo de respuesta normalizado, ya que el tiempo de respuesta promedio de Ganesh aumenta más rápido que el de Rabin. Sin embargo, en ningún momento Rabin supera a Ganesh. Ten en cuenta que con 400 y 800 clientes a 100 Mb/s, Rabin tiene un mayor sobrecosto incluso cuando no está limitado por el ancho de banda. Como se menciona en la Sección 3.1, esto se debe a que Rabin tiene que hashear cada ResultSet dos veces. La sobrecarga desaparece con 1200 y 1600 clientes, ya que la CPU de la base de datos está saturada y limita el rendimiento tanto de Ganesh como de Rabin. 7. SUPERPOSICIÓN DE PROXY En esta sección, abordamos la tercera pregunta planteada en la Sección 4: ¿Es aceptable la superposición del diseño basado en proxy de Ganesh? Para responder a esta pregunta, nos concentramos en su rendimiento en las bandas de mayor ancho de banda. Nuestra evaluación en la Sección 5 mostró que Ganesh, en comparación con Native, puede ofrecer una mejora sustancial en el rendimiento a anchos de banda más bajos. Solo en anchos de banda más altos serían visibles los costos adicionales de latencia, medidos por el tiempo promedio de respuesta para una solicitud de cliente, y de rendimiento, medidos por la cantidad de solicitudes de cliente que pueden ser atendidas por segundo. Al observar la combinación de autoría del benchmark original de BBOARD, no se aprecian ganancias visibles de Ganesh a 100 Mb/s. Sin embargo, Ganesh sigue rastreando a Native en cuanto a rendimiento. Si bien el tiempo promedio de respuesta es mayor para Ganesh, la diferencia absoluta está entre 0.01 y 0.04 segundos y sería imperceptible para el usuario final. La mezcla de navegación muestra una diferencia aún menor en los tiempos de respuesta promedio. Los resultados de la variante del filtro de los benchmarks de BBOARD son similares. Incluso para el benchmark de SUBASTA, la diferencia entre el tiempo de respuesta de Nativo y Ganesh a 100 Mb/s nunca fue mayor a 0.02 segundos. La única excepción a los resultados anteriores se observó en la variante de filtro del benchmark BBOARD, donde Ganesh con 1600 clientes de prueba añadió 0.85 segundos al tiempo de respuesta promedio. Por lo tanto, incluso para redes mucho más rápidas donde el enlace WAN no es el cuello de botella, Ganesh siempre ofrece un rendimiento equivalente al Nativo. Si bien se agrega algo de latencia adicional debido al diseño basado en proxy, generalmente es imperceptible. TRABAJO RELACIONADO Hasta donde sabemos, Ganesh es el primer sistema que combina el uso de técnicas basadas en hash con el almacenamiento en caché de resultados de base de datos para mejorar el rendimiento y los tiempos de respuesta de aplicaciones con contenido dinámico. También creemos que es el primer sistema en demostrar los beneficios de utilizar información estructural para WWW 2007 / Track: Rendimiento y Escalabilidad Sesión: Sistemas Escalables para Contenido Dinámico 318 0.0 0.2 0.4 0.6 0.8 1.0 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Clientes de Prueba Rendimiento Normalizado 31.8 3.8 2.8 2.3 23.8 32.8 5.8 3.6 1.8 2.1 1.1 1.0 0 5 10 15 20 25 30 35 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Clientes de Prueba Tiempo de Respuesta Normalizado (a) Rendimiento Normalizado: Mayor es mejor (b) Tiempo de Respuesta Normalizado: Mayor es peor Para el rendimiento, un resultado normalizado mayor que 1 implica que Rabin es mejor. Para el tiempo de respuesta, un resultado normalizado mayor que 1 implica que Ganesh es mejor. Media de tres pruebas. La desviación estándar máxima para el rendimiento y el tiempo de respuesta fue del 9.1% y del 13.9% de la media correspondiente. Figura 9: Comparación normalizada de Ganesh vs. Rabin - Mezcla de navegación BBOARD detectando similitud. En esta sección, primero discutimos enfoques alternativos para almacenar en caché contenido dinámico y luego examinamos otros usos de primitivas basadas en hash en sistemas distribuidos. 8.1 Almacenamiento en Caché de Contenido Dinámico En la capa de base de datos, varios sistemas han abogado por la caché de nivel intermedio donde partes de la base de datos se replican en el borde o servidor [3, 4, 20]. Estos sistemas almacenan en caché tablas completas en lo que es esencialmente una base de datos replicada o utilizan vistas materializadas de respuestas de consultas anteriores [19]. Requieren una integración estrecha con la base de datos del sistema para garantizar un límite de tiempo en la propagación de actualizaciones. Estos sistemas suelen estar dirigidos a cargas de trabajo que no requieren una consistencia estricta y pueden tolerar datos obsoletos. Además, a diferencia de Ganesh, algunas de estas soluciones de almacenamiento en caché de nivel medio [2, 3], sufren de la complejidad de tener que participar en la planificación de consultas y el procesamiento de consultas distribuidas. Gao et al. [15] proponen utilizar una arquitectura de replicación de objetos distribuidos donde los requisitos de consistencia de las tiendas de datos se adaptan según la aplicación. Estas soluciones requieren recursos sustanciales de desarrollo y un entendimiento detallado de la aplicación que se está modificando. Si bien existen sistemas que intentan automatizar la partición y replicación de la base de datos de una aplicación [34], no proporcionan semántica de transacciones completa. En comparación, Ganesh no debilita ninguna de las semánticas proporcionadas por la base de datos subyacente. El trabajo reciente en la evaluación de opciones de almacenamiento en caché de borde para sitios web dinámicos [38] ha sugerido que, sin una planificación cuidadosa, el empleo de estrategias complejas de descarga puede perjudicar el rendimiento. En cambio, el trabajo aboga por una arquitectura en la que todos los niveles, excepto la base de datos, deberían ser trasladados al borde. Nuestra evaluación de Ganesh ha demostrado que sería beneficioso para estos escenarios. Para mejorar la escalabilidad de la base de datos, C-JDBC [10], SSS [22] y Ganymed [28] también abogan por el uso de una arquitectura basada en interposición para clusterizar y replicar bases de datos de forma transparente a nivel de middleware. Los enfoques de estas arquitecturas y Ganesh son complementarios y se beneficiarían mutuamente. Avanzando hacia la capa de presentación, se ha producido una amplia adopción de la caché basada en fragmentos [14], la cual mejora la utilización de la caché al almacenar por separado diferentes partes de las páginas web generadas. Si bien el almacenamiento en caché basado en fragmentos funciona en el borde, una propuesta reciente ha propuesto trasladar el ensamblaje de páginas web a los clientes para optimizar la entrega de contenido [31]. Si bien Ganesh no se utiliza en la capa de presentación, los mismos principios se han aplicado en la Detección de Transferencias Duplicadas [25] para aumentar la eficiencia de la caché web, así como para el acceso web a través de enlaces con ancho de banda limitado [33]. 8.2 Sistemas basados en hash En los últimos años han surgido muchos sistemas que explotan técnicas basadas en hash. En el centro de todos estos sistemas se encuentra la idea de detectar similitudes en los datos sin necesidad de interpretar esos datos. Esta idea simple pero elegante se basa en el hash criptográfico, como se discutió anteriormente en la Sección 2. Las aplicaciones exitosas de esta idea abarcan una amplia gama de sistemas de almacenamiento. Los ejemplos incluyen la copia de seguridad entre pares de archivos informáticos personales [11], el archivado eficiente de datos [29] y la búsqueda de archivos similares [21]. Spring y Wetherall [35] aplican principios similares a nivel de red. Utilizando cachés sincronizadas en ambos extremos de un enlace de red, los datos duplicados son reemplazados por tokens más pequeños para su transmisión y luego restaurados en el extremo remoto. Este y otros sistemas basados en hash como los sistemas de archivos CASPER [37] y LBFS [26], y optimizadores de ancho de banda de Capa-2 como Riverbed y Peribit utilizan la huella digital de Rabin [30] para descubrir tramos de similitud en los datos. Este enfoque es especialmente útil cuando los elementos de datos son modificados en su lugar a través de inserciones, eliminaciones y actualizaciones. Sin embargo, como se muestra en la Sección 6, el rendimiento de esta técnica puede experimentar una caída dramática en presencia de reordenamiento de datos. Ganesh en cambio utiliza los límites de fila como divisores para detectar similitudes. El uso más agresivo de técnicas basadas en hash es por sistemas que utilizan hashes como identificadores principales para objetos en almacenamiento persistente. Los sistemas de almacenamiento como CFS [12] y PAST [13] que han sido construidos utilizando tablas hash distribuidas entran en esta categoría. Single Instance Storage [6] y Venti [29] son otros ejemplos de tales sistemas. Como se discute en la Sección 2.2, el uso de hashes criptográficos para abordar datos persistentes representa un nivel más profundo de confianza en su resistencia a colisiones que la asumida por Ganesh. Si el tiempo revela deficiencias en el algoritmo hash, el esfuerzo necesario para corregir la falla es mucho mayor. En Ganesh, simplemente se trata de reemplazar el algoritmo hash. 9. CONCLUSIÓN El creciente uso de contenido web dinámico generado a partir de bases de datos relacionales aumenta las demandas de ancho de banda de la WAN. Las soluciones de almacenamiento en caché tradicionales para reducir el ancho de banda y la latencia suelen ser ineficaces para este tipo de contenido. Este documento muestra que el impacto de los accesos a bases de datos a través de WAN puede reducirse sustancialmente mediante la arquitectura Ganesh sin comprometer la estricta semántica de consistencia de las bases de datos. La esencia de la arquitectura Ganesh es el uso de la computación en los bordes para reducir la comunicación a través de Internet. Ganesh es capaz de utilizar hashes criptográficos para detectar similitud con resultados anteriores y enviar recetas compactas de resultados en lugar de resultados completos en la sesión de Sistemas Escalables para Contenido Dinámico 319 de WWW 2007 / Track: Rendimiento y Escalabilidad. Nuestro diseño utiliza la interposición para lograr una transparencia completa: los clientes, los servidores de aplicaciones y los servidores de bases de datos no son conscientes de la presencia de Ganesh y no requieren ninguna modificación. Nuestra evaluación experimental confirma que Ganesh, aunque conceptualmente simple, puede ser altamente efectivo en mejorar el rendimiento y el tiempo de respuesta. Nuestros resultados también confirman que aprovechar la estructura presente en los resultados de la base de datos para detectar similitudes es crucial para esta mejora en el rendimiento. REFERENCIAS [1] AKELLA, A., SESHAN, S., Y SHAIKH, A. Una evaluación empírica de los cuellos de botella en Internet de área amplia. En Proc. 3ª Conferencia ACM SIGCOMM sobre Medición de Internet (Miami Beach, FL, EE. UU., Oct. 2003), pp. 101-114. [2] ALTINEL, M., BORNH ¨OVD, C., KRISHNAMURTHY, S., MOHAN, C., PIRAHESH, H., Y REINWALD, B. Tablas de caché: allanando el camino para una caché de base de datos adaptativa. En Proc. del 29º VLDB (Berlín, Alemania, 2003), pp. 718-729. [3] ALTINEL, M., LUO, Q., KRISHNAMURTHY, S., MOHAN, C., PIRAHESH, H., LINDSAY, B. G., WOO, H., Y BROWN, L. Dbcache: Caché de base de datos para servidores de aplicaciones web. En Proc. 2002 ACM SIGMOD (2002), pp. 612-612. [4] AMIRI, K., PARK, S., TEWARI, R., Y PADMANABHAN, S. Dbproxy: una caché de datos dinámica para aplicaciones web. En Proc. Conferencia Internacional de Ingeniería de Datos de IEEE (ICDE) (Mar. 2003). [5] BLACK, J. Compare-by-hash: Un análisis razonado. En Proc. Conferencia Técnica Anual USENIX 2006 (Boston, MA, mayo de 2006), pp. 85-90. [6] BOLOSKY, W. J., CORBIN, S., GOEBEL, D., y DOUCEUR, J. R. Almacenamiento de instancia única en Windows 2000. En Proc. 4to Simposio de Sistemas Windows de USENIX (Seattle, WA, ago. 2000), pp. 13-24. [7] BREWER, E. A. Lecciones de servicios a gran escala. IEEE Internet Computing 5, 4 (2001), 46-55. [8] BRODER, A., GLASSMAN, S., MANASSE, M., AND ZWEIG, G. Agrupamiento sintáctico de la web. En Proc. 6ta Conferencia Internacional WWW (1997). [9] CECCHET, E., CHANDA, A., ELNIKETY, S., MARGUERITE, J., Y ZWAENEPOEL, W. Comparación de rendimiento de arquitecturas de middleware para generar contenido web dinámico. En Proc. Cuarta Conferencia Internacional de Middleware ACM/IFIP/USENIX (Río de Janeiro, Brasil, junio de 2003). [10] CECCHET, E., MARGUERITE, J., Y ZWAENEPOEL, W. C-JDBC: Middleware flexible de agrupación de bases de datos. En Proc. Conferencia Técnica Anual USENIX 2004 (Boston, MA, junio de 2004). [11] COX, L. P., MURRAY, C. D., Y NOBLE, B. D. Pastiche: Haciendo que la copia de seguridad sea barata y fácil. En OSDI: Simposio sobre Diseño e Implementación de Sistemas Operativos (2002). [12] DABEK, F., KAASHOEK, M. F., KARGER, D., MORRIS, R., Y STOICA, I. Almacenamiento cooperativo de amplia área con CFS. En el 18º Simposio ACM sobre Principios de Sistemas Operativos (Banff, Canadá, octubre de 2001). [13] DRUSCHEL, P., Y ROWSTRON, A. PASADO: Una utilidad de almacenamiento entre pares a gran escala y persistente. En HotOS VIII (Schloss Elmau, Alemania, mayo de 2001), pp. 75-80. [14] Incluye el lado del borde. http://www.esi.org. [15] GAO, L., DAHLIN, M., NAYATE, A., ZHENG, J., Y IYENGAR, A. Replicación de datos específica de la aplicación para servicios en el borde. En WWW 03: Proc. Duodécima Conferencia Internacional sobre la World Wide Web (2003), pp. 449-460. [16] HEMMINGER, S. Netem - emulando redes reales en el laboratorio. En Proc. 2005 Linux Conference Australia (Canberra, Australia, Abr. 2005). [17] HENSON, V. Un análisis de compare-by-hash. En Proc. 9º Taller sobre Temas Candentes en Sistemas Operativos (HotOS IX) (mayo de 2003), pp. 13-18. [18] Benchmarks de Jmob. http://jmob.objectweb.org/. [19] LABRINIDIS, A., Y ROUSSOPOULOS, N. Equilibrando el rendimiento y la frescura de los datos en servidores de bases de datos web. En Proc. 29ª Conferencia VLDB (Sept. 2003). [20] LARSON, P.-A., GOLDSTEIN, J., Y ZHOU, J. Caché transparente de bases de datos en el nivel intermedio en SQL Server. En Proc. 2003 ACM SIGMOD (2003), pp. 661-661. [21] MANBER, U. Encontrar archivos similares en un sistema de archivos grande. En Proc. Conferencia Técnica de Invierno de USENIX 1994 (San Francisco, CA, 17-21 de 1994), pp. 1-10. [22] MANJHI, A., AILAMAKI, A., MAGGS, B. M., MOWRY, T. C., OLSTON, C., Y TOMASIC, A. Escalabilidad y seguridad simultáneas para aplicaciones web intensivas en datos. En Proc. 2006 ACM SIGMOD (junio de 2006), pp. 241-252. [23] MENEZES, A. J., VANSTONE, S. A., Y OORSCHOT, P. C. V. Manual de Criptografía Aplicada. CRC Press, 1996. [24] MILLER, R. B. \n\nCRC Press, 1996. [24] MILLER, R. B. Tiempo de respuesta en transacciones conversacionales entre humanos y computadoras. En Proc. Conferencia Conjunta de Computación de Otoño de AFIPS (1968), pp. 267-277. [25] MOGUL, J. C., CHAN, Y. M., Y KELLY, T. Diseño, implementación y evaluación de la detección de transferencias duplicadas en http. En Proc. Primer Simposio sobre Diseño e Implementación de Sistemas en Red (San Francisco, CA, Mar. 2004). [26] MUTHITACHAROEN, A., CHEN, B., Y MAZIERES, D. Un sistema de archivos en red de bajo ancho de banda. En Proc. 18º Simposio de la ACM sobre Principios de Sistemas Operativos (Banff, Canadá, Oct. 2001). [27] PFEIFER, D., Y JAKSCHITSCH, H. Caché basada en métodos en aplicaciones de servidores multinivel. En Proc. Quinto Simposio Internacional sobre Objetos y Aplicaciones Distribuidas (Catania, Sicilia, Italia, noviembre de 2003). [28] PLATTNER, C., Y ALONSO, G. Ganymed: Replicación escalable para aplicaciones web transaccionales. En Proc. 5ta Conferencia Internacional de Middleware ACM/IFIP/USENIX (2004), pp. 155-174. [29] QUINLAN, S., Y DORWARD, S. Venti: Un nuevo enfoque para el almacenamiento de archivos. En Proc. Conferencia FAST 2002 sobre Tecnologías de Archivo y Almacenamiento (2002). [30] RABIN, M. Huellas dactilares mediante polinomios aleatorios. En el Informe Técnico TR-15-81 (1981) del Centro de Investigación en Tecnología Informática de la Universidad de Harvard. [31] RABINOVICH, M., XIAO, Z., DOUGLIS, F., Y KALMANEK, C. Mover los lados de los bordes incluye a los clientes reales en el borde. En Proc. 4to Simposio USENIX sobre Tecnologías y Sistemas de Internet (Seattle, WA, Mar. 2003). [32] REESE, G. Programación de bases de datos con JDBC y Java, 1ra ed. OReilly, junio de 1997. [33] RHEA, S., LIANG, K., Y BREWER, E. Caché web basada en valores. En Proc. Duodécima Conferencia Internacional de la World Wide Web (mayo de 2003). [34] SIVASUBRAMANIAN, S., ALONSO, G., PIERRE, G., Y VAN STEEN, M. Globedb: Replicación autónoma de datos para aplicaciones web. En WWW 05: Actas de la 14ª Conferencia Internacional de la World-Wide Web (mayo de 2005). [35] SPRING, N. T., Y WETHERALL, D. Una técnica independiente de protocolo para eliminar el tráfico de red redundante. En Proc. de ACM SIGCOMM (Ago. 2000). [36] TOLIA, N., HARKES, J., KOZUCH, M., Y SATYANARAYANAN, M. Integrando almacenamiento portátil y distribuido. En Proc. 3ra Conferencia USENIX sobre Tecnologías de Archivos y Almacenamiento (San Francisco, CA, Mar. 2004). [37] TOLIA, N., KOZUCH, M., SATYANARAYANAN, M., KARP, B., PERRIG, A., Y BRESSOUD, T. Uso oportunista del almacenamiento direccionable por contenido para sistemas de archivos distribuidos. En Proc. Conferencia Técnica Anual USENIX 2003 (San Antonio, TX, junio de 2003), pp. 127-140. [38] YUAN, C., CHEN, Y., Y ZHANG, Z. Evaluación de almacenamiento en caché/descarga en el borde para la entrega de contenido dinámico. En WWW 03: Proc. Duodécima Conferencia Internacional sobre la World Wide Web (2003), pp. 461-471. WWW 2007 / Pista: Rendimiento y Escalabilidad Sesión: Sistemas Escalables para Contenido Dinámico 320 ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "natural chunk boundary": {
            "translated_key": "límite natural de fragmento",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Consistency-preserving Caching of Dynamic Database Content∗ Niraj Tolia and M. Satyanarayanan Carnegie Mellon University {ntolia,satya}@cs.cmu.edu ABSTRACT With the growing use of dynamic web content generated from relational databases, traditional caching solutions for throughput and latency improvements are ineffective.",
                "We describe a middleware layer called Ganesh that reduces the volume of data transmitted without semantic interpretation of queries or results.",
                "It achieves this reduction through the use of cryptographic hashing to detect similarities with previous results.",
                "These benefits do not require any compromise of the strict consistency semantics provided by the back-end database.",
                "Further, Ganesh does not require modifications to applications, web servers, or database servers, and works with closed-source applications and databases.",
                "Using two benchmarks representative of dynamic web sites, measurements of our prototype show that it can increase end-to-end throughput by as much as twofold for non-data intensive applications and by as much as tenfold for data intensive ones.",
                "Categories and Subject Descriptors C.2.4 [Computer-Communication Networks]: Distributed Systems; H.2.4 [Database Management]: Systems General Terms Design, Performance 1.",
                "INTRODUCTION An increasing fraction of web content is dynamically generated from back-end relational databases.",
                "Even when database content remains unchanged, temporal locality of access cannot be exploited because dynamic content is not cacheable by web browsers or by intermediate caching servers such as Akamai mirrors.",
                "In a multitiered architecture, each web request can stress the WAN link between the web server and the database.",
                "This causes user experience to be highly variable because there is no caching to insulate the client from bursty loads.",
                "Previous attempts in caching dynamic database content have generally weakened transactional semantics [3, 4] or required application modifications [15, 34].",
                "We report on a new solution that takes the form of a databaseagnostic middleware layer called Ganesh.",
                "Ganesh makes no effort to semantically interpret the contents of queries or their results.",
                "Instead, it relies exclusively on cryptographic hashing to detect similarities with previous results.",
                "Hash-based similarity detection has seen increasing use in distributed file systems [26, 36, 37] for improving performance on low-bandwidth networks.",
                "However, these techniques have not been used for relational databases.",
                "Unlike previous approaches that use generic methods to detect similarity, Ganesh exploits the structure of relational database results to yield superior performance improvement.",
                "One faces at least three challenges in applying hash-based similarity detection to back-end databases.",
                "First, previous work in this space has traditionally viewed storage content as uninterpreted bags of bits with no internal structure.",
                "This allows hash-based techniques to operate on long, contiguous runs of data for maximum effectiveness.",
                "In contrast, relational databases have rich internal structure that may not be as amenable to hash-based similarity detection.",
                "Second, relational databases have very tight integrity and consistency constraints that must not be compromised by the use of hash-based techniques.",
                "Third, the source code of commercial databases is typically not available.",
                "This is in contrast to previous work which presumed availability of source code.",
                "Our experiments show that Ganesh, while conceptually simple, can improve performance significantly at bandwidths representative of todays commercial Internet.",
                "On benchmarks modeling multitiered web applications, the throughput improvement was as high as tenfold for data-intensive workloads.",
                "For workloads that were not data-intensive, throughput improvements of up to twofold were observed.",
                "Even when bandwidth was not a constraint, Ganesh had low overhead and did not hurt performance.",
                "Our experiments also confirm that exploiting the structure present in database results is crucial to this performance improvement. 2.",
                "BACKGROUND 2.1 Dynamic Content Generation As the World Wide Web has grown, many web sites have decentralized their data and functionality by pushing them to the edges of the Internet.",
                "Today, eBusiness systems often use a three-tiered architecture consisting of a front-end web server, an application server, and a back-end database server.",
                "Figure 1 illustrates this architecture.",
                "The first two tiers can be replicated close to a concentration of clients at the edge of the Internet.",
                "This improves user experience by lowering end-to-end latency and reducing exposure WWW 2007 / Track: Performance and Scalability Session: Scalable Systems for Dynamic Content 311 Back-End Database Server Front-End Web and Application Servers Figure 1: Multi-Tier Architecture to backbone traffic congestion.",
                "It can also increase the availability and scalability of web services.",
                "Content that is generated dynamically from the back-end database cannot be cached in the first two tiers.",
                "While databases can be easily replicated in a LAN, this is infeasible in a WAN because of the difficult task of simultaneously providing strong consistency, availability, and tolerance to network partitions [7].",
                "As a result, databases tend to be centralized to meet the strong consistency requirements of many eBusiness applications such as banking, finance, and online retailing [38].",
                "Thus, the back-end database is usually located far from many sets of first and second-tier nodes [2].",
                "In the absence of both caching and replication, WAN bandwidth can easily become a limiting factor in the performance and scalability of data-intensive applications. 2.2 Hash-Based Systems Ganeshs focus is on efficient transmission of results by discovering similarities with the results of previous queries.",
                "As SQL queries can generate large results, hash-based techniques lend themselves well to the problem of efficiently transferring these large results across bandwidth constrained links.",
                "The use of hash-based techniques to reduce the volume of data transmitted has emerged as a common theme of many recent storage systems, as discussed in Section 8.2.",
                "These techniques rely on some basic assumptions.",
                "Cryptographic hash functions are assumed to be collision-resistant.",
                "In other words, it is computationally intractable to find two inputs that hash to the same output.",
                "The functions are also assumed to be one-way; that is, finding an input that results in a specific output is computationally infeasible.",
                "Menezes et al. [23] provide more details about these assumptions.",
                "The above assumptions allow hash-based systems to assume that collisions do not occur.",
                "Hence, they are able to treat the hash of a data item as its unique identifier.",
                "A collection of data items effectively becomes content-addressable, allowing a small hash to serve as a codeword for a much larger data item in permanent storage or network transmission.",
                "The assumption that collisions are so rare as to be effectively non-existent has recently come under fire [17].",
                "However, as explained by Black [5], we believe that these issues do not form a concern for Ganesh.",
                "All communication is between trusted parts of the system and an adversary has no way to force Ganesh to accept invalid data.",
                "Further, Ganesh does not depend critically on any specific hash function.",
                "While we currently use SHA-1, replacing it with a different hash function would be simple.",
                "There would be no impact on performance as stronger hash functions (e.g.",
                "SHA256) only add a few extra bytes and the generated hashes are still orders of magnitude smaller than the data items they represent.",
                "No re-hashing of permanent storage is required since Ganesh only uses hashing on volatile data. 3.",
                "DESIGN AND IMPLEMENTATION Ganesh exploits redundancy in the result stream to avoid transmitting result fragments that are already present at the query site.",
                "Redundancy can arise naturally in many different ways.",
                "For example, a query repeated after a certain interval may return a different result because of updates to the database; however, there may be significant commonality between the two results.",
                "As another example, a user who is refining a search may generate a sequence of queries with overlapping results.",
                "When Ganesh detects redundancy, it suppresses transmission of the corresponding result fragments.",
                "Instead, it transmits a much smaller digest of those fragments and lets the query site reconstruct the result through hash lookup in a cache of previous results.",
                "In effect, Ganesh uses computation at the edges to reduce Internet communication.",
                "Our description of Ganesh focuses on four aspects.",
                "We first explain our approach to detecting similarity in query results.",
                "Next, we discuss how the Ganesh architecture is completely invisible to all components of a multi-tier system.",
                "We then describe Ganeshs proxy-based approach and the dataflow for detecting similarity. 3.1 Detecting Similarity One of the key design decisions in Ganesh is how similarity is detected.",
                "There are many potential ways to decompose a result into fragments.",
                "The optimal way is, of course, the one that results in the smallest possible object for transmission for a given querys results.",
                "Finding this optimal decomposition is a difficult problem because of the large space of possibilities and because the optimal choice depends on many factors such as the contents of the querys result, the history of recent results, and the cache management algorithm.",
                "When an object is opaque, the use of Rabin fingerprints [8, 30] to detect common data between two objects has been successfully shown in the past by systems such as LBFS [26] and CASPER [37].",
                "Rabin fingerprinting uses a sliding window over the data to compute a rolling hash.",
                "Assuming that the hash function is uniformly distributed, a chunk boundary is defined whenever the lower order bits of the hash value equal some predetermined value.",
                "The number of lower order bits used defines the average chunk size.",
                "These sub-divided chunks of the object become the unit of comparison for detecting similarity between different objects.",
                "As the locations of boundaries found by using Rabin fingerprints is stochastically determined, they usually fail to align with any structural properties of the underlying data.",
                "The algorithm therefore deals well with in-place updates, insertions and deletions.",
                "However, it performs poorly in the presence of any reordering of data.",
                "Figure 2 shows an example where two results, A and B, consisting of three rows, have the same data but have different sort attributes.",
                "In the extreme case, Rabin fingerprinting might be unable to find any similar data due to the way it detects chunk boundaries.",
                "Fortunately, Ganesh can use domain specific knowledge for more precise boundary detection.",
                "The information we exploit is that a querys result reflects the structure of a relational database where all data is organized as tables and rows.",
                "It is therefore simple to check for similarity with previous results at two granularities: first the entire result, and then individual rows.",
                "The end of a row in a result serves as a <br>natural chunk boundary</br>.",
                "It is important to note that using the tabular structure in results only involves shallow interpretation of the data.",
                "Ganesh does not perform any deeper semantic interpretation such as understanding data types, result schema, or integrity constraints.",
                "Tuning Rabin fingerprinting for a workload can also be difficult.",
                "If the average chunk size is too large, chunks can span multiple result rows.",
                "However, selecting a smaller average chunk size increases the amount of metadata required to the describe the results.",
                "WWW 2007 / Track: Performance and Scalability Session: Scalable Systems for Dynamic Content 312 Figure 2: Rabin Fingerprinting vs. Ganeshs Chunking This, in turn, would decrease the savings obtained via its use.",
                "Rabin fingerprinting also needs two computationally-expensive passes over the data: once to determine chunk boundaries and one again to generate cryptographic hashes for the chunks.",
                "Ganesh only needs a single pass for hash generation as the chunk boundaries are provided by the datas natural structure.",
                "The performance comparison in Section 6 shows that Ganeshs row-based algorithm outperforms Rabin fingerprinting.",
                "Given that previous work has already shown that Rabin fingerprinting performs better than gzip [26], we do not compare Ganesh to compression algorithms in this paper. 3.2 Transparency The key factor influencing our design was the need for Ganesh to be completely transparent to all components of a typical eBusiness system: web servers, application servers, and database servers.",
                "Without this, Ganesh stands little chance of having a significant real-world impact.",
                "Requiring modifications to any of the above components would raise the barrier for entry of Ganesh into an existing system, and thus reduce its chances of adoption.",
                "Preserving transparency is simplified by the fact that Ganesh is purely a performance enhancement, not a functionality or usability enhancement.",
                "We chose agent interposition as the architectural approach to realizing our goal.",
                "This approach relies on the existence of a compact programming interface that is already widely used by target software.",
                "It also relies on a mechanism to easily add new code without disrupting existing module structure.",
                "These conditions are easily met in our context because of the popularity of Java as the programming language for eBusiness systems.",
                "The Java Database Connectivity (JDBC) API [32] allows Java applications to access a wide variety of databases and even other tabular data repositories such as flat files.",
                "Access to these data sources is provided by JDBC drivers that translate between the JDBC API and the database communication mechanism.",
                "Figure 3(a) shows how JDBC is typically used in an application.",
                "As the JDBC interface is standardized, one can substitute one JDBC driver for another without application modifications.",
                "The JDBC driver thus becomes the natural module to exploit for code interposition.",
                "As shown in Figure 3(b), the native JDBC driver is replaced with a Ganesh JDBC driver that presents the same standardized interface.",
                "The Ganesh driver maintains an in-memory cache of result fragments from previous queries and performs reassembly of results.",
                "At the database, we add a new process called the Ganesh proxy.",
                "This proxy, which can be shared by multiple front-end nodes, consists of two parts: code to detect similarity in result fragments and the original native JDBC driver that communicates with the database.",
                "The use of a proxy at the database makes Ganesh database-agnostic and simplifies prototyping and experimentation.",
                "Ganesh is thus able to work with a wide range of databases and applications, requiring no modifications to either. 3.3 Proxy-Based Caching The native JDBC driver shown in Figure 3(a) is a lightweight code component supplied by the database vendor.",
                "Its main funcClient Database Web and Application Server Native JDBC Driver WAN (a) Native Architecture Client Database Ganesh Proxy Native JDBC Driver WAN Web and Application Server Ganesh JDBC Driver (b) Ganeshs Interposition-based Architecture Figure 3: Native vs. Ganesh Architecture tion is to mediate communication between the application and the remote database.",
                "It forwards queries, buffers entire results, and responds to application requests to view parts of results.",
                "The Ganesh JDBC driver shown in Figure 3(b) presents the application with an interface identical to that provided by the native driver.",
                "It provides the ability to reconstruct results from compact hash-based descriptions sent by the proxy.",
                "To perform this reconstruction, the driver maintains an in-memory cache of recentlyreceived results.",
                "This cache is only used as a source of result fragments in reconstructing results.",
                "No attempt is made by the Ganesh driver or proxy to track database updates.",
                "The lack of cache consistency does not hurt correctness as a description of the results is always fetched from the proxy - at worst, there will be no performance benefit from using Ganesh.",
                "Stale data will simply be paged out of the cache over time.",
                "The Ganesh proxy accesses the database via the native JDBC driver, which remains unchanged between Figures 3(a) and (b).",
                "The database is thus completely unaware of the existence of the proxy.",
                "The proxy does not examine any queries received from the Ganesh driver but passes them to the native driver.",
                "Instead, the proxy is responsible for inspecting database output received from the native driver, detecting similar results, and generating hash-based encodings of these results whenever enough similarity is found.",
                "While this architecture does not decrease the load on a database, as mentioned earlier in Section 2.1, it is much easier to replicate databases for scalability in a LAN than in a WAN.",
                "To generate a hash-based encoding, the proxy must be aware of what result fragments are available in the Ganesh drivers cache.",
                "One approach is to be optimistic, and to assume that all result fragments are available.",
                "This will result in the smallest possible initial transmission of a result.",
                "However, in cases where there is little overlap with previous results, the Ganesh driver will have to make many calls to the proxy during reconstruction to fetch missing result fragments.",
                "To avoid this situation, the proxy loosely tracks the state of the Ganesh drivers cache.",
                "Since both components are under our control, it is relatively simple to do this without resorting to gray-box techniques or explicit communication for maintaining cache coherence.",
                "Instead, the proxy simulates the Ganesh drivers cache management algorithm and uses this to maintain a list of hashes for which the Ganesh driver is likely to possess the result fragments.",
                "In case of mistracking, there will be no loss of correctness but there will be extra round-trip delays to fetch the missing fragments.",
                "If the client detects loss of synchronization with the proxy, it can ask the proxy to reset the state shared between them.",
                "Also note that the proxy does not need to keep the result fragments themselves, only their hashes.",
                "This allows the proxy to remain scalable even when it is shared by many front-end nodes.",
                "WWW 2007 / Track: Performance and Scalability Session: Scalable Systems for Dynamic Content 313 Object Output Stream Convert ResultSet Object Input Stream Convert ResultSet All Data Recipe ResultSet All Data ResultSet Network Ganesh Proxy Ganesh JDBC Driver Result Set Recipe Result Set Yes Yes No No GaneshInputStream GaneshOutputStream Figure 4: Dataflow for Result Handling 3.4 Encoding and Decoding Results The Ganesh proxy receives database output as Java objects from the native JDBC driver.",
                "It examines this output to see if a Java object of type ResultSet is present.",
                "The JDBC interface uses this data type to store results of database queries.",
                "If a ResultSet object is found, it is shrunk as discussed below.",
                "All other Java objects are passed through unmodified.",
                "As discussed in Section 3.1, the proxy uses the row boundaries defined in the ResultSet to partition it into fragments consisting of single result rows.",
                "All ResultSet objects are converted into objects of a new type called RecipeResultSet.",
                "We use the term recipe for this compact description of a database result because of its similarity to a file recipe in the CASPER file system [37].",
                "The conversion replaces each result fragment that is likely to be present in the Ganesh drivers cache by a SHA-1 hash of that fragment.",
                "Previously unseen result fragments are retained verbatim.",
                "The proxy also retains hashes for the new result fragments as they will be present in the drivers cache in the future.",
                "Note that the proxy only caches hashes for result fragments and does not cache recipes.",
                "The proxy constructs a RecipeResultSet by checking for similarity at the entire result and then the row level.",
                "If the entire result is predicted to be present in the Ganesh drivers cache, the RecipeResultSet is simply a single hash of the entire result.",
                "Otherwise, it contains hashes for those rows predicted to be present in that cache; all other rows are retained verbatim.",
                "If the proxy estimates an overall space savings, it will transmit the RecipeResultSet.",
                "Otherwise the original ResultSet is transmitted.",
                "The RecipeResultSet objects are transformed back into ResultSet objects by the Ganesh driver.",
                "Figure 4 illustrates ResultSet handling at both ends.",
                "Each SHA-1 hash found in a RecipeResultSet is looked up in the local cache of result fragments.",
                "On a hit, the hash is replaced by the corresponding fragment.",
                "On a miss, the driver contacts the Ganesh proxy to fetch the fragment.",
                "All previously unseen result fragments that were retained verbatim by the proxy are hashed and added to the result cache.",
                "There should be very few misses if the proxy has accurately tracked the Ganesh drivers cache state.",
                "A future optimization would be to batch the fetch of missing fragments.",
                "This would be valuable when there are many small missing fragments in a high-latency WAN.",
                "Once the transformation is complete, the fully reconstructed ResultSet object is passed up to the application. 4.",
                "EXPERIMENTAL VALIDATION Three questions follow from the goals and design of Ganesh: • First, can performance can be improved significantly by exploiting similarity across database results?",
                "Benchmark Dataset Details 500,000 Users, 12,000 Stories BBOARD 2.0 GB 3,298,000 Comments AUCTION 1.3 GB 1,000,000 Users, 34,000 Items Table 1: Benchmark Dataset Details • Second, how important is Ganeshs structural similarity detection relative to Rabin fingerprintings similarity detection? • Third, is the overhead of the proxy-based design acceptable?",
                "Our evaluation answers these question through controlled experiments with the Ganesh prototype.",
                "This section describes the benchmarks used, our evaluation procedure, and the experimental setup.",
                "Results of the experiments are presented in Sections 5, 6, and 7. 4.1 Benchmarks Our evaluation is based on two benchmarks [18] that have been widely used by other researchers to evaluate various aspects of multi-tier [27] and eBusiness architectures [9].",
                "The first benchmark, BBOARD, is modeled after Slashdot, a technology-oriented news site.",
                "The second benchmark, AUCTION, is modeled after eBay, an online auction site.",
                "In both benchmarks, most content is dynamically generated from information stored in a database.",
                "Details of the datasets used can be found in Table 1. 4.1.1 The BBOARD Benchmark The BBOARD benchmark, also known as RUBBoS [18], models Slashdot, a popular technology-oriented web site.",
                "Slashdot aggregates links to news stories and other topics of interest found elsewhere on the web.",
                "The site also serves as a bulletin board by allowing users to comment on the posted stories in a threaded conversation form.",
                "It is not uncommon for a story to gather hundreds of comments in a matter of hours.",
                "The BBOARD benchmark is similar to the site and models the activities of a user, including readonly operations such as browsing the stories of the day, browsing story categories, and viewing comments as well as write operations such as new user registration, adding and moderating comments, and story submission.",
                "The benchmark consists of three different phases: a short warmup phase, a runtime phase representing the main body of the workload, and a short cool-down phase.",
                "In this paper we only report results from the runtime phase.",
                "The warm-up phase is important in establishing dynamic system state, but measurements from that phase are not significant for our evaluation.",
                "The cool-down phase is solely for allowing the benchmark to shut down.",
                "The warm-up, runtime, and cool-down phases are 2, 15, and 2 minutes respectively.",
                "The number of simulated clients were 400, 800, 1200, and 1600.",
                "The benchmark is available in a Java Servlets and PHP version and has different datasets; we evaluated Ganesh using the Java Servlets version and the Expanded dataset.",
                "The BBOARD benchmark defines two different workloads.",
                "The first, the Authoring mix, consists of 70% read-only operations and 30% read-write operations.",
                "The second, the Browsing mix, contains only read-only operations and does not update the database. 4.1.2 The AUCTION Benchmark The AUCTION benchmark, also known as RUBiS [18], models eBay, the online auction site.",
                "The eBay web site is used to buy and sell items via an auction format.",
                "The main activities of a user include browsing, selling, or bidding for items.",
                "Modeling the activities on this site, this benchmark includes read-only activities such as browsing items by category and by region, as well as read-write WWW 2007 / Track: Performance and Scalability Session: Scalable Systems for Dynamic Content 314 NetEm Router Ganesh Proxy Clients Web and Application Server Database Server Figure 5: Experimental Setup activities such as bidding for items, buying and selling items, and leaving feedback.",
                "As with BBOARD, the benchmark consists of three different phases.",
                "The warm-up, runtime, and cool-down phases for this experiment are 1.5, 15, and 1 minutes respectively.",
                "We tested Ganesh with four client configurations where the number of test clients was set to 400, 800, 1200, and 1600.",
                "The benchmark is available in a Enterprise Java Bean (EJB), Java Servlets, and PHP version and has different datasets; we evaluated Ganesh with the Java Servlets version and the Expanded dataset.",
                "The AUCTION benchmark defines two different workloads.",
                "The first, the Bidding mix, consists of 70% read-only operations and 30% read-write operations.",
                "The second, the Browsing mix, contains only read-only operations and does not update the database. 4.2 Experimental Procedure Both benchmarks involve a synthetic workload of clients accessing a web server.",
                "The number of clients emulated is an experimental parameter.",
                "Each emulated client runs an instance of the benchmark in its own thread, using a matrix to transition between different benchmark states.",
                "The matrix defines a stochastic model with probabilities of transitioning between the different states that represent typical user actions.",
                "An example transition is a user logging into the AUCTION system and then deciding on whether to post an item for sale or bid on active auctions.",
                "Each client also models user think time between requests.",
                "The think time is modeled as an exponential distribution with a mean of 7 seconds.",
                "We evaluate Ganesh along two axes: number of clients and WAN bandwidth.",
                "Higher loads are especially useful in understanding Ganeshs performance when the CPU or disk of the database server or proxy is the limiting factor.",
                "A previous study has shown that approximately 50% of the wide-area Internet bottlenecks observed had an available bandwidth under 10 Mb/s [1].",
                "Based on this work, we focus our evaluation on the WAN bandwidth of 5 Mb/s with 66 ms of round-trip latency, representative of severely constrained network paths, and 20 Mb/s with 33 ms of round-trip latency, representative of a moderately constrained network path.",
                "We also report Ganeshs performance at 100 Mb/s with no added round-trip latency.",
                "This bandwidth, representative of an unconstrained network, is especially useful in revealing any potential overhead of Ganesh in situations where WAN bandwidth is not the limiting factor.",
                "For each combination of number of clients and WAN bandwidth, we measured results from the two configurations listed below: • Native: This configuration corresponds to Figure 3(a).",
                "Native avoids Ganeshs overhead in using a proxy and performing Java object serialization. • Ganesh: This configuration corresponds to Figure 3(b).",
                "For a given number of clients and WAN bandwidth, comparing these results to the corresponding Native results gives the performance benefit due to the Ganesh middleware system.",
                "The metric used to quantify the improvement in throughput is the number of client requests that can be serviced per second.",
                "The metric used to quantify Ganeshs overhead is the average response time for a client request.",
                "For all of the experiments, the Ganesh driver used by the application server used a cache size of 100,000 items1 .",
                "The proxy was effective in tracking the Ganesh drivers cache state; for all of our experiments the miss rate on the driver never exceeded 0.7%. 4.3 Experimental Setup The experimental setup used for the benchmarks can be seen in Figure 5.",
                "All machines were 3.2 GHz Pentium 4s (with HyperThreading enabled.)",
                "With the exception of the database server, all machines had 2 GB of SDRAM and ran the Fedora Core Linux distribution.",
                "The database server had 4 GB of SDRAM.",
                "We used Apaches Tomcat as both the application server that hosted the Java Servlets and the web server.",
                "Both benchmarks used Java Servlets to generate the dynamic content.",
                "The database server used the open source MySQL database.",
                "For the native JDBC drivers, we used the Connector/J drivers provided by MySQL.",
                "The application server used Suns Java Virtual Machine as the runtime environment for the Java Servlets.",
                "The sysstat tool was used to monitor the CPU, network, disk, and memory utilization on all machines.",
                "The machines were connected by a switched gigabit Ethernet network.",
                "As shown in Figure 5, the front-end web and application server was separated from the proxy and database server by a NetEm router [16].",
                "This router allowed us to control the bandwidth and latency settings on the network.",
                "The NetEm router is a standard PC with two network cards running the Linux Traffic Control and Network Emulation software.",
                "The bandwidth and latency constraints were only applied to the link between the application server and the database for the native case and between the application server and the proxy for the Ganesh case.",
                "There is no communication between the application server and the database with Ganesh as all data flows through the proxy.",
                "As our focus was on the WAN link between the application server and the database, there were no constraints on the link between the simulated test clients and the web server. 5.",
                "THROUGHPUT AND RESPONSE TIME In this section, we address the first question raised in Section 4: Can performance can be improved significantly by exploiting similarity across database results?",
                "To answer this question, we use results from the BBOARD and AUCTION benchmarks.",
                "We use two metrics to quantify the performance improvement obtainable through the use of Ganesh: throughput, from the perspective of the web server, and average response time, from the perspective of the client.",
                "Throughput is measured in terms of the number of client requests that can be serviced per second. 5.1 BBOARD Results and Analysis 5.1.1 Authoring Mix Figures 6 (a) and (b) present the average number of requests serviced per second and the average response time for these requests as perceived by the clients for BBOARDs Authoring Mix.",
                "As Figure 6 (a) shows, Native easily saturates the 5 Mb/s link.",
                "At 400 clients, the Native solution delivers 29 requests/sec with an average response time of 8.3 seconds.",
                "Natives throughput drops with an increase in test clients as clients timeout due to congestion at the application server.",
                "Usability studies have shown that response times above 10 seconds cause the user to move on to 1 As Java lacks a sizeof() operator, Java caches therefore limit their size based on the number of objects.",
                "The size of cache dumps taken at the end of the experiments never exceeded 212 MB.",
                "WWW 2007 / Track: Performance and Scalability Session: Scalable Systems for Dynamic Content 315 0 50 100 150 200 250 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Test Clients Requests/sec Native Ganesh 0.001 0.01 0.1 1 10 100 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Test Clients Avg.Resp.Time(sec) Native Ganesh Note Logscale (a) Throughput: Authoring Mix (b) Response Time: Authoring Mix 0 50 100 150 200 250 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Test Clients Requests/sec Native Ganesh 0.001 0.01 0.1 1 10 100 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Test Clients Avg.Resp.Time(sec) Native Ganesh Note Logscale (c) Throughput: Browsing Mix (d) Response Time: Browsing Mix Mean of three trials.",
                "The maximum standard deviation for throughput and response time was 9.8% and 11.9% of the corresponding mean.",
                "Figure 6: BBOARD Benchmark - Throughput and Average Response Time other tasks [24].",
                "Based on these numbers, increasing the number of test clients makes the Native system unusable.",
                "Ganesh at 5 Mb/s, however, delivers a twofold improvement with 400 test clients and a fivefold improvement at 1200 clients.",
                "Ganeshs performance drops slightly at 1200 and 1600 clients as the network is saturated.",
                "Compared to Native, Figure 6 (b) shows that Ganeshs response times are substantially lower with sub-second response times at 400 clients.",
                "Figure 6 (a) also shows that for 400 and 800 test clients Ganesh at 5 Mb/s has the same throughput and average response time as Native at 20 Mb/s.",
                "Only at 1200 and 1600 clients does Native at 20 Mb/s deliver higher throughput than Ganesh at 5 Mb/s.",
                "Comparing both Ganesh and Native at 20 Mb/s, we see that Ganesh is no longer bandwidth constrained and delivers up to a twofold improvement over Native at 1600 test clients.",
                "As Ganesh does not saturate the network with higher test client configurations, at 1600 test clients, its average response time is 0.1 seconds rather than Natives 7.7 seconds.",
                "As expected, there are no visible gains from Ganesh at the higher bandwidth of 100 Mb/s where the network is no longer the bottleneck.",
                "Ganesh, however, still tracks Native in terms of throughput. 5.1.2 Browsing Mix Figures 6 (c) and (d) present the average number of requests serviced per second and the average response time for these requests as perceived by the clients for BBOARDs Browsing Mix.",
                "Regardless of the test client configuration, Figure 6 (c) shows that Natives throughput at 5 Mb/s is limited to 10 reqs/sec.",
                "Ganesh at 5 Mb/s with 400 test clients, delivers more than a sixfold increase in throughput.",
                "The improvement increases to over a elevenfold increase at 800 test clients before Ganesh saturates the network.",
                "Further, Figure 6 (d) shows that Natives average response time of 35 seconds at 400 test clients make the system unusable.",
                "These high response times further increase with the addition of test clients.",
                "Even with the 1600 test client configuration Ganesh delivers an acceptable average response time of 8.2 seconds.",
                "Due to the data-intensive nature of the Browsing mix, Ganesh at 5 Mb/s surprisingly performs much better than Native at 20 Mb/s.",
                "Further, as shown in Figure 6 (d), while the average response time for Native at 20 Mb/s is acceptable at 400 test clients, it is unusable with 800 test clients with an average response time of 15.8 seconds.",
                "Like the 5 Mb/s case, this response time increases with the addition of extra test clients.",
                "Ganesh at 20 Mb/s and both Native and Ganesh at 100 Mb/s are not bandwidth limited.",
                "However, performance plateaus out after 1200 test clients due to the database CPU being saturated. 5.1.3 Filter Variant We were surprised by the Native performance from the BBOARD benchmark.",
                "At the bandwidth of 5 Mb/s, Native performance was lower than what we had expected.",
                "It turned out the benchmark code that displays stories read all the comments associated with the particular story from the database and only then did some postprocessing to select the comments to be displayed.",
                "While this is exactly the behavior of SlashCode, the code base behind the Slashdot web site, we decided to modify the benchmark to perform some pre-filtering at the database.",
                "This modified benchmark, named the Filter Variant, models a developer who applies optimizations at the SQL level to transfer less data.",
                "In the interests of brevity, we only briefly summarize the results from the Authoring mix.",
                "For the Authoring mix, at 800 test clients at 5 Mb/s, Figure 7 (a) shows that Natives throughput increase by 85% when compared to the original benchmark while Ganeshs improvement is smaller at 15%.",
                "Natives performance drops above 800 clients as the test clients time out due to high response times.",
                "The most significant gain for Native is seen at 20 Mb/s.",
                "At 1600 test clients, when compared to the original benchmark, Native sees a 73% improvement in throughput and a 77% reduction in average response time.",
                "While WWW 2007 / Track: Performance and Scalability Session: Scalable Systems for Dynamic Content 316 0 50 100 150 200 250 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Test Clients Requests/sec Native Ganesh 0.001 0.01 0.1 1 10 100 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Test Clients Avg.Resp.Time(sec) Native Ganesh Note Logscale (a) Throughput: Authoring Mix (b) Response Time: Authoring Mix Mean of three trials.",
                "The maximum standard deviation for throughput and response time was 7.2% and 11.5% of the corresponding mean.",
                "Figure 7: BBOARD Benchmark - Filter Variant - Throughput and Average Response Time Ganesh sees no improvement when compared to the original, it still processes 19% more requests/sec than Native.",
                "Thus, while the optimizations were more helpful to Native, Ganesh still delivers an improvement in performance. 5.2 AUCTION Results and Analysis 5.2.1 Bidding Mix Figures 8 (a) and (b) present the average number of requests serviced per second and the average response time for these requests as perceived by the clients for AUCTIONs Bidding Mix.",
                "As mentioned earlier, the Bidding mix consists of a mixture of read and write operations.",
                "The AUCTION benchmark is not as data intensive as BBOARD.",
                "Therefore, most of the gains are observed at the lower bandwidth of 5 Mb/s.",
                "Figure 8 (a) shows that the increase in throughput due to Ganesh ranges from 8% at 400 test clients to 18% with 1600 test clients.",
                "As seen in Figure 8 (b), the average response times for Ganesh are significantly lower than Native ranging from a decrease of 84% at 800 test clients to 88% at 1600 test clients.",
                "Figure 8 (a) also shows that with a fourfold increase of bandwidth from 5 Mb/s to 20 Mb/s, Native is no longer bandwidth constrained and there is no performance difference between Ganesh and Native.",
                "With the higher test client configurations, we did observe that the bandwidth used by Ganesh was lower than Native.",
                "Ganesh might still be useful in these non-constrained scenarios if bandwidth is purchased on a metered basis.",
                "Similar results are seen for the 100 Mb/s scenario. 5.2.2 Browsing Mix For AUCTIONs Browsing Mix, Figures 8 (c) and (d) present the average number of requests serviced per second and the average response time for these requests as perceived by the clients.",
                "Again, most of the gains are observed at lower bandwidths.",
                "At 5 Mb/s, Native and Ganesh deliver similar throughput and response times with 400 test clients.",
                "While the throughput for both remains the same at 800 test clients, Figure 8 (d) shows that Ganeshs average response time is 62% lower than Native.",
                "Native saturates the link at 800 clients and adding extra test clients only increases the average response time.",
                "Ganesh, regardless of the test client configuration, is not bandwidth constrained and maintains the same response time.",
                "At 1600 test clients, Figure 8 (c) shows that Ganeshs throughput is almost twice that of Native.",
                "At the higher bandwidths of 20 and 100 Mb/s, neither Ganesh nor Native is bandwidth limited and deliver equivalent throughput and response times.",
                "Benchmark Orig.",
                "Size Ganesh Size Rabin Size SelectSort1 223.6 MB 5.4 MB 219.3 MB SelectSort2 223.6 MB 5.4 MB 223.6 MB Table 2: Similarity Microbenchmarks 6.",
                "STRUCTURAL VS. RABIN SIMILARITY In this section, we address the second question raised in Section 4: How important is Ganeshs structural similarity detection relative to Rabin fingerprinting-based similarity detecting?",
                "To answer this question, we used microbenchmarks and the BBOARD and AUCTION benchmarks.",
                "As Ganesh always performed better than Rabin fingerprinting, we only present a subset of the results here in the interests of brevity. 6.1 Microbenchmarks Two microbenchmarks show an example of the effects of data reordering on Rabin fingerprinting algorithm.",
                "In the first microbenchmark, SelectSort1, a query with a specified sort order selects 223.6 MB of data spread over approximately 280 K rows.",
                "The query is then repeated with a different sort attribute.",
                "While the same number of rows and the same data is returned, the order of rows is different.",
                "In such a scenario, one would expect a large amount of similarity to be detected between both results.",
                "As Table 2 shows, Ganeshs row-based algorithm achieves a 97.6% reduction while the Rabin fingerprinting algorithm, with the average chunk size parameter set to 4 KB, only achieves a 1% reduction.",
                "The reason, as shown earlier in Figure 2, is that with Rabin fingerprinting, the spans of data between two consecutive boundaries usually cross row boundaries.",
                "With the order of the rows changing in the second result and the Rabin fingerprints now spanning different rows, the algorithm is unable to detect significant similarity.",
                "The small gain seen is mostly for those single rows that are large enough to be broken into multiple chunks.",
                "SelectSort2, another micro-benchmark executed the same queries but increased the minimum chunk size of the Rabin fingerprinting algorithm.",
                "As can be seen in Table 2, even the small gain from the previous microbenchmark disappears as the minimum chunk size was greater than the average row size.",
                "While one can partially address these problems by dynamically varying the parameters of the Rabin fingerprinting algorithm, this can be computationally expensive, especially in the presence of changing workloads. 6.2 Application Benchmarks We ran the BBOARD benchmark described in Section 4.1.1 on two versions of Ganesh: the first with Rabin fingerprinting used as WWW 2007 / Track: Performance and Scalability Session: Scalable Systems for Dynamic Content 317 0 50 100 150 200 250 300 350 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Test Clients Requests/sec Native Ganesh 0.001 0.01 0.1 1 10 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Test Clients Avg.Resp.Time(sec) Native Ganesh Note Logscale (a) Throughput: Bidding Mix (b) Response Time: Bidding Mix 0 50 100 150 200 250 300 350 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Test Clients Requests/sec Native Ganesh 0.001 0.01 0.1 1 10 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Test Clients Avg.Resp.Time(sec) Native Ganesh Note Logscale (c) Throughput: Browsing Mix (d) Response Time: Browsing Mix Mean of three trials.",
                "The maximum standard deviation for throughput and response time was 2.2% and 11.8% of the corresponding mean.",
                "Figure 8: AUCTION Benchmark - Throughput and Average Response Time the chunking algorithm and the second with Ganeshs row-based algorithm.",
                "Rabins results for the Browsing Mix are normalized to Ganeshs results and presented in Figure 9.",
                "As Figure 9 (a) shows, at 5 Mb/s, independent of the test client configuration, Rabin significantly underperforms Ganesh.",
                "This happens because of a combination of two reasons.",
                "First, as outlined in Section 3.1, Rabin finds less similarity as it does not exploit the results structural information.",
                "Second, this benchmark contained some queries that generated large results.",
                "In this case, Rabin, with a small average chunk size, generated a large number of objects that evicted other useful data from the cache.",
                "In contrast, Ganesh was able to detect these large rows and correspondingly increase the size of the chunks.",
                "This was confirmed as cache statistics showed that Ganeshs hit ratio was roughly three time that of Rabin.",
                "Throughput measurements at 20 Mb/s were similar with the exception of Rabins performance with 400 test clients.",
                "In this case, Ganesh was not network limited and, in fact, the throughput was the same as 400 clients at 5 Mb/s.",
                "Rabin, however, took advantage of the bandwidth increase from 5 to 20 Mb/s to deliver a slightly better performance.",
                "At 100 Mb/s, Rabins throughput was almost similar to Ganesh as bandwidth was no longer a bottleneck.",
                "The normalized response time, presented in Figure 9 (b), shows similar trends.",
                "At 5 and 20 Mb/s, the addition of test clients decreases the normalized response time as Ganeshs average response time increases faster than Rabins.",
                "However, at no point does Rabin outperform Ganesh.",
                "Note that at 400 and 800 clients at 100 Mb/s, Rabin does have a higher overhead even when it is not bandwidth constrained.",
                "As mentioned in Section 3.1, this is due to the fact that Rabin has to hash each ResultSet twice.",
                "The overhead disappears with 1200 and 1600 clients as the database CPU is saturated and limits the performance of both Ganesh and Rabin. 7.",
                "PROXY OVERHEAD In this section, we address the third question raised in Section 4: Is the overhead of Ganeshs proxy-based design acceptable?",
                "To answer this question, we concentrate on its performance at the higher bandwidths.",
                "Our evaluation in Section 5 showed that Ganesh, when compared to Native, can deliver a substantial throughput improvement at lower bandwidths.",
                "It is only at higher bandwidths that latency, measured by the average response time for a client request, and throughput, measured by the number of client requests that can be serviced per second, overheads would be visible.",
                "Looking at the Authoring mix of the original BBOARD benchmark, there are no visible gains from Ganesh at 100 Mb/s.",
                "Ganesh, however, still tracks Native in terms of throughput.",
                "While the average response time is higher for Ganesh, the absolute difference is in between 0.01 and 0.04 seconds and would be imperceptible to the end-user.",
                "The Browsing mix shows an even smaller difference in average response times.",
                "The results from the filter variant of the BBOARD benchmarks are similar.",
                "Even for the AUCTION benchmark, the difference between Native and Ganeshs response time at 100 Mb/s was never greater than 0.02 seconds.",
                "The only exception to the above results was seen in the filter variant of the BBOARD benchmark where Ganesh at 1600 test clients added 0.85 seconds to the average response time.",
                "Thus, even for much faster networks where the WAN link is not the bottleneck, Ganesh always delivers throughput equivalent to Native.",
                "While some extra latency is added by the proxy-based design, it is usually imperceptible. 8.",
                "RELATED WORK To the best of our knowledge, Ganesh is the first system that combines the use of hash-based techniques with caching of database results to improve throughput and response times for applications with dynamic content.",
                "We also believe that it is also the first system to demonstrate the benefits of using structural information for WWW 2007 / Track: Performance and Scalability Session: Scalable Systems for Dynamic Content 318 0.0 0.2 0.4 0.6 0.8 1.0 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Test Clients Norm.Throughput 31.8 3.8 2.8 2.3 23.8 32.8 5.8 3.6 1.8 2.1 1.1 1.0 0 5 10 15 20 25 30 35 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Test Clients Norm.ResponseTime (a) Normalized Throughput: Higher is better (b) Normalized Response Time: Higher is worse For throughput, a normalized result greater than 1 implies that Rabin is better, For response time, a normalized result greater than 1 implies that Ganesh is better.",
                "Mean of three trials.",
                "The maximum standard deviation for throughput and response time was 9.1% and 13.9% of the corresponding mean.",
                "Figure 9: Normalized Comparison of Ganesh vs. Rabin - BBOARD Browsing Mix detecting similarity.",
                "In this section, we first discuss alternative approaches to caching dynamic content and then examine other uses of hash-based primitives in distributed systems. 8.1 Caching Dynamic Content At the database layer, a number of systems have advocated middletier caching where parts of the database are replicated at the edge or server [3, 4, 20].",
                "These systems either cache entire tables in what is essentially a replicated database or use materialized views from previous query replies [19].",
                "They require tight integration with the back-end database to ensure a time bound on the propagation of updates.",
                "These systems are also usually targeted towards workloads that do not require strict consistency and can tolerate stale data.",
                "Further, unlike Ganesh, some of these mid-tier caching solutions [2, 3], suffer from the complexity of having to participate in query planing and distributed query processing.",
                "Gao et al. [15] propose using a distributed object replication architecture where the data stores consistency requirements are adapted on a per-application basis.",
                "These solutions require substantial developer resources and detailed understanding of the application being modified.",
                "While systems that attempt to automate the partitioning and replication of an applications database exist [34], they do not provide full transaction semantics.",
                "In comparison, Ganesh does not weaken any of the semantics provided by the underlying database.",
                "Recent work in the evaluation of edge caching options for dynamic web sites [38] has suggested that, without careful planning, employing complex offloading strategies can hurt performance.",
                "Instead, the work advocates for an architecture in which all tiers except the database should be offloaded to the edge.",
                "Our evaluation of Ganesh has shown that it would benefit these scenarios.",
                "To improve database scalability, C-JDBC [10], SSS [22], and Ganymed [28] also advocate the use of an interposition-based architecture to transparently cluster and replicate databases at the middleware level.",
                "The approaches of these architectures and Ganesh are complementary and they would benefit each other.",
                "Moving up to the presentation layer, there has been widespread adoption of fragment-based caching [14], which improves cache utilization by separately caching different parts of generated web pages.",
                "While fragment-based caching works at the edge, a recent proposal has proposed moving web page assembly to the clients to optimize content delivery [31].",
                "While Ganesh is not used at the presentation layer, the same principles have been applied in Duplicate Transfer Detection [25] to increase web cache efficiency as well as for web access across bandwidth limited links [33]. 8.2 Hash-based Systems The past few years have seen the emergence of many systems that exploit hash-based techniques.",
                "At the heart of all these systems is the idea of detecting similarity in data without requiring interpretation of that data.",
                "This simple yet elegant idea relies on cryptographic hashing, as discussed earlier in Section 2.",
                "Successful applications of this idea span a wide range of storage systems.",
                "Examples include peer-to-peer backup of personal computing files [11], storage-efficient archiving of data [29], and finding similar files [21].",
                "Spring and Wetherall [35] apply similar principles at the network level.",
                "Using synchronized caches at both ends of a network link, duplicated data is replaced by smaller tokens for transmission and then restored at the remote end.",
                "This and other hash-based systems such as the CASPER [37] and LBFS [26] filesystems, and Layer-2 bandwidth optimizers such as Riverbed and Peribit use Rabin fingerprinting [30] to discover spans of commonality in data.",
                "This approach is especially useful when data items are modified in-place through insertions, deletions, and updates.",
                "However, as Section 6 shows, the performance of this technique can show a dramatic drop in the presence of data reordering.",
                "Ganesh instead uses row boundaries as dividers for detecting similarity.",
                "The most aggressive use of hash-based techniques is by systems that use hashes as the primary identifiers for objects in persistent storage.",
                "Storage systems such as CFS [12] and PAST [13] that have been built using distributed hash tables fall into this category.",
                "Single Instance Storage [6] and Venti [29] are other examples of such systems.",
                "As discussed in Section 2.2, the use of cryptographic hashes for addressing persistent data represents a deeper level of faith in their collision-resistance than that assumed by Ganesh.",
                "If time reveals shortcomings in the hash algorithm, the effort involved in correcting the flaw is much greater.",
                "In Ganesh, it is merely a matter of replacing the hash algorithm. 9.",
                "CONCLUSION The growing use of dynamic web content generated from relational databases places increased demands on WAN bandwidth.",
                "Traditional caching solutions for bandwidth and latency reduction are often ineffective for such content.",
                "This paper shows that the impact of WAN accesses to databases can be substantially reduced through the Ganesh architecture without any compromise of the databases strict consistency semantics.",
                "The essence of the Ganesh architecture is the use of computation at the edges to reduce communication through the Internet.",
                "Ganesh is able to use cryptographic hashes to detect similarity with previous results and send WWW 2007 / Track: Performance and Scalability Session: Scalable Systems for Dynamic Content 319 compact recipes of results rather than full results.",
                "Our design uses interposition to achieve complete transparency: clients, application servers, and database servers are all unaware of Ganeshs presence and require no modification.",
                "Our experimental evaluation confirms that Ganesh, while conceptually simple, can be highly effective in improving throughput and response time.",
                "Our results also confirm that exploiting the structure present in database results to detect similarity is crucial to this performance improvement. 10.",
                "REFERENCES [1] AKELLA, A., SESHAN, S., AND SHAIKH, A.",
                "An empirical evaluation of wide-area internet bottlenecks.",
                "In Proc. 3rd ACM SIGCOMM Conference on Internet Measurement (Miami Beach, FL, USA, Oct. 2003), pp. 101-114. [2] ALTINEL, M., BORNH ¨OVD, C., KRISHNAMURTHY, S., MOHAN, C., PIRAHESH, H., AND REINWALD, B. Cache tables: Paving the way for an adaptive database cache.",
                "In Proc. of 29th VLDB (Berlin, Germany, 2003), pp. 718-729. [3] ALTINEL, M., LUO, Q., KRISHNAMURTHY, S., MOHAN, C., PIRAHESH, H., LINDSAY, B. G., WOO, H., AND BROWN, L. Dbcache: Database caching for web application servers.",
                "In Proc. 2002 ACM SIGMOD (2002), pp. 612-612. [4] AMIRI, K., PARK, S., TEWARI, R., AND PADMANABHAN, S. Dbproxy: A dynamic data cache for web applications.",
                "In Proc.",
                "IEEE International Conference on Data Engineering (ICDE) (Mar. 2003). [5] BLACK, J. Compare-by-hash: A reasoned analysis.",
                "In Proc. 2006 USENIX Annual Technical Conference (Boston, MA, May 2006), pp. 85-90. [6] BOLOSKY, W. J., CORBIN, S., GOEBEL, D., , AND DOUCEUR, J. R. Single instance storage in windows 2000.",
                "In Proc. 4th USENIX Windows Systems Symposium (Seattle, WA, Aug. 2000), pp. 13-24. [7] BREWER, E. A.",
                "Lessons from giant-scale services.",
                "IEEE Internet Computing 5, 4 (2001), 46-55. [8] BRODER, A., GLASSMAN, S., MANASSE, M., AND ZWEIG, G. Syntactic clustering of the web.",
                "In Proc. 6th International WWW Conference (1997). [9] CECCHET, E., CHANDA, A., ELNIKETY, S., MARGUERITE, J., AND ZWAENEPOEL, W. Performance comparison of middleware architectures for generating dynamic web content.",
                "In Proc.",
                "Fourth ACM/IFIP/USENIX International Middleware Conference (Rio de Janeiro, Brazil, June 2003). [10] CECCHET, E., MARGUERITE, J., AND ZWAENEPOEL, W. C-JDBC: Flexible database clustering middleware.",
                "In Proc. 2004 USENIX Annual Technical Conference (Boston, MA, June 2004). [11] COX, L. P., MURRAY, C. D., AND NOBLE, B. D. Pastiche: Making backup cheap and easy.",
                "In OSDI: Symposium on Operating Systems Design and Implementation (2002). [12] DABEK, F., KAASHOEK, M. F., KARGER, D., MORRIS, R., AND STOICA, I. Wide-area cooperative storage with CFS.",
                "In 18th ACM Symposium on Operating Systems Principles (Banff, Canada, Oct. 2001). [13] DRUSCHEL, P., AND ROWSTRON, A.",
                "PAST: A large-scale, persistent peer-to-peer storage utility.",
                "In HotOS VIII (Schloss Elmau, Germany, May 2001), pp. 75-80. [14] Edge side includes. http://www.esi.org. [15] GAO, L., DAHLIN, M., NAYATE, A., ZHENG, J., AND IYENGAR, A.",
                "Application specific data replication for edge services.",
                "In WWW 03: Proc.",
                "Twelfth International Conference on World Wide Web (2003), pp. 449-460. [16] HEMMINGER, S. Netem - emulating real networks in the lab.",
                "In Proc. 2005 Linux Conference Australia (Canberra, Australia, Apr. 2005). [17] HENSON, V. An analysis of compare-by-hash.",
                "In Proc. 9th Workshop on Hot Topics in Operating Systems (HotOS IX) (May 2003), pp. 13-18. [18] Jmob benchmarks. http://jmob.objectweb.org/. [19] LABRINIDIS, A., AND ROUSSOPOULOS, N. Balancing performance and data freshness in web database servers.",
                "In Proc. 29th VLDB Conference (Sept. 2003). [20] LARSON, P.-A., GOLDSTEIN, J., AND ZHOU, J. Transparent mid-tier database caching in sql server.",
                "In Proc. 2003 ACM SIGMOD (2003), pp. 661-661. [21] MANBER, U.",
                "Finding similar files in a large file system.",
                "In Proc.",
                "USENIX Winter 1994 Technical Conference (San Fransisco, CA, 17-21 1994), pp. 1-10. [22] MANJHI, A., AILAMAKI, A., MAGGS, B. M., MOWRY, T. C., OLSTON, C., AND TOMASIC, A.",
                "Simultaneous scalability and security for data-intensive web applications.",
                "In Proc. 2006 ACM SIGMOD (June 2006), pp. 241-252. [23] MENEZES, A. J., VANSTONE, S. A., AND OORSCHOT, P. C. V. Handbook of Applied Cryptography.",
                "CRC Press, 1996. [24] MILLER, R. B.",
                "Response time in man-computer conversational transactions.",
                "In Proc.",
                "AFIPS Fall Joint Computer Conference (1968), pp. 267-277. [25] MOGUL, J. C., CHAN, Y. M., AND KELLY, T. Design, implementation, and evaluation of duplicate transfer detection in http.",
                "In Proc.",
                "First Symposium on Networked Systems Design and Implementation (San Francisco, CA, Mar. 2004). [26] MUTHITACHAROEN, A., CHEN, B., AND MAZIERES, D. A low-bandwidth network file system.",
                "In Proc. 18th ACM Symposium on Operating Systems Principles (Banff, Canada, Oct. 2001). [27] PFEIFER, D., AND JAKSCHITSCH, H. Method-based caching in multi-tiered server applications.",
                "In Proc.",
                "Fifth International Symposium on Distributed Objects and Applications (Catania, Sicily, Italy, Nov. 2003). [28] PLATTNER, C., AND ALONSO, G. Ganymed: Scalable replication for transactional web applications.",
                "In Proc. 5th ACM/IFIP/USENIX International Conference on Middleware (2004), pp. 155-174. [29] QUINLAN, S., AND DORWARD, S. Venti: A new approach to archival storage.",
                "In Proc.",
                "FAST 2002 Conference on File and Storage Technologies (2002). [30] RABIN, M. Fingerprinting by random polynomials.",
                "In Harvard University Center for Research in Computing Technology Technical Report TR-15-81 (1981). [31] RABINOVICH, M., XIAO, Z., DOUGLIS, F., AND KALMANEK, C. Moving edge side includes to the real edge - the clients.",
                "In Proc. 4th USENIX Symposium on Internet Technologies and Systems (Seattle, WA, Mar. 2003). [32] REESE, G. Database Programming with JDBC and Java, 1st ed.",
                "OReilly, June 1997. [33] RHEA, S., LIANG, K., AND BREWER, E. Value-based web caching.",
                "In Proc.",
                "Twelfth International World Wide Web Conference (May 2003). [34] SIVASUBRAMANIAN, S., ALONSO, G., PIERRE, G., AND VAN STEEN, M. Globedb: Autonomic data replication for web applications.",
                "In WWW 05: Proc. 14th International World-Wide Web conference (May 2005). [35] SPRING, N. T., AND WETHERALL, D. A protocol-independent technique for eliminating redundant network traffic.",
                "In Proc. of ACM SIGCOMM (Aug. 2000). [36] TOLIA, N., HARKES, J., KOZUCH, M., AND SATYANARAYANAN, M. Integrating portable and distributed storage.",
                "In Proc. 3rd USENIX Conference on File and Storage Technologies (San Francisco, CA, Mar. 2004). [37] TOLIA, N., KOZUCH, M., SATYANARAYANAN, M., KARP, B., PERRIG, A., AND BRESSOUD, T. Opportunistic use of content addressable storage for distributed file systems.",
                "In Proc. 2003 USENIX Annual Technical Conference (San Antonio, TX, June 2003), pp. 127-140. [38] YUAN, C., CHEN, Y., AND ZHANG, Z.",
                "Evaluation of edge caching/offloading for dynamic content delivery.",
                "In WWW 03: Proc.",
                "Twelfth International Conference on World Wide Web (2003), pp. 461-471.",
                "WWW 2007 / Track: Performance and Scalability Session: Scalable Systems for Dynamic Content 320"
            ],
            "original_annotated_samples": [
                "The end of a row in a result serves as a <br>natural chunk boundary</br>."
            ],
            "translated_annotated_samples": [
                "El final de una fila en un resultado sirve como un <br>límite natural de fragmento</br>."
            ],
            "translated_text": "Conservación de la consistencia en el almacenamiento en caché de contenido dinámico de bases de datos∗ Niraj Tolia y M. Satyanarayanan Universidad Carnegie Mellon {ntolia,satya}@cs.cmu.edu RESUMEN Con el creciente uso de contenido web dinámico generado a partir de bases de datos relacionales, las soluciones de almacenamiento en caché tradicionales para mejorar el rendimiento y la latencia son ineficaces. Describimos una capa de middleware llamada Ganesh que reduce el volumen de datos transmitidos sin interpretación semántica de consultas o resultados. Se logra esta reducción mediante el uso de hash criptográficos para detectar similitudes con resultados anteriores. Estos beneficios no requieren ningún compromiso con la semántica de consistencia estricta proporcionada por la base de datos del servidor. Además, Ganesh no requiere modificaciones en aplicaciones, servidores web o servidores de bases de datos, y funciona con aplicaciones y bases de datos de código cerrado. Usando dos puntos de referencia representativos de sitios web dinámicos, las mediciones de nuestro prototipo muestran que puede aumentar el rendimiento de extremo a extremo hasta en un factor de dos para aplicaciones no intensivas en datos y hasta en un factor de diez para las intensivas en datos. Categorías y Descriptores de Asignaturas C.2.4 [Redes de Computadoras-Comunicación]: Sistemas Distribuidos; H.2.4 [Gestión de Bases de Datos]: Términos Generales de Sistemas de Diseño, Rendimiento 1. INTRODUCCIÓN Una fracción creciente del contenido web se genera dinámicamente a partir de bases de datos relacionales en el backend. Incluso cuando el contenido de la base de datos permanece sin cambios, la localidad temporal de acceso no puede ser explotada porque el contenido dinámico no es almacenable en caché por los navegadores web o por servidores de almacenamiento en caché intermedios como los espejos de Akamai. En una arquitectura multinivel, cada solicitud web puede tensionar el enlace WAN entre el servidor web y la base de datos. Esto provoca que la experiencia del usuario sea altamente variable porque no hay almacenamiento en caché para aislar al cliente de cargas repentinas. Los intentos previos de almacenar en caché contenido dinámico de bases de datos generalmente han debilitado la semántica transaccional [3, 4] o han requerido modificaciones en la aplicación [15, 34]. Informamos sobre una nueva solución que toma la forma de una capa intermedia de middleware independiente de la base de datos llamada Ganesh. Ganesh no hace ningún esfuerzo por interpretar semánticamente el contenido de las consultas o sus resultados. En cambio, se basa exclusivamente en el hash criptográfico para detectar similitudes con resultados anteriores. La detección de similitud basada en hash ha sido cada vez más utilizada en sistemas de archivos distribuidos [26, 36, 37] para mejorar el rendimiento en redes de baja capacidad de ancho de banda. Sin embargo, estas técnicas no se han utilizado para bases de datos relacionales. A diferencia de enfoques anteriores que utilizan métodos genéricos para detectar similitud, Ganesh explota la estructura de los resultados de la base de datos relacional para lograr una mejora superior en el rendimiento. Uno se enfrenta al menos a tres desafíos al aplicar la detección de similitud basada en hash a las bases de datos de back-end. Primero, el trabajo previo en este ámbito ha considerado tradicionalmente el contenido de almacenamiento como bolsas de bits no interpretadas y sin estructura interna. Esto permite que las técnicas basadas en hash operen en largas y contiguas secuencias de datos para lograr la máxima efectividad. Por el contrario, las bases de datos relacionales tienen una estructura interna compleja que puede no ser tan propicia para la detección de similitudes basada en hash. Segundo, las bases de datos relacionales tienen restricciones de integridad y consistencia muy estrictas que no deben comprometerse por el uso de técnicas basadas en hash. Tercero, el código fuente de las bases de datos comerciales generalmente no está disponible. Esto contrasta con trabajos anteriores que presumían la disponibilidad del código fuente. Nuestros experimentos muestran que Ganesh, aunque conceptualmente simple, puede mejorar significativamente el rendimiento en anchos de banda representativos del Internet comercial actual. En los modelos de referencia de aplicaciones web multinivel, la mejora en el rendimiento fue de hasta diez veces para cargas de trabajo intensivas en datos. Para cargas de trabajo que no eran intensivas en datos, se observaron mejoras en el rendimiento de hasta el doble. Incluso cuando el ancho de banda no era una limitación, Ganesh tenía un bajo sobrecosto y no afectaba el rendimiento. Nuestros experimentos también confirman que aprovechar la estructura presente en los resultados de la base de datos es crucial para esta mejora en el rendimiento. Antecedentes 2.1 Generación de Contenido Dinámico A medida que la World Wide Web ha crecido, muchos sitios web han descentralizado sus datos y funcionalidades al llevarlos a los extremos de Internet. Hoy en día, los sistemas de comercio electrónico a menudo utilizan una arquitectura de tres niveles que consta de un servidor web de front-end, un servidor de aplicaciones y un servidor de base de datos de back-end. La Figura 1 ilustra esta arquitectura. Los dos primeros niveles se pueden replicar cerca de una concentración de clientes en el borde de Internet. Esto mejora la experiencia del usuario al reducir la latencia de extremo a extremo y disminuir la exposición al congestionamiento del tráfico de la columna vertebral. También puede aumentar la disponibilidad y escalabilidad de los servicios web. El contenido que se genera dinámicamente desde la base de datos del servidor no puede ser almacenado en caché en los dos primeros niveles. Si bien las bases de datos pueden replicarse fácilmente en una LAN, esto es inviable en una WAN debido a la difícil tarea de proporcionar simultáneamente una consistencia sólida, disponibilidad y tolerancia a particiones de red [7]. Como resultado, las bases de datos tienden a ser centralizadas para cumplir con los fuertes requisitos de consistencia de muchas aplicaciones de comercio electrónico como la banca, las finanzas y la venta al por menor en línea [38]. Por lo tanto, la base de datos del back-end suele estar ubicada lejos de muchos conjuntos de nodos de primer y segundo nivel [2]. En ausencia de almacenamiento en caché y replicación, el ancho de banda de la WAN puede convertirse fácilmente en un factor limitante en el rendimiento y la escalabilidad de aplicaciones intensivas en datos. El enfoque de Ganesh en los sistemas basados en hash es la transmisión eficiente de resultados al descubrir similitudes con los resultados de consultas anteriores. Dado que las consultas SQL pueden generar resultados grandes, las técnicas basadas en hash se prestan bien al problema de transferir eficientemente estos grandes resultados a través de enlaces con ancho de banda limitado. El uso de técnicas basadas en hash para reducir el volumen de datos transmitidos ha surgido como un tema común en muchos sistemas de almacenamiento recientes, como se discute en la Sección 8.2. Estas técnicas se basan en algunas suposiciones básicas. Se asume que las funciones hash criptográficas son resistentes a colisiones. En otras palabras, es computacionalmente intratable encontrar dos entradas que se hash a la misma salida. Las funciones también se asumen como unidireccionales; es decir, encontrar una entrada que resulte en una salida específica es computacionalmente inviable. Menezes et al. [23] proporcionan más detalles sobre estas suposiciones. Las suposiciones anteriores permiten a los sistemas basados en hash asumir que no se producen colisiones. Por lo tanto, pueden tratar el hash de un elemento de datos como su identificador único. Una colección de elementos de datos se convierte efectivamente en direccionable por contenido, permitiendo que un hash pequeño funcione como una palabra de código para un elemento de datos mucho más grande en almacenamiento permanente o transmisión en red. La suposición de que las colisiones son tan raras que prácticamente no existen ha sido cuestionada recientemente [17]. Sin embargo, como explicó Black [5], creemos que estos problemas no son una preocupación para Ganesh. Toda comunicación es entre partes confiables del sistema y un adversario no tiene forma de obligar a Ganesh a aceptar datos inválidos. Además, Ganesh no depende críticamente de ninguna función hash específica. Si bien actualmente usamos SHA-1, reemplazarlo con una función hash diferente sería sencillo. No habría impacto en el rendimiento con funciones hash más fuertes (por ejemplo, SHA256) solo añade unos pocos bytes adicionales y los hashes generados siguen siendo órdenes de magnitud más pequeños que los elementos de datos que representan. No es necesario volver a almacenar permanentemente ya que Ganesh solo utiliza el hash en datos volátiles. 3. DISEÑO E IMPLEMENTACIÓN Ganesh explota la redundancia en el flujo de resultados para evitar transmitir fragmentos de resultados que ya están presentes en el sitio de la consulta. La redundancia puede surgir de forma natural de muchas maneras diferentes. Por ejemplo, una consulta repetida después de un cierto intervalo puede devolver un resultado diferente debido a actualizaciones en la base de datos; sin embargo, puede haber una significativa similitud entre los dos resultados. Como otro ejemplo, un usuario que está refinando una búsqueda puede generar una secuencia de consultas con resultados superpuestos. Cuando Ganesh detecta redundancia, suprime la transmisión de los fragmentos de resultado correspondientes. En cambio, transmite un resumen mucho más pequeño de esos fragmentos y permite que el sitio de consulta reconstruya el resultado a través de la búsqueda de hash en una caché de resultados anteriores. De hecho, Ganesh utiliza la computación en los bordes para reducir la comunicación por Internet. Nuestra descripción de Ganesh se centra en cuatro aspectos. Primero explicamos nuestro enfoque para detectar similitud en los resultados de la consulta. A continuación, discutimos cómo la arquitectura Ganesh es completamente invisible para todos los componentes de un sistema de múltiples niveles. Luego describimos el enfoque basado en proxy de Ganesh y el flujo de datos para detectar similitudes. 3.1 Detectar similitud Una de las decisiones clave de diseño en Ganesh es cómo se detecta la similitud. Hay muchas formas potenciales de descomponer un resultado en fragmentos.  I the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the thees I,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,, Encontrar esta descomposición óptima es un problema difícil debido al amplio espacio de posibilidades y porque la elección óptima depende de muchos factores, como el contenido del resultado de las consultas, el historial de resultados recientes y el algoritmo de gestión de caché. Cuando un objeto es opaco, el uso de huellas digitales de Rabin [8, 30] para detectar datos comunes entre dos objetos ha sido demostrado con éxito en el pasado por sistemas como LBFS [26] y CASPER [37]. El fingerprinting de Rabin utiliza una ventana deslizante sobre los datos para calcular un hash rodante. Suponiendo que la función hash está distribuida uniformemente, un límite de fragmento se define cuando los bits de orden inferior del valor hash son iguales a algún valor predeterminado. El número de bits de orden inferior utilizados define el tamaño promedio del fragmento. Estos fragmentos subdivididos del objeto se convierten en la unidad de comparación para detectar similitudes entre diferentes objetos. Dado que las ubicaciones de los límites encontrados mediante el uso de las huellas de Rabin están determinadas de manera estocástica, generalmente no logran alinearse con ninguna propiedad estructural de los datos subyacentes. Por lo tanto, el algoritmo maneja bien las actualizaciones en su lugar, inserciones y eliminaciones. Sin embargo, tiene un rendimiento deficiente en presencia de cualquier reordenamiento de datos. La Figura 2 muestra un ejemplo donde dos resultados, A y B, que constan de tres filas, tienen los mismos datos pero diferentes atributos de ordenamiento. En el caso extremo, la huella digital de Rabin podría no ser capaz de encontrar datos similares debido a la forma en que detecta los límites de los fragmentos. Afortunadamente, Ganesh puede utilizar conocimientos específicos del dominio para una detección de límites más precisa. La información que explotamos es que el resultado de una consulta refleja la estructura de una base de datos relacional donde todos los datos están organizados en tablas y filas. Por lo tanto, es sencillo verificar la similitud con resultados anteriores en dos niveles de granularidad: primero el resultado completo y luego las filas individuales. El final de una fila en un resultado sirve como un <br>límite natural de fragmento</br>. Es importante tener en cuenta que el uso de la estructura tabular en los resultados solo implica una interpretación superficial de los datos. Ganesh no realiza ninguna interpretación semántica más profunda, como comprender tipos de datos, esquemas de resultados o restricciones de integridad. Ajustar la huella digital de Rabin para una carga de trabajo también puede ser difícil. Si el tamaño promedio de los fragmentos es demasiado grande, los fragmentos pueden abarcar varias filas de resultados. Sin embargo, seleccionar un tamaño de fragmento promedio más pequeño aumenta la cantidad de metadatos necesarios para describir los resultados. Esto, a su vez, disminuiría los ahorros obtenidos mediante su uso. El fingerprinting de Rabin también requiere dos pasadas computacionalmente costosas sobre los datos: una vez para determinar los límites de los fragmentos y otra vez para generar hashes criptográficos para los fragmentos. Ganesh solo necesita un único pase para la generación de hash, ya que los límites de los fragmentos son proporcionados por la estructura natural de los datos. La comparación de rendimiento en la Sección 6 muestra que el algoritmo basado en filas de Ganesh supera al fingerprinting de Rabin. Dado que trabajos anteriores ya han demostrado que la huella digital de Rabin funciona mejor que gzip [26], no comparamos a Ganesh con algoritmos de compresión en este artículo. 3.2 Transparencia El factor clave que influyó en nuestro diseño fue la necesidad de que Ganesh fuera completamente transparente para todos los componentes de un sistema típico de comercio electrónico: servidores web, servidores de aplicaciones y servidores de bases de datos. Sin esto, Ganesh tiene pocas posibilidades de tener un impacto significativo en el mundo real. Requerir modificaciones en cualquiera de los componentes mencionados aumentaría la barrera de entrada de Ganesh en un sistema existente, y por lo tanto reduciría sus posibilidades de adopción. Preservar la transparencia se simplifica por el hecho de que Ganesh es simplemente una mejora de rendimiento, no una mejora de funcionalidad o usabilidad. Elegimos la interposición de agentes como enfoque arquitectónico para lograr nuestro objetivo. Este enfoque se basa en la existencia de una interfaz de programación compacta que ya es ampliamente utilizada por el software objetivo. También se basa en un mecanismo para agregar fácilmente nuevo código sin interrumpir la estructura de módulos existente. Estas condiciones se cumplen fácilmente en nuestro contexto debido a la popularidad de Java como el lenguaje de programación para sistemas de comercio electrónico. La API de Conectividad de Base de Datos de Java (JDBC) [32] permite a las aplicaciones de Java acceder a una amplia variedad de bases de datos e incluso a otros repositorios de datos tabulares como archivos planos. El acceso a estas fuentes de datos es proporcionado por controladores JDBC que traducen entre la API JDBC y el mecanismo de comunicación de la base de datos. La figura 3(a) muestra cómo se utiliza típicamente JDBC en una aplicación. Dado que la interfaz JDBC está estandarizada, se puede sustituir un controlador JDBC por otro sin necesidad de de modificar la aplicación. El controlador JDBC se convierte así en el módulo natural para aprovechar la interposición de código. Como se muestra en la Figura 3(b), el controlador JDBC nativo es reemplazado por un controlador JDBC Ganesh que presenta la misma interfaz estandarizada. El controlador Ganesh mantiene una caché en memoria de fragmentos de resultados de consultas anteriores y realiza el reensamblaje de resultados. En la base de datos, agregamos un nuevo proceso llamado el proxy Ganesh. Este proxy, que puede ser compartido por múltiples nodos front-end, consta de dos partes: código para detectar similitud en fragmentos de resultados y el controlador JDBC nativo original que se comunica con la base de datos. El uso de un proxy en la base de datos hace que Ganesh sea independiente de la base de datos y simplifica la creación de prototipos y experimentación. Ganesh es capaz de trabajar con una amplia gama de bases de datos y aplicaciones, sin necesidad de realizar modificaciones en ninguna de ellas. 3.3 Caché basada en proxy El controlador JDBC nativo mostrado en la Figura 3(a) es un componente de código ligero suministrado por el proveedor de la base de datos. Su función principal es mediar la comunicación entre la aplicación y la base de datos remota. Reenvía consultas, almacena resultados completos y responde a solicitudes de la aplicación para ver partes de los resultados. El controlador JDBC de Ganesh mostrado en la Figura 3(b) presenta a la aplicación una interfaz idéntica a la proporcionada por el controlador nativo. Proporciona la capacidad de reconstruir resultados a partir de descripciones compactas basadas en hash enviadas por el proxy. Para realizar esta reconstrucción, el controlador mantiene una caché en memoria de los resultados recibidos recientemente. Esta caché solo se utiliza como fuente de fragmentos de resultados en la reconstrucción de resultados. El conductor Ganesh o el proxy no intentan rastrear las actualizaciones de la base de datos. La falta de consistencia en la caché no afecta a la corrección, ya que la descripción de los resultados siempre se obtiene del proxy; en el peor de los casos, no habrá beneficio de rendimiento al usar Ganesh. Los datos obsoletos simplemente se eliminarán de la caché con el tiempo. El proxy de Ganesh accede a la base de datos a través del controlador JDBC nativo, que permanece sin cambios entre las Figuras 3(a) y (b). La base de datos está completamente ajena a la existencia del proxy. El proxy no examina ninguna consulta recibida del controlador Ganesh, sino que las pasa al controlador nativo. En cambio, el proxy es responsable de inspeccionar la salida de la base de datos recibida del controlador nativo, detectar resultados similares y generar codificaciones basadas en hash de estos resultados siempre que se encuentre suficiente similitud. Si bien esta arquitectura no disminuye la carga en una base de datos, como se mencionó anteriormente en la Sección 2.1, es mucho más fácil replicar bases de datos para escalabilidad en una LAN que en una WAN. Para generar una codificación basada en hash, el proxy debe estar al tanto de qué fragmentos de resultados están disponibles en la caché de controladores de Ganesh. Un enfoque es ser optimista y asumir que todos los fragmentos de resultados están disponibles. Esto resultará en la transmisión inicial más pequeña posible de un resultado. Sin embargo, en casos donde hay poca superposición con resultados anteriores, el controlador Ganesh tendrá que realizar muchas llamadas al proxy durante la reconstrucción para recuperar fragmentos de resultados faltantes. Para evitar esta situación, el proxy sigue de manera flexible el estado de la caché de controladores de Ganesh. Dado que ambos componentes están bajo nuestro control, es relativamente sencillo hacer esto sin recurrir a técnicas de caja gris o comunicación explícita para mantener la coherencia de la caché. En cambio, el proxy simula el algoritmo de gestión de caché de controladores de Ganesh y lo utiliza para mantener una lista de hashes para los cuales es probable que el controlador de Ganesh posea los fragmentos de resultado. En caso de desviación de seguimiento, no habrá pérdida de corrección, pero habrá retrasos adicionales en el viaje de ida y vuelta para recuperar los fragmentos faltantes. Si el cliente detecta la pérdida de sincronización con el proxy, puede pedirle al proxy que restablezca el estado compartido entre ellos. También hay que tener en cuenta que el proxy no necesita guardar los fragmentos de resultado en sí, solo sus hashes. Esto permite que el proxy siga siendo escalable incluso cuando es compartido por muchos nodos front-end. El proxy Ganesh recibe la salida de la base de datos como objetos Java del controlador JDBC nativo. Examina esta salida para ver si está presente un objeto Java del tipo ResultSet. La interfaz JDBC utiliza este tipo de dato para almacenar los resultados de las consultas a la base de datos. Si se encuentra un objeto ResultSet, se reduce como se discute a continuación. Todos los demás objetos de Java se pasan sin modificar. Como se discute en la Sección 3.1, el proxy utiliza los límites de fila definidos en el ResultSet para dividirlo en fragmentos que consisten en filas de resultado individuales. Todos los objetos ResultSet se convierten en objetos de un nuevo tipo llamado RecipeResultSet. Utilizamos el término receta para esta descripción compacta de un resultado de base de datos debido a su similitud con una receta de archivo en el sistema de archivos CASPER [37]. La conversión reemplaza cada fragmento de resultado que probablemente esté presente en la caché de controladores de Ganesh por un hash SHA-1 de ese fragmento. Los fragmentos de resultados previamente no vistos se conservan textualmente. El proxy también retiene los hashes de los nuevos fragmentos de resultados, ya que estarán presentes en la caché de los controladores en el futuro. Ten en cuenta que el proxy solo almacena en caché los hashes de los fragmentos de resultados y no almacena en caché las recetas. El proxy construye un RecipeResultSet verificando la similitud en todo el resultado y luego a nivel de fila. Si se predice que todo el resultado estará presente en la caché de los controladores de Ganesh, el RecipeResultSet será simplemente un único hash de todo el resultado. De lo contrario, contiene hashes para aquellas filas que se predice que están presentes en esa caché; todas las demás filas se conservan textualmente. Si el proxy estima un ahorro de espacio general, transmitirá el RecipeResultSet. De lo contrario, se transmite el ResultSet original. Los objetos RecipeResultSet son transformados de vuelta en objetos ResultSet por el controlador Ganesh. La Figura 4 ilustra el manejo de ResultSet en ambos extremos. Cada hash SHA-1 encontrado en un RecipeResultSet se busca en la caché local de fragmentos de resultados. En caso de acierto, el hash es reemplazado por el fragmento correspondiente. En caso de error, el conductor contacta al proxy de Ganesh para recuperar el fragmento. Todos los fragmentos de resultados previamente no vistos que fueron retenidos textualmente por el proxy se hasheado y se han añadido a la caché de resultados. Debería haber muy pocos fallos si el proxy ha seguido con precisión el estado de la caché de controladores de Ganesh. Una optimización futura sería agrupar la obtención de fragmentos faltantes. Esto sería valioso cuando hay muchos pequeños fragmentos faltantes en una WAN de alta latencia. Una vez que la transformación esté completa, el objeto ResultSet completamente reconstruido se pasa a la aplicación. 4. VALIDACIÓN EXPERIMENTAL Tres preguntas surgen de los objetivos y diseño de Ganesh: • Primero, ¿se puede mejorar significativamente el rendimiento al explotar la similitud entre los resultados de la base de datos? Detalles del conjunto de datos de referencia 500,000 usuarios, 12,000 historias BBOARD 2.0 GB 3,298,000 comentarios SUBASTA 1.3 GB 1,000,000 usuarios, 34,000 elementos Tabla 1: Detalles del conjunto de datos de referencia • En segundo lugar, ¿qué tan importante es la detección de similitud estructural de Ganesh en comparación con la detección de similitud de la huella digital de Rabin? • En tercer lugar, ¿es aceptable la sobrecarga del diseño basado en proxy? Nuestra evaluación responde a estas preguntas a través de experimentos controlados con el prototipo Ganesh. Esta sección describe los puntos de referencia utilizados, nuestro procedimiento de evaluación y la configuración experimental. Los resultados de los experimentos se presentan en las Secciones 5, 6 y 7. 4.1 Puntos de referencia Nuestra evaluación se basa en dos puntos de referencia [18] que han sido ampliamente utilizados por otros investigadores para evaluar varios aspectos de arquitecturas multi-tier [27] y de comercio electrónico [9]. El primer punto de referencia, BBOARD, está modelado según Slashdot, un sitio de noticias orientado a la tecnología. El segundo punto de referencia, AUCTION, está modelado según eBay, un sitio de subastas en línea. En ambos puntos de referencia, la mayoría del contenido se genera dinámicamente a partir de la información almacenada en una base de datos. Los detalles de los conjuntos de datos utilizados se pueden encontrar en la Tabla 1. 4.1.1 El Benchmark BBOARD El benchmark BBOARD, también conocido como RUBBoS [18], modela Slashdot, un popular sitio web orientado a la tecnología. Slashdot recopila enlaces a noticias y otros temas de interés encontrados en otros lugares de la web. El sitio también funciona como un tablón de anuncios al permitir a los usuarios comentar en las historias publicadas en forma de conversación en hilos. No es raro que una historia recopile cientos de comentarios en cuestión de horas. El benchmark BBOARD es similar al sitio y modela las actividades de un usuario, incluyendo operaciones de solo lectura como navegar por las historias del día, explorar categorías de historias y ver comentarios, así como operaciones de escritura como registro de nuevos usuarios, agregar y moderar comentarios, y enviar historias. El benchmark consiste en tres fases diferentes: una fase de calentamiento corta, una fase de ejecución que representa el cuerpo principal de la carga de trabajo, y una fase de enfriamiento corta. En este documento solo informamos sobre los resultados de la fase de ejecución. La fase de calentamiento es importante para establecer el estado del sistema dinámico, pero las mediciones de esa fase no son significativas para nuestra evaluación. La fase de enfriamiento es únicamente para permitir que el punto de referencia se apague. Las fases de calentamiento, ejercicio y enfriamiento son de 2, 15 y 2 minutos respectivamente. El número de clientes simulados fue de 400, 800, 1200 y 1600. El punto de referencia está disponible en una versión de Java Servlets y PHP y tiene diferentes conjuntos de datos; evaluamos a Ganesh utilizando la versión de Java Servlets y el conjunto de datos Expandido. El benchmark BBOARD define dos cargas de trabajo diferentes. El primero, la mezcla de Autoría, consiste en un 70% de operaciones de solo lectura y un 30% de operaciones de lectura y escritura. El segundo, la mezcla de navegación, contiene solo operaciones de solo lectura y no actualiza la base de datos. 4.1.2 El Benchmark de SUBASTA El benchmark de SUBASTA, también conocido como RUBiS [18], modela eBay, el sitio de subastas en línea. El sitio web de eBay se utiliza para comprar y vender artículos a través de un formato de subasta. Las principales actividades de un usuario incluyen navegar, vender o pujar por artículos. Modelando las actividades en este sitio, este punto de referencia incluye actividades de solo lectura como navegar por artículos por categoría y por región, así como actividades de lectura-escritura como pujar por artículos, comprar y vender artículos, y dejar comentarios. Al igual que con BBOARD, el benchmark consiste en tres fases diferentes. Las fases de calentamiento, ejecución y enfriamiento para este experimento son de 1.5, 15 y 1 minutos respectivamente. Probamos Ganesh con cuatro configuraciones de clientes donde el número de clientes de prueba se estableció en 400, 800, 1200 y 1600. El punto de referencia está disponible en una versión de Enterprise Java Bean (EJB), Java Servlets y PHP y tiene diferentes conjuntos de datos; evaluamos Ganesh con la versión de Java Servlets y el conjunto de datos Expandido. El benchmark de SUBASTA define dos cargas de trabajo diferentes. El primero, la mezcla de Ofertas, consiste en un 70% de operaciones de solo lectura y un 30% de operaciones de lectura-escritura. El segundo, la mezcla de navegación, contiene solo operaciones de solo lectura y no actualiza la base de datos. 4.2 Procedimiento Experimental Ambos benchmarks involucran una carga de trabajo sintética de clientes accediendo a un servidor web. El número de clientes emulados es un parámetro experimental. Cada cliente emulado ejecuta una instancia del benchmark en su propio hilo, utilizando una matriz para hacer la transición entre diferentes estados del benchmark. La matriz define un modelo estocástico con probabilidades de transición entre los diferentes estados que representan las acciones típicas de los usuarios. Un ejemplo de transición es un usuario iniciando sesión en el sistema de SUBASTA y luego decidiendo si publicar un artículo en venta o pujar en subastas activas. Cada cliente también modela el tiempo de pensamiento del usuario entre las solicitudes. El tiempo de pensamiento se modela como una distribución exponencial con una media de 7 segundos. Evaluamos a Ganesh a lo largo de dos ejes: número de clientes y ancho de banda de la WAN. Las cargas más altas son especialmente útiles para comprender el rendimiento de Ganesh cuando la CPU o el disco del servidor de base de datos o del proxy son el factor limitante. Un estudio previo ha demostrado que aproximadamente el 50% de los cuellos de botella de Internet de gran área observados tenían un ancho de banda disponible inferior a 10 Mb/s [1]. Basándonos en este trabajo, enfocamos nuestra evaluación en el ancho de banda de la WAN de 5 Mb/s con una latencia de ida y vuelta de 66 ms, representativa de rutas de red severamente restringidas, y 20 Mb/s con una latencia de ida y vuelta de 33 ms, representativa de una ruta de red moderadamente restringida. También informamos sobre el rendimiento de Ganesh a 100 Mb/s sin agregar latencia de ida y vuelta. Este ancho de banda, representativo de una red sin restricciones, es especialmente útil para revelar cualquier sobrecarga potencial de Ganesh en situaciones donde el ancho de banda de la WAN no es el factor limitante. Para cada combinación de número de clientes y ancho de banda de WAN, medimos los resultados de las dos configuraciones enumeradas a continuación: • Nativa: Esta configuración corresponde a la Figura 3(a). El nativo evita la sobrecarga de Ganesh al usar un proxy y realizar la serialización de objetos Java. • Ganesh: Esta configuración corresponde a la Figura 3(b). Para un número dado de clientes y ancho de banda de WAN, comparar estos resultados con los resultados nativos correspondientes proporciona el beneficio de rendimiento debido al sistema de middleware Ganesh. La métrica utilizada para cuantificar la mejora en el rendimiento es el número de solicitudes de clientes que pueden ser atendidas por segundo. La métrica utilizada para cuantificar el rendimiento de Ganesh es el tiempo promedio de respuesta para una solicitud de cliente. Para todos los experimentos, el controlador Ganesh utilizado por el servidor de aplicaciones usó un tamaño de caché de 100,000 elementos. El proxy fue efectivo en rastrear el estado de la caché de los controladores Ganesh; para todos nuestros experimentos, la tasa de fallos en el controlador nunca superó el 0.7%. 4.3 Configuración Experimental La configuración experimental utilizada para las pruebas se puede ver en la Figura 5. Todas las máquinas eran Pentium 4 de 3.2 GHz (con HyperThreading habilitado). Con la excepción del servidor de base de datos, todas las máquinas tenían 2 GB de SDRAM y ejecutaban la distribución de Linux Fedora Core. El servidor de la base de datos tenía 4 GB de SDRAM. Utilizamos Apache Tomcat como tanto el servidor de aplicaciones que alojaba los Servlets de Java como el servidor web. Ambos benchmarks utilizaron Java Servlets para generar el contenido dinámico. El servidor de la base de datos utilizó la base de datos de código abierto MySQL. Para los controladores JDBC nativos, utilizamos los controladores Connector/J proporcionados por MySQL. El servidor de aplicaciones utilizaba la Máquina Virtual de Java de Sun como entorno de ejecución para los Servlets de Java. La herramienta sysstat se utilizó para monitorear la utilización de la CPU, red, disco y memoria en todas las máquinas. Las máquinas estaban conectadas por una red Ethernet gigabit conmutada. Como se muestra en la Figura 5, el servidor web y de aplicación de front-end fue separado del servidor de proxy y base de datos por un enrutador NetEm [16]. Este enrutador nos permitió controlar la configuración de ancho de banda y latencia en la red. El enrutador NetEm es un PC estándar con dos tarjetas de red que ejecuta el software de Control de Tráfico de Linux y Emulación de Red. Las restricciones de ancho de banda y latencia solo se aplicaron al enlace entre el servidor de aplicaciones y la base de datos para el caso nativo y entre el servidor de aplicaciones y el proxy para el caso de Ganesh. No hay comunicación entre el servidor de aplicaciones y la base de datos con Ganesh, ya que todos los datos fluyen a través del proxy. Como nuestro enfoque estaba en el enlace WAN entre el servidor de aplicaciones y la base de datos, no hubo restricciones en el enlace entre los clientes de prueba simulados y el servidor web. 5. DESEMPEÑO Y TIEMPO DE RESPUESTA En esta sección, abordamos la primera pregunta planteada en la Sección 4: ¿Se puede mejorar significativamente el rendimiento explotando la similitud entre los resultados de la base de datos? Para responder a esta pregunta, utilizamos los resultados de los benchmarks BBOARD y AUCTION. Utilizamos dos métricas para cuantificar la mejora en el rendimiento obtenible a través del uso de Ganesh: el throughput, desde la perspectiva del servidor web, y el tiempo de respuesta promedio, desde la perspectiva del cliente. El rendimiento se mide en términos del número de solicitudes de clientes que pueden ser atendidas por segundo. Los resultados y análisis de BBOARD 5.1 Figuras 6 (a) y (b) presentan el número promedio de solicitudes atendidas por segundo y el tiempo de respuesta promedio para estas solicitudes tal como lo perciben los clientes para la Mezcla de Autoría de BBOARD. Como muestra la Figura 6 (a), Native satura fácilmente el enlace de 5 Mb/s. Con 400 clientes, la solución nativa entrega 29 solicitudes/segundo con un tiempo de respuesta promedio de 8.3 segundos. La capacidad de procesamiento de los clientes disminuye con un aumento en los clientes de prueba, ya que los clientes se agotan debido a la congestión en el servidor de aplicaciones. Los estudios de usabilidad han demostrado que los tiempos de respuesta superiores a 10 segundos hacen que el usuario pase a 1. Dado que Java carece de un operador sizeof(), los cachés de Java limitan su tamaño en función del número de objetos. El tamaño de los volcados de caché tomados al final de los experimentos nunca superó los 212 MB. WWW 2007 / Pista: Rendimiento y Escalabilidad Sesión: Sistemas Escalables para Contenido Dinámico 315 0 50 100 150 200 250 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Solicitudes de Clientes de Prueba por Segundo Nativo Ganesh 0.001 0.01 0.1 1 10 100 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Tiempo Promedio de Respuesta de Clientes de Prueba Nativo Ganesh Nota Escala Logarítmica (a) Rendimiento: Mezcla de Autoría (b) Tiempo de Respuesta: Mezcla de Autoría 0 50 100 150 200 250 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Solicitudes de Clientes de Prueba por Segundo Nativo Ganesh 0.001 0.01 0.1 1 10 100 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Tiempo Promedio de Respuesta de Clientes de Prueba Nativo Ganesh Nota Escala Logarítmica (c) Rendimiento: Mezcla de Navegación (d) Tiempo de Respuesta: Mezcla de Navegación Promedio de tres pruebas. La desviación estándar máxima para el rendimiento y el tiempo de respuesta fue del 9.8% y 11.9% de la media correspondiente. Figura 6: BBOARD Benchmark - Rendimiento y Tiempo de Respuesta Promedio de otras tareas [24]. Basándose en estos números, aumentar el número de clientes de prueba hace que el sistema Nativo sea inutilizable. Ganesh a 5 Mb/s, sin embargo, ofrece una mejora doble con 400 clientes de prueba y una mejora quintuple con 1200 clientes. El rendimiento de Ganesh disminuye ligeramente a 1200 y 1600 clientes debido a que la red está saturada. En comparación con Native, la Figura 6 (b) muestra que los tiempos de respuesta de Ganesh son considerablemente más bajos con tiempos de respuesta de menos de un segundo con 400 clientes. La Figura 6 (a) también muestra que para 400 y 800 clientes de prueba, Ganesh a 5 Mb/s tiene el mismo rendimiento y tiempo de respuesta promedio que Native a 20 Mb/s. Solo con 1200 y 1600 clientes, Native a 20 Mb/s ofrece un rendimiento mayor que Ganesh a 5 Mb/s. Al comparar tanto a Ganesh como a Native a 20 Mb/s, vemos que Ganesh ya no está limitado por el ancho de banda y ofrece hasta una mejora del doble sobre Native con 1600 clientes de prueba. Como Ganesh no satura la red con configuraciones de cliente de prueba más altas, con 1600 clientes de prueba, su tiempo de respuesta promedio es de 0.1 segundos en lugar de los 7.7 segundos de Natives. Como era de esperar, no hay ganancias visibles de Ganesh en el ancho de banda más alto de 100 Mb/s donde la red ya no es el cuello de botella. Sin embargo, Ganesh sigue monitoreando a Native en cuanto a rendimiento. Las Figuras 6 (c) y (d) presentan el número promedio de solicitudes atendidas por segundo y el tiempo de respuesta promedio para estas solicitudes tal como lo perciben los clientes para la Mezcla de Navegación de BBOARDs. Independientemente de la configuración del cliente de prueba, la Figura 6 (c) muestra que el rendimiento de los Nativos a 5 Mb/s está limitado a 10 reqs/seg. Ganesh a 5 Mb/s con 400 clientes de prueba, ofrece un aumento de más de seis veces en el rendimiento. La mejora aumenta a más de once veces a 800 clientes de prueba antes de que Ganesh sature la red. Además, la Figura 6 (d) muestra que el tiempo de respuesta promedio de los Nativos de 35 segundos con 400 clientes de prueba hace que el sistema sea inutilizable. Estos altos tiempos de respuesta aumentan aún más con la adición de clientes de prueba. Incluso con la configuración del cliente de prueba de 1600, Ganesh ofrece un tiempo de respuesta promedio aceptable de 8.2 segundos. Debido a la naturaleza intensiva en datos de la mezcla de navegación, Ganesh a 5 Mb/s sorprendentemente tiene un rendimiento mucho mejor que Native a 20 Mb/s. Además, como se muestra en la Figura 6 (d), si bien el tiempo de respuesta promedio para Native a 20 Mb/s es aceptable con 400 clientes de prueba, resulta inutilizable con 800 clientes de prueba, con un tiempo de respuesta promedio de 15.8 segundos. Al igual que en el caso de 5 Mb/s, este tiempo de respuesta aumenta con la adición de clientes de prueba adicionales. Ganesh a 20 Mb/s y tanto Native como Ganesh a 100 Mb/s no tienen limitaciones de ancho de banda. Sin embargo, el rendimiento se estanca después de 1200 clientes de prueba debido a que la CPU de la base de datos está saturada. 5.1.3 Variante de filtro Nos sorprendió el rendimiento nativo del benchmark BBOARD. A una velocidad de banda ancha de 5 Mb/s, el rendimiento nativo fue más bajo de lo que esperábamos. Resultó que el código de referencia que muestra historias leía todos los comentarios asociados con la historia en particular de la base de datos y solo entonces realizaba un postprocesamiento para seleccionar los comentarios que se mostrarían. Si bien este es exactamente el comportamiento de SlashCode, la base de código detrás del sitio web de Slashdot, decidimos modificar la prueba de rendimiento para realizar cierto prefiltrado en la base de datos. Este benchmark modificado, llamado el Filtro de Variantes, modela a un desarrollador que aplica optimizaciones a nivel de SQL para transferir menos datos. En aras de la brevedad, solo resumimos brevemente los resultados de la mezcla de autores. Para la mezcla de Autoría, con 800 clientes de prueba a 5 Mb/s, la Figura 7 (a) muestra que el rendimiento de Natives aumenta un 85% en comparación con el punto de referencia original, mientras que la mejora de Ganesh es menor, del 15%. El rendimiento de los servidores disminuye por encima de los 800 clientes, ya que los clientes de prueba se agotan debido a los altos tiempos de respuesta. La ganancia más significativa para Native se observa a 20 Mb/s. En 1600 clientes de prueba, en comparación con el punto de referencia original, Native experimenta una mejora del 73% en el rendimiento y una reducción del 77% en el tiempo de respuesta promedio. Mientras WWW 2007 / Pista: Rendimiento y Escalabilidad Sesión: Sistemas Escalables para Contenido Dinámico 316 0 50 100 150 200 250 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Clientes de Prueba Solicitudes/seg Nativo Ganesh 0.001 0.01 0.1 1 10 100 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Clientes de Prueba Tiempo de Resp. Promedio (seg) Nativo Ganesh Nota Escala Logarítmica (a) Rendimiento: Mezcla de Autoría (b) Tiempo de Respuesta: Mezcla de Autoría Promedio de tres pruebas. La desviación estándar máxima para el rendimiento y el tiempo de respuesta fue del 7.2% y del 11.5% de la media correspondiente. Figura 7: BBOARD Benchmark - Variante de filtro - Rendimiento y Tiempo de Respuesta Promedio Ganesh no observa ninguna mejora en comparación con el original, aún procesa un 19% más de solicitudes/seg que Native. Por lo tanto, aunque las optimizaciones fueron más útiles para Native, Ganesh todavía ofrece una mejora en el rendimiento. 5.2 Resultados y Análisis de la SUBASTA 5.2.1 Figuras de la Mezcla de Ofertas Los gráficos 8 (a) y (b) presentan el número promedio de solicitudes atendidas por segundo y el tiempo de respuesta promedio para estas solicitudes tal como son percibidas por los clientes para la Mezcla de Ofertas de las SUBASTAS. Como se mencionó anteriormente, la mezcla de ofertas consiste en una combinación de operaciones de lectura y escritura. El benchmark AUCTION no es tan intensivo en datos como BBOARD. Por lo tanto, la mayoría de las ganancias se observan en el ancho de banda más bajo de 5 Mb/s. La figura 8 (a) muestra que el aumento en el rendimiento debido a Ganesh varía desde un 8% con 400 clientes de prueba hasta un 18% con 1600 clientes de prueba. Como se observa en la Figura 8 (b), los tiempos de respuesta promedio para Ganesh son significativamente más bajos que los de Native, con una disminución del 84% a 800 clientes de prueba y del 88% a 1600 clientes de prueba. La Figura 8 (a) también muestra que con un aumento cuádruple del ancho de banda de 5 Mb/s a 20 Mb/s, Native ya no está limitado por el ancho de banda y no hay diferencia de rendimiento entre Ganesh y Native. Con las configuraciones de cliente de prueba más altas, observamos que el ancho de banda utilizado por Ganesh era menor que el de Nativo. Ganesh podría seguir siendo útil en estos escenarios no restringidos si se compra ancho de banda de forma medible. Se observan resultados similares para el escenario de 100 Mb/s. 5.2.2 Mezcla de Navegación Para la Mezcla de Navegación de SUBASTAS, las Figuras 8 (c) y (d) presentan el número promedio de solicitudes atendidas por segundo y el tiempo promedio de respuesta para estas solicitudes tal como lo perciben los clientes. Una vez más, la mayoría de las ganancias se observan en anchos de banda más bajos. A 5 Mb/s, Native y Ganesh ofrecen un rendimiento y tiempos de respuesta similares con 400 clientes de prueba. Mientras que el rendimiento para ambos permanece igual en 800 clientes de prueba, la Figura 8 (d) muestra que el tiempo de respuesta promedio de Ganesh es un 62% menor que el de Native. El servidor satura el enlace con 800 clientes y agregar clientes de prueba adicionales solo aumenta el tiempo promedio de respuesta. Ganesh, independientemente de la configuración del cliente de prueba, no tiene restricciones de ancho de banda y mantiene el mismo tiempo de respuesta. A 1600 clientes de prueba, la Figura 8 (c) muestra que el rendimiento de Ganesh es casi el doble que el de Nativo. En los anchos de banda más altos de 20 y 100 Mb/s, ni Ganesh ni Native tienen limitaciones de ancho de banda y ofrecen un rendimiento y tiempos de respuesta equivalentes. Referencia original. Tamaño Ganesh Tamaño Rabin Tamaño SelectSort1 223.6 MB 5.4 MB 219.3 MB SelectSort2 223.6 MB 5.4 MB 223.6 MB Tabla 2: Microbenchmarks de similitud 6. SIMILITUD ESTRUCTURAL VS. SIMILITUD DE RABIN En esta sección, abordamos la segunda pregunta planteada en la Sección 4: ¿Qué tan importante es la detección de similitud estructural de Ganesh en comparación con la detección de similitud basada en la huella digital de Rabin? Para responder a esta pregunta, utilizamos microbenchmarks y los benchmarks BBOARD y AUCTION. Dado que Ganesh siempre tuvo un mejor rendimiento que Rabin en la huella dactilar, aquí presentamos solo un subconjunto de los resultados en aras de la brevedad. 6.1 Microbenchmarks Dos microbenchmarks muestran un ejemplo de los efectos de la reordenación de datos en el algoritmo de huella dactilar de Rabin. En el primer microbenchmark, SelectSort1, una consulta con un orden de clasificación especificado selecciona 223.6 MB de datos distribuidos en aproximadamente 280 K filas. La consulta se repite entonces con un atributo de ordenación diferente. Si bien se devuelve el mismo número de filas y los mismos datos, el orden de las filas es diferente. En un escenario así, se esperaría detectar una gran cantidad de similitud entre ambos resultados. Como muestra la Tabla 2, el algoritmo basado en filas de Ganesh logra una reducción del 97.6%, mientras que el algoritmo de huella digital de Rabin, con el parámetro de tamaño de fragmento promedio establecido en 4 KB, solo logra una reducción del 1%. La razón, como se muestra anteriormente en la Figura 2, es que con la huella digital de Rabin, los tramos de datos entre dos límites consecutivos suelen cruzar los límites de fila. Con el cambio en el orden de las filas en el segundo resultado y los fingerprints de Rabin ahora abarcando diferentes filas, el algoritmo no puede detectar similitud significativa. La pequeña ganancia observada se debe principalmente a aquellas filas individuales que son lo suficientemente grandes como para dividirse en múltiples fragmentos. SelectSort2, otro micro-benchmark ejecutó las mismas consultas pero aumentó el tamaño mínimo del fragmento del algoritmo de huella digital de Rabin. Como se puede ver en la Tabla 2, incluso la pequeña ganancia del microbenchmark anterior desaparece cuando el tamaño mínimo de fragmento fue mayor que el tamaño promedio de fila. Si bien se pueden abordar parcialmente estos problemas variando dinámicamente los parámetros del algoritmo de huella digital de Rabin, esto puede resultar computacionalmente costoso, especialmente en presencia de cargas de trabajo cambiantes. 6.2 Benchmarks de Aplicación Ejecutamos el benchmark BBOARD descrito en la Sección 4.1.1 en dos versiones de Ganesh: la primera con la huella digital de Rabin utilizada como WWW 2007 / Track: Sesión de Rendimiento y Escalabilidad: Sistemas Escalables para Contenido Dinámico 317 0 50 100 150 200 250 300 350 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Clientes de Prueba Solicitudes/seg Ganesh Nativo 0.001 0.01 0.1 1 10 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Clientes de Prueba Tiempo de Respuesta Promedio (seg) Ganesh Nativo Nota Escala Logarítmica (a) Rendimiento: Mezcla de Ofertas (b) Tiempo de Respuesta: Mezcla de Ofertas 0 50 100 150 200 250 300 350 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Clientes de Prueba Solicitudes/seg Ganesh Nativo 0.001 0.01 0.1 1 10 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Clientes de Prueba Tiempo de Respuesta Promedio (seg) Ganesh Nativo Nota Escala Logarítmica (c) Rendimiento: Mezcla de Navegación (d) Tiempo de Respuesta: Mezcla de Navegación Promedio de tres pruebas. La desviación estándar máxima para el rendimiento y el tiempo de respuesta fue del 2.2% y del 11.8% de la media correspondiente. Figura 8: Referencia de la subasta AUCTION - Rendimiento y Tiempo de Respuesta Promedio del algoritmo de fragmentación y el segundo con el algoritmo basado en filas de Ganesh. Los resultados de Rabins para la Mezcla de Navegación se normalizan con los resultados de Ganesh y se presentan en la Figura 9. Como muestra la Figura 9 (a), a 5 Mb/s, independientemente de la configuración del cliente de prueba, Rabin tiene un rendimiento significativamente inferior a Ganesh. Esto sucede debido a una combinación de dos razones. Primero, como se describe en la Sección 3.1, Rabin encuentra menos similitud ya que no explota la información estructural de los resultados. Segundo, este punto de referencia contenía algunas consultas que generaron resultados grandes. En este caso, Rabin, con un tamaño de fragmento promedio pequeño, generó una gran cantidad de objetos que desplazaron otros datos útiles de la caché. Por el contrario, Ganesh pudo detectar estas filas grandes y aumentar correspondientemente el tamaño de los bloques. Esto fue confirmado ya que las estadísticas de caché mostraron que la proporción de aciertos de Ganesh era aproximadamente tres veces mayor que la de Rabin. Las mediciones de rendimiento a 20 Mb/s fueron similares, con la excepción del rendimiento de Rabins con 400 clientes de prueba. En este caso, Ganesh no estaba limitado por la red y, de hecho, el rendimiento era el mismo que el de 400 clientes a 5 Mb/s. Rabin, sin embargo, aprovechó el aumento del ancho de banda de 5 a 20 Mb/s para ofrecer un rendimiento ligeramente mejor. A 100 Mb/s, el rendimiento de Rabin era casi similar al de Ganesh ya que el ancho de banda ya no era un cuello de botella. El tiempo de respuesta normalizado, presentado en la Figura 9 (b), muestra tendencias similares. A 5 y 20 Mb/s, la adición de clientes de prueba disminuye el tiempo de respuesta normalizado, ya que el tiempo de respuesta promedio de Ganesh aumenta más rápido que el de Rabin. Sin embargo, en ningún momento Rabin supera a Ganesh. Ten en cuenta que con 400 y 800 clientes a 100 Mb/s, Rabin tiene un mayor sobrecosto incluso cuando no está limitado por el ancho de banda. Como se menciona en la Sección 3.1, esto se debe a que Rabin tiene que hashear cada ResultSet dos veces. La sobrecarga desaparece con 1200 y 1600 clientes, ya que la CPU de la base de datos está saturada y limita el rendimiento tanto de Ganesh como de Rabin. 7. SUPERPOSICIÓN DE PROXY En esta sección, abordamos la tercera pregunta planteada en la Sección 4: ¿Es aceptable la superposición del diseño basado en proxy de Ganesh? Para responder a esta pregunta, nos concentramos en su rendimiento en las bandas de mayor ancho de banda. Nuestra evaluación en la Sección 5 mostró que Ganesh, en comparación con Native, puede ofrecer una mejora sustancial en el rendimiento a anchos de banda más bajos. Solo en anchos de banda más altos serían visibles los costos adicionales de latencia, medidos por el tiempo promedio de respuesta para una solicitud de cliente, y de rendimiento, medidos por la cantidad de solicitudes de cliente que pueden ser atendidas por segundo. Al observar la combinación de autoría del benchmark original de BBOARD, no se aprecian ganancias visibles de Ganesh a 100 Mb/s. Sin embargo, Ganesh sigue rastreando a Native en cuanto a rendimiento. Si bien el tiempo promedio de respuesta es mayor para Ganesh, la diferencia absoluta está entre 0.01 y 0.04 segundos y sería imperceptible para el usuario final. La mezcla de navegación muestra una diferencia aún menor en los tiempos de respuesta promedio. Los resultados de la variante del filtro de los benchmarks de BBOARD son similares. Incluso para el benchmark de SUBASTA, la diferencia entre el tiempo de respuesta de Nativo y Ganesh a 100 Mb/s nunca fue mayor a 0.02 segundos. La única excepción a los resultados anteriores se observó en la variante de filtro del benchmark BBOARD, donde Ganesh con 1600 clientes de prueba añadió 0.85 segundos al tiempo de respuesta promedio. Por lo tanto, incluso para redes mucho más rápidas donde el enlace WAN no es el cuello de botella, Ganesh siempre ofrece un rendimiento equivalente al Nativo. Si bien se agrega algo de latencia adicional debido al diseño basado en proxy, generalmente es imperceptible. TRABAJO RELACIONADO Hasta donde sabemos, Ganesh es el primer sistema que combina el uso de técnicas basadas en hash con el almacenamiento en caché de resultados de base de datos para mejorar el rendimiento y los tiempos de respuesta de aplicaciones con contenido dinámico. También creemos que es el primer sistema en demostrar los beneficios de utilizar información estructural para WWW 2007 / Track: Rendimiento y Escalabilidad Sesión: Sistemas Escalables para Contenido Dinámico 318 0.0 0.2 0.4 0.6 0.8 1.0 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Clientes de Prueba Rendimiento Normalizado 31.8 3.8 2.8 2.3 23.8 32.8 5.8 3.6 1.8 2.1 1.1 1.0 0 5 10 15 20 25 30 35 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Clientes de Prueba Tiempo de Respuesta Normalizado (a) Rendimiento Normalizado: Mayor es mejor (b) Tiempo de Respuesta Normalizado: Mayor es peor Para el rendimiento, un resultado normalizado mayor que 1 implica que Rabin es mejor. Para el tiempo de respuesta, un resultado normalizado mayor que 1 implica que Ganesh es mejor. Media de tres pruebas. La desviación estándar máxima para el rendimiento y el tiempo de respuesta fue del 9.1% y del 13.9% de la media correspondiente. Figura 9: Comparación normalizada de Ganesh vs. Rabin - Mezcla de navegación BBOARD detectando similitud. En esta sección, primero discutimos enfoques alternativos para almacenar en caché contenido dinámico y luego examinamos otros usos de primitivas basadas en hash en sistemas distribuidos. 8.1 Almacenamiento en Caché de Contenido Dinámico En la capa de base de datos, varios sistemas han abogado por la caché de nivel intermedio donde partes de la base de datos se replican en el borde o servidor [3, 4, 20]. Estos sistemas almacenan en caché tablas completas en lo que es esencialmente una base de datos replicada o utilizan vistas materializadas de respuestas de consultas anteriores [19]. Requieren una integración estrecha con la base de datos del sistema para garantizar un límite de tiempo en la propagación de actualizaciones. Estos sistemas suelen estar dirigidos a cargas de trabajo que no requieren una consistencia estricta y pueden tolerar datos obsoletos. Además, a diferencia de Ganesh, algunas de estas soluciones de almacenamiento en caché de nivel medio [2, 3], sufren de la complejidad de tener que participar en la planificación de consultas y el procesamiento de consultas distribuidas. Gao et al. [15] proponen utilizar una arquitectura de replicación de objetos distribuidos donde los requisitos de consistencia de las tiendas de datos se adaptan según la aplicación. Estas soluciones requieren recursos sustanciales de desarrollo y un entendimiento detallado de la aplicación que se está modificando. Si bien existen sistemas que intentan automatizar la partición y replicación de la base de datos de una aplicación [34], no proporcionan semántica de transacciones completa. En comparación, Ganesh no debilita ninguna de las semánticas proporcionadas por la base de datos subyacente. El trabajo reciente en la evaluación de opciones de almacenamiento en caché de borde para sitios web dinámicos [38] ha sugerido que, sin una planificación cuidadosa, el empleo de estrategias complejas de descarga puede perjudicar el rendimiento. En cambio, el trabajo aboga por una arquitectura en la que todos los niveles, excepto la base de datos, deberían ser trasladados al borde. Nuestra evaluación de Ganesh ha demostrado que sería beneficioso para estos escenarios. Para mejorar la escalabilidad de la base de datos, C-JDBC [10], SSS [22] y Ganymed [28] también abogan por el uso de una arquitectura basada en interposición para clusterizar y replicar bases de datos de forma transparente a nivel de middleware. Los enfoques de estas arquitecturas y Ganesh son complementarios y se beneficiarían mutuamente. Avanzando hacia la capa de presentación, se ha producido una amplia adopción de la caché basada en fragmentos [14], la cual mejora la utilización de la caché al almacenar por separado diferentes partes de las páginas web generadas. Si bien el almacenamiento en caché basado en fragmentos funciona en el borde, una propuesta reciente ha propuesto trasladar el ensamblaje de páginas web a los clientes para optimizar la entrega de contenido [31]. Si bien Ganesh no se utiliza en la capa de presentación, los mismos principios se han aplicado en la Detección de Transferencias Duplicadas [25] para aumentar la eficiencia de la caché web, así como para el acceso web a través de enlaces con ancho de banda limitado [33]. 8.2 Sistemas basados en hash En los últimos años han surgido muchos sistemas que explotan técnicas basadas en hash. En el centro de todos estos sistemas se encuentra la idea de detectar similitudes en los datos sin necesidad de interpretar esos datos. Esta idea simple pero elegante se basa en el hash criptográfico, como se discutió anteriormente en la Sección 2. Las aplicaciones exitosas de esta idea abarcan una amplia gama de sistemas de almacenamiento. Los ejemplos incluyen la copia de seguridad entre pares de archivos informáticos personales [11], el archivado eficiente de datos [29] y la búsqueda de archivos similares [21]. Spring y Wetherall [35] aplican principios similares a nivel de red. Utilizando cachés sincronizadas en ambos extremos de un enlace de red, los datos duplicados son reemplazados por tokens más pequeños para su transmisión y luego restaurados en el extremo remoto. Este y otros sistemas basados en hash como los sistemas de archivos CASPER [37] y LBFS [26], y optimizadores de ancho de banda de Capa-2 como Riverbed y Peribit utilizan la huella digital de Rabin [30] para descubrir tramos de similitud en los datos. Este enfoque es especialmente útil cuando los elementos de datos son modificados en su lugar a través de inserciones, eliminaciones y actualizaciones. Sin embargo, como se muestra en la Sección 6, el rendimiento de esta técnica puede experimentar una caída dramática en presencia de reordenamiento de datos. Ganesh en cambio utiliza los límites de fila como divisores para detectar similitudes. El uso más agresivo de técnicas basadas en hash es por sistemas que utilizan hashes como identificadores principales para objetos en almacenamiento persistente. Los sistemas de almacenamiento como CFS [12] y PAST [13] que han sido construidos utilizando tablas hash distribuidas entran en esta categoría. Single Instance Storage [6] y Venti [29] son otros ejemplos de tales sistemas. Como se discute en la Sección 2.2, el uso de hashes criptográficos para abordar datos persistentes representa un nivel más profundo de confianza en su resistencia a colisiones que la asumida por Ganesh. Si el tiempo revela deficiencias en el algoritmo hash, el esfuerzo necesario para corregir la falla es mucho mayor. En Ganesh, simplemente se trata de reemplazar el algoritmo hash. 9. CONCLUSIÓN El creciente uso de contenido web dinámico generado a partir de bases de datos relacionales aumenta las demandas de ancho de banda de la WAN. Las soluciones de almacenamiento en caché tradicionales para reducir el ancho de banda y la latencia suelen ser ineficaces para este tipo de contenido. Este documento muestra que el impacto de los accesos a bases de datos a través de WAN puede reducirse sustancialmente mediante la arquitectura Ganesh sin comprometer la estricta semántica de consistencia de las bases de datos. La esencia de la arquitectura Ganesh es el uso de la computación en los bordes para reducir la comunicación a través de Internet. Ganesh es capaz de utilizar hashes criptográficos para detectar similitud con resultados anteriores y enviar recetas compactas de resultados en lugar de resultados completos en la sesión de Sistemas Escalables para Contenido Dinámico 319 de WWW 2007 / Track: Rendimiento y Escalabilidad. Nuestro diseño utiliza la interposición para lograr una transparencia completa: los clientes, los servidores de aplicaciones y los servidores de bases de datos no son conscientes de la presencia de Ganesh y no requieren ninguna modificación. Nuestra evaluación experimental confirma que Ganesh, aunque conceptualmente simple, puede ser altamente efectivo en mejorar el rendimiento y el tiempo de respuesta. Nuestros resultados también confirman que aprovechar la estructura presente en los resultados de la base de datos para detectar similitudes es crucial para esta mejora en el rendimiento. REFERENCIAS [1] AKELLA, A., SESHAN, S., Y SHAIKH, A. Una evaluación empírica de los cuellos de botella en Internet de área amplia. En Proc. 3ª Conferencia ACM SIGCOMM sobre Medición de Internet (Miami Beach, FL, EE. UU., Oct. 2003), pp. 101-114. [2] ALTINEL, M., BORNH ¨OVD, C., KRISHNAMURTHY, S., MOHAN, C., PIRAHESH, H., Y REINWALD, B. Tablas de caché: allanando el camino para una caché de base de datos adaptativa. En Proc. del 29º VLDB (Berlín, Alemania, 2003), pp. 718-729. [3] ALTINEL, M., LUO, Q., KRISHNAMURTHY, S., MOHAN, C., PIRAHESH, H., LINDSAY, B. G., WOO, H., Y BROWN, L. Dbcache: Caché de base de datos para servidores de aplicaciones web. En Proc. 2002 ACM SIGMOD (2002), pp. 612-612. [4] AMIRI, K., PARK, S., TEWARI, R., Y PADMANABHAN, S. Dbproxy: una caché de datos dinámica para aplicaciones web. En Proc. Conferencia Internacional de Ingeniería de Datos de IEEE (ICDE) (Mar. 2003). [5] BLACK, J. Compare-by-hash: Un análisis razonado. En Proc. Conferencia Técnica Anual USENIX 2006 (Boston, MA, mayo de 2006), pp. 85-90. [6] BOLOSKY, W. J., CORBIN, S., GOEBEL, D., y DOUCEUR, J. R. Almacenamiento de instancia única en Windows 2000. En Proc. 4to Simposio de Sistemas Windows de USENIX (Seattle, WA, ago. 2000), pp. 13-24. [7] BREWER, E. A. Lecciones de servicios a gran escala. IEEE Internet Computing 5, 4 (2001), 46-55. [8] BRODER, A., GLASSMAN, S., MANASSE, M., AND ZWEIG, G. Agrupamiento sintáctico de la web. En Proc. 6ta Conferencia Internacional WWW (1997). [9] CECCHET, E., CHANDA, A., ELNIKETY, S., MARGUERITE, J., Y ZWAENEPOEL, W. Comparación de rendimiento de arquitecturas de middleware para generar contenido web dinámico. En Proc. Cuarta Conferencia Internacional de Middleware ACM/IFIP/USENIX (Río de Janeiro, Brasil, junio de 2003). [10] CECCHET, E., MARGUERITE, J., Y ZWAENEPOEL, W. C-JDBC: Middleware flexible de agrupación de bases de datos. En Proc. Conferencia Técnica Anual USENIX 2004 (Boston, MA, junio de 2004). [11] COX, L. P., MURRAY, C. D., Y NOBLE, B. D. Pastiche: Haciendo que la copia de seguridad sea barata y fácil. En OSDI: Simposio sobre Diseño e Implementación de Sistemas Operativos (2002). [12] DABEK, F., KAASHOEK, M. F., KARGER, D., MORRIS, R., Y STOICA, I. Almacenamiento cooperativo de amplia área con CFS. En el 18º Simposio ACM sobre Principios de Sistemas Operativos (Banff, Canadá, octubre de 2001). [13] DRUSCHEL, P., Y ROWSTRON, A. PASADO: Una utilidad de almacenamiento entre pares a gran escala y persistente. En HotOS VIII (Schloss Elmau, Alemania, mayo de 2001), pp. 75-80. [14] Incluye el lado del borde. http://www.esi.org. [15] GAO, L., DAHLIN, M., NAYATE, A., ZHENG, J., Y IYENGAR, A. Replicación de datos específica de la aplicación para servicios en el borde. En WWW 03: Proc. Duodécima Conferencia Internacional sobre la World Wide Web (2003), pp. 449-460. [16] HEMMINGER, S. Netem - emulando redes reales en el laboratorio. En Proc. 2005 Linux Conference Australia (Canberra, Australia, Abr. 2005). [17] HENSON, V. Un análisis de compare-by-hash. En Proc. 9º Taller sobre Temas Candentes en Sistemas Operativos (HotOS IX) (mayo de 2003), pp. 13-18. [18] Benchmarks de Jmob. http://jmob.objectweb.org/. [19] LABRINIDIS, A., Y ROUSSOPOULOS, N. Equilibrando el rendimiento y la frescura de los datos en servidores de bases de datos web. En Proc. 29ª Conferencia VLDB (Sept. 2003). [20] LARSON, P.-A., GOLDSTEIN, J., Y ZHOU, J. Caché transparente de bases de datos en el nivel intermedio en SQL Server. En Proc. 2003 ACM SIGMOD (2003), pp. 661-661. [21] MANBER, U. Encontrar archivos similares en un sistema de archivos grande. En Proc. Conferencia Técnica de Invierno de USENIX 1994 (San Francisco, CA, 17-21 de 1994), pp. 1-10. [22] MANJHI, A., AILAMAKI, A., MAGGS, B. M., MOWRY, T. C., OLSTON, C., Y TOMASIC, A. Escalabilidad y seguridad simultáneas para aplicaciones web intensivas en datos. En Proc. 2006 ACM SIGMOD (junio de 2006), pp. 241-252. [23] MENEZES, A. J., VANSTONE, S. A., Y OORSCHOT, P. C. V. Manual de Criptografía Aplicada. CRC Press, 1996. [24] MILLER, R. B. \n\nCRC Press, 1996. [24] MILLER, R. B. Tiempo de respuesta en transacciones conversacionales entre humanos y computadoras. En Proc. Conferencia Conjunta de Computación de Otoño de AFIPS (1968), pp. 267-277. [25] MOGUL, J. C., CHAN, Y. M., Y KELLY, T. Diseño, implementación y evaluación de la detección de transferencias duplicadas en http. En Proc. Primer Simposio sobre Diseño e Implementación de Sistemas en Red (San Francisco, CA, Mar. 2004). [26] MUTHITACHAROEN, A., CHEN, B., Y MAZIERES, D. Un sistema de archivos en red de bajo ancho de banda. En Proc. 18º Simposio de la ACM sobre Principios de Sistemas Operativos (Banff, Canadá, Oct. 2001). [27] PFEIFER, D., Y JAKSCHITSCH, H. Caché basada en métodos en aplicaciones de servidores multinivel. En Proc. Quinto Simposio Internacional sobre Objetos y Aplicaciones Distribuidas (Catania, Sicilia, Italia, noviembre de 2003). [28] PLATTNER, C., Y ALONSO, G. Ganymed: Replicación escalable para aplicaciones web transaccionales. En Proc. 5ta Conferencia Internacional de Middleware ACM/IFIP/USENIX (2004), pp. 155-174. [29] QUINLAN, S., Y DORWARD, S. Venti: Un nuevo enfoque para el almacenamiento de archivos. En Proc. Conferencia FAST 2002 sobre Tecnologías de Archivo y Almacenamiento (2002). [30] RABIN, M. Huellas dactilares mediante polinomios aleatorios. En el Informe Técnico TR-15-81 (1981) del Centro de Investigación en Tecnología Informática de la Universidad de Harvard. [31] RABINOVICH, M., XIAO, Z., DOUGLIS, F., Y KALMANEK, C. Mover los lados de los bordes incluye a los clientes reales en el borde. En Proc. 4to Simposio USENIX sobre Tecnologías y Sistemas de Internet (Seattle, WA, Mar. 2003). [32] REESE, G. Programación de bases de datos con JDBC y Java, 1ra ed. OReilly, junio de 1997. [33] RHEA, S., LIANG, K., Y BREWER, E. Caché web basada en valores. En Proc. Duodécima Conferencia Internacional de la World Wide Web (mayo de 2003). [34] SIVASUBRAMANIAN, S., ALONSO, G., PIERRE, G., Y VAN STEEN, M. Globedb: Replicación autónoma de datos para aplicaciones web. En WWW 05: Actas de la 14ª Conferencia Internacional de la World-Wide Web (mayo de 2005). [35] SPRING, N. T., Y WETHERALL, D. Una técnica independiente de protocolo para eliminar el tráfico de red redundante. En Proc. de ACM SIGCOMM (Ago. 2000). [36] TOLIA, N., HARKES, J., KOZUCH, M., Y SATYANARAYANAN, M. Integrando almacenamiento portátil y distribuido. En Proc. 3ra Conferencia USENIX sobre Tecnologías de Archivos y Almacenamiento (San Francisco, CA, Mar. 2004). [37] TOLIA, N., KOZUCH, M., SATYANARAYANAN, M., KARP, B., PERRIG, A., Y BRESSOUD, T. Uso oportunista del almacenamiento direccionable por contenido para sistemas de archivos distribuidos. En Proc. Conferencia Técnica Anual USENIX 2003 (San Antonio, TX, junio de 2003), pp. 127-140. [38] YUAN, C., CHEN, Y., Y ZHANG, Z. Evaluación de almacenamiento en caché/descarga en el borde para la entrega de contenido dinámico. En WWW 03: Proc. Duodécima Conferencia Internacional sobre la World Wide Web (2003), pp. 461-471. WWW 2007 / Pista: Rendimiento y Escalabilidad Sesión: Sistemas Escalables para Contenido Dinámico 320 ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "proxy": {
            "translated_key": "proxy",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Consistency-preserving Caching of Dynamic Database Content∗ Niraj Tolia and M. Satyanarayanan Carnegie Mellon University {ntolia,satya}@cs.cmu.edu ABSTRACT With the growing use of dynamic web content generated from relational databases, traditional caching solutions for throughput and latency improvements are ineffective.",
                "We describe a middleware layer called Ganesh that reduces the volume of data transmitted without semantic interpretation of queries or results.",
                "It achieves this reduction through the use of cryptographic hashing to detect similarities with previous results.",
                "These benefits do not require any compromise of the strict consistency semantics provided by the back-end database.",
                "Further, Ganesh does not require modifications to applications, web servers, or database servers, and works with closed-source applications and databases.",
                "Using two benchmarks representative of dynamic web sites, measurements of our prototype show that it can increase end-to-end throughput by as much as twofold for non-data intensive applications and by as much as tenfold for data intensive ones.",
                "Categories and Subject Descriptors C.2.4 [Computer-Communication Networks]: Distributed Systems; H.2.4 [Database Management]: Systems General Terms Design, Performance 1.",
                "INTRODUCTION An increasing fraction of web content is dynamically generated from back-end relational databases.",
                "Even when database content remains unchanged, temporal locality of access cannot be exploited because dynamic content is not cacheable by web browsers or by intermediate caching servers such as Akamai mirrors.",
                "In a multitiered architecture, each web request can stress the WAN link between the web server and the database.",
                "This causes user experience to be highly variable because there is no caching to insulate the client from bursty loads.",
                "Previous attempts in caching dynamic database content have generally weakened transactional semantics [3, 4] or required application modifications [15, 34].",
                "We report on a new solution that takes the form of a databaseagnostic middleware layer called Ganesh.",
                "Ganesh makes no effort to semantically interpret the contents of queries or their results.",
                "Instead, it relies exclusively on cryptographic hashing to detect similarities with previous results.",
                "Hash-based similarity detection has seen increasing use in distributed file systems [26, 36, 37] for improving performance on low-bandwidth networks.",
                "However, these techniques have not been used for relational databases.",
                "Unlike previous approaches that use generic methods to detect similarity, Ganesh exploits the structure of relational database results to yield superior performance improvement.",
                "One faces at least three challenges in applying hash-based similarity detection to back-end databases.",
                "First, previous work in this space has traditionally viewed storage content as uninterpreted bags of bits with no internal structure.",
                "This allows hash-based techniques to operate on long, contiguous runs of data for maximum effectiveness.",
                "In contrast, relational databases have rich internal structure that may not be as amenable to hash-based similarity detection.",
                "Second, relational databases have very tight integrity and consistency constraints that must not be compromised by the use of hash-based techniques.",
                "Third, the source code of commercial databases is typically not available.",
                "This is in contrast to previous work which presumed availability of source code.",
                "Our experiments show that Ganesh, while conceptually simple, can improve performance significantly at bandwidths representative of todays commercial Internet.",
                "On benchmarks modeling multitiered web applications, the throughput improvement was as high as tenfold for data-intensive workloads.",
                "For workloads that were not data-intensive, throughput improvements of up to twofold were observed.",
                "Even when bandwidth was not a constraint, Ganesh had low overhead and did not hurt performance.",
                "Our experiments also confirm that exploiting the structure present in database results is crucial to this performance improvement. 2.",
                "BACKGROUND 2.1 Dynamic Content Generation As the World Wide Web has grown, many web sites have decentralized their data and functionality by pushing them to the edges of the Internet.",
                "Today, eBusiness systems often use a three-tiered architecture consisting of a front-end web server, an application server, and a back-end database server.",
                "Figure 1 illustrates this architecture.",
                "The first two tiers can be replicated close to a concentration of clients at the edge of the Internet.",
                "This improves user experience by lowering end-to-end latency and reducing exposure WWW 2007 / Track: Performance and Scalability Session: Scalable Systems for Dynamic Content 311 Back-End Database Server Front-End Web and Application Servers Figure 1: Multi-Tier Architecture to backbone traffic congestion.",
                "It can also increase the availability and scalability of web services.",
                "Content that is generated dynamically from the back-end database cannot be cached in the first two tiers.",
                "While databases can be easily replicated in a LAN, this is infeasible in a WAN because of the difficult task of simultaneously providing strong consistency, availability, and tolerance to network partitions [7].",
                "As a result, databases tend to be centralized to meet the strong consistency requirements of many eBusiness applications such as banking, finance, and online retailing [38].",
                "Thus, the back-end database is usually located far from many sets of first and second-tier nodes [2].",
                "In the absence of both caching and replication, WAN bandwidth can easily become a limiting factor in the performance and scalability of data-intensive applications. 2.2 Hash-Based Systems Ganeshs focus is on efficient transmission of results by discovering similarities with the results of previous queries.",
                "As SQL queries can generate large results, hash-based techniques lend themselves well to the problem of efficiently transferring these large results across bandwidth constrained links.",
                "The use of hash-based techniques to reduce the volume of data transmitted has emerged as a common theme of many recent storage systems, as discussed in Section 8.2.",
                "These techniques rely on some basic assumptions.",
                "Cryptographic hash functions are assumed to be collision-resistant.",
                "In other words, it is computationally intractable to find two inputs that hash to the same output.",
                "The functions are also assumed to be one-way; that is, finding an input that results in a specific output is computationally infeasible.",
                "Menezes et al. [23] provide more details about these assumptions.",
                "The above assumptions allow hash-based systems to assume that collisions do not occur.",
                "Hence, they are able to treat the hash of a data item as its unique identifier.",
                "A collection of data items effectively becomes content-addressable, allowing a small hash to serve as a codeword for a much larger data item in permanent storage or network transmission.",
                "The assumption that collisions are so rare as to be effectively non-existent has recently come under fire [17].",
                "However, as explained by Black [5], we believe that these issues do not form a concern for Ganesh.",
                "All communication is between trusted parts of the system and an adversary has no way to force Ganesh to accept invalid data.",
                "Further, Ganesh does not depend critically on any specific hash function.",
                "While we currently use SHA-1, replacing it with a different hash function would be simple.",
                "There would be no impact on performance as stronger hash functions (e.g.",
                "SHA256) only add a few extra bytes and the generated hashes are still orders of magnitude smaller than the data items they represent.",
                "No re-hashing of permanent storage is required since Ganesh only uses hashing on volatile data. 3.",
                "DESIGN AND IMPLEMENTATION Ganesh exploits redundancy in the result stream to avoid transmitting result fragments that are already present at the query site.",
                "Redundancy can arise naturally in many different ways.",
                "For example, a query repeated after a certain interval may return a different result because of updates to the database; however, there may be significant commonality between the two results.",
                "As another example, a user who is refining a search may generate a sequence of queries with overlapping results.",
                "When Ganesh detects redundancy, it suppresses transmission of the corresponding result fragments.",
                "Instead, it transmits a much smaller digest of those fragments and lets the query site reconstruct the result through hash lookup in a cache of previous results.",
                "In effect, Ganesh uses computation at the edges to reduce Internet communication.",
                "Our description of Ganesh focuses on four aspects.",
                "We first explain our approach to detecting similarity in query results.",
                "Next, we discuss how the Ganesh architecture is completely invisible to all components of a multi-tier system.",
                "We then describe Ganeshs <br>proxy</br>-based approach and the dataflow for detecting similarity. 3.1 Detecting Similarity One of the key design decisions in Ganesh is how similarity is detected.",
                "There are many potential ways to decompose a result into fragments.",
                "The optimal way is, of course, the one that results in the smallest possible object for transmission for a given querys results.",
                "Finding this optimal decomposition is a difficult problem because of the large space of possibilities and because the optimal choice depends on many factors such as the contents of the querys result, the history of recent results, and the cache management algorithm.",
                "When an object is opaque, the use of Rabin fingerprints [8, 30] to detect common data between two objects has been successfully shown in the past by systems such as LBFS [26] and CASPER [37].",
                "Rabin fingerprinting uses a sliding window over the data to compute a rolling hash.",
                "Assuming that the hash function is uniformly distributed, a chunk boundary is defined whenever the lower order bits of the hash value equal some predetermined value.",
                "The number of lower order bits used defines the average chunk size.",
                "These sub-divided chunks of the object become the unit of comparison for detecting similarity between different objects.",
                "As the locations of boundaries found by using Rabin fingerprints is stochastically determined, they usually fail to align with any structural properties of the underlying data.",
                "The algorithm therefore deals well with in-place updates, insertions and deletions.",
                "However, it performs poorly in the presence of any reordering of data.",
                "Figure 2 shows an example where two results, A and B, consisting of three rows, have the same data but have different sort attributes.",
                "In the extreme case, Rabin fingerprinting might be unable to find any similar data due to the way it detects chunk boundaries.",
                "Fortunately, Ganesh can use domain specific knowledge for more precise boundary detection.",
                "The information we exploit is that a querys result reflects the structure of a relational database where all data is organized as tables and rows.",
                "It is therefore simple to check for similarity with previous results at two granularities: first the entire result, and then individual rows.",
                "The end of a row in a result serves as a natural chunk boundary.",
                "It is important to note that using the tabular structure in results only involves shallow interpretation of the data.",
                "Ganesh does not perform any deeper semantic interpretation such as understanding data types, result schema, or integrity constraints.",
                "Tuning Rabin fingerprinting for a workload can also be difficult.",
                "If the average chunk size is too large, chunks can span multiple result rows.",
                "However, selecting a smaller average chunk size increases the amount of metadata required to the describe the results.",
                "WWW 2007 / Track: Performance and Scalability Session: Scalable Systems for Dynamic Content 312 Figure 2: Rabin Fingerprinting vs. Ganeshs Chunking This, in turn, would decrease the savings obtained via its use.",
                "Rabin fingerprinting also needs two computationally-expensive passes over the data: once to determine chunk boundaries and one again to generate cryptographic hashes for the chunks.",
                "Ganesh only needs a single pass for hash generation as the chunk boundaries are provided by the datas natural structure.",
                "The performance comparison in Section 6 shows that Ganeshs row-based algorithm outperforms Rabin fingerprinting.",
                "Given that previous work has already shown that Rabin fingerprinting performs better than gzip [26], we do not compare Ganesh to compression algorithms in this paper. 3.2 Transparency The key factor influencing our design was the need for Ganesh to be completely transparent to all components of a typical eBusiness system: web servers, application servers, and database servers.",
                "Without this, Ganesh stands little chance of having a significant real-world impact.",
                "Requiring modifications to any of the above components would raise the barrier for entry of Ganesh into an existing system, and thus reduce its chances of adoption.",
                "Preserving transparency is simplified by the fact that Ganesh is purely a performance enhancement, not a functionality or usability enhancement.",
                "We chose agent interposition as the architectural approach to realizing our goal.",
                "This approach relies on the existence of a compact programming interface that is already widely used by target software.",
                "It also relies on a mechanism to easily add new code without disrupting existing module structure.",
                "These conditions are easily met in our context because of the popularity of Java as the programming language for eBusiness systems.",
                "The Java Database Connectivity (JDBC) API [32] allows Java applications to access a wide variety of databases and even other tabular data repositories such as flat files.",
                "Access to these data sources is provided by JDBC drivers that translate between the JDBC API and the database communication mechanism.",
                "Figure 3(a) shows how JDBC is typically used in an application.",
                "As the JDBC interface is standardized, one can substitute one JDBC driver for another without application modifications.",
                "The JDBC driver thus becomes the natural module to exploit for code interposition.",
                "As shown in Figure 3(b), the native JDBC driver is replaced with a Ganesh JDBC driver that presents the same standardized interface.",
                "The Ganesh driver maintains an in-memory cache of result fragments from previous queries and performs reassembly of results.",
                "At the database, we add a new process called the Ganesh <br>proxy</br>.",
                "This <br>proxy</br>, which can be shared by multiple front-end nodes, consists of two parts: code to detect similarity in result fragments and the original native JDBC driver that communicates with the database.",
                "The use of a <br>proxy</br> at the database makes Ganesh database-agnostic and simplifies prototyping and experimentation.",
                "Ganesh is thus able to work with a wide range of databases and applications, requiring no modifications to either. 3.3 <br>proxy</br>-Based Caching The native JDBC driver shown in Figure 3(a) is a lightweight code component supplied by the database vendor.",
                "Its main funcClient Database Web and Application Server Native JDBC Driver WAN (a) Native Architecture Client Database Ganesh <br>proxy</br> Native JDBC Driver WAN Web and Application Server Ganesh JDBC Driver (b) Ganeshs Interposition-based Architecture Figure 3: Native vs. Ganesh Architecture tion is to mediate communication between the application and the remote database.",
                "It forwards queries, buffers entire results, and responds to application requests to view parts of results.",
                "The Ganesh JDBC driver shown in Figure 3(b) presents the application with an interface identical to that provided by the native driver.",
                "It provides the ability to reconstruct results from compact hash-based descriptions sent by the <br>proxy</br>.",
                "To perform this reconstruction, the driver maintains an in-memory cache of recentlyreceived results.",
                "This cache is only used as a source of result fragments in reconstructing results.",
                "No attempt is made by the Ganesh driver or <br>proxy</br> to track database updates.",
                "The lack of cache consistency does not hurt correctness as a description of the results is always fetched from the <br>proxy</br> - at worst, there will be no performance benefit from using Ganesh.",
                "Stale data will simply be paged out of the cache over time.",
                "The Ganesh <br>proxy</br> accesses the database via the native JDBC driver, which remains unchanged between Figures 3(a) and (b).",
                "The database is thus completely unaware of the existence of the <br>proxy</br>.",
                "The <br>proxy</br> does not examine any queries received from the Ganesh driver but passes them to the native driver.",
                "Instead, the <br>proxy</br> is responsible for inspecting database output received from the native driver, detecting similar results, and generating hash-based encodings of these results whenever enough similarity is found.",
                "While this architecture does not decrease the load on a database, as mentioned earlier in Section 2.1, it is much easier to replicate databases for scalability in a LAN than in a WAN.",
                "To generate a hash-based encoding, the <br>proxy</br> must be aware of what result fragments are available in the Ganesh drivers cache.",
                "One approach is to be optimistic, and to assume that all result fragments are available.",
                "This will result in the smallest possible initial transmission of a result.",
                "However, in cases where there is little overlap with previous results, the Ganesh driver will have to make many calls to the <br>proxy</br> during reconstruction to fetch missing result fragments.",
                "To avoid this situation, the <br>proxy</br> loosely tracks the state of the Ganesh drivers cache.",
                "Since both components are under our control, it is relatively simple to do this without resorting to gray-box techniques or explicit communication for maintaining cache coherence.",
                "Instead, the <br>proxy</br> simulates the Ganesh drivers cache management algorithm and uses this to maintain a list of hashes for which the Ganesh driver is likely to possess the result fragments.",
                "In case of mistracking, there will be no loss of correctness but there will be extra round-trip delays to fetch the missing fragments.",
                "If the client detects loss of synchronization with the <br>proxy</br>, it can ask the <br>proxy</br> to reset the state shared between them.",
                "Also note that the <br>proxy</br> does not need to keep the result fragments themselves, only their hashes.",
                "This allows the <br>proxy</br> to remain scalable even when it is shared by many front-end nodes.",
                "WWW 2007 / Track: Performance and Scalability Session: Scalable Systems for Dynamic Content 313 Object Output Stream Convert ResultSet Object Input Stream Convert ResultSet All Data Recipe ResultSet All Data ResultSet Network Ganesh <br>proxy</br> Ganesh JDBC Driver Result Set Recipe Result Set Yes Yes No No GaneshInputStream GaneshOutputStream Figure 4: Dataflow for Result Handling 3.4 Encoding and Decoding Results The Ganesh <br>proxy</br> receives database output as Java objects from the native JDBC driver.",
                "It examines this output to see if a Java object of type ResultSet is present.",
                "The JDBC interface uses this data type to store results of database queries.",
                "If a ResultSet object is found, it is shrunk as discussed below.",
                "All other Java objects are passed through unmodified.",
                "As discussed in Section 3.1, the <br>proxy</br> uses the row boundaries defined in the ResultSet to partition it into fragments consisting of single result rows.",
                "All ResultSet objects are converted into objects of a new type called RecipeResultSet.",
                "We use the term recipe for this compact description of a database result because of its similarity to a file recipe in the CASPER file system [37].",
                "The conversion replaces each result fragment that is likely to be present in the Ganesh drivers cache by a SHA-1 hash of that fragment.",
                "Previously unseen result fragments are retained verbatim.",
                "The <br>proxy</br> also retains hashes for the new result fragments as they will be present in the drivers cache in the future.",
                "Note that the <br>proxy</br> only caches hashes for result fragments and does not cache recipes.",
                "The <br>proxy</br> constructs a RecipeResultSet by checking for similarity at the entire result and then the row level.",
                "If the entire result is predicted to be present in the Ganesh drivers cache, the RecipeResultSet is simply a single hash of the entire result.",
                "Otherwise, it contains hashes for those rows predicted to be present in that cache; all other rows are retained verbatim.",
                "If the <br>proxy</br> estimates an overall space savings, it will transmit the RecipeResultSet.",
                "Otherwise the original ResultSet is transmitted.",
                "The RecipeResultSet objects are transformed back into ResultSet objects by the Ganesh driver.",
                "Figure 4 illustrates ResultSet handling at both ends.",
                "Each SHA-1 hash found in a RecipeResultSet is looked up in the local cache of result fragments.",
                "On a hit, the hash is replaced by the corresponding fragment.",
                "On a miss, the driver contacts the Ganesh <br>proxy</br> to fetch the fragment.",
                "All previously unseen result fragments that were retained verbatim by the <br>proxy</br> are hashed and added to the result cache.",
                "There should be very few misses if the <br>proxy</br> has accurately tracked the Ganesh drivers cache state.",
                "A future optimization would be to batch the fetch of missing fragments.",
                "This would be valuable when there are many small missing fragments in a high-latency WAN.",
                "Once the transformation is complete, the fully reconstructed ResultSet object is passed up to the application. 4.",
                "EXPERIMENTAL VALIDATION Three questions follow from the goals and design of Ganesh: • First, can performance can be improved significantly by exploiting similarity across database results?",
                "Benchmark Dataset Details 500,000 Users, 12,000 Stories BBOARD 2.0 GB 3,298,000 Comments AUCTION 1.3 GB 1,000,000 Users, 34,000 Items Table 1: Benchmark Dataset Details • Second, how important is Ganeshs structural similarity detection relative to Rabin fingerprintings similarity detection? • Third, is the overhead of the <br>proxy</br>-based design acceptable?",
                "Our evaluation answers these question through controlled experiments with the Ganesh prototype.",
                "This section describes the benchmarks used, our evaluation procedure, and the experimental setup.",
                "Results of the experiments are presented in Sections 5, 6, and 7. 4.1 Benchmarks Our evaluation is based on two benchmarks [18] that have been widely used by other researchers to evaluate various aspects of multi-tier [27] and eBusiness architectures [9].",
                "The first benchmark, BBOARD, is modeled after Slashdot, a technology-oriented news site.",
                "The second benchmark, AUCTION, is modeled after eBay, an online auction site.",
                "In both benchmarks, most content is dynamically generated from information stored in a database.",
                "Details of the datasets used can be found in Table 1. 4.1.1 The BBOARD Benchmark The BBOARD benchmark, also known as RUBBoS [18], models Slashdot, a popular technology-oriented web site.",
                "Slashdot aggregates links to news stories and other topics of interest found elsewhere on the web.",
                "The site also serves as a bulletin board by allowing users to comment on the posted stories in a threaded conversation form.",
                "It is not uncommon for a story to gather hundreds of comments in a matter of hours.",
                "The BBOARD benchmark is similar to the site and models the activities of a user, including readonly operations such as browsing the stories of the day, browsing story categories, and viewing comments as well as write operations such as new user registration, adding and moderating comments, and story submission.",
                "The benchmark consists of three different phases: a short warmup phase, a runtime phase representing the main body of the workload, and a short cool-down phase.",
                "In this paper we only report results from the runtime phase.",
                "The warm-up phase is important in establishing dynamic system state, but measurements from that phase are not significant for our evaluation.",
                "The cool-down phase is solely for allowing the benchmark to shut down.",
                "The warm-up, runtime, and cool-down phases are 2, 15, and 2 minutes respectively.",
                "The number of simulated clients were 400, 800, 1200, and 1600.",
                "The benchmark is available in a Java Servlets and PHP version and has different datasets; we evaluated Ganesh using the Java Servlets version and the Expanded dataset.",
                "The BBOARD benchmark defines two different workloads.",
                "The first, the Authoring mix, consists of 70% read-only operations and 30% read-write operations.",
                "The second, the Browsing mix, contains only read-only operations and does not update the database. 4.1.2 The AUCTION Benchmark The AUCTION benchmark, also known as RUBiS [18], models eBay, the online auction site.",
                "The eBay web site is used to buy and sell items via an auction format.",
                "The main activities of a user include browsing, selling, or bidding for items.",
                "Modeling the activities on this site, this benchmark includes read-only activities such as browsing items by category and by region, as well as read-write WWW 2007 / Track: Performance and Scalability Session: Scalable Systems for Dynamic Content 314 NetEm Router Ganesh <br>proxy</br> Clients Web and Application Server Database Server Figure 5: Experimental Setup activities such as bidding for items, buying and selling items, and leaving feedback.",
                "As with BBOARD, the benchmark consists of three different phases.",
                "The warm-up, runtime, and cool-down phases for this experiment are 1.5, 15, and 1 minutes respectively.",
                "We tested Ganesh with four client configurations where the number of test clients was set to 400, 800, 1200, and 1600.",
                "The benchmark is available in a Enterprise Java Bean (EJB), Java Servlets, and PHP version and has different datasets; we evaluated Ganesh with the Java Servlets version and the Expanded dataset.",
                "The AUCTION benchmark defines two different workloads.",
                "The first, the Bidding mix, consists of 70% read-only operations and 30% read-write operations.",
                "The second, the Browsing mix, contains only read-only operations and does not update the database. 4.2 Experimental Procedure Both benchmarks involve a synthetic workload of clients accessing a web server.",
                "The number of clients emulated is an experimental parameter.",
                "Each emulated client runs an instance of the benchmark in its own thread, using a matrix to transition between different benchmark states.",
                "The matrix defines a stochastic model with probabilities of transitioning between the different states that represent typical user actions.",
                "An example transition is a user logging into the AUCTION system and then deciding on whether to post an item for sale or bid on active auctions.",
                "Each client also models user think time between requests.",
                "The think time is modeled as an exponential distribution with a mean of 7 seconds.",
                "We evaluate Ganesh along two axes: number of clients and WAN bandwidth.",
                "Higher loads are especially useful in understanding Ganeshs performance when the CPU or disk of the database server or <br>proxy</br> is the limiting factor.",
                "A previous study has shown that approximately 50% of the wide-area Internet bottlenecks observed had an available bandwidth under 10 Mb/s [1].",
                "Based on this work, we focus our evaluation on the WAN bandwidth of 5 Mb/s with 66 ms of round-trip latency, representative of severely constrained network paths, and 20 Mb/s with 33 ms of round-trip latency, representative of a moderately constrained network path.",
                "We also report Ganeshs performance at 100 Mb/s with no added round-trip latency.",
                "This bandwidth, representative of an unconstrained network, is especially useful in revealing any potential overhead of Ganesh in situations where WAN bandwidth is not the limiting factor.",
                "For each combination of number of clients and WAN bandwidth, we measured results from the two configurations listed below: • Native: This configuration corresponds to Figure 3(a).",
                "Native avoids Ganeshs overhead in using a <br>proxy</br> and performing Java object serialization. • Ganesh: This configuration corresponds to Figure 3(b).",
                "For a given number of clients and WAN bandwidth, comparing these results to the corresponding Native results gives the performance benefit due to the Ganesh middleware system.",
                "The metric used to quantify the improvement in throughput is the number of client requests that can be serviced per second.",
                "The metric used to quantify Ganeshs overhead is the average response time for a client request.",
                "For all of the experiments, the Ganesh driver used by the application server used a cache size of 100,000 items1 .",
                "The <br>proxy</br> was effective in tracking the Ganesh drivers cache state; for all of our experiments the miss rate on the driver never exceeded 0.7%. 4.3 Experimental Setup The experimental setup used for the benchmarks can be seen in Figure 5.",
                "All machines were 3.2 GHz Pentium 4s (with HyperThreading enabled.)",
                "With the exception of the database server, all machines had 2 GB of SDRAM and ran the Fedora Core Linux distribution.",
                "The database server had 4 GB of SDRAM.",
                "We used Apaches Tomcat as both the application server that hosted the Java Servlets and the web server.",
                "Both benchmarks used Java Servlets to generate the dynamic content.",
                "The database server used the open source MySQL database.",
                "For the native JDBC drivers, we used the Connector/J drivers provided by MySQL.",
                "The application server used Suns Java Virtual Machine as the runtime environment for the Java Servlets.",
                "The sysstat tool was used to monitor the CPU, network, disk, and memory utilization on all machines.",
                "The machines were connected by a switched gigabit Ethernet network.",
                "As shown in Figure 5, the front-end web and application server was separated from the <br>proxy</br> and database server by a NetEm router [16].",
                "This router allowed us to control the bandwidth and latency settings on the network.",
                "The NetEm router is a standard PC with two network cards running the Linux Traffic Control and Network Emulation software.",
                "The bandwidth and latency constraints were only applied to the link between the application server and the database for the native case and between the application server and the <br>proxy</br> for the Ganesh case.",
                "There is no communication between the application server and the database with Ganesh as all data flows through the <br>proxy</br>.",
                "As our focus was on the WAN link between the application server and the database, there were no constraints on the link between the simulated test clients and the web server. 5.",
                "THROUGHPUT AND RESPONSE TIME In this section, we address the first question raised in Section 4: Can performance can be improved significantly by exploiting similarity across database results?",
                "To answer this question, we use results from the BBOARD and AUCTION benchmarks.",
                "We use two metrics to quantify the performance improvement obtainable through the use of Ganesh: throughput, from the perspective of the web server, and average response time, from the perspective of the client.",
                "Throughput is measured in terms of the number of client requests that can be serviced per second. 5.1 BBOARD Results and Analysis 5.1.1 Authoring Mix Figures 6 (a) and (b) present the average number of requests serviced per second and the average response time for these requests as perceived by the clients for BBOARDs Authoring Mix.",
                "As Figure 6 (a) shows, Native easily saturates the 5 Mb/s link.",
                "At 400 clients, the Native solution delivers 29 requests/sec with an average response time of 8.3 seconds.",
                "Natives throughput drops with an increase in test clients as clients timeout due to congestion at the application server.",
                "Usability studies have shown that response times above 10 seconds cause the user to move on to 1 As Java lacks a sizeof() operator, Java caches therefore limit their size based on the number of objects.",
                "The size of cache dumps taken at the end of the experiments never exceeded 212 MB.",
                "WWW 2007 / Track: Performance and Scalability Session: Scalable Systems for Dynamic Content 315 0 50 100 150 200 250 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Test Clients Requests/sec Native Ganesh 0.001 0.01 0.1 1 10 100 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Test Clients Avg.Resp.Time(sec) Native Ganesh Note Logscale (a) Throughput: Authoring Mix (b) Response Time: Authoring Mix 0 50 100 150 200 250 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Test Clients Requests/sec Native Ganesh 0.001 0.01 0.1 1 10 100 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Test Clients Avg.Resp.Time(sec) Native Ganesh Note Logscale (c) Throughput: Browsing Mix (d) Response Time: Browsing Mix Mean of three trials.",
                "The maximum standard deviation for throughput and response time was 9.8% and 11.9% of the corresponding mean.",
                "Figure 6: BBOARD Benchmark - Throughput and Average Response Time other tasks [24].",
                "Based on these numbers, increasing the number of test clients makes the Native system unusable.",
                "Ganesh at 5 Mb/s, however, delivers a twofold improvement with 400 test clients and a fivefold improvement at 1200 clients.",
                "Ganeshs performance drops slightly at 1200 and 1600 clients as the network is saturated.",
                "Compared to Native, Figure 6 (b) shows that Ganeshs response times are substantially lower with sub-second response times at 400 clients.",
                "Figure 6 (a) also shows that for 400 and 800 test clients Ganesh at 5 Mb/s has the same throughput and average response time as Native at 20 Mb/s.",
                "Only at 1200 and 1600 clients does Native at 20 Mb/s deliver higher throughput than Ganesh at 5 Mb/s.",
                "Comparing both Ganesh and Native at 20 Mb/s, we see that Ganesh is no longer bandwidth constrained and delivers up to a twofold improvement over Native at 1600 test clients.",
                "As Ganesh does not saturate the network with higher test client configurations, at 1600 test clients, its average response time is 0.1 seconds rather than Natives 7.7 seconds.",
                "As expected, there are no visible gains from Ganesh at the higher bandwidth of 100 Mb/s where the network is no longer the bottleneck.",
                "Ganesh, however, still tracks Native in terms of throughput. 5.1.2 Browsing Mix Figures 6 (c) and (d) present the average number of requests serviced per second and the average response time for these requests as perceived by the clients for BBOARDs Browsing Mix.",
                "Regardless of the test client configuration, Figure 6 (c) shows that Natives throughput at 5 Mb/s is limited to 10 reqs/sec.",
                "Ganesh at 5 Mb/s with 400 test clients, delivers more than a sixfold increase in throughput.",
                "The improvement increases to over a elevenfold increase at 800 test clients before Ganesh saturates the network.",
                "Further, Figure 6 (d) shows that Natives average response time of 35 seconds at 400 test clients make the system unusable.",
                "These high response times further increase with the addition of test clients.",
                "Even with the 1600 test client configuration Ganesh delivers an acceptable average response time of 8.2 seconds.",
                "Due to the data-intensive nature of the Browsing mix, Ganesh at 5 Mb/s surprisingly performs much better than Native at 20 Mb/s.",
                "Further, as shown in Figure 6 (d), while the average response time for Native at 20 Mb/s is acceptable at 400 test clients, it is unusable with 800 test clients with an average response time of 15.8 seconds.",
                "Like the 5 Mb/s case, this response time increases with the addition of extra test clients.",
                "Ganesh at 20 Mb/s and both Native and Ganesh at 100 Mb/s are not bandwidth limited.",
                "However, performance plateaus out after 1200 test clients due to the database CPU being saturated. 5.1.3 Filter Variant We were surprised by the Native performance from the BBOARD benchmark.",
                "At the bandwidth of 5 Mb/s, Native performance was lower than what we had expected.",
                "It turned out the benchmark code that displays stories read all the comments associated with the particular story from the database and only then did some postprocessing to select the comments to be displayed.",
                "While this is exactly the behavior of SlashCode, the code base behind the Slashdot web site, we decided to modify the benchmark to perform some pre-filtering at the database.",
                "This modified benchmark, named the Filter Variant, models a developer who applies optimizations at the SQL level to transfer less data.",
                "In the interests of brevity, we only briefly summarize the results from the Authoring mix.",
                "For the Authoring mix, at 800 test clients at 5 Mb/s, Figure 7 (a) shows that Natives throughput increase by 85% when compared to the original benchmark while Ganeshs improvement is smaller at 15%.",
                "Natives performance drops above 800 clients as the test clients time out due to high response times.",
                "The most significant gain for Native is seen at 20 Mb/s.",
                "At 1600 test clients, when compared to the original benchmark, Native sees a 73% improvement in throughput and a 77% reduction in average response time.",
                "While WWW 2007 / Track: Performance and Scalability Session: Scalable Systems for Dynamic Content 316 0 50 100 150 200 250 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Test Clients Requests/sec Native Ganesh 0.001 0.01 0.1 1 10 100 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Test Clients Avg.Resp.Time(sec) Native Ganesh Note Logscale (a) Throughput: Authoring Mix (b) Response Time: Authoring Mix Mean of three trials.",
                "The maximum standard deviation for throughput and response time was 7.2% and 11.5% of the corresponding mean.",
                "Figure 7: BBOARD Benchmark - Filter Variant - Throughput and Average Response Time Ganesh sees no improvement when compared to the original, it still processes 19% more requests/sec than Native.",
                "Thus, while the optimizations were more helpful to Native, Ganesh still delivers an improvement in performance. 5.2 AUCTION Results and Analysis 5.2.1 Bidding Mix Figures 8 (a) and (b) present the average number of requests serviced per second and the average response time for these requests as perceived by the clients for AUCTIONs Bidding Mix.",
                "As mentioned earlier, the Bidding mix consists of a mixture of read and write operations.",
                "The AUCTION benchmark is not as data intensive as BBOARD.",
                "Therefore, most of the gains are observed at the lower bandwidth of 5 Mb/s.",
                "Figure 8 (a) shows that the increase in throughput due to Ganesh ranges from 8% at 400 test clients to 18% with 1600 test clients.",
                "As seen in Figure 8 (b), the average response times for Ganesh are significantly lower than Native ranging from a decrease of 84% at 800 test clients to 88% at 1600 test clients.",
                "Figure 8 (a) also shows that with a fourfold increase of bandwidth from 5 Mb/s to 20 Mb/s, Native is no longer bandwidth constrained and there is no performance difference between Ganesh and Native.",
                "With the higher test client configurations, we did observe that the bandwidth used by Ganesh was lower than Native.",
                "Ganesh might still be useful in these non-constrained scenarios if bandwidth is purchased on a metered basis.",
                "Similar results are seen for the 100 Mb/s scenario. 5.2.2 Browsing Mix For AUCTIONs Browsing Mix, Figures 8 (c) and (d) present the average number of requests serviced per second and the average response time for these requests as perceived by the clients.",
                "Again, most of the gains are observed at lower bandwidths.",
                "At 5 Mb/s, Native and Ganesh deliver similar throughput and response times with 400 test clients.",
                "While the throughput for both remains the same at 800 test clients, Figure 8 (d) shows that Ganeshs average response time is 62% lower than Native.",
                "Native saturates the link at 800 clients and adding extra test clients only increases the average response time.",
                "Ganesh, regardless of the test client configuration, is not bandwidth constrained and maintains the same response time.",
                "At 1600 test clients, Figure 8 (c) shows that Ganeshs throughput is almost twice that of Native.",
                "At the higher bandwidths of 20 and 100 Mb/s, neither Ganesh nor Native is bandwidth limited and deliver equivalent throughput and response times.",
                "Benchmark Orig.",
                "Size Ganesh Size Rabin Size SelectSort1 223.6 MB 5.4 MB 219.3 MB SelectSort2 223.6 MB 5.4 MB 223.6 MB Table 2: Similarity Microbenchmarks 6.",
                "STRUCTURAL VS. RABIN SIMILARITY In this section, we address the second question raised in Section 4: How important is Ganeshs structural similarity detection relative to Rabin fingerprinting-based similarity detecting?",
                "To answer this question, we used microbenchmarks and the BBOARD and AUCTION benchmarks.",
                "As Ganesh always performed better than Rabin fingerprinting, we only present a subset of the results here in the interests of brevity. 6.1 Microbenchmarks Two microbenchmarks show an example of the effects of data reordering on Rabin fingerprinting algorithm.",
                "In the first microbenchmark, SelectSort1, a query with a specified sort order selects 223.6 MB of data spread over approximately 280 K rows.",
                "The query is then repeated with a different sort attribute.",
                "While the same number of rows and the same data is returned, the order of rows is different.",
                "In such a scenario, one would expect a large amount of similarity to be detected between both results.",
                "As Table 2 shows, Ganeshs row-based algorithm achieves a 97.6% reduction while the Rabin fingerprinting algorithm, with the average chunk size parameter set to 4 KB, only achieves a 1% reduction.",
                "The reason, as shown earlier in Figure 2, is that with Rabin fingerprinting, the spans of data between two consecutive boundaries usually cross row boundaries.",
                "With the order of the rows changing in the second result and the Rabin fingerprints now spanning different rows, the algorithm is unable to detect significant similarity.",
                "The small gain seen is mostly for those single rows that are large enough to be broken into multiple chunks.",
                "SelectSort2, another micro-benchmark executed the same queries but increased the minimum chunk size of the Rabin fingerprinting algorithm.",
                "As can be seen in Table 2, even the small gain from the previous microbenchmark disappears as the minimum chunk size was greater than the average row size.",
                "While one can partially address these problems by dynamically varying the parameters of the Rabin fingerprinting algorithm, this can be computationally expensive, especially in the presence of changing workloads. 6.2 Application Benchmarks We ran the BBOARD benchmark described in Section 4.1.1 on two versions of Ganesh: the first with Rabin fingerprinting used as WWW 2007 / Track: Performance and Scalability Session: Scalable Systems for Dynamic Content 317 0 50 100 150 200 250 300 350 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Test Clients Requests/sec Native Ganesh 0.001 0.01 0.1 1 10 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Test Clients Avg.Resp.Time(sec) Native Ganesh Note Logscale (a) Throughput: Bidding Mix (b) Response Time: Bidding Mix 0 50 100 150 200 250 300 350 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Test Clients Requests/sec Native Ganesh 0.001 0.01 0.1 1 10 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Test Clients Avg.Resp.Time(sec) Native Ganesh Note Logscale (c) Throughput: Browsing Mix (d) Response Time: Browsing Mix Mean of three trials.",
                "The maximum standard deviation for throughput and response time was 2.2% and 11.8% of the corresponding mean.",
                "Figure 8: AUCTION Benchmark - Throughput and Average Response Time the chunking algorithm and the second with Ganeshs row-based algorithm.",
                "Rabins results for the Browsing Mix are normalized to Ganeshs results and presented in Figure 9.",
                "As Figure 9 (a) shows, at 5 Mb/s, independent of the test client configuration, Rabin significantly underperforms Ganesh.",
                "This happens because of a combination of two reasons.",
                "First, as outlined in Section 3.1, Rabin finds less similarity as it does not exploit the results structural information.",
                "Second, this benchmark contained some queries that generated large results.",
                "In this case, Rabin, with a small average chunk size, generated a large number of objects that evicted other useful data from the cache.",
                "In contrast, Ganesh was able to detect these large rows and correspondingly increase the size of the chunks.",
                "This was confirmed as cache statistics showed that Ganeshs hit ratio was roughly three time that of Rabin.",
                "Throughput measurements at 20 Mb/s were similar with the exception of Rabins performance with 400 test clients.",
                "In this case, Ganesh was not network limited and, in fact, the throughput was the same as 400 clients at 5 Mb/s.",
                "Rabin, however, took advantage of the bandwidth increase from 5 to 20 Mb/s to deliver a slightly better performance.",
                "At 100 Mb/s, Rabins throughput was almost similar to Ganesh as bandwidth was no longer a bottleneck.",
                "The normalized response time, presented in Figure 9 (b), shows similar trends.",
                "At 5 and 20 Mb/s, the addition of test clients decreases the normalized response time as Ganeshs average response time increases faster than Rabins.",
                "However, at no point does Rabin outperform Ganesh.",
                "Note that at 400 and 800 clients at 100 Mb/s, Rabin does have a higher overhead even when it is not bandwidth constrained.",
                "As mentioned in Section 3.1, this is due to the fact that Rabin has to hash each ResultSet twice.",
                "The overhead disappears with 1200 and 1600 clients as the database CPU is saturated and limits the performance of both Ganesh and Rabin. 7.",
                "<br>proxy</br> OVERHEAD In this section, we address the third question raised in Section 4: Is the overhead of Ganeshs <br>proxy</br>-based design acceptable?",
                "To answer this question, we concentrate on its performance at the higher bandwidths.",
                "Our evaluation in Section 5 showed that Ganesh, when compared to Native, can deliver a substantial throughput improvement at lower bandwidths.",
                "It is only at higher bandwidths that latency, measured by the average response time for a client request, and throughput, measured by the number of client requests that can be serviced per second, overheads would be visible.",
                "Looking at the Authoring mix of the original BBOARD benchmark, there are no visible gains from Ganesh at 100 Mb/s.",
                "Ganesh, however, still tracks Native in terms of throughput.",
                "While the average response time is higher for Ganesh, the absolute difference is in between 0.01 and 0.04 seconds and would be imperceptible to the end-user.",
                "The Browsing mix shows an even smaller difference in average response times.",
                "The results from the filter variant of the BBOARD benchmarks are similar.",
                "Even for the AUCTION benchmark, the difference between Native and Ganeshs response time at 100 Mb/s was never greater than 0.02 seconds.",
                "The only exception to the above results was seen in the filter variant of the BBOARD benchmark where Ganesh at 1600 test clients added 0.85 seconds to the average response time.",
                "Thus, even for much faster networks where the WAN link is not the bottleneck, Ganesh always delivers throughput equivalent to Native.",
                "While some extra latency is added by the <br>proxy</br>-based design, it is usually imperceptible. 8.",
                "RELATED WORK To the best of our knowledge, Ganesh is the first system that combines the use of hash-based techniques with caching of database results to improve throughput and response times for applications with dynamic content.",
                "We also believe that it is also the first system to demonstrate the benefits of using structural information for WWW 2007 / Track: Performance and Scalability Session: Scalable Systems for Dynamic Content 318 0.0 0.2 0.4 0.6 0.8 1.0 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Test Clients Norm.Throughput 31.8 3.8 2.8 2.3 23.8 32.8 5.8 3.6 1.8 2.1 1.1 1.0 0 5 10 15 20 25 30 35 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Test Clients Norm.ResponseTime (a) Normalized Throughput: Higher is better (b) Normalized Response Time: Higher is worse For throughput, a normalized result greater than 1 implies that Rabin is better, For response time, a normalized result greater than 1 implies that Ganesh is better.",
                "Mean of three trials.",
                "The maximum standard deviation for throughput and response time was 9.1% and 13.9% of the corresponding mean.",
                "Figure 9: Normalized Comparison of Ganesh vs. Rabin - BBOARD Browsing Mix detecting similarity.",
                "In this section, we first discuss alternative approaches to caching dynamic content and then examine other uses of hash-based primitives in distributed systems. 8.1 Caching Dynamic Content At the database layer, a number of systems have advocated middletier caching where parts of the database are replicated at the edge or server [3, 4, 20].",
                "These systems either cache entire tables in what is essentially a replicated database or use materialized views from previous query replies [19].",
                "They require tight integration with the back-end database to ensure a time bound on the propagation of updates.",
                "These systems are also usually targeted towards workloads that do not require strict consistency and can tolerate stale data.",
                "Further, unlike Ganesh, some of these mid-tier caching solutions [2, 3], suffer from the complexity of having to participate in query planing and distributed query processing.",
                "Gao et al. [15] propose using a distributed object replication architecture where the data stores consistency requirements are adapted on a per-application basis.",
                "These solutions require substantial developer resources and detailed understanding of the application being modified.",
                "While systems that attempt to automate the partitioning and replication of an applications database exist [34], they do not provide full transaction semantics.",
                "In comparison, Ganesh does not weaken any of the semantics provided by the underlying database.",
                "Recent work in the evaluation of edge caching options for dynamic web sites [38] has suggested that, without careful planning, employing complex offloading strategies can hurt performance.",
                "Instead, the work advocates for an architecture in which all tiers except the database should be offloaded to the edge.",
                "Our evaluation of Ganesh has shown that it would benefit these scenarios.",
                "To improve database scalability, C-JDBC [10], SSS [22], and Ganymed [28] also advocate the use of an interposition-based architecture to transparently cluster and replicate databases at the middleware level.",
                "The approaches of these architectures and Ganesh are complementary and they would benefit each other.",
                "Moving up to the presentation layer, there has been widespread adoption of fragment-based caching [14], which improves cache utilization by separately caching different parts of generated web pages.",
                "While fragment-based caching works at the edge, a recent proposal has proposed moving web page assembly to the clients to optimize content delivery [31].",
                "While Ganesh is not used at the presentation layer, the same principles have been applied in Duplicate Transfer Detection [25] to increase web cache efficiency as well as for web access across bandwidth limited links [33]. 8.2 Hash-based Systems The past few years have seen the emergence of many systems that exploit hash-based techniques.",
                "At the heart of all these systems is the idea of detecting similarity in data without requiring interpretation of that data.",
                "This simple yet elegant idea relies on cryptographic hashing, as discussed earlier in Section 2.",
                "Successful applications of this idea span a wide range of storage systems.",
                "Examples include peer-to-peer backup of personal computing files [11], storage-efficient archiving of data [29], and finding similar files [21].",
                "Spring and Wetherall [35] apply similar principles at the network level.",
                "Using synchronized caches at both ends of a network link, duplicated data is replaced by smaller tokens for transmission and then restored at the remote end.",
                "This and other hash-based systems such as the CASPER [37] and LBFS [26] filesystems, and Layer-2 bandwidth optimizers such as Riverbed and Peribit use Rabin fingerprinting [30] to discover spans of commonality in data.",
                "This approach is especially useful when data items are modified in-place through insertions, deletions, and updates.",
                "However, as Section 6 shows, the performance of this technique can show a dramatic drop in the presence of data reordering.",
                "Ganesh instead uses row boundaries as dividers for detecting similarity.",
                "The most aggressive use of hash-based techniques is by systems that use hashes as the primary identifiers for objects in persistent storage.",
                "Storage systems such as CFS [12] and PAST [13] that have been built using distributed hash tables fall into this category.",
                "Single Instance Storage [6] and Venti [29] are other examples of such systems.",
                "As discussed in Section 2.2, the use of cryptographic hashes for addressing persistent data represents a deeper level of faith in their collision-resistance than that assumed by Ganesh.",
                "If time reveals shortcomings in the hash algorithm, the effort involved in correcting the flaw is much greater.",
                "In Ganesh, it is merely a matter of replacing the hash algorithm. 9.",
                "CONCLUSION The growing use of dynamic web content generated from relational databases places increased demands on WAN bandwidth.",
                "Traditional caching solutions for bandwidth and latency reduction are often ineffective for such content.",
                "This paper shows that the impact of WAN accesses to databases can be substantially reduced through the Ganesh architecture without any compromise of the databases strict consistency semantics.",
                "The essence of the Ganesh architecture is the use of computation at the edges to reduce communication through the Internet.",
                "Ganesh is able to use cryptographic hashes to detect similarity with previous results and send WWW 2007 / Track: Performance and Scalability Session: Scalable Systems for Dynamic Content 319 compact recipes of results rather than full results.",
                "Our design uses interposition to achieve complete transparency: clients, application servers, and database servers are all unaware of Ganeshs presence and require no modification.",
                "Our experimental evaluation confirms that Ganesh, while conceptually simple, can be highly effective in improving throughput and response time.",
                "Our results also confirm that exploiting the structure present in database results to detect similarity is crucial to this performance improvement. 10.",
                "REFERENCES [1] AKELLA, A., SESHAN, S., AND SHAIKH, A.",
                "An empirical evaluation of wide-area internet bottlenecks.",
                "In Proc. 3rd ACM SIGCOMM Conference on Internet Measurement (Miami Beach, FL, USA, Oct. 2003), pp. 101-114. [2] ALTINEL, M., BORNH ¨OVD, C., KRISHNAMURTHY, S., MOHAN, C., PIRAHESH, H., AND REINWALD, B. Cache tables: Paving the way for an adaptive database cache.",
                "In Proc. of 29th VLDB (Berlin, Germany, 2003), pp. 718-729. [3] ALTINEL, M., LUO, Q., KRISHNAMURTHY, S., MOHAN, C., PIRAHESH, H., LINDSAY, B. G., WOO, H., AND BROWN, L. Dbcache: Database caching for web application servers.",
                "In Proc. 2002 ACM SIGMOD (2002), pp. 612-612. [4] AMIRI, K., PARK, S., TEWARI, R., AND PADMANABHAN, S. Dbproxy: A dynamic data cache for web applications.",
                "In Proc.",
                "IEEE International Conference on Data Engineering (ICDE) (Mar. 2003). [5] BLACK, J. Compare-by-hash: A reasoned analysis.",
                "In Proc. 2006 USENIX Annual Technical Conference (Boston, MA, May 2006), pp. 85-90. [6] BOLOSKY, W. J., CORBIN, S., GOEBEL, D., , AND DOUCEUR, J. R. Single instance storage in windows 2000.",
                "In Proc. 4th USENIX Windows Systems Symposium (Seattle, WA, Aug. 2000), pp. 13-24. [7] BREWER, E. A.",
                "Lessons from giant-scale services.",
                "IEEE Internet Computing 5, 4 (2001), 46-55. [8] BRODER, A., GLASSMAN, S., MANASSE, M., AND ZWEIG, G. Syntactic clustering of the web.",
                "In Proc. 6th International WWW Conference (1997). [9] CECCHET, E., CHANDA, A., ELNIKETY, S., MARGUERITE, J., AND ZWAENEPOEL, W. Performance comparison of middleware architectures for generating dynamic web content.",
                "In Proc.",
                "Fourth ACM/IFIP/USENIX International Middleware Conference (Rio de Janeiro, Brazil, June 2003). [10] CECCHET, E., MARGUERITE, J., AND ZWAENEPOEL, W. C-JDBC: Flexible database clustering middleware.",
                "In Proc. 2004 USENIX Annual Technical Conference (Boston, MA, June 2004). [11] COX, L. P., MURRAY, C. D., AND NOBLE, B. D. Pastiche: Making backup cheap and easy.",
                "In OSDI: Symposium on Operating Systems Design and Implementation (2002). [12] DABEK, F., KAASHOEK, M. F., KARGER, D., MORRIS, R., AND STOICA, I. Wide-area cooperative storage with CFS.",
                "In 18th ACM Symposium on Operating Systems Principles (Banff, Canada, Oct. 2001). [13] DRUSCHEL, P., AND ROWSTRON, A.",
                "PAST: A large-scale, persistent peer-to-peer storage utility.",
                "In HotOS VIII (Schloss Elmau, Germany, May 2001), pp. 75-80. [14] Edge side includes. http://www.esi.org. [15] GAO, L., DAHLIN, M., NAYATE, A., ZHENG, J., AND IYENGAR, A.",
                "Application specific data replication for edge services.",
                "In WWW 03: Proc.",
                "Twelfth International Conference on World Wide Web (2003), pp. 449-460. [16] HEMMINGER, S. Netem - emulating real networks in the lab.",
                "In Proc. 2005 Linux Conference Australia (Canberra, Australia, Apr. 2005). [17] HENSON, V. An analysis of compare-by-hash.",
                "In Proc. 9th Workshop on Hot Topics in Operating Systems (HotOS IX) (May 2003), pp. 13-18. [18] Jmob benchmarks. http://jmob.objectweb.org/. [19] LABRINIDIS, A., AND ROUSSOPOULOS, N. Balancing performance and data freshness in web database servers.",
                "In Proc. 29th VLDB Conference (Sept. 2003). [20] LARSON, P.-A., GOLDSTEIN, J., AND ZHOU, J. Transparent mid-tier database caching in sql server.",
                "In Proc. 2003 ACM SIGMOD (2003), pp. 661-661. [21] MANBER, U.",
                "Finding similar files in a large file system.",
                "In Proc.",
                "USENIX Winter 1994 Technical Conference (San Fransisco, CA, 17-21 1994), pp. 1-10. [22] MANJHI, A., AILAMAKI, A., MAGGS, B. M., MOWRY, T. C., OLSTON, C., AND TOMASIC, A.",
                "Simultaneous scalability and security for data-intensive web applications.",
                "In Proc. 2006 ACM SIGMOD (June 2006), pp. 241-252. [23] MENEZES, A. J., VANSTONE, S. A., AND OORSCHOT, P. C. V. Handbook of Applied Cryptography.",
                "CRC Press, 1996. [24] MILLER, R. B.",
                "Response time in man-computer conversational transactions.",
                "In Proc.",
                "AFIPS Fall Joint Computer Conference (1968), pp. 267-277. [25] MOGUL, J. C., CHAN, Y. M., AND KELLY, T. Design, implementation, and evaluation of duplicate transfer detection in http.",
                "In Proc.",
                "First Symposium on Networked Systems Design and Implementation (San Francisco, CA, Mar. 2004). [26] MUTHITACHAROEN, A., CHEN, B., AND MAZIERES, D. A low-bandwidth network file system.",
                "In Proc. 18th ACM Symposium on Operating Systems Principles (Banff, Canada, Oct. 2001). [27] PFEIFER, D., AND JAKSCHITSCH, H. Method-based caching in multi-tiered server applications.",
                "In Proc.",
                "Fifth International Symposium on Distributed Objects and Applications (Catania, Sicily, Italy, Nov. 2003). [28] PLATTNER, C., AND ALONSO, G. Ganymed: Scalable replication for transactional web applications.",
                "In Proc. 5th ACM/IFIP/USENIX International Conference on Middleware (2004), pp. 155-174. [29] QUINLAN, S., AND DORWARD, S. Venti: A new approach to archival storage.",
                "In Proc.",
                "FAST 2002 Conference on File and Storage Technologies (2002). [30] RABIN, M. Fingerprinting by random polynomials.",
                "In Harvard University Center for Research in Computing Technology Technical Report TR-15-81 (1981). [31] RABINOVICH, M., XIAO, Z., DOUGLIS, F., AND KALMANEK, C. Moving edge side includes to the real edge - the clients.",
                "In Proc. 4th USENIX Symposium on Internet Technologies and Systems (Seattle, WA, Mar. 2003). [32] REESE, G. Database Programming with JDBC and Java, 1st ed.",
                "OReilly, June 1997. [33] RHEA, S., LIANG, K., AND BREWER, E. Value-based web caching.",
                "In Proc.",
                "Twelfth International World Wide Web Conference (May 2003). [34] SIVASUBRAMANIAN, S., ALONSO, G., PIERRE, G., AND VAN STEEN, M. Globedb: Autonomic data replication for web applications.",
                "In WWW 05: Proc. 14th International World-Wide Web conference (May 2005). [35] SPRING, N. T., AND WETHERALL, D. A protocol-independent technique for eliminating redundant network traffic.",
                "In Proc. of ACM SIGCOMM (Aug. 2000). [36] TOLIA, N., HARKES, J., KOZUCH, M., AND SATYANARAYANAN, M. Integrating portable and distributed storage.",
                "In Proc. 3rd USENIX Conference on File and Storage Technologies (San Francisco, CA, Mar. 2004). [37] TOLIA, N., KOZUCH, M., SATYANARAYANAN, M., KARP, B., PERRIG, A., AND BRESSOUD, T. Opportunistic use of content addressable storage for distributed file systems.",
                "In Proc. 2003 USENIX Annual Technical Conference (San Antonio, TX, June 2003), pp. 127-140. [38] YUAN, C., CHEN, Y., AND ZHANG, Z.",
                "Evaluation of edge caching/offloading for dynamic content delivery.",
                "In WWW 03: Proc.",
                "Twelfth International Conference on World Wide Web (2003), pp. 461-471.",
                "WWW 2007 / Track: Performance and Scalability Session: Scalable Systems for Dynamic Content 320"
            ],
            "original_annotated_samples": [
                "We then describe Ganeshs <br>proxy</br>-based approach and the dataflow for detecting similarity. 3.1 Detecting Similarity One of the key design decisions in Ganesh is how similarity is detected.",
                "At the database, we add a new process called the Ganesh <br>proxy</br>.",
                "This <br>proxy</br>, which can be shared by multiple front-end nodes, consists of two parts: code to detect similarity in result fragments and the original native JDBC driver that communicates with the database.",
                "The use of a <br>proxy</br> at the database makes Ganesh database-agnostic and simplifies prototyping and experimentation.",
                "Ganesh is thus able to work with a wide range of databases and applications, requiring no modifications to either. 3.3 <br>proxy</br>-Based Caching The native JDBC driver shown in Figure 3(a) is a lightweight code component supplied by the database vendor."
            ],
            "translated_annotated_samples": [
                "Luego describimos el <br>enfoque basado en proxy</br> de Ganesh y el flujo de datos para detectar similitudes. 3.1 Detectar similitud Una de las decisiones clave de diseño en Ganesh es cómo se detecta la similitud.",
                "En la base de datos, agregamos un nuevo proceso llamado el <br>proxy</br> Ganesh.",
                "Este <br>proxy</br>, que puede ser compartido por múltiples nodos front-end, consta de dos partes: código para detectar similitud en fragmentos de resultados y el controlador JDBC nativo original que se comunica con la base de datos.",
                "El uso de un <br>proxy</br> en la base de datos hace que Ganesh sea independiente de la base de datos y simplifica la creación de prototipos y experimentación.",
                "Ganesh es capaz de trabajar con una amplia gama de bases de datos y aplicaciones, sin necesidad de realizar modificaciones en ninguna de ellas. 3.3 <br>Caché basada en proxy</br> El controlador JDBC nativo mostrado en la Figura 3(a) es un componente de código ligero suministrado por el proveedor de la base de datos."
            ],
            "translated_text": "Conservación de la consistencia en el almacenamiento en caché de contenido dinámico de bases de datos∗ Niraj Tolia y M. Satyanarayanan Universidad Carnegie Mellon {ntolia,satya}@cs.cmu.edu RESUMEN Con el creciente uso de contenido web dinámico generado a partir de bases de datos relacionales, las soluciones de almacenamiento en caché tradicionales para mejorar el rendimiento y la latencia son ineficaces. Describimos una capa de middleware llamada Ganesh que reduce el volumen de datos transmitidos sin interpretación semántica de consultas o resultados. Se logra esta reducción mediante el uso de hash criptográficos para detectar similitudes con resultados anteriores. Estos beneficios no requieren ningún compromiso con la semántica de consistencia estricta proporcionada por la base de datos del servidor. Además, Ganesh no requiere modificaciones en aplicaciones, servidores web o servidores de bases de datos, y funciona con aplicaciones y bases de datos de código cerrado. Usando dos puntos de referencia representativos de sitios web dinámicos, las mediciones de nuestro prototipo muestran que puede aumentar el rendimiento de extremo a extremo hasta en un factor de dos para aplicaciones no intensivas en datos y hasta en un factor de diez para las intensivas en datos. Categorías y Descriptores de Asignaturas C.2.4 [Redes de Computadoras-Comunicación]: Sistemas Distribuidos; H.2.4 [Gestión de Bases de Datos]: Términos Generales de Sistemas de Diseño, Rendimiento 1. INTRODUCCIÓN Una fracción creciente del contenido web se genera dinámicamente a partir de bases de datos relacionales en el backend. Incluso cuando el contenido de la base de datos permanece sin cambios, la localidad temporal de acceso no puede ser explotada porque el contenido dinámico no es almacenable en caché por los navegadores web o por servidores de almacenamiento en caché intermedios como los espejos de Akamai. En una arquitectura multinivel, cada solicitud web puede tensionar el enlace WAN entre el servidor web y la base de datos. Esto provoca que la experiencia del usuario sea altamente variable porque no hay almacenamiento en caché para aislar al cliente de cargas repentinas. Los intentos previos de almacenar en caché contenido dinámico de bases de datos generalmente han debilitado la semántica transaccional [3, 4] o han requerido modificaciones en la aplicación [15, 34]. Informamos sobre una nueva solución que toma la forma de una capa intermedia de middleware independiente de la base de datos llamada Ganesh. Ganesh no hace ningún esfuerzo por interpretar semánticamente el contenido de las consultas o sus resultados. En cambio, se basa exclusivamente en el hash criptográfico para detectar similitudes con resultados anteriores. La detección de similitud basada en hash ha sido cada vez más utilizada en sistemas de archivos distribuidos [26, 36, 37] para mejorar el rendimiento en redes de baja capacidad de ancho de banda. Sin embargo, estas técnicas no se han utilizado para bases de datos relacionales. A diferencia de enfoques anteriores que utilizan métodos genéricos para detectar similitud, Ganesh explota la estructura de los resultados de la base de datos relacional para lograr una mejora superior en el rendimiento. Uno se enfrenta al menos a tres desafíos al aplicar la detección de similitud basada en hash a las bases de datos de back-end. Primero, el trabajo previo en este ámbito ha considerado tradicionalmente el contenido de almacenamiento como bolsas de bits no interpretadas y sin estructura interna. Esto permite que las técnicas basadas en hash operen en largas y contiguas secuencias de datos para lograr la máxima efectividad. Por el contrario, las bases de datos relacionales tienen una estructura interna compleja que puede no ser tan propicia para la detección de similitudes basada en hash. Segundo, las bases de datos relacionales tienen restricciones de integridad y consistencia muy estrictas que no deben comprometerse por el uso de técnicas basadas en hash. Tercero, el código fuente de las bases de datos comerciales generalmente no está disponible. Esto contrasta con trabajos anteriores que presumían la disponibilidad del código fuente. Nuestros experimentos muestran que Ganesh, aunque conceptualmente simple, puede mejorar significativamente el rendimiento en anchos de banda representativos del Internet comercial actual. En los modelos de referencia de aplicaciones web multinivel, la mejora en el rendimiento fue de hasta diez veces para cargas de trabajo intensivas en datos. Para cargas de trabajo que no eran intensivas en datos, se observaron mejoras en el rendimiento de hasta el doble. Incluso cuando el ancho de banda no era una limitación, Ganesh tenía un bajo sobrecosto y no afectaba el rendimiento. Nuestros experimentos también confirman que aprovechar la estructura presente en los resultados de la base de datos es crucial para esta mejora en el rendimiento. Antecedentes 2.1 Generación de Contenido Dinámico A medida que la World Wide Web ha crecido, muchos sitios web han descentralizado sus datos y funcionalidades al llevarlos a los extremos de Internet. Hoy en día, los sistemas de comercio electrónico a menudo utilizan una arquitectura de tres niveles que consta de un servidor web de front-end, un servidor de aplicaciones y un servidor de base de datos de back-end. La Figura 1 ilustra esta arquitectura. Los dos primeros niveles se pueden replicar cerca de una concentración de clientes en el borde de Internet. Esto mejora la experiencia del usuario al reducir la latencia de extremo a extremo y disminuir la exposición al congestionamiento del tráfico de la columna vertebral. También puede aumentar la disponibilidad y escalabilidad de los servicios web. El contenido que se genera dinámicamente desde la base de datos del servidor no puede ser almacenado en caché en los dos primeros niveles. Si bien las bases de datos pueden replicarse fácilmente en una LAN, esto es inviable en una WAN debido a la difícil tarea de proporcionar simultáneamente una consistencia sólida, disponibilidad y tolerancia a particiones de red [7]. Como resultado, las bases de datos tienden a ser centralizadas para cumplir con los fuertes requisitos de consistencia de muchas aplicaciones de comercio electrónico como la banca, las finanzas y la venta al por menor en línea [38]. Por lo tanto, la base de datos del back-end suele estar ubicada lejos de muchos conjuntos de nodos de primer y segundo nivel [2]. En ausencia de almacenamiento en caché y replicación, el ancho de banda de la WAN puede convertirse fácilmente en un factor limitante en el rendimiento y la escalabilidad de aplicaciones intensivas en datos. El enfoque de Ganesh en los sistemas basados en hash es la transmisión eficiente de resultados al descubrir similitudes con los resultados de consultas anteriores. Dado que las consultas SQL pueden generar resultados grandes, las técnicas basadas en hash se prestan bien al problema de transferir eficientemente estos grandes resultados a través de enlaces con ancho de banda limitado. El uso de técnicas basadas en hash para reducir el volumen de datos transmitidos ha surgido como un tema común en muchos sistemas de almacenamiento recientes, como se discute en la Sección 8.2. Estas técnicas se basan en algunas suposiciones básicas. Se asume que las funciones hash criptográficas son resistentes a colisiones. En otras palabras, es computacionalmente intratable encontrar dos entradas que se hash a la misma salida. Las funciones también se asumen como unidireccionales; es decir, encontrar una entrada que resulte en una salida específica es computacionalmente inviable. Menezes et al. [23] proporcionan más detalles sobre estas suposiciones. Las suposiciones anteriores permiten a los sistemas basados en hash asumir que no se producen colisiones. Por lo tanto, pueden tratar el hash de un elemento de datos como su identificador único. Una colección de elementos de datos se convierte efectivamente en direccionable por contenido, permitiendo que un hash pequeño funcione como una palabra de código para un elemento de datos mucho más grande en almacenamiento permanente o transmisión en red. La suposición de que las colisiones son tan raras que prácticamente no existen ha sido cuestionada recientemente [17]. Sin embargo, como explicó Black [5], creemos que estos problemas no son una preocupación para Ganesh. Toda comunicación es entre partes confiables del sistema y un adversario no tiene forma de obligar a Ganesh a aceptar datos inválidos. Además, Ganesh no depende críticamente de ninguna función hash específica. Si bien actualmente usamos SHA-1, reemplazarlo con una función hash diferente sería sencillo. No habría impacto en el rendimiento con funciones hash más fuertes (por ejemplo, SHA256) solo añade unos pocos bytes adicionales y los hashes generados siguen siendo órdenes de magnitud más pequeños que los elementos de datos que representan. No es necesario volver a almacenar permanentemente ya que Ganesh solo utiliza el hash en datos volátiles. 3. DISEÑO E IMPLEMENTACIÓN Ganesh explota la redundancia en el flujo de resultados para evitar transmitir fragmentos de resultados que ya están presentes en el sitio de la consulta. La redundancia puede surgir de forma natural de muchas maneras diferentes. Por ejemplo, una consulta repetida después de un cierto intervalo puede devolver un resultado diferente debido a actualizaciones en la base de datos; sin embargo, puede haber una significativa similitud entre los dos resultados. Como otro ejemplo, un usuario que está refinando una búsqueda puede generar una secuencia de consultas con resultados superpuestos. Cuando Ganesh detecta redundancia, suprime la transmisión de los fragmentos de resultado correspondientes. En cambio, transmite un resumen mucho más pequeño de esos fragmentos y permite que el sitio de consulta reconstruya el resultado a través de la búsqueda de hash en una caché de resultados anteriores. De hecho, Ganesh utiliza la computación en los bordes para reducir la comunicación por Internet. Nuestra descripción de Ganesh se centra en cuatro aspectos. Primero explicamos nuestro enfoque para detectar similitud en los resultados de la consulta. A continuación, discutimos cómo la arquitectura Ganesh es completamente invisible para todos los componentes de un sistema de múltiples niveles. Luego describimos el <br>enfoque basado en proxy</br> de Ganesh y el flujo de datos para detectar similitudes. 3.1 Detectar similitud Una de las decisiones clave de diseño en Ganesh es cómo se detecta la similitud. Hay muchas formas potenciales de descomponer un resultado en fragmentos.  I the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the thees I,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,, Encontrar esta descomposición óptima es un problema difícil debido al amplio espacio de posibilidades y porque la elección óptima depende de muchos factores, como el contenido del resultado de las consultas, el historial de resultados recientes y el algoritmo de gestión de caché. Cuando un objeto es opaco, el uso de huellas digitales de Rabin [8, 30] para detectar datos comunes entre dos objetos ha sido demostrado con éxito en el pasado por sistemas como LBFS [26] y CASPER [37]. El fingerprinting de Rabin utiliza una ventana deslizante sobre los datos para calcular un hash rodante. Suponiendo que la función hash está distribuida uniformemente, un límite de fragmento se define cuando los bits de orden inferior del valor hash son iguales a algún valor predeterminado. El número de bits de orden inferior utilizados define el tamaño promedio del fragmento. Estos fragmentos subdivididos del objeto se convierten en la unidad de comparación para detectar similitudes entre diferentes objetos. Dado que las ubicaciones de los límites encontrados mediante el uso de las huellas de Rabin están determinadas de manera estocástica, generalmente no logran alinearse con ninguna propiedad estructural de los datos subyacentes. Por lo tanto, el algoritmo maneja bien las actualizaciones en su lugar, inserciones y eliminaciones. Sin embargo, tiene un rendimiento deficiente en presencia de cualquier reordenamiento de datos. La Figura 2 muestra un ejemplo donde dos resultados, A y B, que constan de tres filas, tienen los mismos datos pero diferentes atributos de ordenamiento. En el caso extremo, la huella digital de Rabin podría no ser capaz de encontrar datos similares debido a la forma en que detecta los límites de los fragmentos. Afortunadamente, Ganesh puede utilizar conocimientos específicos del dominio para una detección de límites más precisa. La información que explotamos es que el resultado de una consulta refleja la estructura de una base de datos relacional donde todos los datos están organizados en tablas y filas. Por lo tanto, es sencillo verificar la similitud con resultados anteriores en dos niveles de granularidad: primero el resultado completo y luego las filas individuales. El final de una fila en un resultado sirve como un límite natural de fragmento. Es importante tener en cuenta que el uso de la estructura tabular en los resultados solo implica una interpretación superficial de los datos. Ganesh no realiza ninguna interpretación semántica más profunda, como comprender tipos de datos, esquemas de resultados o restricciones de integridad. Ajustar la huella digital de Rabin para una carga de trabajo también puede ser difícil. Si el tamaño promedio de los fragmentos es demasiado grande, los fragmentos pueden abarcar varias filas de resultados. Sin embargo, seleccionar un tamaño de fragmento promedio más pequeño aumenta la cantidad de metadatos necesarios para describir los resultados. Esto, a su vez, disminuiría los ahorros obtenidos mediante su uso. El fingerprinting de Rabin también requiere dos pasadas computacionalmente costosas sobre los datos: una vez para determinar los límites de los fragmentos y otra vez para generar hashes criptográficos para los fragmentos. Ganesh solo necesita un único pase para la generación de hash, ya que los límites de los fragmentos son proporcionados por la estructura natural de los datos. La comparación de rendimiento en la Sección 6 muestra que el algoritmo basado en filas de Ganesh supera al fingerprinting de Rabin. Dado que trabajos anteriores ya han demostrado que la huella digital de Rabin funciona mejor que gzip [26], no comparamos a Ganesh con algoritmos de compresión en este artículo. 3.2 Transparencia El factor clave que influyó en nuestro diseño fue la necesidad de que Ganesh fuera completamente transparente para todos los componentes de un sistema típico de comercio electrónico: servidores web, servidores de aplicaciones y servidores de bases de datos. Sin esto, Ganesh tiene pocas posibilidades de tener un impacto significativo en el mundo real. Requerir modificaciones en cualquiera de los componentes mencionados aumentaría la barrera de entrada de Ganesh en un sistema existente, y por lo tanto reduciría sus posibilidades de adopción. Preservar la transparencia se simplifica por el hecho de que Ganesh es simplemente una mejora de rendimiento, no una mejora de funcionalidad o usabilidad. Elegimos la interposición de agentes como enfoque arquitectónico para lograr nuestro objetivo. Este enfoque se basa en la existencia de una interfaz de programación compacta que ya es ampliamente utilizada por el software objetivo. También se basa en un mecanismo para agregar fácilmente nuevo código sin interrumpir la estructura de módulos existente. Estas condiciones se cumplen fácilmente en nuestro contexto debido a la popularidad de Java como el lenguaje de programación para sistemas de comercio electrónico. La API de Conectividad de Base de Datos de Java (JDBC) [32] permite a las aplicaciones de Java acceder a una amplia variedad de bases de datos e incluso a otros repositorios de datos tabulares como archivos planos. El acceso a estas fuentes de datos es proporcionado por controladores JDBC que traducen entre la API JDBC y el mecanismo de comunicación de la base de datos. La figura 3(a) muestra cómo se utiliza típicamente JDBC en una aplicación. Dado que la interfaz JDBC está estandarizada, se puede sustituir un controlador JDBC por otro sin necesidad de de modificar la aplicación. El controlador JDBC se convierte así en el módulo natural para aprovechar la interposición de código. Como se muestra en la Figura 3(b), el controlador JDBC nativo es reemplazado por un controlador JDBC Ganesh que presenta la misma interfaz estandarizada. El controlador Ganesh mantiene una caché en memoria de fragmentos de resultados de consultas anteriores y realiza el reensamblaje de resultados. En la base de datos, agregamos un nuevo proceso llamado el <br>proxy</br> Ganesh. Este <br>proxy</br>, que puede ser compartido por múltiples nodos front-end, consta de dos partes: código para detectar similitud en fragmentos de resultados y el controlador JDBC nativo original que se comunica con la base de datos. El uso de un <br>proxy</br> en la base de datos hace que Ganesh sea independiente de la base de datos y simplifica la creación de prototipos y experimentación. Ganesh es capaz de trabajar con una amplia gama de bases de datos y aplicaciones, sin necesidad de realizar modificaciones en ninguna de ellas. 3.3 <br>Caché basada en proxy</br> El controlador JDBC nativo mostrado en la Figura 3(a) es un componente de código ligero suministrado por el proveedor de la base de datos. ",
            "candidates": [],
            "error": [
                [
                    "enfoque basado en proxy",
                    "proxy",
                    "proxy",
                    "proxy",
                    "Caché basada en proxy"
                ]
            ]
        },
        "jdbc driver": {
            "translated_key": "controlador JDBC",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Consistency-preserving Caching of Dynamic Database Content∗ Niraj Tolia and M. Satyanarayanan Carnegie Mellon University {ntolia,satya}@cs.cmu.edu ABSTRACT With the growing use of dynamic web content generated from relational databases, traditional caching solutions for throughput and latency improvements are ineffective.",
                "We describe a middleware layer called Ganesh that reduces the volume of data transmitted without semantic interpretation of queries or results.",
                "It achieves this reduction through the use of cryptographic hashing to detect similarities with previous results.",
                "These benefits do not require any compromise of the strict consistency semantics provided by the back-end database.",
                "Further, Ganesh does not require modifications to applications, web servers, or database servers, and works with closed-source applications and databases.",
                "Using two benchmarks representative of dynamic web sites, measurements of our prototype show that it can increase end-to-end throughput by as much as twofold for non-data intensive applications and by as much as tenfold for data intensive ones.",
                "Categories and Subject Descriptors C.2.4 [Computer-Communication Networks]: Distributed Systems; H.2.4 [Database Management]: Systems General Terms Design, Performance 1.",
                "INTRODUCTION An increasing fraction of web content is dynamically generated from back-end relational databases.",
                "Even when database content remains unchanged, temporal locality of access cannot be exploited because dynamic content is not cacheable by web browsers or by intermediate caching servers such as Akamai mirrors.",
                "In a multitiered architecture, each web request can stress the WAN link between the web server and the database.",
                "This causes user experience to be highly variable because there is no caching to insulate the client from bursty loads.",
                "Previous attempts in caching dynamic database content have generally weakened transactional semantics [3, 4] or required application modifications [15, 34].",
                "We report on a new solution that takes the form of a databaseagnostic middleware layer called Ganesh.",
                "Ganesh makes no effort to semantically interpret the contents of queries or their results.",
                "Instead, it relies exclusively on cryptographic hashing to detect similarities with previous results.",
                "Hash-based similarity detection has seen increasing use in distributed file systems [26, 36, 37] for improving performance on low-bandwidth networks.",
                "However, these techniques have not been used for relational databases.",
                "Unlike previous approaches that use generic methods to detect similarity, Ganesh exploits the structure of relational database results to yield superior performance improvement.",
                "One faces at least three challenges in applying hash-based similarity detection to back-end databases.",
                "First, previous work in this space has traditionally viewed storage content as uninterpreted bags of bits with no internal structure.",
                "This allows hash-based techniques to operate on long, contiguous runs of data for maximum effectiveness.",
                "In contrast, relational databases have rich internal structure that may not be as amenable to hash-based similarity detection.",
                "Second, relational databases have very tight integrity and consistency constraints that must not be compromised by the use of hash-based techniques.",
                "Third, the source code of commercial databases is typically not available.",
                "This is in contrast to previous work which presumed availability of source code.",
                "Our experiments show that Ganesh, while conceptually simple, can improve performance significantly at bandwidths representative of todays commercial Internet.",
                "On benchmarks modeling multitiered web applications, the throughput improvement was as high as tenfold for data-intensive workloads.",
                "For workloads that were not data-intensive, throughput improvements of up to twofold were observed.",
                "Even when bandwidth was not a constraint, Ganesh had low overhead and did not hurt performance.",
                "Our experiments also confirm that exploiting the structure present in database results is crucial to this performance improvement. 2.",
                "BACKGROUND 2.1 Dynamic Content Generation As the World Wide Web has grown, many web sites have decentralized their data and functionality by pushing them to the edges of the Internet.",
                "Today, eBusiness systems often use a three-tiered architecture consisting of a front-end web server, an application server, and a back-end database server.",
                "Figure 1 illustrates this architecture.",
                "The first two tiers can be replicated close to a concentration of clients at the edge of the Internet.",
                "This improves user experience by lowering end-to-end latency and reducing exposure WWW 2007 / Track: Performance and Scalability Session: Scalable Systems for Dynamic Content 311 Back-End Database Server Front-End Web and Application Servers Figure 1: Multi-Tier Architecture to backbone traffic congestion.",
                "It can also increase the availability and scalability of web services.",
                "Content that is generated dynamically from the back-end database cannot be cached in the first two tiers.",
                "While databases can be easily replicated in a LAN, this is infeasible in a WAN because of the difficult task of simultaneously providing strong consistency, availability, and tolerance to network partitions [7].",
                "As a result, databases tend to be centralized to meet the strong consistency requirements of many eBusiness applications such as banking, finance, and online retailing [38].",
                "Thus, the back-end database is usually located far from many sets of first and second-tier nodes [2].",
                "In the absence of both caching and replication, WAN bandwidth can easily become a limiting factor in the performance and scalability of data-intensive applications. 2.2 Hash-Based Systems Ganeshs focus is on efficient transmission of results by discovering similarities with the results of previous queries.",
                "As SQL queries can generate large results, hash-based techniques lend themselves well to the problem of efficiently transferring these large results across bandwidth constrained links.",
                "The use of hash-based techniques to reduce the volume of data transmitted has emerged as a common theme of many recent storage systems, as discussed in Section 8.2.",
                "These techniques rely on some basic assumptions.",
                "Cryptographic hash functions are assumed to be collision-resistant.",
                "In other words, it is computationally intractable to find two inputs that hash to the same output.",
                "The functions are also assumed to be one-way; that is, finding an input that results in a specific output is computationally infeasible.",
                "Menezes et al. [23] provide more details about these assumptions.",
                "The above assumptions allow hash-based systems to assume that collisions do not occur.",
                "Hence, they are able to treat the hash of a data item as its unique identifier.",
                "A collection of data items effectively becomes content-addressable, allowing a small hash to serve as a codeword for a much larger data item in permanent storage or network transmission.",
                "The assumption that collisions are so rare as to be effectively non-existent has recently come under fire [17].",
                "However, as explained by Black [5], we believe that these issues do not form a concern for Ganesh.",
                "All communication is between trusted parts of the system and an adversary has no way to force Ganesh to accept invalid data.",
                "Further, Ganesh does not depend critically on any specific hash function.",
                "While we currently use SHA-1, replacing it with a different hash function would be simple.",
                "There would be no impact on performance as stronger hash functions (e.g.",
                "SHA256) only add a few extra bytes and the generated hashes are still orders of magnitude smaller than the data items they represent.",
                "No re-hashing of permanent storage is required since Ganesh only uses hashing on volatile data. 3.",
                "DESIGN AND IMPLEMENTATION Ganesh exploits redundancy in the result stream to avoid transmitting result fragments that are already present at the query site.",
                "Redundancy can arise naturally in many different ways.",
                "For example, a query repeated after a certain interval may return a different result because of updates to the database; however, there may be significant commonality between the two results.",
                "As another example, a user who is refining a search may generate a sequence of queries with overlapping results.",
                "When Ganesh detects redundancy, it suppresses transmission of the corresponding result fragments.",
                "Instead, it transmits a much smaller digest of those fragments and lets the query site reconstruct the result through hash lookup in a cache of previous results.",
                "In effect, Ganesh uses computation at the edges to reduce Internet communication.",
                "Our description of Ganesh focuses on four aspects.",
                "We first explain our approach to detecting similarity in query results.",
                "Next, we discuss how the Ganesh architecture is completely invisible to all components of a multi-tier system.",
                "We then describe Ganeshs proxy-based approach and the dataflow for detecting similarity. 3.1 Detecting Similarity One of the key design decisions in Ganesh is how similarity is detected.",
                "There are many potential ways to decompose a result into fragments.",
                "The optimal way is, of course, the one that results in the smallest possible object for transmission for a given querys results.",
                "Finding this optimal decomposition is a difficult problem because of the large space of possibilities and because the optimal choice depends on many factors such as the contents of the querys result, the history of recent results, and the cache management algorithm.",
                "When an object is opaque, the use of Rabin fingerprints [8, 30] to detect common data between two objects has been successfully shown in the past by systems such as LBFS [26] and CASPER [37].",
                "Rabin fingerprinting uses a sliding window over the data to compute a rolling hash.",
                "Assuming that the hash function is uniformly distributed, a chunk boundary is defined whenever the lower order bits of the hash value equal some predetermined value.",
                "The number of lower order bits used defines the average chunk size.",
                "These sub-divided chunks of the object become the unit of comparison for detecting similarity between different objects.",
                "As the locations of boundaries found by using Rabin fingerprints is stochastically determined, they usually fail to align with any structural properties of the underlying data.",
                "The algorithm therefore deals well with in-place updates, insertions and deletions.",
                "However, it performs poorly in the presence of any reordering of data.",
                "Figure 2 shows an example where two results, A and B, consisting of three rows, have the same data but have different sort attributes.",
                "In the extreme case, Rabin fingerprinting might be unable to find any similar data due to the way it detects chunk boundaries.",
                "Fortunately, Ganesh can use domain specific knowledge for more precise boundary detection.",
                "The information we exploit is that a querys result reflects the structure of a relational database where all data is organized as tables and rows.",
                "It is therefore simple to check for similarity with previous results at two granularities: first the entire result, and then individual rows.",
                "The end of a row in a result serves as a natural chunk boundary.",
                "It is important to note that using the tabular structure in results only involves shallow interpretation of the data.",
                "Ganesh does not perform any deeper semantic interpretation such as understanding data types, result schema, or integrity constraints.",
                "Tuning Rabin fingerprinting for a workload can also be difficult.",
                "If the average chunk size is too large, chunks can span multiple result rows.",
                "However, selecting a smaller average chunk size increases the amount of metadata required to the describe the results.",
                "WWW 2007 / Track: Performance and Scalability Session: Scalable Systems for Dynamic Content 312 Figure 2: Rabin Fingerprinting vs. Ganeshs Chunking This, in turn, would decrease the savings obtained via its use.",
                "Rabin fingerprinting also needs two computationally-expensive passes over the data: once to determine chunk boundaries and one again to generate cryptographic hashes for the chunks.",
                "Ganesh only needs a single pass for hash generation as the chunk boundaries are provided by the datas natural structure.",
                "The performance comparison in Section 6 shows that Ganeshs row-based algorithm outperforms Rabin fingerprinting.",
                "Given that previous work has already shown that Rabin fingerprinting performs better than gzip [26], we do not compare Ganesh to compression algorithms in this paper. 3.2 Transparency The key factor influencing our design was the need for Ganesh to be completely transparent to all components of a typical eBusiness system: web servers, application servers, and database servers.",
                "Without this, Ganesh stands little chance of having a significant real-world impact.",
                "Requiring modifications to any of the above components would raise the barrier for entry of Ganesh into an existing system, and thus reduce its chances of adoption.",
                "Preserving transparency is simplified by the fact that Ganesh is purely a performance enhancement, not a functionality or usability enhancement.",
                "We chose agent interposition as the architectural approach to realizing our goal.",
                "This approach relies on the existence of a compact programming interface that is already widely used by target software.",
                "It also relies on a mechanism to easily add new code without disrupting existing module structure.",
                "These conditions are easily met in our context because of the popularity of Java as the programming language for eBusiness systems.",
                "The Java Database Connectivity (JDBC) API [32] allows Java applications to access a wide variety of databases and even other tabular data repositories such as flat files.",
                "Access to these data sources is provided by JDBC drivers that translate between the JDBC API and the database communication mechanism.",
                "Figure 3(a) shows how JDBC is typically used in an application.",
                "As the JDBC interface is standardized, one can substitute one <br>jdbc driver</br> for another without application modifications.",
                "The <br>jdbc driver</br> thus becomes the natural module to exploit for code interposition.",
                "As shown in Figure 3(b), the native <br>jdbc driver</br> is replaced with a Ganesh <br>jdbc driver</br> that presents the same standardized interface.",
                "The Ganesh driver maintains an in-memory cache of result fragments from previous queries and performs reassembly of results.",
                "At the database, we add a new process called the Ganesh proxy.",
                "This proxy, which can be shared by multiple front-end nodes, consists of two parts: code to detect similarity in result fragments and the original native <br>jdbc driver</br> that communicates with the database.",
                "The use of a proxy at the database makes Ganesh database-agnostic and simplifies prototyping and experimentation.",
                "Ganesh is thus able to work with a wide range of databases and applications, requiring no modifications to either. 3.3 Proxy-Based Caching The native <br>jdbc driver</br> shown in Figure 3(a) is a lightweight code component supplied by the database vendor.",
                "Its main funcClient Database Web and Application Server Native <br>jdbc driver</br> WAN (a) Native Architecture Client Database Ganesh Proxy Native <br>jdbc driver</br> WAN Web and Application Server Ganesh JDBC Driver (b) Ganeshs Interposition-based Architecture Figure 3: Native vs. Ganesh Architecture tion is to mediate communication between the application and the remote database.",
                "It forwards queries, buffers entire results, and responds to application requests to view parts of results.",
                "The Ganesh <br>jdbc driver</br> shown in Figure 3(b) presents the application with an interface identical to that provided by the native driver.",
                "It provides the ability to reconstruct results from compact hash-based descriptions sent by the proxy.",
                "To perform this reconstruction, the driver maintains an in-memory cache of recentlyreceived results.",
                "This cache is only used as a source of result fragments in reconstructing results.",
                "No attempt is made by the Ganesh driver or proxy to track database updates.",
                "The lack of cache consistency does not hurt correctness as a description of the results is always fetched from the proxy - at worst, there will be no performance benefit from using Ganesh.",
                "Stale data will simply be paged out of the cache over time.",
                "The Ganesh proxy accesses the database via the native <br>jdbc driver</br>, which remains unchanged between Figures 3(a) and (b).",
                "The database is thus completely unaware of the existence of the proxy.",
                "The proxy does not examine any queries received from the Ganesh driver but passes them to the native driver.",
                "Instead, the proxy is responsible for inspecting database output received from the native driver, detecting similar results, and generating hash-based encodings of these results whenever enough similarity is found.",
                "While this architecture does not decrease the load on a database, as mentioned earlier in Section 2.1, it is much easier to replicate databases for scalability in a LAN than in a WAN.",
                "To generate a hash-based encoding, the proxy must be aware of what result fragments are available in the Ganesh drivers cache.",
                "One approach is to be optimistic, and to assume that all result fragments are available.",
                "This will result in the smallest possible initial transmission of a result.",
                "However, in cases where there is little overlap with previous results, the Ganesh driver will have to make many calls to the proxy during reconstruction to fetch missing result fragments.",
                "To avoid this situation, the proxy loosely tracks the state of the Ganesh drivers cache.",
                "Since both components are under our control, it is relatively simple to do this without resorting to gray-box techniques or explicit communication for maintaining cache coherence.",
                "Instead, the proxy simulates the Ganesh drivers cache management algorithm and uses this to maintain a list of hashes for which the Ganesh driver is likely to possess the result fragments.",
                "In case of mistracking, there will be no loss of correctness but there will be extra round-trip delays to fetch the missing fragments.",
                "If the client detects loss of synchronization with the proxy, it can ask the proxy to reset the state shared between them.",
                "Also note that the proxy does not need to keep the result fragments themselves, only their hashes.",
                "This allows the proxy to remain scalable even when it is shared by many front-end nodes.",
                "WWW 2007 / Track: Performance and Scalability Session: Scalable Systems for Dynamic Content 313 Object Output Stream Convert ResultSet Object Input Stream Convert ResultSet All Data Recipe ResultSet All Data ResultSet Network Ganesh Proxy Ganesh <br>jdbc driver</br> Result Set Recipe Result Set Yes Yes No No GaneshInputStream GaneshOutputStream Figure 4: Dataflow for Result Handling 3.4 Encoding and Decoding Results The Ganesh proxy receives database output as Java objects from the native <br>jdbc driver</br>.",
                "It examines this output to see if a Java object of type ResultSet is present.",
                "The JDBC interface uses this data type to store results of database queries.",
                "If a ResultSet object is found, it is shrunk as discussed below.",
                "All other Java objects are passed through unmodified.",
                "As discussed in Section 3.1, the proxy uses the row boundaries defined in the ResultSet to partition it into fragments consisting of single result rows.",
                "All ResultSet objects are converted into objects of a new type called RecipeResultSet.",
                "We use the term recipe for this compact description of a database result because of its similarity to a file recipe in the CASPER file system [37].",
                "The conversion replaces each result fragment that is likely to be present in the Ganesh drivers cache by a SHA-1 hash of that fragment.",
                "Previously unseen result fragments are retained verbatim.",
                "The proxy also retains hashes for the new result fragments as they will be present in the drivers cache in the future.",
                "Note that the proxy only caches hashes for result fragments and does not cache recipes.",
                "The proxy constructs a RecipeResultSet by checking for similarity at the entire result and then the row level.",
                "If the entire result is predicted to be present in the Ganesh drivers cache, the RecipeResultSet is simply a single hash of the entire result.",
                "Otherwise, it contains hashes for those rows predicted to be present in that cache; all other rows are retained verbatim.",
                "If the proxy estimates an overall space savings, it will transmit the RecipeResultSet.",
                "Otherwise the original ResultSet is transmitted.",
                "The RecipeResultSet objects are transformed back into ResultSet objects by the Ganesh driver.",
                "Figure 4 illustrates ResultSet handling at both ends.",
                "Each SHA-1 hash found in a RecipeResultSet is looked up in the local cache of result fragments.",
                "On a hit, the hash is replaced by the corresponding fragment.",
                "On a miss, the driver contacts the Ganesh proxy to fetch the fragment.",
                "All previously unseen result fragments that were retained verbatim by the proxy are hashed and added to the result cache.",
                "There should be very few misses if the proxy has accurately tracked the Ganesh drivers cache state.",
                "A future optimization would be to batch the fetch of missing fragments.",
                "This would be valuable when there are many small missing fragments in a high-latency WAN.",
                "Once the transformation is complete, the fully reconstructed ResultSet object is passed up to the application. 4.",
                "EXPERIMENTAL VALIDATION Three questions follow from the goals and design of Ganesh: • First, can performance can be improved significantly by exploiting similarity across database results?",
                "Benchmark Dataset Details 500,000 Users, 12,000 Stories BBOARD 2.0 GB 3,298,000 Comments AUCTION 1.3 GB 1,000,000 Users, 34,000 Items Table 1: Benchmark Dataset Details • Second, how important is Ganeshs structural similarity detection relative to Rabin fingerprintings similarity detection? • Third, is the overhead of the proxy-based design acceptable?",
                "Our evaluation answers these question through controlled experiments with the Ganesh prototype.",
                "This section describes the benchmarks used, our evaluation procedure, and the experimental setup.",
                "Results of the experiments are presented in Sections 5, 6, and 7. 4.1 Benchmarks Our evaluation is based on two benchmarks [18] that have been widely used by other researchers to evaluate various aspects of multi-tier [27] and eBusiness architectures [9].",
                "The first benchmark, BBOARD, is modeled after Slashdot, a technology-oriented news site.",
                "The second benchmark, AUCTION, is modeled after eBay, an online auction site.",
                "In both benchmarks, most content is dynamically generated from information stored in a database.",
                "Details of the datasets used can be found in Table 1. 4.1.1 The BBOARD Benchmark The BBOARD benchmark, also known as RUBBoS [18], models Slashdot, a popular technology-oriented web site.",
                "Slashdot aggregates links to news stories and other topics of interest found elsewhere on the web.",
                "The site also serves as a bulletin board by allowing users to comment on the posted stories in a threaded conversation form.",
                "It is not uncommon for a story to gather hundreds of comments in a matter of hours.",
                "The BBOARD benchmark is similar to the site and models the activities of a user, including readonly operations such as browsing the stories of the day, browsing story categories, and viewing comments as well as write operations such as new user registration, adding and moderating comments, and story submission.",
                "The benchmark consists of three different phases: a short warmup phase, a runtime phase representing the main body of the workload, and a short cool-down phase.",
                "In this paper we only report results from the runtime phase.",
                "The warm-up phase is important in establishing dynamic system state, but measurements from that phase are not significant for our evaluation.",
                "The cool-down phase is solely for allowing the benchmark to shut down.",
                "The warm-up, runtime, and cool-down phases are 2, 15, and 2 minutes respectively.",
                "The number of simulated clients were 400, 800, 1200, and 1600.",
                "The benchmark is available in a Java Servlets and PHP version and has different datasets; we evaluated Ganesh using the Java Servlets version and the Expanded dataset.",
                "The BBOARD benchmark defines two different workloads.",
                "The first, the Authoring mix, consists of 70% read-only operations and 30% read-write operations.",
                "The second, the Browsing mix, contains only read-only operations and does not update the database. 4.1.2 The AUCTION Benchmark The AUCTION benchmark, also known as RUBiS [18], models eBay, the online auction site.",
                "The eBay web site is used to buy and sell items via an auction format.",
                "The main activities of a user include browsing, selling, or bidding for items.",
                "Modeling the activities on this site, this benchmark includes read-only activities such as browsing items by category and by region, as well as read-write WWW 2007 / Track: Performance and Scalability Session: Scalable Systems for Dynamic Content 314 NetEm Router Ganesh Proxy Clients Web and Application Server Database Server Figure 5: Experimental Setup activities such as bidding for items, buying and selling items, and leaving feedback.",
                "As with BBOARD, the benchmark consists of three different phases.",
                "The warm-up, runtime, and cool-down phases for this experiment are 1.5, 15, and 1 minutes respectively.",
                "We tested Ganesh with four client configurations where the number of test clients was set to 400, 800, 1200, and 1600.",
                "The benchmark is available in a Enterprise Java Bean (EJB), Java Servlets, and PHP version and has different datasets; we evaluated Ganesh with the Java Servlets version and the Expanded dataset.",
                "The AUCTION benchmark defines two different workloads.",
                "The first, the Bidding mix, consists of 70% read-only operations and 30% read-write operations.",
                "The second, the Browsing mix, contains only read-only operations and does not update the database. 4.2 Experimental Procedure Both benchmarks involve a synthetic workload of clients accessing a web server.",
                "The number of clients emulated is an experimental parameter.",
                "Each emulated client runs an instance of the benchmark in its own thread, using a matrix to transition between different benchmark states.",
                "The matrix defines a stochastic model with probabilities of transitioning between the different states that represent typical user actions.",
                "An example transition is a user logging into the AUCTION system and then deciding on whether to post an item for sale or bid on active auctions.",
                "Each client also models user think time between requests.",
                "The think time is modeled as an exponential distribution with a mean of 7 seconds.",
                "We evaluate Ganesh along two axes: number of clients and WAN bandwidth.",
                "Higher loads are especially useful in understanding Ganeshs performance when the CPU or disk of the database server or proxy is the limiting factor.",
                "A previous study has shown that approximately 50% of the wide-area Internet bottlenecks observed had an available bandwidth under 10 Mb/s [1].",
                "Based on this work, we focus our evaluation on the WAN bandwidth of 5 Mb/s with 66 ms of round-trip latency, representative of severely constrained network paths, and 20 Mb/s with 33 ms of round-trip latency, representative of a moderately constrained network path.",
                "We also report Ganeshs performance at 100 Mb/s with no added round-trip latency.",
                "This bandwidth, representative of an unconstrained network, is especially useful in revealing any potential overhead of Ganesh in situations where WAN bandwidth is not the limiting factor.",
                "For each combination of number of clients and WAN bandwidth, we measured results from the two configurations listed below: • Native: This configuration corresponds to Figure 3(a).",
                "Native avoids Ganeshs overhead in using a proxy and performing Java object serialization. • Ganesh: This configuration corresponds to Figure 3(b).",
                "For a given number of clients and WAN bandwidth, comparing these results to the corresponding Native results gives the performance benefit due to the Ganesh middleware system.",
                "The metric used to quantify the improvement in throughput is the number of client requests that can be serviced per second.",
                "The metric used to quantify Ganeshs overhead is the average response time for a client request.",
                "For all of the experiments, the Ganesh driver used by the application server used a cache size of 100,000 items1 .",
                "The proxy was effective in tracking the Ganesh drivers cache state; for all of our experiments the miss rate on the driver never exceeded 0.7%. 4.3 Experimental Setup The experimental setup used for the benchmarks can be seen in Figure 5.",
                "All machines were 3.2 GHz Pentium 4s (with HyperThreading enabled.)",
                "With the exception of the database server, all machines had 2 GB of SDRAM and ran the Fedora Core Linux distribution.",
                "The database server had 4 GB of SDRAM.",
                "We used Apaches Tomcat as both the application server that hosted the Java Servlets and the web server.",
                "Both benchmarks used Java Servlets to generate the dynamic content.",
                "The database server used the open source MySQL database.",
                "For the native JDBC drivers, we used the Connector/J drivers provided by MySQL.",
                "The application server used Suns Java Virtual Machine as the runtime environment for the Java Servlets.",
                "The sysstat tool was used to monitor the CPU, network, disk, and memory utilization on all machines.",
                "The machines were connected by a switched gigabit Ethernet network.",
                "As shown in Figure 5, the front-end web and application server was separated from the proxy and database server by a NetEm router [16].",
                "This router allowed us to control the bandwidth and latency settings on the network.",
                "The NetEm router is a standard PC with two network cards running the Linux Traffic Control and Network Emulation software.",
                "The bandwidth and latency constraints were only applied to the link between the application server and the database for the native case and between the application server and the proxy for the Ganesh case.",
                "There is no communication between the application server and the database with Ganesh as all data flows through the proxy.",
                "As our focus was on the WAN link between the application server and the database, there were no constraints on the link between the simulated test clients and the web server. 5.",
                "THROUGHPUT AND RESPONSE TIME In this section, we address the first question raised in Section 4: Can performance can be improved significantly by exploiting similarity across database results?",
                "To answer this question, we use results from the BBOARD and AUCTION benchmarks.",
                "We use two metrics to quantify the performance improvement obtainable through the use of Ganesh: throughput, from the perspective of the web server, and average response time, from the perspective of the client.",
                "Throughput is measured in terms of the number of client requests that can be serviced per second. 5.1 BBOARD Results and Analysis 5.1.1 Authoring Mix Figures 6 (a) and (b) present the average number of requests serviced per second and the average response time for these requests as perceived by the clients for BBOARDs Authoring Mix.",
                "As Figure 6 (a) shows, Native easily saturates the 5 Mb/s link.",
                "At 400 clients, the Native solution delivers 29 requests/sec with an average response time of 8.3 seconds.",
                "Natives throughput drops with an increase in test clients as clients timeout due to congestion at the application server.",
                "Usability studies have shown that response times above 10 seconds cause the user to move on to 1 As Java lacks a sizeof() operator, Java caches therefore limit their size based on the number of objects.",
                "The size of cache dumps taken at the end of the experiments never exceeded 212 MB.",
                "WWW 2007 / Track: Performance and Scalability Session: Scalable Systems for Dynamic Content 315 0 50 100 150 200 250 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Test Clients Requests/sec Native Ganesh 0.001 0.01 0.1 1 10 100 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Test Clients Avg.Resp.Time(sec) Native Ganesh Note Logscale (a) Throughput: Authoring Mix (b) Response Time: Authoring Mix 0 50 100 150 200 250 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Test Clients Requests/sec Native Ganesh 0.001 0.01 0.1 1 10 100 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Test Clients Avg.Resp.Time(sec) Native Ganesh Note Logscale (c) Throughput: Browsing Mix (d) Response Time: Browsing Mix Mean of three trials.",
                "The maximum standard deviation for throughput and response time was 9.8% and 11.9% of the corresponding mean.",
                "Figure 6: BBOARD Benchmark - Throughput and Average Response Time other tasks [24].",
                "Based on these numbers, increasing the number of test clients makes the Native system unusable.",
                "Ganesh at 5 Mb/s, however, delivers a twofold improvement with 400 test clients and a fivefold improvement at 1200 clients.",
                "Ganeshs performance drops slightly at 1200 and 1600 clients as the network is saturated.",
                "Compared to Native, Figure 6 (b) shows that Ganeshs response times are substantially lower with sub-second response times at 400 clients.",
                "Figure 6 (a) also shows that for 400 and 800 test clients Ganesh at 5 Mb/s has the same throughput and average response time as Native at 20 Mb/s.",
                "Only at 1200 and 1600 clients does Native at 20 Mb/s deliver higher throughput than Ganesh at 5 Mb/s.",
                "Comparing both Ganesh and Native at 20 Mb/s, we see that Ganesh is no longer bandwidth constrained and delivers up to a twofold improvement over Native at 1600 test clients.",
                "As Ganesh does not saturate the network with higher test client configurations, at 1600 test clients, its average response time is 0.1 seconds rather than Natives 7.7 seconds.",
                "As expected, there are no visible gains from Ganesh at the higher bandwidth of 100 Mb/s where the network is no longer the bottleneck.",
                "Ganesh, however, still tracks Native in terms of throughput. 5.1.2 Browsing Mix Figures 6 (c) and (d) present the average number of requests serviced per second and the average response time for these requests as perceived by the clients for BBOARDs Browsing Mix.",
                "Regardless of the test client configuration, Figure 6 (c) shows that Natives throughput at 5 Mb/s is limited to 10 reqs/sec.",
                "Ganesh at 5 Mb/s with 400 test clients, delivers more than a sixfold increase in throughput.",
                "The improvement increases to over a elevenfold increase at 800 test clients before Ganesh saturates the network.",
                "Further, Figure 6 (d) shows that Natives average response time of 35 seconds at 400 test clients make the system unusable.",
                "These high response times further increase with the addition of test clients.",
                "Even with the 1600 test client configuration Ganesh delivers an acceptable average response time of 8.2 seconds.",
                "Due to the data-intensive nature of the Browsing mix, Ganesh at 5 Mb/s surprisingly performs much better than Native at 20 Mb/s.",
                "Further, as shown in Figure 6 (d), while the average response time for Native at 20 Mb/s is acceptable at 400 test clients, it is unusable with 800 test clients with an average response time of 15.8 seconds.",
                "Like the 5 Mb/s case, this response time increases with the addition of extra test clients.",
                "Ganesh at 20 Mb/s and both Native and Ganesh at 100 Mb/s are not bandwidth limited.",
                "However, performance plateaus out after 1200 test clients due to the database CPU being saturated. 5.1.3 Filter Variant We were surprised by the Native performance from the BBOARD benchmark.",
                "At the bandwidth of 5 Mb/s, Native performance was lower than what we had expected.",
                "It turned out the benchmark code that displays stories read all the comments associated with the particular story from the database and only then did some postprocessing to select the comments to be displayed.",
                "While this is exactly the behavior of SlashCode, the code base behind the Slashdot web site, we decided to modify the benchmark to perform some pre-filtering at the database.",
                "This modified benchmark, named the Filter Variant, models a developer who applies optimizations at the SQL level to transfer less data.",
                "In the interests of brevity, we only briefly summarize the results from the Authoring mix.",
                "For the Authoring mix, at 800 test clients at 5 Mb/s, Figure 7 (a) shows that Natives throughput increase by 85% when compared to the original benchmark while Ganeshs improvement is smaller at 15%.",
                "Natives performance drops above 800 clients as the test clients time out due to high response times.",
                "The most significant gain for Native is seen at 20 Mb/s.",
                "At 1600 test clients, when compared to the original benchmark, Native sees a 73% improvement in throughput and a 77% reduction in average response time.",
                "While WWW 2007 / Track: Performance and Scalability Session: Scalable Systems for Dynamic Content 316 0 50 100 150 200 250 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Test Clients Requests/sec Native Ganesh 0.001 0.01 0.1 1 10 100 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Test Clients Avg.Resp.Time(sec) Native Ganesh Note Logscale (a) Throughput: Authoring Mix (b) Response Time: Authoring Mix Mean of three trials.",
                "The maximum standard deviation for throughput and response time was 7.2% and 11.5% of the corresponding mean.",
                "Figure 7: BBOARD Benchmark - Filter Variant - Throughput and Average Response Time Ganesh sees no improvement when compared to the original, it still processes 19% more requests/sec than Native.",
                "Thus, while the optimizations were more helpful to Native, Ganesh still delivers an improvement in performance. 5.2 AUCTION Results and Analysis 5.2.1 Bidding Mix Figures 8 (a) and (b) present the average number of requests serviced per second and the average response time for these requests as perceived by the clients for AUCTIONs Bidding Mix.",
                "As mentioned earlier, the Bidding mix consists of a mixture of read and write operations.",
                "The AUCTION benchmark is not as data intensive as BBOARD.",
                "Therefore, most of the gains are observed at the lower bandwidth of 5 Mb/s.",
                "Figure 8 (a) shows that the increase in throughput due to Ganesh ranges from 8% at 400 test clients to 18% with 1600 test clients.",
                "As seen in Figure 8 (b), the average response times for Ganesh are significantly lower than Native ranging from a decrease of 84% at 800 test clients to 88% at 1600 test clients.",
                "Figure 8 (a) also shows that with a fourfold increase of bandwidth from 5 Mb/s to 20 Mb/s, Native is no longer bandwidth constrained and there is no performance difference between Ganesh and Native.",
                "With the higher test client configurations, we did observe that the bandwidth used by Ganesh was lower than Native.",
                "Ganesh might still be useful in these non-constrained scenarios if bandwidth is purchased on a metered basis.",
                "Similar results are seen for the 100 Mb/s scenario. 5.2.2 Browsing Mix For AUCTIONs Browsing Mix, Figures 8 (c) and (d) present the average number of requests serviced per second and the average response time for these requests as perceived by the clients.",
                "Again, most of the gains are observed at lower bandwidths.",
                "At 5 Mb/s, Native and Ganesh deliver similar throughput and response times with 400 test clients.",
                "While the throughput for both remains the same at 800 test clients, Figure 8 (d) shows that Ganeshs average response time is 62% lower than Native.",
                "Native saturates the link at 800 clients and adding extra test clients only increases the average response time.",
                "Ganesh, regardless of the test client configuration, is not bandwidth constrained and maintains the same response time.",
                "At 1600 test clients, Figure 8 (c) shows that Ganeshs throughput is almost twice that of Native.",
                "At the higher bandwidths of 20 and 100 Mb/s, neither Ganesh nor Native is bandwidth limited and deliver equivalent throughput and response times.",
                "Benchmark Orig.",
                "Size Ganesh Size Rabin Size SelectSort1 223.6 MB 5.4 MB 219.3 MB SelectSort2 223.6 MB 5.4 MB 223.6 MB Table 2: Similarity Microbenchmarks 6.",
                "STRUCTURAL VS. RABIN SIMILARITY In this section, we address the second question raised in Section 4: How important is Ganeshs structural similarity detection relative to Rabin fingerprinting-based similarity detecting?",
                "To answer this question, we used microbenchmarks and the BBOARD and AUCTION benchmarks.",
                "As Ganesh always performed better than Rabin fingerprinting, we only present a subset of the results here in the interests of brevity. 6.1 Microbenchmarks Two microbenchmarks show an example of the effects of data reordering on Rabin fingerprinting algorithm.",
                "In the first microbenchmark, SelectSort1, a query with a specified sort order selects 223.6 MB of data spread over approximately 280 K rows.",
                "The query is then repeated with a different sort attribute.",
                "While the same number of rows and the same data is returned, the order of rows is different.",
                "In such a scenario, one would expect a large amount of similarity to be detected between both results.",
                "As Table 2 shows, Ganeshs row-based algorithm achieves a 97.6% reduction while the Rabin fingerprinting algorithm, with the average chunk size parameter set to 4 KB, only achieves a 1% reduction.",
                "The reason, as shown earlier in Figure 2, is that with Rabin fingerprinting, the spans of data between two consecutive boundaries usually cross row boundaries.",
                "With the order of the rows changing in the second result and the Rabin fingerprints now spanning different rows, the algorithm is unable to detect significant similarity.",
                "The small gain seen is mostly for those single rows that are large enough to be broken into multiple chunks.",
                "SelectSort2, another micro-benchmark executed the same queries but increased the minimum chunk size of the Rabin fingerprinting algorithm.",
                "As can be seen in Table 2, even the small gain from the previous microbenchmark disappears as the minimum chunk size was greater than the average row size.",
                "While one can partially address these problems by dynamically varying the parameters of the Rabin fingerprinting algorithm, this can be computationally expensive, especially in the presence of changing workloads. 6.2 Application Benchmarks We ran the BBOARD benchmark described in Section 4.1.1 on two versions of Ganesh: the first with Rabin fingerprinting used as WWW 2007 / Track: Performance and Scalability Session: Scalable Systems for Dynamic Content 317 0 50 100 150 200 250 300 350 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Test Clients Requests/sec Native Ganesh 0.001 0.01 0.1 1 10 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Test Clients Avg.Resp.Time(sec) Native Ganesh Note Logscale (a) Throughput: Bidding Mix (b) Response Time: Bidding Mix 0 50 100 150 200 250 300 350 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Test Clients Requests/sec Native Ganesh 0.001 0.01 0.1 1 10 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Test Clients Avg.Resp.Time(sec) Native Ganesh Note Logscale (c) Throughput: Browsing Mix (d) Response Time: Browsing Mix Mean of three trials.",
                "The maximum standard deviation for throughput and response time was 2.2% and 11.8% of the corresponding mean.",
                "Figure 8: AUCTION Benchmark - Throughput and Average Response Time the chunking algorithm and the second with Ganeshs row-based algorithm.",
                "Rabins results for the Browsing Mix are normalized to Ganeshs results and presented in Figure 9.",
                "As Figure 9 (a) shows, at 5 Mb/s, independent of the test client configuration, Rabin significantly underperforms Ganesh.",
                "This happens because of a combination of two reasons.",
                "First, as outlined in Section 3.1, Rabin finds less similarity as it does not exploit the results structural information.",
                "Second, this benchmark contained some queries that generated large results.",
                "In this case, Rabin, with a small average chunk size, generated a large number of objects that evicted other useful data from the cache.",
                "In contrast, Ganesh was able to detect these large rows and correspondingly increase the size of the chunks.",
                "This was confirmed as cache statistics showed that Ganeshs hit ratio was roughly three time that of Rabin.",
                "Throughput measurements at 20 Mb/s were similar with the exception of Rabins performance with 400 test clients.",
                "In this case, Ganesh was not network limited and, in fact, the throughput was the same as 400 clients at 5 Mb/s.",
                "Rabin, however, took advantage of the bandwidth increase from 5 to 20 Mb/s to deliver a slightly better performance.",
                "At 100 Mb/s, Rabins throughput was almost similar to Ganesh as bandwidth was no longer a bottleneck.",
                "The normalized response time, presented in Figure 9 (b), shows similar trends.",
                "At 5 and 20 Mb/s, the addition of test clients decreases the normalized response time as Ganeshs average response time increases faster than Rabins.",
                "However, at no point does Rabin outperform Ganesh.",
                "Note that at 400 and 800 clients at 100 Mb/s, Rabin does have a higher overhead even when it is not bandwidth constrained.",
                "As mentioned in Section 3.1, this is due to the fact that Rabin has to hash each ResultSet twice.",
                "The overhead disappears with 1200 and 1600 clients as the database CPU is saturated and limits the performance of both Ganesh and Rabin. 7.",
                "PROXY OVERHEAD In this section, we address the third question raised in Section 4: Is the overhead of Ganeshs proxy-based design acceptable?",
                "To answer this question, we concentrate on its performance at the higher bandwidths.",
                "Our evaluation in Section 5 showed that Ganesh, when compared to Native, can deliver a substantial throughput improvement at lower bandwidths.",
                "It is only at higher bandwidths that latency, measured by the average response time for a client request, and throughput, measured by the number of client requests that can be serviced per second, overheads would be visible.",
                "Looking at the Authoring mix of the original BBOARD benchmark, there are no visible gains from Ganesh at 100 Mb/s.",
                "Ganesh, however, still tracks Native in terms of throughput.",
                "While the average response time is higher for Ganesh, the absolute difference is in between 0.01 and 0.04 seconds and would be imperceptible to the end-user.",
                "The Browsing mix shows an even smaller difference in average response times.",
                "The results from the filter variant of the BBOARD benchmarks are similar.",
                "Even for the AUCTION benchmark, the difference between Native and Ganeshs response time at 100 Mb/s was never greater than 0.02 seconds.",
                "The only exception to the above results was seen in the filter variant of the BBOARD benchmark where Ganesh at 1600 test clients added 0.85 seconds to the average response time.",
                "Thus, even for much faster networks where the WAN link is not the bottleneck, Ganesh always delivers throughput equivalent to Native.",
                "While some extra latency is added by the proxy-based design, it is usually imperceptible. 8.",
                "RELATED WORK To the best of our knowledge, Ganesh is the first system that combines the use of hash-based techniques with caching of database results to improve throughput and response times for applications with dynamic content.",
                "We also believe that it is also the first system to demonstrate the benefits of using structural information for WWW 2007 / Track: Performance and Scalability Session: Scalable Systems for Dynamic Content 318 0.0 0.2 0.4 0.6 0.8 1.0 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Test Clients Norm.Throughput 31.8 3.8 2.8 2.3 23.8 32.8 5.8 3.6 1.8 2.1 1.1 1.0 0 5 10 15 20 25 30 35 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Test Clients Norm.ResponseTime (a) Normalized Throughput: Higher is better (b) Normalized Response Time: Higher is worse For throughput, a normalized result greater than 1 implies that Rabin is better, For response time, a normalized result greater than 1 implies that Ganesh is better.",
                "Mean of three trials.",
                "The maximum standard deviation for throughput and response time was 9.1% and 13.9% of the corresponding mean.",
                "Figure 9: Normalized Comparison of Ganesh vs. Rabin - BBOARD Browsing Mix detecting similarity.",
                "In this section, we first discuss alternative approaches to caching dynamic content and then examine other uses of hash-based primitives in distributed systems. 8.1 Caching Dynamic Content At the database layer, a number of systems have advocated middletier caching where parts of the database are replicated at the edge or server [3, 4, 20].",
                "These systems either cache entire tables in what is essentially a replicated database or use materialized views from previous query replies [19].",
                "They require tight integration with the back-end database to ensure a time bound on the propagation of updates.",
                "These systems are also usually targeted towards workloads that do not require strict consistency and can tolerate stale data.",
                "Further, unlike Ganesh, some of these mid-tier caching solutions [2, 3], suffer from the complexity of having to participate in query planing and distributed query processing.",
                "Gao et al. [15] propose using a distributed object replication architecture where the data stores consistency requirements are adapted on a per-application basis.",
                "These solutions require substantial developer resources and detailed understanding of the application being modified.",
                "While systems that attempt to automate the partitioning and replication of an applications database exist [34], they do not provide full transaction semantics.",
                "In comparison, Ganesh does not weaken any of the semantics provided by the underlying database.",
                "Recent work in the evaluation of edge caching options for dynamic web sites [38] has suggested that, without careful planning, employing complex offloading strategies can hurt performance.",
                "Instead, the work advocates for an architecture in which all tiers except the database should be offloaded to the edge.",
                "Our evaluation of Ganesh has shown that it would benefit these scenarios.",
                "To improve database scalability, C-JDBC [10], SSS [22], and Ganymed [28] also advocate the use of an interposition-based architecture to transparently cluster and replicate databases at the middleware level.",
                "The approaches of these architectures and Ganesh are complementary and they would benefit each other.",
                "Moving up to the presentation layer, there has been widespread adoption of fragment-based caching [14], which improves cache utilization by separately caching different parts of generated web pages.",
                "While fragment-based caching works at the edge, a recent proposal has proposed moving web page assembly to the clients to optimize content delivery [31].",
                "While Ganesh is not used at the presentation layer, the same principles have been applied in Duplicate Transfer Detection [25] to increase web cache efficiency as well as for web access across bandwidth limited links [33]. 8.2 Hash-based Systems The past few years have seen the emergence of many systems that exploit hash-based techniques.",
                "At the heart of all these systems is the idea of detecting similarity in data without requiring interpretation of that data.",
                "This simple yet elegant idea relies on cryptographic hashing, as discussed earlier in Section 2.",
                "Successful applications of this idea span a wide range of storage systems.",
                "Examples include peer-to-peer backup of personal computing files [11], storage-efficient archiving of data [29], and finding similar files [21].",
                "Spring and Wetherall [35] apply similar principles at the network level.",
                "Using synchronized caches at both ends of a network link, duplicated data is replaced by smaller tokens for transmission and then restored at the remote end.",
                "This and other hash-based systems such as the CASPER [37] and LBFS [26] filesystems, and Layer-2 bandwidth optimizers such as Riverbed and Peribit use Rabin fingerprinting [30] to discover spans of commonality in data.",
                "This approach is especially useful when data items are modified in-place through insertions, deletions, and updates.",
                "However, as Section 6 shows, the performance of this technique can show a dramatic drop in the presence of data reordering.",
                "Ganesh instead uses row boundaries as dividers for detecting similarity.",
                "The most aggressive use of hash-based techniques is by systems that use hashes as the primary identifiers for objects in persistent storage.",
                "Storage systems such as CFS [12] and PAST [13] that have been built using distributed hash tables fall into this category.",
                "Single Instance Storage [6] and Venti [29] are other examples of such systems.",
                "As discussed in Section 2.2, the use of cryptographic hashes for addressing persistent data represents a deeper level of faith in their collision-resistance than that assumed by Ganesh.",
                "If time reveals shortcomings in the hash algorithm, the effort involved in correcting the flaw is much greater.",
                "In Ganesh, it is merely a matter of replacing the hash algorithm. 9.",
                "CONCLUSION The growing use of dynamic web content generated from relational databases places increased demands on WAN bandwidth.",
                "Traditional caching solutions for bandwidth and latency reduction are often ineffective for such content.",
                "This paper shows that the impact of WAN accesses to databases can be substantially reduced through the Ganesh architecture without any compromise of the databases strict consistency semantics.",
                "The essence of the Ganesh architecture is the use of computation at the edges to reduce communication through the Internet.",
                "Ganesh is able to use cryptographic hashes to detect similarity with previous results and send WWW 2007 / Track: Performance and Scalability Session: Scalable Systems for Dynamic Content 319 compact recipes of results rather than full results.",
                "Our design uses interposition to achieve complete transparency: clients, application servers, and database servers are all unaware of Ganeshs presence and require no modification.",
                "Our experimental evaluation confirms that Ganesh, while conceptually simple, can be highly effective in improving throughput and response time.",
                "Our results also confirm that exploiting the structure present in database results to detect similarity is crucial to this performance improvement. 10.",
                "REFERENCES [1] AKELLA, A., SESHAN, S., AND SHAIKH, A.",
                "An empirical evaluation of wide-area internet bottlenecks.",
                "In Proc. 3rd ACM SIGCOMM Conference on Internet Measurement (Miami Beach, FL, USA, Oct. 2003), pp. 101-114. [2] ALTINEL, M., BORNH ¨OVD, C., KRISHNAMURTHY, S., MOHAN, C., PIRAHESH, H., AND REINWALD, B. Cache tables: Paving the way for an adaptive database cache.",
                "In Proc. of 29th VLDB (Berlin, Germany, 2003), pp. 718-729. [3] ALTINEL, M., LUO, Q., KRISHNAMURTHY, S., MOHAN, C., PIRAHESH, H., LINDSAY, B. G., WOO, H., AND BROWN, L. Dbcache: Database caching for web application servers.",
                "In Proc. 2002 ACM SIGMOD (2002), pp. 612-612. [4] AMIRI, K., PARK, S., TEWARI, R., AND PADMANABHAN, S. Dbproxy: A dynamic data cache for web applications.",
                "In Proc.",
                "IEEE International Conference on Data Engineering (ICDE) (Mar. 2003). [5] BLACK, J. Compare-by-hash: A reasoned analysis.",
                "In Proc. 2006 USENIX Annual Technical Conference (Boston, MA, May 2006), pp. 85-90. [6] BOLOSKY, W. J., CORBIN, S., GOEBEL, D., , AND DOUCEUR, J. R. Single instance storage in windows 2000.",
                "In Proc. 4th USENIX Windows Systems Symposium (Seattle, WA, Aug. 2000), pp. 13-24. [7] BREWER, E. A.",
                "Lessons from giant-scale services.",
                "IEEE Internet Computing 5, 4 (2001), 46-55. [8] BRODER, A., GLASSMAN, S., MANASSE, M., AND ZWEIG, G. Syntactic clustering of the web.",
                "In Proc. 6th International WWW Conference (1997). [9] CECCHET, E., CHANDA, A., ELNIKETY, S., MARGUERITE, J., AND ZWAENEPOEL, W. Performance comparison of middleware architectures for generating dynamic web content.",
                "In Proc.",
                "Fourth ACM/IFIP/USENIX International Middleware Conference (Rio de Janeiro, Brazil, June 2003). [10] CECCHET, E., MARGUERITE, J., AND ZWAENEPOEL, W. C-JDBC: Flexible database clustering middleware.",
                "In Proc. 2004 USENIX Annual Technical Conference (Boston, MA, June 2004). [11] COX, L. P., MURRAY, C. D., AND NOBLE, B. D. Pastiche: Making backup cheap and easy.",
                "In OSDI: Symposium on Operating Systems Design and Implementation (2002). [12] DABEK, F., KAASHOEK, M. F., KARGER, D., MORRIS, R., AND STOICA, I. Wide-area cooperative storage with CFS.",
                "In 18th ACM Symposium on Operating Systems Principles (Banff, Canada, Oct. 2001). [13] DRUSCHEL, P., AND ROWSTRON, A.",
                "PAST: A large-scale, persistent peer-to-peer storage utility.",
                "In HotOS VIII (Schloss Elmau, Germany, May 2001), pp. 75-80. [14] Edge side includes. http://www.esi.org. [15] GAO, L., DAHLIN, M., NAYATE, A., ZHENG, J., AND IYENGAR, A.",
                "Application specific data replication for edge services.",
                "In WWW 03: Proc.",
                "Twelfth International Conference on World Wide Web (2003), pp. 449-460. [16] HEMMINGER, S. Netem - emulating real networks in the lab.",
                "In Proc. 2005 Linux Conference Australia (Canberra, Australia, Apr. 2005). [17] HENSON, V. An analysis of compare-by-hash.",
                "In Proc. 9th Workshop on Hot Topics in Operating Systems (HotOS IX) (May 2003), pp. 13-18. [18] Jmob benchmarks. http://jmob.objectweb.org/. [19] LABRINIDIS, A., AND ROUSSOPOULOS, N. Balancing performance and data freshness in web database servers.",
                "In Proc. 29th VLDB Conference (Sept. 2003). [20] LARSON, P.-A., GOLDSTEIN, J., AND ZHOU, J. Transparent mid-tier database caching in sql server.",
                "In Proc. 2003 ACM SIGMOD (2003), pp. 661-661. [21] MANBER, U.",
                "Finding similar files in a large file system.",
                "In Proc.",
                "USENIX Winter 1994 Technical Conference (San Fransisco, CA, 17-21 1994), pp. 1-10. [22] MANJHI, A., AILAMAKI, A., MAGGS, B. M., MOWRY, T. C., OLSTON, C., AND TOMASIC, A.",
                "Simultaneous scalability and security for data-intensive web applications.",
                "In Proc. 2006 ACM SIGMOD (June 2006), pp. 241-252. [23] MENEZES, A. J., VANSTONE, S. A., AND OORSCHOT, P. C. V. Handbook of Applied Cryptography.",
                "CRC Press, 1996. [24] MILLER, R. B.",
                "Response time in man-computer conversational transactions.",
                "In Proc.",
                "AFIPS Fall Joint Computer Conference (1968), pp. 267-277. [25] MOGUL, J. C., CHAN, Y. M., AND KELLY, T. Design, implementation, and evaluation of duplicate transfer detection in http.",
                "In Proc.",
                "First Symposium on Networked Systems Design and Implementation (San Francisco, CA, Mar. 2004). [26] MUTHITACHAROEN, A., CHEN, B., AND MAZIERES, D. A low-bandwidth network file system.",
                "In Proc. 18th ACM Symposium on Operating Systems Principles (Banff, Canada, Oct. 2001). [27] PFEIFER, D., AND JAKSCHITSCH, H. Method-based caching in multi-tiered server applications.",
                "In Proc.",
                "Fifth International Symposium on Distributed Objects and Applications (Catania, Sicily, Italy, Nov. 2003). [28] PLATTNER, C., AND ALONSO, G. Ganymed: Scalable replication for transactional web applications.",
                "In Proc. 5th ACM/IFIP/USENIX International Conference on Middleware (2004), pp. 155-174. [29] QUINLAN, S., AND DORWARD, S. Venti: A new approach to archival storage.",
                "In Proc.",
                "FAST 2002 Conference on File and Storage Technologies (2002). [30] RABIN, M. Fingerprinting by random polynomials.",
                "In Harvard University Center for Research in Computing Technology Technical Report TR-15-81 (1981). [31] RABINOVICH, M., XIAO, Z., DOUGLIS, F., AND KALMANEK, C. Moving edge side includes to the real edge - the clients.",
                "In Proc. 4th USENIX Symposium on Internet Technologies and Systems (Seattle, WA, Mar. 2003). [32] REESE, G. Database Programming with JDBC and Java, 1st ed.",
                "OReilly, June 1997. [33] RHEA, S., LIANG, K., AND BREWER, E. Value-based web caching.",
                "In Proc.",
                "Twelfth International World Wide Web Conference (May 2003). [34] SIVASUBRAMANIAN, S., ALONSO, G., PIERRE, G., AND VAN STEEN, M. Globedb: Autonomic data replication for web applications.",
                "In WWW 05: Proc. 14th International World-Wide Web conference (May 2005). [35] SPRING, N. T., AND WETHERALL, D. A protocol-independent technique for eliminating redundant network traffic.",
                "In Proc. of ACM SIGCOMM (Aug. 2000). [36] TOLIA, N., HARKES, J., KOZUCH, M., AND SATYANARAYANAN, M. Integrating portable and distributed storage.",
                "In Proc. 3rd USENIX Conference on File and Storage Technologies (San Francisco, CA, Mar. 2004). [37] TOLIA, N., KOZUCH, M., SATYANARAYANAN, M., KARP, B., PERRIG, A., AND BRESSOUD, T. Opportunistic use of content addressable storage for distributed file systems.",
                "In Proc. 2003 USENIX Annual Technical Conference (San Antonio, TX, June 2003), pp. 127-140. [38] YUAN, C., CHEN, Y., AND ZHANG, Z.",
                "Evaluation of edge caching/offloading for dynamic content delivery.",
                "In WWW 03: Proc.",
                "Twelfth International Conference on World Wide Web (2003), pp. 461-471.",
                "WWW 2007 / Track: Performance and Scalability Session: Scalable Systems for Dynamic Content 320"
            ],
            "original_annotated_samples": [
                "As the JDBC interface is standardized, one can substitute one <br>jdbc driver</br> for another without application modifications.",
                "The <br>jdbc driver</br> thus becomes the natural module to exploit for code interposition.",
                "As shown in Figure 3(b), the native <br>jdbc driver</br> is replaced with a Ganesh <br>jdbc driver</br> that presents the same standardized interface.",
                "This proxy, which can be shared by multiple front-end nodes, consists of two parts: code to detect similarity in result fragments and the original native <br>jdbc driver</br> that communicates with the database.",
                "Ganesh is thus able to work with a wide range of databases and applications, requiring no modifications to either. 3.3 Proxy-Based Caching The native <br>jdbc driver</br> shown in Figure 3(a) is a lightweight code component supplied by the database vendor."
            ],
            "translated_annotated_samples": [
                "Dado que la interfaz JDBC está estandarizada, se puede sustituir un <br>controlador JDBC</br> por otro sin necesidad de de modificar la aplicación.",
                "El <br>controlador JDBC</br> se convierte así en el módulo natural para aprovechar la interposición de código.",
                "Como se muestra en la Figura 3(b), el controlador JDBC nativo es reemplazado por un controlador JDBC Ganesh que presenta la misma interfaz estandarizada.",
                "Este proxy, que puede ser compartido por múltiples nodos front-end, consta de dos partes: código para detectar similitud en fragmentos de resultados y el <br>controlador JDBC</br> nativo original que se comunica con la base de datos.",
                "Ganesh es capaz de trabajar con una amplia gama de bases de datos y aplicaciones, sin necesidad de realizar modificaciones en ninguna de ellas. 3.3 Caché basada en proxy El <br>controlador JDBC</br> nativo mostrado en la Figura 3(a) es un componente de código ligero suministrado por el proveedor de la base de datos."
            ],
            "translated_text": "Conservación de la consistencia en el almacenamiento en caché de contenido dinámico de bases de datos∗ Niraj Tolia y M. Satyanarayanan Universidad Carnegie Mellon {ntolia,satya}@cs.cmu.edu RESUMEN Con el creciente uso de contenido web dinámico generado a partir de bases de datos relacionales, las soluciones de almacenamiento en caché tradicionales para mejorar el rendimiento y la latencia son ineficaces. Describimos una capa de middleware llamada Ganesh que reduce el volumen de datos transmitidos sin interpretación semántica de consultas o resultados. Se logra esta reducción mediante el uso de hash criptográficos para detectar similitudes con resultados anteriores. Estos beneficios no requieren ningún compromiso con la semántica de consistencia estricta proporcionada por la base de datos del servidor. Además, Ganesh no requiere modificaciones en aplicaciones, servidores web o servidores de bases de datos, y funciona con aplicaciones y bases de datos de código cerrado. Usando dos puntos de referencia representativos de sitios web dinámicos, las mediciones de nuestro prototipo muestran que puede aumentar el rendimiento de extremo a extremo hasta en un factor de dos para aplicaciones no intensivas en datos y hasta en un factor de diez para las intensivas en datos. Categorías y Descriptores de Asignaturas C.2.4 [Redes de Computadoras-Comunicación]: Sistemas Distribuidos; H.2.4 [Gestión de Bases de Datos]: Términos Generales de Sistemas de Diseño, Rendimiento 1. INTRODUCCIÓN Una fracción creciente del contenido web se genera dinámicamente a partir de bases de datos relacionales en el backend. Incluso cuando el contenido de la base de datos permanece sin cambios, la localidad temporal de acceso no puede ser explotada porque el contenido dinámico no es almacenable en caché por los navegadores web o por servidores de almacenamiento en caché intermedios como los espejos de Akamai. En una arquitectura multinivel, cada solicitud web puede tensionar el enlace WAN entre el servidor web y la base de datos. Esto provoca que la experiencia del usuario sea altamente variable porque no hay almacenamiento en caché para aislar al cliente de cargas repentinas. Los intentos previos de almacenar en caché contenido dinámico de bases de datos generalmente han debilitado la semántica transaccional [3, 4] o han requerido modificaciones en la aplicación [15, 34]. Informamos sobre una nueva solución que toma la forma de una capa intermedia de middleware independiente de la base de datos llamada Ganesh. Ganesh no hace ningún esfuerzo por interpretar semánticamente el contenido de las consultas o sus resultados. En cambio, se basa exclusivamente en el hash criptográfico para detectar similitudes con resultados anteriores. La detección de similitud basada en hash ha sido cada vez más utilizada en sistemas de archivos distribuidos [26, 36, 37] para mejorar el rendimiento en redes de baja capacidad de ancho de banda. Sin embargo, estas técnicas no se han utilizado para bases de datos relacionales. A diferencia de enfoques anteriores que utilizan métodos genéricos para detectar similitud, Ganesh explota la estructura de los resultados de la base de datos relacional para lograr una mejora superior en el rendimiento. Uno se enfrenta al menos a tres desafíos al aplicar la detección de similitud basada en hash a las bases de datos de back-end. Primero, el trabajo previo en este ámbito ha considerado tradicionalmente el contenido de almacenamiento como bolsas de bits no interpretadas y sin estructura interna. Esto permite que las técnicas basadas en hash operen en largas y contiguas secuencias de datos para lograr la máxima efectividad. Por el contrario, las bases de datos relacionales tienen una estructura interna compleja que puede no ser tan propicia para la detección de similitudes basada en hash. Segundo, las bases de datos relacionales tienen restricciones de integridad y consistencia muy estrictas que no deben comprometerse por el uso de técnicas basadas en hash. Tercero, el código fuente de las bases de datos comerciales generalmente no está disponible. Esto contrasta con trabajos anteriores que presumían la disponibilidad del código fuente. Nuestros experimentos muestran que Ganesh, aunque conceptualmente simple, puede mejorar significativamente el rendimiento en anchos de banda representativos del Internet comercial actual. En los modelos de referencia de aplicaciones web multinivel, la mejora en el rendimiento fue de hasta diez veces para cargas de trabajo intensivas en datos. Para cargas de trabajo que no eran intensivas en datos, se observaron mejoras en el rendimiento de hasta el doble. Incluso cuando el ancho de banda no era una limitación, Ganesh tenía un bajo sobrecosto y no afectaba el rendimiento. Nuestros experimentos también confirman que aprovechar la estructura presente en los resultados de la base de datos es crucial para esta mejora en el rendimiento. Antecedentes 2.1 Generación de Contenido Dinámico A medida que la World Wide Web ha crecido, muchos sitios web han descentralizado sus datos y funcionalidades al llevarlos a los extremos de Internet. Hoy en día, los sistemas de comercio electrónico a menudo utilizan una arquitectura de tres niveles que consta de un servidor web de front-end, un servidor de aplicaciones y un servidor de base de datos de back-end. La Figura 1 ilustra esta arquitectura. Los dos primeros niveles se pueden replicar cerca de una concentración de clientes en el borde de Internet. Esto mejora la experiencia del usuario al reducir la latencia de extremo a extremo y disminuir la exposición al congestionamiento del tráfico de la columna vertebral. También puede aumentar la disponibilidad y escalabilidad de los servicios web. El contenido que se genera dinámicamente desde la base de datos del servidor no puede ser almacenado en caché en los dos primeros niveles. Si bien las bases de datos pueden replicarse fácilmente en una LAN, esto es inviable en una WAN debido a la difícil tarea de proporcionar simultáneamente una consistencia sólida, disponibilidad y tolerancia a particiones de red [7]. Como resultado, las bases de datos tienden a ser centralizadas para cumplir con los fuertes requisitos de consistencia de muchas aplicaciones de comercio electrónico como la banca, las finanzas y la venta al por menor en línea [38]. Por lo tanto, la base de datos del back-end suele estar ubicada lejos de muchos conjuntos de nodos de primer y segundo nivel [2]. En ausencia de almacenamiento en caché y replicación, el ancho de banda de la WAN puede convertirse fácilmente en un factor limitante en el rendimiento y la escalabilidad de aplicaciones intensivas en datos. El enfoque de Ganesh en los sistemas basados en hash es la transmisión eficiente de resultados al descubrir similitudes con los resultados de consultas anteriores. Dado que las consultas SQL pueden generar resultados grandes, las técnicas basadas en hash se prestan bien al problema de transferir eficientemente estos grandes resultados a través de enlaces con ancho de banda limitado. El uso de técnicas basadas en hash para reducir el volumen de datos transmitidos ha surgido como un tema común en muchos sistemas de almacenamiento recientes, como se discute en la Sección 8.2. Estas técnicas se basan en algunas suposiciones básicas. Se asume que las funciones hash criptográficas son resistentes a colisiones. En otras palabras, es computacionalmente intratable encontrar dos entradas que se hash a la misma salida. Las funciones también se asumen como unidireccionales; es decir, encontrar una entrada que resulte en una salida específica es computacionalmente inviable. Menezes et al. [23] proporcionan más detalles sobre estas suposiciones. Las suposiciones anteriores permiten a los sistemas basados en hash asumir que no se producen colisiones. Por lo tanto, pueden tratar el hash de un elemento de datos como su identificador único. Una colección de elementos de datos se convierte efectivamente en direccionable por contenido, permitiendo que un hash pequeño funcione como una palabra de código para un elemento de datos mucho más grande en almacenamiento permanente o transmisión en red. La suposición de que las colisiones son tan raras que prácticamente no existen ha sido cuestionada recientemente [17]. Sin embargo, como explicó Black [5], creemos que estos problemas no son una preocupación para Ganesh. Toda comunicación es entre partes confiables del sistema y un adversario no tiene forma de obligar a Ganesh a aceptar datos inválidos. Además, Ganesh no depende críticamente de ninguna función hash específica. Si bien actualmente usamos SHA-1, reemplazarlo con una función hash diferente sería sencillo. No habría impacto en el rendimiento con funciones hash más fuertes (por ejemplo, SHA256) solo añade unos pocos bytes adicionales y los hashes generados siguen siendo órdenes de magnitud más pequeños que los elementos de datos que representan. No es necesario volver a almacenar permanentemente ya que Ganesh solo utiliza el hash en datos volátiles. 3. DISEÑO E IMPLEMENTACIÓN Ganesh explota la redundancia en el flujo de resultados para evitar transmitir fragmentos de resultados que ya están presentes en el sitio de la consulta. La redundancia puede surgir de forma natural de muchas maneras diferentes. Por ejemplo, una consulta repetida después de un cierto intervalo puede devolver un resultado diferente debido a actualizaciones en la base de datos; sin embargo, puede haber una significativa similitud entre los dos resultados. Como otro ejemplo, un usuario que está refinando una búsqueda puede generar una secuencia de consultas con resultados superpuestos. Cuando Ganesh detecta redundancia, suprime la transmisión de los fragmentos de resultado correspondientes. En cambio, transmite un resumen mucho más pequeño de esos fragmentos y permite que el sitio de consulta reconstruya el resultado a través de la búsqueda de hash en una caché de resultados anteriores. De hecho, Ganesh utiliza la computación en los bordes para reducir la comunicación por Internet. Nuestra descripción de Ganesh se centra en cuatro aspectos. Primero explicamos nuestro enfoque para detectar similitud en los resultados de la consulta. A continuación, discutimos cómo la arquitectura Ganesh es completamente invisible para todos los componentes de un sistema de múltiples niveles. Luego describimos el enfoque basado en proxy de Ganesh y el flujo de datos para detectar similitudes. 3.1 Detectar similitud Una de las decisiones clave de diseño en Ganesh es cómo se detecta la similitud. Hay muchas formas potenciales de descomponer un resultado en fragmentos.  I the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the thees I,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,, Encontrar esta descomposición óptima es un problema difícil debido al amplio espacio de posibilidades y porque la elección óptima depende de muchos factores, como el contenido del resultado de las consultas, el historial de resultados recientes y el algoritmo de gestión de caché. Cuando un objeto es opaco, el uso de huellas digitales de Rabin [8, 30] para detectar datos comunes entre dos objetos ha sido demostrado con éxito en el pasado por sistemas como LBFS [26] y CASPER [37]. El fingerprinting de Rabin utiliza una ventana deslizante sobre los datos para calcular un hash rodante. Suponiendo que la función hash está distribuida uniformemente, un límite de fragmento se define cuando los bits de orden inferior del valor hash son iguales a algún valor predeterminado. El número de bits de orden inferior utilizados define el tamaño promedio del fragmento. Estos fragmentos subdivididos del objeto se convierten en la unidad de comparación para detectar similitudes entre diferentes objetos. Dado que las ubicaciones de los límites encontrados mediante el uso de las huellas de Rabin están determinadas de manera estocástica, generalmente no logran alinearse con ninguna propiedad estructural de los datos subyacentes. Por lo tanto, el algoritmo maneja bien las actualizaciones en su lugar, inserciones y eliminaciones. Sin embargo, tiene un rendimiento deficiente en presencia de cualquier reordenamiento de datos. La Figura 2 muestra un ejemplo donde dos resultados, A y B, que constan de tres filas, tienen los mismos datos pero diferentes atributos de ordenamiento. En el caso extremo, la huella digital de Rabin podría no ser capaz de encontrar datos similares debido a la forma en que detecta los límites de los fragmentos. Afortunadamente, Ganesh puede utilizar conocimientos específicos del dominio para una detección de límites más precisa. La información que explotamos es que el resultado de una consulta refleja la estructura de una base de datos relacional donde todos los datos están organizados en tablas y filas. Por lo tanto, es sencillo verificar la similitud con resultados anteriores en dos niveles de granularidad: primero el resultado completo y luego las filas individuales. El final de una fila en un resultado sirve como un límite natural de fragmento. Es importante tener en cuenta que el uso de la estructura tabular en los resultados solo implica una interpretación superficial de los datos. Ganesh no realiza ninguna interpretación semántica más profunda, como comprender tipos de datos, esquemas de resultados o restricciones de integridad. Ajustar la huella digital de Rabin para una carga de trabajo también puede ser difícil. Si el tamaño promedio de los fragmentos es demasiado grande, los fragmentos pueden abarcar varias filas de resultados. Sin embargo, seleccionar un tamaño de fragmento promedio más pequeño aumenta la cantidad de metadatos necesarios para describir los resultados. Esto, a su vez, disminuiría los ahorros obtenidos mediante su uso. El fingerprinting de Rabin también requiere dos pasadas computacionalmente costosas sobre los datos: una vez para determinar los límites de los fragmentos y otra vez para generar hashes criptográficos para los fragmentos. Ganesh solo necesita un único pase para la generación de hash, ya que los límites de los fragmentos son proporcionados por la estructura natural de los datos. La comparación de rendimiento en la Sección 6 muestra que el algoritmo basado en filas de Ganesh supera al fingerprinting de Rabin. Dado que trabajos anteriores ya han demostrado que la huella digital de Rabin funciona mejor que gzip [26], no comparamos a Ganesh con algoritmos de compresión en este artículo. 3.2 Transparencia El factor clave que influyó en nuestro diseño fue la necesidad de que Ganesh fuera completamente transparente para todos los componentes de un sistema típico de comercio electrónico: servidores web, servidores de aplicaciones y servidores de bases de datos. Sin esto, Ganesh tiene pocas posibilidades de tener un impacto significativo en el mundo real. Requerir modificaciones en cualquiera de los componentes mencionados aumentaría la barrera de entrada de Ganesh en un sistema existente, y por lo tanto reduciría sus posibilidades de adopción. Preservar la transparencia se simplifica por el hecho de que Ganesh es simplemente una mejora de rendimiento, no una mejora de funcionalidad o usabilidad. Elegimos la interposición de agentes como enfoque arquitectónico para lograr nuestro objetivo. Este enfoque se basa en la existencia de una interfaz de programación compacta que ya es ampliamente utilizada por el software objetivo. También se basa en un mecanismo para agregar fácilmente nuevo código sin interrumpir la estructura de módulos existente. Estas condiciones se cumplen fácilmente en nuestro contexto debido a la popularidad de Java como el lenguaje de programación para sistemas de comercio electrónico. La API de Conectividad de Base de Datos de Java (JDBC) [32] permite a las aplicaciones de Java acceder a una amplia variedad de bases de datos e incluso a otros repositorios de datos tabulares como archivos planos. El acceso a estas fuentes de datos es proporcionado por controladores JDBC que traducen entre la API JDBC y el mecanismo de comunicación de la base de datos. La figura 3(a) muestra cómo se utiliza típicamente JDBC en una aplicación. Dado que la interfaz JDBC está estandarizada, se puede sustituir un <br>controlador JDBC</br> por otro sin necesidad de de modificar la aplicación. El <br>controlador JDBC</br> se convierte así en el módulo natural para aprovechar la interposición de código. Como se muestra en la Figura 3(b), el controlador JDBC nativo es reemplazado por un controlador JDBC Ganesh que presenta la misma interfaz estandarizada. El controlador Ganesh mantiene una caché en memoria de fragmentos de resultados de consultas anteriores y realiza el reensamblaje de resultados. En la base de datos, agregamos un nuevo proceso llamado el proxy Ganesh. Este proxy, que puede ser compartido por múltiples nodos front-end, consta de dos partes: código para detectar similitud en fragmentos de resultados y el <br>controlador JDBC</br> nativo original que se comunica con la base de datos. El uso de un proxy en la base de datos hace que Ganesh sea independiente de la base de datos y simplifica la creación de prototipos y experimentación. Ganesh es capaz de trabajar con una amplia gama de bases de datos y aplicaciones, sin necesidad de realizar modificaciones en ninguna de ellas. 3.3 Caché basada en proxy El <br>controlador JDBC</br> nativo mostrado en la Figura 3(a) es un componente de código ligero suministrado por el proveedor de la base de datos. ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "resultset object": {
            "translated_key": "objeto ResultSet",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Consistency-preserving Caching of Dynamic Database Content∗ Niraj Tolia and M. Satyanarayanan Carnegie Mellon University {ntolia,satya}@cs.cmu.edu ABSTRACT With the growing use of dynamic web content generated from relational databases, traditional caching solutions for throughput and latency improvements are ineffective.",
                "We describe a middleware layer called Ganesh that reduces the volume of data transmitted without semantic interpretation of queries or results.",
                "It achieves this reduction through the use of cryptographic hashing to detect similarities with previous results.",
                "These benefits do not require any compromise of the strict consistency semantics provided by the back-end database.",
                "Further, Ganesh does not require modifications to applications, web servers, or database servers, and works with closed-source applications and databases.",
                "Using two benchmarks representative of dynamic web sites, measurements of our prototype show that it can increase end-to-end throughput by as much as twofold for non-data intensive applications and by as much as tenfold for data intensive ones.",
                "Categories and Subject Descriptors C.2.4 [Computer-Communication Networks]: Distributed Systems; H.2.4 [Database Management]: Systems General Terms Design, Performance 1.",
                "INTRODUCTION An increasing fraction of web content is dynamically generated from back-end relational databases.",
                "Even when database content remains unchanged, temporal locality of access cannot be exploited because dynamic content is not cacheable by web browsers or by intermediate caching servers such as Akamai mirrors.",
                "In a multitiered architecture, each web request can stress the WAN link between the web server and the database.",
                "This causes user experience to be highly variable because there is no caching to insulate the client from bursty loads.",
                "Previous attempts in caching dynamic database content have generally weakened transactional semantics [3, 4] or required application modifications [15, 34].",
                "We report on a new solution that takes the form of a databaseagnostic middleware layer called Ganesh.",
                "Ganesh makes no effort to semantically interpret the contents of queries or their results.",
                "Instead, it relies exclusively on cryptographic hashing to detect similarities with previous results.",
                "Hash-based similarity detection has seen increasing use in distributed file systems [26, 36, 37] for improving performance on low-bandwidth networks.",
                "However, these techniques have not been used for relational databases.",
                "Unlike previous approaches that use generic methods to detect similarity, Ganesh exploits the structure of relational database results to yield superior performance improvement.",
                "One faces at least three challenges in applying hash-based similarity detection to back-end databases.",
                "First, previous work in this space has traditionally viewed storage content as uninterpreted bags of bits with no internal structure.",
                "This allows hash-based techniques to operate on long, contiguous runs of data for maximum effectiveness.",
                "In contrast, relational databases have rich internal structure that may not be as amenable to hash-based similarity detection.",
                "Second, relational databases have very tight integrity and consistency constraints that must not be compromised by the use of hash-based techniques.",
                "Third, the source code of commercial databases is typically not available.",
                "This is in contrast to previous work which presumed availability of source code.",
                "Our experiments show that Ganesh, while conceptually simple, can improve performance significantly at bandwidths representative of todays commercial Internet.",
                "On benchmarks modeling multitiered web applications, the throughput improvement was as high as tenfold for data-intensive workloads.",
                "For workloads that were not data-intensive, throughput improvements of up to twofold were observed.",
                "Even when bandwidth was not a constraint, Ganesh had low overhead and did not hurt performance.",
                "Our experiments also confirm that exploiting the structure present in database results is crucial to this performance improvement. 2.",
                "BACKGROUND 2.1 Dynamic Content Generation As the World Wide Web has grown, many web sites have decentralized their data and functionality by pushing them to the edges of the Internet.",
                "Today, eBusiness systems often use a three-tiered architecture consisting of a front-end web server, an application server, and a back-end database server.",
                "Figure 1 illustrates this architecture.",
                "The first two tiers can be replicated close to a concentration of clients at the edge of the Internet.",
                "This improves user experience by lowering end-to-end latency and reducing exposure WWW 2007 / Track: Performance and Scalability Session: Scalable Systems for Dynamic Content 311 Back-End Database Server Front-End Web and Application Servers Figure 1: Multi-Tier Architecture to backbone traffic congestion.",
                "It can also increase the availability and scalability of web services.",
                "Content that is generated dynamically from the back-end database cannot be cached in the first two tiers.",
                "While databases can be easily replicated in a LAN, this is infeasible in a WAN because of the difficult task of simultaneously providing strong consistency, availability, and tolerance to network partitions [7].",
                "As a result, databases tend to be centralized to meet the strong consistency requirements of many eBusiness applications such as banking, finance, and online retailing [38].",
                "Thus, the back-end database is usually located far from many sets of first and second-tier nodes [2].",
                "In the absence of both caching and replication, WAN bandwidth can easily become a limiting factor in the performance and scalability of data-intensive applications. 2.2 Hash-Based Systems Ganeshs focus is on efficient transmission of results by discovering similarities with the results of previous queries.",
                "As SQL queries can generate large results, hash-based techniques lend themselves well to the problem of efficiently transferring these large results across bandwidth constrained links.",
                "The use of hash-based techniques to reduce the volume of data transmitted has emerged as a common theme of many recent storage systems, as discussed in Section 8.2.",
                "These techniques rely on some basic assumptions.",
                "Cryptographic hash functions are assumed to be collision-resistant.",
                "In other words, it is computationally intractable to find two inputs that hash to the same output.",
                "The functions are also assumed to be one-way; that is, finding an input that results in a specific output is computationally infeasible.",
                "Menezes et al. [23] provide more details about these assumptions.",
                "The above assumptions allow hash-based systems to assume that collisions do not occur.",
                "Hence, they are able to treat the hash of a data item as its unique identifier.",
                "A collection of data items effectively becomes content-addressable, allowing a small hash to serve as a codeword for a much larger data item in permanent storage or network transmission.",
                "The assumption that collisions are so rare as to be effectively non-existent has recently come under fire [17].",
                "However, as explained by Black [5], we believe that these issues do not form a concern for Ganesh.",
                "All communication is between trusted parts of the system and an adversary has no way to force Ganesh to accept invalid data.",
                "Further, Ganesh does not depend critically on any specific hash function.",
                "While we currently use SHA-1, replacing it with a different hash function would be simple.",
                "There would be no impact on performance as stronger hash functions (e.g.",
                "SHA256) only add a few extra bytes and the generated hashes are still orders of magnitude smaller than the data items they represent.",
                "No re-hashing of permanent storage is required since Ganesh only uses hashing on volatile data. 3.",
                "DESIGN AND IMPLEMENTATION Ganesh exploits redundancy in the result stream to avoid transmitting result fragments that are already present at the query site.",
                "Redundancy can arise naturally in many different ways.",
                "For example, a query repeated after a certain interval may return a different result because of updates to the database; however, there may be significant commonality between the two results.",
                "As another example, a user who is refining a search may generate a sequence of queries with overlapping results.",
                "When Ganesh detects redundancy, it suppresses transmission of the corresponding result fragments.",
                "Instead, it transmits a much smaller digest of those fragments and lets the query site reconstruct the result through hash lookup in a cache of previous results.",
                "In effect, Ganesh uses computation at the edges to reduce Internet communication.",
                "Our description of Ganesh focuses on four aspects.",
                "We first explain our approach to detecting similarity in query results.",
                "Next, we discuss how the Ganesh architecture is completely invisible to all components of a multi-tier system.",
                "We then describe Ganeshs proxy-based approach and the dataflow for detecting similarity. 3.1 Detecting Similarity One of the key design decisions in Ganesh is how similarity is detected.",
                "There are many potential ways to decompose a result into fragments.",
                "The optimal way is, of course, the one that results in the smallest possible object for transmission for a given querys results.",
                "Finding this optimal decomposition is a difficult problem because of the large space of possibilities and because the optimal choice depends on many factors such as the contents of the querys result, the history of recent results, and the cache management algorithm.",
                "When an object is opaque, the use of Rabin fingerprints [8, 30] to detect common data between two objects has been successfully shown in the past by systems such as LBFS [26] and CASPER [37].",
                "Rabin fingerprinting uses a sliding window over the data to compute a rolling hash.",
                "Assuming that the hash function is uniformly distributed, a chunk boundary is defined whenever the lower order bits of the hash value equal some predetermined value.",
                "The number of lower order bits used defines the average chunk size.",
                "These sub-divided chunks of the object become the unit of comparison for detecting similarity between different objects.",
                "As the locations of boundaries found by using Rabin fingerprints is stochastically determined, they usually fail to align with any structural properties of the underlying data.",
                "The algorithm therefore deals well with in-place updates, insertions and deletions.",
                "However, it performs poorly in the presence of any reordering of data.",
                "Figure 2 shows an example where two results, A and B, consisting of three rows, have the same data but have different sort attributes.",
                "In the extreme case, Rabin fingerprinting might be unable to find any similar data due to the way it detects chunk boundaries.",
                "Fortunately, Ganesh can use domain specific knowledge for more precise boundary detection.",
                "The information we exploit is that a querys result reflects the structure of a relational database where all data is organized as tables and rows.",
                "It is therefore simple to check for similarity with previous results at two granularities: first the entire result, and then individual rows.",
                "The end of a row in a result serves as a natural chunk boundary.",
                "It is important to note that using the tabular structure in results only involves shallow interpretation of the data.",
                "Ganesh does not perform any deeper semantic interpretation such as understanding data types, result schema, or integrity constraints.",
                "Tuning Rabin fingerprinting for a workload can also be difficult.",
                "If the average chunk size is too large, chunks can span multiple result rows.",
                "However, selecting a smaller average chunk size increases the amount of metadata required to the describe the results.",
                "WWW 2007 / Track: Performance and Scalability Session: Scalable Systems for Dynamic Content 312 Figure 2: Rabin Fingerprinting vs. Ganeshs Chunking This, in turn, would decrease the savings obtained via its use.",
                "Rabin fingerprinting also needs two computationally-expensive passes over the data: once to determine chunk boundaries and one again to generate cryptographic hashes for the chunks.",
                "Ganesh only needs a single pass for hash generation as the chunk boundaries are provided by the datas natural structure.",
                "The performance comparison in Section 6 shows that Ganeshs row-based algorithm outperforms Rabin fingerprinting.",
                "Given that previous work has already shown that Rabin fingerprinting performs better than gzip [26], we do not compare Ganesh to compression algorithms in this paper. 3.2 Transparency The key factor influencing our design was the need for Ganesh to be completely transparent to all components of a typical eBusiness system: web servers, application servers, and database servers.",
                "Without this, Ganesh stands little chance of having a significant real-world impact.",
                "Requiring modifications to any of the above components would raise the barrier for entry of Ganesh into an existing system, and thus reduce its chances of adoption.",
                "Preserving transparency is simplified by the fact that Ganesh is purely a performance enhancement, not a functionality or usability enhancement.",
                "We chose agent interposition as the architectural approach to realizing our goal.",
                "This approach relies on the existence of a compact programming interface that is already widely used by target software.",
                "It also relies on a mechanism to easily add new code without disrupting existing module structure.",
                "These conditions are easily met in our context because of the popularity of Java as the programming language for eBusiness systems.",
                "The Java Database Connectivity (JDBC) API [32] allows Java applications to access a wide variety of databases and even other tabular data repositories such as flat files.",
                "Access to these data sources is provided by JDBC drivers that translate between the JDBC API and the database communication mechanism.",
                "Figure 3(a) shows how JDBC is typically used in an application.",
                "As the JDBC interface is standardized, one can substitute one JDBC driver for another without application modifications.",
                "The JDBC driver thus becomes the natural module to exploit for code interposition.",
                "As shown in Figure 3(b), the native JDBC driver is replaced with a Ganesh JDBC driver that presents the same standardized interface.",
                "The Ganesh driver maintains an in-memory cache of result fragments from previous queries and performs reassembly of results.",
                "At the database, we add a new process called the Ganesh proxy.",
                "This proxy, which can be shared by multiple front-end nodes, consists of two parts: code to detect similarity in result fragments and the original native JDBC driver that communicates with the database.",
                "The use of a proxy at the database makes Ganesh database-agnostic and simplifies prototyping and experimentation.",
                "Ganesh is thus able to work with a wide range of databases and applications, requiring no modifications to either. 3.3 Proxy-Based Caching The native JDBC driver shown in Figure 3(a) is a lightweight code component supplied by the database vendor.",
                "Its main funcClient Database Web and Application Server Native JDBC Driver WAN (a) Native Architecture Client Database Ganesh Proxy Native JDBC Driver WAN Web and Application Server Ganesh JDBC Driver (b) Ganeshs Interposition-based Architecture Figure 3: Native vs. Ganesh Architecture tion is to mediate communication between the application and the remote database.",
                "It forwards queries, buffers entire results, and responds to application requests to view parts of results.",
                "The Ganesh JDBC driver shown in Figure 3(b) presents the application with an interface identical to that provided by the native driver.",
                "It provides the ability to reconstruct results from compact hash-based descriptions sent by the proxy.",
                "To perform this reconstruction, the driver maintains an in-memory cache of recentlyreceived results.",
                "This cache is only used as a source of result fragments in reconstructing results.",
                "No attempt is made by the Ganesh driver or proxy to track database updates.",
                "The lack of cache consistency does not hurt correctness as a description of the results is always fetched from the proxy - at worst, there will be no performance benefit from using Ganesh.",
                "Stale data will simply be paged out of the cache over time.",
                "The Ganesh proxy accesses the database via the native JDBC driver, which remains unchanged between Figures 3(a) and (b).",
                "The database is thus completely unaware of the existence of the proxy.",
                "The proxy does not examine any queries received from the Ganesh driver but passes them to the native driver.",
                "Instead, the proxy is responsible for inspecting database output received from the native driver, detecting similar results, and generating hash-based encodings of these results whenever enough similarity is found.",
                "While this architecture does not decrease the load on a database, as mentioned earlier in Section 2.1, it is much easier to replicate databases for scalability in a LAN than in a WAN.",
                "To generate a hash-based encoding, the proxy must be aware of what result fragments are available in the Ganesh drivers cache.",
                "One approach is to be optimistic, and to assume that all result fragments are available.",
                "This will result in the smallest possible initial transmission of a result.",
                "However, in cases where there is little overlap with previous results, the Ganesh driver will have to make many calls to the proxy during reconstruction to fetch missing result fragments.",
                "To avoid this situation, the proxy loosely tracks the state of the Ganesh drivers cache.",
                "Since both components are under our control, it is relatively simple to do this without resorting to gray-box techniques or explicit communication for maintaining cache coherence.",
                "Instead, the proxy simulates the Ganesh drivers cache management algorithm and uses this to maintain a list of hashes for which the Ganesh driver is likely to possess the result fragments.",
                "In case of mistracking, there will be no loss of correctness but there will be extra round-trip delays to fetch the missing fragments.",
                "If the client detects loss of synchronization with the proxy, it can ask the proxy to reset the state shared between them.",
                "Also note that the proxy does not need to keep the result fragments themselves, only their hashes.",
                "This allows the proxy to remain scalable even when it is shared by many front-end nodes.",
                "WWW 2007 / Track: Performance and Scalability Session: Scalable Systems for Dynamic Content 313 Object Output Stream Convert <br>resultset object</br> Input Stream Convert ResultSet All Data Recipe ResultSet All Data ResultSet Network Ganesh Proxy Ganesh JDBC Driver Result Set Recipe Result Set Yes Yes No No GaneshInputStream GaneshOutputStream Figure 4: Dataflow for Result Handling 3.4 Encoding and Decoding Results The Ganesh proxy receives database output as Java objects from the native JDBC driver.",
                "It examines this output to see if a Java object of type ResultSet is present.",
                "The JDBC interface uses this data type to store results of database queries.",
                "If a <br>resultset object</br> is found, it is shrunk as discussed below.",
                "All other Java objects are passed through unmodified.",
                "As discussed in Section 3.1, the proxy uses the row boundaries defined in the ResultSet to partition it into fragments consisting of single result rows.",
                "All ResultSet objects are converted into objects of a new type called RecipeResultSet.",
                "We use the term recipe for this compact description of a database result because of its similarity to a file recipe in the CASPER file system [37].",
                "The conversion replaces each result fragment that is likely to be present in the Ganesh drivers cache by a SHA-1 hash of that fragment.",
                "Previously unseen result fragments are retained verbatim.",
                "The proxy also retains hashes for the new result fragments as they will be present in the drivers cache in the future.",
                "Note that the proxy only caches hashes for result fragments and does not cache recipes.",
                "The proxy constructs a RecipeResultSet by checking for similarity at the entire result and then the row level.",
                "If the entire result is predicted to be present in the Ganesh drivers cache, the RecipeResultSet is simply a single hash of the entire result.",
                "Otherwise, it contains hashes for those rows predicted to be present in that cache; all other rows are retained verbatim.",
                "If the proxy estimates an overall space savings, it will transmit the RecipeResultSet.",
                "Otherwise the original ResultSet is transmitted.",
                "The RecipeResultSet objects are transformed back into ResultSet objects by the Ganesh driver.",
                "Figure 4 illustrates ResultSet handling at both ends.",
                "Each SHA-1 hash found in a RecipeResultSet is looked up in the local cache of result fragments.",
                "On a hit, the hash is replaced by the corresponding fragment.",
                "On a miss, the driver contacts the Ganesh proxy to fetch the fragment.",
                "All previously unseen result fragments that were retained verbatim by the proxy are hashed and added to the result cache.",
                "There should be very few misses if the proxy has accurately tracked the Ganesh drivers cache state.",
                "A future optimization would be to batch the fetch of missing fragments.",
                "This would be valuable when there are many small missing fragments in a high-latency WAN.",
                "Once the transformation is complete, the fully reconstructed <br>resultset object</br> is passed up to the application. 4.",
                "EXPERIMENTAL VALIDATION Three questions follow from the goals and design of Ganesh: • First, can performance can be improved significantly by exploiting similarity across database results?",
                "Benchmark Dataset Details 500,000 Users, 12,000 Stories BBOARD 2.0 GB 3,298,000 Comments AUCTION 1.3 GB 1,000,000 Users, 34,000 Items Table 1: Benchmark Dataset Details • Second, how important is Ganeshs structural similarity detection relative to Rabin fingerprintings similarity detection? • Third, is the overhead of the proxy-based design acceptable?",
                "Our evaluation answers these question through controlled experiments with the Ganesh prototype.",
                "This section describes the benchmarks used, our evaluation procedure, and the experimental setup.",
                "Results of the experiments are presented in Sections 5, 6, and 7. 4.1 Benchmarks Our evaluation is based on two benchmarks [18] that have been widely used by other researchers to evaluate various aspects of multi-tier [27] and eBusiness architectures [9].",
                "The first benchmark, BBOARD, is modeled after Slashdot, a technology-oriented news site.",
                "The second benchmark, AUCTION, is modeled after eBay, an online auction site.",
                "In both benchmarks, most content is dynamically generated from information stored in a database.",
                "Details of the datasets used can be found in Table 1. 4.1.1 The BBOARD Benchmark The BBOARD benchmark, also known as RUBBoS [18], models Slashdot, a popular technology-oriented web site.",
                "Slashdot aggregates links to news stories and other topics of interest found elsewhere on the web.",
                "The site also serves as a bulletin board by allowing users to comment on the posted stories in a threaded conversation form.",
                "It is not uncommon for a story to gather hundreds of comments in a matter of hours.",
                "The BBOARD benchmark is similar to the site and models the activities of a user, including readonly operations such as browsing the stories of the day, browsing story categories, and viewing comments as well as write operations such as new user registration, adding and moderating comments, and story submission.",
                "The benchmark consists of three different phases: a short warmup phase, a runtime phase representing the main body of the workload, and a short cool-down phase.",
                "In this paper we only report results from the runtime phase.",
                "The warm-up phase is important in establishing dynamic system state, but measurements from that phase are not significant for our evaluation.",
                "The cool-down phase is solely for allowing the benchmark to shut down.",
                "The warm-up, runtime, and cool-down phases are 2, 15, and 2 minutes respectively.",
                "The number of simulated clients were 400, 800, 1200, and 1600.",
                "The benchmark is available in a Java Servlets and PHP version and has different datasets; we evaluated Ganesh using the Java Servlets version and the Expanded dataset.",
                "The BBOARD benchmark defines two different workloads.",
                "The first, the Authoring mix, consists of 70% read-only operations and 30% read-write operations.",
                "The second, the Browsing mix, contains only read-only operations and does not update the database. 4.1.2 The AUCTION Benchmark The AUCTION benchmark, also known as RUBiS [18], models eBay, the online auction site.",
                "The eBay web site is used to buy and sell items via an auction format.",
                "The main activities of a user include browsing, selling, or bidding for items.",
                "Modeling the activities on this site, this benchmark includes read-only activities such as browsing items by category and by region, as well as read-write WWW 2007 / Track: Performance and Scalability Session: Scalable Systems for Dynamic Content 314 NetEm Router Ganesh Proxy Clients Web and Application Server Database Server Figure 5: Experimental Setup activities such as bidding for items, buying and selling items, and leaving feedback.",
                "As with BBOARD, the benchmark consists of three different phases.",
                "The warm-up, runtime, and cool-down phases for this experiment are 1.5, 15, and 1 minutes respectively.",
                "We tested Ganesh with four client configurations where the number of test clients was set to 400, 800, 1200, and 1600.",
                "The benchmark is available in a Enterprise Java Bean (EJB), Java Servlets, and PHP version and has different datasets; we evaluated Ganesh with the Java Servlets version and the Expanded dataset.",
                "The AUCTION benchmark defines two different workloads.",
                "The first, the Bidding mix, consists of 70% read-only operations and 30% read-write operations.",
                "The second, the Browsing mix, contains only read-only operations and does not update the database. 4.2 Experimental Procedure Both benchmarks involve a synthetic workload of clients accessing a web server.",
                "The number of clients emulated is an experimental parameter.",
                "Each emulated client runs an instance of the benchmark in its own thread, using a matrix to transition between different benchmark states.",
                "The matrix defines a stochastic model with probabilities of transitioning between the different states that represent typical user actions.",
                "An example transition is a user logging into the AUCTION system and then deciding on whether to post an item for sale or bid on active auctions.",
                "Each client also models user think time between requests.",
                "The think time is modeled as an exponential distribution with a mean of 7 seconds.",
                "We evaluate Ganesh along two axes: number of clients and WAN bandwidth.",
                "Higher loads are especially useful in understanding Ganeshs performance when the CPU or disk of the database server or proxy is the limiting factor.",
                "A previous study has shown that approximately 50% of the wide-area Internet bottlenecks observed had an available bandwidth under 10 Mb/s [1].",
                "Based on this work, we focus our evaluation on the WAN bandwidth of 5 Mb/s with 66 ms of round-trip latency, representative of severely constrained network paths, and 20 Mb/s with 33 ms of round-trip latency, representative of a moderately constrained network path.",
                "We also report Ganeshs performance at 100 Mb/s with no added round-trip latency.",
                "This bandwidth, representative of an unconstrained network, is especially useful in revealing any potential overhead of Ganesh in situations where WAN bandwidth is not the limiting factor.",
                "For each combination of number of clients and WAN bandwidth, we measured results from the two configurations listed below: • Native: This configuration corresponds to Figure 3(a).",
                "Native avoids Ganeshs overhead in using a proxy and performing Java object serialization. • Ganesh: This configuration corresponds to Figure 3(b).",
                "For a given number of clients and WAN bandwidth, comparing these results to the corresponding Native results gives the performance benefit due to the Ganesh middleware system.",
                "The metric used to quantify the improvement in throughput is the number of client requests that can be serviced per second.",
                "The metric used to quantify Ganeshs overhead is the average response time for a client request.",
                "For all of the experiments, the Ganesh driver used by the application server used a cache size of 100,000 items1 .",
                "The proxy was effective in tracking the Ganesh drivers cache state; for all of our experiments the miss rate on the driver never exceeded 0.7%. 4.3 Experimental Setup The experimental setup used for the benchmarks can be seen in Figure 5.",
                "All machines were 3.2 GHz Pentium 4s (with HyperThreading enabled.)",
                "With the exception of the database server, all machines had 2 GB of SDRAM and ran the Fedora Core Linux distribution.",
                "The database server had 4 GB of SDRAM.",
                "We used Apaches Tomcat as both the application server that hosted the Java Servlets and the web server.",
                "Both benchmarks used Java Servlets to generate the dynamic content.",
                "The database server used the open source MySQL database.",
                "For the native JDBC drivers, we used the Connector/J drivers provided by MySQL.",
                "The application server used Suns Java Virtual Machine as the runtime environment for the Java Servlets.",
                "The sysstat tool was used to monitor the CPU, network, disk, and memory utilization on all machines.",
                "The machines were connected by a switched gigabit Ethernet network.",
                "As shown in Figure 5, the front-end web and application server was separated from the proxy and database server by a NetEm router [16].",
                "This router allowed us to control the bandwidth and latency settings on the network.",
                "The NetEm router is a standard PC with two network cards running the Linux Traffic Control and Network Emulation software.",
                "The bandwidth and latency constraints were only applied to the link between the application server and the database for the native case and between the application server and the proxy for the Ganesh case.",
                "There is no communication between the application server and the database with Ganesh as all data flows through the proxy.",
                "As our focus was on the WAN link between the application server and the database, there were no constraints on the link between the simulated test clients and the web server. 5.",
                "THROUGHPUT AND RESPONSE TIME In this section, we address the first question raised in Section 4: Can performance can be improved significantly by exploiting similarity across database results?",
                "To answer this question, we use results from the BBOARD and AUCTION benchmarks.",
                "We use two metrics to quantify the performance improvement obtainable through the use of Ganesh: throughput, from the perspective of the web server, and average response time, from the perspective of the client.",
                "Throughput is measured in terms of the number of client requests that can be serviced per second. 5.1 BBOARD Results and Analysis 5.1.1 Authoring Mix Figures 6 (a) and (b) present the average number of requests serviced per second and the average response time for these requests as perceived by the clients for BBOARDs Authoring Mix.",
                "As Figure 6 (a) shows, Native easily saturates the 5 Mb/s link.",
                "At 400 clients, the Native solution delivers 29 requests/sec with an average response time of 8.3 seconds.",
                "Natives throughput drops with an increase in test clients as clients timeout due to congestion at the application server.",
                "Usability studies have shown that response times above 10 seconds cause the user to move on to 1 As Java lacks a sizeof() operator, Java caches therefore limit their size based on the number of objects.",
                "The size of cache dumps taken at the end of the experiments never exceeded 212 MB.",
                "WWW 2007 / Track: Performance and Scalability Session: Scalable Systems for Dynamic Content 315 0 50 100 150 200 250 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Test Clients Requests/sec Native Ganesh 0.001 0.01 0.1 1 10 100 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Test Clients Avg.Resp.Time(sec) Native Ganesh Note Logscale (a) Throughput: Authoring Mix (b) Response Time: Authoring Mix 0 50 100 150 200 250 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Test Clients Requests/sec Native Ganesh 0.001 0.01 0.1 1 10 100 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Test Clients Avg.Resp.Time(sec) Native Ganesh Note Logscale (c) Throughput: Browsing Mix (d) Response Time: Browsing Mix Mean of three trials.",
                "The maximum standard deviation for throughput and response time was 9.8% and 11.9% of the corresponding mean.",
                "Figure 6: BBOARD Benchmark - Throughput and Average Response Time other tasks [24].",
                "Based on these numbers, increasing the number of test clients makes the Native system unusable.",
                "Ganesh at 5 Mb/s, however, delivers a twofold improvement with 400 test clients and a fivefold improvement at 1200 clients.",
                "Ganeshs performance drops slightly at 1200 and 1600 clients as the network is saturated.",
                "Compared to Native, Figure 6 (b) shows that Ganeshs response times are substantially lower with sub-second response times at 400 clients.",
                "Figure 6 (a) also shows that for 400 and 800 test clients Ganesh at 5 Mb/s has the same throughput and average response time as Native at 20 Mb/s.",
                "Only at 1200 and 1600 clients does Native at 20 Mb/s deliver higher throughput than Ganesh at 5 Mb/s.",
                "Comparing both Ganesh and Native at 20 Mb/s, we see that Ganesh is no longer bandwidth constrained and delivers up to a twofold improvement over Native at 1600 test clients.",
                "As Ganesh does not saturate the network with higher test client configurations, at 1600 test clients, its average response time is 0.1 seconds rather than Natives 7.7 seconds.",
                "As expected, there are no visible gains from Ganesh at the higher bandwidth of 100 Mb/s where the network is no longer the bottleneck.",
                "Ganesh, however, still tracks Native in terms of throughput. 5.1.2 Browsing Mix Figures 6 (c) and (d) present the average number of requests serviced per second and the average response time for these requests as perceived by the clients for BBOARDs Browsing Mix.",
                "Regardless of the test client configuration, Figure 6 (c) shows that Natives throughput at 5 Mb/s is limited to 10 reqs/sec.",
                "Ganesh at 5 Mb/s with 400 test clients, delivers more than a sixfold increase in throughput.",
                "The improvement increases to over a elevenfold increase at 800 test clients before Ganesh saturates the network.",
                "Further, Figure 6 (d) shows that Natives average response time of 35 seconds at 400 test clients make the system unusable.",
                "These high response times further increase with the addition of test clients.",
                "Even with the 1600 test client configuration Ganesh delivers an acceptable average response time of 8.2 seconds.",
                "Due to the data-intensive nature of the Browsing mix, Ganesh at 5 Mb/s surprisingly performs much better than Native at 20 Mb/s.",
                "Further, as shown in Figure 6 (d), while the average response time for Native at 20 Mb/s is acceptable at 400 test clients, it is unusable with 800 test clients with an average response time of 15.8 seconds.",
                "Like the 5 Mb/s case, this response time increases with the addition of extra test clients.",
                "Ganesh at 20 Mb/s and both Native and Ganesh at 100 Mb/s are not bandwidth limited.",
                "However, performance plateaus out after 1200 test clients due to the database CPU being saturated. 5.1.3 Filter Variant We were surprised by the Native performance from the BBOARD benchmark.",
                "At the bandwidth of 5 Mb/s, Native performance was lower than what we had expected.",
                "It turned out the benchmark code that displays stories read all the comments associated with the particular story from the database and only then did some postprocessing to select the comments to be displayed.",
                "While this is exactly the behavior of SlashCode, the code base behind the Slashdot web site, we decided to modify the benchmark to perform some pre-filtering at the database.",
                "This modified benchmark, named the Filter Variant, models a developer who applies optimizations at the SQL level to transfer less data.",
                "In the interests of brevity, we only briefly summarize the results from the Authoring mix.",
                "For the Authoring mix, at 800 test clients at 5 Mb/s, Figure 7 (a) shows that Natives throughput increase by 85% when compared to the original benchmark while Ganeshs improvement is smaller at 15%.",
                "Natives performance drops above 800 clients as the test clients time out due to high response times.",
                "The most significant gain for Native is seen at 20 Mb/s.",
                "At 1600 test clients, when compared to the original benchmark, Native sees a 73% improvement in throughput and a 77% reduction in average response time.",
                "While WWW 2007 / Track: Performance and Scalability Session: Scalable Systems for Dynamic Content 316 0 50 100 150 200 250 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Test Clients Requests/sec Native Ganesh 0.001 0.01 0.1 1 10 100 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Test Clients Avg.Resp.Time(sec) Native Ganesh Note Logscale (a) Throughput: Authoring Mix (b) Response Time: Authoring Mix Mean of three trials.",
                "The maximum standard deviation for throughput and response time was 7.2% and 11.5% of the corresponding mean.",
                "Figure 7: BBOARD Benchmark - Filter Variant - Throughput and Average Response Time Ganesh sees no improvement when compared to the original, it still processes 19% more requests/sec than Native.",
                "Thus, while the optimizations were more helpful to Native, Ganesh still delivers an improvement in performance. 5.2 AUCTION Results and Analysis 5.2.1 Bidding Mix Figures 8 (a) and (b) present the average number of requests serviced per second and the average response time for these requests as perceived by the clients for AUCTIONs Bidding Mix.",
                "As mentioned earlier, the Bidding mix consists of a mixture of read and write operations.",
                "The AUCTION benchmark is not as data intensive as BBOARD.",
                "Therefore, most of the gains are observed at the lower bandwidth of 5 Mb/s.",
                "Figure 8 (a) shows that the increase in throughput due to Ganesh ranges from 8% at 400 test clients to 18% with 1600 test clients.",
                "As seen in Figure 8 (b), the average response times for Ganesh are significantly lower than Native ranging from a decrease of 84% at 800 test clients to 88% at 1600 test clients.",
                "Figure 8 (a) also shows that with a fourfold increase of bandwidth from 5 Mb/s to 20 Mb/s, Native is no longer bandwidth constrained and there is no performance difference between Ganesh and Native.",
                "With the higher test client configurations, we did observe that the bandwidth used by Ganesh was lower than Native.",
                "Ganesh might still be useful in these non-constrained scenarios if bandwidth is purchased on a metered basis.",
                "Similar results are seen for the 100 Mb/s scenario. 5.2.2 Browsing Mix For AUCTIONs Browsing Mix, Figures 8 (c) and (d) present the average number of requests serviced per second and the average response time for these requests as perceived by the clients.",
                "Again, most of the gains are observed at lower bandwidths.",
                "At 5 Mb/s, Native and Ganesh deliver similar throughput and response times with 400 test clients.",
                "While the throughput for both remains the same at 800 test clients, Figure 8 (d) shows that Ganeshs average response time is 62% lower than Native.",
                "Native saturates the link at 800 clients and adding extra test clients only increases the average response time.",
                "Ganesh, regardless of the test client configuration, is not bandwidth constrained and maintains the same response time.",
                "At 1600 test clients, Figure 8 (c) shows that Ganeshs throughput is almost twice that of Native.",
                "At the higher bandwidths of 20 and 100 Mb/s, neither Ganesh nor Native is bandwidth limited and deliver equivalent throughput and response times.",
                "Benchmark Orig.",
                "Size Ganesh Size Rabin Size SelectSort1 223.6 MB 5.4 MB 219.3 MB SelectSort2 223.6 MB 5.4 MB 223.6 MB Table 2: Similarity Microbenchmarks 6.",
                "STRUCTURAL VS. RABIN SIMILARITY In this section, we address the second question raised in Section 4: How important is Ganeshs structural similarity detection relative to Rabin fingerprinting-based similarity detecting?",
                "To answer this question, we used microbenchmarks and the BBOARD and AUCTION benchmarks.",
                "As Ganesh always performed better than Rabin fingerprinting, we only present a subset of the results here in the interests of brevity. 6.1 Microbenchmarks Two microbenchmarks show an example of the effects of data reordering on Rabin fingerprinting algorithm.",
                "In the first microbenchmark, SelectSort1, a query with a specified sort order selects 223.6 MB of data spread over approximately 280 K rows.",
                "The query is then repeated with a different sort attribute.",
                "While the same number of rows and the same data is returned, the order of rows is different.",
                "In such a scenario, one would expect a large amount of similarity to be detected between both results.",
                "As Table 2 shows, Ganeshs row-based algorithm achieves a 97.6% reduction while the Rabin fingerprinting algorithm, with the average chunk size parameter set to 4 KB, only achieves a 1% reduction.",
                "The reason, as shown earlier in Figure 2, is that with Rabin fingerprinting, the spans of data between two consecutive boundaries usually cross row boundaries.",
                "With the order of the rows changing in the second result and the Rabin fingerprints now spanning different rows, the algorithm is unable to detect significant similarity.",
                "The small gain seen is mostly for those single rows that are large enough to be broken into multiple chunks.",
                "SelectSort2, another micro-benchmark executed the same queries but increased the minimum chunk size of the Rabin fingerprinting algorithm.",
                "As can be seen in Table 2, even the small gain from the previous microbenchmark disappears as the minimum chunk size was greater than the average row size.",
                "While one can partially address these problems by dynamically varying the parameters of the Rabin fingerprinting algorithm, this can be computationally expensive, especially in the presence of changing workloads. 6.2 Application Benchmarks We ran the BBOARD benchmark described in Section 4.1.1 on two versions of Ganesh: the first with Rabin fingerprinting used as WWW 2007 / Track: Performance and Scalability Session: Scalable Systems for Dynamic Content 317 0 50 100 150 200 250 300 350 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Test Clients Requests/sec Native Ganesh 0.001 0.01 0.1 1 10 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Test Clients Avg.Resp.Time(sec) Native Ganesh Note Logscale (a) Throughput: Bidding Mix (b) Response Time: Bidding Mix 0 50 100 150 200 250 300 350 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Test Clients Requests/sec Native Ganesh 0.001 0.01 0.1 1 10 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Test Clients Avg.Resp.Time(sec) Native Ganesh Note Logscale (c) Throughput: Browsing Mix (d) Response Time: Browsing Mix Mean of three trials.",
                "The maximum standard deviation for throughput and response time was 2.2% and 11.8% of the corresponding mean.",
                "Figure 8: AUCTION Benchmark - Throughput and Average Response Time the chunking algorithm and the second with Ganeshs row-based algorithm.",
                "Rabins results for the Browsing Mix are normalized to Ganeshs results and presented in Figure 9.",
                "As Figure 9 (a) shows, at 5 Mb/s, independent of the test client configuration, Rabin significantly underperforms Ganesh.",
                "This happens because of a combination of two reasons.",
                "First, as outlined in Section 3.1, Rabin finds less similarity as it does not exploit the results structural information.",
                "Second, this benchmark contained some queries that generated large results.",
                "In this case, Rabin, with a small average chunk size, generated a large number of objects that evicted other useful data from the cache.",
                "In contrast, Ganesh was able to detect these large rows and correspondingly increase the size of the chunks.",
                "This was confirmed as cache statistics showed that Ganeshs hit ratio was roughly three time that of Rabin.",
                "Throughput measurements at 20 Mb/s were similar with the exception of Rabins performance with 400 test clients.",
                "In this case, Ganesh was not network limited and, in fact, the throughput was the same as 400 clients at 5 Mb/s.",
                "Rabin, however, took advantage of the bandwidth increase from 5 to 20 Mb/s to deliver a slightly better performance.",
                "At 100 Mb/s, Rabins throughput was almost similar to Ganesh as bandwidth was no longer a bottleneck.",
                "The normalized response time, presented in Figure 9 (b), shows similar trends.",
                "At 5 and 20 Mb/s, the addition of test clients decreases the normalized response time as Ganeshs average response time increases faster than Rabins.",
                "However, at no point does Rabin outperform Ganesh.",
                "Note that at 400 and 800 clients at 100 Mb/s, Rabin does have a higher overhead even when it is not bandwidth constrained.",
                "As mentioned in Section 3.1, this is due to the fact that Rabin has to hash each ResultSet twice.",
                "The overhead disappears with 1200 and 1600 clients as the database CPU is saturated and limits the performance of both Ganesh and Rabin. 7.",
                "PROXY OVERHEAD In this section, we address the third question raised in Section 4: Is the overhead of Ganeshs proxy-based design acceptable?",
                "To answer this question, we concentrate on its performance at the higher bandwidths.",
                "Our evaluation in Section 5 showed that Ganesh, when compared to Native, can deliver a substantial throughput improvement at lower bandwidths.",
                "It is only at higher bandwidths that latency, measured by the average response time for a client request, and throughput, measured by the number of client requests that can be serviced per second, overheads would be visible.",
                "Looking at the Authoring mix of the original BBOARD benchmark, there are no visible gains from Ganesh at 100 Mb/s.",
                "Ganesh, however, still tracks Native in terms of throughput.",
                "While the average response time is higher for Ganesh, the absolute difference is in between 0.01 and 0.04 seconds and would be imperceptible to the end-user.",
                "The Browsing mix shows an even smaller difference in average response times.",
                "The results from the filter variant of the BBOARD benchmarks are similar.",
                "Even for the AUCTION benchmark, the difference between Native and Ganeshs response time at 100 Mb/s was never greater than 0.02 seconds.",
                "The only exception to the above results was seen in the filter variant of the BBOARD benchmark where Ganesh at 1600 test clients added 0.85 seconds to the average response time.",
                "Thus, even for much faster networks where the WAN link is not the bottleneck, Ganesh always delivers throughput equivalent to Native.",
                "While some extra latency is added by the proxy-based design, it is usually imperceptible. 8.",
                "RELATED WORK To the best of our knowledge, Ganesh is the first system that combines the use of hash-based techniques with caching of database results to improve throughput and response times for applications with dynamic content.",
                "We also believe that it is also the first system to demonstrate the benefits of using structural information for WWW 2007 / Track: Performance and Scalability Session: Scalable Systems for Dynamic Content 318 0.0 0.2 0.4 0.6 0.8 1.0 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Test Clients Norm.Throughput 31.8 3.8 2.8 2.3 23.8 32.8 5.8 3.6 1.8 2.1 1.1 1.0 0 5 10 15 20 25 30 35 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Test Clients Norm.ResponseTime (a) Normalized Throughput: Higher is better (b) Normalized Response Time: Higher is worse For throughput, a normalized result greater than 1 implies that Rabin is better, For response time, a normalized result greater than 1 implies that Ganesh is better.",
                "Mean of three trials.",
                "The maximum standard deviation for throughput and response time was 9.1% and 13.9% of the corresponding mean.",
                "Figure 9: Normalized Comparison of Ganesh vs. Rabin - BBOARD Browsing Mix detecting similarity.",
                "In this section, we first discuss alternative approaches to caching dynamic content and then examine other uses of hash-based primitives in distributed systems. 8.1 Caching Dynamic Content At the database layer, a number of systems have advocated middletier caching where parts of the database are replicated at the edge or server [3, 4, 20].",
                "These systems either cache entire tables in what is essentially a replicated database or use materialized views from previous query replies [19].",
                "They require tight integration with the back-end database to ensure a time bound on the propagation of updates.",
                "These systems are also usually targeted towards workloads that do not require strict consistency and can tolerate stale data.",
                "Further, unlike Ganesh, some of these mid-tier caching solutions [2, 3], suffer from the complexity of having to participate in query planing and distributed query processing.",
                "Gao et al. [15] propose using a distributed object replication architecture where the data stores consistency requirements are adapted on a per-application basis.",
                "These solutions require substantial developer resources and detailed understanding of the application being modified.",
                "While systems that attempt to automate the partitioning and replication of an applications database exist [34], they do not provide full transaction semantics.",
                "In comparison, Ganesh does not weaken any of the semantics provided by the underlying database.",
                "Recent work in the evaluation of edge caching options for dynamic web sites [38] has suggested that, without careful planning, employing complex offloading strategies can hurt performance.",
                "Instead, the work advocates for an architecture in which all tiers except the database should be offloaded to the edge.",
                "Our evaluation of Ganesh has shown that it would benefit these scenarios.",
                "To improve database scalability, C-JDBC [10], SSS [22], and Ganymed [28] also advocate the use of an interposition-based architecture to transparently cluster and replicate databases at the middleware level.",
                "The approaches of these architectures and Ganesh are complementary and they would benefit each other.",
                "Moving up to the presentation layer, there has been widespread adoption of fragment-based caching [14], which improves cache utilization by separately caching different parts of generated web pages.",
                "While fragment-based caching works at the edge, a recent proposal has proposed moving web page assembly to the clients to optimize content delivery [31].",
                "While Ganesh is not used at the presentation layer, the same principles have been applied in Duplicate Transfer Detection [25] to increase web cache efficiency as well as for web access across bandwidth limited links [33]. 8.2 Hash-based Systems The past few years have seen the emergence of many systems that exploit hash-based techniques.",
                "At the heart of all these systems is the idea of detecting similarity in data without requiring interpretation of that data.",
                "This simple yet elegant idea relies on cryptographic hashing, as discussed earlier in Section 2.",
                "Successful applications of this idea span a wide range of storage systems.",
                "Examples include peer-to-peer backup of personal computing files [11], storage-efficient archiving of data [29], and finding similar files [21].",
                "Spring and Wetherall [35] apply similar principles at the network level.",
                "Using synchronized caches at both ends of a network link, duplicated data is replaced by smaller tokens for transmission and then restored at the remote end.",
                "This and other hash-based systems such as the CASPER [37] and LBFS [26] filesystems, and Layer-2 bandwidth optimizers such as Riverbed and Peribit use Rabin fingerprinting [30] to discover spans of commonality in data.",
                "This approach is especially useful when data items are modified in-place through insertions, deletions, and updates.",
                "However, as Section 6 shows, the performance of this technique can show a dramatic drop in the presence of data reordering.",
                "Ganesh instead uses row boundaries as dividers for detecting similarity.",
                "The most aggressive use of hash-based techniques is by systems that use hashes as the primary identifiers for objects in persistent storage.",
                "Storage systems such as CFS [12] and PAST [13] that have been built using distributed hash tables fall into this category.",
                "Single Instance Storage [6] and Venti [29] are other examples of such systems.",
                "As discussed in Section 2.2, the use of cryptographic hashes for addressing persistent data represents a deeper level of faith in their collision-resistance than that assumed by Ganesh.",
                "If time reveals shortcomings in the hash algorithm, the effort involved in correcting the flaw is much greater.",
                "In Ganesh, it is merely a matter of replacing the hash algorithm. 9.",
                "CONCLUSION The growing use of dynamic web content generated from relational databases places increased demands on WAN bandwidth.",
                "Traditional caching solutions for bandwidth and latency reduction are often ineffective for such content.",
                "This paper shows that the impact of WAN accesses to databases can be substantially reduced through the Ganesh architecture without any compromise of the databases strict consistency semantics.",
                "The essence of the Ganesh architecture is the use of computation at the edges to reduce communication through the Internet.",
                "Ganesh is able to use cryptographic hashes to detect similarity with previous results and send WWW 2007 / Track: Performance and Scalability Session: Scalable Systems for Dynamic Content 319 compact recipes of results rather than full results.",
                "Our design uses interposition to achieve complete transparency: clients, application servers, and database servers are all unaware of Ganeshs presence and require no modification.",
                "Our experimental evaluation confirms that Ganesh, while conceptually simple, can be highly effective in improving throughput and response time.",
                "Our results also confirm that exploiting the structure present in database results to detect similarity is crucial to this performance improvement. 10.",
                "REFERENCES [1] AKELLA, A., SESHAN, S., AND SHAIKH, A.",
                "An empirical evaluation of wide-area internet bottlenecks.",
                "In Proc. 3rd ACM SIGCOMM Conference on Internet Measurement (Miami Beach, FL, USA, Oct. 2003), pp. 101-114. [2] ALTINEL, M., BORNH ¨OVD, C., KRISHNAMURTHY, S., MOHAN, C., PIRAHESH, H., AND REINWALD, B. Cache tables: Paving the way for an adaptive database cache.",
                "In Proc. of 29th VLDB (Berlin, Germany, 2003), pp. 718-729. [3] ALTINEL, M., LUO, Q., KRISHNAMURTHY, S., MOHAN, C., PIRAHESH, H., LINDSAY, B. G., WOO, H., AND BROWN, L. Dbcache: Database caching for web application servers.",
                "In Proc. 2002 ACM SIGMOD (2002), pp. 612-612. [4] AMIRI, K., PARK, S., TEWARI, R., AND PADMANABHAN, S. Dbproxy: A dynamic data cache for web applications.",
                "In Proc.",
                "IEEE International Conference on Data Engineering (ICDE) (Mar. 2003). [5] BLACK, J. Compare-by-hash: A reasoned analysis.",
                "In Proc. 2006 USENIX Annual Technical Conference (Boston, MA, May 2006), pp. 85-90. [6] BOLOSKY, W. J., CORBIN, S., GOEBEL, D., , AND DOUCEUR, J. R. Single instance storage in windows 2000.",
                "In Proc. 4th USENIX Windows Systems Symposium (Seattle, WA, Aug. 2000), pp. 13-24. [7] BREWER, E. A.",
                "Lessons from giant-scale services.",
                "IEEE Internet Computing 5, 4 (2001), 46-55. [8] BRODER, A., GLASSMAN, S., MANASSE, M., AND ZWEIG, G. Syntactic clustering of the web.",
                "In Proc. 6th International WWW Conference (1997). [9] CECCHET, E., CHANDA, A., ELNIKETY, S., MARGUERITE, J., AND ZWAENEPOEL, W. Performance comparison of middleware architectures for generating dynamic web content.",
                "In Proc.",
                "Fourth ACM/IFIP/USENIX International Middleware Conference (Rio de Janeiro, Brazil, June 2003). [10] CECCHET, E., MARGUERITE, J., AND ZWAENEPOEL, W. C-JDBC: Flexible database clustering middleware.",
                "In Proc. 2004 USENIX Annual Technical Conference (Boston, MA, June 2004). [11] COX, L. P., MURRAY, C. D., AND NOBLE, B. D. Pastiche: Making backup cheap and easy.",
                "In OSDI: Symposium on Operating Systems Design and Implementation (2002). [12] DABEK, F., KAASHOEK, M. F., KARGER, D., MORRIS, R., AND STOICA, I. Wide-area cooperative storage with CFS.",
                "In 18th ACM Symposium on Operating Systems Principles (Banff, Canada, Oct. 2001). [13] DRUSCHEL, P., AND ROWSTRON, A.",
                "PAST: A large-scale, persistent peer-to-peer storage utility.",
                "In HotOS VIII (Schloss Elmau, Germany, May 2001), pp. 75-80. [14] Edge side includes. http://www.esi.org. [15] GAO, L., DAHLIN, M., NAYATE, A., ZHENG, J., AND IYENGAR, A.",
                "Application specific data replication for edge services.",
                "In WWW 03: Proc.",
                "Twelfth International Conference on World Wide Web (2003), pp. 449-460. [16] HEMMINGER, S. Netem - emulating real networks in the lab.",
                "In Proc. 2005 Linux Conference Australia (Canberra, Australia, Apr. 2005). [17] HENSON, V. An analysis of compare-by-hash.",
                "In Proc. 9th Workshop on Hot Topics in Operating Systems (HotOS IX) (May 2003), pp. 13-18. [18] Jmob benchmarks. http://jmob.objectweb.org/. [19] LABRINIDIS, A., AND ROUSSOPOULOS, N. Balancing performance and data freshness in web database servers.",
                "In Proc. 29th VLDB Conference (Sept. 2003). [20] LARSON, P.-A., GOLDSTEIN, J., AND ZHOU, J. Transparent mid-tier database caching in sql server.",
                "In Proc. 2003 ACM SIGMOD (2003), pp. 661-661. [21] MANBER, U.",
                "Finding similar files in a large file system.",
                "In Proc.",
                "USENIX Winter 1994 Technical Conference (San Fransisco, CA, 17-21 1994), pp. 1-10. [22] MANJHI, A., AILAMAKI, A., MAGGS, B. M., MOWRY, T. C., OLSTON, C., AND TOMASIC, A.",
                "Simultaneous scalability and security for data-intensive web applications.",
                "In Proc. 2006 ACM SIGMOD (June 2006), pp. 241-252. [23] MENEZES, A. J., VANSTONE, S. A., AND OORSCHOT, P. C. V. Handbook of Applied Cryptography.",
                "CRC Press, 1996. [24] MILLER, R. B.",
                "Response time in man-computer conversational transactions.",
                "In Proc.",
                "AFIPS Fall Joint Computer Conference (1968), pp. 267-277. [25] MOGUL, J. C., CHAN, Y. M., AND KELLY, T. Design, implementation, and evaluation of duplicate transfer detection in http.",
                "In Proc.",
                "First Symposium on Networked Systems Design and Implementation (San Francisco, CA, Mar. 2004). [26] MUTHITACHAROEN, A., CHEN, B., AND MAZIERES, D. A low-bandwidth network file system.",
                "In Proc. 18th ACM Symposium on Operating Systems Principles (Banff, Canada, Oct. 2001). [27] PFEIFER, D., AND JAKSCHITSCH, H. Method-based caching in multi-tiered server applications.",
                "In Proc.",
                "Fifth International Symposium on Distributed Objects and Applications (Catania, Sicily, Italy, Nov. 2003). [28] PLATTNER, C., AND ALONSO, G. Ganymed: Scalable replication for transactional web applications.",
                "In Proc. 5th ACM/IFIP/USENIX International Conference on Middleware (2004), pp. 155-174. [29] QUINLAN, S., AND DORWARD, S. Venti: A new approach to archival storage.",
                "In Proc.",
                "FAST 2002 Conference on File and Storage Technologies (2002). [30] RABIN, M. Fingerprinting by random polynomials.",
                "In Harvard University Center for Research in Computing Technology Technical Report TR-15-81 (1981). [31] RABINOVICH, M., XIAO, Z., DOUGLIS, F., AND KALMANEK, C. Moving edge side includes to the real edge - the clients.",
                "In Proc. 4th USENIX Symposium on Internet Technologies and Systems (Seattle, WA, Mar. 2003). [32] REESE, G. Database Programming with JDBC and Java, 1st ed.",
                "OReilly, June 1997. [33] RHEA, S., LIANG, K., AND BREWER, E. Value-based web caching.",
                "In Proc.",
                "Twelfth International World Wide Web Conference (May 2003). [34] SIVASUBRAMANIAN, S., ALONSO, G., PIERRE, G., AND VAN STEEN, M. Globedb: Autonomic data replication for web applications.",
                "In WWW 05: Proc. 14th International World-Wide Web conference (May 2005). [35] SPRING, N. T., AND WETHERALL, D. A protocol-independent technique for eliminating redundant network traffic.",
                "In Proc. of ACM SIGCOMM (Aug. 2000). [36] TOLIA, N., HARKES, J., KOZUCH, M., AND SATYANARAYANAN, M. Integrating portable and distributed storage.",
                "In Proc. 3rd USENIX Conference on File and Storage Technologies (San Francisco, CA, Mar. 2004). [37] TOLIA, N., KOZUCH, M., SATYANARAYANAN, M., KARP, B., PERRIG, A., AND BRESSOUD, T. Opportunistic use of content addressable storage for distributed file systems.",
                "In Proc. 2003 USENIX Annual Technical Conference (San Antonio, TX, June 2003), pp. 127-140. [38] YUAN, C., CHEN, Y., AND ZHANG, Z.",
                "Evaluation of edge caching/offloading for dynamic content delivery.",
                "In WWW 03: Proc.",
                "Twelfth International Conference on World Wide Web (2003), pp. 461-471.",
                "WWW 2007 / Track: Performance and Scalability Session: Scalable Systems for Dynamic Content 320"
            ],
            "original_annotated_samples": [
                "WWW 2007 / Track: Performance and Scalability Session: Scalable Systems for Dynamic Content 313 Object Output Stream Convert <br>resultset object</br> Input Stream Convert ResultSet All Data Recipe ResultSet All Data ResultSet Network Ganesh Proxy Ganesh JDBC Driver Result Set Recipe Result Set Yes Yes No No GaneshInputStream GaneshOutputStream Figure 4: Dataflow for Result Handling 3.4 Encoding and Decoding Results The Ganesh proxy receives database output as Java objects from the native JDBC driver.",
                "If a <br>resultset object</br> is found, it is shrunk as discussed below.",
                "Once the transformation is complete, the fully reconstructed <br>resultset object</br> is passed up to the application. 4."
            ],
            "translated_annotated_samples": [
                "El proxy Ganesh recibe la salida de la base de datos como objetos Java del controlador JDBC nativo.",
                "Si se encuentra un <br>objeto ResultSet</br>, se reduce como se discute a continuación.",
                "Una vez que la transformación esté completa, el <br>objeto ResultSet</br> completamente reconstruido se pasa a la aplicación. 4."
            ],
            "translated_text": "Conservación de la consistencia en el almacenamiento en caché de contenido dinámico de bases de datos∗ Niraj Tolia y M. Satyanarayanan Universidad Carnegie Mellon {ntolia,satya}@cs.cmu.edu RESUMEN Con el creciente uso de contenido web dinámico generado a partir de bases de datos relacionales, las soluciones de almacenamiento en caché tradicionales para mejorar el rendimiento y la latencia son ineficaces. Describimos una capa de middleware llamada Ganesh que reduce el volumen de datos transmitidos sin interpretación semántica de consultas o resultados. Se logra esta reducción mediante el uso de hash criptográficos para detectar similitudes con resultados anteriores. Estos beneficios no requieren ningún compromiso con la semántica de consistencia estricta proporcionada por la base de datos del servidor. Además, Ganesh no requiere modificaciones en aplicaciones, servidores web o servidores de bases de datos, y funciona con aplicaciones y bases de datos de código cerrado. Usando dos puntos de referencia representativos de sitios web dinámicos, las mediciones de nuestro prototipo muestran que puede aumentar el rendimiento de extremo a extremo hasta en un factor de dos para aplicaciones no intensivas en datos y hasta en un factor de diez para las intensivas en datos. Categorías y Descriptores de Asignaturas C.2.4 [Redes de Computadoras-Comunicación]: Sistemas Distribuidos; H.2.4 [Gestión de Bases de Datos]: Términos Generales de Sistemas de Diseño, Rendimiento 1. INTRODUCCIÓN Una fracción creciente del contenido web se genera dinámicamente a partir de bases de datos relacionales en el backend. Incluso cuando el contenido de la base de datos permanece sin cambios, la localidad temporal de acceso no puede ser explotada porque el contenido dinámico no es almacenable en caché por los navegadores web o por servidores de almacenamiento en caché intermedios como los espejos de Akamai. En una arquitectura multinivel, cada solicitud web puede tensionar el enlace WAN entre el servidor web y la base de datos. Esto provoca que la experiencia del usuario sea altamente variable porque no hay almacenamiento en caché para aislar al cliente de cargas repentinas. Los intentos previos de almacenar en caché contenido dinámico de bases de datos generalmente han debilitado la semántica transaccional [3, 4] o han requerido modificaciones en la aplicación [15, 34]. Informamos sobre una nueva solución que toma la forma de una capa intermedia de middleware independiente de la base de datos llamada Ganesh. Ganesh no hace ningún esfuerzo por interpretar semánticamente el contenido de las consultas o sus resultados. En cambio, se basa exclusivamente en el hash criptográfico para detectar similitudes con resultados anteriores. La detección de similitud basada en hash ha sido cada vez más utilizada en sistemas de archivos distribuidos [26, 36, 37] para mejorar el rendimiento en redes de baja capacidad de ancho de banda. Sin embargo, estas técnicas no se han utilizado para bases de datos relacionales. A diferencia de enfoques anteriores que utilizan métodos genéricos para detectar similitud, Ganesh explota la estructura de los resultados de la base de datos relacional para lograr una mejora superior en el rendimiento. Uno se enfrenta al menos a tres desafíos al aplicar la detección de similitud basada en hash a las bases de datos de back-end. Primero, el trabajo previo en este ámbito ha considerado tradicionalmente el contenido de almacenamiento como bolsas de bits no interpretadas y sin estructura interna. Esto permite que las técnicas basadas en hash operen en largas y contiguas secuencias de datos para lograr la máxima efectividad. Por el contrario, las bases de datos relacionales tienen una estructura interna compleja que puede no ser tan propicia para la detección de similitudes basada en hash. Segundo, las bases de datos relacionales tienen restricciones de integridad y consistencia muy estrictas que no deben comprometerse por el uso de técnicas basadas en hash. Tercero, el código fuente de las bases de datos comerciales generalmente no está disponible. Esto contrasta con trabajos anteriores que presumían la disponibilidad del código fuente. Nuestros experimentos muestran que Ganesh, aunque conceptualmente simple, puede mejorar significativamente el rendimiento en anchos de banda representativos del Internet comercial actual. En los modelos de referencia de aplicaciones web multinivel, la mejora en el rendimiento fue de hasta diez veces para cargas de trabajo intensivas en datos. Para cargas de trabajo que no eran intensivas en datos, se observaron mejoras en el rendimiento de hasta el doble. Incluso cuando el ancho de banda no era una limitación, Ganesh tenía un bajo sobrecosto y no afectaba el rendimiento. Nuestros experimentos también confirman que aprovechar la estructura presente en los resultados de la base de datos es crucial para esta mejora en el rendimiento. Antecedentes 2.1 Generación de Contenido Dinámico A medida que la World Wide Web ha crecido, muchos sitios web han descentralizado sus datos y funcionalidades al llevarlos a los extremos de Internet. Hoy en día, los sistemas de comercio electrónico a menudo utilizan una arquitectura de tres niveles que consta de un servidor web de front-end, un servidor de aplicaciones y un servidor de base de datos de back-end. La Figura 1 ilustra esta arquitectura. Los dos primeros niveles se pueden replicar cerca de una concentración de clientes en el borde de Internet. Esto mejora la experiencia del usuario al reducir la latencia de extremo a extremo y disminuir la exposición al congestionamiento del tráfico de la columna vertebral. También puede aumentar la disponibilidad y escalabilidad de los servicios web. El contenido que se genera dinámicamente desde la base de datos del servidor no puede ser almacenado en caché en los dos primeros niveles. Si bien las bases de datos pueden replicarse fácilmente en una LAN, esto es inviable en una WAN debido a la difícil tarea de proporcionar simultáneamente una consistencia sólida, disponibilidad y tolerancia a particiones de red [7]. Como resultado, las bases de datos tienden a ser centralizadas para cumplir con los fuertes requisitos de consistencia de muchas aplicaciones de comercio electrónico como la banca, las finanzas y la venta al por menor en línea [38]. Por lo tanto, la base de datos del back-end suele estar ubicada lejos de muchos conjuntos de nodos de primer y segundo nivel [2]. En ausencia de almacenamiento en caché y replicación, el ancho de banda de la WAN puede convertirse fácilmente en un factor limitante en el rendimiento y la escalabilidad de aplicaciones intensivas en datos. El enfoque de Ganesh en los sistemas basados en hash es la transmisión eficiente de resultados al descubrir similitudes con los resultados de consultas anteriores. Dado que las consultas SQL pueden generar resultados grandes, las técnicas basadas en hash se prestan bien al problema de transferir eficientemente estos grandes resultados a través de enlaces con ancho de banda limitado. El uso de técnicas basadas en hash para reducir el volumen de datos transmitidos ha surgido como un tema común en muchos sistemas de almacenamiento recientes, como se discute en la Sección 8.2. Estas técnicas se basan en algunas suposiciones básicas. Se asume que las funciones hash criptográficas son resistentes a colisiones. En otras palabras, es computacionalmente intratable encontrar dos entradas que se hash a la misma salida. Las funciones también se asumen como unidireccionales; es decir, encontrar una entrada que resulte en una salida específica es computacionalmente inviable. Menezes et al. [23] proporcionan más detalles sobre estas suposiciones. Las suposiciones anteriores permiten a los sistemas basados en hash asumir que no se producen colisiones. Por lo tanto, pueden tratar el hash de un elemento de datos como su identificador único. Una colección de elementos de datos se convierte efectivamente en direccionable por contenido, permitiendo que un hash pequeño funcione como una palabra de código para un elemento de datos mucho más grande en almacenamiento permanente o transmisión en red. La suposición de que las colisiones son tan raras que prácticamente no existen ha sido cuestionada recientemente [17]. Sin embargo, como explicó Black [5], creemos que estos problemas no son una preocupación para Ganesh. Toda comunicación es entre partes confiables del sistema y un adversario no tiene forma de obligar a Ganesh a aceptar datos inválidos. Además, Ganesh no depende críticamente de ninguna función hash específica. Si bien actualmente usamos SHA-1, reemplazarlo con una función hash diferente sería sencillo. No habría impacto en el rendimiento con funciones hash más fuertes (por ejemplo, SHA256) solo añade unos pocos bytes adicionales y los hashes generados siguen siendo órdenes de magnitud más pequeños que los elementos de datos que representan. No es necesario volver a almacenar permanentemente ya que Ganesh solo utiliza el hash en datos volátiles. 3. DISEÑO E IMPLEMENTACIÓN Ganesh explota la redundancia en el flujo de resultados para evitar transmitir fragmentos de resultados que ya están presentes en el sitio de la consulta. La redundancia puede surgir de forma natural de muchas maneras diferentes. Por ejemplo, una consulta repetida después de un cierto intervalo puede devolver un resultado diferente debido a actualizaciones en la base de datos; sin embargo, puede haber una significativa similitud entre los dos resultados. Como otro ejemplo, un usuario que está refinando una búsqueda puede generar una secuencia de consultas con resultados superpuestos. Cuando Ganesh detecta redundancia, suprime la transmisión de los fragmentos de resultado correspondientes. En cambio, transmite un resumen mucho más pequeño de esos fragmentos y permite que el sitio de consulta reconstruya el resultado a través de la búsqueda de hash en una caché de resultados anteriores. De hecho, Ganesh utiliza la computación en los bordes para reducir la comunicación por Internet. Nuestra descripción de Ganesh se centra en cuatro aspectos. Primero explicamos nuestro enfoque para detectar similitud en los resultados de la consulta. A continuación, discutimos cómo la arquitectura Ganesh es completamente invisible para todos los componentes de un sistema de múltiples niveles. Luego describimos el enfoque basado en proxy de Ganesh y el flujo de datos para detectar similitudes. 3.1 Detectar similitud Una de las decisiones clave de diseño en Ganesh es cómo se detecta la similitud. Hay muchas formas potenciales de descomponer un resultado en fragmentos.  I the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the thees I,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,, Encontrar esta descomposición óptima es un problema difícil debido al amplio espacio de posibilidades y porque la elección óptima depende de muchos factores, como el contenido del resultado de las consultas, el historial de resultados recientes y el algoritmo de gestión de caché. Cuando un objeto es opaco, el uso de huellas digitales de Rabin [8, 30] para detectar datos comunes entre dos objetos ha sido demostrado con éxito en el pasado por sistemas como LBFS [26] y CASPER [37]. El fingerprinting de Rabin utiliza una ventana deslizante sobre los datos para calcular un hash rodante. Suponiendo que la función hash está distribuida uniformemente, un límite de fragmento se define cuando los bits de orden inferior del valor hash son iguales a algún valor predeterminado. El número de bits de orden inferior utilizados define el tamaño promedio del fragmento. Estos fragmentos subdivididos del objeto se convierten en la unidad de comparación para detectar similitudes entre diferentes objetos. Dado que las ubicaciones de los límites encontrados mediante el uso de las huellas de Rabin están determinadas de manera estocástica, generalmente no logran alinearse con ninguna propiedad estructural de los datos subyacentes. Por lo tanto, el algoritmo maneja bien las actualizaciones en su lugar, inserciones y eliminaciones. Sin embargo, tiene un rendimiento deficiente en presencia de cualquier reordenamiento de datos. La Figura 2 muestra un ejemplo donde dos resultados, A y B, que constan de tres filas, tienen los mismos datos pero diferentes atributos de ordenamiento. En el caso extremo, la huella digital de Rabin podría no ser capaz de encontrar datos similares debido a la forma en que detecta los límites de los fragmentos. Afortunadamente, Ganesh puede utilizar conocimientos específicos del dominio para una detección de límites más precisa. La información que explotamos es que el resultado de una consulta refleja la estructura de una base de datos relacional donde todos los datos están organizados en tablas y filas. Por lo tanto, es sencillo verificar la similitud con resultados anteriores en dos niveles de granularidad: primero el resultado completo y luego las filas individuales. El final de una fila en un resultado sirve como un límite natural de fragmento. Es importante tener en cuenta que el uso de la estructura tabular en los resultados solo implica una interpretación superficial de los datos. Ganesh no realiza ninguna interpretación semántica más profunda, como comprender tipos de datos, esquemas de resultados o restricciones de integridad. Ajustar la huella digital de Rabin para una carga de trabajo también puede ser difícil. Si el tamaño promedio de los fragmentos es demasiado grande, los fragmentos pueden abarcar varias filas de resultados. Sin embargo, seleccionar un tamaño de fragmento promedio más pequeño aumenta la cantidad de metadatos necesarios para describir los resultados. Esto, a su vez, disminuiría los ahorros obtenidos mediante su uso. El fingerprinting de Rabin también requiere dos pasadas computacionalmente costosas sobre los datos: una vez para determinar los límites de los fragmentos y otra vez para generar hashes criptográficos para los fragmentos. Ganesh solo necesita un único pase para la generación de hash, ya que los límites de los fragmentos son proporcionados por la estructura natural de los datos. La comparación de rendimiento en la Sección 6 muestra que el algoritmo basado en filas de Ganesh supera al fingerprinting de Rabin. Dado que trabajos anteriores ya han demostrado que la huella digital de Rabin funciona mejor que gzip [26], no comparamos a Ganesh con algoritmos de compresión en este artículo. 3.2 Transparencia El factor clave que influyó en nuestro diseño fue la necesidad de que Ganesh fuera completamente transparente para todos los componentes de un sistema típico de comercio electrónico: servidores web, servidores de aplicaciones y servidores de bases de datos. Sin esto, Ganesh tiene pocas posibilidades de tener un impacto significativo en el mundo real. Requerir modificaciones en cualquiera de los componentes mencionados aumentaría la barrera de entrada de Ganesh en un sistema existente, y por lo tanto reduciría sus posibilidades de adopción. Preservar la transparencia se simplifica por el hecho de que Ganesh es simplemente una mejora de rendimiento, no una mejora de funcionalidad o usabilidad. Elegimos la interposición de agentes como enfoque arquitectónico para lograr nuestro objetivo. Este enfoque se basa en la existencia de una interfaz de programación compacta que ya es ampliamente utilizada por el software objetivo. También se basa en un mecanismo para agregar fácilmente nuevo código sin interrumpir la estructura de módulos existente. Estas condiciones se cumplen fácilmente en nuestro contexto debido a la popularidad de Java como el lenguaje de programación para sistemas de comercio electrónico. La API de Conectividad de Base de Datos de Java (JDBC) [32] permite a las aplicaciones de Java acceder a una amplia variedad de bases de datos e incluso a otros repositorios de datos tabulares como archivos planos. El acceso a estas fuentes de datos es proporcionado por controladores JDBC que traducen entre la API JDBC y el mecanismo de comunicación de la base de datos. La figura 3(a) muestra cómo se utiliza típicamente JDBC en una aplicación. Dado que la interfaz JDBC está estandarizada, se puede sustituir un controlador JDBC por otro sin necesidad de de modificar la aplicación. El controlador JDBC se convierte así en el módulo natural para aprovechar la interposición de código. Como se muestra en la Figura 3(b), el controlador JDBC nativo es reemplazado por un controlador JDBC Ganesh que presenta la misma interfaz estandarizada. El controlador Ganesh mantiene una caché en memoria de fragmentos de resultados de consultas anteriores y realiza el reensamblaje de resultados. En la base de datos, agregamos un nuevo proceso llamado el proxy Ganesh. Este proxy, que puede ser compartido por múltiples nodos front-end, consta de dos partes: código para detectar similitud en fragmentos de resultados y el controlador JDBC nativo original que se comunica con la base de datos. El uso de un proxy en la base de datos hace que Ganesh sea independiente de la base de datos y simplifica la creación de prototipos y experimentación. Ganesh es capaz de trabajar con una amplia gama de bases de datos y aplicaciones, sin necesidad de realizar modificaciones en ninguna de ellas. 3.3 Caché basada en proxy El controlador JDBC nativo mostrado en la Figura 3(a) es un componente de código ligero suministrado por el proveedor de la base de datos. Su función principal es mediar la comunicación entre la aplicación y la base de datos remota. Reenvía consultas, almacena resultados completos y responde a solicitudes de la aplicación para ver partes de los resultados. El controlador JDBC de Ganesh mostrado en la Figura 3(b) presenta a la aplicación una interfaz idéntica a la proporcionada por el controlador nativo. Proporciona la capacidad de reconstruir resultados a partir de descripciones compactas basadas en hash enviadas por el proxy. Para realizar esta reconstrucción, el controlador mantiene una caché en memoria de los resultados recibidos recientemente. Esta caché solo se utiliza como fuente de fragmentos de resultados en la reconstrucción de resultados. El conductor Ganesh o el proxy no intentan rastrear las actualizaciones de la base de datos. La falta de consistencia en la caché no afecta a la corrección, ya que la descripción de los resultados siempre se obtiene del proxy; en el peor de los casos, no habrá beneficio de rendimiento al usar Ganesh. Los datos obsoletos simplemente se eliminarán de la caché con el tiempo. El proxy de Ganesh accede a la base de datos a través del controlador JDBC nativo, que permanece sin cambios entre las Figuras 3(a) y (b). La base de datos está completamente ajena a la existencia del proxy. El proxy no examina ninguna consulta recibida del controlador Ganesh, sino que las pasa al controlador nativo. En cambio, el proxy es responsable de inspeccionar la salida de la base de datos recibida del controlador nativo, detectar resultados similares y generar codificaciones basadas en hash de estos resultados siempre que se encuentre suficiente similitud. Si bien esta arquitectura no disminuye la carga en una base de datos, como se mencionó anteriormente en la Sección 2.1, es mucho más fácil replicar bases de datos para escalabilidad en una LAN que en una WAN. Para generar una codificación basada en hash, el proxy debe estar al tanto de qué fragmentos de resultados están disponibles en la caché de controladores de Ganesh. Un enfoque es ser optimista y asumir que todos los fragmentos de resultados están disponibles. Esto resultará en la transmisión inicial más pequeña posible de un resultado. Sin embargo, en casos donde hay poca superposición con resultados anteriores, el controlador Ganesh tendrá que realizar muchas llamadas al proxy durante la reconstrucción para recuperar fragmentos de resultados faltantes. Para evitar esta situación, el proxy sigue de manera flexible el estado de la caché de controladores de Ganesh. Dado que ambos componentes están bajo nuestro control, es relativamente sencillo hacer esto sin recurrir a técnicas de caja gris o comunicación explícita para mantener la coherencia de la caché. En cambio, el proxy simula el algoritmo de gestión de caché de controladores de Ganesh y lo utiliza para mantener una lista de hashes para los cuales es probable que el controlador de Ganesh posea los fragmentos de resultado. En caso de desviación de seguimiento, no habrá pérdida de corrección, pero habrá retrasos adicionales en el viaje de ida y vuelta para recuperar los fragmentos faltantes. Si el cliente detecta la pérdida de sincronización con el proxy, puede pedirle al proxy que restablezca el estado compartido entre ellos. También hay que tener en cuenta que el proxy no necesita guardar los fragmentos de resultado en sí, solo sus hashes. Esto permite que el proxy siga siendo escalable incluso cuando es compartido por muchos nodos front-end. El proxy Ganesh recibe la salida de la base de datos como objetos Java del controlador JDBC nativo. Examina esta salida para ver si está presente un objeto Java del tipo ResultSet. La interfaz JDBC utiliza este tipo de dato para almacenar los resultados de las consultas a la base de datos. Si se encuentra un <br>objeto ResultSet</br>, se reduce como se discute a continuación. Todos los demás objetos de Java se pasan sin modificar. Como se discute en la Sección 3.1, el proxy utiliza los límites de fila definidos en el ResultSet para dividirlo en fragmentos que consisten en filas de resultado individuales. Todos los objetos ResultSet se convierten en objetos de un nuevo tipo llamado RecipeResultSet. Utilizamos el término receta para esta descripción compacta de un resultado de base de datos debido a su similitud con una receta de archivo en el sistema de archivos CASPER [37]. La conversión reemplaza cada fragmento de resultado que probablemente esté presente en la caché de controladores de Ganesh por un hash SHA-1 de ese fragmento. Los fragmentos de resultados previamente no vistos se conservan textualmente. El proxy también retiene los hashes de los nuevos fragmentos de resultados, ya que estarán presentes en la caché de los controladores en el futuro. Ten en cuenta que el proxy solo almacena en caché los hashes de los fragmentos de resultados y no almacena en caché las recetas. El proxy construye un RecipeResultSet verificando la similitud en todo el resultado y luego a nivel de fila. Si se predice que todo el resultado estará presente en la caché de los controladores de Ganesh, el RecipeResultSet será simplemente un único hash de todo el resultado. De lo contrario, contiene hashes para aquellas filas que se predice que están presentes en esa caché; todas las demás filas se conservan textualmente. Si el proxy estima un ahorro de espacio general, transmitirá el RecipeResultSet. De lo contrario, se transmite el ResultSet original. Los objetos RecipeResultSet son transformados de vuelta en objetos ResultSet por el controlador Ganesh. La Figura 4 ilustra el manejo de ResultSet en ambos extremos. Cada hash SHA-1 encontrado en un RecipeResultSet se busca en la caché local de fragmentos de resultados. En caso de acierto, el hash es reemplazado por el fragmento correspondiente. En caso de error, el conductor contacta al proxy de Ganesh para recuperar el fragmento. Todos los fragmentos de resultados previamente no vistos que fueron retenidos textualmente por el proxy se hasheado y se han añadido a la caché de resultados. Debería haber muy pocos fallos si el proxy ha seguido con precisión el estado de la caché de controladores de Ganesh. Una optimización futura sería agrupar la obtención de fragmentos faltantes. Esto sería valioso cuando hay muchos pequeños fragmentos faltantes en una WAN de alta latencia. Una vez que la transformación esté completa, el <br>objeto ResultSet</br> completamente reconstruido se pasa a la aplicación. 4. VALIDACIÓN EXPERIMENTAL Tres preguntas surgen de los objetivos y diseño de Ganesh: • Primero, ¿se puede mejorar significativamente el rendimiento al explotar la similitud entre los resultados de la base de datos? Detalles del conjunto de datos de referencia 500,000 usuarios, 12,000 historias BBOARD 2.0 GB 3,298,000 comentarios SUBASTA 1.3 GB 1,000,000 usuarios, 34,000 elementos Tabla 1: Detalles del conjunto de datos de referencia • En segundo lugar, ¿qué tan importante es la detección de similitud estructural de Ganesh en comparación con la detección de similitud de la huella digital de Rabin? • En tercer lugar, ¿es aceptable la sobrecarga del diseño basado en proxy? Nuestra evaluación responde a estas preguntas a través de experimentos controlados con el prototipo Ganesh. Esta sección describe los puntos de referencia utilizados, nuestro procedimiento de evaluación y la configuración experimental. Los resultados de los experimentos se presentan en las Secciones 5, 6 y 7. 4.1 Puntos de referencia Nuestra evaluación se basa en dos puntos de referencia [18] que han sido ampliamente utilizados por otros investigadores para evaluar varios aspectos de arquitecturas multi-tier [27] y de comercio electrónico [9]. El primer punto de referencia, BBOARD, está modelado según Slashdot, un sitio de noticias orientado a la tecnología. El segundo punto de referencia, AUCTION, está modelado según eBay, un sitio de subastas en línea. En ambos puntos de referencia, la mayoría del contenido se genera dinámicamente a partir de la información almacenada en una base de datos. Los detalles de los conjuntos de datos utilizados se pueden encontrar en la Tabla 1. 4.1.1 El Benchmark BBOARD El benchmark BBOARD, también conocido como RUBBoS [18], modela Slashdot, un popular sitio web orientado a la tecnología. Slashdot recopila enlaces a noticias y otros temas de interés encontrados en otros lugares de la web. El sitio también funciona como un tablón de anuncios al permitir a los usuarios comentar en las historias publicadas en forma de conversación en hilos. No es raro que una historia recopile cientos de comentarios en cuestión de horas. El benchmark BBOARD es similar al sitio y modela las actividades de un usuario, incluyendo operaciones de solo lectura como navegar por las historias del día, explorar categorías de historias y ver comentarios, así como operaciones de escritura como registro de nuevos usuarios, agregar y moderar comentarios, y enviar historias. El benchmark consiste en tres fases diferentes: una fase de calentamiento corta, una fase de ejecución que representa el cuerpo principal de la carga de trabajo, y una fase de enfriamiento corta. En este documento solo informamos sobre los resultados de la fase de ejecución. La fase de calentamiento es importante para establecer el estado del sistema dinámico, pero las mediciones de esa fase no son significativas para nuestra evaluación. La fase de enfriamiento es únicamente para permitir que el punto de referencia se apague. Las fases de calentamiento, ejercicio y enfriamiento son de 2, 15 y 2 minutos respectivamente. El número de clientes simulados fue de 400, 800, 1200 y 1600. El punto de referencia está disponible en una versión de Java Servlets y PHP y tiene diferentes conjuntos de datos; evaluamos a Ganesh utilizando la versión de Java Servlets y el conjunto de datos Expandido. El benchmark BBOARD define dos cargas de trabajo diferentes. El primero, la mezcla de Autoría, consiste en un 70% de operaciones de solo lectura y un 30% de operaciones de lectura y escritura. El segundo, la mezcla de navegación, contiene solo operaciones de solo lectura y no actualiza la base de datos. 4.1.2 El Benchmark de SUBASTA El benchmark de SUBASTA, también conocido como RUBiS [18], modela eBay, el sitio de subastas en línea. El sitio web de eBay se utiliza para comprar y vender artículos a través de un formato de subasta. Las principales actividades de un usuario incluyen navegar, vender o pujar por artículos. Modelando las actividades en este sitio, este punto de referencia incluye actividades de solo lectura como navegar por artículos por categoría y por región, así como actividades de lectura-escritura como pujar por artículos, comprar y vender artículos, y dejar comentarios. Al igual que con BBOARD, el benchmark consiste en tres fases diferentes. Las fases de calentamiento, ejecución y enfriamiento para este experimento son de 1.5, 15 y 1 minutos respectivamente. Probamos Ganesh con cuatro configuraciones de clientes donde el número de clientes de prueba se estableció en 400, 800, 1200 y 1600. El punto de referencia está disponible en una versión de Enterprise Java Bean (EJB), Java Servlets y PHP y tiene diferentes conjuntos de datos; evaluamos Ganesh con la versión de Java Servlets y el conjunto de datos Expandido. El benchmark de SUBASTA define dos cargas de trabajo diferentes. El primero, la mezcla de Ofertas, consiste en un 70% de operaciones de solo lectura y un 30% de operaciones de lectura-escritura. El segundo, la mezcla de navegación, contiene solo operaciones de solo lectura y no actualiza la base de datos. 4.2 Procedimiento Experimental Ambos benchmarks involucran una carga de trabajo sintética de clientes accediendo a un servidor web. El número de clientes emulados es un parámetro experimental. Cada cliente emulado ejecuta una instancia del benchmark en su propio hilo, utilizando una matriz para hacer la transición entre diferentes estados del benchmark. La matriz define un modelo estocástico con probabilidades de transición entre los diferentes estados que representan las acciones típicas de los usuarios. Un ejemplo de transición es un usuario iniciando sesión en el sistema de SUBASTA y luego decidiendo si publicar un artículo en venta o pujar en subastas activas. Cada cliente también modela el tiempo de pensamiento del usuario entre las solicitudes. El tiempo de pensamiento se modela como una distribución exponencial con una media de 7 segundos. Evaluamos a Ganesh a lo largo de dos ejes: número de clientes y ancho de banda de la WAN. Las cargas más altas son especialmente útiles para comprender el rendimiento de Ganesh cuando la CPU o el disco del servidor de base de datos o del proxy son el factor limitante. Un estudio previo ha demostrado que aproximadamente el 50% de los cuellos de botella de Internet de gran área observados tenían un ancho de banda disponible inferior a 10 Mb/s [1]. Basándonos en este trabajo, enfocamos nuestra evaluación en el ancho de banda de la WAN de 5 Mb/s con una latencia de ida y vuelta de 66 ms, representativa de rutas de red severamente restringidas, y 20 Mb/s con una latencia de ida y vuelta de 33 ms, representativa de una ruta de red moderadamente restringida. También informamos sobre el rendimiento de Ganesh a 100 Mb/s sin agregar latencia de ida y vuelta. Este ancho de banda, representativo de una red sin restricciones, es especialmente útil para revelar cualquier sobrecarga potencial de Ganesh en situaciones donde el ancho de banda de la WAN no es el factor limitante. Para cada combinación de número de clientes y ancho de banda de WAN, medimos los resultados de las dos configuraciones enumeradas a continuación: • Nativa: Esta configuración corresponde a la Figura 3(a). El nativo evita la sobrecarga de Ganesh al usar un proxy y realizar la serialización de objetos Java. • Ganesh: Esta configuración corresponde a la Figura 3(b). Para un número dado de clientes y ancho de banda de WAN, comparar estos resultados con los resultados nativos correspondientes proporciona el beneficio de rendimiento debido al sistema de middleware Ganesh. La métrica utilizada para cuantificar la mejora en el rendimiento es el número de solicitudes de clientes que pueden ser atendidas por segundo. La métrica utilizada para cuantificar el rendimiento de Ganesh es el tiempo promedio de respuesta para una solicitud de cliente. Para todos los experimentos, el controlador Ganesh utilizado por el servidor de aplicaciones usó un tamaño de caché de 100,000 elementos. El proxy fue efectivo en rastrear el estado de la caché de los controladores Ganesh; para todos nuestros experimentos, la tasa de fallos en el controlador nunca superó el 0.7%. 4.3 Configuración Experimental La configuración experimental utilizada para las pruebas se puede ver en la Figura 5. Todas las máquinas eran Pentium 4 de 3.2 GHz (con HyperThreading habilitado). Con la excepción del servidor de base de datos, todas las máquinas tenían 2 GB de SDRAM y ejecutaban la distribución de Linux Fedora Core. El servidor de la base de datos tenía 4 GB de SDRAM. Utilizamos Apache Tomcat como tanto el servidor de aplicaciones que alojaba los Servlets de Java como el servidor web. Ambos benchmarks utilizaron Java Servlets para generar el contenido dinámico. El servidor de la base de datos utilizó la base de datos de código abierto MySQL. Para los controladores JDBC nativos, utilizamos los controladores Connector/J proporcionados por MySQL. El servidor de aplicaciones utilizaba la Máquina Virtual de Java de Sun como entorno de ejecución para los Servlets de Java. La herramienta sysstat se utilizó para monitorear la utilización de la CPU, red, disco y memoria en todas las máquinas. Las máquinas estaban conectadas por una red Ethernet gigabit conmutada. Como se muestra en la Figura 5, el servidor web y de aplicación de front-end fue separado del servidor de proxy y base de datos por un enrutador NetEm [16]. Este enrutador nos permitió controlar la configuración de ancho de banda y latencia en la red. El enrutador NetEm es un PC estándar con dos tarjetas de red que ejecuta el software de Control de Tráfico de Linux y Emulación de Red. Las restricciones de ancho de banda y latencia solo se aplicaron al enlace entre el servidor de aplicaciones y la base de datos para el caso nativo y entre el servidor de aplicaciones y el proxy para el caso de Ganesh. No hay comunicación entre el servidor de aplicaciones y la base de datos con Ganesh, ya que todos los datos fluyen a través del proxy. Como nuestro enfoque estaba en el enlace WAN entre el servidor de aplicaciones y la base de datos, no hubo restricciones en el enlace entre los clientes de prueba simulados y el servidor web. 5. DESEMPEÑO Y TIEMPO DE RESPUESTA En esta sección, abordamos la primera pregunta planteada en la Sección 4: ¿Se puede mejorar significativamente el rendimiento explotando la similitud entre los resultados de la base de datos? Para responder a esta pregunta, utilizamos los resultados de los benchmarks BBOARD y AUCTION. Utilizamos dos métricas para cuantificar la mejora en el rendimiento obtenible a través del uso de Ganesh: el throughput, desde la perspectiva del servidor web, y el tiempo de respuesta promedio, desde la perspectiva del cliente. El rendimiento se mide en términos del número de solicitudes de clientes que pueden ser atendidas por segundo. Los resultados y análisis de BBOARD 5.1 Figuras 6 (a) y (b) presentan el número promedio de solicitudes atendidas por segundo y el tiempo de respuesta promedio para estas solicitudes tal como lo perciben los clientes para la Mezcla de Autoría de BBOARD. Como muestra la Figura 6 (a), Native satura fácilmente el enlace de 5 Mb/s. Con 400 clientes, la solución nativa entrega 29 solicitudes/segundo con un tiempo de respuesta promedio de 8.3 segundos. La capacidad de procesamiento de los clientes disminuye con un aumento en los clientes de prueba, ya que los clientes se agotan debido a la congestión en el servidor de aplicaciones. Los estudios de usabilidad han demostrado que los tiempos de respuesta superiores a 10 segundos hacen que el usuario pase a 1. Dado que Java carece de un operador sizeof(), los cachés de Java limitan su tamaño en función del número de objetos. El tamaño de los volcados de caché tomados al final de los experimentos nunca superó los 212 MB. WWW 2007 / Pista: Rendimiento y Escalabilidad Sesión: Sistemas Escalables para Contenido Dinámico 315 0 50 100 150 200 250 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Solicitudes de Clientes de Prueba por Segundo Nativo Ganesh 0.001 0.01 0.1 1 10 100 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Tiempo Promedio de Respuesta de Clientes de Prueba Nativo Ganesh Nota Escala Logarítmica (a) Rendimiento: Mezcla de Autoría (b) Tiempo de Respuesta: Mezcla de Autoría 0 50 100 150 200 250 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Solicitudes de Clientes de Prueba por Segundo Nativo Ganesh 0.001 0.01 0.1 1 10 100 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Tiempo Promedio de Respuesta de Clientes de Prueba Nativo Ganesh Nota Escala Logarítmica (c) Rendimiento: Mezcla de Navegación (d) Tiempo de Respuesta: Mezcla de Navegación Promedio de tres pruebas. La desviación estándar máxima para el rendimiento y el tiempo de respuesta fue del 9.8% y 11.9% de la media correspondiente. Figura 6: BBOARD Benchmark - Rendimiento y Tiempo de Respuesta Promedio de otras tareas [24]. Basándose en estos números, aumentar el número de clientes de prueba hace que el sistema Nativo sea inutilizable. Ganesh a 5 Mb/s, sin embargo, ofrece una mejora doble con 400 clientes de prueba y una mejora quintuple con 1200 clientes. El rendimiento de Ganesh disminuye ligeramente a 1200 y 1600 clientes debido a que la red está saturada. En comparación con Native, la Figura 6 (b) muestra que los tiempos de respuesta de Ganesh son considerablemente más bajos con tiempos de respuesta de menos de un segundo con 400 clientes. La Figura 6 (a) también muestra que para 400 y 800 clientes de prueba, Ganesh a 5 Mb/s tiene el mismo rendimiento y tiempo de respuesta promedio que Native a 20 Mb/s. Solo con 1200 y 1600 clientes, Native a 20 Mb/s ofrece un rendimiento mayor que Ganesh a 5 Mb/s. Al comparar tanto a Ganesh como a Native a 20 Mb/s, vemos que Ganesh ya no está limitado por el ancho de banda y ofrece hasta una mejora del doble sobre Native con 1600 clientes de prueba. Como Ganesh no satura la red con configuraciones de cliente de prueba más altas, con 1600 clientes de prueba, su tiempo de respuesta promedio es de 0.1 segundos en lugar de los 7.7 segundos de Natives. Como era de esperar, no hay ganancias visibles de Ganesh en el ancho de banda más alto de 100 Mb/s donde la red ya no es el cuello de botella. Sin embargo, Ganesh sigue monitoreando a Native en cuanto a rendimiento. Las Figuras 6 (c) y (d) presentan el número promedio de solicitudes atendidas por segundo y el tiempo de respuesta promedio para estas solicitudes tal como lo perciben los clientes para la Mezcla de Navegación de BBOARDs. Independientemente de la configuración del cliente de prueba, la Figura 6 (c) muestra que el rendimiento de los Nativos a 5 Mb/s está limitado a 10 reqs/seg. Ganesh a 5 Mb/s con 400 clientes de prueba, ofrece un aumento de más de seis veces en el rendimiento. La mejora aumenta a más de once veces a 800 clientes de prueba antes de que Ganesh sature la red. Además, la Figura 6 (d) muestra que el tiempo de respuesta promedio de los Nativos de 35 segundos con 400 clientes de prueba hace que el sistema sea inutilizable. Estos altos tiempos de respuesta aumentan aún más con la adición de clientes de prueba. Incluso con la configuración del cliente de prueba de 1600, Ganesh ofrece un tiempo de respuesta promedio aceptable de 8.2 segundos. Debido a la naturaleza intensiva en datos de la mezcla de navegación, Ganesh a 5 Mb/s sorprendentemente tiene un rendimiento mucho mejor que Native a 20 Mb/s. Además, como se muestra en la Figura 6 (d), si bien el tiempo de respuesta promedio para Native a 20 Mb/s es aceptable con 400 clientes de prueba, resulta inutilizable con 800 clientes de prueba, con un tiempo de respuesta promedio de 15.8 segundos. Al igual que en el caso de 5 Mb/s, este tiempo de respuesta aumenta con la adición de clientes de prueba adicionales. Ganesh a 20 Mb/s y tanto Native como Ganesh a 100 Mb/s no tienen limitaciones de ancho de banda. Sin embargo, el rendimiento se estanca después de 1200 clientes de prueba debido a que la CPU de la base de datos está saturada. 5.1.3 Variante de filtro Nos sorprendió el rendimiento nativo del benchmark BBOARD. A una velocidad de banda ancha de 5 Mb/s, el rendimiento nativo fue más bajo de lo que esperábamos. Resultó que el código de referencia que muestra historias leía todos los comentarios asociados con la historia en particular de la base de datos y solo entonces realizaba un postprocesamiento para seleccionar los comentarios que se mostrarían. Si bien este es exactamente el comportamiento de SlashCode, la base de código detrás del sitio web de Slashdot, decidimos modificar la prueba de rendimiento para realizar cierto prefiltrado en la base de datos. Este benchmark modificado, llamado el Filtro de Variantes, modela a un desarrollador que aplica optimizaciones a nivel de SQL para transferir menos datos. En aras de la brevedad, solo resumimos brevemente los resultados de la mezcla de autores. Para la mezcla de Autoría, con 800 clientes de prueba a 5 Mb/s, la Figura 7 (a) muestra que el rendimiento de Natives aumenta un 85% en comparación con el punto de referencia original, mientras que la mejora de Ganesh es menor, del 15%. El rendimiento de los servidores disminuye por encima de los 800 clientes, ya que los clientes de prueba se agotan debido a los altos tiempos de respuesta. La ganancia más significativa para Native se observa a 20 Mb/s. En 1600 clientes de prueba, en comparación con el punto de referencia original, Native experimenta una mejora del 73% en el rendimiento y una reducción del 77% en el tiempo de respuesta promedio. Mientras WWW 2007 / Pista: Rendimiento y Escalabilidad Sesión: Sistemas Escalables para Contenido Dinámico 316 0 50 100 150 200 250 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Clientes de Prueba Solicitudes/seg Nativo Ganesh 0.001 0.01 0.1 1 10 100 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Clientes de Prueba Tiempo de Resp. Promedio (seg) Nativo Ganesh Nota Escala Logarítmica (a) Rendimiento: Mezcla de Autoría (b) Tiempo de Respuesta: Mezcla de Autoría Promedio de tres pruebas. La desviación estándar máxima para el rendimiento y el tiempo de respuesta fue del 7.2% y del 11.5% de la media correspondiente. Figura 7: BBOARD Benchmark - Variante de filtro - Rendimiento y Tiempo de Respuesta Promedio Ganesh no observa ninguna mejora en comparación con el original, aún procesa un 19% más de solicitudes/seg que Native. Por lo tanto, aunque las optimizaciones fueron más útiles para Native, Ganesh todavía ofrece una mejora en el rendimiento. 5.2 Resultados y Análisis de la SUBASTA 5.2.1 Figuras de la Mezcla de Ofertas Los gráficos 8 (a) y (b) presentan el número promedio de solicitudes atendidas por segundo y el tiempo de respuesta promedio para estas solicitudes tal como son percibidas por los clientes para la Mezcla de Ofertas de las SUBASTAS. Como se mencionó anteriormente, la mezcla de ofertas consiste en una combinación de operaciones de lectura y escritura. El benchmark AUCTION no es tan intensivo en datos como BBOARD. Por lo tanto, la mayoría de las ganancias se observan en el ancho de banda más bajo de 5 Mb/s. La figura 8 (a) muestra que el aumento en el rendimiento debido a Ganesh varía desde un 8% con 400 clientes de prueba hasta un 18% con 1600 clientes de prueba. Como se observa en la Figura 8 (b), los tiempos de respuesta promedio para Ganesh son significativamente más bajos que los de Native, con una disminución del 84% a 800 clientes de prueba y del 88% a 1600 clientes de prueba. La Figura 8 (a) también muestra que con un aumento cuádruple del ancho de banda de 5 Mb/s a 20 Mb/s, Native ya no está limitado por el ancho de banda y no hay diferencia de rendimiento entre Ganesh y Native. Con las configuraciones de cliente de prueba más altas, observamos que el ancho de banda utilizado por Ganesh era menor que el de Nativo. Ganesh podría seguir siendo útil en estos escenarios no restringidos si se compra ancho de banda de forma medible. Se observan resultados similares para el escenario de 100 Mb/s. 5.2.2 Mezcla de Navegación Para la Mezcla de Navegación de SUBASTAS, las Figuras 8 (c) y (d) presentan el número promedio de solicitudes atendidas por segundo y el tiempo promedio de respuesta para estas solicitudes tal como lo perciben los clientes. Una vez más, la mayoría de las ganancias se observan en anchos de banda más bajos. A 5 Mb/s, Native y Ganesh ofrecen un rendimiento y tiempos de respuesta similares con 400 clientes de prueba. Mientras que el rendimiento para ambos permanece igual en 800 clientes de prueba, la Figura 8 (d) muestra que el tiempo de respuesta promedio de Ganesh es un 62% menor que el de Native. El servidor satura el enlace con 800 clientes y agregar clientes de prueba adicionales solo aumenta el tiempo promedio de respuesta. Ganesh, independientemente de la configuración del cliente de prueba, no tiene restricciones de ancho de banda y mantiene el mismo tiempo de respuesta. A 1600 clientes de prueba, la Figura 8 (c) muestra que el rendimiento de Ganesh es casi el doble que el de Nativo. En los anchos de banda más altos de 20 y 100 Mb/s, ni Ganesh ni Native tienen limitaciones de ancho de banda y ofrecen un rendimiento y tiempos de respuesta equivalentes. Referencia original. Tamaño Ganesh Tamaño Rabin Tamaño SelectSort1 223.6 MB 5.4 MB 219.3 MB SelectSort2 223.6 MB 5.4 MB 223.6 MB Tabla 2: Microbenchmarks de similitud 6. SIMILITUD ESTRUCTURAL VS. SIMILITUD DE RABIN En esta sección, abordamos la segunda pregunta planteada en la Sección 4: ¿Qué tan importante es la detección de similitud estructural de Ganesh en comparación con la detección de similitud basada en la huella digital de Rabin? Para responder a esta pregunta, utilizamos microbenchmarks y los benchmarks BBOARD y AUCTION. Dado que Ganesh siempre tuvo un mejor rendimiento que Rabin en la huella dactilar, aquí presentamos solo un subconjunto de los resultados en aras de la brevedad. 6.1 Microbenchmarks Dos microbenchmarks muestran un ejemplo de los efectos de la reordenación de datos en el algoritmo de huella dactilar de Rabin. En el primer microbenchmark, SelectSort1, una consulta con un orden de clasificación especificado selecciona 223.6 MB de datos distribuidos en aproximadamente 280 K filas. La consulta se repite entonces con un atributo de ordenación diferente. Si bien se devuelve el mismo número de filas y los mismos datos, el orden de las filas es diferente. En un escenario así, se esperaría detectar una gran cantidad de similitud entre ambos resultados. Como muestra la Tabla 2, el algoritmo basado en filas de Ganesh logra una reducción del 97.6%, mientras que el algoritmo de huella digital de Rabin, con el parámetro de tamaño de fragmento promedio establecido en 4 KB, solo logra una reducción del 1%. La razón, como se muestra anteriormente en la Figura 2, es que con la huella digital de Rabin, los tramos de datos entre dos límites consecutivos suelen cruzar los límites de fila. Con el cambio en el orden de las filas en el segundo resultado y los fingerprints de Rabin ahora abarcando diferentes filas, el algoritmo no puede detectar similitud significativa. La pequeña ganancia observada se debe principalmente a aquellas filas individuales que son lo suficientemente grandes como para dividirse en múltiples fragmentos. SelectSort2, otro micro-benchmark ejecutó las mismas consultas pero aumentó el tamaño mínimo del fragmento del algoritmo de huella digital de Rabin. Como se puede ver en la Tabla 2, incluso la pequeña ganancia del microbenchmark anterior desaparece cuando el tamaño mínimo de fragmento fue mayor que el tamaño promedio de fila. Si bien se pueden abordar parcialmente estos problemas variando dinámicamente los parámetros del algoritmo de huella digital de Rabin, esto puede resultar computacionalmente costoso, especialmente en presencia de cargas de trabajo cambiantes. 6.2 Benchmarks de Aplicación Ejecutamos el benchmark BBOARD descrito en la Sección 4.1.1 en dos versiones de Ganesh: la primera con la huella digital de Rabin utilizada como WWW 2007 / Track: Sesión de Rendimiento y Escalabilidad: Sistemas Escalables para Contenido Dinámico 317 0 50 100 150 200 250 300 350 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Clientes de Prueba Solicitudes/seg Ganesh Nativo 0.001 0.01 0.1 1 10 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Clientes de Prueba Tiempo de Respuesta Promedio (seg) Ganesh Nativo Nota Escala Logarítmica (a) Rendimiento: Mezcla de Ofertas (b) Tiempo de Respuesta: Mezcla de Ofertas 0 50 100 150 200 250 300 350 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Clientes de Prueba Solicitudes/seg Ganesh Nativo 0.001 0.01 0.1 1 10 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Clientes de Prueba Tiempo de Respuesta Promedio (seg) Ganesh Nativo Nota Escala Logarítmica (c) Rendimiento: Mezcla de Navegación (d) Tiempo de Respuesta: Mezcla de Navegación Promedio de tres pruebas. La desviación estándar máxima para el rendimiento y el tiempo de respuesta fue del 2.2% y del 11.8% de la media correspondiente. Figura 8: Referencia de la subasta AUCTION - Rendimiento y Tiempo de Respuesta Promedio del algoritmo de fragmentación y el segundo con el algoritmo basado en filas de Ganesh. Los resultados de Rabins para la Mezcla de Navegación se normalizan con los resultados de Ganesh y se presentan en la Figura 9. Como muestra la Figura 9 (a), a 5 Mb/s, independientemente de la configuración del cliente de prueba, Rabin tiene un rendimiento significativamente inferior a Ganesh. Esto sucede debido a una combinación de dos razones. Primero, como se describe en la Sección 3.1, Rabin encuentra menos similitud ya que no explota la información estructural de los resultados. Segundo, este punto de referencia contenía algunas consultas que generaron resultados grandes. En este caso, Rabin, con un tamaño de fragmento promedio pequeño, generó una gran cantidad de objetos que desplazaron otros datos útiles de la caché. Por el contrario, Ganesh pudo detectar estas filas grandes y aumentar correspondientemente el tamaño de los bloques. Esto fue confirmado ya que las estadísticas de caché mostraron que la proporción de aciertos de Ganesh era aproximadamente tres veces mayor que la de Rabin. Las mediciones de rendimiento a 20 Mb/s fueron similares, con la excepción del rendimiento de Rabins con 400 clientes de prueba. En este caso, Ganesh no estaba limitado por la red y, de hecho, el rendimiento era el mismo que el de 400 clientes a 5 Mb/s. Rabin, sin embargo, aprovechó el aumento del ancho de banda de 5 a 20 Mb/s para ofrecer un rendimiento ligeramente mejor. A 100 Mb/s, el rendimiento de Rabin era casi similar al de Ganesh ya que el ancho de banda ya no era un cuello de botella. El tiempo de respuesta normalizado, presentado en la Figura 9 (b), muestra tendencias similares. A 5 y 20 Mb/s, la adición de clientes de prueba disminuye el tiempo de respuesta normalizado, ya que el tiempo de respuesta promedio de Ganesh aumenta más rápido que el de Rabin. Sin embargo, en ningún momento Rabin supera a Ganesh. Ten en cuenta que con 400 y 800 clientes a 100 Mb/s, Rabin tiene un mayor sobrecosto incluso cuando no está limitado por el ancho de banda. Como se menciona en la Sección 3.1, esto se debe a que Rabin tiene que hashear cada ResultSet dos veces. La sobrecarga desaparece con 1200 y 1600 clientes, ya que la CPU de la base de datos está saturada y limita el rendimiento tanto de Ganesh como de Rabin. 7. SUPERPOSICIÓN DE PROXY En esta sección, abordamos la tercera pregunta planteada en la Sección 4: ¿Es aceptable la superposición del diseño basado en proxy de Ganesh? Para responder a esta pregunta, nos concentramos en su rendimiento en las bandas de mayor ancho de banda. Nuestra evaluación en la Sección 5 mostró que Ganesh, en comparación con Native, puede ofrecer una mejora sustancial en el rendimiento a anchos de banda más bajos. Solo en anchos de banda más altos serían visibles los costos adicionales de latencia, medidos por el tiempo promedio de respuesta para una solicitud de cliente, y de rendimiento, medidos por la cantidad de solicitudes de cliente que pueden ser atendidas por segundo. Al observar la combinación de autoría del benchmark original de BBOARD, no se aprecian ganancias visibles de Ganesh a 100 Mb/s. Sin embargo, Ganesh sigue rastreando a Native en cuanto a rendimiento. Si bien el tiempo promedio de respuesta es mayor para Ganesh, la diferencia absoluta está entre 0.01 y 0.04 segundos y sería imperceptible para el usuario final. La mezcla de navegación muestra una diferencia aún menor en los tiempos de respuesta promedio. Los resultados de la variante del filtro de los benchmarks de BBOARD son similares. Incluso para el benchmark de SUBASTA, la diferencia entre el tiempo de respuesta de Nativo y Ganesh a 100 Mb/s nunca fue mayor a 0.02 segundos. La única excepción a los resultados anteriores se observó en la variante de filtro del benchmark BBOARD, donde Ganesh con 1600 clientes de prueba añadió 0.85 segundos al tiempo de respuesta promedio. Por lo tanto, incluso para redes mucho más rápidas donde el enlace WAN no es el cuello de botella, Ganesh siempre ofrece un rendimiento equivalente al Nativo. Si bien se agrega algo de latencia adicional debido al diseño basado en proxy, generalmente es imperceptible. TRABAJO RELACIONADO Hasta donde sabemos, Ganesh es el primer sistema que combina el uso de técnicas basadas en hash con el almacenamiento en caché de resultados de base de datos para mejorar el rendimiento y los tiempos de respuesta de aplicaciones con contenido dinámico. También creemos que es el primer sistema en demostrar los beneficios de utilizar información estructural para WWW 2007 / Track: Rendimiento y Escalabilidad Sesión: Sistemas Escalables para Contenido Dinámico 318 0.0 0.2 0.4 0.6 0.8 1.0 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Clientes de Prueba Rendimiento Normalizado 31.8 3.8 2.8 2.3 23.8 32.8 5.8 3.6 1.8 2.1 1.1 1.0 0 5 10 15 20 25 30 35 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Clientes de Prueba Tiempo de Respuesta Normalizado (a) Rendimiento Normalizado: Mayor es mejor (b) Tiempo de Respuesta Normalizado: Mayor es peor Para el rendimiento, un resultado normalizado mayor que 1 implica que Rabin es mejor. Para el tiempo de respuesta, un resultado normalizado mayor que 1 implica que Ganesh es mejor. Media de tres pruebas. La desviación estándar máxima para el rendimiento y el tiempo de respuesta fue del 9.1% y del 13.9% de la media correspondiente. Figura 9: Comparación normalizada de Ganesh vs. Rabin - Mezcla de navegación BBOARD detectando similitud. En esta sección, primero discutimos enfoques alternativos para almacenar en caché contenido dinámico y luego examinamos otros usos de primitivas basadas en hash en sistemas distribuidos. 8.1 Almacenamiento en Caché de Contenido Dinámico En la capa de base de datos, varios sistemas han abogado por la caché de nivel intermedio donde partes de la base de datos se replican en el borde o servidor [3, 4, 20]. Estos sistemas almacenan en caché tablas completas en lo que es esencialmente una base de datos replicada o utilizan vistas materializadas de respuestas de consultas anteriores [19]. Requieren una integración estrecha con la base de datos del sistema para garantizar un límite de tiempo en la propagación de actualizaciones. Estos sistemas suelen estar dirigidos a cargas de trabajo que no requieren una consistencia estricta y pueden tolerar datos obsoletos. Además, a diferencia de Ganesh, algunas de estas soluciones de almacenamiento en caché de nivel medio [2, 3], sufren de la complejidad de tener que participar en la planificación de consultas y el procesamiento de consultas distribuidas. Gao et al. [15] proponen utilizar una arquitectura de replicación de objetos distribuidos donde los requisitos de consistencia de las tiendas de datos se adaptan según la aplicación. Estas soluciones requieren recursos sustanciales de desarrollo y un entendimiento detallado de la aplicación que se está modificando. Si bien existen sistemas que intentan automatizar la partición y replicación de la base de datos de una aplicación [34], no proporcionan semántica de transacciones completa. En comparación, Ganesh no debilita ninguna de las semánticas proporcionadas por la base de datos subyacente. El trabajo reciente en la evaluación de opciones de almacenamiento en caché de borde para sitios web dinámicos [38] ha sugerido que, sin una planificación cuidadosa, el empleo de estrategias complejas de descarga puede perjudicar el rendimiento. En cambio, el trabajo aboga por una arquitectura en la que todos los niveles, excepto la base de datos, deberían ser trasladados al borde. Nuestra evaluación de Ganesh ha demostrado que sería beneficioso para estos escenarios. Para mejorar la escalabilidad de la base de datos, C-JDBC [10], SSS [22] y Ganymed [28] también abogan por el uso de una arquitectura basada en interposición para clusterizar y replicar bases de datos de forma transparente a nivel de middleware. Los enfoques de estas arquitecturas y Ganesh son complementarios y se beneficiarían mutuamente. Avanzando hacia la capa de presentación, se ha producido una amplia adopción de la caché basada en fragmentos [14], la cual mejora la utilización de la caché al almacenar por separado diferentes partes de las páginas web generadas. Si bien el almacenamiento en caché basado en fragmentos funciona en el borde, una propuesta reciente ha propuesto trasladar el ensamblaje de páginas web a los clientes para optimizar la entrega de contenido [31]. Si bien Ganesh no se utiliza en la capa de presentación, los mismos principios se han aplicado en la Detección de Transferencias Duplicadas [25] para aumentar la eficiencia de la caché web, así como para el acceso web a través de enlaces con ancho de banda limitado [33]. 8.2 Sistemas basados en hash En los últimos años han surgido muchos sistemas que explotan técnicas basadas en hash. En el centro de todos estos sistemas se encuentra la idea de detectar similitudes en los datos sin necesidad de interpretar esos datos. Esta idea simple pero elegante se basa en el hash criptográfico, como se discutió anteriormente en la Sección 2. Las aplicaciones exitosas de esta idea abarcan una amplia gama de sistemas de almacenamiento. Los ejemplos incluyen la copia de seguridad entre pares de archivos informáticos personales [11], el archivado eficiente de datos [29] y la búsqueda de archivos similares [21]. Spring y Wetherall [35] aplican principios similares a nivel de red. Utilizando cachés sincronizadas en ambos extremos de un enlace de red, los datos duplicados son reemplazados por tokens más pequeños para su transmisión y luego restaurados en el extremo remoto. Este y otros sistemas basados en hash como los sistemas de archivos CASPER [37] y LBFS [26], y optimizadores de ancho de banda de Capa-2 como Riverbed y Peribit utilizan la huella digital de Rabin [30] para descubrir tramos de similitud en los datos. Este enfoque es especialmente útil cuando los elementos de datos son modificados en su lugar a través de inserciones, eliminaciones y actualizaciones. Sin embargo, como se muestra en la Sección 6, el rendimiento de esta técnica puede experimentar una caída dramática en presencia de reordenamiento de datos. Ganesh en cambio utiliza los límites de fila como divisores para detectar similitudes. El uso más agresivo de técnicas basadas en hash es por sistemas que utilizan hashes como identificadores principales para objetos en almacenamiento persistente. Los sistemas de almacenamiento como CFS [12] y PAST [13] que han sido construidos utilizando tablas hash distribuidas entran en esta categoría. Single Instance Storage [6] y Venti [29] son otros ejemplos de tales sistemas. Como se discute en la Sección 2.2, el uso de hashes criptográficos para abordar datos persistentes representa un nivel más profundo de confianza en su resistencia a colisiones que la asumida por Ganesh. Si el tiempo revela deficiencias en el algoritmo hash, el esfuerzo necesario para corregir la falla es mucho mayor. En Ganesh, simplemente se trata de reemplazar el algoritmo hash. 9. CONCLUSIÓN El creciente uso de contenido web dinámico generado a partir de bases de datos relacionales aumenta las demandas de ancho de banda de la WAN. Las soluciones de almacenamiento en caché tradicionales para reducir el ancho de banda y la latencia suelen ser ineficaces para este tipo de contenido. Este documento muestra que el impacto de los accesos a bases de datos a través de WAN puede reducirse sustancialmente mediante la arquitectura Ganesh sin comprometer la estricta semántica de consistencia de las bases de datos. La esencia de la arquitectura Ganesh es el uso de la computación en los bordes para reducir la comunicación a través de Internet. Ganesh es capaz de utilizar hashes criptográficos para detectar similitud con resultados anteriores y enviar recetas compactas de resultados en lugar de resultados completos en la sesión de Sistemas Escalables para Contenido Dinámico 319 de WWW 2007 / Track: Rendimiento y Escalabilidad. Nuestro diseño utiliza la interposición para lograr una transparencia completa: los clientes, los servidores de aplicaciones y los servidores de bases de datos no son conscientes de la presencia de Ganesh y no requieren ninguna modificación. Nuestra evaluación experimental confirma que Ganesh, aunque conceptualmente simple, puede ser altamente efectivo en mejorar el rendimiento y el tiempo de respuesta. Nuestros resultados también confirman que aprovechar la estructura presente en los resultados de la base de datos para detectar similitudes es crucial para esta mejora en el rendimiento. REFERENCIAS [1] AKELLA, A., SESHAN, S., Y SHAIKH, A. Una evaluación empírica de los cuellos de botella en Internet de área amplia. En Proc. 3ª Conferencia ACM SIGCOMM sobre Medición de Internet (Miami Beach, FL, EE. UU., Oct. 2003), pp. 101-114. [2] ALTINEL, M., BORNH ¨OVD, C., KRISHNAMURTHY, S., MOHAN, C., PIRAHESH, H., Y REINWALD, B. Tablas de caché: allanando el camino para una caché de base de datos adaptativa. En Proc. del 29º VLDB (Berlín, Alemania, 2003), pp. 718-729. [3] ALTINEL, M., LUO, Q., KRISHNAMURTHY, S., MOHAN, C., PIRAHESH, H., LINDSAY, B. G., WOO, H., Y BROWN, L. Dbcache: Caché de base de datos para servidores de aplicaciones web. En Proc. 2002 ACM SIGMOD (2002), pp. 612-612. [4] AMIRI, K., PARK, S., TEWARI, R., Y PADMANABHAN, S. Dbproxy: una caché de datos dinámica para aplicaciones web. En Proc. Conferencia Internacional de Ingeniería de Datos de IEEE (ICDE) (Mar. 2003). [5] BLACK, J. Compare-by-hash: Un análisis razonado. En Proc. Conferencia Técnica Anual USENIX 2006 (Boston, MA, mayo de 2006), pp. 85-90. [6] BOLOSKY, W. J., CORBIN, S., GOEBEL, D., y DOUCEUR, J. R. Almacenamiento de instancia única en Windows 2000. En Proc. 4to Simposio de Sistemas Windows de USENIX (Seattle, WA, ago. 2000), pp. 13-24. [7] BREWER, E. A. Lecciones de servicios a gran escala. IEEE Internet Computing 5, 4 (2001), 46-55. [8] BRODER, A., GLASSMAN, S., MANASSE, M., AND ZWEIG, G. Agrupamiento sintáctico de la web. En Proc. 6ta Conferencia Internacional WWW (1997). [9] CECCHET, E., CHANDA, A., ELNIKETY, S., MARGUERITE, J., Y ZWAENEPOEL, W. Comparación de rendimiento de arquitecturas de middleware para generar contenido web dinámico. En Proc. Cuarta Conferencia Internacional de Middleware ACM/IFIP/USENIX (Río de Janeiro, Brasil, junio de 2003). [10] CECCHET, E., MARGUERITE, J., Y ZWAENEPOEL, W. C-JDBC: Middleware flexible de agrupación de bases de datos. En Proc. Conferencia Técnica Anual USENIX 2004 (Boston, MA, junio de 2004). [11] COX, L. P., MURRAY, C. D., Y NOBLE, B. D. Pastiche: Haciendo que la copia de seguridad sea barata y fácil. En OSDI: Simposio sobre Diseño e Implementación de Sistemas Operativos (2002). [12] DABEK, F., KAASHOEK, M. F., KARGER, D., MORRIS, R., Y STOICA, I. Almacenamiento cooperativo de amplia área con CFS. En el 18º Simposio ACM sobre Principios de Sistemas Operativos (Banff, Canadá, octubre de 2001). [13] DRUSCHEL, P., Y ROWSTRON, A. PASADO: Una utilidad de almacenamiento entre pares a gran escala y persistente. En HotOS VIII (Schloss Elmau, Alemania, mayo de 2001), pp. 75-80. [14] Incluye el lado del borde. http://www.esi.org. [15] GAO, L., DAHLIN, M., NAYATE, A., ZHENG, J., Y IYENGAR, A. Replicación de datos específica de la aplicación para servicios en el borde. En WWW 03: Proc. Duodécima Conferencia Internacional sobre la World Wide Web (2003), pp. 449-460. [16] HEMMINGER, S. Netem - emulando redes reales en el laboratorio. En Proc. 2005 Linux Conference Australia (Canberra, Australia, Abr. 2005). [17] HENSON, V. Un análisis de compare-by-hash. En Proc. 9º Taller sobre Temas Candentes en Sistemas Operativos (HotOS IX) (mayo de 2003), pp. 13-18. [18] Benchmarks de Jmob. http://jmob.objectweb.org/. [19] LABRINIDIS, A., Y ROUSSOPOULOS, N. Equilibrando el rendimiento y la frescura de los datos en servidores de bases de datos web. En Proc. 29ª Conferencia VLDB (Sept. 2003). [20] LARSON, P.-A., GOLDSTEIN, J., Y ZHOU, J. Caché transparente de bases de datos en el nivel intermedio en SQL Server. En Proc. 2003 ACM SIGMOD (2003), pp. 661-661. [21] MANBER, U. Encontrar archivos similares en un sistema de archivos grande. En Proc. Conferencia Técnica de Invierno de USENIX 1994 (San Francisco, CA, 17-21 de 1994), pp. 1-10. [22] MANJHI, A., AILAMAKI, A., MAGGS, B. M., MOWRY, T. C., OLSTON, C., Y TOMASIC, A. Escalabilidad y seguridad simultáneas para aplicaciones web intensivas en datos. En Proc. 2006 ACM SIGMOD (junio de 2006), pp. 241-252. [23] MENEZES, A. J., VANSTONE, S. A., Y OORSCHOT, P. C. V. Manual de Criptografía Aplicada. CRC Press, 1996. [24] MILLER, R. B. \n\nCRC Press, 1996. [24] MILLER, R. B. Tiempo de respuesta en transacciones conversacionales entre humanos y computadoras. En Proc. Conferencia Conjunta de Computación de Otoño de AFIPS (1968), pp. 267-277. [25] MOGUL, J. C., CHAN, Y. M., Y KELLY, T. Diseño, implementación y evaluación de la detección de transferencias duplicadas en http. En Proc. Primer Simposio sobre Diseño e Implementación de Sistemas en Red (San Francisco, CA, Mar. 2004). [26] MUTHITACHAROEN, A., CHEN, B., Y MAZIERES, D. Un sistema de archivos en red de bajo ancho de banda. En Proc. 18º Simposio de la ACM sobre Principios de Sistemas Operativos (Banff, Canadá, Oct. 2001). [27] PFEIFER, D., Y JAKSCHITSCH, H. Caché basada en métodos en aplicaciones de servidores multinivel. En Proc. Quinto Simposio Internacional sobre Objetos y Aplicaciones Distribuidas (Catania, Sicilia, Italia, noviembre de 2003). [28] PLATTNER, C., Y ALONSO, G. Ganymed: Replicación escalable para aplicaciones web transaccionales. En Proc. 5ta Conferencia Internacional de Middleware ACM/IFIP/USENIX (2004), pp. 155-174. [29] QUINLAN, S., Y DORWARD, S. Venti: Un nuevo enfoque para el almacenamiento de archivos. En Proc. Conferencia FAST 2002 sobre Tecnologías de Archivo y Almacenamiento (2002). [30] RABIN, M. Huellas dactilares mediante polinomios aleatorios. En el Informe Técnico TR-15-81 (1981) del Centro de Investigación en Tecnología Informática de la Universidad de Harvard. [31] RABINOVICH, M., XIAO, Z., DOUGLIS, F., Y KALMANEK, C. Mover los lados de los bordes incluye a los clientes reales en el borde. En Proc. 4to Simposio USENIX sobre Tecnologías y Sistemas de Internet (Seattle, WA, Mar. 2003). [32] REESE, G. Programación de bases de datos con JDBC y Java, 1ra ed. OReilly, junio de 1997. [33] RHEA, S., LIANG, K., Y BREWER, E. Caché web basada en valores. En Proc. Duodécima Conferencia Internacional de la World Wide Web (mayo de 2003). [34] SIVASUBRAMANIAN, S., ALONSO, G., PIERRE, G., Y VAN STEEN, M. Globedb: Replicación autónoma de datos para aplicaciones web. En WWW 05: Actas de la 14ª Conferencia Internacional de la World-Wide Web (mayo de 2005). [35] SPRING, N. T., Y WETHERALL, D. Una técnica independiente de protocolo para eliminar el tráfico de red redundante. En Proc. de ACM SIGCOMM (Ago. 2000). [36] TOLIA, N., HARKES, J., KOZUCH, M., Y SATYANARAYANAN, M. Integrando almacenamiento portátil y distribuido. En Proc. 3ra Conferencia USENIX sobre Tecnologías de Archivos y Almacenamiento (San Francisco, CA, Mar. 2004). [37] TOLIA, N., KOZUCH, M., SATYANARAYANAN, M., KARP, B., PERRIG, A., Y BRESSOUD, T. Uso oportunista del almacenamiento direccionable por contenido para sistemas de archivos distribuidos. En Proc. Conferencia Técnica Anual USENIX 2003 (San Antonio, TX, junio de 2003), pp. 127-140. [38] YUAN, C., CHEN, Y., Y ZHANG, Z. Evaluación de almacenamiento en caché/descarga en el borde para la entrega de contenido dinámico. En WWW 03: Proc. Duodécima Conferencia Internacional sobre la World Wide Web (2003), pp. 461-471. WWW 2007 / Pista: Rendimiento y Escalabilidad Sesión: Sistemas Escalables para Contenido Dinámico 320 ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "bboard benchmark": {
            "translated_key": "Benchmark BBOARD",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Consistency-preserving Caching of Dynamic Database Content∗ Niraj Tolia and M. Satyanarayanan Carnegie Mellon University {ntolia,satya}@cs.cmu.edu ABSTRACT With the growing use of dynamic web content generated from relational databases, traditional caching solutions for throughput and latency improvements are ineffective.",
                "We describe a middleware layer called Ganesh that reduces the volume of data transmitted without semantic interpretation of queries or results.",
                "It achieves this reduction through the use of cryptographic hashing to detect similarities with previous results.",
                "These benefits do not require any compromise of the strict consistency semantics provided by the back-end database.",
                "Further, Ganesh does not require modifications to applications, web servers, or database servers, and works with closed-source applications and databases.",
                "Using two benchmarks representative of dynamic web sites, measurements of our prototype show that it can increase end-to-end throughput by as much as twofold for non-data intensive applications and by as much as tenfold for data intensive ones.",
                "Categories and Subject Descriptors C.2.4 [Computer-Communication Networks]: Distributed Systems; H.2.4 [Database Management]: Systems General Terms Design, Performance 1.",
                "INTRODUCTION An increasing fraction of web content is dynamically generated from back-end relational databases.",
                "Even when database content remains unchanged, temporal locality of access cannot be exploited because dynamic content is not cacheable by web browsers or by intermediate caching servers such as Akamai mirrors.",
                "In a multitiered architecture, each web request can stress the WAN link between the web server and the database.",
                "This causes user experience to be highly variable because there is no caching to insulate the client from bursty loads.",
                "Previous attempts in caching dynamic database content have generally weakened transactional semantics [3, 4] or required application modifications [15, 34].",
                "We report on a new solution that takes the form of a databaseagnostic middleware layer called Ganesh.",
                "Ganesh makes no effort to semantically interpret the contents of queries or their results.",
                "Instead, it relies exclusively on cryptographic hashing to detect similarities with previous results.",
                "Hash-based similarity detection has seen increasing use in distributed file systems [26, 36, 37] for improving performance on low-bandwidth networks.",
                "However, these techniques have not been used for relational databases.",
                "Unlike previous approaches that use generic methods to detect similarity, Ganesh exploits the structure of relational database results to yield superior performance improvement.",
                "One faces at least three challenges in applying hash-based similarity detection to back-end databases.",
                "First, previous work in this space has traditionally viewed storage content as uninterpreted bags of bits with no internal structure.",
                "This allows hash-based techniques to operate on long, contiguous runs of data for maximum effectiveness.",
                "In contrast, relational databases have rich internal structure that may not be as amenable to hash-based similarity detection.",
                "Second, relational databases have very tight integrity and consistency constraints that must not be compromised by the use of hash-based techniques.",
                "Third, the source code of commercial databases is typically not available.",
                "This is in contrast to previous work which presumed availability of source code.",
                "Our experiments show that Ganesh, while conceptually simple, can improve performance significantly at bandwidths representative of todays commercial Internet.",
                "On benchmarks modeling multitiered web applications, the throughput improvement was as high as tenfold for data-intensive workloads.",
                "For workloads that were not data-intensive, throughput improvements of up to twofold were observed.",
                "Even when bandwidth was not a constraint, Ganesh had low overhead and did not hurt performance.",
                "Our experiments also confirm that exploiting the structure present in database results is crucial to this performance improvement. 2.",
                "BACKGROUND 2.1 Dynamic Content Generation As the World Wide Web has grown, many web sites have decentralized their data and functionality by pushing them to the edges of the Internet.",
                "Today, eBusiness systems often use a three-tiered architecture consisting of a front-end web server, an application server, and a back-end database server.",
                "Figure 1 illustrates this architecture.",
                "The first two tiers can be replicated close to a concentration of clients at the edge of the Internet.",
                "This improves user experience by lowering end-to-end latency and reducing exposure WWW 2007 / Track: Performance and Scalability Session: Scalable Systems for Dynamic Content 311 Back-End Database Server Front-End Web and Application Servers Figure 1: Multi-Tier Architecture to backbone traffic congestion.",
                "It can also increase the availability and scalability of web services.",
                "Content that is generated dynamically from the back-end database cannot be cached in the first two tiers.",
                "While databases can be easily replicated in a LAN, this is infeasible in a WAN because of the difficult task of simultaneously providing strong consistency, availability, and tolerance to network partitions [7].",
                "As a result, databases tend to be centralized to meet the strong consistency requirements of many eBusiness applications such as banking, finance, and online retailing [38].",
                "Thus, the back-end database is usually located far from many sets of first and second-tier nodes [2].",
                "In the absence of both caching and replication, WAN bandwidth can easily become a limiting factor in the performance and scalability of data-intensive applications. 2.2 Hash-Based Systems Ganeshs focus is on efficient transmission of results by discovering similarities with the results of previous queries.",
                "As SQL queries can generate large results, hash-based techniques lend themselves well to the problem of efficiently transferring these large results across bandwidth constrained links.",
                "The use of hash-based techniques to reduce the volume of data transmitted has emerged as a common theme of many recent storage systems, as discussed in Section 8.2.",
                "These techniques rely on some basic assumptions.",
                "Cryptographic hash functions are assumed to be collision-resistant.",
                "In other words, it is computationally intractable to find two inputs that hash to the same output.",
                "The functions are also assumed to be one-way; that is, finding an input that results in a specific output is computationally infeasible.",
                "Menezes et al. [23] provide more details about these assumptions.",
                "The above assumptions allow hash-based systems to assume that collisions do not occur.",
                "Hence, they are able to treat the hash of a data item as its unique identifier.",
                "A collection of data items effectively becomes content-addressable, allowing a small hash to serve as a codeword for a much larger data item in permanent storage or network transmission.",
                "The assumption that collisions are so rare as to be effectively non-existent has recently come under fire [17].",
                "However, as explained by Black [5], we believe that these issues do not form a concern for Ganesh.",
                "All communication is between trusted parts of the system and an adversary has no way to force Ganesh to accept invalid data.",
                "Further, Ganesh does not depend critically on any specific hash function.",
                "While we currently use SHA-1, replacing it with a different hash function would be simple.",
                "There would be no impact on performance as stronger hash functions (e.g.",
                "SHA256) only add a few extra bytes and the generated hashes are still orders of magnitude smaller than the data items they represent.",
                "No re-hashing of permanent storage is required since Ganesh only uses hashing on volatile data. 3.",
                "DESIGN AND IMPLEMENTATION Ganesh exploits redundancy in the result stream to avoid transmitting result fragments that are already present at the query site.",
                "Redundancy can arise naturally in many different ways.",
                "For example, a query repeated after a certain interval may return a different result because of updates to the database; however, there may be significant commonality between the two results.",
                "As another example, a user who is refining a search may generate a sequence of queries with overlapping results.",
                "When Ganesh detects redundancy, it suppresses transmission of the corresponding result fragments.",
                "Instead, it transmits a much smaller digest of those fragments and lets the query site reconstruct the result through hash lookup in a cache of previous results.",
                "In effect, Ganesh uses computation at the edges to reduce Internet communication.",
                "Our description of Ganesh focuses on four aspects.",
                "We first explain our approach to detecting similarity in query results.",
                "Next, we discuss how the Ganesh architecture is completely invisible to all components of a multi-tier system.",
                "We then describe Ganeshs proxy-based approach and the dataflow for detecting similarity. 3.1 Detecting Similarity One of the key design decisions in Ganesh is how similarity is detected.",
                "There are many potential ways to decompose a result into fragments.",
                "The optimal way is, of course, the one that results in the smallest possible object for transmission for a given querys results.",
                "Finding this optimal decomposition is a difficult problem because of the large space of possibilities and because the optimal choice depends on many factors such as the contents of the querys result, the history of recent results, and the cache management algorithm.",
                "When an object is opaque, the use of Rabin fingerprints [8, 30] to detect common data between two objects has been successfully shown in the past by systems such as LBFS [26] and CASPER [37].",
                "Rabin fingerprinting uses a sliding window over the data to compute a rolling hash.",
                "Assuming that the hash function is uniformly distributed, a chunk boundary is defined whenever the lower order bits of the hash value equal some predetermined value.",
                "The number of lower order bits used defines the average chunk size.",
                "These sub-divided chunks of the object become the unit of comparison for detecting similarity between different objects.",
                "As the locations of boundaries found by using Rabin fingerprints is stochastically determined, they usually fail to align with any structural properties of the underlying data.",
                "The algorithm therefore deals well with in-place updates, insertions and deletions.",
                "However, it performs poorly in the presence of any reordering of data.",
                "Figure 2 shows an example where two results, A and B, consisting of three rows, have the same data but have different sort attributes.",
                "In the extreme case, Rabin fingerprinting might be unable to find any similar data due to the way it detects chunk boundaries.",
                "Fortunately, Ganesh can use domain specific knowledge for more precise boundary detection.",
                "The information we exploit is that a querys result reflects the structure of a relational database where all data is organized as tables and rows.",
                "It is therefore simple to check for similarity with previous results at two granularities: first the entire result, and then individual rows.",
                "The end of a row in a result serves as a natural chunk boundary.",
                "It is important to note that using the tabular structure in results only involves shallow interpretation of the data.",
                "Ganesh does not perform any deeper semantic interpretation such as understanding data types, result schema, or integrity constraints.",
                "Tuning Rabin fingerprinting for a workload can also be difficult.",
                "If the average chunk size is too large, chunks can span multiple result rows.",
                "However, selecting a smaller average chunk size increases the amount of metadata required to the describe the results.",
                "WWW 2007 / Track: Performance and Scalability Session: Scalable Systems for Dynamic Content 312 Figure 2: Rabin Fingerprinting vs. Ganeshs Chunking This, in turn, would decrease the savings obtained via its use.",
                "Rabin fingerprinting also needs two computationally-expensive passes over the data: once to determine chunk boundaries and one again to generate cryptographic hashes for the chunks.",
                "Ganesh only needs a single pass for hash generation as the chunk boundaries are provided by the datas natural structure.",
                "The performance comparison in Section 6 shows that Ganeshs row-based algorithm outperforms Rabin fingerprinting.",
                "Given that previous work has already shown that Rabin fingerprinting performs better than gzip [26], we do not compare Ganesh to compression algorithms in this paper. 3.2 Transparency The key factor influencing our design was the need for Ganesh to be completely transparent to all components of a typical eBusiness system: web servers, application servers, and database servers.",
                "Without this, Ganesh stands little chance of having a significant real-world impact.",
                "Requiring modifications to any of the above components would raise the barrier for entry of Ganesh into an existing system, and thus reduce its chances of adoption.",
                "Preserving transparency is simplified by the fact that Ganesh is purely a performance enhancement, not a functionality or usability enhancement.",
                "We chose agent interposition as the architectural approach to realizing our goal.",
                "This approach relies on the existence of a compact programming interface that is already widely used by target software.",
                "It also relies on a mechanism to easily add new code without disrupting existing module structure.",
                "These conditions are easily met in our context because of the popularity of Java as the programming language for eBusiness systems.",
                "The Java Database Connectivity (JDBC) API [32] allows Java applications to access a wide variety of databases and even other tabular data repositories such as flat files.",
                "Access to these data sources is provided by JDBC drivers that translate between the JDBC API and the database communication mechanism.",
                "Figure 3(a) shows how JDBC is typically used in an application.",
                "As the JDBC interface is standardized, one can substitute one JDBC driver for another without application modifications.",
                "The JDBC driver thus becomes the natural module to exploit for code interposition.",
                "As shown in Figure 3(b), the native JDBC driver is replaced with a Ganesh JDBC driver that presents the same standardized interface.",
                "The Ganesh driver maintains an in-memory cache of result fragments from previous queries and performs reassembly of results.",
                "At the database, we add a new process called the Ganesh proxy.",
                "This proxy, which can be shared by multiple front-end nodes, consists of two parts: code to detect similarity in result fragments and the original native JDBC driver that communicates with the database.",
                "The use of a proxy at the database makes Ganesh database-agnostic and simplifies prototyping and experimentation.",
                "Ganesh is thus able to work with a wide range of databases and applications, requiring no modifications to either. 3.3 Proxy-Based Caching The native JDBC driver shown in Figure 3(a) is a lightweight code component supplied by the database vendor.",
                "Its main funcClient Database Web and Application Server Native JDBC Driver WAN (a) Native Architecture Client Database Ganesh Proxy Native JDBC Driver WAN Web and Application Server Ganesh JDBC Driver (b) Ganeshs Interposition-based Architecture Figure 3: Native vs. Ganesh Architecture tion is to mediate communication between the application and the remote database.",
                "It forwards queries, buffers entire results, and responds to application requests to view parts of results.",
                "The Ganesh JDBC driver shown in Figure 3(b) presents the application with an interface identical to that provided by the native driver.",
                "It provides the ability to reconstruct results from compact hash-based descriptions sent by the proxy.",
                "To perform this reconstruction, the driver maintains an in-memory cache of recentlyreceived results.",
                "This cache is only used as a source of result fragments in reconstructing results.",
                "No attempt is made by the Ganesh driver or proxy to track database updates.",
                "The lack of cache consistency does not hurt correctness as a description of the results is always fetched from the proxy - at worst, there will be no performance benefit from using Ganesh.",
                "Stale data will simply be paged out of the cache over time.",
                "The Ganesh proxy accesses the database via the native JDBC driver, which remains unchanged between Figures 3(a) and (b).",
                "The database is thus completely unaware of the existence of the proxy.",
                "The proxy does not examine any queries received from the Ganesh driver but passes them to the native driver.",
                "Instead, the proxy is responsible for inspecting database output received from the native driver, detecting similar results, and generating hash-based encodings of these results whenever enough similarity is found.",
                "While this architecture does not decrease the load on a database, as mentioned earlier in Section 2.1, it is much easier to replicate databases for scalability in a LAN than in a WAN.",
                "To generate a hash-based encoding, the proxy must be aware of what result fragments are available in the Ganesh drivers cache.",
                "One approach is to be optimistic, and to assume that all result fragments are available.",
                "This will result in the smallest possible initial transmission of a result.",
                "However, in cases where there is little overlap with previous results, the Ganesh driver will have to make many calls to the proxy during reconstruction to fetch missing result fragments.",
                "To avoid this situation, the proxy loosely tracks the state of the Ganesh drivers cache.",
                "Since both components are under our control, it is relatively simple to do this without resorting to gray-box techniques or explicit communication for maintaining cache coherence.",
                "Instead, the proxy simulates the Ganesh drivers cache management algorithm and uses this to maintain a list of hashes for which the Ganesh driver is likely to possess the result fragments.",
                "In case of mistracking, there will be no loss of correctness but there will be extra round-trip delays to fetch the missing fragments.",
                "If the client detects loss of synchronization with the proxy, it can ask the proxy to reset the state shared between them.",
                "Also note that the proxy does not need to keep the result fragments themselves, only their hashes.",
                "This allows the proxy to remain scalable even when it is shared by many front-end nodes.",
                "WWW 2007 / Track: Performance and Scalability Session: Scalable Systems for Dynamic Content 313 Object Output Stream Convert ResultSet Object Input Stream Convert ResultSet All Data Recipe ResultSet All Data ResultSet Network Ganesh Proxy Ganesh JDBC Driver Result Set Recipe Result Set Yes Yes No No GaneshInputStream GaneshOutputStream Figure 4: Dataflow for Result Handling 3.4 Encoding and Decoding Results The Ganesh proxy receives database output as Java objects from the native JDBC driver.",
                "It examines this output to see if a Java object of type ResultSet is present.",
                "The JDBC interface uses this data type to store results of database queries.",
                "If a ResultSet object is found, it is shrunk as discussed below.",
                "All other Java objects are passed through unmodified.",
                "As discussed in Section 3.1, the proxy uses the row boundaries defined in the ResultSet to partition it into fragments consisting of single result rows.",
                "All ResultSet objects are converted into objects of a new type called RecipeResultSet.",
                "We use the term recipe for this compact description of a database result because of its similarity to a file recipe in the CASPER file system [37].",
                "The conversion replaces each result fragment that is likely to be present in the Ganesh drivers cache by a SHA-1 hash of that fragment.",
                "Previously unseen result fragments are retained verbatim.",
                "The proxy also retains hashes for the new result fragments as they will be present in the drivers cache in the future.",
                "Note that the proxy only caches hashes for result fragments and does not cache recipes.",
                "The proxy constructs a RecipeResultSet by checking for similarity at the entire result and then the row level.",
                "If the entire result is predicted to be present in the Ganesh drivers cache, the RecipeResultSet is simply a single hash of the entire result.",
                "Otherwise, it contains hashes for those rows predicted to be present in that cache; all other rows are retained verbatim.",
                "If the proxy estimates an overall space savings, it will transmit the RecipeResultSet.",
                "Otherwise the original ResultSet is transmitted.",
                "The RecipeResultSet objects are transformed back into ResultSet objects by the Ganesh driver.",
                "Figure 4 illustrates ResultSet handling at both ends.",
                "Each SHA-1 hash found in a RecipeResultSet is looked up in the local cache of result fragments.",
                "On a hit, the hash is replaced by the corresponding fragment.",
                "On a miss, the driver contacts the Ganesh proxy to fetch the fragment.",
                "All previously unseen result fragments that were retained verbatim by the proxy are hashed and added to the result cache.",
                "There should be very few misses if the proxy has accurately tracked the Ganesh drivers cache state.",
                "A future optimization would be to batch the fetch of missing fragments.",
                "This would be valuable when there are many small missing fragments in a high-latency WAN.",
                "Once the transformation is complete, the fully reconstructed ResultSet object is passed up to the application. 4.",
                "EXPERIMENTAL VALIDATION Three questions follow from the goals and design of Ganesh: • First, can performance can be improved significantly by exploiting similarity across database results?",
                "Benchmark Dataset Details 500,000 Users, 12,000 Stories BBOARD 2.0 GB 3,298,000 Comments AUCTION 1.3 GB 1,000,000 Users, 34,000 Items Table 1: Benchmark Dataset Details • Second, how important is Ganeshs structural similarity detection relative to Rabin fingerprintings similarity detection? • Third, is the overhead of the proxy-based design acceptable?",
                "Our evaluation answers these question through controlled experiments with the Ganesh prototype.",
                "This section describes the benchmarks used, our evaluation procedure, and the experimental setup.",
                "Results of the experiments are presented in Sections 5, 6, and 7. 4.1 Benchmarks Our evaluation is based on two benchmarks [18] that have been widely used by other researchers to evaluate various aspects of multi-tier [27] and eBusiness architectures [9].",
                "The first benchmark, BBOARD, is modeled after Slashdot, a technology-oriented news site.",
                "The second benchmark, AUCTION, is modeled after eBay, an online auction site.",
                "In both benchmarks, most content is dynamically generated from information stored in a database.",
                "Details of the datasets used can be found in Table 1. 4.1.1 The <br>bboard benchmark</br> The <br>bboard benchmark</br>, also known as RUBBoS [18], models Slashdot, a popular technology-oriented web site.",
                "Slashdot aggregates links to news stories and other topics of interest found elsewhere on the web.",
                "The site also serves as a bulletin board by allowing users to comment on the posted stories in a threaded conversation form.",
                "It is not uncommon for a story to gather hundreds of comments in a matter of hours.",
                "The <br>bboard benchmark</br> is similar to the site and models the activities of a user, including readonly operations such as browsing the stories of the day, browsing story categories, and viewing comments as well as write operations such as new user registration, adding and moderating comments, and story submission.",
                "The benchmark consists of three different phases: a short warmup phase, a runtime phase representing the main body of the workload, and a short cool-down phase.",
                "In this paper we only report results from the runtime phase.",
                "The warm-up phase is important in establishing dynamic system state, but measurements from that phase are not significant for our evaluation.",
                "The cool-down phase is solely for allowing the benchmark to shut down.",
                "The warm-up, runtime, and cool-down phases are 2, 15, and 2 minutes respectively.",
                "The number of simulated clients were 400, 800, 1200, and 1600.",
                "The benchmark is available in a Java Servlets and PHP version and has different datasets; we evaluated Ganesh using the Java Servlets version and the Expanded dataset.",
                "The <br>bboard benchmark</br> defines two different workloads.",
                "The first, the Authoring mix, consists of 70% read-only operations and 30% read-write operations.",
                "The second, the Browsing mix, contains only read-only operations and does not update the database. 4.1.2 The AUCTION Benchmark The AUCTION benchmark, also known as RUBiS [18], models eBay, the online auction site.",
                "The eBay web site is used to buy and sell items via an auction format.",
                "The main activities of a user include browsing, selling, or bidding for items.",
                "Modeling the activities on this site, this benchmark includes read-only activities such as browsing items by category and by region, as well as read-write WWW 2007 / Track: Performance and Scalability Session: Scalable Systems for Dynamic Content 314 NetEm Router Ganesh Proxy Clients Web and Application Server Database Server Figure 5: Experimental Setup activities such as bidding for items, buying and selling items, and leaving feedback.",
                "As with BBOARD, the benchmark consists of three different phases.",
                "The warm-up, runtime, and cool-down phases for this experiment are 1.5, 15, and 1 minutes respectively.",
                "We tested Ganesh with four client configurations where the number of test clients was set to 400, 800, 1200, and 1600.",
                "The benchmark is available in a Enterprise Java Bean (EJB), Java Servlets, and PHP version and has different datasets; we evaluated Ganesh with the Java Servlets version and the Expanded dataset.",
                "The AUCTION benchmark defines two different workloads.",
                "The first, the Bidding mix, consists of 70% read-only operations and 30% read-write operations.",
                "The second, the Browsing mix, contains only read-only operations and does not update the database. 4.2 Experimental Procedure Both benchmarks involve a synthetic workload of clients accessing a web server.",
                "The number of clients emulated is an experimental parameter.",
                "Each emulated client runs an instance of the benchmark in its own thread, using a matrix to transition between different benchmark states.",
                "The matrix defines a stochastic model with probabilities of transitioning between the different states that represent typical user actions.",
                "An example transition is a user logging into the AUCTION system and then deciding on whether to post an item for sale or bid on active auctions.",
                "Each client also models user think time between requests.",
                "The think time is modeled as an exponential distribution with a mean of 7 seconds.",
                "We evaluate Ganesh along two axes: number of clients and WAN bandwidth.",
                "Higher loads are especially useful in understanding Ganeshs performance when the CPU or disk of the database server or proxy is the limiting factor.",
                "A previous study has shown that approximately 50% of the wide-area Internet bottlenecks observed had an available bandwidth under 10 Mb/s [1].",
                "Based on this work, we focus our evaluation on the WAN bandwidth of 5 Mb/s with 66 ms of round-trip latency, representative of severely constrained network paths, and 20 Mb/s with 33 ms of round-trip latency, representative of a moderately constrained network path.",
                "We also report Ganeshs performance at 100 Mb/s with no added round-trip latency.",
                "This bandwidth, representative of an unconstrained network, is especially useful in revealing any potential overhead of Ganesh in situations where WAN bandwidth is not the limiting factor.",
                "For each combination of number of clients and WAN bandwidth, we measured results from the two configurations listed below: • Native: This configuration corresponds to Figure 3(a).",
                "Native avoids Ganeshs overhead in using a proxy and performing Java object serialization. • Ganesh: This configuration corresponds to Figure 3(b).",
                "For a given number of clients and WAN bandwidth, comparing these results to the corresponding Native results gives the performance benefit due to the Ganesh middleware system.",
                "The metric used to quantify the improvement in throughput is the number of client requests that can be serviced per second.",
                "The metric used to quantify Ganeshs overhead is the average response time for a client request.",
                "For all of the experiments, the Ganesh driver used by the application server used a cache size of 100,000 items1 .",
                "The proxy was effective in tracking the Ganesh drivers cache state; for all of our experiments the miss rate on the driver never exceeded 0.7%. 4.3 Experimental Setup The experimental setup used for the benchmarks can be seen in Figure 5.",
                "All machines were 3.2 GHz Pentium 4s (with HyperThreading enabled.)",
                "With the exception of the database server, all machines had 2 GB of SDRAM and ran the Fedora Core Linux distribution.",
                "The database server had 4 GB of SDRAM.",
                "We used Apaches Tomcat as both the application server that hosted the Java Servlets and the web server.",
                "Both benchmarks used Java Servlets to generate the dynamic content.",
                "The database server used the open source MySQL database.",
                "For the native JDBC drivers, we used the Connector/J drivers provided by MySQL.",
                "The application server used Suns Java Virtual Machine as the runtime environment for the Java Servlets.",
                "The sysstat tool was used to monitor the CPU, network, disk, and memory utilization on all machines.",
                "The machines were connected by a switched gigabit Ethernet network.",
                "As shown in Figure 5, the front-end web and application server was separated from the proxy and database server by a NetEm router [16].",
                "This router allowed us to control the bandwidth and latency settings on the network.",
                "The NetEm router is a standard PC with two network cards running the Linux Traffic Control and Network Emulation software.",
                "The bandwidth and latency constraints were only applied to the link between the application server and the database for the native case and between the application server and the proxy for the Ganesh case.",
                "There is no communication between the application server and the database with Ganesh as all data flows through the proxy.",
                "As our focus was on the WAN link between the application server and the database, there were no constraints on the link between the simulated test clients and the web server. 5.",
                "THROUGHPUT AND RESPONSE TIME In this section, we address the first question raised in Section 4: Can performance can be improved significantly by exploiting similarity across database results?",
                "To answer this question, we use results from the BBOARD and AUCTION benchmarks.",
                "We use two metrics to quantify the performance improvement obtainable through the use of Ganesh: throughput, from the perspective of the web server, and average response time, from the perspective of the client.",
                "Throughput is measured in terms of the number of client requests that can be serviced per second. 5.1 BBOARD Results and Analysis 5.1.1 Authoring Mix Figures 6 (a) and (b) present the average number of requests serviced per second and the average response time for these requests as perceived by the clients for BBOARDs Authoring Mix.",
                "As Figure 6 (a) shows, Native easily saturates the 5 Mb/s link.",
                "At 400 clients, the Native solution delivers 29 requests/sec with an average response time of 8.3 seconds.",
                "Natives throughput drops with an increase in test clients as clients timeout due to congestion at the application server.",
                "Usability studies have shown that response times above 10 seconds cause the user to move on to 1 As Java lacks a sizeof() operator, Java caches therefore limit their size based on the number of objects.",
                "The size of cache dumps taken at the end of the experiments never exceeded 212 MB.",
                "WWW 2007 / Track: Performance and Scalability Session: Scalable Systems for Dynamic Content 315 0 50 100 150 200 250 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Test Clients Requests/sec Native Ganesh 0.001 0.01 0.1 1 10 100 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Test Clients Avg.Resp.Time(sec) Native Ganesh Note Logscale (a) Throughput: Authoring Mix (b) Response Time: Authoring Mix 0 50 100 150 200 250 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Test Clients Requests/sec Native Ganesh 0.001 0.01 0.1 1 10 100 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Test Clients Avg.Resp.Time(sec) Native Ganesh Note Logscale (c) Throughput: Browsing Mix (d) Response Time: Browsing Mix Mean of three trials.",
                "The maximum standard deviation for throughput and response time was 9.8% and 11.9% of the corresponding mean.",
                "Figure 6: <br>bboard benchmark</br> - Throughput and Average Response Time other tasks [24].",
                "Based on these numbers, increasing the number of test clients makes the Native system unusable.",
                "Ganesh at 5 Mb/s, however, delivers a twofold improvement with 400 test clients and a fivefold improvement at 1200 clients.",
                "Ganeshs performance drops slightly at 1200 and 1600 clients as the network is saturated.",
                "Compared to Native, Figure 6 (b) shows that Ganeshs response times are substantially lower with sub-second response times at 400 clients.",
                "Figure 6 (a) also shows that for 400 and 800 test clients Ganesh at 5 Mb/s has the same throughput and average response time as Native at 20 Mb/s.",
                "Only at 1200 and 1600 clients does Native at 20 Mb/s deliver higher throughput than Ganesh at 5 Mb/s.",
                "Comparing both Ganesh and Native at 20 Mb/s, we see that Ganesh is no longer bandwidth constrained and delivers up to a twofold improvement over Native at 1600 test clients.",
                "As Ganesh does not saturate the network with higher test client configurations, at 1600 test clients, its average response time is 0.1 seconds rather than Natives 7.7 seconds.",
                "As expected, there are no visible gains from Ganesh at the higher bandwidth of 100 Mb/s where the network is no longer the bottleneck.",
                "Ganesh, however, still tracks Native in terms of throughput. 5.1.2 Browsing Mix Figures 6 (c) and (d) present the average number of requests serviced per second and the average response time for these requests as perceived by the clients for BBOARDs Browsing Mix.",
                "Regardless of the test client configuration, Figure 6 (c) shows that Natives throughput at 5 Mb/s is limited to 10 reqs/sec.",
                "Ganesh at 5 Mb/s with 400 test clients, delivers more than a sixfold increase in throughput.",
                "The improvement increases to over a elevenfold increase at 800 test clients before Ganesh saturates the network.",
                "Further, Figure 6 (d) shows that Natives average response time of 35 seconds at 400 test clients make the system unusable.",
                "These high response times further increase with the addition of test clients.",
                "Even with the 1600 test client configuration Ganesh delivers an acceptable average response time of 8.2 seconds.",
                "Due to the data-intensive nature of the Browsing mix, Ganesh at 5 Mb/s surprisingly performs much better than Native at 20 Mb/s.",
                "Further, as shown in Figure 6 (d), while the average response time for Native at 20 Mb/s is acceptable at 400 test clients, it is unusable with 800 test clients with an average response time of 15.8 seconds.",
                "Like the 5 Mb/s case, this response time increases with the addition of extra test clients.",
                "Ganesh at 20 Mb/s and both Native and Ganesh at 100 Mb/s are not bandwidth limited.",
                "However, performance plateaus out after 1200 test clients due to the database CPU being saturated. 5.1.3 Filter Variant We were surprised by the Native performance from the <br>bboard benchmark</br>.",
                "At the bandwidth of 5 Mb/s, Native performance was lower than what we had expected.",
                "It turned out the benchmark code that displays stories read all the comments associated with the particular story from the database and only then did some postprocessing to select the comments to be displayed.",
                "While this is exactly the behavior of SlashCode, the code base behind the Slashdot web site, we decided to modify the benchmark to perform some pre-filtering at the database.",
                "This modified benchmark, named the Filter Variant, models a developer who applies optimizations at the SQL level to transfer less data.",
                "In the interests of brevity, we only briefly summarize the results from the Authoring mix.",
                "For the Authoring mix, at 800 test clients at 5 Mb/s, Figure 7 (a) shows that Natives throughput increase by 85% when compared to the original benchmark while Ganeshs improvement is smaller at 15%.",
                "Natives performance drops above 800 clients as the test clients time out due to high response times.",
                "The most significant gain for Native is seen at 20 Mb/s.",
                "At 1600 test clients, when compared to the original benchmark, Native sees a 73% improvement in throughput and a 77% reduction in average response time.",
                "While WWW 2007 / Track: Performance and Scalability Session: Scalable Systems for Dynamic Content 316 0 50 100 150 200 250 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Test Clients Requests/sec Native Ganesh 0.001 0.01 0.1 1 10 100 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Test Clients Avg.Resp.Time(sec) Native Ganesh Note Logscale (a) Throughput: Authoring Mix (b) Response Time: Authoring Mix Mean of three trials.",
                "The maximum standard deviation for throughput and response time was 7.2% and 11.5% of the corresponding mean.",
                "Figure 7: <br>bboard benchmark</br> - Filter Variant - Throughput and Average Response Time Ganesh sees no improvement when compared to the original, it still processes 19% more requests/sec than Native.",
                "Thus, while the optimizations were more helpful to Native, Ganesh still delivers an improvement in performance. 5.2 AUCTION Results and Analysis 5.2.1 Bidding Mix Figures 8 (a) and (b) present the average number of requests serviced per second and the average response time for these requests as perceived by the clients for AUCTIONs Bidding Mix.",
                "As mentioned earlier, the Bidding mix consists of a mixture of read and write operations.",
                "The AUCTION benchmark is not as data intensive as BBOARD.",
                "Therefore, most of the gains are observed at the lower bandwidth of 5 Mb/s.",
                "Figure 8 (a) shows that the increase in throughput due to Ganesh ranges from 8% at 400 test clients to 18% with 1600 test clients.",
                "As seen in Figure 8 (b), the average response times for Ganesh are significantly lower than Native ranging from a decrease of 84% at 800 test clients to 88% at 1600 test clients.",
                "Figure 8 (a) also shows that with a fourfold increase of bandwidth from 5 Mb/s to 20 Mb/s, Native is no longer bandwidth constrained and there is no performance difference between Ganesh and Native.",
                "With the higher test client configurations, we did observe that the bandwidth used by Ganesh was lower than Native.",
                "Ganesh might still be useful in these non-constrained scenarios if bandwidth is purchased on a metered basis.",
                "Similar results are seen for the 100 Mb/s scenario. 5.2.2 Browsing Mix For AUCTIONs Browsing Mix, Figures 8 (c) and (d) present the average number of requests serviced per second and the average response time for these requests as perceived by the clients.",
                "Again, most of the gains are observed at lower bandwidths.",
                "At 5 Mb/s, Native and Ganesh deliver similar throughput and response times with 400 test clients.",
                "While the throughput for both remains the same at 800 test clients, Figure 8 (d) shows that Ganeshs average response time is 62% lower than Native.",
                "Native saturates the link at 800 clients and adding extra test clients only increases the average response time.",
                "Ganesh, regardless of the test client configuration, is not bandwidth constrained and maintains the same response time.",
                "At 1600 test clients, Figure 8 (c) shows that Ganeshs throughput is almost twice that of Native.",
                "At the higher bandwidths of 20 and 100 Mb/s, neither Ganesh nor Native is bandwidth limited and deliver equivalent throughput and response times.",
                "Benchmark Orig.",
                "Size Ganesh Size Rabin Size SelectSort1 223.6 MB 5.4 MB 219.3 MB SelectSort2 223.6 MB 5.4 MB 223.6 MB Table 2: Similarity Microbenchmarks 6.",
                "STRUCTURAL VS. RABIN SIMILARITY In this section, we address the second question raised in Section 4: How important is Ganeshs structural similarity detection relative to Rabin fingerprinting-based similarity detecting?",
                "To answer this question, we used microbenchmarks and the BBOARD and AUCTION benchmarks.",
                "As Ganesh always performed better than Rabin fingerprinting, we only present a subset of the results here in the interests of brevity. 6.1 Microbenchmarks Two microbenchmarks show an example of the effects of data reordering on Rabin fingerprinting algorithm.",
                "In the first microbenchmark, SelectSort1, a query with a specified sort order selects 223.6 MB of data spread over approximately 280 K rows.",
                "The query is then repeated with a different sort attribute.",
                "While the same number of rows and the same data is returned, the order of rows is different.",
                "In such a scenario, one would expect a large amount of similarity to be detected between both results.",
                "As Table 2 shows, Ganeshs row-based algorithm achieves a 97.6% reduction while the Rabin fingerprinting algorithm, with the average chunk size parameter set to 4 KB, only achieves a 1% reduction.",
                "The reason, as shown earlier in Figure 2, is that with Rabin fingerprinting, the spans of data between two consecutive boundaries usually cross row boundaries.",
                "With the order of the rows changing in the second result and the Rabin fingerprints now spanning different rows, the algorithm is unable to detect significant similarity.",
                "The small gain seen is mostly for those single rows that are large enough to be broken into multiple chunks.",
                "SelectSort2, another micro-benchmark executed the same queries but increased the minimum chunk size of the Rabin fingerprinting algorithm.",
                "As can be seen in Table 2, even the small gain from the previous microbenchmark disappears as the minimum chunk size was greater than the average row size.",
                "While one can partially address these problems by dynamically varying the parameters of the Rabin fingerprinting algorithm, this can be computationally expensive, especially in the presence of changing workloads. 6.2 Application Benchmarks We ran the <br>bboard benchmark</br> described in Section 4.1.1 on two versions of Ganesh: the first with Rabin fingerprinting used as WWW 2007 / Track: Performance and Scalability Session: Scalable Systems for Dynamic Content 317 0 50 100 150 200 250 300 350 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Test Clients Requests/sec Native Ganesh 0.001 0.01 0.1 1 10 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Test Clients Avg.Resp.Time(sec) Native Ganesh Note Logscale (a) Throughput: Bidding Mix (b) Response Time: Bidding Mix 0 50 100 150 200 250 300 350 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Test Clients Requests/sec Native Ganesh 0.001 0.01 0.1 1 10 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Test Clients Avg.Resp.Time(sec) Native Ganesh Note Logscale (c) Throughput: Browsing Mix (d) Response Time: Browsing Mix Mean of three trials.",
                "The maximum standard deviation for throughput and response time was 2.2% and 11.8% of the corresponding mean.",
                "Figure 8: AUCTION Benchmark - Throughput and Average Response Time the chunking algorithm and the second with Ganeshs row-based algorithm.",
                "Rabins results for the Browsing Mix are normalized to Ganeshs results and presented in Figure 9.",
                "As Figure 9 (a) shows, at 5 Mb/s, independent of the test client configuration, Rabin significantly underperforms Ganesh.",
                "This happens because of a combination of two reasons.",
                "First, as outlined in Section 3.1, Rabin finds less similarity as it does not exploit the results structural information.",
                "Second, this benchmark contained some queries that generated large results.",
                "In this case, Rabin, with a small average chunk size, generated a large number of objects that evicted other useful data from the cache.",
                "In contrast, Ganesh was able to detect these large rows and correspondingly increase the size of the chunks.",
                "This was confirmed as cache statistics showed that Ganeshs hit ratio was roughly three time that of Rabin.",
                "Throughput measurements at 20 Mb/s were similar with the exception of Rabins performance with 400 test clients.",
                "In this case, Ganesh was not network limited and, in fact, the throughput was the same as 400 clients at 5 Mb/s.",
                "Rabin, however, took advantage of the bandwidth increase from 5 to 20 Mb/s to deliver a slightly better performance.",
                "At 100 Mb/s, Rabins throughput was almost similar to Ganesh as bandwidth was no longer a bottleneck.",
                "The normalized response time, presented in Figure 9 (b), shows similar trends.",
                "At 5 and 20 Mb/s, the addition of test clients decreases the normalized response time as Ganeshs average response time increases faster than Rabins.",
                "However, at no point does Rabin outperform Ganesh.",
                "Note that at 400 and 800 clients at 100 Mb/s, Rabin does have a higher overhead even when it is not bandwidth constrained.",
                "As mentioned in Section 3.1, this is due to the fact that Rabin has to hash each ResultSet twice.",
                "The overhead disappears with 1200 and 1600 clients as the database CPU is saturated and limits the performance of both Ganesh and Rabin. 7.",
                "PROXY OVERHEAD In this section, we address the third question raised in Section 4: Is the overhead of Ganeshs proxy-based design acceptable?",
                "To answer this question, we concentrate on its performance at the higher bandwidths.",
                "Our evaluation in Section 5 showed that Ganesh, when compared to Native, can deliver a substantial throughput improvement at lower bandwidths.",
                "It is only at higher bandwidths that latency, measured by the average response time for a client request, and throughput, measured by the number of client requests that can be serviced per second, overheads would be visible.",
                "Looking at the Authoring mix of the original <br>bboard benchmark</br>, there are no visible gains from Ganesh at 100 Mb/s.",
                "Ganesh, however, still tracks Native in terms of throughput.",
                "While the average response time is higher for Ganesh, the absolute difference is in between 0.01 and 0.04 seconds and would be imperceptible to the end-user.",
                "The Browsing mix shows an even smaller difference in average response times.",
                "The results from the filter variant of the BBOARD benchmarks are similar.",
                "Even for the AUCTION benchmark, the difference between Native and Ganeshs response time at 100 Mb/s was never greater than 0.02 seconds.",
                "The only exception to the above results was seen in the filter variant of the <br>bboard benchmark</br> where Ganesh at 1600 test clients added 0.85 seconds to the average response time.",
                "Thus, even for much faster networks where the WAN link is not the bottleneck, Ganesh always delivers throughput equivalent to Native.",
                "While some extra latency is added by the proxy-based design, it is usually imperceptible. 8.",
                "RELATED WORK To the best of our knowledge, Ganesh is the first system that combines the use of hash-based techniques with caching of database results to improve throughput and response times for applications with dynamic content.",
                "We also believe that it is also the first system to demonstrate the benefits of using structural information for WWW 2007 / Track: Performance and Scalability Session: Scalable Systems for Dynamic Content 318 0.0 0.2 0.4 0.6 0.8 1.0 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Test Clients Norm.Throughput 31.8 3.8 2.8 2.3 23.8 32.8 5.8 3.6 1.8 2.1 1.1 1.0 0 5 10 15 20 25 30 35 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Test Clients Norm.ResponseTime (a) Normalized Throughput: Higher is better (b) Normalized Response Time: Higher is worse For throughput, a normalized result greater than 1 implies that Rabin is better, For response time, a normalized result greater than 1 implies that Ganesh is better.",
                "Mean of three trials.",
                "The maximum standard deviation for throughput and response time was 9.1% and 13.9% of the corresponding mean.",
                "Figure 9: Normalized Comparison of Ganesh vs. Rabin - BBOARD Browsing Mix detecting similarity.",
                "In this section, we first discuss alternative approaches to caching dynamic content and then examine other uses of hash-based primitives in distributed systems. 8.1 Caching Dynamic Content At the database layer, a number of systems have advocated middletier caching where parts of the database are replicated at the edge or server [3, 4, 20].",
                "These systems either cache entire tables in what is essentially a replicated database or use materialized views from previous query replies [19].",
                "They require tight integration with the back-end database to ensure a time bound on the propagation of updates.",
                "These systems are also usually targeted towards workloads that do not require strict consistency and can tolerate stale data.",
                "Further, unlike Ganesh, some of these mid-tier caching solutions [2, 3], suffer from the complexity of having to participate in query planing and distributed query processing.",
                "Gao et al. [15] propose using a distributed object replication architecture where the data stores consistency requirements are adapted on a per-application basis.",
                "These solutions require substantial developer resources and detailed understanding of the application being modified.",
                "While systems that attempt to automate the partitioning and replication of an applications database exist [34], they do not provide full transaction semantics.",
                "In comparison, Ganesh does not weaken any of the semantics provided by the underlying database.",
                "Recent work in the evaluation of edge caching options for dynamic web sites [38] has suggested that, without careful planning, employing complex offloading strategies can hurt performance.",
                "Instead, the work advocates for an architecture in which all tiers except the database should be offloaded to the edge.",
                "Our evaluation of Ganesh has shown that it would benefit these scenarios.",
                "To improve database scalability, C-JDBC [10], SSS [22], and Ganymed [28] also advocate the use of an interposition-based architecture to transparently cluster and replicate databases at the middleware level.",
                "The approaches of these architectures and Ganesh are complementary and they would benefit each other.",
                "Moving up to the presentation layer, there has been widespread adoption of fragment-based caching [14], which improves cache utilization by separately caching different parts of generated web pages.",
                "While fragment-based caching works at the edge, a recent proposal has proposed moving web page assembly to the clients to optimize content delivery [31].",
                "While Ganesh is not used at the presentation layer, the same principles have been applied in Duplicate Transfer Detection [25] to increase web cache efficiency as well as for web access across bandwidth limited links [33]. 8.2 Hash-based Systems The past few years have seen the emergence of many systems that exploit hash-based techniques.",
                "At the heart of all these systems is the idea of detecting similarity in data without requiring interpretation of that data.",
                "This simple yet elegant idea relies on cryptographic hashing, as discussed earlier in Section 2.",
                "Successful applications of this idea span a wide range of storage systems.",
                "Examples include peer-to-peer backup of personal computing files [11], storage-efficient archiving of data [29], and finding similar files [21].",
                "Spring and Wetherall [35] apply similar principles at the network level.",
                "Using synchronized caches at both ends of a network link, duplicated data is replaced by smaller tokens for transmission and then restored at the remote end.",
                "This and other hash-based systems such as the CASPER [37] and LBFS [26] filesystems, and Layer-2 bandwidth optimizers such as Riverbed and Peribit use Rabin fingerprinting [30] to discover spans of commonality in data.",
                "This approach is especially useful when data items are modified in-place through insertions, deletions, and updates.",
                "However, as Section 6 shows, the performance of this technique can show a dramatic drop in the presence of data reordering.",
                "Ganesh instead uses row boundaries as dividers for detecting similarity.",
                "The most aggressive use of hash-based techniques is by systems that use hashes as the primary identifiers for objects in persistent storage.",
                "Storage systems such as CFS [12] and PAST [13] that have been built using distributed hash tables fall into this category.",
                "Single Instance Storage [6] and Venti [29] are other examples of such systems.",
                "As discussed in Section 2.2, the use of cryptographic hashes for addressing persistent data represents a deeper level of faith in their collision-resistance than that assumed by Ganesh.",
                "If time reveals shortcomings in the hash algorithm, the effort involved in correcting the flaw is much greater.",
                "In Ganesh, it is merely a matter of replacing the hash algorithm. 9.",
                "CONCLUSION The growing use of dynamic web content generated from relational databases places increased demands on WAN bandwidth.",
                "Traditional caching solutions for bandwidth and latency reduction are often ineffective for such content.",
                "This paper shows that the impact of WAN accesses to databases can be substantially reduced through the Ganesh architecture without any compromise of the databases strict consistency semantics.",
                "The essence of the Ganesh architecture is the use of computation at the edges to reduce communication through the Internet.",
                "Ganesh is able to use cryptographic hashes to detect similarity with previous results and send WWW 2007 / Track: Performance and Scalability Session: Scalable Systems for Dynamic Content 319 compact recipes of results rather than full results.",
                "Our design uses interposition to achieve complete transparency: clients, application servers, and database servers are all unaware of Ganeshs presence and require no modification.",
                "Our experimental evaluation confirms that Ganesh, while conceptually simple, can be highly effective in improving throughput and response time.",
                "Our results also confirm that exploiting the structure present in database results to detect similarity is crucial to this performance improvement. 10.",
                "REFERENCES [1] AKELLA, A., SESHAN, S., AND SHAIKH, A.",
                "An empirical evaluation of wide-area internet bottlenecks.",
                "In Proc. 3rd ACM SIGCOMM Conference on Internet Measurement (Miami Beach, FL, USA, Oct. 2003), pp. 101-114. [2] ALTINEL, M., BORNH ¨OVD, C., KRISHNAMURTHY, S., MOHAN, C., PIRAHESH, H., AND REINWALD, B. Cache tables: Paving the way for an adaptive database cache.",
                "In Proc. of 29th VLDB (Berlin, Germany, 2003), pp. 718-729. [3] ALTINEL, M., LUO, Q., KRISHNAMURTHY, S., MOHAN, C., PIRAHESH, H., LINDSAY, B. G., WOO, H., AND BROWN, L. Dbcache: Database caching for web application servers.",
                "In Proc. 2002 ACM SIGMOD (2002), pp. 612-612. [4] AMIRI, K., PARK, S., TEWARI, R., AND PADMANABHAN, S. Dbproxy: A dynamic data cache for web applications.",
                "In Proc.",
                "IEEE International Conference on Data Engineering (ICDE) (Mar. 2003). [5] BLACK, J. Compare-by-hash: A reasoned analysis.",
                "In Proc. 2006 USENIX Annual Technical Conference (Boston, MA, May 2006), pp. 85-90. [6] BOLOSKY, W. J., CORBIN, S., GOEBEL, D., , AND DOUCEUR, J. R. Single instance storage in windows 2000.",
                "In Proc. 4th USENIX Windows Systems Symposium (Seattle, WA, Aug. 2000), pp. 13-24. [7] BREWER, E. A.",
                "Lessons from giant-scale services.",
                "IEEE Internet Computing 5, 4 (2001), 46-55. [8] BRODER, A., GLASSMAN, S., MANASSE, M., AND ZWEIG, G. Syntactic clustering of the web.",
                "In Proc. 6th International WWW Conference (1997). [9] CECCHET, E., CHANDA, A., ELNIKETY, S., MARGUERITE, J., AND ZWAENEPOEL, W. Performance comparison of middleware architectures for generating dynamic web content.",
                "In Proc.",
                "Fourth ACM/IFIP/USENIX International Middleware Conference (Rio de Janeiro, Brazil, June 2003). [10] CECCHET, E., MARGUERITE, J., AND ZWAENEPOEL, W. C-JDBC: Flexible database clustering middleware.",
                "In Proc. 2004 USENIX Annual Technical Conference (Boston, MA, June 2004). [11] COX, L. P., MURRAY, C. D., AND NOBLE, B. D. Pastiche: Making backup cheap and easy.",
                "In OSDI: Symposium on Operating Systems Design and Implementation (2002). [12] DABEK, F., KAASHOEK, M. F., KARGER, D., MORRIS, R., AND STOICA, I. Wide-area cooperative storage with CFS.",
                "In 18th ACM Symposium on Operating Systems Principles (Banff, Canada, Oct. 2001). [13] DRUSCHEL, P., AND ROWSTRON, A.",
                "PAST: A large-scale, persistent peer-to-peer storage utility.",
                "In HotOS VIII (Schloss Elmau, Germany, May 2001), pp. 75-80. [14] Edge side includes. http://www.esi.org. [15] GAO, L., DAHLIN, M., NAYATE, A., ZHENG, J., AND IYENGAR, A.",
                "Application specific data replication for edge services.",
                "In WWW 03: Proc.",
                "Twelfth International Conference on World Wide Web (2003), pp. 449-460. [16] HEMMINGER, S. Netem - emulating real networks in the lab.",
                "In Proc. 2005 Linux Conference Australia (Canberra, Australia, Apr. 2005). [17] HENSON, V. An analysis of compare-by-hash.",
                "In Proc. 9th Workshop on Hot Topics in Operating Systems (HotOS IX) (May 2003), pp. 13-18. [18] Jmob benchmarks. http://jmob.objectweb.org/. [19] LABRINIDIS, A., AND ROUSSOPOULOS, N. Balancing performance and data freshness in web database servers.",
                "In Proc. 29th VLDB Conference (Sept. 2003). [20] LARSON, P.-A., GOLDSTEIN, J., AND ZHOU, J. Transparent mid-tier database caching in sql server.",
                "In Proc. 2003 ACM SIGMOD (2003), pp. 661-661. [21] MANBER, U.",
                "Finding similar files in a large file system.",
                "In Proc.",
                "USENIX Winter 1994 Technical Conference (San Fransisco, CA, 17-21 1994), pp. 1-10. [22] MANJHI, A., AILAMAKI, A., MAGGS, B. M., MOWRY, T. C., OLSTON, C., AND TOMASIC, A.",
                "Simultaneous scalability and security for data-intensive web applications.",
                "In Proc. 2006 ACM SIGMOD (June 2006), pp. 241-252. [23] MENEZES, A. J., VANSTONE, S. A., AND OORSCHOT, P. C. V. Handbook of Applied Cryptography.",
                "CRC Press, 1996. [24] MILLER, R. B.",
                "Response time in man-computer conversational transactions.",
                "In Proc.",
                "AFIPS Fall Joint Computer Conference (1968), pp. 267-277. [25] MOGUL, J. C., CHAN, Y. M., AND KELLY, T. Design, implementation, and evaluation of duplicate transfer detection in http.",
                "In Proc.",
                "First Symposium on Networked Systems Design and Implementation (San Francisco, CA, Mar. 2004). [26] MUTHITACHAROEN, A., CHEN, B., AND MAZIERES, D. A low-bandwidth network file system.",
                "In Proc. 18th ACM Symposium on Operating Systems Principles (Banff, Canada, Oct. 2001). [27] PFEIFER, D., AND JAKSCHITSCH, H. Method-based caching in multi-tiered server applications.",
                "In Proc.",
                "Fifth International Symposium on Distributed Objects and Applications (Catania, Sicily, Italy, Nov. 2003). [28] PLATTNER, C., AND ALONSO, G. Ganymed: Scalable replication for transactional web applications.",
                "In Proc. 5th ACM/IFIP/USENIX International Conference on Middleware (2004), pp. 155-174. [29] QUINLAN, S., AND DORWARD, S. Venti: A new approach to archival storage.",
                "In Proc.",
                "FAST 2002 Conference on File and Storage Technologies (2002). [30] RABIN, M. Fingerprinting by random polynomials.",
                "In Harvard University Center for Research in Computing Technology Technical Report TR-15-81 (1981). [31] RABINOVICH, M., XIAO, Z., DOUGLIS, F., AND KALMANEK, C. Moving edge side includes to the real edge - the clients.",
                "In Proc. 4th USENIX Symposium on Internet Technologies and Systems (Seattle, WA, Mar. 2003). [32] REESE, G. Database Programming with JDBC and Java, 1st ed.",
                "OReilly, June 1997. [33] RHEA, S., LIANG, K., AND BREWER, E. Value-based web caching.",
                "In Proc.",
                "Twelfth International World Wide Web Conference (May 2003). [34] SIVASUBRAMANIAN, S., ALONSO, G., PIERRE, G., AND VAN STEEN, M. Globedb: Autonomic data replication for web applications.",
                "In WWW 05: Proc. 14th International World-Wide Web conference (May 2005). [35] SPRING, N. T., AND WETHERALL, D. A protocol-independent technique for eliminating redundant network traffic.",
                "In Proc. of ACM SIGCOMM (Aug. 2000). [36] TOLIA, N., HARKES, J., KOZUCH, M., AND SATYANARAYANAN, M. Integrating portable and distributed storage.",
                "In Proc. 3rd USENIX Conference on File and Storage Technologies (San Francisco, CA, Mar. 2004). [37] TOLIA, N., KOZUCH, M., SATYANARAYANAN, M., KARP, B., PERRIG, A., AND BRESSOUD, T. Opportunistic use of content addressable storage for distributed file systems.",
                "In Proc. 2003 USENIX Annual Technical Conference (San Antonio, TX, June 2003), pp. 127-140. [38] YUAN, C., CHEN, Y., AND ZHANG, Z.",
                "Evaluation of edge caching/offloading for dynamic content delivery.",
                "In WWW 03: Proc.",
                "Twelfth International Conference on World Wide Web (2003), pp. 461-471.",
                "WWW 2007 / Track: Performance and Scalability Session: Scalable Systems for Dynamic Content 320"
            ],
            "original_annotated_samples": [
                "Details of the datasets used can be found in Table 1. 4.1.1 The <br>bboard benchmark</br> The <br>bboard benchmark</br>, also known as RUBBoS [18], models Slashdot, a popular technology-oriented web site.",
                "The <br>bboard benchmark</br> is similar to the site and models the activities of a user, including readonly operations such as browsing the stories of the day, browsing story categories, and viewing comments as well as write operations such as new user registration, adding and moderating comments, and story submission.",
                "The <br>bboard benchmark</br> defines two different workloads.",
                "Figure 6: <br>bboard benchmark</br> - Throughput and Average Response Time other tasks [24].",
                "However, performance plateaus out after 1200 test clients due to the database CPU being saturated. 5.1.3 Filter Variant We were surprised by the Native performance from the <br>bboard benchmark</br>."
            ],
            "translated_annotated_samples": [
                "Los detalles de los conjuntos de datos utilizados se pueden encontrar en la Tabla 1. 4.1.1 El <br>Benchmark BBOARD</br> El benchmark BBOARD, también conocido como RUBBoS [18], modela Slashdot, un popular sitio web orientado a la tecnología.",
                "El <br>benchmark BBOARD</br> es similar al sitio y modela las actividades de un usuario, incluyendo operaciones de solo lectura como navegar por las historias del día, explorar categorías de historias y ver comentarios, así como operaciones de escritura como registro de nuevos usuarios, agregar y moderar comentarios, y enviar historias.",
                "El <br>benchmark BBOARD</br> define dos cargas de trabajo diferentes.",
                "Figura 6: BBOARD Benchmark - Rendimiento y Tiempo de Respuesta Promedio de otras tareas [24].",
                "Sin embargo, el rendimiento se estanca después de 1200 clientes de prueba debido a que la CPU de la base de datos está saturada. 5.1.3 Variante de filtro Nos sorprendió el rendimiento nativo del <br>benchmark BBOARD</br>."
            ],
            "translated_text": "Conservación de la consistencia en el almacenamiento en caché de contenido dinámico de bases de datos∗ Niraj Tolia y M. Satyanarayanan Universidad Carnegie Mellon {ntolia,satya}@cs.cmu.edu RESUMEN Con el creciente uso de contenido web dinámico generado a partir de bases de datos relacionales, las soluciones de almacenamiento en caché tradicionales para mejorar el rendimiento y la latencia son ineficaces. Describimos una capa de middleware llamada Ganesh que reduce el volumen de datos transmitidos sin interpretación semántica de consultas o resultados. Se logra esta reducción mediante el uso de hash criptográficos para detectar similitudes con resultados anteriores. Estos beneficios no requieren ningún compromiso con la semántica de consistencia estricta proporcionada por la base de datos del servidor. Además, Ganesh no requiere modificaciones en aplicaciones, servidores web o servidores de bases de datos, y funciona con aplicaciones y bases de datos de código cerrado. Usando dos puntos de referencia representativos de sitios web dinámicos, las mediciones de nuestro prototipo muestran que puede aumentar el rendimiento de extremo a extremo hasta en un factor de dos para aplicaciones no intensivas en datos y hasta en un factor de diez para las intensivas en datos. Categorías y Descriptores de Asignaturas C.2.4 [Redes de Computadoras-Comunicación]: Sistemas Distribuidos; H.2.4 [Gestión de Bases de Datos]: Términos Generales de Sistemas de Diseño, Rendimiento 1. INTRODUCCIÓN Una fracción creciente del contenido web se genera dinámicamente a partir de bases de datos relacionales en el backend. Incluso cuando el contenido de la base de datos permanece sin cambios, la localidad temporal de acceso no puede ser explotada porque el contenido dinámico no es almacenable en caché por los navegadores web o por servidores de almacenamiento en caché intermedios como los espejos de Akamai. En una arquitectura multinivel, cada solicitud web puede tensionar el enlace WAN entre el servidor web y la base de datos. Esto provoca que la experiencia del usuario sea altamente variable porque no hay almacenamiento en caché para aislar al cliente de cargas repentinas. Los intentos previos de almacenar en caché contenido dinámico de bases de datos generalmente han debilitado la semántica transaccional [3, 4] o han requerido modificaciones en la aplicación [15, 34]. Informamos sobre una nueva solución que toma la forma de una capa intermedia de middleware independiente de la base de datos llamada Ganesh. Ganesh no hace ningún esfuerzo por interpretar semánticamente el contenido de las consultas o sus resultados. En cambio, se basa exclusivamente en el hash criptográfico para detectar similitudes con resultados anteriores. La detección de similitud basada en hash ha sido cada vez más utilizada en sistemas de archivos distribuidos [26, 36, 37] para mejorar el rendimiento en redes de baja capacidad de ancho de banda. Sin embargo, estas técnicas no se han utilizado para bases de datos relacionales. A diferencia de enfoques anteriores que utilizan métodos genéricos para detectar similitud, Ganesh explota la estructura de los resultados de la base de datos relacional para lograr una mejora superior en el rendimiento. Uno se enfrenta al menos a tres desafíos al aplicar la detección de similitud basada en hash a las bases de datos de back-end. Primero, el trabajo previo en este ámbito ha considerado tradicionalmente el contenido de almacenamiento como bolsas de bits no interpretadas y sin estructura interna. Esto permite que las técnicas basadas en hash operen en largas y contiguas secuencias de datos para lograr la máxima efectividad. Por el contrario, las bases de datos relacionales tienen una estructura interna compleja que puede no ser tan propicia para la detección de similitudes basada en hash. Segundo, las bases de datos relacionales tienen restricciones de integridad y consistencia muy estrictas que no deben comprometerse por el uso de técnicas basadas en hash. Tercero, el código fuente de las bases de datos comerciales generalmente no está disponible. Esto contrasta con trabajos anteriores que presumían la disponibilidad del código fuente. Nuestros experimentos muestran que Ganesh, aunque conceptualmente simple, puede mejorar significativamente el rendimiento en anchos de banda representativos del Internet comercial actual. En los modelos de referencia de aplicaciones web multinivel, la mejora en el rendimiento fue de hasta diez veces para cargas de trabajo intensivas en datos. Para cargas de trabajo que no eran intensivas en datos, se observaron mejoras en el rendimiento de hasta el doble. Incluso cuando el ancho de banda no era una limitación, Ganesh tenía un bajo sobrecosto y no afectaba el rendimiento. Nuestros experimentos también confirman que aprovechar la estructura presente en los resultados de la base de datos es crucial para esta mejora en el rendimiento. Antecedentes 2.1 Generación de Contenido Dinámico A medida que la World Wide Web ha crecido, muchos sitios web han descentralizado sus datos y funcionalidades al llevarlos a los extremos de Internet. Hoy en día, los sistemas de comercio electrónico a menudo utilizan una arquitectura de tres niveles que consta de un servidor web de front-end, un servidor de aplicaciones y un servidor de base de datos de back-end. La Figura 1 ilustra esta arquitectura. Los dos primeros niveles se pueden replicar cerca de una concentración de clientes en el borde de Internet. Esto mejora la experiencia del usuario al reducir la latencia de extremo a extremo y disminuir la exposición al congestionamiento del tráfico de la columna vertebral. También puede aumentar la disponibilidad y escalabilidad de los servicios web. El contenido que se genera dinámicamente desde la base de datos del servidor no puede ser almacenado en caché en los dos primeros niveles. Si bien las bases de datos pueden replicarse fácilmente en una LAN, esto es inviable en una WAN debido a la difícil tarea de proporcionar simultáneamente una consistencia sólida, disponibilidad y tolerancia a particiones de red [7]. Como resultado, las bases de datos tienden a ser centralizadas para cumplir con los fuertes requisitos de consistencia de muchas aplicaciones de comercio electrónico como la banca, las finanzas y la venta al por menor en línea [38]. Por lo tanto, la base de datos del back-end suele estar ubicada lejos de muchos conjuntos de nodos de primer y segundo nivel [2]. En ausencia de almacenamiento en caché y replicación, el ancho de banda de la WAN puede convertirse fácilmente en un factor limitante en el rendimiento y la escalabilidad de aplicaciones intensivas en datos. El enfoque de Ganesh en los sistemas basados en hash es la transmisión eficiente de resultados al descubrir similitudes con los resultados de consultas anteriores. Dado que las consultas SQL pueden generar resultados grandes, las técnicas basadas en hash se prestan bien al problema de transferir eficientemente estos grandes resultados a través de enlaces con ancho de banda limitado. El uso de técnicas basadas en hash para reducir el volumen de datos transmitidos ha surgido como un tema común en muchos sistemas de almacenamiento recientes, como se discute en la Sección 8.2. Estas técnicas se basan en algunas suposiciones básicas. Se asume que las funciones hash criptográficas son resistentes a colisiones. En otras palabras, es computacionalmente intratable encontrar dos entradas que se hash a la misma salida. Las funciones también se asumen como unidireccionales; es decir, encontrar una entrada que resulte en una salida específica es computacionalmente inviable. Menezes et al. [23] proporcionan más detalles sobre estas suposiciones. Las suposiciones anteriores permiten a los sistemas basados en hash asumir que no se producen colisiones. Por lo tanto, pueden tratar el hash de un elemento de datos como su identificador único. Una colección de elementos de datos se convierte efectivamente en direccionable por contenido, permitiendo que un hash pequeño funcione como una palabra de código para un elemento de datos mucho más grande en almacenamiento permanente o transmisión en red. La suposición de que las colisiones son tan raras que prácticamente no existen ha sido cuestionada recientemente [17]. Sin embargo, como explicó Black [5], creemos que estos problemas no son una preocupación para Ganesh. Toda comunicación es entre partes confiables del sistema y un adversario no tiene forma de obligar a Ganesh a aceptar datos inválidos. Además, Ganesh no depende críticamente de ninguna función hash específica. Si bien actualmente usamos SHA-1, reemplazarlo con una función hash diferente sería sencillo. No habría impacto en el rendimiento con funciones hash más fuertes (por ejemplo, SHA256) solo añade unos pocos bytes adicionales y los hashes generados siguen siendo órdenes de magnitud más pequeños que los elementos de datos que representan. No es necesario volver a almacenar permanentemente ya que Ganesh solo utiliza el hash en datos volátiles. 3. DISEÑO E IMPLEMENTACIÓN Ganesh explota la redundancia en el flujo de resultados para evitar transmitir fragmentos de resultados que ya están presentes en el sitio de la consulta. La redundancia puede surgir de forma natural de muchas maneras diferentes. Por ejemplo, una consulta repetida después de un cierto intervalo puede devolver un resultado diferente debido a actualizaciones en la base de datos; sin embargo, puede haber una significativa similitud entre los dos resultados. Como otro ejemplo, un usuario que está refinando una búsqueda puede generar una secuencia de consultas con resultados superpuestos. Cuando Ganesh detecta redundancia, suprime la transmisión de los fragmentos de resultado correspondientes. En cambio, transmite un resumen mucho más pequeño de esos fragmentos y permite que el sitio de consulta reconstruya el resultado a través de la búsqueda de hash en una caché de resultados anteriores. De hecho, Ganesh utiliza la computación en los bordes para reducir la comunicación por Internet. Nuestra descripción de Ganesh se centra en cuatro aspectos. Primero explicamos nuestro enfoque para detectar similitud en los resultados de la consulta. A continuación, discutimos cómo la arquitectura Ganesh es completamente invisible para todos los componentes de un sistema de múltiples niveles. Luego describimos el enfoque basado en proxy de Ganesh y el flujo de datos para detectar similitudes. 3.1 Detectar similitud Una de las decisiones clave de diseño en Ganesh es cómo se detecta la similitud. Hay muchas formas potenciales de descomponer un resultado en fragmentos.  I the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the thees I,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,, Encontrar esta descomposición óptima es un problema difícil debido al amplio espacio de posibilidades y porque la elección óptima depende de muchos factores, como el contenido del resultado de las consultas, el historial de resultados recientes y el algoritmo de gestión de caché. Cuando un objeto es opaco, el uso de huellas digitales de Rabin [8, 30] para detectar datos comunes entre dos objetos ha sido demostrado con éxito en el pasado por sistemas como LBFS [26] y CASPER [37]. El fingerprinting de Rabin utiliza una ventana deslizante sobre los datos para calcular un hash rodante. Suponiendo que la función hash está distribuida uniformemente, un límite de fragmento se define cuando los bits de orden inferior del valor hash son iguales a algún valor predeterminado. El número de bits de orden inferior utilizados define el tamaño promedio del fragmento. Estos fragmentos subdivididos del objeto se convierten en la unidad de comparación para detectar similitudes entre diferentes objetos. Dado que las ubicaciones de los límites encontrados mediante el uso de las huellas de Rabin están determinadas de manera estocástica, generalmente no logran alinearse con ninguna propiedad estructural de los datos subyacentes. Por lo tanto, el algoritmo maneja bien las actualizaciones en su lugar, inserciones y eliminaciones. Sin embargo, tiene un rendimiento deficiente en presencia de cualquier reordenamiento de datos. La Figura 2 muestra un ejemplo donde dos resultados, A y B, que constan de tres filas, tienen los mismos datos pero diferentes atributos de ordenamiento. En el caso extremo, la huella digital de Rabin podría no ser capaz de encontrar datos similares debido a la forma en que detecta los límites de los fragmentos. Afortunadamente, Ganesh puede utilizar conocimientos específicos del dominio para una detección de límites más precisa. La información que explotamos es que el resultado de una consulta refleja la estructura de una base de datos relacional donde todos los datos están organizados en tablas y filas. Por lo tanto, es sencillo verificar la similitud con resultados anteriores en dos niveles de granularidad: primero el resultado completo y luego las filas individuales. El final de una fila en un resultado sirve como un límite natural de fragmento. Es importante tener en cuenta que el uso de la estructura tabular en los resultados solo implica una interpretación superficial de los datos. Ganesh no realiza ninguna interpretación semántica más profunda, como comprender tipos de datos, esquemas de resultados o restricciones de integridad. Ajustar la huella digital de Rabin para una carga de trabajo también puede ser difícil. Si el tamaño promedio de los fragmentos es demasiado grande, los fragmentos pueden abarcar varias filas de resultados. Sin embargo, seleccionar un tamaño de fragmento promedio más pequeño aumenta la cantidad de metadatos necesarios para describir los resultados. Esto, a su vez, disminuiría los ahorros obtenidos mediante su uso. El fingerprinting de Rabin también requiere dos pasadas computacionalmente costosas sobre los datos: una vez para determinar los límites de los fragmentos y otra vez para generar hashes criptográficos para los fragmentos. Ganesh solo necesita un único pase para la generación de hash, ya que los límites de los fragmentos son proporcionados por la estructura natural de los datos. La comparación de rendimiento en la Sección 6 muestra que el algoritmo basado en filas de Ganesh supera al fingerprinting de Rabin. Dado que trabajos anteriores ya han demostrado que la huella digital de Rabin funciona mejor que gzip [26], no comparamos a Ganesh con algoritmos de compresión en este artículo. 3.2 Transparencia El factor clave que influyó en nuestro diseño fue la necesidad de que Ganesh fuera completamente transparente para todos los componentes de un sistema típico de comercio electrónico: servidores web, servidores de aplicaciones y servidores de bases de datos. Sin esto, Ganesh tiene pocas posibilidades de tener un impacto significativo en el mundo real. Requerir modificaciones en cualquiera de los componentes mencionados aumentaría la barrera de entrada de Ganesh en un sistema existente, y por lo tanto reduciría sus posibilidades de adopción. Preservar la transparencia se simplifica por el hecho de que Ganesh es simplemente una mejora de rendimiento, no una mejora de funcionalidad o usabilidad. Elegimos la interposición de agentes como enfoque arquitectónico para lograr nuestro objetivo. Este enfoque se basa en la existencia de una interfaz de programación compacta que ya es ampliamente utilizada por el software objetivo. También se basa en un mecanismo para agregar fácilmente nuevo código sin interrumpir la estructura de módulos existente. Estas condiciones se cumplen fácilmente en nuestro contexto debido a la popularidad de Java como el lenguaje de programación para sistemas de comercio electrónico. La API de Conectividad de Base de Datos de Java (JDBC) [32] permite a las aplicaciones de Java acceder a una amplia variedad de bases de datos e incluso a otros repositorios de datos tabulares como archivos planos. El acceso a estas fuentes de datos es proporcionado por controladores JDBC que traducen entre la API JDBC y el mecanismo de comunicación de la base de datos. La figura 3(a) muestra cómo se utiliza típicamente JDBC en una aplicación. Dado que la interfaz JDBC está estandarizada, se puede sustituir un controlador JDBC por otro sin necesidad de de modificar la aplicación. El controlador JDBC se convierte así en el módulo natural para aprovechar la interposición de código. Como se muestra en la Figura 3(b), el controlador JDBC nativo es reemplazado por un controlador JDBC Ganesh que presenta la misma interfaz estandarizada. El controlador Ganesh mantiene una caché en memoria de fragmentos de resultados de consultas anteriores y realiza el reensamblaje de resultados. En la base de datos, agregamos un nuevo proceso llamado el proxy Ganesh. Este proxy, que puede ser compartido por múltiples nodos front-end, consta de dos partes: código para detectar similitud en fragmentos de resultados y el controlador JDBC nativo original que se comunica con la base de datos. El uso de un proxy en la base de datos hace que Ganesh sea independiente de la base de datos y simplifica la creación de prototipos y experimentación. Ganesh es capaz de trabajar con una amplia gama de bases de datos y aplicaciones, sin necesidad de realizar modificaciones en ninguna de ellas. 3.3 Caché basada en proxy El controlador JDBC nativo mostrado en la Figura 3(a) es un componente de código ligero suministrado por el proveedor de la base de datos. Su función principal es mediar la comunicación entre la aplicación y la base de datos remota. Reenvía consultas, almacena resultados completos y responde a solicitudes de la aplicación para ver partes de los resultados. El controlador JDBC de Ganesh mostrado en la Figura 3(b) presenta a la aplicación una interfaz idéntica a la proporcionada por el controlador nativo. Proporciona la capacidad de reconstruir resultados a partir de descripciones compactas basadas en hash enviadas por el proxy. Para realizar esta reconstrucción, el controlador mantiene una caché en memoria de los resultados recibidos recientemente. Esta caché solo se utiliza como fuente de fragmentos de resultados en la reconstrucción de resultados. El conductor Ganesh o el proxy no intentan rastrear las actualizaciones de la base de datos. La falta de consistencia en la caché no afecta a la corrección, ya que la descripción de los resultados siempre se obtiene del proxy; en el peor de los casos, no habrá beneficio de rendimiento al usar Ganesh. Los datos obsoletos simplemente se eliminarán de la caché con el tiempo. El proxy de Ganesh accede a la base de datos a través del controlador JDBC nativo, que permanece sin cambios entre las Figuras 3(a) y (b). La base de datos está completamente ajena a la existencia del proxy. El proxy no examina ninguna consulta recibida del controlador Ganesh, sino que las pasa al controlador nativo. En cambio, el proxy es responsable de inspeccionar la salida de la base de datos recibida del controlador nativo, detectar resultados similares y generar codificaciones basadas en hash de estos resultados siempre que se encuentre suficiente similitud. Si bien esta arquitectura no disminuye la carga en una base de datos, como se mencionó anteriormente en la Sección 2.1, es mucho más fácil replicar bases de datos para escalabilidad en una LAN que en una WAN. Para generar una codificación basada en hash, el proxy debe estar al tanto de qué fragmentos de resultados están disponibles en la caché de controladores de Ganesh. Un enfoque es ser optimista y asumir que todos los fragmentos de resultados están disponibles. Esto resultará en la transmisión inicial más pequeña posible de un resultado. Sin embargo, en casos donde hay poca superposición con resultados anteriores, el controlador Ganesh tendrá que realizar muchas llamadas al proxy durante la reconstrucción para recuperar fragmentos de resultados faltantes. Para evitar esta situación, el proxy sigue de manera flexible el estado de la caché de controladores de Ganesh. Dado que ambos componentes están bajo nuestro control, es relativamente sencillo hacer esto sin recurrir a técnicas de caja gris o comunicación explícita para mantener la coherencia de la caché. En cambio, el proxy simula el algoritmo de gestión de caché de controladores de Ganesh y lo utiliza para mantener una lista de hashes para los cuales es probable que el controlador de Ganesh posea los fragmentos de resultado. En caso de desviación de seguimiento, no habrá pérdida de corrección, pero habrá retrasos adicionales en el viaje de ida y vuelta para recuperar los fragmentos faltantes. Si el cliente detecta la pérdida de sincronización con el proxy, puede pedirle al proxy que restablezca el estado compartido entre ellos. También hay que tener en cuenta que el proxy no necesita guardar los fragmentos de resultado en sí, solo sus hashes. Esto permite que el proxy siga siendo escalable incluso cuando es compartido por muchos nodos front-end. El proxy Ganesh recibe la salida de la base de datos como objetos Java del controlador JDBC nativo. Examina esta salida para ver si está presente un objeto Java del tipo ResultSet. La interfaz JDBC utiliza este tipo de dato para almacenar los resultados de las consultas a la base de datos. Si se encuentra un objeto ResultSet, se reduce como se discute a continuación. Todos los demás objetos de Java se pasan sin modificar. Como se discute en la Sección 3.1, el proxy utiliza los límites de fila definidos en el ResultSet para dividirlo en fragmentos que consisten en filas de resultado individuales. Todos los objetos ResultSet se convierten en objetos de un nuevo tipo llamado RecipeResultSet. Utilizamos el término receta para esta descripción compacta de un resultado de base de datos debido a su similitud con una receta de archivo en el sistema de archivos CASPER [37]. La conversión reemplaza cada fragmento de resultado que probablemente esté presente en la caché de controladores de Ganesh por un hash SHA-1 de ese fragmento. Los fragmentos de resultados previamente no vistos se conservan textualmente. El proxy también retiene los hashes de los nuevos fragmentos de resultados, ya que estarán presentes en la caché de los controladores en el futuro. Ten en cuenta que el proxy solo almacena en caché los hashes de los fragmentos de resultados y no almacena en caché las recetas. El proxy construye un RecipeResultSet verificando la similitud en todo el resultado y luego a nivel de fila. Si se predice que todo el resultado estará presente en la caché de los controladores de Ganesh, el RecipeResultSet será simplemente un único hash de todo el resultado. De lo contrario, contiene hashes para aquellas filas que se predice que están presentes en esa caché; todas las demás filas se conservan textualmente. Si el proxy estima un ahorro de espacio general, transmitirá el RecipeResultSet. De lo contrario, se transmite el ResultSet original. Los objetos RecipeResultSet son transformados de vuelta en objetos ResultSet por el controlador Ganesh. La Figura 4 ilustra el manejo de ResultSet en ambos extremos. Cada hash SHA-1 encontrado en un RecipeResultSet se busca en la caché local de fragmentos de resultados. En caso de acierto, el hash es reemplazado por el fragmento correspondiente. En caso de error, el conductor contacta al proxy de Ganesh para recuperar el fragmento. Todos los fragmentos de resultados previamente no vistos que fueron retenidos textualmente por el proxy se hasheado y se han añadido a la caché de resultados. Debería haber muy pocos fallos si el proxy ha seguido con precisión el estado de la caché de controladores de Ganesh. Una optimización futura sería agrupar la obtención de fragmentos faltantes. Esto sería valioso cuando hay muchos pequeños fragmentos faltantes en una WAN de alta latencia. Una vez que la transformación esté completa, el objeto ResultSet completamente reconstruido se pasa a la aplicación. 4. VALIDACIÓN EXPERIMENTAL Tres preguntas surgen de los objetivos y diseño de Ganesh: • Primero, ¿se puede mejorar significativamente el rendimiento al explotar la similitud entre los resultados de la base de datos? Detalles del conjunto de datos de referencia 500,000 usuarios, 12,000 historias BBOARD 2.0 GB 3,298,000 comentarios SUBASTA 1.3 GB 1,000,000 usuarios, 34,000 elementos Tabla 1: Detalles del conjunto de datos de referencia • En segundo lugar, ¿qué tan importante es la detección de similitud estructural de Ganesh en comparación con la detección de similitud de la huella digital de Rabin? • En tercer lugar, ¿es aceptable la sobrecarga del diseño basado en proxy? Nuestra evaluación responde a estas preguntas a través de experimentos controlados con el prototipo Ganesh. Esta sección describe los puntos de referencia utilizados, nuestro procedimiento de evaluación y la configuración experimental. Los resultados de los experimentos se presentan en las Secciones 5, 6 y 7. 4.1 Puntos de referencia Nuestra evaluación se basa en dos puntos de referencia [18] que han sido ampliamente utilizados por otros investigadores para evaluar varios aspectos de arquitecturas multi-tier [27] y de comercio electrónico [9]. El primer punto de referencia, BBOARD, está modelado según Slashdot, un sitio de noticias orientado a la tecnología. El segundo punto de referencia, AUCTION, está modelado según eBay, un sitio de subastas en línea. En ambos puntos de referencia, la mayoría del contenido se genera dinámicamente a partir de la información almacenada en una base de datos. Los detalles de los conjuntos de datos utilizados se pueden encontrar en la Tabla 1. 4.1.1 El <br>Benchmark BBOARD</br> El benchmark BBOARD, también conocido como RUBBoS [18], modela Slashdot, un popular sitio web orientado a la tecnología. Slashdot recopila enlaces a noticias y otros temas de interés encontrados en otros lugares de la web. El sitio también funciona como un tablón de anuncios al permitir a los usuarios comentar en las historias publicadas en forma de conversación en hilos. No es raro que una historia recopile cientos de comentarios en cuestión de horas. El <br>benchmark BBOARD</br> es similar al sitio y modela las actividades de un usuario, incluyendo operaciones de solo lectura como navegar por las historias del día, explorar categorías de historias y ver comentarios, así como operaciones de escritura como registro de nuevos usuarios, agregar y moderar comentarios, y enviar historias. El benchmark consiste en tres fases diferentes: una fase de calentamiento corta, una fase de ejecución que representa el cuerpo principal de la carga de trabajo, y una fase de enfriamiento corta. En este documento solo informamos sobre los resultados de la fase de ejecución. La fase de calentamiento es importante para establecer el estado del sistema dinámico, pero las mediciones de esa fase no son significativas para nuestra evaluación. La fase de enfriamiento es únicamente para permitir que el punto de referencia se apague. Las fases de calentamiento, ejercicio y enfriamiento son de 2, 15 y 2 minutos respectivamente. El número de clientes simulados fue de 400, 800, 1200 y 1600. El punto de referencia está disponible en una versión de Java Servlets y PHP y tiene diferentes conjuntos de datos; evaluamos a Ganesh utilizando la versión de Java Servlets y el conjunto de datos Expandido. El <br>benchmark BBOARD</br> define dos cargas de trabajo diferentes. El primero, la mezcla de Autoría, consiste en un 70% de operaciones de solo lectura y un 30% de operaciones de lectura y escritura. El segundo, la mezcla de navegación, contiene solo operaciones de solo lectura y no actualiza la base de datos. 4.1.2 El Benchmark de SUBASTA El benchmark de SUBASTA, también conocido como RUBiS [18], modela eBay, el sitio de subastas en línea. El sitio web de eBay se utiliza para comprar y vender artículos a través de un formato de subasta. Las principales actividades de un usuario incluyen navegar, vender o pujar por artículos. Modelando las actividades en este sitio, este punto de referencia incluye actividades de solo lectura como navegar por artículos por categoría y por región, así como actividades de lectura-escritura como pujar por artículos, comprar y vender artículos, y dejar comentarios. Al igual que con BBOARD, el benchmark consiste en tres fases diferentes. Las fases de calentamiento, ejecución y enfriamiento para este experimento son de 1.5, 15 y 1 minutos respectivamente. Probamos Ganesh con cuatro configuraciones de clientes donde el número de clientes de prueba se estableció en 400, 800, 1200 y 1600. El punto de referencia está disponible en una versión de Enterprise Java Bean (EJB), Java Servlets y PHP y tiene diferentes conjuntos de datos; evaluamos Ganesh con la versión de Java Servlets y el conjunto de datos Expandido. El benchmark de SUBASTA define dos cargas de trabajo diferentes. El primero, la mezcla de Ofertas, consiste en un 70% de operaciones de solo lectura y un 30% de operaciones de lectura-escritura. El segundo, la mezcla de navegación, contiene solo operaciones de solo lectura y no actualiza la base de datos. 4.2 Procedimiento Experimental Ambos benchmarks involucran una carga de trabajo sintética de clientes accediendo a un servidor web. El número de clientes emulados es un parámetro experimental. Cada cliente emulado ejecuta una instancia del benchmark en su propio hilo, utilizando una matriz para hacer la transición entre diferentes estados del benchmark. La matriz define un modelo estocástico con probabilidades de transición entre los diferentes estados que representan las acciones típicas de los usuarios. Un ejemplo de transición es un usuario iniciando sesión en el sistema de SUBASTA y luego decidiendo si publicar un artículo en venta o pujar en subastas activas. Cada cliente también modela el tiempo de pensamiento del usuario entre las solicitudes. El tiempo de pensamiento se modela como una distribución exponencial con una media de 7 segundos. Evaluamos a Ganesh a lo largo de dos ejes: número de clientes y ancho de banda de la WAN. Las cargas más altas son especialmente útiles para comprender el rendimiento de Ganesh cuando la CPU o el disco del servidor de base de datos o del proxy son el factor limitante. Un estudio previo ha demostrado que aproximadamente el 50% de los cuellos de botella de Internet de gran área observados tenían un ancho de banda disponible inferior a 10 Mb/s [1]. Basándonos en este trabajo, enfocamos nuestra evaluación en el ancho de banda de la WAN de 5 Mb/s con una latencia de ida y vuelta de 66 ms, representativa de rutas de red severamente restringidas, y 20 Mb/s con una latencia de ida y vuelta de 33 ms, representativa de una ruta de red moderadamente restringida. También informamos sobre el rendimiento de Ganesh a 100 Mb/s sin agregar latencia de ida y vuelta. Este ancho de banda, representativo de una red sin restricciones, es especialmente útil para revelar cualquier sobrecarga potencial de Ganesh en situaciones donde el ancho de banda de la WAN no es el factor limitante. Para cada combinación de número de clientes y ancho de banda de WAN, medimos los resultados de las dos configuraciones enumeradas a continuación: • Nativa: Esta configuración corresponde a la Figura 3(a). El nativo evita la sobrecarga de Ganesh al usar un proxy y realizar la serialización de objetos Java. • Ganesh: Esta configuración corresponde a la Figura 3(b). Para un número dado de clientes y ancho de banda de WAN, comparar estos resultados con los resultados nativos correspondientes proporciona el beneficio de rendimiento debido al sistema de middleware Ganesh. La métrica utilizada para cuantificar la mejora en el rendimiento es el número de solicitudes de clientes que pueden ser atendidas por segundo. La métrica utilizada para cuantificar el rendimiento de Ganesh es el tiempo promedio de respuesta para una solicitud de cliente. Para todos los experimentos, el controlador Ganesh utilizado por el servidor de aplicaciones usó un tamaño de caché de 100,000 elementos. El proxy fue efectivo en rastrear el estado de la caché de los controladores Ganesh; para todos nuestros experimentos, la tasa de fallos en el controlador nunca superó el 0.7%. 4.3 Configuración Experimental La configuración experimental utilizada para las pruebas se puede ver en la Figura 5. Todas las máquinas eran Pentium 4 de 3.2 GHz (con HyperThreading habilitado). Con la excepción del servidor de base de datos, todas las máquinas tenían 2 GB de SDRAM y ejecutaban la distribución de Linux Fedora Core. El servidor de la base de datos tenía 4 GB de SDRAM. Utilizamos Apache Tomcat como tanto el servidor de aplicaciones que alojaba los Servlets de Java como el servidor web. Ambos benchmarks utilizaron Java Servlets para generar el contenido dinámico. El servidor de la base de datos utilizó la base de datos de código abierto MySQL. Para los controladores JDBC nativos, utilizamos los controladores Connector/J proporcionados por MySQL. El servidor de aplicaciones utilizaba la Máquina Virtual de Java de Sun como entorno de ejecución para los Servlets de Java. La herramienta sysstat se utilizó para monitorear la utilización de la CPU, red, disco y memoria en todas las máquinas. Las máquinas estaban conectadas por una red Ethernet gigabit conmutada. Como se muestra en la Figura 5, el servidor web y de aplicación de front-end fue separado del servidor de proxy y base de datos por un enrutador NetEm [16]. Este enrutador nos permitió controlar la configuración de ancho de banda y latencia en la red. El enrutador NetEm es un PC estándar con dos tarjetas de red que ejecuta el software de Control de Tráfico de Linux y Emulación de Red. Las restricciones de ancho de banda y latencia solo se aplicaron al enlace entre el servidor de aplicaciones y la base de datos para el caso nativo y entre el servidor de aplicaciones y el proxy para el caso de Ganesh. No hay comunicación entre el servidor de aplicaciones y la base de datos con Ganesh, ya que todos los datos fluyen a través del proxy. Como nuestro enfoque estaba en el enlace WAN entre el servidor de aplicaciones y la base de datos, no hubo restricciones en el enlace entre los clientes de prueba simulados y el servidor web. 5. DESEMPEÑO Y TIEMPO DE RESPUESTA En esta sección, abordamos la primera pregunta planteada en la Sección 4: ¿Se puede mejorar significativamente el rendimiento explotando la similitud entre los resultados de la base de datos? Para responder a esta pregunta, utilizamos los resultados de los benchmarks BBOARD y AUCTION. Utilizamos dos métricas para cuantificar la mejora en el rendimiento obtenible a través del uso de Ganesh: el throughput, desde la perspectiva del servidor web, y el tiempo de respuesta promedio, desde la perspectiva del cliente. El rendimiento se mide en términos del número de solicitudes de clientes que pueden ser atendidas por segundo. Los resultados y análisis de BBOARD 5.1 Figuras 6 (a) y (b) presentan el número promedio de solicitudes atendidas por segundo y el tiempo de respuesta promedio para estas solicitudes tal como lo perciben los clientes para la Mezcla de Autoría de BBOARD. Como muestra la Figura 6 (a), Native satura fácilmente el enlace de 5 Mb/s. Con 400 clientes, la solución nativa entrega 29 solicitudes/segundo con un tiempo de respuesta promedio de 8.3 segundos. La capacidad de procesamiento de los clientes disminuye con un aumento en los clientes de prueba, ya que los clientes se agotan debido a la congestión en el servidor de aplicaciones. Los estudios de usabilidad han demostrado que los tiempos de respuesta superiores a 10 segundos hacen que el usuario pase a 1. Dado que Java carece de un operador sizeof(), los cachés de Java limitan su tamaño en función del número de objetos. El tamaño de los volcados de caché tomados al final de los experimentos nunca superó los 212 MB. WWW 2007 / Pista: Rendimiento y Escalabilidad Sesión: Sistemas Escalables para Contenido Dinámico 315 0 50 100 150 200 250 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Solicitudes de Clientes de Prueba por Segundo Nativo Ganesh 0.001 0.01 0.1 1 10 100 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Tiempo Promedio de Respuesta de Clientes de Prueba Nativo Ganesh Nota Escala Logarítmica (a) Rendimiento: Mezcla de Autoría (b) Tiempo de Respuesta: Mezcla de Autoría 0 50 100 150 200 250 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Solicitudes de Clientes de Prueba por Segundo Nativo Ganesh 0.001 0.01 0.1 1 10 100 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Tiempo Promedio de Respuesta de Clientes de Prueba Nativo Ganesh Nota Escala Logarítmica (c) Rendimiento: Mezcla de Navegación (d) Tiempo de Respuesta: Mezcla de Navegación Promedio de tres pruebas. La desviación estándar máxima para el rendimiento y el tiempo de respuesta fue del 9.8% y 11.9% de la media correspondiente. Figura 6: BBOARD Benchmark - Rendimiento y Tiempo de Respuesta Promedio de otras tareas [24]. Basándose en estos números, aumentar el número de clientes de prueba hace que el sistema Nativo sea inutilizable. Ganesh a 5 Mb/s, sin embargo, ofrece una mejora doble con 400 clientes de prueba y una mejora quintuple con 1200 clientes. El rendimiento de Ganesh disminuye ligeramente a 1200 y 1600 clientes debido a que la red está saturada. En comparación con Native, la Figura 6 (b) muestra que los tiempos de respuesta de Ganesh son considerablemente más bajos con tiempos de respuesta de menos de un segundo con 400 clientes. La Figura 6 (a) también muestra que para 400 y 800 clientes de prueba, Ganesh a 5 Mb/s tiene el mismo rendimiento y tiempo de respuesta promedio que Native a 20 Mb/s. Solo con 1200 y 1600 clientes, Native a 20 Mb/s ofrece un rendimiento mayor que Ganesh a 5 Mb/s. Al comparar tanto a Ganesh como a Native a 20 Mb/s, vemos que Ganesh ya no está limitado por el ancho de banda y ofrece hasta una mejora del doble sobre Native con 1600 clientes de prueba. Como Ganesh no satura la red con configuraciones de cliente de prueba más altas, con 1600 clientes de prueba, su tiempo de respuesta promedio es de 0.1 segundos en lugar de los 7.7 segundos de Natives. Como era de esperar, no hay ganancias visibles de Ganesh en el ancho de banda más alto de 100 Mb/s donde la red ya no es el cuello de botella. Sin embargo, Ganesh sigue monitoreando a Native en cuanto a rendimiento. Las Figuras 6 (c) y (d) presentan el número promedio de solicitudes atendidas por segundo y el tiempo de respuesta promedio para estas solicitudes tal como lo perciben los clientes para la Mezcla de Navegación de BBOARDs. Independientemente de la configuración del cliente de prueba, la Figura 6 (c) muestra que el rendimiento de los Nativos a 5 Mb/s está limitado a 10 reqs/seg. Ganesh a 5 Mb/s con 400 clientes de prueba, ofrece un aumento de más de seis veces en el rendimiento. La mejora aumenta a más de once veces a 800 clientes de prueba antes de que Ganesh sature la red. Además, la Figura 6 (d) muestra que el tiempo de respuesta promedio de los Nativos de 35 segundos con 400 clientes de prueba hace que el sistema sea inutilizable. Estos altos tiempos de respuesta aumentan aún más con la adición de clientes de prueba. Incluso con la configuración del cliente de prueba de 1600, Ganesh ofrece un tiempo de respuesta promedio aceptable de 8.2 segundos. Debido a la naturaleza intensiva en datos de la mezcla de navegación, Ganesh a 5 Mb/s sorprendentemente tiene un rendimiento mucho mejor que Native a 20 Mb/s. Además, como se muestra en la Figura 6 (d), si bien el tiempo de respuesta promedio para Native a 20 Mb/s es aceptable con 400 clientes de prueba, resulta inutilizable con 800 clientes de prueba, con un tiempo de respuesta promedio de 15.8 segundos. Al igual que en el caso de 5 Mb/s, este tiempo de respuesta aumenta con la adición de clientes de prueba adicionales. Ganesh a 20 Mb/s y tanto Native como Ganesh a 100 Mb/s no tienen limitaciones de ancho de banda. Sin embargo, el rendimiento se estanca después de 1200 clientes de prueba debido a que la CPU de la base de datos está saturada. 5.1.3 Variante de filtro Nos sorprendió el rendimiento nativo del <br>benchmark BBOARD</br>. ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "read-write operation": {
            "translated_key": "operaciones de lectura y escritura",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Consistency-preserving Caching of Dynamic Database Content∗ Niraj Tolia and M. Satyanarayanan Carnegie Mellon University {ntolia,satya}@cs.cmu.edu ABSTRACT With the growing use of dynamic web content generated from relational databases, traditional caching solutions for throughput and latency improvements are ineffective.",
                "We describe a middleware layer called Ganesh that reduces the volume of data transmitted without semantic interpretation of queries or results.",
                "It achieves this reduction through the use of cryptographic hashing to detect similarities with previous results.",
                "These benefits do not require any compromise of the strict consistency semantics provided by the back-end database.",
                "Further, Ganesh does not require modifications to applications, web servers, or database servers, and works with closed-source applications and databases.",
                "Using two benchmarks representative of dynamic web sites, measurements of our prototype show that it can increase end-to-end throughput by as much as twofold for non-data intensive applications and by as much as tenfold for data intensive ones.",
                "Categories and Subject Descriptors C.2.4 [Computer-Communication Networks]: Distributed Systems; H.2.4 [Database Management]: Systems General Terms Design, Performance 1.",
                "INTRODUCTION An increasing fraction of web content is dynamically generated from back-end relational databases.",
                "Even when database content remains unchanged, temporal locality of access cannot be exploited because dynamic content is not cacheable by web browsers or by intermediate caching servers such as Akamai mirrors.",
                "In a multitiered architecture, each web request can stress the WAN link between the web server and the database.",
                "This causes user experience to be highly variable because there is no caching to insulate the client from bursty loads.",
                "Previous attempts in caching dynamic database content have generally weakened transactional semantics [3, 4] or required application modifications [15, 34].",
                "We report on a new solution that takes the form of a databaseagnostic middleware layer called Ganesh.",
                "Ganesh makes no effort to semantically interpret the contents of queries or their results.",
                "Instead, it relies exclusively on cryptographic hashing to detect similarities with previous results.",
                "Hash-based similarity detection has seen increasing use in distributed file systems [26, 36, 37] for improving performance on low-bandwidth networks.",
                "However, these techniques have not been used for relational databases.",
                "Unlike previous approaches that use generic methods to detect similarity, Ganesh exploits the structure of relational database results to yield superior performance improvement.",
                "One faces at least three challenges in applying hash-based similarity detection to back-end databases.",
                "First, previous work in this space has traditionally viewed storage content as uninterpreted bags of bits with no internal structure.",
                "This allows hash-based techniques to operate on long, contiguous runs of data for maximum effectiveness.",
                "In contrast, relational databases have rich internal structure that may not be as amenable to hash-based similarity detection.",
                "Second, relational databases have very tight integrity and consistency constraints that must not be compromised by the use of hash-based techniques.",
                "Third, the source code of commercial databases is typically not available.",
                "This is in contrast to previous work which presumed availability of source code.",
                "Our experiments show that Ganesh, while conceptually simple, can improve performance significantly at bandwidths representative of todays commercial Internet.",
                "On benchmarks modeling multitiered web applications, the throughput improvement was as high as tenfold for data-intensive workloads.",
                "For workloads that were not data-intensive, throughput improvements of up to twofold were observed.",
                "Even when bandwidth was not a constraint, Ganesh had low overhead and did not hurt performance.",
                "Our experiments also confirm that exploiting the structure present in database results is crucial to this performance improvement. 2.",
                "BACKGROUND 2.1 Dynamic Content Generation As the World Wide Web has grown, many web sites have decentralized their data and functionality by pushing them to the edges of the Internet.",
                "Today, eBusiness systems often use a three-tiered architecture consisting of a front-end web server, an application server, and a back-end database server.",
                "Figure 1 illustrates this architecture.",
                "The first two tiers can be replicated close to a concentration of clients at the edge of the Internet.",
                "This improves user experience by lowering end-to-end latency and reducing exposure WWW 2007 / Track: Performance and Scalability Session: Scalable Systems for Dynamic Content 311 Back-End Database Server Front-End Web and Application Servers Figure 1: Multi-Tier Architecture to backbone traffic congestion.",
                "It can also increase the availability and scalability of web services.",
                "Content that is generated dynamically from the back-end database cannot be cached in the first two tiers.",
                "While databases can be easily replicated in a LAN, this is infeasible in a WAN because of the difficult task of simultaneously providing strong consistency, availability, and tolerance to network partitions [7].",
                "As a result, databases tend to be centralized to meet the strong consistency requirements of many eBusiness applications such as banking, finance, and online retailing [38].",
                "Thus, the back-end database is usually located far from many sets of first and second-tier nodes [2].",
                "In the absence of both caching and replication, WAN bandwidth can easily become a limiting factor in the performance and scalability of data-intensive applications. 2.2 Hash-Based Systems Ganeshs focus is on efficient transmission of results by discovering similarities with the results of previous queries.",
                "As SQL queries can generate large results, hash-based techniques lend themselves well to the problem of efficiently transferring these large results across bandwidth constrained links.",
                "The use of hash-based techniques to reduce the volume of data transmitted has emerged as a common theme of many recent storage systems, as discussed in Section 8.2.",
                "These techniques rely on some basic assumptions.",
                "Cryptographic hash functions are assumed to be collision-resistant.",
                "In other words, it is computationally intractable to find two inputs that hash to the same output.",
                "The functions are also assumed to be one-way; that is, finding an input that results in a specific output is computationally infeasible.",
                "Menezes et al. [23] provide more details about these assumptions.",
                "The above assumptions allow hash-based systems to assume that collisions do not occur.",
                "Hence, they are able to treat the hash of a data item as its unique identifier.",
                "A collection of data items effectively becomes content-addressable, allowing a small hash to serve as a codeword for a much larger data item in permanent storage or network transmission.",
                "The assumption that collisions are so rare as to be effectively non-existent has recently come under fire [17].",
                "However, as explained by Black [5], we believe that these issues do not form a concern for Ganesh.",
                "All communication is between trusted parts of the system and an adversary has no way to force Ganesh to accept invalid data.",
                "Further, Ganesh does not depend critically on any specific hash function.",
                "While we currently use SHA-1, replacing it with a different hash function would be simple.",
                "There would be no impact on performance as stronger hash functions (e.g.",
                "SHA256) only add a few extra bytes and the generated hashes are still orders of magnitude smaller than the data items they represent.",
                "No re-hashing of permanent storage is required since Ganesh only uses hashing on volatile data. 3.",
                "DESIGN AND IMPLEMENTATION Ganesh exploits redundancy in the result stream to avoid transmitting result fragments that are already present at the query site.",
                "Redundancy can arise naturally in many different ways.",
                "For example, a query repeated after a certain interval may return a different result because of updates to the database; however, there may be significant commonality between the two results.",
                "As another example, a user who is refining a search may generate a sequence of queries with overlapping results.",
                "When Ganesh detects redundancy, it suppresses transmission of the corresponding result fragments.",
                "Instead, it transmits a much smaller digest of those fragments and lets the query site reconstruct the result through hash lookup in a cache of previous results.",
                "In effect, Ganesh uses computation at the edges to reduce Internet communication.",
                "Our description of Ganesh focuses on four aspects.",
                "We first explain our approach to detecting similarity in query results.",
                "Next, we discuss how the Ganesh architecture is completely invisible to all components of a multi-tier system.",
                "We then describe Ganeshs proxy-based approach and the dataflow for detecting similarity. 3.1 Detecting Similarity One of the key design decisions in Ganesh is how similarity is detected.",
                "There are many potential ways to decompose a result into fragments.",
                "The optimal way is, of course, the one that results in the smallest possible object for transmission for a given querys results.",
                "Finding this optimal decomposition is a difficult problem because of the large space of possibilities and because the optimal choice depends on many factors such as the contents of the querys result, the history of recent results, and the cache management algorithm.",
                "When an object is opaque, the use of Rabin fingerprints [8, 30] to detect common data between two objects has been successfully shown in the past by systems such as LBFS [26] and CASPER [37].",
                "Rabin fingerprinting uses a sliding window over the data to compute a rolling hash.",
                "Assuming that the hash function is uniformly distributed, a chunk boundary is defined whenever the lower order bits of the hash value equal some predetermined value.",
                "The number of lower order bits used defines the average chunk size.",
                "These sub-divided chunks of the object become the unit of comparison for detecting similarity between different objects.",
                "As the locations of boundaries found by using Rabin fingerprints is stochastically determined, they usually fail to align with any structural properties of the underlying data.",
                "The algorithm therefore deals well with in-place updates, insertions and deletions.",
                "However, it performs poorly in the presence of any reordering of data.",
                "Figure 2 shows an example where two results, A and B, consisting of three rows, have the same data but have different sort attributes.",
                "In the extreme case, Rabin fingerprinting might be unable to find any similar data due to the way it detects chunk boundaries.",
                "Fortunately, Ganesh can use domain specific knowledge for more precise boundary detection.",
                "The information we exploit is that a querys result reflects the structure of a relational database where all data is organized as tables and rows.",
                "It is therefore simple to check for similarity with previous results at two granularities: first the entire result, and then individual rows.",
                "The end of a row in a result serves as a natural chunk boundary.",
                "It is important to note that using the tabular structure in results only involves shallow interpretation of the data.",
                "Ganesh does not perform any deeper semantic interpretation such as understanding data types, result schema, or integrity constraints.",
                "Tuning Rabin fingerprinting for a workload can also be difficult.",
                "If the average chunk size is too large, chunks can span multiple result rows.",
                "However, selecting a smaller average chunk size increases the amount of metadata required to the describe the results.",
                "WWW 2007 / Track: Performance and Scalability Session: Scalable Systems for Dynamic Content 312 Figure 2: Rabin Fingerprinting vs. Ganeshs Chunking This, in turn, would decrease the savings obtained via its use.",
                "Rabin fingerprinting also needs two computationally-expensive passes over the data: once to determine chunk boundaries and one again to generate cryptographic hashes for the chunks.",
                "Ganesh only needs a single pass for hash generation as the chunk boundaries are provided by the datas natural structure.",
                "The performance comparison in Section 6 shows that Ganeshs row-based algorithm outperforms Rabin fingerprinting.",
                "Given that previous work has already shown that Rabin fingerprinting performs better than gzip [26], we do not compare Ganesh to compression algorithms in this paper. 3.2 Transparency The key factor influencing our design was the need for Ganesh to be completely transparent to all components of a typical eBusiness system: web servers, application servers, and database servers.",
                "Without this, Ganesh stands little chance of having a significant real-world impact.",
                "Requiring modifications to any of the above components would raise the barrier for entry of Ganesh into an existing system, and thus reduce its chances of adoption.",
                "Preserving transparency is simplified by the fact that Ganesh is purely a performance enhancement, not a functionality or usability enhancement.",
                "We chose agent interposition as the architectural approach to realizing our goal.",
                "This approach relies on the existence of a compact programming interface that is already widely used by target software.",
                "It also relies on a mechanism to easily add new code without disrupting existing module structure.",
                "These conditions are easily met in our context because of the popularity of Java as the programming language for eBusiness systems.",
                "The Java Database Connectivity (JDBC) API [32] allows Java applications to access a wide variety of databases and even other tabular data repositories such as flat files.",
                "Access to these data sources is provided by JDBC drivers that translate between the JDBC API and the database communication mechanism.",
                "Figure 3(a) shows how JDBC is typically used in an application.",
                "As the JDBC interface is standardized, one can substitute one JDBC driver for another without application modifications.",
                "The JDBC driver thus becomes the natural module to exploit for code interposition.",
                "As shown in Figure 3(b), the native JDBC driver is replaced with a Ganesh JDBC driver that presents the same standardized interface.",
                "The Ganesh driver maintains an in-memory cache of result fragments from previous queries and performs reassembly of results.",
                "At the database, we add a new process called the Ganesh proxy.",
                "This proxy, which can be shared by multiple front-end nodes, consists of two parts: code to detect similarity in result fragments and the original native JDBC driver that communicates with the database.",
                "The use of a proxy at the database makes Ganesh database-agnostic and simplifies prototyping and experimentation.",
                "Ganesh is thus able to work with a wide range of databases and applications, requiring no modifications to either. 3.3 Proxy-Based Caching The native JDBC driver shown in Figure 3(a) is a lightweight code component supplied by the database vendor.",
                "Its main funcClient Database Web and Application Server Native JDBC Driver WAN (a) Native Architecture Client Database Ganesh Proxy Native JDBC Driver WAN Web and Application Server Ganesh JDBC Driver (b) Ganeshs Interposition-based Architecture Figure 3: Native vs. Ganesh Architecture tion is to mediate communication between the application and the remote database.",
                "It forwards queries, buffers entire results, and responds to application requests to view parts of results.",
                "The Ganesh JDBC driver shown in Figure 3(b) presents the application with an interface identical to that provided by the native driver.",
                "It provides the ability to reconstruct results from compact hash-based descriptions sent by the proxy.",
                "To perform this reconstruction, the driver maintains an in-memory cache of recentlyreceived results.",
                "This cache is only used as a source of result fragments in reconstructing results.",
                "No attempt is made by the Ganesh driver or proxy to track database updates.",
                "The lack of cache consistency does not hurt correctness as a description of the results is always fetched from the proxy - at worst, there will be no performance benefit from using Ganesh.",
                "Stale data will simply be paged out of the cache over time.",
                "The Ganesh proxy accesses the database via the native JDBC driver, which remains unchanged between Figures 3(a) and (b).",
                "The database is thus completely unaware of the existence of the proxy.",
                "The proxy does not examine any queries received from the Ganesh driver but passes them to the native driver.",
                "Instead, the proxy is responsible for inspecting database output received from the native driver, detecting similar results, and generating hash-based encodings of these results whenever enough similarity is found.",
                "While this architecture does not decrease the load on a database, as mentioned earlier in Section 2.1, it is much easier to replicate databases for scalability in a LAN than in a WAN.",
                "To generate a hash-based encoding, the proxy must be aware of what result fragments are available in the Ganesh drivers cache.",
                "One approach is to be optimistic, and to assume that all result fragments are available.",
                "This will result in the smallest possible initial transmission of a result.",
                "However, in cases where there is little overlap with previous results, the Ganesh driver will have to make many calls to the proxy during reconstruction to fetch missing result fragments.",
                "To avoid this situation, the proxy loosely tracks the state of the Ganesh drivers cache.",
                "Since both components are under our control, it is relatively simple to do this without resorting to gray-box techniques or explicit communication for maintaining cache coherence.",
                "Instead, the proxy simulates the Ganesh drivers cache management algorithm and uses this to maintain a list of hashes for which the Ganesh driver is likely to possess the result fragments.",
                "In case of mistracking, there will be no loss of correctness but there will be extra round-trip delays to fetch the missing fragments.",
                "If the client detects loss of synchronization with the proxy, it can ask the proxy to reset the state shared between them.",
                "Also note that the proxy does not need to keep the result fragments themselves, only their hashes.",
                "This allows the proxy to remain scalable even when it is shared by many front-end nodes.",
                "WWW 2007 / Track: Performance and Scalability Session: Scalable Systems for Dynamic Content 313 Object Output Stream Convert ResultSet Object Input Stream Convert ResultSet All Data Recipe ResultSet All Data ResultSet Network Ganesh Proxy Ganesh JDBC Driver Result Set Recipe Result Set Yes Yes No No GaneshInputStream GaneshOutputStream Figure 4: Dataflow for Result Handling 3.4 Encoding and Decoding Results The Ganesh proxy receives database output as Java objects from the native JDBC driver.",
                "It examines this output to see if a Java object of type ResultSet is present.",
                "The JDBC interface uses this data type to store results of database queries.",
                "If a ResultSet object is found, it is shrunk as discussed below.",
                "All other Java objects are passed through unmodified.",
                "As discussed in Section 3.1, the proxy uses the row boundaries defined in the ResultSet to partition it into fragments consisting of single result rows.",
                "All ResultSet objects are converted into objects of a new type called RecipeResultSet.",
                "We use the term recipe for this compact description of a database result because of its similarity to a file recipe in the CASPER file system [37].",
                "The conversion replaces each result fragment that is likely to be present in the Ganesh drivers cache by a SHA-1 hash of that fragment.",
                "Previously unseen result fragments are retained verbatim.",
                "The proxy also retains hashes for the new result fragments as they will be present in the drivers cache in the future.",
                "Note that the proxy only caches hashes for result fragments and does not cache recipes.",
                "The proxy constructs a RecipeResultSet by checking for similarity at the entire result and then the row level.",
                "If the entire result is predicted to be present in the Ganesh drivers cache, the RecipeResultSet is simply a single hash of the entire result.",
                "Otherwise, it contains hashes for those rows predicted to be present in that cache; all other rows are retained verbatim.",
                "If the proxy estimates an overall space savings, it will transmit the RecipeResultSet.",
                "Otherwise the original ResultSet is transmitted.",
                "The RecipeResultSet objects are transformed back into ResultSet objects by the Ganesh driver.",
                "Figure 4 illustrates ResultSet handling at both ends.",
                "Each SHA-1 hash found in a RecipeResultSet is looked up in the local cache of result fragments.",
                "On a hit, the hash is replaced by the corresponding fragment.",
                "On a miss, the driver contacts the Ganesh proxy to fetch the fragment.",
                "All previously unseen result fragments that were retained verbatim by the proxy are hashed and added to the result cache.",
                "There should be very few misses if the proxy has accurately tracked the Ganesh drivers cache state.",
                "A future optimization would be to batch the fetch of missing fragments.",
                "This would be valuable when there are many small missing fragments in a high-latency WAN.",
                "Once the transformation is complete, the fully reconstructed ResultSet object is passed up to the application. 4.",
                "EXPERIMENTAL VALIDATION Three questions follow from the goals and design of Ganesh: • First, can performance can be improved significantly by exploiting similarity across database results?",
                "Benchmark Dataset Details 500,000 Users, 12,000 Stories BBOARD 2.0 GB 3,298,000 Comments AUCTION 1.3 GB 1,000,000 Users, 34,000 Items Table 1: Benchmark Dataset Details • Second, how important is Ganeshs structural similarity detection relative to Rabin fingerprintings similarity detection? • Third, is the overhead of the proxy-based design acceptable?",
                "Our evaluation answers these question through controlled experiments with the Ganesh prototype.",
                "This section describes the benchmarks used, our evaluation procedure, and the experimental setup.",
                "Results of the experiments are presented in Sections 5, 6, and 7. 4.1 Benchmarks Our evaluation is based on two benchmarks [18] that have been widely used by other researchers to evaluate various aspects of multi-tier [27] and eBusiness architectures [9].",
                "The first benchmark, BBOARD, is modeled after Slashdot, a technology-oriented news site.",
                "The second benchmark, AUCTION, is modeled after eBay, an online auction site.",
                "In both benchmarks, most content is dynamically generated from information stored in a database.",
                "Details of the datasets used can be found in Table 1. 4.1.1 The BBOARD Benchmark The BBOARD benchmark, also known as RUBBoS [18], models Slashdot, a popular technology-oriented web site.",
                "Slashdot aggregates links to news stories and other topics of interest found elsewhere on the web.",
                "The site also serves as a bulletin board by allowing users to comment on the posted stories in a threaded conversation form.",
                "It is not uncommon for a story to gather hundreds of comments in a matter of hours.",
                "The BBOARD benchmark is similar to the site and models the activities of a user, including readonly operations such as browsing the stories of the day, browsing story categories, and viewing comments as well as write operations such as new user registration, adding and moderating comments, and story submission.",
                "The benchmark consists of three different phases: a short warmup phase, a runtime phase representing the main body of the workload, and a short cool-down phase.",
                "In this paper we only report results from the runtime phase.",
                "The warm-up phase is important in establishing dynamic system state, but measurements from that phase are not significant for our evaluation.",
                "The cool-down phase is solely for allowing the benchmark to shut down.",
                "The warm-up, runtime, and cool-down phases are 2, 15, and 2 minutes respectively.",
                "The number of simulated clients were 400, 800, 1200, and 1600.",
                "The benchmark is available in a Java Servlets and PHP version and has different datasets; we evaluated Ganesh using the Java Servlets version and the Expanded dataset.",
                "The BBOARD benchmark defines two different workloads.",
                "The first, the Authoring mix, consists of 70% read-only operations and 30% <br>read-write operation</br>s.",
                "The second, the Browsing mix, contains only read-only operations and does not update the database. 4.1.2 The AUCTION Benchmark The AUCTION benchmark, also known as RUBiS [18], models eBay, the online auction site.",
                "The eBay web site is used to buy and sell items via an auction format.",
                "The main activities of a user include browsing, selling, or bidding for items.",
                "Modeling the activities on this site, this benchmark includes read-only activities such as browsing items by category and by region, as well as read-write WWW 2007 / Track: Performance and Scalability Session: Scalable Systems for Dynamic Content 314 NetEm Router Ganesh Proxy Clients Web and Application Server Database Server Figure 5: Experimental Setup activities such as bidding for items, buying and selling items, and leaving feedback.",
                "As with BBOARD, the benchmark consists of three different phases.",
                "The warm-up, runtime, and cool-down phases for this experiment are 1.5, 15, and 1 minutes respectively.",
                "We tested Ganesh with four client configurations where the number of test clients was set to 400, 800, 1200, and 1600.",
                "The benchmark is available in a Enterprise Java Bean (EJB), Java Servlets, and PHP version and has different datasets; we evaluated Ganesh with the Java Servlets version and the Expanded dataset.",
                "The AUCTION benchmark defines two different workloads.",
                "The first, the Bidding mix, consists of 70% read-only operations and 30% <br>read-write operation</br>s.",
                "The second, the Browsing mix, contains only read-only operations and does not update the database. 4.2 Experimental Procedure Both benchmarks involve a synthetic workload of clients accessing a web server.",
                "The number of clients emulated is an experimental parameter.",
                "Each emulated client runs an instance of the benchmark in its own thread, using a matrix to transition between different benchmark states.",
                "The matrix defines a stochastic model with probabilities of transitioning between the different states that represent typical user actions.",
                "An example transition is a user logging into the AUCTION system and then deciding on whether to post an item for sale or bid on active auctions.",
                "Each client also models user think time between requests.",
                "The think time is modeled as an exponential distribution with a mean of 7 seconds.",
                "We evaluate Ganesh along two axes: number of clients and WAN bandwidth.",
                "Higher loads are especially useful in understanding Ganeshs performance when the CPU or disk of the database server or proxy is the limiting factor.",
                "A previous study has shown that approximately 50% of the wide-area Internet bottlenecks observed had an available bandwidth under 10 Mb/s [1].",
                "Based on this work, we focus our evaluation on the WAN bandwidth of 5 Mb/s with 66 ms of round-trip latency, representative of severely constrained network paths, and 20 Mb/s with 33 ms of round-trip latency, representative of a moderately constrained network path.",
                "We also report Ganeshs performance at 100 Mb/s with no added round-trip latency.",
                "This bandwidth, representative of an unconstrained network, is especially useful in revealing any potential overhead of Ganesh in situations where WAN bandwidth is not the limiting factor.",
                "For each combination of number of clients and WAN bandwidth, we measured results from the two configurations listed below: • Native: This configuration corresponds to Figure 3(a).",
                "Native avoids Ganeshs overhead in using a proxy and performing Java object serialization. • Ganesh: This configuration corresponds to Figure 3(b).",
                "For a given number of clients and WAN bandwidth, comparing these results to the corresponding Native results gives the performance benefit due to the Ganesh middleware system.",
                "The metric used to quantify the improvement in throughput is the number of client requests that can be serviced per second.",
                "The metric used to quantify Ganeshs overhead is the average response time for a client request.",
                "For all of the experiments, the Ganesh driver used by the application server used a cache size of 100,000 items1 .",
                "The proxy was effective in tracking the Ganesh drivers cache state; for all of our experiments the miss rate on the driver never exceeded 0.7%. 4.3 Experimental Setup The experimental setup used for the benchmarks can be seen in Figure 5.",
                "All machines were 3.2 GHz Pentium 4s (with HyperThreading enabled.)",
                "With the exception of the database server, all machines had 2 GB of SDRAM and ran the Fedora Core Linux distribution.",
                "The database server had 4 GB of SDRAM.",
                "We used Apaches Tomcat as both the application server that hosted the Java Servlets and the web server.",
                "Both benchmarks used Java Servlets to generate the dynamic content.",
                "The database server used the open source MySQL database.",
                "For the native JDBC drivers, we used the Connector/J drivers provided by MySQL.",
                "The application server used Suns Java Virtual Machine as the runtime environment for the Java Servlets.",
                "The sysstat tool was used to monitor the CPU, network, disk, and memory utilization on all machines.",
                "The machines were connected by a switched gigabit Ethernet network.",
                "As shown in Figure 5, the front-end web and application server was separated from the proxy and database server by a NetEm router [16].",
                "This router allowed us to control the bandwidth and latency settings on the network.",
                "The NetEm router is a standard PC with two network cards running the Linux Traffic Control and Network Emulation software.",
                "The bandwidth and latency constraints were only applied to the link between the application server and the database for the native case and between the application server and the proxy for the Ganesh case.",
                "There is no communication between the application server and the database with Ganesh as all data flows through the proxy.",
                "As our focus was on the WAN link between the application server and the database, there were no constraints on the link between the simulated test clients and the web server. 5.",
                "THROUGHPUT AND RESPONSE TIME In this section, we address the first question raised in Section 4: Can performance can be improved significantly by exploiting similarity across database results?",
                "To answer this question, we use results from the BBOARD and AUCTION benchmarks.",
                "We use two metrics to quantify the performance improvement obtainable through the use of Ganesh: throughput, from the perspective of the web server, and average response time, from the perspective of the client.",
                "Throughput is measured in terms of the number of client requests that can be serviced per second. 5.1 BBOARD Results and Analysis 5.1.1 Authoring Mix Figures 6 (a) and (b) present the average number of requests serviced per second and the average response time for these requests as perceived by the clients for BBOARDs Authoring Mix.",
                "As Figure 6 (a) shows, Native easily saturates the 5 Mb/s link.",
                "At 400 clients, the Native solution delivers 29 requests/sec with an average response time of 8.3 seconds.",
                "Natives throughput drops with an increase in test clients as clients timeout due to congestion at the application server.",
                "Usability studies have shown that response times above 10 seconds cause the user to move on to 1 As Java lacks a sizeof() operator, Java caches therefore limit their size based on the number of objects.",
                "The size of cache dumps taken at the end of the experiments never exceeded 212 MB.",
                "WWW 2007 / Track: Performance and Scalability Session: Scalable Systems for Dynamic Content 315 0 50 100 150 200 250 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Test Clients Requests/sec Native Ganesh 0.001 0.01 0.1 1 10 100 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Test Clients Avg.Resp.Time(sec) Native Ganesh Note Logscale (a) Throughput: Authoring Mix (b) Response Time: Authoring Mix 0 50 100 150 200 250 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Test Clients Requests/sec Native Ganesh 0.001 0.01 0.1 1 10 100 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Test Clients Avg.Resp.Time(sec) Native Ganesh Note Logscale (c) Throughput: Browsing Mix (d) Response Time: Browsing Mix Mean of three trials.",
                "The maximum standard deviation for throughput and response time was 9.8% and 11.9% of the corresponding mean.",
                "Figure 6: BBOARD Benchmark - Throughput and Average Response Time other tasks [24].",
                "Based on these numbers, increasing the number of test clients makes the Native system unusable.",
                "Ganesh at 5 Mb/s, however, delivers a twofold improvement with 400 test clients and a fivefold improvement at 1200 clients.",
                "Ganeshs performance drops slightly at 1200 and 1600 clients as the network is saturated.",
                "Compared to Native, Figure 6 (b) shows that Ganeshs response times are substantially lower with sub-second response times at 400 clients.",
                "Figure 6 (a) also shows that for 400 and 800 test clients Ganesh at 5 Mb/s has the same throughput and average response time as Native at 20 Mb/s.",
                "Only at 1200 and 1600 clients does Native at 20 Mb/s deliver higher throughput than Ganesh at 5 Mb/s.",
                "Comparing both Ganesh and Native at 20 Mb/s, we see that Ganesh is no longer bandwidth constrained and delivers up to a twofold improvement over Native at 1600 test clients.",
                "As Ganesh does not saturate the network with higher test client configurations, at 1600 test clients, its average response time is 0.1 seconds rather than Natives 7.7 seconds.",
                "As expected, there are no visible gains from Ganesh at the higher bandwidth of 100 Mb/s where the network is no longer the bottleneck.",
                "Ganesh, however, still tracks Native in terms of throughput. 5.1.2 Browsing Mix Figures 6 (c) and (d) present the average number of requests serviced per second and the average response time for these requests as perceived by the clients for BBOARDs Browsing Mix.",
                "Regardless of the test client configuration, Figure 6 (c) shows that Natives throughput at 5 Mb/s is limited to 10 reqs/sec.",
                "Ganesh at 5 Mb/s with 400 test clients, delivers more than a sixfold increase in throughput.",
                "The improvement increases to over a elevenfold increase at 800 test clients before Ganesh saturates the network.",
                "Further, Figure 6 (d) shows that Natives average response time of 35 seconds at 400 test clients make the system unusable.",
                "These high response times further increase with the addition of test clients.",
                "Even with the 1600 test client configuration Ganesh delivers an acceptable average response time of 8.2 seconds.",
                "Due to the data-intensive nature of the Browsing mix, Ganesh at 5 Mb/s surprisingly performs much better than Native at 20 Mb/s.",
                "Further, as shown in Figure 6 (d), while the average response time for Native at 20 Mb/s is acceptable at 400 test clients, it is unusable with 800 test clients with an average response time of 15.8 seconds.",
                "Like the 5 Mb/s case, this response time increases with the addition of extra test clients.",
                "Ganesh at 20 Mb/s and both Native and Ganesh at 100 Mb/s are not bandwidth limited.",
                "However, performance plateaus out after 1200 test clients due to the database CPU being saturated. 5.1.3 Filter Variant We were surprised by the Native performance from the BBOARD benchmark.",
                "At the bandwidth of 5 Mb/s, Native performance was lower than what we had expected.",
                "It turned out the benchmark code that displays stories read all the comments associated with the particular story from the database and only then did some postprocessing to select the comments to be displayed.",
                "While this is exactly the behavior of SlashCode, the code base behind the Slashdot web site, we decided to modify the benchmark to perform some pre-filtering at the database.",
                "This modified benchmark, named the Filter Variant, models a developer who applies optimizations at the SQL level to transfer less data.",
                "In the interests of brevity, we only briefly summarize the results from the Authoring mix.",
                "For the Authoring mix, at 800 test clients at 5 Mb/s, Figure 7 (a) shows that Natives throughput increase by 85% when compared to the original benchmark while Ganeshs improvement is smaller at 15%.",
                "Natives performance drops above 800 clients as the test clients time out due to high response times.",
                "The most significant gain for Native is seen at 20 Mb/s.",
                "At 1600 test clients, when compared to the original benchmark, Native sees a 73% improvement in throughput and a 77% reduction in average response time.",
                "While WWW 2007 / Track: Performance and Scalability Session: Scalable Systems for Dynamic Content 316 0 50 100 150 200 250 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Test Clients Requests/sec Native Ganesh 0.001 0.01 0.1 1 10 100 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Test Clients Avg.Resp.Time(sec) Native Ganesh Note Logscale (a) Throughput: Authoring Mix (b) Response Time: Authoring Mix Mean of three trials.",
                "The maximum standard deviation for throughput and response time was 7.2% and 11.5% of the corresponding mean.",
                "Figure 7: BBOARD Benchmark - Filter Variant - Throughput and Average Response Time Ganesh sees no improvement when compared to the original, it still processes 19% more requests/sec than Native.",
                "Thus, while the optimizations were more helpful to Native, Ganesh still delivers an improvement in performance. 5.2 AUCTION Results and Analysis 5.2.1 Bidding Mix Figures 8 (a) and (b) present the average number of requests serviced per second and the average response time for these requests as perceived by the clients for AUCTIONs Bidding Mix.",
                "As mentioned earlier, the Bidding mix consists of a mixture of read and write operations.",
                "The AUCTION benchmark is not as data intensive as BBOARD.",
                "Therefore, most of the gains are observed at the lower bandwidth of 5 Mb/s.",
                "Figure 8 (a) shows that the increase in throughput due to Ganesh ranges from 8% at 400 test clients to 18% with 1600 test clients.",
                "As seen in Figure 8 (b), the average response times for Ganesh are significantly lower than Native ranging from a decrease of 84% at 800 test clients to 88% at 1600 test clients.",
                "Figure 8 (a) also shows that with a fourfold increase of bandwidth from 5 Mb/s to 20 Mb/s, Native is no longer bandwidth constrained and there is no performance difference between Ganesh and Native.",
                "With the higher test client configurations, we did observe that the bandwidth used by Ganesh was lower than Native.",
                "Ganesh might still be useful in these non-constrained scenarios if bandwidth is purchased on a metered basis.",
                "Similar results are seen for the 100 Mb/s scenario. 5.2.2 Browsing Mix For AUCTIONs Browsing Mix, Figures 8 (c) and (d) present the average number of requests serviced per second and the average response time for these requests as perceived by the clients.",
                "Again, most of the gains are observed at lower bandwidths.",
                "At 5 Mb/s, Native and Ganesh deliver similar throughput and response times with 400 test clients.",
                "While the throughput for both remains the same at 800 test clients, Figure 8 (d) shows that Ganeshs average response time is 62% lower than Native.",
                "Native saturates the link at 800 clients and adding extra test clients only increases the average response time.",
                "Ganesh, regardless of the test client configuration, is not bandwidth constrained and maintains the same response time.",
                "At 1600 test clients, Figure 8 (c) shows that Ganeshs throughput is almost twice that of Native.",
                "At the higher bandwidths of 20 and 100 Mb/s, neither Ganesh nor Native is bandwidth limited and deliver equivalent throughput and response times.",
                "Benchmark Orig.",
                "Size Ganesh Size Rabin Size SelectSort1 223.6 MB 5.4 MB 219.3 MB SelectSort2 223.6 MB 5.4 MB 223.6 MB Table 2: Similarity Microbenchmarks 6.",
                "STRUCTURAL VS. RABIN SIMILARITY In this section, we address the second question raised in Section 4: How important is Ganeshs structural similarity detection relative to Rabin fingerprinting-based similarity detecting?",
                "To answer this question, we used microbenchmarks and the BBOARD and AUCTION benchmarks.",
                "As Ganesh always performed better than Rabin fingerprinting, we only present a subset of the results here in the interests of brevity. 6.1 Microbenchmarks Two microbenchmarks show an example of the effects of data reordering on Rabin fingerprinting algorithm.",
                "In the first microbenchmark, SelectSort1, a query with a specified sort order selects 223.6 MB of data spread over approximately 280 K rows.",
                "The query is then repeated with a different sort attribute.",
                "While the same number of rows and the same data is returned, the order of rows is different.",
                "In such a scenario, one would expect a large amount of similarity to be detected between both results.",
                "As Table 2 shows, Ganeshs row-based algorithm achieves a 97.6% reduction while the Rabin fingerprinting algorithm, with the average chunk size parameter set to 4 KB, only achieves a 1% reduction.",
                "The reason, as shown earlier in Figure 2, is that with Rabin fingerprinting, the spans of data between two consecutive boundaries usually cross row boundaries.",
                "With the order of the rows changing in the second result and the Rabin fingerprints now spanning different rows, the algorithm is unable to detect significant similarity.",
                "The small gain seen is mostly for those single rows that are large enough to be broken into multiple chunks.",
                "SelectSort2, another micro-benchmark executed the same queries but increased the minimum chunk size of the Rabin fingerprinting algorithm.",
                "As can be seen in Table 2, even the small gain from the previous microbenchmark disappears as the minimum chunk size was greater than the average row size.",
                "While one can partially address these problems by dynamically varying the parameters of the Rabin fingerprinting algorithm, this can be computationally expensive, especially in the presence of changing workloads. 6.2 Application Benchmarks We ran the BBOARD benchmark described in Section 4.1.1 on two versions of Ganesh: the first with Rabin fingerprinting used as WWW 2007 / Track: Performance and Scalability Session: Scalable Systems for Dynamic Content 317 0 50 100 150 200 250 300 350 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Test Clients Requests/sec Native Ganesh 0.001 0.01 0.1 1 10 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Test Clients Avg.Resp.Time(sec) Native Ganesh Note Logscale (a) Throughput: Bidding Mix (b) Response Time: Bidding Mix 0 50 100 150 200 250 300 350 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Test Clients Requests/sec Native Ganesh 0.001 0.01 0.1 1 10 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Test Clients Avg.Resp.Time(sec) Native Ganesh Note Logscale (c) Throughput: Browsing Mix (d) Response Time: Browsing Mix Mean of three trials.",
                "The maximum standard deviation for throughput and response time was 2.2% and 11.8% of the corresponding mean.",
                "Figure 8: AUCTION Benchmark - Throughput and Average Response Time the chunking algorithm and the second with Ganeshs row-based algorithm.",
                "Rabins results for the Browsing Mix are normalized to Ganeshs results and presented in Figure 9.",
                "As Figure 9 (a) shows, at 5 Mb/s, independent of the test client configuration, Rabin significantly underperforms Ganesh.",
                "This happens because of a combination of two reasons.",
                "First, as outlined in Section 3.1, Rabin finds less similarity as it does not exploit the results structural information.",
                "Second, this benchmark contained some queries that generated large results.",
                "In this case, Rabin, with a small average chunk size, generated a large number of objects that evicted other useful data from the cache.",
                "In contrast, Ganesh was able to detect these large rows and correspondingly increase the size of the chunks.",
                "This was confirmed as cache statistics showed that Ganeshs hit ratio was roughly three time that of Rabin.",
                "Throughput measurements at 20 Mb/s were similar with the exception of Rabins performance with 400 test clients.",
                "In this case, Ganesh was not network limited and, in fact, the throughput was the same as 400 clients at 5 Mb/s.",
                "Rabin, however, took advantage of the bandwidth increase from 5 to 20 Mb/s to deliver a slightly better performance.",
                "At 100 Mb/s, Rabins throughput was almost similar to Ganesh as bandwidth was no longer a bottleneck.",
                "The normalized response time, presented in Figure 9 (b), shows similar trends.",
                "At 5 and 20 Mb/s, the addition of test clients decreases the normalized response time as Ganeshs average response time increases faster than Rabins.",
                "However, at no point does Rabin outperform Ganesh.",
                "Note that at 400 and 800 clients at 100 Mb/s, Rabin does have a higher overhead even when it is not bandwidth constrained.",
                "As mentioned in Section 3.1, this is due to the fact that Rabin has to hash each ResultSet twice.",
                "The overhead disappears with 1200 and 1600 clients as the database CPU is saturated and limits the performance of both Ganesh and Rabin. 7.",
                "PROXY OVERHEAD In this section, we address the third question raised in Section 4: Is the overhead of Ganeshs proxy-based design acceptable?",
                "To answer this question, we concentrate on its performance at the higher bandwidths.",
                "Our evaluation in Section 5 showed that Ganesh, when compared to Native, can deliver a substantial throughput improvement at lower bandwidths.",
                "It is only at higher bandwidths that latency, measured by the average response time for a client request, and throughput, measured by the number of client requests that can be serviced per second, overheads would be visible.",
                "Looking at the Authoring mix of the original BBOARD benchmark, there are no visible gains from Ganesh at 100 Mb/s.",
                "Ganesh, however, still tracks Native in terms of throughput.",
                "While the average response time is higher for Ganesh, the absolute difference is in between 0.01 and 0.04 seconds and would be imperceptible to the end-user.",
                "The Browsing mix shows an even smaller difference in average response times.",
                "The results from the filter variant of the BBOARD benchmarks are similar.",
                "Even for the AUCTION benchmark, the difference between Native and Ganeshs response time at 100 Mb/s was never greater than 0.02 seconds.",
                "The only exception to the above results was seen in the filter variant of the BBOARD benchmark where Ganesh at 1600 test clients added 0.85 seconds to the average response time.",
                "Thus, even for much faster networks where the WAN link is not the bottleneck, Ganesh always delivers throughput equivalent to Native.",
                "While some extra latency is added by the proxy-based design, it is usually imperceptible. 8.",
                "RELATED WORK To the best of our knowledge, Ganesh is the first system that combines the use of hash-based techniques with caching of database results to improve throughput and response times for applications with dynamic content.",
                "We also believe that it is also the first system to demonstrate the benefits of using structural information for WWW 2007 / Track: Performance and Scalability Session: Scalable Systems for Dynamic Content 318 0.0 0.2 0.4 0.6 0.8 1.0 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Test Clients Norm.Throughput 31.8 3.8 2.8 2.3 23.8 32.8 5.8 3.6 1.8 2.1 1.1 1.0 0 5 10 15 20 25 30 35 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Test Clients Norm.ResponseTime (a) Normalized Throughput: Higher is better (b) Normalized Response Time: Higher is worse For throughput, a normalized result greater than 1 implies that Rabin is better, For response time, a normalized result greater than 1 implies that Ganesh is better.",
                "Mean of three trials.",
                "The maximum standard deviation for throughput and response time was 9.1% and 13.9% of the corresponding mean.",
                "Figure 9: Normalized Comparison of Ganesh vs. Rabin - BBOARD Browsing Mix detecting similarity.",
                "In this section, we first discuss alternative approaches to caching dynamic content and then examine other uses of hash-based primitives in distributed systems. 8.1 Caching Dynamic Content At the database layer, a number of systems have advocated middletier caching where parts of the database are replicated at the edge or server [3, 4, 20].",
                "These systems either cache entire tables in what is essentially a replicated database or use materialized views from previous query replies [19].",
                "They require tight integration with the back-end database to ensure a time bound on the propagation of updates.",
                "These systems are also usually targeted towards workloads that do not require strict consistency and can tolerate stale data.",
                "Further, unlike Ganesh, some of these mid-tier caching solutions [2, 3], suffer from the complexity of having to participate in query planing and distributed query processing.",
                "Gao et al. [15] propose using a distributed object replication architecture where the data stores consistency requirements are adapted on a per-application basis.",
                "These solutions require substantial developer resources and detailed understanding of the application being modified.",
                "While systems that attempt to automate the partitioning and replication of an applications database exist [34], they do not provide full transaction semantics.",
                "In comparison, Ganesh does not weaken any of the semantics provided by the underlying database.",
                "Recent work in the evaluation of edge caching options for dynamic web sites [38] has suggested that, without careful planning, employing complex offloading strategies can hurt performance.",
                "Instead, the work advocates for an architecture in which all tiers except the database should be offloaded to the edge.",
                "Our evaluation of Ganesh has shown that it would benefit these scenarios.",
                "To improve database scalability, C-JDBC [10], SSS [22], and Ganymed [28] also advocate the use of an interposition-based architecture to transparently cluster and replicate databases at the middleware level.",
                "The approaches of these architectures and Ganesh are complementary and they would benefit each other.",
                "Moving up to the presentation layer, there has been widespread adoption of fragment-based caching [14], which improves cache utilization by separately caching different parts of generated web pages.",
                "While fragment-based caching works at the edge, a recent proposal has proposed moving web page assembly to the clients to optimize content delivery [31].",
                "While Ganesh is not used at the presentation layer, the same principles have been applied in Duplicate Transfer Detection [25] to increase web cache efficiency as well as for web access across bandwidth limited links [33]. 8.2 Hash-based Systems The past few years have seen the emergence of many systems that exploit hash-based techniques.",
                "At the heart of all these systems is the idea of detecting similarity in data without requiring interpretation of that data.",
                "This simple yet elegant idea relies on cryptographic hashing, as discussed earlier in Section 2.",
                "Successful applications of this idea span a wide range of storage systems.",
                "Examples include peer-to-peer backup of personal computing files [11], storage-efficient archiving of data [29], and finding similar files [21].",
                "Spring and Wetherall [35] apply similar principles at the network level.",
                "Using synchronized caches at both ends of a network link, duplicated data is replaced by smaller tokens for transmission and then restored at the remote end.",
                "This and other hash-based systems such as the CASPER [37] and LBFS [26] filesystems, and Layer-2 bandwidth optimizers such as Riverbed and Peribit use Rabin fingerprinting [30] to discover spans of commonality in data.",
                "This approach is especially useful when data items are modified in-place through insertions, deletions, and updates.",
                "However, as Section 6 shows, the performance of this technique can show a dramatic drop in the presence of data reordering.",
                "Ganesh instead uses row boundaries as dividers for detecting similarity.",
                "The most aggressive use of hash-based techniques is by systems that use hashes as the primary identifiers for objects in persistent storage.",
                "Storage systems such as CFS [12] and PAST [13] that have been built using distributed hash tables fall into this category.",
                "Single Instance Storage [6] and Venti [29] are other examples of such systems.",
                "As discussed in Section 2.2, the use of cryptographic hashes for addressing persistent data represents a deeper level of faith in their collision-resistance than that assumed by Ganesh.",
                "If time reveals shortcomings in the hash algorithm, the effort involved in correcting the flaw is much greater.",
                "In Ganesh, it is merely a matter of replacing the hash algorithm. 9.",
                "CONCLUSION The growing use of dynamic web content generated from relational databases places increased demands on WAN bandwidth.",
                "Traditional caching solutions for bandwidth and latency reduction are often ineffective for such content.",
                "This paper shows that the impact of WAN accesses to databases can be substantially reduced through the Ganesh architecture without any compromise of the databases strict consistency semantics.",
                "The essence of the Ganesh architecture is the use of computation at the edges to reduce communication through the Internet.",
                "Ganesh is able to use cryptographic hashes to detect similarity with previous results and send WWW 2007 / Track: Performance and Scalability Session: Scalable Systems for Dynamic Content 319 compact recipes of results rather than full results.",
                "Our design uses interposition to achieve complete transparency: clients, application servers, and database servers are all unaware of Ganeshs presence and require no modification.",
                "Our experimental evaluation confirms that Ganesh, while conceptually simple, can be highly effective in improving throughput and response time.",
                "Our results also confirm that exploiting the structure present in database results to detect similarity is crucial to this performance improvement. 10.",
                "REFERENCES [1] AKELLA, A., SESHAN, S., AND SHAIKH, A.",
                "An empirical evaluation of wide-area internet bottlenecks.",
                "In Proc. 3rd ACM SIGCOMM Conference on Internet Measurement (Miami Beach, FL, USA, Oct. 2003), pp. 101-114. [2] ALTINEL, M., BORNH ¨OVD, C., KRISHNAMURTHY, S., MOHAN, C., PIRAHESH, H., AND REINWALD, B. Cache tables: Paving the way for an adaptive database cache.",
                "In Proc. of 29th VLDB (Berlin, Germany, 2003), pp. 718-729. [3] ALTINEL, M., LUO, Q., KRISHNAMURTHY, S., MOHAN, C., PIRAHESH, H., LINDSAY, B. G., WOO, H., AND BROWN, L. Dbcache: Database caching for web application servers.",
                "In Proc. 2002 ACM SIGMOD (2002), pp. 612-612. [4] AMIRI, K., PARK, S., TEWARI, R., AND PADMANABHAN, S. Dbproxy: A dynamic data cache for web applications.",
                "In Proc.",
                "IEEE International Conference on Data Engineering (ICDE) (Mar. 2003). [5] BLACK, J. Compare-by-hash: A reasoned analysis.",
                "In Proc. 2006 USENIX Annual Technical Conference (Boston, MA, May 2006), pp. 85-90. [6] BOLOSKY, W. J., CORBIN, S., GOEBEL, D., , AND DOUCEUR, J. R. Single instance storage in windows 2000.",
                "In Proc. 4th USENIX Windows Systems Symposium (Seattle, WA, Aug. 2000), pp. 13-24. [7] BREWER, E. A.",
                "Lessons from giant-scale services.",
                "IEEE Internet Computing 5, 4 (2001), 46-55. [8] BRODER, A., GLASSMAN, S., MANASSE, M., AND ZWEIG, G. Syntactic clustering of the web.",
                "In Proc. 6th International WWW Conference (1997). [9] CECCHET, E., CHANDA, A., ELNIKETY, S., MARGUERITE, J., AND ZWAENEPOEL, W. Performance comparison of middleware architectures for generating dynamic web content.",
                "In Proc.",
                "Fourth ACM/IFIP/USENIX International Middleware Conference (Rio de Janeiro, Brazil, June 2003). [10] CECCHET, E., MARGUERITE, J., AND ZWAENEPOEL, W. C-JDBC: Flexible database clustering middleware.",
                "In Proc. 2004 USENIX Annual Technical Conference (Boston, MA, June 2004). [11] COX, L. P., MURRAY, C. D., AND NOBLE, B. D. Pastiche: Making backup cheap and easy.",
                "In OSDI: Symposium on Operating Systems Design and Implementation (2002). [12] DABEK, F., KAASHOEK, M. F., KARGER, D., MORRIS, R., AND STOICA, I. Wide-area cooperative storage with CFS.",
                "In 18th ACM Symposium on Operating Systems Principles (Banff, Canada, Oct. 2001). [13] DRUSCHEL, P., AND ROWSTRON, A.",
                "PAST: A large-scale, persistent peer-to-peer storage utility.",
                "In HotOS VIII (Schloss Elmau, Germany, May 2001), pp. 75-80. [14] Edge side includes. http://www.esi.org. [15] GAO, L., DAHLIN, M., NAYATE, A., ZHENG, J., AND IYENGAR, A.",
                "Application specific data replication for edge services.",
                "In WWW 03: Proc.",
                "Twelfth International Conference on World Wide Web (2003), pp. 449-460. [16] HEMMINGER, S. Netem - emulating real networks in the lab.",
                "In Proc. 2005 Linux Conference Australia (Canberra, Australia, Apr. 2005). [17] HENSON, V. An analysis of compare-by-hash.",
                "In Proc. 9th Workshop on Hot Topics in Operating Systems (HotOS IX) (May 2003), pp. 13-18. [18] Jmob benchmarks. http://jmob.objectweb.org/. [19] LABRINIDIS, A., AND ROUSSOPOULOS, N. Balancing performance and data freshness in web database servers.",
                "In Proc. 29th VLDB Conference (Sept. 2003). [20] LARSON, P.-A., GOLDSTEIN, J., AND ZHOU, J. Transparent mid-tier database caching in sql server.",
                "In Proc. 2003 ACM SIGMOD (2003), pp. 661-661. [21] MANBER, U.",
                "Finding similar files in a large file system.",
                "In Proc.",
                "USENIX Winter 1994 Technical Conference (San Fransisco, CA, 17-21 1994), pp. 1-10. [22] MANJHI, A., AILAMAKI, A., MAGGS, B. M., MOWRY, T. C., OLSTON, C., AND TOMASIC, A.",
                "Simultaneous scalability and security for data-intensive web applications.",
                "In Proc. 2006 ACM SIGMOD (June 2006), pp. 241-252. [23] MENEZES, A. J., VANSTONE, S. A., AND OORSCHOT, P. C. V. Handbook of Applied Cryptography.",
                "CRC Press, 1996. [24] MILLER, R. B.",
                "Response time in man-computer conversational transactions.",
                "In Proc.",
                "AFIPS Fall Joint Computer Conference (1968), pp. 267-277. [25] MOGUL, J. C., CHAN, Y. M., AND KELLY, T. Design, implementation, and evaluation of duplicate transfer detection in http.",
                "In Proc.",
                "First Symposium on Networked Systems Design and Implementation (San Francisco, CA, Mar. 2004). [26] MUTHITACHAROEN, A., CHEN, B., AND MAZIERES, D. A low-bandwidth network file system.",
                "In Proc. 18th ACM Symposium on Operating Systems Principles (Banff, Canada, Oct. 2001). [27] PFEIFER, D., AND JAKSCHITSCH, H. Method-based caching in multi-tiered server applications.",
                "In Proc.",
                "Fifth International Symposium on Distributed Objects and Applications (Catania, Sicily, Italy, Nov. 2003). [28] PLATTNER, C., AND ALONSO, G. Ganymed: Scalable replication for transactional web applications.",
                "In Proc. 5th ACM/IFIP/USENIX International Conference on Middleware (2004), pp. 155-174. [29] QUINLAN, S., AND DORWARD, S. Venti: A new approach to archival storage.",
                "In Proc.",
                "FAST 2002 Conference on File and Storage Technologies (2002). [30] RABIN, M. Fingerprinting by random polynomials.",
                "In Harvard University Center for Research in Computing Technology Technical Report TR-15-81 (1981). [31] RABINOVICH, M., XIAO, Z., DOUGLIS, F., AND KALMANEK, C. Moving edge side includes to the real edge - the clients.",
                "In Proc. 4th USENIX Symposium on Internet Technologies and Systems (Seattle, WA, Mar. 2003). [32] REESE, G. Database Programming with JDBC and Java, 1st ed.",
                "OReilly, June 1997. [33] RHEA, S., LIANG, K., AND BREWER, E. Value-based web caching.",
                "In Proc.",
                "Twelfth International World Wide Web Conference (May 2003). [34] SIVASUBRAMANIAN, S., ALONSO, G., PIERRE, G., AND VAN STEEN, M. Globedb: Autonomic data replication for web applications.",
                "In WWW 05: Proc. 14th International World-Wide Web conference (May 2005). [35] SPRING, N. T., AND WETHERALL, D. A protocol-independent technique for eliminating redundant network traffic.",
                "In Proc. of ACM SIGCOMM (Aug. 2000). [36] TOLIA, N., HARKES, J., KOZUCH, M., AND SATYANARAYANAN, M. Integrating portable and distributed storage.",
                "In Proc. 3rd USENIX Conference on File and Storage Technologies (San Francisco, CA, Mar. 2004). [37] TOLIA, N., KOZUCH, M., SATYANARAYANAN, M., KARP, B., PERRIG, A., AND BRESSOUD, T. Opportunistic use of content addressable storage for distributed file systems.",
                "In Proc. 2003 USENIX Annual Technical Conference (San Antonio, TX, June 2003), pp. 127-140. [38] YUAN, C., CHEN, Y., AND ZHANG, Z.",
                "Evaluation of edge caching/offloading for dynamic content delivery.",
                "In WWW 03: Proc.",
                "Twelfth International Conference on World Wide Web (2003), pp. 461-471.",
                "WWW 2007 / Track: Performance and Scalability Session: Scalable Systems for Dynamic Content 320"
            ],
            "original_annotated_samples": [
                "The first, the Authoring mix, consists of 70% read-only operations and 30% <br>read-write operation</br>s.",
                "The first, the Bidding mix, consists of 70% read-only operations and 30% <br>read-write operation</br>s."
            ],
            "translated_annotated_samples": [
                "El primero, la mezcla de Autoría, consiste en un 70% de operaciones de solo lectura y un 30% de <br>operaciones de lectura y escritura</br>.",
                "El primero, la mezcla de Ofertas, consiste en un 70% de operaciones de solo lectura y un 30% de <br>operaciones de lectura-escritura</br>."
            ],
            "translated_text": "Conservación de la consistencia en el almacenamiento en caché de contenido dinámico de bases de datos∗ Niraj Tolia y M. Satyanarayanan Universidad Carnegie Mellon {ntolia,satya}@cs.cmu.edu RESUMEN Con el creciente uso de contenido web dinámico generado a partir de bases de datos relacionales, las soluciones de almacenamiento en caché tradicionales para mejorar el rendimiento y la latencia son ineficaces. Describimos una capa de middleware llamada Ganesh que reduce el volumen de datos transmitidos sin interpretación semántica de consultas o resultados. Se logra esta reducción mediante el uso de hash criptográficos para detectar similitudes con resultados anteriores. Estos beneficios no requieren ningún compromiso con la semántica de consistencia estricta proporcionada por la base de datos del servidor. Además, Ganesh no requiere modificaciones en aplicaciones, servidores web o servidores de bases de datos, y funciona con aplicaciones y bases de datos de código cerrado. Usando dos puntos de referencia representativos de sitios web dinámicos, las mediciones de nuestro prototipo muestran que puede aumentar el rendimiento de extremo a extremo hasta en un factor de dos para aplicaciones no intensivas en datos y hasta en un factor de diez para las intensivas en datos. Categorías y Descriptores de Asignaturas C.2.4 [Redes de Computadoras-Comunicación]: Sistemas Distribuidos; H.2.4 [Gestión de Bases de Datos]: Términos Generales de Sistemas de Diseño, Rendimiento 1. INTRODUCCIÓN Una fracción creciente del contenido web se genera dinámicamente a partir de bases de datos relacionales en el backend. Incluso cuando el contenido de la base de datos permanece sin cambios, la localidad temporal de acceso no puede ser explotada porque el contenido dinámico no es almacenable en caché por los navegadores web o por servidores de almacenamiento en caché intermedios como los espejos de Akamai. En una arquitectura multinivel, cada solicitud web puede tensionar el enlace WAN entre el servidor web y la base de datos. Esto provoca que la experiencia del usuario sea altamente variable porque no hay almacenamiento en caché para aislar al cliente de cargas repentinas. Los intentos previos de almacenar en caché contenido dinámico de bases de datos generalmente han debilitado la semántica transaccional [3, 4] o han requerido modificaciones en la aplicación [15, 34]. Informamos sobre una nueva solución que toma la forma de una capa intermedia de middleware independiente de la base de datos llamada Ganesh. Ganesh no hace ningún esfuerzo por interpretar semánticamente el contenido de las consultas o sus resultados. En cambio, se basa exclusivamente en el hash criptográfico para detectar similitudes con resultados anteriores. La detección de similitud basada en hash ha sido cada vez más utilizada en sistemas de archivos distribuidos [26, 36, 37] para mejorar el rendimiento en redes de baja capacidad de ancho de banda. Sin embargo, estas técnicas no se han utilizado para bases de datos relacionales. A diferencia de enfoques anteriores que utilizan métodos genéricos para detectar similitud, Ganesh explota la estructura de los resultados de la base de datos relacional para lograr una mejora superior en el rendimiento. Uno se enfrenta al menos a tres desafíos al aplicar la detección de similitud basada en hash a las bases de datos de back-end. Primero, el trabajo previo en este ámbito ha considerado tradicionalmente el contenido de almacenamiento como bolsas de bits no interpretadas y sin estructura interna. Esto permite que las técnicas basadas en hash operen en largas y contiguas secuencias de datos para lograr la máxima efectividad. Por el contrario, las bases de datos relacionales tienen una estructura interna compleja que puede no ser tan propicia para la detección de similitudes basada en hash. Segundo, las bases de datos relacionales tienen restricciones de integridad y consistencia muy estrictas que no deben comprometerse por el uso de técnicas basadas en hash. Tercero, el código fuente de las bases de datos comerciales generalmente no está disponible. Esto contrasta con trabajos anteriores que presumían la disponibilidad del código fuente. Nuestros experimentos muestran que Ganesh, aunque conceptualmente simple, puede mejorar significativamente el rendimiento en anchos de banda representativos del Internet comercial actual. En los modelos de referencia de aplicaciones web multinivel, la mejora en el rendimiento fue de hasta diez veces para cargas de trabajo intensivas en datos. Para cargas de trabajo que no eran intensivas en datos, se observaron mejoras en el rendimiento de hasta el doble. Incluso cuando el ancho de banda no era una limitación, Ganesh tenía un bajo sobrecosto y no afectaba el rendimiento. Nuestros experimentos también confirman que aprovechar la estructura presente en los resultados de la base de datos es crucial para esta mejora en el rendimiento. Antecedentes 2.1 Generación de Contenido Dinámico A medida que la World Wide Web ha crecido, muchos sitios web han descentralizado sus datos y funcionalidades al llevarlos a los extremos de Internet. Hoy en día, los sistemas de comercio electrónico a menudo utilizan una arquitectura de tres niveles que consta de un servidor web de front-end, un servidor de aplicaciones y un servidor de base de datos de back-end. La Figura 1 ilustra esta arquitectura. Los dos primeros niveles se pueden replicar cerca de una concentración de clientes en el borde de Internet. Esto mejora la experiencia del usuario al reducir la latencia de extremo a extremo y disminuir la exposición al congestionamiento del tráfico de la columna vertebral. También puede aumentar la disponibilidad y escalabilidad de los servicios web. El contenido que se genera dinámicamente desde la base de datos del servidor no puede ser almacenado en caché en los dos primeros niveles. Si bien las bases de datos pueden replicarse fácilmente en una LAN, esto es inviable en una WAN debido a la difícil tarea de proporcionar simultáneamente una consistencia sólida, disponibilidad y tolerancia a particiones de red [7]. Como resultado, las bases de datos tienden a ser centralizadas para cumplir con los fuertes requisitos de consistencia de muchas aplicaciones de comercio electrónico como la banca, las finanzas y la venta al por menor en línea [38]. Por lo tanto, la base de datos del back-end suele estar ubicada lejos de muchos conjuntos de nodos de primer y segundo nivel [2]. En ausencia de almacenamiento en caché y replicación, el ancho de banda de la WAN puede convertirse fácilmente en un factor limitante en el rendimiento y la escalabilidad de aplicaciones intensivas en datos. El enfoque de Ganesh en los sistemas basados en hash es la transmisión eficiente de resultados al descubrir similitudes con los resultados de consultas anteriores. Dado que las consultas SQL pueden generar resultados grandes, las técnicas basadas en hash se prestan bien al problema de transferir eficientemente estos grandes resultados a través de enlaces con ancho de banda limitado. El uso de técnicas basadas en hash para reducir el volumen de datos transmitidos ha surgido como un tema común en muchos sistemas de almacenamiento recientes, como se discute en la Sección 8.2. Estas técnicas se basan en algunas suposiciones básicas. Se asume que las funciones hash criptográficas son resistentes a colisiones. En otras palabras, es computacionalmente intratable encontrar dos entradas que se hash a la misma salida. Las funciones también se asumen como unidireccionales; es decir, encontrar una entrada que resulte en una salida específica es computacionalmente inviable. Menezes et al. [23] proporcionan más detalles sobre estas suposiciones. Las suposiciones anteriores permiten a los sistemas basados en hash asumir que no se producen colisiones. Por lo tanto, pueden tratar el hash de un elemento de datos como su identificador único. Una colección de elementos de datos se convierte efectivamente en direccionable por contenido, permitiendo que un hash pequeño funcione como una palabra de código para un elemento de datos mucho más grande en almacenamiento permanente o transmisión en red. La suposición de que las colisiones son tan raras que prácticamente no existen ha sido cuestionada recientemente [17]. Sin embargo, como explicó Black [5], creemos que estos problemas no son una preocupación para Ganesh. Toda comunicación es entre partes confiables del sistema y un adversario no tiene forma de obligar a Ganesh a aceptar datos inválidos. Además, Ganesh no depende críticamente de ninguna función hash específica. Si bien actualmente usamos SHA-1, reemplazarlo con una función hash diferente sería sencillo. No habría impacto en el rendimiento con funciones hash más fuertes (por ejemplo, SHA256) solo añade unos pocos bytes adicionales y los hashes generados siguen siendo órdenes de magnitud más pequeños que los elementos de datos que representan. No es necesario volver a almacenar permanentemente ya que Ganesh solo utiliza el hash en datos volátiles. 3. DISEÑO E IMPLEMENTACIÓN Ganesh explota la redundancia en el flujo de resultados para evitar transmitir fragmentos de resultados que ya están presentes en el sitio de la consulta. La redundancia puede surgir de forma natural de muchas maneras diferentes. Por ejemplo, una consulta repetida después de un cierto intervalo puede devolver un resultado diferente debido a actualizaciones en la base de datos; sin embargo, puede haber una significativa similitud entre los dos resultados. Como otro ejemplo, un usuario que está refinando una búsqueda puede generar una secuencia de consultas con resultados superpuestos. Cuando Ganesh detecta redundancia, suprime la transmisión de los fragmentos de resultado correspondientes. En cambio, transmite un resumen mucho más pequeño de esos fragmentos y permite que el sitio de consulta reconstruya el resultado a través de la búsqueda de hash en una caché de resultados anteriores. De hecho, Ganesh utiliza la computación en los bordes para reducir la comunicación por Internet. Nuestra descripción de Ganesh se centra en cuatro aspectos. Primero explicamos nuestro enfoque para detectar similitud en los resultados de la consulta. A continuación, discutimos cómo la arquitectura Ganesh es completamente invisible para todos los componentes de un sistema de múltiples niveles. Luego describimos el enfoque basado en proxy de Ganesh y el flujo de datos para detectar similitudes. 3.1 Detectar similitud Una de las decisiones clave de diseño en Ganesh es cómo se detecta la similitud. Hay muchas formas potenciales de descomponer un resultado en fragmentos.  I the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the thees I,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,, Encontrar esta descomposición óptima es un problema difícil debido al amplio espacio de posibilidades y porque la elección óptima depende de muchos factores, como el contenido del resultado de las consultas, el historial de resultados recientes y el algoritmo de gestión de caché. Cuando un objeto es opaco, el uso de huellas digitales de Rabin [8, 30] para detectar datos comunes entre dos objetos ha sido demostrado con éxito en el pasado por sistemas como LBFS [26] y CASPER [37]. El fingerprinting de Rabin utiliza una ventana deslizante sobre los datos para calcular un hash rodante. Suponiendo que la función hash está distribuida uniformemente, un límite de fragmento se define cuando los bits de orden inferior del valor hash son iguales a algún valor predeterminado. El número de bits de orden inferior utilizados define el tamaño promedio del fragmento. Estos fragmentos subdivididos del objeto se convierten en la unidad de comparación para detectar similitudes entre diferentes objetos. Dado que las ubicaciones de los límites encontrados mediante el uso de las huellas de Rabin están determinadas de manera estocástica, generalmente no logran alinearse con ninguna propiedad estructural de los datos subyacentes. Por lo tanto, el algoritmo maneja bien las actualizaciones en su lugar, inserciones y eliminaciones. Sin embargo, tiene un rendimiento deficiente en presencia de cualquier reordenamiento de datos. La Figura 2 muestra un ejemplo donde dos resultados, A y B, que constan de tres filas, tienen los mismos datos pero diferentes atributos de ordenamiento. En el caso extremo, la huella digital de Rabin podría no ser capaz de encontrar datos similares debido a la forma en que detecta los límites de los fragmentos. Afortunadamente, Ganesh puede utilizar conocimientos específicos del dominio para una detección de límites más precisa. La información que explotamos es que el resultado de una consulta refleja la estructura de una base de datos relacional donde todos los datos están organizados en tablas y filas. Por lo tanto, es sencillo verificar la similitud con resultados anteriores en dos niveles de granularidad: primero el resultado completo y luego las filas individuales. El final de una fila en un resultado sirve como un límite natural de fragmento. Es importante tener en cuenta que el uso de la estructura tabular en los resultados solo implica una interpretación superficial de los datos. Ganesh no realiza ninguna interpretación semántica más profunda, como comprender tipos de datos, esquemas de resultados o restricciones de integridad. Ajustar la huella digital de Rabin para una carga de trabajo también puede ser difícil. Si el tamaño promedio de los fragmentos es demasiado grande, los fragmentos pueden abarcar varias filas de resultados. Sin embargo, seleccionar un tamaño de fragmento promedio más pequeño aumenta la cantidad de metadatos necesarios para describir los resultados. Esto, a su vez, disminuiría los ahorros obtenidos mediante su uso. El fingerprinting de Rabin también requiere dos pasadas computacionalmente costosas sobre los datos: una vez para determinar los límites de los fragmentos y otra vez para generar hashes criptográficos para los fragmentos. Ganesh solo necesita un único pase para la generación de hash, ya que los límites de los fragmentos son proporcionados por la estructura natural de los datos. La comparación de rendimiento en la Sección 6 muestra que el algoritmo basado en filas de Ganesh supera al fingerprinting de Rabin. Dado que trabajos anteriores ya han demostrado que la huella digital de Rabin funciona mejor que gzip [26], no comparamos a Ganesh con algoritmos de compresión en este artículo. 3.2 Transparencia El factor clave que influyó en nuestro diseño fue la necesidad de que Ganesh fuera completamente transparente para todos los componentes de un sistema típico de comercio electrónico: servidores web, servidores de aplicaciones y servidores de bases de datos. Sin esto, Ganesh tiene pocas posibilidades de tener un impacto significativo en el mundo real. Requerir modificaciones en cualquiera de los componentes mencionados aumentaría la barrera de entrada de Ganesh en un sistema existente, y por lo tanto reduciría sus posibilidades de adopción. Preservar la transparencia se simplifica por el hecho de que Ganesh es simplemente una mejora de rendimiento, no una mejora de funcionalidad o usabilidad. Elegimos la interposición de agentes como enfoque arquitectónico para lograr nuestro objetivo. Este enfoque se basa en la existencia de una interfaz de programación compacta que ya es ampliamente utilizada por el software objetivo. También se basa en un mecanismo para agregar fácilmente nuevo código sin interrumpir la estructura de módulos existente. Estas condiciones se cumplen fácilmente en nuestro contexto debido a la popularidad de Java como el lenguaje de programación para sistemas de comercio electrónico. La API de Conectividad de Base de Datos de Java (JDBC) [32] permite a las aplicaciones de Java acceder a una amplia variedad de bases de datos e incluso a otros repositorios de datos tabulares como archivos planos. El acceso a estas fuentes de datos es proporcionado por controladores JDBC que traducen entre la API JDBC y el mecanismo de comunicación de la base de datos. La figura 3(a) muestra cómo se utiliza típicamente JDBC en una aplicación. Dado que la interfaz JDBC está estandarizada, se puede sustituir un controlador JDBC por otro sin necesidad de de modificar la aplicación. El controlador JDBC se convierte así en el módulo natural para aprovechar la interposición de código. Como se muestra en la Figura 3(b), el controlador JDBC nativo es reemplazado por un controlador JDBC Ganesh que presenta la misma interfaz estandarizada. El controlador Ganesh mantiene una caché en memoria de fragmentos de resultados de consultas anteriores y realiza el reensamblaje de resultados. En la base de datos, agregamos un nuevo proceso llamado el proxy Ganesh. Este proxy, que puede ser compartido por múltiples nodos front-end, consta de dos partes: código para detectar similitud en fragmentos de resultados y el controlador JDBC nativo original que se comunica con la base de datos. El uso de un proxy en la base de datos hace que Ganesh sea independiente de la base de datos y simplifica la creación de prototipos y experimentación. Ganesh es capaz de trabajar con una amplia gama de bases de datos y aplicaciones, sin necesidad de realizar modificaciones en ninguna de ellas. 3.3 Caché basada en proxy El controlador JDBC nativo mostrado en la Figura 3(a) es un componente de código ligero suministrado por el proveedor de la base de datos. Su función principal es mediar la comunicación entre la aplicación y la base de datos remota. Reenvía consultas, almacena resultados completos y responde a solicitudes de la aplicación para ver partes de los resultados. El controlador JDBC de Ganesh mostrado en la Figura 3(b) presenta a la aplicación una interfaz idéntica a la proporcionada por el controlador nativo. Proporciona la capacidad de reconstruir resultados a partir de descripciones compactas basadas en hash enviadas por el proxy. Para realizar esta reconstrucción, el controlador mantiene una caché en memoria de los resultados recibidos recientemente. Esta caché solo se utiliza como fuente de fragmentos de resultados en la reconstrucción de resultados. El conductor Ganesh o el proxy no intentan rastrear las actualizaciones de la base de datos. La falta de consistencia en la caché no afecta a la corrección, ya que la descripción de los resultados siempre se obtiene del proxy; en el peor de los casos, no habrá beneficio de rendimiento al usar Ganesh. Los datos obsoletos simplemente se eliminarán de la caché con el tiempo. El proxy de Ganesh accede a la base de datos a través del controlador JDBC nativo, que permanece sin cambios entre las Figuras 3(a) y (b). La base de datos está completamente ajena a la existencia del proxy. El proxy no examina ninguna consulta recibida del controlador Ganesh, sino que las pasa al controlador nativo. En cambio, el proxy es responsable de inspeccionar la salida de la base de datos recibida del controlador nativo, detectar resultados similares y generar codificaciones basadas en hash de estos resultados siempre que se encuentre suficiente similitud. Si bien esta arquitectura no disminuye la carga en una base de datos, como se mencionó anteriormente en la Sección 2.1, es mucho más fácil replicar bases de datos para escalabilidad en una LAN que en una WAN. Para generar una codificación basada en hash, el proxy debe estar al tanto de qué fragmentos de resultados están disponibles en la caché de controladores de Ganesh. Un enfoque es ser optimista y asumir que todos los fragmentos de resultados están disponibles. Esto resultará en la transmisión inicial más pequeña posible de un resultado. Sin embargo, en casos donde hay poca superposición con resultados anteriores, el controlador Ganesh tendrá que realizar muchas llamadas al proxy durante la reconstrucción para recuperar fragmentos de resultados faltantes. Para evitar esta situación, el proxy sigue de manera flexible el estado de la caché de controladores de Ganesh. Dado que ambos componentes están bajo nuestro control, es relativamente sencillo hacer esto sin recurrir a técnicas de caja gris o comunicación explícita para mantener la coherencia de la caché. En cambio, el proxy simula el algoritmo de gestión de caché de controladores de Ganesh y lo utiliza para mantener una lista de hashes para los cuales es probable que el controlador de Ganesh posea los fragmentos de resultado. En caso de desviación de seguimiento, no habrá pérdida de corrección, pero habrá retrasos adicionales en el viaje de ida y vuelta para recuperar los fragmentos faltantes. Si el cliente detecta la pérdida de sincronización con el proxy, puede pedirle al proxy que restablezca el estado compartido entre ellos. También hay que tener en cuenta que el proxy no necesita guardar los fragmentos de resultado en sí, solo sus hashes. Esto permite que el proxy siga siendo escalable incluso cuando es compartido por muchos nodos front-end. El proxy Ganesh recibe la salida de la base de datos como objetos Java del controlador JDBC nativo. Examina esta salida para ver si está presente un objeto Java del tipo ResultSet. La interfaz JDBC utiliza este tipo de dato para almacenar los resultados de las consultas a la base de datos. Si se encuentra un objeto ResultSet, se reduce como se discute a continuación. Todos los demás objetos de Java se pasan sin modificar. Como se discute en la Sección 3.1, el proxy utiliza los límites de fila definidos en el ResultSet para dividirlo en fragmentos que consisten en filas de resultado individuales. Todos los objetos ResultSet se convierten en objetos de un nuevo tipo llamado RecipeResultSet. Utilizamos el término receta para esta descripción compacta de un resultado de base de datos debido a su similitud con una receta de archivo en el sistema de archivos CASPER [37]. La conversión reemplaza cada fragmento de resultado que probablemente esté presente en la caché de controladores de Ganesh por un hash SHA-1 de ese fragmento. Los fragmentos de resultados previamente no vistos se conservan textualmente. El proxy también retiene los hashes de los nuevos fragmentos de resultados, ya que estarán presentes en la caché de los controladores en el futuro. Ten en cuenta que el proxy solo almacena en caché los hashes de los fragmentos de resultados y no almacena en caché las recetas. El proxy construye un RecipeResultSet verificando la similitud en todo el resultado y luego a nivel de fila. Si se predice que todo el resultado estará presente en la caché de los controladores de Ganesh, el RecipeResultSet será simplemente un único hash de todo el resultado. De lo contrario, contiene hashes para aquellas filas que se predice que están presentes en esa caché; todas las demás filas se conservan textualmente. Si el proxy estima un ahorro de espacio general, transmitirá el RecipeResultSet. De lo contrario, se transmite el ResultSet original. Los objetos RecipeResultSet son transformados de vuelta en objetos ResultSet por el controlador Ganesh. La Figura 4 ilustra el manejo de ResultSet en ambos extremos. Cada hash SHA-1 encontrado en un RecipeResultSet se busca en la caché local de fragmentos de resultados. En caso de acierto, el hash es reemplazado por el fragmento correspondiente. En caso de error, el conductor contacta al proxy de Ganesh para recuperar el fragmento. Todos los fragmentos de resultados previamente no vistos que fueron retenidos textualmente por el proxy se hasheado y se han añadido a la caché de resultados. Debería haber muy pocos fallos si el proxy ha seguido con precisión el estado de la caché de controladores de Ganesh. Una optimización futura sería agrupar la obtención de fragmentos faltantes. Esto sería valioso cuando hay muchos pequeños fragmentos faltantes en una WAN de alta latencia. Una vez que la transformación esté completa, el objeto ResultSet completamente reconstruido se pasa a la aplicación. 4. VALIDACIÓN EXPERIMENTAL Tres preguntas surgen de los objetivos y diseño de Ganesh: • Primero, ¿se puede mejorar significativamente el rendimiento al explotar la similitud entre los resultados de la base de datos? Detalles del conjunto de datos de referencia 500,000 usuarios, 12,000 historias BBOARD 2.0 GB 3,298,000 comentarios SUBASTA 1.3 GB 1,000,000 usuarios, 34,000 elementos Tabla 1: Detalles del conjunto de datos de referencia • En segundo lugar, ¿qué tan importante es la detección de similitud estructural de Ganesh en comparación con la detección de similitud de la huella digital de Rabin? • En tercer lugar, ¿es aceptable la sobrecarga del diseño basado en proxy? Nuestra evaluación responde a estas preguntas a través de experimentos controlados con el prototipo Ganesh. Esta sección describe los puntos de referencia utilizados, nuestro procedimiento de evaluación y la configuración experimental. Los resultados de los experimentos se presentan en las Secciones 5, 6 y 7. 4.1 Puntos de referencia Nuestra evaluación se basa en dos puntos de referencia [18] que han sido ampliamente utilizados por otros investigadores para evaluar varios aspectos de arquitecturas multi-tier [27] y de comercio electrónico [9]. El primer punto de referencia, BBOARD, está modelado según Slashdot, un sitio de noticias orientado a la tecnología. El segundo punto de referencia, AUCTION, está modelado según eBay, un sitio de subastas en línea. En ambos puntos de referencia, la mayoría del contenido se genera dinámicamente a partir de la información almacenada en una base de datos. Los detalles de los conjuntos de datos utilizados se pueden encontrar en la Tabla 1. 4.1.1 El Benchmark BBOARD El benchmark BBOARD, también conocido como RUBBoS [18], modela Slashdot, un popular sitio web orientado a la tecnología. Slashdot recopila enlaces a noticias y otros temas de interés encontrados en otros lugares de la web. El sitio también funciona como un tablón de anuncios al permitir a los usuarios comentar en las historias publicadas en forma de conversación en hilos. No es raro que una historia recopile cientos de comentarios en cuestión de horas. El benchmark BBOARD es similar al sitio y modela las actividades de un usuario, incluyendo operaciones de solo lectura como navegar por las historias del día, explorar categorías de historias y ver comentarios, así como operaciones de escritura como registro de nuevos usuarios, agregar y moderar comentarios, y enviar historias. El benchmark consiste en tres fases diferentes: una fase de calentamiento corta, una fase de ejecución que representa el cuerpo principal de la carga de trabajo, y una fase de enfriamiento corta. En este documento solo informamos sobre los resultados de la fase de ejecución. La fase de calentamiento es importante para establecer el estado del sistema dinámico, pero las mediciones de esa fase no son significativas para nuestra evaluación. La fase de enfriamiento es únicamente para permitir que el punto de referencia se apague. Las fases de calentamiento, ejercicio y enfriamiento son de 2, 15 y 2 minutos respectivamente. El número de clientes simulados fue de 400, 800, 1200 y 1600. El punto de referencia está disponible en una versión de Java Servlets y PHP y tiene diferentes conjuntos de datos; evaluamos a Ganesh utilizando la versión de Java Servlets y el conjunto de datos Expandido. El benchmark BBOARD define dos cargas de trabajo diferentes. El primero, la mezcla de Autoría, consiste en un 70% de operaciones de solo lectura y un 30% de <br>operaciones de lectura y escritura</br>. El segundo, la mezcla de navegación, contiene solo operaciones de solo lectura y no actualiza la base de datos. 4.1.2 El Benchmark de SUBASTA El benchmark de SUBASTA, también conocido como RUBiS [18], modela eBay, el sitio de subastas en línea. El sitio web de eBay se utiliza para comprar y vender artículos a través de un formato de subasta. Las principales actividades de un usuario incluyen navegar, vender o pujar por artículos. Modelando las actividades en este sitio, este punto de referencia incluye actividades de solo lectura como navegar por artículos por categoría y por región, así como actividades de lectura-escritura como pujar por artículos, comprar y vender artículos, y dejar comentarios. Al igual que con BBOARD, el benchmark consiste en tres fases diferentes. Las fases de calentamiento, ejecución y enfriamiento para este experimento son de 1.5, 15 y 1 minutos respectivamente. Probamos Ganesh con cuatro configuraciones de clientes donde el número de clientes de prueba se estableció en 400, 800, 1200 y 1600. El punto de referencia está disponible en una versión de Enterprise Java Bean (EJB), Java Servlets y PHP y tiene diferentes conjuntos de datos; evaluamos Ganesh con la versión de Java Servlets y el conjunto de datos Expandido. El benchmark de SUBASTA define dos cargas de trabajo diferentes. El primero, la mezcla de Ofertas, consiste en un 70% de operaciones de solo lectura y un 30% de <br>operaciones de lectura-escritura</br>. El segundo, la mezcla de navegación, contiene solo operaciones de solo lectura y no actualiza la base de datos. 4.2 Procedimiento Experimental Ambos benchmarks involucran una carga de trabajo sintética de clientes accediendo a un servidor web. El número de clientes emulados es un parámetro experimental. Cada cliente emulado ejecuta una instancia del benchmark en su propio hilo, utilizando una matriz para hacer la transición entre diferentes estados del benchmark. La matriz define un modelo estocástico con probabilidades de transición entre los diferentes estados que representan las acciones típicas de los usuarios. Un ejemplo de transición es un usuario iniciando sesión en el sistema de SUBASTA y luego decidiendo si publicar un artículo en venta o pujar en subastas activas. Cada cliente también modela el tiempo de pensamiento del usuario entre las solicitudes. El tiempo de pensamiento se modela como una distribución exponencial con una media de 7 segundos. Evaluamos a Ganesh a lo largo de dos ejes: número de clientes y ancho de banda de la WAN. Las cargas más altas son especialmente útiles para comprender el rendimiento de Ganesh cuando la CPU o el disco del servidor de base de datos o del proxy son el factor limitante. Un estudio previo ha demostrado que aproximadamente el 50% de los cuellos de botella de Internet de gran área observados tenían un ancho de banda disponible inferior a 10 Mb/s [1]. Basándonos en este trabajo, enfocamos nuestra evaluación en el ancho de banda de la WAN de 5 Mb/s con una latencia de ida y vuelta de 66 ms, representativa de rutas de red severamente restringidas, y 20 Mb/s con una latencia de ida y vuelta de 33 ms, representativa de una ruta de red moderadamente restringida. También informamos sobre el rendimiento de Ganesh a 100 Mb/s sin agregar latencia de ida y vuelta. Este ancho de banda, representativo de una red sin restricciones, es especialmente útil para revelar cualquier sobrecarga potencial de Ganesh en situaciones donde el ancho de banda de la WAN no es el factor limitante. Para cada combinación de número de clientes y ancho de banda de WAN, medimos los resultados de las dos configuraciones enumeradas a continuación: • Nativa: Esta configuración corresponde a la Figura 3(a). El nativo evita la sobrecarga de Ganesh al usar un proxy y realizar la serialización de objetos Java. • Ganesh: Esta configuración corresponde a la Figura 3(b). Para un número dado de clientes y ancho de banda de WAN, comparar estos resultados con los resultados nativos correspondientes proporciona el beneficio de rendimiento debido al sistema de middleware Ganesh. La métrica utilizada para cuantificar la mejora en el rendimiento es el número de solicitudes de clientes que pueden ser atendidas por segundo. La métrica utilizada para cuantificar el rendimiento de Ganesh es el tiempo promedio de respuesta para una solicitud de cliente. Para todos los experimentos, el controlador Ganesh utilizado por el servidor de aplicaciones usó un tamaño de caché de 100,000 elementos. El proxy fue efectivo en rastrear el estado de la caché de los controladores Ganesh; para todos nuestros experimentos, la tasa de fallos en el controlador nunca superó el 0.7%. 4.3 Configuración Experimental La configuración experimental utilizada para las pruebas se puede ver en la Figura 5. Todas las máquinas eran Pentium 4 de 3.2 GHz (con HyperThreading habilitado). Con la excepción del servidor de base de datos, todas las máquinas tenían 2 GB de SDRAM y ejecutaban la distribución de Linux Fedora Core. El servidor de la base de datos tenía 4 GB de SDRAM. Utilizamos Apache Tomcat como tanto el servidor de aplicaciones que alojaba los Servlets de Java como el servidor web. Ambos benchmarks utilizaron Java Servlets para generar el contenido dinámico. El servidor de la base de datos utilizó la base de datos de código abierto MySQL. Para los controladores JDBC nativos, utilizamos los controladores Connector/J proporcionados por MySQL. El servidor de aplicaciones utilizaba la Máquina Virtual de Java de Sun como entorno de ejecución para los Servlets de Java. La herramienta sysstat se utilizó para monitorear la utilización de la CPU, red, disco y memoria en todas las máquinas. Las máquinas estaban conectadas por una red Ethernet gigabit conmutada. Como se muestra en la Figura 5, el servidor web y de aplicación de front-end fue separado del servidor de proxy y base de datos por un enrutador NetEm [16]. Este enrutador nos permitió controlar la configuración de ancho de banda y latencia en la red. El enrutador NetEm es un PC estándar con dos tarjetas de red que ejecuta el software de Control de Tráfico de Linux y Emulación de Red. Las restricciones de ancho de banda y latencia solo se aplicaron al enlace entre el servidor de aplicaciones y la base de datos para el caso nativo y entre el servidor de aplicaciones y el proxy para el caso de Ganesh. No hay comunicación entre el servidor de aplicaciones y la base de datos con Ganesh, ya que todos los datos fluyen a través del proxy. Como nuestro enfoque estaba en el enlace WAN entre el servidor de aplicaciones y la base de datos, no hubo restricciones en el enlace entre los clientes de prueba simulados y el servidor web. 5. DESEMPEÑO Y TIEMPO DE RESPUESTA En esta sección, abordamos la primera pregunta planteada en la Sección 4: ¿Se puede mejorar significativamente el rendimiento explotando la similitud entre los resultados de la base de datos? Para responder a esta pregunta, utilizamos los resultados de los benchmarks BBOARD y AUCTION. Utilizamos dos métricas para cuantificar la mejora en el rendimiento obtenible a través del uso de Ganesh: el throughput, desde la perspectiva del servidor web, y el tiempo de respuesta promedio, desde la perspectiva del cliente. El rendimiento se mide en términos del número de solicitudes de clientes que pueden ser atendidas por segundo. Los resultados y análisis de BBOARD 5.1 Figuras 6 (a) y (b) presentan el número promedio de solicitudes atendidas por segundo y el tiempo de respuesta promedio para estas solicitudes tal como lo perciben los clientes para la Mezcla de Autoría de BBOARD. Como muestra la Figura 6 (a), Native satura fácilmente el enlace de 5 Mb/s. Con 400 clientes, la solución nativa entrega 29 solicitudes/segundo con un tiempo de respuesta promedio de 8.3 segundos. La capacidad de procesamiento de los clientes disminuye con un aumento en los clientes de prueba, ya que los clientes se agotan debido a la congestión en el servidor de aplicaciones. Los estudios de usabilidad han demostrado que los tiempos de respuesta superiores a 10 segundos hacen que el usuario pase a 1. Dado que Java carece de un operador sizeof(), los cachés de Java limitan su tamaño en función del número de objetos. El tamaño de los volcados de caché tomados al final de los experimentos nunca superó los 212 MB. WWW 2007 / Pista: Rendimiento y Escalabilidad Sesión: Sistemas Escalables para Contenido Dinámico 315 0 50 100 150 200 250 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Solicitudes de Clientes de Prueba por Segundo Nativo Ganesh 0.001 0.01 0.1 1 10 100 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Tiempo Promedio de Respuesta de Clientes de Prueba Nativo Ganesh Nota Escala Logarítmica (a) Rendimiento: Mezcla de Autoría (b) Tiempo de Respuesta: Mezcla de Autoría 0 50 100 150 200 250 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Solicitudes de Clientes de Prueba por Segundo Nativo Ganesh 0.001 0.01 0.1 1 10 100 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Tiempo Promedio de Respuesta de Clientes de Prueba Nativo Ganesh Nota Escala Logarítmica (c) Rendimiento: Mezcla de Navegación (d) Tiempo de Respuesta: Mezcla de Navegación Promedio de tres pruebas. La desviación estándar máxima para el rendimiento y el tiempo de respuesta fue del 9.8% y 11.9% de la media correspondiente. Figura 6: BBOARD Benchmark - Rendimiento y Tiempo de Respuesta Promedio de otras tareas [24]. Basándose en estos números, aumentar el número de clientes de prueba hace que el sistema Nativo sea inutilizable. Ganesh a 5 Mb/s, sin embargo, ofrece una mejora doble con 400 clientes de prueba y una mejora quintuple con 1200 clientes. El rendimiento de Ganesh disminuye ligeramente a 1200 y 1600 clientes debido a que la red está saturada. En comparación con Native, la Figura 6 (b) muestra que los tiempos de respuesta de Ganesh son considerablemente más bajos con tiempos de respuesta de menos de un segundo con 400 clientes. La Figura 6 (a) también muestra que para 400 y 800 clientes de prueba, Ganesh a 5 Mb/s tiene el mismo rendimiento y tiempo de respuesta promedio que Native a 20 Mb/s. Solo con 1200 y 1600 clientes, Native a 20 Mb/s ofrece un rendimiento mayor que Ganesh a 5 Mb/s. Al comparar tanto a Ganesh como a Native a 20 Mb/s, vemos que Ganesh ya no está limitado por el ancho de banda y ofrece hasta una mejora del doble sobre Native con 1600 clientes de prueba. Como Ganesh no satura la red con configuraciones de cliente de prueba más altas, con 1600 clientes de prueba, su tiempo de respuesta promedio es de 0.1 segundos en lugar de los 7.7 segundos de Natives. Como era de esperar, no hay ganancias visibles de Ganesh en el ancho de banda más alto de 100 Mb/s donde la red ya no es el cuello de botella. Sin embargo, Ganesh sigue monitoreando a Native en cuanto a rendimiento. Las Figuras 6 (c) y (d) presentan el número promedio de solicitudes atendidas por segundo y el tiempo de respuesta promedio para estas solicitudes tal como lo perciben los clientes para la Mezcla de Navegación de BBOARDs. Independientemente de la configuración del cliente de prueba, la Figura 6 (c) muestra que el rendimiento de los Nativos a 5 Mb/s está limitado a 10 reqs/seg. Ganesh a 5 Mb/s con 400 clientes de prueba, ofrece un aumento de más de seis veces en el rendimiento. La mejora aumenta a más de once veces a 800 clientes de prueba antes de que Ganesh sature la red. Además, la Figura 6 (d) muestra que el tiempo de respuesta promedio de los Nativos de 35 segundos con 400 clientes de prueba hace que el sistema sea inutilizable. Estos altos tiempos de respuesta aumentan aún más con la adición de clientes de prueba. Incluso con la configuración del cliente de prueba de 1600, Ganesh ofrece un tiempo de respuesta promedio aceptable de 8.2 segundos. Debido a la naturaleza intensiva en datos de la mezcla de navegación, Ganesh a 5 Mb/s sorprendentemente tiene un rendimiento mucho mejor que Native a 20 Mb/s. Además, como se muestra en la Figura 6 (d), si bien el tiempo de respuesta promedio para Native a 20 Mb/s es aceptable con 400 clientes de prueba, resulta inutilizable con 800 clientes de prueba, con un tiempo de respuesta promedio de 15.8 segundos. Al igual que en el caso de 5 Mb/s, este tiempo de respuesta aumenta con la adición de clientes de prueba adicionales. Ganesh a 20 Mb/s y tanto Native como Ganesh a 100 Mb/s no tienen limitaciones de ancho de banda. Sin embargo, el rendimiento se estanca después de 1200 clientes de prueba debido a que la CPU de la base de datos está saturada. 5.1.3 Variante de filtro Nos sorprendió el rendimiento nativo del benchmark BBOARD. A una velocidad de banda ancha de 5 Mb/s, el rendimiento nativo fue más bajo de lo que esperábamos. Resultó que el código de referencia que muestra historias leía todos los comentarios asociados con la historia en particular de la base de datos y solo entonces realizaba un postprocesamiento para seleccionar los comentarios que se mostrarían. Si bien este es exactamente el comportamiento de SlashCode, la base de código detrás del sitio web de Slashdot, decidimos modificar la prueba de rendimiento para realizar cierto prefiltrado en la base de datos. Este benchmark modificado, llamado el Filtro de Variantes, modela a un desarrollador que aplica optimizaciones a nivel de SQL para transferir menos datos. En aras de la brevedad, solo resumimos brevemente los resultados de la mezcla de autores. Para la mezcla de Autoría, con 800 clientes de prueba a 5 Mb/s, la Figura 7 (a) muestra que el rendimiento de Natives aumenta un 85% en comparación con el punto de referencia original, mientras que la mejora de Ganesh es menor, del 15%. El rendimiento de los servidores disminuye por encima de los 800 clientes, ya que los clientes de prueba se agotan debido a los altos tiempos de respuesta. La ganancia más significativa para Native se observa a 20 Mb/s. En 1600 clientes de prueba, en comparación con el punto de referencia original, Native experimenta una mejora del 73% en el rendimiento y una reducción del 77% en el tiempo de respuesta promedio. Mientras WWW 2007 / Pista: Rendimiento y Escalabilidad Sesión: Sistemas Escalables para Contenido Dinámico 316 0 50 100 150 200 250 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Clientes de Prueba Solicitudes/seg Nativo Ganesh 0.001 0.01 0.1 1 10 100 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Clientes de Prueba Tiempo de Resp. Promedio (seg) Nativo Ganesh Nota Escala Logarítmica (a) Rendimiento: Mezcla de Autoría (b) Tiempo de Respuesta: Mezcla de Autoría Promedio de tres pruebas. La desviación estándar máxima para el rendimiento y el tiempo de respuesta fue del 7.2% y del 11.5% de la media correspondiente. Figura 7: BBOARD Benchmark - Variante de filtro - Rendimiento y Tiempo de Respuesta Promedio Ganesh no observa ninguna mejora en comparación con el original, aún procesa un 19% más de solicitudes/seg que Native. Por lo tanto, aunque las optimizaciones fueron más útiles para Native, Ganesh todavía ofrece una mejora en el rendimiento. 5.2 Resultados y Análisis de la SUBASTA 5.2.1 Figuras de la Mezcla de Ofertas Los gráficos 8 (a) y (b) presentan el número promedio de solicitudes atendidas por segundo y el tiempo de respuesta promedio para estas solicitudes tal como son percibidas por los clientes para la Mezcla de Ofertas de las SUBASTAS. Como se mencionó anteriormente, la mezcla de ofertas consiste en una combinación de operaciones de lectura y escritura. El benchmark AUCTION no es tan intensivo en datos como BBOARD. Por lo tanto, la mayoría de las ganancias se observan en el ancho de banda más bajo de 5 Mb/s. La figura 8 (a) muestra que el aumento en el rendimiento debido a Ganesh varía desde un 8% con 400 clientes de prueba hasta un 18% con 1600 clientes de prueba. Como se observa en la Figura 8 (b), los tiempos de respuesta promedio para Ganesh son significativamente más bajos que los de Native, con una disminución del 84% a 800 clientes de prueba y del 88% a 1600 clientes de prueba. La Figura 8 (a) también muestra que con un aumento cuádruple del ancho de banda de 5 Mb/s a 20 Mb/s, Native ya no está limitado por el ancho de banda y no hay diferencia de rendimiento entre Ganesh y Native. Con las configuraciones de cliente de prueba más altas, observamos que el ancho de banda utilizado por Ganesh era menor que el de Nativo. Ganesh podría seguir siendo útil en estos escenarios no restringidos si se compra ancho de banda de forma medible. Se observan resultados similares para el escenario de 100 Mb/s. 5.2.2 Mezcla de Navegación Para la Mezcla de Navegación de SUBASTAS, las Figuras 8 (c) y (d) presentan el número promedio de solicitudes atendidas por segundo y el tiempo promedio de respuesta para estas solicitudes tal como lo perciben los clientes. Una vez más, la mayoría de las ganancias se observan en anchos de banda más bajos. A 5 Mb/s, Native y Ganesh ofrecen un rendimiento y tiempos de respuesta similares con 400 clientes de prueba. Mientras que el rendimiento para ambos permanece igual en 800 clientes de prueba, la Figura 8 (d) muestra que el tiempo de respuesta promedio de Ganesh es un 62% menor que el de Native. El servidor satura el enlace con 800 clientes y agregar clientes de prueba adicionales solo aumenta el tiempo promedio de respuesta. Ganesh, independientemente de la configuración del cliente de prueba, no tiene restricciones de ancho de banda y mantiene el mismo tiempo de respuesta. A 1600 clientes de prueba, la Figura 8 (c) muestra que el rendimiento de Ganesh es casi el doble que el de Nativo. En los anchos de banda más altos de 20 y 100 Mb/s, ni Ganesh ni Native tienen limitaciones de ancho de banda y ofrecen un rendimiento y tiempos de respuesta equivalentes. Referencia original. Tamaño Ganesh Tamaño Rabin Tamaño SelectSort1 223.6 MB 5.4 MB 219.3 MB SelectSort2 223.6 MB 5.4 MB 223.6 MB Tabla 2: Microbenchmarks de similitud 6. SIMILITUD ESTRUCTURAL VS. SIMILITUD DE RABIN En esta sección, abordamos la segunda pregunta planteada en la Sección 4: ¿Qué tan importante es la detección de similitud estructural de Ganesh en comparación con la detección de similitud basada en la huella digital de Rabin? Para responder a esta pregunta, utilizamos microbenchmarks y los benchmarks BBOARD y AUCTION. Dado que Ganesh siempre tuvo un mejor rendimiento que Rabin en la huella dactilar, aquí presentamos solo un subconjunto de los resultados en aras de la brevedad. 6.1 Microbenchmarks Dos microbenchmarks muestran un ejemplo de los efectos de la reordenación de datos en el algoritmo de huella dactilar de Rabin. En el primer microbenchmark, SelectSort1, una consulta con un orden de clasificación especificado selecciona 223.6 MB de datos distribuidos en aproximadamente 280 K filas. La consulta se repite entonces con un atributo de ordenación diferente. Si bien se devuelve el mismo número de filas y los mismos datos, el orden de las filas es diferente. En un escenario así, se esperaría detectar una gran cantidad de similitud entre ambos resultados. Como muestra la Tabla 2, el algoritmo basado en filas de Ganesh logra una reducción del 97.6%, mientras que el algoritmo de huella digital de Rabin, con el parámetro de tamaño de fragmento promedio establecido en 4 KB, solo logra una reducción del 1%. La razón, como se muestra anteriormente en la Figura 2, es que con la huella digital de Rabin, los tramos de datos entre dos límites consecutivos suelen cruzar los límites de fila. Con el cambio en el orden de las filas en el segundo resultado y los fingerprints de Rabin ahora abarcando diferentes filas, el algoritmo no puede detectar similitud significativa. La pequeña ganancia observada se debe principalmente a aquellas filas individuales que son lo suficientemente grandes como para dividirse en múltiples fragmentos. SelectSort2, otro micro-benchmark ejecutó las mismas consultas pero aumentó el tamaño mínimo del fragmento del algoritmo de huella digital de Rabin. Como se puede ver en la Tabla 2, incluso la pequeña ganancia del microbenchmark anterior desaparece cuando el tamaño mínimo de fragmento fue mayor que el tamaño promedio de fila. Si bien se pueden abordar parcialmente estos problemas variando dinámicamente los parámetros del algoritmo de huella digital de Rabin, esto puede resultar computacionalmente costoso, especialmente en presencia de cargas de trabajo cambiantes. 6.2 Benchmarks de Aplicación Ejecutamos el benchmark BBOARD descrito en la Sección 4.1.1 en dos versiones de Ganesh: la primera con la huella digital de Rabin utilizada como WWW 2007 / Track: Sesión de Rendimiento y Escalabilidad: Sistemas Escalables para Contenido Dinámico 317 0 50 100 150 200 250 300 350 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Clientes de Prueba Solicitudes/seg Ganesh Nativo 0.001 0.01 0.1 1 10 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Clientes de Prueba Tiempo de Respuesta Promedio (seg) Ganesh Nativo Nota Escala Logarítmica (a) Rendimiento: Mezcla de Ofertas (b) Tiempo de Respuesta: Mezcla de Ofertas 0 50 100 150 200 250 300 350 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Clientes de Prueba Solicitudes/seg Ganesh Nativo 0.001 0.01 0.1 1 10 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Clientes de Prueba Tiempo de Respuesta Promedio (seg) Ganesh Nativo Nota Escala Logarítmica (c) Rendimiento: Mezcla de Navegación (d) Tiempo de Respuesta: Mezcla de Navegación Promedio de tres pruebas. La desviación estándar máxima para el rendimiento y el tiempo de respuesta fue del 2.2% y del 11.8% de la media correspondiente. Figura 8: Referencia de la subasta AUCTION - Rendimiento y Tiempo de Respuesta Promedio del algoritmo de fragmentación y el segundo con el algoritmo basado en filas de Ganesh. Los resultados de Rabins para la Mezcla de Navegación se normalizan con los resultados de Ganesh y se presentan en la Figura 9. Como muestra la Figura 9 (a), a 5 Mb/s, independientemente de la configuración del cliente de prueba, Rabin tiene un rendimiento significativamente inferior a Ganesh. Esto sucede debido a una combinación de dos razones. Primero, como se describe en la Sección 3.1, Rabin encuentra menos similitud ya que no explota la información estructural de los resultados. Segundo, este punto de referencia contenía algunas consultas que generaron resultados grandes. En este caso, Rabin, con un tamaño de fragmento promedio pequeño, generó una gran cantidad de objetos que desplazaron otros datos útiles de la caché. Por el contrario, Ganesh pudo detectar estas filas grandes y aumentar correspondientemente el tamaño de los bloques. Esto fue confirmado ya que las estadísticas de caché mostraron que la proporción de aciertos de Ganesh era aproximadamente tres veces mayor que la de Rabin. Las mediciones de rendimiento a 20 Mb/s fueron similares, con la excepción del rendimiento de Rabins con 400 clientes de prueba. En este caso, Ganesh no estaba limitado por la red y, de hecho, el rendimiento era el mismo que el de 400 clientes a 5 Mb/s. Rabin, sin embargo, aprovechó el aumento del ancho de banda de 5 a 20 Mb/s para ofrecer un rendimiento ligeramente mejor. A 100 Mb/s, el rendimiento de Rabin era casi similar al de Ganesh ya que el ancho de banda ya no era un cuello de botella. El tiempo de respuesta normalizado, presentado en la Figura 9 (b), muestra tendencias similares. A 5 y 20 Mb/s, la adición de clientes de prueba disminuye el tiempo de respuesta normalizado, ya que el tiempo de respuesta promedio de Ganesh aumenta más rápido que el de Rabin. Sin embargo, en ningún momento Rabin supera a Ganesh. Ten en cuenta que con 400 y 800 clientes a 100 Mb/s, Rabin tiene un mayor sobrecosto incluso cuando no está limitado por el ancho de banda. Como se menciona en la Sección 3.1, esto se debe a que Rabin tiene que hashear cada ResultSet dos veces. La sobrecarga desaparece con 1200 y 1600 clientes, ya que la CPU de la base de datos está saturada y limita el rendimiento tanto de Ganesh como de Rabin. 7. SUPERPOSICIÓN DE PROXY En esta sección, abordamos la tercera pregunta planteada en la Sección 4: ¿Es aceptable la superposición del diseño basado en proxy de Ganesh? Para responder a esta pregunta, nos concentramos en su rendimiento en las bandas de mayor ancho de banda. Nuestra evaluación en la Sección 5 mostró que Ganesh, en comparación con Native, puede ofrecer una mejora sustancial en el rendimiento a anchos de banda más bajos. Solo en anchos de banda más altos serían visibles los costos adicionales de latencia, medidos por el tiempo promedio de respuesta para una solicitud de cliente, y de rendimiento, medidos por la cantidad de solicitudes de cliente que pueden ser atendidas por segundo. Al observar la combinación de autoría del benchmark original de BBOARD, no se aprecian ganancias visibles de Ganesh a 100 Mb/s. Sin embargo, Ganesh sigue rastreando a Native en cuanto a rendimiento. Si bien el tiempo promedio de respuesta es mayor para Ganesh, la diferencia absoluta está entre 0.01 y 0.04 segundos y sería imperceptible para el usuario final. La mezcla de navegación muestra una diferencia aún menor en los tiempos de respuesta promedio. Los resultados de la variante del filtro de los benchmarks de BBOARD son similares. Incluso para el benchmark de SUBASTA, la diferencia entre el tiempo de respuesta de Nativo y Ganesh a 100 Mb/s nunca fue mayor a 0.02 segundos. La única excepción a los resultados anteriores se observó en la variante de filtro del benchmark BBOARD, donde Ganesh con 1600 clientes de prueba añadió 0.85 segundos al tiempo de respuesta promedio. Por lo tanto, incluso para redes mucho más rápidas donde el enlace WAN no es el cuello de botella, Ganesh siempre ofrece un rendimiento equivalente al Nativo. Si bien se agrega algo de latencia adicional debido al diseño basado en proxy, generalmente es imperceptible. TRABAJO RELACIONADO Hasta donde sabemos, Ganesh es el primer sistema que combina el uso de técnicas basadas en hash con el almacenamiento en caché de resultados de base de datos para mejorar el rendimiento y los tiempos de respuesta de aplicaciones con contenido dinámico. También creemos que es el primer sistema en demostrar los beneficios de utilizar información estructural para WWW 2007 / Track: Rendimiento y Escalabilidad Sesión: Sistemas Escalables para Contenido Dinámico 318 0.0 0.2 0.4 0.6 0.8 1.0 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Clientes de Prueba Rendimiento Normalizado 31.8 3.8 2.8 2.3 23.8 32.8 5.8 3.6 1.8 2.1 1.1 1.0 0 5 10 15 20 25 30 35 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Clientes de Prueba Tiempo de Respuesta Normalizado (a) Rendimiento Normalizado: Mayor es mejor (b) Tiempo de Respuesta Normalizado: Mayor es peor Para el rendimiento, un resultado normalizado mayor que 1 implica que Rabin es mejor. Para el tiempo de respuesta, un resultado normalizado mayor que 1 implica que Ganesh es mejor. Media de tres pruebas. La desviación estándar máxima para el rendimiento y el tiempo de respuesta fue del 9.1% y del 13.9% de la media correspondiente. Figura 9: Comparación normalizada de Ganesh vs. Rabin - Mezcla de navegación BBOARD detectando similitud. En esta sección, primero discutimos enfoques alternativos para almacenar en caché contenido dinámico y luego examinamos otros usos de primitivas basadas en hash en sistemas distribuidos. 8.1 Almacenamiento en Caché de Contenido Dinámico En la capa de base de datos, varios sistemas han abogado por la caché de nivel intermedio donde partes de la base de datos se replican en el borde o servidor [3, 4, 20]. Estos sistemas almacenan en caché tablas completas en lo que es esencialmente una base de datos replicada o utilizan vistas materializadas de respuestas de consultas anteriores [19]. Requieren una integración estrecha con la base de datos del sistema para garantizar un límite de tiempo en la propagación de actualizaciones. Estos sistemas suelen estar dirigidos a cargas de trabajo que no requieren una consistencia estricta y pueden tolerar datos obsoletos. Además, a diferencia de Ganesh, algunas de estas soluciones de almacenamiento en caché de nivel medio [2, 3], sufren de la complejidad de tener que participar en la planificación de consultas y el procesamiento de consultas distribuidas. Gao et al. [15] proponen utilizar una arquitectura de replicación de objetos distribuidos donde los requisitos de consistencia de las tiendas de datos se adaptan según la aplicación. Estas soluciones requieren recursos sustanciales de desarrollo y un entendimiento detallado de la aplicación que se está modificando. Si bien existen sistemas que intentan automatizar la partición y replicación de la base de datos de una aplicación [34], no proporcionan semántica de transacciones completa. En comparación, Ganesh no debilita ninguna de las semánticas proporcionadas por la base de datos subyacente. El trabajo reciente en la evaluación de opciones de almacenamiento en caché de borde para sitios web dinámicos [38] ha sugerido que, sin una planificación cuidadosa, el empleo de estrategias complejas de descarga puede perjudicar el rendimiento. En cambio, el trabajo aboga por una arquitectura en la que todos los niveles, excepto la base de datos, deberían ser trasladados al borde. Nuestra evaluación de Ganesh ha demostrado que sería beneficioso para estos escenarios. Para mejorar la escalabilidad de la base de datos, C-JDBC [10], SSS [22] y Ganymed [28] también abogan por el uso de una arquitectura basada en interposición para clusterizar y replicar bases de datos de forma transparente a nivel de middleware. Los enfoques de estas arquitecturas y Ganesh son complementarios y se beneficiarían mutuamente. Avanzando hacia la capa de presentación, se ha producido una amplia adopción de la caché basada en fragmentos [14], la cual mejora la utilización de la caché al almacenar por separado diferentes partes de las páginas web generadas. Si bien el almacenamiento en caché basado en fragmentos funciona en el borde, una propuesta reciente ha propuesto trasladar el ensamblaje de páginas web a los clientes para optimizar la entrega de contenido [31]. Si bien Ganesh no se utiliza en la capa de presentación, los mismos principios se han aplicado en la Detección de Transferencias Duplicadas [25] para aumentar la eficiencia de la caché web, así como para el acceso web a través de enlaces con ancho de banda limitado [33]. 8.2 Sistemas basados en hash En los últimos años han surgido muchos sistemas que explotan técnicas basadas en hash. En el centro de todos estos sistemas se encuentra la idea de detectar similitudes en los datos sin necesidad de interpretar esos datos. Esta idea simple pero elegante se basa en el hash criptográfico, como se discutió anteriormente en la Sección 2. Las aplicaciones exitosas de esta idea abarcan una amplia gama de sistemas de almacenamiento. Los ejemplos incluyen la copia de seguridad entre pares de archivos informáticos personales [11], el archivado eficiente de datos [29] y la búsqueda de archivos similares [21]. Spring y Wetherall [35] aplican principios similares a nivel de red. Utilizando cachés sincronizadas en ambos extremos de un enlace de red, los datos duplicados son reemplazados por tokens más pequeños para su transmisión y luego restaurados en el extremo remoto. Este y otros sistemas basados en hash como los sistemas de archivos CASPER [37] y LBFS [26], y optimizadores de ancho de banda de Capa-2 como Riverbed y Peribit utilizan la huella digital de Rabin [30] para descubrir tramos de similitud en los datos. Este enfoque es especialmente útil cuando los elementos de datos son modificados en su lugar a través de inserciones, eliminaciones y actualizaciones. Sin embargo, como se muestra en la Sección 6, el rendimiento de esta técnica puede experimentar una caída dramática en presencia de reordenamiento de datos. Ganesh en cambio utiliza los límites de fila como divisores para detectar similitudes. El uso más agresivo de técnicas basadas en hash es por sistemas que utilizan hashes como identificadores principales para objetos en almacenamiento persistente. Los sistemas de almacenamiento como CFS [12] y PAST [13] que han sido construidos utilizando tablas hash distribuidas entran en esta categoría. Single Instance Storage [6] y Venti [29] son otros ejemplos de tales sistemas. Como se discute en la Sección 2.2, el uso de hashes criptográficos para abordar datos persistentes representa un nivel más profundo de confianza en su resistencia a colisiones que la asumida por Ganesh. Si el tiempo revela deficiencias en el algoritmo hash, el esfuerzo necesario para corregir la falla es mucho mayor. En Ganesh, simplemente se trata de reemplazar el algoritmo hash. 9. CONCLUSIÓN El creciente uso de contenido web dinámico generado a partir de bases de datos relacionales aumenta las demandas de ancho de banda de la WAN. Las soluciones de almacenamiento en caché tradicionales para reducir el ancho de banda y la latencia suelen ser ineficaces para este tipo de contenido. Este documento muestra que el impacto de los accesos a bases de datos a través de WAN puede reducirse sustancialmente mediante la arquitectura Ganesh sin comprometer la estricta semántica de consistencia de las bases de datos. La esencia de la arquitectura Ganesh es el uso de la computación en los bordes para reducir la comunicación a través de Internet. Ganesh es capaz de utilizar hashes criptográficos para detectar similitud con resultados anteriores y enviar recetas compactas de resultados en lugar de resultados completos en la sesión de Sistemas Escalables para Contenido Dinámico 319 de WWW 2007 / Track: Rendimiento y Escalabilidad. Nuestro diseño utiliza la interposición para lograr una transparencia completa: los clientes, los servidores de aplicaciones y los servidores de bases de datos no son conscientes de la presencia de Ganesh y no requieren ninguna modificación. Nuestra evaluación experimental confirma que Ganesh, aunque conceptualmente simple, puede ser altamente efectivo en mejorar el rendimiento y el tiempo de respuesta. Nuestros resultados también confirman que aprovechar la estructura presente en los resultados de la base de datos para detectar similitudes es crucial para esta mejora en el rendimiento. REFERENCIAS [1] AKELLA, A., SESHAN, S., Y SHAIKH, A. Una evaluación empírica de los cuellos de botella en Internet de área amplia. En Proc. 3ª Conferencia ACM SIGCOMM sobre Medición de Internet (Miami Beach, FL, EE. UU., Oct. 2003), pp. 101-114. [2] ALTINEL, M., BORNH ¨OVD, C., KRISHNAMURTHY, S., MOHAN, C., PIRAHESH, H., Y REINWALD, B. Tablas de caché: allanando el camino para una caché de base de datos adaptativa. En Proc. del 29º VLDB (Berlín, Alemania, 2003), pp. 718-729. [3] ALTINEL, M., LUO, Q., KRISHNAMURTHY, S., MOHAN, C., PIRAHESH, H., LINDSAY, B. G., WOO, H., Y BROWN, L. Dbcache: Caché de base de datos para servidores de aplicaciones web. En Proc. 2002 ACM SIGMOD (2002), pp. 612-612. [4] AMIRI, K., PARK, S., TEWARI, R., Y PADMANABHAN, S. Dbproxy: una caché de datos dinámica para aplicaciones web. En Proc. Conferencia Internacional de Ingeniería de Datos de IEEE (ICDE) (Mar. 2003). [5] BLACK, J. Compare-by-hash: Un análisis razonado. En Proc. Conferencia Técnica Anual USENIX 2006 (Boston, MA, mayo de 2006), pp. 85-90. [6] BOLOSKY, W. J., CORBIN, S., GOEBEL, D., y DOUCEUR, J. R. Almacenamiento de instancia única en Windows 2000. En Proc. 4to Simposio de Sistemas Windows de USENIX (Seattle, WA, ago. 2000), pp. 13-24. [7] BREWER, E. A. Lecciones de servicios a gran escala. IEEE Internet Computing 5, 4 (2001), 46-55. [8] BRODER, A., GLASSMAN, S., MANASSE, M., AND ZWEIG, G. Agrupamiento sintáctico de la web. En Proc. 6ta Conferencia Internacional WWW (1997). [9] CECCHET, E., CHANDA, A., ELNIKETY, S., MARGUERITE, J., Y ZWAENEPOEL, W. Comparación de rendimiento de arquitecturas de middleware para generar contenido web dinámico. En Proc. Cuarta Conferencia Internacional de Middleware ACM/IFIP/USENIX (Río de Janeiro, Brasil, junio de 2003). [10] CECCHET, E., MARGUERITE, J., Y ZWAENEPOEL, W. C-JDBC: Middleware flexible de agrupación de bases de datos. En Proc. Conferencia Técnica Anual USENIX 2004 (Boston, MA, junio de 2004). [11] COX, L. P., MURRAY, C. D., Y NOBLE, B. D. Pastiche: Haciendo que la copia de seguridad sea barata y fácil. En OSDI: Simposio sobre Diseño e Implementación de Sistemas Operativos (2002). [12] DABEK, F., KAASHOEK, M. F., KARGER, D., MORRIS, R., Y STOICA, I. Almacenamiento cooperativo de amplia área con CFS. En el 18º Simposio ACM sobre Principios de Sistemas Operativos (Banff, Canadá, octubre de 2001). [13] DRUSCHEL, P., Y ROWSTRON, A. PASADO: Una utilidad de almacenamiento entre pares a gran escala y persistente. En HotOS VIII (Schloss Elmau, Alemania, mayo de 2001), pp. 75-80. [14] Incluye el lado del borde. http://www.esi.org. [15] GAO, L., DAHLIN, M., NAYATE, A., ZHENG, J., Y IYENGAR, A. Replicación de datos específica de la aplicación para servicios en el borde. En WWW 03: Proc. Duodécima Conferencia Internacional sobre la World Wide Web (2003), pp. 449-460. [16] HEMMINGER, S. Netem - emulando redes reales en el laboratorio. En Proc. 2005 Linux Conference Australia (Canberra, Australia, Abr. 2005). [17] HENSON, V. Un análisis de compare-by-hash. En Proc. 9º Taller sobre Temas Candentes en Sistemas Operativos (HotOS IX) (mayo de 2003), pp. 13-18. [18] Benchmarks de Jmob. http://jmob.objectweb.org/. [19] LABRINIDIS, A., Y ROUSSOPOULOS, N. Equilibrando el rendimiento y la frescura de los datos en servidores de bases de datos web. En Proc. 29ª Conferencia VLDB (Sept. 2003). [20] LARSON, P.-A., GOLDSTEIN, J., Y ZHOU, J. Caché transparente de bases de datos en el nivel intermedio en SQL Server. En Proc. 2003 ACM SIGMOD (2003), pp. 661-661. [21] MANBER, U. Encontrar archivos similares en un sistema de archivos grande. En Proc. Conferencia Técnica de Invierno de USENIX 1994 (San Francisco, CA, 17-21 de 1994), pp. 1-10. [22] MANJHI, A., AILAMAKI, A., MAGGS, B. M., MOWRY, T. C., OLSTON, C., Y TOMASIC, A. Escalabilidad y seguridad simultáneas para aplicaciones web intensivas en datos. En Proc. 2006 ACM SIGMOD (junio de 2006), pp. 241-252. [23] MENEZES, A. J., VANSTONE, S. A., Y OORSCHOT, P. C. V. Manual de Criptografía Aplicada. CRC Press, 1996. [24] MILLER, R. B. \n\nCRC Press, 1996. [24] MILLER, R. B. Tiempo de respuesta en transacciones conversacionales entre humanos y computadoras. En Proc. Conferencia Conjunta de Computación de Otoño de AFIPS (1968), pp. 267-277. [25] MOGUL, J. C., CHAN, Y. M., Y KELLY, T. Diseño, implementación y evaluación de la detección de transferencias duplicadas en http. En Proc. Primer Simposio sobre Diseño e Implementación de Sistemas en Red (San Francisco, CA, Mar. 2004). [26] MUTHITACHAROEN, A., CHEN, B., Y MAZIERES, D. Un sistema de archivos en red de bajo ancho de banda. En Proc. 18º Simposio de la ACM sobre Principios de Sistemas Operativos (Banff, Canadá, Oct. 2001). [27] PFEIFER, D., Y JAKSCHITSCH, H. Caché basada en métodos en aplicaciones de servidores multinivel. En Proc. Quinto Simposio Internacional sobre Objetos y Aplicaciones Distribuidas (Catania, Sicilia, Italia, noviembre de 2003). [28] PLATTNER, C., Y ALONSO, G. Ganymed: Replicación escalable para aplicaciones web transaccionales. En Proc. 5ta Conferencia Internacional de Middleware ACM/IFIP/USENIX (2004), pp. 155-174. [29] QUINLAN, S., Y DORWARD, S. Venti: Un nuevo enfoque para el almacenamiento de archivos. En Proc. Conferencia FAST 2002 sobre Tecnologías de Archivo y Almacenamiento (2002). [30] RABIN, M. Huellas dactilares mediante polinomios aleatorios. En el Informe Técnico TR-15-81 (1981) del Centro de Investigación en Tecnología Informática de la Universidad de Harvard. [31] RABINOVICH, M., XIAO, Z., DOUGLIS, F., Y KALMANEK, C. Mover los lados de los bordes incluye a los clientes reales en el borde. En Proc. 4to Simposio USENIX sobre Tecnologías y Sistemas de Internet (Seattle, WA, Mar. 2003). [32] REESE, G. Programación de bases de datos con JDBC y Java, 1ra ed. OReilly, junio de 1997. [33] RHEA, S., LIANG, K., Y BREWER, E. Caché web basada en valores. En Proc. Duodécima Conferencia Internacional de la World Wide Web (mayo de 2003). [34] SIVASUBRAMANIAN, S., ALONSO, G., PIERRE, G., Y VAN STEEN, M. Globedb: Replicación autónoma de datos para aplicaciones web. En WWW 05: Actas de la 14ª Conferencia Internacional de la World-Wide Web (mayo de 2005). [35] SPRING, N. T., Y WETHERALL, D. Una técnica independiente de protocolo para eliminar el tráfico de red redundante. En Proc. de ACM SIGCOMM (Ago. 2000). [36] TOLIA, N., HARKES, J., KOZUCH, M., Y SATYANARAYANAN, M. Integrando almacenamiento portátil y distribuido. En Proc. 3ra Conferencia USENIX sobre Tecnologías de Archivos y Almacenamiento (San Francisco, CA, Mar. 2004). [37] TOLIA, N., KOZUCH, M., SATYANARAYANAN, M., KARP, B., PERRIG, A., Y BRESSOUD, T. Uso oportunista del almacenamiento direccionable por contenido para sistemas de archivos distribuidos. En Proc. Conferencia Técnica Anual USENIX 2003 (San Antonio, TX, junio de 2003), pp. 127-140. [38] YUAN, C., CHEN, Y., Y ZHANG, Z. Evaluación de almacenamiento en caché/descarga en el borde para la entrega de contenido dinámico. En WWW 03: Proc. Duodécima Conferencia Internacional sobre la World Wide Web (2003), pp. 461-471. WWW 2007 / Pista: Rendimiento y Escalabilidad Sesión: Sistemas Escalables para Contenido Dinámico 320 ",
            "candidates": [],
            "error": [
                [
                    "operaciones de lectura y escritura",
                    "operaciones de lectura-escritura"
                ]
            ]
        },
        "reciperesultset": {
            "translated_key": "RecipeResultSet",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Consistency-preserving Caching of Dynamic Database Content∗ Niraj Tolia and M. Satyanarayanan Carnegie Mellon University {ntolia,satya}@cs.cmu.edu ABSTRACT With the growing use of dynamic web content generated from relational databases, traditional caching solutions for throughput and latency improvements are ineffective.",
                "We describe a middleware layer called Ganesh that reduces the volume of data transmitted without semantic interpretation of queries or results.",
                "It achieves this reduction through the use of cryptographic hashing to detect similarities with previous results.",
                "These benefits do not require any compromise of the strict consistency semantics provided by the back-end database.",
                "Further, Ganesh does not require modifications to applications, web servers, or database servers, and works with closed-source applications and databases.",
                "Using two benchmarks representative of dynamic web sites, measurements of our prototype show that it can increase end-to-end throughput by as much as twofold for non-data intensive applications and by as much as tenfold for data intensive ones.",
                "Categories and Subject Descriptors C.2.4 [Computer-Communication Networks]: Distributed Systems; H.2.4 [Database Management]: Systems General Terms Design, Performance 1.",
                "INTRODUCTION An increasing fraction of web content is dynamically generated from back-end relational databases.",
                "Even when database content remains unchanged, temporal locality of access cannot be exploited because dynamic content is not cacheable by web browsers or by intermediate caching servers such as Akamai mirrors.",
                "In a multitiered architecture, each web request can stress the WAN link between the web server and the database.",
                "This causes user experience to be highly variable because there is no caching to insulate the client from bursty loads.",
                "Previous attempts in caching dynamic database content have generally weakened transactional semantics [3, 4] or required application modifications [15, 34].",
                "We report on a new solution that takes the form of a databaseagnostic middleware layer called Ganesh.",
                "Ganesh makes no effort to semantically interpret the contents of queries or their results.",
                "Instead, it relies exclusively on cryptographic hashing to detect similarities with previous results.",
                "Hash-based similarity detection has seen increasing use in distributed file systems [26, 36, 37] for improving performance on low-bandwidth networks.",
                "However, these techniques have not been used for relational databases.",
                "Unlike previous approaches that use generic methods to detect similarity, Ganesh exploits the structure of relational database results to yield superior performance improvement.",
                "One faces at least three challenges in applying hash-based similarity detection to back-end databases.",
                "First, previous work in this space has traditionally viewed storage content as uninterpreted bags of bits with no internal structure.",
                "This allows hash-based techniques to operate on long, contiguous runs of data for maximum effectiveness.",
                "In contrast, relational databases have rich internal structure that may not be as amenable to hash-based similarity detection.",
                "Second, relational databases have very tight integrity and consistency constraints that must not be compromised by the use of hash-based techniques.",
                "Third, the source code of commercial databases is typically not available.",
                "This is in contrast to previous work which presumed availability of source code.",
                "Our experiments show that Ganesh, while conceptually simple, can improve performance significantly at bandwidths representative of todays commercial Internet.",
                "On benchmarks modeling multitiered web applications, the throughput improvement was as high as tenfold for data-intensive workloads.",
                "For workloads that were not data-intensive, throughput improvements of up to twofold were observed.",
                "Even when bandwidth was not a constraint, Ganesh had low overhead and did not hurt performance.",
                "Our experiments also confirm that exploiting the structure present in database results is crucial to this performance improvement. 2.",
                "BACKGROUND 2.1 Dynamic Content Generation As the World Wide Web has grown, many web sites have decentralized their data and functionality by pushing them to the edges of the Internet.",
                "Today, eBusiness systems often use a three-tiered architecture consisting of a front-end web server, an application server, and a back-end database server.",
                "Figure 1 illustrates this architecture.",
                "The first two tiers can be replicated close to a concentration of clients at the edge of the Internet.",
                "This improves user experience by lowering end-to-end latency and reducing exposure WWW 2007 / Track: Performance and Scalability Session: Scalable Systems for Dynamic Content 311 Back-End Database Server Front-End Web and Application Servers Figure 1: Multi-Tier Architecture to backbone traffic congestion.",
                "It can also increase the availability and scalability of web services.",
                "Content that is generated dynamically from the back-end database cannot be cached in the first two tiers.",
                "While databases can be easily replicated in a LAN, this is infeasible in a WAN because of the difficult task of simultaneously providing strong consistency, availability, and tolerance to network partitions [7].",
                "As a result, databases tend to be centralized to meet the strong consistency requirements of many eBusiness applications such as banking, finance, and online retailing [38].",
                "Thus, the back-end database is usually located far from many sets of first and second-tier nodes [2].",
                "In the absence of both caching and replication, WAN bandwidth can easily become a limiting factor in the performance and scalability of data-intensive applications. 2.2 Hash-Based Systems Ganeshs focus is on efficient transmission of results by discovering similarities with the results of previous queries.",
                "As SQL queries can generate large results, hash-based techniques lend themselves well to the problem of efficiently transferring these large results across bandwidth constrained links.",
                "The use of hash-based techniques to reduce the volume of data transmitted has emerged as a common theme of many recent storage systems, as discussed in Section 8.2.",
                "These techniques rely on some basic assumptions.",
                "Cryptographic hash functions are assumed to be collision-resistant.",
                "In other words, it is computationally intractable to find two inputs that hash to the same output.",
                "The functions are also assumed to be one-way; that is, finding an input that results in a specific output is computationally infeasible.",
                "Menezes et al. [23] provide more details about these assumptions.",
                "The above assumptions allow hash-based systems to assume that collisions do not occur.",
                "Hence, they are able to treat the hash of a data item as its unique identifier.",
                "A collection of data items effectively becomes content-addressable, allowing a small hash to serve as a codeword for a much larger data item in permanent storage or network transmission.",
                "The assumption that collisions are so rare as to be effectively non-existent has recently come under fire [17].",
                "However, as explained by Black [5], we believe that these issues do not form a concern for Ganesh.",
                "All communication is between trusted parts of the system and an adversary has no way to force Ganesh to accept invalid data.",
                "Further, Ganesh does not depend critically on any specific hash function.",
                "While we currently use SHA-1, replacing it with a different hash function would be simple.",
                "There would be no impact on performance as stronger hash functions (e.g.",
                "SHA256) only add a few extra bytes and the generated hashes are still orders of magnitude smaller than the data items they represent.",
                "No re-hashing of permanent storage is required since Ganesh only uses hashing on volatile data. 3.",
                "DESIGN AND IMPLEMENTATION Ganesh exploits redundancy in the result stream to avoid transmitting result fragments that are already present at the query site.",
                "Redundancy can arise naturally in many different ways.",
                "For example, a query repeated after a certain interval may return a different result because of updates to the database; however, there may be significant commonality between the two results.",
                "As another example, a user who is refining a search may generate a sequence of queries with overlapping results.",
                "When Ganesh detects redundancy, it suppresses transmission of the corresponding result fragments.",
                "Instead, it transmits a much smaller digest of those fragments and lets the query site reconstruct the result through hash lookup in a cache of previous results.",
                "In effect, Ganesh uses computation at the edges to reduce Internet communication.",
                "Our description of Ganesh focuses on four aspects.",
                "We first explain our approach to detecting similarity in query results.",
                "Next, we discuss how the Ganesh architecture is completely invisible to all components of a multi-tier system.",
                "We then describe Ganeshs proxy-based approach and the dataflow for detecting similarity. 3.1 Detecting Similarity One of the key design decisions in Ganesh is how similarity is detected.",
                "There are many potential ways to decompose a result into fragments.",
                "The optimal way is, of course, the one that results in the smallest possible object for transmission for a given querys results.",
                "Finding this optimal decomposition is a difficult problem because of the large space of possibilities and because the optimal choice depends on many factors such as the contents of the querys result, the history of recent results, and the cache management algorithm.",
                "When an object is opaque, the use of Rabin fingerprints [8, 30] to detect common data between two objects has been successfully shown in the past by systems such as LBFS [26] and CASPER [37].",
                "Rabin fingerprinting uses a sliding window over the data to compute a rolling hash.",
                "Assuming that the hash function is uniformly distributed, a chunk boundary is defined whenever the lower order bits of the hash value equal some predetermined value.",
                "The number of lower order bits used defines the average chunk size.",
                "These sub-divided chunks of the object become the unit of comparison for detecting similarity between different objects.",
                "As the locations of boundaries found by using Rabin fingerprints is stochastically determined, they usually fail to align with any structural properties of the underlying data.",
                "The algorithm therefore deals well with in-place updates, insertions and deletions.",
                "However, it performs poorly in the presence of any reordering of data.",
                "Figure 2 shows an example where two results, A and B, consisting of three rows, have the same data but have different sort attributes.",
                "In the extreme case, Rabin fingerprinting might be unable to find any similar data due to the way it detects chunk boundaries.",
                "Fortunately, Ganesh can use domain specific knowledge for more precise boundary detection.",
                "The information we exploit is that a querys result reflects the structure of a relational database where all data is organized as tables and rows.",
                "It is therefore simple to check for similarity with previous results at two granularities: first the entire result, and then individual rows.",
                "The end of a row in a result serves as a natural chunk boundary.",
                "It is important to note that using the tabular structure in results only involves shallow interpretation of the data.",
                "Ganesh does not perform any deeper semantic interpretation such as understanding data types, result schema, or integrity constraints.",
                "Tuning Rabin fingerprinting for a workload can also be difficult.",
                "If the average chunk size is too large, chunks can span multiple result rows.",
                "However, selecting a smaller average chunk size increases the amount of metadata required to the describe the results.",
                "WWW 2007 / Track: Performance and Scalability Session: Scalable Systems for Dynamic Content 312 Figure 2: Rabin Fingerprinting vs. Ganeshs Chunking This, in turn, would decrease the savings obtained via its use.",
                "Rabin fingerprinting also needs two computationally-expensive passes over the data: once to determine chunk boundaries and one again to generate cryptographic hashes for the chunks.",
                "Ganesh only needs a single pass for hash generation as the chunk boundaries are provided by the datas natural structure.",
                "The performance comparison in Section 6 shows that Ganeshs row-based algorithm outperforms Rabin fingerprinting.",
                "Given that previous work has already shown that Rabin fingerprinting performs better than gzip [26], we do not compare Ganesh to compression algorithms in this paper. 3.2 Transparency The key factor influencing our design was the need for Ganesh to be completely transparent to all components of a typical eBusiness system: web servers, application servers, and database servers.",
                "Without this, Ganesh stands little chance of having a significant real-world impact.",
                "Requiring modifications to any of the above components would raise the barrier for entry of Ganesh into an existing system, and thus reduce its chances of adoption.",
                "Preserving transparency is simplified by the fact that Ganesh is purely a performance enhancement, not a functionality or usability enhancement.",
                "We chose agent interposition as the architectural approach to realizing our goal.",
                "This approach relies on the existence of a compact programming interface that is already widely used by target software.",
                "It also relies on a mechanism to easily add new code without disrupting existing module structure.",
                "These conditions are easily met in our context because of the popularity of Java as the programming language for eBusiness systems.",
                "The Java Database Connectivity (JDBC) API [32] allows Java applications to access a wide variety of databases and even other tabular data repositories such as flat files.",
                "Access to these data sources is provided by JDBC drivers that translate between the JDBC API and the database communication mechanism.",
                "Figure 3(a) shows how JDBC is typically used in an application.",
                "As the JDBC interface is standardized, one can substitute one JDBC driver for another without application modifications.",
                "The JDBC driver thus becomes the natural module to exploit for code interposition.",
                "As shown in Figure 3(b), the native JDBC driver is replaced with a Ganesh JDBC driver that presents the same standardized interface.",
                "The Ganesh driver maintains an in-memory cache of result fragments from previous queries and performs reassembly of results.",
                "At the database, we add a new process called the Ganesh proxy.",
                "This proxy, which can be shared by multiple front-end nodes, consists of two parts: code to detect similarity in result fragments and the original native JDBC driver that communicates with the database.",
                "The use of a proxy at the database makes Ganesh database-agnostic and simplifies prototyping and experimentation.",
                "Ganesh is thus able to work with a wide range of databases and applications, requiring no modifications to either. 3.3 Proxy-Based Caching The native JDBC driver shown in Figure 3(a) is a lightweight code component supplied by the database vendor.",
                "Its main funcClient Database Web and Application Server Native JDBC Driver WAN (a) Native Architecture Client Database Ganesh Proxy Native JDBC Driver WAN Web and Application Server Ganesh JDBC Driver (b) Ganeshs Interposition-based Architecture Figure 3: Native vs. Ganesh Architecture tion is to mediate communication between the application and the remote database.",
                "It forwards queries, buffers entire results, and responds to application requests to view parts of results.",
                "The Ganesh JDBC driver shown in Figure 3(b) presents the application with an interface identical to that provided by the native driver.",
                "It provides the ability to reconstruct results from compact hash-based descriptions sent by the proxy.",
                "To perform this reconstruction, the driver maintains an in-memory cache of recentlyreceived results.",
                "This cache is only used as a source of result fragments in reconstructing results.",
                "No attempt is made by the Ganesh driver or proxy to track database updates.",
                "The lack of cache consistency does not hurt correctness as a description of the results is always fetched from the proxy - at worst, there will be no performance benefit from using Ganesh.",
                "Stale data will simply be paged out of the cache over time.",
                "The Ganesh proxy accesses the database via the native JDBC driver, which remains unchanged between Figures 3(a) and (b).",
                "The database is thus completely unaware of the existence of the proxy.",
                "The proxy does not examine any queries received from the Ganesh driver but passes them to the native driver.",
                "Instead, the proxy is responsible for inspecting database output received from the native driver, detecting similar results, and generating hash-based encodings of these results whenever enough similarity is found.",
                "While this architecture does not decrease the load on a database, as mentioned earlier in Section 2.1, it is much easier to replicate databases for scalability in a LAN than in a WAN.",
                "To generate a hash-based encoding, the proxy must be aware of what result fragments are available in the Ganesh drivers cache.",
                "One approach is to be optimistic, and to assume that all result fragments are available.",
                "This will result in the smallest possible initial transmission of a result.",
                "However, in cases where there is little overlap with previous results, the Ganesh driver will have to make many calls to the proxy during reconstruction to fetch missing result fragments.",
                "To avoid this situation, the proxy loosely tracks the state of the Ganesh drivers cache.",
                "Since both components are under our control, it is relatively simple to do this without resorting to gray-box techniques or explicit communication for maintaining cache coherence.",
                "Instead, the proxy simulates the Ganesh drivers cache management algorithm and uses this to maintain a list of hashes for which the Ganesh driver is likely to possess the result fragments.",
                "In case of mistracking, there will be no loss of correctness but there will be extra round-trip delays to fetch the missing fragments.",
                "If the client detects loss of synchronization with the proxy, it can ask the proxy to reset the state shared between them.",
                "Also note that the proxy does not need to keep the result fragments themselves, only their hashes.",
                "This allows the proxy to remain scalable even when it is shared by many front-end nodes.",
                "WWW 2007 / Track: Performance and Scalability Session: Scalable Systems for Dynamic Content 313 Object Output Stream Convert ResultSet Object Input Stream Convert ResultSet All Data Recipe ResultSet All Data ResultSet Network Ganesh Proxy Ganesh JDBC Driver Result Set Recipe Result Set Yes Yes No No GaneshInputStream GaneshOutputStream Figure 4: Dataflow for Result Handling 3.4 Encoding and Decoding Results The Ganesh proxy receives database output as Java objects from the native JDBC driver.",
                "It examines this output to see if a Java object of type ResultSet is present.",
                "The JDBC interface uses this data type to store results of database queries.",
                "If a ResultSet object is found, it is shrunk as discussed below.",
                "All other Java objects are passed through unmodified.",
                "As discussed in Section 3.1, the proxy uses the row boundaries defined in the ResultSet to partition it into fragments consisting of single result rows.",
                "All ResultSet objects are converted into objects of a new type called <br>reciperesultset</br>.",
                "We use the term recipe for this compact description of a database result because of its similarity to a file recipe in the CASPER file system [37].",
                "The conversion replaces each result fragment that is likely to be present in the Ganesh drivers cache by a SHA-1 hash of that fragment.",
                "Previously unseen result fragments are retained verbatim.",
                "The proxy also retains hashes for the new result fragments as they will be present in the drivers cache in the future.",
                "Note that the proxy only caches hashes for result fragments and does not cache recipes.",
                "The proxy constructs a <br>reciperesultset</br> by checking for similarity at the entire result and then the row level.",
                "If the entire result is predicted to be present in the Ganesh drivers cache, the <br>reciperesultset</br> is simply a single hash of the entire result.",
                "Otherwise, it contains hashes for those rows predicted to be present in that cache; all other rows are retained verbatim.",
                "If the proxy estimates an overall space savings, it will transmit the <br>reciperesultset</br>.",
                "Otherwise the original ResultSet is transmitted.",
                "The <br>reciperesultset</br> objects are transformed back into ResultSet objects by the Ganesh driver.",
                "Figure 4 illustrates ResultSet handling at both ends.",
                "Each SHA-1 hash found in a <br>reciperesultset</br> is looked up in the local cache of result fragments.",
                "On a hit, the hash is replaced by the corresponding fragment.",
                "On a miss, the driver contacts the Ganesh proxy to fetch the fragment.",
                "All previously unseen result fragments that were retained verbatim by the proxy are hashed and added to the result cache.",
                "There should be very few misses if the proxy has accurately tracked the Ganesh drivers cache state.",
                "A future optimization would be to batch the fetch of missing fragments.",
                "This would be valuable when there are many small missing fragments in a high-latency WAN.",
                "Once the transformation is complete, the fully reconstructed ResultSet object is passed up to the application. 4.",
                "EXPERIMENTAL VALIDATION Three questions follow from the goals and design of Ganesh: • First, can performance can be improved significantly by exploiting similarity across database results?",
                "Benchmark Dataset Details 500,000 Users, 12,000 Stories BBOARD 2.0 GB 3,298,000 Comments AUCTION 1.3 GB 1,000,000 Users, 34,000 Items Table 1: Benchmark Dataset Details • Second, how important is Ganeshs structural similarity detection relative to Rabin fingerprintings similarity detection? • Third, is the overhead of the proxy-based design acceptable?",
                "Our evaluation answers these question through controlled experiments with the Ganesh prototype.",
                "This section describes the benchmarks used, our evaluation procedure, and the experimental setup.",
                "Results of the experiments are presented in Sections 5, 6, and 7. 4.1 Benchmarks Our evaluation is based on two benchmarks [18] that have been widely used by other researchers to evaluate various aspects of multi-tier [27] and eBusiness architectures [9].",
                "The first benchmark, BBOARD, is modeled after Slashdot, a technology-oriented news site.",
                "The second benchmark, AUCTION, is modeled after eBay, an online auction site.",
                "In both benchmarks, most content is dynamically generated from information stored in a database.",
                "Details of the datasets used can be found in Table 1. 4.1.1 The BBOARD Benchmark The BBOARD benchmark, also known as RUBBoS [18], models Slashdot, a popular technology-oriented web site.",
                "Slashdot aggregates links to news stories and other topics of interest found elsewhere on the web.",
                "The site also serves as a bulletin board by allowing users to comment on the posted stories in a threaded conversation form.",
                "It is not uncommon for a story to gather hundreds of comments in a matter of hours.",
                "The BBOARD benchmark is similar to the site and models the activities of a user, including readonly operations such as browsing the stories of the day, browsing story categories, and viewing comments as well as write operations such as new user registration, adding and moderating comments, and story submission.",
                "The benchmark consists of three different phases: a short warmup phase, a runtime phase representing the main body of the workload, and a short cool-down phase.",
                "In this paper we only report results from the runtime phase.",
                "The warm-up phase is important in establishing dynamic system state, but measurements from that phase are not significant for our evaluation.",
                "The cool-down phase is solely for allowing the benchmark to shut down.",
                "The warm-up, runtime, and cool-down phases are 2, 15, and 2 minutes respectively.",
                "The number of simulated clients were 400, 800, 1200, and 1600.",
                "The benchmark is available in a Java Servlets and PHP version and has different datasets; we evaluated Ganesh using the Java Servlets version and the Expanded dataset.",
                "The BBOARD benchmark defines two different workloads.",
                "The first, the Authoring mix, consists of 70% read-only operations and 30% read-write operations.",
                "The second, the Browsing mix, contains only read-only operations and does not update the database. 4.1.2 The AUCTION Benchmark The AUCTION benchmark, also known as RUBiS [18], models eBay, the online auction site.",
                "The eBay web site is used to buy and sell items via an auction format.",
                "The main activities of a user include browsing, selling, or bidding for items.",
                "Modeling the activities on this site, this benchmark includes read-only activities such as browsing items by category and by region, as well as read-write WWW 2007 / Track: Performance and Scalability Session: Scalable Systems for Dynamic Content 314 NetEm Router Ganesh Proxy Clients Web and Application Server Database Server Figure 5: Experimental Setup activities such as bidding for items, buying and selling items, and leaving feedback.",
                "As with BBOARD, the benchmark consists of three different phases.",
                "The warm-up, runtime, and cool-down phases for this experiment are 1.5, 15, and 1 minutes respectively.",
                "We tested Ganesh with four client configurations where the number of test clients was set to 400, 800, 1200, and 1600.",
                "The benchmark is available in a Enterprise Java Bean (EJB), Java Servlets, and PHP version and has different datasets; we evaluated Ganesh with the Java Servlets version and the Expanded dataset.",
                "The AUCTION benchmark defines two different workloads.",
                "The first, the Bidding mix, consists of 70% read-only operations and 30% read-write operations.",
                "The second, the Browsing mix, contains only read-only operations and does not update the database. 4.2 Experimental Procedure Both benchmarks involve a synthetic workload of clients accessing a web server.",
                "The number of clients emulated is an experimental parameter.",
                "Each emulated client runs an instance of the benchmark in its own thread, using a matrix to transition between different benchmark states.",
                "The matrix defines a stochastic model with probabilities of transitioning between the different states that represent typical user actions.",
                "An example transition is a user logging into the AUCTION system and then deciding on whether to post an item for sale or bid on active auctions.",
                "Each client also models user think time between requests.",
                "The think time is modeled as an exponential distribution with a mean of 7 seconds.",
                "We evaluate Ganesh along two axes: number of clients and WAN bandwidth.",
                "Higher loads are especially useful in understanding Ganeshs performance when the CPU or disk of the database server or proxy is the limiting factor.",
                "A previous study has shown that approximately 50% of the wide-area Internet bottlenecks observed had an available bandwidth under 10 Mb/s [1].",
                "Based on this work, we focus our evaluation on the WAN bandwidth of 5 Mb/s with 66 ms of round-trip latency, representative of severely constrained network paths, and 20 Mb/s with 33 ms of round-trip latency, representative of a moderately constrained network path.",
                "We also report Ganeshs performance at 100 Mb/s with no added round-trip latency.",
                "This bandwidth, representative of an unconstrained network, is especially useful in revealing any potential overhead of Ganesh in situations where WAN bandwidth is not the limiting factor.",
                "For each combination of number of clients and WAN bandwidth, we measured results from the two configurations listed below: • Native: This configuration corresponds to Figure 3(a).",
                "Native avoids Ganeshs overhead in using a proxy and performing Java object serialization. • Ganesh: This configuration corresponds to Figure 3(b).",
                "For a given number of clients and WAN bandwidth, comparing these results to the corresponding Native results gives the performance benefit due to the Ganesh middleware system.",
                "The metric used to quantify the improvement in throughput is the number of client requests that can be serviced per second.",
                "The metric used to quantify Ganeshs overhead is the average response time for a client request.",
                "For all of the experiments, the Ganesh driver used by the application server used a cache size of 100,000 items1 .",
                "The proxy was effective in tracking the Ganesh drivers cache state; for all of our experiments the miss rate on the driver never exceeded 0.7%. 4.3 Experimental Setup The experimental setup used for the benchmarks can be seen in Figure 5.",
                "All machines were 3.2 GHz Pentium 4s (with HyperThreading enabled.)",
                "With the exception of the database server, all machines had 2 GB of SDRAM and ran the Fedora Core Linux distribution.",
                "The database server had 4 GB of SDRAM.",
                "We used Apaches Tomcat as both the application server that hosted the Java Servlets and the web server.",
                "Both benchmarks used Java Servlets to generate the dynamic content.",
                "The database server used the open source MySQL database.",
                "For the native JDBC drivers, we used the Connector/J drivers provided by MySQL.",
                "The application server used Suns Java Virtual Machine as the runtime environment for the Java Servlets.",
                "The sysstat tool was used to monitor the CPU, network, disk, and memory utilization on all machines.",
                "The machines were connected by a switched gigabit Ethernet network.",
                "As shown in Figure 5, the front-end web and application server was separated from the proxy and database server by a NetEm router [16].",
                "This router allowed us to control the bandwidth and latency settings on the network.",
                "The NetEm router is a standard PC with two network cards running the Linux Traffic Control and Network Emulation software.",
                "The bandwidth and latency constraints were only applied to the link between the application server and the database for the native case and between the application server and the proxy for the Ganesh case.",
                "There is no communication between the application server and the database with Ganesh as all data flows through the proxy.",
                "As our focus was on the WAN link between the application server and the database, there were no constraints on the link between the simulated test clients and the web server. 5.",
                "THROUGHPUT AND RESPONSE TIME In this section, we address the first question raised in Section 4: Can performance can be improved significantly by exploiting similarity across database results?",
                "To answer this question, we use results from the BBOARD and AUCTION benchmarks.",
                "We use two metrics to quantify the performance improvement obtainable through the use of Ganesh: throughput, from the perspective of the web server, and average response time, from the perspective of the client.",
                "Throughput is measured in terms of the number of client requests that can be serviced per second. 5.1 BBOARD Results and Analysis 5.1.1 Authoring Mix Figures 6 (a) and (b) present the average number of requests serviced per second and the average response time for these requests as perceived by the clients for BBOARDs Authoring Mix.",
                "As Figure 6 (a) shows, Native easily saturates the 5 Mb/s link.",
                "At 400 clients, the Native solution delivers 29 requests/sec with an average response time of 8.3 seconds.",
                "Natives throughput drops with an increase in test clients as clients timeout due to congestion at the application server.",
                "Usability studies have shown that response times above 10 seconds cause the user to move on to 1 As Java lacks a sizeof() operator, Java caches therefore limit their size based on the number of objects.",
                "The size of cache dumps taken at the end of the experiments never exceeded 212 MB.",
                "WWW 2007 / Track: Performance and Scalability Session: Scalable Systems for Dynamic Content 315 0 50 100 150 200 250 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Test Clients Requests/sec Native Ganesh 0.001 0.01 0.1 1 10 100 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Test Clients Avg.Resp.Time(sec) Native Ganesh Note Logscale (a) Throughput: Authoring Mix (b) Response Time: Authoring Mix 0 50 100 150 200 250 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Test Clients Requests/sec Native Ganesh 0.001 0.01 0.1 1 10 100 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Test Clients Avg.Resp.Time(sec) Native Ganesh Note Logscale (c) Throughput: Browsing Mix (d) Response Time: Browsing Mix Mean of three trials.",
                "The maximum standard deviation for throughput and response time was 9.8% and 11.9% of the corresponding mean.",
                "Figure 6: BBOARD Benchmark - Throughput and Average Response Time other tasks [24].",
                "Based on these numbers, increasing the number of test clients makes the Native system unusable.",
                "Ganesh at 5 Mb/s, however, delivers a twofold improvement with 400 test clients and a fivefold improvement at 1200 clients.",
                "Ganeshs performance drops slightly at 1200 and 1600 clients as the network is saturated.",
                "Compared to Native, Figure 6 (b) shows that Ganeshs response times are substantially lower with sub-second response times at 400 clients.",
                "Figure 6 (a) also shows that for 400 and 800 test clients Ganesh at 5 Mb/s has the same throughput and average response time as Native at 20 Mb/s.",
                "Only at 1200 and 1600 clients does Native at 20 Mb/s deliver higher throughput than Ganesh at 5 Mb/s.",
                "Comparing both Ganesh and Native at 20 Mb/s, we see that Ganesh is no longer bandwidth constrained and delivers up to a twofold improvement over Native at 1600 test clients.",
                "As Ganesh does not saturate the network with higher test client configurations, at 1600 test clients, its average response time is 0.1 seconds rather than Natives 7.7 seconds.",
                "As expected, there are no visible gains from Ganesh at the higher bandwidth of 100 Mb/s where the network is no longer the bottleneck.",
                "Ganesh, however, still tracks Native in terms of throughput. 5.1.2 Browsing Mix Figures 6 (c) and (d) present the average number of requests serviced per second and the average response time for these requests as perceived by the clients for BBOARDs Browsing Mix.",
                "Regardless of the test client configuration, Figure 6 (c) shows that Natives throughput at 5 Mb/s is limited to 10 reqs/sec.",
                "Ganesh at 5 Mb/s with 400 test clients, delivers more than a sixfold increase in throughput.",
                "The improvement increases to over a elevenfold increase at 800 test clients before Ganesh saturates the network.",
                "Further, Figure 6 (d) shows that Natives average response time of 35 seconds at 400 test clients make the system unusable.",
                "These high response times further increase with the addition of test clients.",
                "Even with the 1600 test client configuration Ganesh delivers an acceptable average response time of 8.2 seconds.",
                "Due to the data-intensive nature of the Browsing mix, Ganesh at 5 Mb/s surprisingly performs much better than Native at 20 Mb/s.",
                "Further, as shown in Figure 6 (d), while the average response time for Native at 20 Mb/s is acceptable at 400 test clients, it is unusable with 800 test clients with an average response time of 15.8 seconds.",
                "Like the 5 Mb/s case, this response time increases with the addition of extra test clients.",
                "Ganesh at 20 Mb/s and both Native and Ganesh at 100 Mb/s are not bandwidth limited.",
                "However, performance plateaus out after 1200 test clients due to the database CPU being saturated. 5.1.3 Filter Variant We were surprised by the Native performance from the BBOARD benchmark.",
                "At the bandwidth of 5 Mb/s, Native performance was lower than what we had expected.",
                "It turned out the benchmark code that displays stories read all the comments associated with the particular story from the database and only then did some postprocessing to select the comments to be displayed.",
                "While this is exactly the behavior of SlashCode, the code base behind the Slashdot web site, we decided to modify the benchmark to perform some pre-filtering at the database.",
                "This modified benchmark, named the Filter Variant, models a developer who applies optimizations at the SQL level to transfer less data.",
                "In the interests of brevity, we only briefly summarize the results from the Authoring mix.",
                "For the Authoring mix, at 800 test clients at 5 Mb/s, Figure 7 (a) shows that Natives throughput increase by 85% when compared to the original benchmark while Ganeshs improvement is smaller at 15%.",
                "Natives performance drops above 800 clients as the test clients time out due to high response times.",
                "The most significant gain for Native is seen at 20 Mb/s.",
                "At 1600 test clients, when compared to the original benchmark, Native sees a 73% improvement in throughput and a 77% reduction in average response time.",
                "While WWW 2007 / Track: Performance and Scalability Session: Scalable Systems for Dynamic Content 316 0 50 100 150 200 250 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Test Clients Requests/sec Native Ganesh 0.001 0.01 0.1 1 10 100 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Test Clients Avg.Resp.Time(sec) Native Ganesh Note Logscale (a) Throughput: Authoring Mix (b) Response Time: Authoring Mix Mean of three trials.",
                "The maximum standard deviation for throughput and response time was 7.2% and 11.5% of the corresponding mean.",
                "Figure 7: BBOARD Benchmark - Filter Variant - Throughput and Average Response Time Ganesh sees no improvement when compared to the original, it still processes 19% more requests/sec than Native.",
                "Thus, while the optimizations were more helpful to Native, Ganesh still delivers an improvement in performance. 5.2 AUCTION Results and Analysis 5.2.1 Bidding Mix Figures 8 (a) and (b) present the average number of requests serviced per second and the average response time for these requests as perceived by the clients for AUCTIONs Bidding Mix.",
                "As mentioned earlier, the Bidding mix consists of a mixture of read and write operations.",
                "The AUCTION benchmark is not as data intensive as BBOARD.",
                "Therefore, most of the gains are observed at the lower bandwidth of 5 Mb/s.",
                "Figure 8 (a) shows that the increase in throughput due to Ganesh ranges from 8% at 400 test clients to 18% with 1600 test clients.",
                "As seen in Figure 8 (b), the average response times for Ganesh are significantly lower than Native ranging from a decrease of 84% at 800 test clients to 88% at 1600 test clients.",
                "Figure 8 (a) also shows that with a fourfold increase of bandwidth from 5 Mb/s to 20 Mb/s, Native is no longer bandwidth constrained and there is no performance difference between Ganesh and Native.",
                "With the higher test client configurations, we did observe that the bandwidth used by Ganesh was lower than Native.",
                "Ganesh might still be useful in these non-constrained scenarios if bandwidth is purchased on a metered basis.",
                "Similar results are seen for the 100 Mb/s scenario. 5.2.2 Browsing Mix For AUCTIONs Browsing Mix, Figures 8 (c) and (d) present the average number of requests serviced per second and the average response time for these requests as perceived by the clients.",
                "Again, most of the gains are observed at lower bandwidths.",
                "At 5 Mb/s, Native and Ganesh deliver similar throughput and response times with 400 test clients.",
                "While the throughput for both remains the same at 800 test clients, Figure 8 (d) shows that Ganeshs average response time is 62% lower than Native.",
                "Native saturates the link at 800 clients and adding extra test clients only increases the average response time.",
                "Ganesh, regardless of the test client configuration, is not bandwidth constrained and maintains the same response time.",
                "At 1600 test clients, Figure 8 (c) shows that Ganeshs throughput is almost twice that of Native.",
                "At the higher bandwidths of 20 and 100 Mb/s, neither Ganesh nor Native is bandwidth limited and deliver equivalent throughput and response times.",
                "Benchmark Orig.",
                "Size Ganesh Size Rabin Size SelectSort1 223.6 MB 5.4 MB 219.3 MB SelectSort2 223.6 MB 5.4 MB 223.6 MB Table 2: Similarity Microbenchmarks 6.",
                "STRUCTURAL VS. RABIN SIMILARITY In this section, we address the second question raised in Section 4: How important is Ganeshs structural similarity detection relative to Rabin fingerprinting-based similarity detecting?",
                "To answer this question, we used microbenchmarks and the BBOARD and AUCTION benchmarks.",
                "As Ganesh always performed better than Rabin fingerprinting, we only present a subset of the results here in the interests of brevity. 6.1 Microbenchmarks Two microbenchmarks show an example of the effects of data reordering on Rabin fingerprinting algorithm.",
                "In the first microbenchmark, SelectSort1, a query with a specified sort order selects 223.6 MB of data spread over approximately 280 K rows.",
                "The query is then repeated with a different sort attribute.",
                "While the same number of rows and the same data is returned, the order of rows is different.",
                "In such a scenario, one would expect a large amount of similarity to be detected between both results.",
                "As Table 2 shows, Ganeshs row-based algorithm achieves a 97.6% reduction while the Rabin fingerprinting algorithm, with the average chunk size parameter set to 4 KB, only achieves a 1% reduction.",
                "The reason, as shown earlier in Figure 2, is that with Rabin fingerprinting, the spans of data between two consecutive boundaries usually cross row boundaries.",
                "With the order of the rows changing in the second result and the Rabin fingerprints now spanning different rows, the algorithm is unable to detect significant similarity.",
                "The small gain seen is mostly for those single rows that are large enough to be broken into multiple chunks.",
                "SelectSort2, another micro-benchmark executed the same queries but increased the minimum chunk size of the Rabin fingerprinting algorithm.",
                "As can be seen in Table 2, even the small gain from the previous microbenchmark disappears as the minimum chunk size was greater than the average row size.",
                "While one can partially address these problems by dynamically varying the parameters of the Rabin fingerprinting algorithm, this can be computationally expensive, especially in the presence of changing workloads. 6.2 Application Benchmarks We ran the BBOARD benchmark described in Section 4.1.1 on two versions of Ganesh: the first with Rabin fingerprinting used as WWW 2007 / Track: Performance and Scalability Session: Scalable Systems for Dynamic Content 317 0 50 100 150 200 250 300 350 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Test Clients Requests/sec Native Ganesh 0.001 0.01 0.1 1 10 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Test Clients Avg.Resp.Time(sec) Native Ganesh Note Logscale (a) Throughput: Bidding Mix (b) Response Time: Bidding Mix 0 50 100 150 200 250 300 350 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Test Clients Requests/sec Native Ganesh 0.001 0.01 0.1 1 10 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Test Clients Avg.Resp.Time(sec) Native Ganesh Note Logscale (c) Throughput: Browsing Mix (d) Response Time: Browsing Mix Mean of three trials.",
                "The maximum standard deviation for throughput and response time was 2.2% and 11.8% of the corresponding mean.",
                "Figure 8: AUCTION Benchmark - Throughput and Average Response Time the chunking algorithm and the second with Ganeshs row-based algorithm.",
                "Rabins results for the Browsing Mix are normalized to Ganeshs results and presented in Figure 9.",
                "As Figure 9 (a) shows, at 5 Mb/s, independent of the test client configuration, Rabin significantly underperforms Ganesh.",
                "This happens because of a combination of two reasons.",
                "First, as outlined in Section 3.1, Rabin finds less similarity as it does not exploit the results structural information.",
                "Second, this benchmark contained some queries that generated large results.",
                "In this case, Rabin, with a small average chunk size, generated a large number of objects that evicted other useful data from the cache.",
                "In contrast, Ganesh was able to detect these large rows and correspondingly increase the size of the chunks.",
                "This was confirmed as cache statistics showed that Ganeshs hit ratio was roughly three time that of Rabin.",
                "Throughput measurements at 20 Mb/s were similar with the exception of Rabins performance with 400 test clients.",
                "In this case, Ganesh was not network limited and, in fact, the throughput was the same as 400 clients at 5 Mb/s.",
                "Rabin, however, took advantage of the bandwidth increase from 5 to 20 Mb/s to deliver a slightly better performance.",
                "At 100 Mb/s, Rabins throughput was almost similar to Ganesh as bandwidth was no longer a bottleneck.",
                "The normalized response time, presented in Figure 9 (b), shows similar trends.",
                "At 5 and 20 Mb/s, the addition of test clients decreases the normalized response time as Ganeshs average response time increases faster than Rabins.",
                "However, at no point does Rabin outperform Ganesh.",
                "Note that at 400 and 800 clients at 100 Mb/s, Rabin does have a higher overhead even when it is not bandwidth constrained.",
                "As mentioned in Section 3.1, this is due to the fact that Rabin has to hash each ResultSet twice.",
                "The overhead disappears with 1200 and 1600 clients as the database CPU is saturated and limits the performance of both Ganesh and Rabin. 7.",
                "PROXY OVERHEAD In this section, we address the third question raised in Section 4: Is the overhead of Ganeshs proxy-based design acceptable?",
                "To answer this question, we concentrate on its performance at the higher bandwidths.",
                "Our evaluation in Section 5 showed that Ganesh, when compared to Native, can deliver a substantial throughput improvement at lower bandwidths.",
                "It is only at higher bandwidths that latency, measured by the average response time for a client request, and throughput, measured by the number of client requests that can be serviced per second, overheads would be visible.",
                "Looking at the Authoring mix of the original BBOARD benchmark, there are no visible gains from Ganesh at 100 Mb/s.",
                "Ganesh, however, still tracks Native in terms of throughput.",
                "While the average response time is higher for Ganesh, the absolute difference is in between 0.01 and 0.04 seconds and would be imperceptible to the end-user.",
                "The Browsing mix shows an even smaller difference in average response times.",
                "The results from the filter variant of the BBOARD benchmarks are similar.",
                "Even for the AUCTION benchmark, the difference between Native and Ganeshs response time at 100 Mb/s was never greater than 0.02 seconds.",
                "The only exception to the above results was seen in the filter variant of the BBOARD benchmark where Ganesh at 1600 test clients added 0.85 seconds to the average response time.",
                "Thus, even for much faster networks where the WAN link is not the bottleneck, Ganesh always delivers throughput equivalent to Native.",
                "While some extra latency is added by the proxy-based design, it is usually imperceptible. 8.",
                "RELATED WORK To the best of our knowledge, Ganesh is the first system that combines the use of hash-based techniques with caching of database results to improve throughput and response times for applications with dynamic content.",
                "We also believe that it is also the first system to demonstrate the benefits of using structural information for WWW 2007 / Track: Performance and Scalability Session: Scalable Systems for Dynamic Content 318 0.0 0.2 0.4 0.6 0.8 1.0 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Test Clients Norm.Throughput 31.8 3.8 2.8 2.3 23.8 32.8 5.8 3.6 1.8 2.1 1.1 1.0 0 5 10 15 20 25 30 35 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Test Clients Norm.ResponseTime (a) Normalized Throughput: Higher is better (b) Normalized Response Time: Higher is worse For throughput, a normalized result greater than 1 implies that Rabin is better, For response time, a normalized result greater than 1 implies that Ganesh is better.",
                "Mean of three trials.",
                "The maximum standard deviation for throughput and response time was 9.1% and 13.9% of the corresponding mean.",
                "Figure 9: Normalized Comparison of Ganesh vs. Rabin - BBOARD Browsing Mix detecting similarity.",
                "In this section, we first discuss alternative approaches to caching dynamic content and then examine other uses of hash-based primitives in distributed systems. 8.1 Caching Dynamic Content At the database layer, a number of systems have advocated middletier caching where parts of the database are replicated at the edge or server [3, 4, 20].",
                "These systems either cache entire tables in what is essentially a replicated database or use materialized views from previous query replies [19].",
                "They require tight integration with the back-end database to ensure a time bound on the propagation of updates.",
                "These systems are also usually targeted towards workloads that do not require strict consistency and can tolerate stale data.",
                "Further, unlike Ganesh, some of these mid-tier caching solutions [2, 3], suffer from the complexity of having to participate in query planing and distributed query processing.",
                "Gao et al. [15] propose using a distributed object replication architecture where the data stores consistency requirements are adapted on a per-application basis.",
                "These solutions require substantial developer resources and detailed understanding of the application being modified.",
                "While systems that attempt to automate the partitioning and replication of an applications database exist [34], they do not provide full transaction semantics.",
                "In comparison, Ganesh does not weaken any of the semantics provided by the underlying database.",
                "Recent work in the evaluation of edge caching options for dynamic web sites [38] has suggested that, without careful planning, employing complex offloading strategies can hurt performance.",
                "Instead, the work advocates for an architecture in which all tiers except the database should be offloaded to the edge.",
                "Our evaluation of Ganesh has shown that it would benefit these scenarios.",
                "To improve database scalability, C-JDBC [10], SSS [22], and Ganymed [28] also advocate the use of an interposition-based architecture to transparently cluster and replicate databases at the middleware level.",
                "The approaches of these architectures and Ganesh are complementary and they would benefit each other.",
                "Moving up to the presentation layer, there has been widespread adoption of fragment-based caching [14], which improves cache utilization by separately caching different parts of generated web pages.",
                "While fragment-based caching works at the edge, a recent proposal has proposed moving web page assembly to the clients to optimize content delivery [31].",
                "While Ganesh is not used at the presentation layer, the same principles have been applied in Duplicate Transfer Detection [25] to increase web cache efficiency as well as for web access across bandwidth limited links [33]. 8.2 Hash-based Systems The past few years have seen the emergence of many systems that exploit hash-based techniques.",
                "At the heart of all these systems is the idea of detecting similarity in data without requiring interpretation of that data.",
                "This simple yet elegant idea relies on cryptographic hashing, as discussed earlier in Section 2.",
                "Successful applications of this idea span a wide range of storage systems.",
                "Examples include peer-to-peer backup of personal computing files [11], storage-efficient archiving of data [29], and finding similar files [21].",
                "Spring and Wetherall [35] apply similar principles at the network level.",
                "Using synchronized caches at both ends of a network link, duplicated data is replaced by smaller tokens for transmission and then restored at the remote end.",
                "This and other hash-based systems such as the CASPER [37] and LBFS [26] filesystems, and Layer-2 bandwidth optimizers such as Riverbed and Peribit use Rabin fingerprinting [30] to discover spans of commonality in data.",
                "This approach is especially useful when data items are modified in-place through insertions, deletions, and updates.",
                "However, as Section 6 shows, the performance of this technique can show a dramatic drop in the presence of data reordering.",
                "Ganesh instead uses row boundaries as dividers for detecting similarity.",
                "The most aggressive use of hash-based techniques is by systems that use hashes as the primary identifiers for objects in persistent storage.",
                "Storage systems such as CFS [12] and PAST [13] that have been built using distributed hash tables fall into this category.",
                "Single Instance Storage [6] and Venti [29] are other examples of such systems.",
                "As discussed in Section 2.2, the use of cryptographic hashes for addressing persistent data represents a deeper level of faith in their collision-resistance than that assumed by Ganesh.",
                "If time reveals shortcomings in the hash algorithm, the effort involved in correcting the flaw is much greater.",
                "In Ganesh, it is merely a matter of replacing the hash algorithm. 9.",
                "CONCLUSION The growing use of dynamic web content generated from relational databases places increased demands on WAN bandwidth.",
                "Traditional caching solutions for bandwidth and latency reduction are often ineffective for such content.",
                "This paper shows that the impact of WAN accesses to databases can be substantially reduced through the Ganesh architecture without any compromise of the databases strict consistency semantics.",
                "The essence of the Ganesh architecture is the use of computation at the edges to reduce communication through the Internet.",
                "Ganesh is able to use cryptographic hashes to detect similarity with previous results and send WWW 2007 / Track: Performance and Scalability Session: Scalable Systems for Dynamic Content 319 compact recipes of results rather than full results.",
                "Our design uses interposition to achieve complete transparency: clients, application servers, and database servers are all unaware of Ganeshs presence and require no modification.",
                "Our experimental evaluation confirms that Ganesh, while conceptually simple, can be highly effective in improving throughput and response time.",
                "Our results also confirm that exploiting the structure present in database results to detect similarity is crucial to this performance improvement. 10.",
                "REFERENCES [1] AKELLA, A., SESHAN, S., AND SHAIKH, A.",
                "An empirical evaluation of wide-area internet bottlenecks.",
                "In Proc. 3rd ACM SIGCOMM Conference on Internet Measurement (Miami Beach, FL, USA, Oct. 2003), pp. 101-114. [2] ALTINEL, M., BORNH ¨OVD, C., KRISHNAMURTHY, S., MOHAN, C., PIRAHESH, H., AND REINWALD, B. Cache tables: Paving the way for an adaptive database cache.",
                "In Proc. of 29th VLDB (Berlin, Germany, 2003), pp. 718-729. [3] ALTINEL, M., LUO, Q., KRISHNAMURTHY, S., MOHAN, C., PIRAHESH, H., LINDSAY, B. G., WOO, H., AND BROWN, L. Dbcache: Database caching for web application servers.",
                "In Proc. 2002 ACM SIGMOD (2002), pp. 612-612. [4] AMIRI, K., PARK, S., TEWARI, R., AND PADMANABHAN, S. Dbproxy: A dynamic data cache for web applications.",
                "In Proc.",
                "IEEE International Conference on Data Engineering (ICDE) (Mar. 2003). [5] BLACK, J. Compare-by-hash: A reasoned analysis.",
                "In Proc. 2006 USENIX Annual Technical Conference (Boston, MA, May 2006), pp. 85-90. [6] BOLOSKY, W. J., CORBIN, S., GOEBEL, D., , AND DOUCEUR, J. R. Single instance storage in windows 2000.",
                "In Proc. 4th USENIX Windows Systems Symposium (Seattle, WA, Aug. 2000), pp. 13-24. [7] BREWER, E. A.",
                "Lessons from giant-scale services.",
                "IEEE Internet Computing 5, 4 (2001), 46-55. [8] BRODER, A., GLASSMAN, S., MANASSE, M., AND ZWEIG, G. Syntactic clustering of the web.",
                "In Proc. 6th International WWW Conference (1997). [9] CECCHET, E., CHANDA, A., ELNIKETY, S., MARGUERITE, J., AND ZWAENEPOEL, W. Performance comparison of middleware architectures for generating dynamic web content.",
                "In Proc.",
                "Fourth ACM/IFIP/USENIX International Middleware Conference (Rio de Janeiro, Brazil, June 2003). [10] CECCHET, E., MARGUERITE, J., AND ZWAENEPOEL, W. C-JDBC: Flexible database clustering middleware.",
                "In Proc. 2004 USENIX Annual Technical Conference (Boston, MA, June 2004). [11] COX, L. P., MURRAY, C. D., AND NOBLE, B. D. Pastiche: Making backup cheap and easy.",
                "In OSDI: Symposium on Operating Systems Design and Implementation (2002). [12] DABEK, F., KAASHOEK, M. F., KARGER, D., MORRIS, R., AND STOICA, I. Wide-area cooperative storage with CFS.",
                "In 18th ACM Symposium on Operating Systems Principles (Banff, Canada, Oct. 2001). [13] DRUSCHEL, P., AND ROWSTRON, A.",
                "PAST: A large-scale, persistent peer-to-peer storage utility.",
                "In HotOS VIII (Schloss Elmau, Germany, May 2001), pp. 75-80. [14] Edge side includes. http://www.esi.org. [15] GAO, L., DAHLIN, M., NAYATE, A., ZHENG, J., AND IYENGAR, A.",
                "Application specific data replication for edge services.",
                "In WWW 03: Proc.",
                "Twelfth International Conference on World Wide Web (2003), pp. 449-460. [16] HEMMINGER, S. Netem - emulating real networks in the lab.",
                "In Proc. 2005 Linux Conference Australia (Canberra, Australia, Apr. 2005). [17] HENSON, V. An analysis of compare-by-hash.",
                "In Proc. 9th Workshop on Hot Topics in Operating Systems (HotOS IX) (May 2003), pp. 13-18. [18] Jmob benchmarks. http://jmob.objectweb.org/. [19] LABRINIDIS, A., AND ROUSSOPOULOS, N. Balancing performance and data freshness in web database servers.",
                "In Proc. 29th VLDB Conference (Sept. 2003). [20] LARSON, P.-A., GOLDSTEIN, J., AND ZHOU, J. Transparent mid-tier database caching in sql server.",
                "In Proc. 2003 ACM SIGMOD (2003), pp. 661-661. [21] MANBER, U.",
                "Finding similar files in a large file system.",
                "In Proc.",
                "USENIX Winter 1994 Technical Conference (San Fransisco, CA, 17-21 1994), pp. 1-10. [22] MANJHI, A., AILAMAKI, A., MAGGS, B. M., MOWRY, T. C., OLSTON, C., AND TOMASIC, A.",
                "Simultaneous scalability and security for data-intensive web applications.",
                "In Proc. 2006 ACM SIGMOD (June 2006), pp. 241-252. [23] MENEZES, A. J., VANSTONE, S. A., AND OORSCHOT, P. C. V. Handbook of Applied Cryptography.",
                "CRC Press, 1996. [24] MILLER, R. B.",
                "Response time in man-computer conversational transactions.",
                "In Proc.",
                "AFIPS Fall Joint Computer Conference (1968), pp. 267-277. [25] MOGUL, J. C., CHAN, Y. M., AND KELLY, T. Design, implementation, and evaluation of duplicate transfer detection in http.",
                "In Proc.",
                "First Symposium on Networked Systems Design and Implementation (San Francisco, CA, Mar. 2004). [26] MUTHITACHAROEN, A., CHEN, B., AND MAZIERES, D. A low-bandwidth network file system.",
                "In Proc. 18th ACM Symposium on Operating Systems Principles (Banff, Canada, Oct. 2001). [27] PFEIFER, D., AND JAKSCHITSCH, H. Method-based caching in multi-tiered server applications.",
                "In Proc.",
                "Fifth International Symposium on Distributed Objects and Applications (Catania, Sicily, Italy, Nov. 2003). [28] PLATTNER, C., AND ALONSO, G. Ganymed: Scalable replication for transactional web applications.",
                "In Proc. 5th ACM/IFIP/USENIX International Conference on Middleware (2004), pp. 155-174. [29] QUINLAN, S., AND DORWARD, S. Venti: A new approach to archival storage.",
                "In Proc.",
                "FAST 2002 Conference on File and Storage Technologies (2002). [30] RABIN, M. Fingerprinting by random polynomials.",
                "In Harvard University Center for Research in Computing Technology Technical Report TR-15-81 (1981). [31] RABINOVICH, M., XIAO, Z., DOUGLIS, F., AND KALMANEK, C. Moving edge side includes to the real edge - the clients.",
                "In Proc. 4th USENIX Symposium on Internet Technologies and Systems (Seattle, WA, Mar. 2003). [32] REESE, G. Database Programming with JDBC and Java, 1st ed.",
                "OReilly, June 1997. [33] RHEA, S., LIANG, K., AND BREWER, E. Value-based web caching.",
                "In Proc.",
                "Twelfth International World Wide Web Conference (May 2003). [34] SIVASUBRAMANIAN, S., ALONSO, G., PIERRE, G., AND VAN STEEN, M. Globedb: Autonomic data replication for web applications.",
                "In WWW 05: Proc. 14th International World-Wide Web conference (May 2005). [35] SPRING, N. T., AND WETHERALL, D. A protocol-independent technique for eliminating redundant network traffic.",
                "In Proc. of ACM SIGCOMM (Aug. 2000). [36] TOLIA, N., HARKES, J., KOZUCH, M., AND SATYANARAYANAN, M. Integrating portable and distributed storage.",
                "In Proc. 3rd USENIX Conference on File and Storage Technologies (San Francisco, CA, Mar. 2004). [37] TOLIA, N., KOZUCH, M., SATYANARAYANAN, M., KARP, B., PERRIG, A., AND BRESSOUD, T. Opportunistic use of content addressable storage for distributed file systems.",
                "In Proc. 2003 USENIX Annual Technical Conference (San Antonio, TX, June 2003), pp. 127-140. [38] YUAN, C., CHEN, Y., AND ZHANG, Z.",
                "Evaluation of edge caching/offloading for dynamic content delivery.",
                "In WWW 03: Proc.",
                "Twelfth International Conference on World Wide Web (2003), pp. 461-471.",
                "WWW 2007 / Track: Performance and Scalability Session: Scalable Systems for Dynamic Content 320"
            ],
            "original_annotated_samples": [
                "All ResultSet objects are converted into objects of a new type called <br>reciperesultset</br>.",
                "The proxy constructs a <br>reciperesultset</br> by checking for similarity at the entire result and then the row level.",
                "If the entire result is predicted to be present in the Ganesh drivers cache, the <br>reciperesultset</br> is simply a single hash of the entire result.",
                "If the proxy estimates an overall space savings, it will transmit the <br>reciperesultset</br>.",
                "The <br>reciperesultset</br> objects are transformed back into ResultSet objects by the Ganesh driver."
            ],
            "translated_annotated_samples": [
                "Todos los objetos ResultSet se convierten en objetos de un nuevo tipo llamado RecipeResultSet.",
                "El proxy construye un <br>RecipeResultSet</br> verificando la similitud en todo el resultado y luego a nivel de fila.",
                "Si se predice que todo el resultado estará presente en la caché de los controladores de Ganesh, el <br>RecipeResultSet</br> será simplemente un único hash de todo el resultado.",
                "Si el proxy estima un ahorro de espacio general, transmitirá el <br>RecipeResultSet</br>.",
                "Los <br>objetos RecipeResultSet</br> son transformados de vuelta en objetos ResultSet por el controlador Ganesh."
            ],
            "translated_text": "Conservación de la consistencia en el almacenamiento en caché de contenido dinámico de bases de datos∗ Niraj Tolia y M. Satyanarayanan Universidad Carnegie Mellon {ntolia,satya}@cs.cmu.edu RESUMEN Con el creciente uso de contenido web dinámico generado a partir de bases de datos relacionales, las soluciones de almacenamiento en caché tradicionales para mejorar el rendimiento y la latencia son ineficaces. Describimos una capa de middleware llamada Ganesh que reduce el volumen de datos transmitidos sin interpretación semántica de consultas o resultados. Se logra esta reducción mediante el uso de hash criptográficos para detectar similitudes con resultados anteriores. Estos beneficios no requieren ningún compromiso con la semántica de consistencia estricta proporcionada por la base de datos del servidor. Además, Ganesh no requiere modificaciones en aplicaciones, servidores web o servidores de bases de datos, y funciona con aplicaciones y bases de datos de código cerrado. Usando dos puntos de referencia representativos de sitios web dinámicos, las mediciones de nuestro prototipo muestran que puede aumentar el rendimiento de extremo a extremo hasta en un factor de dos para aplicaciones no intensivas en datos y hasta en un factor de diez para las intensivas en datos. Categorías y Descriptores de Asignaturas C.2.4 [Redes de Computadoras-Comunicación]: Sistemas Distribuidos; H.2.4 [Gestión de Bases de Datos]: Términos Generales de Sistemas de Diseño, Rendimiento 1. INTRODUCCIÓN Una fracción creciente del contenido web se genera dinámicamente a partir de bases de datos relacionales en el backend. Incluso cuando el contenido de la base de datos permanece sin cambios, la localidad temporal de acceso no puede ser explotada porque el contenido dinámico no es almacenable en caché por los navegadores web o por servidores de almacenamiento en caché intermedios como los espejos de Akamai. En una arquitectura multinivel, cada solicitud web puede tensionar el enlace WAN entre el servidor web y la base de datos. Esto provoca que la experiencia del usuario sea altamente variable porque no hay almacenamiento en caché para aislar al cliente de cargas repentinas. Los intentos previos de almacenar en caché contenido dinámico de bases de datos generalmente han debilitado la semántica transaccional [3, 4] o han requerido modificaciones en la aplicación [15, 34]. Informamos sobre una nueva solución que toma la forma de una capa intermedia de middleware independiente de la base de datos llamada Ganesh. Ganesh no hace ningún esfuerzo por interpretar semánticamente el contenido de las consultas o sus resultados. En cambio, se basa exclusivamente en el hash criptográfico para detectar similitudes con resultados anteriores. La detección de similitud basada en hash ha sido cada vez más utilizada en sistemas de archivos distribuidos [26, 36, 37] para mejorar el rendimiento en redes de baja capacidad de ancho de banda. Sin embargo, estas técnicas no se han utilizado para bases de datos relacionales. A diferencia de enfoques anteriores que utilizan métodos genéricos para detectar similitud, Ganesh explota la estructura de los resultados de la base de datos relacional para lograr una mejora superior en el rendimiento. Uno se enfrenta al menos a tres desafíos al aplicar la detección de similitud basada en hash a las bases de datos de back-end. Primero, el trabajo previo en este ámbito ha considerado tradicionalmente el contenido de almacenamiento como bolsas de bits no interpretadas y sin estructura interna. Esto permite que las técnicas basadas en hash operen en largas y contiguas secuencias de datos para lograr la máxima efectividad. Por el contrario, las bases de datos relacionales tienen una estructura interna compleja que puede no ser tan propicia para la detección de similitudes basada en hash. Segundo, las bases de datos relacionales tienen restricciones de integridad y consistencia muy estrictas que no deben comprometerse por el uso de técnicas basadas en hash. Tercero, el código fuente de las bases de datos comerciales generalmente no está disponible. Esto contrasta con trabajos anteriores que presumían la disponibilidad del código fuente. Nuestros experimentos muestran que Ganesh, aunque conceptualmente simple, puede mejorar significativamente el rendimiento en anchos de banda representativos del Internet comercial actual. En los modelos de referencia de aplicaciones web multinivel, la mejora en el rendimiento fue de hasta diez veces para cargas de trabajo intensivas en datos. Para cargas de trabajo que no eran intensivas en datos, se observaron mejoras en el rendimiento de hasta el doble. Incluso cuando el ancho de banda no era una limitación, Ganesh tenía un bajo sobrecosto y no afectaba el rendimiento. Nuestros experimentos también confirman que aprovechar la estructura presente en los resultados de la base de datos es crucial para esta mejora en el rendimiento. Antecedentes 2.1 Generación de Contenido Dinámico A medida que la World Wide Web ha crecido, muchos sitios web han descentralizado sus datos y funcionalidades al llevarlos a los extremos de Internet. Hoy en día, los sistemas de comercio electrónico a menudo utilizan una arquitectura de tres niveles que consta de un servidor web de front-end, un servidor de aplicaciones y un servidor de base de datos de back-end. La Figura 1 ilustra esta arquitectura. Los dos primeros niveles se pueden replicar cerca de una concentración de clientes en el borde de Internet. Esto mejora la experiencia del usuario al reducir la latencia de extremo a extremo y disminuir la exposición al congestionamiento del tráfico de la columna vertebral. También puede aumentar la disponibilidad y escalabilidad de los servicios web. El contenido que se genera dinámicamente desde la base de datos del servidor no puede ser almacenado en caché en los dos primeros niveles. Si bien las bases de datos pueden replicarse fácilmente en una LAN, esto es inviable en una WAN debido a la difícil tarea de proporcionar simultáneamente una consistencia sólida, disponibilidad y tolerancia a particiones de red [7]. Como resultado, las bases de datos tienden a ser centralizadas para cumplir con los fuertes requisitos de consistencia de muchas aplicaciones de comercio electrónico como la banca, las finanzas y la venta al por menor en línea [38]. Por lo tanto, la base de datos del back-end suele estar ubicada lejos de muchos conjuntos de nodos de primer y segundo nivel [2]. En ausencia de almacenamiento en caché y replicación, el ancho de banda de la WAN puede convertirse fácilmente en un factor limitante en el rendimiento y la escalabilidad de aplicaciones intensivas en datos. El enfoque de Ganesh en los sistemas basados en hash es la transmisión eficiente de resultados al descubrir similitudes con los resultados de consultas anteriores. Dado que las consultas SQL pueden generar resultados grandes, las técnicas basadas en hash se prestan bien al problema de transferir eficientemente estos grandes resultados a través de enlaces con ancho de banda limitado. El uso de técnicas basadas en hash para reducir el volumen de datos transmitidos ha surgido como un tema común en muchos sistemas de almacenamiento recientes, como se discute en la Sección 8.2. Estas técnicas se basan en algunas suposiciones básicas. Se asume que las funciones hash criptográficas son resistentes a colisiones. En otras palabras, es computacionalmente intratable encontrar dos entradas que se hash a la misma salida. Las funciones también se asumen como unidireccionales; es decir, encontrar una entrada que resulte en una salida específica es computacionalmente inviable. Menezes et al. [23] proporcionan más detalles sobre estas suposiciones. Las suposiciones anteriores permiten a los sistemas basados en hash asumir que no se producen colisiones. Por lo tanto, pueden tratar el hash de un elemento de datos como su identificador único. Una colección de elementos de datos se convierte efectivamente en direccionable por contenido, permitiendo que un hash pequeño funcione como una palabra de código para un elemento de datos mucho más grande en almacenamiento permanente o transmisión en red. La suposición de que las colisiones son tan raras que prácticamente no existen ha sido cuestionada recientemente [17]. Sin embargo, como explicó Black [5], creemos que estos problemas no son una preocupación para Ganesh. Toda comunicación es entre partes confiables del sistema y un adversario no tiene forma de obligar a Ganesh a aceptar datos inválidos. Además, Ganesh no depende críticamente de ninguna función hash específica. Si bien actualmente usamos SHA-1, reemplazarlo con una función hash diferente sería sencillo. No habría impacto en el rendimiento con funciones hash más fuertes (por ejemplo, SHA256) solo añade unos pocos bytes adicionales y los hashes generados siguen siendo órdenes de magnitud más pequeños que los elementos de datos que representan. No es necesario volver a almacenar permanentemente ya que Ganesh solo utiliza el hash en datos volátiles. 3. DISEÑO E IMPLEMENTACIÓN Ganesh explota la redundancia en el flujo de resultados para evitar transmitir fragmentos de resultados que ya están presentes en el sitio de la consulta. La redundancia puede surgir de forma natural de muchas maneras diferentes. Por ejemplo, una consulta repetida después de un cierto intervalo puede devolver un resultado diferente debido a actualizaciones en la base de datos; sin embargo, puede haber una significativa similitud entre los dos resultados. Como otro ejemplo, un usuario que está refinando una búsqueda puede generar una secuencia de consultas con resultados superpuestos. Cuando Ganesh detecta redundancia, suprime la transmisión de los fragmentos de resultado correspondientes. En cambio, transmite un resumen mucho más pequeño de esos fragmentos y permite que el sitio de consulta reconstruya el resultado a través de la búsqueda de hash en una caché de resultados anteriores. De hecho, Ganesh utiliza la computación en los bordes para reducir la comunicación por Internet. Nuestra descripción de Ganesh se centra en cuatro aspectos. Primero explicamos nuestro enfoque para detectar similitud en los resultados de la consulta. A continuación, discutimos cómo la arquitectura Ganesh es completamente invisible para todos los componentes de un sistema de múltiples niveles. Luego describimos el enfoque basado en proxy de Ganesh y el flujo de datos para detectar similitudes. 3.1 Detectar similitud Una de las decisiones clave de diseño en Ganesh es cómo se detecta la similitud. Hay muchas formas potenciales de descomponer un resultado en fragmentos.  I the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the thees I,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,, Encontrar esta descomposición óptima es un problema difícil debido al amplio espacio de posibilidades y porque la elección óptima depende de muchos factores, como el contenido del resultado de las consultas, el historial de resultados recientes y el algoritmo de gestión de caché. Cuando un objeto es opaco, el uso de huellas digitales de Rabin [8, 30] para detectar datos comunes entre dos objetos ha sido demostrado con éxito en el pasado por sistemas como LBFS [26] y CASPER [37]. El fingerprinting de Rabin utiliza una ventana deslizante sobre los datos para calcular un hash rodante. Suponiendo que la función hash está distribuida uniformemente, un límite de fragmento se define cuando los bits de orden inferior del valor hash son iguales a algún valor predeterminado. El número de bits de orden inferior utilizados define el tamaño promedio del fragmento. Estos fragmentos subdivididos del objeto se convierten en la unidad de comparación para detectar similitudes entre diferentes objetos. Dado que las ubicaciones de los límites encontrados mediante el uso de las huellas de Rabin están determinadas de manera estocástica, generalmente no logran alinearse con ninguna propiedad estructural de los datos subyacentes. Por lo tanto, el algoritmo maneja bien las actualizaciones en su lugar, inserciones y eliminaciones. Sin embargo, tiene un rendimiento deficiente en presencia de cualquier reordenamiento de datos. La Figura 2 muestra un ejemplo donde dos resultados, A y B, que constan de tres filas, tienen los mismos datos pero diferentes atributos de ordenamiento. En el caso extremo, la huella digital de Rabin podría no ser capaz de encontrar datos similares debido a la forma en que detecta los límites de los fragmentos. Afortunadamente, Ganesh puede utilizar conocimientos específicos del dominio para una detección de límites más precisa. La información que explotamos es que el resultado de una consulta refleja la estructura de una base de datos relacional donde todos los datos están organizados en tablas y filas. Por lo tanto, es sencillo verificar la similitud con resultados anteriores en dos niveles de granularidad: primero el resultado completo y luego las filas individuales. El final de una fila en un resultado sirve como un límite natural de fragmento. Es importante tener en cuenta que el uso de la estructura tabular en los resultados solo implica una interpretación superficial de los datos. Ganesh no realiza ninguna interpretación semántica más profunda, como comprender tipos de datos, esquemas de resultados o restricciones de integridad. Ajustar la huella digital de Rabin para una carga de trabajo también puede ser difícil. Si el tamaño promedio de los fragmentos es demasiado grande, los fragmentos pueden abarcar varias filas de resultados. Sin embargo, seleccionar un tamaño de fragmento promedio más pequeño aumenta la cantidad de metadatos necesarios para describir los resultados. Esto, a su vez, disminuiría los ahorros obtenidos mediante su uso. El fingerprinting de Rabin también requiere dos pasadas computacionalmente costosas sobre los datos: una vez para determinar los límites de los fragmentos y otra vez para generar hashes criptográficos para los fragmentos. Ganesh solo necesita un único pase para la generación de hash, ya que los límites de los fragmentos son proporcionados por la estructura natural de los datos. La comparación de rendimiento en la Sección 6 muestra que el algoritmo basado en filas de Ganesh supera al fingerprinting de Rabin. Dado que trabajos anteriores ya han demostrado que la huella digital de Rabin funciona mejor que gzip [26], no comparamos a Ganesh con algoritmos de compresión en este artículo. 3.2 Transparencia El factor clave que influyó en nuestro diseño fue la necesidad de que Ganesh fuera completamente transparente para todos los componentes de un sistema típico de comercio electrónico: servidores web, servidores de aplicaciones y servidores de bases de datos. Sin esto, Ganesh tiene pocas posibilidades de tener un impacto significativo en el mundo real. Requerir modificaciones en cualquiera de los componentes mencionados aumentaría la barrera de entrada de Ganesh en un sistema existente, y por lo tanto reduciría sus posibilidades de adopción. Preservar la transparencia se simplifica por el hecho de que Ganesh es simplemente una mejora de rendimiento, no una mejora de funcionalidad o usabilidad. Elegimos la interposición de agentes como enfoque arquitectónico para lograr nuestro objetivo. Este enfoque se basa en la existencia de una interfaz de programación compacta que ya es ampliamente utilizada por el software objetivo. También se basa en un mecanismo para agregar fácilmente nuevo código sin interrumpir la estructura de módulos existente. Estas condiciones se cumplen fácilmente en nuestro contexto debido a la popularidad de Java como el lenguaje de programación para sistemas de comercio electrónico. La API de Conectividad de Base de Datos de Java (JDBC) [32] permite a las aplicaciones de Java acceder a una amplia variedad de bases de datos e incluso a otros repositorios de datos tabulares como archivos planos. El acceso a estas fuentes de datos es proporcionado por controladores JDBC que traducen entre la API JDBC y el mecanismo de comunicación de la base de datos. La figura 3(a) muestra cómo se utiliza típicamente JDBC en una aplicación. Dado que la interfaz JDBC está estandarizada, se puede sustituir un controlador JDBC por otro sin necesidad de de modificar la aplicación. El controlador JDBC se convierte así en el módulo natural para aprovechar la interposición de código. Como se muestra en la Figura 3(b), el controlador JDBC nativo es reemplazado por un controlador JDBC Ganesh que presenta la misma interfaz estandarizada. El controlador Ganesh mantiene una caché en memoria de fragmentos de resultados de consultas anteriores y realiza el reensamblaje de resultados. En la base de datos, agregamos un nuevo proceso llamado el proxy Ganesh. Este proxy, que puede ser compartido por múltiples nodos front-end, consta de dos partes: código para detectar similitud en fragmentos de resultados y el controlador JDBC nativo original que se comunica con la base de datos. El uso de un proxy en la base de datos hace que Ganesh sea independiente de la base de datos y simplifica la creación de prototipos y experimentación. Ganesh es capaz de trabajar con una amplia gama de bases de datos y aplicaciones, sin necesidad de realizar modificaciones en ninguna de ellas. 3.3 Caché basada en proxy El controlador JDBC nativo mostrado en la Figura 3(a) es un componente de código ligero suministrado por el proveedor de la base de datos. Su función principal es mediar la comunicación entre la aplicación y la base de datos remota. Reenvía consultas, almacena resultados completos y responde a solicitudes de la aplicación para ver partes de los resultados. El controlador JDBC de Ganesh mostrado en la Figura 3(b) presenta a la aplicación una interfaz idéntica a la proporcionada por el controlador nativo. Proporciona la capacidad de reconstruir resultados a partir de descripciones compactas basadas en hash enviadas por el proxy. Para realizar esta reconstrucción, el controlador mantiene una caché en memoria de los resultados recibidos recientemente. Esta caché solo se utiliza como fuente de fragmentos de resultados en la reconstrucción de resultados. El conductor Ganesh o el proxy no intentan rastrear las actualizaciones de la base de datos. La falta de consistencia en la caché no afecta a la corrección, ya que la descripción de los resultados siempre se obtiene del proxy; en el peor de los casos, no habrá beneficio de rendimiento al usar Ganesh. Los datos obsoletos simplemente se eliminarán de la caché con el tiempo. El proxy de Ganesh accede a la base de datos a través del controlador JDBC nativo, que permanece sin cambios entre las Figuras 3(a) y (b). La base de datos está completamente ajena a la existencia del proxy. El proxy no examina ninguna consulta recibida del controlador Ganesh, sino que las pasa al controlador nativo. En cambio, el proxy es responsable de inspeccionar la salida de la base de datos recibida del controlador nativo, detectar resultados similares y generar codificaciones basadas en hash de estos resultados siempre que se encuentre suficiente similitud. Si bien esta arquitectura no disminuye la carga en una base de datos, como se mencionó anteriormente en la Sección 2.1, es mucho más fácil replicar bases de datos para escalabilidad en una LAN que en una WAN. Para generar una codificación basada en hash, el proxy debe estar al tanto de qué fragmentos de resultados están disponibles en la caché de controladores de Ganesh. Un enfoque es ser optimista y asumir que todos los fragmentos de resultados están disponibles. Esto resultará en la transmisión inicial más pequeña posible de un resultado. Sin embargo, en casos donde hay poca superposición con resultados anteriores, el controlador Ganesh tendrá que realizar muchas llamadas al proxy durante la reconstrucción para recuperar fragmentos de resultados faltantes. Para evitar esta situación, el proxy sigue de manera flexible el estado de la caché de controladores de Ganesh. Dado que ambos componentes están bajo nuestro control, es relativamente sencillo hacer esto sin recurrir a técnicas de caja gris o comunicación explícita para mantener la coherencia de la caché. En cambio, el proxy simula el algoritmo de gestión de caché de controladores de Ganesh y lo utiliza para mantener una lista de hashes para los cuales es probable que el controlador de Ganesh posea los fragmentos de resultado. En caso de desviación de seguimiento, no habrá pérdida de corrección, pero habrá retrasos adicionales en el viaje de ida y vuelta para recuperar los fragmentos faltantes. Si el cliente detecta la pérdida de sincronización con el proxy, puede pedirle al proxy que restablezca el estado compartido entre ellos. También hay que tener en cuenta que el proxy no necesita guardar los fragmentos de resultado en sí, solo sus hashes. Esto permite que el proxy siga siendo escalable incluso cuando es compartido por muchos nodos front-end. El proxy Ganesh recibe la salida de la base de datos como objetos Java del controlador JDBC nativo. Examina esta salida para ver si está presente un objeto Java del tipo ResultSet. La interfaz JDBC utiliza este tipo de dato para almacenar los resultados de las consultas a la base de datos. Si se encuentra un objeto ResultSet, se reduce como se discute a continuación. Todos los demás objetos de Java se pasan sin modificar. Como se discute en la Sección 3.1, el proxy utiliza los límites de fila definidos en el ResultSet para dividirlo en fragmentos que consisten en filas de resultado individuales. Todos los objetos ResultSet se convierten en objetos de un nuevo tipo llamado RecipeResultSet. Utilizamos el término receta para esta descripción compacta de un resultado de base de datos debido a su similitud con una receta de archivo en el sistema de archivos CASPER [37]. La conversión reemplaza cada fragmento de resultado que probablemente esté presente en la caché de controladores de Ganesh por un hash SHA-1 de ese fragmento. Los fragmentos de resultados previamente no vistos se conservan textualmente. El proxy también retiene los hashes de los nuevos fragmentos de resultados, ya que estarán presentes en la caché de los controladores en el futuro. Ten en cuenta que el proxy solo almacena en caché los hashes de los fragmentos de resultados y no almacena en caché las recetas. El proxy construye un <br>RecipeResultSet</br> verificando la similitud en todo el resultado y luego a nivel de fila. Si se predice que todo el resultado estará presente en la caché de los controladores de Ganesh, el <br>RecipeResultSet</br> será simplemente un único hash de todo el resultado. De lo contrario, contiene hashes para aquellas filas que se predice que están presentes en esa caché; todas las demás filas se conservan textualmente. Si el proxy estima un ahorro de espacio general, transmitirá el <br>RecipeResultSet</br>. De lo contrario, se transmite el ResultSet original. Los <br>objetos RecipeResultSet</br> son transformados de vuelta en objetos ResultSet por el controlador Ganesh. ",
            "candidates": [],
            "error": [
                [
                    "RecipeResultSet",
                    "RecipeResultSet",
                    "RecipeResultSet",
                    "objetos RecipeResultSet"
                ]
            ]
        },
        "content addressable storage": {
            "translated_key": "almacenamiento direccionable por contenido",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Consistency-preserving Caching of Dynamic Database Content∗ Niraj Tolia and M. Satyanarayanan Carnegie Mellon University {ntolia,satya}@cs.cmu.edu ABSTRACT With the growing use of dynamic web content generated from relational databases, traditional caching solutions for throughput and latency improvements are ineffective.",
                "We describe a middleware layer called Ganesh that reduces the volume of data transmitted without semantic interpretation of queries or results.",
                "It achieves this reduction through the use of cryptographic hashing to detect similarities with previous results.",
                "These benefits do not require any compromise of the strict consistency semantics provided by the back-end database.",
                "Further, Ganesh does not require modifications to applications, web servers, or database servers, and works with closed-source applications and databases.",
                "Using two benchmarks representative of dynamic web sites, measurements of our prototype show that it can increase end-to-end throughput by as much as twofold for non-data intensive applications and by as much as tenfold for data intensive ones.",
                "Categories and Subject Descriptors C.2.4 [Computer-Communication Networks]: Distributed Systems; H.2.4 [Database Management]: Systems General Terms Design, Performance 1.",
                "INTRODUCTION An increasing fraction of web content is dynamically generated from back-end relational databases.",
                "Even when database content remains unchanged, temporal locality of access cannot be exploited because dynamic content is not cacheable by web browsers or by intermediate caching servers such as Akamai mirrors.",
                "In a multitiered architecture, each web request can stress the WAN link between the web server and the database.",
                "This causes user experience to be highly variable because there is no caching to insulate the client from bursty loads.",
                "Previous attempts in caching dynamic database content have generally weakened transactional semantics [3, 4] or required application modifications [15, 34].",
                "We report on a new solution that takes the form of a databaseagnostic middleware layer called Ganesh.",
                "Ganesh makes no effort to semantically interpret the contents of queries or their results.",
                "Instead, it relies exclusively on cryptographic hashing to detect similarities with previous results.",
                "Hash-based similarity detection has seen increasing use in distributed file systems [26, 36, 37] for improving performance on low-bandwidth networks.",
                "However, these techniques have not been used for relational databases.",
                "Unlike previous approaches that use generic methods to detect similarity, Ganesh exploits the structure of relational database results to yield superior performance improvement.",
                "One faces at least three challenges in applying hash-based similarity detection to back-end databases.",
                "First, previous work in this space has traditionally viewed storage content as uninterpreted bags of bits with no internal structure.",
                "This allows hash-based techniques to operate on long, contiguous runs of data for maximum effectiveness.",
                "In contrast, relational databases have rich internal structure that may not be as amenable to hash-based similarity detection.",
                "Second, relational databases have very tight integrity and consistency constraints that must not be compromised by the use of hash-based techniques.",
                "Third, the source code of commercial databases is typically not available.",
                "This is in contrast to previous work which presumed availability of source code.",
                "Our experiments show that Ganesh, while conceptually simple, can improve performance significantly at bandwidths representative of todays commercial Internet.",
                "On benchmarks modeling multitiered web applications, the throughput improvement was as high as tenfold for data-intensive workloads.",
                "For workloads that were not data-intensive, throughput improvements of up to twofold were observed.",
                "Even when bandwidth was not a constraint, Ganesh had low overhead and did not hurt performance.",
                "Our experiments also confirm that exploiting the structure present in database results is crucial to this performance improvement. 2.",
                "BACKGROUND 2.1 Dynamic Content Generation As the World Wide Web has grown, many web sites have decentralized their data and functionality by pushing them to the edges of the Internet.",
                "Today, eBusiness systems often use a three-tiered architecture consisting of a front-end web server, an application server, and a back-end database server.",
                "Figure 1 illustrates this architecture.",
                "The first two tiers can be replicated close to a concentration of clients at the edge of the Internet.",
                "This improves user experience by lowering end-to-end latency and reducing exposure WWW 2007 / Track: Performance and Scalability Session: Scalable Systems for Dynamic Content 311 Back-End Database Server Front-End Web and Application Servers Figure 1: Multi-Tier Architecture to backbone traffic congestion.",
                "It can also increase the availability and scalability of web services.",
                "Content that is generated dynamically from the back-end database cannot be cached in the first two tiers.",
                "While databases can be easily replicated in a LAN, this is infeasible in a WAN because of the difficult task of simultaneously providing strong consistency, availability, and tolerance to network partitions [7].",
                "As a result, databases tend to be centralized to meet the strong consistency requirements of many eBusiness applications such as banking, finance, and online retailing [38].",
                "Thus, the back-end database is usually located far from many sets of first and second-tier nodes [2].",
                "In the absence of both caching and replication, WAN bandwidth can easily become a limiting factor in the performance and scalability of data-intensive applications. 2.2 Hash-Based Systems Ganeshs focus is on efficient transmission of results by discovering similarities with the results of previous queries.",
                "As SQL queries can generate large results, hash-based techniques lend themselves well to the problem of efficiently transferring these large results across bandwidth constrained links.",
                "The use of hash-based techniques to reduce the volume of data transmitted has emerged as a common theme of many recent storage systems, as discussed in Section 8.2.",
                "These techniques rely on some basic assumptions.",
                "Cryptographic hash functions are assumed to be collision-resistant.",
                "In other words, it is computationally intractable to find two inputs that hash to the same output.",
                "The functions are also assumed to be one-way; that is, finding an input that results in a specific output is computationally infeasible.",
                "Menezes et al. [23] provide more details about these assumptions.",
                "The above assumptions allow hash-based systems to assume that collisions do not occur.",
                "Hence, they are able to treat the hash of a data item as its unique identifier.",
                "A collection of data items effectively becomes content-addressable, allowing a small hash to serve as a codeword for a much larger data item in permanent storage or network transmission.",
                "The assumption that collisions are so rare as to be effectively non-existent has recently come under fire [17].",
                "However, as explained by Black [5], we believe that these issues do not form a concern for Ganesh.",
                "All communication is between trusted parts of the system and an adversary has no way to force Ganesh to accept invalid data.",
                "Further, Ganesh does not depend critically on any specific hash function.",
                "While we currently use SHA-1, replacing it with a different hash function would be simple.",
                "There would be no impact on performance as stronger hash functions (e.g.",
                "SHA256) only add a few extra bytes and the generated hashes are still orders of magnitude smaller than the data items they represent.",
                "No re-hashing of permanent storage is required since Ganesh only uses hashing on volatile data. 3.",
                "DESIGN AND IMPLEMENTATION Ganesh exploits redundancy in the result stream to avoid transmitting result fragments that are already present at the query site.",
                "Redundancy can arise naturally in many different ways.",
                "For example, a query repeated after a certain interval may return a different result because of updates to the database; however, there may be significant commonality between the two results.",
                "As another example, a user who is refining a search may generate a sequence of queries with overlapping results.",
                "When Ganesh detects redundancy, it suppresses transmission of the corresponding result fragments.",
                "Instead, it transmits a much smaller digest of those fragments and lets the query site reconstruct the result through hash lookup in a cache of previous results.",
                "In effect, Ganesh uses computation at the edges to reduce Internet communication.",
                "Our description of Ganesh focuses on four aspects.",
                "We first explain our approach to detecting similarity in query results.",
                "Next, we discuss how the Ganesh architecture is completely invisible to all components of a multi-tier system.",
                "We then describe Ganeshs proxy-based approach and the dataflow for detecting similarity. 3.1 Detecting Similarity One of the key design decisions in Ganesh is how similarity is detected.",
                "There are many potential ways to decompose a result into fragments.",
                "The optimal way is, of course, the one that results in the smallest possible object for transmission for a given querys results.",
                "Finding this optimal decomposition is a difficult problem because of the large space of possibilities and because the optimal choice depends on many factors such as the contents of the querys result, the history of recent results, and the cache management algorithm.",
                "When an object is opaque, the use of Rabin fingerprints [8, 30] to detect common data between two objects has been successfully shown in the past by systems such as LBFS [26] and CASPER [37].",
                "Rabin fingerprinting uses a sliding window over the data to compute a rolling hash.",
                "Assuming that the hash function is uniformly distributed, a chunk boundary is defined whenever the lower order bits of the hash value equal some predetermined value.",
                "The number of lower order bits used defines the average chunk size.",
                "These sub-divided chunks of the object become the unit of comparison for detecting similarity between different objects.",
                "As the locations of boundaries found by using Rabin fingerprints is stochastically determined, they usually fail to align with any structural properties of the underlying data.",
                "The algorithm therefore deals well with in-place updates, insertions and deletions.",
                "However, it performs poorly in the presence of any reordering of data.",
                "Figure 2 shows an example where two results, A and B, consisting of three rows, have the same data but have different sort attributes.",
                "In the extreme case, Rabin fingerprinting might be unable to find any similar data due to the way it detects chunk boundaries.",
                "Fortunately, Ganesh can use domain specific knowledge for more precise boundary detection.",
                "The information we exploit is that a querys result reflects the structure of a relational database where all data is organized as tables and rows.",
                "It is therefore simple to check for similarity with previous results at two granularities: first the entire result, and then individual rows.",
                "The end of a row in a result serves as a natural chunk boundary.",
                "It is important to note that using the tabular structure in results only involves shallow interpretation of the data.",
                "Ganesh does not perform any deeper semantic interpretation such as understanding data types, result schema, or integrity constraints.",
                "Tuning Rabin fingerprinting for a workload can also be difficult.",
                "If the average chunk size is too large, chunks can span multiple result rows.",
                "However, selecting a smaller average chunk size increases the amount of metadata required to the describe the results.",
                "WWW 2007 / Track: Performance and Scalability Session: Scalable Systems for Dynamic Content 312 Figure 2: Rabin Fingerprinting vs. Ganeshs Chunking This, in turn, would decrease the savings obtained via its use.",
                "Rabin fingerprinting also needs two computationally-expensive passes over the data: once to determine chunk boundaries and one again to generate cryptographic hashes for the chunks.",
                "Ganesh only needs a single pass for hash generation as the chunk boundaries are provided by the datas natural structure.",
                "The performance comparison in Section 6 shows that Ganeshs row-based algorithm outperforms Rabin fingerprinting.",
                "Given that previous work has already shown that Rabin fingerprinting performs better than gzip [26], we do not compare Ganesh to compression algorithms in this paper. 3.2 Transparency The key factor influencing our design was the need for Ganesh to be completely transparent to all components of a typical eBusiness system: web servers, application servers, and database servers.",
                "Without this, Ganesh stands little chance of having a significant real-world impact.",
                "Requiring modifications to any of the above components would raise the barrier for entry of Ganesh into an existing system, and thus reduce its chances of adoption.",
                "Preserving transparency is simplified by the fact that Ganesh is purely a performance enhancement, not a functionality or usability enhancement.",
                "We chose agent interposition as the architectural approach to realizing our goal.",
                "This approach relies on the existence of a compact programming interface that is already widely used by target software.",
                "It also relies on a mechanism to easily add new code without disrupting existing module structure.",
                "These conditions are easily met in our context because of the popularity of Java as the programming language for eBusiness systems.",
                "The Java Database Connectivity (JDBC) API [32] allows Java applications to access a wide variety of databases and even other tabular data repositories such as flat files.",
                "Access to these data sources is provided by JDBC drivers that translate between the JDBC API and the database communication mechanism.",
                "Figure 3(a) shows how JDBC is typically used in an application.",
                "As the JDBC interface is standardized, one can substitute one JDBC driver for another without application modifications.",
                "The JDBC driver thus becomes the natural module to exploit for code interposition.",
                "As shown in Figure 3(b), the native JDBC driver is replaced with a Ganesh JDBC driver that presents the same standardized interface.",
                "The Ganesh driver maintains an in-memory cache of result fragments from previous queries and performs reassembly of results.",
                "At the database, we add a new process called the Ganesh proxy.",
                "This proxy, which can be shared by multiple front-end nodes, consists of two parts: code to detect similarity in result fragments and the original native JDBC driver that communicates with the database.",
                "The use of a proxy at the database makes Ganesh database-agnostic and simplifies prototyping and experimentation.",
                "Ganesh is thus able to work with a wide range of databases and applications, requiring no modifications to either. 3.3 Proxy-Based Caching The native JDBC driver shown in Figure 3(a) is a lightweight code component supplied by the database vendor.",
                "Its main funcClient Database Web and Application Server Native JDBC Driver WAN (a) Native Architecture Client Database Ganesh Proxy Native JDBC Driver WAN Web and Application Server Ganesh JDBC Driver (b) Ganeshs Interposition-based Architecture Figure 3: Native vs. Ganesh Architecture tion is to mediate communication between the application and the remote database.",
                "It forwards queries, buffers entire results, and responds to application requests to view parts of results.",
                "The Ganesh JDBC driver shown in Figure 3(b) presents the application with an interface identical to that provided by the native driver.",
                "It provides the ability to reconstruct results from compact hash-based descriptions sent by the proxy.",
                "To perform this reconstruction, the driver maintains an in-memory cache of recentlyreceived results.",
                "This cache is only used as a source of result fragments in reconstructing results.",
                "No attempt is made by the Ganesh driver or proxy to track database updates.",
                "The lack of cache consistency does not hurt correctness as a description of the results is always fetched from the proxy - at worst, there will be no performance benefit from using Ganesh.",
                "Stale data will simply be paged out of the cache over time.",
                "The Ganesh proxy accesses the database via the native JDBC driver, which remains unchanged between Figures 3(a) and (b).",
                "The database is thus completely unaware of the existence of the proxy.",
                "The proxy does not examine any queries received from the Ganesh driver but passes them to the native driver.",
                "Instead, the proxy is responsible for inspecting database output received from the native driver, detecting similar results, and generating hash-based encodings of these results whenever enough similarity is found.",
                "While this architecture does not decrease the load on a database, as mentioned earlier in Section 2.1, it is much easier to replicate databases for scalability in a LAN than in a WAN.",
                "To generate a hash-based encoding, the proxy must be aware of what result fragments are available in the Ganesh drivers cache.",
                "One approach is to be optimistic, and to assume that all result fragments are available.",
                "This will result in the smallest possible initial transmission of a result.",
                "However, in cases where there is little overlap with previous results, the Ganesh driver will have to make many calls to the proxy during reconstruction to fetch missing result fragments.",
                "To avoid this situation, the proxy loosely tracks the state of the Ganesh drivers cache.",
                "Since both components are under our control, it is relatively simple to do this without resorting to gray-box techniques or explicit communication for maintaining cache coherence.",
                "Instead, the proxy simulates the Ganesh drivers cache management algorithm and uses this to maintain a list of hashes for which the Ganesh driver is likely to possess the result fragments.",
                "In case of mistracking, there will be no loss of correctness but there will be extra round-trip delays to fetch the missing fragments.",
                "If the client detects loss of synchronization with the proxy, it can ask the proxy to reset the state shared between them.",
                "Also note that the proxy does not need to keep the result fragments themselves, only their hashes.",
                "This allows the proxy to remain scalable even when it is shared by many front-end nodes.",
                "WWW 2007 / Track: Performance and Scalability Session: Scalable Systems for Dynamic Content 313 Object Output Stream Convert ResultSet Object Input Stream Convert ResultSet All Data Recipe ResultSet All Data ResultSet Network Ganesh Proxy Ganesh JDBC Driver Result Set Recipe Result Set Yes Yes No No GaneshInputStream GaneshOutputStream Figure 4: Dataflow for Result Handling 3.4 Encoding and Decoding Results The Ganesh proxy receives database output as Java objects from the native JDBC driver.",
                "It examines this output to see if a Java object of type ResultSet is present.",
                "The JDBC interface uses this data type to store results of database queries.",
                "If a ResultSet object is found, it is shrunk as discussed below.",
                "All other Java objects are passed through unmodified.",
                "As discussed in Section 3.1, the proxy uses the row boundaries defined in the ResultSet to partition it into fragments consisting of single result rows.",
                "All ResultSet objects are converted into objects of a new type called RecipeResultSet.",
                "We use the term recipe for this compact description of a database result because of its similarity to a file recipe in the CASPER file system [37].",
                "The conversion replaces each result fragment that is likely to be present in the Ganesh drivers cache by a SHA-1 hash of that fragment.",
                "Previously unseen result fragments are retained verbatim.",
                "The proxy also retains hashes for the new result fragments as they will be present in the drivers cache in the future.",
                "Note that the proxy only caches hashes for result fragments and does not cache recipes.",
                "The proxy constructs a RecipeResultSet by checking for similarity at the entire result and then the row level.",
                "If the entire result is predicted to be present in the Ganesh drivers cache, the RecipeResultSet is simply a single hash of the entire result.",
                "Otherwise, it contains hashes for those rows predicted to be present in that cache; all other rows are retained verbatim.",
                "If the proxy estimates an overall space savings, it will transmit the RecipeResultSet.",
                "Otherwise the original ResultSet is transmitted.",
                "The RecipeResultSet objects are transformed back into ResultSet objects by the Ganesh driver.",
                "Figure 4 illustrates ResultSet handling at both ends.",
                "Each SHA-1 hash found in a RecipeResultSet is looked up in the local cache of result fragments.",
                "On a hit, the hash is replaced by the corresponding fragment.",
                "On a miss, the driver contacts the Ganesh proxy to fetch the fragment.",
                "All previously unseen result fragments that were retained verbatim by the proxy are hashed and added to the result cache.",
                "There should be very few misses if the proxy has accurately tracked the Ganesh drivers cache state.",
                "A future optimization would be to batch the fetch of missing fragments.",
                "This would be valuable when there are many small missing fragments in a high-latency WAN.",
                "Once the transformation is complete, the fully reconstructed ResultSet object is passed up to the application. 4.",
                "EXPERIMENTAL VALIDATION Three questions follow from the goals and design of Ganesh: • First, can performance can be improved significantly by exploiting similarity across database results?",
                "Benchmark Dataset Details 500,000 Users, 12,000 Stories BBOARD 2.0 GB 3,298,000 Comments AUCTION 1.3 GB 1,000,000 Users, 34,000 Items Table 1: Benchmark Dataset Details • Second, how important is Ganeshs structural similarity detection relative to Rabin fingerprintings similarity detection? • Third, is the overhead of the proxy-based design acceptable?",
                "Our evaluation answers these question through controlled experiments with the Ganesh prototype.",
                "This section describes the benchmarks used, our evaluation procedure, and the experimental setup.",
                "Results of the experiments are presented in Sections 5, 6, and 7. 4.1 Benchmarks Our evaluation is based on two benchmarks [18] that have been widely used by other researchers to evaluate various aspects of multi-tier [27] and eBusiness architectures [9].",
                "The first benchmark, BBOARD, is modeled after Slashdot, a technology-oriented news site.",
                "The second benchmark, AUCTION, is modeled after eBay, an online auction site.",
                "In both benchmarks, most content is dynamically generated from information stored in a database.",
                "Details of the datasets used can be found in Table 1. 4.1.1 The BBOARD Benchmark The BBOARD benchmark, also known as RUBBoS [18], models Slashdot, a popular technology-oriented web site.",
                "Slashdot aggregates links to news stories and other topics of interest found elsewhere on the web.",
                "The site also serves as a bulletin board by allowing users to comment on the posted stories in a threaded conversation form.",
                "It is not uncommon for a story to gather hundreds of comments in a matter of hours.",
                "The BBOARD benchmark is similar to the site and models the activities of a user, including readonly operations such as browsing the stories of the day, browsing story categories, and viewing comments as well as write operations such as new user registration, adding and moderating comments, and story submission.",
                "The benchmark consists of three different phases: a short warmup phase, a runtime phase representing the main body of the workload, and a short cool-down phase.",
                "In this paper we only report results from the runtime phase.",
                "The warm-up phase is important in establishing dynamic system state, but measurements from that phase are not significant for our evaluation.",
                "The cool-down phase is solely for allowing the benchmark to shut down.",
                "The warm-up, runtime, and cool-down phases are 2, 15, and 2 minutes respectively.",
                "The number of simulated clients were 400, 800, 1200, and 1600.",
                "The benchmark is available in a Java Servlets and PHP version and has different datasets; we evaluated Ganesh using the Java Servlets version and the Expanded dataset.",
                "The BBOARD benchmark defines two different workloads.",
                "The first, the Authoring mix, consists of 70% read-only operations and 30% read-write operations.",
                "The second, the Browsing mix, contains only read-only operations and does not update the database. 4.1.2 The AUCTION Benchmark The AUCTION benchmark, also known as RUBiS [18], models eBay, the online auction site.",
                "The eBay web site is used to buy and sell items via an auction format.",
                "The main activities of a user include browsing, selling, or bidding for items.",
                "Modeling the activities on this site, this benchmark includes read-only activities such as browsing items by category and by region, as well as read-write WWW 2007 / Track: Performance and Scalability Session: Scalable Systems for Dynamic Content 314 NetEm Router Ganesh Proxy Clients Web and Application Server Database Server Figure 5: Experimental Setup activities such as bidding for items, buying and selling items, and leaving feedback.",
                "As with BBOARD, the benchmark consists of three different phases.",
                "The warm-up, runtime, and cool-down phases for this experiment are 1.5, 15, and 1 minutes respectively.",
                "We tested Ganesh with four client configurations where the number of test clients was set to 400, 800, 1200, and 1600.",
                "The benchmark is available in a Enterprise Java Bean (EJB), Java Servlets, and PHP version and has different datasets; we evaluated Ganesh with the Java Servlets version and the Expanded dataset.",
                "The AUCTION benchmark defines two different workloads.",
                "The first, the Bidding mix, consists of 70% read-only operations and 30% read-write operations.",
                "The second, the Browsing mix, contains only read-only operations and does not update the database. 4.2 Experimental Procedure Both benchmarks involve a synthetic workload of clients accessing a web server.",
                "The number of clients emulated is an experimental parameter.",
                "Each emulated client runs an instance of the benchmark in its own thread, using a matrix to transition between different benchmark states.",
                "The matrix defines a stochastic model with probabilities of transitioning between the different states that represent typical user actions.",
                "An example transition is a user logging into the AUCTION system and then deciding on whether to post an item for sale or bid on active auctions.",
                "Each client also models user think time between requests.",
                "The think time is modeled as an exponential distribution with a mean of 7 seconds.",
                "We evaluate Ganesh along two axes: number of clients and WAN bandwidth.",
                "Higher loads are especially useful in understanding Ganeshs performance when the CPU or disk of the database server or proxy is the limiting factor.",
                "A previous study has shown that approximately 50% of the wide-area Internet bottlenecks observed had an available bandwidth under 10 Mb/s [1].",
                "Based on this work, we focus our evaluation on the WAN bandwidth of 5 Mb/s with 66 ms of round-trip latency, representative of severely constrained network paths, and 20 Mb/s with 33 ms of round-trip latency, representative of a moderately constrained network path.",
                "We also report Ganeshs performance at 100 Mb/s with no added round-trip latency.",
                "This bandwidth, representative of an unconstrained network, is especially useful in revealing any potential overhead of Ganesh in situations where WAN bandwidth is not the limiting factor.",
                "For each combination of number of clients and WAN bandwidth, we measured results from the two configurations listed below: • Native: This configuration corresponds to Figure 3(a).",
                "Native avoids Ganeshs overhead in using a proxy and performing Java object serialization. • Ganesh: This configuration corresponds to Figure 3(b).",
                "For a given number of clients and WAN bandwidth, comparing these results to the corresponding Native results gives the performance benefit due to the Ganesh middleware system.",
                "The metric used to quantify the improvement in throughput is the number of client requests that can be serviced per second.",
                "The metric used to quantify Ganeshs overhead is the average response time for a client request.",
                "For all of the experiments, the Ganesh driver used by the application server used a cache size of 100,000 items1 .",
                "The proxy was effective in tracking the Ganesh drivers cache state; for all of our experiments the miss rate on the driver never exceeded 0.7%. 4.3 Experimental Setup The experimental setup used for the benchmarks can be seen in Figure 5.",
                "All machines were 3.2 GHz Pentium 4s (with HyperThreading enabled.)",
                "With the exception of the database server, all machines had 2 GB of SDRAM and ran the Fedora Core Linux distribution.",
                "The database server had 4 GB of SDRAM.",
                "We used Apaches Tomcat as both the application server that hosted the Java Servlets and the web server.",
                "Both benchmarks used Java Servlets to generate the dynamic content.",
                "The database server used the open source MySQL database.",
                "For the native JDBC drivers, we used the Connector/J drivers provided by MySQL.",
                "The application server used Suns Java Virtual Machine as the runtime environment for the Java Servlets.",
                "The sysstat tool was used to monitor the CPU, network, disk, and memory utilization on all machines.",
                "The machines were connected by a switched gigabit Ethernet network.",
                "As shown in Figure 5, the front-end web and application server was separated from the proxy and database server by a NetEm router [16].",
                "This router allowed us to control the bandwidth and latency settings on the network.",
                "The NetEm router is a standard PC with two network cards running the Linux Traffic Control and Network Emulation software.",
                "The bandwidth and latency constraints were only applied to the link between the application server and the database for the native case and between the application server and the proxy for the Ganesh case.",
                "There is no communication between the application server and the database with Ganesh as all data flows through the proxy.",
                "As our focus was on the WAN link between the application server and the database, there were no constraints on the link between the simulated test clients and the web server. 5.",
                "THROUGHPUT AND RESPONSE TIME In this section, we address the first question raised in Section 4: Can performance can be improved significantly by exploiting similarity across database results?",
                "To answer this question, we use results from the BBOARD and AUCTION benchmarks.",
                "We use two metrics to quantify the performance improvement obtainable through the use of Ganesh: throughput, from the perspective of the web server, and average response time, from the perspective of the client.",
                "Throughput is measured in terms of the number of client requests that can be serviced per second. 5.1 BBOARD Results and Analysis 5.1.1 Authoring Mix Figures 6 (a) and (b) present the average number of requests serviced per second and the average response time for these requests as perceived by the clients for BBOARDs Authoring Mix.",
                "As Figure 6 (a) shows, Native easily saturates the 5 Mb/s link.",
                "At 400 clients, the Native solution delivers 29 requests/sec with an average response time of 8.3 seconds.",
                "Natives throughput drops with an increase in test clients as clients timeout due to congestion at the application server.",
                "Usability studies have shown that response times above 10 seconds cause the user to move on to 1 As Java lacks a sizeof() operator, Java caches therefore limit their size based on the number of objects.",
                "The size of cache dumps taken at the end of the experiments never exceeded 212 MB.",
                "WWW 2007 / Track: Performance and Scalability Session: Scalable Systems for Dynamic Content 315 0 50 100 150 200 250 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Test Clients Requests/sec Native Ganesh 0.001 0.01 0.1 1 10 100 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Test Clients Avg.Resp.Time(sec) Native Ganesh Note Logscale (a) Throughput: Authoring Mix (b) Response Time: Authoring Mix 0 50 100 150 200 250 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Test Clients Requests/sec Native Ganesh 0.001 0.01 0.1 1 10 100 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Test Clients Avg.Resp.Time(sec) Native Ganesh Note Logscale (c) Throughput: Browsing Mix (d) Response Time: Browsing Mix Mean of three trials.",
                "The maximum standard deviation for throughput and response time was 9.8% and 11.9% of the corresponding mean.",
                "Figure 6: BBOARD Benchmark - Throughput and Average Response Time other tasks [24].",
                "Based on these numbers, increasing the number of test clients makes the Native system unusable.",
                "Ganesh at 5 Mb/s, however, delivers a twofold improvement with 400 test clients and a fivefold improvement at 1200 clients.",
                "Ganeshs performance drops slightly at 1200 and 1600 clients as the network is saturated.",
                "Compared to Native, Figure 6 (b) shows that Ganeshs response times are substantially lower with sub-second response times at 400 clients.",
                "Figure 6 (a) also shows that for 400 and 800 test clients Ganesh at 5 Mb/s has the same throughput and average response time as Native at 20 Mb/s.",
                "Only at 1200 and 1600 clients does Native at 20 Mb/s deliver higher throughput than Ganesh at 5 Mb/s.",
                "Comparing both Ganesh and Native at 20 Mb/s, we see that Ganesh is no longer bandwidth constrained and delivers up to a twofold improvement over Native at 1600 test clients.",
                "As Ganesh does not saturate the network with higher test client configurations, at 1600 test clients, its average response time is 0.1 seconds rather than Natives 7.7 seconds.",
                "As expected, there are no visible gains from Ganesh at the higher bandwidth of 100 Mb/s where the network is no longer the bottleneck.",
                "Ganesh, however, still tracks Native in terms of throughput. 5.1.2 Browsing Mix Figures 6 (c) and (d) present the average number of requests serviced per second and the average response time for these requests as perceived by the clients for BBOARDs Browsing Mix.",
                "Regardless of the test client configuration, Figure 6 (c) shows that Natives throughput at 5 Mb/s is limited to 10 reqs/sec.",
                "Ganesh at 5 Mb/s with 400 test clients, delivers more than a sixfold increase in throughput.",
                "The improvement increases to over a elevenfold increase at 800 test clients before Ganesh saturates the network.",
                "Further, Figure 6 (d) shows that Natives average response time of 35 seconds at 400 test clients make the system unusable.",
                "These high response times further increase with the addition of test clients.",
                "Even with the 1600 test client configuration Ganesh delivers an acceptable average response time of 8.2 seconds.",
                "Due to the data-intensive nature of the Browsing mix, Ganesh at 5 Mb/s surprisingly performs much better than Native at 20 Mb/s.",
                "Further, as shown in Figure 6 (d), while the average response time for Native at 20 Mb/s is acceptable at 400 test clients, it is unusable with 800 test clients with an average response time of 15.8 seconds.",
                "Like the 5 Mb/s case, this response time increases with the addition of extra test clients.",
                "Ganesh at 20 Mb/s and both Native and Ganesh at 100 Mb/s are not bandwidth limited.",
                "However, performance plateaus out after 1200 test clients due to the database CPU being saturated. 5.1.3 Filter Variant We were surprised by the Native performance from the BBOARD benchmark.",
                "At the bandwidth of 5 Mb/s, Native performance was lower than what we had expected.",
                "It turned out the benchmark code that displays stories read all the comments associated with the particular story from the database and only then did some postprocessing to select the comments to be displayed.",
                "While this is exactly the behavior of SlashCode, the code base behind the Slashdot web site, we decided to modify the benchmark to perform some pre-filtering at the database.",
                "This modified benchmark, named the Filter Variant, models a developer who applies optimizations at the SQL level to transfer less data.",
                "In the interests of brevity, we only briefly summarize the results from the Authoring mix.",
                "For the Authoring mix, at 800 test clients at 5 Mb/s, Figure 7 (a) shows that Natives throughput increase by 85% when compared to the original benchmark while Ganeshs improvement is smaller at 15%.",
                "Natives performance drops above 800 clients as the test clients time out due to high response times.",
                "The most significant gain for Native is seen at 20 Mb/s.",
                "At 1600 test clients, when compared to the original benchmark, Native sees a 73% improvement in throughput and a 77% reduction in average response time.",
                "While WWW 2007 / Track: Performance and Scalability Session: Scalable Systems for Dynamic Content 316 0 50 100 150 200 250 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Test Clients Requests/sec Native Ganesh 0.001 0.01 0.1 1 10 100 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Test Clients Avg.Resp.Time(sec) Native Ganesh Note Logscale (a) Throughput: Authoring Mix (b) Response Time: Authoring Mix Mean of three trials.",
                "The maximum standard deviation for throughput and response time was 7.2% and 11.5% of the corresponding mean.",
                "Figure 7: BBOARD Benchmark - Filter Variant - Throughput and Average Response Time Ganesh sees no improvement when compared to the original, it still processes 19% more requests/sec than Native.",
                "Thus, while the optimizations were more helpful to Native, Ganesh still delivers an improvement in performance. 5.2 AUCTION Results and Analysis 5.2.1 Bidding Mix Figures 8 (a) and (b) present the average number of requests serviced per second and the average response time for these requests as perceived by the clients for AUCTIONs Bidding Mix.",
                "As mentioned earlier, the Bidding mix consists of a mixture of read and write operations.",
                "The AUCTION benchmark is not as data intensive as BBOARD.",
                "Therefore, most of the gains are observed at the lower bandwidth of 5 Mb/s.",
                "Figure 8 (a) shows that the increase in throughput due to Ganesh ranges from 8% at 400 test clients to 18% with 1600 test clients.",
                "As seen in Figure 8 (b), the average response times for Ganesh are significantly lower than Native ranging from a decrease of 84% at 800 test clients to 88% at 1600 test clients.",
                "Figure 8 (a) also shows that with a fourfold increase of bandwidth from 5 Mb/s to 20 Mb/s, Native is no longer bandwidth constrained and there is no performance difference between Ganesh and Native.",
                "With the higher test client configurations, we did observe that the bandwidth used by Ganesh was lower than Native.",
                "Ganesh might still be useful in these non-constrained scenarios if bandwidth is purchased on a metered basis.",
                "Similar results are seen for the 100 Mb/s scenario. 5.2.2 Browsing Mix For AUCTIONs Browsing Mix, Figures 8 (c) and (d) present the average number of requests serviced per second and the average response time for these requests as perceived by the clients.",
                "Again, most of the gains are observed at lower bandwidths.",
                "At 5 Mb/s, Native and Ganesh deliver similar throughput and response times with 400 test clients.",
                "While the throughput for both remains the same at 800 test clients, Figure 8 (d) shows that Ganeshs average response time is 62% lower than Native.",
                "Native saturates the link at 800 clients and adding extra test clients only increases the average response time.",
                "Ganesh, regardless of the test client configuration, is not bandwidth constrained and maintains the same response time.",
                "At 1600 test clients, Figure 8 (c) shows that Ganeshs throughput is almost twice that of Native.",
                "At the higher bandwidths of 20 and 100 Mb/s, neither Ganesh nor Native is bandwidth limited and deliver equivalent throughput and response times.",
                "Benchmark Orig.",
                "Size Ganesh Size Rabin Size SelectSort1 223.6 MB 5.4 MB 219.3 MB SelectSort2 223.6 MB 5.4 MB 223.6 MB Table 2: Similarity Microbenchmarks 6.",
                "STRUCTURAL VS. RABIN SIMILARITY In this section, we address the second question raised in Section 4: How important is Ganeshs structural similarity detection relative to Rabin fingerprinting-based similarity detecting?",
                "To answer this question, we used microbenchmarks and the BBOARD and AUCTION benchmarks.",
                "As Ganesh always performed better than Rabin fingerprinting, we only present a subset of the results here in the interests of brevity. 6.1 Microbenchmarks Two microbenchmarks show an example of the effects of data reordering on Rabin fingerprinting algorithm.",
                "In the first microbenchmark, SelectSort1, a query with a specified sort order selects 223.6 MB of data spread over approximately 280 K rows.",
                "The query is then repeated with a different sort attribute.",
                "While the same number of rows and the same data is returned, the order of rows is different.",
                "In such a scenario, one would expect a large amount of similarity to be detected between both results.",
                "As Table 2 shows, Ganeshs row-based algorithm achieves a 97.6% reduction while the Rabin fingerprinting algorithm, with the average chunk size parameter set to 4 KB, only achieves a 1% reduction.",
                "The reason, as shown earlier in Figure 2, is that with Rabin fingerprinting, the spans of data between two consecutive boundaries usually cross row boundaries.",
                "With the order of the rows changing in the second result and the Rabin fingerprints now spanning different rows, the algorithm is unable to detect significant similarity.",
                "The small gain seen is mostly for those single rows that are large enough to be broken into multiple chunks.",
                "SelectSort2, another micro-benchmark executed the same queries but increased the minimum chunk size of the Rabin fingerprinting algorithm.",
                "As can be seen in Table 2, even the small gain from the previous microbenchmark disappears as the minimum chunk size was greater than the average row size.",
                "While one can partially address these problems by dynamically varying the parameters of the Rabin fingerprinting algorithm, this can be computationally expensive, especially in the presence of changing workloads. 6.2 Application Benchmarks We ran the BBOARD benchmark described in Section 4.1.1 on two versions of Ganesh: the first with Rabin fingerprinting used as WWW 2007 / Track: Performance and Scalability Session: Scalable Systems for Dynamic Content 317 0 50 100 150 200 250 300 350 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Test Clients Requests/sec Native Ganesh 0.001 0.01 0.1 1 10 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Test Clients Avg.Resp.Time(sec) Native Ganesh Note Logscale (a) Throughput: Bidding Mix (b) Response Time: Bidding Mix 0 50 100 150 200 250 300 350 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Test Clients Requests/sec Native Ganesh 0.001 0.01 0.1 1 10 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Test Clients Avg.Resp.Time(sec) Native Ganesh Note Logscale (c) Throughput: Browsing Mix (d) Response Time: Browsing Mix Mean of three trials.",
                "The maximum standard deviation for throughput and response time was 2.2% and 11.8% of the corresponding mean.",
                "Figure 8: AUCTION Benchmark - Throughput and Average Response Time the chunking algorithm and the second with Ganeshs row-based algorithm.",
                "Rabins results for the Browsing Mix are normalized to Ganeshs results and presented in Figure 9.",
                "As Figure 9 (a) shows, at 5 Mb/s, independent of the test client configuration, Rabin significantly underperforms Ganesh.",
                "This happens because of a combination of two reasons.",
                "First, as outlined in Section 3.1, Rabin finds less similarity as it does not exploit the results structural information.",
                "Second, this benchmark contained some queries that generated large results.",
                "In this case, Rabin, with a small average chunk size, generated a large number of objects that evicted other useful data from the cache.",
                "In contrast, Ganesh was able to detect these large rows and correspondingly increase the size of the chunks.",
                "This was confirmed as cache statistics showed that Ganeshs hit ratio was roughly three time that of Rabin.",
                "Throughput measurements at 20 Mb/s were similar with the exception of Rabins performance with 400 test clients.",
                "In this case, Ganesh was not network limited and, in fact, the throughput was the same as 400 clients at 5 Mb/s.",
                "Rabin, however, took advantage of the bandwidth increase from 5 to 20 Mb/s to deliver a slightly better performance.",
                "At 100 Mb/s, Rabins throughput was almost similar to Ganesh as bandwidth was no longer a bottleneck.",
                "The normalized response time, presented in Figure 9 (b), shows similar trends.",
                "At 5 and 20 Mb/s, the addition of test clients decreases the normalized response time as Ganeshs average response time increases faster than Rabins.",
                "However, at no point does Rabin outperform Ganesh.",
                "Note that at 400 and 800 clients at 100 Mb/s, Rabin does have a higher overhead even when it is not bandwidth constrained.",
                "As mentioned in Section 3.1, this is due to the fact that Rabin has to hash each ResultSet twice.",
                "The overhead disappears with 1200 and 1600 clients as the database CPU is saturated and limits the performance of both Ganesh and Rabin. 7.",
                "PROXY OVERHEAD In this section, we address the third question raised in Section 4: Is the overhead of Ganeshs proxy-based design acceptable?",
                "To answer this question, we concentrate on its performance at the higher bandwidths.",
                "Our evaluation in Section 5 showed that Ganesh, when compared to Native, can deliver a substantial throughput improvement at lower bandwidths.",
                "It is only at higher bandwidths that latency, measured by the average response time for a client request, and throughput, measured by the number of client requests that can be serviced per second, overheads would be visible.",
                "Looking at the Authoring mix of the original BBOARD benchmark, there are no visible gains from Ganesh at 100 Mb/s.",
                "Ganesh, however, still tracks Native in terms of throughput.",
                "While the average response time is higher for Ganesh, the absolute difference is in between 0.01 and 0.04 seconds and would be imperceptible to the end-user.",
                "The Browsing mix shows an even smaller difference in average response times.",
                "The results from the filter variant of the BBOARD benchmarks are similar.",
                "Even for the AUCTION benchmark, the difference between Native and Ganeshs response time at 100 Mb/s was never greater than 0.02 seconds.",
                "The only exception to the above results was seen in the filter variant of the BBOARD benchmark where Ganesh at 1600 test clients added 0.85 seconds to the average response time.",
                "Thus, even for much faster networks where the WAN link is not the bottleneck, Ganesh always delivers throughput equivalent to Native.",
                "While some extra latency is added by the proxy-based design, it is usually imperceptible. 8.",
                "RELATED WORK To the best of our knowledge, Ganesh is the first system that combines the use of hash-based techniques with caching of database results to improve throughput and response times for applications with dynamic content.",
                "We also believe that it is also the first system to demonstrate the benefits of using structural information for WWW 2007 / Track: Performance and Scalability Session: Scalable Systems for Dynamic Content 318 0.0 0.2 0.4 0.6 0.8 1.0 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Test Clients Norm.Throughput 31.8 3.8 2.8 2.3 23.8 32.8 5.8 3.6 1.8 2.1 1.1 1.0 0 5 10 15 20 25 30 35 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Test Clients Norm.ResponseTime (a) Normalized Throughput: Higher is better (b) Normalized Response Time: Higher is worse For throughput, a normalized result greater than 1 implies that Rabin is better, For response time, a normalized result greater than 1 implies that Ganesh is better.",
                "Mean of three trials.",
                "The maximum standard deviation for throughput and response time was 9.1% and 13.9% of the corresponding mean.",
                "Figure 9: Normalized Comparison of Ganesh vs. Rabin - BBOARD Browsing Mix detecting similarity.",
                "In this section, we first discuss alternative approaches to caching dynamic content and then examine other uses of hash-based primitives in distributed systems. 8.1 Caching Dynamic Content At the database layer, a number of systems have advocated middletier caching where parts of the database are replicated at the edge or server [3, 4, 20].",
                "These systems either cache entire tables in what is essentially a replicated database or use materialized views from previous query replies [19].",
                "They require tight integration with the back-end database to ensure a time bound on the propagation of updates.",
                "These systems are also usually targeted towards workloads that do not require strict consistency and can tolerate stale data.",
                "Further, unlike Ganesh, some of these mid-tier caching solutions [2, 3], suffer from the complexity of having to participate in query planing and distributed query processing.",
                "Gao et al. [15] propose using a distributed object replication architecture where the data stores consistency requirements are adapted on a per-application basis.",
                "These solutions require substantial developer resources and detailed understanding of the application being modified.",
                "While systems that attempt to automate the partitioning and replication of an applications database exist [34], they do not provide full transaction semantics.",
                "In comparison, Ganesh does not weaken any of the semantics provided by the underlying database.",
                "Recent work in the evaluation of edge caching options for dynamic web sites [38] has suggested that, without careful planning, employing complex offloading strategies can hurt performance.",
                "Instead, the work advocates for an architecture in which all tiers except the database should be offloaded to the edge.",
                "Our evaluation of Ganesh has shown that it would benefit these scenarios.",
                "To improve database scalability, C-JDBC [10], SSS [22], and Ganymed [28] also advocate the use of an interposition-based architecture to transparently cluster and replicate databases at the middleware level.",
                "The approaches of these architectures and Ganesh are complementary and they would benefit each other.",
                "Moving up to the presentation layer, there has been widespread adoption of fragment-based caching [14], which improves cache utilization by separately caching different parts of generated web pages.",
                "While fragment-based caching works at the edge, a recent proposal has proposed moving web page assembly to the clients to optimize content delivery [31].",
                "While Ganesh is not used at the presentation layer, the same principles have been applied in Duplicate Transfer Detection [25] to increase web cache efficiency as well as for web access across bandwidth limited links [33]. 8.2 Hash-based Systems The past few years have seen the emergence of many systems that exploit hash-based techniques.",
                "At the heart of all these systems is the idea of detecting similarity in data without requiring interpretation of that data.",
                "This simple yet elegant idea relies on cryptographic hashing, as discussed earlier in Section 2.",
                "Successful applications of this idea span a wide range of storage systems.",
                "Examples include peer-to-peer backup of personal computing files [11], storage-efficient archiving of data [29], and finding similar files [21].",
                "Spring and Wetherall [35] apply similar principles at the network level.",
                "Using synchronized caches at both ends of a network link, duplicated data is replaced by smaller tokens for transmission and then restored at the remote end.",
                "This and other hash-based systems such as the CASPER [37] and LBFS [26] filesystems, and Layer-2 bandwidth optimizers such as Riverbed and Peribit use Rabin fingerprinting [30] to discover spans of commonality in data.",
                "This approach is especially useful when data items are modified in-place through insertions, deletions, and updates.",
                "However, as Section 6 shows, the performance of this technique can show a dramatic drop in the presence of data reordering.",
                "Ganesh instead uses row boundaries as dividers for detecting similarity.",
                "The most aggressive use of hash-based techniques is by systems that use hashes as the primary identifiers for objects in persistent storage.",
                "Storage systems such as CFS [12] and PAST [13] that have been built using distributed hash tables fall into this category.",
                "Single Instance Storage [6] and Venti [29] are other examples of such systems.",
                "As discussed in Section 2.2, the use of cryptographic hashes for addressing persistent data represents a deeper level of faith in their collision-resistance than that assumed by Ganesh.",
                "If time reveals shortcomings in the hash algorithm, the effort involved in correcting the flaw is much greater.",
                "In Ganesh, it is merely a matter of replacing the hash algorithm. 9.",
                "CONCLUSION The growing use of dynamic web content generated from relational databases places increased demands on WAN bandwidth.",
                "Traditional caching solutions for bandwidth and latency reduction are often ineffective for such content.",
                "This paper shows that the impact of WAN accesses to databases can be substantially reduced through the Ganesh architecture without any compromise of the databases strict consistency semantics.",
                "The essence of the Ganesh architecture is the use of computation at the edges to reduce communication through the Internet.",
                "Ganesh is able to use cryptographic hashes to detect similarity with previous results and send WWW 2007 / Track: Performance and Scalability Session: Scalable Systems for Dynamic Content 319 compact recipes of results rather than full results.",
                "Our design uses interposition to achieve complete transparency: clients, application servers, and database servers are all unaware of Ganeshs presence and require no modification.",
                "Our experimental evaluation confirms that Ganesh, while conceptually simple, can be highly effective in improving throughput and response time.",
                "Our results also confirm that exploiting the structure present in database results to detect similarity is crucial to this performance improvement. 10.",
                "REFERENCES [1] AKELLA, A., SESHAN, S., AND SHAIKH, A.",
                "An empirical evaluation of wide-area internet bottlenecks.",
                "In Proc. 3rd ACM SIGCOMM Conference on Internet Measurement (Miami Beach, FL, USA, Oct. 2003), pp. 101-114. [2] ALTINEL, M., BORNH ¨OVD, C., KRISHNAMURTHY, S., MOHAN, C., PIRAHESH, H., AND REINWALD, B. Cache tables: Paving the way for an adaptive database cache.",
                "In Proc. of 29th VLDB (Berlin, Germany, 2003), pp. 718-729. [3] ALTINEL, M., LUO, Q., KRISHNAMURTHY, S., MOHAN, C., PIRAHESH, H., LINDSAY, B. G., WOO, H., AND BROWN, L. Dbcache: Database caching for web application servers.",
                "In Proc. 2002 ACM SIGMOD (2002), pp. 612-612. [4] AMIRI, K., PARK, S., TEWARI, R., AND PADMANABHAN, S. Dbproxy: A dynamic data cache for web applications.",
                "In Proc.",
                "IEEE International Conference on Data Engineering (ICDE) (Mar. 2003). [5] BLACK, J. Compare-by-hash: A reasoned analysis.",
                "In Proc. 2006 USENIX Annual Technical Conference (Boston, MA, May 2006), pp. 85-90. [6] BOLOSKY, W. J., CORBIN, S., GOEBEL, D., , AND DOUCEUR, J. R. Single instance storage in windows 2000.",
                "In Proc. 4th USENIX Windows Systems Symposium (Seattle, WA, Aug. 2000), pp. 13-24. [7] BREWER, E. A.",
                "Lessons from giant-scale services.",
                "IEEE Internet Computing 5, 4 (2001), 46-55. [8] BRODER, A., GLASSMAN, S., MANASSE, M., AND ZWEIG, G. Syntactic clustering of the web.",
                "In Proc. 6th International WWW Conference (1997). [9] CECCHET, E., CHANDA, A., ELNIKETY, S., MARGUERITE, J., AND ZWAENEPOEL, W. Performance comparison of middleware architectures for generating dynamic web content.",
                "In Proc.",
                "Fourth ACM/IFIP/USENIX International Middleware Conference (Rio de Janeiro, Brazil, June 2003). [10] CECCHET, E., MARGUERITE, J., AND ZWAENEPOEL, W. C-JDBC: Flexible database clustering middleware.",
                "In Proc. 2004 USENIX Annual Technical Conference (Boston, MA, June 2004). [11] COX, L. P., MURRAY, C. D., AND NOBLE, B. D. Pastiche: Making backup cheap and easy.",
                "In OSDI: Symposium on Operating Systems Design and Implementation (2002). [12] DABEK, F., KAASHOEK, M. F., KARGER, D., MORRIS, R., AND STOICA, I. Wide-area cooperative storage with CFS.",
                "In 18th ACM Symposium on Operating Systems Principles (Banff, Canada, Oct. 2001). [13] DRUSCHEL, P., AND ROWSTRON, A.",
                "PAST: A large-scale, persistent peer-to-peer storage utility.",
                "In HotOS VIII (Schloss Elmau, Germany, May 2001), pp. 75-80. [14] Edge side includes. http://www.esi.org. [15] GAO, L., DAHLIN, M., NAYATE, A., ZHENG, J., AND IYENGAR, A.",
                "Application specific data replication for edge services.",
                "In WWW 03: Proc.",
                "Twelfth International Conference on World Wide Web (2003), pp. 449-460. [16] HEMMINGER, S. Netem - emulating real networks in the lab.",
                "In Proc. 2005 Linux Conference Australia (Canberra, Australia, Apr. 2005). [17] HENSON, V. An analysis of compare-by-hash.",
                "In Proc. 9th Workshop on Hot Topics in Operating Systems (HotOS IX) (May 2003), pp. 13-18. [18] Jmob benchmarks. http://jmob.objectweb.org/. [19] LABRINIDIS, A., AND ROUSSOPOULOS, N. Balancing performance and data freshness in web database servers.",
                "In Proc. 29th VLDB Conference (Sept. 2003). [20] LARSON, P.-A., GOLDSTEIN, J., AND ZHOU, J. Transparent mid-tier database caching in sql server.",
                "In Proc. 2003 ACM SIGMOD (2003), pp. 661-661. [21] MANBER, U.",
                "Finding similar files in a large file system.",
                "In Proc.",
                "USENIX Winter 1994 Technical Conference (San Fransisco, CA, 17-21 1994), pp. 1-10. [22] MANJHI, A., AILAMAKI, A., MAGGS, B. M., MOWRY, T. C., OLSTON, C., AND TOMASIC, A.",
                "Simultaneous scalability and security for data-intensive web applications.",
                "In Proc. 2006 ACM SIGMOD (June 2006), pp. 241-252. [23] MENEZES, A. J., VANSTONE, S. A., AND OORSCHOT, P. C. V. Handbook of Applied Cryptography.",
                "CRC Press, 1996. [24] MILLER, R. B.",
                "Response time in man-computer conversational transactions.",
                "In Proc.",
                "AFIPS Fall Joint Computer Conference (1968), pp. 267-277. [25] MOGUL, J. C., CHAN, Y. M., AND KELLY, T. Design, implementation, and evaluation of duplicate transfer detection in http.",
                "In Proc.",
                "First Symposium on Networked Systems Design and Implementation (San Francisco, CA, Mar. 2004). [26] MUTHITACHAROEN, A., CHEN, B., AND MAZIERES, D. A low-bandwidth network file system.",
                "In Proc. 18th ACM Symposium on Operating Systems Principles (Banff, Canada, Oct. 2001). [27] PFEIFER, D., AND JAKSCHITSCH, H. Method-based caching in multi-tiered server applications.",
                "In Proc.",
                "Fifth International Symposium on Distributed Objects and Applications (Catania, Sicily, Italy, Nov. 2003). [28] PLATTNER, C., AND ALONSO, G. Ganymed: Scalable replication for transactional web applications.",
                "In Proc. 5th ACM/IFIP/USENIX International Conference on Middleware (2004), pp. 155-174. [29] QUINLAN, S., AND DORWARD, S. Venti: A new approach to archival storage.",
                "In Proc.",
                "FAST 2002 Conference on File and Storage Technologies (2002). [30] RABIN, M. Fingerprinting by random polynomials.",
                "In Harvard University Center for Research in Computing Technology Technical Report TR-15-81 (1981). [31] RABINOVICH, M., XIAO, Z., DOUGLIS, F., AND KALMANEK, C. Moving edge side includes to the real edge - the clients.",
                "In Proc. 4th USENIX Symposium on Internet Technologies and Systems (Seattle, WA, Mar. 2003). [32] REESE, G. Database Programming with JDBC and Java, 1st ed.",
                "OReilly, June 1997. [33] RHEA, S., LIANG, K., AND BREWER, E. Value-based web caching.",
                "In Proc.",
                "Twelfth International World Wide Web Conference (May 2003). [34] SIVASUBRAMANIAN, S., ALONSO, G., PIERRE, G., AND VAN STEEN, M. Globedb: Autonomic data replication for web applications.",
                "In WWW 05: Proc. 14th International World-Wide Web conference (May 2005). [35] SPRING, N. T., AND WETHERALL, D. A protocol-independent technique for eliminating redundant network traffic.",
                "In Proc. of ACM SIGCOMM (Aug. 2000). [36] TOLIA, N., HARKES, J., KOZUCH, M., AND SATYANARAYANAN, M. Integrating portable and distributed storage.",
                "In Proc. 3rd USENIX Conference on File and Storage Technologies (San Francisco, CA, Mar. 2004). [37] TOLIA, N., KOZUCH, M., SATYANARAYANAN, M., KARP, B., PERRIG, A., AND BRESSOUD, T. Opportunistic use of <br>content addressable storage</br> for distributed file systems.",
                "In Proc. 2003 USENIX Annual Technical Conference (San Antonio, TX, June 2003), pp. 127-140. [38] YUAN, C., CHEN, Y., AND ZHANG, Z.",
                "Evaluation of edge caching/offloading for dynamic content delivery.",
                "In WWW 03: Proc.",
                "Twelfth International Conference on World Wide Web (2003), pp. 461-471.",
                "WWW 2007 / Track: Performance and Scalability Session: Scalable Systems for Dynamic Content 320"
            ],
            "original_annotated_samples": [
                "In Proc. 3rd USENIX Conference on File and Storage Technologies (San Francisco, CA, Mar. 2004). [37] TOLIA, N., KOZUCH, M., SATYANARAYANAN, M., KARP, B., PERRIG, A., AND BRESSOUD, T. Opportunistic use of <br>content addressable storage</br> for distributed file systems."
            ],
            "translated_annotated_samples": [
                "En Proc. 3ra Conferencia USENIX sobre Tecnologías de Archivos y Almacenamiento (San Francisco, CA, Mar. 2004). [37] TOLIA, N., KOZUCH, M., SATYANARAYANAN, M., KARP, B., PERRIG, A., Y BRESSOUD, T. Uso oportunista del <br>almacenamiento direccionable por contenido</br> para sistemas de archivos distribuidos."
            ],
            "translated_text": "Conservación de la consistencia en el almacenamiento en caché de contenido dinámico de bases de datos∗ Niraj Tolia y M. Satyanarayanan Universidad Carnegie Mellon {ntolia,satya}@cs.cmu.edu RESUMEN Con el creciente uso de contenido web dinámico generado a partir de bases de datos relacionales, las soluciones de almacenamiento en caché tradicionales para mejorar el rendimiento y la latencia son ineficaces. Describimos una capa de middleware llamada Ganesh que reduce el volumen de datos transmitidos sin interpretación semántica de consultas o resultados. Se logra esta reducción mediante el uso de hash criptográficos para detectar similitudes con resultados anteriores. Estos beneficios no requieren ningún compromiso con la semántica de consistencia estricta proporcionada por la base de datos del servidor. Además, Ganesh no requiere modificaciones en aplicaciones, servidores web o servidores de bases de datos, y funciona con aplicaciones y bases de datos de código cerrado. Usando dos puntos de referencia representativos de sitios web dinámicos, las mediciones de nuestro prototipo muestran que puede aumentar el rendimiento de extremo a extremo hasta en un factor de dos para aplicaciones no intensivas en datos y hasta en un factor de diez para las intensivas en datos. Categorías y Descriptores de Asignaturas C.2.4 [Redes de Computadoras-Comunicación]: Sistemas Distribuidos; H.2.4 [Gestión de Bases de Datos]: Términos Generales de Sistemas de Diseño, Rendimiento 1. INTRODUCCIÓN Una fracción creciente del contenido web se genera dinámicamente a partir de bases de datos relacionales en el backend. Incluso cuando el contenido de la base de datos permanece sin cambios, la localidad temporal de acceso no puede ser explotada porque el contenido dinámico no es almacenable en caché por los navegadores web o por servidores de almacenamiento en caché intermedios como los espejos de Akamai. En una arquitectura multinivel, cada solicitud web puede tensionar el enlace WAN entre el servidor web y la base de datos. Esto provoca que la experiencia del usuario sea altamente variable porque no hay almacenamiento en caché para aislar al cliente de cargas repentinas. Los intentos previos de almacenar en caché contenido dinámico de bases de datos generalmente han debilitado la semántica transaccional [3, 4] o han requerido modificaciones en la aplicación [15, 34]. Informamos sobre una nueva solución que toma la forma de una capa intermedia de middleware independiente de la base de datos llamada Ganesh. Ganesh no hace ningún esfuerzo por interpretar semánticamente el contenido de las consultas o sus resultados. En cambio, se basa exclusivamente en el hash criptográfico para detectar similitudes con resultados anteriores. La detección de similitud basada en hash ha sido cada vez más utilizada en sistemas de archivos distribuidos [26, 36, 37] para mejorar el rendimiento en redes de baja capacidad de ancho de banda. Sin embargo, estas técnicas no se han utilizado para bases de datos relacionales. A diferencia de enfoques anteriores que utilizan métodos genéricos para detectar similitud, Ganesh explota la estructura de los resultados de la base de datos relacional para lograr una mejora superior en el rendimiento. Uno se enfrenta al menos a tres desafíos al aplicar la detección de similitud basada en hash a las bases de datos de back-end. Primero, el trabajo previo en este ámbito ha considerado tradicionalmente el contenido de almacenamiento como bolsas de bits no interpretadas y sin estructura interna. Esto permite que las técnicas basadas en hash operen en largas y contiguas secuencias de datos para lograr la máxima efectividad. Por el contrario, las bases de datos relacionales tienen una estructura interna compleja que puede no ser tan propicia para la detección de similitudes basada en hash. Segundo, las bases de datos relacionales tienen restricciones de integridad y consistencia muy estrictas que no deben comprometerse por el uso de técnicas basadas en hash. Tercero, el código fuente de las bases de datos comerciales generalmente no está disponible. Esto contrasta con trabajos anteriores que presumían la disponibilidad del código fuente. Nuestros experimentos muestran que Ganesh, aunque conceptualmente simple, puede mejorar significativamente el rendimiento en anchos de banda representativos del Internet comercial actual. En los modelos de referencia de aplicaciones web multinivel, la mejora en el rendimiento fue de hasta diez veces para cargas de trabajo intensivas en datos. Para cargas de trabajo que no eran intensivas en datos, se observaron mejoras en el rendimiento de hasta el doble. Incluso cuando el ancho de banda no era una limitación, Ganesh tenía un bajo sobrecosto y no afectaba el rendimiento. Nuestros experimentos también confirman que aprovechar la estructura presente en los resultados de la base de datos es crucial para esta mejora en el rendimiento. Antecedentes 2.1 Generación de Contenido Dinámico A medida que la World Wide Web ha crecido, muchos sitios web han descentralizado sus datos y funcionalidades al llevarlos a los extremos de Internet. Hoy en día, los sistemas de comercio electrónico a menudo utilizan una arquitectura de tres niveles que consta de un servidor web de front-end, un servidor de aplicaciones y un servidor de base de datos de back-end. La Figura 1 ilustra esta arquitectura. Los dos primeros niveles se pueden replicar cerca de una concentración de clientes en el borde de Internet. Esto mejora la experiencia del usuario al reducir la latencia de extremo a extremo y disminuir la exposición al congestionamiento del tráfico de la columna vertebral. También puede aumentar la disponibilidad y escalabilidad de los servicios web. El contenido que se genera dinámicamente desde la base de datos del servidor no puede ser almacenado en caché en los dos primeros niveles. Si bien las bases de datos pueden replicarse fácilmente en una LAN, esto es inviable en una WAN debido a la difícil tarea de proporcionar simultáneamente una consistencia sólida, disponibilidad y tolerancia a particiones de red [7]. Como resultado, las bases de datos tienden a ser centralizadas para cumplir con los fuertes requisitos de consistencia de muchas aplicaciones de comercio electrónico como la banca, las finanzas y la venta al por menor en línea [38]. Por lo tanto, la base de datos del back-end suele estar ubicada lejos de muchos conjuntos de nodos de primer y segundo nivel [2]. En ausencia de almacenamiento en caché y replicación, el ancho de banda de la WAN puede convertirse fácilmente en un factor limitante en el rendimiento y la escalabilidad de aplicaciones intensivas en datos. El enfoque de Ganesh en los sistemas basados en hash es la transmisión eficiente de resultados al descubrir similitudes con los resultados de consultas anteriores. Dado que las consultas SQL pueden generar resultados grandes, las técnicas basadas en hash se prestan bien al problema de transferir eficientemente estos grandes resultados a través de enlaces con ancho de banda limitado. El uso de técnicas basadas en hash para reducir el volumen de datos transmitidos ha surgido como un tema común en muchos sistemas de almacenamiento recientes, como se discute en la Sección 8.2. Estas técnicas se basan en algunas suposiciones básicas. Se asume que las funciones hash criptográficas son resistentes a colisiones. En otras palabras, es computacionalmente intratable encontrar dos entradas que se hash a la misma salida. Las funciones también se asumen como unidireccionales; es decir, encontrar una entrada que resulte en una salida específica es computacionalmente inviable. Menezes et al. [23] proporcionan más detalles sobre estas suposiciones. Las suposiciones anteriores permiten a los sistemas basados en hash asumir que no se producen colisiones. Por lo tanto, pueden tratar el hash de un elemento de datos como su identificador único. Una colección de elementos de datos se convierte efectivamente en direccionable por contenido, permitiendo que un hash pequeño funcione como una palabra de código para un elemento de datos mucho más grande en almacenamiento permanente o transmisión en red. La suposición de que las colisiones son tan raras que prácticamente no existen ha sido cuestionada recientemente [17]. Sin embargo, como explicó Black [5], creemos que estos problemas no son una preocupación para Ganesh. Toda comunicación es entre partes confiables del sistema y un adversario no tiene forma de obligar a Ganesh a aceptar datos inválidos. Además, Ganesh no depende críticamente de ninguna función hash específica. Si bien actualmente usamos SHA-1, reemplazarlo con una función hash diferente sería sencillo. No habría impacto en el rendimiento con funciones hash más fuertes (por ejemplo, SHA256) solo añade unos pocos bytes adicionales y los hashes generados siguen siendo órdenes de magnitud más pequeños que los elementos de datos que representan. No es necesario volver a almacenar permanentemente ya que Ganesh solo utiliza el hash en datos volátiles. 3. DISEÑO E IMPLEMENTACIÓN Ganesh explota la redundancia en el flujo de resultados para evitar transmitir fragmentos de resultados que ya están presentes en el sitio de la consulta. La redundancia puede surgir de forma natural de muchas maneras diferentes. Por ejemplo, una consulta repetida después de un cierto intervalo puede devolver un resultado diferente debido a actualizaciones en la base de datos; sin embargo, puede haber una significativa similitud entre los dos resultados. Como otro ejemplo, un usuario que está refinando una búsqueda puede generar una secuencia de consultas con resultados superpuestos. Cuando Ganesh detecta redundancia, suprime la transmisión de los fragmentos de resultado correspondientes. En cambio, transmite un resumen mucho más pequeño de esos fragmentos y permite que el sitio de consulta reconstruya el resultado a través de la búsqueda de hash en una caché de resultados anteriores. De hecho, Ganesh utiliza la computación en los bordes para reducir la comunicación por Internet. Nuestra descripción de Ganesh se centra en cuatro aspectos. Primero explicamos nuestro enfoque para detectar similitud en los resultados de la consulta. A continuación, discutimos cómo la arquitectura Ganesh es completamente invisible para todos los componentes de un sistema de múltiples niveles. Luego describimos el enfoque basado en proxy de Ganesh y el flujo de datos para detectar similitudes. 3.1 Detectar similitud Una de las decisiones clave de diseño en Ganesh es cómo se detecta la similitud. Hay muchas formas potenciales de descomponer un resultado en fragmentos.  I the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the thees I,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,, Encontrar esta descomposición óptima es un problema difícil debido al amplio espacio de posibilidades y porque la elección óptima depende de muchos factores, como el contenido del resultado de las consultas, el historial de resultados recientes y el algoritmo de gestión de caché. Cuando un objeto es opaco, el uso de huellas digitales de Rabin [8, 30] para detectar datos comunes entre dos objetos ha sido demostrado con éxito en el pasado por sistemas como LBFS [26] y CASPER [37]. El fingerprinting de Rabin utiliza una ventana deslizante sobre los datos para calcular un hash rodante. Suponiendo que la función hash está distribuida uniformemente, un límite de fragmento se define cuando los bits de orden inferior del valor hash son iguales a algún valor predeterminado. El número de bits de orden inferior utilizados define el tamaño promedio del fragmento. Estos fragmentos subdivididos del objeto se convierten en la unidad de comparación para detectar similitudes entre diferentes objetos. Dado que las ubicaciones de los límites encontrados mediante el uso de las huellas de Rabin están determinadas de manera estocástica, generalmente no logran alinearse con ninguna propiedad estructural de los datos subyacentes. Por lo tanto, el algoritmo maneja bien las actualizaciones en su lugar, inserciones y eliminaciones. Sin embargo, tiene un rendimiento deficiente en presencia de cualquier reordenamiento de datos. La Figura 2 muestra un ejemplo donde dos resultados, A y B, que constan de tres filas, tienen los mismos datos pero diferentes atributos de ordenamiento. En el caso extremo, la huella digital de Rabin podría no ser capaz de encontrar datos similares debido a la forma en que detecta los límites de los fragmentos. Afortunadamente, Ganesh puede utilizar conocimientos específicos del dominio para una detección de límites más precisa. La información que explotamos es que el resultado de una consulta refleja la estructura de una base de datos relacional donde todos los datos están organizados en tablas y filas. Por lo tanto, es sencillo verificar la similitud con resultados anteriores en dos niveles de granularidad: primero el resultado completo y luego las filas individuales. El final de una fila en un resultado sirve como un límite natural de fragmento. Es importante tener en cuenta que el uso de la estructura tabular en los resultados solo implica una interpretación superficial de los datos. Ganesh no realiza ninguna interpretación semántica más profunda, como comprender tipos de datos, esquemas de resultados o restricciones de integridad. Ajustar la huella digital de Rabin para una carga de trabajo también puede ser difícil. Si el tamaño promedio de los fragmentos es demasiado grande, los fragmentos pueden abarcar varias filas de resultados. Sin embargo, seleccionar un tamaño de fragmento promedio más pequeño aumenta la cantidad de metadatos necesarios para describir los resultados. Esto, a su vez, disminuiría los ahorros obtenidos mediante su uso. El fingerprinting de Rabin también requiere dos pasadas computacionalmente costosas sobre los datos: una vez para determinar los límites de los fragmentos y otra vez para generar hashes criptográficos para los fragmentos. Ganesh solo necesita un único pase para la generación de hash, ya que los límites de los fragmentos son proporcionados por la estructura natural de los datos. La comparación de rendimiento en la Sección 6 muestra que el algoritmo basado en filas de Ganesh supera al fingerprinting de Rabin. Dado que trabajos anteriores ya han demostrado que la huella digital de Rabin funciona mejor que gzip [26], no comparamos a Ganesh con algoritmos de compresión en este artículo. 3.2 Transparencia El factor clave que influyó en nuestro diseño fue la necesidad de que Ganesh fuera completamente transparente para todos los componentes de un sistema típico de comercio electrónico: servidores web, servidores de aplicaciones y servidores de bases de datos. Sin esto, Ganesh tiene pocas posibilidades de tener un impacto significativo en el mundo real. Requerir modificaciones en cualquiera de los componentes mencionados aumentaría la barrera de entrada de Ganesh en un sistema existente, y por lo tanto reduciría sus posibilidades de adopción. Preservar la transparencia se simplifica por el hecho de que Ganesh es simplemente una mejora de rendimiento, no una mejora de funcionalidad o usabilidad. Elegimos la interposición de agentes como enfoque arquitectónico para lograr nuestro objetivo. Este enfoque se basa en la existencia de una interfaz de programación compacta que ya es ampliamente utilizada por el software objetivo. También se basa en un mecanismo para agregar fácilmente nuevo código sin interrumpir la estructura de módulos existente. Estas condiciones se cumplen fácilmente en nuestro contexto debido a la popularidad de Java como el lenguaje de programación para sistemas de comercio electrónico. La API de Conectividad de Base de Datos de Java (JDBC) [32] permite a las aplicaciones de Java acceder a una amplia variedad de bases de datos e incluso a otros repositorios de datos tabulares como archivos planos. El acceso a estas fuentes de datos es proporcionado por controladores JDBC que traducen entre la API JDBC y el mecanismo de comunicación de la base de datos. La figura 3(a) muestra cómo se utiliza típicamente JDBC en una aplicación. Dado que la interfaz JDBC está estandarizada, se puede sustituir un controlador JDBC por otro sin necesidad de de modificar la aplicación. El controlador JDBC se convierte así en el módulo natural para aprovechar la interposición de código. Como se muestra en la Figura 3(b), el controlador JDBC nativo es reemplazado por un controlador JDBC Ganesh que presenta la misma interfaz estandarizada. El controlador Ganesh mantiene una caché en memoria de fragmentos de resultados de consultas anteriores y realiza el reensamblaje de resultados. En la base de datos, agregamos un nuevo proceso llamado el proxy Ganesh. Este proxy, que puede ser compartido por múltiples nodos front-end, consta de dos partes: código para detectar similitud en fragmentos de resultados y el controlador JDBC nativo original que se comunica con la base de datos. El uso de un proxy en la base de datos hace que Ganesh sea independiente de la base de datos y simplifica la creación de prototipos y experimentación. Ganesh es capaz de trabajar con una amplia gama de bases de datos y aplicaciones, sin necesidad de realizar modificaciones en ninguna de ellas. 3.3 Caché basada en proxy El controlador JDBC nativo mostrado en la Figura 3(a) es un componente de código ligero suministrado por el proveedor de la base de datos. Su función principal es mediar la comunicación entre la aplicación y la base de datos remota. Reenvía consultas, almacena resultados completos y responde a solicitudes de la aplicación para ver partes de los resultados. El controlador JDBC de Ganesh mostrado en la Figura 3(b) presenta a la aplicación una interfaz idéntica a la proporcionada por el controlador nativo. Proporciona la capacidad de reconstruir resultados a partir de descripciones compactas basadas en hash enviadas por el proxy. Para realizar esta reconstrucción, el controlador mantiene una caché en memoria de los resultados recibidos recientemente. Esta caché solo se utiliza como fuente de fragmentos de resultados en la reconstrucción de resultados. El conductor Ganesh o el proxy no intentan rastrear las actualizaciones de la base de datos. La falta de consistencia en la caché no afecta a la corrección, ya que la descripción de los resultados siempre se obtiene del proxy; en el peor de los casos, no habrá beneficio de rendimiento al usar Ganesh. Los datos obsoletos simplemente se eliminarán de la caché con el tiempo. El proxy de Ganesh accede a la base de datos a través del controlador JDBC nativo, que permanece sin cambios entre las Figuras 3(a) y (b). La base de datos está completamente ajena a la existencia del proxy. El proxy no examina ninguna consulta recibida del controlador Ganesh, sino que las pasa al controlador nativo. En cambio, el proxy es responsable de inspeccionar la salida de la base de datos recibida del controlador nativo, detectar resultados similares y generar codificaciones basadas en hash de estos resultados siempre que se encuentre suficiente similitud. Si bien esta arquitectura no disminuye la carga en una base de datos, como se mencionó anteriormente en la Sección 2.1, es mucho más fácil replicar bases de datos para escalabilidad en una LAN que en una WAN. Para generar una codificación basada en hash, el proxy debe estar al tanto de qué fragmentos de resultados están disponibles en la caché de controladores de Ganesh. Un enfoque es ser optimista y asumir que todos los fragmentos de resultados están disponibles. Esto resultará en la transmisión inicial más pequeña posible de un resultado. Sin embargo, en casos donde hay poca superposición con resultados anteriores, el controlador Ganesh tendrá que realizar muchas llamadas al proxy durante la reconstrucción para recuperar fragmentos de resultados faltantes. Para evitar esta situación, el proxy sigue de manera flexible el estado de la caché de controladores de Ganesh. Dado que ambos componentes están bajo nuestro control, es relativamente sencillo hacer esto sin recurrir a técnicas de caja gris o comunicación explícita para mantener la coherencia de la caché. En cambio, el proxy simula el algoritmo de gestión de caché de controladores de Ganesh y lo utiliza para mantener una lista de hashes para los cuales es probable que el controlador de Ganesh posea los fragmentos de resultado. En caso de desviación de seguimiento, no habrá pérdida de corrección, pero habrá retrasos adicionales en el viaje de ida y vuelta para recuperar los fragmentos faltantes. Si el cliente detecta la pérdida de sincronización con el proxy, puede pedirle al proxy que restablezca el estado compartido entre ellos. También hay que tener en cuenta que el proxy no necesita guardar los fragmentos de resultado en sí, solo sus hashes. Esto permite que el proxy siga siendo escalable incluso cuando es compartido por muchos nodos front-end. El proxy Ganesh recibe la salida de la base de datos como objetos Java del controlador JDBC nativo. Examina esta salida para ver si está presente un objeto Java del tipo ResultSet. La interfaz JDBC utiliza este tipo de dato para almacenar los resultados de las consultas a la base de datos. Si se encuentra un objeto ResultSet, se reduce como se discute a continuación. Todos los demás objetos de Java se pasan sin modificar. Como se discute en la Sección 3.1, el proxy utiliza los límites de fila definidos en el ResultSet para dividirlo en fragmentos que consisten en filas de resultado individuales. Todos los objetos ResultSet se convierten en objetos de un nuevo tipo llamado RecipeResultSet. Utilizamos el término receta para esta descripción compacta de un resultado de base de datos debido a su similitud con una receta de archivo en el sistema de archivos CASPER [37]. La conversión reemplaza cada fragmento de resultado que probablemente esté presente en la caché de controladores de Ganesh por un hash SHA-1 de ese fragmento. Los fragmentos de resultados previamente no vistos se conservan textualmente. El proxy también retiene los hashes de los nuevos fragmentos de resultados, ya que estarán presentes en la caché de los controladores en el futuro. Ten en cuenta que el proxy solo almacena en caché los hashes de los fragmentos de resultados y no almacena en caché las recetas. El proxy construye un RecipeResultSet verificando la similitud en todo el resultado y luego a nivel de fila. Si se predice que todo el resultado estará presente en la caché de los controladores de Ganesh, el RecipeResultSet será simplemente un único hash de todo el resultado. De lo contrario, contiene hashes para aquellas filas que se predice que están presentes en esa caché; todas las demás filas se conservan textualmente. Si el proxy estima un ahorro de espacio general, transmitirá el RecipeResultSet. De lo contrario, se transmite el ResultSet original. Los objetos RecipeResultSet son transformados de vuelta en objetos ResultSet por el controlador Ganesh. La Figura 4 ilustra el manejo de ResultSet en ambos extremos. Cada hash SHA-1 encontrado en un RecipeResultSet se busca en la caché local de fragmentos de resultados. En caso de acierto, el hash es reemplazado por el fragmento correspondiente. En caso de error, el conductor contacta al proxy de Ganesh para recuperar el fragmento. Todos los fragmentos de resultados previamente no vistos que fueron retenidos textualmente por el proxy se hasheado y se han añadido a la caché de resultados. Debería haber muy pocos fallos si el proxy ha seguido con precisión el estado de la caché de controladores de Ganesh. Una optimización futura sería agrupar la obtención de fragmentos faltantes. Esto sería valioso cuando hay muchos pequeños fragmentos faltantes en una WAN de alta latencia. Una vez que la transformación esté completa, el objeto ResultSet completamente reconstruido se pasa a la aplicación. 4. VALIDACIÓN EXPERIMENTAL Tres preguntas surgen de los objetivos y diseño de Ganesh: • Primero, ¿se puede mejorar significativamente el rendimiento al explotar la similitud entre los resultados de la base de datos? Detalles del conjunto de datos de referencia 500,000 usuarios, 12,000 historias BBOARD 2.0 GB 3,298,000 comentarios SUBASTA 1.3 GB 1,000,000 usuarios, 34,000 elementos Tabla 1: Detalles del conjunto de datos de referencia • En segundo lugar, ¿qué tan importante es la detección de similitud estructural de Ganesh en comparación con la detección de similitud de la huella digital de Rabin? • En tercer lugar, ¿es aceptable la sobrecarga del diseño basado en proxy? Nuestra evaluación responde a estas preguntas a través de experimentos controlados con el prototipo Ganesh. Esta sección describe los puntos de referencia utilizados, nuestro procedimiento de evaluación y la configuración experimental. Los resultados de los experimentos se presentan en las Secciones 5, 6 y 7. 4.1 Puntos de referencia Nuestra evaluación se basa en dos puntos de referencia [18] que han sido ampliamente utilizados por otros investigadores para evaluar varios aspectos de arquitecturas multi-tier [27] y de comercio electrónico [9]. El primer punto de referencia, BBOARD, está modelado según Slashdot, un sitio de noticias orientado a la tecnología. El segundo punto de referencia, AUCTION, está modelado según eBay, un sitio de subastas en línea. En ambos puntos de referencia, la mayoría del contenido se genera dinámicamente a partir de la información almacenada en una base de datos. Los detalles de los conjuntos de datos utilizados se pueden encontrar en la Tabla 1. 4.1.1 El Benchmark BBOARD El benchmark BBOARD, también conocido como RUBBoS [18], modela Slashdot, un popular sitio web orientado a la tecnología. Slashdot recopila enlaces a noticias y otros temas de interés encontrados en otros lugares de la web. El sitio también funciona como un tablón de anuncios al permitir a los usuarios comentar en las historias publicadas en forma de conversación en hilos. No es raro que una historia recopile cientos de comentarios en cuestión de horas. El benchmark BBOARD es similar al sitio y modela las actividades de un usuario, incluyendo operaciones de solo lectura como navegar por las historias del día, explorar categorías de historias y ver comentarios, así como operaciones de escritura como registro de nuevos usuarios, agregar y moderar comentarios, y enviar historias. El benchmark consiste en tres fases diferentes: una fase de calentamiento corta, una fase de ejecución que representa el cuerpo principal de la carga de trabajo, y una fase de enfriamiento corta. En este documento solo informamos sobre los resultados de la fase de ejecución. La fase de calentamiento es importante para establecer el estado del sistema dinámico, pero las mediciones de esa fase no son significativas para nuestra evaluación. La fase de enfriamiento es únicamente para permitir que el punto de referencia se apague. Las fases de calentamiento, ejercicio y enfriamiento son de 2, 15 y 2 minutos respectivamente. El número de clientes simulados fue de 400, 800, 1200 y 1600. El punto de referencia está disponible en una versión de Java Servlets y PHP y tiene diferentes conjuntos de datos; evaluamos a Ganesh utilizando la versión de Java Servlets y el conjunto de datos Expandido. El benchmark BBOARD define dos cargas de trabajo diferentes. El primero, la mezcla de Autoría, consiste en un 70% de operaciones de solo lectura y un 30% de operaciones de lectura y escritura. El segundo, la mezcla de navegación, contiene solo operaciones de solo lectura y no actualiza la base de datos. 4.1.2 El Benchmark de SUBASTA El benchmark de SUBASTA, también conocido como RUBiS [18], modela eBay, el sitio de subastas en línea. El sitio web de eBay se utiliza para comprar y vender artículos a través de un formato de subasta. Las principales actividades de un usuario incluyen navegar, vender o pujar por artículos. Modelando las actividades en este sitio, este punto de referencia incluye actividades de solo lectura como navegar por artículos por categoría y por región, así como actividades de lectura-escritura como pujar por artículos, comprar y vender artículos, y dejar comentarios. Al igual que con BBOARD, el benchmark consiste en tres fases diferentes. Las fases de calentamiento, ejecución y enfriamiento para este experimento son de 1.5, 15 y 1 minutos respectivamente. Probamos Ganesh con cuatro configuraciones de clientes donde el número de clientes de prueba se estableció en 400, 800, 1200 y 1600. El punto de referencia está disponible en una versión de Enterprise Java Bean (EJB), Java Servlets y PHP y tiene diferentes conjuntos de datos; evaluamos Ganesh con la versión de Java Servlets y el conjunto de datos Expandido. El benchmark de SUBASTA define dos cargas de trabajo diferentes. El primero, la mezcla de Ofertas, consiste en un 70% de operaciones de solo lectura y un 30% de operaciones de lectura-escritura. El segundo, la mezcla de navegación, contiene solo operaciones de solo lectura y no actualiza la base de datos. 4.2 Procedimiento Experimental Ambos benchmarks involucran una carga de trabajo sintética de clientes accediendo a un servidor web. El número de clientes emulados es un parámetro experimental. Cada cliente emulado ejecuta una instancia del benchmark en su propio hilo, utilizando una matriz para hacer la transición entre diferentes estados del benchmark. La matriz define un modelo estocástico con probabilidades de transición entre los diferentes estados que representan las acciones típicas de los usuarios. Un ejemplo de transición es un usuario iniciando sesión en el sistema de SUBASTA y luego decidiendo si publicar un artículo en venta o pujar en subastas activas. Cada cliente también modela el tiempo de pensamiento del usuario entre las solicitudes. El tiempo de pensamiento se modela como una distribución exponencial con una media de 7 segundos. Evaluamos a Ganesh a lo largo de dos ejes: número de clientes y ancho de banda de la WAN. Las cargas más altas son especialmente útiles para comprender el rendimiento de Ganesh cuando la CPU o el disco del servidor de base de datos o del proxy son el factor limitante. Un estudio previo ha demostrado que aproximadamente el 50% de los cuellos de botella de Internet de gran área observados tenían un ancho de banda disponible inferior a 10 Mb/s [1]. Basándonos en este trabajo, enfocamos nuestra evaluación en el ancho de banda de la WAN de 5 Mb/s con una latencia de ida y vuelta de 66 ms, representativa de rutas de red severamente restringidas, y 20 Mb/s con una latencia de ida y vuelta de 33 ms, representativa de una ruta de red moderadamente restringida. También informamos sobre el rendimiento de Ganesh a 100 Mb/s sin agregar latencia de ida y vuelta. Este ancho de banda, representativo de una red sin restricciones, es especialmente útil para revelar cualquier sobrecarga potencial de Ganesh en situaciones donde el ancho de banda de la WAN no es el factor limitante. Para cada combinación de número de clientes y ancho de banda de WAN, medimos los resultados de las dos configuraciones enumeradas a continuación: • Nativa: Esta configuración corresponde a la Figura 3(a). El nativo evita la sobrecarga de Ganesh al usar un proxy y realizar la serialización de objetos Java. • Ganesh: Esta configuración corresponde a la Figura 3(b). Para un número dado de clientes y ancho de banda de WAN, comparar estos resultados con los resultados nativos correspondientes proporciona el beneficio de rendimiento debido al sistema de middleware Ganesh. La métrica utilizada para cuantificar la mejora en el rendimiento es el número de solicitudes de clientes que pueden ser atendidas por segundo. La métrica utilizada para cuantificar el rendimiento de Ganesh es el tiempo promedio de respuesta para una solicitud de cliente. Para todos los experimentos, el controlador Ganesh utilizado por el servidor de aplicaciones usó un tamaño de caché de 100,000 elementos. El proxy fue efectivo en rastrear el estado de la caché de los controladores Ganesh; para todos nuestros experimentos, la tasa de fallos en el controlador nunca superó el 0.7%. 4.3 Configuración Experimental La configuración experimental utilizada para las pruebas se puede ver en la Figura 5. Todas las máquinas eran Pentium 4 de 3.2 GHz (con HyperThreading habilitado). Con la excepción del servidor de base de datos, todas las máquinas tenían 2 GB de SDRAM y ejecutaban la distribución de Linux Fedora Core. El servidor de la base de datos tenía 4 GB de SDRAM. Utilizamos Apache Tomcat como tanto el servidor de aplicaciones que alojaba los Servlets de Java como el servidor web. Ambos benchmarks utilizaron Java Servlets para generar el contenido dinámico. El servidor de la base de datos utilizó la base de datos de código abierto MySQL. Para los controladores JDBC nativos, utilizamos los controladores Connector/J proporcionados por MySQL. El servidor de aplicaciones utilizaba la Máquina Virtual de Java de Sun como entorno de ejecución para los Servlets de Java. La herramienta sysstat se utilizó para monitorear la utilización de la CPU, red, disco y memoria en todas las máquinas. Las máquinas estaban conectadas por una red Ethernet gigabit conmutada. Como se muestra en la Figura 5, el servidor web y de aplicación de front-end fue separado del servidor de proxy y base de datos por un enrutador NetEm [16]. Este enrutador nos permitió controlar la configuración de ancho de banda y latencia en la red. El enrutador NetEm es un PC estándar con dos tarjetas de red que ejecuta el software de Control de Tráfico de Linux y Emulación de Red. Las restricciones de ancho de banda y latencia solo se aplicaron al enlace entre el servidor de aplicaciones y la base de datos para el caso nativo y entre el servidor de aplicaciones y el proxy para el caso de Ganesh. No hay comunicación entre el servidor de aplicaciones y la base de datos con Ganesh, ya que todos los datos fluyen a través del proxy. Como nuestro enfoque estaba en el enlace WAN entre el servidor de aplicaciones y la base de datos, no hubo restricciones en el enlace entre los clientes de prueba simulados y el servidor web. 5. DESEMPEÑO Y TIEMPO DE RESPUESTA En esta sección, abordamos la primera pregunta planteada en la Sección 4: ¿Se puede mejorar significativamente el rendimiento explotando la similitud entre los resultados de la base de datos? Para responder a esta pregunta, utilizamos los resultados de los benchmarks BBOARD y AUCTION. Utilizamos dos métricas para cuantificar la mejora en el rendimiento obtenible a través del uso de Ganesh: el throughput, desde la perspectiva del servidor web, y el tiempo de respuesta promedio, desde la perspectiva del cliente. El rendimiento se mide en términos del número de solicitudes de clientes que pueden ser atendidas por segundo. Los resultados y análisis de BBOARD 5.1 Figuras 6 (a) y (b) presentan el número promedio de solicitudes atendidas por segundo y el tiempo de respuesta promedio para estas solicitudes tal como lo perciben los clientes para la Mezcla de Autoría de BBOARD. Como muestra la Figura 6 (a), Native satura fácilmente el enlace de 5 Mb/s. Con 400 clientes, la solución nativa entrega 29 solicitudes/segundo con un tiempo de respuesta promedio de 8.3 segundos. La capacidad de procesamiento de los clientes disminuye con un aumento en los clientes de prueba, ya que los clientes se agotan debido a la congestión en el servidor de aplicaciones. Los estudios de usabilidad han demostrado que los tiempos de respuesta superiores a 10 segundos hacen que el usuario pase a 1. Dado que Java carece de un operador sizeof(), los cachés de Java limitan su tamaño en función del número de objetos. El tamaño de los volcados de caché tomados al final de los experimentos nunca superó los 212 MB. WWW 2007 / Pista: Rendimiento y Escalabilidad Sesión: Sistemas Escalables para Contenido Dinámico 315 0 50 100 150 200 250 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Solicitudes de Clientes de Prueba por Segundo Nativo Ganesh 0.001 0.01 0.1 1 10 100 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Tiempo Promedio de Respuesta de Clientes de Prueba Nativo Ganesh Nota Escala Logarítmica (a) Rendimiento: Mezcla de Autoría (b) Tiempo de Respuesta: Mezcla de Autoría 0 50 100 150 200 250 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Solicitudes de Clientes de Prueba por Segundo Nativo Ganesh 0.001 0.01 0.1 1 10 100 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Tiempo Promedio de Respuesta de Clientes de Prueba Nativo Ganesh Nota Escala Logarítmica (c) Rendimiento: Mezcla de Navegación (d) Tiempo de Respuesta: Mezcla de Navegación Promedio de tres pruebas. La desviación estándar máxima para el rendimiento y el tiempo de respuesta fue del 9.8% y 11.9% de la media correspondiente. Figura 6: BBOARD Benchmark - Rendimiento y Tiempo de Respuesta Promedio de otras tareas [24]. Basándose en estos números, aumentar el número de clientes de prueba hace que el sistema Nativo sea inutilizable. Ganesh a 5 Mb/s, sin embargo, ofrece una mejora doble con 400 clientes de prueba y una mejora quintuple con 1200 clientes. El rendimiento de Ganesh disminuye ligeramente a 1200 y 1600 clientes debido a que la red está saturada. En comparación con Native, la Figura 6 (b) muestra que los tiempos de respuesta de Ganesh son considerablemente más bajos con tiempos de respuesta de menos de un segundo con 400 clientes. La Figura 6 (a) también muestra que para 400 y 800 clientes de prueba, Ganesh a 5 Mb/s tiene el mismo rendimiento y tiempo de respuesta promedio que Native a 20 Mb/s. Solo con 1200 y 1600 clientes, Native a 20 Mb/s ofrece un rendimiento mayor que Ganesh a 5 Mb/s. Al comparar tanto a Ganesh como a Native a 20 Mb/s, vemos que Ganesh ya no está limitado por el ancho de banda y ofrece hasta una mejora del doble sobre Native con 1600 clientes de prueba. Como Ganesh no satura la red con configuraciones de cliente de prueba más altas, con 1600 clientes de prueba, su tiempo de respuesta promedio es de 0.1 segundos en lugar de los 7.7 segundos de Natives. Como era de esperar, no hay ganancias visibles de Ganesh en el ancho de banda más alto de 100 Mb/s donde la red ya no es el cuello de botella. Sin embargo, Ganesh sigue monitoreando a Native en cuanto a rendimiento. Las Figuras 6 (c) y (d) presentan el número promedio de solicitudes atendidas por segundo y el tiempo de respuesta promedio para estas solicitudes tal como lo perciben los clientes para la Mezcla de Navegación de BBOARDs. Independientemente de la configuración del cliente de prueba, la Figura 6 (c) muestra que el rendimiento de los Nativos a 5 Mb/s está limitado a 10 reqs/seg. Ganesh a 5 Mb/s con 400 clientes de prueba, ofrece un aumento de más de seis veces en el rendimiento. La mejora aumenta a más de once veces a 800 clientes de prueba antes de que Ganesh sature la red. Además, la Figura 6 (d) muestra que el tiempo de respuesta promedio de los Nativos de 35 segundos con 400 clientes de prueba hace que el sistema sea inutilizable. Estos altos tiempos de respuesta aumentan aún más con la adición de clientes de prueba. Incluso con la configuración del cliente de prueba de 1600, Ganesh ofrece un tiempo de respuesta promedio aceptable de 8.2 segundos. Debido a la naturaleza intensiva en datos de la mezcla de navegación, Ganesh a 5 Mb/s sorprendentemente tiene un rendimiento mucho mejor que Native a 20 Mb/s. Además, como se muestra en la Figura 6 (d), si bien el tiempo de respuesta promedio para Native a 20 Mb/s es aceptable con 400 clientes de prueba, resulta inutilizable con 800 clientes de prueba, con un tiempo de respuesta promedio de 15.8 segundos. Al igual que en el caso de 5 Mb/s, este tiempo de respuesta aumenta con la adición de clientes de prueba adicionales. Ganesh a 20 Mb/s y tanto Native como Ganesh a 100 Mb/s no tienen limitaciones de ancho de banda. Sin embargo, el rendimiento se estanca después de 1200 clientes de prueba debido a que la CPU de la base de datos está saturada. 5.1.3 Variante de filtro Nos sorprendió el rendimiento nativo del benchmark BBOARD. A una velocidad de banda ancha de 5 Mb/s, el rendimiento nativo fue más bajo de lo que esperábamos. Resultó que el código de referencia que muestra historias leía todos los comentarios asociados con la historia en particular de la base de datos y solo entonces realizaba un postprocesamiento para seleccionar los comentarios que se mostrarían. Si bien este es exactamente el comportamiento de SlashCode, la base de código detrás del sitio web de Slashdot, decidimos modificar la prueba de rendimiento para realizar cierto prefiltrado en la base de datos. Este benchmark modificado, llamado el Filtro de Variantes, modela a un desarrollador que aplica optimizaciones a nivel de SQL para transferir menos datos. En aras de la brevedad, solo resumimos brevemente los resultados de la mezcla de autores. Para la mezcla de Autoría, con 800 clientes de prueba a 5 Mb/s, la Figura 7 (a) muestra que el rendimiento de Natives aumenta un 85% en comparación con el punto de referencia original, mientras que la mejora de Ganesh es menor, del 15%. El rendimiento de los servidores disminuye por encima de los 800 clientes, ya que los clientes de prueba se agotan debido a los altos tiempos de respuesta. La ganancia más significativa para Native se observa a 20 Mb/s. En 1600 clientes de prueba, en comparación con el punto de referencia original, Native experimenta una mejora del 73% en el rendimiento y una reducción del 77% en el tiempo de respuesta promedio. Mientras WWW 2007 / Pista: Rendimiento y Escalabilidad Sesión: Sistemas Escalables para Contenido Dinámico 316 0 50 100 150 200 250 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Clientes de Prueba Solicitudes/seg Nativo Ganesh 0.001 0.01 0.1 1 10 100 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Clientes de Prueba Tiempo de Resp. Promedio (seg) Nativo Ganesh Nota Escala Logarítmica (a) Rendimiento: Mezcla de Autoría (b) Tiempo de Respuesta: Mezcla de Autoría Promedio de tres pruebas. La desviación estándar máxima para el rendimiento y el tiempo de respuesta fue del 7.2% y del 11.5% de la media correspondiente. Figura 7: BBOARD Benchmark - Variante de filtro - Rendimiento y Tiempo de Respuesta Promedio Ganesh no observa ninguna mejora en comparación con el original, aún procesa un 19% más de solicitudes/seg que Native. Por lo tanto, aunque las optimizaciones fueron más útiles para Native, Ganesh todavía ofrece una mejora en el rendimiento. 5.2 Resultados y Análisis de la SUBASTA 5.2.1 Figuras de la Mezcla de Ofertas Los gráficos 8 (a) y (b) presentan el número promedio de solicitudes atendidas por segundo y el tiempo de respuesta promedio para estas solicitudes tal como son percibidas por los clientes para la Mezcla de Ofertas de las SUBASTAS. Como se mencionó anteriormente, la mezcla de ofertas consiste en una combinación de operaciones de lectura y escritura. El benchmark AUCTION no es tan intensivo en datos como BBOARD. Por lo tanto, la mayoría de las ganancias se observan en el ancho de banda más bajo de 5 Mb/s. La figura 8 (a) muestra que el aumento en el rendimiento debido a Ganesh varía desde un 8% con 400 clientes de prueba hasta un 18% con 1600 clientes de prueba. Como se observa en la Figura 8 (b), los tiempos de respuesta promedio para Ganesh son significativamente más bajos que los de Native, con una disminución del 84% a 800 clientes de prueba y del 88% a 1600 clientes de prueba. La Figura 8 (a) también muestra que con un aumento cuádruple del ancho de banda de 5 Mb/s a 20 Mb/s, Native ya no está limitado por el ancho de banda y no hay diferencia de rendimiento entre Ganesh y Native. Con las configuraciones de cliente de prueba más altas, observamos que el ancho de banda utilizado por Ganesh era menor que el de Nativo. Ganesh podría seguir siendo útil en estos escenarios no restringidos si se compra ancho de banda de forma medible. Se observan resultados similares para el escenario de 100 Mb/s. 5.2.2 Mezcla de Navegación Para la Mezcla de Navegación de SUBASTAS, las Figuras 8 (c) y (d) presentan el número promedio de solicitudes atendidas por segundo y el tiempo promedio de respuesta para estas solicitudes tal como lo perciben los clientes. Una vez más, la mayoría de las ganancias se observan en anchos de banda más bajos. A 5 Mb/s, Native y Ganesh ofrecen un rendimiento y tiempos de respuesta similares con 400 clientes de prueba. Mientras que el rendimiento para ambos permanece igual en 800 clientes de prueba, la Figura 8 (d) muestra que el tiempo de respuesta promedio de Ganesh es un 62% menor que el de Native. El servidor satura el enlace con 800 clientes y agregar clientes de prueba adicionales solo aumenta el tiempo promedio de respuesta. Ganesh, independientemente de la configuración del cliente de prueba, no tiene restricciones de ancho de banda y mantiene el mismo tiempo de respuesta. A 1600 clientes de prueba, la Figura 8 (c) muestra que el rendimiento de Ganesh es casi el doble que el de Nativo. En los anchos de banda más altos de 20 y 100 Mb/s, ni Ganesh ni Native tienen limitaciones de ancho de banda y ofrecen un rendimiento y tiempos de respuesta equivalentes. Referencia original. Tamaño Ganesh Tamaño Rabin Tamaño SelectSort1 223.6 MB 5.4 MB 219.3 MB SelectSort2 223.6 MB 5.4 MB 223.6 MB Tabla 2: Microbenchmarks de similitud 6. SIMILITUD ESTRUCTURAL VS. SIMILITUD DE RABIN En esta sección, abordamos la segunda pregunta planteada en la Sección 4: ¿Qué tan importante es la detección de similitud estructural de Ganesh en comparación con la detección de similitud basada en la huella digital de Rabin? Para responder a esta pregunta, utilizamos microbenchmarks y los benchmarks BBOARD y AUCTION. Dado que Ganesh siempre tuvo un mejor rendimiento que Rabin en la huella dactilar, aquí presentamos solo un subconjunto de los resultados en aras de la brevedad. 6.1 Microbenchmarks Dos microbenchmarks muestran un ejemplo de los efectos de la reordenación de datos en el algoritmo de huella dactilar de Rabin. En el primer microbenchmark, SelectSort1, una consulta con un orden de clasificación especificado selecciona 223.6 MB de datos distribuidos en aproximadamente 280 K filas. La consulta se repite entonces con un atributo de ordenación diferente. Si bien se devuelve el mismo número de filas y los mismos datos, el orden de las filas es diferente. En un escenario así, se esperaría detectar una gran cantidad de similitud entre ambos resultados. Como muestra la Tabla 2, el algoritmo basado en filas de Ganesh logra una reducción del 97.6%, mientras que el algoritmo de huella digital de Rabin, con el parámetro de tamaño de fragmento promedio establecido en 4 KB, solo logra una reducción del 1%. La razón, como se muestra anteriormente en la Figura 2, es que con la huella digital de Rabin, los tramos de datos entre dos límites consecutivos suelen cruzar los límites de fila. Con el cambio en el orden de las filas en el segundo resultado y los fingerprints de Rabin ahora abarcando diferentes filas, el algoritmo no puede detectar similitud significativa. La pequeña ganancia observada se debe principalmente a aquellas filas individuales que son lo suficientemente grandes como para dividirse en múltiples fragmentos. SelectSort2, otro micro-benchmark ejecutó las mismas consultas pero aumentó el tamaño mínimo del fragmento del algoritmo de huella digital de Rabin. Como se puede ver en la Tabla 2, incluso la pequeña ganancia del microbenchmark anterior desaparece cuando el tamaño mínimo de fragmento fue mayor que el tamaño promedio de fila. Si bien se pueden abordar parcialmente estos problemas variando dinámicamente los parámetros del algoritmo de huella digital de Rabin, esto puede resultar computacionalmente costoso, especialmente en presencia de cargas de trabajo cambiantes. 6.2 Benchmarks de Aplicación Ejecutamos el benchmark BBOARD descrito en la Sección 4.1.1 en dos versiones de Ganesh: la primera con la huella digital de Rabin utilizada como WWW 2007 / Track: Sesión de Rendimiento y Escalabilidad: Sistemas Escalables para Contenido Dinámico 317 0 50 100 150 200 250 300 350 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Clientes de Prueba Solicitudes/seg Ganesh Nativo 0.001 0.01 0.1 1 10 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Clientes de Prueba Tiempo de Respuesta Promedio (seg) Ganesh Nativo Nota Escala Logarítmica (a) Rendimiento: Mezcla de Ofertas (b) Tiempo de Respuesta: Mezcla de Ofertas 0 50 100 150 200 250 300 350 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Clientes de Prueba Solicitudes/seg Ganesh Nativo 0.001 0.01 0.1 1 10 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Clientes de Prueba Tiempo de Respuesta Promedio (seg) Ganesh Nativo Nota Escala Logarítmica (c) Rendimiento: Mezcla de Navegación (d) Tiempo de Respuesta: Mezcla de Navegación Promedio de tres pruebas. La desviación estándar máxima para el rendimiento y el tiempo de respuesta fue del 2.2% y del 11.8% de la media correspondiente. Figura 8: Referencia de la subasta AUCTION - Rendimiento y Tiempo de Respuesta Promedio del algoritmo de fragmentación y el segundo con el algoritmo basado en filas de Ganesh. Los resultados de Rabins para la Mezcla de Navegación se normalizan con los resultados de Ganesh y se presentan en la Figura 9. Como muestra la Figura 9 (a), a 5 Mb/s, independientemente de la configuración del cliente de prueba, Rabin tiene un rendimiento significativamente inferior a Ganesh. Esto sucede debido a una combinación de dos razones. Primero, como se describe en la Sección 3.1, Rabin encuentra menos similitud ya que no explota la información estructural de los resultados. Segundo, este punto de referencia contenía algunas consultas que generaron resultados grandes. En este caso, Rabin, con un tamaño de fragmento promedio pequeño, generó una gran cantidad de objetos que desplazaron otros datos útiles de la caché. Por el contrario, Ganesh pudo detectar estas filas grandes y aumentar correspondientemente el tamaño de los bloques. Esto fue confirmado ya que las estadísticas de caché mostraron que la proporción de aciertos de Ganesh era aproximadamente tres veces mayor que la de Rabin. Las mediciones de rendimiento a 20 Mb/s fueron similares, con la excepción del rendimiento de Rabins con 400 clientes de prueba. En este caso, Ganesh no estaba limitado por la red y, de hecho, el rendimiento era el mismo que el de 400 clientes a 5 Mb/s. Rabin, sin embargo, aprovechó el aumento del ancho de banda de 5 a 20 Mb/s para ofrecer un rendimiento ligeramente mejor. A 100 Mb/s, el rendimiento de Rabin era casi similar al de Ganesh ya que el ancho de banda ya no era un cuello de botella. El tiempo de respuesta normalizado, presentado en la Figura 9 (b), muestra tendencias similares. A 5 y 20 Mb/s, la adición de clientes de prueba disminuye el tiempo de respuesta normalizado, ya que el tiempo de respuesta promedio de Ganesh aumenta más rápido que el de Rabin. Sin embargo, en ningún momento Rabin supera a Ganesh. Ten en cuenta que con 400 y 800 clientes a 100 Mb/s, Rabin tiene un mayor sobrecosto incluso cuando no está limitado por el ancho de banda. Como se menciona en la Sección 3.1, esto se debe a que Rabin tiene que hashear cada ResultSet dos veces. La sobrecarga desaparece con 1200 y 1600 clientes, ya que la CPU de la base de datos está saturada y limita el rendimiento tanto de Ganesh como de Rabin. 7. SUPERPOSICIÓN DE PROXY En esta sección, abordamos la tercera pregunta planteada en la Sección 4: ¿Es aceptable la superposición del diseño basado en proxy de Ganesh? Para responder a esta pregunta, nos concentramos en su rendimiento en las bandas de mayor ancho de banda. Nuestra evaluación en la Sección 5 mostró que Ganesh, en comparación con Native, puede ofrecer una mejora sustancial en el rendimiento a anchos de banda más bajos. Solo en anchos de banda más altos serían visibles los costos adicionales de latencia, medidos por el tiempo promedio de respuesta para una solicitud de cliente, y de rendimiento, medidos por la cantidad de solicitudes de cliente que pueden ser atendidas por segundo. Al observar la combinación de autoría del benchmark original de BBOARD, no se aprecian ganancias visibles de Ganesh a 100 Mb/s. Sin embargo, Ganesh sigue rastreando a Native en cuanto a rendimiento. Si bien el tiempo promedio de respuesta es mayor para Ganesh, la diferencia absoluta está entre 0.01 y 0.04 segundos y sería imperceptible para el usuario final. La mezcla de navegación muestra una diferencia aún menor en los tiempos de respuesta promedio. Los resultados de la variante del filtro de los benchmarks de BBOARD son similares. Incluso para el benchmark de SUBASTA, la diferencia entre el tiempo de respuesta de Nativo y Ganesh a 100 Mb/s nunca fue mayor a 0.02 segundos. La única excepción a los resultados anteriores se observó en la variante de filtro del benchmark BBOARD, donde Ganesh con 1600 clientes de prueba añadió 0.85 segundos al tiempo de respuesta promedio. Por lo tanto, incluso para redes mucho más rápidas donde el enlace WAN no es el cuello de botella, Ganesh siempre ofrece un rendimiento equivalente al Nativo. Si bien se agrega algo de latencia adicional debido al diseño basado en proxy, generalmente es imperceptible. TRABAJO RELACIONADO Hasta donde sabemos, Ganesh es el primer sistema que combina el uso de técnicas basadas en hash con el almacenamiento en caché de resultados de base de datos para mejorar el rendimiento y los tiempos de respuesta de aplicaciones con contenido dinámico. También creemos que es el primer sistema en demostrar los beneficios de utilizar información estructural para WWW 2007 / Track: Rendimiento y Escalabilidad Sesión: Sistemas Escalables para Contenido Dinámico 318 0.0 0.2 0.4 0.6 0.8 1.0 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Clientes de Prueba Rendimiento Normalizado 31.8 3.8 2.8 2.3 23.8 32.8 5.8 3.6 1.8 2.1 1.1 1.0 0 5 10 15 20 25 30 35 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Clientes de Prueba Tiempo de Respuesta Normalizado (a) Rendimiento Normalizado: Mayor es mejor (b) Tiempo de Respuesta Normalizado: Mayor es peor Para el rendimiento, un resultado normalizado mayor que 1 implica que Rabin es mejor. Para el tiempo de respuesta, un resultado normalizado mayor que 1 implica que Ganesh es mejor. Media de tres pruebas. La desviación estándar máxima para el rendimiento y el tiempo de respuesta fue del 9.1% y del 13.9% de la media correspondiente. Figura 9: Comparación normalizada de Ganesh vs. Rabin - Mezcla de navegación BBOARD detectando similitud. En esta sección, primero discutimos enfoques alternativos para almacenar en caché contenido dinámico y luego examinamos otros usos de primitivas basadas en hash en sistemas distribuidos. 8.1 Almacenamiento en Caché de Contenido Dinámico En la capa de base de datos, varios sistemas han abogado por la caché de nivel intermedio donde partes de la base de datos se replican en el borde o servidor [3, 4, 20]. Estos sistemas almacenan en caché tablas completas en lo que es esencialmente una base de datos replicada o utilizan vistas materializadas de respuestas de consultas anteriores [19]. Requieren una integración estrecha con la base de datos del sistema para garantizar un límite de tiempo en la propagación de actualizaciones. Estos sistemas suelen estar dirigidos a cargas de trabajo que no requieren una consistencia estricta y pueden tolerar datos obsoletos. Además, a diferencia de Ganesh, algunas de estas soluciones de almacenamiento en caché de nivel medio [2, 3], sufren de la complejidad de tener que participar en la planificación de consultas y el procesamiento de consultas distribuidas. Gao et al. [15] proponen utilizar una arquitectura de replicación de objetos distribuidos donde los requisitos de consistencia de las tiendas de datos se adaptan según la aplicación. Estas soluciones requieren recursos sustanciales de desarrollo y un entendimiento detallado de la aplicación que se está modificando. Si bien existen sistemas que intentan automatizar la partición y replicación de la base de datos de una aplicación [34], no proporcionan semántica de transacciones completa. En comparación, Ganesh no debilita ninguna de las semánticas proporcionadas por la base de datos subyacente. El trabajo reciente en la evaluación de opciones de almacenamiento en caché de borde para sitios web dinámicos [38] ha sugerido que, sin una planificación cuidadosa, el empleo de estrategias complejas de descarga puede perjudicar el rendimiento. En cambio, el trabajo aboga por una arquitectura en la que todos los niveles, excepto la base de datos, deberían ser trasladados al borde. Nuestra evaluación de Ganesh ha demostrado que sería beneficioso para estos escenarios. Para mejorar la escalabilidad de la base de datos, C-JDBC [10], SSS [22] y Ganymed [28] también abogan por el uso de una arquitectura basada en interposición para clusterizar y replicar bases de datos de forma transparente a nivel de middleware. Los enfoques de estas arquitecturas y Ganesh son complementarios y se beneficiarían mutuamente. Avanzando hacia la capa de presentación, se ha producido una amplia adopción de la caché basada en fragmentos [14], la cual mejora la utilización de la caché al almacenar por separado diferentes partes de las páginas web generadas. Si bien el almacenamiento en caché basado en fragmentos funciona en el borde, una propuesta reciente ha propuesto trasladar el ensamblaje de páginas web a los clientes para optimizar la entrega de contenido [31]. Si bien Ganesh no se utiliza en la capa de presentación, los mismos principios se han aplicado en la Detección de Transferencias Duplicadas [25] para aumentar la eficiencia de la caché web, así como para el acceso web a través de enlaces con ancho de banda limitado [33]. 8.2 Sistemas basados en hash En los últimos años han surgido muchos sistemas que explotan técnicas basadas en hash. En el centro de todos estos sistemas se encuentra la idea de detectar similitudes en los datos sin necesidad de interpretar esos datos. Esta idea simple pero elegante se basa en el hash criptográfico, como se discutió anteriormente en la Sección 2. Las aplicaciones exitosas de esta idea abarcan una amplia gama de sistemas de almacenamiento. Los ejemplos incluyen la copia de seguridad entre pares de archivos informáticos personales [11], el archivado eficiente de datos [29] y la búsqueda de archivos similares [21]. Spring y Wetherall [35] aplican principios similares a nivel de red. Utilizando cachés sincronizadas en ambos extremos de un enlace de red, los datos duplicados son reemplazados por tokens más pequeños para su transmisión y luego restaurados en el extremo remoto. Este y otros sistemas basados en hash como los sistemas de archivos CASPER [37] y LBFS [26], y optimizadores de ancho de banda de Capa-2 como Riverbed y Peribit utilizan la huella digital de Rabin [30] para descubrir tramos de similitud en los datos. Este enfoque es especialmente útil cuando los elementos de datos son modificados en su lugar a través de inserciones, eliminaciones y actualizaciones. Sin embargo, como se muestra en la Sección 6, el rendimiento de esta técnica puede experimentar una caída dramática en presencia de reordenamiento de datos. Ganesh en cambio utiliza los límites de fila como divisores para detectar similitudes. El uso más agresivo de técnicas basadas en hash es por sistemas que utilizan hashes como identificadores principales para objetos en almacenamiento persistente. Los sistemas de almacenamiento como CFS [12] y PAST [13] que han sido construidos utilizando tablas hash distribuidas entran en esta categoría. Single Instance Storage [6] y Venti [29] son otros ejemplos de tales sistemas. Como se discute en la Sección 2.2, el uso de hashes criptográficos para abordar datos persistentes representa un nivel más profundo de confianza en su resistencia a colisiones que la asumida por Ganesh. Si el tiempo revela deficiencias en el algoritmo hash, el esfuerzo necesario para corregir la falla es mucho mayor. En Ganesh, simplemente se trata de reemplazar el algoritmo hash. 9. CONCLUSIÓN El creciente uso de contenido web dinámico generado a partir de bases de datos relacionales aumenta las demandas de ancho de banda de la WAN. Las soluciones de almacenamiento en caché tradicionales para reducir el ancho de banda y la latencia suelen ser ineficaces para este tipo de contenido. Este documento muestra que el impacto de los accesos a bases de datos a través de WAN puede reducirse sustancialmente mediante la arquitectura Ganesh sin comprometer la estricta semántica de consistencia de las bases de datos. La esencia de la arquitectura Ganesh es el uso de la computación en los bordes para reducir la comunicación a través de Internet. Ganesh es capaz de utilizar hashes criptográficos para detectar similitud con resultados anteriores y enviar recetas compactas de resultados en lugar de resultados completos en la sesión de Sistemas Escalables para Contenido Dinámico 319 de WWW 2007 / Track: Rendimiento y Escalabilidad. Nuestro diseño utiliza la interposición para lograr una transparencia completa: los clientes, los servidores de aplicaciones y los servidores de bases de datos no son conscientes de la presencia de Ganesh y no requieren ninguna modificación. Nuestra evaluación experimental confirma que Ganesh, aunque conceptualmente simple, puede ser altamente efectivo en mejorar el rendimiento y el tiempo de respuesta. Nuestros resultados también confirman que aprovechar la estructura presente en los resultados de la base de datos para detectar similitudes es crucial para esta mejora en el rendimiento. REFERENCIAS [1] AKELLA, A., SESHAN, S., Y SHAIKH, A. Una evaluación empírica de los cuellos de botella en Internet de área amplia. En Proc. 3ª Conferencia ACM SIGCOMM sobre Medición de Internet (Miami Beach, FL, EE. UU., Oct. 2003), pp. 101-114. [2] ALTINEL, M., BORNH ¨OVD, C., KRISHNAMURTHY, S., MOHAN, C., PIRAHESH, H., Y REINWALD, B. Tablas de caché: allanando el camino para una caché de base de datos adaptativa. En Proc. del 29º VLDB (Berlín, Alemania, 2003), pp. 718-729. [3] ALTINEL, M., LUO, Q., KRISHNAMURTHY, S., MOHAN, C., PIRAHESH, H., LINDSAY, B. G., WOO, H., Y BROWN, L. Dbcache: Caché de base de datos para servidores de aplicaciones web. En Proc. 2002 ACM SIGMOD (2002), pp. 612-612. [4] AMIRI, K., PARK, S., TEWARI, R., Y PADMANABHAN, S. Dbproxy: una caché de datos dinámica para aplicaciones web. En Proc. Conferencia Internacional de Ingeniería de Datos de IEEE (ICDE) (Mar. 2003). [5] BLACK, J. Compare-by-hash: Un análisis razonado. En Proc. Conferencia Técnica Anual USENIX 2006 (Boston, MA, mayo de 2006), pp. 85-90. [6] BOLOSKY, W. J., CORBIN, S., GOEBEL, D., y DOUCEUR, J. R. Almacenamiento de instancia única en Windows 2000. En Proc. 4to Simposio de Sistemas Windows de USENIX (Seattle, WA, ago. 2000), pp. 13-24. [7] BREWER, E. A. Lecciones de servicios a gran escala. IEEE Internet Computing 5, 4 (2001), 46-55. [8] BRODER, A., GLASSMAN, S., MANASSE, M., AND ZWEIG, G. Agrupamiento sintáctico de la web. En Proc. 6ta Conferencia Internacional WWW (1997). [9] CECCHET, E., CHANDA, A., ELNIKETY, S., MARGUERITE, J., Y ZWAENEPOEL, W. Comparación de rendimiento de arquitecturas de middleware para generar contenido web dinámico. En Proc. Cuarta Conferencia Internacional de Middleware ACM/IFIP/USENIX (Río de Janeiro, Brasil, junio de 2003). [10] CECCHET, E., MARGUERITE, J., Y ZWAENEPOEL, W. C-JDBC: Middleware flexible de agrupación de bases de datos. En Proc. Conferencia Técnica Anual USENIX 2004 (Boston, MA, junio de 2004). [11] COX, L. P., MURRAY, C. D., Y NOBLE, B. D. Pastiche: Haciendo que la copia de seguridad sea barata y fácil. En OSDI: Simposio sobre Diseño e Implementación de Sistemas Operativos (2002). [12] DABEK, F., KAASHOEK, M. F., KARGER, D., MORRIS, R., Y STOICA, I. Almacenamiento cooperativo de amplia área con CFS. En el 18º Simposio ACM sobre Principios de Sistemas Operativos (Banff, Canadá, octubre de 2001). [13] DRUSCHEL, P., Y ROWSTRON, A. PASADO: Una utilidad de almacenamiento entre pares a gran escala y persistente. En HotOS VIII (Schloss Elmau, Alemania, mayo de 2001), pp. 75-80. [14] Incluye el lado del borde. http://www.esi.org. [15] GAO, L., DAHLIN, M., NAYATE, A., ZHENG, J., Y IYENGAR, A. Replicación de datos específica de la aplicación para servicios en el borde. En WWW 03: Proc. Duodécima Conferencia Internacional sobre la World Wide Web (2003), pp. 449-460. [16] HEMMINGER, S. Netem - emulando redes reales en el laboratorio. En Proc. 2005 Linux Conference Australia (Canberra, Australia, Abr. 2005). [17] HENSON, V. Un análisis de compare-by-hash. En Proc. 9º Taller sobre Temas Candentes en Sistemas Operativos (HotOS IX) (mayo de 2003), pp. 13-18. [18] Benchmarks de Jmob. http://jmob.objectweb.org/. [19] LABRINIDIS, A., Y ROUSSOPOULOS, N. Equilibrando el rendimiento y la frescura de los datos en servidores de bases de datos web. En Proc. 29ª Conferencia VLDB (Sept. 2003). [20] LARSON, P.-A., GOLDSTEIN, J., Y ZHOU, J. Caché transparente de bases de datos en el nivel intermedio en SQL Server. En Proc. 2003 ACM SIGMOD (2003), pp. 661-661. [21] MANBER, U. Encontrar archivos similares en un sistema de archivos grande. En Proc. Conferencia Técnica de Invierno de USENIX 1994 (San Francisco, CA, 17-21 de 1994), pp. 1-10. [22] MANJHI, A., AILAMAKI, A., MAGGS, B. M., MOWRY, T. C., OLSTON, C., Y TOMASIC, A. Escalabilidad y seguridad simultáneas para aplicaciones web intensivas en datos. En Proc. 2006 ACM SIGMOD (junio de 2006), pp. 241-252. [23] MENEZES, A. J., VANSTONE, S. A., Y OORSCHOT, P. C. V. Manual de Criptografía Aplicada. CRC Press, 1996. [24] MILLER, R. B. \n\nCRC Press, 1996. [24] MILLER, R. B. Tiempo de respuesta en transacciones conversacionales entre humanos y computadoras. En Proc. Conferencia Conjunta de Computación de Otoño de AFIPS (1968), pp. 267-277. [25] MOGUL, J. C., CHAN, Y. M., Y KELLY, T. Diseño, implementación y evaluación de la detección de transferencias duplicadas en http. En Proc. Primer Simposio sobre Diseño e Implementación de Sistemas en Red (San Francisco, CA, Mar. 2004). [26] MUTHITACHAROEN, A., CHEN, B., Y MAZIERES, D. Un sistema de archivos en red de bajo ancho de banda. En Proc. 18º Simposio de la ACM sobre Principios de Sistemas Operativos (Banff, Canadá, Oct. 2001). [27] PFEIFER, D., Y JAKSCHITSCH, H. Caché basada en métodos en aplicaciones de servidores multinivel. En Proc. Quinto Simposio Internacional sobre Objetos y Aplicaciones Distribuidas (Catania, Sicilia, Italia, noviembre de 2003). [28] PLATTNER, C., Y ALONSO, G. Ganymed: Replicación escalable para aplicaciones web transaccionales. En Proc. 5ta Conferencia Internacional de Middleware ACM/IFIP/USENIX (2004), pp. 155-174. [29] QUINLAN, S., Y DORWARD, S. Venti: Un nuevo enfoque para el almacenamiento de archivos. En Proc. Conferencia FAST 2002 sobre Tecnologías de Archivo y Almacenamiento (2002). [30] RABIN, M. Huellas dactilares mediante polinomios aleatorios. En el Informe Técnico TR-15-81 (1981) del Centro de Investigación en Tecnología Informática de la Universidad de Harvard. [31] RABINOVICH, M., XIAO, Z., DOUGLIS, F., Y KALMANEK, C. Mover los lados de los bordes incluye a los clientes reales en el borde. En Proc. 4to Simposio USENIX sobre Tecnologías y Sistemas de Internet (Seattle, WA, Mar. 2003). [32] REESE, G. Programación de bases de datos con JDBC y Java, 1ra ed. OReilly, junio de 1997. [33] RHEA, S., LIANG, K., Y BREWER, E. Caché web basada en valores. En Proc. Duodécima Conferencia Internacional de la World Wide Web (mayo de 2003). [34] SIVASUBRAMANIAN, S., ALONSO, G., PIERRE, G., Y VAN STEEN, M. Globedb: Replicación autónoma de datos para aplicaciones web. En WWW 05: Actas de la 14ª Conferencia Internacional de la World-Wide Web (mayo de 2005). [35] SPRING, N. T., Y WETHERALL, D. Una técnica independiente de protocolo para eliminar el tráfico de red redundante. En Proc. de ACM SIGCOMM (Ago. 2000). [36] TOLIA, N., HARKES, J., KOZUCH, M., Y SATYANARAYANAN, M. Integrando almacenamiento portátil y distribuido. En Proc. 3ra Conferencia USENIX sobre Tecnologías de Archivos y Almacenamiento (San Francisco, CA, Mar. 2004). [37] TOLIA, N., KOZUCH, M., SATYANARAYANAN, M., KARP, B., PERRIG, A., Y BRESSOUD, T. Uso oportunista del <br>almacenamiento direccionable por contenido</br> para sistemas de archivos distribuidos. En Proc. Conferencia Técnica Anual USENIX 2003 (San Antonio, TX, junio de 2003), pp. 127-140. [38] YUAN, C., CHEN, Y., Y ZHANG, Z. Evaluación de almacenamiento en caché/descarga en el borde para la entrega de contenido dinámico. En WWW 03: Proc. Duodécima Conferencia Internacional sobre la World Wide Web (2003), pp. 461-471. WWW 2007 / Pista: Rendimiento y Escalabilidad Sesión: Sistemas Escalables para Contenido Dinámico 320 ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "relational database system": {
            "translated_key": "sistema de base de datos relacional",
            "is_in_text": false,
            "original_annotated_sentences": [
                "Consistency-preserving Caching of Dynamic Database Content∗ Niraj Tolia and M. Satyanarayanan Carnegie Mellon University {ntolia,satya}@cs.cmu.edu ABSTRACT With the growing use of dynamic web content generated from relational databases, traditional caching solutions for throughput and latency improvements are ineffective.",
                "We describe a middleware layer called Ganesh that reduces the volume of data transmitted without semantic interpretation of queries or results.",
                "It achieves this reduction through the use of cryptographic hashing to detect similarities with previous results.",
                "These benefits do not require any compromise of the strict consistency semantics provided by the back-end database.",
                "Further, Ganesh does not require modifications to applications, web servers, or database servers, and works with closed-source applications and databases.",
                "Using two benchmarks representative of dynamic web sites, measurements of our prototype show that it can increase end-to-end throughput by as much as twofold for non-data intensive applications and by as much as tenfold for data intensive ones.",
                "Categories and Subject Descriptors C.2.4 [Computer-Communication Networks]: Distributed Systems; H.2.4 [Database Management]: Systems General Terms Design, Performance 1.",
                "INTRODUCTION An increasing fraction of web content is dynamically generated from back-end relational databases.",
                "Even when database content remains unchanged, temporal locality of access cannot be exploited because dynamic content is not cacheable by web browsers or by intermediate caching servers such as Akamai mirrors.",
                "In a multitiered architecture, each web request can stress the WAN link between the web server and the database.",
                "This causes user experience to be highly variable because there is no caching to insulate the client from bursty loads.",
                "Previous attempts in caching dynamic database content have generally weakened transactional semantics [3, 4] or required application modifications [15, 34].",
                "We report on a new solution that takes the form of a databaseagnostic middleware layer called Ganesh.",
                "Ganesh makes no effort to semantically interpret the contents of queries or their results.",
                "Instead, it relies exclusively on cryptographic hashing to detect similarities with previous results.",
                "Hash-based similarity detection has seen increasing use in distributed file systems [26, 36, 37] for improving performance on low-bandwidth networks.",
                "However, these techniques have not been used for relational databases.",
                "Unlike previous approaches that use generic methods to detect similarity, Ganesh exploits the structure of relational database results to yield superior performance improvement.",
                "One faces at least three challenges in applying hash-based similarity detection to back-end databases.",
                "First, previous work in this space has traditionally viewed storage content as uninterpreted bags of bits with no internal structure.",
                "This allows hash-based techniques to operate on long, contiguous runs of data for maximum effectiveness.",
                "In contrast, relational databases have rich internal structure that may not be as amenable to hash-based similarity detection.",
                "Second, relational databases have very tight integrity and consistency constraints that must not be compromised by the use of hash-based techniques.",
                "Third, the source code of commercial databases is typically not available.",
                "This is in contrast to previous work which presumed availability of source code.",
                "Our experiments show that Ganesh, while conceptually simple, can improve performance significantly at bandwidths representative of todays commercial Internet.",
                "On benchmarks modeling multitiered web applications, the throughput improvement was as high as tenfold for data-intensive workloads.",
                "For workloads that were not data-intensive, throughput improvements of up to twofold were observed.",
                "Even when bandwidth was not a constraint, Ganesh had low overhead and did not hurt performance.",
                "Our experiments also confirm that exploiting the structure present in database results is crucial to this performance improvement. 2.",
                "BACKGROUND 2.1 Dynamic Content Generation As the World Wide Web has grown, many web sites have decentralized their data and functionality by pushing them to the edges of the Internet.",
                "Today, eBusiness systems often use a three-tiered architecture consisting of a front-end web server, an application server, and a back-end database server.",
                "Figure 1 illustrates this architecture.",
                "The first two tiers can be replicated close to a concentration of clients at the edge of the Internet.",
                "This improves user experience by lowering end-to-end latency and reducing exposure WWW 2007 / Track: Performance and Scalability Session: Scalable Systems for Dynamic Content 311 Back-End Database Server Front-End Web and Application Servers Figure 1: Multi-Tier Architecture to backbone traffic congestion.",
                "It can also increase the availability and scalability of web services.",
                "Content that is generated dynamically from the back-end database cannot be cached in the first two tiers.",
                "While databases can be easily replicated in a LAN, this is infeasible in a WAN because of the difficult task of simultaneously providing strong consistency, availability, and tolerance to network partitions [7].",
                "As a result, databases tend to be centralized to meet the strong consistency requirements of many eBusiness applications such as banking, finance, and online retailing [38].",
                "Thus, the back-end database is usually located far from many sets of first and second-tier nodes [2].",
                "In the absence of both caching and replication, WAN bandwidth can easily become a limiting factor in the performance and scalability of data-intensive applications. 2.2 Hash-Based Systems Ganeshs focus is on efficient transmission of results by discovering similarities with the results of previous queries.",
                "As SQL queries can generate large results, hash-based techniques lend themselves well to the problem of efficiently transferring these large results across bandwidth constrained links.",
                "The use of hash-based techniques to reduce the volume of data transmitted has emerged as a common theme of many recent storage systems, as discussed in Section 8.2.",
                "These techniques rely on some basic assumptions.",
                "Cryptographic hash functions are assumed to be collision-resistant.",
                "In other words, it is computationally intractable to find two inputs that hash to the same output.",
                "The functions are also assumed to be one-way; that is, finding an input that results in a specific output is computationally infeasible.",
                "Menezes et al. [23] provide more details about these assumptions.",
                "The above assumptions allow hash-based systems to assume that collisions do not occur.",
                "Hence, they are able to treat the hash of a data item as its unique identifier.",
                "A collection of data items effectively becomes content-addressable, allowing a small hash to serve as a codeword for a much larger data item in permanent storage or network transmission.",
                "The assumption that collisions are so rare as to be effectively non-existent has recently come under fire [17].",
                "However, as explained by Black [5], we believe that these issues do not form a concern for Ganesh.",
                "All communication is between trusted parts of the system and an adversary has no way to force Ganesh to accept invalid data.",
                "Further, Ganesh does not depend critically on any specific hash function.",
                "While we currently use SHA-1, replacing it with a different hash function would be simple.",
                "There would be no impact on performance as stronger hash functions (e.g.",
                "SHA256) only add a few extra bytes and the generated hashes are still orders of magnitude smaller than the data items they represent.",
                "No re-hashing of permanent storage is required since Ganesh only uses hashing on volatile data. 3.",
                "DESIGN AND IMPLEMENTATION Ganesh exploits redundancy in the result stream to avoid transmitting result fragments that are already present at the query site.",
                "Redundancy can arise naturally in many different ways.",
                "For example, a query repeated after a certain interval may return a different result because of updates to the database; however, there may be significant commonality between the two results.",
                "As another example, a user who is refining a search may generate a sequence of queries with overlapping results.",
                "When Ganesh detects redundancy, it suppresses transmission of the corresponding result fragments.",
                "Instead, it transmits a much smaller digest of those fragments and lets the query site reconstruct the result through hash lookup in a cache of previous results.",
                "In effect, Ganesh uses computation at the edges to reduce Internet communication.",
                "Our description of Ganesh focuses on four aspects.",
                "We first explain our approach to detecting similarity in query results.",
                "Next, we discuss how the Ganesh architecture is completely invisible to all components of a multi-tier system.",
                "We then describe Ganeshs proxy-based approach and the dataflow for detecting similarity. 3.1 Detecting Similarity One of the key design decisions in Ganesh is how similarity is detected.",
                "There are many potential ways to decompose a result into fragments.",
                "The optimal way is, of course, the one that results in the smallest possible object for transmission for a given querys results.",
                "Finding this optimal decomposition is a difficult problem because of the large space of possibilities and because the optimal choice depends on many factors such as the contents of the querys result, the history of recent results, and the cache management algorithm.",
                "When an object is opaque, the use of Rabin fingerprints [8, 30] to detect common data between two objects has been successfully shown in the past by systems such as LBFS [26] and CASPER [37].",
                "Rabin fingerprinting uses a sliding window over the data to compute a rolling hash.",
                "Assuming that the hash function is uniformly distributed, a chunk boundary is defined whenever the lower order bits of the hash value equal some predetermined value.",
                "The number of lower order bits used defines the average chunk size.",
                "These sub-divided chunks of the object become the unit of comparison for detecting similarity between different objects.",
                "As the locations of boundaries found by using Rabin fingerprints is stochastically determined, they usually fail to align with any structural properties of the underlying data.",
                "The algorithm therefore deals well with in-place updates, insertions and deletions.",
                "However, it performs poorly in the presence of any reordering of data.",
                "Figure 2 shows an example where two results, A and B, consisting of three rows, have the same data but have different sort attributes.",
                "In the extreme case, Rabin fingerprinting might be unable to find any similar data due to the way it detects chunk boundaries.",
                "Fortunately, Ganesh can use domain specific knowledge for more precise boundary detection.",
                "The information we exploit is that a querys result reflects the structure of a relational database where all data is organized as tables and rows.",
                "It is therefore simple to check for similarity with previous results at two granularities: first the entire result, and then individual rows.",
                "The end of a row in a result serves as a natural chunk boundary.",
                "It is important to note that using the tabular structure in results only involves shallow interpretation of the data.",
                "Ganesh does not perform any deeper semantic interpretation such as understanding data types, result schema, or integrity constraints.",
                "Tuning Rabin fingerprinting for a workload can also be difficult.",
                "If the average chunk size is too large, chunks can span multiple result rows.",
                "However, selecting a smaller average chunk size increases the amount of metadata required to the describe the results.",
                "WWW 2007 / Track: Performance and Scalability Session: Scalable Systems for Dynamic Content 312 Figure 2: Rabin Fingerprinting vs. Ganeshs Chunking This, in turn, would decrease the savings obtained via its use.",
                "Rabin fingerprinting also needs two computationally-expensive passes over the data: once to determine chunk boundaries and one again to generate cryptographic hashes for the chunks.",
                "Ganesh only needs a single pass for hash generation as the chunk boundaries are provided by the datas natural structure.",
                "The performance comparison in Section 6 shows that Ganeshs row-based algorithm outperforms Rabin fingerprinting.",
                "Given that previous work has already shown that Rabin fingerprinting performs better than gzip [26], we do not compare Ganesh to compression algorithms in this paper. 3.2 Transparency The key factor influencing our design was the need for Ganesh to be completely transparent to all components of a typical eBusiness system: web servers, application servers, and database servers.",
                "Without this, Ganesh stands little chance of having a significant real-world impact.",
                "Requiring modifications to any of the above components would raise the barrier for entry of Ganesh into an existing system, and thus reduce its chances of adoption.",
                "Preserving transparency is simplified by the fact that Ganesh is purely a performance enhancement, not a functionality or usability enhancement.",
                "We chose agent interposition as the architectural approach to realizing our goal.",
                "This approach relies on the existence of a compact programming interface that is already widely used by target software.",
                "It also relies on a mechanism to easily add new code without disrupting existing module structure.",
                "These conditions are easily met in our context because of the popularity of Java as the programming language for eBusiness systems.",
                "The Java Database Connectivity (JDBC) API [32] allows Java applications to access a wide variety of databases and even other tabular data repositories such as flat files.",
                "Access to these data sources is provided by JDBC drivers that translate between the JDBC API and the database communication mechanism.",
                "Figure 3(a) shows how JDBC is typically used in an application.",
                "As the JDBC interface is standardized, one can substitute one JDBC driver for another without application modifications.",
                "The JDBC driver thus becomes the natural module to exploit for code interposition.",
                "As shown in Figure 3(b), the native JDBC driver is replaced with a Ganesh JDBC driver that presents the same standardized interface.",
                "The Ganesh driver maintains an in-memory cache of result fragments from previous queries and performs reassembly of results.",
                "At the database, we add a new process called the Ganesh proxy.",
                "This proxy, which can be shared by multiple front-end nodes, consists of two parts: code to detect similarity in result fragments and the original native JDBC driver that communicates with the database.",
                "The use of a proxy at the database makes Ganesh database-agnostic and simplifies prototyping and experimentation.",
                "Ganesh is thus able to work with a wide range of databases and applications, requiring no modifications to either. 3.3 Proxy-Based Caching The native JDBC driver shown in Figure 3(a) is a lightweight code component supplied by the database vendor.",
                "Its main funcClient Database Web and Application Server Native JDBC Driver WAN (a) Native Architecture Client Database Ganesh Proxy Native JDBC Driver WAN Web and Application Server Ganesh JDBC Driver (b) Ganeshs Interposition-based Architecture Figure 3: Native vs. Ganesh Architecture tion is to mediate communication between the application and the remote database.",
                "It forwards queries, buffers entire results, and responds to application requests to view parts of results.",
                "The Ganesh JDBC driver shown in Figure 3(b) presents the application with an interface identical to that provided by the native driver.",
                "It provides the ability to reconstruct results from compact hash-based descriptions sent by the proxy.",
                "To perform this reconstruction, the driver maintains an in-memory cache of recentlyreceived results.",
                "This cache is only used as a source of result fragments in reconstructing results.",
                "No attempt is made by the Ganesh driver or proxy to track database updates.",
                "The lack of cache consistency does not hurt correctness as a description of the results is always fetched from the proxy - at worst, there will be no performance benefit from using Ganesh.",
                "Stale data will simply be paged out of the cache over time.",
                "The Ganesh proxy accesses the database via the native JDBC driver, which remains unchanged between Figures 3(a) and (b).",
                "The database is thus completely unaware of the existence of the proxy.",
                "The proxy does not examine any queries received from the Ganesh driver but passes them to the native driver.",
                "Instead, the proxy is responsible for inspecting database output received from the native driver, detecting similar results, and generating hash-based encodings of these results whenever enough similarity is found.",
                "While this architecture does not decrease the load on a database, as mentioned earlier in Section 2.1, it is much easier to replicate databases for scalability in a LAN than in a WAN.",
                "To generate a hash-based encoding, the proxy must be aware of what result fragments are available in the Ganesh drivers cache.",
                "One approach is to be optimistic, and to assume that all result fragments are available.",
                "This will result in the smallest possible initial transmission of a result.",
                "However, in cases where there is little overlap with previous results, the Ganesh driver will have to make many calls to the proxy during reconstruction to fetch missing result fragments.",
                "To avoid this situation, the proxy loosely tracks the state of the Ganesh drivers cache.",
                "Since both components are under our control, it is relatively simple to do this without resorting to gray-box techniques or explicit communication for maintaining cache coherence.",
                "Instead, the proxy simulates the Ganesh drivers cache management algorithm and uses this to maintain a list of hashes for which the Ganesh driver is likely to possess the result fragments.",
                "In case of mistracking, there will be no loss of correctness but there will be extra round-trip delays to fetch the missing fragments.",
                "If the client detects loss of synchronization with the proxy, it can ask the proxy to reset the state shared between them.",
                "Also note that the proxy does not need to keep the result fragments themselves, only their hashes.",
                "This allows the proxy to remain scalable even when it is shared by many front-end nodes.",
                "WWW 2007 / Track: Performance and Scalability Session: Scalable Systems for Dynamic Content 313 Object Output Stream Convert ResultSet Object Input Stream Convert ResultSet All Data Recipe ResultSet All Data ResultSet Network Ganesh Proxy Ganesh JDBC Driver Result Set Recipe Result Set Yes Yes No No GaneshInputStream GaneshOutputStream Figure 4: Dataflow for Result Handling 3.4 Encoding and Decoding Results The Ganesh proxy receives database output as Java objects from the native JDBC driver.",
                "It examines this output to see if a Java object of type ResultSet is present.",
                "The JDBC interface uses this data type to store results of database queries.",
                "If a ResultSet object is found, it is shrunk as discussed below.",
                "All other Java objects are passed through unmodified.",
                "As discussed in Section 3.1, the proxy uses the row boundaries defined in the ResultSet to partition it into fragments consisting of single result rows.",
                "All ResultSet objects are converted into objects of a new type called RecipeResultSet.",
                "We use the term recipe for this compact description of a database result because of its similarity to a file recipe in the CASPER file system [37].",
                "The conversion replaces each result fragment that is likely to be present in the Ganesh drivers cache by a SHA-1 hash of that fragment.",
                "Previously unseen result fragments are retained verbatim.",
                "The proxy also retains hashes for the new result fragments as they will be present in the drivers cache in the future.",
                "Note that the proxy only caches hashes for result fragments and does not cache recipes.",
                "The proxy constructs a RecipeResultSet by checking for similarity at the entire result and then the row level.",
                "If the entire result is predicted to be present in the Ganesh drivers cache, the RecipeResultSet is simply a single hash of the entire result.",
                "Otherwise, it contains hashes for those rows predicted to be present in that cache; all other rows are retained verbatim.",
                "If the proxy estimates an overall space savings, it will transmit the RecipeResultSet.",
                "Otherwise the original ResultSet is transmitted.",
                "The RecipeResultSet objects are transformed back into ResultSet objects by the Ganesh driver.",
                "Figure 4 illustrates ResultSet handling at both ends.",
                "Each SHA-1 hash found in a RecipeResultSet is looked up in the local cache of result fragments.",
                "On a hit, the hash is replaced by the corresponding fragment.",
                "On a miss, the driver contacts the Ganesh proxy to fetch the fragment.",
                "All previously unseen result fragments that were retained verbatim by the proxy are hashed and added to the result cache.",
                "There should be very few misses if the proxy has accurately tracked the Ganesh drivers cache state.",
                "A future optimization would be to batch the fetch of missing fragments.",
                "This would be valuable when there are many small missing fragments in a high-latency WAN.",
                "Once the transformation is complete, the fully reconstructed ResultSet object is passed up to the application. 4.",
                "EXPERIMENTAL VALIDATION Three questions follow from the goals and design of Ganesh: • First, can performance can be improved significantly by exploiting similarity across database results?",
                "Benchmark Dataset Details 500,000 Users, 12,000 Stories BBOARD 2.0 GB 3,298,000 Comments AUCTION 1.3 GB 1,000,000 Users, 34,000 Items Table 1: Benchmark Dataset Details • Second, how important is Ganeshs structural similarity detection relative to Rabin fingerprintings similarity detection? • Third, is the overhead of the proxy-based design acceptable?",
                "Our evaluation answers these question through controlled experiments with the Ganesh prototype.",
                "This section describes the benchmarks used, our evaluation procedure, and the experimental setup.",
                "Results of the experiments are presented in Sections 5, 6, and 7. 4.1 Benchmarks Our evaluation is based on two benchmarks [18] that have been widely used by other researchers to evaluate various aspects of multi-tier [27] and eBusiness architectures [9].",
                "The first benchmark, BBOARD, is modeled after Slashdot, a technology-oriented news site.",
                "The second benchmark, AUCTION, is modeled after eBay, an online auction site.",
                "In both benchmarks, most content is dynamically generated from information stored in a database.",
                "Details of the datasets used can be found in Table 1. 4.1.1 The BBOARD Benchmark The BBOARD benchmark, also known as RUBBoS [18], models Slashdot, a popular technology-oriented web site.",
                "Slashdot aggregates links to news stories and other topics of interest found elsewhere on the web.",
                "The site also serves as a bulletin board by allowing users to comment on the posted stories in a threaded conversation form.",
                "It is not uncommon for a story to gather hundreds of comments in a matter of hours.",
                "The BBOARD benchmark is similar to the site and models the activities of a user, including readonly operations such as browsing the stories of the day, browsing story categories, and viewing comments as well as write operations such as new user registration, adding and moderating comments, and story submission.",
                "The benchmark consists of three different phases: a short warmup phase, a runtime phase representing the main body of the workload, and a short cool-down phase.",
                "In this paper we only report results from the runtime phase.",
                "The warm-up phase is important in establishing dynamic system state, but measurements from that phase are not significant for our evaluation.",
                "The cool-down phase is solely for allowing the benchmark to shut down.",
                "The warm-up, runtime, and cool-down phases are 2, 15, and 2 minutes respectively.",
                "The number of simulated clients were 400, 800, 1200, and 1600.",
                "The benchmark is available in a Java Servlets and PHP version and has different datasets; we evaluated Ganesh using the Java Servlets version and the Expanded dataset.",
                "The BBOARD benchmark defines two different workloads.",
                "The first, the Authoring mix, consists of 70% read-only operations and 30% read-write operations.",
                "The second, the Browsing mix, contains only read-only operations and does not update the database. 4.1.2 The AUCTION Benchmark The AUCTION benchmark, also known as RUBiS [18], models eBay, the online auction site.",
                "The eBay web site is used to buy and sell items via an auction format.",
                "The main activities of a user include browsing, selling, or bidding for items.",
                "Modeling the activities on this site, this benchmark includes read-only activities such as browsing items by category and by region, as well as read-write WWW 2007 / Track: Performance and Scalability Session: Scalable Systems for Dynamic Content 314 NetEm Router Ganesh Proxy Clients Web and Application Server Database Server Figure 5: Experimental Setup activities such as bidding for items, buying and selling items, and leaving feedback.",
                "As with BBOARD, the benchmark consists of three different phases.",
                "The warm-up, runtime, and cool-down phases for this experiment are 1.5, 15, and 1 minutes respectively.",
                "We tested Ganesh with four client configurations where the number of test clients was set to 400, 800, 1200, and 1600.",
                "The benchmark is available in a Enterprise Java Bean (EJB), Java Servlets, and PHP version and has different datasets; we evaluated Ganesh with the Java Servlets version and the Expanded dataset.",
                "The AUCTION benchmark defines two different workloads.",
                "The first, the Bidding mix, consists of 70% read-only operations and 30% read-write operations.",
                "The second, the Browsing mix, contains only read-only operations and does not update the database. 4.2 Experimental Procedure Both benchmarks involve a synthetic workload of clients accessing a web server.",
                "The number of clients emulated is an experimental parameter.",
                "Each emulated client runs an instance of the benchmark in its own thread, using a matrix to transition between different benchmark states.",
                "The matrix defines a stochastic model with probabilities of transitioning between the different states that represent typical user actions.",
                "An example transition is a user logging into the AUCTION system and then deciding on whether to post an item for sale or bid on active auctions.",
                "Each client also models user think time between requests.",
                "The think time is modeled as an exponential distribution with a mean of 7 seconds.",
                "We evaluate Ganesh along two axes: number of clients and WAN bandwidth.",
                "Higher loads are especially useful in understanding Ganeshs performance when the CPU or disk of the database server or proxy is the limiting factor.",
                "A previous study has shown that approximately 50% of the wide-area Internet bottlenecks observed had an available bandwidth under 10 Mb/s [1].",
                "Based on this work, we focus our evaluation on the WAN bandwidth of 5 Mb/s with 66 ms of round-trip latency, representative of severely constrained network paths, and 20 Mb/s with 33 ms of round-trip latency, representative of a moderately constrained network path.",
                "We also report Ganeshs performance at 100 Mb/s with no added round-trip latency.",
                "This bandwidth, representative of an unconstrained network, is especially useful in revealing any potential overhead of Ganesh in situations where WAN bandwidth is not the limiting factor.",
                "For each combination of number of clients and WAN bandwidth, we measured results from the two configurations listed below: • Native: This configuration corresponds to Figure 3(a).",
                "Native avoids Ganeshs overhead in using a proxy and performing Java object serialization. • Ganesh: This configuration corresponds to Figure 3(b).",
                "For a given number of clients and WAN bandwidth, comparing these results to the corresponding Native results gives the performance benefit due to the Ganesh middleware system.",
                "The metric used to quantify the improvement in throughput is the number of client requests that can be serviced per second.",
                "The metric used to quantify Ganeshs overhead is the average response time for a client request.",
                "For all of the experiments, the Ganesh driver used by the application server used a cache size of 100,000 items1 .",
                "The proxy was effective in tracking the Ganesh drivers cache state; for all of our experiments the miss rate on the driver never exceeded 0.7%. 4.3 Experimental Setup The experimental setup used for the benchmarks can be seen in Figure 5.",
                "All machines were 3.2 GHz Pentium 4s (with HyperThreading enabled.)",
                "With the exception of the database server, all machines had 2 GB of SDRAM and ran the Fedora Core Linux distribution.",
                "The database server had 4 GB of SDRAM.",
                "We used Apaches Tomcat as both the application server that hosted the Java Servlets and the web server.",
                "Both benchmarks used Java Servlets to generate the dynamic content.",
                "The database server used the open source MySQL database.",
                "For the native JDBC drivers, we used the Connector/J drivers provided by MySQL.",
                "The application server used Suns Java Virtual Machine as the runtime environment for the Java Servlets.",
                "The sysstat tool was used to monitor the CPU, network, disk, and memory utilization on all machines.",
                "The machines were connected by a switched gigabit Ethernet network.",
                "As shown in Figure 5, the front-end web and application server was separated from the proxy and database server by a NetEm router [16].",
                "This router allowed us to control the bandwidth and latency settings on the network.",
                "The NetEm router is a standard PC with two network cards running the Linux Traffic Control and Network Emulation software.",
                "The bandwidth and latency constraints were only applied to the link between the application server and the database for the native case and between the application server and the proxy for the Ganesh case.",
                "There is no communication between the application server and the database with Ganesh as all data flows through the proxy.",
                "As our focus was on the WAN link between the application server and the database, there were no constraints on the link between the simulated test clients and the web server. 5.",
                "THROUGHPUT AND RESPONSE TIME In this section, we address the first question raised in Section 4: Can performance can be improved significantly by exploiting similarity across database results?",
                "To answer this question, we use results from the BBOARD and AUCTION benchmarks.",
                "We use two metrics to quantify the performance improvement obtainable through the use of Ganesh: throughput, from the perspective of the web server, and average response time, from the perspective of the client.",
                "Throughput is measured in terms of the number of client requests that can be serviced per second. 5.1 BBOARD Results and Analysis 5.1.1 Authoring Mix Figures 6 (a) and (b) present the average number of requests serviced per second and the average response time for these requests as perceived by the clients for BBOARDs Authoring Mix.",
                "As Figure 6 (a) shows, Native easily saturates the 5 Mb/s link.",
                "At 400 clients, the Native solution delivers 29 requests/sec with an average response time of 8.3 seconds.",
                "Natives throughput drops with an increase in test clients as clients timeout due to congestion at the application server.",
                "Usability studies have shown that response times above 10 seconds cause the user to move on to 1 As Java lacks a sizeof() operator, Java caches therefore limit their size based on the number of objects.",
                "The size of cache dumps taken at the end of the experiments never exceeded 212 MB.",
                "WWW 2007 / Track: Performance and Scalability Session: Scalable Systems for Dynamic Content 315 0 50 100 150 200 250 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Test Clients Requests/sec Native Ganesh 0.001 0.01 0.1 1 10 100 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Test Clients Avg.Resp.Time(sec) Native Ganesh Note Logscale (a) Throughput: Authoring Mix (b) Response Time: Authoring Mix 0 50 100 150 200 250 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Test Clients Requests/sec Native Ganesh 0.001 0.01 0.1 1 10 100 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Test Clients Avg.Resp.Time(sec) Native Ganesh Note Logscale (c) Throughput: Browsing Mix (d) Response Time: Browsing Mix Mean of three trials.",
                "The maximum standard deviation for throughput and response time was 9.8% and 11.9% of the corresponding mean.",
                "Figure 6: BBOARD Benchmark - Throughput and Average Response Time other tasks [24].",
                "Based on these numbers, increasing the number of test clients makes the Native system unusable.",
                "Ganesh at 5 Mb/s, however, delivers a twofold improvement with 400 test clients and a fivefold improvement at 1200 clients.",
                "Ganeshs performance drops slightly at 1200 and 1600 clients as the network is saturated.",
                "Compared to Native, Figure 6 (b) shows that Ganeshs response times are substantially lower with sub-second response times at 400 clients.",
                "Figure 6 (a) also shows that for 400 and 800 test clients Ganesh at 5 Mb/s has the same throughput and average response time as Native at 20 Mb/s.",
                "Only at 1200 and 1600 clients does Native at 20 Mb/s deliver higher throughput than Ganesh at 5 Mb/s.",
                "Comparing both Ganesh and Native at 20 Mb/s, we see that Ganesh is no longer bandwidth constrained and delivers up to a twofold improvement over Native at 1600 test clients.",
                "As Ganesh does not saturate the network with higher test client configurations, at 1600 test clients, its average response time is 0.1 seconds rather than Natives 7.7 seconds.",
                "As expected, there are no visible gains from Ganesh at the higher bandwidth of 100 Mb/s where the network is no longer the bottleneck.",
                "Ganesh, however, still tracks Native in terms of throughput. 5.1.2 Browsing Mix Figures 6 (c) and (d) present the average number of requests serviced per second and the average response time for these requests as perceived by the clients for BBOARDs Browsing Mix.",
                "Regardless of the test client configuration, Figure 6 (c) shows that Natives throughput at 5 Mb/s is limited to 10 reqs/sec.",
                "Ganesh at 5 Mb/s with 400 test clients, delivers more than a sixfold increase in throughput.",
                "The improvement increases to over a elevenfold increase at 800 test clients before Ganesh saturates the network.",
                "Further, Figure 6 (d) shows that Natives average response time of 35 seconds at 400 test clients make the system unusable.",
                "These high response times further increase with the addition of test clients.",
                "Even with the 1600 test client configuration Ganesh delivers an acceptable average response time of 8.2 seconds.",
                "Due to the data-intensive nature of the Browsing mix, Ganesh at 5 Mb/s surprisingly performs much better than Native at 20 Mb/s.",
                "Further, as shown in Figure 6 (d), while the average response time for Native at 20 Mb/s is acceptable at 400 test clients, it is unusable with 800 test clients with an average response time of 15.8 seconds.",
                "Like the 5 Mb/s case, this response time increases with the addition of extra test clients.",
                "Ganesh at 20 Mb/s and both Native and Ganesh at 100 Mb/s are not bandwidth limited.",
                "However, performance plateaus out after 1200 test clients due to the database CPU being saturated. 5.1.3 Filter Variant We were surprised by the Native performance from the BBOARD benchmark.",
                "At the bandwidth of 5 Mb/s, Native performance was lower than what we had expected.",
                "It turned out the benchmark code that displays stories read all the comments associated with the particular story from the database and only then did some postprocessing to select the comments to be displayed.",
                "While this is exactly the behavior of SlashCode, the code base behind the Slashdot web site, we decided to modify the benchmark to perform some pre-filtering at the database.",
                "This modified benchmark, named the Filter Variant, models a developer who applies optimizations at the SQL level to transfer less data.",
                "In the interests of brevity, we only briefly summarize the results from the Authoring mix.",
                "For the Authoring mix, at 800 test clients at 5 Mb/s, Figure 7 (a) shows that Natives throughput increase by 85% when compared to the original benchmark while Ganeshs improvement is smaller at 15%.",
                "Natives performance drops above 800 clients as the test clients time out due to high response times.",
                "The most significant gain for Native is seen at 20 Mb/s.",
                "At 1600 test clients, when compared to the original benchmark, Native sees a 73% improvement in throughput and a 77% reduction in average response time.",
                "While WWW 2007 / Track: Performance and Scalability Session: Scalable Systems for Dynamic Content 316 0 50 100 150 200 250 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Test Clients Requests/sec Native Ganesh 0.001 0.01 0.1 1 10 100 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Test Clients Avg.Resp.Time(sec) Native Ganesh Note Logscale (a) Throughput: Authoring Mix (b) Response Time: Authoring Mix Mean of three trials.",
                "The maximum standard deviation for throughput and response time was 7.2% and 11.5% of the corresponding mean.",
                "Figure 7: BBOARD Benchmark - Filter Variant - Throughput and Average Response Time Ganesh sees no improvement when compared to the original, it still processes 19% more requests/sec than Native.",
                "Thus, while the optimizations were more helpful to Native, Ganesh still delivers an improvement in performance. 5.2 AUCTION Results and Analysis 5.2.1 Bidding Mix Figures 8 (a) and (b) present the average number of requests serviced per second and the average response time for these requests as perceived by the clients for AUCTIONs Bidding Mix.",
                "As mentioned earlier, the Bidding mix consists of a mixture of read and write operations.",
                "The AUCTION benchmark is not as data intensive as BBOARD.",
                "Therefore, most of the gains are observed at the lower bandwidth of 5 Mb/s.",
                "Figure 8 (a) shows that the increase in throughput due to Ganesh ranges from 8% at 400 test clients to 18% with 1600 test clients.",
                "As seen in Figure 8 (b), the average response times for Ganesh are significantly lower than Native ranging from a decrease of 84% at 800 test clients to 88% at 1600 test clients.",
                "Figure 8 (a) also shows that with a fourfold increase of bandwidth from 5 Mb/s to 20 Mb/s, Native is no longer bandwidth constrained and there is no performance difference between Ganesh and Native.",
                "With the higher test client configurations, we did observe that the bandwidth used by Ganesh was lower than Native.",
                "Ganesh might still be useful in these non-constrained scenarios if bandwidth is purchased on a metered basis.",
                "Similar results are seen for the 100 Mb/s scenario. 5.2.2 Browsing Mix For AUCTIONs Browsing Mix, Figures 8 (c) and (d) present the average number of requests serviced per second and the average response time for these requests as perceived by the clients.",
                "Again, most of the gains are observed at lower bandwidths.",
                "At 5 Mb/s, Native and Ganesh deliver similar throughput and response times with 400 test clients.",
                "While the throughput for both remains the same at 800 test clients, Figure 8 (d) shows that Ganeshs average response time is 62% lower than Native.",
                "Native saturates the link at 800 clients and adding extra test clients only increases the average response time.",
                "Ganesh, regardless of the test client configuration, is not bandwidth constrained and maintains the same response time.",
                "At 1600 test clients, Figure 8 (c) shows that Ganeshs throughput is almost twice that of Native.",
                "At the higher bandwidths of 20 and 100 Mb/s, neither Ganesh nor Native is bandwidth limited and deliver equivalent throughput and response times.",
                "Benchmark Orig.",
                "Size Ganesh Size Rabin Size SelectSort1 223.6 MB 5.4 MB 219.3 MB SelectSort2 223.6 MB 5.4 MB 223.6 MB Table 2: Similarity Microbenchmarks 6.",
                "STRUCTURAL VS. RABIN SIMILARITY In this section, we address the second question raised in Section 4: How important is Ganeshs structural similarity detection relative to Rabin fingerprinting-based similarity detecting?",
                "To answer this question, we used microbenchmarks and the BBOARD and AUCTION benchmarks.",
                "As Ganesh always performed better than Rabin fingerprinting, we only present a subset of the results here in the interests of brevity. 6.1 Microbenchmarks Two microbenchmarks show an example of the effects of data reordering on Rabin fingerprinting algorithm.",
                "In the first microbenchmark, SelectSort1, a query with a specified sort order selects 223.6 MB of data spread over approximately 280 K rows.",
                "The query is then repeated with a different sort attribute.",
                "While the same number of rows and the same data is returned, the order of rows is different.",
                "In such a scenario, one would expect a large amount of similarity to be detected between both results.",
                "As Table 2 shows, Ganeshs row-based algorithm achieves a 97.6% reduction while the Rabin fingerprinting algorithm, with the average chunk size parameter set to 4 KB, only achieves a 1% reduction.",
                "The reason, as shown earlier in Figure 2, is that with Rabin fingerprinting, the spans of data between two consecutive boundaries usually cross row boundaries.",
                "With the order of the rows changing in the second result and the Rabin fingerprints now spanning different rows, the algorithm is unable to detect significant similarity.",
                "The small gain seen is mostly for those single rows that are large enough to be broken into multiple chunks.",
                "SelectSort2, another micro-benchmark executed the same queries but increased the minimum chunk size of the Rabin fingerprinting algorithm.",
                "As can be seen in Table 2, even the small gain from the previous microbenchmark disappears as the minimum chunk size was greater than the average row size.",
                "While one can partially address these problems by dynamically varying the parameters of the Rabin fingerprinting algorithm, this can be computationally expensive, especially in the presence of changing workloads. 6.2 Application Benchmarks We ran the BBOARD benchmark described in Section 4.1.1 on two versions of Ganesh: the first with Rabin fingerprinting used as WWW 2007 / Track: Performance and Scalability Session: Scalable Systems for Dynamic Content 317 0 50 100 150 200 250 300 350 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Test Clients Requests/sec Native Ganesh 0.001 0.01 0.1 1 10 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Test Clients Avg.Resp.Time(sec) Native Ganesh Note Logscale (a) Throughput: Bidding Mix (b) Response Time: Bidding Mix 0 50 100 150 200 250 300 350 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Test Clients Requests/sec Native Ganesh 0.001 0.01 0.1 1 10 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Test Clients Avg.Resp.Time(sec) Native Ganesh Note Logscale (c) Throughput: Browsing Mix (d) Response Time: Browsing Mix Mean of three trials.",
                "The maximum standard deviation for throughput and response time was 2.2% and 11.8% of the corresponding mean.",
                "Figure 8: AUCTION Benchmark - Throughput and Average Response Time the chunking algorithm and the second with Ganeshs row-based algorithm.",
                "Rabins results for the Browsing Mix are normalized to Ganeshs results and presented in Figure 9.",
                "As Figure 9 (a) shows, at 5 Mb/s, independent of the test client configuration, Rabin significantly underperforms Ganesh.",
                "This happens because of a combination of two reasons.",
                "First, as outlined in Section 3.1, Rabin finds less similarity as it does not exploit the results structural information.",
                "Second, this benchmark contained some queries that generated large results.",
                "In this case, Rabin, with a small average chunk size, generated a large number of objects that evicted other useful data from the cache.",
                "In contrast, Ganesh was able to detect these large rows and correspondingly increase the size of the chunks.",
                "This was confirmed as cache statistics showed that Ganeshs hit ratio was roughly three time that of Rabin.",
                "Throughput measurements at 20 Mb/s were similar with the exception of Rabins performance with 400 test clients.",
                "In this case, Ganesh was not network limited and, in fact, the throughput was the same as 400 clients at 5 Mb/s.",
                "Rabin, however, took advantage of the bandwidth increase from 5 to 20 Mb/s to deliver a slightly better performance.",
                "At 100 Mb/s, Rabins throughput was almost similar to Ganesh as bandwidth was no longer a bottleneck.",
                "The normalized response time, presented in Figure 9 (b), shows similar trends.",
                "At 5 and 20 Mb/s, the addition of test clients decreases the normalized response time as Ganeshs average response time increases faster than Rabins.",
                "However, at no point does Rabin outperform Ganesh.",
                "Note that at 400 and 800 clients at 100 Mb/s, Rabin does have a higher overhead even when it is not bandwidth constrained.",
                "As mentioned in Section 3.1, this is due to the fact that Rabin has to hash each ResultSet twice.",
                "The overhead disappears with 1200 and 1600 clients as the database CPU is saturated and limits the performance of both Ganesh and Rabin. 7.",
                "PROXY OVERHEAD In this section, we address the third question raised in Section 4: Is the overhead of Ganeshs proxy-based design acceptable?",
                "To answer this question, we concentrate on its performance at the higher bandwidths.",
                "Our evaluation in Section 5 showed that Ganesh, when compared to Native, can deliver a substantial throughput improvement at lower bandwidths.",
                "It is only at higher bandwidths that latency, measured by the average response time for a client request, and throughput, measured by the number of client requests that can be serviced per second, overheads would be visible.",
                "Looking at the Authoring mix of the original BBOARD benchmark, there are no visible gains from Ganesh at 100 Mb/s.",
                "Ganesh, however, still tracks Native in terms of throughput.",
                "While the average response time is higher for Ganesh, the absolute difference is in between 0.01 and 0.04 seconds and would be imperceptible to the end-user.",
                "The Browsing mix shows an even smaller difference in average response times.",
                "The results from the filter variant of the BBOARD benchmarks are similar.",
                "Even for the AUCTION benchmark, the difference between Native and Ganeshs response time at 100 Mb/s was never greater than 0.02 seconds.",
                "The only exception to the above results was seen in the filter variant of the BBOARD benchmark where Ganesh at 1600 test clients added 0.85 seconds to the average response time.",
                "Thus, even for much faster networks where the WAN link is not the bottleneck, Ganesh always delivers throughput equivalent to Native.",
                "While some extra latency is added by the proxy-based design, it is usually imperceptible. 8.",
                "RELATED WORK To the best of our knowledge, Ganesh is the first system that combines the use of hash-based techniques with caching of database results to improve throughput and response times for applications with dynamic content.",
                "We also believe that it is also the first system to demonstrate the benefits of using structural information for WWW 2007 / Track: Performance and Scalability Session: Scalable Systems for Dynamic Content 318 0.0 0.2 0.4 0.6 0.8 1.0 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Test Clients Norm.Throughput 31.8 3.8 2.8 2.3 23.8 32.8 5.8 3.6 1.8 2.1 1.1 1.0 0 5 10 15 20 25 30 35 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Test Clients Norm.ResponseTime (a) Normalized Throughput: Higher is better (b) Normalized Response Time: Higher is worse For throughput, a normalized result greater than 1 implies that Rabin is better, For response time, a normalized result greater than 1 implies that Ganesh is better.",
                "Mean of three trials.",
                "The maximum standard deviation for throughput and response time was 9.1% and 13.9% of the corresponding mean.",
                "Figure 9: Normalized Comparison of Ganesh vs. Rabin - BBOARD Browsing Mix detecting similarity.",
                "In this section, we first discuss alternative approaches to caching dynamic content and then examine other uses of hash-based primitives in distributed systems. 8.1 Caching Dynamic Content At the database layer, a number of systems have advocated middletier caching where parts of the database are replicated at the edge or server [3, 4, 20].",
                "These systems either cache entire tables in what is essentially a replicated database or use materialized views from previous query replies [19].",
                "They require tight integration with the back-end database to ensure a time bound on the propagation of updates.",
                "These systems are also usually targeted towards workloads that do not require strict consistency and can tolerate stale data.",
                "Further, unlike Ganesh, some of these mid-tier caching solutions [2, 3], suffer from the complexity of having to participate in query planing and distributed query processing.",
                "Gao et al. [15] propose using a distributed object replication architecture where the data stores consistency requirements are adapted on a per-application basis.",
                "These solutions require substantial developer resources and detailed understanding of the application being modified.",
                "While systems that attempt to automate the partitioning and replication of an applications database exist [34], they do not provide full transaction semantics.",
                "In comparison, Ganesh does not weaken any of the semantics provided by the underlying database.",
                "Recent work in the evaluation of edge caching options for dynamic web sites [38] has suggested that, without careful planning, employing complex offloading strategies can hurt performance.",
                "Instead, the work advocates for an architecture in which all tiers except the database should be offloaded to the edge.",
                "Our evaluation of Ganesh has shown that it would benefit these scenarios.",
                "To improve database scalability, C-JDBC [10], SSS [22], and Ganymed [28] also advocate the use of an interposition-based architecture to transparently cluster and replicate databases at the middleware level.",
                "The approaches of these architectures and Ganesh are complementary and they would benefit each other.",
                "Moving up to the presentation layer, there has been widespread adoption of fragment-based caching [14], which improves cache utilization by separately caching different parts of generated web pages.",
                "While fragment-based caching works at the edge, a recent proposal has proposed moving web page assembly to the clients to optimize content delivery [31].",
                "While Ganesh is not used at the presentation layer, the same principles have been applied in Duplicate Transfer Detection [25] to increase web cache efficiency as well as for web access across bandwidth limited links [33]. 8.2 Hash-based Systems The past few years have seen the emergence of many systems that exploit hash-based techniques.",
                "At the heart of all these systems is the idea of detecting similarity in data without requiring interpretation of that data.",
                "This simple yet elegant idea relies on cryptographic hashing, as discussed earlier in Section 2.",
                "Successful applications of this idea span a wide range of storage systems.",
                "Examples include peer-to-peer backup of personal computing files [11], storage-efficient archiving of data [29], and finding similar files [21].",
                "Spring and Wetherall [35] apply similar principles at the network level.",
                "Using synchronized caches at both ends of a network link, duplicated data is replaced by smaller tokens for transmission and then restored at the remote end.",
                "This and other hash-based systems such as the CASPER [37] and LBFS [26] filesystems, and Layer-2 bandwidth optimizers such as Riverbed and Peribit use Rabin fingerprinting [30] to discover spans of commonality in data.",
                "This approach is especially useful when data items are modified in-place through insertions, deletions, and updates.",
                "However, as Section 6 shows, the performance of this technique can show a dramatic drop in the presence of data reordering.",
                "Ganesh instead uses row boundaries as dividers for detecting similarity.",
                "The most aggressive use of hash-based techniques is by systems that use hashes as the primary identifiers for objects in persistent storage.",
                "Storage systems such as CFS [12] and PAST [13] that have been built using distributed hash tables fall into this category.",
                "Single Instance Storage [6] and Venti [29] are other examples of such systems.",
                "As discussed in Section 2.2, the use of cryptographic hashes for addressing persistent data represents a deeper level of faith in their collision-resistance than that assumed by Ganesh.",
                "If time reveals shortcomings in the hash algorithm, the effort involved in correcting the flaw is much greater.",
                "In Ganesh, it is merely a matter of replacing the hash algorithm. 9.",
                "CONCLUSION The growing use of dynamic web content generated from relational databases places increased demands on WAN bandwidth.",
                "Traditional caching solutions for bandwidth and latency reduction are often ineffective for such content.",
                "This paper shows that the impact of WAN accesses to databases can be substantially reduced through the Ganesh architecture without any compromise of the databases strict consistency semantics.",
                "The essence of the Ganesh architecture is the use of computation at the edges to reduce communication through the Internet.",
                "Ganesh is able to use cryptographic hashes to detect similarity with previous results and send WWW 2007 / Track: Performance and Scalability Session: Scalable Systems for Dynamic Content 319 compact recipes of results rather than full results.",
                "Our design uses interposition to achieve complete transparency: clients, application servers, and database servers are all unaware of Ganeshs presence and require no modification.",
                "Our experimental evaluation confirms that Ganesh, while conceptually simple, can be highly effective in improving throughput and response time.",
                "Our results also confirm that exploiting the structure present in database results to detect similarity is crucial to this performance improvement. 10.",
                "REFERENCES [1] AKELLA, A., SESHAN, S., AND SHAIKH, A.",
                "An empirical evaluation of wide-area internet bottlenecks.",
                "In Proc. 3rd ACM SIGCOMM Conference on Internet Measurement (Miami Beach, FL, USA, Oct. 2003), pp. 101-114. [2] ALTINEL, M., BORNH ¨OVD, C., KRISHNAMURTHY, S., MOHAN, C., PIRAHESH, H., AND REINWALD, B. Cache tables: Paving the way for an adaptive database cache.",
                "In Proc. of 29th VLDB (Berlin, Germany, 2003), pp. 718-729. [3] ALTINEL, M., LUO, Q., KRISHNAMURTHY, S., MOHAN, C., PIRAHESH, H., LINDSAY, B. G., WOO, H., AND BROWN, L. Dbcache: Database caching for web application servers.",
                "In Proc. 2002 ACM SIGMOD (2002), pp. 612-612. [4] AMIRI, K., PARK, S., TEWARI, R., AND PADMANABHAN, S. Dbproxy: A dynamic data cache for web applications.",
                "In Proc.",
                "IEEE International Conference on Data Engineering (ICDE) (Mar. 2003). [5] BLACK, J. Compare-by-hash: A reasoned analysis.",
                "In Proc. 2006 USENIX Annual Technical Conference (Boston, MA, May 2006), pp. 85-90. [6] BOLOSKY, W. J., CORBIN, S., GOEBEL, D., , AND DOUCEUR, J. R. Single instance storage in windows 2000.",
                "In Proc. 4th USENIX Windows Systems Symposium (Seattle, WA, Aug. 2000), pp. 13-24. [7] BREWER, E. A.",
                "Lessons from giant-scale services.",
                "IEEE Internet Computing 5, 4 (2001), 46-55. [8] BRODER, A., GLASSMAN, S., MANASSE, M., AND ZWEIG, G. Syntactic clustering of the web.",
                "In Proc. 6th International WWW Conference (1997). [9] CECCHET, E., CHANDA, A., ELNIKETY, S., MARGUERITE, J., AND ZWAENEPOEL, W. Performance comparison of middleware architectures for generating dynamic web content.",
                "In Proc.",
                "Fourth ACM/IFIP/USENIX International Middleware Conference (Rio de Janeiro, Brazil, June 2003). [10] CECCHET, E., MARGUERITE, J., AND ZWAENEPOEL, W. C-JDBC: Flexible database clustering middleware.",
                "In Proc. 2004 USENIX Annual Technical Conference (Boston, MA, June 2004). [11] COX, L. P., MURRAY, C. D., AND NOBLE, B. D. Pastiche: Making backup cheap and easy.",
                "In OSDI: Symposium on Operating Systems Design and Implementation (2002). [12] DABEK, F., KAASHOEK, M. F., KARGER, D., MORRIS, R., AND STOICA, I. Wide-area cooperative storage with CFS.",
                "In 18th ACM Symposium on Operating Systems Principles (Banff, Canada, Oct. 2001). [13] DRUSCHEL, P., AND ROWSTRON, A.",
                "PAST: A large-scale, persistent peer-to-peer storage utility.",
                "In HotOS VIII (Schloss Elmau, Germany, May 2001), pp. 75-80. [14] Edge side includes. http://www.esi.org. [15] GAO, L., DAHLIN, M., NAYATE, A., ZHENG, J., AND IYENGAR, A.",
                "Application specific data replication for edge services.",
                "In WWW 03: Proc.",
                "Twelfth International Conference on World Wide Web (2003), pp. 449-460. [16] HEMMINGER, S. Netem - emulating real networks in the lab.",
                "In Proc. 2005 Linux Conference Australia (Canberra, Australia, Apr. 2005). [17] HENSON, V. An analysis of compare-by-hash.",
                "In Proc. 9th Workshop on Hot Topics in Operating Systems (HotOS IX) (May 2003), pp. 13-18. [18] Jmob benchmarks. http://jmob.objectweb.org/. [19] LABRINIDIS, A., AND ROUSSOPOULOS, N. Balancing performance and data freshness in web database servers.",
                "In Proc. 29th VLDB Conference (Sept. 2003). [20] LARSON, P.-A., GOLDSTEIN, J., AND ZHOU, J. Transparent mid-tier database caching in sql server.",
                "In Proc. 2003 ACM SIGMOD (2003), pp. 661-661. [21] MANBER, U.",
                "Finding similar files in a large file system.",
                "In Proc.",
                "USENIX Winter 1994 Technical Conference (San Fransisco, CA, 17-21 1994), pp. 1-10. [22] MANJHI, A., AILAMAKI, A., MAGGS, B. M., MOWRY, T. C., OLSTON, C., AND TOMASIC, A.",
                "Simultaneous scalability and security for data-intensive web applications.",
                "In Proc. 2006 ACM SIGMOD (June 2006), pp. 241-252. [23] MENEZES, A. J., VANSTONE, S. A., AND OORSCHOT, P. C. V. Handbook of Applied Cryptography.",
                "CRC Press, 1996. [24] MILLER, R. B.",
                "Response time in man-computer conversational transactions.",
                "In Proc.",
                "AFIPS Fall Joint Computer Conference (1968), pp. 267-277. [25] MOGUL, J. C., CHAN, Y. M., AND KELLY, T. Design, implementation, and evaluation of duplicate transfer detection in http.",
                "In Proc.",
                "First Symposium on Networked Systems Design and Implementation (San Francisco, CA, Mar. 2004). [26] MUTHITACHAROEN, A., CHEN, B., AND MAZIERES, D. A low-bandwidth network file system.",
                "In Proc. 18th ACM Symposium on Operating Systems Principles (Banff, Canada, Oct. 2001). [27] PFEIFER, D., AND JAKSCHITSCH, H. Method-based caching in multi-tiered server applications.",
                "In Proc.",
                "Fifth International Symposium on Distributed Objects and Applications (Catania, Sicily, Italy, Nov. 2003). [28] PLATTNER, C., AND ALONSO, G. Ganymed: Scalable replication for transactional web applications.",
                "In Proc. 5th ACM/IFIP/USENIX International Conference on Middleware (2004), pp. 155-174. [29] QUINLAN, S., AND DORWARD, S. Venti: A new approach to archival storage.",
                "In Proc.",
                "FAST 2002 Conference on File and Storage Technologies (2002). [30] RABIN, M. Fingerprinting by random polynomials.",
                "In Harvard University Center for Research in Computing Technology Technical Report TR-15-81 (1981). [31] RABINOVICH, M., XIAO, Z., DOUGLIS, F., AND KALMANEK, C. Moving edge side includes to the real edge - the clients.",
                "In Proc. 4th USENIX Symposium on Internet Technologies and Systems (Seattle, WA, Mar. 2003). [32] REESE, G. Database Programming with JDBC and Java, 1st ed.",
                "OReilly, June 1997. [33] RHEA, S., LIANG, K., AND BREWER, E. Value-based web caching.",
                "In Proc.",
                "Twelfth International World Wide Web Conference (May 2003). [34] SIVASUBRAMANIAN, S., ALONSO, G., PIERRE, G., AND VAN STEEN, M. Globedb: Autonomic data replication for web applications.",
                "In WWW 05: Proc. 14th International World-Wide Web conference (May 2005). [35] SPRING, N. T., AND WETHERALL, D. A protocol-independent technique for eliminating redundant network traffic.",
                "In Proc. of ACM SIGCOMM (Aug. 2000). [36] TOLIA, N., HARKES, J., KOZUCH, M., AND SATYANARAYANAN, M. Integrating portable and distributed storage.",
                "In Proc. 3rd USENIX Conference on File and Storage Technologies (San Francisco, CA, Mar. 2004). [37] TOLIA, N., KOZUCH, M., SATYANARAYANAN, M., KARP, B., PERRIG, A., AND BRESSOUD, T. Opportunistic use of content addressable storage for distributed file systems.",
                "In Proc. 2003 USENIX Annual Technical Conference (San Antonio, TX, June 2003), pp. 127-140. [38] YUAN, C., CHEN, Y., AND ZHANG, Z.",
                "Evaluation of edge caching/offloading for dynamic content delivery.",
                "In WWW 03: Proc.",
                "Twelfth International Conference on World Wide Web (2003), pp. 461-471.",
                "WWW 2007 / Track: Performance and Scalability Session: Scalable Systems for Dynamic Content 320"
            ],
            "original_annotated_samples": [],
            "translated_annotated_samples": [],
            "translated_text": "",
            "candidates": [],
            "error": [
                []
            ]
        },
        "database cache": {
            "translated_key": "caché de base de datos",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Consistency-preserving Caching of Dynamic Database Content∗ Niraj Tolia and M. Satyanarayanan Carnegie Mellon University {ntolia,satya}@cs.cmu.edu ABSTRACT With the growing use of dynamic web content generated from relational databases, traditional caching solutions for throughput and latency improvements are ineffective.",
                "We describe a middleware layer called Ganesh that reduces the volume of data transmitted without semantic interpretation of queries or results.",
                "It achieves this reduction through the use of cryptographic hashing to detect similarities with previous results.",
                "These benefits do not require any compromise of the strict consistency semantics provided by the back-end database.",
                "Further, Ganesh does not require modifications to applications, web servers, or database servers, and works with closed-source applications and databases.",
                "Using two benchmarks representative of dynamic web sites, measurements of our prototype show that it can increase end-to-end throughput by as much as twofold for non-data intensive applications and by as much as tenfold for data intensive ones.",
                "Categories and Subject Descriptors C.2.4 [Computer-Communication Networks]: Distributed Systems; H.2.4 [Database Management]: Systems General Terms Design, Performance 1.",
                "INTRODUCTION An increasing fraction of web content is dynamically generated from back-end relational databases.",
                "Even when database content remains unchanged, temporal locality of access cannot be exploited because dynamic content is not cacheable by web browsers or by intermediate caching servers such as Akamai mirrors.",
                "In a multitiered architecture, each web request can stress the WAN link between the web server and the database.",
                "This causes user experience to be highly variable because there is no caching to insulate the client from bursty loads.",
                "Previous attempts in caching dynamic database content have generally weakened transactional semantics [3, 4] or required application modifications [15, 34].",
                "We report on a new solution that takes the form of a databaseagnostic middleware layer called Ganesh.",
                "Ganesh makes no effort to semantically interpret the contents of queries or their results.",
                "Instead, it relies exclusively on cryptographic hashing to detect similarities with previous results.",
                "Hash-based similarity detection has seen increasing use in distributed file systems [26, 36, 37] for improving performance on low-bandwidth networks.",
                "However, these techniques have not been used for relational databases.",
                "Unlike previous approaches that use generic methods to detect similarity, Ganesh exploits the structure of relational database results to yield superior performance improvement.",
                "One faces at least three challenges in applying hash-based similarity detection to back-end databases.",
                "First, previous work in this space has traditionally viewed storage content as uninterpreted bags of bits with no internal structure.",
                "This allows hash-based techniques to operate on long, contiguous runs of data for maximum effectiveness.",
                "In contrast, relational databases have rich internal structure that may not be as amenable to hash-based similarity detection.",
                "Second, relational databases have very tight integrity and consistency constraints that must not be compromised by the use of hash-based techniques.",
                "Third, the source code of commercial databases is typically not available.",
                "This is in contrast to previous work which presumed availability of source code.",
                "Our experiments show that Ganesh, while conceptually simple, can improve performance significantly at bandwidths representative of todays commercial Internet.",
                "On benchmarks modeling multitiered web applications, the throughput improvement was as high as tenfold for data-intensive workloads.",
                "For workloads that were not data-intensive, throughput improvements of up to twofold were observed.",
                "Even when bandwidth was not a constraint, Ganesh had low overhead and did not hurt performance.",
                "Our experiments also confirm that exploiting the structure present in database results is crucial to this performance improvement. 2.",
                "BACKGROUND 2.1 Dynamic Content Generation As the World Wide Web has grown, many web sites have decentralized their data and functionality by pushing them to the edges of the Internet.",
                "Today, eBusiness systems often use a three-tiered architecture consisting of a front-end web server, an application server, and a back-end database server.",
                "Figure 1 illustrates this architecture.",
                "The first two tiers can be replicated close to a concentration of clients at the edge of the Internet.",
                "This improves user experience by lowering end-to-end latency and reducing exposure WWW 2007 / Track: Performance and Scalability Session: Scalable Systems for Dynamic Content 311 Back-End Database Server Front-End Web and Application Servers Figure 1: Multi-Tier Architecture to backbone traffic congestion.",
                "It can also increase the availability and scalability of web services.",
                "Content that is generated dynamically from the back-end database cannot be cached in the first two tiers.",
                "While databases can be easily replicated in a LAN, this is infeasible in a WAN because of the difficult task of simultaneously providing strong consistency, availability, and tolerance to network partitions [7].",
                "As a result, databases tend to be centralized to meet the strong consistency requirements of many eBusiness applications such as banking, finance, and online retailing [38].",
                "Thus, the back-end database is usually located far from many sets of first and second-tier nodes [2].",
                "In the absence of both caching and replication, WAN bandwidth can easily become a limiting factor in the performance and scalability of data-intensive applications. 2.2 Hash-Based Systems Ganeshs focus is on efficient transmission of results by discovering similarities with the results of previous queries.",
                "As SQL queries can generate large results, hash-based techniques lend themselves well to the problem of efficiently transferring these large results across bandwidth constrained links.",
                "The use of hash-based techniques to reduce the volume of data transmitted has emerged as a common theme of many recent storage systems, as discussed in Section 8.2.",
                "These techniques rely on some basic assumptions.",
                "Cryptographic hash functions are assumed to be collision-resistant.",
                "In other words, it is computationally intractable to find two inputs that hash to the same output.",
                "The functions are also assumed to be one-way; that is, finding an input that results in a specific output is computationally infeasible.",
                "Menezes et al. [23] provide more details about these assumptions.",
                "The above assumptions allow hash-based systems to assume that collisions do not occur.",
                "Hence, they are able to treat the hash of a data item as its unique identifier.",
                "A collection of data items effectively becomes content-addressable, allowing a small hash to serve as a codeword for a much larger data item in permanent storage or network transmission.",
                "The assumption that collisions are so rare as to be effectively non-existent has recently come under fire [17].",
                "However, as explained by Black [5], we believe that these issues do not form a concern for Ganesh.",
                "All communication is between trusted parts of the system and an adversary has no way to force Ganesh to accept invalid data.",
                "Further, Ganesh does not depend critically on any specific hash function.",
                "While we currently use SHA-1, replacing it with a different hash function would be simple.",
                "There would be no impact on performance as stronger hash functions (e.g.",
                "SHA256) only add a few extra bytes and the generated hashes are still orders of magnitude smaller than the data items they represent.",
                "No re-hashing of permanent storage is required since Ganesh only uses hashing on volatile data. 3.",
                "DESIGN AND IMPLEMENTATION Ganesh exploits redundancy in the result stream to avoid transmitting result fragments that are already present at the query site.",
                "Redundancy can arise naturally in many different ways.",
                "For example, a query repeated after a certain interval may return a different result because of updates to the database; however, there may be significant commonality between the two results.",
                "As another example, a user who is refining a search may generate a sequence of queries with overlapping results.",
                "When Ganesh detects redundancy, it suppresses transmission of the corresponding result fragments.",
                "Instead, it transmits a much smaller digest of those fragments and lets the query site reconstruct the result through hash lookup in a cache of previous results.",
                "In effect, Ganesh uses computation at the edges to reduce Internet communication.",
                "Our description of Ganesh focuses on four aspects.",
                "We first explain our approach to detecting similarity in query results.",
                "Next, we discuss how the Ganesh architecture is completely invisible to all components of a multi-tier system.",
                "We then describe Ganeshs proxy-based approach and the dataflow for detecting similarity. 3.1 Detecting Similarity One of the key design decisions in Ganesh is how similarity is detected.",
                "There are many potential ways to decompose a result into fragments.",
                "The optimal way is, of course, the one that results in the smallest possible object for transmission for a given querys results.",
                "Finding this optimal decomposition is a difficult problem because of the large space of possibilities and because the optimal choice depends on many factors such as the contents of the querys result, the history of recent results, and the cache management algorithm.",
                "When an object is opaque, the use of Rabin fingerprints [8, 30] to detect common data between two objects has been successfully shown in the past by systems such as LBFS [26] and CASPER [37].",
                "Rabin fingerprinting uses a sliding window over the data to compute a rolling hash.",
                "Assuming that the hash function is uniformly distributed, a chunk boundary is defined whenever the lower order bits of the hash value equal some predetermined value.",
                "The number of lower order bits used defines the average chunk size.",
                "These sub-divided chunks of the object become the unit of comparison for detecting similarity between different objects.",
                "As the locations of boundaries found by using Rabin fingerprints is stochastically determined, they usually fail to align with any structural properties of the underlying data.",
                "The algorithm therefore deals well with in-place updates, insertions and deletions.",
                "However, it performs poorly in the presence of any reordering of data.",
                "Figure 2 shows an example where two results, A and B, consisting of three rows, have the same data but have different sort attributes.",
                "In the extreme case, Rabin fingerprinting might be unable to find any similar data due to the way it detects chunk boundaries.",
                "Fortunately, Ganesh can use domain specific knowledge for more precise boundary detection.",
                "The information we exploit is that a querys result reflects the structure of a relational database where all data is organized as tables and rows.",
                "It is therefore simple to check for similarity with previous results at two granularities: first the entire result, and then individual rows.",
                "The end of a row in a result serves as a natural chunk boundary.",
                "It is important to note that using the tabular structure in results only involves shallow interpretation of the data.",
                "Ganesh does not perform any deeper semantic interpretation such as understanding data types, result schema, or integrity constraints.",
                "Tuning Rabin fingerprinting for a workload can also be difficult.",
                "If the average chunk size is too large, chunks can span multiple result rows.",
                "However, selecting a smaller average chunk size increases the amount of metadata required to the describe the results.",
                "WWW 2007 / Track: Performance and Scalability Session: Scalable Systems for Dynamic Content 312 Figure 2: Rabin Fingerprinting vs. Ganeshs Chunking This, in turn, would decrease the savings obtained via its use.",
                "Rabin fingerprinting also needs two computationally-expensive passes over the data: once to determine chunk boundaries and one again to generate cryptographic hashes for the chunks.",
                "Ganesh only needs a single pass for hash generation as the chunk boundaries are provided by the datas natural structure.",
                "The performance comparison in Section 6 shows that Ganeshs row-based algorithm outperforms Rabin fingerprinting.",
                "Given that previous work has already shown that Rabin fingerprinting performs better than gzip [26], we do not compare Ganesh to compression algorithms in this paper. 3.2 Transparency The key factor influencing our design was the need for Ganesh to be completely transparent to all components of a typical eBusiness system: web servers, application servers, and database servers.",
                "Without this, Ganesh stands little chance of having a significant real-world impact.",
                "Requiring modifications to any of the above components would raise the barrier for entry of Ganesh into an existing system, and thus reduce its chances of adoption.",
                "Preserving transparency is simplified by the fact that Ganesh is purely a performance enhancement, not a functionality or usability enhancement.",
                "We chose agent interposition as the architectural approach to realizing our goal.",
                "This approach relies on the existence of a compact programming interface that is already widely used by target software.",
                "It also relies on a mechanism to easily add new code without disrupting existing module structure.",
                "These conditions are easily met in our context because of the popularity of Java as the programming language for eBusiness systems.",
                "The Java Database Connectivity (JDBC) API [32] allows Java applications to access a wide variety of databases and even other tabular data repositories such as flat files.",
                "Access to these data sources is provided by JDBC drivers that translate between the JDBC API and the database communication mechanism.",
                "Figure 3(a) shows how JDBC is typically used in an application.",
                "As the JDBC interface is standardized, one can substitute one JDBC driver for another without application modifications.",
                "The JDBC driver thus becomes the natural module to exploit for code interposition.",
                "As shown in Figure 3(b), the native JDBC driver is replaced with a Ganesh JDBC driver that presents the same standardized interface.",
                "The Ganesh driver maintains an in-memory cache of result fragments from previous queries and performs reassembly of results.",
                "At the database, we add a new process called the Ganesh proxy.",
                "This proxy, which can be shared by multiple front-end nodes, consists of two parts: code to detect similarity in result fragments and the original native JDBC driver that communicates with the database.",
                "The use of a proxy at the database makes Ganesh database-agnostic and simplifies prototyping and experimentation.",
                "Ganesh is thus able to work with a wide range of databases and applications, requiring no modifications to either. 3.3 Proxy-Based Caching The native JDBC driver shown in Figure 3(a) is a lightweight code component supplied by the database vendor.",
                "Its main funcClient Database Web and Application Server Native JDBC Driver WAN (a) Native Architecture Client Database Ganesh Proxy Native JDBC Driver WAN Web and Application Server Ganesh JDBC Driver (b) Ganeshs Interposition-based Architecture Figure 3: Native vs. Ganesh Architecture tion is to mediate communication between the application and the remote database.",
                "It forwards queries, buffers entire results, and responds to application requests to view parts of results.",
                "The Ganesh JDBC driver shown in Figure 3(b) presents the application with an interface identical to that provided by the native driver.",
                "It provides the ability to reconstruct results from compact hash-based descriptions sent by the proxy.",
                "To perform this reconstruction, the driver maintains an in-memory cache of recentlyreceived results.",
                "This cache is only used as a source of result fragments in reconstructing results.",
                "No attempt is made by the Ganesh driver or proxy to track database updates.",
                "The lack of cache consistency does not hurt correctness as a description of the results is always fetched from the proxy - at worst, there will be no performance benefit from using Ganesh.",
                "Stale data will simply be paged out of the cache over time.",
                "The Ganesh proxy accesses the database via the native JDBC driver, which remains unchanged between Figures 3(a) and (b).",
                "The database is thus completely unaware of the existence of the proxy.",
                "The proxy does not examine any queries received from the Ganesh driver but passes them to the native driver.",
                "Instead, the proxy is responsible for inspecting database output received from the native driver, detecting similar results, and generating hash-based encodings of these results whenever enough similarity is found.",
                "While this architecture does not decrease the load on a database, as mentioned earlier in Section 2.1, it is much easier to replicate databases for scalability in a LAN than in a WAN.",
                "To generate a hash-based encoding, the proxy must be aware of what result fragments are available in the Ganesh drivers cache.",
                "One approach is to be optimistic, and to assume that all result fragments are available.",
                "This will result in the smallest possible initial transmission of a result.",
                "However, in cases where there is little overlap with previous results, the Ganesh driver will have to make many calls to the proxy during reconstruction to fetch missing result fragments.",
                "To avoid this situation, the proxy loosely tracks the state of the Ganesh drivers cache.",
                "Since both components are under our control, it is relatively simple to do this without resorting to gray-box techniques or explicit communication for maintaining cache coherence.",
                "Instead, the proxy simulates the Ganesh drivers cache management algorithm and uses this to maintain a list of hashes for which the Ganesh driver is likely to possess the result fragments.",
                "In case of mistracking, there will be no loss of correctness but there will be extra round-trip delays to fetch the missing fragments.",
                "If the client detects loss of synchronization with the proxy, it can ask the proxy to reset the state shared between them.",
                "Also note that the proxy does not need to keep the result fragments themselves, only their hashes.",
                "This allows the proxy to remain scalable even when it is shared by many front-end nodes.",
                "WWW 2007 / Track: Performance and Scalability Session: Scalable Systems for Dynamic Content 313 Object Output Stream Convert ResultSet Object Input Stream Convert ResultSet All Data Recipe ResultSet All Data ResultSet Network Ganesh Proxy Ganesh JDBC Driver Result Set Recipe Result Set Yes Yes No No GaneshInputStream GaneshOutputStream Figure 4: Dataflow for Result Handling 3.4 Encoding and Decoding Results The Ganesh proxy receives database output as Java objects from the native JDBC driver.",
                "It examines this output to see if a Java object of type ResultSet is present.",
                "The JDBC interface uses this data type to store results of database queries.",
                "If a ResultSet object is found, it is shrunk as discussed below.",
                "All other Java objects are passed through unmodified.",
                "As discussed in Section 3.1, the proxy uses the row boundaries defined in the ResultSet to partition it into fragments consisting of single result rows.",
                "All ResultSet objects are converted into objects of a new type called RecipeResultSet.",
                "We use the term recipe for this compact description of a database result because of its similarity to a file recipe in the CASPER file system [37].",
                "The conversion replaces each result fragment that is likely to be present in the Ganesh drivers cache by a SHA-1 hash of that fragment.",
                "Previously unseen result fragments are retained verbatim.",
                "The proxy also retains hashes for the new result fragments as they will be present in the drivers cache in the future.",
                "Note that the proxy only caches hashes for result fragments and does not cache recipes.",
                "The proxy constructs a RecipeResultSet by checking for similarity at the entire result and then the row level.",
                "If the entire result is predicted to be present in the Ganesh drivers cache, the RecipeResultSet is simply a single hash of the entire result.",
                "Otherwise, it contains hashes for those rows predicted to be present in that cache; all other rows are retained verbatim.",
                "If the proxy estimates an overall space savings, it will transmit the RecipeResultSet.",
                "Otherwise the original ResultSet is transmitted.",
                "The RecipeResultSet objects are transformed back into ResultSet objects by the Ganesh driver.",
                "Figure 4 illustrates ResultSet handling at both ends.",
                "Each SHA-1 hash found in a RecipeResultSet is looked up in the local cache of result fragments.",
                "On a hit, the hash is replaced by the corresponding fragment.",
                "On a miss, the driver contacts the Ganesh proxy to fetch the fragment.",
                "All previously unseen result fragments that were retained verbatim by the proxy are hashed and added to the result cache.",
                "There should be very few misses if the proxy has accurately tracked the Ganesh drivers cache state.",
                "A future optimization would be to batch the fetch of missing fragments.",
                "This would be valuable when there are many small missing fragments in a high-latency WAN.",
                "Once the transformation is complete, the fully reconstructed ResultSet object is passed up to the application. 4.",
                "EXPERIMENTAL VALIDATION Three questions follow from the goals and design of Ganesh: • First, can performance can be improved significantly by exploiting similarity across database results?",
                "Benchmark Dataset Details 500,000 Users, 12,000 Stories BBOARD 2.0 GB 3,298,000 Comments AUCTION 1.3 GB 1,000,000 Users, 34,000 Items Table 1: Benchmark Dataset Details • Second, how important is Ganeshs structural similarity detection relative to Rabin fingerprintings similarity detection? • Third, is the overhead of the proxy-based design acceptable?",
                "Our evaluation answers these question through controlled experiments with the Ganesh prototype.",
                "This section describes the benchmarks used, our evaluation procedure, and the experimental setup.",
                "Results of the experiments are presented in Sections 5, 6, and 7. 4.1 Benchmarks Our evaluation is based on two benchmarks [18] that have been widely used by other researchers to evaluate various aspects of multi-tier [27] and eBusiness architectures [9].",
                "The first benchmark, BBOARD, is modeled after Slashdot, a technology-oriented news site.",
                "The second benchmark, AUCTION, is modeled after eBay, an online auction site.",
                "In both benchmarks, most content is dynamically generated from information stored in a database.",
                "Details of the datasets used can be found in Table 1. 4.1.1 The BBOARD Benchmark The BBOARD benchmark, also known as RUBBoS [18], models Slashdot, a popular technology-oriented web site.",
                "Slashdot aggregates links to news stories and other topics of interest found elsewhere on the web.",
                "The site also serves as a bulletin board by allowing users to comment on the posted stories in a threaded conversation form.",
                "It is not uncommon for a story to gather hundreds of comments in a matter of hours.",
                "The BBOARD benchmark is similar to the site and models the activities of a user, including readonly operations such as browsing the stories of the day, browsing story categories, and viewing comments as well as write operations such as new user registration, adding and moderating comments, and story submission.",
                "The benchmark consists of three different phases: a short warmup phase, a runtime phase representing the main body of the workload, and a short cool-down phase.",
                "In this paper we only report results from the runtime phase.",
                "The warm-up phase is important in establishing dynamic system state, but measurements from that phase are not significant for our evaluation.",
                "The cool-down phase is solely for allowing the benchmark to shut down.",
                "The warm-up, runtime, and cool-down phases are 2, 15, and 2 minutes respectively.",
                "The number of simulated clients were 400, 800, 1200, and 1600.",
                "The benchmark is available in a Java Servlets and PHP version and has different datasets; we evaluated Ganesh using the Java Servlets version and the Expanded dataset.",
                "The BBOARD benchmark defines two different workloads.",
                "The first, the Authoring mix, consists of 70% read-only operations and 30% read-write operations.",
                "The second, the Browsing mix, contains only read-only operations and does not update the database. 4.1.2 The AUCTION Benchmark The AUCTION benchmark, also known as RUBiS [18], models eBay, the online auction site.",
                "The eBay web site is used to buy and sell items via an auction format.",
                "The main activities of a user include browsing, selling, or bidding for items.",
                "Modeling the activities on this site, this benchmark includes read-only activities such as browsing items by category and by region, as well as read-write WWW 2007 / Track: Performance and Scalability Session: Scalable Systems for Dynamic Content 314 NetEm Router Ganesh Proxy Clients Web and Application Server Database Server Figure 5: Experimental Setup activities such as bidding for items, buying and selling items, and leaving feedback.",
                "As with BBOARD, the benchmark consists of three different phases.",
                "The warm-up, runtime, and cool-down phases for this experiment are 1.5, 15, and 1 minutes respectively.",
                "We tested Ganesh with four client configurations where the number of test clients was set to 400, 800, 1200, and 1600.",
                "The benchmark is available in a Enterprise Java Bean (EJB), Java Servlets, and PHP version and has different datasets; we evaluated Ganesh with the Java Servlets version and the Expanded dataset.",
                "The AUCTION benchmark defines two different workloads.",
                "The first, the Bidding mix, consists of 70% read-only operations and 30% read-write operations.",
                "The second, the Browsing mix, contains only read-only operations and does not update the database. 4.2 Experimental Procedure Both benchmarks involve a synthetic workload of clients accessing a web server.",
                "The number of clients emulated is an experimental parameter.",
                "Each emulated client runs an instance of the benchmark in its own thread, using a matrix to transition between different benchmark states.",
                "The matrix defines a stochastic model with probabilities of transitioning between the different states that represent typical user actions.",
                "An example transition is a user logging into the AUCTION system and then deciding on whether to post an item for sale or bid on active auctions.",
                "Each client also models user think time between requests.",
                "The think time is modeled as an exponential distribution with a mean of 7 seconds.",
                "We evaluate Ganesh along two axes: number of clients and WAN bandwidth.",
                "Higher loads are especially useful in understanding Ganeshs performance when the CPU or disk of the database server or proxy is the limiting factor.",
                "A previous study has shown that approximately 50% of the wide-area Internet bottlenecks observed had an available bandwidth under 10 Mb/s [1].",
                "Based on this work, we focus our evaluation on the WAN bandwidth of 5 Mb/s with 66 ms of round-trip latency, representative of severely constrained network paths, and 20 Mb/s with 33 ms of round-trip latency, representative of a moderately constrained network path.",
                "We also report Ganeshs performance at 100 Mb/s with no added round-trip latency.",
                "This bandwidth, representative of an unconstrained network, is especially useful in revealing any potential overhead of Ganesh in situations where WAN bandwidth is not the limiting factor.",
                "For each combination of number of clients and WAN bandwidth, we measured results from the two configurations listed below: • Native: This configuration corresponds to Figure 3(a).",
                "Native avoids Ganeshs overhead in using a proxy and performing Java object serialization. • Ganesh: This configuration corresponds to Figure 3(b).",
                "For a given number of clients and WAN bandwidth, comparing these results to the corresponding Native results gives the performance benefit due to the Ganesh middleware system.",
                "The metric used to quantify the improvement in throughput is the number of client requests that can be serviced per second.",
                "The metric used to quantify Ganeshs overhead is the average response time for a client request.",
                "For all of the experiments, the Ganesh driver used by the application server used a cache size of 100,000 items1 .",
                "The proxy was effective in tracking the Ganesh drivers cache state; for all of our experiments the miss rate on the driver never exceeded 0.7%. 4.3 Experimental Setup The experimental setup used for the benchmarks can be seen in Figure 5.",
                "All machines were 3.2 GHz Pentium 4s (with HyperThreading enabled.)",
                "With the exception of the database server, all machines had 2 GB of SDRAM and ran the Fedora Core Linux distribution.",
                "The database server had 4 GB of SDRAM.",
                "We used Apaches Tomcat as both the application server that hosted the Java Servlets and the web server.",
                "Both benchmarks used Java Servlets to generate the dynamic content.",
                "The database server used the open source MySQL database.",
                "For the native JDBC drivers, we used the Connector/J drivers provided by MySQL.",
                "The application server used Suns Java Virtual Machine as the runtime environment for the Java Servlets.",
                "The sysstat tool was used to monitor the CPU, network, disk, and memory utilization on all machines.",
                "The machines were connected by a switched gigabit Ethernet network.",
                "As shown in Figure 5, the front-end web and application server was separated from the proxy and database server by a NetEm router [16].",
                "This router allowed us to control the bandwidth and latency settings on the network.",
                "The NetEm router is a standard PC with two network cards running the Linux Traffic Control and Network Emulation software.",
                "The bandwidth and latency constraints were only applied to the link between the application server and the database for the native case and between the application server and the proxy for the Ganesh case.",
                "There is no communication between the application server and the database with Ganesh as all data flows through the proxy.",
                "As our focus was on the WAN link between the application server and the database, there were no constraints on the link between the simulated test clients and the web server. 5.",
                "THROUGHPUT AND RESPONSE TIME In this section, we address the first question raised in Section 4: Can performance can be improved significantly by exploiting similarity across database results?",
                "To answer this question, we use results from the BBOARD and AUCTION benchmarks.",
                "We use two metrics to quantify the performance improvement obtainable through the use of Ganesh: throughput, from the perspective of the web server, and average response time, from the perspective of the client.",
                "Throughput is measured in terms of the number of client requests that can be serviced per second. 5.1 BBOARD Results and Analysis 5.1.1 Authoring Mix Figures 6 (a) and (b) present the average number of requests serviced per second and the average response time for these requests as perceived by the clients for BBOARDs Authoring Mix.",
                "As Figure 6 (a) shows, Native easily saturates the 5 Mb/s link.",
                "At 400 clients, the Native solution delivers 29 requests/sec with an average response time of 8.3 seconds.",
                "Natives throughput drops with an increase in test clients as clients timeout due to congestion at the application server.",
                "Usability studies have shown that response times above 10 seconds cause the user to move on to 1 As Java lacks a sizeof() operator, Java caches therefore limit their size based on the number of objects.",
                "The size of cache dumps taken at the end of the experiments never exceeded 212 MB.",
                "WWW 2007 / Track: Performance and Scalability Session: Scalable Systems for Dynamic Content 315 0 50 100 150 200 250 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Test Clients Requests/sec Native Ganesh 0.001 0.01 0.1 1 10 100 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Test Clients Avg.Resp.Time(sec) Native Ganesh Note Logscale (a) Throughput: Authoring Mix (b) Response Time: Authoring Mix 0 50 100 150 200 250 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Test Clients Requests/sec Native Ganesh 0.001 0.01 0.1 1 10 100 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Test Clients Avg.Resp.Time(sec) Native Ganesh Note Logscale (c) Throughput: Browsing Mix (d) Response Time: Browsing Mix Mean of three trials.",
                "The maximum standard deviation for throughput and response time was 9.8% and 11.9% of the corresponding mean.",
                "Figure 6: BBOARD Benchmark - Throughput and Average Response Time other tasks [24].",
                "Based on these numbers, increasing the number of test clients makes the Native system unusable.",
                "Ganesh at 5 Mb/s, however, delivers a twofold improvement with 400 test clients and a fivefold improvement at 1200 clients.",
                "Ganeshs performance drops slightly at 1200 and 1600 clients as the network is saturated.",
                "Compared to Native, Figure 6 (b) shows that Ganeshs response times are substantially lower with sub-second response times at 400 clients.",
                "Figure 6 (a) also shows that for 400 and 800 test clients Ganesh at 5 Mb/s has the same throughput and average response time as Native at 20 Mb/s.",
                "Only at 1200 and 1600 clients does Native at 20 Mb/s deliver higher throughput than Ganesh at 5 Mb/s.",
                "Comparing both Ganesh and Native at 20 Mb/s, we see that Ganesh is no longer bandwidth constrained and delivers up to a twofold improvement over Native at 1600 test clients.",
                "As Ganesh does not saturate the network with higher test client configurations, at 1600 test clients, its average response time is 0.1 seconds rather than Natives 7.7 seconds.",
                "As expected, there are no visible gains from Ganesh at the higher bandwidth of 100 Mb/s where the network is no longer the bottleneck.",
                "Ganesh, however, still tracks Native in terms of throughput. 5.1.2 Browsing Mix Figures 6 (c) and (d) present the average number of requests serviced per second and the average response time for these requests as perceived by the clients for BBOARDs Browsing Mix.",
                "Regardless of the test client configuration, Figure 6 (c) shows that Natives throughput at 5 Mb/s is limited to 10 reqs/sec.",
                "Ganesh at 5 Mb/s with 400 test clients, delivers more than a sixfold increase in throughput.",
                "The improvement increases to over a elevenfold increase at 800 test clients before Ganesh saturates the network.",
                "Further, Figure 6 (d) shows that Natives average response time of 35 seconds at 400 test clients make the system unusable.",
                "These high response times further increase with the addition of test clients.",
                "Even with the 1600 test client configuration Ganesh delivers an acceptable average response time of 8.2 seconds.",
                "Due to the data-intensive nature of the Browsing mix, Ganesh at 5 Mb/s surprisingly performs much better than Native at 20 Mb/s.",
                "Further, as shown in Figure 6 (d), while the average response time for Native at 20 Mb/s is acceptable at 400 test clients, it is unusable with 800 test clients with an average response time of 15.8 seconds.",
                "Like the 5 Mb/s case, this response time increases with the addition of extra test clients.",
                "Ganesh at 20 Mb/s and both Native and Ganesh at 100 Mb/s are not bandwidth limited.",
                "However, performance plateaus out after 1200 test clients due to the database CPU being saturated. 5.1.3 Filter Variant We were surprised by the Native performance from the BBOARD benchmark.",
                "At the bandwidth of 5 Mb/s, Native performance was lower than what we had expected.",
                "It turned out the benchmark code that displays stories read all the comments associated with the particular story from the database and only then did some postprocessing to select the comments to be displayed.",
                "While this is exactly the behavior of SlashCode, the code base behind the Slashdot web site, we decided to modify the benchmark to perform some pre-filtering at the database.",
                "This modified benchmark, named the Filter Variant, models a developer who applies optimizations at the SQL level to transfer less data.",
                "In the interests of brevity, we only briefly summarize the results from the Authoring mix.",
                "For the Authoring mix, at 800 test clients at 5 Mb/s, Figure 7 (a) shows that Natives throughput increase by 85% when compared to the original benchmark while Ganeshs improvement is smaller at 15%.",
                "Natives performance drops above 800 clients as the test clients time out due to high response times.",
                "The most significant gain for Native is seen at 20 Mb/s.",
                "At 1600 test clients, when compared to the original benchmark, Native sees a 73% improvement in throughput and a 77% reduction in average response time.",
                "While WWW 2007 / Track: Performance and Scalability Session: Scalable Systems for Dynamic Content 316 0 50 100 150 200 250 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Test Clients Requests/sec Native Ganesh 0.001 0.01 0.1 1 10 100 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Test Clients Avg.Resp.Time(sec) Native Ganesh Note Logscale (a) Throughput: Authoring Mix (b) Response Time: Authoring Mix Mean of three trials.",
                "The maximum standard deviation for throughput and response time was 7.2% and 11.5% of the corresponding mean.",
                "Figure 7: BBOARD Benchmark - Filter Variant - Throughput and Average Response Time Ganesh sees no improvement when compared to the original, it still processes 19% more requests/sec than Native.",
                "Thus, while the optimizations were more helpful to Native, Ganesh still delivers an improvement in performance. 5.2 AUCTION Results and Analysis 5.2.1 Bidding Mix Figures 8 (a) and (b) present the average number of requests serviced per second and the average response time for these requests as perceived by the clients for AUCTIONs Bidding Mix.",
                "As mentioned earlier, the Bidding mix consists of a mixture of read and write operations.",
                "The AUCTION benchmark is not as data intensive as BBOARD.",
                "Therefore, most of the gains are observed at the lower bandwidth of 5 Mb/s.",
                "Figure 8 (a) shows that the increase in throughput due to Ganesh ranges from 8% at 400 test clients to 18% with 1600 test clients.",
                "As seen in Figure 8 (b), the average response times for Ganesh are significantly lower than Native ranging from a decrease of 84% at 800 test clients to 88% at 1600 test clients.",
                "Figure 8 (a) also shows that with a fourfold increase of bandwidth from 5 Mb/s to 20 Mb/s, Native is no longer bandwidth constrained and there is no performance difference between Ganesh and Native.",
                "With the higher test client configurations, we did observe that the bandwidth used by Ganesh was lower than Native.",
                "Ganesh might still be useful in these non-constrained scenarios if bandwidth is purchased on a metered basis.",
                "Similar results are seen for the 100 Mb/s scenario. 5.2.2 Browsing Mix For AUCTIONs Browsing Mix, Figures 8 (c) and (d) present the average number of requests serviced per second and the average response time for these requests as perceived by the clients.",
                "Again, most of the gains are observed at lower bandwidths.",
                "At 5 Mb/s, Native and Ganesh deliver similar throughput and response times with 400 test clients.",
                "While the throughput for both remains the same at 800 test clients, Figure 8 (d) shows that Ganeshs average response time is 62% lower than Native.",
                "Native saturates the link at 800 clients and adding extra test clients only increases the average response time.",
                "Ganesh, regardless of the test client configuration, is not bandwidth constrained and maintains the same response time.",
                "At 1600 test clients, Figure 8 (c) shows that Ganeshs throughput is almost twice that of Native.",
                "At the higher bandwidths of 20 and 100 Mb/s, neither Ganesh nor Native is bandwidth limited and deliver equivalent throughput and response times.",
                "Benchmark Orig.",
                "Size Ganesh Size Rabin Size SelectSort1 223.6 MB 5.4 MB 219.3 MB SelectSort2 223.6 MB 5.4 MB 223.6 MB Table 2: Similarity Microbenchmarks 6.",
                "STRUCTURAL VS. RABIN SIMILARITY In this section, we address the second question raised in Section 4: How important is Ganeshs structural similarity detection relative to Rabin fingerprinting-based similarity detecting?",
                "To answer this question, we used microbenchmarks and the BBOARD and AUCTION benchmarks.",
                "As Ganesh always performed better than Rabin fingerprinting, we only present a subset of the results here in the interests of brevity. 6.1 Microbenchmarks Two microbenchmarks show an example of the effects of data reordering on Rabin fingerprinting algorithm.",
                "In the first microbenchmark, SelectSort1, a query with a specified sort order selects 223.6 MB of data spread over approximately 280 K rows.",
                "The query is then repeated with a different sort attribute.",
                "While the same number of rows and the same data is returned, the order of rows is different.",
                "In such a scenario, one would expect a large amount of similarity to be detected between both results.",
                "As Table 2 shows, Ganeshs row-based algorithm achieves a 97.6% reduction while the Rabin fingerprinting algorithm, with the average chunk size parameter set to 4 KB, only achieves a 1% reduction.",
                "The reason, as shown earlier in Figure 2, is that with Rabin fingerprinting, the spans of data between two consecutive boundaries usually cross row boundaries.",
                "With the order of the rows changing in the second result and the Rabin fingerprints now spanning different rows, the algorithm is unable to detect significant similarity.",
                "The small gain seen is mostly for those single rows that are large enough to be broken into multiple chunks.",
                "SelectSort2, another micro-benchmark executed the same queries but increased the minimum chunk size of the Rabin fingerprinting algorithm.",
                "As can be seen in Table 2, even the small gain from the previous microbenchmark disappears as the minimum chunk size was greater than the average row size.",
                "While one can partially address these problems by dynamically varying the parameters of the Rabin fingerprinting algorithm, this can be computationally expensive, especially in the presence of changing workloads. 6.2 Application Benchmarks We ran the BBOARD benchmark described in Section 4.1.1 on two versions of Ganesh: the first with Rabin fingerprinting used as WWW 2007 / Track: Performance and Scalability Session: Scalable Systems for Dynamic Content 317 0 50 100 150 200 250 300 350 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Test Clients Requests/sec Native Ganesh 0.001 0.01 0.1 1 10 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Test Clients Avg.Resp.Time(sec) Native Ganesh Note Logscale (a) Throughput: Bidding Mix (b) Response Time: Bidding Mix 0 50 100 150 200 250 300 350 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Test Clients Requests/sec Native Ganesh 0.001 0.01 0.1 1 10 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Test Clients Avg.Resp.Time(sec) Native Ganesh Note Logscale (c) Throughput: Browsing Mix (d) Response Time: Browsing Mix Mean of three trials.",
                "The maximum standard deviation for throughput and response time was 2.2% and 11.8% of the corresponding mean.",
                "Figure 8: AUCTION Benchmark - Throughput and Average Response Time the chunking algorithm and the second with Ganeshs row-based algorithm.",
                "Rabins results for the Browsing Mix are normalized to Ganeshs results and presented in Figure 9.",
                "As Figure 9 (a) shows, at 5 Mb/s, independent of the test client configuration, Rabin significantly underperforms Ganesh.",
                "This happens because of a combination of two reasons.",
                "First, as outlined in Section 3.1, Rabin finds less similarity as it does not exploit the results structural information.",
                "Second, this benchmark contained some queries that generated large results.",
                "In this case, Rabin, with a small average chunk size, generated a large number of objects that evicted other useful data from the cache.",
                "In contrast, Ganesh was able to detect these large rows and correspondingly increase the size of the chunks.",
                "This was confirmed as cache statistics showed that Ganeshs hit ratio was roughly three time that of Rabin.",
                "Throughput measurements at 20 Mb/s were similar with the exception of Rabins performance with 400 test clients.",
                "In this case, Ganesh was not network limited and, in fact, the throughput was the same as 400 clients at 5 Mb/s.",
                "Rabin, however, took advantage of the bandwidth increase from 5 to 20 Mb/s to deliver a slightly better performance.",
                "At 100 Mb/s, Rabins throughput was almost similar to Ganesh as bandwidth was no longer a bottleneck.",
                "The normalized response time, presented in Figure 9 (b), shows similar trends.",
                "At 5 and 20 Mb/s, the addition of test clients decreases the normalized response time as Ganeshs average response time increases faster than Rabins.",
                "However, at no point does Rabin outperform Ganesh.",
                "Note that at 400 and 800 clients at 100 Mb/s, Rabin does have a higher overhead even when it is not bandwidth constrained.",
                "As mentioned in Section 3.1, this is due to the fact that Rabin has to hash each ResultSet twice.",
                "The overhead disappears with 1200 and 1600 clients as the database CPU is saturated and limits the performance of both Ganesh and Rabin. 7.",
                "PROXY OVERHEAD In this section, we address the third question raised in Section 4: Is the overhead of Ganeshs proxy-based design acceptable?",
                "To answer this question, we concentrate on its performance at the higher bandwidths.",
                "Our evaluation in Section 5 showed that Ganesh, when compared to Native, can deliver a substantial throughput improvement at lower bandwidths.",
                "It is only at higher bandwidths that latency, measured by the average response time for a client request, and throughput, measured by the number of client requests that can be serviced per second, overheads would be visible.",
                "Looking at the Authoring mix of the original BBOARD benchmark, there are no visible gains from Ganesh at 100 Mb/s.",
                "Ganesh, however, still tracks Native in terms of throughput.",
                "While the average response time is higher for Ganesh, the absolute difference is in between 0.01 and 0.04 seconds and would be imperceptible to the end-user.",
                "The Browsing mix shows an even smaller difference in average response times.",
                "The results from the filter variant of the BBOARD benchmarks are similar.",
                "Even for the AUCTION benchmark, the difference between Native and Ganeshs response time at 100 Mb/s was never greater than 0.02 seconds.",
                "The only exception to the above results was seen in the filter variant of the BBOARD benchmark where Ganesh at 1600 test clients added 0.85 seconds to the average response time.",
                "Thus, even for much faster networks where the WAN link is not the bottleneck, Ganesh always delivers throughput equivalent to Native.",
                "While some extra latency is added by the proxy-based design, it is usually imperceptible. 8.",
                "RELATED WORK To the best of our knowledge, Ganesh is the first system that combines the use of hash-based techniques with caching of database results to improve throughput and response times for applications with dynamic content.",
                "We also believe that it is also the first system to demonstrate the benefits of using structural information for WWW 2007 / Track: Performance and Scalability Session: Scalable Systems for Dynamic Content 318 0.0 0.2 0.4 0.6 0.8 1.0 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Test Clients Norm.Throughput 31.8 3.8 2.8 2.3 23.8 32.8 5.8 3.6 1.8 2.1 1.1 1.0 0 5 10 15 20 25 30 35 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Test Clients Norm.ResponseTime (a) Normalized Throughput: Higher is better (b) Normalized Response Time: Higher is worse For throughput, a normalized result greater than 1 implies that Rabin is better, For response time, a normalized result greater than 1 implies that Ganesh is better.",
                "Mean of three trials.",
                "The maximum standard deviation for throughput and response time was 9.1% and 13.9% of the corresponding mean.",
                "Figure 9: Normalized Comparison of Ganesh vs. Rabin - BBOARD Browsing Mix detecting similarity.",
                "In this section, we first discuss alternative approaches to caching dynamic content and then examine other uses of hash-based primitives in distributed systems. 8.1 Caching Dynamic Content At the database layer, a number of systems have advocated middletier caching where parts of the database are replicated at the edge or server [3, 4, 20].",
                "These systems either cache entire tables in what is essentially a replicated database or use materialized views from previous query replies [19].",
                "They require tight integration with the back-end database to ensure a time bound on the propagation of updates.",
                "These systems are also usually targeted towards workloads that do not require strict consistency and can tolerate stale data.",
                "Further, unlike Ganesh, some of these mid-tier caching solutions [2, 3], suffer from the complexity of having to participate in query planing and distributed query processing.",
                "Gao et al. [15] propose using a distributed object replication architecture where the data stores consistency requirements are adapted on a per-application basis.",
                "These solutions require substantial developer resources and detailed understanding of the application being modified.",
                "While systems that attempt to automate the partitioning and replication of an applications database exist [34], they do not provide full transaction semantics.",
                "In comparison, Ganesh does not weaken any of the semantics provided by the underlying database.",
                "Recent work in the evaluation of edge caching options for dynamic web sites [38] has suggested that, without careful planning, employing complex offloading strategies can hurt performance.",
                "Instead, the work advocates for an architecture in which all tiers except the database should be offloaded to the edge.",
                "Our evaluation of Ganesh has shown that it would benefit these scenarios.",
                "To improve database scalability, C-JDBC [10], SSS [22], and Ganymed [28] also advocate the use of an interposition-based architecture to transparently cluster and replicate databases at the middleware level.",
                "The approaches of these architectures and Ganesh are complementary and they would benefit each other.",
                "Moving up to the presentation layer, there has been widespread adoption of fragment-based caching [14], which improves cache utilization by separately caching different parts of generated web pages.",
                "While fragment-based caching works at the edge, a recent proposal has proposed moving web page assembly to the clients to optimize content delivery [31].",
                "While Ganesh is not used at the presentation layer, the same principles have been applied in Duplicate Transfer Detection [25] to increase web cache efficiency as well as for web access across bandwidth limited links [33]. 8.2 Hash-based Systems The past few years have seen the emergence of many systems that exploit hash-based techniques.",
                "At the heart of all these systems is the idea of detecting similarity in data without requiring interpretation of that data.",
                "This simple yet elegant idea relies on cryptographic hashing, as discussed earlier in Section 2.",
                "Successful applications of this idea span a wide range of storage systems.",
                "Examples include peer-to-peer backup of personal computing files [11], storage-efficient archiving of data [29], and finding similar files [21].",
                "Spring and Wetherall [35] apply similar principles at the network level.",
                "Using synchronized caches at both ends of a network link, duplicated data is replaced by smaller tokens for transmission and then restored at the remote end.",
                "This and other hash-based systems such as the CASPER [37] and LBFS [26] filesystems, and Layer-2 bandwidth optimizers such as Riverbed and Peribit use Rabin fingerprinting [30] to discover spans of commonality in data.",
                "This approach is especially useful when data items are modified in-place through insertions, deletions, and updates.",
                "However, as Section 6 shows, the performance of this technique can show a dramatic drop in the presence of data reordering.",
                "Ganesh instead uses row boundaries as dividers for detecting similarity.",
                "The most aggressive use of hash-based techniques is by systems that use hashes as the primary identifiers for objects in persistent storage.",
                "Storage systems such as CFS [12] and PAST [13] that have been built using distributed hash tables fall into this category.",
                "Single Instance Storage [6] and Venti [29] are other examples of such systems.",
                "As discussed in Section 2.2, the use of cryptographic hashes for addressing persistent data represents a deeper level of faith in their collision-resistance than that assumed by Ganesh.",
                "If time reveals shortcomings in the hash algorithm, the effort involved in correcting the flaw is much greater.",
                "In Ganesh, it is merely a matter of replacing the hash algorithm. 9.",
                "CONCLUSION The growing use of dynamic web content generated from relational databases places increased demands on WAN bandwidth.",
                "Traditional caching solutions for bandwidth and latency reduction are often ineffective for such content.",
                "This paper shows that the impact of WAN accesses to databases can be substantially reduced through the Ganesh architecture without any compromise of the databases strict consistency semantics.",
                "The essence of the Ganesh architecture is the use of computation at the edges to reduce communication through the Internet.",
                "Ganesh is able to use cryptographic hashes to detect similarity with previous results and send WWW 2007 / Track: Performance and Scalability Session: Scalable Systems for Dynamic Content 319 compact recipes of results rather than full results.",
                "Our design uses interposition to achieve complete transparency: clients, application servers, and database servers are all unaware of Ganeshs presence and require no modification.",
                "Our experimental evaluation confirms that Ganesh, while conceptually simple, can be highly effective in improving throughput and response time.",
                "Our results also confirm that exploiting the structure present in database results to detect similarity is crucial to this performance improvement. 10.",
                "REFERENCES [1] AKELLA, A., SESHAN, S., AND SHAIKH, A.",
                "An empirical evaluation of wide-area internet bottlenecks.",
                "In Proc. 3rd ACM SIGCOMM Conference on Internet Measurement (Miami Beach, FL, USA, Oct. 2003), pp. 101-114. [2] ALTINEL, M., BORNH ¨OVD, C., KRISHNAMURTHY, S., MOHAN, C., PIRAHESH, H., AND REINWALD, B. Cache tables: Paving the way for an adaptive <br>database cache</br>.",
                "In Proc. of 29th VLDB (Berlin, Germany, 2003), pp. 718-729. [3] ALTINEL, M., LUO, Q., KRISHNAMURTHY, S., MOHAN, C., PIRAHESH, H., LINDSAY, B. G., WOO, H., AND BROWN, L. Dbcache: Database caching for web application servers.",
                "In Proc. 2002 ACM SIGMOD (2002), pp. 612-612. [4] AMIRI, K., PARK, S., TEWARI, R., AND PADMANABHAN, S. Dbproxy: A dynamic data cache for web applications.",
                "In Proc.",
                "IEEE International Conference on Data Engineering (ICDE) (Mar. 2003). [5] BLACK, J. Compare-by-hash: A reasoned analysis.",
                "In Proc. 2006 USENIX Annual Technical Conference (Boston, MA, May 2006), pp. 85-90. [6] BOLOSKY, W. J., CORBIN, S., GOEBEL, D., , AND DOUCEUR, J. R. Single instance storage in windows 2000.",
                "In Proc. 4th USENIX Windows Systems Symposium (Seattle, WA, Aug. 2000), pp. 13-24. [7] BREWER, E. A.",
                "Lessons from giant-scale services.",
                "IEEE Internet Computing 5, 4 (2001), 46-55. [8] BRODER, A., GLASSMAN, S., MANASSE, M., AND ZWEIG, G. Syntactic clustering of the web.",
                "In Proc. 6th International WWW Conference (1997). [9] CECCHET, E., CHANDA, A., ELNIKETY, S., MARGUERITE, J., AND ZWAENEPOEL, W. Performance comparison of middleware architectures for generating dynamic web content.",
                "In Proc.",
                "Fourth ACM/IFIP/USENIX International Middleware Conference (Rio de Janeiro, Brazil, June 2003). [10] CECCHET, E., MARGUERITE, J., AND ZWAENEPOEL, W. C-JDBC: Flexible database clustering middleware.",
                "In Proc. 2004 USENIX Annual Technical Conference (Boston, MA, June 2004). [11] COX, L. P., MURRAY, C. D., AND NOBLE, B. D. Pastiche: Making backup cheap and easy.",
                "In OSDI: Symposium on Operating Systems Design and Implementation (2002). [12] DABEK, F., KAASHOEK, M. F., KARGER, D., MORRIS, R., AND STOICA, I. Wide-area cooperative storage with CFS.",
                "In 18th ACM Symposium on Operating Systems Principles (Banff, Canada, Oct. 2001). [13] DRUSCHEL, P., AND ROWSTRON, A.",
                "PAST: A large-scale, persistent peer-to-peer storage utility.",
                "In HotOS VIII (Schloss Elmau, Germany, May 2001), pp. 75-80. [14] Edge side includes. http://www.esi.org. [15] GAO, L., DAHLIN, M., NAYATE, A., ZHENG, J., AND IYENGAR, A.",
                "Application specific data replication for edge services.",
                "In WWW 03: Proc.",
                "Twelfth International Conference on World Wide Web (2003), pp. 449-460. [16] HEMMINGER, S. Netem - emulating real networks in the lab.",
                "In Proc. 2005 Linux Conference Australia (Canberra, Australia, Apr. 2005). [17] HENSON, V. An analysis of compare-by-hash.",
                "In Proc. 9th Workshop on Hot Topics in Operating Systems (HotOS IX) (May 2003), pp. 13-18. [18] Jmob benchmarks. http://jmob.objectweb.org/. [19] LABRINIDIS, A., AND ROUSSOPOULOS, N. Balancing performance and data freshness in web database servers.",
                "In Proc. 29th VLDB Conference (Sept. 2003). [20] LARSON, P.-A., GOLDSTEIN, J., AND ZHOU, J. Transparent mid-tier database caching in sql server.",
                "In Proc. 2003 ACM SIGMOD (2003), pp. 661-661. [21] MANBER, U.",
                "Finding similar files in a large file system.",
                "In Proc.",
                "USENIX Winter 1994 Technical Conference (San Fransisco, CA, 17-21 1994), pp. 1-10. [22] MANJHI, A., AILAMAKI, A., MAGGS, B. M., MOWRY, T. C., OLSTON, C., AND TOMASIC, A.",
                "Simultaneous scalability and security for data-intensive web applications.",
                "In Proc. 2006 ACM SIGMOD (June 2006), pp. 241-252. [23] MENEZES, A. J., VANSTONE, S. A., AND OORSCHOT, P. C. V. Handbook of Applied Cryptography.",
                "CRC Press, 1996. [24] MILLER, R. B.",
                "Response time in man-computer conversational transactions.",
                "In Proc.",
                "AFIPS Fall Joint Computer Conference (1968), pp. 267-277. [25] MOGUL, J. C., CHAN, Y. M., AND KELLY, T. Design, implementation, and evaluation of duplicate transfer detection in http.",
                "In Proc.",
                "First Symposium on Networked Systems Design and Implementation (San Francisco, CA, Mar. 2004). [26] MUTHITACHAROEN, A., CHEN, B., AND MAZIERES, D. A low-bandwidth network file system.",
                "In Proc. 18th ACM Symposium on Operating Systems Principles (Banff, Canada, Oct. 2001). [27] PFEIFER, D., AND JAKSCHITSCH, H. Method-based caching in multi-tiered server applications.",
                "In Proc.",
                "Fifth International Symposium on Distributed Objects and Applications (Catania, Sicily, Italy, Nov. 2003). [28] PLATTNER, C., AND ALONSO, G. Ganymed: Scalable replication for transactional web applications.",
                "In Proc. 5th ACM/IFIP/USENIX International Conference on Middleware (2004), pp. 155-174. [29] QUINLAN, S., AND DORWARD, S. Venti: A new approach to archival storage.",
                "In Proc.",
                "FAST 2002 Conference on File and Storage Technologies (2002). [30] RABIN, M. Fingerprinting by random polynomials.",
                "In Harvard University Center for Research in Computing Technology Technical Report TR-15-81 (1981). [31] RABINOVICH, M., XIAO, Z., DOUGLIS, F., AND KALMANEK, C. Moving edge side includes to the real edge - the clients.",
                "In Proc. 4th USENIX Symposium on Internet Technologies and Systems (Seattle, WA, Mar. 2003). [32] REESE, G. Database Programming with JDBC and Java, 1st ed.",
                "OReilly, June 1997. [33] RHEA, S., LIANG, K., AND BREWER, E. Value-based web caching.",
                "In Proc.",
                "Twelfth International World Wide Web Conference (May 2003). [34] SIVASUBRAMANIAN, S., ALONSO, G., PIERRE, G., AND VAN STEEN, M. Globedb: Autonomic data replication for web applications.",
                "In WWW 05: Proc. 14th International World-Wide Web conference (May 2005). [35] SPRING, N. T., AND WETHERALL, D. A protocol-independent technique for eliminating redundant network traffic.",
                "In Proc. of ACM SIGCOMM (Aug. 2000). [36] TOLIA, N., HARKES, J., KOZUCH, M., AND SATYANARAYANAN, M. Integrating portable and distributed storage.",
                "In Proc. 3rd USENIX Conference on File and Storage Technologies (San Francisco, CA, Mar. 2004). [37] TOLIA, N., KOZUCH, M., SATYANARAYANAN, M., KARP, B., PERRIG, A., AND BRESSOUD, T. Opportunistic use of content addressable storage for distributed file systems.",
                "In Proc. 2003 USENIX Annual Technical Conference (San Antonio, TX, June 2003), pp. 127-140. [38] YUAN, C., CHEN, Y., AND ZHANG, Z.",
                "Evaluation of edge caching/offloading for dynamic content delivery.",
                "In WWW 03: Proc.",
                "Twelfth International Conference on World Wide Web (2003), pp. 461-471.",
                "WWW 2007 / Track: Performance and Scalability Session: Scalable Systems for Dynamic Content 320"
            ],
            "original_annotated_samples": [
                "In Proc. 3rd ACM SIGCOMM Conference on Internet Measurement (Miami Beach, FL, USA, Oct. 2003), pp. 101-114. [2] ALTINEL, M., BORNH ¨OVD, C., KRISHNAMURTHY, S., MOHAN, C., PIRAHESH, H., AND REINWALD, B. Cache tables: Paving the way for an adaptive <br>database cache</br>."
            ],
            "translated_annotated_samples": [
                "En Proc. 3ª Conferencia ACM SIGCOMM sobre Medición de Internet (Miami Beach, FL, EE. UU., Oct. 2003), pp. 101-114. [2] ALTINEL, M., BORNH ¨OVD, C., KRISHNAMURTHY, S., MOHAN, C., PIRAHESH, H., Y REINWALD, B. Tablas de caché: allanando el camino para una <br>caché de base de datos</br> adaptativa."
            ],
            "translated_text": "Conservación de la consistencia en el almacenamiento en caché de contenido dinámico de bases de datos∗ Niraj Tolia y M. Satyanarayanan Universidad Carnegie Mellon {ntolia,satya}@cs.cmu.edu RESUMEN Con el creciente uso de contenido web dinámico generado a partir de bases de datos relacionales, las soluciones de almacenamiento en caché tradicionales para mejorar el rendimiento y la latencia son ineficaces. Describimos una capa de middleware llamada Ganesh que reduce el volumen de datos transmitidos sin interpretación semántica de consultas o resultados. Se logra esta reducción mediante el uso de hash criptográficos para detectar similitudes con resultados anteriores. Estos beneficios no requieren ningún compromiso con la semántica de consistencia estricta proporcionada por la base de datos del servidor. Además, Ganesh no requiere modificaciones en aplicaciones, servidores web o servidores de bases de datos, y funciona con aplicaciones y bases de datos de código cerrado. Usando dos puntos de referencia representativos de sitios web dinámicos, las mediciones de nuestro prototipo muestran que puede aumentar el rendimiento de extremo a extremo hasta en un factor de dos para aplicaciones no intensivas en datos y hasta en un factor de diez para las intensivas en datos. Categorías y Descriptores de Asignaturas C.2.4 [Redes de Computadoras-Comunicación]: Sistemas Distribuidos; H.2.4 [Gestión de Bases de Datos]: Términos Generales de Sistemas de Diseño, Rendimiento 1. INTRODUCCIÓN Una fracción creciente del contenido web se genera dinámicamente a partir de bases de datos relacionales en el backend. Incluso cuando el contenido de la base de datos permanece sin cambios, la localidad temporal de acceso no puede ser explotada porque el contenido dinámico no es almacenable en caché por los navegadores web o por servidores de almacenamiento en caché intermedios como los espejos de Akamai. En una arquitectura multinivel, cada solicitud web puede tensionar el enlace WAN entre el servidor web y la base de datos. Esto provoca que la experiencia del usuario sea altamente variable porque no hay almacenamiento en caché para aislar al cliente de cargas repentinas. Los intentos previos de almacenar en caché contenido dinámico de bases de datos generalmente han debilitado la semántica transaccional [3, 4] o han requerido modificaciones en la aplicación [15, 34]. Informamos sobre una nueva solución que toma la forma de una capa intermedia de middleware independiente de la base de datos llamada Ganesh. Ganesh no hace ningún esfuerzo por interpretar semánticamente el contenido de las consultas o sus resultados. En cambio, se basa exclusivamente en el hash criptográfico para detectar similitudes con resultados anteriores. La detección de similitud basada en hash ha sido cada vez más utilizada en sistemas de archivos distribuidos [26, 36, 37] para mejorar el rendimiento en redes de baja capacidad de ancho de banda. Sin embargo, estas técnicas no se han utilizado para bases de datos relacionales. A diferencia de enfoques anteriores que utilizan métodos genéricos para detectar similitud, Ganesh explota la estructura de los resultados de la base de datos relacional para lograr una mejora superior en el rendimiento. Uno se enfrenta al menos a tres desafíos al aplicar la detección de similitud basada en hash a las bases de datos de back-end. Primero, el trabajo previo en este ámbito ha considerado tradicionalmente el contenido de almacenamiento como bolsas de bits no interpretadas y sin estructura interna. Esto permite que las técnicas basadas en hash operen en largas y contiguas secuencias de datos para lograr la máxima efectividad. Por el contrario, las bases de datos relacionales tienen una estructura interna compleja que puede no ser tan propicia para la detección de similitudes basada en hash. Segundo, las bases de datos relacionales tienen restricciones de integridad y consistencia muy estrictas que no deben comprometerse por el uso de técnicas basadas en hash. Tercero, el código fuente de las bases de datos comerciales generalmente no está disponible. Esto contrasta con trabajos anteriores que presumían la disponibilidad del código fuente. Nuestros experimentos muestran que Ganesh, aunque conceptualmente simple, puede mejorar significativamente el rendimiento en anchos de banda representativos del Internet comercial actual. En los modelos de referencia de aplicaciones web multinivel, la mejora en el rendimiento fue de hasta diez veces para cargas de trabajo intensivas en datos. Para cargas de trabajo que no eran intensivas en datos, se observaron mejoras en el rendimiento de hasta el doble. Incluso cuando el ancho de banda no era una limitación, Ganesh tenía un bajo sobrecosto y no afectaba el rendimiento. Nuestros experimentos también confirman que aprovechar la estructura presente en los resultados de la base de datos es crucial para esta mejora en el rendimiento. Antecedentes 2.1 Generación de Contenido Dinámico A medida que la World Wide Web ha crecido, muchos sitios web han descentralizado sus datos y funcionalidades al llevarlos a los extremos de Internet. Hoy en día, los sistemas de comercio electrónico a menudo utilizan una arquitectura de tres niveles que consta de un servidor web de front-end, un servidor de aplicaciones y un servidor de base de datos de back-end. La Figura 1 ilustra esta arquitectura. Los dos primeros niveles se pueden replicar cerca de una concentración de clientes en el borde de Internet. Esto mejora la experiencia del usuario al reducir la latencia de extremo a extremo y disminuir la exposición al congestionamiento del tráfico de la columna vertebral. También puede aumentar la disponibilidad y escalabilidad de los servicios web. El contenido que se genera dinámicamente desde la base de datos del servidor no puede ser almacenado en caché en los dos primeros niveles. Si bien las bases de datos pueden replicarse fácilmente en una LAN, esto es inviable en una WAN debido a la difícil tarea de proporcionar simultáneamente una consistencia sólida, disponibilidad y tolerancia a particiones de red [7]. Como resultado, las bases de datos tienden a ser centralizadas para cumplir con los fuertes requisitos de consistencia de muchas aplicaciones de comercio electrónico como la banca, las finanzas y la venta al por menor en línea [38]. Por lo tanto, la base de datos del back-end suele estar ubicada lejos de muchos conjuntos de nodos de primer y segundo nivel [2]. En ausencia de almacenamiento en caché y replicación, el ancho de banda de la WAN puede convertirse fácilmente en un factor limitante en el rendimiento y la escalabilidad de aplicaciones intensivas en datos. El enfoque de Ganesh en los sistemas basados en hash es la transmisión eficiente de resultados al descubrir similitudes con los resultados de consultas anteriores. Dado que las consultas SQL pueden generar resultados grandes, las técnicas basadas en hash se prestan bien al problema de transferir eficientemente estos grandes resultados a través de enlaces con ancho de banda limitado. El uso de técnicas basadas en hash para reducir el volumen de datos transmitidos ha surgido como un tema común en muchos sistemas de almacenamiento recientes, como se discute en la Sección 8.2. Estas técnicas se basan en algunas suposiciones básicas. Se asume que las funciones hash criptográficas son resistentes a colisiones. En otras palabras, es computacionalmente intratable encontrar dos entradas que se hash a la misma salida. Las funciones también se asumen como unidireccionales; es decir, encontrar una entrada que resulte en una salida específica es computacionalmente inviable. Menezes et al. [23] proporcionan más detalles sobre estas suposiciones. Las suposiciones anteriores permiten a los sistemas basados en hash asumir que no se producen colisiones. Por lo tanto, pueden tratar el hash de un elemento de datos como su identificador único. Una colección de elementos de datos se convierte efectivamente en direccionable por contenido, permitiendo que un hash pequeño funcione como una palabra de código para un elemento de datos mucho más grande en almacenamiento permanente o transmisión en red. La suposición de que las colisiones son tan raras que prácticamente no existen ha sido cuestionada recientemente [17]. Sin embargo, como explicó Black [5], creemos que estos problemas no son una preocupación para Ganesh. Toda comunicación es entre partes confiables del sistema y un adversario no tiene forma de obligar a Ganesh a aceptar datos inválidos. Además, Ganesh no depende críticamente de ninguna función hash específica. Si bien actualmente usamos SHA-1, reemplazarlo con una función hash diferente sería sencillo. No habría impacto en el rendimiento con funciones hash más fuertes (por ejemplo, SHA256) solo añade unos pocos bytes adicionales y los hashes generados siguen siendo órdenes de magnitud más pequeños que los elementos de datos que representan. No es necesario volver a almacenar permanentemente ya que Ganesh solo utiliza el hash en datos volátiles. 3. DISEÑO E IMPLEMENTACIÓN Ganesh explota la redundancia en el flujo de resultados para evitar transmitir fragmentos de resultados que ya están presentes en el sitio de la consulta. La redundancia puede surgir de forma natural de muchas maneras diferentes. Por ejemplo, una consulta repetida después de un cierto intervalo puede devolver un resultado diferente debido a actualizaciones en la base de datos; sin embargo, puede haber una significativa similitud entre los dos resultados. Como otro ejemplo, un usuario que está refinando una búsqueda puede generar una secuencia de consultas con resultados superpuestos. Cuando Ganesh detecta redundancia, suprime la transmisión de los fragmentos de resultado correspondientes. En cambio, transmite un resumen mucho más pequeño de esos fragmentos y permite que el sitio de consulta reconstruya el resultado a través de la búsqueda de hash en una caché de resultados anteriores. De hecho, Ganesh utiliza la computación en los bordes para reducir la comunicación por Internet. Nuestra descripción de Ganesh se centra en cuatro aspectos. Primero explicamos nuestro enfoque para detectar similitud en los resultados de la consulta. A continuación, discutimos cómo la arquitectura Ganesh es completamente invisible para todos los componentes de un sistema de múltiples niveles. Luego describimos el enfoque basado en proxy de Ganesh y el flujo de datos para detectar similitudes. 3.1 Detectar similitud Una de las decisiones clave de diseño en Ganesh es cómo se detecta la similitud. Hay muchas formas potenciales de descomponer un resultado en fragmentos.  I the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the thees I,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,, Encontrar esta descomposición óptima es un problema difícil debido al amplio espacio de posibilidades y porque la elección óptima depende de muchos factores, como el contenido del resultado de las consultas, el historial de resultados recientes y el algoritmo de gestión de caché. Cuando un objeto es opaco, el uso de huellas digitales de Rabin [8, 30] para detectar datos comunes entre dos objetos ha sido demostrado con éxito en el pasado por sistemas como LBFS [26] y CASPER [37]. El fingerprinting de Rabin utiliza una ventana deslizante sobre los datos para calcular un hash rodante. Suponiendo que la función hash está distribuida uniformemente, un límite de fragmento se define cuando los bits de orden inferior del valor hash son iguales a algún valor predeterminado. El número de bits de orden inferior utilizados define el tamaño promedio del fragmento. Estos fragmentos subdivididos del objeto se convierten en la unidad de comparación para detectar similitudes entre diferentes objetos. Dado que las ubicaciones de los límites encontrados mediante el uso de las huellas de Rabin están determinadas de manera estocástica, generalmente no logran alinearse con ninguna propiedad estructural de los datos subyacentes. Por lo tanto, el algoritmo maneja bien las actualizaciones en su lugar, inserciones y eliminaciones. Sin embargo, tiene un rendimiento deficiente en presencia de cualquier reordenamiento de datos. La Figura 2 muestra un ejemplo donde dos resultados, A y B, que constan de tres filas, tienen los mismos datos pero diferentes atributos de ordenamiento. En el caso extremo, la huella digital de Rabin podría no ser capaz de encontrar datos similares debido a la forma en que detecta los límites de los fragmentos. Afortunadamente, Ganesh puede utilizar conocimientos específicos del dominio para una detección de límites más precisa. La información que explotamos es que el resultado de una consulta refleja la estructura de una base de datos relacional donde todos los datos están organizados en tablas y filas. Por lo tanto, es sencillo verificar la similitud con resultados anteriores en dos niveles de granularidad: primero el resultado completo y luego las filas individuales. El final de una fila en un resultado sirve como un límite natural de fragmento. Es importante tener en cuenta que el uso de la estructura tabular en los resultados solo implica una interpretación superficial de los datos. Ganesh no realiza ninguna interpretación semántica más profunda, como comprender tipos de datos, esquemas de resultados o restricciones de integridad. Ajustar la huella digital de Rabin para una carga de trabajo también puede ser difícil. Si el tamaño promedio de los fragmentos es demasiado grande, los fragmentos pueden abarcar varias filas de resultados. Sin embargo, seleccionar un tamaño de fragmento promedio más pequeño aumenta la cantidad de metadatos necesarios para describir los resultados. Esto, a su vez, disminuiría los ahorros obtenidos mediante su uso. El fingerprinting de Rabin también requiere dos pasadas computacionalmente costosas sobre los datos: una vez para determinar los límites de los fragmentos y otra vez para generar hashes criptográficos para los fragmentos. Ganesh solo necesita un único pase para la generación de hash, ya que los límites de los fragmentos son proporcionados por la estructura natural de los datos. La comparación de rendimiento en la Sección 6 muestra que el algoritmo basado en filas de Ganesh supera al fingerprinting de Rabin. Dado que trabajos anteriores ya han demostrado que la huella digital de Rabin funciona mejor que gzip [26], no comparamos a Ganesh con algoritmos de compresión en este artículo. 3.2 Transparencia El factor clave que influyó en nuestro diseño fue la necesidad de que Ganesh fuera completamente transparente para todos los componentes de un sistema típico de comercio electrónico: servidores web, servidores de aplicaciones y servidores de bases de datos. Sin esto, Ganesh tiene pocas posibilidades de tener un impacto significativo en el mundo real. Requerir modificaciones en cualquiera de los componentes mencionados aumentaría la barrera de entrada de Ganesh en un sistema existente, y por lo tanto reduciría sus posibilidades de adopción. Preservar la transparencia se simplifica por el hecho de que Ganesh es simplemente una mejora de rendimiento, no una mejora de funcionalidad o usabilidad. Elegimos la interposición de agentes como enfoque arquitectónico para lograr nuestro objetivo. Este enfoque se basa en la existencia de una interfaz de programación compacta que ya es ampliamente utilizada por el software objetivo. También se basa en un mecanismo para agregar fácilmente nuevo código sin interrumpir la estructura de módulos existente. Estas condiciones se cumplen fácilmente en nuestro contexto debido a la popularidad de Java como el lenguaje de programación para sistemas de comercio electrónico. La API de Conectividad de Base de Datos de Java (JDBC) [32] permite a las aplicaciones de Java acceder a una amplia variedad de bases de datos e incluso a otros repositorios de datos tabulares como archivos planos. El acceso a estas fuentes de datos es proporcionado por controladores JDBC que traducen entre la API JDBC y el mecanismo de comunicación de la base de datos. La figura 3(a) muestra cómo se utiliza típicamente JDBC en una aplicación. Dado que la interfaz JDBC está estandarizada, se puede sustituir un controlador JDBC por otro sin necesidad de de modificar la aplicación. El controlador JDBC se convierte así en el módulo natural para aprovechar la interposición de código. Como se muestra en la Figura 3(b), el controlador JDBC nativo es reemplazado por un controlador JDBC Ganesh que presenta la misma interfaz estandarizada. El controlador Ganesh mantiene una caché en memoria de fragmentos de resultados de consultas anteriores y realiza el reensamblaje de resultados. En la base de datos, agregamos un nuevo proceso llamado el proxy Ganesh. Este proxy, que puede ser compartido por múltiples nodos front-end, consta de dos partes: código para detectar similitud en fragmentos de resultados y el controlador JDBC nativo original que se comunica con la base de datos. El uso de un proxy en la base de datos hace que Ganesh sea independiente de la base de datos y simplifica la creación de prototipos y experimentación. Ganesh es capaz de trabajar con una amplia gama de bases de datos y aplicaciones, sin necesidad de realizar modificaciones en ninguna de ellas. 3.3 Caché basada en proxy El controlador JDBC nativo mostrado en la Figura 3(a) es un componente de código ligero suministrado por el proveedor de la base de datos. Su función principal es mediar la comunicación entre la aplicación y la base de datos remota. Reenvía consultas, almacena resultados completos y responde a solicitudes de la aplicación para ver partes de los resultados. El controlador JDBC de Ganesh mostrado en la Figura 3(b) presenta a la aplicación una interfaz idéntica a la proporcionada por el controlador nativo. Proporciona la capacidad de reconstruir resultados a partir de descripciones compactas basadas en hash enviadas por el proxy. Para realizar esta reconstrucción, el controlador mantiene una caché en memoria de los resultados recibidos recientemente. Esta caché solo se utiliza como fuente de fragmentos de resultados en la reconstrucción de resultados. El conductor Ganesh o el proxy no intentan rastrear las actualizaciones de la base de datos. La falta de consistencia en la caché no afecta a la corrección, ya que la descripción de los resultados siempre se obtiene del proxy; en el peor de los casos, no habrá beneficio de rendimiento al usar Ganesh. Los datos obsoletos simplemente se eliminarán de la caché con el tiempo. El proxy de Ganesh accede a la base de datos a través del controlador JDBC nativo, que permanece sin cambios entre las Figuras 3(a) y (b). La base de datos está completamente ajena a la existencia del proxy. El proxy no examina ninguna consulta recibida del controlador Ganesh, sino que las pasa al controlador nativo. En cambio, el proxy es responsable de inspeccionar la salida de la base de datos recibida del controlador nativo, detectar resultados similares y generar codificaciones basadas en hash de estos resultados siempre que se encuentre suficiente similitud. Si bien esta arquitectura no disminuye la carga en una base de datos, como se mencionó anteriormente en la Sección 2.1, es mucho más fácil replicar bases de datos para escalabilidad en una LAN que en una WAN. Para generar una codificación basada en hash, el proxy debe estar al tanto de qué fragmentos de resultados están disponibles en la caché de controladores de Ganesh. Un enfoque es ser optimista y asumir que todos los fragmentos de resultados están disponibles. Esto resultará en la transmisión inicial más pequeña posible de un resultado. Sin embargo, en casos donde hay poca superposición con resultados anteriores, el controlador Ganesh tendrá que realizar muchas llamadas al proxy durante la reconstrucción para recuperar fragmentos de resultados faltantes. Para evitar esta situación, el proxy sigue de manera flexible el estado de la caché de controladores de Ganesh. Dado que ambos componentes están bajo nuestro control, es relativamente sencillo hacer esto sin recurrir a técnicas de caja gris o comunicación explícita para mantener la coherencia de la caché. En cambio, el proxy simula el algoritmo de gestión de caché de controladores de Ganesh y lo utiliza para mantener una lista de hashes para los cuales es probable que el controlador de Ganesh posea los fragmentos de resultado. En caso de desviación de seguimiento, no habrá pérdida de corrección, pero habrá retrasos adicionales en el viaje de ida y vuelta para recuperar los fragmentos faltantes. Si el cliente detecta la pérdida de sincronización con el proxy, puede pedirle al proxy que restablezca el estado compartido entre ellos. También hay que tener en cuenta que el proxy no necesita guardar los fragmentos de resultado en sí, solo sus hashes. Esto permite que el proxy siga siendo escalable incluso cuando es compartido por muchos nodos front-end. El proxy Ganesh recibe la salida de la base de datos como objetos Java del controlador JDBC nativo. Examina esta salida para ver si está presente un objeto Java del tipo ResultSet. La interfaz JDBC utiliza este tipo de dato para almacenar los resultados de las consultas a la base de datos. Si se encuentra un objeto ResultSet, se reduce como se discute a continuación. Todos los demás objetos de Java se pasan sin modificar. Como se discute en la Sección 3.1, el proxy utiliza los límites de fila definidos en el ResultSet para dividirlo en fragmentos que consisten en filas de resultado individuales. Todos los objetos ResultSet se convierten en objetos de un nuevo tipo llamado RecipeResultSet. Utilizamos el término receta para esta descripción compacta de un resultado de base de datos debido a su similitud con una receta de archivo en el sistema de archivos CASPER [37]. La conversión reemplaza cada fragmento de resultado que probablemente esté presente en la caché de controladores de Ganesh por un hash SHA-1 de ese fragmento. Los fragmentos de resultados previamente no vistos se conservan textualmente. El proxy también retiene los hashes de los nuevos fragmentos de resultados, ya que estarán presentes en la caché de los controladores en el futuro. Ten en cuenta que el proxy solo almacena en caché los hashes de los fragmentos de resultados y no almacena en caché las recetas. El proxy construye un RecipeResultSet verificando la similitud en todo el resultado y luego a nivel de fila. Si se predice que todo el resultado estará presente en la caché de los controladores de Ganesh, el RecipeResultSet será simplemente un único hash de todo el resultado. De lo contrario, contiene hashes para aquellas filas que se predice que están presentes en esa caché; todas las demás filas se conservan textualmente. Si el proxy estima un ahorro de espacio general, transmitirá el RecipeResultSet. De lo contrario, se transmite el ResultSet original. Los objetos RecipeResultSet son transformados de vuelta en objetos ResultSet por el controlador Ganesh. La Figura 4 ilustra el manejo de ResultSet en ambos extremos. Cada hash SHA-1 encontrado en un RecipeResultSet se busca en la caché local de fragmentos de resultados. En caso de acierto, el hash es reemplazado por el fragmento correspondiente. En caso de error, el conductor contacta al proxy de Ganesh para recuperar el fragmento. Todos los fragmentos de resultados previamente no vistos que fueron retenidos textualmente por el proxy se hasheado y se han añadido a la caché de resultados. Debería haber muy pocos fallos si el proxy ha seguido con precisión el estado de la caché de controladores de Ganesh. Una optimización futura sería agrupar la obtención de fragmentos faltantes. Esto sería valioso cuando hay muchos pequeños fragmentos faltantes en una WAN de alta latencia. Una vez que la transformación esté completa, el objeto ResultSet completamente reconstruido se pasa a la aplicación. 4. VALIDACIÓN EXPERIMENTAL Tres preguntas surgen de los objetivos y diseño de Ganesh: • Primero, ¿se puede mejorar significativamente el rendimiento al explotar la similitud entre los resultados de la base de datos? Detalles del conjunto de datos de referencia 500,000 usuarios, 12,000 historias BBOARD 2.0 GB 3,298,000 comentarios SUBASTA 1.3 GB 1,000,000 usuarios, 34,000 elementos Tabla 1: Detalles del conjunto de datos de referencia • En segundo lugar, ¿qué tan importante es la detección de similitud estructural de Ganesh en comparación con la detección de similitud de la huella digital de Rabin? • En tercer lugar, ¿es aceptable la sobrecarga del diseño basado en proxy? Nuestra evaluación responde a estas preguntas a través de experimentos controlados con el prototipo Ganesh. Esta sección describe los puntos de referencia utilizados, nuestro procedimiento de evaluación y la configuración experimental. Los resultados de los experimentos se presentan en las Secciones 5, 6 y 7. 4.1 Puntos de referencia Nuestra evaluación se basa en dos puntos de referencia [18] que han sido ampliamente utilizados por otros investigadores para evaluar varios aspectos de arquitecturas multi-tier [27] y de comercio electrónico [9]. El primer punto de referencia, BBOARD, está modelado según Slashdot, un sitio de noticias orientado a la tecnología. El segundo punto de referencia, AUCTION, está modelado según eBay, un sitio de subastas en línea. En ambos puntos de referencia, la mayoría del contenido se genera dinámicamente a partir de la información almacenada en una base de datos. Los detalles de los conjuntos de datos utilizados se pueden encontrar en la Tabla 1. 4.1.1 El Benchmark BBOARD El benchmark BBOARD, también conocido como RUBBoS [18], modela Slashdot, un popular sitio web orientado a la tecnología. Slashdot recopila enlaces a noticias y otros temas de interés encontrados en otros lugares de la web. El sitio también funciona como un tablón de anuncios al permitir a los usuarios comentar en las historias publicadas en forma de conversación en hilos. No es raro que una historia recopile cientos de comentarios en cuestión de horas. El benchmark BBOARD es similar al sitio y modela las actividades de un usuario, incluyendo operaciones de solo lectura como navegar por las historias del día, explorar categorías de historias y ver comentarios, así como operaciones de escritura como registro de nuevos usuarios, agregar y moderar comentarios, y enviar historias. El benchmark consiste en tres fases diferentes: una fase de calentamiento corta, una fase de ejecución que representa el cuerpo principal de la carga de trabajo, y una fase de enfriamiento corta. En este documento solo informamos sobre los resultados de la fase de ejecución. La fase de calentamiento es importante para establecer el estado del sistema dinámico, pero las mediciones de esa fase no son significativas para nuestra evaluación. La fase de enfriamiento es únicamente para permitir que el punto de referencia se apague. Las fases de calentamiento, ejercicio y enfriamiento son de 2, 15 y 2 minutos respectivamente. El número de clientes simulados fue de 400, 800, 1200 y 1600. El punto de referencia está disponible en una versión de Java Servlets y PHP y tiene diferentes conjuntos de datos; evaluamos a Ganesh utilizando la versión de Java Servlets y el conjunto de datos Expandido. El benchmark BBOARD define dos cargas de trabajo diferentes. El primero, la mezcla de Autoría, consiste en un 70% de operaciones de solo lectura y un 30% de operaciones de lectura y escritura. El segundo, la mezcla de navegación, contiene solo operaciones de solo lectura y no actualiza la base de datos. 4.1.2 El Benchmark de SUBASTA El benchmark de SUBASTA, también conocido como RUBiS [18], modela eBay, el sitio de subastas en línea. El sitio web de eBay se utiliza para comprar y vender artículos a través de un formato de subasta. Las principales actividades de un usuario incluyen navegar, vender o pujar por artículos. Modelando las actividades en este sitio, este punto de referencia incluye actividades de solo lectura como navegar por artículos por categoría y por región, así como actividades de lectura-escritura como pujar por artículos, comprar y vender artículos, y dejar comentarios. Al igual que con BBOARD, el benchmark consiste en tres fases diferentes. Las fases de calentamiento, ejecución y enfriamiento para este experimento son de 1.5, 15 y 1 minutos respectivamente. Probamos Ganesh con cuatro configuraciones de clientes donde el número de clientes de prueba se estableció en 400, 800, 1200 y 1600. El punto de referencia está disponible en una versión de Enterprise Java Bean (EJB), Java Servlets y PHP y tiene diferentes conjuntos de datos; evaluamos Ganesh con la versión de Java Servlets y el conjunto de datos Expandido. El benchmark de SUBASTA define dos cargas de trabajo diferentes. El primero, la mezcla de Ofertas, consiste en un 70% de operaciones de solo lectura y un 30% de operaciones de lectura-escritura. El segundo, la mezcla de navegación, contiene solo operaciones de solo lectura y no actualiza la base de datos. 4.2 Procedimiento Experimental Ambos benchmarks involucran una carga de trabajo sintética de clientes accediendo a un servidor web. El número de clientes emulados es un parámetro experimental. Cada cliente emulado ejecuta una instancia del benchmark en su propio hilo, utilizando una matriz para hacer la transición entre diferentes estados del benchmark. La matriz define un modelo estocástico con probabilidades de transición entre los diferentes estados que representan las acciones típicas de los usuarios. Un ejemplo de transición es un usuario iniciando sesión en el sistema de SUBASTA y luego decidiendo si publicar un artículo en venta o pujar en subastas activas. Cada cliente también modela el tiempo de pensamiento del usuario entre las solicitudes. El tiempo de pensamiento se modela como una distribución exponencial con una media de 7 segundos. Evaluamos a Ganesh a lo largo de dos ejes: número de clientes y ancho de banda de la WAN. Las cargas más altas son especialmente útiles para comprender el rendimiento de Ganesh cuando la CPU o el disco del servidor de base de datos o del proxy son el factor limitante. Un estudio previo ha demostrado que aproximadamente el 50% de los cuellos de botella de Internet de gran área observados tenían un ancho de banda disponible inferior a 10 Mb/s [1]. Basándonos en este trabajo, enfocamos nuestra evaluación en el ancho de banda de la WAN de 5 Mb/s con una latencia de ida y vuelta de 66 ms, representativa de rutas de red severamente restringidas, y 20 Mb/s con una latencia de ida y vuelta de 33 ms, representativa de una ruta de red moderadamente restringida. También informamos sobre el rendimiento de Ganesh a 100 Mb/s sin agregar latencia de ida y vuelta. Este ancho de banda, representativo de una red sin restricciones, es especialmente útil para revelar cualquier sobrecarga potencial de Ganesh en situaciones donde el ancho de banda de la WAN no es el factor limitante. Para cada combinación de número de clientes y ancho de banda de WAN, medimos los resultados de las dos configuraciones enumeradas a continuación: • Nativa: Esta configuración corresponde a la Figura 3(a). El nativo evita la sobrecarga de Ganesh al usar un proxy y realizar la serialización de objetos Java. • Ganesh: Esta configuración corresponde a la Figura 3(b). Para un número dado de clientes y ancho de banda de WAN, comparar estos resultados con los resultados nativos correspondientes proporciona el beneficio de rendimiento debido al sistema de middleware Ganesh. La métrica utilizada para cuantificar la mejora en el rendimiento es el número de solicitudes de clientes que pueden ser atendidas por segundo. La métrica utilizada para cuantificar el rendimiento de Ganesh es el tiempo promedio de respuesta para una solicitud de cliente. Para todos los experimentos, el controlador Ganesh utilizado por el servidor de aplicaciones usó un tamaño de caché de 100,000 elementos. El proxy fue efectivo en rastrear el estado de la caché de los controladores Ganesh; para todos nuestros experimentos, la tasa de fallos en el controlador nunca superó el 0.7%. 4.3 Configuración Experimental La configuración experimental utilizada para las pruebas se puede ver en la Figura 5. Todas las máquinas eran Pentium 4 de 3.2 GHz (con HyperThreading habilitado). Con la excepción del servidor de base de datos, todas las máquinas tenían 2 GB de SDRAM y ejecutaban la distribución de Linux Fedora Core. El servidor de la base de datos tenía 4 GB de SDRAM. Utilizamos Apache Tomcat como tanto el servidor de aplicaciones que alojaba los Servlets de Java como el servidor web. Ambos benchmarks utilizaron Java Servlets para generar el contenido dinámico. El servidor de la base de datos utilizó la base de datos de código abierto MySQL. Para los controladores JDBC nativos, utilizamos los controladores Connector/J proporcionados por MySQL. El servidor de aplicaciones utilizaba la Máquina Virtual de Java de Sun como entorno de ejecución para los Servlets de Java. La herramienta sysstat se utilizó para monitorear la utilización de la CPU, red, disco y memoria en todas las máquinas. Las máquinas estaban conectadas por una red Ethernet gigabit conmutada. Como se muestra en la Figura 5, el servidor web y de aplicación de front-end fue separado del servidor de proxy y base de datos por un enrutador NetEm [16]. Este enrutador nos permitió controlar la configuración de ancho de banda y latencia en la red. El enrutador NetEm es un PC estándar con dos tarjetas de red que ejecuta el software de Control de Tráfico de Linux y Emulación de Red. Las restricciones de ancho de banda y latencia solo se aplicaron al enlace entre el servidor de aplicaciones y la base de datos para el caso nativo y entre el servidor de aplicaciones y el proxy para el caso de Ganesh. No hay comunicación entre el servidor de aplicaciones y la base de datos con Ganesh, ya que todos los datos fluyen a través del proxy. Como nuestro enfoque estaba en el enlace WAN entre el servidor de aplicaciones y la base de datos, no hubo restricciones en el enlace entre los clientes de prueba simulados y el servidor web. 5. DESEMPEÑO Y TIEMPO DE RESPUESTA En esta sección, abordamos la primera pregunta planteada en la Sección 4: ¿Se puede mejorar significativamente el rendimiento explotando la similitud entre los resultados de la base de datos? Para responder a esta pregunta, utilizamos los resultados de los benchmarks BBOARD y AUCTION. Utilizamos dos métricas para cuantificar la mejora en el rendimiento obtenible a través del uso de Ganesh: el throughput, desde la perspectiva del servidor web, y el tiempo de respuesta promedio, desde la perspectiva del cliente. El rendimiento se mide en términos del número de solicitudes de clientes que pueden ser atendidas por segundo. Los resultados y análisis de BBOARD 5.1 Figuras 6 (a) y (b) presentan el número promedio de solicitudes atendidas por segundo y el tiempo de respuesta promedio para estas solicitudes tal como lo perciben los clientes para la Mezcla de Autoría de BBOARD. Como muestra la Figura 6 (a), Native satura fácilmente el enlace de 5 Mb/s. Con 400 clientes, la solución nativa entrega 29 solicitudes/segundo con un tiempo de respuesta promedio de 8.3 segundos. La capacidad de procesamiento de los clientes disminuye con un aumento en los clientes de prueba, ya que los clientes se agotan debido a la congestión en el servidor de aplicaciones. Los estudios de usabilidad han demostrado que los tiempos de respuesta superiores a 10 segundos hacen que el usuario pase a 1. Dado que Java carece de un operador sizeof(), los cachés de Java limitan su tamaño en función del número de objetos. El tamaño de los volcados de caché tomados al final de los experimentos nunca superó los 212 MB. WWW 2007 / Pista: Rendimiento y Escalabilidad Sesión: Sistemas Escalables para Contenido Dinámico 315 0 50 100 150 200 250 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Solicitudes de Clientes de Prueba por Segundo Nativo Ganesh 0.001 0.01 0.1 1 10 100 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Tiempo Promedio de Respuesta de Clientes de Prueba Nativo Ganesh Nota Escala Logarítmica (a) Rendimiento: Mezcla de Autoría (b) Tiempo de Respuesta: Mezcla de Autoría 0 50 100 150 200 250 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Solicitudes de Clientes de Prueba por Segundo Nativo Ganesh 0.001 0.01 0.1 1 10 100 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Tiempo Promedio de Respuesta de Clientes de Prueba Nativo Ganesh Nota Escala Logarítmica (c) Rendimiento: Mezcla de Navegación (d) Tiempo de Respuesta: Mezcla de Navegación Promedio de tres pruebas. La desviación estándar máxima para el rendimiento y el tiempo de respuesta fue del 9.8% y 11.9% de la media correspondiente. Figura 6: BBOARD Benchmark - Rendimiento y Tiempo de Respuesta Promedio de otras tareas [24]. Basándose en estos números, aumentar el número de clientes de prueba hace que el sistema Nativo sea inutilizable. Ganesh a 5 Mb/s, sin embargo, ofrece una mejora doble con 400 clientes de prueba y una mejora quintuple con 1200 clientes. El rendimiento de Ganesh disminuye ligeramente a 1200 y 1600 clientes debido a que la red está saturada. En comparación con Native, la Figura 6 (b) muestra que los tiempos de respuesta de Ganesh son considerablemente más bajos con tiempos de respuesta de menos de un segundo con 400 clientes. La Figura 6 (a) también muestra que para 400 y 800 clientes de prueba, Ganesh a 5 Mb/s tiene el mismo rendimiento y tiempo de respuesta promedio que Native a 20 Mb/s. Solo con 1200 y 1600 clientes, Native a 20 Mb/s ofrece un rendimiento mayor que Ganesh a 5 Mb/s. Al comparar tanto a Ganesh como a Native a 20 Mb/s, vemos que Ganesh ya no está limitado por el ancho de banda y ofrece hasta una mejora del doble sobre Native con 1600 clientes de prueba. Como Ganesh no satura la red con configuraciones de cliente de prueba más altas, con 1600 clientes de prueba, su tiempo de respuesta promedio es de 0.1 segundos en lugar de los 7.7 segundos de Natives. Como era de esperar, no hay ganancias visibles de Ganesh en el ancho de banda más alto de 100 Mb/s donde la red ya no es el cuello de botella. Sin embargo, Ganesh sigue monitoreando a Native en cuanto a rendimiento. Las Figuras 6 (c) y (d) presentan el número promedio de solicitudes atendidas por segundo y el tiempo de respuesta promedio para estas solicitudes tal como lo perciben los clientes para la Mezcla de Navegación de BBOARDs. Independientemente de la configuración del cliente de prueba, la Figura 6 (c) muestra que el rendimiento de los Nativos a 5 Mb/s está limitado a 10 reqs/seg. Ganesh a 5 Mb/s con 400 clientes de prueba, ofrece un aumento de más de seis veces en el rendimiento. La mejora aumenta a más de once veces a 800 clientes de prueba antes de que Ganesh sature la red. Además, la Figura 6 (d) muestra que el tiempo de respuesta promedio de los Nativos de 35 segundos con 400 clientes de prueba hace que el sistema sea inutilizable. Estos altos tiempos de respuesta aumentan aún más con la adición de clientes de prueba. Incluso con la configuración del cliente de prueba de 1600, Ganesh ofrece un tiempo de respuesta promedio aceptable de 8.2 segundos. Debido a la naturaleza intensiva en datos de la mezcla de navegación, Ganesh a 5 Mb/s sorprendentemente tiene un rendimiento mucho mejor que Native a 20 Mb/s. Además, como se muestra en la Figura 6 (d), si bien el tiempo de respuesta promedio para Native a 20 Mb/s es aceptable con 400 clientes de prueba, resulta inutilizable con 800 clientes de prueba, con un tiempo de respuesta promedio de 15.8 segundos. Al igual que en el caso de 5 Mb/s, este tiempo de respuesta aumenta con la adición de clientes de prueba adicionales. Ganesh a 20 Mb/s y tanto Native como Ganesh a 100 Mb/s no tienen limitaciones de ancho de banda. Sin embargo, el rendimiento se estanca después de 1200 clientes de prueba debido a que la CPU de la base de datos está saturada. 5.1.3 Variante de filtro Nos sorprendió el rendimiento nativo del benchmark BBOARD. A una velocidad de banda ancha de 5 Mb/s, el rendimiento nativo fue más bajo de lo que esperábamos. Resultó que el código de referencia que muestra historias leía todos los comentarios asociados con la historia en particular de la base de datos y solo entonces realizaba un postprocesamiento para seleccionar los comentarios que se mostrarían. Si bien este es exactamente el comportamiento de SlashCode, la base de código detrás del sitio web de Slashdot, decidimos modificar la prueba de rendimiento para realizar cierto prefiltrado en la base de datos. Este benchmark modificado, llamado el Filtro de Variantes, modela a un desarrollador que aplica optimizaciones a nivel de SQL para transferir menos datos. En aras de la brevedad, solo resumimos brevemente los resultados de la mezcla de autores. Para la mezcla de Autoría, con 800 clientes de prueba a 5 Mb/s, la Figura 7 (a) muestra que el rendimiento de Natives aumenta un 85% en comparación con el punto de referencia original, mientras que la mejora de Ganesh es menor, del 15%. El rendimiento de los servidores disminuye por encima de los 800 clientes, ya que los clientes de prueba se agotan debido a los altos tiempos de respuesta. La ganancia más significativa para Native se observa a 20 Mb/s. En 1600 clientes de prueba, en comparación con el punto de referencia original, Native experimenta una mejora del 73% en el rendimiento y una reducción del 77% en el tiempo de respuesta promedio. Mientras WWW 2007 / Pista: Rendimiento y Escalabilidad Sesión: Sistemas Escalables para Contenido Dinámico 316 0 50 100 150 200 250 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Clientes de Prueba Solicitudes/seg Nativo Ganesh 0.001 0.01 0.1 1 10 100 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Clientes de Prueba Tiempo de Resp. Promedio (seg) Nativo Ganesh Nota Escala Logarítmica (a) Rendimiento: Mezcla de Autoría (b) Tiempo de Respuesta: Mezcla de Autoría Promedio de tres pruebas. La desviación estándar máxima para el rendimiento y el tiempo de respuesta fue del 7.2% y del 11.5% de la media correspondiente. Figura 7: BBOARD Benchmark - Variante de filtro - Rendimiento y Tiempo de Respuesta Promedio Ganesh no observa ninguna mejora en comparación con el original, aún procesa un 19% más de solicitudes/seg que Native. Por lo tanto, aunque las optimizaciones fueron más útiles para Native, Ganesh todavía ofrece una mejora en el rendimiento. 5.2 Resultados y Análisis de la SUBASTA 5.2.1 Figuras de la Mezcla de Ofertas Los gráficos 8 (a) y (b) presentan el número promedio de solicitudes atendidas por segundo y el tiempo de respuesta promedio para estas solicitudes tal como son percibidas por los clientes para la Mezcla de Ofertas de las SUBASTAS. Como se mencionó anteriormente, la mezcla de ofertas consiste en una combinación de operaciones de lectura y escritura. El benchmark AUCTION no es tan intensivo en datos como BBOARD. Por lo tanto, la mayoría de las ganancias se observan en el ancho de banda más bajo de 5 Mb/s. La figura 8 (a) muestra que el aumento en el rendimiento debido a Ganesh varía desde un 8% con 400 clientes de prueba hasta un 18% con 1600 clientes de prueba. Como se observa en la Figura 8 (b), los tiempos de respuesta promedio para Ganesh son significativamente más bajos que los de Native, con una disminución del 84% a 800 clientes de prueba y del 88% a 1600 clientes de prueba. La Figura 8 (a) también muestra que con un aumento cuádruple del ancho de banda de 5 Mb/s a 20 Mb/s, Native ya no está limitado por el ancho de banda y no hay diferencia de rendimiento entre Ganesh y Native. Con las configuraciones de cliente de prueba más altas, observamos que el ancho de banda utilizado por Ganesh era menor que el de Nativo. Ganesh podría seguir siendo útil en estos escenarios no restringidos si se compra ancho de banda de forma medible. Se observan resultados similares para el escenario de 100 Mb/s. 5.2.2 Mezcla de Navegación Para la Mezcla de Navegación de SUBASTAS, las Figuras 8 (c) y (d) presentan el número promedio de solicitudes atendidas por segundo y el tiempo promedio de respuesta para estas solicitudes tal como lo perciben los clientes. Una vez más, la mayoría de las ganancias se observan en anchos de banda más bajos. A 5 Mb/s, Native y Ganesh ofrecen un rendimiento y tiempos de respuesta similares con 400 clientes de prueba. Mientras que el rendimiento para ambos permanece igual en 800 clientes de prueba, la Figura 8 (d) muestra que el tiempo de respuesta promedio de Ganesh es un 62% menor que el de Native. El servidor satura el enlace con 800 clientes y agregar clientes de prueba adicionales solo aumenta el tiempo promedio de respuesta. Ganesh, independientemente de la configuración del cliente de prueba, no tiene restricciones de ancho de banda y mantiene el mismo tiempo de respuesta. A 1600 clientes de prueba, la Figura 8 (c) muestra que el rendimiento de Ganesh es casi el doble que el de Nativo. En los anchos de banda más altos de 20 y 100 Mb/s, ni Ganesh ni Native tienen limitaciones de ancho de banda y ofrecen un rendimiento y tiempos de respuesta equivalentes. Referencia original. Tamaño Ganesh Tamaño Rabin Tamaño SelectSort1 223.6 MB 5.4 MB 219.3 MB SelectSort2 223.6 MB 5.4 MB 223.6 MB Tabla 2: Microbenchmarks de similitud 6. SIMILITUD ESTRUCTURAL VS. SIMILITUD DE RABIN En esta sección, abordamos la segunda pregunta planteada en la Sección 4: ¿Qué tan importante es la detección de similitud estructural de Ganesh en comparación con la detección de similitud basada en la huella digital de Rabin? Para responder a esta pregunta, utilizamos microbenchmarks y los benchmarks BBOARD y AUCTION. Dado que Ganesh siempre tuvo un mejor rendimiento que Rabin en la huella dactilar, aquí presentamos solo un subconjunto de los resultados en aras de la brevedad. 6.1 Microbenchmarks Dos microbenchmarks muestran un ejemplo de los efectos de la reordenación de datos en el algoritmo de huella dactilar de Rabin. En el primer microbenchmark, SelectSort1, una consulta con un orden de clasificación especificado selecciona 223.6 MB de datos distribuidos en aproximadamente 280 K filas. La consulta se repite entonces con un atributo de ordenación diferente. Si bien se devuelve el mismo número de filas y los mismos datos, el orden de las filas es diferente. En un escenario así, se esperaría detectar una gran cantidad de similitud entre ambos resultados. Como muestra la Tabla 2, el algoritmo basado en filas de Ganesh logra una reducción del 97.6%, mientras que el algoritmo de huella digital de Rabin, con el parámetro de tamaño de fragmento promedio establecido en 4 KB, solo logra una reducción del 1%. La razón, como se muestra anteriormente en la Figura 2, es que con la huella digital de Rabin, los tramos de datos entre dos límites consecutivos suelen cruzar los límites de fila. Con el cambio en el orden de las filas en el segundo resultado y los fingerprints de Rabin ahora abarcando diferentes filas, el algoritmo no puede detectar similitud significativa. La pequeña ganancia observada se debe principalmente a aquellas filas individuales que son lo suficientemente grandes como para dividirse en múltiples fragmentos. SelectSort2, otro micro-benchmark ejecutó las mismas consultas pero aumentó el tamaño mínimo del fragmento del algoritmo de huella digital de Rabin. Como se puede ver en la Tabla 2, incluso la pequeña ganancia del microbenchmark anterior desaparece cuando el tamaño mínimo de fragmento fue mayor que el tamaño promedio de fila. Si bien se pueden abordar parcialmente estos problemas variando dinámicamente los parámetros del algoritmo de huella digital de Rabin, esto puede resultar computacionalmente costoso, especialmente en presencia de cargas de trabajo cambiantes. 6.2 Benchmarks de Aplicación Ejecutamos el benchmark BBOARD descrito en la Sección 4.1.1 en dos versiones de Ganesh: la primera con la huella digital de Rabin utilizada como WWW 2007 / Track: Sesión de Rendimiento y Escalabilidad: Sistemas Escalables para Contenido Dinámico 317 0 50 100 150 200 250 300 350 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Clientes de Prueba Solicitudes/seg Ganesh Nativo 0.001 0.01 0.1 1 10 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Clientes de Prueba Tiempo de Respuesta Promedio (seg) Ganesh Nativo Nota Escala Logarítmica (a) Rendimiento: Mezcla de Ofertas (b) Tiempo de Respuesta: Mezcla de Ofertas 0 50 100 150 200 250 300 350 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Clientes de Prueba Solicitudes/seg Ganesh Nativo 0.001 0.01 0.1 1 10 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Clientes de Prueba Tiempo de Respuesta Promedio (seg) Ganesh Nativo Nota Escala Logarítmica (c) Rendimiento: Mezcla de Navegación (d) Tiempo de Respuesta: Mezcla de Navegación Promedio de tres pruebas. La desviación estándar máxima para el rendimiento y el tiempo de respuesta fue del 2.2% y del 11.8% de la media correspondiente. Figura 8: Referencia de la subasta AUCTION - Rendimiento y Tiempo de Respuesta Promedio del algoritmo de fragmentación y el segundo con el algoritmo basado en filas de Ganesh. Los resultados de Rabins para la Mezcla de Navegación se normalizan con los resultados de Ganesh y se presentan en la Figura 9. Como muestra la Figura 9 (a), a 5 Mb/s, independientemente de la configuración del cliente de prueba, Rabin tiene un rendimiento significativamente inferior a Ganesh. Esto sucede debido a una combinación de dos razones. Primero, como se describe en la Sección 3.1, Rabin encuentra menos similitud ya que no explota la información estructural de los resultados. Segundo, este punto de referencia contenía algunas consultas que generaron resultados grandes. En este caso, Rabin, con un tamaño de fragmento promedio pequeño, generó una gran cantidad de objetos que desplazaron otros datos útiles de la caché. Por el contrario, Ganesh pudo detectar estas filas grandes y aumentar correspondientemente el tamaño de los bloques. Esto fue confirmado ya que las estadísticas de caché mostraron que la proporción de aciertos de Ganesh era aproximadamente tres veces mayor que la de Rabin. Las mediciones de rendimiento a 20 Mb/s fueron similares, con la excepción del rendimiento de Rabins con 400 clientes de prueba. En este caso, Ganesh no estaba limitado por la red y, de hecho, el rendimiento era el mismo que el de 400 clientes a 5 Mb/s. Rabin, sin embargo, aprovechó el aumento del ancho de banda de 5 a 20 Mb/s para ofrecer un rendimiento ligeramente mejor. A 100 Mb/s, el rendimiento de Rabin era casi similar al de Ganesh ya que el ancho de banda ya no era un cuello de botella. El tiempo de respuesta normalizado, presentado en la Figura 9 (b), muestra tendencias similares. A 5 y 20 Mb/s, la adición de clientes de prueba disminuye el tiempo de respuesta normalizado, ya que el tiempo de respuesta promedio de Ganesh aumenta más rápido que el de Rabin. Sin embargo, en ningún momento Rabin supera a Ganesh. Ten en cuenta que con 400 y 800 clientes a 100 Mb/s, Rabin tiene un mayor sobrecosto incluso cuando no está limitado por el ancho de banda. Como se menciona en la Sección 3.1, esto se debe a que Rabin tiene que hashear cada ResultSet dos veces. La sobrecarga desaparece con 1200 y 1600 clientes, ya que la CPU de la base de datos está saturada y limita el rendimiento tanto de Ganesh como de Rabin. 7. SUPERPOSICIÓN DE PROXY En esta sección, abordamos la tercera pregunta planteada en la Sección 4: ¿Es aceptable la superposición del diseño basado en proxy de Ganesh? Para responder a esta pregunta, nos concentramos en su rendimiento en las bandas de mayor ancho de banda. Nuestra evaluación en la Sección 5 mostró que Ganesh, en comparación con Native, puede ofrecer una mejora sustancial en el rendimiento a anchos de banda más bajos. Solo en anchos de banda más altos serían visibles los costos adicionales de latencia, medidos por el tiempo promedio de respuesta para una solicitud de cliente, y de rendimiento, medidos por la cantidad de solicitudes de cliente que pueden ser atendidas por segundo. Al observar la combinación de autoría del benchmark original de BBOARD, no se aprecian ganancias visibles de Ganesh a 100 Mb/s. Sin embargo, Ganesh sigue rastreando a Native en cuanto a rendimiento. Si bien el tiempo promedio de respuesta es mayor para Ganesh, la diferencia absoluta está entre 0.01 y 0.04 segundos y sería imperceptible para el usuario final. La mezcla de navegación muestra una diferencia aún menor en los tiempos de respuesta promedio. Los resultados de la variante del filtro de los benchmarks de BBOARD son similares. Incluso para el benchmark de SUBASTA, la diferencia entre el tiempo de respuesta de Nativo y Ganesh a 100 Mb/s nunca fue mayor a 0.02 segundos. La única excepción a los resultados anteriores se observó en la variante de filtro del benchmark BBOARD, donde Ganesh con 1600 clientes de prueba añadió 0.85 segundos al tiempo de respuesta promedio. Por lo tanto, incluso para redes mucho más rápidas donde el enlace WAN no es el cuello de botella, Ganesh siempre ofrece un rendimiento equivalente al Nativo. Si bien se agrega algo de latencia adicional debido al diseño basado en proxy, generalmente es imperceptible. TRABAJO RELACIONADO Hasta donde sabemos, Ganesh es el primer sistema que combina el uso de técnicas basadas en hash con el almacenamiento en caché de resultados de base de datos para mejorar el rendimiento y los tiempos de respuesta de aplicaciones con contenido dinámico. También creemos que es el primer sistema en demostrar los beneficios de utilizar información estructural para WWW 2007 / Track: Rendimiento y Escalabilidad Sesión: Sistemas Escalables para Contenido Dinámico 318 0.0 0.2 0.4 0.6 0.8 1.0 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Clientes de Prueba Rendimiento Normalizado 31.8 3.8 2.8 2.3 23.8 32.8 5.8 3.6 1.8 2.1 1.1 1.0 0 5 10 15 20 25 30 35 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Clientes de Prueba Tiempo de Respuesta Normalizado (a) Rendimiento Normalizado: Mayor es mejor (b) Tiempo de Respuesta Normalizado: Mayor es peor Para el rendimiento, un resultado normalizado mayor que 1 implica que Rabin es mejor. Para el tiempo de respuesta, un resultado normalizado mayor que 1 implica que Ganesh es mejor. Media de tres pruebas. La desviación estándar máxima para el rendimiento y el tiempo de respuesta fue del 9.1% y del 13.9% de la media correspondiente. Figura 9: Comparación normalizada de Ganesh vs. Rabin - Mezcla de navegación BBOARD detectando similitud. En esta sección, primero discutimos enfoques alternativos para almacenar en caché contenido dinámico y luego examinamos otros usos de primitivas basadas en hash en sistemas distribuidos. 8.1 Almacenamiento en Caché de Contenido Dinámico En la capa de base de datos, varios sistemas han abogado por la caché de nivel intermedio donde partes de la base de datos se replican en el borde o servidor [3, 4, 20]. Estos sistemas almacenan en caché tablas completas en lo que es esencialmente una base de datos replicada o utilizan vistas materializadas de respuestas de consultas anteriores [19]. Requieren una integración estrecha con la base de datos del sistema para garantizar un límite de tiempo en la propagación de actualizaciones. Estos sistemas suelen estar dirigidos a cargas de trabajo que no requieren una consistencia estricta y pueden tolerar datos obsoletos. Además, a diferencia de Ganesh, algunas de estas soluciones de almacenamiento en caché de nivel medio [2, 3], sufren de la complejidad de tener que participar en la planificación de consultas y el procesamiento de consultas distribuidas. Gao et al. [15] proponen utilizar una arquitectura de replicación de objetos distribuidos donde los requisitos de consistencia de las tiendas de datos se adaptan según la aplicación. Estas soluciones requieren recursos sustanciales de desarrollo y un entendimiento detallado de la aplicación que se está modificando. Si bien existen sistemas que intentan automatizar la partición y replicación de la base de datos de una aplicación [34], no proporcionan semántica de transacciones completa. En comparación, Ganesh no debilita ninguna de las semánticas proporcionadas por la base de datos subyacente. El trabajo reciente en la evaluación de opciones de almacenamiento en caché de borde para sitios web dinámicos [38] ha sugerido que, sin una planificación cuidadosa, el empleo de estrategias complejas de descarga puede perjudicar el rendimiento. En cambio, el trabajo aboga por una arquitectura en la que todos los niveles, excepto la base de datos, deberían ser trasladados al borde. Nuestra evaluación de Ganesh ha demostrado que sería beneficioso para estos escenarios. Para mejorar la escalabilidad de la base de datos, C-JDBC [10], SSS [22] y Ganymed [28] también abogan por el uso de una arquitectura basada en interposición para clusterizar y replicar bases de datos de forma transparente a nivel de middleware. Los enfoques de estas arquitecturas y Ganesh son complementarios y se beneficiarían mutuamente. Avanzando hacia la capa de presentación, se ha producido una amplia adopción de la caché basada en fragmentos [14], la cual mejora la utilización de la caché al almacenar por separado diferentes partes de las páginas web generadas. Si bien el almacenamiento en caché basado en fragmentos funciona en el borde, una propuesta reciente ha propuesto trasladar el ensamblaje de páginas web a los clientes para optimizar la entrega de contenido [31]. Si bien Ganesh no se utiliza en la capa de presentación, los mismos principios se han aplicado en la Detección de Transferencias Duplicadas [25] para aumentar la eficiencia de la caché web, así como para el acceso web a través de enlaces con ancho de banda limitado [33]. 8.2 Sistemas basados en hash En los últimos años han surgido muchos sistemas que explotan técnicas basadas en hash. En el centro de todos estos sistemas se encuentra la idea de detectar similitudes en los datos sin necesidad de interpretar esos datos. Esta idea simple pero elegante se basa en el hash criptográfico, como se discutió anteriormente en la Sección 2. Las aplicaciones exitosas de esta idea abarcan una amplia gama de sistemas de almacenamiento. Los ejemplos incluyen la copia de seguridad entre pares de archivos informáticos personales [11], el archivado eficiente de datos [29] y la búsqueda de archivos similares [21]. Spring y Wetherall [35] aplican principios similares a nivel de red. Utilizando cachés sincronizadas en ambos extremos de un enlace de red, los datos duplicados son reemplazados por tokens más pequeños para su transmisión y luego restaurados en el extremo remoto. Este y otros sistemas basados en hash como los sistemas de archivos CASPER [37] y LBFS [26], y optimizadores de ancho de banda de Capa-2 como Riverbed y Peribit utilizan la huella digital de Rabin [30] para descubrir tramos de similitud en los datos. Este enfoque es especialmente útil cuando los elementos de datos son modificados en su lugar a través de inserciones, eliminaciones y actualizaciones. Sin embargo, como se muestra en la Sección 6, el rendimiento de esta técnica puede experimentar una caída dramática en presencia de reordenamiento de datos. Ganesh en cambio utiliza los límites de fila como divisores para detectar similitudes. El uso más agresivo de técnicas basadas en hash es por sistemas que utilizan hashes como identificadores principales para objetos en almacenamiento persistente. Los sistemas de almacenamiento como CFS [12] y PAST [13] que han sido construidos utilizando tablas hash distribuidas entran en esta categoría. Single Instance Storage [6] y Venti [29] son otros ejemplos de tales sistemas. Como se discute en la Sección 2.2, el uso de hashes criptográficos para abordar datos persistentes representa un nivel más profundo de confianza en su resistencia a colisiones que la asumida por Ganesh. Si el tiempo revela deficiencias en el algoritmo hash, el esfuerzo necesario para corregir la falla es mucho mayor. En Ganesh, simplemente se trata de reemplazar el algoritmo hash. 9. CONCLUSIÓN El creciente uso de contenido web dinámico generado a partir de bases de datos relacionales aumenta las demandas de ancho de banda de la WAN. Las soluciones de almacenamiento en caché tradicionales para reducir el ancho de banda y la latencia suelen ser ineficaces para este tipo de contenido. Este documento muestra que el impacto de los accesos a bases de datos a través de WAN puede reducirse sustancialmente mediante la arquitectura Ganesh sin comprometer la estricta semántica de consistencia de las bases de datos. La esencia de la arquitectura Ganesh es el uso de la computación en los bordes para reducir la comunicación a través de Internet. Ganesh es capaz de utilizar hashes criptográficos para detectar similitud con resultados anteriores y enviar recetas compactas de resultados en lugar de resultados completos en la sesión de Sistemas Escalables para Contenido Dinámico 319 de WWW 2007 / Track: Rendimiento y Escalabilidad. Nuestro diseño utiliza la interposición para lograr una transparencia completa: los clientes, los servidores de aplicaciones y los servidores de bases de datos no son conscientes de la presencia de Ganesh y no requieren ninguna modificación. Nuestra evaluación experimental confirma que Ganesh, aunque conceptualmente simple, puede ser altamente efectivo en mejorar el rendimiento y el tiempo de respuesta. Nuestros resultados también confirman que aprovechar la estructura presente en los resultados de la base de datos para detectar similitudes es crucial para esta mejora en el rendimiento. REFERENCIAS [1] AKELLA, A., SESHAN, S., Y SHAIKH, A. Una evaluación empírica de los cuellos de botella en Internet de área amplia. En Proc. 3ª Conferencia ACM SIGCOMM sobre Medición de Internet (Miami Beach, FL, EE. UU., Oct. 2003), pp. 101-114. [2] ALTINEL, M., BORNH ¨OVD, C., KRISHNAMURTHY, S., MOHAN, C., PIRAHESH, H., Y REINWALD, B. Tablas de caché: allanando el camino para una <br>caché de base de datos</br> adaptativa. En Proc. del 29º VLDB (Berlín, Alemania, 2003), pp. 718-729. [3] ALTINEL, M., LUO, Q., KRISHNAMURTHY, S., MOHAN, C., PIRAHESH, H., LINDSAY, B. G., WOO, H., Y BROWN, L. Dbcache: Caché de base de datos para servidores de aplicaciones web. En Proc. 2002 ACM SIGMOD (2002), pp. 612-612. [4] AMIRI, K., PARK, S., TEWARI, R., Y PADMANABHAN, S. Dbproxy: una caché de datos dinámica para aplicaciones web. En Proc. Conferencia Internacional de Ingeniería de Datos de IEEE (ICDE) (Mar. 2003). [5] BLACK, J. Compare-by-hash: Un análisis razonado. En Proc. Conferencia Técnica Anual USENIX 2006 (Boston, MA, mayo de 2006), pp. 85-90. [6] BOLOSKY, W. J., CORBIN, S., GOEBEL, D., y DOUCEUR, J. R. Almacenamiento de instancia única en Windows 2000. En Proc. 4to Simposio de Sistemas Windows de USENIX (Seattle, WA, ago. 2000), pp. 13-24. [7] BREWER, E. A. Lecciones de servicios a gran escala. IEEE Internet Computing 5, 4 (2001), 46-55. [8] BRODER, A., GLASSMAN, S., MANASSE, M., AND ZWEIG, G. Agrupamiento sintáctico de la web. En Proc. 6ta Conferencia Internacional WWW (1997). [9] CECCHET, E., CHANDA, A., ELNIKETY, S., MARGUERITE, J., Y ZWAENEPOEL, W. Comparación de rendimiento de arquitecturas de middleware para generar contenido web dinámico. En Proc. Cuarta Conferencia Internacional de Middleware ACM/IFIP/USENIX (Río de Janeiro, Brasil, junio de 2003). [10] CECCHET, E., MARGUERITE, J., Y ZWAENEPOEL, W. C-JDBC: Middleware flexible de agrupación de bases de datos. En Proc. Conferencia Técnica Anual USENIX 2004 (Boston, MA, junio de 2004). [11] COX, L. P., MURRAY, C. D., Y NOBLE, B. D. Pastiche: Haciendo que la copia de seguridad sea barata y fácil. En OSDI: Simposio sobre Diseño e Implementación de Sistemas Operativos (2002). [12] DABEK, F., KAASHOEK, M. F., KARGER, D., MORRIS, R., Y STOICA, I. Almacenamiento cooperativo de amplia área con CFS. En el 18º Simposio ACM sobre Principios de Sistemas Operativos (Banff, Canadá, octubre de 2001). [13] DRUSCHEL, P., Y ROWSTRON, A. PASADO: Una utilidad de almacenamiento entre pares a gran escala y persistente. En HotOS VIII (Schloss Elmau, Alemania, mayo de 2001), pp. 75-80. [14] Incluye el lado del borde. http://www.esi.org. [15] GAO, L., DAHLIN, M., NAYATE, A., ZHENG, J., Y IYENGAR, A. Replicación de datos específica de la aplicación para servicios en el borde. En WWW 03: Proc. Duodécima Conferencia Internacional sobre la World Wide Web (2003), pp. 449-460. [16] HEMMINGER, S. Netem - emulando redes reales en el laboratorio. En Proc. 2005 Linux Conference Australia (Canberra, Australia, Abr. 2005). [17] HENSON, V. Un análisis de compare-by-hash. En Proc. 9º Taller sobre Temas Candentes en Sistemas Operativos (HotOS IX) (mayo de 2003), pp. 13-18. [18] Benchmarks de Jmob. http://jmob.objectweb.org/. [19] LABRINIDIS, A., Y ROUSSOPOULOS, N. Equilibrando el rendimiento y la frescura de los datos en servidores de bases de datos web. En Proc. 29ª Conferencia VLDB (Sept. 2003). [20] LARSON, P.-A., GOLDSTEIN, J., Y ZHOU, J. Caché transparente de bases de datos en el nivel intermedio en SQL Server. En Proc. 2003 ACM SIGMOD (2003), pp. 661-661. [21] MANBER, U. Encontrar archivos similares en un sistema de archivos grande. En Proc. Conferencia Técnica de Invierno de USENIX 1994 (San Francisco, CA, 17-21 de 1994), pp. 1-10. [22] MANJHI, A., AILAMAKI, A., MAGGS, B. M., MOWRY, T. C., OLSTON, C., Y TOMASIC, A. Escalabilidad y seguridad simultáneas para aplicaciones web intensivas en datos. En Proc. 2006 ACM SIGMOD (junio de 2006), pp. 241-252. [23] MENEZES, A. J., VANSTONE, S. A., Y OORSCHOT, P. C. V. Manual de Criptografía Aplicada. CRC Press, 1996. [24] MILLER, R. B. \n\nCRC Press, 1996. [24] MILLER, R. B. Tiempo de respuesta en transacciones conversacionales entre humanos y computadoras. En Proc. Conferencia Conjunta de Computación de Otoño de AFIPS (1968), pp. 267-277. [25] MOGUL, J. C., CHAN, Y. M., Y KELLY, T. Diseño, implementación y evaluación de la detección de transferencias duplicadas en http. En Proc. Primer Simposio sobre Diseño e Implementación de Sistemas en Red (San Francisco, CA, Mar. 2004). [26] MUTHITACHAROEN, A., CHEN, B., Y MAZIERES, D. Un sistema de archivos en red de bajo ancho de banda. En Proc. 18º Simposio de la ACM sobre Principios de Sistemas Operativos (Banff, Canadá, Oct. 2001). [27] PFEIFER, D., Y JAKSCHITSCH, H. Caché basada en métodos en aplicaciones de servidores multinivel. En Proc. Quinto Simposio Internacional sobre Objetos y Aplicaciones Distribuidas (Catania, Sicilia, Italia, noviembre de 2003). [28] PLATTNER, C., Y ALONSO, G. Ganymed: Replicación escalable para aplicaciones web transaccionales. En Proc. 5ta Conferencia Internacional de Middleware ACM/IFIP/USENIX (2004), pp. 155-174. [29] QUINLAN, S., Y DORWARD, S. Venti: Un nuevo enfoque para el almacenamiento de archivos. En Proc. Conferencia FAST 2002 sobre Tecnologías de Archivo y Almacenamiento (2002). [30] RABIN, M. Huellas dactilares mediante polinomios aleatorios. En el Informe Técnico TR-15-81 (1981) del Centro de Investigación en Tecnología Informática de la Universidad de Harvard. [31] RABINOVICH, M., XIAO, Z., DOUGLIS, F., Y KALMANEK, C. Mover los lados de los bordes incluye a los clientes reales en el borde. En Proc. 4to Simposio USENIX sobre Tecnologías y Sistemas de Internet (Seattle, WA, Mar. 2003). [32] REESE, G. Programación de bases de datos con JDBC y Java, 1ra ed. OReilly, junio de 1997. [33] RHEA, S., LIANG, K., Y BREWER, E. Caché web basada en valores. En Proc. Duodécima Conferencia Internacional de la World Wide Web (mayo de 2003). [34] SIVASUBRAMANIAN, S., ALONSO, G., PIERRE, G., Y VAN STEEN, M. Globedb: Replicación autónoma de datos para aplicaciones web. En WWW 05: Actas de la 14ª Conferencia Internacional de la World-Wide Web (mayo de 2005). [35] SPRING, N. T., Y WETHERALL, D. Una técnica independiente de protocolo para eliminar el tráfico de red redundante. En Proc. de ACM SIGCOMM (Ago. 2000). [36] TOLIA, N., HARKES, J., KOZUCH, M., Y SATYANARAYANAN, M. Integrando almacenamiento portátil y distribuido. En Proc. 3ra Conferencia USENIX sobre Tecnologías de Archivos y Almacenamiento (San Francisco, CA, Mar. 2004). [37] TOLIA, N., KOZUCH, M., SATYANARAYANAN, M., KARP, B., PERRIG, A., Y BRESSOUD, T. Uso oportunista del almacenamiento direccionable por contenido para sistemas de archivos distribuidos. En Proc. Conferencia Técnica Anual USENIX 2003 (San Antonio, TX, junio de 2003), pp. 127-140. [38] YUAN, C., CHEN, Y., Y ZHANG, Z. Evaluación de almacenamiento en caché/descarga en el borde para la entrega de contenido dinámico. En WWW 03: Proc. Duodécima Conferencia Internacional sobre la World Wide Web (2003), pp. 461-471. WWW 2007 / Pista: Rendimiento y Escalabilidad Sesión: Sistemas Escalables para Contenido Dinámico 320 ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "wide area network": {
            "translated_key": "red de área amplia",
            "is_in_text": false,
            "original_annotated_sentences": [
                "Consistency-preserving Caching of Dynamic Database Content∗ Niraj Tolia and M. Satyanarayanan Carnegie Mellon University {ntolia,satya}@cs.cmu.edu ABSTRACT With the growing use of dynamic web content generated from relational databases, traditional caching solutions for throughput and latency improvements are ineffective.",
                "We describe a middleware layer called Ganesh that reduces the volume of data transmitted without semantic interpretation of queries or results.",
                "It achieves this reduction through the use of cryptographic hashing to detect similarities with previous results.",
                "These benefits do not require any compromise of the strict consistency semantics provided by the back-end database.",
                "Further, Ganesh does not require modifications to applications, web servers, or database servers, and works with closed-source applications and databases.",
                "Using two benchmarks representative of dynamic web sites, measurements of our prototype show that it can increase end-to-end throughput by as much as twofold for non-data intensive applications and by as much as tenfold for data intensive ones.",
                "Categories and Subject Descriptors C.2.4 [Computer-Communication Networks]: Distributed Systems; H.2.4 [Database Management]: Systems General Terms Design, Performance 1.",
                "INTRODUCTION An increasing fraction of web content is dynamically generated from back-end relational databases.",
                "Even when database content remains unchanged, temporal locality of access cannot be exploited because dynamic content is not cacheable by web browsers or by intermediate caching servers such as Akamai mirrors.",
                "In a multitiered architecture, each web request can stress the WAN link between the web server and the database.",
                "This causes user experience to be highly variable because there is no caching to insulate the client from bursty loads.",
                "Previous attempts in caching dynamic database content have generally weakened transactional semantics [3, 4] or required application modifications [15, 34].",
                "We report on a new solution that takes the form of a databaseagnostic middleware layer called Ganesh.",
                "Ganesh makes no effort to semantically interpret the contents of queries or their results.",
                "Instead, it relies exclusively on cryptographic hashing to detect similarities with previous results.",
                "Hash-based similarity detection has seen increasing use in distributed file systems [26, 36, 37] for improving performance on low-bandwidth networks.",
                "However, these techniques have not been used for relational databases.",
                "Unlike previous approaches that use generic methods to detect similarity, Ganesh exploits the structure of relational database results to yield superior performance improvement.",
                "One faces at least three challenges in applying hash-based similarity detection to back-end databases.",
                "First, previous work in this space has traditionally viewed storage content as uninterpreted bags of bits with no internal structure.",
                "This allows hash-based techniques to operate on long, contiguous runs of data for maximum effectiveness.",
                "In contrast, relational databases have rich internal structure that may not be as amenable to hash-based similarity detection.",
                "Second, relational databases have very tight integrity and consistency constraints that must not be compromised by the use of hash-based techniques.",
                "Third, the source code of commercial databases is typically not available.",
                "This is in contrast to previous work which presumed availability of source code.",
                "Our experiments show that Ganesh, while conceptually simple, can improve performance significantly at bandwidths representative of todays commercial Internet.",
                "On benchmarks modeling multitiered web applications, the throughput improvement was as high as tenfold for data-intensive workloads.",
                "For workloads that were not data-intensive, throughput improvements of up to twofold were observed.",
                "Even when bandwidth was not a constraint, Ganesh had low overhead and did not hurt performance.",
                "Our experiments also confirm that exploiting the structure present in database results is crucial to this performance improvement. 2.",
                "BACKGROUND 2.1 Dynamic Content Generation As the World Wide Web has grown, many web sites have decentralized their data and functionality by pushing them to the edges of the Internet.",
                "Today, eBusiness systems often use a three-tiered architecture consisting of a front-end web server, an application server, and a back-end database server.",
                "Figure 1 illustrates this architecture.",
                "The first two tiers can be replicated close to a concentration of clients at the edge of the Internet.",
                "This improves user experience by lowering end-to-end latency and reducing exposure WWW 2007 / Track: Performance and Scalability Session: Scalable Systems for Dynamic Content 311 Back-End Database Server Front-End Web and Application Servers Figure 1: Multi-Tier Architecture to backbone traffic congestion.",
                "It can also increase the availability and scalability of web services.",
                "Content that is generated dynamically from the back-end database cannot be cached in the first two tiers.",
                "While databases can be easily replicated in a LAN, this is infeasible in a WAN because of the difficult task of simultaneously providing strong consistency, availability, and tolerance to network partitions [7].",
                "As a result, databases tend to be centralized to meet the strong consistency requirements of many eBusiness applications such as banking, finance, and online retailing [38].",
                "Thus, the back-end database is usually located far from many sets of first and second-tier nodes [2].",
                "In the absence of both caching and replication, WAN bandwidth can easily become a limiting factor in the performance and scalability of data-intensive applications. 2.2 Hash-Based Systems Ganeshs focus is on efficient transmission of results by discovering similarities with the results of previous queries.",
                "As SQL queries can generate large results, hash-based techniques lend themselves well to the problem of efficiently transferring these large results across bandwidth constrained links.",
                "The use of hash-based techniques to reduce the volume of data transmitted has emerged as a common theme of many recent storage systems, as discussed in Section 8.2.",
                "These techniques rely on some basic assumptions.",
                "Cryptographic hash functions are assumed to be collision-resistant.",
                "In other words, it is computationally intractable to find two inputs that hash to the same output.",
                "The functions are also assumed to be one-way; that is, finding an input that results in a specific output is computationally infeasible.",
                "Menezes et al. [23] provide more details about these assumptions.",
                "The above assumptions allow hash-based systems to assume that collisions do not occur.",
                "Hence, they are able to treat the hash of a data item as its unique identifier.",
                "A collection of data items effectively becomes content-addressable, allowing a small hash to serve as a codeword for a much larger data item in permanent storage or network transmission.",
                "The assumption that collisions are so rare as to be effectively non-existent has recently come under fire [17].",
                "However, as explained by Black [5], we believe that these issues do not form a concern for Ganesh.",
                "All communication is between trusted parts of the system and an adversary has no way to force Ganesh to accept invalid data.",
                "Further, Ganesh does not depend critically on any specific hash function.",
                "While we currently use SHA-1, replacing it with a different hash function would be simple.",
                "There would be no impact on performance as stronger hash functions (e.g.",
                "SHA256) only add a few extra bytes and the generated hashes are still orders of magnitude smaller than the data items they represent.",
                "No re-hashing of permanent storage is required since Ganesh only uses hashing on volatile data. 3.",
                "DESIGN AND IMPLEMENTATION Ganesh exploits redundancy in the result stream to avoid transmitting result fragments that are already present at the query site.",
                "Redundancy can arise naturally in many different ways.",
                "For example, a query repeated after a certain interval may return a different result because of updates to the database; however, there may be significant commonality between the two results.",
                "As another example, a user who is refining a search may generate a sequence of queries with overlapping results.",
                "When Ganesh detects redundancy, it suppresses transmission of the corresponding result fragments.",
                "Instead, it transmits a much smaller digest of those fragments and lets the query site reconstruct the result through hash lookup in a cache of previous results.",
                "In effect, Ganesh uses computation at the edges to reduce Internet communication.",
                "Our description of Ganesh focuses on four aspects.",
                "We first explain our approach to detecting similarity in query results.",
                "Next, we discuss how the Ganesh architecture is completely invisible to all components of a multi-tier system.",
                "We then describe Ganeshs proxy-based approach and the dataflow for detecting similarity. 3.1 Detecting Similarity One of the key design decisions in Ganesh is how similarity is detected.",
                "There are many potential ways to decompose a result into fragments.",
                "The optimal way is, of course, the one that results in the smallest possible object for transmission for a given querys results.",
                "Finding this optimal decomposition is a difficult problem because of the large space of possibilities and because the optimal choice depends on many factors such as the contents of the querys result, the history of recent results, and the cache management algorithm.",
                "When an object is opaque, the use of Rabin fingerprints [8, 30] to detect common data between two objects has been successfully shown in the past by systems such as LBFS [26] and CASPER [37].",
                "Rabin fingerprinting uses a sliding window over the data to compute a rolling hash.",
                "Assuming that the hash function is uniformly distributed, a chunk boundary is defined whenever the lower order bits of the hash value equal some predetermined value.",
                "The number of lower order bits used defines the average chunk size.",
                "These sub-divided chunks of the object become the unit of comparison for detecting similarity between different objects.",
                "As the locations of boundaries found by using Rabin fingerprints is stochastically determined, they usually fail to align with any structural properties of the underlying data.",
                "The algorithm therefore deals well with in-place updates, insertions and deletions.",
                "However, it performs poorly in the presence of any reordering of data.",
                "Figure 2 shows an example where two results, A and B, consisting of three rows, have the same data but have different sort attributes.",
                "In the extreme case, Rabin fingerprinting might be unable to find any similar data due to the way it detects chunk boundaries.",
                "Fortunately, Ganesh can use domain specific knowledge for more precise boundary detection.",
                "The information we exploit is that a querys result reflects the structure of a relational database where all data is organized as tables and rows.",
                "It is therefore simple to check for similarity with previous results at two granularities: first the entire result, and then individual rows.",
                "The end of a row in a result serves as a natural chunk boundary.",
                "It is important to note that using the tabular structure in results only involves shallow interpretation of the data.",
                "Ganesh does not perform any deeper semantic interpretation such as understanding data types, result schema, or integrity constraints.",
                "Tuning Rabin fingerprinting for a workload can also be difficult.",
                "If the average chunk size is too large, chunks can span multiple result rows.",
                "However, selecting a smaller average chunk size increases the amount of metadata required to the describe the results.",
                "WWW 2007 / Track: Performance and Scalability Session: Scalable Systems for Dynamic Content 312 Figure 2: Rabin Fingerprinting vs. Ganeshs Chunking This, in turn, would decrease the savings obtained via its use.",
                "Rabin fingerprinting also needs two computationally-expensive passes over the data: once to determine chunk boundaries and one again to generate cryptographic hashes for the chunks.",
                "Ganesh only needs a single pass for hash generation as the chunk boundaries are provided by the datas natural structure.",
                "The performance comparison in Section 6 shows that Ganeshs row-based algorithm outperforms Rabin fingerprinting.",
                "Given that previous work has already shown that Rabin fingerprinting performs better than gzip [26], we do not compare Ganesh to compression algorithms in this paper. 3.2 Transparency The key factor influencing our design was the need for Ganesh to be completely transparent to all components of a typical eBusiness system: web servers, application servers, and database servers.",
                "Without this, Ganesh stands little chance of having a significant real-world impact.",
                "Requiring modifications to any of the above components would raise the barrier for entry of Ganesh into an existing system, and thus reduce its chances of adoption.",
                "Preserving transparency is simplified by the fact that Ganesh is purely a performance enhancement, not a functionality or usability enhancement.",
                "We chose agent interposition as the architectural approach to realizing our goal.",
                "This approach relies on the existence of a compact programming interface that is already widely used by target software.",
                "It also relies on a mechanism to easily add new code without disrupting existing module structure.",
                "These conditions are easily met in our context because of the popularity of Java as the programming language for eBusiness systems.",
                "The Java Database Connectivity (JDBC) API [32] allows Java applications to access a wide variety of databases and even other tabular data repositories such as flat files.",
                "Access to these data sources is provided by JDBC drivers that translate between the JDBC API and the database communication mechanism.",
                "Figure 3(a) shows how JDBC is typically used in an application.",
                "As the JDBC interface is standardized, one can substitute one JDBC driver for another without application modifications.",
                "The JDBC driver thus becomes the natural module to exploit for code interposition.",
                "As shown in Figure 3(b), the native JDBC driver is replaced with a Ganesh JDBC driver that presents the same standardized interface.",
                "The Ganesh driver maintains an in-memory cache of result fragments from previous queries and performs reassembly of results.",
                "At the database, we add a new process called the Ganesh proxy.",
                "This proxy, which can be shared by multiple front-end nodes, consists of two parts: code to detect similarity in result fragments and the original native JDBC driver that communicates with the database.",
                "The use of a proxy at the database makes Ganesh database-agnostic and simplifies prototyping and experimentation.",
                "Ganesh is thus able to work with a wide range of databases and applications, requiring no modifications to either. 3.3 Proxy-Based Caching The native JDBC driver shown in Figure 3(a) is a lightweight code component supplied by the database vendor.",
                "Its main funcClient Database Web and Application Server Native JDBC Driver WAN (a) Native Architecture Client Database Ganesh Proxy Native JDBC Driver WAN Web and Application Server Ganesh JDBC Driver (b) Ganeshs Interposition-based Architecture Figure 3: Native vs. Ganesh Architecture tion is to mediate communication between the application and the remote database.",
                "It forwards queries, buffers entire results, and responds to application requests to view parts of results.",
                "The Ganesh JDBC driver shown in Figure 3(b) presents the application with an interface identical to that provided by the native driver.",
                "It provides the ability to reconstruct results from compact hash-based descriptions sent by the proxy.",
                "To perform this reconstruction, the driver maintains an in-memory cache of recentlyreceived results.",
                "This cache is only used as a source of result fragments in reconstructing results.",
                "No attempt is made by the Ganesh driver or proxy to track database updates.",
                "The lack of cache consistency does not hurt correctness as a description of the results is always fetched from the proxy - at worst, there will be no performance benefit from using Ganesh.",
                "Stale data will simply be paged out of the cache over time.",
                "The Ganesh proxy accesses the database via the native JDBC driver, which remains unchanged between Figures 3(a) and (b).",
                "The database is thus completely unaware of the existence of the proxy.",
                "The proxy does not examine any queries received from the Ganesh driver but passes them to the native driver.",
                "Instead, the proxy is responsible for inspecting database output received from the native driver, detecting similar results, and generating hash-based encodings of these results whenever enough similarity is found.",
                "While this architecture does not decrease the load on a database, as mentioned earlier in Section 2.1, it is much easier to replicate databases for scalability in a LAN than in a WAN.",
                "To generate a hash-based encoding, the proxy must be aware of what result fragments are available in the Ganesh drivers cache.",
                "One approach is to be optimistic, and to assume that all result fragments are available.",
                "This will result in the smallest possible initial transmission of a result.",
                "However, in cases where there is little overlap with previous results, the Ganesh driver will have to make many calls to the proxy during reconstruction to fetch missing result fragments.",
                "To avoid this situation, the proxy loosely tracks the state of the Ganesh drivers cache.",
                "Since both components are under our control, it is relatively simple to do this without resorting to gray-box techniques or explicit communication for maintaining cache coherence.",
                "Instead, the proxy simulates the Ganesh drivers cache management algorithm and uses this to maintain a list of hashes for which the Ganesh driver is likely to possess the result fragments.",
                "In case of mistracking, there will be no loss of correctness but there will be extra round-trip delays to fetch the missing fragments.",
                "If the client detects loss of synchronization with the proxy, it can ask the proxy to reset the state shared between them.",
                "Also note that the proxy does not need to keep the result fragments themselves, only their hashes.",
                "This allows the proxy to remain scalable even when it is shared by many front-end nodes.",
                "WWW 2007 / Track: Performance and Scalability Session: Scalable Systems for Dynamic Content 313 Object Output Stream Convert ResultSet Object Input Stream Convert ResultSet All Data Recipe ResultSet All Data ResultSet Network Ganesh Proxy Ganesh JDBC Driver Result Set Recipe Result Set Yes Yes No No GaneshInputStream GaneshOutputStream Figure 4: Dataflow for Result Handling 3.4 Encoding and Decoding Results The Ganesh proxy receives database output as Java objects from the native JDBC driver.",
                "It examines this output to see if a Java object of type ResultSet is present.",
                "The JDBC interface uses this data type to store results of database queries.",
                "If a ResultSet object is found, it is shrunk as discussed below.",
                "All other Java objects are passed through unmodified.",
                "As discussed in Section 3.1, the proxy uses the row boundaries defined in the ResultSet to partition it into fragments consisting of single result rows.",
                "All ResultSet objects are converted into objects of a new type called RecipeResultSet.",
                "We use the term recipe for this compact description of a database result because of its similarity to a file recipe in the CASPER file system [37].",
                "The conversion replaces each result fragment that is likely to be present in the Ganesh drivers cache by a SHA-1 hash of that fragment.",
                "Previously unseen result fragments are retained verbatim.",
                "The proxy also retains hashes for the new result fragments as they will be present in the drivers cache in the future.",
                "Note that the proxy only caches hashes for result fragments and does not cache recipes.",
                "The proxy constructs a RecipeResultSet by checking for similarity at the entire result and then the row level.",
                "If the entire result is predicted to be present in the Ganesh drivers cache, the RecipeResultSet is simply a single hash of the entire result.",
                "Otherwise, it contains hashes for those rows predicted to be present in that cache; all other rows are retained verbatim.",
                "If the proxy estimates an overall space savings, it will transmit the RecipeResultSet.",
                "Otherwise the original ResultSet is transmitted.",
                "The RecipeResultSet objects are transformed back into ResultSet objects by the Ganesh driver.",
                "Figure 4 illustrates ResultSet handling at both ends.",
                "Each SHA-1 hash found in a RecipeResultSet is looked up in the local cache of result fragments.",
                "On a hit, the hash is replaced by the corresponding fragment.",
                "On a miss, the driver contacts the Ganesh proxy to fetch the fragment.",
                "All previously unseen result fragments that were retained verbatim by the proxy are hashed and added to the result cache.",
                "There should be very few misses if the proxy has accurately tracked the Ganesh drivers cache state.",
                "A future optimization would be to batch the fetch of missing fragments.",
                "This would be valuable when there are many small missing fragments in a high-latency WAN.",
                "Once the transformation is complete, the fully reconstructed ResultSet object is passed up to the application. 4.",
                "EXPERIMENTAL VALIDATION Three questions follow from the goals and design of Ganesh: • First, can performance can be improved significantly by exploiting similarity across database results?",
                "Benchmark Dataset Details 500,000 Users, 12,000 Stories BBOARD 2.0 GB 3,298,000 Comments AUCTION 1.3 GB 1,000,000 Users, 34,000 Items Table 1: Benchmark Dataset Details • Second, how important is Ganeshs structural similarity detection relative to Rabin fingerprintings similarity detection? • Third, is the overhead of the proxy-based design acceptable?",
                "Our evaluation answers these question through controlled experiments with the Ganesh prototype.",
                "This section describes the benchmarks used, our evaluation procedure, and the experimental setup.",
                "Results of the experiments are presented in Sections 5, 6, and 7. 4.1 Benchmarks Our evaluation is based on two benchmarks [18] that have been widely used by other researchers to evaluate various aspects of multi-tier [27] and eBusiness architectures [9].",
                "The first benchmark, BBOARD, is modeled after Slashdot, a technology-oriented news site.",
                "The second benchmark, AUCTION, is modeled after eBay, an online auction site.",
                "In both benchmarks, most content is dynamically generated from information stored in a database.",
                "Details of the datasets used can be found in Table 1. 4.1.1 The BBOARD Benchmark The BBOARD benchmark, also known as RUBBoS [18], models Slashdot, a popular technology-oriented web site.",
                "Slashdot aggregates links to news stories and other topics of interest found elsewhere on the web.",
                "The site also serves as a bulletin board by allowing users to comment on the posted stories in a threaded conversation form.",
                "It is not uncommon for a story to gather hundreds of comments in a matter of hours.",
                "The BBOARD benchmark is similar to the site and models the activities of a user, including readonly operations such as browsing the stories of the day, browsing story categories, and viewing comments as well as write operations such as new user registration, adding and moderating comments, and story submission.",
                "The benchmark consists of three different phases: a short warmup phase, a runtime phase representing the main body of the workload, and a short cool-down phase.",
                "In this paper we only report results from the runtime phase.",
                "The warm-up phase is important in establishing dynamic system state, but measurements from that phase are not significant for our evaluation.",
                "The cool-down phase is solely for allowing the benchmark to shut down.",
                "The warm-up, runtime, and cool-down phases are 2, 15, and 2 minutes respectively.",
                "The number of simulated clients were 400, 800, 1200, and 1600.",
                "The benchmark is available in a Java Servlets and PHP version and has different datasets; we evaluated Ganesh using the Java Servlets version and the Expanded dataset.",
                "The BBOARD benchmark defines two different workloads.",
                "The first, the Authoring mix, consists of 70% read-only operations and 30% read-write operations.",
                "The second, the Browsing mix, contains only read-only operations and does not update the database. 4.1.2 The AUCTION Benchmark The AUCTION benchmark, also known as RUBiS [18], models eBay, the online auction site.",
                "The eBay web site is used to buy and sell items via an auction format.",
                "The main activities of a user include browsing, selling, or bidding for items.",
                "Modeling the activities on this site, this benchmark includes read-only activities such as browsing items by category and by region, as well as read-write WWW 2007 / Track: Performance and Scalability Session: Scalable Systems for Dynamic Content 314 NetEm Router Ganesh Proxy Clients Web and Application Server Database Server Figure 5: Experimental Setup activities such as bidding for items, buying and selling items, and leaving feedback.",
                "As with BBOARD, the benchmark consists of three different phases.",
                "The warm-up, runtime, and cool-down phases for this experiment are 1.5, 15, and 1 minutes respectively.",
                "We tested Ganesh with four client configurations where the number of test clients was set to 400, 800, 1200, and 1600.",
                "The benchmark is available in a Enterprise Java Bean (EJB), Java Servlets, and PHP version and has different datasets; we evaluated Ganesh with the Java Servlets version and the Expanded dataset.",
                "The AUCTION benchmark defines two different workloads.",
                "The first, the Bidding mix, consists of 70% read-only operations and 30% read-write operations.",
                "The second, the Browsing mix, contains only read-only operations and does not update the database. 4.2 Experimental Procedure Both benchmarks involve a synthetic workload of clients accessing a web server.",
                "The number of clients emulated is an experimental parameter.",
                "Each emulated client runs an instance of the benchmark in its own thread, using a matrix to transition between different benchmark states.",
                "The matrix defines a stochastic model with probabilities of transitioning between the different states that represent typical user actions.",
                "An example transition is a user logging into the AUCTION system and then deciding on whether to post an item for sale or bid on active auctions.",
                "Each client also models user think time between requests.",
                "The think time is modeled as an exponential distribution with a mean of 7 seconds.",
                "We evaluate Ganesh along two axes: number of clients and WAN bandwidth.",
                "Higher loads are especially useful in understanding Ganeshs performance when the CPU or disk of the database server or proxy is the limiting factor.",
                "A previous study has shown that approximately 50% of the wide-area Internet bottlenecks observed had an available bandwidth under 10 Mb/s [1].",
                "Based on this work, we focus our evaluation on the WAN bandwidth of 5 Mb/s with 66 ms of round-trip latency, representative of severely constrained network paths, and 20 Mb/s with 33 ms of round-trip latency, representative of a moderately constrained network path.",
                "We also report Ganeshs performance at 100 Mb/s with no added round-trip latency.",
                "This bandwidth, representative of an unconstrained network, is especially useful in revealing any potential overhead of Ganesh in situations where WAN bandwidth is not the limiting factor.",
                "For each combination of number of clients and WAN bandwidth, we measured results from the two configurations listed below: • Native: This configuration corresponds to Figure 3(a).",
                "Native avoids Ganeshs overhead in using a proxy and performing Java object serialization. • Ganesh: This configuration corresponds to Figure 3(b).",
                "For a given number of clients and WAN bandwidth, comparing these results to the corresponding Native results gives the performance benefit due to the Ganesh middleware system.",
                "The metric used to quantify the improvement in throughput is the number of client requests that can be serviced per second.",
                "The metric used to quantify Ganeshs overhead is the average response time for a client request.",
                "For all of the experiments, the Ganesh driver used by the application server used a cache size of 100,000 items1 .",
                "The proxy was effective in tracking the Ganesh drivers cache state; for all of our experiments the miss rate on the driver never exceeded 0.7%. 4.3 Experimental Setup The experimental setup used for the benchmarks can be seen in Figure 5.",
                "All machines were 3.2 GHz Pentium 4s (with HyperThreading enabled.)",
                "With the exception of the database server, all machines had 2 GB of SDRAM and ran the Fedora Core Linux distribution.",
                "The database server had 4 GB of SDRAM.",
                "We used Apaches Tomcat as both the application server that hosted the Java Servlets and the web server.",
                "Both benchmarks used Java Servlets to generate the dynamic content.",
                "The database server used the open source MySQL database.",
                "For the native JDBC drivers, we used the Connector/J drivers provided by MySQL.",
                "The application server used Suns Java Virtual Machine as the runtime environment for the Java Servlets.",
                "The sysstat tool was used to monitor the CPU, network, disk, and memory utilization on all machines.",
                "The machines were connected by a switched gigabit Ethernet network.",
                "As shown in Figure 5, the front-end web and application server was separated from the proxy and database server by a NetEm router [16].",
                "This router allowed us to control the bandwidth and latency settings on the network.",
                "The NetEm router is a standard PC with two network cards running the Linux Traffic Control and Network Emulation software.",
                "The bandwidth and latency constraints were only applied to the link between the application server and the database for the native case and between the application server and the proxy for the Ganesh case.",
                "There is no communication between the application server and the database with Ganesh as all data flows through the proxy.",
                "As our focus was on the WAN link between the application server and the database, there were no constraints on the link between the simulated test clients and the web server. 5.",
                "THROUGHPUT AND RESPONSE TIME In this section, we address the first question raised in Section 4: Can performance can be improved significantly by exploiting similarity across database results?",
                "To answer this question, we use results from the BBOARD and AUCTION benchmarks.",
                "We use two metrics to quantify the performance improvement obtainable through the use of Ganesh: throughput, from the perspective of the web server, and average response time, from the perspective of the client.",
                "Throughput is measured in terms of the number of client requests that can be serviced per second. 5.1 BBOARD Results and Analysis 5.1.1 Authoring Mix Figures 6 (a) and (b) present the average number of requests serviced per second and the average response time for these requests as perceived by the clients for BBOARDs Authoring Mix.",
                "As Figure 6 (a) shows, Native easily saturates the 5 Mb/s link.",
                "At 400 clients, the Native solution delivers 29 requests/sec with an average response time of 8.3 seconds.",
                "Natives throughput drops with an increase in test clients as clients timeout due to congestion at the application server.",
                "Usability studies have shown that response times above 10 seconds cause the user to move on to 1 As Java lacks a sizeof() operator, Java caches therefore limit their size based on the number of objects.",
                "The size of cache dumps taken at the end of the experiments never exceeded 212 MB.",
                "WWW 2007 / Track: Performance and Scalability Session: Scalable Systems for Dynamic Content 315 0 50 100 150 200 250 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Test Clients Requests/sec Native Ganesh 0.001 0.01 0.1 1 10 100 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Test Clients Avg.Resp.Time(sec) Native Ganesh Note Logscale (a) Throughput: Authoring Mix (b) Response Time: Authoring Mix 0 50 100 150 200 250 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Test Clients Requests/sec Native Ganesh 0.001 0.01 0.1 1 10 100 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Test Clients Avg.Resp.Time(sec) Native Ganesh Note Logscale (c) Throughput: Browsing Mix (d) Response Time: Browsing Mix Mean of three trials.",
                "The maximum standard deviation for throughput and response time was 9.8% and 11.9% of the corresponding mean.",
                "Figure 6: BBOARD Benchmark - Throughput and Average Response Time other tasks [24].",
                "Based on these numbers, increasing the number of test clients makes the Native system unusable.",
                "Ganesh at 5 Mb/s, however, delivers a twofold improvement with 400 test clients and a fivefold improvement at 1200 clients.",
                "Ganeshs performance drops slightly at 1200 and 1600 clients as the network is saturated.",
                "Compared to Native, Figure 6 (b) shows that Ganeshs response times are substantially lower with sub-second response times at 400 clients.",
                "Figure 6 (a) also shows that for 400 and 800 test clients Ganesh at 5 Mb/s has the same throughput and average response time as Native at 20 Mb/s.",
                "Only at 1200 and 1600 clients does Native at 20 Mb/s deliver higher throughput than Ganesh at 5 Mb/s.",
                "Comparing both Ganesh and Native at 20 Mb/s, we see that Ganesh is no longer bandwidth constrained and delivers up to a twofold improvement over Native at 1600 test clients.",
                "As Ganesh does not saturate the network with higher test client configurations, at 1600 test clients, its average response time is 0.1 seconds rather than Natives 7.7 seconds.",
                "As expected, there are no visible gains from Ganesh at the higher bandwidth of 100 Mb/s where the network is no longer the bottleneck.",
                "Ganesh, however, still tracks Native in terms of throughput. 5.1.2 Browsing Mix Figures 6 (c) and (d) present the average number of requests serviced per second and the average response time for these requests as perceived by the clients for BBOARDs Browsing Mix.",
                "Regardless of the test client configuration, Figure 6 (c) shows that Natives throughput at 5 Mb/s is limited to 10 reqs/sec.",
                "Ganesh at 5 Mb/s with 400 test clients, delivers more than a sixfold increase in throughput.",
                "The improvement increases to over a elevenfold increase at 800 test clients before Ganesh saturates the network.",
                "Further, Figure 6 (d) shows that Natives average response time of 35 seconds at 400 test clients make the system unusable.",
                "These high response times further increase with the addition of test clients.",
                "Even with the 1600 test client configuration Ganesh delivers an acceptable average response time of 8.2 seconds.",
                "Due to the data-intensive nature of the Browsing mix, Ganesh at 5 Mb/s surprisingly performs much better than Native at 20 Mb/s.",
                "Further, as shown in Figure 6 (d), while the average response time for Native at 20 Mb/s is acceptable at 400 test clients, it is unusable with 800 test clients with an average response time of 15.8 seconds.",
                "Like the 5 Mb/s case, this response time increases with the addition of extra test clients.",
                "Ganesh at 20 Mb/s and both Native and Ganesh at 100 Mb/s are not bandwidth limited.",
                "However, performance plateaus out after 1200 test clients due to the database CPU being saturated. 5.1.3 Filter Variant We were surprised by the Native performance from the BBOARD benchmark.",
                "At the bandwidth of 5 Mb/s, Native performance was lower than what we had expected.",
                "It turned out the benchmark code that displays stories read all the comments associated with the particular story from the database and only then did some postprocessing to select the comments to be displayed.",
                "While this is exactly the behavior of SlashCode, the code base behind the Slashdot web site, we decided to modify the benchmark to perform some pre-filtering at the database.",
                "This modified benchmark, named the Filter Variant, models a developer who applies optimizations at the SQL level to transfer less data.",
                "In the interests of brevity, we only briefly summarize the results from the Authoring mix.",
                "For the Authoring mix, at 800 test clients at 5 Mb/s, Figure 7 (a) shows that Natives throughput increase by 85% when compared to the original benchmark while Ganeshs improvement is smaller at 15%.",
                "Natives performance drops above 800 clients as the test clients time out due to high response times.",
                "The most significant gain for Native is seen at 20 Mb/s.",
                "At 1600 test clients, when compared to the original benchmark, Native sees a 73% improvement in throughput and a 77% reduction in average response time.",
                "While WWW 2007 / Track: Performance and Scalability Session: Scalable Systems for Dynamic Content 316 0 50 100 150 200 250 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Test Clients Requests/sec Native Ganesh 0.001 0.01 0.1 1 10 100 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Test Clients Avg.Resp.Time(sec) Native Ganesh Note Logscale (a) Throughput: Authoring Mix (b) Response Time: Authoring Mix Mean of three trials.",
                "The maximum standard deviation for throughput and response time was 7.2% and 11.5% of the corresponding mean.",
                "Figure 7: BBOARD Benchmark - Filter Variant - Throughput and Average Response Time Ganesh sees no improvement when compared to the original, it still processes 19% more requests/sec than Native.",
                "Thus, while the optimizations were more helpful to Native, Ganesh still delivers an improvement in performance. 5.2 AUCTION Results and Analysis 5.2.1 Bidding Mix Figures 8 (a) and (b) present the average number of requests serviced per second and the average response time for these requests as perceived by the clients for AUCTIONs Bidding Mix.",
                "As mentioned earlier, the Bidding mix consists of a mixture of read and write operations.",
                "The AUCTION benchmark is not as data intensive as BBOARD.",
                "Therefore, most of the gains are observed at the lower bandwidth of 5 Mb/s.",
                "Figure 8 (a) shows that the increase in throughput due to Ganesh ranges from 8% at 400 test clients to 18% with 1600 test clients.",
                "As seen in Figure 8 (b), the average response times for Ganesh are significantly lower than Native ranging from a decrease of 84% at 800 test clients to 88% at 1600 test clients.",
                "Figure 8 (a) also shows that with a fourfold increase of bandwidth from 5 Mb/s to 20 Mb/s, Native is no longer bandwidth constrained and there is no performance difference between Ganesh and Native.",
                "With the higher test client configurations, we did observe that the bandwidth used by Ganesh was lower than Native.",
                "Ganesh might still be useful in these non-constrained scenarios if bandwidth is purchased on a metered basis.",
                "Similar results are seen for the 100 Mb/s scenario. 5.2.2 Browsing Mix For AUCTIONs Browsing Mix, Figures 8 (c) and (d) present the average number of requests serviced per second and the average response time for these requests as perceived by the clients.",
                "Again, most of the gains are observed at lower bandwidths.",
                "At 5 Mb/s, Native and Ganesh deliver similar throughput and response times with 400 test clients.",
                "While the throughput for both remains the same at 800 test clients, Figure 8 (d) shows that Ganeshs average response time is 62% lower than Native.",
                "Native saturates the link at 800 clients and adding extra test clients only increases the average response time.",
                "Ganesh, regardless of the test client configuration, is not bandwidth constrained and maintains the same response time.",
                "At 1600 test clients, Figure 8 (c) shows that Ganeshs throughput is almost twice that of Native.",
                "At the higher bandwidths of 20 and 100 Mb/s, neither Ganesh nor Native is bandwidth limited and deliver equivalent throughput and response times.",
                "Benchmark Orig.",
                "Size Ganesh Size Rabin Size SelectSort1 223.6 MB 5.4 MB 219.3 MB SelectSort2 223.6 MB 5.4 MB 223.6 MB Table 2: Similarity Microbenchmarks 6.",
                "STRUCTURAL VS. RABIN SIMILARITY In this section, we address the second question raised in Section 4: How important is Ganeshs structural similarity detection relative to Rabin fingerprinting-based similarity detecting?",
                "To answer this question, we used microbenchmarks and the BBOARD and AUCTION benchmarks.",
                "As Ganesh always performed better than Rabin fingerprinting, we only present a subset of the results here in the interests of brevity. 6.1 Microbenchmarks Two microbenchmarks show an example of the effects of data reordering on Rabin fingerprinting algorithm.",
                "In the first microbenchmark, SelectSort1, a query with a specified sort order selects 223.6 MB of data spread over approximately 280 K rows.",
                "The query is then repeated with a different sort attribute.",
                "While the same number of rows and the same data is returned, the order of rows is different.",
                "In such a scenario, one would expect a large amount of similarity to be detected between both results.",
                "As Table 2 shows, Ganeshs row-based algorithm achieves a 97.6% reduction while the Rabin fingerprinting algorithm, with the average chunk size parameter set to 4 KB, only achieves a 1% reduction.",
                "The reason, as shown earlier in Figure 2, is that with Rabin fingerprinting, the spans of data between two consecutive boundaries usually cross row boundaries.",
                "With the order of the rows changing in the second result and the Rabin fingerprints now spanning different rows, the algorithm is unable to detect significant similarity.",
                "The small gain seen is mostly for those single rows that are large enough to be broken into multiple chunks.",
                "SelectSort2, another micro-benchmark executed the same queries but increased the minimum chunk size of the Rabin fingerprinting algorithm.",
                "As can be seen in Table 2, even the small gain from the previous microbenchmark disappears as the minimum chunk size was greater than the average row size.",
                "While one can partially address these problems by dynamically varying the parameters of the Rabin fingerprinting algorithm, this can be computationally expensive, especially in the presence of changing workloads. 6.2 Application Benchmarks We ran the BBOARD benchmark described in Section 4.1.1 on two versions of Ganesh: the first with Rabin fingerprinting used as WWW 2007 / Track: Performance and Scalability Session: Scalable Systems for Dynamic Content 317 0 50 100 150 200 250 300 350 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Test Clients Requests/sec Native Ganesh 0.001 0.01 0.1 1 10 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Test Clients Avg.Resp.Time(sec) Native Ganesh Note Logscale (a) Throughput: Bidding Mix (b) Response Time: Bidding Mix 0 50 100 150 200 250 300 350 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Test Clients Requests/sec Native Ganesh 0.001 0.01 0.1 1 10 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Test Clients Avg.Resp.Time(sec) Native Ganesh Note Logscale (c) Throughput: Browsing Mix (d) Response Time: Browsing Mix Mean of three trials.",
                "The maximum standard deviation for throughput and response time was 2.2% and 11.8% of the corresponding mean.",
                "Figure 8: AUCTION Benchmark - Throughput and Average Response Time the chunking algorithm and the second with Ganeshs row-based algorithm.",
                "Rabins results for the Browsing Mix are normalized to Ganeshs results and presented in Figure 9.",
                "As Figure 9 (a) shows, at 5 Mb/s, independent of the test client configuration, Rabin significantly underperforms Ganesh.",
                "This happens because of a combination of two reasons.",
                "First, as outlined in Section 3.1, Rabin finds less similarity as it does not exploit the results structural information.",
                "Second, this benchmark contained some queries that generated large results.",
                "In this case, Rabin, with a small average chunk size, generated a large number of objects that evicted other useful data from the cache.",
                "In contrast, Ganesh was able to detect these large rows and correspondingly increase the size of the chunks.",
                "This was confirmed as cache statistics showed that Ganeshs hit ratio was roughly three time that of Rabin.",
                "Throughput measurements at 20 Mb/s were similar with the exception of Rabins performance with 400 test clients.",
                "In this case, Ganesh was not network limited and, in fact, the throughput was the same as 400 clients at 5 Mb/s.",
                "Rabin, however, took advantage of the bandwidth increase from 5 to 20 Mb/s to deliver a slightly better performance.",
                "At 100 Mb/s, Rabins throughput was almost similar to Ganesh as bandwidth was no longer a bottleneck.",
                "The normalized response time, presented in Figure 9 (b), shows similar trends.",
                "At 5 and 20 Mb/s, the addition of test clients decreases the normalized response time as Ganeshs average response time increases faster than Rabins.",
                "However, at no point does Rabin outperform Ganesh.",
                "Note that at 400 and 800 clients at 100 Mb/s, Rabin does have a higher overhead even when it is not bandwidth constrained.",
                "As mentioned in Section 3.1, this is due to the fact that Rabin has to hash each ResultSet twice.",
                "The overhead disappears with 1200 and 1600 clients as the database CPU is saturated and limits the performance of both Ganesh and Rabin. 7.",
                "PROXY OVERHEAD In this section, we address the third question raised in Section 4: Is the overhead of Ganeshs proxy-based design acceptable?",
                "To answer this question, we concentrate on its performance at the higher bandwidths.",
                "Our evaluation in Section 5 showed that Ganesh, when compared to Native, can deliver a substantial throughput improvement at lower bandwidths.",
                "It is only at higher bandwidths that latency, measured by the average response time for a client request, and throughput, measured by the number of client requests that can be serviced per second, overheads would be visible.",
                "Looking at the Authoring mix of the original BBOARD benchmark, there are no visible gains from Ganesh at 100 Mb/s.",
                "Ganesh, however, still tracks Native in terms of throughput.",
                "While the average response time is higher for Ganesh, the absolute difference is in between 0.01 and 0.04 seconds and would be imperceptible to the end-user.",
                "The Browsing mix shows an even smaller difference in average response times.",
                "The results from the filter variant of the BBOARD benchmarks are similar.",
                "Even for the AUCTION benchmark, the difference between Native and Ganeshs response time at 100 Mb/s was never greater than 0.02 seconds.",
                "The only exception to the above results was seen in the filter variant of the BBOARD benchmark where Ganesh at 1600 test clients added 0.85 seconds to the average response time.",
                "Thus, even for much faster networks where the WAN link is not the bottleneck, Ganesh always delivers throughput equivalent to Native.",
                "While some extra latency is added by the proxy-based design, it is usually imperceptible. 8.",
                "RELATED WORK To the best of our knowledge, Ganesh is the first system that combines the use of hash-based techniques with caching of database results to improve throughput and response times for applications with dynamic content.",
                "We also believe that it is also the first system to demonstrate the benefits of using structural information for WWW 2007 / Track: Performance and Scalability Session: Scalable Systems for Dynamic Content 318 0.0 0.2 0.4 0.6 0.8 1.0 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Test Clients Norm.Throughput 31.8 3.8 2.8 2.3 23.8 32.8 5.8 3.6 1.8 2.1 1.1 1.0 0 5 10 15 20 25 30 35 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Test Clients Norm.ResponseTime (a) Normalized Throughput: Higher is better (b) Normalized Response Time: Higher is worse For throughput, a normalized result greater than 1 implies that Rabin is better, For response time, a normalized result greater than 1 implies that Ganesh is better.",
                "Mean of three trials.",
                "The maximum standard deviation for throughput and response time was 9.1% and 13.9% of the corresponding mean.",
                "Figure 9: Normalized Comparison of Ganesh vs. Rabin - BBOARD Browsing Mix detecting similarity.",
                "In this section, we first discuss alternative approaches to caching dynamic content and then examine other uses of hash-based primitives in distributed systems. 8.1 Caching Dynamic Content At the database layer, a number of systems have advocated middletier caching where parts of the database are replicated at the edge or server [3, 4, 20].",
                "These systems either cache entire tables in what is essentially a replicated database or use materialized views from previous query replies [19].",
                "They require tight integration with the back-end database to ensure a time bound on the propagation of updates.",
                "These systems are also usually targeted towards workloads that do not require strict consistency and can tolerate stale data.",
                "Further, unlike Ganesh, some of these mid-tier caching solutions [2, 3], suffer from the complexity of having to participate in query planing and distributed query processing.",
                "Gao et al. [15] propose using a distributed object replication architecture where the data stores consistency requirements are adapted on a per-application basis.",
                "These solutions require substantial developer resources and detailed understanding of the application being modified.",
                "While systems that attempt to automate the partitioning and replication of an applications database exist [34], they do not provide full transaction semantics.",
                "In comparison, Ganesh does not weaken any of the semantics provided by the underlying database.",
                "Recent work in the evaluation of edge caching options for dynamic web sites [38] has suggested that, without careful planning, employing complex offloading strategies can hurt performance.",
                "Instead, the work advocates for an architecture in which all tiers except the database should be offloaded to the edge.",
                "Our evaluation of Ganesh has shown that it would benefit these scenarios.",
                "To improve database scalability, C-JDBC [10], SSS [22], and Ganymed [28] also advocate the use of an interposition-based architecture to transparently cluster and replicate databases at the middleware level.",
                "The approaches of these architectures and Ganesh are complementary and they would benefit each other.",
                "Moving up to the presentation layer, there has been widespread adoption of fragment-based caching [14], which improves cache utilization by separately caching different parts of generated web pages.",
                "While fragment-based caching works at the edge, a recent proposal has proposed moving web page assembly to the clients to optimize content delivery [31].",
                "While Ganesh is not used at the presentation layer, the same principles have been applied in Duplicate Transfer Detection [25] to increase web cache efficiency as well as for web access across bandwidth limited links [33]. 8.2 Hash-based Systems The past few years have seen the emergence of many systems that exploit hash-based techniques.",
                "At the heart of all these systems is the idea of detecting similarity in data without requiring interpretation of that data.",
                "This simple yet elegant idea relies on cryptographic hashing, as discussed earlier in Section 2.",
                "Successful applications of this idea span a wide range of storage systems.",
                "Examples include peer-to-peer backup of personal computing files [11], storage-efficient archiving of data [29], and finding similar files [21].",
                "Spring and Wetherall [35] apply similar principles at the network level.",
                "Using synchronized caches at both ends of a network link, duplicated data is replaced by smaller tokens for transmission and then restored at the remote end.",
                "This and other hash-based systems such as the CASPER [37] and LBFS [26] filesystems, and Layer-2 bandwidth optimizers such as Riverbed and Peribit use Rabin fingerprinting [30] to discover spans of commonality in data.",
                "This approach is especially useful when data items are modified in-place through insertions, deletions, and updates.",
                "However, as Section 6 shows, the performance of this technique can show a dramatic drop in the presence of data reordering.",
                "Ganesh instead uses row boundaries as dividers for detecting similarity.",
                "The most aggressive use of hash-based techniques is by systems that use hashes as the primary identifiers for objects in persistent storage.",
                "Storage systems such as CFS [12] and PAST [13] that have been built using distributed hash tables fall into this category.",
                "Single Instance Storage [6] and Venti [29] are other examples of such systems.",
                "As discussed in Section 2.2, the use of cryptographic hashes for addressing persistent data represents a deeper level of faith in their collision-resistance than that assumed by Ganesh.",
                "If time reveals shortcomings in the hash algorithm, the effort involved in correcting the flaw is much greater.",
                "In Ganesh, it is merely a matter of replacing the hash algorithm. 9.",
                "CONCLUSION The growing use of dynamic web content generated from relational databases places increased demands on WAN bandwidth.",
                "Traditional caching solutions for bandwidth and latency reduction are often ineffective for such content.",
                "This paper shows that the impact of WAN accesses to databases can be substantially reduced through the Ganesh architecture without any compromise of the databases strict consistency semantics.",
                "The essence of the Ganesh architecture is the use of computation at the edges to reduce communication through the Internet.",
                "Ganesh is able to use cryptographic hashes to detect similarity with previous results and send WWW 2007 / Track: Performance and Scalability Session: Scalable Systems for Dynamic Content 319 compact recipes of results rather than full results.",
                "Our design uses interposition to achieve complete transparency: clients, application servers, and database servers are all unaware of Ganeshs presence and require no modification.",
                "Our experimental evaluation confirms that Ganesh, while conceptually simple, can be highly effective in improving throughput and response time.",
                "Our results also confirm that exploiting the structure present in database results to detect similarity is crucial to this performance improvement. 10.",
                "REFERENCES [1] AKELLA, A., SESHAN, S., AND SHAIKH, A.",
                "An empirical evaluation of wide-area internet bottlenecks.",
                "In Proc. 3rd ACM SIGCOMM Conference on Internet Measurement (Miami Beach, FL, USA, Oct. 2003), pp. 101-114. [2] ALTINEL, M., BORNH ¨OVD, C., KRISHNAMURTHY, S., MOHAN, C., PIRAHESH, H., AND REINWALD, B. Cache tables: Paving the way for an adaptive database cache.",
                "In Proc. of 29th VLDB (Berlin, Germany, 2003), pp. 718-729. [3] ALTINEL, M., LUO, Q., KRISHNAMURTHY, S., MOHAN, C., PIRAHESH, H., LINDSAY, B. G., WOO, H., AND BROWN, L. Dbcache: Database caching for web application servers.",
                "In Proc. 2002 ACM SIGMOD (2002), pp. 612-612. [4] AMIRI, K., PARK, S., TEWARI, R., AND PADMANABHAN, S. Dbproxy: A dynamic data cache for web applications.",
                "In Proc.",
                "IEEE International Conference on Data Engineering (ICDE) (Mar. 2003). [5] BLACK, J. Compare-by-hash: A reasoned analysis.",
                "In Proc. 2006 USENIX Annual Technical Conference (Boston, MA, May 2006), pp. 85-90. [6] BOLOSKY, W. J., CORBIN, S., GOEBEL, D., , AND DOUCEUR, J. R. Single instance storage in windows 2000.",
                "In Proc. 4th USENIX Windows Systems Symposium (Seattle, WA, Aug. 2000), pp. 13-24. [7] BREWER, E. A.",
                "Lessons from giant-scale services.",
                "IEEE Internet Computing 5, 4 (2001), 46-55. [8] BRODER, A., GLASSMAN, S., MANASSE, M., AND ZWEIG, G. Syntactic clustering of the web.",
                "In Proc. 6th International WWW Conference (1997). [9] CECCHET, E., CHANDA, A., ELNIKETY, S., MARGUERITE, J., AND ZWAENEPOEL, W. Performance comparison of middleware architectures for generating dynamic web content.",
                "In Proc.",
                "Fourth ACM/IFIP/USENIX International Middleware Conference (Rio de Janeiro, Brazil, June 2003). [10] CECCHET, E., MARGUERITE, J., AND ZWAENEPOEL, W. C-JDBC: Flexible database clustering middleware.",
                "In Proc. 2004 USENIX Annual Technical Conference (Boston, MA, June 2004). [11] COX, L. P., MURRAY, C. D., AND NOBLE, B. D. Pastiche: Making backup cheap and easy.",
                "In OSDI: Symposium on Operating Systems Design and Implementation (2002). [12] DABEK, F., KAASHOEK, M. F., KARGER, D., MORRIS, R., AND STOICA, I. Wide-area cooperative storage with CFS.",
                "In 18th ACM Symposium on Operating Systems Principles (Banff, Canada, Oct. 2001). [13] DRUSCHEL, P., AND ROWSTRON, A.",
                "PAST: A large-scale, persistent peer-to-peer storage utility.",
                "In HotOS VIII (Schloss Elmau, Germany, May 2001), pp. 75-80. [14] Edge side includes. http://www.esi.org. [15] GAO, L., DAHLIN, M., NAYATE, A., ZHENG, J., AND IYENGAR, A.",
                "Application specific data replication for edge services.",
                "In WWW 03: Proc.",
                "Twelfth International Conference on World Wide Web (2003), pp. 449-460. [16] HEMMINGER, S. Netem - emulating real networks in the lab.",
                "In Proc. 2005 Linux Conference Australia (Canberra, Australia, Apr. 2005). [17] HENSON, V. An analysis of compare-by-hash.",
                "In Proc. 9th Workshop on Hot Topics in Operating Systems (HotOS IX) (May 2003), pp. 13-18. [18] Jmob benchmarks. http://jmob.objectweb.org/. [19] LABRINIDIS, A., AND ROUSSOPOULOS, N. Balancing performance and data freshness in web database servers.",
                "In Proc. 29th VLDB Conference (Sept. 2003). [20] LARSON, P.-A., GOLDSTEIN, J., AND ZHOU, J. Transparent mid-tier database caching in sql server.",
                "In Proc. 2003 ACM SIGMOD (2003), pp. 661-661. [21] MANBER, U.",
                "Finding similar files in a large file system.",
                "In Proc.",
                "USENIX Winter 1994 Technical Conference (San Fransisco, CA, 17-21 1994), pp. 1-10. [22] MANJHI, A., AILAMAKI, A., MAGGS, B. M., MOWRY, T. C., OLSTON, C., AND TOMASIC, A.",
                "Simultaneous scalability and security for data-intensive web applications.",
                "In Proc. 2006 ACM SIGMOD (June 2006), pp. 241-252. [23] MENEZES, A. J., VANSTONE, S. A., AND OORSCHOT, P. C. V. Handbook of Applied Cryptography.",
                "CRC Press, 1996. [24] MILLER, R. B.",
                "Response time in man-computer conversational transactions.",
                "In Proc.",
                "AFIPS Fall Joint Computer Conference (1968), pp. 267-277. [25] MOGUL, J. C., CHAN, Y. M., AND KELLY, T. Design, implementation, and evaluation of duplicate transfer detection in http.",
                "In Proc.",
                "First Symposium on Networked Systems Design and Implementation (San Francisco, CA, Mar. 2004). [26] MUTHITACHAROEN, A., CHEN, B., AND MAZIERES, D. A low-bandwidth network file system.",
                "In Proc. 18th ACM Symposium on Operating Systems Principles (Banff, Canada, Oct. 2001). [27] PFEIFER, D., AND JAKSCHITSCH, H. Method-based caching in multi-tiered server applications.",
                "In Proc.",
                "Fifth International Symposium on Distributed Objects and Applications (Catania, Sicily, Italy, Nov. 2003). [28] PLATTNER, C., AND ALONSO, G. Ganymed: Scalable replication for transactional web applications.",
                "In Proc. 5th ACM/IFIP/USENIX International Conference on Middleware (2004), pp. 155-174. [29] QUINLAN, S., AND DORWARD, S. Venti: A new approach to archival storage.",
                "In Proc.",
                "FAST 2002 Conference on File and Storage Technologies (2002). [30] RABIN, M. Fingerprinting by random polynomials.",
                "In Harvard University Center for Research in Computing Technology Technical Report TR-15-81 (1981). [31] RABINOVICH, M., XIAO, Z., DOUGLIS, F., AND KALMANEK, C. Moving edge side includes to the real edge - the clients.",
                "In Proc. 4th USENIX Symposium on Internet Technologies and Systems (Seattle, WA, Mar. 2003). [32] REESE, G. Database Programming with JDBC and Java, 1st ed.",
                "OReilly, June 1997. [33] RHEA, S., LIANG, K., AND BREWER, E. Value-based web caching.",
                "In Proc.",
                "Twelfth International World Wide Web Conference (May 2003). [34] SIVASUBRAMANIAN, S., ALONSO, G., PIERRE, G., AND VAN STEEN, M. Globedb: Autonomic data replication for web applications.",
                "In WWW 05: Proc. 14th International World-Wide Web conference (May 2005). [35] SPRING, N. T., AND WETHERALL, D. A protocol-independent technique for eliminating redundant network traffic.",
                "In Proc. of ACM SIGCOMM (Aug. 2000). [36] TOLIA, N., HARKES, J., KOZUCH, M., AND SATYANARAYANAN, M. Integrating portable and distributed storage.",
                "In Proc. 3rd USENIX Conference on File and Storage Technologies (San Francisco, CA, Mar. 2004). [37] TOLIA, N., KOZUCH, M., SATYANARAYANAN, M., KARP, B., PERRIG, A., AND BRESSOUD, T. Opportunistic use of content addressable storage for distributed file systems.",
                "In Proc. 2003 USENIX Annual Technical Conference (San Antonio, TX, June 2003), pp. 127-140. [38] YUAN, C., CHEN, Y., AND ZHANG, Z.",
                "Evaluation of edge caching/offloading for dynamic content delivery.",
                "In WWW 03: Proc.",
                "Twelfth International Conference on World Wide Web (2003), pp. 461-471.",
                "WWW 2007 / Track: Performance and Scalability Session: Scalable Systems for Dynamic Content 320"
            ],
            "original_annotated_samples": [],
            "translated_annotated_samples": [],
            "translated_text": "",
            "candidates": [],
            "error": [
                []
            ]
        },
        "bandwidth optimization": {
            "translated_key": "optimización del ancho de banda",
            "is_in_text": false,
            "original_annotated_sentences": [
                "Consistency-preserving Caching of Dynamic Database Content∗ Niraj Tolia and M. Satyanarayanan Carnegie Mellon University {ntolia,satya}@cs.cmu.edu ABSTRACT With the growing use of dynamic web content generated from relational databases, traditional caching solutions for throughput and latency improvements are ineffective.",
                "We describe a middleware layer called Ganesh that reduces the volume of data transmitted without semantic interpretation of queries or results.",
                "It achieves this reduction through the use of cryptographic hashing to detect similarities with previous results.",
                "These benefits do not require any compromise of the strict consistency semantics provided by the back-end database.",
                "Further, Ganesh does not require modifications to applications, web servers, or database servers, and works with closed-source applications and databases.",
                "Using two benchmarks representative of dynamic web sites, measurements of our prototype show that it can increase end-to-end throughput by as much as twofold for non-data intensive applications and by as much as tenfold for data intensive ones.",
                "Categories and Subject Descriptors C.2.4 [Computer-Communication Networks]: Distributed Systems; H.2.4 [Database Management]: Systems General Terms Design, Performance 1.",
                "INTRODUCTION An increasing fraction of web content is dynamically generated from back-end relational databases.",
                "Even when database content remains unchanged, temporal locality of access cannot be exploited because dynamic content is not cacheable by web browsers or by intermediate caching servers such as Akamai mirrors.",
                "In a multitiered architecture, each web request can stress the WAN link between the web server and the database.",
                "This causes user experience to be highly variable because there is no caching to insulate the client from bursty loads.",
                "Previous attempts in caching dynamic database content have generally weakened transactional semantics [3, 4] or required application modifications [15, 34].",
                "We report on a new solution that takes the form of a databaseagnostic middleware layer called Ganesh.",
                "Ganesh makes no effort to semantically interpret the contents of queries or their results.",
                "Instead, it relies exclusively on cryptographic hashing to detect similarities with previous results.",
                "Hash-based similarity detection has seen increasing use in distributed file systems [26, 36, 37] for improving performance on low-bandwidth networks.",
                "However, these techniques have not been used for relational databases.",
                "Unlike previous approaches that use generic methods to detect similarity, Ganesh exploits the structure of relational database results to yield superior performance improvement.",
                "One faces at least three challenges in applying hash-based similarity detection to back-end databases.",
                "First, previous work in this space has traditionally viewed storage content as uninterpreted bags of bits with no internal structure.",
                "This allows hash-based techniques to operate on long, contiguous runs of data for maximum effectiveness.",
                "In contrast, relational databases have rich internal structure that may not be as amenable to hash-based similarity detection.",
                "Second, relational databases have very tight integrity and consistency constraints that must not be compromised by the use of hash-based techniques.",
                "Third, the source code of commercial databases is typically not available.",
                "This is in contrast to previous work which presumed availability of source code.",
                "Our experiments show that Ganesh, while conceptually simple, can improve performance significantly at bandwidths representative of todays commercial Internet.",
                "On benchmarks modeling multitiered web applications, the throughput improvement was as high as tenfold for data-intensive workloads.",
                "For workloads that were not data-intensive, throughput improvements of up to twofold were observed.",
                "Even when bandwidth was not a constraint, Ganesh had low overhead and did not hurt performance.",
                "Our experiments also confirm that exploiting the structure present in database results is crucial to this performance improvement. 2.",
                "BACKGROUND 2.1 Dynamic Content Generation As the World Wide Web has grown, many web sites have decentralized their data and functionality by pushing them to the edges of the Internet.",
                "Today, eBusiness systems often use a three-tiered architecture consisting of a front-end web server, an application server, and a back-end database server.",
                "Figure 1 illustrates this architecture.",
                "The first two tiers can be replicated close to a concentration of clients at the edge of the Internet.",
                "This improves user experience by lowering end-to-end latency and reducing exposure WWW 2007 / Track: Performance and Scalability Session: Scalable Systems for Dynamic Content 311 Back-End Database Server Front-End Web and Application Servers Figure 1: Multi-Tier Architecture to backbone traffic congestion.",
                "It can also increase the availability and scalability of web services.",
                "Content that is generated dynamically from the back-end database cannot be cached in the first two tiers.",
                "While databases can be easily replicated in a LAN, this is infeasible in a WAN because of the difficult task of simultaneously providing strong consistency, availability, and tolerance to network partitions [7].",
                "As a result, databases tend to be centralized to meet the strong consistency requirements of many eBusiness applications such as banking, finance, and online retailing [38].",
                "Thus, the back-end database is usually located far from many sets of first and second-tier nodes [2].",
                "In the absence of both caching and replication, WAN bandwidth can easily become a limiting factor in the performance and scalability of data-intensive applications. 2.2 Hash-Based Systems Ganeshs focus is on efficient transmission of results by discovering similarities with the results of previous queries.",
                "As SQL queries can generate large results, hash-based techniques lend themselves well to the problem of efficiently transferring these large results across bandwidth constrained links.",
                "The use of hash-based techniques to reduce the volume of data transmitted has emerged as a common theme of many recent storage systems, as discussed in Section 8.2.",
                "These techniques rely on some basic assumptions.",
                "Cryptographic hash functions are assumed to be collision-resistant.",
                "In other words, it is computationally intractable to find two inputs that hash to the same output.",
                "The functions are also assumed to be one-way; that is, finding an input that results in a specific output is computationally infeasible.",
                "Menezes et al. [23] provide more details about these assumptions.",
                "The above assumptions allow hash-based systems to assume that collisions do not occur.",
                "Hence, they are able to treat the hash of a data item as its unique identifier.",
                "A collection of data items effectively becomes content-addressable, allowing a small hash to serve as a codeword for a much larger data item in permanent storage or network transmission.",
                "The assumption that collisions are so rare as to be effectively non-existent has recently come under fire [17].",
                "However, as explained by Black [5], we believe that these issues do not form a concern for Ganesh.",
                "All communication is between trusted parts of the system and an adversary has no way to force Ganesh to accept invalid data.",
                "Further, Ganesh does not depend critically on any specific hash function.",
                "While we currently use SHA-1, replacing it with a different hash function would be simple.",
                "There would be no impact on performance as stronger hash functions (e.g.",
                "SHA256) only add a few extra bytes and the generated hashes are still orders of magnitude smaller than the data items they represent.",
                "No re-hashing of permanent storage is required since Ganesh only uses hashing on volatile data. 3.",
                "DESIGN AND IMPLEMENTATION Ganesh exploits redundancy in the result stream to avoid transmitting result fragments that are already present at the query site.",
                "Redundancy can arise naturally in many different ways.",
                "For example, a query repeated after a certain interval may return a different result because of updates to the database; however, there may be significant commonality between the two results.",
                "As another example, a user who is refining a search may generate a sequence of queries with overlapping results.",
                "When Ganesh detects redundancy, it suppresses transmission of the corresponding result fragments.",
                "Instead, it transmits a much smaller digest of those fragments and lets the query site reconstruct the result through hash lookup in a cache of previous results.",
                "In effect, Ganesh uses computation at the edges to reduce Internet communication.",
                "Our description of Ganesh focuses on four aspects.",
                "We first explain our approach to detecting similarity in query results.",
                "Next, we discuss how the Ganesh architecture is completely invisible to all components of a multi-tier system.",
                "We then describe Ganeshs proxy-based approach and the dataflow for detecting similarity. 3.1 Detecting Similarity One of the key design decisions in Ganesh is how similarity is detected.",
                "There are many potential ways to decompose a result into fragments.",
                "The optimal way is, of course, the one that results in the smallest possible object for transmission for a given querys results.",
                "Finding this optimal decomposition is a difficult problem because of the large space of possibilities and because the optimal choice depends on many factors such as the contents of the querys result, the history of recent results, and the cache management algorithm.",
                "When an object is opaque, the use of Rabin fingerprints [8, 30] to detect common data between two objects has been successfully shown in the past by systems such as LBFS [26] and CASPER [37].",
                "Rabin fingerprinting uses a sliding window over the data to compute a rolling hash.",
                "Assuming that the hash function is uniformly distributed, a chunk boundary is defined whenever the lower order bits of the hash value equal some predetermined value.",
                "The number of lower order bits used defines the average chunk size.",
                "These sub-divided chunks of the object become the unit of comparison for detecting similarity between different objects.",
                "As the locations of boundaries found by using Rabin fingerprints is stochastically determined, they usually fail to align with any structural properties of the underlying data.",
                "The algorithm therefore deals well with in-place updates, insertions and deletions.",
                "However, it performs poorly in the presence of any reordering of data.",
                "Figure 2 shows an example where two results, A and B, consisting of three rows, have the same data but have different sort attributes.",
                "In the extreme case, Rabin fingerprinting might be unable to find any similar data due to the way it detects chunk boundaries.",
                "Fortunately, Ganesh can use domain specific knowledge for more precise boundary detection.",
                "The information we exploit is that a querys result reflects the structure of a relational database where all data is organized as tables and rows.",
                "It is therefore simple to check for similarity with previous results at two granularities: first the entire result, and then individual rows.",
                "The end of a row in a result serves as a natural chunk boundary.",
                "It is important to note that using the tabular structure in results only involves shallow interpretation of the data.",
                "Ganesh does not perform any deeper semantic interpretation such as understanding data types, result schema, or integrity constraints.",
                "Tuning Rabin fingerprinting for a workload can also be difficult.",
                "If the average chunk size is too large, chunks can span multiple result rows.",
                "However, selecting a smaller average chunk size increases the amount of metadata required to the describe the results.",
                "WWW 2007 / Track: Performance and Scalability Session: Scalable Systems for Dynamic Content 312 Figure 2: Rabin Fingerprinting vs. Ganeshs Chunking This, in turn, would decrease the savings obtained via its use.",
                "Rabin fingerprinting also needs two computationally-expensive passes over the data: once to determine chunk boundaries and one again to generate cryptographic hashes for the chunks.",
                "Ganesh only needs a single pass for hash generation as the chunk boundaries are provided by the datas natural structure.",
                "The performance comparison in Section 6 shows that Ganeshs row-based algorithm outperforms Rabin fingerprinting.",
                "Given that previous work has already shown that Rabin fingerprinting performs better than gzip [26], we do not compare Ganesh to compression algorithms in this paper. 3.2 Transparency The key factor influencing our design was the need for Ganesh to be completely transparent to all components of a typical eBusiness system: web servers, application servers, and database servers.",
                "Without this, Ganesh stands little chance of having a significant real-world impact.",
                "Requiring modifications to any of the above components would raise the barrier for entry of Ganesh into an existing system, and thus reduce its chances of adoption.",
                "Preserving transparency is simplified by the fact that Ganesh is purely a performance enhancement, not a functionality or usability enhancement.",
                "We chose agent interposition as the architectural approach to realizing our goal.",
                "This approach relies on the existence of a compact programming interface that is already widely used by target software.",
                "It also relies on a mechanism to easily add new code without disrupting existing module structure.",
                "These conditions are easily met in our context because of the popularity of Java as the programming language for eBusiness systems.",
                "The Java Database Connectivity (JDBC) API [32] allows Java applications to access a wide variety of databases and even other tabular data repositories such as flat files.",
                "Access to these data sources is provided by JDBC drivers that translate between the JDBC API and the database communication mechanism.",
                "Figure 3(a) shows how JDBC is typically used in an application.",
                "As the JDBC interface is standardized, one can substitute one JDBC driver for another without application modifications.",
                "The JDBC driver thus becomes the natural module to exploit for code interposition.",
                "As shown in Figure 3(b), the native JDBC driver is replaced with a Ganesh JDBC driver that presents the same standardized interface.",
                "The Ganesh driver maintains an in-memory cache of result fragments from previous queries and performs reassembly of results.",
                "At the database, we add a new process called the Ganesh proxy.",
                "This proxy, which can be shared by multiple front-end nodes, consists of two parts: code to detect similarity in result fragments and the original native JDBC driver that communicates with the database.",
                "The use of a proxy at the database makes Ganesh database-agnostic and simplifies prototyping and experimentation.",
                "Ganesh is thus able to work with a wide range of databases and applications, requiring no modifications to either. 3.3 Proxy-Based Caching The native JDBC driver shown in Figure 3(a) is a lightweight code component supplied by the database vendor.",
                "Its main funcClient Database Web and Application Server Native JDBC Driver WAN (a) Native Architecture Client Database Ganesh Proxy Native JDBC Driver WAN Web and Application Server Ganesh JDBC Driver (b) Ganeshs Interposition-based Architecture Figure 3: Native vs. Ganesh Architecture tion is to mediate communication between the application and the remote database.",
                "It forwards queries, buffers entire results, and responds to application requests to view parts of results.",
                "The Ganesh JDBC driver shown in Figure 3(b) presents the application with an interface identical to that provided by the native driver.",
                "It provides the ability to reconstruct results from compact hash-based descriptions sent by the proxy.",
                "To perform this reconstruction, the driver maintains an in-memory cache of recentlyreceived results.",
                "This cache is only used as a source of result fragments in reconstructing results.",
                "No attempt is made by the Ganesh driver or proxy to track database updates.",
                "The lack of cache consistency does not hurt correctness as a description of the results is always fetched from the proxy - at worst, there will be no performance benefit from using Ganesh.",
                "Stale data will simply be paged out of the cache over time.",
                "The Ganesh proxy accesses the database via the native JDBC driver, which remains unchanged between Figures 3(a) and (b).",
                "The database is thus completely unaware of the existence of the proxy.",
                "The proxy does not examine any queries received from the Ganesh driver but passes them to the native driver.",
                "Instead, the proxy is responsible for inspecting database output received from the native driver, detecting similar results, and generating hash-based encodings of these results whenever enough similarity is found.",
                "While this architecture does not decrease the load on a database, as mentioned earlier in Section 2.1, it is much easier to replicate databases for scalability in a LAN than in a WAN.",
                "To generate a hash-based encoding, the proxy must be aware of what result fragments are available in the Ganesh drivers cache.",
                "One approach is to be optimistic, and to assume that all result fragments are available.",
                "This will result in the smallest possible initial transmission of a result.",
                "However, in cases where there is little overlap with previous results, the Ganesh driver will have to make many calls to the proxy during reconstruction to fetch missing result fragments.",
                "To avoid this situation, the proxy loosely tracks the state of the Ganesh drivers cache.",
                "Since both components are under our control, it is relatively simple to do this without resorting to gray-box techniques or explicit communication for maintaining cache coherence.",
                "Instead, the proxy simulates the Ganesh drivers cache management algorithm and uses this to maintain a list of hashes for which the Ganesh driver is likely to possess the result fragments.",
                "In case of mistracking, there will be no loss of correctness but there will be extra round-trip delays to fetch the missing fragments.",
                "If the client detects loss of synchronization with the proxy, it can ask the proxy to reset the state shared between them.",
                "Also note that the proxy does not need to keep the result fragments themselves, only their hashes.",
                "This allows the proxy to remain scalable even when it is shared by many front-end nodes.",
                "WWW 2007 / Track: Performance and Scalability Session: Scalable Systems for Dynamic Content 313 Object Output Stream Convert ResultSet Object Input Stream Convert ResultSet All Data Recipe ResultSet All Data ResultSet Network Ganesh Proxy Ganesh JDBC Driver Result Set Recipe Result Set Yes Yes No No GaneshInputStream GaneshOutputStream Figure 4: Dataflow for Result Handling 3.4 Encoding and Decoding Results The Ganesh proxy receives database output as Java objects from the native JDBC driver.",
                "It examines this output to see if a Java object of type ResultSet is present.",
                "The JDBC interface uses this data type to store results of database queries.",
                "If a ResultSet object is found, it is shrunk as discussed below.",
                "All other Java objects are passed through unmodified.",
                "As discussed in Section 3.1, the proxy uses the row boundaries defined in the ResultSet to partition it into fragments consisting of single result rows.",
                "All ResultSet objects are converted into objects of a new type called RecipeResultSet.",
                "We use the term recipe for this compact description of a database result because of its similarity to a file recipe in the CASPER file system [37].",
                "The conversion replaces each result fragment that is likely to be present in the Ganesh drivers cache by a SHA-1 hash of that fragment.",
                "Previously unseen result fragments are retained verbatim.",
                "The proxy also retains hashes for the new result fragments as they will be present in the drivers cache in the future.",
                "Note that the proxy only caches hashes for result fragments and does not cache recipes.",
                "The proxy constructs a RecipeResultSet by checking for similarity at the entire result and then the row level.",
                "If the entire result is predicted to be present in the Ganesh drivers cache, the RecipeResultSet is simply a single hash of the entire result.",
                "Otherwise, it contains hashes for those rows predicted to be present in that cache; all other rows are retained verbatim.",
                "If the proxy estimates an overall space savings, it will transmit the RecipeResultSet.",
                "Otherwise the original ResultSet is transmitted.",
                "The RecipeResultSet objects are transformed back into ResultSet objects by the Ganesh driver.",
                "Figure 4 illustrates ResultSet handling at both ends.",
                "Each SHA-1 hash found in a RecipeResultSet is looked up in the local cache of result fragments.",
                "On a hit, the hash is replaced by the corresponding fragment.",
                "On a miss, the driver contacts the Ganesh proxy to fetch the fragment.",
                "All previously unseen result fragments that were retained verbatim by the proxy are hashed and added to the result cache.",
                "There should be very few misses if the proxy has accurately tracked the Ganesh drivers cache state.",
                "A future optimization would be to batch the fetch of missing fragments.",
                "This would be valuable when there are many small missing fragments in a high-latency WAN.",
                "Once the transformation is complete, the fully reconstructed ResultSet object is passed up to the application. 4.",
                "EXPERIMENTAL VALIDATION Three questions follow from the goals and design of Ganesh: • First, can performance can be improved significantly by exploiting similarity across database results?",
                "Benchmark Dataset Details 500,000 Users, 12,000 Stories BBOARD 2.0 GB 3,298,000 Comments AUCTION 1.3 GB 1,000,000 Users, 34,000 Items Table 1: Benchmark Dataset Details • Second, how important is Ganeshs structural similarity detection relative to Rabin fingerprintings similarity detection? • Third, is the overhead of the proxy-based design acceptable?",
                "Our evaluation answers these question through controlled experiments with the Ganesh prototype.",
                "This section describes the benchmarks used, our evaluation procedure, and the experimental setup.",
                "Results of the experiments are presented in Sections 5, 6, and 7. 4.1 Benchmarks Our evaluation is based on two benchmarks [18] that have been widely used by other researchers to evaluate various aspects of multi-tier [27] and eBusiness architectures [9].",
                "The first benchmark, BBOARD, is modeled after Slashdot, a technology-oriented news site.",
                "The second benchmark, AUCTION, is modeled after eBay, an online auction site.",
                "In both benchmarks, most content is dynamically generated from information stored in a database.",
                "Details of the datasets used can be found in Table 1. 4.1.1 The BBOARD Benchmark The BBOARD benchmark, also known as RUBBoS [18], models Slashdot, a popular technology-oriented web site.",
                "Slashdot aggregates links to news stories and other topics of interest found elsewhere on the web.",
                "The site also serves as a bulletin board by allowing users to comment on the posted stories in a threaded conversation form.",
                "It is not uncommon for a story to gather hundreds of comments in a matter of hours.",
                "The BBOARD benchmark is similar to the site and models the activities of a user, including readonly operations such as browsing the stories of the day, browsing story categories, and viewing comments as well as write operations such as new user registration, adding and moderating comments, and story submission.",
                "The benchmark consists of three different phases: a short warmup phase, a runtime phase representing the main body of the workload, and a short cool-down phase.",
                "In this paper we only report results from the runtime phase.",
                "The warm-up phase is important in establishing dynamic system state, but measurements from that phase are not significant for our evaluation.",
                "The cool-down phase is solely for allowing the benchmark to shut down.",
                "The warm-up, runtime, and cool-down phases are 2, 15, and 2 minutes respectively.",
                "The number of simulated clients were 400, 800, 1200, and 1600.",
                "The benchmark is available in a Java Servlets and PHP version and has different datasets; we evaluated Ganesh using the Java Servlets version and the Expanded dataset.",
                "The BBOARD benchmark defines two different workloads.",
                "The first, the Authoring mix, consists of 70% read-only operations and 30% read-write operations.",
                "The second, the Browsing mix, contains only read-only operations and does not update the database. 4.1.2 The AUCTION Benchmark The AUCTION benchmark, also known as RUBiS [18], models eBay, the online auction site.",
                "The eBay web site is used to buy and sell items via an auction format.",
                "The main activities of a user include browsing, selling, or bidding for items.",
                "Modeling the activities on this site, this benchmark includes read-only activities such as browsing items by category and by region, as well as read-write WWW 2007 / Track: Performance and Scalability Session: Scalable Systems for Dynamic Content 314 NetEm Router Ganesh Proxy Clients Web and Application Server Database Server Figure 5: Experimental Setup activities such as bidding for items, buying and selling items, and leaving feedback.",
                "As with BBOARD, the benchmark consists of three different phases.",
                "The warm-up, runtime, and cool-down phases for this experiment are 1.5, 15, and 1 minutes respectively.",
                "We tested Ganesh with four client configurations where the number of test clients was set to 400, 800, 1200, and 1600.",
                "The benchmark is available in a Enterprise Java Bean (EJB), Java Servlets, and PHP version and has different datasets; we evaluated Ganesh with the Java Servlets version and the Expanded dataset.",
                "The AUCTION benchmark defines two different workloads.",
                "The first, the Bidding mix, consists of 70% read-only operations and 30% read-write operations.",
                "The second, the Browsing mix, contains only read-only operations and does not update the database. 4.2 Experimental Procedure Both benchmarks involve a synthetic workload of clients accessing a web server.",
                "The number of clients emulated is an experimental parameter.",
                "Each emulated client runs an instance of the benchmark in its own thread, using a matrix to transition between different benchmark states.",
                "The matrix defines a stochastic model with probabilities of transitioning between the different states that represent typical user actions.",
                "An example transition is a user logging into the AUCTION system and then deciding on whether to post an item for sale or bid on active auctions.",
                "Each client also models user think time between requests.",
                "The think time is modeled as an exponential distribution with a mean of 7 seconds.",
                "We evaluate Ganesh along two axes: number of clients and WAN bandwidth.",
                "Higher loads are especially useful in understanding Ganeshs performance when the CPU or disk of the database server or proxy is the limiting factor.",
                "A previous study has shown that approximately 50% of the wide-area Internet bottlenecks observed had an available bandwidth under 10 Mb/s [1].",
                "Based on this work, we focus our evaluation on the WAN bandwidth of 5 Mb/s with 66 ms of round-trip latency, representative of severely constrained network paths, and 20 Mb/s with 33 ms of round-trip latency, representative of a moderately constrained network path.",
                "We also report Ganeshs performance at 100 Mb/s with no added round-trip latency.",
                "This bandwidth, representative of an unconstrained network, is especially useful in revealing any potential overhead of Ganesh in situations where WAN bandwidth is not the limiting factor.",
                "For each combination of number of clients and WAN bandwidth, we measured results from the two configurations listed below: • Native: This configuration corresponds to Figure 3(a).",
                "Native avoids Ganeshs overhead in using a proxy and performing Java object serialization. • Ganesh: This configuration corresponds to Figure 3(b).",
                "For a given number of clients and WAN bandwidth, comparing these results to the corresponding Native results gives the performance benefit due to the Ganesh middleware system.",
                "The metric used to quantify the improvement in throughput is the number of client requests that can be serviced per second.",
                "The metric used to quantify Ganeshs overhead is the average response time for a client request.",
                "For all of the experiments, the Ganesh driver used by the application server used a cache size of 100,000 items1 .",
                "The proxy was effective in tracking the Ganesh drivers cache state; for all of our experiments the miss rate on the driver never exceeded 0.7%. 4.3 Experimental Setup The experimental setup used for the benchmarks can be seen in Figure 5.",
                "All machines were 3.2 GHz Pentium 4s (with HyperThreading enabled.)",
                "With the exception of the database server, all machines had 2 GB of SDRAM and ran the Fedora Core Linux distribution.",
                "The database server had 4 GB of SDRAM.",
                "We used Apaches Tomcat as both the application server that hosted the Java Servlets and the web server.",
                "Both benchmarks used Java Servlets to generate the dynamic content.",
                "The database server used the open source MySQL database.",
                "For the native JDBC drivers, we used the Connector/J drivers provided by MySQL.",
                "The application server used Suns Java Virtual Machine as the runtime environment for the Java Servlets.",
                "The sysstat tool was used to monitor the CPU, network, disk, and memory utilization on all machines.",
                "The machines were connected by a switched gigabit Ethernet network.",
                "As shown in Figure 5, the front-end web and application server was separated from the proxy and database server by a NetEm router [16].",
                "This router allowed us to control the bandwidth and latency settings on the network.",
                "The NetEm router is a standard PC with two network cards running the Linux Traffic Control and Network Emulation software.",
                "The bandwidth and latency constraints were only applied to the link between the application server and the database for the native case and between the application server and the proxy for the Ganesh case.",
                "There is no communication between the application server and the database with Ganesh as all data flows through the proxy.",
                "As our focus was on the WAN link between the application server and the database, there were no constraints on the link between the simulated test clients and the web server. 5.",
                "THROUGHPUT AND RESPONSE TIME In this section, we address the first question raised in Section 4: Can performance can be improved significantly by exploiting similarity across database results?",
                "To answer this question, we use results from the BBOARD and AUCTION benchmarks.",
                "We use two metrics to quantify the performance improvement obtainable through the use of Ganesh: throughput, from the perspective of the web server, and average response time, from the perspective of the client.",
                "Throughput is measured in terms of the number of client requests that can be serviced per second. 5.1 BBOARD Results and Analysis 5.1.1 Authoring Mix Figures 6 (a) and (b) present the average number of requests serviced per second and the average response time for these requests as perceived by the clients for BBOARDs Authoring Mix.",
                "As Figure 6 (a) shows, Native easily saturates the 5 Mb/s link.",
                "At 400 clients, the Native solution delivers 29 requests/sec with an average response time of 8.3 seconds.",
                "Natives throughput drops with an increase in test clients as clients timeout due to congestion at the application server.",
                "Usability studies have shown that response times above 10 seconds cause the user to move on to 1 As Java lacks a sizeof() operator, Java caches therefore limit their size based on the number of objects.",
                "The size of cache dumps taken at the end of the experiments never exceeded 212 MB.",
                "WWW 2007 / Track: Performance and Scalability Session: Scalable Systems for Dynamic Content 315 0 50 100 150 200 250 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Test Clients Requests/sec Native Ganesh 0.001 0.01 0.1 1 10 100 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Test Clients Avg.Resp.Time(sec) Native Ganesh Note Logscale (a) Throughput: Authoring Mix (b) Response Time: Authoring Mix 0 50 100 150 200 250 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Test Clients Requests/sec Native Ganesh 0.001 0.01 0.1 1 10 100 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Test Clients Avg.Resp.Time(sec) Native Ganesh Note Logscale (c) Throughput: Browsing Mix (d) Response Time: Browsing Mix Mean of three trials.",
                "The maximum standard deviation for throughput and response time was 9.8% and 11.9% of the corresponding mean.",
                "Figure 6: BBOARD Benchmark - Throughput and Average Response Time other tasks [24].",
                "Based on these numbers, increasing the number of test clients makes the Native system unusable.",
                "Ganesh at 5 Mb/s, however, delivers a twofold improvement with 400 test clients and a fivefold improvement at 1200 clients.",
                "Ganeshs performance drops slightly at 1200 and 1600 clients as the network is saturated.",
                "Compared to Native, Figure 6 (b) shows that Ganeshs response times are substantially lower with sub-second response times at 400 clients.",
                "Figure 6 (a) also shows that for 400 and 800 test clients Ganesh at 5 Mb/s has the same throughput and average response time as Native at 20 Mb/s.",
                "Only at 1200 and 1600 clients does Native at 20 Mb/s deliver higher throughput than Ganesh at 5 Mb/s.",
                "Comparing both Ganesh and Native at 20 Mb/s, we see that Ganesh is no longer bandwidth constrained and delivers up to a twofold improvement over Native at 1600 test clients.",
                "As Ganesh does not saturate the network with higher test client configurations, at 1600 test clients, its average response time is 0.1 seconds rather than Natives 7.7 seconds.",
                "As expected, there are no visible gains from Ganesh at the higher bandwidth of 100 Mb/s where the network is no longer the bottleneck.",
                "Ganesh, however, still tracks Native in terms of throughput. 5.1.2 Browsing Mix Figures 6 (c) and (d) present the average number of requests serviced per second and the average response time for these requests as perceived by the clients for BBOARDs Browsing Mix.",
                "Regardless of the test client configuration, Figure 6 (c) shows that Natives throughput at 5 Mb/s is limited to 10 reqs/sec.",
                "Ganesh at 5 Mb/s with 400 test clients, delivers more than a sixfold increase in throughput.",
                "The improvement increases to over a elevenfold increase at 800 test clients before Ganesh saturates the network.",
                "Further, Figure 6 (d) shows that Natives average response time of 35 seconds at 400 test clients make the system unusable.",
                "These high response times further increase with the addition of test clients.",
                "Even with the 1600 test client configuration Ganesh delivers an acceptable average response time of 8.2 seconds.",
                "Due to the data-intensive nature of the Browsing mix, Ganesh at 5 Mb/s surprisingly performs much better than Native at 20 Mb/s.",
                "Further, as shown in Figure 6 (d), while the average response time for Native at 20 Mb/s is acceptable at 400 test clients, it is unusable with 800 test clients with an average response time of 15.8 seconds.",
                "Like the 5 Mb/s case, this response time increases with the addition of extra test clients.",
                "Ganesh at 20 Mb/s and both Native and Ganesh at 100 Mb/s are not bandwidth limited.",
                "However, performance plateaus out after 1200 test clients due to the database CPU being saturated. 5.1.3 Filter Variant We were surprised by the Native performance from the BBOARD benchmark.",
                "At the bandwidth of 5 Mb/s, Native performance was lower than what we had expected.",
                "It turned out the benchmark code that displays stories read all the comments associated with the particular story from the database and only then did some postprocessing to select the comments to be displayed.",
                "While this is exactly the behavior of SlashCode, the code base behind the Slashdot web site, we decided to modify the benchmark to perform some pre-filtering at the database.",
                "This modified benchmark, named the Filter Variant, models a developer who applies optimizations at the SQL level to transfer less data.",
                "In the interests of brevity, we only briefly summarize the results from the Authoring mix.",
                "For the Authoring mix, at 800 test clients at 5 Mb/s, Figure 7 (a) shows that Natives throughput increase by 85% when compared to the original benchmark while Ganeshs improvement is smaller at 15%.",
                "Natives performance drops above 800 clients as the test clients time out due to high response times.",
                "The most significant gain for Native is seen at 20 Mb/s.",
                "At 1600 test clients, when compared to the original benchmark, Native sees a 73% improvement in throughput and a 77% reduction in average response time.",
                "While WWW 2007 / Track: Performance and Scalability Session: Scalable Systems for Dynamic Content 316 0 50 100 150 200 250 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Test Clients Requests/sec Native Ganesh 0.001 0.01 0.1 1 10 100 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Test Clients Avg.Resp.Time(sec) Native Ganesh Note Logscale (a) Throughput: Authoring Mix (b) Response Time: Authoring Mix Mean of three trials.",
                "The maximum standard deviation for throughput and response time was 7.2% and 11.5% of the corresponding mean.",
                "Figure 7: BBOARD Benchmark - Filter Variant - Throughput and Average Response Time Ganesh sees no improvement when compared to the original, it still processes 19% more requests/sec than Native.",
                "Thus, while the optimizations were more helpful to Native, Ganesh still delivers an improvement in performance. 5.2 AUCTION Results and Analysis 5.2.1 Bidding Mix Figures 8 (a) and (b) present the average number of requests serviced per second and the average response time for these requests as perceived by the clients for AUCTIONs Bidding Mix.",
                "As mentioned earlier, the Bidding mix consists of a mixture of read and write operations.",
                "The AUCTION benchmark is not as data intensive as BBOARD.",
                "Therefore, most of the gains are observed at the lower bandwidth of 5 Mb/s.",
                "Figure 8 (a) shows that the increase in throughput due to Ganesh ranges from 8% at 400 test clients to 18% with 1600 test clients.",
                "As seen in Figure 8 (b), the average response times for Ganesh are significantly lower than Native ranging from a decrease of 84% at 800 test clients to 88% at 1600 test clients.",
                "Figure 8 (a) also shows that with a fourfold increase of bandwidth from 5 Mb/s to 20 Mb/s, Native is no longer bandwidth constrained and there is no performance difference between Ganesh and Native.",
                "With the higher test client configurations, we did observe that the bandwidth used by Ganesh was lower than Native.",
                "Ganesh might still be useful in these non-constrained scenarios if bandwidth is purchased on a metered basis.",
                "Similar results are seen for the 100 Mb/s scenario. 5.2.2 Browsing Mix For AUCTIONs Browsing Mix, Figures 8 (c) and (d) present the average number of requests serviced per second and the average response time for these requests as perceived by the clients.",
                "Again, most of the gains are observed at lower bandwidths.",
                "At 5 Mb/s, Native and Ganesh deliver similar throughput and response times with 400 test clients.",
                "While the throughput for both remains the same at 800 test clients, Figure 8 (d) shows that Ganeshs average response time is 62% lower than Native.",
                "Native saturates the link at 800 clients and adding extra test clients only increases the average response time.",
                "Ganesh, regardless of the test client configuration, is not bandwidth constrained and maintains the same response time.",
                "At 1600 test clients, Figure 8 (c) shows that Ganeshs throughput is almost twice that of Native.",
                "At the higher bandwidths of 20 and 100 Mb/s, neither Ganesh nor Native is bandwidth limited and deliver equivalent throughput and response times.",
                "Benchmark Orig.",
                "Size Ganesh Size Rabin Size SelectSort1 223.6 MB 5.4 MB 219.3 MB SelectSort2 223.6 MB 5.4 MB 223.6 MB Table 2: Similarity Microbenchmarks 6.",
                "STRUCTURAL VS. RABIN SIMILARITY In this section, we address the second question raised in Section 4: How important is Ganeshs structural similarity detection relative to Rabin fingerprinting-based similarity detecting?",
                "To answer this question, we used microbenchmarks and the BBOARD and AUCTION benchmarks.",
                "As Ganesh always performed better than Rabin fingerprinting, we only present a subset of the results here in the interests of brevity. 6.1 Microbenchmarks Two microbenchmarks show an example of the effects of data reordering on Rabin fingerprinting algorithm.",
                "In the first microbenchmark, SelectSort1, a query with a specified sort order selects 223.6 MB of data spread over approximately 280 K rows.",
                "The query is then repeated with a different sort attribute.",
                "While the same number of rows and the same data is returned, the order of rows is different.",
                "In such a scenario, one would expect a large amount of similarity to be detected between both results.",
                "As Table 2 shows, Ganeshs row-based algorithm achieves a 97.6% reduction while the Rabin fingerprinting algorithm, with the average chunk size parameter set to 4 KB, only achieves a 1% reduction.",
                "The reason, as shown earlier in Figure 2, is that with Rabin fingerprinting, the spans of data between two consecutive boundaries usually cross row boundaries.",
                "With the order of the rows changing in the second result and the Rabin fingerprints now spanning different rows, the algorithm is unable to detect significant similarity.",
                "The small gain seen is mostly for those single rows that are large enough to be broken into multiple chunks.",
                "SelectSort2, another micro-benchmark executed the same queries but increased the minimum chunk size of the Rabin fingerprinting algorithm.",
                "As can be seen in Table 2, even the small gain from the previous microbenchmark disappears as the minimum chunk size was greater than the average row size.",
                "While one can partially address these problems by dynamically varying the parameters of the Rabin fingerprinting algorithm, this can be computationally expensive, especially in the presence of changing workloads. 6.2 Application Benchmarks We ran the BBOARD benchmark described in Section 4.1.1 on two versions of Ganesh: the first with Rabin fingerprinting used as WWW 2007 / Track: Performance and Scalability Session: Scalable Systems for Dynamic Content 317 0 50 100 150 200 250 300 350 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Test Clients Requests/sec Native Ganesh 0.001 0.01 0.1 1 10 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Test Clients Avg.Resp.Time(sec) Native Ganesh Note Logscale (a) Throughput: Bidding Mix (b) Response Time: Bidding Mix 0 50 100 150 200 250 300 350 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Test Clients Requests/sec Native Ganesh 0.001 0.01 0.1 1 10 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Test Clients Avg.Resp.Time(sec) Native Ganesh Note Logscale (c) Throughput: Browsing Mix (d) Response Time: Browsing Mix Mean of three trials.",
                "The maximum standard deviation for throughput and response time was 2.2% and 11.8% of the corresponding mean.",
                "Figure 8: AUCTION Benchmark - Throughput and Average Response Time the chunking algorithm and the second with Ganeshs row-based algorithm.",
                "Rabins results for the Browsing Mix are normalized to Ganeshs results and presented in Figure 9.",
                "As Figure 9 (a) shows, at 5 Mb/s, independent of the test client configuration, Rabin significantly underperforms Ganesh.",
                "This happens because of a combination of two reasons.",
                "First, as outlined in Section 3.1, Rabin finds less similarity as it does not exploit the results structural information.",
                "Second, this benchmark contained some queries that generated large results.",
                "In this case, Rabin, with a small average chunk size, generated a large number of objects that evicted other useful data from the cache.",
                "In contrast, Ganesh was able to detect these large rows and correspondingly increase the size of the chunks.",
                "This was confirmed as cache statistics showed that Ganeshs hit ratio was roughly three time that of Rabin.",
                "Throughput measurements at 20 Mb/s were similar with the exception of Rabins performance with 400 test clients.",
                "In this case, Ganesh was not network limited and, in fact, the throughput was the same as 400 clients at 5 Mb/s.",
                "Rabin, however, took advantage of the bandwidth increase from 5 to 20 Mb/s to deliver a slightly better performance.",
                "At 100 Mb/s, Rabins throughput was almost similar to Ganesh as bandwidth was no longer a bottleneck.",
                "The normalized response time, presented in Figure 9 (b), shows similar trends.",
                "At 5 and 20 Mb/s, the addition of test clients decreases the normalized response time as Ganeshs average response time increases faster than Rabins.",
                "However, at no point does Rabin outperform Ganesh.",
                "Note that at 400 and 800 clients at 100 Mb/s, Rabin does have a higher overhead even when it is not bandwidth constrained.",
                "As mentioned in Section 3.1, this is due to the fact that Rabin has to hash each ResultSet twice.",
                "The overhead disappears with 1200 and 1600 clients as the database CPU is saturated and limits the performance of both Ganesh and Rabin. 7.",
                "PROXY OVERHEAD In this section, we address the third question raised in Section 4: Is the overhead of Ganeshs proxy-based design acceptable?",
                "To answer this question, we concentrate on its performance at the higher bandwidths.",
                "Our evaluation in Section 5 showed that Ganesh, when compared to Native, can deliver a substantial throughput improvement at lower bandwidths.",
                "It is only at higher bandwidths that latency, measured by the average response time for a client request, and throughput, measured by the number of client requests that can be serviced per second, overheads would be visible.",
                "Looking at the Authoring mix of the original BBOARD benchmark, there are no visible gains from Ganesh at 100 Mb/s.",
                "Ganesh, however, still tracks Native in terms of throughput.",
                "While the average response time is higher for Ganesh, the absolute difference is in between 0.01 and 0.04 seconds and would be imperceptible to the end-user.",
                "The Browsing mix shows an even smaller difference in average response times.",
                "The results from the filter variant of the BBOARD benchmarks are similar.",
                "Even for the AUCTION benchmark, the difference between Native and Ganeshs response time at 100 Mb/s was never greater than 0.02 seconds.",
                "The only exception to the above results was seen in the filter variant of the BBOARD benchmark where Ganesh at 1600 test clients added 0.85 seconds to the average response time.",
                "Thus, even for much faster networks where the WAN link is not the bottleneck, Ganesh always delivers throughput equivalent to Native.",
                "While some extra latency is added by the proxy-based design, it is usually imperceptible. 8.",
                "RELATED WORK To the best of our knowledge, Ganesh is the first system that combines the use of hash-based techniques with caching of database results to improve throughput and response times for applications with dynamic content.",
                "We also believe that it is also the first system to demonstrate the benefits of using structural information for WWW 2007 / Track: Performance and Scalability Session: Scalable Systems for Dynamic Content 318 0.0 0.2 0.4 0.6 0.8 1.0 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Test Clients Norm.Throughput 31.8 3.8 2.8 2.3 23.8 32.8 5.8 3.6 1.8 2.1 1.1 1.0 0 5 10 15 20 25 30 35 400 800 1200 1600 400 800 1200 1600 400 800 1200 1600 5 Mb/s 20 Mb/s 100 Mb/s Test Clients Norm.ResponseTime (a) Normalized Throughput: Higher is better (b) Normalized Response Time: Higher is worse For throughput, a normalized result greater than 1 implies that Rabin is better, For response time, a normalized result greater than 1 implies that Ganesh is better.",
                "Mean of three trials.",
                "The maximum standard deviation for throughput and response time was 9.1% and 13.9% of the corresponding mean.",
                "Figure 9: Normalized Comparison of Ganesh vs. Rabin - BBOARD Browsing Mix detecting similarity.",
                "In this section, we first discuss alternative approaches to caching dynamic content and then examine other uses of hash-based primitives in distributed systems. 8.1 Caching Dynamic Content At the database layer, a number of systems have advocated middletier caching where parts of the database are replicated at the edge or server [3, 4, 20].",
                "These systems either cache entire tables in what is essentially a replicated database or use materialized views from previous query replies [19].",
                "They require tight integration with the back-end database to ensure a time bound on the propagation of updates.",
                "These systems are also usually targeted towards workloads that do not require strict consistency and can tolerate stale data.",
                "Further, unlike Ganesh, some of these mid-tier caching solutions [2, 3], suffer from the complexity of having to participate in query planing and distributed query processing.",
                "Gao et al. [15] propose using a distributed object replication architecture where the data stores consistency requirements are adapted on a per-application basis.",
                "These solutions require substantial developer resources and detailed understanding of the application being modified.",
                "While systems that attempt to automate the partitioning and replication of an applications database exist [34], they do not provide full transaction semantics.",
                "In comparison, Ganesh does not weaken any of the semantics provided by the underlying database.",
                "Recent work in the evaluation of edge caching options for dynamic web sites [38] has suggested that, without careful planning, employing complex offloading strategies can hurt performance.",
                "Instead, the work advocates for an architecture in which all tiers except the database should be offloaded to the edge.",
                "Our evaluation of Ganesh has shown that it would benefit these scenarios.",
                "To improve database scalability, C-JDBC [10], SSS [22], and Ganymed [28] also advocate the use of an interposition-based architecture to transparently cluster and replicate databases at the middleware level.",
                "The approaches of these architectures and Ganesh are complementary and they would benefit each other.",
                "Moving up to the presentation layer, there has been widespread adoption of fragment-based caching [14], which improves cache utilization by separately caching different parts of generated web pages.",
                "While fragment-based caching works at the edge, a recent proposal has proposed moving web page assembly to the clients to optimize content delivery [31].",
                "While Ganesh is not used at the presentation layer, the same principles have been applied in Duplicate Transfer Detection [25] to increase web cache efficiency as well as for web access across bandwidth limited links [33]. 8.2 Hash-based Systems The past few years have seen the emergence of many systems that exploit hash-based techniques.",
                "At the heart of all these systems is the idea of detecting similarity in data without requiring interpretation of that data.",
                "This simple yet elegant idea relies on cryptographic hashing, as discussed earlier in Section 2.",
                "Successful applications of this idea span a wide range of storage systems.",
                "Examples include peer-to-peer backup of personal computing files [11], storage-efficient archiving of data [29], and finding similar files [21].",
                "Spring and Wetherall [35] apply similar principles at the network level.",
                "Using synchronized caches at both ends of a network link, duplicated data is replaced by smaller tokens for transmission and then restored at the remote end.",
                "This and other hash-based systems such as the CASPER [37] and LBFS [26] filesystems, and Layer-2 bandwidth optimizers such as Riverbed and Peribit use Rabin fingerprinting [30] to discover spans of commonality in data.",
                "This approach is especially useful when data items are modified in-place through insertions, deletions, and updates.",
                "However, as Section 6 shows, the performance of this technique can show a dramatic drop in the presence of data reordering.",
                "Ganesh instead uses row boundaries as dividers for detecting similarity.",
                "The most aggressive use of hash-based techniques is by systems that use hashes as the primary identifiers for objects in persistent storage.",
                "Storage systems such as CFS [12] and PAST [13] that have been built using distributed hash tables fall into this category.",
                "Single Instance Storage [6] and Venti [29] are other examples of such systems.",
                "As discussed in Section 2.2, the use of cryptographic hashes for addressing persistent data represents a deeper level of faith in their collision-resistance than that assumed by Ganesh.",
                "If time reveals shortcomings in the hash algorithm, the effort involved in correcting the flaw is much greater.",
                "In Ganesh, it is merely a matter of replacing the hash algorithm. 9.",
                "CONCLUSION The growing use of dynamic web content generated from relational databases places increased demands on WAN bandwidth.",
                "Traditional caching solutions for bandwidth and latency reduction are often ineffective for such content.",
                "This paper shows that the impact of WAN accesses to databases can be substantially reduced through the Ganesh architecture without any compromise of the databases strict consistency semantics.",
                "The essence of the Ganesh architecture is the use of computation at the edges to reduce communication through the Internet.",
                "Ganesh is able to use cryptographic hashes to detect similarity with previous results and send WWW 2007 / Track: Performance and Scalability Session: Scalable Systems for Dynamic Content 319 compact recipes of results rather than full results.",
                "Our design uses interposition to achieve complete transparency: clients, application servers, and database servers are all unaware of Ganeshs presence and require no modification.",
                "Our experimental evaluation confirms that Ganesh, while conceptually simple, can be highly effective in improving throughput and response time.",
                "Our results also confirm that exploiting the structure present in database results to detect similarity is crucial to this performance improvement. 10.",
                "REFERENCES [1] AKELLA, A., SESHAN, S., AND SHAIKH, A.",
                "An empirical evaluation of wide-area internet bottlenecks.",
                "In Proc. 3rd ACM SIGCOMM Conference on Internet Measurement (Miami Beach, FL, USA, Oct. 2003), pp. 101-114. [2] ALTINEL, M., BORNH ¨OVD, C., KRISHNAMURTHY, S., MOHAN, C., PIRAHESH, H., AND REINWALD, B. Cache tables: Paving the way for an adaptive database cache.",
                "In Proc. of 29th VLDB (Berlin, Germany, 2003), pp. 718-729. [3] ALTINEL, M., LUO, Q., KRISHNAMURTHY, S., MOHAN, C., PIRAHESH, H., LINDSAY, B. G., WOO, H., AND BROWN, L. Dbcache: Database caching for web application servers.",
                "In Proc. 2002 ACM SIGMOD (2002), pp. 612-612. [4] AMIRI, K., PARK, S., TEWARI, R., AND PADMANABHAN, S. Dbproxy: A dynamic data cache for web applications.",
                "In Proc.",
                "IEEE International Conference on Data Engineering (ICDE) (Mar. 2003). [5] BLACK, J. Compare-by-hash: A reasoned analysis.",
                "In Proc. 2006 USENIX Annual Technical Conference (Boston, MA, May 2006), pp. 85-90. [6] BOLOSKY, W. J., CORBIN, S., GOEBEL, D., , AND DOUCEUR, J. R. Single instance storage in windows 2000.",
                "In Proc. 4th USENIX Windows Systems Symposium (Seattle, WA, Aug. 2000), pp. 13-24. [7] BREWER, E. A.",
                "Lessons from giant-scale services.",
                "IEEE Internet Computing 5, 4 (2001), 46-55. [8] BRODER, A., GLASSMAN, S., MANASSE, M., AND ZWEIG, G. Syntactic clustering of the web.",
                "In Proc. 6th International WWW Conference (1997). [9] CECCHET, E., CHANDA, A., ELNIKETY, S., MARGUERITE, J., AND ZWAENEPOEL, W. Performance comparison of middleware architectures for generating dynamic web content.",
                "In Proc.",
                "Fourth ACM/IFIP/USENIX International Middleware Conference (Rio de Janeiro, Brazil, June 2003). [10] CECCHET, E., MARGUERITE, J., AND ZWAENEPOEL, W. C-JDBC: Flexible database clustering middleware.",
                "In Proc. 2004 USENIX Annual Technical Conference (Boston, MA, June 2004). [11] COX, L. P., MURRAY, C. D., AND NOBLE, B. D. Pastiche: Making backup cheap and easy.",
                "In OSDI: Symposium on Operating Systems Design and Implementation (2002). [12] DABEK, F., KAASHOEK, M. F., KARGER, D., MORRIS, R., AND STOICA, I. Wide-area cooperative storage with CFS.",
                "In 18th ACM Symposium on Operating Systems Principles (Banff, Canada, Oct. 2001). [13] DRUSCHEL, P., AND ROWSTRON, A.",
                "PAST: A large-scale, persistent peer-to-peer storage utility.",
                "In HotOS VIII (Schloss Elmau, Germany, May 2001), pp. 75-80. [14] Edge side includes. http://www.esi.org. [15] GAO, L., DAHLIN, M., NAYATE, A., ZHENG, J., AND IYENGAR, A.",
                "Application specific data replication for edge services.",
                "In WWW 03: Proc.",
                "Twelfth International Conference on World Wide Web (2003), pp. 449-460. [16] HEMMINGER, S. Netem - emulating real networks in the lab.",
                "In Proc. 2005 Linux Conference Australia (Canberra, Australia, Apr. 2005). [17] HENSON, V. An analysis of compare-by-hash.",
                "In Proc. 9th Workshop on Hot Topics in Operating Systems (HotOS IX) (May 2003), pp. 13-18. [18] Jmob benchmarks. http://jmob.objectweb.org/. [19] LABRINIDIS, A., AND ROUSSOPOULOS, N. Balancing performance and data freshness in web database servers.",
                "In Proc. 29th VLDB Conference (Sept. 2003). [20] LARSON, P.-A., GOLDSTEIN, J., AND ZHOU, J. Transparent mid-tier database caching in sql server.",
                "In Proc. 2003 ACM SIGMOD (2003), pp. 661-661. [21] MANBER, U.",
                "Finding similar files in a large file system.",
                "In Proc.",
                "USENIX Winter 1994 Technical Conference (San Fransisco, CA, 17-21 1994), pp. 1-10. [22] MANJHI, A., AILAMAKI, A., MAGGS, B. M., MOWRY, T. C., OLSTON, C., AND TOMASIC, A.",
                "Simultaneous scalability and security for data-intensive web applications.",
                "In Proc. 2006 ACM SIGMOD (June 2006), pp. 241-252. [23] MENEZES, A. J., VANSTONE, S. A., AND OORSCHOT, P. C. V. Handbook of Applied Cryptography.",
                "CRC Press, 1996. [24] MILLER, R. B.",
                "Response time in man-computer conversational transactions.",
                "In Proc.",
                "AFIPS Fall Joint Computer Conference (1968), pp. 267-277. [25] MOGUL, J. C., CHAN, Y. M., AND KELLY, T. Design, implementation, and evaluation of duplicate transfer detection in http.",
                "In Proc.",
                "First Symposium on Networked Systems Design and Implementation (San Francisco, CA, Mar. 2004). [26] MUTHITACHAROEN, A., CHEN, B., AND MAZIERES, D. A low-bandwidth network file system.",
                "In Proc. 18th ACM Symposium on Operating Systems Principles (Banff, Canada, Oct. 2001). [27] PFEIFER, D., AND JAKSCHITSCH, H. Method-based caching in multi-tiered server applications.",
                "In Proc.",
                "Fifth International Symposium on Distributed Objects and Applications (Catania, Sicily, Italy, Nov. 2003). [28] PLATTNER, C., AND ALONSO, G. Ganymed: Scalable replication for transactional web applications.",
                "In Proc. 5th ACM/IFIP/USENIX International Conference on Middleware (2004), pp. 155-174. [29] QUINLAN, S., AND DORWARD, S. Venti: A new approach to archival storage.",
                "In Proc.",
                "FAST 2002 Conference on File and Storage Technologies (2002). [30] RABIN, M. Fingerprinting by random polynomials.",
                "In Harvard University Center for Research in Computing Technology Technical Report TR-15-81 (1981). [31] RABINOVICH, M., XIAO, Z., DOUGLIS, F., AND KALMANEK, C. Moving edge side includes to the real edge - the clients.",
                "In Proc. 4th USENIX Symposium on Internet Technologies and Systems (Seattle, WA, Mar. 2003). [32] REESE, G. Database Programming with JDBC and Java, 1st ed.",
                "OReilly, June 1997. [33] RHEA, S., LIANG, K., AND BREWER, E. Value-based web caching.",
                "In Proc.",
                "Twelfth International World Wide Web Conference (May 2003). [34] SIVASUBRAMANIAN, S., ALONSO, G., PIERRE, G., AND VAN STEEN, M. Globedb: Autonomic data replication for web applications.",
                "In WWW 05: Proc. 14th International World-Wide Web conference (May 2005). [35] SPRING, N. T., AND WETHERALL, D. A protocol-independent technique for eliminating redundant network traffic.",
                "In Proc. of ACM SIGCOMM (Aug. 2000). [36] TOLIA, N., HARKES, J., KOZUCH, M., AND SATYANARAYANAN, M. Integrating portable and distributed storage.",
                "In Proc. 3rd USENIX Conference on File and Storage Technologies (San Francisco, CA, Mar. 2004). [37] TOLIA, N., KOZUCH, M., SATYANARAYANAN, M., KARP, B., PERRIG, A., AND BRESSOUD, T. Opportunistic use of content addressable storage for distributed file systems.",
                "In Proc. 2003 USENIX Annual Technical Conference (San Antonio, TX, June 2003), pp. 127-140. [38] YUAN, C., CHEN, Y., AND ZHANG, Z.",
                "Evaluation of edge caching/offloading for dynamic content delivery.",
                "In WWW 03: Proc.",
                "Twelfth International Conference on World Wide Web (2003), pp. 461-471.",
                "WWW 2007 / Track: Performance and Scalability Session: Scalable Systems for Dynamic Content 320"
            ],
            "original_annotated_samples": [],
            "translated_annotated_samples": [],
            "translated_text": "",
            "candidates": [],
            "error": [
                []
            ]
        }
    }
}