{
    "id": "S0098300413002720",
    "original_text": "Artificial Neural Networks (ANN) have been widely used in science and engineering problems. They attempt to model the ability of biological nervous systems to recognize patterns and objects. ANN basic architecture consists of networks of primitive functions capable of receiving multiple weighted inputs that are evaluated in terms of their success at discriminating the classes in Τa. Different types of primitive functions and network configurations result in varying models (Hastie et al., 2009; Rojas, 1996). During training network connection weights are adjusted if the separation of inputs and predefined classes incurs an error. Convergence proceeds until the reduction in error between iterations reaches a decay threshold (Kotsiantis, 2007; Rojas, 1996). We use feed-forward networks with a single hidden layer of nodes, a so called Multi-Layer Perceptron (MLP) (Venables and Ripley, 2002), and select one of two possible parameters: size, the number nodes in the hidden layer.",
    "original_translation": "Las Redes Neuronales Artificiales (RNA) han sido ampliamente utilizadas en problemas de ciencia e ingeniería. Intentan modelar la capacidad de los sistemas nerviosos biológicos para reconocer patrones y objetos. La arquitectura básica de ANN consiste en redes de funciones primitivas capaces de recibir múltiples entradas ponderadas que se evalúan en función de su éxito en discriminar las clases en Τa. Diferentes tipos de funciones primitivas y configuraciones de red resultan en modelos variados (Hastie et al., 2009; Rojas, 1996). Durante el entrenamiento, los pesos de la conexión de la red se ajustan si la separación de las entradas y las clases predefinidas incurre en un error. La convergencia continúa hasta que la reducción del error entre iteraciones alcanza un umbral de decaimiento (Kotsiantis, 2007; Rojas, 1996). Utilizamos redes de retroalimentación con una sola capa oculta de nodos, un Perceptrón Multicapa (MLP) (Venables y Ripley, 2002), y seleccionamos uno de dos posibles parámetros: tamaño, el número de nodos en la capa oculta.",
    "original_sentences": [
        "Artificial Neural Networks (ANN) have been widely used in science and engineering problems.",
        "They attempt to model the ability of biological nervous systems to recognize patterns and objects.",
        "ANN basic architecture consists of networks of primitive functions capable of receiving multiple weighted inputs that are evaluated in terms of their success at discriminating the classes in Τa.",
        "Different types of primitive functions and network configurations result in varying models (Hastie et al., 2009; Rojas, 1996).",
        "During training network connection weights are adjusted if the separation of inputs and predefined classes incurs an error.",
        "Convergence proceeds until the reduction in error between iterations reaches a decay threshold (Kotsiantis, 2007; Rojas, 1996).",
        "We use feed-forward networks with a single hidden layer of nodes, a so called Multi-Layer Perceptron (MLP) (Venables and Ripley, 2002), and select one of two possible parameters: size, the number nodes in the hidden layer."
    ],
    "error_count": 0,
    "keys": {
        "adjusted if the separation of inputs and predefined classes incurs an error": {
            "translated_key": "ajustan si la separación de las entradas y las clases predefinidas incurre en un error",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Artificial Neural Networks (ANN) have been widely used in science and engineering problems.",
                "They attempt to model the ability of biological nervous systems to recognize patterns and objects.",
                "ANN basic architecture consists of networks of primitive functions capable of receiving multiple weighted inputs that are evaluated in terms of their success at discriminating the classes in Τa.",
                "Different types of primitive functions and network configurations result in varying models (Hastie et al., 2009; Rojas, 1996).",
                "During training network connection weights are <br>adjusted if the separation of inputs and predefined classes incurs an error</br>.",
                "Convergence proceeds until the reduction in error between iterations reaches a decay threshold (Kotsiantis, 2007; Rojas, 1996).",
                "We use feed-forward networks with a single hidden layer of nodes, a so called Multi-Layer Perceptron (MLP) (Venables and Ripley, 2002), and select one of two possible parameters: size, the number nodes in the hidden layer."
            ],
            "original_annotated_samples": [
                "During training network connection weights are <br>adjusted if the separation of inputs and predefined classes incurs an error</br>."
            ],
            "translated_annotated_samples": [
                "Output: Durante el entrenamiento, los pesos de conexión de la red se <br>ajustan si la separación de las entradas y las clases predefinidas incurre en un error</br>."
            ],
            "translated_text": "Las Redes Neuronales Artificiales (RNA) han sido ampliamente utilizadas en problemas de ciencia e ingeniería. Intentan modelar la capacidad de los sistemas nerviosos biológicos para reconocer patrones y objetos. La arquitectura básica de ANN consiste en redes de funciones primitivas capaces de recibir múltiples entradas ponderadas que se evalúan en función de su éxito en discriminar las clases en Τa. Diferentes tipos de funciones primitivas y configuraciones de red resultan en modelos variados (Hastie et al., 2009; Rojas, 1996). Output: Durante el entrenamiento, los pesos de conexión de la red se <br>ajustan si la separación de las entradas y las clases predefinidas incurre en un error</br>. La convergencia continúa hasta que la reducción del error entre iteraciones alcanza un umbral de decaimiento (Kotsiantis, 2007; Rojas, 1996). Utilizamos redes de retroalimentación con una sola capa oculta de nodos, un Perceptrón Multicapa (MLP) (Venables y Ripley, 2002), y seleccionamos uno de dos posibles parámetros: tamaño, el número de nodos en la capa oculta. ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "ANN": {
            "translated_key": "ANN",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Artificial Neural Networks (<br>ANN</br>) have been widely used in science and engineering problems.",
                "They attempt to model the ability of biological nervous systems to recognize patterns and objects.",
                "<br>ANN</br> basic architecture consists of networks of primitive functions capable of receiving multiple weighted inputs that are evaluated in terms of their success at discriminating the classes in Τa.",
                "Different types of primitive functions and network configurations result in varying models (Hastie et al., 2009; Rojas, 1996).",
                "During training network connection weights are adjusted if the separation of inputs and predefined classes incurs an error.",
                "Convergence proceeds until the reduction in error between iterations reaches a decay threshold (Kotsiantis, 2007; Rojas, 1996).",
                "We use feed-forward networks with a single hidden layer of nodes, a so called Multi-Layer Perceptron (MLP) (Venables and Ripley, 2002), and select one of two possible parameters: size, the number nodes in the hidden layer."
            ],
            "original_annotated_samples": [
                "Artificial Neural Networks (<br>ANN</br>) have been widely used in science and engineering problems.",
                "<br>ANN</br> basic architecture consists of networks of primitive functions capable of receiving multiple weighted inputs that are evaluated in terms of their success at discriminating the classes in Τa."
            ],
            "translated_annotated_samples": [
                "Output: Las Redes Neuronales Artificiales (<br>ANN</br>) han sido ampliamente utilizadas en problemas de ciencia e ingeniería.",
                "Output: La arquitectura básica de <br>ANN</br> consiste en redes de funciones primitivas capaces de recibir múltiples entradas ponderadas que se evalúan en términos de su éxito en discriminar las clases en Τa."
            ],
            "translated_text": "Output: Las Redes Neuronales Artificiales (<br>ANN</br>) han sido ampliamente utilizadas en problemas de ciencia e ingeniería. Intentan modelar la capacidad de los sistemas nerviosos biológicos para reconocer patrones y objetos. Output: La arquitectura básica de <br>ANN</br> consiste en redes de funciones primitivas capaces de recibir múltiples entradas ponderadas que se evalúan en términos de su éxito en discriminar las clases en Τa. Diferentes tipos de funciones primitivas y configuraciones de red resultan en modelos variados (Hastie et al., 2009; Rojas, 1996). Durante el entrenamiento, los pesos de la conexión de la red se ajustan si la separación de las entradas y las clases predefinidas incurre en un error. La convergencia continúa hasta que la reducción del error entre iteraciones alcanza un umbral de decaimiento (Kotsiantis, 2007; Rojas, 1996). Utilizamos redes de retroalimentación con una sola capa oculta de nodos, un Perceptrón Multicapa (MLP) (Venables y Ripley, 2002), y seleccionamos uno de dos posibles parámetros: tamaño, el número de nodos en la capa oculta. ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "ANN basic architecture": {
            "translated_key": "arquitectura básica de ANN",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Artificial Neural Networks (ANN) have been widely used in science and engineering problems.",
                "They attempt to model the ability of biological nervous systems to recognize patterns and objects.",
                "<br>ANN basic architecture</br> consists of networks of primitive functions capable of receiving multiple weighted inputs that are evaluated in terms of their success at discriminating the classes in Τa.",
                "Different types of primitive functions and network configurations result in varying models (Hastie et al., 2009; Rojas, 1996).",
                "During training network connection weights are adjusted if the separation of inputs and predefined classes incurs an error.",
                "Convergence proceeds until the reduction in error between iterations reaches a decay threshold (Kotsiantis, 2007; Rojas, 1996).",
                "We use feed-forward networks with a single hidden layer of nodes, a so called Multi-Layer Perceptron (MLP) (Venables and Ripley, 2002), and select one of two possible parameters: size, the number nodes in the hidden layer."
            ],
            "original_annotated_samples": [
                "<br>ANN basic architecture</br> consists of networks of primitive functions capable of receiving multiple weighted inputs that are evaluated in terms of their success at discriminating the classes in Τa."
            ],
            "translated_annotated_samples": [
                "Output: La <br>arquitectura básica de ANN</br> consiste en redes de funciones primitivas capaces de recibir múltiples entradas ponderadas que se evalúan en términos de su éxito en discriminar las clases en Τa."
            ],
            "translated_text": "Las Redes Neuronales Artificiales (RNA) han sido ampliamente utilizadas en problemas de ciencia e ingeniería. Intentan modelar la capacidad de los sistemas nerviosos biológicos para reconocer patrones y objetos. Output: La <br>arquitectura básica de ANN</br> consiste en redes de funciones primitivas capaces de recibir múltiples entradas ponderadas que se evalúan en términos de su éxito en discriminar las clases en Τa. Diferentes tipos de funciones primitivas y configuraciones de red resultan en modelos variados (Hastie et al., 2009; Rojas, 1996). Durante el entrenamiento, los pesos de la conexión de la red se ajustan si la separación de las entradas y las clases predefinidas incurre en un error. La convergencia continúa hasta que la reducción del error entre iteraciones alcanza un umbral de decaimiento (Kotsiantis, 2007; Rojas, 1996). Utilizamos redes de retroalimentación con una sola capa oculta de nodos, un Perceptrón Multicapa (MLP) (Venables y Ripley, 2002), y seleccionamos uno de dos posibles parámetros: tamaño, el número de nodos en la capa oculta. ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "Artificial Neural Networks": {
            "translated_key": "Las Redes Neuronales Artificiales",
            "is_in_text": true,
            "original_annotated_sentences": [
                "<br>Artificial Neural Networks</br> (ANN) have been widely used in science and engineering problems.",
                "They attempt to model the ability of biological nervous systems to recognize patterns and objects.",
                "ANN basic architecture consists of networks of primitive functions capable of receiving multiple weighted inputs that are evaluated in terms of their success at discriminating the classes in Τa.",
                "Different types of primitive functions and network configurations result in varying models (Hastie et al., 2009; Rojas, 1996).",
                "During training network connection weights are adjusted if the separation of inputs and predefined classes incurs an error.",
                "Convergence proceeds until the reduction in error between iterations reaches a decay threshold (Kotsiantis, 2007; Rojas, 1996).",
                "We use feed-forward networks with a single hidden layer of nodes, a so called Multi-Layer Perceptron (MLP) (Venables and Ripley, 2002), and select one of two possible parameters: size, the number nodes in the hidden layer."
            ],
            "original_annotated_samples": [
                "<br>Artificial Neural Networks</br> (ANN) have been widely used in science and engineering problems."
            ],
            "translated_annotated_samples": [
                "Output: <br>Las Redes Neuronales Artificiales</br> (RNA) han sido ampliamente utilizadas en problemas de ciencia e ingeniería."
            ],
            "translated_text": "Output: <br>Las Redes Neuronales Artificiales</br> (RNA) han sido ampliamente utilizadas en problemas de ciencia e ingeniería. Intentan modelar la capacidad de los sistemas nerviosos biológicos para reconocer patrones y objetos. La arquitectura básica de ANN consiste en redes de funciones primitivas capaces de recibir múltiples entradas ponderadas que se evalúan en función de su éxito en discriminar las clases en Τa. Diferentes tipos de funciones primitivas y configuraciones de red resultan en modelos variados (Hastie et al., 2009; Rojas, 1996). Durante el entrenamiento, los pesos de la conexión de la red se ajustan si la separación de las entradas y las clases predefinidas incurre en un error. La convergencia continúa hasta que la reducción del error entre iteraciones alcanza un umbral de decaimiento (Kotsiantis, 2007; Rojas, 1996). Utilizamos redes de retroalimentación con una sola capa oculta de nodos, un Perceptrón Multicapa (MLP) (Venables y Ripley, 2002), y seleccionamos uno de dos posibles parámetros: tamaño, el número de nodos en la capa oculta. ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "Convergence": {
            "translated_key": "La convergencia",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Artificial Neural Networks (ANN) have been widely used in science and engineering problems.",
                "They attempt to model the ability of biological nervous systems to recognize patterns and objects.",
                "ANN basic architecture consists of networks of primitive functions capable of receiving multiple weighted inputs that are evaluated in terms of their success at discriminating the classes in Τa.",
                "Different types of primitive functions and network configurations result in varying models (Hastie et al., 2009; Rojas, 1996).",
                "During training network connection weights are adjusted if the separation of inputs and predefined classes incurs an error.",
                "<br>Convergence</br> proceeds until the reduction in error between iterations reaches a decay threshold (Kotsiantis, 2007; Rojas, 1996).",
                "We use feed-forward networks with a single hidden layer of nodes, a so called Multi-Layer Perceptron (MLP) (Venables and Ripley, 2002), and select one of two possible parameters: size, the number nodes in the hidden layer."
            ],
            "original_annotated_samples": [
                "<br>Convergence</br> proceeds until the reduction in error between iterations reaches a decay threshold (Kotsiantis, 2007; Rojas, 1996)."
            ],
            "translated_annotated_samples": [
                "Output: <br>La convergencia</br> continúa hasta que la reducción del error entre las iteraciones alcanza un umbral de decaimiento (Kotsiantis, 2007; Rojas, 1996)."
            ],
            "translated_text": "Las Redes Neuronales Artificiales (RNA) han sido ampliamente utilizadas en problemas de ciencia e ingeniería. Intentan modelar la capacidad de los sistemas nerviosos biológicos para reconocer patrones y objetos. La arquitectura básica de ANN consiste en redes de funciones primitivas capaces de recibir múltiples entradas ponderadas que se evalúan en función de su éxito en discriminar las clases en Τa. Diferentes tipos de funciones primitivas y configuraciones de red resultan en modelos variados (Hastie et al., 2009; Rojas, 1996). Durante el entrenamiento, los pesos de la conexión de la red se ajustan si la separación de las entradas y las clases predefinidas incurre en un error. Output: <br>La convergencia</br> continúa hasta que la reducción del error entre las iteraciones alcanza un umbral de decaimiento (Kotsiantis, 2007; Rojas, 1996). Utilizamos redes de retroalimentación con una sola capa oculta de nodos, un Perceptrón Multicapa (MLP) (Venables y Ripley, 2002), y seleccionamos uno de dos posibles parámetros: tamaño, el número de nodos en la capa oculta. ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "Different types of primitive functions and network configurations": {
            "translated_key": "Diferentes tipos de funciones primitivas y configuraciones de red",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Artificial Neural Networks (ANN) have been widely used in science and engineering problems.",
                "They attempt to model the ability of biological nervous systems to recognize patterns and objects.",
                "ANN basic architecture consists of networks of primitive functions capable of receiving multiple weighted inputs that are evaluated in terms of their success at discriminating the classes in Τa.",
                "<br>Different types of primitive functions and network configurations</br> result in varying models (Hastie et al., 2009; Rojas, 1996).",
                "During training network connection weights are adjusted if the separation of inputs and predefined classes incurs an error.",
                "Convergence proceeds until the reduction in error between iterations reaches a decay threshold (Kotsiantis, 2007; Rojas, 1996).",
                "We use feed-forward networks with a single hidden layer of nodes, a so called Multi-Layer Perceptron (MLP) (Venables and Ripley, 2002), and select one of two possible parameters: size, the number nodes in the hidden layer."
            ],
            "original_annotated_samples": [
                "<br>Different types of primitive functions and network configurations</br> result in varying models (Hastie et al., 2009; Rojas, 1996)."
            ],
            "translated_annotated_samples": [
                "Output: <br>Diferentes tipos de funciones primitivas y configuraciones de red</br> resultan en modelos variables (Hastie et al., 2009; Rojas, 1996)."
            ],
            "translated_text": "Las Redes Neuronales Artificiales (RNA) han sido ampliamente utilizadas en problemas de ciencia e ingeniería. Intentan modelar la capacidad de los sistemas nerviosos biológicos para reconocer patrones y objetos. La arquitectura básica de ANN consiste en redes de funciones primitivas capaces de recibir múltiples entradas ponderadas que se evalúan en función de su éxito en discriminar las clases en Τa. Output: <br>Diferentes tipos de funciones primitivas y configuraciones de red</br> resultan en modelos variables (Hastie et al., 2009; Rojas, 1996). Durante el entrenamiento, los pesos de la conexión de la red se ajustan si la separación de las entradas y las clases predefinidas incurre en un error. La convergencia continúa hasta que la reducción del error entre iteraciones alcanza un umbral de decaimiento (Kotsiantis, 2007; Rojas, 1996). Utilizamos redes de retroalimentación con una sola capa oculta de nodos, un Perceptrón Multicapa (MLP) (Venables y Ripley, 2002), y seleccionamos uno de dos posibles parámetros: tamaño, el número de nodos en la capa oculta. ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "feed-forward networks with a single hidden layer of nodes": {
            "translated_key": "redes de retroalimentación con una sola capa oculta de nodos",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Artificial Neural Networks (ANN) have been widely used in science and engineering problems.",
                "They attempt to model the ability of biological nervous systems to recognize patterns and objects.",
                "ANN basic architecture consists of networks of primitive functions capable of receiving multiple weighted inputs that are evaluated in terms of their success at discriminating the classes in Τa.",
                "Different types of primitive functions and network configurations result in varying models (Hastie et al., 2009; Rojas, 1996).",
                "During training network connection weights are adjusted if the separation of inputs and predefined classes incurs an error.",
                "Convergence proceeds until the reduction in error between iterations reaches a decay threshold (Kotsiantis, 2007; Rojas, 1996).",
                "We use <br>feed-forward networks with a single hidden layer of nodes</br>, a so called Multi-Layer Perceptron (MLP) (Venables and Ripley, 2002), and select one of two possible parameters: size, the number nodes in the hidden layer."
            ],
            "original_annotated_samples": [
                "We use <br>feed-forward networks with a single hidden layer of nodes</br>, a so called Multi-Layer Perceptron (MLP) (Venables and Ripley, 2002), and select one of two possible parameters: size, the number nodes in the hidden layer."
            ],
            "translated_annotated_samples": [
                "Output: Utilizamos <br>redes de retroalimentación con una sola capa oculta de nodos</br>, un Perceptrón Multicapa (MLP) (Venables y Ripley, 2002), y seleccionamos uno de dos posibles parámetros: tamaño, el número de nodos en la capa oculta."
            ],
            "translated_text": "Las Redes Neuronales Artificiales (RNA) han sido ampliamente utilizadas en problemas de ciencia e ingeniería. Intentan modelar la capacidad de los sistemas nerviosos biológicos para reconocer patrones y objetos. La arquitectura básica de ANN consiste en redes de funciones primitivas capaces de recibir múltiples entradas ponderadas que se evalúan en función de su éxito en discriminar las clases en Τa. Diferentes tipos de funciones primitivas y configuraciones de red resultan en modelos variados (Hastie et al., 2009; Rojas, 1996). Durante el entrenamiento, los pesos de la conexión de la red se ajustan si la separación de las entradas y las clases predefinidas incurre en un error. La convergencia continúa hasta que la reducción del error entre iteraciones alcanza un umbral de decaimiento (Kotsiantis, 2007; Rojas, 1996). Output: Utilizamos <br>redes de retroalimentación con una sola capa oculta de nodos</br>, un Perceptrón Multicapa (MLP) (Venables y Ripley, 2002), y seleccionamos uno de dos posibles parámetros: tamaño, el número de nodos en la capa oculta. ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "MLP": {
            "translated_key": "MLP",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Artificial Neural Networks (ANN) have been widely used in science and engineering problems.",
                "They attempt to model the ability of biological nervous systems to recognize patterns and objects.",
                "ANN basic architecture consists of networks of primitive functions capable of receiving multiple weighted inputs that are evaluated in terms of their success at discriminating the classes in Τa.",
                "Different types of primitive functions and network configurations result in varying models (Hastie et al., 2009; Rojas, 1996).",
                "During training network connection weights are adjusted if the separation of inputs and predefined classes incurs an error.",
                "Convergence proceeds until the reduction in error between iterations reaches a decay threshold (Kotsiantis, 2007; Rojas, 1996).",
                "We use feed-forward networks with a single hidden layer of nodes, a so called Multi-Layer Perceptron (<br>MLP</br>) (Venables and Ripley, 2002), and select one of two possible parameters: size, the number nodes in the hidden layer."
            ],
            "original_annotated_samples": [
                "We use feed-forward networks with a single hidden layer of nodes, a so called Multi-Layer Perceptron (<br>MLP</br>) (Venables and Ripley, 2002), and select one of two possible parameters: size, the number nodes in the hidden layer."
            ],
            "translated_annotated_samples": [
                "Output: Utilizamos redes de alimentación directa con una sola capa oculta de nodos, una llamada Perceptrón Multicapa (<br>MLP</br>) (Venables y Ripley, 2002), y seleccionamos uno de dos posibles parámetros: tamaño, el número de nodos en la capa oculta."
            ],
            "translated_text": "Las Redes Neuronales Artificiales (RNA) han sido ampliamente utilizadas en problemas de ciencia e ingeniería. Intentan modelar la capacidad de los sistemas nerviosos biológicos para reconocer patrones y objetos. La arquitectura básica de ANN consiste en redes de funciones primitivas capaces de recibir múltiples entradas ponderadas que se evalúan en función de su éxito en discriminar las clases en Τa. Diferentes tipos de funciones primitivas y configuraciones de red resultan en modelos variados (Hastie et al., 2009; Rojas, 1996). Durante el entrenamiento, los pesos de la conexión de la red se ajustan si la separación de las entradas y las clases predefinidas incurre en un error. La convergencia continúa hasta que la reducción del error entre iteraciones alcanza un umbral de decaimiento (Kotsiantis, 2007; Rojas, 1996). Output: Utilizamos redes de alimentación directa con una sola capa oculta de nodos, una llamada Perceptrón Multicapa (<br>MLP</br>) (Venables y Ripley, 2002), y seleccionamos uno de dos posibles parámetros: tamaño, el número de nodos en la capa oculta. ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "model the ability of biological nervous systems to recognize patterns and objects": {
            "translated_key": "modelar la capacidad de los sistemas nerviosos biológicos para reconocer patrones y objetos",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Artificial Neural Networks (ANN) have been widely used in science and engineering problems.",
                "They attempt to <br>model the ability of biological nervous systems to recognize patterns and objects</br>.",
                "ANN basic architecture consists of networks of primitive functions capable of receiving multiple weighted inputs that are evaluated in terms of their success at discriminating the classes in Τa.",
                "Different types of primitive functions and network configurations result in varying models (Hastie et al., 2009; Rojas, 1996).",
                "During training network connection weights are adjusted if the separation of inputs and predefined classes incurs an error.",
                "Convergence proceeds until the reduction in error between iterations reaches a decay threshold (Kotsiantis, 2007; Rojas, 1996).",
                "We use feed-forward networks with a single hidden layer of nodes, a so called Multi-Layer Perceptron (MLP) (Venables and Ripley, 2002), and select one of two possible parameters: size, the number nodes in the hidden layer."
            ],
            "original_annotated_samples": [
                "They attempt to <br>model the ability of biological nervous systems to recognize patterns and objects</br>."
            ],
            "translated_annotated_samples": [
                "Output: Intentan <br>modelar la capacidad de los sistemas nerviosos biológicos para reconocer patrones y objetos</br>."
            ],
            "translated_text": "Las Redes Neuronales Artificiales (RNA) han sido ampliamente utilizadas en problemas de ciencia e ingeniería. Output: Intentan <br>modelar la capacidad de los sistemas nerviosos biológicos para reconocer patrones y objetos</br>. La arquitectura básica de ANN consiste en redes de funciones primitivas capaces de recibir múltiples entradas ponderadas que se evalúan en función de su éxito en discriminar las clases en Τa. Diferentes tipos de funciones primitivas y configuraciones de red resultan en modelos variados (Hastie et al., 2009; Rojas, 1996). Durante el entrenamiento, los pesos de la conexión de la red se ajustan si la separación de las entradas y las clases predefinidas incurre en un error. La convergencia continúa hasta que la reducción del error entre iteraciones alcanza un umbral de decaimiento (Kotsiantis, 2007; Rojas, 1996). Utilizamos redes de retroalimentación con una sola capa oculta de nodos, un Perceptrón Multicapa (MLP) (Venables y Ripley, 2002), y seleccionamos uno de dos posibles parámetros: tamaño, el número de nodos en la capa oculta. ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "Multi-Layer Perceptron": {
            "translated_key": "Perceptrón Multi-Capa",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Artificial Neural Networks (ANN) have been widely used in science and engineering problems.",
                "They attempt to model the ability of biological nervous systems to recognize patterns and objects.",
                "ANN basic architecture consists of networks of primitive functions capable of receiving multiple weighted inputs that are evaluated in terms of their success at discriminating the classes in Τa.",
                "Different types of primitive functions and network configurations result in varying models (Hastie et al., 2009; Rojas, 1996).",
                "During training network connection weights are adjusted if the separation of inputs and predefined classes incurs an error.",
                "Convergence proceeds until the reduction in error between iterations reaches a decay threshold (Kotsiantis, 2007; Rojas, 1996).",
                "We use feed-forward networks with a single hidden layer of nodes, a so called <br>Multi-Layer Perceptron</br> (MLP) (Venables and Ripley, 2002), and select one of two possible parameters: size, the number nodes in the hidden layer."
            ],
            "original_annotated_samples": [
                "We use feed-forward networks with a single hidden layer of nodes, a so called <br>Multi-Layer Perceptron</br> (MLP) (Venables and Ripley, 2002), and select one of two possible parameters: size, the number nodes in the hidden layer."
            ],
            "translated_annotated_samples": [
                "Output: Utilizamos redes de alimentación directa con una sola capa oculta de nodos, un llamado <br>Perceptrón Multi-Capa</br> (MLP) (Venables y Ripley, 2002), y seleccionamos uno de dos posibles parámetros: tamaño, el número de nodos en la capa oculta."
            ],
            "translated_text": "Las Redes Neuronales Artificiales (RNA) han sido ampliamente utilizadas en problemas de ciencia e ingeniería. Intentan modelar la capacidad de los sistemas nerviosos biológicos para reconocer patrones y objetos. La arquitectura básica de ANN consiste en redes de funciones primitivas capaces de recibir múltiples entradas ponderadas que se evalúan en función de su éxito en discriminar las clases en Τa. Diferentes tipos de funciones primitivas y configuraciones de red resultan en modelos variados (Hastie et al., 2009; Rojas, 1996). Durante el entrenamiento, los pesos de la conexión de la red se ajustan si la separación de las entradas y las clases predefinidas incurre en un error. La convergencia continúa hasta que la reducción del error entre iteraciones alcanza un umbral de decaimiento (Kotsiantis, 2007; Rojas, 1996). Output: Utilizamos redes de alimentación directa con una sola capa oculta de nodos, un llamado <br>Perceptrón Multi-Capa</br> (MLP) (Venables y Ripley, 2002), y seleccionamos uno de dos posibles parámetros: tamaño, el número de nodos en la capa oculta. ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "networks of primitive functions": {
            "translated_key": "redes de funciones primitivas",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Artificial Neural Networks (ANN) have been widely used in science and engineering problems.",
                "They attempt to model the ability of biological nervous systems to recognize patterns and objects.",
                "ANN basic architecture consists of <br>networks of primitive functions</br> capable of receiving multiple weighted inputs that are evaluated in terms of their success at discriminating the classes in Τa.",
                "Different types of primitive functions and network configurations result in varying models (Hastie et al., 2009; Rojas, 1996).",
                "During training network connection weights are adjusted if the separation of inputs and predefined classes incurs an error.",
                "Convergence proceeds until the reduction in error between iterations reaches a decay threshold (Kotsiantis, 2007; Rojas, 1996).",
                "We use feed-forward networks with a single hidden layer of nodes, a so called Multi-Layer Perceptron (MLP) (Venables and Ripley, 2002), and select one of two possible parameters: size, the number nodes in the hidden layer."
            ],
            "original_annotated_samples": [
                "ANN basic architecture consists of <br>networks of primitive functions</br> capable of receiving multiple weighted inputs that are evaluated in terms of their success at discriminating the classes in Τa."
            ],
            "translated_annotated_samples": [
                "Output: La arquitectura básica de las ANN consiste en <br>redes de funciones primitivas</br> capaces de recibir múltiples entradas ponderadas que se evalúan en términos de su éxito en discriminar las clases en Τa."
            ],
            "translated_text": "Las Redes Neuronales Artificiales (RNA) han sido ampliamente utilizadas en problemas de ciencia e ingeniería. Intentan modelar la capacidad de los sistemas nerviosos biológicos para reconocer patrones y objetos. Output: La arquitectura básica de las ANN consiste en <br>redes de funciones primitivas</br> capaces de recibir múltiples entradas ponderadas que se evalúan en términos de su éxito en discriminar las clases en Τa. Diferentes tipos de funciones primitivas y configuraciones de red resultan en modelos variados (Hastie et al., 2009; Rojas, 1996). Durante el entrenamiento, los pesos de la conexión de la red se ajustan si la separación de las entradas y las clases predefinidas incurre en un error. La convergencia continúa hasta que la reducción del error entre iteraciones alcanza un umbral de decaimiento (Kotsiantis, 2007; Rojas, 1996). Utilizamos redes de retroalimentación con una sola capa oculta de nodos, un Perceptrón Multicapa (MLP) (Venables y Ripley, 2002), y seleccionamos uno de dos posibles parámetros: tamaño, el número de nodos en la capa oculta. ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "receiving multiple weighted inputs": {
            "translated_key": "recibir múltiples entradas ponderadas",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Artificial Neural Networks (ANN) have been widely used in science and engineering problems.",
                "They attempt to model the ability of biological nervous systems to recognize patterns and objects.",
                "ANN basic architecture consists of networks of primitive functions capable of <br>receiving multiple weighted inputs</br> that are evaluated in terms of their success at discriminating the classes in Τa.",
                "Different types of primitive functions and network configurations result in varying models (Hastie et al., 2009; Rojas, 1996).",
                "During training network connection weights are adjusted if the separation of inputs and predefined classes incurs an error.",
                "Convergence proceeds until the reduction in error between iterations reaches a decay threshold (Kotsiantis, 2007; Rojas, 1996).",
                "We use feed-forward networks with a single hidden layer of nodes, a so called Multi-Layer Perceptron (MLP) (Venables and Ripley, 2002), and select one of two possible parameters: size, the number nodes in the hidden layer."
            ],
            "original_annotated_samples": [
                "ANN basic architecture consists of networks of primitive functions capable of <br>receiving multiple weighted inputs</br> that are evaluated in terms of their success at discriminating the classes in Τa."
            ],
            "translated_annotated_samples": [
                "Output: La arquitectura básica de las ANN consiste en redes de funciones primitivas capaces de <br>recibir múltiples entradas ponderadas</br> que se evalúan en términos de su éxito en discriminar las clases en Τa."
            ],
            "translated_text": "Las Redes Neuronales Artificiales (RNA) han sido ampliamente utilizadas en problemas de ciencia e ingeniería. Intentan modelar la capacidad de los sistemas nerviosos biológicos para reconocer patrones y objetos. Output: La arquitectura básica de las ANN consiste en redes de funciones primitivas capaces de <br>recibir múltiples entradas ponderadas</br> que se evalúan en términos de su éxito en discriminar las clases en Τa. Diferentes tipos de funciones primitivas y configuraciones de red resultan en modelos variados (Hastie et al., 2009; Rojas, 1996). Durante el entrenamiento, los pesos de la conexión de la red se ajustan si la separación de las entradas y las clases predefinidas incurre en un error. La convergencia continúa hasta que la reducción del error entre iteraciones alcanza un umbral de decaimiento (Kotsiantis, 2007; Rojas, 1996). Utilizamos redes de retroalimentación con una sola capa oculta de nodos, un Perceptrón Multicapa (MLP) (Venables y Ripley, 2002), y seleccionamos uno de dos posibles parámetros: tamaño, el número de nodos en la capa oculta. ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "science and engineering problems": {
            "translated_key": "problemas de ciencia e ingeniería",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Artificial Neural Networks (ANN) have been widely used in <br>science and engineering problems</br>.",
                "They attempt to model the ability of biological nervous systems to recognize patterns and objects.",
                "ANN basic architecture consists of networks of primitive functions capable of receiving multiple weighted inputs that are evaluated in terms of their success at discriminating the classes in Τa.",
                "Different types of primitive functions and network configurations result in varying models (Hastie et al., 2009; Rojas, 1996).",
                "During training network connection weights are adjusted if the separation of inputs and predefined classes incurs an error.",
                "Convergence proceeds until the reduction in error between iterations reaches a decay threshold (Kotsiantis, 2007; Rojas, 1996).",
                "We use feed-forward networks with a single hidden layer of nodes, a so called Multi-Layer Perceptron (MLP) (Venables and Ripley, 2002), and select one of two possible parameters: size, the number nodes in the hidden layer."
            ],
            "original_annotated_samples": [
                "Artificial Neural Networks (ANN) have been widely used in <br>science and engineering problems</br>."
            ],
            "translated_annotated_samples": [
                "Output: Las Redes Neuronales Artificiales (ANN) se han utilizado ampliamente en <br>problemas de ciencia e ingeniería</br>."
            ],
            "translated_text": "Output: Las Redes Neuronales Artificiales (ANN) se han utilizado ampliamente en <br>problemas de ciencia e ingeniería</br>. Intentan modelar la capacidad de los sistemas nerviosos biológicos para reconocer patrones y objetos. La arquitectura básica de ANN consiste en redes de funciones primitivas capaces de recibir múltiples entradas ponderadas que se evalúan en función de su éxito en discriminar las clases en Τa. Diferentes tipos de funciones primitivas y configuraciones de red resultan en modelos variados (Hastie et al., 2009; Rojas, 1996). Durante el entrenamiento, los pesos de la conexión de la red se ajustan si la separación de las entradas y las clases predefinidas incurre en un error. La convergencia continúa hasta que la reducción del error entre iteraciones alcanza un umbral de decaimiento (Kotsiantis, 2007; Rojas, 1996). Utilizamos redes de retroalimentación con una sola capa oculta de nodos, un Perceptrón Multicapa (MLP) (Venables y Ripley, 2002), y seleccionamos uno de dos posibles parámetros: tamaño, el número de nodos en la capa oculta. ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "select one of two possible parameters": {
            "translated_key": "seleccionamos uno de dos posibles parámetros",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Artificial Neural Networks (ANN) have been widely used in science and engineering problems.",
                "They attempt to model the ability of biological nervous systems to recognize patterns and objects.",
                "ANN basic architecture consists of networks of primitive functions capable of receiving multiple weighted inputs that are evaluated in terms of their success at discriminating the classes in Τa.",
                "Different types of primitive functions and network configurations result in varying models (Hastie et al., 2009; Rojas, 1996).",
                "During training network connection weights are adjusted if the separation of inputs and predefined classes incurs an error.",
                "Convergence proceeds until the reduction in error between iterations reaches a decay threshold (Kotsiantis, 2007; Rojas, 1996).",
                "We use feed-forward networks with a single hidden layer of nodes, a so called Multi-Layer Perceptron (MLP) (Venables and Ripley, 2002), and <br>select one of two possible parameters</br>: size, the number nodes in the hidden layer."
            ],
            "original_annotated_samples": [
                "We use feed-forward networks with a single hidden layer of nodes, a so called Multi-Layer Perceptron (MLP) (Venables and Ripley, 2002), and <br>select one of two possible parameters</br>: size, the number nodes in the hidden layer."
            ],
            "translated_annotated_samples": [
                "Output: Utilizamos redes de avance con una sola capa oculta de nodos, una llamada Perceptrón Multicapa (MLP) (Venables y Ripley, 2002), y <br>seleccionamos uno de dos posibles parámetros</br>: tamaño, el número de nodos en la capa oculta."
            ],
            "translated_text": "Las Redes Neuronales Artificiales (RNA) han sido ampliamente utilizadas en problemas de ciencia e ingeniería. Intentan modelar la capacidad de los sistemas nerviosos biológicos para reconocer patrones y objetos. La arquitectura básica de ANN consiste en redes de funciones primitivas capaces de recibir múltiples entradas ponderadas que se evalúan en función de su éxito en discriminar las clases en Τa. Diferentes tipos de funciones primitivas y configuraciones de red resultan en modelos variados (Hastie et al., 2009; Rojas, 1996). Durante el entrenamiento, los pesos de la conexión de la red se ajustan si la separación de las entradas y las clases predefinidas incurre en un error. La convergencia continúa hasta que la reducción del error entre iteraciones alcanza un umbral de decaimiento (Kotsiantis, 2007; Rojas, 1996). Output: Utilizamos redes de avance con una sola capa oculta de nodos, una llamada Perceptrón Multicapa (MLP) (Venables y Ripley, 2002), y <br>seleccionamos uno de dos posibles parámetros</br>: tamaño, el número de nodos en la capa oculta. ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "the reduction in error between iterations reaches a decay threshold": {
            "translated_key": "la reducción del error entre las iteraciones alcanza un umbral de decaimiento",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Artificial Neural Networks (ANN) have been widely used in science and engineering problems.",
                "They attempt to model the ability of biological nervous systems to recognize patterns and objects.",
                "ANN basic architecture consists of networks of primitive functions capable of receiving multiple weighted inputs that are evaluated in terms of their success at discriminating the classes in Τa.",
                "Different types of primitive functions and network configurations result in varying models (Hastie et al., 2009; Rojas, 1996).",
                "During training network connection weights are adjusted if the separation of inputs and predefined classes incurs an error.",
                "Convergence proceeds until <br>the reduction in error between iterations reaches a decay threshold</br> (Kotsiantis, 2007; Rojas, 1996).",
                "We use feed-forward networks with a single hidden layer of nodes, a so called Multi-Layer Perceptron (MLP) (Venables and Ripley, 2002), and select one of two possible parameters: size, the number nodes in the hidden layer."
            ],
            "original_annotated_samples": [
                "Convergence proceeds until <br>the reduction in error between iterations reaches a decay threshold</br> (Kotsiantis, 2007; Rojas, 1996)."
            ],
            "translated_annotated_samples": [
                "Output: La convergencia continúa hasta que <br>la reducción del error entre las iteraciones alcanza un umbral de decaimiento</br> (Kotsiantis, 2007; Rojas, 1996)."
            ],
            "translated_text": "Las Redes Neuronales Artificiales (RNA) han sido ampliamente utilizadas en problemas de ciencia e ingeniería. Intentan modelar la capacidad de los sistemas nerviosos biológicos para reconocer patrones y objetos. La arquitectura básica de ANN consiste en redes de funciones primitivas capaces de recibir múltiples entradas ponderadas que se evalúan en función de su éxito en discriminar las clases en Τa. Diferentes tipos de funciones primitivas y configuraciones de red resultan en modelos variados (Hastie et al., 2009; Rojas, 1996). Durante el entrenamiento, los pesos de la conexión de la red se ajustan si la separación de las entradas y las clases predefinidas incurre en un error. Output: La convergencia continúa hasta que <br>la reducción del error entre las iteraciones alcanza un umbral de decaimiento</br> (Kotsiantis, 2007; Rojas, 1996). Utilizamos redes de retroalimentación con una sola capa oculta de nodos, un Perceptrón Multicapa (MLP) (Venables y Ripley, 2002), y seleccionamos uno de dos posibles parámetros: tamaño, el número de nodos en la capa oculta. ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "training network connection": {
            "translated_key": "entrenamiento de la conexión de la red",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Artificial Neural Networks (ANN) have been widely used in science and engineering problems.",
                "They attempt to model the ability of biological nervous systems to recognize patterns and objects.",
                "ANN basic architecture consists of networks of primitive functions capable of receiving multiple weighted inputs that are evaluated in terms of their success at discriminating the classes in Τa.",
                "Different types of primitive functions and network configurations result in varying models (Hastie et al., 2009; Rojas, 1996).",
                "During <br>training network connection</br> weights are adjusted if the separation of inputs and predefined classes incurs an error.",
                "Convergence proceeds until the reduction in error between iterations reaches a decay threshold (Kotsiantis, 2007; Rojas, 1996).",
                "We use feed-forward networks with a single hidden layer of nodes, a so called Multi-Layer Perceptron (MLP) (Venables and Ripley, 2002), and select one of two possible parameters: size, the number nodes in the hidden layer."
            ],
            "original_annotated_samples": [
                "During <br>training network connection</br> weights are adjusted if the separation of inputs and predefined classes incurs an error."
            ],
            "translated_annotated_samples": [
                "Output: Durante el <br>entrenamiento de la conexión de la red</br> se ajustan los pesos si la separación de las entradas y las clases predefinidas incurre en un error."
            ],
            "translated_text": "Las Redes Neuronales Artificiales (RNA) han sido ampliamente utilizadas en problemas de ciencia e ingeniería. Intentan modelar la capacidad de los sistemas nerviosos biológicos para reconocer patrones y objetos. La arquitectura básica de ANN consiste en redes de funciones primitivas capaces de recibir múltiples entradas ponderadas que se evalúan en función de su éxito en discriminar las clases en Τa. Diferentes tipos de funciones primitivas y configuraciones de red resultan en modelos variados (Hastie et al., 2009; Rojas, 1996). Output: Durante el <br>entrenamiento de la conexión de la red</br> se ajustan los pesos si la separación de las entradas y las clases predefinidas incurre en un error. La convergencia continúa hasta que la reducción del error entre iteraciones alcanza un umbral de decaimiento (Kotsiantis, 2007; Rojas, 1996). Utilizamos redes de retroalimentación con una sola capa oculta de nodos, un Perceptrón Multicapa (MLP) (Venables y Ripley, 2002), y seleccionamos uno de dos posibles parámetros: tamaño, el número de nodos en la capa oculta. ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        },
        "weights": {
            "translated_key": "pesos",
            "is_in_text": true,
            "original_annotated_sentences": [
                "Artificial Neural Networks (ANN) have been widely used in science and engineering problems.",
                "They attempt to model the ability of biological nervous systems to recognize patterns and objects.",
                "ANN basic architecture consists of networks of primitive functions capable of receiving multiple weighted inputs that are evaluated in terms of their success at discriminating the classes in Τa.",
                "Different types of primitive functions and network configurations result in varying models (Hastie et al., 2009; Rojas, 1996).",
                "During training network connection <br>weights</br> are adjusted if the separation of inputs and predefined classes incurs an error.",
                "Convergence proceeds until the reduction in error between iterations reaches a decay threshold (Kotsiantis, 2007; Rojas, 1996).",
                "We use feed-forward networks with a single hidden layer of nodes, a so called Multi-Layer Perceptron (MLP) (Venables and Ripley, 2002), and select one of two possible parameters: size, the number nodes in the hidden layer."
            ],
            "original_annotated_samples": [
                "During training network connection <br>weights</br> are adjusted if the separation of inputs and predefined classes incurs an error."
            ],
            "translated_annotated_samples": [
                "Output: Durante el entrenamiento de la conexión de red, los <br>pesos</br> se ajustan si la separación de las entradas y las clases predefinidas incurre en un error."
            ],
            "translated_text": "Las Redes Neuronales Artificiales (RNA) han sido ampliamente utilizadas en problemas de ciencia e ingeniería. Intentan modelar la capacidad de los sistemas nerviosos biológicos para reconocer patrones y objetos. La arquitectura básica de ANN consiste en redes de funciones primitivas capaces de recibir múltiples entradas ponderadas que se evalúan en función de su éxito en discriminar las clases en Τa. Diferentes tipos de funciones primitivas y configuraciones de red resultan en modelos variados (Hastie et al., 2009; Rojas, 1996). Output: Durante el entrenamiento de la conexión de red, los <br>pesos</br> se ajustan si la separación de las entradas y las clases predefinidas incurre en un error. La convergencia continúa hasta que la reducción del error entre iteraciones alcanza un umbral de decaimiento (Kotsiantis, 2007; Rojas, 1996). Utilizamos redes de retroalimentación con una sola capa oculta de nodos, un Perceptrón Multicapa (MLP) (Venables y Ripley, 2002), y seleccionamos uno de dos posibles parámetros: tamaño, el número de nodos en la capa oculta. ",
            "candidates": [],
            "error": [
                [
                    ""
                ]
            ]
        }
    }
}